import{S as ekt,i as okt,s as rkt,e as a,k as l,w as F,t as o,M as tkt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as akt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as pXr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function nkt(L){let g,v,p,m,_,d,h,Mo,mi,_f,rt,gi,hi,yA,uf,je,We,pi,yn,LA,Ln,xn,xA,_i,$n,$A,ui,bf,Ca;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Mo=o(`, make sure its
`),mi=a("code"),_f=o("model_type"),rt=o(" attribute is set to the same key you use when registering the config (here "),gi=a("code"),hi=o('"new-model"'),yA=o(")."),uf=l(),je=a("p"),We=o("Likewise, if your "),pi=a("code"),yn=o("NewModel"),LA=o(" is a subclass of "),Ln=a("a"),xn=o("PreTrainedModel"),xA=o(`, make sure its
`),_i=a("code"),$n=o("config_class"),$A=o(` attribute is set to the same class you use when registering the model (here
`),ui=a("code"),bf=o("NewModelConfig"),Ca=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var J$=s(p);m=r(J$,"NewModelConfig"),J$.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var bi=s(d);h=r(bi,"PretrainedConfig"),bi.forEach(t),Mo=r(Ae,`, make sure its
`),mi=n(Ae,"CODE",{});var Y$=s(mi);_f=r(Y$,"model_type"),Y$.forEach(t),rt=r(Ae," attribute is set to the same key you use when registering the config (here "),gi=n(Ae,"CODE",{});var K$=s(gi);hi=r(K$,'"new-model"'),K$.forEach(t),yA=r(Ae,")."),Ae.forEach(t),uf=i(Qe),je=n(Qe,"P",{});var Eo=s(je);We=r(Eo,"Likewise, if your "),pi=n(Eo,"CODE",{});var wa=s(pi);yn=r(wa,"NewModel"),wa.forEach(t),LA=r(Eo," is a subclass of "),Ln=n(Eo,"A",{href:!0});var Z$=s(Ln);xn=r(Z$,"PreTrainedModel"),Z$.forEach(t),xA=r(Eo,`, make sure its
`),_i=n(Eo,"CODE",{});var vf=s(_i);$n=r(vf,"config_class"),vf.forEach(t),$A=r(Eo,` attribute is set to the same class you use when registering the model (here
`),ui=n(Eo,"CODE",{});var ek=s(ui);bf=r(ek,"NewModelConfig"),ek.forEach(t),Ca=r(Eo,")."),Eo.forEach(t),this.h()},h(){c(Ln,"href","/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Mo),e(g,mi),e(mi,_f),e(g,rt),e(g,gi),e(gi,hi),e(g,yA),b(Qe,uf,Ae),b(Qe,je,Ae),e(je,We),e(je,pi),e(pi,yn),e(je,LA),e(je,Ln),e(Ln,xn),e(je,xA),e(je,_i),e(_i,$n),e(je,$A),e(je,ui),e(ui,bf),e(je,Ca)},d(Qe){Qe&&t(g),Qe&&t(uf),Qe&&t(je)}}}function skt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ikt(L){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function dkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ckt(L){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function fkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _kt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ukt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Tkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ekt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ckt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Akt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ykt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $kt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Skt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ikt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Okt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ukt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ykt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _St(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ESt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ASt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ySt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $St(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ISt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function USt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rRt(L){let g,v,p,m,_,d,h,Mo,mi,_f,rt,gi,hi,yA,uf,je,We,pi,yn,LA,Ln,xn,xA,_i,$n,$A,ui,bf,Ca,Qe,Ae,J$,bi,Y$,K$,Eo,wa,Z$,vf,ek,AOe,pqe,vi,Ff,_oe,kA,yOe,uoe,LOe,_qe,kn,xOe,boe,$Oe,kOe,voe,SOe,ROe,uqe,SA,bqe,ok,POe,vqe,Tf,Fqe,Fi,Mf,Foe,RA,BOe,Toe,IOe,Tqe,Co,PA,NOe,BA,qOe,rk,jOe,DOe,GOe,IA,OOe,Moe,VOe,XOe,zOe,Er,NA,WOe,Eoe,QOe,HOe,Ti,UOe,Coe,JOe,YOe,woe,KOe,ZOe,eVe,A,Ef,Aoe,oVe,rVe,tk,tVe,aVe,nVe,Cf,yoe,sVe,lVe,ak,iVe,dVe,cVe,wf,Loe,fVe,mVe,nk,gVe,hVe,pVe,Af,xoe,_Ve,uVe,sk,bVe,vVe,FVe,yf,$oe,TVe,MVe,lk,EVe,CVe,wVe,Lf,koe,AVe,yVe,ik,LVe,xVe,$Ve,xf,Soe,kVe,SVe,dk,RVe,PVe,BVe,$f,Roe,IVe,NVe,ck,qVe,jVe,DVe,kf,Poe,GVe,OVe,fk,VVe,XVe,zVe,Sf,Boe,WVe,QVe,mk,HVe,UVe,JVe,Rf,Ioe,YVe,KVe,gk,ZVe,eXe,oXe,Pf,Noe,rXe,tXe,hk,aXe,nXe,sXe,Bf,qoe,lXe,iXe,pk,dXe,cXe,fXe,If,joe,mXe,gXe,_k,hXe,pXe,_Xe,Nf,Doe,uXe,bXe,uk,vXe,FXe,TXe,qf,Goe,MXe,EXe,bk,CXe,wXe,AXe,jf,Ooe,yXe,LXe,vk,xXe,$Xe,kXe,Df,Voe,SXe,RXe,Fk,PXe,BXe,IXe,Gf,Xoe,NXe,qXe,Tk,jXe,DXe,GXe,Of,zoe,OXe,VXe,Mk,XXe,zXe,WXe,Vf,Woe,QXe,HXe,Ek,UXe,JXe,YXe,Xf,Qoe,KXe,ZXe,Ck,eze,oze,rze,zf,Hoe,tze,aze,wk,nze,sze,lze,Wf,Uoe,ize,dze,Ak,cze,fze,mze,Qf,Joe,gze,hze,yk,pze,_ze,uze,Hf,Yoe,bze,vze,Lk,Fze,Tze,Mze,Uf,Koe,Eze,Cze,xk,wze,Aze,yze,Jf,Zoe,Lze,xze,$k,$ze,kze,Sze,Yf,ere,Rze,Pze,kk,Bze,Ize,Nze,Kf,ore,qze,jze,Sk,Dze,Gze,Oze,Zf,rre,Vze,Xze,Rk,zze,Wze,Qze,em,tre,Hze,Uze,Pk,Jze,Yze,Kze,om,are,Zze,eWe,Bk,oWe,rWe,tWe,rm,nre,aWe,nWe,Ik,sWe,lWe,iWe,tm,sre,dWe,cWe,Nk,fWe,mWe,gWe,am,lre,hWe,pWe,qk,_We,uWe,bWe,nm,ire,vWe,FWe,jk,TWe,MWe,EWe,sm,dre,CWe,wWe,Dk,AWe,yWe,LWe,lm,cre,xWe,$We,Gk,kWe,SWe,RWe,im,fre,PWe,BWe,Ok,IWe,NWe,qWe,dm,mre,jWe,DWe,Vk,GWe,OWe,VWe,cm,gre,XWe,zWe,Xk,WWe,QWe,HWe,fm,hre,UWe,JWe,zk,YWe,KWe,ZWe,mm,pre,eQe,oQe,Wk,rQe,tQe,aQe,gm,_re,nQe,sQe,Qk,lQe,iQe,dQe,hm,ure,cQe,fQe,Hk,mQe,gQe,hQe,pm,bre,pQe,_Qe,Uk,uQe,bQe,vQe,_m,vre,FQe,TQe,Jk,MQe,EQe,CQe,um,Fre,wQe,AQe,Yk,yQe,LQe,xQe,bm,Tre,$Qe,kQe,Kk,SQe,RQe,PQe,vm,Mre,BQe,IQe,Zk,NQe,qQe,jQe,Fm,Ere,DQe,GQe,eS,OQe,VQe,XQe,Tm,Cre,zQe,WQe,oS,QQe,HQe,UQe,Mm,wre,JQe,YQe,rS,KQe,ZQe,eHe,Em,Are,oHe,rHe,tS,tHe,aHe,nHe,Cm,yre,sHe,lHe,aS,iHe,dHe,cHe,wm,Lre,fHe,mHe,nS,gHe,hHe,pHe,Am,xre,_He,uHe,sS,bHe,vHe,FHe,ym,$re,THe,MHe,lS,EHe,CHe,wHe,Lm,kre,AHe,yHe,iS,LHe,xHe,$He,xm,Sre,kHe,SHe,dS,RHe,PHe,BHe,$m,Rre,IHe,NHe,cS,qHe,jHe,DHe,km,Pre,GHe,OHe,fS,VHe,XHe,zHe,Sm,Bre,WHe,QHe,mS,HHe,UHe,JHe,Rm,Ire,YHe,KHe,gS,ZHe,eUe,oUe,Pm,Nre,rUe,tUe,hS,aUe,nUe,sUe,Bm,qre,lUe,iUe,pS,dUe,cUe,fUe,Im,jre,mUe,gUe,_S,hUe,pUe,_Ue,Nm,Dre,uUe,bUe,uS,vUe,FUe,TUe,qm,Gre,MUe,EUe,bS,CUe,wUe,AUe,jm,Ore,yUe,LUe,vS,xUe,$Ue,kUe,Dm,Vre,SUe,RUe,FS,PUe,BUe,IUe,Gm,Xre,NUe,qUe,TS,jUe,DUe,GUe,Om,zre,OUe,VUe,MS,XUe,zUe,WUe,Vm,Wre,QUe,HUe,ES,UUe,JUe,YUe,Xm,Qre,KUe,ZUe,CS,eJe,oJe,rJe,zm,Hre,tJe,aJe,wS,nJe,sJe,lJe,Wm,Ure,iJe,dJe,AS,cJe,fJe,mJe,Qm,Jre,gJe,hJe,yS,pJe,_Je,uJe,Hm,Yre,bJe,vJe,LS,FJe,TJe,MJe,Um,Kre,EJe,CJe,xS,wJe,AJe,yJe,Jm,Zre,LJe,xJe,$S,$Je,kJe,SJe,Ym,ete,RJe,PJe,kS,BJe,IJe,NJe,Km,ote,qJe,jJe,SS,DJe,GJe,OJe,Zm,rte,VJe,XJe,RS,zJe,WJe,QJe,eg,tte,HJe,UJe,PS,JJe,YJe,KJe,og,ate,ZJe,eYe,BS,oYe,rYe,tYe,rg,nte,aYe,nYe,IS,sYe,lYe,iYe,tg,ste,dYe,cYe,NS,fYe,mYe,gYe,ag,lte,hYe,pYe,qS,_Ye,uYe,bYe,ng,ite,vYe,FYe,jS,TYe,MYe,EYe,sg,dte,CYe,wYe,DS,AYe,yYe,LYe,lg,cte,xYe,$Ye,GS,kYe,SYe,RYe,ig,fte,PYe,BYe,OS,IYe,NYe,qYe,dg,mte,jYe,DYe,VS,GYe,OYe,VYe,cg,gte,XYe,zYe,XS,WYe,QYe,HYe,fg,hte,UYe,JYe,zS,YYe,KYe,ZYe,mg,pte,eKe,oKe,WS,rKe,tKe,aKe,gg,_te,nKe,sKe,QS,lKe,iKe,dKe,hg,ute,cKe,fKe,HS,mKe,gKe,hKe,pg,bte,pKe,_Ke,US,uKe,bKe,vKe,_g,vte,FKe,TKe,JS,MKe,EKe,CKe,ug,Fte,wKe,AKe,YS,yKe,LKe,xKe,bg,Tte,$Ke,kKe,KS,SKe,RKe,PKe,vg,Mte,BKe,IKe,ZS,NKe,qKe,jKe,Fg,Ete,DKe,GKe,eR,OKe,VKe,XKe,Tg,Cte,zKe,WKe,oR,QKe,HKe,UKe,Mg,wte,JKe,YKe,rR,KKe,ZKe,eZe,Eg,Ate,oZe,rZe,tR,tZe,aZe,nZe,Cg,yte,sZe,lZe,aR,iZe,dZe,cZe,wg,fZe,Ag,qA,mZe,Lte,gZe,Mqe,Mi,yg,xte,jA,hZe,$te,pZe,Eqe,wo,DA,_Ze,GA,uZe,nR,bZe,vZe,FZe,OA,TZe,kte,MZe,EZe,CZe,Cr,VA,wZe,Ste,AZe,yZe,Aa,LZe,Rte,xZe,$Ze,Pte,kZe,SZe,Bte,RZe,PZe,BZe,k,Sn,Ite,IZe,NZe,sR,qZe,jZe,lR,DZe,GZe,OZe,Rn,Nte,VZe,XZe,iR,zZe,WZe,dR,QZe,HZe,UZe,Pn,qte,JZe,YZe,cR,KZe,ZZe,fR,eeo,oeo,reo,Lg,jte,teo,aeo,mR,neo,seo,leo,Bn,Dte,ieo,deo,gR,ceo,feo,hR,meo,geo,heo,xg,Gte,peo,_eo,pR,ueo,beo,veo,$g,Ote,Feo,Teo,_R,Meo,Eeo,Ceo,kg,Vte,weo,Aeo,uR,yeo,Leo,xeo,In,Xte,$eo,keo,bR,Seo,Reo,vR,Peo,Beo,Ieo,Nn,zte,Neo,qeo,FR,jeo,Deo,TR,Geo,Oeo,Veo,qn,Wte,Xeo,zeo,MR,Weo,Qeo,ER,Heo,Ueo,Jeo,Sg,Qte,Yeo,Keo,CR,Zeo,eoo,ooo,Rg,Hte,roo,too,wR,aoo,noo,soo,jn,Ute,loo,ioo,AR,doo,coo,yR,foo,moo,goo,Pg,Jte,hoo,poo,LR,_oo,uoo,boo,Dn,Yte,voo,Foo,xR,Too,Moo,$R,Eoo,Coo,woo,Gn,Kte,Aoo,yoo,kR,Loo,xoo,SR,$oo,koo,Soo,On,Zte,Roo,Poo,RR,Boo,Ioo,PR,Noo,qoo,joo,Vn,eae,Doo,Goo,BR,Ooo,Voo,IR,Xoo,zoo,Woo,Bg,oae,Qoo,Hoo,NR,Uoo,Joo,Yoo,Xn,rae,Koo,Zoo,qR,ero,oro,jR,rro,tro,aro,zn,tae,nro,sro,DR,lro,iro,GR,dro,cro,fro,Wn,aae,mro,gro,OR,hro,pro,VR,_ro,uro,bro,Qn,nae,vro,Fro,XR,Tro,Mro,zR,Ero,Cro,wro,Hn,sae,Aro,yro,WR,Lro,xro,QR,$ro,kro,Sro,Un,lae,Rro,Pro,HR,Bro,Iro,UR,Nro,qro,jro,Ig,iae,Dro,Gro,JR,Oro,Vro,Xro,Jn,dae,zro,Wro,YR,Qro,Hro,KR,Uro,Jro,Yro,Ng,cae,Kro,Zro,ZR,eto,oto,rto,Yn,fae,tto,ato,eP,nto,sto,oP,lto,ito,dto,Kn,mae,cto,fto,rP,mto,gto,tP,hto,pto,_to,Zn,gae,uto,bto,aP,vto,Fto,nP,Tto,Mto,Eto,qg,hae,Cto,wto,sP,Ato,yto,Lto,es,pae,xto,$to,lP,kto,Sto,iP,Rto,Pto,Bto,os,_ae,Ito,Nto,dP,qto,jto,cP,Dto,Gto,Oto,jg,uae,Vto,Xto,fP,zto,Wto,Qto,rs,bae,Hto,Uto,mP,Jto,Yto,gP,Kto,Zto,eao,ts,vae,oao,rao,hP,tao,aao,pP,nao,sao,lao,as,Fae,iao,dao,_P,cao,fao,uP,mao,gao,hao,ns,Tae,pao,_ao,bP,uao,bao,vP,vao,Fao,Tao,ss,Mae,Mao,Eao,FP,Cao,wao,TP,Aao,yao,Lao,ls,Eae,xao,$ao,MP,kao,Sao,EP,Rao,Pao,Bao,is,Cae,Iao,Nao,CP,qao,jao,wP,Dao,Gao,Oao,Dg,wae,Vao,Xao,AP,zao,Wao,Qao,ds,Aae,Hao,Uao,yP,Jao,Yao,LP,Kao,Zao,eno,Gg,yae,ono,rno,xP,tno,ano,nno,Og,Lae,sno,lno,$P,ino,dno,cno,cs,xae,fno,mno,kP,gno,hno,SP,pno,_no,uno,fs,$ae,bno,vno,RP,Fno,Tno,PP,Mno,Eno,Cno,ms,kae,wno,Ano,BP,yno,Lno,IP,xno,$no,kno,Vg,Sae,Sno,Rno,NP,Pno,Bno,Ino,gs,Rae,Nno,qno,qP,jno,Dno,jP,Gno,Ono,Vno,hs,Pae,Xno,zno,DP,Wno,Qno,GP,Hno,Uno,Jno,ps,Bae,Yno,Kno,OP,Zno,eso,VP,oso,rso,tso,_s,Iae,aso,nso,XP,sso,lso,zP,iso,dso,cso,us,Nae,fso,mso,WP,gso,hso,QP,pso,_so,uso,Xg,qae,bso,vso,HP,Fso,Tso,Mso,bs,jae,Eso,Cso,UP,wso,Aso,JP,yso,Lso,xso,zg,Dae,$so,kso,YP,Sso,Rso,Pso,Wg,Gae,Bso,Iso,KP,Nso,qso,jso,Qg,Oae,Dso,Gso,ZP,Oso,Vso,Xso,Hg,Vae,zso,Wso,eB,Qso,Hso,Uso,vs,Xae,Jso,Yso,oB,Kso,Zso,rB,elo,olo,rlo,Ug,zae,tlo,alo,tB,nlo,slo,llo,Fs,Wae,ilo,dlo,aB,clo,flo,nB,mlo,glo,hlo,Ts,Qae,plo,_lo,sB,ulo,blo,lB,vlo,Flo,Tlo,Ms,Hae,Mlo,Elo,iB,Clo,wlo,dB,Alo,ylo,Llo,Es,Uae,xlo,$lo,cB,klo,Slo,fB,Rlo,Plo,Blo,Cs,Jae,Ilo,Nlo,mB,qlo,jlo,gB,Dlo,Glo,Olo,ws,Yae,Vlo,Xlo,hB,zlo,Wlo,pB,Qlo,Hlo,Ulo,Jg,Kae,Jlo,Ylo,_B,Klo,Zlo,eio,Yg,Zae,oio,rio,uB,tio,aio,nio,As,ene,sio,lio,bB,iio,dio,vB,cio,fio,mio,ys,one,gio,hio,FB,pio,_io,TB,uio,bio,vio,Ls,rne,Fio,Tio,MB,Mio,Eio,EB,Cio,wio,Aio,Kg,tne,yio,Lio,CB,xio,$io,kio,Zg,ane,Sio,Rio,wB,Pio,Bio,Iio,eh,nne,Nio,qio,AB,jio,Dio,Gio,xs,sne,Oio,Vio,yB,Xio,zio,LB,Wio,Qio,Hio,oh,lne,Uio,Jio,xB,Yio,Kio,Zio,rh,ine,edo,odo,$B,rdo,tdo,ado,th,dne,ndo,sdo,kB,ldo,ido,ddo,$s,cne,cdo,fdo,SB,mdo,gdo,RB,hdo,pdo,_do,ah,fne,udo,bdo,PB,vdo,Fdo,Tdo,nh,mne,Mdo,Edo,BB,Cdo,wdo,Ado,ks,gne,ydo,Ldo,IB,xdo,$do,NB,kdo,Sdo,Rdo,Ss,hne,Pdo,Bdo,qB,Ido,Ndo,jB,qdo,jdo,Ddo,Rs,pne,Gdo,Odo,DB,Vdo,Xdo,GB,zdo,Wdo,Qdo,Ps,_ne,Hdo,Udo,OB,Jdo,Ydo,VB,Kdo,Zdo,eco,sh,oco,lh,XA,rco,une,tco,Cqe,Ei,ih,bne,zA,aco,vne,nco,wqe,Ao,WA,sco,QA,lco,XB,ico,dco,cco,HA,fco,Fne,mco,gco,hco,He,UA,pco,Tne,_co,uco,ya,bco,Mne,vco,Fco,Ene,Tco,Mco,Cne,Eco,Cco,wco,Y,dh,wne,Aco,yco,zB,Lco,xco,$co,ch,Ane,kco,Sco,WB,Rco,Pco,Bco,fh,yne,Ico,Nco,QB,qco,jco,Dco,mh,Lne,Gco,Oco,HB,Vco,Xco,zco,gh,xne,Wco,Qco,UB,Hco,Uco,Jco,hh,$ne,Yco,Kco,JB,Zco,efo,ofo,ph,kne,rfo,tfo,YB,afo,nfo,sfo,_h,Sne,lfo,ifo,KB,dfo,cfo,ffo,uh,Rne,mfo,gfo,ZB,hfo,pfo,_fo,bh,Pne,ufo,bfo,eI,vfo,Ffo,Tfo,vh,Bne,Mfo,Efo,oI,Cfo,wfo,Afo,Fh,Ine,yfo,Lfo,rI,xfo,$fo,kfo,Th,Nne,Sfo,Rfo,tI,Pfo,Bfo,Ifo,Mh,qne,Nfo,qfo,aI,jfo,Dfo,Gfo,Eh,jne,Ofo,Vfo,nI,Xfo,zfo,Wfo,Ch,Dne,Qfo,Hfo,sI,Ufo,Jfo,Yfo,wh,Gne,Kfo,Zfo,lI,emo,omo,rmo,Ah,One,tmo,amo,iI,nmo,smo,lmo,yh,Vne,imo,dmo,dI,cmo,fmo,mmo,Lh,Xne,gmo,hmo,cI,pmo,_mo,umo,xh,zne,bmo,vmo,fI,Fmo,Tmo,Mmo,$h,Wne,Emo,Cmo,mI,wmo,Amo,ymo,kh,Qne,Lmo,xmo,gI,$mo,kmo,Smo,Sh,Hne,Rmo,Pmo,hI,Bmo,Imo,Nmo,Rh,Une,qmo,jmo,pI,Dmo,Gmo,Omo,Ph,Jne,Vmo,Xmo,_I,zmo,Wmo,Qmo,Bh,Yne,Hmo,Umo,uI,Jmo,Ymo,Kmo,Ih,Kne,Zmo,ego,bI,ogo,rgo,tgo,Nh,Zne,ago,ngo,vI,sgo,lgo,igo,qh,dgo,jh,cgo,Dh,JA,fgo,ese,mgo,Aqe,Ci,Gh,ose,YA,ggo,rse,hgo,yqe,yo,KA,pgo,ZA,_go,FI,ugo,bgo,vgo,ey,Fgo,tse,Tgo,Mgo,Ego,Ue,oy,Cgo,ase,wgo,Ago,wi,ygo,nse,Lgo,xgo,sse,$go,kgo,Sgo,he,Oh,lse,Rgo,Pgo,TI,Bgo,Igo,Ngo,Vh,ise,qgo,jgo,dse,Dgo,Ggo,Ogo,Xh,cse,Vgo,Xgo,MI,zgo,Wgo,Qgo,zh,fse,Hgo,Ugo,EI,Jgo,Ygo,Kgo,Wh,mse,Zgo,eho,CI,oho,rho,tho,Qh,gse,aho,nho,wI,sho,lho,iho,Hh,hse,dho,cho,AI,fho,mho,gho,Uh,pse,hho,pho,yI,_ho,uho,bho,Jh,_se,vho,Fho,LI,Tho,Mho,Eho,Yh,use,Cho,who,xI,Aho,yho,Lho,Kh,bse,xho,$ho,$I,kho,Sho,Rho,Zh,vse,Pho,Bho,kI,Iho,Nho,qho,ep,Fse,jho,Dho,SI,Gho,Oho,Vho,op,Tse,Xho,zho,RI,Who,Qho,Hho,rp,Mse,Uho,Jho,PI,Yho,Kho,Zho,tp,Ese,epo,opo,BI,rpo,tpo,apo,ap,Cse,npo,spo,II,lpo,ipo,dpo,np,cpo,sp,fpo,lp,ry,mpo,wse,gpo,Lqe,Ai,ip,Ase,ty,hpo,yse,ppo,xqe,Lo,ay,_po,yi,upo,NI,bpo,vpo,qI,Fpo,Tpo,Mpo,ny,Epo,Lse,Cpo,wpo,Apo,tt,sy,ypo,xse,Lpo,xpo,Li,$po,$se,kpo,Spo,jI,Rpo,Ppo,Bpo,dp,Ipo,Je,ly,Npo,kse,qpo,jpo,La,Dpo,Sse,Gpo,Opo,Rse,Vpo,Xpo,Pse,zpo,Wpo,Qpo,x,cp,Bse,Hpo,Upo,DI,Jpo,Ypo,Kpo,fp,Ise,Zpo,e_o,GI,o_o,r_o,t_o,mp,Nse,a_o,n_o,OI,s_o,l_o,i_o,gp,qse,d_o,c_o,VI,f_o,m_o,g_o,hp,jse,h_o,p_o,XI,__o,u_o,b_o,pp,Dse,v_o,F_o,zI,T_o,M_o,E_o,_p,Gse,C_o,w_o,WI,A_o,y_o,L_o,up,Ose,x_o,$_o,QI,k_o,S_o,R_o,bp,Vse,P_o,B_o,HI,I_o,N_o,q_o,vp,Xse,j_o,D_o,UI,G_o,O_o,V_o,Fp,zse,X_o,z_o,JI,W_o,Q_o,H_o,Tp,Wse,U_o,J_o,YI,Y_o,K_o,Z_o,Mp,Qse,euo,ouo,KI,ruo,tuo,auo,Ep,Hse,nuo,suo,ZI,luo,iuo,duo,Cp,Use,cuo,fuo,eN,muo,guo,huo,wp,Jse,puo,_uo,oN,uuo,buo,vuo,Ap,Yse,Fuo,Tuo,rN,Muo,Euo,Cuo,yp,Kse,wuo,Auo,tN,yuo,Luo,xuo,Lp,Zse,$uo,kuo,aN,Suo,Ruo,Puo,xp,ele,Buo,Iuo,nN,Nuo,quo,juo,$p,ole,Duo,Guo,sN,Ouo,Vuo,Xuo,kp,rle,zuo,Wuo,lN,Quo,Huo,Uuo,Sp,tle,Juo,Yuo,iN,Kuo,Zuo,e4o,Rp,ale,o4o,r4o,dN,t4o,a4o,n4o,Pp,nle,s4o,l4o,cN,i4o,d4o,c4o,Bp,sle,f4o,m4o,fN,g4o,h4o,p4o,Ip,lle,_4o,u4o,mN,b4o,v4o,F4o,Np,ile,T4o,M4o,gN,E4o,C4o,w4o,qp,dle,A4o,y4o,hN,L4o,x4o,$4o,jp,cle,k4o,S4o,pN,R4o,P4o,B4o,Dp,fle,I4o,N4o,_N,q4o,j4o,D4o,Gp,mle,G4o,O4o,uN,V4o,X4o,z4o,Op,gle,W4o,Q4o,bN,H4o,U4o,J4o,Bs,hle,Y4o,K4o,vN,Z4o,e1o,FN,o1o,r1o,t1o,Vp,ple,a1o,n1o,TN,s1o,l1o,i1o,Xp,_le,d1o,c1o,MN,f1o,m1o,g1o,zp,ule,h1o,p1o,EN,_1o,u1o,b1o,Wp,ble,v1o,F1o,CN,T1o,M1o,E1o,Qp,vle,C1o,w1o,wN,A1o,y1o,L1o,Hp,Fle,x1o,$1o,AN,k1o,S1o,R1o,Up,Tle,P1o,B1o,yN,I1o,N1o,q1o,Jp,Mle,j1o,D1o,LN,G1o,O1o,V1o,Yp,Ele,X1o,z1o,xN,W1o,Q1o,H1o,Kp,Cle,U1o,J1o,$N,Y1o,K1o,Z1o,Zp,wle,ebo,obo,kN,rbo,tbo,abo,e_,Ale,nbo,sbo,SN,lbo,ibo,dbo,o_,yle,cbo,fbo,RN,mbo,gbo,hbo,r_,Lle,pbo,_bo,PN,ubo,bbo,vbo,t_,xle,Fbo,Tbo,BN,Mbo,Ebo,Cbo,a_,$le,wbo,Abo,IN,ybo,Lbo,xbo,n_,kle,$bo,kbo,NN,Sbo,Rbo,Pbo,s_,Sle,Bbo,Ibo,qN,Nbo,qbo,jbo,l_,Rle,Dbo,Gbo,jN,Obo,Vbo,Xbo,i_,Ple,zbo,Wbo,DN,Qbo,Hbo,Ubo,d_,Ble,Jbo,Ybo,GN,Kbo,Zbo,e2o,c_,Ile,o2o,r2o,ON,t2o,a2o,n2o,f_,Nle,s2o,l2o,VN,i2o,d2o,c2o,m_,qle,f2o,m2o,XN,g2o,h2o,p2o,g_,jle,_2o,u2o,zN,b2o,v2o,F2o,h_,Dle,T2o,M2o,WN,E2o,C2o,w2o,p_,Gle,A2o,y2o,QN,L2o,x2o,$2o,__,Ole,k2o,S2o,HN,R2o,P2o,B2o,u_,Vle,I2o,N2o,UN,q2o,j2o,D2o,b_,Xle,G2o,O2o,JN,V2o,X2o,z2o,v_,zle,W2o,Q2o,YN,H2o,U2o,J2o,F_,Wle,Y2o,K2o,KN,Z2o,evo,ovo,T_,Qle,rvo,tvo,ZN,avo,nvo,svo,M_,Hle,lvo,ivo,eq,dvo,cvo,fvo,E_,Ule,mvo,gvo,oq,hvo,pvo,_vo,C_,Jle,uvo,bvo,rq,vvo,Fvo,Tvo,w_,Yle,Mvo,Evo,tq,Cvo,wvo,Avo,A_,Kle,yvo,Lvo,aq,xvo,$vo,kvo,y_,Zle,Svo,Rvo,nq,Pvo,Bvo,Ivo,L_,eie,Nvo,qvo,sq,jvo,Dvo,Gvo,x_,oie,Ovo,Vvo,lq,Xvo,zvo,Wvo,$_,rie,Qvo,Hvo,iq,Uvo,Jvo,Yvo,k_,tie,Kvo,Zvo,dq,e3o,o3o,r3o,S_,aie,t3o,a3o,cq,n3o,s3o,l3o,R_,nie,i3o,d3o,fq,c3o,f3o,m3o,P_,sie,g3o,h3o,mq,p3o,_3o,u3o,B_,lie,b3o,v3o,gq,F3o,T3o,M3o,I_,iie,E3o,C3o,hq,w3o,A3o,y3o,N_,die,L3o,x3o,pq,$3o,k3o,S3o,q_,cie,R3o,P3o,_q,B3o,I3o,N3o,j_,fie,q3o,j3o,uq,D3o,G3o,O3o,D_,mie,V3o,X3o,bq,z3o,W3o,Q3o,G_,gie,H3o,U3o,vq,J3o,Y3o,K3o,O_,hie,Z3o,eFo,Fq,oFo,rFo,tFo,V_,pie,aFo,nFo,Tq,sFo,lFo,iFo,X_,_ie,dFo,cFo,Mq,fFo,mFo,gFo,z_,uie,hFo,pFo,Eq,_Fo,uFo,bFo,W_,bie,vFo,FFo,Cq,TFo,MFo,EFo,Q_,vie,CFo,wFo,wq,AFo,yFo,LFo,H_,Fie,xFo,$Fo,Aq,kFo,SFo,RFo,U_,Tie,PFo,BFo,yq,IFo,NFo,qFo,J_,Mie,jFo,DFo,Lq,GFo,OFo,VFo,Y_,Eie,XFo,zFo,xq,WFo,QFo,HFo,K_,Cie,UFo,JFo,$q,YFo,KFo,ZFo,Z_,wie,eTo,oTo,kq,rTo,tTo,aTo,eu,Aie,nTo,sTo,Sq,lTo,iTo,dTo,ou,yie,cTo,fTo,Rq,mTo,gTo,hTo,ru,Lie,pTo,_To,Pq,uTo,bTo,vTo,tu,xie,FTo,TTo,Bq,MTo,ETo,CTo,au,wTo,$ie,ATo,yTo,kie,LTo,xTo,nu,$qe,xi,su,Sie,iy,$To,Rie,kTo,kqe,xo,dy,STo,$i,RTo,Iq,PTo,BTo,Nq,ITo,NTo,qTo,cy,jTo,Pie,DTo,GTo,OTo,at,fy,VTo,Bie,XTo,zTo,ki,WTo,Iie,QTo,HTo,qq,UTo,JTo,YTo,lu,KTo,Ye,my,ZTo,Nie,e7o,o7o,xa,r7o,qie,t7o,a7o,jie,n7o,s7o,Die,l7o,i7o,d7o,G,iu,Gie,c7o,f7o,jq,m7o,g7o,h7o,du,Oie,p7o,_7o,Dq,u7o,b7o,v7o,cu,Vie,F7o,T7o,Gq,M7o,E7o,C7o,fu,Xie,w7o,A7o,Oq,y7o,L7o,x7o,mu,zie,$7o,k7o,Vq,S7o,R7o,P7o,gu,Wie,B7o,I7o,Xq,N7o,q7o,j7o,hu,Qie,D7o,G7o,zq,O7o,V7o,X7o,pu,Hie,z7o,W7o,Wq,Q7o,H7o,U7o,_u,Uie,J7o,Y7o,Qq,K7o,Z7o,eMo,uu,Jie,oMo,rMo,Hq,tMo,aMo,nMo,bu,Yie,sMo,lMo,Uq,iMo,dMo,cMo,vu,Kie,fMo,mMo,Jq,gMo,hMo,pMo,Fu,Zie,_Mo,uMo,Yq,bMo,vMo,FMo,Tu,ede,TMo,MMo,Kq,EMo,CMo,wMo,Mu,ode,AMo,yMo,Zq,LMo,xMo,$Mo,Eu,rde,kMo,SMo,ej,RMo,PMo,BMo,Cu,tde,IMo,NMo,oj,qMo,jMo,DMo,wu,ade,GMo,OMo,rj,VMo,XMo,zMo,Au,nde,WMo,QMo,tj,HMo,UMo,JMo,yu,sde,YMo,KMo,aj,ZMo,eEo,oEo,Lu,lde,rEo,tEo,nj,aEo,nEo,sEo,xu,ide,lEo,iEo,sj,dEo,cEo,fEo,$u,dde,mEo,gEo,lj,hEo,pEo,_Eo,ku,cde,uEo,bEo,ij,vEo,FEo,TEo,Su,fde,MEo,EEo,dj,CEo,wEo,AEo,Ru,mde,yEo,LEo,cj,xEo,$Eo,kEo,Pu,gde,SEo,REo,fj,PEo,BEo,IEo,Bu,hde,NEo,qEo,mj,jEo,DEo,GEo,Iu,pde,OEo,VEo,gj,XEo,zEo,WEo,Nu,_de,QEo,HEo,hj,UEo,JEo,YEo,qu,ude,KEo,ZEo,pj,eCo,oCo,rCo,ju,bde,tCo,aCo,_j,nCo,sCo,lCo,Du,vde,iCo,dCo,uj,cCo,fCo,mCo,Gu,Fde,gCo,hCo,bj,pCo,_Co,uCo,Ou,Tde,bCo,vCo,vj,FCo,TCo,MCo,Vu,Mde,ECo,CCo,Fj,wCo,ACo,yCo,Xu,Ede,LCo,xCo,Tj,$Co,kCo,SCo,zu,Cde,RCo,PCo,Mj,BCo,ICo,NCo,Wu,wde,qCo,jCo,Ej,DCo,GCo,OCo,Qu,Ade,VCo,XCo,Cj,zCo,WCo,QCo,Hu,yde,HCo,UCo,wj,JCo,YCo,KCo,Uu,Lde,ZCo,e5o,Aj,o5o,r5o,t5o,Ju,a5o,xde,n5o,s5o,$de,l5o,i5o,Yu,Sqe,Si,Ku,kde,gy,d5o,Sde,c5o,Rqe,$o,hy,f5o,Ri,m5o,yj,g5o,h5o,Lj,p5o,_5o,u5o,py,b5o,Rde,v5o,F5o,T5o,nt,_y,M5o,Pde,E5o,C5o,Pi,w5o,Bde,A5o,y5o,xj,L5o,x5o,$5o,Zu,k5o,Ke,uy,S5o,Ide,R5o,P5o,$a,B5o,Nde,I5o,N5o,qde,q5o,j5o,jde,D5o,G5o,O5o,z,e4,Dde,V5o,X5o,$j,z5o,W5o,Q5o,o4,Gde,H5o,U5o,kj,J5o,Y5o,K5o,r4,Ode,Z5o,ewo,Sj,owo,rwo,two,t4,Vde,awo,nwo,Rj,swo,lwo,iwo,a4,Xde,dwo,cwo,Pj,fwo,mwo,gwo,n4,zde,hwo,pwo,Bj,_wo,uwo,bwo,s4,Wde,vwo,Fwo,Ij,Two,Mwo,Ewo,l4,Qde,Cwo,wwo,Nj,Awo,ywo,Lwo,i4,Hde,xwo,$wo,qj,kwo,Swo,Rwo,d4,Ude,Pwo,Bwo,jj,Iwo,Nwo,qwo,c4,Jde,jwo,Dwo,Dj,Gwo,Owo,Vwo,f4,Yde,Xwo,zwo,Gj,Wwo,Qwo,Hwo,m4,Kde,Uwo,Jwo,Oj,Ywo,Kwo,Zwo,g4,Zde,e0o,o0o,Vj,r0o,t0o,a0o,h4,ece,n0o,s0o,Xj,l0o,i0o,d0o,p4,oce,c0o,f0o,zj,m0o,g0o,h0o,_4,rce,p0o,_0o,Wj,u0o,b0o,v0o,u4,tce,F0o,T0o,Qj,M0o,E0o,C0o,b4,ace,w0o,A0o,Hj,y0o,L0o,x0o,v4,nce,$0o,k0o,Uj,S0o,R0o,P0o,F4,sce,B0o,I0o,Jj,N0o,q0o,j0o,T4,lce,D0o,G0o,Yj,O0o,V0o,X0o,M4,ice,z0o,W0o,Kj,Q0o,H0o,U0o,E4,dce,J0o,Y0o,Zj,K0o,Z0o,e6o,C4,cce,o6o,r6o,eD,t6o,a6o,n6o,w4,fce,s6o,l6o,oD,i6o,d6o,c6o,A4,mce,f6o,m6o,rD,g6o,h6o,p6o,y4,gce,_6o,u6o,tD,b6o,v6o,F6o,L4,hce,T6o,M6o,aD,E6o,C6o,w6o,x4,pce,A6o,y6o,nD,L6o,x6o,$6o,$4,_ce,k6o,S6o,sD,R6o,P6o,B6o,k4,uce,I6o,N6o,lD,q6o,j6o,D6o,S4,bce,G6o,O6o,iD,V6o,X6o,z6o,R4,vce,W6o,Q6o,dD,H6o,U6o,J6o,P4,Fce,Y6o,K6o,cD,Z6o,eAo,oAo,B4,Tce,rAo,tAo,fD,aAo,nAo,sAo,I4,Mce,lAo,iAo,mD,dAo,cAo,fAo,N4,Ece,mAo,gAo,gD,hAo,pAo,_Ao,q4,uAo,Cce,bAo,vAo,wce,FAo,TAo,j4,Pqe,Bi,D4,Ace,by,MAo,yce,EAo,Bqe,ko,vy,CAo,Ii,wAo,hD,AAo,yAo,pD,LAo,xAo,$Ao,Fy,kAo,Lce,SAo,RAo,PAo,st,Ty,BAo,xce,IAo,NAo,Ni,qAo,$ce,jAo,DAo,_D,GAo,OAo,VAo,G4,XAo,Ze,My,zAo,kce,WAo,QAo,ka,HAo,Sce,UAo,JAo,Rce,YAo,KAo,Pce,ZAo,eyo,oyo,Q,O4,Bce,ryo,tyo,uD,ayo,nyo,syo,V4,Ice,lyo,iyo,bD,dyo,cyo,fyo,X4,Nce,myo,gyo,vD,hyo,pyo,_yo,z4,qce,uyo,byo,FD,vyo,Fyo,Tyo,W4,jce,Myo,Eyo,TD,Cyo,wyo,Ayo,Q4,Dce,yyo,Lyo,MD,xyo,$yo,kyo,H4,Gce,Syo,Ryo,ED,Pyo,Byo,Iyo,U4,Oce,Nyo,qyo,CD,jyo,Dyo,Gyo,J4,Vce,Oyo,Vyo,wD,Xyo,zyo,Wyo,Y4,Xce,Qyo,Hyo,AD,Uyo,Jyo,Yyo,K4,zce,Kyo,Zyo,yD,eLo,oLo,rLo,Z4,Wce,tLo,aLo,LD,nLo,sLo,lLo,e1,Qce,iLo,dLo,xD,cLo,fLo,mLo,o1,Hce,gLo,hLo,$D,pLo,_Lo,uLo,r1,Uce,bLo,vLo,kD,FLo,TLo,MLo,t1,Jce,ELo,CLo,SD,wLo,ALo,yLo,a1,Yce,LLo,xLo,RD,$Lo,kLo,SLo,n1,Kce,RLo,PLo,PD,BLo,ILo,NLo,s1,Zce,qLo,jLo,BD,DLo,GLo,OLo,l1,efe,VLo,XLo,ID,zLo,WLo,QLo,i1,ofe,HLo,ULo,ND,JLo,YLo,KLo,d1,rfe,ZLo,e8o,qD,o8o,r8o,t8o,c1,tfe,a8o,n8o,jD,s8o,l8o,i8o,f1,afe,d8o,c8o,DD,f8o,m8o,g8o,m1,nfe,h8o,p8o,GD,_8o,u8o,b8o,g1,sfe,v8o,F8o,OD,T8o,M8o,E8o,h1,lfe,C8o,w8o,VD,A8o,y8o,L8o,p1,ife,x8o,$8o,XD,k8o,S8o,R8o,_1,dfe,P8o,B8o,zD,I8o,N8o,q8o,u1,cfe,j8o,D8o,WD,G8o,O8o,V8o,b1,ffe,X8o,z8o,mfe,W8o,Q8o,H8o,v1,gfe,U8o,J8o,QD,Y8o,K8o,Z8o,F1,hfe,e9o,o9o,HD,r9o,t9o,a9o,T1,pfe,n9o,s9o,UD,l9o,i9o,d9o,M1,_fe,c9o,f9o,JD,m9o,g9o,h9o,E1,p9o,ufe,_9o,u9o,bfe,b9o,v9o,C1,Iqe,qi,w1,vfe,Ey,F9o,Ffe,T9o,Nqe,So,Cy,M9o,ji,E9o,YD,C9o,w9o,KD,A9o,y9o,L9o,wy,x9o,Tfe,$9o,k9o,S9o,lt,Ay,R9o,Mfe,P9o,B9o,Di,I9o,Efe,N9o,q9o,ZD,j9o,D9o,G9o,A1,O9o,eo,yy,V9o,Cfe,X9o,z9o,Sa,W9o,wfe,Q9o,H9o,Afe,U9o,J9o,yfe,Y9o,K9o,Z9o,_e,y1,Lfe,exo,oxo,eG,rxo,txo,axo,L1,xfe,nxo,sxo,oG,lxo,ixo,dxo,x1,$fe,cxo,fxo,rG,mxo,gxo,hxo,$1,kfe,pxo,_xo,tG,uxo,bxo,vxo,k1,Sfe,Fxo,Txo,aG,Mxo,Exo,Cxo,S1,Rfe,wxo,Axo,nG,yxo,Lxo,xxo,R1,Pfe,$xo,kxo,sG,Sxo,Rxo,Pxo,P1,Bfe,Bxo,Ixo,lG,Nxo,qxo,jxo,B1,Ife,Dxo,Gxo,iG,Oxo,Vxo,Xxo,I1,Nfe,zxo,Wxo,dG,Qxo,Hxo,Uxo,N1,qfe,Jxo,Yxo,cG,Kxo,Zxo,e$o,q1,jfe,o$o,r$o,fG,t$o,a$o,n$o,j1,Dfe,s$o,l$o,mG,i$o,d$o,c$o,D1,Gfe,f$o,m$o,gG,g$o,h$o,p$o,G1,Ofe,_$o,u$o,hG,b$o,v$o,F$o,O1,Vfe,T$o,M$o,pG,E$o,C$o,w$o,V1,A$o,Xfe,y$o,L$o,zfe,x$o,$$o,X1,qqe,Gi,z1,Wfe,Ly,k$o,Qfe,S$o,jqe,Ro,xy,R$o,Oi,P$o,_G,B$o,I$o,uG,N$o,q$o,j$o,$y,D$o,Hfe,G$o,O$o,V$o,it,ky,X$o,Ufe,z$o,W$o,Vi,Q$o,Jfe,H$o,U$o,bG,J$o,Y$o,K$o,W1,Z$o,oo,Sy,eko,Yfe,oko,rko,Ra,tko,Kfe,ako,nko,Zfe,sko,lko,eme,iko,dko,cko,N,Q1,ome,fko,mko,vG,gko,hko,pko,H1,rme,_ko,uko,FG,bko,vko,Fko,U1,tme,Tko,Mko,TG,Eko,Cko,wko,J1,ame,Ako,yko,MG,Lko,xko,$ko,Y1,nme,kko,Sko,EG,Rko,Pko,Bko,K1,sme,Iko,Nko,CG,qko,jko,Dko,Z1,lme,Gko,Oko,wG,Vko,Xko,zko,eb,ime,Wko,Qko,AG,Hko,Uko,Jko,ob,dme,Yko,Kko,yG,Zko,eSo,oSo,rb,cme,rSo,tSo,LG,aSo,nSo,sSo,tb,fme,lSo,iSo,xG,dSo,cSo,fSo,ab,mme,mSo,gSo,$G,hSo,pSo,_So,nb,gme,uSo,bSo,kG,vSo,FSo,TSo,sb,hme,MSo,ESo,SG,CSo,wSo,ASo,lb,pme,ySo,LSo,RG,xSo,$So,kSo,ib,_me,SSo,RSo,PG,PSo,BSo,ISo,db,ume,NSo,qSo,BG,jSo,DSo,GSo,cb,bme,OSo,VSo,IG,XSo,zSo,WSo,fb,vme,QSo,HSo,NG,USo,JSo,YSo,mb,Fme,KSo,ZSo,qG,eRo,oRo,rRo,gb,Tme,tRo,aRo,jG,nRo,sRo,lRo,hb,Mme,iRo,dRo,DG,cRo,fRo,mRo,pb,Eme,gRo,hRo,GG,pRo,_Ro,uRo,_b,Cme,bRo,vRo,OG,FRo,TRo,MRo,ub,wme,ERo,CRo,VG,wRo,ARo,yRo,bb,Ame,LRo,xRo,XG,$Ro,kRo,SRo,vb,yme,RRo,PRo,zG,BRo,IRo,NRo,Fb,Lme,qRo,jRo,WG,DRo,GRo,ORo,Tb,xme,VRo,XRo,QG,zRo,WRo,QRo,Mb,$me,HRo,URo,HG,JRo,YRo,KRo,Eb,kme,ZRo,ePo,UG,oPo,rPo,tPo,Cb,Sme,aPo,nPo,JG,sPo,lPo,iPo,wb,Rme,dPo,cPo,YG,fPo,mPo,gPo,Ab,Pme,hPo,pPo,KG,_Po,uPo,bPo,yb,Bme,vPo,FPo,ZG,TPo,MPo,EPo,Lb,Ime,CPo,wPo,eO,APo,yPo,LPo,xb,Nme,xPo,$Po,oO,kPo,SPo,RPo,$b,qme,PPo,BPo,rO,IPo,NPo,qPo,kb,jme,jPo,DPo,tO,GPo,OPo,VPo,Sb,Dme,XPo,zPo,aO,WPo,QPo,HPo,Rb,Gme,UPo,JPo,nO,YPo,KPo,ZPo,Pb,Ome,eBo,oBo,sO,rBo,tBo,aBo,Bb,Vme,nBo,sBo,lO,lBo,iBo,dBo,Ib,Xme,cBo,fBo,iO,mBo,gBo,hBo,Nb,zme,pBo,_Bo,dO,uBo,bBo,vBo,qb,Wme,FBo,TBo,cO,MBo,EBo,CBo,jb,Qme,wBo,ABo,fO,yBo,LBo,xBo,Db,$Bo,Hme,kBo,SBo,Ume,RBo,PBo,Gb,Dqe,Xi,Ob,Jme,Ry,BBo,Yme,IBo,Gqe,Po,Py,NBo,zi,qBo,mO,jBo,DBo,gO,GBo,OBo,VBo,By,XBo,Kme,zBo,WBo,QBo,dt,Iy,HBo,Zme,UBo,JBo,Wi,YBo,ege,KBo,ZBo,hO,eIo,oIo,rIo,Vb,tIo,ro,Ny,aIo,oge,nIo,sIo,Pa,lIo,rge,iIo,dIo,tge,cIo,fIo,age,mIo,gIo,hIo,K,Xb,nge,pIo,_Io,pO,uIo,bIo,vIo,zb,sge,FIo,TIo,_O,MIo,EIo,CIo,Wb,lge,wIo,AIo,uO,yIo,LIo,xIo,Qb,ige,$Io,kIo,bO,SIo,RIo,PIo,Hb,dge,BIo,IIo,vO,NIo,qIo,jIo,Ub,cge,DIo,GIo,FO,OIo,VIo,XIo,Jb,fge,zIo,WIo,TO,QIo,HIo,UIo,Yb,mge,JIo,YIo,MO,KIo,ZIo,eNo,Kb,gge,oNo,rNo,EO,tNo,aNo,nNo,Zb,hge,sNo,lNo,CO,iNo,dNo,cNo,e2,pge,fNo,mNo,wO,gNo,hNo,pNo,o2,_ge,_No,uNo,AO,bNo,vNo,FNo,r2,uge,TNo,MNo,yO,ENo,CNo,wNo,t2,bge,ANo,yNo,LO,LNo,xNo,$No,a2,vge,kNo,SNo,xO,RNo,PNo,BNo,n2,Fge,INo,NNo,$O,qNo,jNo,DNo,s2,Tge,GNo,ONo,kO,VNo,XNo,zNo,l2,Mge,WNo,QNo,SO,HNo,UNo,JNo,i2,Ege,YNo,KNo,RO,ZNo,eqo,oqo,d2,Cge,rqo,tqo,PO,aqo,nqo,sqo,c2,wge,lqo,iqo,BO,dqo,cqo,fqo,f2,Age,mqo,gqo,IO,hqo,pqo,_qo,m2,yge,uqo,bqo,NO,vqo,Fqo,Tqo,g2,Lge,Mqo,Eqo,qO,Cqo,wqo,Aqo,h2,xge,yqo,Lqo,jO,xqo,$qo,kqo,p2,$ge,Sqo,Rqo,DO,Pqo,Bqo,Iqo,_2,kge,Nqo,qqo,GO,jqo,Dqo,Gqo,u2,Sge,Oqo,Vqo,OO,Xqo,zqo,Wqo,b2,Rge,Qqo,Hqo,VO,Uqo,Jqo,Yqo,v2,Kqo,Pge,Zqo,ejo,Bge,ojo,rjo,F2,Oqe,Qi,T2,Ige,qy,tjo,Nge,ajo,Vqe,Bo,jy,njo,Hi,sjo,XO,ljo,ijo,zO,djo,cjo,fjo,Dy,mjo,qge,gjo,hjo,pjo,ct,Gy,_jo,jge,ujo,bjo,Ui,vjo,Dge,Fjo,Tjo,WO,Mjo,Ejo,Cjo,M2,wjo,to,Oy,Ajo,Gge,yjo,Ljo,Ba,xjo,Oge,$jo,kjo,Vge,Sjo,Rjo,Xge,Pjo,Bjo,Ijo,Yr,E2,zge,Njo,qjo,QO,jjo,Djo,Gjo,C2,Wge,Ojo,Vjo,HO,Xjo,zjo,Wjo,w2,Qge,Qjo,Hjo,UO,Ujo,Jjo,Yjo,A2,Hge,Kjo,Zjo,JO,eDo,oDo,rDo,y2,Uge,tDo,aDo,YO,nDo,sDo,lDo,L2,iDo,Jge,dDo,cDo,Yge,fDo,mDo,x2,Xqe,Ji,$2,Kge,Vy,gDo,Zge,hDo,zqe,Io,Xy,pDo,Yi,_Do,KO,uDo,bDo,ZO,vDo,FDo,TDo,zy,MDo,ehe,EDo,CDo,wDo,ft,Wy,ADo,ohe,yDo,LDo,Ki,xDo,rhe,$Do,kDo,eV,SDo,RDo,PDo,k2,BDo,ao,Qy,IDo,the,NDo,qDo,Ia,jDo,ahe,DDo,GDo,nhe,ODo,VDo,she,XDo,zDo,WDo,H,S2,lhe,QDo,HDo,oV,UDo,JDo,YDo,R2,ihe,KDo,ZDo,rV,eGo,oGo,rGo,P2,dhe,tGo,aGo,tV,nGo,sGo,lGo,B2,che,iGo,dGo,aV,cGo,fGo,mGo,I2,fhe,gGo,hGo,nV,pGo,_Go,uGo,N2,mhe,bGo,vGo,sV,FGo,TGo,MGo,q2,ghe,EGo,CGo,lV,wGo,AGo,yGo,j2,hhe,LGo,xGo,iV,$Go,kGo,SGo,D2,phe,RGo,PGo,dV,BGo,IGo,NGo,G2,_he,qGo,jGo,cV,DGo,GGo,OGo,O2,uhe,VGo,XGo,fV,zGo,WGo,QGo,V2,bhe,HGo,UGo,mV,JGo,YGo,KGo,X2,vhe,ZGo,eOo,gV,oOo,rOo,tOo,z2,Fhe,aOo,nOo,hV,sOo,lOo,iOo,W2,The,dOo,cOo,pV,fOo,mOo,gOo,Q2,Mhe,hOo,pOo,_V,_Oo,uOo,bOo,H2,Ehe,vOo,FOo,uV,TOo,MOo,EOo,U2,Che,COo,wOo,bV,AOo,yOo,LOo,J2,whe,xOo,$Oo,vV,kOo,SOo,ROo,Y2,Ahe,POo,BOo,FV,IOo,NOo,qOo,K2,yhe,jOo,DOo,TV,GOo,OOo,VOo,Z2,Lhe,XOo,zOo,MV,WOo,QOo,HOo,ev,xhe,UOo,JOo,EV,YOo,KOo,ZOo,ov,$he,eVo,oVo,CV,rVo,tVo,aVo,rv,khe,nVo,sVo,wV,lVo,iVo,dVo,tv,She,cVo,fVo,AV,mVo,gVo,hVo,av,Rhe,pVo,_Vo,yV,uVo,bVo,vVo,nv,Phe,FVo,TVo,LV,MVo,EVo,CVo,sv,Bhe,wVo,AVo,xV,yVo,LVo,xVo,lv,Ihe,$Vo,kVo,$V,SVo,RVo,PVo,iv,Nhe,BVo,IVo,kV,NVo,qVo,jVo,dv,qhe,DVo,GVo,SV,OVo,VVo,XVo,cv,jhe,zVo,WVo,RV,QVo,HVo,UVo,fv,Dhe,JVo,YVo,PV,KVo,ZVo,eXo,mv,oXo,Ghe,rXo,tXo,Ohe,aXo,nXo,gv,Wqe,Zi,hv,Vhe,Hy,sXo,Xhe,lXo,Qqe,No,Uy,iXo,ed,dXo,BV,cXo,fXo,IV,mXo,gXo,hXo,Jy,pXo,zhe,_Xo,uXo,bXo,mt,Yy,vXo,Whe,FXo,TXo,od,MXo,Qhe,EXo,CXo,NV,wXo,AXo,yXo,pv,LXo,no,Ky,xXo,Hhe,$Xo,kXo,Na,SXo,Uhe,RXo,PXo,Jhe,BXo,IXo,Yhe,NXo,qXo,jXo,V,_v,Khe,DXo,GXo,qV,OXo,VXo,XXo,uv,Zhe,zXo,WXo,jV,QXo,HXo,UXo,bv,epe,JXo,YXo,DV,KXo,ZXo,ezo,vv,ope,ozo,rzo,GV,tzo,azo,nzo,Fv,rpe,szo,lzo,OV,izo,dzo,czo,Tv,tpe,fzo,mzo,VV,gzo,hzo,pzo,Mv,ape,_zo,uzo,XV,bzo,vzo,Fzo,Ev,npe,Tzo,Mzo,zV,Ezo,Czo,wzo,Cv,spe,Azo,yzo,WV,Lzo,xzo,$zo,wv,lpe,kzo,Szo,QV,Rzo,Pzo,Bzo,Av,ipe,Izo,Nzo,HV,qzo,jzo,Dzo,yv,dpe,Gzo,Ozo,UV,Vzo,Xzo,zzo,Lv,cpe,Wzo,Qzo,JV,Hzo,Uzo,Jzo,xv,fpe,Yzo,Kzo,YV,Zzo,eWo,oWo,$v,mpe,rWo,tWo,KV,aWo,nWo,sWo,kv,gpe,lWo,iWo,ZV,dWo,cWo,fWo,Sv,hpe,mWo,gWo,eX,hWo,pWo,_Wo,Rv,ppe,uWo,bWo,oX,vWo,FWo,TWo,Pv,_pe,MWo,EWo,rX,CWo,wWo,AWo,Bv,upe,yWo,LWo,tX,xWo,$Wo,kWo,Iv,bpe,SWo,RWo,aX,PWo,BWo,IWo,Nv,vpe,NWo,qWo,nX,jWo,DWo,GWo,qv,Fpe,OWo,VWo,sX,XWo,zWo,WWo,jv,Tpe,QWo,HWo,lX,UWo,JWo,YWo,Dv,Mpe,KWo,ZWo,iX,eQo,oQo,rQo,Gv,Epe,tQo,aQo,dX,nQo,sQo,lQo,Ov,Cpe,iQo,dQo,cX,cQo,fQo,mQo,Vv,wpe,gQo,hQo,fX,pQo,_Qo,uQo,Xv,Ape,bQo,vQo,mX,FQo,TQo,MQo,zv,ype,EQo,CQo,gX,wQo,AQo,yQo,Wv,Lpe,LQo,xQo,hX,$Qo,kQo,SQo,Qv,xpe,RQo,PQo,pX,BQo,IQo,NQo,Hv,$pe,qQo,jQo,_X,DQo,GQo,OQo,Uv,kpe,VQo,XQo,uX,zQo,WQo,QQo,Jv,Spe,HQo,UQo,bX,JQo,YQo,KQo,Yv,Rpe,ZQo,eHo,vX,oHo,rHo,tHo,Kv,Ppe,aHo,nHo,FX,sHo,lHo,iHo,Zv,Bpe,dHo,cHo,TX,fHo,mHo,gHo,e3,Ipe,hHo,pHo,MX,_Ho,uHo,bHo,o3,Npe,vHo,FHo,EX,THo,MHo,EHo,r3,CHo,qpe,wHo,AHo,jpe,yHo,LHo,t3,Hqe,rd,a3,Dpe,Zy,xHo,Gpe,$Ho,Uqe,qo,eL,kHo,td,SHo,CX,RHo,PHo,wX,BHo,IHo,NHo,oL,qHo,Ope,jHo,DHo,GHo,gt,rL,OHo,Vpe,VHo,XHo,ad,zHo,Xpe,WHo,QHo,AX,HHo,UHo,JHo,n3,YHo,so,tL,KHo,zpe,ZHo,eUo,qa,oUo,Wpe,rUo,tUo,Qpe,aUo,nUo,Hpe,sUo,lUo,iUo,Upe,s3,Jpe,dUo,cUo,yX,fUo,mUo,gUo,l3,hUo,Ype,pUo,_Uo,Kpe,uUo,bUo,i3,Jqe,nd,d3,Zpe,aL,vUo,e_e,FUo,Yqe,jo,nL,TUo,sd,MUo,LX,EUo,CUo,xX,wUo,AUo,yUo,sL,LUo,o_e,xUo,$Uo,kUo,ht,lL,SUo,r_e,RUo,PUo,ld,BUo,t_e,IUo,NUo,$X,qUo,jUo,DUo,c3,GUo,lo,iL,OUo,a_e,VUo,XUo,ja,zUo,n_e,WUo,QUo,s_e,HUo,UUo,l_e,JUo,YUo,KUo,Fe,f3,i_e,ZUo,eJo,kX,oJo,rJo,tJo,m3,d_e,aJo,nJo,SX,sJo,lJo,iJo,g3,c_e,dJo,cJo,RX,fJo,mJo,gJo,h3,f_e,hJo,pJo,PX,_Jo,uJo,bJo,Is,m_e,vJo,FJo,BX,TJo,MJo,IX,EJo,CJo,wJo,p3,g_e,AJo,yJo,NX,LJo,xJo,$Jo,pt,h_e,kJo,SJo,qX,RJo,PJo,jX,BJo,IJo,DX,NJo,qJo,jJo,_3,p_e,DJo,GJo,GX,OJo,VJo,XJo,u3,__e,zJo,WJo,OX,QJo,HJo,UJo,b3,u_e,JJo,YJo,VX,KJo,ZJo,eYo,v3,b_e,oYo,rYo,XX,tYo,aYo,nYo,F3,v_e,sYo,lYo,zX,iYo,dYo,cYo,T3,F_e,fYo,mYo,WX,gYo,hYo,pYo,M3,T_e,_Yo,uYo,QX,bYo,vYo,FYo,E3,TYo,M_e,MYo,EYo,E_e,CYo,wYo,C3,Kqe,id,w3,C_e,dL,AYo,w_e,yYo,Zqe,Do,cL,LYo,dd,xYo,HX,$Yo,kYo,UX,SYo,RYo,PYo,fL,BYo,A_e,IYo,NYo,qYo,_t,mL,jYo,y_e,DYo,GYo,cd,OYo,L_e,VYo,XYo,JX,zYo,WYo,QYo,A3,HYo,io,gL,UYo,x_e,JYo,YYo,Da,KYo,$_e,ZYo,eKo,k_e,oKo,rKo,S_e,tKo,aKo,nKo,R_e,y3,P_e,sKo,lKo,YX,iKo,dKo,cKo,L3,fKo,B_e,mKo,gKo,I_e,hKo,pKo,x3,eje,fd,$3,N_e,hL,_Ko,q_e,uKo,oje,Go,pL,bKo,md,vKo,KX,FKo,TKo,ZX,MKo,EKo,CKo,_L,wKo,j_e,AKo,yKo,LKo,ut,uL,xKo,D_e,$Ko,kKo,gd,SKo,G_e,RKo,PKo,ez,BKo,IKo,NKo,k3,qKo,co,bL,jKo,O_e,DKo,GKo,Ga,OKo,V_e,VKo,XKo,X_e,zKo,WKo,z_e,QKo,HKo,UKo,ke,S3,W_e,JKo,YKo,oz,KKo,ZKo,eZo,R3,Q_e,oZo,rZo,rz,tZo,aZo,nZo,P3,H_e,sZo,lZo,tz,iZo,dZo,cZo,B3,U_e,fZo,mZo,az,gZo,hZo,pZo,I3,J_e,_Zo,uZo,nz,bZo,vZo,FZo,N3,Y_e,TZo,MZo,sz,EZo,CZo,wZo,q3,K_e,AZo,yZo,lz,LZo,xZo,$Zo,j3,Z_e,kZo,SZo,iz,RZo,PZo,BZo,D3,eue,IZo,NZo,dz,qZo,jZo,DZo,G3,GZo,oue,OZo,VZo,rue,XZo,zZo,O3,rje,hd,V3,tue,vL,WZo,aue,QZo,tje,Oo,FL,HZo,pd,UZo,cz,JZo,YZo,fz,KZo,ZZo,eer,TL,oer,nue,rer,ter,aer,bt,ML,ner,sue,ser,ler,_d,ier,lue,der,cer,mz,fer,mer,ger,X3,her,fo,EL,per,iue,_er,uer,Oa,ber,due,ver,Fer,cue,Ter,Mer,fue,Eer,Cer,wer,Kr,z3,mue,Aer,yer,gz,Ler,xer,$er,W3,gue,ker,Ser,hz,Rer,Per,Ber,Q3,hue,Ier,Ner,pz,qer,jer,Der,H3,pue,Ger,Oer,_z,Ver,Xer,zer,U3,_ue,Wer,Qer,uz,Her,Uer,Jer,J3,Yer,uue,Ker,Zer,bue,eor,oor,Y3,aje,ud,K3,vue,CL,ror,Fue,tor,nje,Vo,wL,aor,bd,nor,bz,sor,lor,vz,ior,dor,cor,AL,mor,Tue,gor,hor,por,vt,yL,_or,Mue,uor,bor,vd,vor,Eue,For,Tor,Fz,Mor,Eor,Cor,Z3,wor,mo,LL,Aor,Cue,yor,Lor,Va,xor,wue,$or,kor,Aue,Sor,Ror,yue,Por,Bor,Ior,Se,eF,Lue,Nor,qor,Tz,jor,Dor,Gor,oF,xue,Oor,Vor,Mz,Xor,zor,Wor,rF,$ue,Qor,Hor,Ez,Uor,Jor,Yor,tF,kue,Kor,Zor,Cz,err,orr,rrr,aF,Sue,trr,arr,wz,nrr,srr,lrr,nF,Rue,irr,drr,Az,crr,frr,mrr,sF,Pue,grr,hrr,yz,prr,_rr,urr,lF,Bue,brr,vrr,Lz,Frr,Trr,Mrr,iF,Iue,Err,Crr,xz,wrr,Arr,yrr,dF,Lrr,Nue,xrr,$rr,que,krr,Srr,cF,sje,Fd,fF,jue,xL,Rrr,Due,Prr,lje,Xo,$L,Brr,Td,Irr,$z,Nrr,qrr,kz,jrr,Drr,Grr,kL,Orr,Gue,Vrr,Xrr,zrr,Ft,SL,Wrr,Oue,Qrr,Hrr,Md,Urr,Vue,Jrr,Yrr,Sz,Krr,Zrr,etr,mF,otr,go,RL,rtr,Xue,ttr,atr,Xa,ntr,zue,str,ltr,Wue,itr,dtr,Que,ctr,ftr,mtr,PL,gF,Hue,gtr,htr,Rz,ptr,_tr,utr,hF,Uue,btr,vtr,Pz,Ftr,Ttr,Mtr,pF,Etr,Jue,Ctr,wtr,Yue,Atr,ytr,_F,ije,Ed,uF,Kue,BL,Ltr,Zue,xtr,dje,zo,IL,$tr,Cd,ktr,Bz,Str,Rtr,Iz,Ptr,Btr,Itr,NL,Ntr,e4e,qtr,jtr,Dtr,Tt,qL,Gtr,o4e,Otr,Vtr,wd,Xtr,r4e,ztr,Wtr,Nz,Qtr,Htr,Utr,bF,Jtr,ho,jL,Ytr,t4e,Ktr,Ztr,za,ear,a4e,oar,rar,n4e,tar,aar,s4e,nar,sar,lar,Zr,vF,l4e,iar,dar,qz,car,far,mar,FF,i4e,gar,har,jz,par,_ar,uar,TF,d4e,bar,Far,Dz,Tar,Mar,Ear,MF,c4e,Car,war,Gz,Aar,yar,Lar,EF,f4e,xar,$ar,Oz,kar,Sar,Rar,CF,Par,m4e,Bar,Iar,g4e,Nar,qar,wF,cje,Ad,AF,h4e,DL,jar,p4e,Dar,fje,Wo,GL,Gar,yd,Oar,Vz,Var,Xar,Xz,zar,War,Qar,OL,Har,_4e,Uar,Jar,Yar,Mt,VL,Kar,u4e,Zar,enr,Ld,onr,b4e,rnr,tnr,zz,anr,nnr,snr,yF,lnr,po,XL,inr,v4e,dnr,cnr,Wa,fnr,F4e,mnr,gnr,T4e,hnr,pnr,M4e,_nr,unr,bnr,xd,LF,E4e,vnr,Fnr,Wz,Tnr,Mnr,Enr,xF,C4e,Cnr,wnr,Qz,Anr,ynr,Lnr,$F,w4e,xnr,$nr,Hz,knr,Snr,Rnr,kF,Pnr,A4e,Bnr,Inr,y4e,Nnr,qnr,SF,mje,$d,RF,L4e,zL,jnr,x4e,Dnr,gje,Qo,WL,Gnr,kd,Onr,Uz,Vnr,Xnr,Jz,znr,Wnr,Qnr,QL,Hnr,$4e,Unr,Jnr,Ynr,Et,HL,Knr,k4e,Znr,esr,Sd,osr,S4e,rsr,tsr,Yz,asr,nsr,ssr,PF,lsr,_o,UL,isr,R4e,dsr,csr,Qa,fsr,P4e,msr,gsr,B4e,hsr,psr,I4e,_sr,usr,bsr,JL,BF,N4e,vsr,Fsr,Kz,Tsr,Msr,Esr,IF,q4e,Csr,wsr,Zz,Asr,ysr,Lsr,NF,xsr,j4e,$sr,ksr,D4e,Ssr,Rsr,qF,hje,Rd,jF,G4e,YL,Psr,O4e,Bsr,pje,Ho,KL,Isr,Pd,Nsr,eW,qsr,jsr,oW,Dsr,Gsr,Osr,ZL,Vsr,V4e,Xsr,zsr,Wsr,Ct,e8,Qsr,X4e,Hsr,Usr,Bd,Jsr,z4e,Ysr,Ksr,rW,Zsr,elr,olr,DF,rlr,uo,o8,tlr,W4e,alr,nlr,Ha,slr,Q4e,llr,ilr,H4e,dlr,clr,U4e,flr,mlr,glr,J4e,GF,Y4e,hlr,plr,tW,_lr,ulr,blr,OF,vlr,K4e,Flr,Tlr,Z4e,Mlr,Elr,VF,_je,Id,XF,e1e,r8,Clr,o1e,wlr,uje,Uo,t8,Alr,Nd,ylr,aW,Llr,xlr,nW,$lr,klr,Slr,a8,Rlr,r1e,Plr,Blr,Ilr,wt,n8,Nlr,t1e,qlr,jlr,qd,Dlr,a1e,Glr,Olr,sW,Vlr,Xlr,zlr,zF,Wlr,bo,s8,Qlr,n1e,Hlr,Ulr,Ua,Jlr,s1e,Ylr,Klr,l1e,Zlr,eir,i1e,oir,rir,tir,Ja,WF,d1e,air,nir,lW,sir,lir,iir,QF,c1e,dir,cir,iW,fir,mir,gir,HF,f1e,hir,pir,dW,_ir,uir,bir,UF,m1e,vir,Fir,cW,Tir,Mir,Eir,JF,Cir,g1e,wir,Air,h1e,yir,Lir,YF,bje,jd,KF,p1e,l8,xir,_1e,$ir,vje,Jo,i8,kir,Dd,Sir,fW,Rir,Pir,mW,Bir,Iir,Nir,d8,qir,u1e,jir,Dir,Gir,At,c8,Oir,b1e,Vir,Xir,Gd,zir,v1e,Wir,Qir,gW,Hir,Uir,Jir,ZF,Yir,vo,f8,Kir,F1e,Zir,edr,Ya,odr,T1e,rdr,tdr,M1e,adr,ndr,E1e,sdr,ldr,idr,C1e,eT,w1e,ddr,cdr,hW,fdr,mdr,gdr,oT,hdr,A1e,pdr,_dr,y1e,udr,bdr,rT,Fje,Od,tT,L1e,m8,vdr,x1e,Fdr,Tje,Yo,g8,Tdr,Vd,Mdr,pW,Edr,Cdr,_W,wdr,Adr,ydr,h8,Ldr,$1e,xdr,$dr,kdr,yt,p8,Sdr,k1e,Rdr,Pdr,Xd,Bdr,S1e,Idr,Ndr,uW,qdr,jdr,Ddr,aT,Gdr,wr,_8,Odr,R1e,Vdr,Xdr,Ka,zdr,P1e,Wdr,Qdr,B1e,Hdr,Udr,I1e,Jdr,Ydr,Kdr,q,nT,N1e,Zdr,ecr,bW,ocr,rcr,tcr,sT,q1e,acr,ncr,vW,scr,lcr,icr,lT,j1e,dcr,ccr,FW,fcr,mcr,gcr,iT,D1e,hcr,pcr,TW,_cr,ucr,bcr,dT,G1e,vcr,Fcr,MW,Tcr,Mcr,Ecr,cT,O1e,Ccr,wcr,EW,Acr,ycr,Lcr,fT,V1e,xcr,$cr,CW,kcr,Scr,Rcr,mT,X1e,Pcr,Bcr,wW,Icr,Ncr,qcr,gT,z1e,jcr,Dcr,AW,Gcr,Ocr,Vcr,hT,W1e,Xcr,zcr,yW,Wcr,Qcr,Hcr,pT,Q1e,Ucr,Jcr,LW,Ycr,Kcr,Zcr,_T,H1e,efr,ofr,xW,rfr,tfr,afr,uT,U1e,nfr,sfr,$W,lfr,ifr,dfr,bT,J1e,cfr,ffr,kW,mfr,gfr,hfr,vT,Y1e,pfr,_fr,SW,ufr,bfr,vfr,FT,K1e,Ffr,Tfr,RW,Mfr,Efr,Cfr,TT,Z1e,wfr,Afr,PW,yfr,Lfr,xfr,Ns,ebe,$fr,kfr,BW,Sfr,Rfr,IW,Pfr,Bfr,Ifr,MT,obe,Nfr,qfr,NW,jfr,Dfr,Gfr,ET,rbe,Ofr,Vfr,qW,Xfr,zfr,Wfr,CT,tbe,Qfr,Hfr,jW,Ufr,Jfr,Yfr,wT,abe,Kfr,Zfr,DW,emr,omr,rmr,AT,nbe,tmr,amr,GW,nmr,smr,lmr,yT,sbe,imr,dmr,OW,cmr,fmr,mmr,LT,lbe,gmr,hmr,VW,pmr,_mr,umr,xT,ibe,bmr,vmr,XW,Fmr,Tmr,Mmr,$T,dbe,Emr,Cmr,zW,wmr,Amr,ymr,kT,cbe,Lmr,xmr,WW,$mr,kmr,Smr,ST,fbe,Rmr,Pmr,QW,Bmr,Imr,Nmr,RT,mbe,qmr,jmr,HW,Dmr,Gmr,Omr,PT,gbe,Vmr,Xmr,UW,zmr,Wmr,Qmr,BT,hbe,Hmr,Umr,JW,Jmr,Ymr,Kmr,IT,pbe,Zmr,egr,YW,ogr,rgr,tgr,NT,_be,agr,ngr,KW,sgr,lgr,igr,qT,ube,dgr,cgr,ZW,fgr,mgr,ggr,jT,bbe,hgr,pgr,eQ,_gr,ugr,bgr,DT,vbe,vgr,Fgr,oQ,Tgr,Mgr,Egr,GT,Fbe,Cgr,wgr,rQ,Agr,ygr,Lgr,OT,Tbe,xgr,$gr,tQ,kgr,Sgr,Rgr,VT,Mbe,Pgr,Bgr,aQ,Igr,Ngr,qgr,XT,Ebe,jgr,Dgr,nQ,Ggr,Ogr,Vgr,zT,Cbe,Xgr,zgr,sQ,Wgr,Qgr,Hgr,WT,wbe,Ugr,Jgr,lQ,Ygr,Kgr,Zgr,QT,Abe,ehr,ohr,iQ,rhr,thr,ahr,HT,ybe,nhr,shr,dQ,lhr,ihr,dhr,UT,Lbe,chr,fhr,cQ,mhr,ghr,hhr,JT,Mje,zd,YT,xbe,u8,phr,$be,_hr,Eje,Ko,b8,uhr,Wd,bhr,fQ,vhr,Fhr,mQ,Thr,Mhr,Ehr,v8,Chr,kbe,whr,Ahr,yhr,Lt,F8,Lhr,Sbe,xhr,$hr,Qd,khr,Rbe,Shr,Rhr,gQ,Phr,Bhr,Ihr,KT,Nhr,Ar,T8,qhr,Pbe,jhr,Dhr,Za,Ghr,Bbe,Ohr,Vhr,Ibe,Xhr,zhr,Nbe,Whr,Qhr,Hhr,se,ZT,qbe,Uhr,Jhr,hQ,Yhr,Khr,Zhr,e7,jbe,epr,opr,pQ,rpr,tpr,apr,o7,Dbe,npr,spr,_Q,lpr,ipr,dpr,r7,Gbe,cpr,fpr,uQ,mpr,gpr,hpr,t7,Obe,ppr,_pr,bQ,upr,bpr,vpr,a7,Vbe,Fpr,Tpr,vQ,Mpr,Epr,Cpr,n7,Xbe,wpr,Apr,FQ,ypr,Lpr,xpr,s7,zbe,$pr,kpr,TQ,Spr,Rpr,Ppr,l7,Wbe,Bpr,Ipr,MQ,Npr,qpr,jpr,i7,Qbe,Dpr,Gpr,EQ,Opr,Vpr,Xpr,d7,Hbe,zpr,Wpr,CQ,Qpr,Hpr,Upr,c7,Ube,Jpr,Ypr,wQ,Kpr,Zpr,e_r,f7,Jbe,o_r,r_r,AQ,t_r,a_r,n_r,m7,Ybe,s_r,l_r,yQ,i_r,d_r,c_r,g7,Kbe,f_r,m_r,LQ,g_r,h_r,p_r,h7,Zbe,__r,u_r,xQ,b_r,v_r,F_r,p7,e2e,T_r,M_r,$Q,E_r,C_r,w_r,_7,o2e,A_r,y_r,kQ,L_r,x_r,$_r,u7,r2e,k_r,S_r,SQ,R_r,P_r,B_r,b7,t2e,I_r,N_r,RQ,q_r,j_r,D_r,v7,a2e,G_r,O_r,PQ,V_r,X_r,z_r,F7,n2e,W_r,Q_r,BQ,H_r,U_r,J_r,T7,s2e,Y_r,K_r,IQ,Z_r,eur,our,M7,Cje,Hd,E7,l2e,M8,rur,i2e,tur,wje,Zo,E8,aur,Ud,nur,NQ,sur,lur,qQ,iur,dur,cur,C8,fur,d2e,mur,gur,hur,xt,w8,pur,c2e,_ur,uur,Jd,bur,f2e,vur,Fur,jQ,Tur,Mur,Eur,C7,Cur,yr,A8,wur,m2e,Aur,yur,en,Lur,g2e,xur,$ur,h2e,kur,Sur,p2e,Rur,Pur,Bur,Me,w7,_2e,Iur,Nur,DQ,qur,jur,Dur,A7,u2e,Gur,Our,GQ,Vur,Xur,zur,y7,b2e,Wur,Qur,OQ,Hur,Uur,Jur,L7,v2e,Yur,Kur,VQ,Zur,e4r,o4r,x7,F2e,r4r,t4r,XQ,a4r,n4r,s4r,$7,T2e,l4r,i4r,zQ,d4r,c4r,f4r,k7,M2e,m4r,g4r,WQ,h4r,p4r,_4r,S7,E2e,u4r,b4r,QQ,v4r,F4r,T4r,R7,C2e,M4r,E4r,HQ,C4r,w4r,A4r,P7,w2e,y4r,L4r,UQ,x4r,$4r,k4r,B7,A2e,S4r,R4r,JQ,P4r,B4r,I4r,I7,y2e,N4r,q4r,YQ,j4r,D4r,G4r,N7,Aje,Yd,q7,L2e,y8,O4r,x2e,V4r,yje,er,L8,X4r,Kd,z4r,KQ,W4r,Q4r,ZQ,H4r,U4r,J4r,x8,Y4r,$2e,K4r,Z4r,e1r,$t,$8,o1r,k2e,r1r,t1r,Zd,a1r,S2e,n1r,s1r,eH,l1r,i1r,d1r,j7,c1r,Lr,k8,f1r,R2e,m1r,g1r,on,h1r,P2e,p1r,_1r,B2e,u1r,b1r,I2e,v1r,F1r,T1r,rn,D7,N2e,M1r,E1r,oH,C1r,w1r,A1r,G7,q2e,y1r,L1r,rH,x1r,$1r,k1r,O7,j2e,S1r,R1r,tH,P1r,B1r,I1r,V7,D2e,N1r,q1r,aH,j1r,D1r,G1r,X7,Lje,ec,z7,G2e,S8,O1r,O2e,V1r,xje,or,R8,X1r,oc,z1r,nH,W1r,Q1r,sH,H1r,U1r,J1r,P8,Y1r,V2e,K1r,Z1r,ebr,kt,B8,obr,X2e,rbr,tbr,rc,abr,z2e,nbr,sbr,lH,lbr,ibr,dbr,W7,cbr,xr,I8,fbr,W2e,mbr,gbr,tn,hbr,Q2e,pbr,_br,H2e,ubr,bbr,U2e,vbr,Fbr,Tbr,ie,Q7,J2e,Mbr,Ebr,iH,Cbr,wbr,Abr,H7,Y2e,ybr,Lbr,dH,xbr,$br,kbr,U7,K2e,Sbr,Rbr,cH,Pbr,Bbr,Ibr,J7,Z2e,Nbr,qbr,fH,jbr,Dbr,Gbr,Y7,eve,Obr,Vbr,mH,Xbr,zbr,Wbr,K7,ove,Qbr,Hbr,gH,Ubr,Jbr,Ybr,Z7,rve,Kbr,Zbr,hH,e2r,o2r,r2r,eM,tve,t2r,a2r,pH,n2r,s2r,l2r,oM,ave,i2r,d2r,_H,c2r,f2r,m2r,rM,nve,g2r,h2r,uH,p2r,_2r,u2r,tM,sve,b2r,v2r,bH,F2r,T2r,M2r,aM,lve,E2r,C2r,vH,w2r,A2r,y2r,nM,ive,L2r,x2r,FH,$2r,k2r,S2r,sM,dve,R2r,P2r,TH,B2r,I2r,N2r,lM,cve,q2r,j2r,MH,D2r,G2r,O2r,iM,fve,V2r,X2r,EH,z2r,W2r,Q2r,dM,mve,H2r,U2r,CH,J2r,Y2r,K2r,cM,gve,Z2r,evr,wH,ovr,rvr,tvr,fM,hve,avr,nvr,AH,svr,lvr,ivr,mM,pve,dvr,cvr,yH,fvr,mvr,gvr,gM,$je,tc,hM,_ve,N8,hvr,uve,pvr,kje,rr,q8,_vr,ac,uvr,LH,bvr,vvr,xH,Fvr,Tvr,Mvr,j8,Evr,bve,Cvr,wvr,Avr,St,D8,yvr,vve,Lvr,xvr,nc,$vr,Fve,kvr,Svr,$H,Rvr,Pvr,Bvr,pM,Ivr,$r,G8,Nvr,Tve,qvr,jvr,an,Dvr,Mve,Gvr,Ovr,Eve,Vvr,Xvr,Cve,zvr,Wvr,Qvr,ye,_M,wve,Hvr,Uvr,kH,Jvr,Yvr,Kvr,uM,Ave,Zvr,e3r,SH,o3r,r3r,t3r,bM,yve,a3r,n3r,RH,s3r,l3r,i3r,vM,Lve,d3r,c3r,PH,f3r,m3r,g3r,FM,xve,h3r,p3r,BH,_3r,u3r,b3r,TM,$ve,v3r,F3r,IH,T3r,M3r,E3r,MM,kve,C3r,w3r,NH,A3r,y3r,L3r,EM,Sve,x3r,$3r,qH,k3r,S3r,R3r,CM,Rve,P3r,B3r,jH,I3r,N3r,q3r,wM,Pve,j3r,D3r,DH,G3r,O3r,V3r,AM,Sje,sc,yM,Bve,O8,X3r,Ive,z3r,Rje,tr,V8,W3r,lc,Q3r,GH,H3r,U3r,OH,J3r,Y3r,K3r,X8,Z3r,Nve,eFr,oFr,rFr,Rt,z8,tFr,qve,aFr,nFr,ic,sFr,jve,lFr,iFr,VH,dFr,cFr,fFr,LM,mFr,kr,W8,gFr,Dve,hFr,pFr,nn,_Fr,Gve,uFr,bFr,Ove,vFr,FFr,Vve,TFr,MFr,EFr,oe,xM,Xve,CFr,wFr,XH,AFr,yFr,LFr,$M,zve,xFr,$Fr,zH,kFr,SFr,RFr,kM,Wve,PFr,BFr,WH,IFr,NFr,qFr,SM,Qve,jFr,DFr,QH,GFr,OFr,VFr,RM,Hve,XFr,zFr,HH,WFr,QFr,HFr,PM,Uve,UFr,JFr,UH,YFr,KFr,ZFr,BM,Jve,eTr,oTr,JH,rTr,tTr,aTr,IM,Yve,nTr,sTr,YH,lTr,iTr,dTr,NM,Kve,cTr,fTr,KH,mTr,gTr,hTr,qM,Zve,pTr,_Tr,ZH,uTr,bTr,vTr,jM,e3e,FTr,TTr,eU,MTr,ETr,CTr,DM,o3e,wTr,ATr,oU,yTr,LTr,xTr,GM,r3e,$Tr,kTr,rU,STr,RTr,PTr,OM,t3e,BTr,ITr,tU,NTr,qTr,jTr,VM,a3e,DTr,GTr,aU,OTr,VTr,XTr,XM,n3e,zTr,WTr,nU,QTr,HTr,UTr,zM,s3e,JTr,YTr,sU,KTr,ZTr,e7r,WM,l3e,o7r,r7r,lU,t7r,a7r,n7r,QM,i3e,s7r,l7r,iU,i7r,d7r,c7r,HM,d3e,f7r,m7r,dU,g7r,h7r,p7r,UM,c3e,_7r,u7r,cU,b7r,v7r,F7r,JM,f3e,T7r,M7r,fU,E7r,C7r,w7r,YM,m3e,A7r,y7r,mU,L7r,x7r,$7r,KM,g3e,k7r,S7r,gU,R7r,P7r,B7r,ZM,h3e,I7r,N7r,hU,q7r,j7r,D7r,eE,p3e,G7r,O7r,pU,V7r,X7r,z7r,oE,Pje,dc,rE,_3e,Q8,W7r,u3e,Q7r,Bje,ar,H8,H7r,cc,U7r,_U,J7r,Y7r,uU,K7r,Z7r,eMr,U8,oMr,b3e,rMr,tMr,aMr,Pt,J8,nMr,v3e,sMr,lMr,fc,iMr,F3e,dMr,cMr,bU,fMr,mMr,gMr,tE,hMr,Sr,Y8,pMr,T3e,_Mr,uMr,sn,bMr,M3e,vMr,FMr,E3e,TMr,MMr,C3e,EMr,CMr,wMr,pe,aE,w3e,AMr,yMr,vU,LMr,xMr,$Mr,nE,A3e,kMr,SMr,FU,RMr,PMr,BMr,sE,y3e,IMr,NMr,TU,qMr,jMr,DMr,lE,L3e,GMr,OMr,MU,VMr,XMr,zMr,iE,x3e,WMr,QMr,EU,HMr,UMr,JMr,dE,$3e,YMr,KMr,CU,ZMr,eEr,oEr,cE,k3e,rEr,tEr,wU,aEr,nEr,sEr,fE,S3e,lEr,iEr,AU,dEr,cEr,fEr,mE,R3e,mEr,gEr,yU,hEr,pEr,_Er,gE,P3e,uEr,bEr,LU,vEr,FEr,TEr,hE,B3e,MEr,EEr,xU,CEr,wEr,AEr,pE,I3e,yEr,LEr,$U,xEr,$Er,kEr,_E,N3e,SEr,REr,kU,PEr,BEr,IEr,uE,q3e,NEr,qEr,SU,jEr,DEr,GEr,bE,j3e,OEr,VEr,RU,XEr,zEr,WEr,vE,D3e,QEr,HEr,PU,UEr,JEr,YEr,FE,G3e,KEr,ZEr,BU,eCr,oCr,rCr,TE,Ije,mc,ME,O3e,K8,tCr,V3e,aCr,Nje,nr,Z8,nCr,gc,sCr,IU,lCr,iCr,NU,dCr,cCr,fCr,e9,mCr,X3e,gCr,hCr,pCr,Bt,o9,_Cr,z3e,uCr,bCr,hc,vCr,W3e,FCr,TCr,qU,MCr,ECr,CCr,EE,wCr,Rr,r9,ACr,Q3e,yCr,LCr,ln,xCr,H3e,$Cr,kCr,U3e,SCr,RCr,J3e,PCr,BCr,ICr,t9,CE,Y3e,NCr,qCr,jU,jCr,DCr,GCr,wE,K3e,OCr,VCr,DU,XCr,zCr,WCr,AE,qje,pc,yE,Z3e,a9,QCr,eFe,HCr,jje,sr,n9,UCr,_c,JCr,GU,YCr,KCr,OU,ZCr,e5r,o5r,s9,r5r,oFe,t5r,a5r,n5r,It,l9,s5r,rFe,l5r,i5r,uc,d5r,tFe,c5r,f5r,VU,m5r,g5r,h5r,LE,p5r,Pr,i9,_5r,aFe,u5r,b5r,dn,v5r,nFe,F5r,T5r,sFe,M5r,E5r,lFe,C5r,w5r,A5r,iFe,xE,dFe,y5r,L5r,XU,x5r,$5r,k5r,$E,Dje,bc,kE,cFe,d9,S5r,fFe,R5r,Gje,lr,c9,P5r,vc,B5r,zU,I5r,N5r,WU,q5r,j5r,D5r,f9,G5r,mFe,O5r,V5r,X5r,Nt,m9,z5r,gFe,W5r,Q5r,Fc,H5r,hFe,U5r,J5r,QU,Y5r,K5r,Z5r,SE,ewr,Br,g9,owr,pFe,rwr,twr,cn,awr,_Fe,nwr,swr,uFe,lwr,iwr,bFe,dwr,cwr,fwr,de,RE,vFe,mwr,gwr,HU,hwr,pwr,_wr,PE,FFe,uwr,bwr,UU,vwr,Fwr,Twr,BE,TFe,Mwr,Ewr,JU,Cwr,wwr,Awr,IE,MFe,ywr,Lwr,YU,xwr,$wr,kwr,NE,EFe,Swr,Rwr,KU,Pwr,Bwr,Iwr,qE,CFe,Nwr,qwr,ZU,jwr,Dwr,Gwr,jE,wFe,Owr,Vwr,eJ,Xwr,zwr,Wwr,DE,AFe,Qwr,Hwr,oJ,Uwr,Jwr,Ywr,GE,yFe,Kwr,Zwr,rJ,e0r,o0r,r0r,OE,LFe,t0r,a0r,tJ,n0r,s0r,l0r,VE,xFe,i0r,d0r,aJ,c0r,f0r,m0r,XE,$Fe,g0r,h0r,nJ,p0r,_0r,u0r,zE,kFe,b0r,v0r,sJ,F0r,T0r,M0r,WE,SFe,E0r,C0r,lJ,w0r,A0r,y0r,QE,RFe,L0r,x0r,iJ,$0r,k0r,S0r,HE,PFe,R0r,P0r,dJ,B0r,I0r,N0r,UE,BFe,q0r,j0r,cJ,D0r,G0r,O0r,JE,IFe,V0r,X0r,fJ,z0r,W0r,Q0r,YE,NFe,H0r,U0r,mJ,J0r,Y0r,K0r,KE,qFe,Z0r,e6r,gJ,o6r,r6r,t6r,ZE,Oje,Tc,eC,jFe,h9,a6r,DFe,n6r,Vje,ir,p9,s6r,Mc,l6r,hJ,i6r,d6r,pJ,c6r,f6r,m6r,_9,g6r,GFe,h6r,p6r,_6r,qt,u9,u6r,OFe,b6r,v6r,Ec,F6r,VFe,T6r,M6r,_J,E6r,C6r,w6r,oC,A6r,Ir,b9,y6r,XFe,L6r,x6r,fn,$6r,zFe,k6r,S6r,WFe,R6r,P6r,QFe,B6r,I6r,N6r,ce,rC,HFe,q6r,j6r,uJ,D6r,G6r,O6r,tC,UFe,V6r,X6r,bJ,z6r,W6r,Q6r,aC,JFe,H6r,U6r,vJ,J6r,Y6r,K6r,nC,YFe,Z6r,eAr,FJ,oAr,rAr,tAr,sC,KFe,aAr,nAr,TJ,sAr,lAr,iAr,lC,ZFe,dAr,cAr,MJ,fAr,mAr,gAr,iC,eTe,hAr,pAr,EJ,_Ar,uAr,bAr,dC,oTe,vAr,FAr,CJ,TAr,MAr,EAr,cC,rTe,CAr,wAr,wJ,AAr,yAr,LAr,fC,tTe,xAr,$Ar,AJ,kAr,SAr,RAr,mC,aTe,PAr,BAr,yJ,IAr,NAr,qAr,gC,nTe,jAr,DAr,LJ,GAr,OAr,VAr,hC,sTe,XAr,zAr,xJ,WAr,QAr,HAr,pC,lTe,UAr,JAr,$J,YAr,KAr,ZAr,_C,iTe,eyr,oyr,kJ,ryr,tyr,ayr,uC,dTe,nyr,syr,SJ,lyr,iyr,dyr,bC,cTe,cyr,fyr,RJ,myr,gyr,hyr,vC,fTe,pyr,_yr,PJ,uyr,byr,vyr,FC,mTe,Fyr,Tyr,BJ,Myr,Eyr,Cyr,TC,gTe,wyr,Ayr,IJ,yyr,Lyr,xyr,MC,Xje,Cc,EC,hTe,v9,$yr,pTe,kyr,zje,dr,F9,Syr,wc,Ryr,NJ,Pyr,Byr,qJ,Iyr,Nyr,qyr,T9,jyr,_Te,Dyr,Gyr,Oyr,jt,M9,Vyr,uTe,Xyr,zyr,Ac,Wyr,bTe,Qyr,Hyr,jJ,Uyr,Jyr,Yyr,CC,Kyr,Nr,E9,Zyr,vTe,eLr,oLr,mn,rLr,FTe,tLr,aLr,TTe,nLr,sLr,MTe,lLr,iLr,dLr,ETe,wC,CTe,cLr,fLr,DJ,mLr,gLr,hLr,AC,Wje,yc,yC,wTe,C9,pLr,ATe,_Lr,Qje,cr,w9,uLr,Lc,bLr,GJ,vLr,FLr,OJ,TLr,MLr,ELr,A9,CLr,yTe,wLr,ALr,yLr,Dt,y9,LLr,LTe,xLr,$Lr,xc,kLr,xTe,SLr,RLr,VJ,PLr,BLr,ILr,LC,NLr,qr,L9,qLr,$Te,jLr,DLr,gn,GLr,kTe,OLr,VLr,STe,XLr,zLr,RTe,WLr,QLr,HLr,PTe,xC,BTe,ULr,JLr,XJ,YLr,KLr,ZLr,$C,Hje,$c,kC,ITe,x9,e8r,NTe,o8r,Uje,fr,$9,r8r,kc,t8r,zJ,a8r,n8r,WJ,s8r,l8r,i8r,k9,d8r,qTe,c8r,f8r,m8r,Gt,S9,g8r,jTe,h8r,p8r,Sc,_8r,DTe,u8r,b8r,QJ,v8r,F8r,T8r,SC,M8r,jr,R9,E8r,GTe,C8r,w8r,hn,A8r,OTe,y8r,L8r,VTe,x8r,$8r,XTe,k8r,S8r,R8r,te,RC,zTe,P8r,B8r,HJ,I8r,N8r,q8r,PC,WTe,j8r,D8r,UJ,G8r,O8r,V8r,BC,QTe,X8r,z8r,JJ,W8r,Q8r,H8r,IC,HTe,U8r,J8r,YJ,Y8r,K8r,Z8r,NC,UTe,e9r,o9r,KJ,r9r,t9r,a9r,qC,JTe,n9r,s9r,ZJ,l9r,i9r,d9r,jC,YTe,c9r,f9r,eY,m9r,g9r,h9r,DC,KTe,p9r,_9r,oY,u9r,b9r,v9r,GC,ZTe,F9r,T9r,rY,M9r,E9r,C9r,OC,e7e,w9r,A9r,tY,y9r,L9r,x9r,VC,o7e,$9r,k9r,aY,S9r,R9r,P9r,XC,r7e,B9r,I9r,nY,N9r,q9r,j9r,zC,t7e,D9r,G9r,sY,O9r,V9r,X9r,WC,a7e,z9r,W9r,lY,Q9r,H9r,U9r,QC,n7e,J9r,Y9r,iY,K9r,Z9r,exr,HC,s7e,oxr,rxr,dY,txr,axr,nxr,UC,l7e,sxr,lxr,cY,ixr,dxr,cxr,JC,i7e,fxr,mxr,fY,gxr,hxr,pxr,YC,d7e,_xr,uxr,mY,bxr,vxr,Fxr,KC,c7e,Txr,Mxr,gY,Exr,Cxr,wxr,ZC,f7e,Axr,yxr,hY,Lxr,xxr,$xr,e5,m7e,kxr,Sxr,pY,Rxr,Pxr,Bxr,o5,g7e,Ixr,Nxr,_Y,qxr,jxr,Dxr,r5,h7e,Gxr,Oxr,uY,Vxr,Xxr,zxr,t5,p7e,Wxr,Qxr,bY,Hxr,Uxr,Jxr,a5,Jje,Rc,n5,_7e,P9,Yxr,u7e,Kxr,Yje,mr,B9,Zxr,Pc,e$r,vY,o$r,r$r,FY,t$r,a$r,n$r,I9,s$r,b7e,l$r,i$r,d$r,Ot,N9,c$r,v7e,f$r,m$r,Bc,g$r,F7e,h$r,p$r,TY,_$r,u$r,b$r,s5,v$r,Dr,q9,F$r,T7e,T$r,M$r,pn,E$r,M7e,C$r,w$r,E7e,A$r,y$r,C7e,L$r,x$r,$$r,Re,l5,w7e,k$r,S$r,MY,R$r,P$r,B$r,i5,A7e,I$r,N$r,EY,q$r,j$r,D$r,d5,y7e,G$r,O$r,CY,V$r,X$r,z$r,c5,L7e,W$r,Q$r,wY,H$r,U$r,J$r,f5,x7e,Y$r,K$r,AY,Z$r,ekr,okr,m5,$7e,rkr,tkr,yY,akr,nkr,skr,g5,k7e,lkr,ikr,LY,dkr,ckr,fkr,h5,S7e,mkr,gkr,xY,hkr,pkr,_kr,p5,R7e,ukr,bkr,$Y,vkr,Fkr,Tkr,_5,Kje,Ic,u5,P7e,j9,Mkr,B7e,Ekr,Zje,gr,D9,Ckr,Nc,wkr,kY,Akr,ykr,SY,Lkr,xkr,$kr,G9,kkr,I7e,Skr,Rkr,Pkr,Vt,O9,Bkr,N7e,Ikr,Nkr,qc,qkr,q7e,jkr,Dkr,RY,Gkr,Okr,Vkr,b5,Xkr,Gr,V9,zkr,j7e,Wkr,Qkr,_n,Hkr,D7e,Ukr,Jkr,G7e,Ykr,Kkr,O7e,Zkr,eSr,oSr,Ee,v5,V7e,rSr,tSr,PY,aSr,nSr,sSr,F5,X7e,lSr,iSr,BY,dSr,cSr,fSr,T5,z7e,mSr,gSr,IY,hSr,pSr,_Sr,M5,W7e,uSr,bSr,NY,vSr,FSr,TSr,E5,Q7e,MSr,ESr,qY,CSr,wSr,ASr,C5,H7e,ySr,LSr,jY,xSr,$Sr,kSr,w5,U7e,SSr,RSr,DY,PSr,BSr,ISr,A5,J7e,NSr,qSr,GY,jSr,DSr,GSr,y5,Y7e,OSr,VSr,OY,XSr,zSr,WSr,L5,K7e,QSr,HSr,VY,USr,JSr,YSr,x5,Z7e,KSr,ZSr,XY,eRr,oRr,rRr,$5,eMe,tRr,aRr,zY,nRr,sRr,lRr,k5,eDe,jc,S5,oMe,X9,iRr,rMe,dRr,oDe,hr,z9,cRr,Dc,fRr,WY,mRr,gRr,QY,hRr,pRr,_Rr,W9,uRr,tMe,bRr,vRr,FRr,Xt,Q9,TRr,aMe,MRr,ERr,Gc,CRr,nMe,wRr,ARr,HY,yRr,LRr,xRr,R5,$Rr,Or,H9,kRr,sMe,SRr,RRr,un,PRr,lMe,BRr,IRr,iMe,NRr,qRr,dMe,jRr,DRr,GRr,Le,P5,cMe,ORr,VRr,UY,XRr,zRr,WRr,B5,fMe,QRr,HRr,JY,URr,JRr,YRr,I5,mMe,KRr,ZRr,YY,ePr,oPr,rPr,N5,gMe,tPr,aPr,KY,nPr,sPr,lPr,q5,hMe,iPr,dPr,ZY,cPr,fPr,mPr,j5,pMe,gPr,hPr,eK,pPr,_Pr,uPr,D5,_Me,bPr,vPr,oK,FPr,TPr,MPr,G5,uMe,EPr,CPr,rK,wPr,APr,yPr,O5,bMe,LPr,xPr,tK,$Pr,kPr,SPr,V5,vMe,RPr,PPr,aK,BPr,IPr,NPr,X5,rDe,Oc,z5,FMe,U9,qPr,TMe,jPr,tDe,pr,J9,DPr,Vc,GPr,nK,OPr,VPr,sK,XPr,zPr,WPr,Y9,QPr,MMe,HPr,UPr,JPr,zt,K9,YPr,EMe,KPr,ZPr,Xc,eBr,CMe,oBr,rBr,lK,tBr,aBr,nBr,W5,sBr,Vr,Z9,lBr,wMe,iBr,dBr,bn,cBr,AMe,fBr,mBr,yMe,gBr,hBr,LMe,pBr,_Br,uBr,Pe,Q5,xMe,bBr,vBr,iK,FBr,TBr,MBr,H5,$Me,EBr,CBr,dK,wBr,ABr,yBr,U5,kMe,LBr,xBr,cK,$Br,kBr,SBr,J5,SMe,RBr,PBr,fK,BBr,IBr,NBr,Y5,RMe,qBr,jBr,mK,DBr,GBr,OBr,K5,PMe,VBr,XBr,gK,zBr,WBr,QBr,Z5,BMe,HBr,UBr,hK,JBr,YBr,KBr,ew,IMe,ZBr,eIr,pK,oIr,rIr,tIr,ow,NMe,aIr,nIr,_K,sIr,lIr,iIr,rw,aDe,zc,tw,qMe,ex,dIr,jMe,cIr,nDe,_r,ox,fIr,Wc,mIr,uK,gIr,hIr,bK,pIr,_Ir,uIr,rx,bIr,DMe,vIr,FIr,TIr,Wt,tx,MIr,GMe,EIr,CIr,Qc,wIr,OMe,AIr,yIr,vK,LIr,xIr,$Ir,aw,kIr,Xr,ax,SIr,VMe,RIr,PIr,vn,BIr,XMe,IIr,NIr,zMe,qIr,jIr,WMe,DIr,GIr,OIr,xe,nw,QMe,VIr,XIr,FK,zIr,WIr,QIr,sw,HMe,HIr,UIr,TK,JIr,YIr,KIr,lw,UMe,ZIr,eNr,MK,oNr,rNr,tNr,iw,JMe,aNr,nNr,EK,sNr,lNr,iNr,dw,YMe,dNr,cNr,CK,fNr,mNr,gNr,cw,KMe,hNr,pNr,wK,_Nr,uNr,bNr,fw,ZMe,vNr,FNr,AK,TNr,MNr,ENr,mw,eEe,CNr,wNr,yK,ANr,yNr,LNr,gw,oEe,xNr,$Nr,LK,kNr,SNr,RNr,hw,rEe,PNr,BNr,xK,INr,NNr,qNr,pw,sDe,Hc,_w,tEe,nx,jNr,aEe,DNr,lDe,ur,sx,GNr,Uc,ONr,$K,VNr,XNr,kK,zNr,WNr,QNr,lx,HNr,nEe,UNr,JNr,YNr,Qt,ix,KNr,sEe,ZNr,eqr,Jc,oqr,lEe,rqr,tqr,SK,aqr,nqr,sqr,uw,lqr,zr,dx,iqr,iEe,dqr,cqr,Fn,fqr,dEe,mqr,gqr,cEe,hqr,pqr,fEe,_qr,uqr,bqr,$e,bw,mEe,vqr,Fqr,RK,Tqr,Mqr,Eqr,vw,gEe,Cqr,wqr,PK,Aqr,yqr,Lqr,Fw,hEe,xqr,$qr,BK,kqr,Sqr,Rqr,Tw,pEe,Pqr,Bqr,IK,Iqr,Nqr,qqr,Mw,_Ee,jqr,Dqr,NK,Gqr,Oqr,Vqr,Ew,uEe,Xqr,zqr,qK,Wqr,Qqr,Hqr,Cw,bEe,Uqr,Jqr,jK,Yqr,Kqr,Zqr,ww,vEe,ejr,ojr,DK,rjr,tjr,ajr,Aw,FEe,njr,sjr,GK,ljr,ijr,djr,yw,TEe,cjr,fjr,OK,mjr,gjr,hjr,Lw,iDe,Yc,xw,MEe,cx,pjr,EEe,_jr,dDe,br,fx,ujr,Kc,bjr,VK,vjr,Fjr,XK,Tjr,Mjr,Ejr,mx,Cjr,CEe,wjr,Ajr,yjr,Ht,gx,Ljr,wEe,xjr,$jr,Zc,kjr,AEe,Sjr,Rjr,zK,Pjr,Bjr,Ijr,$w,Njr,Wr,hx,qjr,yEe,jjr,Djr,Tn,Gjr,LEe,Ojr,Vjr,xEe,Xjr,zjr,$Ee,Wjr,Qjr,Hjr,De,kw,kEe,Ujr,Jjr,WK,Yjr,Kjr,Zjr,Sw,SEe,eDr,oDr,QK,rDr,tDr,aDr,Rw,REe,nDr,sDr,HK,lDr,iDr,dDr,Pw,PEe,cDr,fDr,UK,mDr,gDr,hDr,Bw,BEe,pDr,_Dr,JK,uDr,bDr,vDr,Iw,IEe,FDr,TDr,YK,MDr,EDr,CDr,Nw,NEe,wDr,ADr,KK,yDr,LDr,xDr,qw,qEe,$Dr,kDr,ZK,SDr,RDr,PDr,jw,cDe,ef,Dw,jEe,px,BDr,DEe,IDr,fDe,vr,_x,NDr,of,qDr,eZ,jDr,DDr,oZ,GDr,ODr,VDr,ux,XDr,GEe,zDr,WDr,QDr,Ut,bx,HDr,OEe,UDr,JDr,rf,YDr,VEe,KDr,ZDr,rZ,eGr,oGr,rGr,Gw,tGr,Qr,vx,aGr,XEe,nGr,sGr,Mn,lGr,zEe,iGr,dGr,WEe,cGr,fGr,QEe,mGr,gGr,hGr,Ge,Ow,HEe,pGr,_Gr,tZ,uGr,bGr,vGr,Vw,UEe,FGr,TGr,aZ,MGr,EGr,CGr,Xw,JEe,wGr,AGr,nZ,yGr,LGr,xGr,zw,YEe,$Gr,kGr,sZ,SGr,RGr,PGr,Ww,KEe,BGr,IGr,lZ,NGr,qGr,jGr,Qw,ZEe,DGr,GGr,iZ,OGr,VGr,XGr,Hw,eCe,zGr,WGr,dZ,QGr,HGr,UGr,Uw,oCe,JGr,YGr,cZ,KGr,ZGr,eOr,Jw,mDe,tf,Yw,rCe,Fx,oOr,tCe,rOr,gDe,Fr,Tx,tOr,af,aOr,fZ,nOr,sOr,mZ,lOr,iOr,dOr,Mx,cOr,aCe,fOr,mOr,gOr,Jt,Ex,hOr,nCe,pOr,_Or,nf,uOr,sCe,bOr,vOr,gZ,FOr,TOr,MOr,Kw,EOr,Hr,Cx,COr,lCe,wOr,AOr,En,yOr,iCe,LOr,xOr,dCe,$Or,kOr,cCe,SOr,ROr,POr,fCe,Zw,mCe,BOr,IOr,hZ,NOr,qOr,jOr,e0,hDe,sf,o0,gCe,wx,DOr,hCe,GOr,pDe,Tr,Ax,OOr,lf,VOr,pZ,XOr,zOr,_Z,WOr,QOr,HOr,yx,UOr,pCe,JOr,YOr,KOr,Yt,Lx,ZOr,_Ce,eVr,oVr,df,rVr,uCe,tVr,aVr,uZ,nVr,sVr,lVr,r0,iVr,Ur,xx,dVr,bCe,cVr,fVr,Cn,mVr,vCe,gVr,hVr,FCe,pVr,_Vr,TCe,uVr,bVr,vVr,$x,t0,MCe,FVr,TVr,bZ,MVr,EVr,CVr,a0,ECe,wVr,AVr,vZ,yVr,LVr,xVr,n0,_De,cf,s0,CCe,kx,$Vr,wCe,kVr,uDe,Mr,Sx,SVr,ff,RVr,FZ,PVr,BVr,TZ,IVr,NVr,qVr,Rx,jVr,ACe,DVr,GVr,OVr,Kt,Px,VVr,yCe,XVr,zVr,mf,WVr,LCe,QVr,HVr,MZ,UVr,JVr,YVr,l0,KVr,Jr,Bx,ZVr,xCe,eXr,oXr,wn,rXr,$Ce,tXr,aXr,kCe,nXr,sXr,SCe,lXr,iXr,dXr,RCe,i0,PCe,cXr,fXr,EZ,mXr,gXr,hXr,d0,bDe;return d=new re({}),Ca=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),kA=new re({}),SA=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Tf=new pXr({props:{warning:!0,$$slots:{default:[nkt]},$$scope:{ctx:L}}}),RA=new re({}),PA=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/configuration_auto.py#L587"}}),NA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/configuration_auto.py#L610"}}),wg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[skt]},$$scope:{ctx:L}}}),qA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/configuration_auto.py#L733"}}),jA=new re({}),DA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/tokenization_auto.py#L391"}}),VA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17443/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/tokenization_auto.py#L405"}}),sh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[lkt]},$$scope:{ctx:L}}}),XA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/tokenization_auto.py#L604"}}),zA=new re({}),WA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/feature_extraction_auto.py#L190"}}),UA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17443/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/feature_extraction_auto.py#L204"}}),qh=new pXr({props:{$$slots:{default:[ikt]},$$scope:{ctx:L}}}),jh=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[dkt]},$$scope:{ctx:L}}}),JA=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/feature_extraction_auto.py#L331"}}),YA=new re({}),KA=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/processing_auto.py#L88"}}),oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/processing_auto.py#L102"}}),np=new pXr({props:{$$slots:{default:[ckt]},$$scope:{ctx:L}}}),sp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[fkt]},$$scope:{ctx:L}}}),ry=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/processing_auto.py#L255"}}),ty=new re({}),ay=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L739"}}),sy=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),dp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[mkt]},$$scope:{ctx:L}}}),ly=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),nu=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[gkt]},$$scope:{ctx:L}}}),iy=new re({}),dy=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L746"}}),fy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),lu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[hkt]},$$scope:{ctx:L}}}),my=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),Yu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[pkt]},$$scope:{ctx:L}}}),gy=new re({}),hy=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L761"}}),_y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),Zu=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[_kt]},$$scope:{ctx:L}}}),uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),j4=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[ukt]},$$scope:{ctx:L}}}),by=new re({}),vy=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L768"}}),Ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),G4=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[bkt]},$$scope:{ctx:L}}}),My=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),C1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[vkt]},$$scope:{ctx:L}}}),Ey=new re({}),Cy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L775"}}),Ay=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),A1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Fkt]},$$scope:{ctx:L}}}),yy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),X1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Tkt]},$$scope:{ctx:L}}}),Ly=new re({}),xy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L784"}}),ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),W1=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Mkt]},$$scope:{ctx:L}}}),Sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),Gb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Ekt]},$$scope:{ctx:L}}}),Ry=new re({}),Py=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L818"}}),Iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),Vb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Ckt]},$$scope:{ctx:L}}}),Ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),F2=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[wkt]},$$scope:{ctx:L}}}),qy=new re({}),jy=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L825"}}),Gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),M2=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Akt]},$$scope:{ctx:L}}}),Oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),x2=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[ykt]},$$scope:{ctx:L}}}),Vy=new re({}),Xy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L811"}}),Wy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),k2=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[Lkt]},$$scope:{ctx:L}}}),Qy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),gv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[xkt]},$$scope:{ctx:L}}}),Hy=new re({}),Uy=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L793"}}),Yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),pv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[$kt]},$$scope:{ctx:L}}}),Ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),t3=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[kkt]},$$scope:{ctx:L}}}),Zy=new re({}),eL=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L800"}}),rL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),n3=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Skt]},$$scope:{ctx:L}}}),tL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),i3=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Rkt]},$$scope:{ctx:L}}}),aL=new re({}),nL=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L834"}}),lL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),c3=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[Pkt]},$$scope:{ctx:L}}}),iL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),C3=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Bkt]},$$scope:{ctx:L}}}),dL=new re({}),cL=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L873"}}),mL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),A3=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Ikt]},$$scope:{ctx:L}}}),gL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),x3=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Nkt]},$$scope:{ctx:L}}}),hL=new re({}),pL=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L880"}}),uL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),k3=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[qkt]},$$scope:{ctx:L}}}),bL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),O3=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[jkt]},$$scope:{ctx:L}}}),vL=new re({}),FL=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L903"}}),ML=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),X3=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[Dkt]},$$scope:{ctx:L}}}),EL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),Y3=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[Gkt]},$$scope:{ctx:L}}}),CL=new re({}),wL=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L887"}}),yL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),Z3=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Okt]},$$scope:{ctx:L}}}),LL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),cF=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[Vkt]},$$scope:{ctx:L}}}),xL=new re({}),$L=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L894"}}),SL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),mF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Xkt]},$$scope:{ctx:L}}}),RL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),_F=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[zkt]},$$scope:{ctx:L}}}),BL=new re({}),IL=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L912"}}),qL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),bF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Wkt]},$$scope:{ctx:L}}}),jL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),wF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Qkt]},$$scope:{ctx:L}}}),DL=new re({}),GL=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L919"}}),VL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),yF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Hkt]},$$scope:{ctx:L}}}),XL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),SF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Ukt]},$$scope:{ctx:L}}}),zL=new re({}),WL=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L866"}}),HL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),PF=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[Jkt]},$$scope:{ctx:L}}}),UL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),qF=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[Ykt]},$$scope:{ctx:L}}}),YL=new re({}),KL=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L841"}}),e8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),DF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[Kkt]},$$scope:{ctx:L}}}),o8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),VF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[Zkt]},$$scope:{ctx:L}}}),r8=new re({}),t8=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L848"}}),n8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),zF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[eSt]},$$scope:{ctx:L}}}),s8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),YF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[oSt]},$$scope:{ctx:L}}}),l8=new re({}),i8=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_auto.py#L857"}}),c8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),ZF=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[rSt]},$$scope:{ctx:L}}}),f8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),rT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[tSt]},$$scope:{ctx:L}}}),m8=new re({}),g8=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L394"}}),p8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),aT=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[aSt]},$$scope:{ctx:L}}}),_8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),JT=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[nSt]},$$scope:{ctx:L}}}),u8=new re({}),b8=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L401"}}),F8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),KT=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[sSt]},$$scope:{ctx:L}}}),T8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),M7=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[lSt]},$$scope:{ctx:L}}}),M8=new re({}),E8=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L416"}}),w8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),C7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[iSt]},$$scope:{ctx:L}}}),A8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),N7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[dSt]},$$scope:{ctx:L}}}),y8=new re({}),L8=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L432"}}),$8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),j7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[cSt]},$$scope:{ctx:L}}}),k8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),X7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[fSt]},$$scope:{ctx:L}}}),S8=new re({}),R8=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L448"}}),B8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),W7=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[mSt]},$$scope:{ctx:L}}}),I8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),gM=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[gSt]},$$scope:{ctx:L}}}),N8=new re({}),q8=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L455"}}),D8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),pM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[hSt]},$$scope:{ctx:L}}}),G8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),AM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[pSt]},$$scope:{ctx:L}}}),O8=new re({}),V8=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L464"}}),z8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),LM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[_St]},$$scope:{ctx:L}}}),W8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),oE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[uSt]},$$scope:{ctx:L}}}),Q8=new re({}),H8=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),J8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),tE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[bSt]},$$scope:{ctx:L}}}),Y8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),TE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[vSt]},$$scope:{ctx:L}}}),K8=new re({}),Z8=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),o9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),EE=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[FSt]},$$scope:{ctx:L}}}),r9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),AE=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[TSt]},$$scope:{ctx:L}}}),a9=new re({}),n9=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),l9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),LE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[MSt]},$$scope:{ctx:L}}}),i9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),$E=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[ESt]},$$scope:{ctx:L}}}),d9=new re({}),c9=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),m9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),SE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[CSt]},$$scope:{ctx:L}}}),g9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),ZE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[wSt]},$$scope:{ctx:L}}}),h9=new re({}),p9=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L473"}}),u9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),oC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[ASt]},$$scope:{ctx:L}}}),b9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),MC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[ySt]},$$scope:{ctx:L}}}),v9=new re({}),F9=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),M9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),CC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[LSt]},$$scope:{ctx:L}}}),E9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),AC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[xSt]},$$scope:{ctx:L}}}),C9=new re({}),w9=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_tf_auto.py#L516"}}),y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),LC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[$St]},$$scope:{ctx:L}}}),L9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),$C=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[kSt]},$$scope:{ctx:L}}}),x9=new re({}),$9=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L241"}}),S9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),SC=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[SSt]},$$scope:{ctx:L}}}),R9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),a5=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[RSt]},$$scope:{ctx:L}}}),P9=new re({}),B9=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L255"}}),N9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),s5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[PSt]},$$scope:{ctx:L}}}),q9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),_5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[BSt]},$$scope:{ctx:L}}}),j9=new re({}),D9=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L248"}}),O9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),b5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[ISt]},$$scope:{ctx:L}}}),V9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),k5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[NSt]},$$scope:{ctx:L}}}),X9=new re({}),z9=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L262"}}),Q9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),R5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[qSt]},$$scope:{ctx:L}}}),H9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),X5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[jSt]},$$scope:{ctx:L}}}),U9=new re({}),J9=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L269"}}),K9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),W5=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[DSt]},$$scope:{ctx:L}}}),Z9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),rw=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[GSt]},$$scope:{ctx:L}}}),ex=new re({}),ox=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L278"}}),tx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),aw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[OSt]},$$scope:{ctx:L}}}),ax=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),pw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[VSt]},$$scope:{ctx:L}}}),nx=new re({}),sx=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L287"}}),ix=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),uw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[XSt]},$$scope:{ctx:L}}}),dx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),Lw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[zSt]},$$scope:{ctx:L}}}),cx=new re({}),fx=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L294"}}),gx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),$w=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[WSt]},$$scope:{ctx:L}}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),jw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[QSt]},$$scope:{ctx:L}}}),px=new re({}),_x=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L303"}}),bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),Gw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[HSt]},$$scope:{ctx:L}}}),vx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),Jw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[USt]},$$scope:{ctx:L}}}),Fx=new re({}),Tx=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L310"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),Kw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[JSt]},$$scope:{ctx:L}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),e0=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[YSt]},$$scope:{ctx:L}}}),wx=new re({}),Ax=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L319"}}),Lx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),r0=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[KSt]},$$scope:{ctx:L}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),n0=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[ZSt]},$$scope:{ctx:L}}}),kx=new re({}),Sx=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/modeling_flax_auto.py#L328"}}),Px=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L389"}}),l0=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[eRt]},$$scope:{ctx:L}}}),Bx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17443/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17443/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17443/src/transformers/models/auto/auto_factory.py#L417"}}),d0=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[oRt]},$$scope:{ctx:L}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Mo=a("span"),mi=o("Auto Classes"),_f=l(),rt=a("p"),gi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),hi=a("code"),yA=o("from_pretrained()"),uf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),je=l(),We=a("p"),pi=o("Instantiating one of "),yn=a("a"),LA=o("AutoConfig"),Ln=o(", "),xn=a("a"),xA=o("AutoModel"),_i=o(`, and
`),$n=a("a"),$A=o("AutoTokenizer"),ui=o(" will directly create a class of the relevant architecture. For instance"),bf=l(),F(Ca.$$.fragment),Qe=l(),Ae=a("p"),J$=o("will create a model that is an instance of "),bi=a("a"),Y$=o("BertModel"),K$=o("."),Eo=l(),wa=a("p"),Z$=o("There is one class of "),vf=a("code"),ek=o("AutoModel"),AOe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),pqe=l(),vi=a("h2"),Ff=a("a"),_oe=a("span"),F(kA.$$.fragment),yOe=l(),uoe=a("span"),LOe=o("Extending the Auto Classes"),_qe=l(),kn=a("p"),xOe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),boe=a("code"),$Oe=o("NewModel"),kOe=o(", make sure you have a "),voe=a("code"),SOe=o("NewModelConfig"),ROe=o(` then you can add those to the auto
classes like this:`),uqe=l(),F(SA.$$.fragment),bqe=l(),ok=a("p"),POe=o("You will then be able to use the auto classes like you would usually do!"),vqe=l(),F(Tf.$$.fragment),Fqe=l(),Fi=a("h2"),Mf=a("a"),Foe=a("span"),F(RA.$$.fragment),BOe=l(),Toe=a("span"),IOe=o("AutoConfig"),Tqe=l(),Co=a("div"),F(PA.$$.fragment),NOe=l(),BA=a("p"),qOe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),rk=a("a"),jOe=o("from_pretrained()"),DOe=o(" class method."),GOe=l(),IA=a("p"),OOe=o("This class cannot be instantiated directly using "),Moe=a("code"),VOe=o("__init__()"),XOe=o(" (throws an error)."),zOe=l(),Er=a("div"),F(NA.$$.fragment),WOe=l(),Eoe=a("p"),QOe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),HOe=l(),Ti=a("p"),UOe=o("The configuration class to instantiate is selected based on the "),Coe=a("code"),JOe=o("model_type"),YOe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),woe=a("code"),KOe=o("pretrained_model_name_or_path"),ZOe=o(":"),eVe=l(),A=a("ul"),Ef=a("li"),Aoe=a("strong"),oVe=o("albert"),rVe=o(" \u2014 "),tk=a("a"),tVe=o("AlbertConfig"),aVe=o(" (ALBERT model)"),nVe=l(),Cf=a("li"),yoe=a("strong"),sVe=o("bart"),lVe=o(" \u2014 "),ak=a("a"),iVe=o("BartConfig"),dVe=o(" (BART model)"),cVe=l(),wf=a("li"),Loe=a("strong"),fVe=o("beit"),mVe=o(" \u2014 "),nk=a("a"),gVe=o("BeitConfig"),hVe=o(" (BEiT model)"),pVe=l(),Af=a("li"),xoe=a("strong"),_Ve=o("bert"),uVe=o(" \u2014 "),sk=a("a"),bVe=o("BertConfig"),vVe=o(" (BERT model)"),FVe=l(),yf=a("li"),$oe=a("strong"),TVe=o("bert-generation"),MVe=o(" \u2014 "),lk=a("a"),EVe=o("BertGenerationConfig"),CVe=o(" (Bert Generation model)"),wVe=l(),Lf=a("li"),koe=a("strong"),AVe=o("big_bird"),yVe=o(" \u2014 "),ik=a("a"),LVe=o("BigBirdConfig"),xVe=o(" (BigBird model)"),$Ve=l(),xf=a("li"),Soe=a("strong"),kVe=o("bigbird_pegasus"),SVe=o(" \u2014 "),dk=a("a"),RVe=o("BigBirdPegasusConfig"),PVe=o(" (BigBirdPegasus model)"),BVe=l(),$f=a("li"),Roe=a("strong"),IVe=o("blenderbot"),NVe=o(" \u2014 "),ck=a("a"),qVe=o("BlenderbotConfig"),jVe=o(" (Blenderbot model)"),DVe=l(),kf=a("li"),Poe=a("strong"),GVe=o("blenderbot-small"),OVe=o(" \u2014 "),fk=a("a"),VVe=o("BlenderbotSmallConfig"),XVe=o(" (BlenderbotSmall model)"),zVe=l(),Sf=a("li"),Boe=a("strong"),WVe=o("camembert"),QVe=o(" \u2014 "),mk=a("a"),HVe=o("CamembertConfig"),UVe=o(" (CamemBERT model)"),JVe=l(),Rf=a("li"),Ioe=a("strong"),YVe=o("canine"),KVe=o(" \u2014 "),gk=a("a"),ZVe=o("CanineConfig"),eXe=o(" (Canine model)"),oXe=l(),Pf=a("li"),Noe=a("strong"),rXe=o("clip"),tXe=o(" \u2014 "),hk=a("a"),aXe=o("CLIPConfig"),nXe=o(" (CLIP model)"),sXe=l(),Bf=a("li"),qoe=a("strong"),lXe=o("codegen"),iXe=o(" \u2014 "),pk=a("a"),dXe=o("CodeGenConfig"),cXe=o(" (CodeGen model)"),fXe=l(),If=a("li"),joe=a("strong"),mXe=o("convbert"),gXe=o(" \u2014 "),_k=a("a"),hXe=o("ConvBertConfig"),pXe=o(" (ConvBERT model)"),_Xe=l(),Nf=a("li"),Doe=a("strong"),uXe=o("convnext"),bXe=o(" \u2014 "),uk=a("a"),vXe=o("ConvNextConfig"),FXe=o(" (ConvNext model)"),TXe=l(),qf=a("li"),Goe=a("strong"),MXe=o("ctrl"),EXe=o(" \u2014 "),bk=a("a"),CXe=o("CTRLConfig"),wXe=o(" (CTRL model)"),AXe=l(),jf=a("li"),Ooe=a("strong"),yXe=o("cvt"),LXe=o(" \u2014 "),vk=a("a"),xXe=o("CvtConfig"),$Xe=o(" (CvT model)"),kXe=l(),Df=a("li"),Voe=a("strong"),SXe=o("data2vec-audio"),RXe=o(" \u2014 "),Fk=a("a"),PXe=o("Data2VecAudioConfig"),BXe=o(" (Data2VecAudio model)"),IXe=l(),Gf=a("li"),Xoe=a("strong"),NXe=o("data2vec-text"),qXe=o(" \u2014 "),Tk=a("a"),jXe=o("Data2VecTextConfig"),DXe=o(" (Data2VecText model)"),GXe=l(),Of=a("li"),zoe=a("strong"),OXe=o("data2vec-vision"),VXe=o(" \u2014 "),Mk=a("a"),XXe=o("Data2VecVisionConfig"),zXe=o(" (Data2VecVision model)"),WXe=l(),Vf=a("li"),Woe=a("strong"),QXe=o("deberta"),HXe=o(" \u2014 "),Ek=a("a"),UXe=o("DebertaConfig"),JXe=o(" (DeBERTa model)"),YXe=l(),Xf=a("li"),Qoe=a("strong"),KXe=o("deberta-v2"),ZXe=o(" \u2014 "),Ck=a("a"),eze=o("DebertaV2Config"),oze=o(" (DeBERTa-v2 model)"),rze=l(),zf=a("li"),Hoe=a("strong"),tze=o("decision_transformer"),aze=o(" \u2014 "),wk=a("a"),nze=o("DecisionTransformerConfig"),sze=o(" (Decision Transformer model)"),lze=l(),Wf=a("li"),Uoe=a("strong"),ize=o("deit"),dze=o(" \u2014 "),Ak=a("a"),cze=o("DeiTConfig"),fze=o(" (DeiT model)"),mze=l(),Qf=a("li"),Joe=a("strong"),gze=o("detr"),hze=o(" \u2014 "),yk=a("a"),pze=o("DetrConfig"),_ze=o(" (DETR model)"),uze=l(),Hf=a("li"),Yoe=a("strong"),bze=o("distilbert"),vze=o(" \u2014 "),Lk=a("a"),Fze=o("DistilBertConfig"),Tze=o(" (DistilBERT model)"),Mze=l(),Uf=a("li"),Koe=a("strong"),Eze=o("dpr"),Cze=o(" \u2014 "),xk=a("a"),wze=o("DPRConfig"),Aze=o(" (DPR model)"),yze=l(),Jf=a("li"),Zoe=a("strong"),Lze=o("dpt"),xze=o(" \u2014 "),$k=a("a"),$ze=o("DPTConfig"),kze=o(" (DPT model)"),Sze=l(),Yf=a("li"),ere=a("strong"),Rze=o("electra"),Pze=o(" \u2014 "),kk=a("a"),Bze=o("ElectraConfig"),Ize=o(" (ELECTRA model)"),Nze=l(),Kf=a("li"),ore=a("strong"),qze=o("encoder-decoder"),jze=o(" \u2014 "),Sk=a("a"),Dze=o("EncoderDecoderConfig"),Gze=o(" (Encoder decoder model)"),Oze=l(),Zf=a("li"),rre=a("strong"),Vze=o("flaubert"),Xze=o(" \u2014 "),Rk=a("a"),zze=o("FlaubertConfig"),Wze=o(" (FlauBERT model)"),Qze=l(),em=a("li"),tre=a("strong"),Hze=o("flava"),Uze=o(" \u2014 "),Pk=a("a"),Jze=o("FlavaConfig"),Yze=o(" (Flava model)"),Kze=l(),om=a("li"),are=a("strong"),Zze=o("fnet"),eWe=o(" \u2014 "),Bk=a("a"),oWe=o("FNetConfig"),rWe=o(" (FNet model)"),tWe=l(),rm=a("li"),nre=a("strong"),aWe=o("fsmt"),nWe=o(" \u2014 "),Ik=a("a"),sWe=o("FSMTConfig"),lWe=o(" (FairSeq Machine-Translation model)"),iWe=l(),tm=a("li"),sre=a("strong"),dWe=o("funnel"),cWe=o(" \u2014 "),Nk=a("a"),fWe=o("FunnelConfig"),mWe=o(" (Funnel Transformer model)"),gWe=l(),am=a("li"),lre=a("strong"),hWe=o("glpn"),pWe=o(" \u2014 "),qk=a("a"),_We=o("GLPNConfig"),uWe=o(" (GLPN model)"),bWe=l(),nm=a("li"),ire=a("strong"),vWe=o("gpt2"),FWe=o(" \u2014 "),jk=a("a"),TWe=o("GPT2Config"),MWe=o(" (OpenAI GPT-2 model)"),EWe=l(),sm=a("li"),dre=a("strong"),CWe=o("gpt_neo"),wWe=o(" \u2014 "),Dk=a("a"),AWe=o("GPTNeoConfig"),yWe=o(" (GPT Neo model)"),LWe=l(),lm=a("li"),cre=a("strong"),xWe=o("gpt_neox"),$We=o(" \u2014 "),Gk=a("a"),kWe=o("GPTNeoXConfig"),SWe=o(" (GPT NeoX model)"),RWe=l(),im=a("li"),fre=a("strong"),PWe=o("gptj"),BWe=o(" \u2014 "),Ok=a("a"),IWe=o("GPTJConfig"),NWe=o(" (GPT-J model)"),qWe=l(),dm=a("li"),mre=a("strong"),jWe=o("hubert"),DWe=o(" \u2014 "),Vk=a("a"),GWe=o("HubertConfig"),OWe=o(" (Hubert model)"),VWe=l(),cm=a("li"),gre=a("strong"),XWe=o("ibert"),zWe=o(" \u2014 "),Xk=a("a"),WWe=o("IBertConfig"),QWe=o(" (I-BERT model)"),HWe=l(),fm=a("li"),hre=a("strong"),UWe=o("imagegpt"),JWe=o(" \u2014 "),zk=a("a"),YWe=o("ImageGPTConfig"),KWe=o(" (ImageGPT model)"),ZWe=l(),mm=a("li"),pre=a("strong"),eQe=o("layoutlm"),oQe=o(" \u2014 "),Wk=a("a"),rQe=o("LayoutLMConfig"),tQe=o(" (LayoutLM model)"),aQe=l(),gm=a("li"),_re=a("strong"),nQe=o("layoutlmv2"),sQe=o(" \u2014 "),Qk=a("a"),lQe=o("LayoutLMv2Config"),iQe=o(" (LayoutLMv2 model)"),dQe=l(),hm=a("li"),ure=a("strong"),cQe=o("layoutlmv3"),fQe=o(" \u2014 "),Hk=a("a"),mQe=o("LayoutLMv3Config"),gQe=o(" (LayoutLMv3 model)"),hQe=l(),pm=a("li"),bre=a("strong"),pQe=o("led"),_Qe=o(" \u2014 "),Uk=a("a"),uQe=o("LEDConfig"),bQe=o(" (LED model)"),vQe=l(),_m=a("li"),vre=a("strong"),FQe=o("longformer"),TQe=o(" \u2014 "),Jk=a("a"),MQe=o("LongformerConfig"),EQe=o(" (Longformer model)"),CQe=l(),um=a("li"),Fre=a("strong"),wQe=o("luke"),AQe=o(" \u2014 "),Yk=a("a"),yQe=o("LukeConfig"),LQe=o(" (LUKE model)"),xQe=l(),bm=a("li"),Tre=a("strong"),$Qe=o("lxmert"),kQe=o(" \u2014 "),Kk=a("a"),SQe=o("LxmertConfig"),RQe=o(" (LXMERT model)"),PQe=l(),vm=a("li"),Mre=a("strong"),BQe=o("m2m_100"),IQe=o(" \u2014 "),Zk=a("a"),NQe=o("M2M100Config"),qQe=o(" (M2M100 model)"),jQe=l(),Fm=a("li"),Ere=a("strong"),DQe=o("marian"),GQe=o(" \u2014 "),eS=a("a"),OQe=o("MarianConfig"),VQe=o(" (Marian model)"),XQe=l(),Tm=a("li"),Cre=a("strong"),zQe=o("maskformer"),WQe=o(" \u2014 "),oS=a("a"),QQe=o("MaskFormerConfig"),HQe=o(" (MaskFormer model)"),UQe=l(),Mm=a("li"),wre=a("strong"),JQe=o("mbart"),YQe=o(" \u2014 "),rS=a("a"),KQe=o("MBartConfig"),ZQe=o(" (mBART model)"),eHe=l(),Em=a("li"),Are=a("strong"),oHe=o("megatron-bert"),rHe=o(" \u2014 "),tS=a("a"),tHe=o("MegatronBertConfig"),aHe=o(" (MegatronBert model)"),nHe=l(),Cm=a("li"),yre=a("strong"),sHe=o("mobilebert"),lHe=o(" \u2014 "),aS=a("a"),iHe=o("MobileBertConfig"),dHe=o(" (MobileBERT model)"),cHe=l(),wm=a("li"),Lre=a("strong"),fHe=o("mpnet"),mHe=o(" \u2014 "),nS=a("a"),gHe=o("MPNetConfig"),hHe=o(" (MPNet model)"),pHe=l(),Am=a("li"),xre=a("strong"),_He=o("mt5"),uHe=o(" \u2014 "),sS=a("a"),bHe=o("MT5Config"),vHe=o(" (mT5 model)"),FHe=l(),ym=a("li"),$re=a("strong"),THe=o("nystromformer"),MHe=o(" \u2014 "),lS=a("a"),EHe=o("NystromformerConfig"),CHe=o(" (Nystromformer model)"),wHe=l(),Lm=a("li"),kre=a("strong"),AHe=o("openai-gpt"),yHe=o(" \u2014 "),iS=a("a"),LHe=o("OpenAIGPTConfig"),xHe=o(" (OpenAI GPT model)"),$He=l(),xm=a("li"),Sre=a("strong"),kHe=o("opt"),SHe=o(" \u2014 "),dS=a("a"),RHe=o("OPTConfig"),PHe=o(" (OPT model)"),BHe=l(),$m=a("li"),Rre=a("strong"),IHe=o("pegasus"),NHe=o(" \u2014 "),cS=a("a"),qHe=o("PegasusConfig"),jHe=o(" (Pegasus model)"),DHe=l(),km=a("li"),Pre=a("strong"),GHe=o("perceiver"),OHe=o(" \u2014 "),fS=a("a"),VHe=o("PerceiverConfig"),XHe=o(" (Perceiver model)"),zHe=l(),Sm=a("li"),Bre=a("strong"),WHe=o("plbart"),QHe=o(" \u2014 "),mS=a("a"),HHe=o("PLBartConfig"),UHe=o(" (PLBart model)"),JHe=l(),Rm=a("li"),Ire=a("strong"),YHe=o("poolformer"),KHe=o(" \u2014 "),gS=a("a"),ZHe=o("PoolFormerConfig"),eUe=o(" (PoolFormer model)"),oUe=l(),Pm=a("li"),Nre=a("strong"),rUe=o("prophetnet"),tUe=o(" \u2014 "),hS=a("a"),aUe=o("ProphetNetConfig"),nUe=o(" (ProphetNet model)"),sUe=l(),Bm=a("li"),qre=a("strong"),lUe=o("qdqbert"),iUe=o(" \u2014 "),pS=a("a"),dUe=o("QDQBertConfig"),cUe=o(" (QDQBert model)"),fUe=l(),Im=a("li"),jre=a("strong"),mUe=o("rag"),gUe=o(" \u2014 "),_S=a("a"),hUe=o("RagConfig"),pUe=o(" (RAG model)"),_Ue=l(),Nm=a("li"),Dre=a("strong"),uUe=o("realm"),bUe=o(" \u2014 "),uS=a("a"),vUe=o("RealmConfig"),FUe=o(" (Realm model)"),TUe=l(),qm=a("li"),Gre=a("strong"),MUe=o("reformer"),EUe=o(" \u2014 "),bS=a("a"),CUe=o("ReformerConfig"),wUe=o(" (Reformer model)"),AUe=l(),jm=a("li"),Ore=a("strong"),yUe=o("regnet"),LUe=o(" \u2014 "),vS=a("a"),xUe=o("RegNetConfig"),$Ue=o(" (RegNet model)"),kUe=l(),Dm=a("li"),Vre=a("strong"),SUe=o("rembert"),RUe=o(" \u2014 "),FS=a("a"),PUe=o("RemBertConfig"),BUe=o(" (RemBERT model)"),IUe=l(),Gm=a("li"),Xre=a("strong"),NUe=o("resnet"),qUe=o(" \u2014 "),TS=a("a"),jUe=o("ResNetConfig"),DUe=o(" (ResNet model)"),GUe=l(),Om=a("li"),zre=a("strong"),OUe=o("retribert"),VUe=o(" \u2014 "),MS=a("a"),XUe=o("RetriBertConfig"),zUe=o(" (RetriBERT model)"),WUe=l(),Vm=a("li"),Wre=a("strong"),QUe=o("roberta"),HUe=o(" \u2014 "),ES=a("a"),UUe=o("RobertaConfig"),JUe=o(" (RoBERTa model)"),YUe=l(),Xm=a("li"),Qre=a("strong"),KUe=o("roformer"),ZUe=o(" \u2014 "),CS=a("a"),eJe=o("RoFormerConfig"),oJe=o(" (RoFormer model)"),rJe=l(),zm=a("li"),Hre=a("strong"),tJe=o("segformer"),aJe=o(" \u2014 "),wS=a("a"),nJe=o("SegformerConfig"),sJe=o(" (SegFormer model)"),lJe=l(),Wm=a("li"),Ure=a("strong"),iJe=o("sew"),dJe=o(" \u2014 "),AS=a("a"),cJe=o("SEWConfig"),fJe=o(" (SEW model)"),mJe=l(),Qm=a("li"),Jre=a("strong"),gJe=o("sew-d"),hJe=o(" \u2014 "),yS=a("a"),pJe=o("SEWDConfig"),_Je=o(" (SEW-D model)"),uJe=l(),Hm=a("li"),Yre=a("strong"),bJe=o("speech-encoder-decoder"),vJe=o(" \u2014 "),LS=a("a"),FJe=o("SpeechEncoderDecoderConfig"),TJe=o(" (Speech Encoder decoder model)"),MJe=l(),Um=a("li"),Kre=a("strong"),EJe=o("speech_to_text"),CJe=o(" \u2014 "),xS=a("a"),wJe=o("Speech2TextConfig"),AJe=o(" (Speech2Text model)"),yJe=l(),Jm=a("li"),Zre=a("strong"),LJe=o("speech_to_text_2"),xJe=o(" \u2014 "),$S=a("a"),$Je=o("Speech2Text2Config"),kJe=o(" (Speech2Text2 model)"),SJe=l(),Ym=a("li"),ete=a("strong"),RJe=o("splinter"),PJe=o(" \u2014 "),kS=a("a"),BJe=o("SplinterConfig"),IJe=o(" (Splinter model)"),NJe=l(),Km=a("li"),ote=a("strong"),qJe=o("squeezebert"),jJe=o(" \u2014 "),SS=a("a"),DJe=o("SqueezeBertConfig"),GJe=o(" (SqueezeBERT model)"),OJe=l(),Zm=a("li"),rte=a("strong"),VJe=o("swin"),XJe=o(" \u2014 "),RS=a("a"),zJe=o("SwinConfig"),WJe=o(" (Swin model)"),QJe=l(),eg=a("li"),tte=a("strong"),HJe=o("t5"),UJe=o(" \u2014 "),PS=a("a"),JJe=o("T5Config"),YJe=o(" (T5 model)"),KJe=l(),og=a("li"),ate=a("strong"),ZJe=o("tapas"),eYe=o(" \u2014 "),BS=a("a"),oYe=o("TapasConfig"),rYe=o(" (TAPAS model)"),tYe=l(),rg=a("li"),nte=a("strong"),aYe=o("trajectory_transformer"),nYe=o(" \u2014 "),IS=a("a"),sYe=o("TrajectoryTransformerConfig"),lYe=o(" (Trajectory Transformer model)"),iYe=l(),tg=a("li"),ste=a("strong"),dYe=o("transfo-xl"),cYe=o(" \u2014 "),NS=a("a"),fYe=o("TransfoXLConfig"),mYe=o(" (Transformer-XL model)"),gYe=l(),ag=a("li"),lte=a("strong"),hYe=o("trocr"),pYe=o(" \u2014 "),qS=a("a"),_Ye=o("TrOCRConfig"),uYe=o(" (TrOCR model)"),bYe=l(),ng=a("li"),ite=a("strong"),vYe=o("unispeech"),FYe=o(" \u2014 "),jS=a("a"),TYe=o("UniSpeechConfig"),MYe=o(" (UniSpeech model)"),EYe=l(),sg=a("li"),dte=a("strong"),CYe=o("unispeech-sat"),wYe=o(" \u2014 "),DS=a("a"),AYe=o("UniSpeechSatConfig"),yYe=o(" (UniSpeechSat model)"),LYe=l(),lg=a("li"),cte=a("strong"),xYe=o("van"),$Ye=o(" \u2014 "),GS=a("a"),kYe=o("VanConfig"),SYe=o(" (VAN model)"),RYe=l(),ig=a("li"),fte=a("strong"),PYe=o("vilt"),BYe=o(" \u2014 "),OS=a("a"),IYe=o("ViltConfig"),NYe=o(" (ViLT model)"),qYe=l(),dg=a("li"),mte=a("strong"),jYe=o("vision-encoder-decoder"),DYe=o(" \u2014 "),VS=a("a"),GYe=o("VisionEncoderDecoderConfig"),OYe=o(" (Vision Encoder decoder model)"),VYe=l(),cg=a("li"),gte=a("strong"),XYe=o("vision-text-dual-encoder"),zYe=o(" \u2014 "),XS=a("a"),WYe=o("VisionTextDualEncoderConfig"),QYe=o(" (VisionTextDualEncoder model)"),HYe=l(),fg=a("li"),hte=a("strong"),UYe=o("visual_bert"),JYe=o(" \u2014 "),zS=a("a"),YYe=o("VisualBertConfig"),KYe=o(" (VisualBert model)"),ZYe=l(),mg=a("li"),pte=a("strong"),eKe=o("vit"),oKe=o(" \u2014 "),WS=a("a"),rKe=o("ViTConfig"),tKe=o(" (ViT model)"),aKe=l(),gg=a("li"),_te=a("strong"),nKe=o("vit_mae"),sKe=o(" \u2014 "),QS=a("a"),lKe=o("ViTMAEConfig"),iKe=o(" (ViTMAE model)"),dKe=l(),hg=a("li"),ute=a("strong"),cKe=o("wav2vec2"),fKe=o(" \u2014 "),HS=a("a"),mKe=o("Wav2Vec2Config"),gKe=o(" (Wav2Vec2 model)"),hKe=l(),pg=a("li"),bte=a("strong"),pKe=o("wav2vec2-conformer"),_Ke=o(" \u2014 "),US=a("a"),uKe=o("Wav2Vec2ConformerConfig"),bKe=o(" (Wav2Vec2-Conformer model)"),vKe=l(),_g=a("li"),vte=a("strong"),FKe=o("wavlm"),TKe=o(" \u2014 "),JS=a("a"),MKe=o("WavLMConfig"),EKe=o(" (WavLM model)"),CKe=l(),ug=a("li"),Fte=a("strong"),wKe=o("xglm"),AKe=o(" \u2014 "),YS=a("a"),yKe=o("XGLMConfig"),LKe=o(" (XGLM model)"),xKe=l(),bg=a("li"),Tte=a("strong"),$Ke=o("xlm"),kKe=o(" \u2014 "),KS=a("a"),SKe=o("XLMConfig"),RKe=o(" (XLM model)"),PKe=l(),vg=a("li"),Mte=a("strong"),BKe=o("xlm-prophetnet"),IKe=o(" \u2014 "),ZS=a("a"),NKe=o("XLMProphetNetConfig"),qKe=o(" (XLMProphetNet model)"),jKe=l(),Fg=a("li"),Ete=a("strong"),DKe=o("xlm-roberta"),GKe=o(" \u2014 "),eR=a("a"),OKe=o("XLMRobertaConfig"),VKe=o(" (XLM-RoBERTa model)"),XKe=l(),Tg=a("li"),Cte=a("strong"),zKe=o("xlm-roberta-xl"),WKe=o(" \u2014 "),oR=a("a"),QKe=o("XLMRobertaXLConfig"),HKe=o(" (XLM-RoBERTa-XL model)"),UKe=l(),Mg=a("li"),wte=a("strong"),JKe=o("xlnet"),YKe=o(" \u2014 "),rR=a("a"),KKe=o("XLNetConfig"),ZKe=o(" (XLNet model)"),eZe=l(),Eg=a("li"),Ate=a("strong"),oZe=o("yolos"),rZe=o(" \u2014 "),tR=a("a"),tZe=o("YolosConfig"),aZe=o(" (YOLOS model)"),nZe=l(),Cg=a("li"),yte=a("strong"),sZe=o("yoso"),lZe=o(" \u2014 "),aR=a("a"),iZe=o("YosoConfig"),dZe=o(" (YOSO model)"),cZe=l(),F(wg.$$.fragment),fZe=l(),Ag=a("div"),F(qA.$$.fragment),mZe=l(),Lte=a("p"),gZe=o("Register a new configuration for this class."),Mqe=l(),Mi=a("h2"),yg=a("a"),xte=a("span"),F(jA.$$.fragment),hZe=l(),$te=a("span"),pZe=o("AutoTokenizer"),Eqe=l(),wo=a("div"),F(DA.$$.fragment),_Ze=l(),GA=a("p"),uZe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),nR=a("a"),bZe=o("AutoTokenizer.from_pretrained()"),vZe=o(" class method."),FZe=l(),OA=a("p"),TZe=o("This class cannot be instantiated directly using "),kte=a("code"),MZe=o("__init__()"),EZe=o(" (throws an error)."),CZe=l(),Cr=a("div"),F(VA.$$.fragment),wZe=l(),Ste=a("p"),AZe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),yZe=l(),Aa=a("p"),LZe=o("The tokenizer class to instantiate is selected based on the "),Rte=a("code"),xZe=o("model_type"),$Ze=o(` property of the config object (either
passed as an argument or loaded from `),Pte=a("code"),kZe=o("pretrained_model_name_or_path"),SZe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bte=a("code"),RZe=o("pretrained_model_name_or_path"),PZe=o(":"),BZe=l(),k=a("ul"),Sn=a("li"),Ite=a("strong"),IZe=o("albert"),NZe=o(" \u2014 "),sR=a("a"),qZe=o("AlbertTokenizer"),jZe=o(" or "),lR=a("a"),DZe=o("AlbertTokenizerFast"),GZe=o(" (ALBERT model)"),OZe=l(),Rn=a("li"),Nte=a("strong"),VZe=o("bart"),XZe=o(" \u2014 "),iR=a("a"),zZe=o("BartTokenizer"),WZe=o(" or "),dR=a("a"),QZe=o("BartTokenizerFast"),HZe=o(" (BART model)"),UZe=l(),Pn=a("li"),qte=a("strong"),JZe=o("barthez"),YZe=o(" \u2014 "),cR=a("a"),KZe=o("BarthezTokenizer"),ZZe=o(" or "),fR=a("a"),eeo=o("BarthezTokenizerFast"),oeo=o(" (BARThez model)"),reo=l(),Lg=a("li"),jte=a("strong"),teo=o("bartpho"),aeo=o(" \u2014 "),mR=a("a"),neo=o("BartphoTokenizer"),seo=o(" (BARTpho model)"),leo=l(),Bn=a("li"),Dte=a("strong"),ieo=o("bert"),deo=o(" \u2014 "),gR=a("a"),ceo=o("BertTokenizer"),feo=o(" or "),hR=a("a"),meo=o("BertTokenizerFast"),geo=o(" (BERT model)"),heo=l(),xg=a("li"),Gte=a("strong"),peo=o("bert-generation"),_eo=o(" \u2014 "),pR=a("a"),ueo=o("BertGenerationTokenizer"),beo=o(" (Bert Generation model)"),veo=l(),$g=a("li"),Ote=a("strong"),Feo=o("bert-japanese"),Teo=o(" \u2014 "),_R=a("a"),Meo=o("BertJapaneseTokenizer"),Eeo=o(" (BertJapanese model)"),Ceo=l(),kg=a("li"),Vte=a("strong"),weo=o("bertweet"),Aeo=o(" \u2014 "),uR=a("a"),yeo=o("BertweetTokenizer"),Leo=o(" (Bertweet model)"),xeo=l(),In=a("li"),Xte=a("strong"),$eo=o("big_bird"),keo=o(" \u2014 "),bR=a("a"),Seo=o("BigBirdTokenizer"),Reo=o(" or "),vR=a("a"),Peo=o("BigBirdTokenizerFast"),Beo=o(" (BigBird model)"),Ieo=l(),Nn=a("li"),zte=a("strong"),Neo=o("bigbird_pegasus"),qeo=o(" \u2014 "),FR=a("a"),jeo=o("PegasusTokenizer"),Deo=o(" or "),TR=a("a"),Geo=o("PegasusTokenizerFast"),Oeo=o(" (BigBirdPegasus model)"),Veo=l(),qn=a("li"),Wte=a("strong"),Xeo=o("blenderbot"),zeo=o(" \u2014 "),MR=a("a"),Weo=o("BlenderbotTokenizer"),Qeo=o(" or "),ER=a("a"),Heo=o("BlenderbotTokenizerFast"),Ueo=o(" (Blenderbot model)"),Jeo=l(),Sg=a("li"),Qte=a("strong"),Yeo=o("blenderbot-small"),Keo=o(" \u2014 "),CR=a("a"),Zeo=o("BlenderbotSmallTokenizer"),eoo=o(" (BlenderbotSmall model)"),ooo=l(),Rg=a("li"),Hte=a("strong"),roo=o("byt5"),too=o(" \u2014 "),wR=a("a"),aoo=o("ByT5Tokenizer"),noo=o(" (ByT5 model)"),soo=l(),jn=a("li"),Ute=a("strong"),loo=o("camembert"),ioo=o(" \u2014 "),AR=a("a"),doo=o("CamembertTokenizer"),coo=o(" or "),yR=a("a"),foo=o("CamembertTokenizerFast"),moo=o(" (CamemBERT model)"),goo=l(),Pg=a("li"),Jte=a("strong"),hoo=o("canine"),poo=o(" \u2014 "),LR=a("a"),_oo=o("CanineTokenizer"),uoo=o(" (Canine model)"),boo=l(),Dn=a("li"),Yte=a("strong"),voo=o("clip"),Foo=o(" \u2014 "),xR=a("a"),Too=o("CLIPTokenizer"),Moo=o(" or "),$R=a("a"),Eoo=o("CLIPTokenizerFast"),Coo=o(" (CLIP model)"),woo=l(),Gn=a("li"),Kte=a("strong"),Aoo=o("codegen"),yoo=o(" \u2014 "),kR=a("a"),Loo=o("GPT2Tokenizer"),xoo=o(" or "),SR=a("a"),$oo=o("GPT2TokenizerFast"),koo=o(" (CodeGen model)"),Soo=l(),On=a("li"),Zte=a("strong"),Roo=o("convbert"),Poo=o(" \u2014 "),RR=a("a"),Boo=o("ConvBertTokenizer"),Ioo=o(" or "),PR=a("a"),Noo=o("ConvBertTokenizerFast"),qoo=o(" (ConvBERT model)"),joo=l(),Vn=a("li"),eae=a("strong"),Doo=o("cpm"),Goo=o(" \u2014 "),BR=a("a"),Ooo=o("CpmTokenizer"),Voo=o(" or "),IR=a("a"),Xoo=o("CpmTokenizerFast"),zoo=o(" (CPM model)"),Woo=l(),Bg=a("li"),oae=a("strong"),Qoo=o("ctrl"),Hoo=o(" \u2014 "),NR=a("a"),Uoo=o("CTRLTokenizer"),Joo=o(" (CTRL model)"),Yoo=l(),Xn=a("li"),rae=a("strong"),Koo=o("data2vec-text"),Zoo=o(" \u2014 "),qR=a("a"),ero=o("RobertaTokenizer"),oro=o(" or "),jR=a("a"),rro=o("RobertaTokenizerFast"),tro=o(" (Data2VecText model)"),aro=l(),zn=a("li"),tae=a("strong"),nro=o("deberta"),sro=o(" \u2014 "),DR=a("a"),lro=o("DebertaTokenizer"),iro=o(" or "),GR=a("a"),dro=o("DebertaTokenizerFast"),cro=o(" (DeBERTa model)"),fro=l(),Wn=a("li"),aae=a("strong"),mro=o("deberta-v2"),gro=o(" \u2014 "),OR=a("a"),hro=o("DebertaV2Tokenizer"),pro=o(" or "),VR=a("a"),_ro=o("DebertaV2TokenizerFast"),uro=o(" (DeBERTa-v2 model)"),bro=l(),Qn=a("li"),nae=a("strong"),vro=o("distilbert"),Fro=o(" \u2014 "),XR=a("a"),Tro=o("DistilBertTokenizer"),Mro=o(" or "),zR=a("a"),Ero=o("DistilBertTokenizerFast"),Cro=o(" (DistilBERT model)"),wro=l(),Hn=a("li"),sae=a("strong"),Aro=o("dpr"),yro=o(" \u2014 "),WR=a("a"),Lro=o("DPRQuestionEncoderTokenizer"),xro=o(" or "),QR=a("a"),$ro=o("DPRQuestionEncoderTokenizerFast"),kro=o(" (DPR model)"),Sro=l(),Un=a("li"),lae=a("strong"),Rro=o("electra"),Pro=o(" \u2014 "),HR=a("a"),Bro=o("ElectraTokenizer"),Iro=o(" or "),UR=a("a"),Nro=o("ElectraTokenizerFast"),qro=o(" (ELECTRA model)"),jro=l(),Ig=a("li"),iae=a("strong"),Dro=o("flaubert"),Gro=o(" \u2014 "),JR=a("a"),Oro=o("FlaubertTokenizer"),Vro=o(" (FlauBERT model)"),Xro=l(),Jn=a("li"),dae=a("strong"),zro=o("fnet"),Wro=o(" \u2014 "),YR=a("a"),Qro=o("FNetTokenizer"),Hro=o(" or "),KR=a("a"),Uro=o("FNetTokenizerFast"),Jro=o(" (FNet model)"),Yro=l(),Ng=a("li"),cae=a("strong"),Kro=o("fsmt"),Zro=o(" \u2014 "),ZR=a("a"),eto=o("FSMTTokenizer"),oto=o(" (FairSeq Machine-Translation model)"),rto=l(),Yn=a("li"),fae=a("strong"),tto=o("funnel"),ato=o(" \u2014 "),eP=a("a"),nto=o("FunnelTokenizer"),sto=o(" or "),oP=a("a"),lto=o("FunnelTokenizerFast"),ito=o(" (Funnel Transformer model)"),dto=l(),Kn=a("li"),mae=a("strong"),cto=o("gpt2"),fto=o(" \u2014 "),rP=a("a"),mto=o("GPT2Tokenizer"),gto=o(" or "),tP=a("a"),hto=o("GPT2TokenizerFast"),pto=o(" (OpenAI GPT-2 model)"),_to=l(),Zn=a("li"),gae=a("strong"),uto=o("gpt_neo"),bto=o(" \u2014 "),aP=a("a"),vto=o("GPT2Tokenizer"),Fto=o(" or "),nP=a("a"),Tto=o("GPT2TokenizerFast"),Mto=o(" (GPT Neo model)"),Eto=l(),qg=a("li"),hae=a("strong"),Cto=o("gpt_neox"),wto=o(" \u2014 "),sP=a("a"),Ato=o("GPTNeoXTokenizerFast"),yto=o(" (GPT NeoX model)"),Lto=l(),es=a("li"),pae=a("strong"),xto=o("gptj"),$to=o(" \u2014 "),lP=a("a"),kto=o("GPT2Tokenizer"),Sto=o(" or "),iP=a("a"),Rto=o("GPT2TokenizerFast"),Pto=o(" (GPT-J model)"),Bto=l(),os=a("li"),_ae=a("strong"),Ito=o("herbert"),Nto=o(" \u2014 "),dP=a("a"),qto=o("HerbertTokenizer"),jto=o(" or "),cP=a("a"),Dto=o("HerbertTokenizerFast"),Gto=o(" (HerBERT model)"),Oto=l(),jg=a("li"),uae=a("strong"),Vto=o("hubert"),Xto=o(" \u2014 "),fP=a("a"),zto=o("Wav2Vec2CTCTokenizer"),Wto=o(" (Hubert model)"),Qto=l(),rs=a("li"),bae=a("strong"),Hto=o("ibert"),Uto=o(" \u2014 "),mP=a("a"),Jto=o("RobertaTokenizer"),Yto=o(" or "),gP=a("a"),Kto=o("RobertaTokenizerFast"),Zto=o(" (I-BERT model)"),eao=l(),ts=a("li"),vae=a("strong"),oao=o("layoutlm"),rao=o(" \u2014 "),hP=a("a"),tao=o("LayoutLMTokenizer"),aao=o(" or "),pP=a("a"),nao=o("LayoutLMTokenizerFast"),sao=o(" (LayoutLM model)"),lao=l(),as=a("li"),Fae=a("strong"),iao=o("layoutlmv2"),dao=o(" \u2014 "),_P=a("a"),cao=o("LayoutLMv2Tokenizer"),fao=o(" or "),uP=a("a"),mao=o("LayoutLMv2TokenizerFast"),gao=o(" (LayoutLMv2 model)"),hao=l(),ns=a("li"),Tae=a("strong"),pao=o("layoutlmv3"),_ao=o(" \u2014 "),bP=a("a"),uao=o("LayoutLMv3Tokenizer"),bao=o(" or "),vP=a("a"),vao=o("LayoutLMv3TokenizerFast"),Fao=o(" (LayoutLMv3 model)"),Tao=l(),ss=a("li"),Mae=a("strong"),Mao=o("layoutxlm"),Eao=o(" \u2014 "),FP=a("a"),Cao=o("LayoutXLMTokenizer"),wao=o(" or "),TP=a("a"),Aao=o("LayoutXLMTokenizerFast"),yao=o(" (LayoutXLM model)"),Lao=l(),ls=a("li"),Eae=a("strong"),xao=o("led"),$ao=o(" \u2014 "),MP=a("a"),kao=o("LEDTokenizer"),Sao=o(" or "),EP=a("a"),Rao=o("LEDTokenizerFast"),Pao=o(" (LED model)"),Bao=l(),is=a("li"),Cae=a("strong"),Iao=o("longformer"),Nao=o(" \u2014 "),CP=a("a"),qao=o("LongformerTokenizer"),jao=o(" or "),wP=a("a"),Dao=o("LongformerTokenizerFast"),Gao=o(" (Longformer model)"),Oao=l(),Dg=a("li"),wae=a("strong"),Vao=o("luke"),Xao=o(" \u2014 "),AP=a("a"),zao=o("LukeTokenizer"),Wao=o(" (LUKE model)"),Qao=l(),ds=a("li"),Aae=a("strong"),Hao=o("lxmert"),Uao=o(" \u2014 "),yP=a("a"),Jao=o("LxmertTokenizer"),Yao=o(" or "),LP=a("a"),Kao=o("LxmertTokenizerFast"),Zao=o(" (LXMERT model)"),eno=l(),Gg=a("li"),yae=a("strong"),ono=o("m2m_100"),rno=o(" \u2014 "),xP=a("a"),tno=o("M2M100Tokenizer"),ano=o(" (M2M100 model)"),nno=l(),Og=a("li"),Lae=a("strong"),sno=o("marian"),lno=o(" \u2014 "),$P=a("a"),ino=o("MarianTokenizer"),dno=o(" (Marian model)"),cno=l(),cs=a("li"),xae=a("strong"),fno=o("mbart"),mno=o(" \u2014 "),kP=a("a"),gno=o("MBartTokenizer"),hno=o(" or "),SP=a("a"),pno=o("MBartTokenizerFast"),_no=o(" (mBART model)"),uno=l(),fs=a("li"),$ae=a("strong"),bno=o("mbart50"),vno=o(" \u2014 "),RP=a("a"),Fno=o("MBart50Tokenizer"),Tno=o(" or "),PP=a("a"),Mno=o("MBart50TokenizerFast"),Eno=o(" (mBART-50 model)"),Cno=l(),ms=a("li"),kae=a("strong"),wno=o("megatron-bert"),Ano=o(" \u2014 "),BP=a("a"),yno=o("BertTokenizer"),Lno=o(" or "),IP=a("a"),xno=o("BertTokenizerFast"),$no=o(" (MegatronBert model)"),kno=l(),Vg=a("li"),Sae=a("strong"),Sno=o("mluke"),Rno=o(" \u2014 "),NP=a("a"),Pno=o("MLukeTokenizer"),Bno=o(" (mLUKE model)"),Ino=l(),gs=a("li"),Rae=a("strong"),Nno=o("mobilebert"),qno=o(" \u2014 "),qP=a("a"),jno=o("MobileBertTokenizer"),Dno=o(" or "),jP=a("a"),Gno=o("MobileBertTokenizerFast"),Ono=o(" (MobileBERT model)"),Vno=l(),hs=a("li"),Pae=a("strong"),Xno=o("mpnet"),zno=o(" \u2014 "),DP=a("a"),Wno=o("MPNetTokenizer"),Qno=o(" or "),GP=a("a"),Hno=o("MPNetTokenizerFast"),Uno=o(" (MPNet model)"),Jno=l(),ps=a("li"),Bae=a("strong"),Yno=o("mt5"),Kno=o(" \u2014 "),OP=a("a"),Zno=o("MT5Tokenizer"),eso=o(" or "),VP=a("a"),oso=o("MT5TokenizerFast"),rso=o(" (mT5 model)"),tso=l(),_s=a("li"),Iae=a("strong"),aso=o("nystromformer"),nso=o(" \u2014 "),XP=a("a"),sso=o("AlbertTokenizer"),lso=o(" or "),zP=a("a"),iso=o("AlbertTokenizerFast"),dso=o(" (Nystromformer model)"),cso=l(),us=a("li"),Nae=a("strong"),fso=o("openai-gpt"),mso=o(" \u2014 "),WP=a("a"),gso=o("OpenAIGPTTokenizer"),hso=o(" or "),QP=a("a"),pso=o("OpenAIGPTTokenizerFast"),_so=o(" (OpenAI GPT model)"),uso=l(),Xg=a("li"),qae=a("strong"),bso=o("opt"),vso=o(" \u2014 "),HP=a("a"),Fso=o("GPT2Tokenizer"),Tso=o(" (OPT model)"),Mso=l(),bs=a("li"),jae=a("strong"),Eso=o("pegasus"),Cso=o(" \u2014 "),UP=a("a"),wso=o("PegasusTokenizer"),Aso=o(" or "),JP=a("a"),yso=o("PegasusTokenizerFast"),Lso=o(" (Pegasus model)"),xso=l(),zg=a("li"),Dae=a("strong"),$so=o("perceiver"),kso=o(" \u2014 "),YP=a("a"),Sso=o("PerceiverTokenizer"),Rso=o(" (Perceiver model)"),Pso=l(),Wg=a("li"),Gae=a("strong"),Bso=o("phobert"),Iso=o(" \u2014 "),KP=a("a"),Nso=o("PhobertTokenizer"),qso=o(" (PhoBERT model)"),jso=l(),Qg=a("li"),Oae=a("strong"),Dso=o("plbart"),Gso=o(" \u2014 "),ZP=a("a"),Oso=o("PLBartTokenizer"),Vso=o(" (PLBart model)"),Xso=l(),Hg=a("li"),Vae=a("strong"),zso=o("prophetnet"),Wso=o(" \u2014 "),eB=a("a"),Qso=o("ProphetNetTokenizer"),Hso=o(" (ProphetNet model)"),Uso=l(),vs=a("li"),Xae=a("strong"),Jso=o("qdqbert"),Yso=o(" \u2014 "),oB=a("a"),Kso=o("BertTokenizer"),Zso=o(" or "),rB=a("a"),elo=o("BertTokenizerFast"),olo=o(" (QDQBert model)"),rlo=l(),Ug=a("li"),zae=a("strong"),tlo=o("rag"),alo=o(" \u2014 "),tB=a("a"),nlo=o("RagTokenizer"),slo=o(" (RAG model)"),llo=l(),Fs=a("li"),Wae=a("strong"),ilo=o("realm"),dlo=o(" \u2014 "),aB=a("a"),clo=o("RealmTokenizer"),flo=o(" or "),nB=a("a"),mlo=o("RealmTokenizerFast"),glo=o(" (Realm model)"),hlo=l(),Ts=a("li"),Qae=a("strong"),plo=o("reformer"),_lo=o(" \u2014 "),sB=a("a"),ulo=o("ReformerTokenizer"),blo=o(" or "),lB=a("a"),vlo=o("ReformerTokenizerFast"),Flo=o(" (Reformer model)"),Tlo=l(),Ms=a("li"),Hae=a("strong"),Mlo=o("rembert"),Elo=o(" \u2014 "),iB=a("a"),Clo=o("RemBertTokenizer"),wlo=o(" or "),dB=a("a"),Alo=o("RemBertTokenizerFast"),ylo=o(" (RemBERT model)"),Llo=l(),Es=a("li"),Uae=a("strong"),xlo=o("retribert"),$lo=o(" \u2014 "),cB=a("a"),klo=o("RetriBertTokenizer"),Slo=o(" or "),fB=a("a"),Rlo=o("RetriBertTokenizerFast"),Plo=o(" (RetriBERT model)"),Blo=l(),Cs=a("li"),Jae=a("strong"),Ilo=o("roberta"),Nlo=o(" \u2014 "),mB=a("a"),qlo=o("RobertaTokenizer"),jlo=o(" or "),gB=a("a"),Dlo=o("RobertaTokenizerFast"),Glo=o(" (RoBERTa model)"),Olo=l(),ws=a("li"),Yae=a("strong"),Vlo=o("roformer"),Xlo=o(" \u2014 "),hB=a("a"),zlo=o("RoFormerTokenizer"),Wlo=o(" or "),pB=a("a"),Qlo=o("RoFormerTokenizerFast"),Hlo=o(" (RoFormer model)"),Ulo=l(),Jg=a("li"),Kae=a("strong"),Jlo=o("speech_to_text"),Ylo=o(" \u2014 "),_B=a("a"),Klo=o("Speech2TextTokenizer"),Zlo=o(" (Speech2Text model)"),eio=l(),Yg=a("li"),Zae=a("strong"),oio=o("speech_to_text_2"),rio=o(" \u2014 "),uB=a("a"),tio=o("Speech2Text2Tokenizer"),aio=o(" (Speech2Text2 model)"),nio=l(),As=a("li"),ene=a("strong"),sio=o("splinter"),lio=o(" \u2014 "),bB=a("a"),iio=o("SplinterTokenizer"),dio=o(" or "),vB=a("a"),cio=o("SplinterTokenizerFast"),fio=o(" (Splinter model)"),mio=l(),ys=a("li"),one=a("strong"),gio=o("squeezebert"),hio=o(" \u2014 "),FB=a("a"),pio=o("SqueezeBertTokenizer"),_io=o(" or "),TB=a("a"),uio=o("SqueezeBertTokenizerFast"),bio=o(" (SqueezeBERT model)"),vio=l(),Ls=a("li"),rne=a("strong"),Fio=o("t5"),Tio=o(" \u2014 "),MB=a("a"),Mio=o("T5Tokenizer"),Eio=o(" or "),EB=a("a"),Cio=o("T5TokenizerFast"),wio=o(" (T5 model)"),Aio=l(),Kg=a("li"),tne=a("strong"),yio=o("tapas"),Lio=o(" \u2014 "),CB=a("a"),xio=o("TapasTokenizer"),$io=o(" (TAPAS model)"),kio=l(),Zg=a("li"),ane=a("strong"),Sio=o("tapex"),Rio=o(" \u2014 "),wB=a("a"),Pio=o("TapexTokenizer"),Bio=o(" (TAPEX model)"),Iio=l(),eh=a("li"),nne=a("strong"),Nio=o("transfo-xl"),qio=o(" \u2014 "),AB=a("a"),jio=o("TransfoXLTokenizer"),Dio=o(" (Transformer-XL model)"),Gio=l(),xs=a("li"),sne=a("strong"),Oio=o("visual_bert"),Vio=o(" \u2014 "),yB=a("a"),Xio=o("BertTokenizer"),zio=o(" or "),LB=a("a"),Wio=o("BertTokenizerFast"),Qio=o(" (VisualBert model)"),Hio=l(),oh=a("li"),lne=a("strong"),Uio=o("wav2vec2"),Jio=o(" \u2014 "),xB=a("a"),Yio=o("Wav2Vec2CTCTokenizer"),Kio=o(" (Wav2Vec2 model)"),Zio=l(),rh=a("li"),ine=a("strong"),edo=o("wav2vec2-conformer"),odo=o(" \u2014 "),$B=a("a"),rdo=o("Wav2Vec2CTCTokenizer"),tdo=o(" (Wav2Vec2-Conformer model)"),ado=l(),th=a("li"),dne=a("strong"),ndo=o("wav2vec2_phoneme"),sdo=o(" \u2014 "),kB=a("a"),ldo=o("Wav2Vec2PhonemeCTCTokenizer"),ido=o(" (Wav2Vec2Phoneme model)"),ddo=l(),$s=a("li"),cne=a("strong"),cdo=o("xglm"),fdo=o(" \u2014 "),SB=a("a"),mdo=o("XGLMTokenizer"),gdo=o(" or "),RB=a("a"),hdo=o("XGLMTokenizerFast"),pdo=o(" (XGLM model)"),_do=l(),ah=a("li"),fne=a("strong"),udo=o("xlm"),bdo=o(" \u2014 "),PB=a("a"),vdo=o("XLMTokenizer"),Fdo=o(" (XLM model)"),Tdo=l(),nh=a("li"),mne=a("strong"),Mdo=o("xlm-prophetnet"),Edo=o(" \u2014 "),BB=a("a"),Cdo=o("XLMProphetNetTokenizer"),wdo=o(" (XLMProphetNet model)"),Ado=l(),ks=a("li"),gne=a("strong"),ydo=o("xlm-roberta"),Ldo=o(" \u2014 "),IB=a("a"),xdo=o("XLMRobertaTokenizer"),$do=o(" or "),NB=a("a"),kdo=o("XLMRobertaTokenizerFast"),Sdo=o(" (XLM-RoBERTa model)"),Rdo=l(),Ss=a("li"),hne=a("strong"),Pdo=o("xlm-roberta-xl"),Bdo=o(" \u2014 "),qB=a("a"),Ido=o("RobertaTokenizer"),Ndo=o(" or "),jB=a("a"),qdo=o("RobertaTokenizerFast"),jdo=o(" (XLM-RoBERTa-XL model)"),Ddo=l(),Rs=a("li"),pne=a("strong"),Gdo=o("xlnet"),Odo=o(" \u2014 "),DB=a("a"),Vdo=o("XLNetTokenizer"),Xdo=o(" or "),GB=a("a"),zdo=o("XLNetTokenizerFast"),Wdo=o(" (XLNet model)"),Qdo=l(),Ps=a("li"),_ne=a("strong"),Hdo=o("yoso"),Udo=o(" \u2014 "),OB=a("a"),Jdo=o("AlbertTokenizer"),Ydo=o(" or "),VB=a("a"),Kdo=o("AlbertTokenizerFast"),Zdo=o(" (YOSO model)"),eco=l(),F(sh.$$.fragment),oco=l(),lh=a("div"),F(XA.$$.fragment),rco=l(),une=a("p"),tco=o("Register a new tokenizer in this mapping."),Cqe=l(),Ei=a("h2"),ih=a("a"),bne=a("span"),F(zA.$$.fragment),aco=l(),vne=a("span"),nco=o("AutoFeatureExtractor"),wqe=l(),Ao=a("div"),F(WA.$$.fragment),sco=l(),QA=a("p"),lco=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),XB=a("a"),ico=o("AutoFeatureExtractor.from_pretrained()"),dco=o(" class method."),cco=l(),HA=a("p"),fco=o("This class cannot be instantiated directly using "),Fne=a("code"),mco=o("__init__()"),gco=o(" (throws an error)."),hco=l(),He=a("div"),F(UA.$$.fragment),pco=l(),Tne=a("p"),_co=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),uco=l(),ya=a("p"),bco=o("The feature extractor class to instantiate is selected based on the "),Mne=a("code"),vco=o("model_type"),Fco=o(` property of the config object
(either passed as an argument or loaded from `),Ene=a("code"),Tco=o("pretrained_model_name_or_path"),Mco=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Cne=a("code"),Eco=o("pretrained_model_name_or_path"),Cco=o(":"),wco=l(),Y=a("ul"),dh=a("li"),wne=a("strong"),Aco=o("beit"),yco=o(" \u2014 "),zB=a("a"),Lco=o("BeitFeatureExtractor"),xco=o(" (BEiT model)"),$co=l(),ch=a("li"),Ane=a("strong"),kco=o("clip"),Sco=o(" \u2014 "),WB=a("a"),Rco=o("CLIPFeatureExtractor"),Pco=o(" (CLIP model)"),Bco=l(),fh=a("li"),yne=a("strong"),Ico=o("convnext"),Nco=o(" \u2014 "),QB=a("a"),qco=o("ConvNextFeatureExtractor"),jco=o(" (ConvNext model)"),Dco=l(),mh=a("li"),Lne=a("strong"),Gco=o("cvt"),Oco=o(" \u2014 "),HB=a("a"),Vco=o("ConvNextFeatureExtractor"),Xco=o(" (CvT model)"),zco=l(),gh=a("li"),xne=a("strong"),Wco=o("data2vec-audio"),Qco=o(" \u2014 "),UB=a("a"),Hco=o("Wav2Vec2FeatureExtractor"),Uco=o(" (Data2VecAudio model)"),Jco=l(),hh=a("li"),$ne=a("strong"),Yco=o("data2vec-vision"),Kco=o(" \u2014 "),JB=a("a"),Zco=o("BeitFeatureExtractor"),efo=o(" (Data2VecVision model)"),ofo=l(),ph=a("li"),kne=a("strong"),rfo=o("deit"),tfo=o(" \u2014 "),YB=a("a"),afo=o("DeiTFeatureExtractor"),nfo=o(" (DeiT model)"),sfo=l(),_h=a("li"),Sne=a("strong"),lfo=o("detr"),ifo=o(" \u2014 "),KB=a("a"),dfo=o("DetrFeatureExtractor"),cfo=o(" (DETR model)"),ffo=l(),uh=a("li"),Rne=a("strong"),mfo=o("dpt"),gfo=o(" \u2014 "),ZB=a("a"),hfo=o("DPTFeatureExtractor"),pfo=o(" (DPT model)"),_fo=l(),bh=a("li"),Pne=a("strong"),ufo=o("flava"),bfo=o(" \u2014 "),eI=a("a"),vfo=o("FlavaFeatureExtractor"),Ffo=o(" (Flava model)"),Tfo=l(),vh=a("li"),Bne=a("strong"),Mfo=o("glpn"),Efo=o(" \u2014 "),oI=a("a"),Cfo=o("GLPNFeatureExtractor"),wfo=o(" (GLPN model)"),Afo=l(),Fh=a("li"),Ine=a("strong"),yfo=o("hubert"),Lfo=o(" \u2014 "),rI=a("a"),xfo=o("Wav2Vec2FeatureExtractor"),$fo=o(" (Hubert model)"),kfo=l(),Th=a("li"),Nne=a("strong"),Sfo=o("imagegpt"),Rfo=o(" \u2014 "),tI=a("a"),Pfo=o("ImageGPTFeatureExtractor"),Bfo=o(" (ImageGPT model)"),Ifo=l(),Mh=a("li"),qne=a("strong"),Nfo=o("layoutlmv2"),qfo=o(" \u2014 "),aI=a("a"),jfo=o("LayoutLMv2FeatureExtractor"),Dfo=o(" (LayoutLMv2 model)"),Gfo=l(),Eh=a("li"),jne=a("strong"),Ofo=o("layoutlmv3"),Vfo=o(" \u2014 "),nI=a("a"),Xfo=o("LayoutLMv3FeatureExtractor"),zfo=o(" (LayoutLMv3 model)"),Wfo=l(),Ch=a("li"),Dne=a("strong"),Qfo=o("maskformer"),Hfo=o(" \u2014 "),sI=a("a"),Ufo=o("MaskFormerFeatureExtractor"),Jfo=o(" (MaskFormer model)"),Yfo=l(),wh=a("li"),Gne=a("strong"),Kfo=o("perceiver"),Zfo=o(" \u2014 "),lI=a("a"),emo=o("PerceiverFeatureExtractor"),omo=o(" (Perceiver model)"),rmo=l(),Ah=a("li"),One=a("strong"),tmo=o("poolformer"),amo=o(" \u2014 "),iI=a("a"),nmo=o("PoolFormerFeatureExtractor"),smo=o(" (PoolFormer model)"),lmo=l(),yh=a("li"),Vne=a("strong"),imo=o("regnet"),dmo=o(" \u2014 "),dI=a("a"),cmo=o("ConvNextFeatureExtractor"),fmo=o(" (RegNet model)"),mmo=l(),Lh=a("li"),Xne=a("strong"),gmo=o("resnet"),hmo=o(" \u2014 "),cI=a("a"),pmo=o("ConvNextFeatureExtractor"),_mo=o(" (ResNet model)"),umo=l(),xh=a("li"),zne=a("strong"),bmo=o("segformer"),vmo=o(" \u2014 "),fI=a("a"),Fmo=o("SegformerFeatureExtractor"),Tmo=o(" (SegFormer model)"),Mmo=l(),$h=a("li"),Wne=a("strong"),Emo=o("speech_to_text"),Cmo=o(" \u2014 "),mI=a("a"),wmo=o("Speech2TextFeatureExtractor"),Amo=o(" (Speech2Text model)"),ymo=l(),kh=a("li"),Qne=a("strong"),Lmo=o("swin"),xmo=o(" \u2014 "),gI=a("a"),$mo=o("ViTFeatureExtractor"),kmo=o(" (Swin model)"),Smo=l(),Sh=a("li"),Hne=a("strong"),Rmo=o("van"),Pmo=o(" \u2014 "),hI=a("a"),Bmo=o("ConvNextFeatureExtractor"),Imo=o(" (VAN model)"),Nmo=l(),Rh=a("li"),Une=a("strong"),qmo=o("vit"),jmo=o(" \u2014 "),pI=a("a"),Dmo=o("ViTFeatureExtractor"),Gmo=o(" (ViT model)"),Omo=l(),Ph=a("li"),Jne=a("strong"),Vmo=o("vit_mae"),Xmo=o(" \u2014 "),_I=a("a"),zmo=o("ViTFeatureExtractor"),Wmo=o(" (ViTMAE model)"),Qmo=l(),Bh=a("li"),Yne=a("strong"),Hmo=o("wav2vec2"),Umo=o(" \u2014 "),uI=a("a"),Jmo=o("Wav2Vec2FeatureExtractor"),Ymo=o(" (Wav2Vec2 model)"),Kmo=l(),Ih=a("li"),Kne=a("strong"),Zmo=o("wav2vec2-conformer"),ego=o(" \u2014 "),bI=a("a"),ogo=o("Wav2Vec2FeatureExtractor"),rgo=o(" (Wav2Vec2-Conformer model)"),tgo=l(),Nh=a("li"),Zne=a("strong"),ago=o("yolos"),ngo=o(" \u2014 "),vI=a("a"),sgo=o("YolosFeatureExtractor"),lgo=o(" (YOLOS model)"),igo=l(),F(qh.$$.fragment),dgo=l(),F(jh.$$.fragment),cgo=l(),Dh=a("div"),F(JA.$$.fragment),fgo=l(),ese=a("p"),mgo=o("Register a new feature extractor for this class."),Aqe=l(),Ci=a("h2"),Gh=a("a"),ose=a("span"),F(YA.$$.fragment),ggo=l(),rse=a("span"),hgo=o("AutoProcessor"),yqe=l(),yo=a("div"),F(KA.$$.fragment),pgo=l(),ZA=a("p"),_go=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),FI=a("a"),ugo=o("AutoProcessor.from_pretrained()"),bgo=o(" class method."),vgo=l(),ey=a("p"),Fgo=o("This class cannot be instantiated directly using "),tse=a("code"),Tgo=o("__init__()"),Mgo=o(" (throws an error)."),Ego=l(),Ue=a("div"),F(oy.$$.fragment),Cgo=l(),ase=a("p"),wgo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Ago=l(),wi=a("p"),ygo=o("The processor class to instantiate is selected based on the "),nse=a("code"),Lgo=o("model_type"),xgo=o(` property of the config object (either
passed as an argument or loaded from `),sse=a("code"),$go=o("pretrained_model_name_or_path"),kgo=o(" if possible):"),Sgo=l(),he=a("ul"),Oh=a("li"),lse=a("strong"),Rgo=o("clip"),Pgo=o(" \u2014 "),TI=a("a"),Bgo=o("CLIPProcessor"),Igo=o(" (CLIP model)"),Ngo=l(),Vh=a("li"),ise=a("strong"),qgo=o("flava"),jgo=o(" \u2014 "),dse=a("code"),Dgo=o("FLAVAProcessor"),Ggo=o(" (Flava model)"),Ogo=l(),Xh=a("li"),cse=a("strong"),Vgo=o("layoutlmv2"),Xgo=o(" \u2014 "),MI=a("a"),zgo=o("LayoutLMv2Processor"),Wgo=o(" (LayoutLMv2 model)"),Qgo=l(),zh=a("li"),fse=a("strong"),Hgo=o("layoutlmv3"),Ugo=o(" \u2014 "),EI=a("a"),Jgo=o("LayoutLMv3Processor"),Ygo=o(" (LayoutLMv3 model)"),Kgo=l(),Wh=a("li"),mse=a("strong"),Zgo=o("layoutxlm"),eho=o(" \u2014 "),CI=a("a"),oho=o("LayoutXLMProcessor"),rho=o(" (LayoutXLM model)"),tho=l(),Qh=a("li"),gse=a("strong"),aho=o("sew"),nho=o(" \u2014 "),wI=a("a"),sho=o("Wav2Vec2Processor"),lho=o(" (SEW model)"),iho=l(),Hh=a("li"),hse=a("strong"),dho=o("sew-d"),cho=o(" \u2014 "),AI=a("a"),fho=o("Wav2Vec2Processor"),mho=o(" (SEW-D model)"),gho=l(),Uh=a("li"),pse=a("strong"),hho=o("speech_to_text"),pho=o(" \u2014 "),yI=a("a"),_ho=o("Speech2TextProcessor"),uho=o(" (Speech2Text model)"),bho=l(),Jh=a("li"),_se=a("strong"),vho=o("speech_to_text_2"),Fho=o(" \u2014 "),LI=a("a"),Tho=o("Speech2Text2Processor"),Mho=o(" (Speech2Text2 model)"),Eho=l(),Yh=a("li"),use=a("strong"),Cho=o("trocr"),who=o(" \u2014 "),xI=a("a"),Aho=o("TrOCRProcessor"),yho=o(" (TrOCR model)"),Lho=l(),Kh=a("li"),bse=a("strong"),xho=o("unispeech"),$ho=o(" \u2014 "),$I=a("a"),kho=o("Wav2Vec2Processor"),Sho=o(" (UniSpeech model)"),Rho=l(),Zh=a("li"),vse=a("strong"),Pho=o("unispeech-sat"),Bho=o(" \u2014 "),kI=a("a"),Iho=o("Wav2Vec2Processor"),Nho=o(" (UniSpeechSat model)"),qho=l(),ep=a("li"),Fse=a("strong"),jho=o("vilt"),Dho=o(" \u2014 "),SI=a("a"),Gho=o("ViltProcessor"),Oho=o(" (ViLT model)"),Vho=l(),op=a("li"),Tse=a("strong"),Xho=o("vision-text-dual-encoder"),zho=o(" \u2014 "),RI=a("a"),Who=o("VisionTextDualEncoderProcessor"),Qho=o(" (VisionTextDualEncoder model)"),Hho=l(),rp=a("li"),Mse=a("strong"),Uho=o("wav2vec2"),Jho=o(" \u2014 "),PI=a("a"),Yho=o("Wav2Vec2Processor"),Kho=o(" (Wav2Vec2 model)"),Zho=l(),tp=a("li"),Ese=a("strong"),epo=o("wav2vec2-conformer"),opo=o(" \u2014 "),BI=a("a"),rpo=o("Wav2Vec2Processor"),tpo=o(" (Wav2Vec2-Conformer model)"),apo=l(),ap=a("li"),Cse=a("strong"),npo=o("wavlm"),spo=o(" \u2014 "),II=a("a"),lpo=o("Wav2Vec2Processor"),ipo=o(" (WavLM model)"),dpo=l(),F(np.$$.fragment),cpo=l(),F(sp.$$.fragment),fpo=l(),lp=a("div"),F(ry.$$.fragment),mpo=l(),wse=a("p"),gpo=o("Register a new processor for this class."),Lqe=l(),Ai=a("h2"),ip=a("a"),Ase=a("span"),F(ty.$$.fragment),hpo=l(),yse=a("span"),ppo=o("AutoModel"),xqe=l(),Lo=a("div"),F(ay.$$.fragment),_po=l(),yi=a("p"),upo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),NI=a("a"),bpo=o("from_pretrained()"),vpo=o(" class method or the "),qI=a("a"),Fpo=o("from_config()"),Tpo=o(` class
method.`),Mpo=l(),ny=a("p"),Epo=o("This class cannot be instantiated directly using "),Lse=a("code"),Cpo=o("__init__()"),wpo=o(" (throws an error)."),Apo=l(),tt=a("div"),F(sy.$$.fragment),ypo=l(),xse=a("p"),Lpo=o("Instantiates one of the base model classes of the library from a configuration."),xpo=l(),Li=a("p"),$po=o(`Note:
Loading a model from its configuration file does `),$se=a("strong"),kpo=o("not"),Spo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jI=a("a"),Rpo=o("from_pretrained()"),Ppo=o(" to load the model weights."),Bpo=l(),F(dp.$$.fragment),Ipo=l(),Je=a("div"),F(ly.$$.fragment),Npo=l(),kse=a("p"),qpo=o("Instantiate one of the base model classes of the library from a pretrained model."),jpo=l(),La=a("p"),Dpo=o("The model class to instantiate is selected based on the "),Sse=a("code"),Gpo=o("model_type"),Opo=o(` property of the config object (either
passed as an argument or loaded from `),Rse=a("code"),Vpo=o("pretrained_model_name_or_path"),Xpo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pse=a("code"),zpo=o("pretrained_model_name_or_path"),Wpo=o(":"),Qpo=l(),x=a("ul"),cp=a("li"),Bse=a("strong"),Hpo=o("albert"),Upo=o(" \u2014 "),DI=a("a"),Jpo=o("AlbertModel"),Ypo=o(" (ALBERT model)"),Kpo=l(),fp=a("li"),Ise=a("strong"),Zpo=o("bart"),e_o=o(" \u2014 "),GI=a("a"),o_o=o("BartModel"),r_o=o(" (BART model)"),t_o=l(),mp=a("li"),Nse=a("strong"),a_o=o("beit"),n_o=o(" \u2014 "),OI=a("a"),s_o=o("BeitModel"),l_o=o(" (BEiT model)"),i_o=l(),gp=a("li"),qse=a("strong"),d_o=o("bert"),c_o=o(" \u2014 "),VI=a("a"),f_o=o("BertModel"),m_o=o(" (BERT model)"),g_o=l(),hp=a("li"),jse=a("strong"),h_o=o("bert-generation"),p_o=o(" \u2014 "),XI=a("a"),__o=o("BertGenerationEncoder"),u_o=o(" (Bert Generation model)"),b_o=l(),pp=a("li"),Dse=a("strong"),v_o=o("big_bird"),F_o=o(" \u2014 "),zI=a("a"),T_o=o("BigBirdModel"),M_o=o(" (BigBird model)"),E_o=l(),_p=a("li"),Gse=a("strong"),C_o=o("bigbird_pegasus"),w_o=o(" \u2014 "),WI=a("a"),A_o=o("BigBirdPegasusModel"),y_o=o(" (BigBirdPegasus model)"),L_o=l(),up=a("li"),Ose=a("strong"),x_o=o("blenderbot"),$_o=o(" \u2014 "),QI=a("a"),k_o=o("BlenderbotModel"),S_o=o(" (Blenderbot model)"),R_o=l(),bp=a("li"),Vse=a("strong"),P_o=o("blenderbot-small"),B_o=o(" \u2014 "),HI=a("a"),I_o=o("BlenderbotSmallModel"),N_o=o(" (BlenderbotSmall model)"),q_o=l(),vp=a("li"),Xse=a("strong"),j_o=o("camembert"),D_o=o(" \u2014 "),UI=a("a"),G_o=o("CamembertModel"),O_o=o(" (CamemBERT model)"),V_o=l(),Fp=a("li"),zse=a("strong"),X_o=o("canine"),z_o=o(" \u2014 "),JI=a("a"),W_o=o("CanineModel"),Q_o=o(" (Canine model)"),H_o=l(),Tp=a("li"),Wse=a("strong"),U_o=o("clip"),J_o=o(" \u2014 "),YI=a("a"),Y_o=o("CLIPModel"),K_o=o(" (CLIP model)"),Z_o=l(),Mp=a("li"),Qse=a("strong"),euo=o("codegen"),ouo=o(" \u2014 "),KI=a("a"),ruo=o("CodeGenModel"),tuo=o(" (CodeGen model)"),auo=l(),Ep=a("li"),Hse=a("strong"),nuo=o("convbert"),suo=o(" \u2014 "),ZI=a("a"),luo=o("ConvBertModel"),iuo=o(" (ConvBERT model)"),duo=l(),Cp=a("li"),Use=a("strong"),cuo=o("convnext"),fuo=o(" \u2014 "),eN=a("a"),muo=o("ConvNextModel"),guo=o(" (ConvNext model)"),huo=l(),wp=a("li"),Jse=a("strong"),puo=o("ctrl"),_uo=o(" \u2014 "),oN=a("a"),uuo=o("CTRLModel"),buo=o(" (CTRL model)"),vuo=l(),Ap=a("li"),Yse=a("strong"),Fuo=o("cvt"),Tuo=o(" \u2014 "),rN=a("a"),Muo=o("CvtModel"),Euo=o(" (CvT model)"),Cuo=l(),yp=a("li"),Kse=a("strong"),wuo=o("data2vec-audio"),Auo=o(" \u2014 "),tN=a("a"),yuo=o("Data2VecAudioModel"),Luo=o(" (Data2VecAudio model)"),xuo=l(),Lp=a("li"),Zse=a("strong"),$uo=o("data2vec-text"),kuo=o(" \u2014 "),aN=a("a"),Suo=o("Data2VecTextModel"),Ruo=o(" (Data2VecText model)"),Puo=l(),xp=a("li"),ele=a("strong"),Buo=o("data2vec-vision"),Iuo=o(" \u2014 "),nN=a("a"),Nuo=o("Data2VecVisionModel"),quo=o(" (Data2VecVision model)"),juo=l(),$p=a("li"),ole=a("strong"),Duo=o("deberta"),Guo=o(" \u2014 "),sN=a("a"),Ouo=o("DebertaModel"),Vuo=o(" (DeBERTa model)"),Xuo=l(),kp=a("li"),rle=a("strong"),zuo=o("deberta-v2"),Wuo=o(" \u2014 "),lN=a("a"),Quo=o("DebertaV2Model"),Huo=o(" (DeBERTa-v2 model)"),Uuo=l(),Sp=a("li"),tle=a("strong"),Juo=o("decision_transformer"),Yuo=o(" \u2014 "),iN=a("a"),Kuo=o("DecisionTransformerModel"),Zuo=o(" (Decision Transformer model)"),e4o=l(),Rp=a("li"),ale=a("strong"),o4o=o("deit"),r4o=o(" \u2014 "),dN=a("a"),t4o=o("DeiTModel"),a4o=o(" (DeiT model)"),n4o=l(),Pp=a("li"),nle=a("strong"),s4o=o("detr"),l4o=o(" \u2014 "),cN=a("a"),i4o=o("DetrModel"),d4o=o(" (DETR model)"),c4o=l(),Bp=a("li"),sle=a("strong"),f4o=o("distilbert"),m4o=o(" \u2014 "),fN=a("a"),g4o=o("DistilBertModel"),h4o=o(" (DistilBERT model)"),p4o=l(),Ip=a("li"),lle=a("strong"),_4o=o("dpr"),u4o=o(" \u2014 "),mN=a("a"),b4o=o("DPRQuestionEncoder"),v4o=o(" (DPR model)"),F4o=l(),Np=a("li"),ile=a("strong"),T4o=o("dpt"),M4o=o(" \u2014 "),gN=a("a"),E4o=o("DPTModel"),C4o=o(" (DPT model)"),w4o=l(),qp=a("li"),dle=a("strong"),A4o=o("electra"),y4o=o(" \u2014 "),hN=a("a"),L4o=o("ElectraModel"),x4o=o(" (ELECTRA model)"),$4o=l(),jp=a("li"),cle=a("strong"),k4o=o("flaubert"),S4o=o(" \u2014 "),pN=a("a"),R4o=o("FlaubertModel"),P4o=o(" (FlauBERT model)"),B4o=l(),Dp=a("li"),fle=a("strong"),I4o=o("flava"),N4o=o(" \u2014 "),_N=a("a"),q4o=o("FlavaModel"),j4o=o(" (Flava model)"),D4o=l(),Gp=a("li"),mle=a("strong"),G4o=o("fnet"),O4o=o(" \u2014 "),uN=a("a"),V4o=o("FNetModel"),X4o=o(" (FNet model)"),z4o=l(),Op=a("li"),gle=a("strong"),W4o=o("fsmt"),Q4o=o(" \u2014 "),bN=a("a"),H4o=o("FSMTModel"),U4o=o(" (FairSeq Machine-Translation model)"),J4o=l(),Bs=a("li"),hle=a("strong"),Y4o=o("funnel"),K4o=o(" \u2014 "),vN=a("a"),Z4o=o("FunnelModel"),e1o=o(" or "),FN=a("a"),o1o=o("FunnelBaseModel"),r1o=o(" (Funnel Transformer model)"),t1o=l(),Vp=a("li"),ple=a("strong"),a1o=o("glpn"),n1o=o(" \u2014 "),TN=a("a"),s1o=o("GLPNModel"),l1o=o(" (GLPN model)"),i1o=l(),Xp=a("li"),_le=a("strong"),d1o=o("gpt2"),c1o=o(" \u2014 "),MN=a("a"),f1o=o("GPT2Model"),m1o=o(" (OpenAI GPT-2 model)"),g1o=l(),zp=a("li"),ule=a("strong"),h1o=o("gpt_neo"),p1o=o(" \u2014 "),EN=a("a"),_1o=o("GPTNeoModel"),u1o=o(" (GPT Neo model)"),b1o=l(),Wp=a("li"),ble=a("strong"),v1o=o("gpt_neox"),F1o=o(" \u2014 "),CN=a("a"),T1o=o("GPTNeoXModel"),M1o=o(" (GPT NeoX model)"),E1o=l(),Qp=a("li"),vle=a("strong"),C1o=o("gptj"),w1o=o(" \u2014 "),wN=a("a"),A1o=o("GPTJModel"),y1o=o(" (GPT-J model)"),L1o=l(),Hp=a("li"),Fle=a("strong"),x1o=o("hubert"),$1o=o(" \u2014 "),AN=a("a"),k1o=o("HubertModel"),S1o=o(" (Hubert model)"),R1o=l(),Up=a("li"),Tle=a("strong"),P1o=o("ibert"),B1o=o(" \u2014 "),yN=a("a"),I1o=o("IBertModel"),N1o=o(" (I-BERT model)"),q1o=l(),Jp=a("li"),Mle=a("strong"),j1o=o("imagegpt"),D1o=o(" \u2014 "),LN=a("a"),G1o=o("ImageGPTModel"),O1o=o(" (ImageGPT model)"),V1o=l(),Yp=a("li"),Ele=a("strong"),X1o=o("layoutlm"),z1o=o(" \u2014 "),xN=a("a"),W1o=o("LayoutLMModel"),Q1o=o(" (LayoutLM model)"),H1o=l(),Kp=a("li"),Cle=a("strong"),U1o=o("layoutlmv2"),J1o=o(" \u2014 "),$N=a("a"),Y1o=o("LayoutLMv2Model"),K1o=o(" (LayoutLMv2 model)"),Z1o=l(),Zp=a("li"),wle=a("strong"),ebo=o("layoutlmv3"),obo=o(" \u2014 "),kN=a("a"),rbo=o("LayoutLMv3Model"),tbo=o(" (LayoutLMv3 model)"),abo=l(),e_=a("li"),Ale=a("strong"),nbo=o("led"),sbo=o(" \u2014 "),SN=a("a"),lbo=o("LEDModel"),ibo=o(" (LED model)"),dbo=l(),o_=a("li"),yle=a("strong"),cbo=o("longformer"),fbo=o(" \u2014 "),RN=a("a"),mbo=o("LongformerModel"),gbo=o(" (Longformer model)"),hbo=l(),r_=a("li"),Lle=a("strong"),pbo=o("luke"),_bo=o(" \u2014 "),PN=a("a"),ubo=o("LukeModel"),bbo=o(" (LUKE model)"),vbo=l(),t_=a("li"),xle=a("strong"),Fbo=o("lxmert"),Tbo=o(" \u2014 "),BN=a("a"),Mbo=o("LxmertModel"),Ebo=o(" (LXMERT model)"),Cbo=l(),a_=a("li"),$le=a("strong"),wbo=o("m2m_100"),Abo=o(" \u2014 "),IN=a("a"),ybo=o("M2M100Model"),Lbo=o(" (M2M100 model)"),xbo=l(),n_=a("li"),kle=a("strong"),$bo=o("marian"),kbo=o(" \u2014 "),NN=a("a"),Sbo=o("MarianModel"),Rbo=o(" (Marian model)"),Pbo=l(),s_=a("li"),Sle=a("strong"),Bbo=o("maskformer"),Ibo=o(" \u2014 "),qN=a("a"),Nbo=o("MaskFormerModel"),qbo=o(" (MaskFormer model)"),jbo=l(),l_=a("li"),Rle=a("strong"),Dbo=o("mbart"),Gbo=o(" \u2014 "),jN=a("a"),Obo=o("MBartModel"),Vbo=o(" (mBART model)"),Xbo=l(),i_=a("li"),Ple=a("strong"),zbo=o("megatron-bert"),Wbo=o(" \u2014 "),DN=a("a"),Qbo=o("MegatronBertModel"),Hbo=o(" (MegatronBert model)"),Ubo=l(),d_=a("li"),Ble=a("strong"),Jbo=o("mobilebert"),Ybo=o(" \u2014 "),GN=a("a"),Kbo=o("MobileBertModel"),Zbo=o(" (MobileBERT model)"),e2o=l(),c_=a("li"),Ile=a("strong"),o2o=o("mpnet"),r2o=o(" \u2014 "),ON=a("a"),t2o=o("MPNetModel"),a2o=o(" (MPNet model)"),n2o=l(),f_=a("li"),Nle=a("strong"),s2o=o("mt5"),l2o=o(" \u2014 "),VN=a("a"),i2o=o("MT5Model"),d2o=o(" (mT5 model)"),c2o=l(),m_=a("li"),qle=a("strong"),f2o=o("nystromformer"),m2o=o(" \u2014 "),XN=a("a"),g2o=o("NystromformerModel"),h2o=o(" (Nystromformer model)"),p2o=l(),g_=a("li"),jle=a("strong"),_2o=o("openai-gpt"),u2o=o(" \u2014 "),zN=a("a"),b2o=o("OpenAIGPTModel"),v2o=o(" (OpenAI GPT model)"),F2o=l(),h_=a("li"),Dle=a("strong"),T2o=o("opt"),M2o=o(" \u2014 "),WN=a("a"),E2o=o("OPTModel"),C2o=o(" (OPT model)"),w2o=l(),p_=a("li"),Gle=a("strong"),A2o=o("pegasus"),y2o=o(" \u2014 "),QN=a("a"),L2o=o("PegasusModel"),x2o=o(" (Pegasus model)"),$2o=l(),__=a("li"),Ole=a("strong"),k2o=o("perceiver"),S2o=o(" \u2014 "),HN=a("a"),R2o=o("PerceiverModel"),P2o=o(" (Perceiver model)"),B2o=l(),u_=a("li"),Vle=a("strong"),I2o=o("plbart"),N2o=o(" \u2014 "),UN=a("a"),q2o=o("PLBartModel"),j2o=o(" (PLBart model)"),D2o=l(),b_=a("li"),Xle=a("strong"),G2o=o("poolformer"),O2o=o(" \u2014 "),JN=a("a"),V2o=o("PoolFormerModel"),X2o=o(" (PoolFormer model)"),z2o=l(),v_=a("li"),zle=a("strong"),W2o=o("prophetnet"),Q2o=o(" \u2014 "),YN=a("a"),H2o=o("ProphetNetModel"),U2o=o(" (ProphetNet model)"),J2o=l(),F_=a("li"),Wle=a("strong"),Y2o=o("qdqbert"),K2o=o(" \u2014 "),KN=a("a"),Z2o=o("QDQBertModel"),evo=o(" (QDQBert model)"),ovo=l(),T_=a("li"),Qle=a("strong"),rvo=o("reformer"),tvo=o(" \u2014 "),ZN=a("a"),avo=o("ReformerModel"),nvo=o(" (Reformer model)"),svo=l(),M_=a("li"),Hle=a("strong"),lvo=o("regnet"),ivo=o(" \u2014 "),eq=a("a"),dvo=o("RegNetModel"),cvo=o(" (RegNet model)"),fvo=l(),E_=a("li"),Ule=a("strong"),mvo=o("rembert"),gvo=o(" \u2014 "),oq=a("a"),hvo=o("RemBertModel"),pvo=o(" (RemBERT model)"),_vo=l(),C_=a("li"),Jle=a("strong"),uvo=o("resnet"),bvo=o(" \u2014 "),rq=a("a"),vvo=o("ResNetModel"),Fvo=o(" (ResNet model)"),Tvo=l(),w_=a("li"),Yle=a("strong"),Mvo=o("retribert"),Evo=o(" \u2014 "),tq=a("a"),Cvo=o("RetriBertModel"),wvo=o(" (RetriBERT model)"),Avo=l(),A_=a("li"),Kle=a("strong"),yvo=o("roberta"),Lvo=o(" \u2014 "),aq=a("a"),xvo=o("RobertaModel"),$vo=o(" (RoBERTa model)"),kvo=l(),y_=a("li"),Zle=a("strong"),Svo=o("roformer"),Rvo=o(" \u2014 "),nq=a("a"),Pvo=o("RoFormerModel"),Bvo=o(" (RoFormer model)"),Ivo=l(),L_=a("li"),eie=a("strong"),Nvo=o("segformer"),qvo=o(" \u2014 "),sq=a("a"),jvo=o("SegformerModel"),Dvo=o(" (SegFormer model)"),Gvo=l(),x_=a("li"),oie=a("strong"),Ovo=o("sew"),Vvo=o(" \u2014 "),lq=a("a"),Xvo=o("SEWModel"),zvo=o(" (SEW model)"),Wvo=l(),$_=a("li"),rie=a("strong"),Qvo=o("sew-d"),Hvo=o(" \u2014 "),iq=a("a"),Uvo=o("SEWDModel"),Jvo=o(" (SEW-D model)"),Yvo=l(),k_=a("li"),tie=a("strong"),Kvo=o("speech_to_text"),Zvo=o(" \u2014 "),dq=a("a"),e3o=o("Speech2TextModel"),o3o=o(" (Speech2Text model)"),r3o=l(),S_=a("li"),aie=a("strong"),t3o=o("splinter"),a3o=o(" \u2014 "),cq=a("a"),n3o=o("SplinterModel"),s3o=o(" (Splinter model)"),l3o=l(),R_=a("li"),nie=a("strong"),i3o=o("squeezebert"),d3o=o(" \u2014 "),fq=a("a"),c3o=o("SqueezeBertModel"),f3o=o(" (SqueezeBERT model)"),m3o=l(),P_=a("li"),sie=a("strong"),g3o=o("swin"),h3o=o(" \u2014 "),mq=a("a"),p3o=o("SwinModel"),_3o=o(" (Swin model)"),u3o=l(),B_=a("li"),lie=a("strong"),b3o=o("t5"),v3o=o(" \u2014 "),gq=a("a"),F3o=o("T5Model"),T3o=o(" (T5 model)"),M3o=l(),I_=a("li"),iie=a("strong"),E3o=o("tapas"),C3o=o(" \u2014 "),hq=a("a"),w3o=o("TapasModel"),A3o=o(" (TAPAS model)"),y3o=l(),N_=a("li"),die=a("strong"),L3o=o("trajectory_transformer"),x3o=o(" \u2014 "),pq=a("a"),$3o=o("TrajectoryTransformerModel"),k3o=o(" (Trajectory Transformer model)"),S3o=l(),q_=a("li"),cie=a("strong"),R3o=o("transfo-xl"),P3o=o(" \u2014 "),_q=a("a"),B3o=o("TransfoXLModel"),I3o=o(" (Transformer-XL model)"),N3o=l(),j_=a("li"),fie=a("strong"),q3o=o("unispeech"),j3o=o(" \u2014 "),uq=a("a"),D3o=o("UniSpeechModel"),G3o=o(" (UniSpeech model)"),O3o=l(),D_=a("li"),mie=a("strong"),V3o=o("unispeech-sat"),X3o=o(" \u2014 "),bq=a("a"),z3o=o("UniSpeechSatModel"),W3o=o(" (UniSpeechSat model)"),Q3o=l(),G_=a("li"),gie=a("strong"),H3o=o("van"),U3o=o(" \u2014 "),vq=a("a"),J3o=o("VanModel"),Y3o=o(" (VAN model)"),K3o=l(),O_=a("li"),hie=a("strong"),Z3o=o("vilt"),eFo=o(" \u2014 "),Fq=a("a"),oFo=o("ViltModel"),rFo=o(" (ViLT model)"),tFo=l(),V_=a("li"),pie=a("strong"),aFo=o("vision-text-dual-encoder"),nFo=o(" \u2014 "),Tq=a("a"),sFo=o("VisionTextDualEncoderModel"),lFo=o(" (VisionTextDualEncoder model)"),iFo=l(),X_=a("li"),_ie=a("strong"),dFo=o("visual_bert"),cFo=o(" \u2014 "),Mq=a("a"),fFo=o("VisualBertModel"),mFo=o(" (VisualBert model)"),gFo=l(),z_=a("li"),uie=a("strong"),hFo=o("vit"),pFo=o(" \u2014 "),Eq=a("a"),_Fo=o("ViTModel"),uFo=o(" (ViT model)"),bFo=l(),W_=a("li"),bie=a("strong"),vFo=o("vit_mae"),FFo=o(" \u2014 "),Cq=a("a"),TFo=o("ViTMAEModel"),MFo=o(" (ViTMAE model)"),EFo=l(),Q_=a("li"),vie=a("strong"),CFo=o("wav2vec2"),wFo=o(" \u2014 "),wq=a("a"),AFo=o("Wav2Vec2Model"),yFo=o(" (Wav2Vec2 model)"),LFo=l(),H_=a("li"),Fie=a("strong"),xFo=o("wav2vec2-conformer"),$Fo=o(" \u2014 "),Aq=a("a"),kFo=o("Wav2Vec2ConformerModel"),SFo=o(" (Wav2Vec2-Conformer model)"),RFo=l(),U_=a("li"),Tie=a("strong"),PFo=o("wavlm"),BFo=o(" \u2014 "),yq=a("a"),IFo=o("WavLMModel"),NFo=o(" (WavLM model)"),qFo=l(),J_=a("li"),Mie=a("strong"),jFo=o("xglm"),DFo=o(" \u2014 "),Lq=a("a"),GFo=o("XGLMModel"),OFo=o(" (XGLM model)"),VFo=l(),Y_=a("li"),Eie=a("strong"),XFo=o("xlm"),zFo=o(" \u2014 "),xq=a("a"),WFo=o("XLMModel"),QFo=o(" (XLM model)"),HFo=l(),K_=a("li"),Cie=a("strong"),UFo=o("xlm-prophetnet"),JFo=o(" \u2014 "),$q=a("a"),YFo=o("XLMProphetNetModel"),KFo=o(" (XLMProphetNet model)"),ZFo=l(),Z_=a("li"),wie=a("strong"),eTo=o("xlm-roberta"),oTo=o(" \u2014 "),kq=a("a"),rTo=o("XLMRobertaModel"),tTo=o(" (XLM-RoBERTa model)"),aTo=l(),eu=a("li"),Aie=a("strong"),nTo=o("xlm-roberta-xl"),sTo=o(" \u2014 "),Sq=a("a"),lTo=o("XLMRobertaXLModel"),iTo=o(" (XLM-RoBERTa-XL model)"),dTo=l(),ou=a("li"),yie=a("strong"),cTo=o("xlnet"),fTo=o(" \u2014 "),Rq=a("a"),mTo=o("XLNetModel"),gTo=o(" (XLNet model)"),hTo=l(),ru=a("li"),Lie=a("strong"),pTo=o("yolos"),_To=o(" \u2014 "),Pq=a("a"),uTo=o("YolosModel"),bTo=o(" (YOLOS model)"),vTo=l(),tu=a("li"),xie=a("strong"),FTo=o("yoso"),TTo=o(" \u2014 "),Bq=a("a"),MTo=o("YosoModel"),ETo=o(" (YOSO model)"),CTo=l(),au=a("p"),wTo=o("The model is set in evaluation mode by default using "),$ie=a("code"),ATo=o("model.eval()"),yTo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kie=a("code"),LTo=o("model.train()"),xTo=l(),F(nu.$$.fragment),$qe=l(),xi=a("h2"),su=a("a"),Sie=a("span"),F(iy.$$.fragment),$To=l(),Rie=a("span"),kTo=o("AutoModelForPreTraining"),kqe=l(),xo=a("div"),F(dy.$$.fragment),STo=l(),$i=a("p"),RTo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Iq=a("a"),PTo=o("from_pretrained()"),BTo=o(" class method or the "),Nq=a("a"),ITo=o("from_config()"),NTo=o(` class
method.`),qTo=l(),cy=a("p"),jTo=o("This class cannot be instantiated directly using "),Pie=a("code"),DTo=o("__init__()"),GTo=o(" (throws an error)."),OTo=l(),at=a("div"),F(fy.$$.fragment),VTo=l(),Bie=a("p"),XTo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),zTo=l(),ki=a("p"),WTo=o(`Note:
Loading a model from its configuration file does `),Iie=a("strong"),QTo=o("not"),HTo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qq=a("a"),UTo=o("from_pretrained()"),JTo=o(" to load the model weights."),YTo=l(),F(lu.$$.fragment),KTo=l(),Ye=a("div"),F(my.$$.fragment),ZTo=l(),Nie=a("p"),e7o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),o7o=l(),xa=a("p"),r7o=o("The model class to instantiate is selected based on the "),qie=a("code"),t7o=o("model_type"),a7o=o(` property of the config object (either
passed as an argument or loaded from `),jie=a("code"),n7o=o("pretrained_model_name_or_path"),s7o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=a("code"),l7o=o("pretrained_model_name_or_path"),i7o=o(":"),d7o=l(),G=a("ul"),iu=a("li"),Gie=a("strong"),c7o=o("albert"),f7o=o(" \u2014 "),jq=a("a"),m7o=o("AlbertForPreTraining"),g7o=o(" (ALBERT model)"),h7o=l(),du=a("li"),Oie=a("strong"),p7o=o("bart"),_7o=o(" \u2014 "),Dq=a("a"),u7o=o("BartForConditionalGeneration"),b7o=o(" (BART model)"),v7o=l(),cu=a("li"),Vie=a("strong"),F7o=o("bert"),T7o=o(" \u2014 "),Gq=a("a"),M7o=o("BertForPreTraining"),E7o=o(" (BERT model)"),C7o=l(),fu=a("li"),Xie=a("strong"),w7o=o("big_bird"),A7o=o(" \u2014 "),Oq=a("a"),y7o=o("BigBirdForPreTraining"),L7o=o(" (BigBird model)"),x7o=l(),mu=a("li"),zie=a("strong"),$7o=o("camembert"),k7o=o(" \u2014 "),Vq=a("a"),S7o=o("CamembertForMaskedLM"),R7o=o(" (CamemBERT model)"),P7o=l(),gu=a("li"),Wie=a("strong"),B7o=o("ctrl"),I7o=o(" \u2014 "),Xq=a("a"),N7o=o("CTRLLMHeadModel"),q7o=o(" (CTRL model)"),j7o=l(),hu=a("li"),Qie=a("strong"),D7o=o("data2vec-text"),G7o=o(" \u2014 "),zq=a("a"),O7o=o("Data2VecTextForMaskedLM"),V7o=o(" (Data2VecText model)"),X7o=l(),pu=a("li"),Hie=a("strong"),z7o=o("deberta"),W7o=o(" \u2014 "),Wq=a("a"),Q7o=o("DebertaForMaskedLM"),H7o=o(" (DeBERTa model)"),U7o=l(),_u=a("li"),Uie=a("strong"),J7o=o("deberta-v2"),Y7o=o(" \u2014 "),Qq=a("a"),K7o=o("DebertaV2ForMaskedLM"),Z7o=o(" (DeBERTa-v2 model)"),eMo=l(),uu=a("li"),Jie=a("strong"),oMo=o("distilbert"),rMo=o(" \u2014 "),Hq=a("a"),tMo=o("DistilBertForMaskedLM"),aMo=o(" (DistilBERT model)"),nMo=l(),bu=a("li"),Yie=a("strong"),sMo=o("electra"),lMo=o(" \u2014 "),Uq=a("a"),iMo=o("ElectraForPreTraining"),dMo=o(" (ELECTRA model)"),cMo=l(),vu=a("li"),Kie=a("strong"),fMo=o("flaubert"),mMo=o(" \u2014 "),Jq=a("a"),gMo=o("FlaubertWithLMHeadModel"),hMo=o(" (FlauBERT model)"),pMo=l(),Fu=a("li"),Zie=a("strong"),_Mo=o("flava"),uMo=o(" \u2014 "),Yq=a("a"),bMo=o("FlavaForPreTraining"),vMo=o(" (Flava model)"),FMo=l(),Tu=a("li"),ede=a("strong"),TMo=o("fnet"),MMo=o(" \u2014 "),Kq=a("a"),EMo=o("FNetForPreTraining"),CMo=o(" (FNet model)"),wMo=l(),Mu=a("li"),ode=a("strong"),AMo=o("fsmt"),yMo=o(" \u2014 "),Zq=a("a"),LMo=o("FSMTForConditionalGeneration"),xMo=o(" (FairSeq Machine-Translation model)"),$Mo=l(),Eu=a("li"),rde=a("strong"),kMo=o("funnel"),SMo=o(" \u2014 "),ej=a("a"),RMo=o("FunnelForPreTraining"),PMo=o(" (Funnel Transformer model)"),BMo=l(),Cu=a("li"),tde=a("strong"),IMo=o("gpt2"),NMo=o(" \u2014 "),oj=a("a"),qMo=o("GPT2LMHeadModel"),jMo=o(" (OpenAI GPT-2 model)"),DMo=l(),wu=a("li"),ade=a("strong"),GMo=o("ibert"),OMo=o(" \u2014 "),rj=a("a"),VMo=o("IBertForMaskedLM"),XMo=o(" (I-BERT model)"),zMo=l(),Au=a("li"),nde=a("strong"),WMo=o("layoutlm"),QMo=o(" \u2014 "),tj=a("a"),HMo=o("LayoutLMForMaskedLM"),UMo=o(" (LayoutLM model)"),JMo=l(),yu=a("li"),sde=a("strong"),YMo=o("longformer"),KMo=o(" \u2014 "),aj=a("a"),ZMo=o("LongformerForMaskedLM"),eEo=o(" (Longformer model)"),oEo=l(),Lu=a("li"),lde=a("strong"),rEo=o("lxmert"),tEo=o(" \u2014 "),nj=a("a"),aEo=o("LxmertForPreTraining"),nEo=o(" (LXMERT model)"),sEo=l(),xu=a("li"),ide=a("strong"),lEo=o("megatron-bert"),iEo=o(" \u2014 "),sj=a("a"),dEo=o("MegatronBertForPreTraining"),cEo=o(" (MegatronBert model)"),fEo=l(),$u=a("li"),dde=a("strong"),mEo=o("mobilebert"),gEo=o(" \u2014 "),lj=a("a"),hEo=o("MobileBertForPreTraining"),pEo=o(" (MobileBERT model)"),_Eo=l(),ku=a("li"),cde=a("strong"),uEo=o("mpnet"),bEo=o(" \u2014 "),ij=a("a"),vEo=o("MPNetForMaskedLM"),FEo=o(" (MPNet model)"),TEo=l(),Su=a("li"),fde=a("strong"),MEo=o("openai-gpt"),EEo=o(" \u2014 "),dj=a("a"),CEo=o("OpenAIGPTLMHeadModel"),wEo=o(" (OpenAI GPT model)"),AEo=l(),Ru=a("li"),mde=a("strong"),yEo=o("retribert"),LEo=o(" \u2014 "),cj=a("a"),xEo=o("RetriBertModel"),$Eo=o(" (RetriBERT model)"),kEo=l(),Pu=a("li"),gde=a("strong"),SEo=o("roberta"),REo=o(" \u2014 "),fj=a("a"),PEo=o("RobertaForMaskedLM"),BEo=o(" (RoBERTa model)"),IEo=l(),Bu=a("li"),hde=a("strong"),NEo=o("splinter"),qEo=o(" \u2014 "),mj=a("a"),jEo=o("SplinterForPreTraining"),DEo=o(" (Splinter model)"),GEo=l(),Iu=a("li"),pde=a("strong"),OEo=o("squeezebert"),VEo=o(" \u2014 "),gj=a("a"),XEo=o("SqueezeBertForMaskedLM"),zEo=o(" (SqueezeBERT model)"),WEo=l(),Nu=a("li"),_de=a("strong"),QEo=o("t5"),HEo=o(" \u2014 "),hj=a("a"),UEo=o("T5ForConditionalGeneration"),JEo=o(" (T5 model)"),YEo=l(),qu=a("li"),ude=a("strong"),KEo=o("tapas"),ZEo=o(" \u2014 "),pj=a("a"),eCo=o("TapasForMaskedLM"),oCo=o(" (TAPAS model)"),rCo=l(),ju=a("li"),bde=a("strong"),tCo=o("transfo-xl"),aCo=o(" \u2014 "),_j=a("a"),nCo=o("TransfoXLLMHeadModel"),sCo=o(" (Transformer-XL model)"),lCo=l(),Du=a("li"),vde=a("strong"),iCo=o("unispeech"),dCo=o(" \u2014 "),uj=a("a"),cCo=o("UniSpeechForPreTraining"),fCo=o(" (UniSpeech model)"),mCo=l(),Gu=a("li"),Fde=a("strong"),gCo=o("unispeech-sat"),hCo=o(" \u2014 "),bj=a("a"),pCo=o("UniSpeechSatForPreTraining"),_Co=o(" (UniSpeechSat model)"),uCo=l(),Ou=a("li"),Tde=a("strong"),bCo=o("visual_bert"),vCo=o(" \u2014 "),vj=a("a"),FCo=o("VisualBertForPreTraining"),TCo=o(" (VisualBert model)"),MCo=l(),Vu=a("li"),Mde=a("strong"),ECo=o("vit_mae"),CCo=o(" \u2014 "),Fj=a("a"),wCo=o("ViTMAEForPreTraining"),ACo=o(" (ViTMAE model)"),yCo=l(),Xu=a("li"),Ede=a("strong"),LCo=o("wav2vec2"),xCo=o(" \u2014 "),Tj=a("a"),$Co=o("Wav2Vec2ForPreTraining"),kCo=o(" (Wav2Vec2 model)"),SCo=l(),zu=a("li"),Cde=a("strong"),RCo=o("wav2vec2-conformer"),PCo=o(" \u2014 "),Mj=a("a"),BCo=o("Wav2Vec2ConformerForPreTraining"),ICo=o(" (Wav2Vec2-Conformer model)"),NCo=l(),Wu=a("li"),wde=a("strong"),qCo=o("xlm"),jCo=o(" \u2014 "),Ej=a("a"),DCo=o("XLMWithLMHeadModel"),GCo=o(" (XLM model)"),OCo=l(),Qu=a("li"),Ade=a("strong"),VCo=o("xlm-roberta"),XCo=o(" \u2014 "),Cj=a("a"),zCo=o("XLMRobertaForMaskedLM"),WCo=o(" (XLM-RoBERTa model)"),QCo=l(),Hu=a("li"),yde=a("strong"),HCo=o("xlm-roberta-xl"),UCo=o(" \u2014 "),wj=a("a"),JCo=o("XLMRobertaXLForMaskedLM"),YCo=o(" (XLM-RoBERTa-XL model)"),KCo=l(),Uu=a("li"),Lde=a("strong"),ZCo=o("xlnet"),e5o=o(" \u2014 "),Aj=a("a"),o5o=o("XLNetLMHeadModel"),r5o=o(" (XLNet model)"),t5o=l(),Ju=a("p"),a5o=o("The model is set in evaluation mode by default using "),xde=a("code"),n5o=o("model.eval()"),s5o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$de=a("code"),l5o=o("model.train()"),i5o=l(),F(Yu.$$.fragment),Sqe=l(),Si=a("h2"),Ku=a("a"),kde=a("span"),F(gy.$$.fragment),d5o=l(),Sde=a("span"),c5o=o("AutoModelForCausalLM"),Rqe=l(),$o=a("div"),F(hy.$$.fragment),f5o=l(),Ri=a("p"),m5o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),yj=a("a"),g5o=o("from_pretrained()"),h5o=o(" class method or the "),Lj=a("a"),p5o=o("from_config()"),_5o=o(` class
method.`),u5o=l(),py=a("p"),b5o=o("This class cannot be instantiated directly using "),Rde=a("code"),v5o=o("__init__()"),F5o=o(" (throws an error)."),T5o=l(),nt=a("div"),F(_y.$$.fragment),M5o=l(),Pde=a("p"),E5o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),C5o=l(),Pi=a("p"),w5o=o(`Note:
Loading a model from its configuration file does `),Bde=a("strong"),A5o=o("not"),y5o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xj=a("a"),L5o=o("from_pretrained()"),x5o=o(" to load the model weights."),$5o=l(),F(Zu.$$.fragment),k5o=l(),Ke=a("div"),F(uy.$$.fragment),S5o=l(),Ide=a("p"),R5o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),P5o=l(),$a=a("p"),B5o=o("The model class to instantiate is selected based on the "),Nde=a("code"),I5o=o("model_type"),N5o=o(` property of the config object (either
passed as an argument or loaded from `),qde=a("code"),q5o=o("pretrained_model_name_or_path"),j5o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jde=a("code"),D5o=o("pretrained_model_name_or_path"),G5o=o(":"),O5o=l(),z=a("ul"),e4=a("li"),Dde=a("strong"),V5o=o("bart"),X5o=o(" \u2014 "),$j=a("a"),z5o=o("BartForCausalLM"),W5o=o(" (BART model)"),Q5o=l(),o4=a("li"),Gde=a("strong"),H5o=o("bert"),U5o=o(" \u2014 "),kj=a("a"),J5o=o("BertLMHeadModel"),Y5o=o(" (BERT model)"),K5o=l(),r4=a("li"),Ode=a("strong"),Z5o=o("bert-generation"),ewo=o(" \u2014 "),Sj=a("a"),owo=o("BertGenerationDecoder"),rwo=o(" (Bert Generation model)"),two=l(),t4=a("li"),Vde=a("strong"),awo=o("big_bird"),nwo=o(" \u2014 "),Rj=a("a"),swo=o("BigBirdForCausalLM"),lwo=o(" (BigBird model)"),iwo=l(),a4=a("li"),Xde=a("strong"),dwo=o("bigbird_pegasus"),cwo=o(" \u2014 "),Pj=a("a"),fwo=o("BigBirdPegasusForCausalLM"),mwo=o(" (BigBirdPegasus model)"),gwo=l(),n4=a("li"),zde=a("strong"),hwo=o("blenderbot"),pwo=o(" \u2014 "),Bj=a("a"),_wo=o("BlenderbotForCausalLM"),uwo=o(" (Blenderbot model)"),bwo=l(),s4=a("li"),Wde=a("strong"),vwo=o("blenderbot-small"),Fwo=o(" \u2014 "),Ij=a("a"),Two=o("BlenderbotSmallForCausalLM"),Mwo=o(" (BlenderbotSmall model)"),Ewo=l(),l4=a("li"),Qde=a("strong"),Cwo=o("camembert"),wwo=o(" \u2014 "),Nj=a("a"),Awo=o("CamembertForCausalLM"),ywo=o(" (CamemBERT model)"),Lwo=l(),i4=a("li"),Hde=a("strong"),xwo=o("codegen"),$wo=o(" \u2014 "),qj=a("a"),kwo=o("CodeGenForCausalLM"),Swo=o(" (CodeGen model)"),Rwo=l(),d4=a("li"),Ude=a("strong"),Pwo=o("ctrl"),Bwo=o(" \u2014 "),jj=a("a"),Iwo=o("CTRLLMHeadModel"),Nwo=o(" (CTRL model)"),qwo=l(),c4=a("li"),Jde=a("strong"),jwo=o("data2vec-text"),Dwo=o(" \u2014 "),Dj=a("a"),Gwo=o("Data2VecTextForCausalLM"),Owo=o(" (Data2VecText model)"),Vwo=l(),f4=a("li"),Yde=a("strong"),Xwo=o("electra"),zwo=o(" \u2014 "),Gj=a("a"),Wwo=o("ElectraForCausalLM"),Qwo=o(" (ELECTRA model)"),Hwo=l(),m4=a("li"),Kde=a("strong"),Uwo=o("gpt2"),Jwo=o(" \u2014 "),Oj=a("a"),Ywo=o("GPT2LMHeadModel"),Kwo=o(" (OpenAI GPT-2 model)"),Zwo=l(),g4=a("li"),Zde=a("strong"),e0o=o("gpt_neo"),o0o=o(" \u2014 "),Vj=a("a"),r0o=o("GPTNeoForCausalLM"),t0o=o(" (GPT Neo model)"),a0o=l(),h4=a("li"),ece=a("strong"),n0o=o("gpt_neox"),s0o=o(" \u2014 "),Xj=a("a"),l0o=o("GPTNeoXForCausalLM"),i0o=o(" (GPT NeoX model)"),d0o=l(),p4=a("li"),oce=a("strong"),c0o=o("gptj"),f0o=o(" \u2014 "),zj=a("a"),m0o=o("GPTJForCausalLM"),g0o=o(" (GPT-J model)"),h0o=l(),_4=a("li"),rce=a("strong"),p0o=o("marian"),_0o=o(" \u2014 "),Wj=a("a"),u0o=o("MarianForCausalLM"),b0o=o(" (Marian model)"),v0o=l(),u4=a("li"),tce=a("strong"),F0o=o("mbart"),T0o=o(" \u2014 "),Qj=a("a"),M0o=o("MBartForCausalLM"),E0o=o(" (mBART model)"),C0o=l(),b4=a("li"),ace=a("strong"),w0o=o("megatron-bert"),A0o=o(" \u2014 "),Hj=a("a"),y0o=o("MegatronBertForCausalLM"),L0o=o(" (MegatronBert model)"),x0o=l(),v4=a("li"),nce=a("strong"),$0o=o("openai-gpt"),k0o=o(" \u2014 "),Uj=a("a"),S0o=o("OpenAIGPTLMHeadModel"),R0o=o(" (OpenAI GPT model)"),P0o=l(),F4=a("li"),sce=a("strong"),B0o=o("opt"),I0o=o(" \u2014 "),Jj=a("a"),N0o=o("OPTForCausalLM"),q0o=o(" (OPT model)"),j0o=l(),T4=a("li"),lce=a("strong"),D0o=o("pegasus"),G0o=o(" \u2014 "),Yj=a("a"),O0o=o("PegasusForCausalLM"),V0o=o(" (Pegasus model)"),X0o=l(),M4=a("li"),ice=a("strong"),z0o=o("plbart"),W0o=o(" \u2014 "),Kj=a("a"),Q0o=o("PLBartForCausalLM"),H0o=o(" (PLBart model)"),U0o=l(),E4=a("li"),dce=a("strong"),J0o=o("prophetnet"),Y0o=o(" \u2014 "),Zj=a("a"),K0o=o("ProphetNetForCausalLM"),Z0o=o(" (ProphetNet model)"),e6o=l(),C4=a("li"),cce=a("strong"),o6o=o("qdqbert"),r6o=o(" \u2014 "),eD=a("a"),t6o=o("QDQBertLMHeadModel"),a6o=o(" (QDQBert model)"),n6o=l(),w4=a("li"),fce=a("strong"),s6o=o("reformer"),l6o=o(" \u2014 "),oD=a("a"),i6o=o("ReformerModelWithLMHead"),d6o=o(" (Reformer model)"),c6o=l(),A4=a("li"),mce=a("strong"),f6o=o("rembert"),m6o=o(" \u2014 "),rD=a("a"),g6o=o("RemBertForCausalLM"),h6o=o(" (RemBERT model)"),p6o=l(),y4=a("li"),gce=a("strong"),_6o=o("roberta"),u6o=o(" \u2014 "),tD=a("a"),b6o=o("RobertaForCausalLM"),v6o=o(" (RoBERTa model)"),F6o=l(),L4=a("li"),hce=a("strong"),T6o=o("roformer"),M6o=o(" \u2014 "),aD=a("a"),E6o=o("RoFormerForCausalLM"),C6o=o(" (RoFormer model)"),w6o=l(),x4=a("li"),pce=a("strong"),A6o=o("speech_to_text_2"),y6o=o(" \u2014 "),nD=a("a"),L6o=o("Speech2Text2ForCausalLM"),x6o=o(" (Speech2Text2 model)"),$6o=l(),$4=a("li"),_ce=a("strong"),k6o=o("transfo-xl"),S6o=o(" \u2014 "),sD=a("a"),R6o=o("TransfoXLLMHeadModel"),P6o=o(" (Transformer-XL model)"),B6o=l(),k4=a("li"),uce=a("strong"),I6o=o("trocr"),N6o=o(" \u2014 "),lD=a("a"),q6o=o("TrOCRForCausalLM"),j6o=o(" (TrOCR model)"),D6o=l(),S4=a("li"),bce=a("strong"),G6o=o("xglm"),O6o=o(" \u2014 "),iD=a("a"),V6o=o("XGLMForCausalLM"),X6o=o(" (XGLM model)"),z6o=l(),R4=a("li"),vce=a("strong"),W6o=o("xlm"),Q6o=o(" \u2014 "),dD=a("a"),H6o=o("XLMWithLMHeadModel"),U6o=o(" (XLM model)"),J6o=l(),P4=a("li"),Fce=a("strong"),Y6o=o("xlm-prophetnet"),K6o=o(" \u2014 "),cD=a("a"),Z6o=o("XLMProphetNetForCausalLM"),eAo=o(" (XLMProphetNet model)"),oAo=l(),B4=a("li"),Tce=a("strong"),rAo=o("xlm-roberta"),tAo=o(" \u2014 "),fD=a("a"),aAo=o("XLMRobertaForCausalLM"),nAo=o(" (XLM-RoBERTa model)"),sAo=l(),I4=a("li"),Mce=a("strong"),lAo=o("xlm-roberta-xl"),iAo=o(" \u2014 "),mD=a("a"),dAo=o("XLMRobertaXLForCausalLM"),cAo=o(" (XLM-RoBERTa-XL model)"),fAo=l(),N4=a("li"),Ece=a("strong"),mAo=o("xlnet"),gAo=o(" \u2014 "),gD=a("a"),hAo=o("XLNetLMHeadModel"),pAo=o(" (XLNet model)"),_Ao=l(),q4=a("p"),uAo=o("The model is set in evaluation mode by default using "),Cce=a("code"),bAo=o("model.eval()"),vAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wce=a("code"),FAo=o("model.train()"),TAo=l(),F(j4.$$.fragment),Pqe=l(),Bi=a("h2"),D4=a("a"),Ace=a("span"),F(by.$$.fragment),MAo=l(),yce=a("span"),EAo=o("AutoModelForMaskedLM"),Bqe=l(),ko=a("div"),F(vy.$$.fragment),CAo=l(),Ii=a("p"),wAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),hD=a("a"),AAo=o("from_pretrained()"),yAo=o(" class method or the "),pD=a("a"),LAo=o("from_config()"),xAo=o(` class
method.`),$Ao=l(),Fy=a("p"),kAo=o("This class cannot be instantiated directly using "),Lce=a("code"),SAo=o("__init__()"),RAo=o(" (throws an error)."),PAo=l(),st=a("div"),F(Ty.$$.fragment),BAo=l(),xce=a("p"),IAo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),NAo=l(),Ni=a("p"),qAo=o(`Note:
Loading a model from its configuration file does `),$ce=a("strong"),jAo=o("not"),DAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_D=a("a"),GAo=o("from_pretrained()"),OAo=o(" to load the model weights."),VAo=l(),F(G4.$$.fragment),XAo=l(),Ze=a("div"),F(My.$$.fragment),zAo=l(),kce=a("p"),WAo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),QAo=l(),ka=a("p"),HAo=o("The model class to instantiate is selected based on the "),Sce=a("code"),UAo=o("model_type"),JAo=o(` property of the config object (either
passed as an argument or loaded from `),Rce=a("code"),YAo=o("pretrained_model_name_or_path"),KAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pce=a("code"),ZAo=o("pretrained_model_name_or_path"),eyo=o(":"),oyo=l(),Q=a("ul"),O4=a("li"),Bce=a("strong"),ryo=o("albert"),tyo=o(" \u2014 "),uD=a("a"),ayo=o("AlbertForMaskedLM"),nyo=o(" (ALBERT model)"),syo=l(),V4=a("li"),Ice=a("strong"),lyo=o("bart"),iyo=o(" \u2014 "),bD=a("a"),dyo=o("BartForConditionalGeneration"),cyo=o(" (BART model)"),fyo=l(),X4=a("li"),Nce=a("strong"),myo=o("bert"),gyo=o(" \u2014 "),vD=a("a"),hyo=o("BertForMaskedLM"),pyo=o(" (BERT model)"),_yo=l(),z4=a("li"),qce=a("strong"),uyo=o("big_bird"),byo=o(" \u2014 "),FD=a("a"),vyo=o("BigBirdForMaskedLM"),Fyo=o(" (BigBird model)"),Tyo=l(),W4=a("li"),jce=a("strong"),Myo=o("camembert"),Eyo=o(" \u2014 "),TD=a("a"),Cyo=o("CamembertForMaskedLM"),wyo=o(" (CamemBERT model)"),Ayo=l(),Q4=a("li"),Dce=a("strong"),yyo=o("convbert"),Lyo=o(" \u2014 "),MD=a("a"),xyo=o("ConvBertForMaskedLM"),$yo=o(" (ConvBERT model)"),kyo=l(),H4=a("li"),Gce=a("strong"),Syo=o("data2vec-text"),Ryo=o(" \u2014 "),ED=a("a"),Pyo=o("Data2VecTextForMaskedLM"),Byo=o(" (Data2VecText model)"),Iyo=l(),U4=a("li"),Oce=a("strong"),Nyo=o("deberta"),qyo=o(" \u2014 "),CD=a("a"),jyo=o("DebertaForMaskedLM"),Dyo=o(" (DeBERTa model)"),Gyo=l(),J4=a("li"),Vce=a("strong"),Oyo=o("deberta-v2"),Vyo=o(" \u2014 "),wD=a("a"),Xyo=o("DebertaV2ForMaskedLM"),zyo=o(" (DeBERTa-v2 model)"),Wyo=l(),Y4=a("li"),Xce=a("strong"),Qyo=o("distilbert"),Hyo=o(" \u2014 "),AD=a("a"),Uyo=o("DistilBertForMaskedLM"),Jyo=o(" (DistilBERT model)"),Yyo=l(),K4=a("li"),zce=a("strong"),Kyo=o("electra"),Zyo=o(" \u2014 "),yD=a("a"),eLo=o("ElectraForMaskedLM"),oLo=o(" (ELECTRA model)"),rLo=l(),Z4=a("li"),Wce=a("strong"),tLo=o("flaubert"),aLo=o(" \u2014 "),LD=a("a"),nLo=o("FlaubertWithLMHeadModel"),sLo=o(" (FlauBERT model)"),lLo=l(),e1=a("li"),Qce=a("strong"),iLo=o("fnet"),dLo=o(" \u2014 "),xD=a("a"),cLo=o("FNetForMaskedLM"),fLo=o(" (FNet model)"),mLo=l(),o1=a("li"),Hce=a("strong"),gLo=o("funnel"),hLo=o(" \u2014 "),$D=a("a"),pLo=o("FunnelForMaskedLM"),_Lo=o(" (Funnel Transformer model)"),uLo=l(),r1=a("li"),Uce=a("strong"),bLo=o("ibert"),vLo=o(" \u2014 "),kD=a("a"),FLo=o("IBertForMaskedLM"),TLo=o(" (I-BERT model)"),MLo=l(),t1=a("li"),Jce=a("strong"),ELo=o("layoutlm"),CLo=o(" \u2014 "),SD=a("a"),wLo=o("LayoutLMForMaskedLM"),ALo=o(" (LayoutLM model)"),yLo=l(),a1=a("li"),Yce=a("strong"),LLo=o("longformer"),xLo=o(" \u2014 "),RD=a("a"),$Lo=o("LongformerForMaskedLM"),kLo=o(" (Longformer model)"),SLo=l(),n1=a("li"),Kce=a("strong"),RLo=o("mbart"),PLo=o(" \u2014 "),PD=a("a"),BLo=o("MBartForConditionalGeneration"),ILo=o(" (mBART model)"),NLo=l(),s1=a("li"),Zce=a("strong"),qLo=o("megatron-bert"),jLo=o(" \u2014 "),BD=a("a"),DLo=o("MegatronBertForMaskedLM"),GLo=o(" (MegatronBert model)"),OLo=l(),l1=a("li"),efe=a("strong"),VLo=o("mobilebert"),XLo=o(" \u2014 "),ID=a("a"),zLo=o("MobileBertForMaskedLM"),WLo=o(" (MobileBERT model)"),QLo=l(),i1=a("li"),ofe=a("strong"),HLo=o("mpnet"),ULo=o(" \u2014 "),ND=a("a"),JLo=o("MPNetForMaskedLM"),YLo=o(" (MPNet model)"),KLo=l(),d1=a("li"),rfe=a("strong"),ZLo=o("nystromformer"),e8o=o(" \u2014 "),qD=a("a"),o8o=o("NystromformerForMaskedLM"),r8o=o(" (Nystromformer model)"),t8o=l(),c1=a("li"),tfe=a("strong"),a8o=o("perceiver"),n8o=o(" \u2014 "),jD=a("a"),s8o=o("PerceiverForMaskedLM"),l8o=o(" (Perceiver model)"),i8o=l(),f1=a("li"),afe=a("strong"),d8o=o("qdqbert"),c8o=o(" \u2014 "),DD=a("a"),f8o=o("QDQBertForMaskedLM"),m8o=o(" (QDQBert model)"),g8o=l(),m1=a("li"),nfe=a("strong"),h8o=o("reformer"),p8o=o(" \u2014 "),GD=a("a"),_8o=o("ReformerForMaskedLM"),u8o=o(" (Reformer model)"),b8o=l(),g1=a("li"),sfe=a("strong"),v8o=o("rembert"),F8o=o(" \u2014 "),OD=a("a"),T8o=o("RemBertForMaskedLM"),M8o=o(" (RemBERT model)"),E8o=l(),h1=a("li"),lfe=a("strong"),C8o=o("roberta"),w8o=o(" \u2014 "),VD=a("a"),A8o=o("RobertaForMaskedLM"),y8o=o(" (RoBERTa model)"),L8o=l(),p1=a("li"),ife=a("strong"),x8o=o("roformer"),$8o=o(" \u2014 "),XD=a("a"),k8o=o("RoFormerForMaskedLM"),S8o=o(" (RoFormer model)"),R8o=l(),_1=a("li"),dfe=a("strong"),P8o=o("squeezebert"),B8o=o(" \u2014 "),zD=a("a"),I8o=o("SqueezeBertForMaskedLM"),N8o=o(" (SqueezeBERT model)"),q8o=l(),u1=a("li"),cfe=a("strong"),j8o=o("tapas"),D8o=o(" \u2014 "),WD=a("a"),G8o=o("TapasForMaskedLM"),O8o=o(" (TAPAS model)"),V8o=l(),b1=a("li"),ffe=a("strong"),X8o=o("wav2vec2"),z8o=o(" \u2014 "),mfe=a("code"),W8o=o("Wav2Vec2ForMaskedLM"),Q8o=o(" (Wav2Vec2 model)"),H8o=l(),v1=a("li"),gfe=a("strong"),U8o=o("xlm"),J8o=o(" \u2014 "),QD=a("a"),Y8o=o("XLMWithLMHeadModel"),K8o=o(" (XLM model)"),Z8o=l(),F1=a("li"),hfe=a("strong"),e9o=o("xlm-roberta"),o9o=o(" \u2014 "),HD=a("a"),r9o=o("XLMRobertaForMaskedLM"),t9o=o(" (XLM-RoBERTa model)"),a9o=l(),T1=a("li"),pfe=a("strong"),n9o=o("xlm-roberta-xl"),s9o=o(" \u2014 "),UD=a("a"),l9o=o("XLMRobertaXLForMaskedLM"),i9o=o(" (XLM-RoBERTa-XL model)"),d9o=l(),M1=a("li"),_fe=a("strong"),c9o=o("yoso"),f9o=o(" \u2014 "),JD=a("a"),m9o=o("YosoForMaskedLM"),g9o=o(" (YOSO model)"),h9o=l(),E1=a("p"),p9o=o("The model is set in evaluation mode by default using "),ufe=a("code"),_9o=o("model.eval()"),u9o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bfe=a("code"),b9o=o("model.train()"),v9o=l(),F(C1.$$.fragment),Iqe=l(),qi=a("h2"),w1=a("a"),vfe=a("span"),F(Ey.$$.fragment),F9o=l(),Ffe=a("span"),T9o=o("AutoModelForSeq2SeqLM"),Nqe=l(),So=a("div"),F(Cy.$$.fragment),M9o=l(),ji=a("p"),E9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),YD=a("a"),C9o=o("from_pretrained()"),w9o=o(" class method or the "),KD=a("a"),A9o=o("from_config()"),y9o=o(` class
method.`),L9o=l(),wy=a("p"),x9o=o("This class cannot be instantiated directly using "),Tfe=a("code"),$9o=o("__init__()"),k9o=o(" (throws an error)."),S9o=l(),lt=a("div"),F(Ay.$$.fragment),R9o=l(),Mfe=a("p"),P9o=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),B9o=l(),Di=a("p"),I9o=o(`Note:
Loading a model from its configuration file does `),Efe=a("strong"),N9o=o("not"),q9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=a("a"),j9o=o("from_pretrained()"),D9o=o(" to load the model weights."),G9o=l(),F(A1.$$.fragment),O9o=l(),eo=a("div"),F(yy.$$.fragment),V9o=l(),Cfe=a("p"),X9o=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),z9o=l(),Sa=a("p"),W9o=o("The model class to instantiate is selected based on the "),wfe=a("code"),Q9o=o("model_type"),H9o=o(` property of the config object (either
passed as an argument or loaded from `),Afe=a("code"),U9o=o("pretrained_model_name_or_path"),J9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yfe=a("code"),Y9o=o("pretrained_model_name_or_path"),K9o=o(":"),Z9o=l(),_e=a("ul"),y1=a("li"),Lfe=a("strong"),exo=o("bart"),oxo=o(" \u2014 "),eG=a("a"),rxo=o("BartForConditionalGeneration"),txo=o(" (BART model)"),axo=l(),L1=a("li"),xfe=a("strong"),nxo=o("bigbird_pegasus"),sxo=o(" \u2014 "),oG=a("a"),lxo=o("BigBirdPegasusForConditionalGeneration"),ixo=o(" (BigBirdPegasus model)"),dxo=l(),x1=a("li"),$fe=a("strong"),cxo=o("blenderbot"),fxo=o(" \u2014 "),rG=a("a"),mxo=o("BlenderbotForConditionalGeneration"),gxo=o(" (Blenderbot model)"),hxo=l(),$1=a("li"),kfe=a("strong"),pxo=o("blenderbot-small"),_xo=o(" \u2014 "),tG=a("a"),uxo=o("BlenderbotSmallForConditionalGeneration"),bxo=o(" (BlenderbotSmall model)"),vxo=l(),k1=a("li"),Sfe=a("strong"),Fxo=o("encoder-decoder"),Txo=o(" \u2014 "),aG=a("a"),Mxo=o("EncoderDecoderModel"),Exo=o(" (Encoder decoder model)"),Cxo=l(),S1=a("li"),Rfe=a("strong"),wxo=o("fsmt"),Axo=o(" \u2014 "),nG=a("a"),yxo=o("FSMTForConditionalGeneration"),Lxo=o(" (FairSeq Machine-Translation model)"),xxo=l(),R1=a("li"),Pfe=a("strong"),$xo=o("led"),kxo=o(" \u2014 "),sG=a("a"),Sxo=o("LEDForConditionalGeneration"),Rxo=o(" (LED model)"),Pxo=l(),P1=a("li"),Bfe=a("strong"),Bxo=o("m2m_100"),Ixo=o(" \u2014 "),lG=a("a"),Nxo=o("M2M100ForConditionalGeneration"),qxo=o(" (M2M100 model)"),jxo=l(),B1=a("li"),Ife=a("strong"),Dxo=o("marian"),Gxo=o(" \u2014 "),iG=a("a"),Oxo=o("MarianMTModel"),Vxo=o(" (Marian model)"),Xxo=l(),I1=a("li"),Nfe=a("strong"),zxo=o("mbart"),Wxo=o(" \u2014 "),dG=a("a"),Qxo=o("MBartForConditionalGeneration"),Hxo=o(" (mBART model)"),Uxo=l(),N1=a("li"),qfe=a("strong"),Jxo=o("mt5"),Yxo=o(" \u2014 "),cG=a("a"),Kxo=o("MT5ForConditionalGeneration"),Zxo=o(" (mT5 model)"),e$o=l(),q1=a("li"),jfe=a("strong"),o$o=o("pegasus"),r$o=o(" \u2014 "),fG=a("a"),t$o=o("PegasusForConditionalGeneration"),a$o=o(" (Pegasus model)"),n$o=l(),j1=a("li"),Dfe=a("strong"),s$o=o("plbart"),l$o=o(" \u2014 "),mG=a("a"),i$o=o("PLBartForConditionalGeneration"),d$o=o(" (PLBart model)"),c$o=l(),D1=a("li"),Gfe=a("strong"),f$o=o("prophetnet"),m$o=o(" \u2014 "),gG=a("a"),g$o=o("ProphetNetForConditionalGeneration"),h$o=o(" (ProphetNet model)"),p$o=l(),G1=a("li"),Ofe=a("strong"),_$o=o("t5"),u$o=o(" \u2014 "),hG=a("a"),b$o=o("T5ForConditionalGeneration"),v$o=o(" (T5 model)"),F$o=l(),O1=a("li"),Vfe=a("strong"),T$o=o("xlm-prophetnet"),M$o=o(" \u2014 "),pG=a("a"),E$o=o("XLMProphetNetForConditionalGeneration"),C$o=o(" (XLMProphetNet model)"),w$o=l(),V1=a("p"),A$o=o("The model is set in evaluation mode by default using "),Xfe=a("code"),y$o=o("model.eval()"),L$o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zfe=a("code"),x$o=o("model.train()"),$$o=l(),F(X1.$$.fragment),qqe=l(),Gi=a("h2"),z1=a("a"),Wfe=a("span"),F(Ly.$$.fragment),k$o=l(),Qfe=a("span"),S$o=o("AutoModelForSequenceClassification"),jqe=l(),Ro=a("div"),F(xy.$$.fragment),R$o=l(),Oi=a("p"),P$o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_G=a("a"),B$o=o("from_pretrained()"),I$o=o(" class method or the "),uG=a("a"),N$o=o("from_config()"),q$o=o(` class
method.`),j$o=l(),$y=a("p"),D$o=o("This class cannot be instantiated directly using "),Hfe=a("code"),G$o=o("__init__()"),O$o=o(" (throws an error)."),V$o=l(),it=a("div"),F(ky.$$.fragment),X$o=l(),Ufe=a("p"),z$o=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),W$o=l(),Vi=a("p"),Q$o=o(`Note:
Loading a model from its configuration file does `),Jfe=a("strong"),H$o=o("not"),U$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bG=a("a"),J$o=o("from_pretrained()"),Y$o=o(" to load the model weights."),K$o=l(),F(W1.$$.fragment),Z$o=l(),oo=a("div"),F(Sy.$$.fragment),eko=l(),Yfe=a("p"),oko=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),rko=l(),Ra=a("p"),tko=o("The model class to instantiate is selected based on the "),Kfe=a("code"),ako=o("model_type"),nko=o(` property of the config object (either
passed as an argument or loaded from `),Zfe=a("code"),sko=o("pretrained_model_name_or_path"),lko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eme=a("code"),iko=o("pretrained_model_name_or_path"),dko=o(":"),cko=l(),N=a("ul"),Q1=a("li"),ome=a("strong"),fko=o("albert"),mko=o(" \u2014 "),vG=a("a"),gko=o("AlbertForSequenceClassification"),hko=o(" (ALBERT model)"),pko=l(),H1=a("li"),rme=a("strong"),_ko=o("bart"),uko=o(" \u2014 "),FG=a("a"),bko=o("BartForSequenceClassification"),vko=o(" (BART model)"),Fko=l(),U1=a("li"),tme=a("strong"),Tko=o("bert"),Mko=o(" \u2014 "),TG=a("a"),Eko=o("BertForSequenceClassification"),Cko=o(" (BERT model)"),wko=l(),J1=a("li"),ame=a("strong"),Ako=o("big_bird"),yko=o(" \u2014 "),MG=a("a"),Lko=o("BigBirdForSequenceClassification"),xko=o(" (BigBird model)"),$ko=l(),Y1=a("li"),nme=a("strong"),kko=o("bigbird_pegasus"),Sko=o(" \u2014 "),EG=a("a"),Rko=o("BigBirdPegasusForSequenceClassification"),Pko=o(" (BigBirdPegasus model)"),Bko=l(),K1=a("li"),sme=a("strong"),Iko=o("camembert"),Nko=o(" \u2014 "),CG=a("a"),qko=o("CamembertForSequenceClassification"),jko=o(" (CamemBERT model)"),Dko=l(),Z1=a("li"),lme=a("strong"),Gko=o("canine"),Oko=o(" \u2014 "),wG=a("a"),Vko=o("CanineForSequenceClassification"),Xko=o(" (Canine model)"),zko=l(),eb=a("li"),ime=a("strong"),Wko=o("convbert"),Qko=o(" \u2014 "),AG=a("a"),Hko=o("ConvBertForSequenceClassification"),Uko=o(" (ConvBERT model)"),Jko=l(),ob=a("li"),dme=a("strong"),Yko=o("ctrl"),Kko=o(" \u2014 "),yG=a("a"),Zko=o("CTRLForSequenceClassification"),eSo=o(" (CTRL model)"),oSo=l(),rb=a("li"),cme=a("strong"),rSo=o("data2vec-text"),tSo=o(" \u2014 "),LG=a("a"),aSo=o("Data2VecTextForSequenceClassification"),nSo=o(" (Data2VecText model)"),sSo=l(),tb=a("li"),fme=a("strong"),lSo=o("deberta"),iSo=o(" \u2014 "),xG=a("a"),dSo=o("DebertaForSequenceClassification"),cSo=o(" (DeBERTa model)"),fSo=l(),ab=a("li"),mme=a("strong"),mSo=o("deberta-v2"),gSo=o(" \u2014 "),$G=a("a"),hSo=o("DebertaV2ForSequenceClassification"),pSo=o(" (DeBERTa-v2 model)"),_So=l(),nb=a("li"),gme=a("strong"),uSo=o("distilbert"),bSo=o(" \u2014 "),kG=a("a"),vSo=o("DistilBertForSequenceClassification"),FSo=o(" (DistilBERT model)"),TSo=l(),sb=a("li"),hme=a("strong"),MSo=o("electra"),ESo=o(" \u2014 "),SG=a("a"),CSo=o("ElectraForSequenceClassification"),wSo=o(" (ELECTRA model)"),ASo=l(),lb=a("li"),pme=a("strong"),ySo=o("flaubert"),LSo=o(" \u2014 "),RG=a("a"),xSo=o("FlaubertForSequenceClassification"),$So=o(" (FlauBERT model)"),kSo=l(),ib=a("li"),_me=a("strong"),SSo=o("fnet"),RSo=o(" \u2014 "),PG=a("a"),PSo=o("FNetForSequenceClassification"),BSo=o(" (FNet model)"),ISo=l(),db=a("li"),ume=a("strong"),NSo=o("funnel"),qSo=o(" \u2014 "),BG=a("a"),jSo=o("FunnelForSequenceClassification"),DSo=o(" (Funnel Transformer model)"),GSo=l(),cb=a("li"),bme=a("strong"),OSo=o("gpt2"),VSo=o(" \u2014 "),IG=a("a"),XSo=o("GPT2ForSequenceClassification"),zSo=o(" (OpenAI GPT-2 model)"),WSo=l(),fb=a("li"),vme=a("strong"),QSo=o("gpt_neo"),HSo=o(" \u2014 "),NG=a("a"),USo=o("GPTNeoForSequenceClassification"),JSo=o(" (GPT Neo model)"),YSo=l(),mb=a("li"),Fme=a("strong"),KSo=o("gptj"),ZSo=o(" \u2014 "),qG=a("a"),eRo=o("GPTJForSequenceClassification"),oRo=o(" (GPT-J model)"),rRo=l(),gb=a("li"),Tme=a("strong"),tRo=o("ibert"),aRo=o(" \u2014 "),jG=a("a"),nRo=o("IBertForSequenceClassification"),sRo=o(" (I-BERT model)"),lRo=l(),hb=a("li"),Mme=a("strong"),iRo=o("layoutlm"),dRo=o(" \u2014 "),DG=a("a"),cRo=o("LayoutLMForSequenceClassification"),fRo=o(" (LayoutLM model)"),mRo=l(),pb=a("li"),Eme=a("strong"),gRo=o("layoutlmv2"),hRo=o(" \u2014 "),GG=a("a"),pRo=o("LayoutLMv2ForSequenceClassification"),_Ro=o(" (LayoutLMv2 model)"),uRo=l(),_b=a("li"),Cme=a("strong"),bRo=o("layoutlmv3"),vRo=o(" \u2014 "),OG=a("a"),FRo=o("LayoutLMv3ForSequenceClassification"),TRo=o(" (LayoutLMv3 model)"),MRo=l(),ub=a("li"),wme=a("strong"),ERo=o("led"),CRo=o(" \u2014 "),VG=a("a"),wRo=o("LEDForSequenceClassification"),ARo=o(" (LED model)"),yRo=l(),bb=a("li"),Ame=a("strong"),LRo=o("longformer"),xRo=o(" \u2014 "),XG=a("a"),$Ro=o("LongformerForSequenceClassification"),kRo=o(" (Longformer model)"),SRo=l(),vb=a("li"),yme=a("strong"),RRo=o("mbart"),PRo=o(" \u2014 "),zG=a("a"),BRo=o("MBartForSequenceClassification"),IRo=o(" (mBART model)"),NRo=l(),Fb=a("li"),Lme=a("strong"),qRo=o("megatron-bert"),jRo=o(" \u2014 "),WG=a("a"),DRo=o("MegatronBertForSequenceClassification"),GRo=o(" (MegatronBert model)"),ORo=l(),Tb=a("li"),xme=a("strong"),VRo=o("mobilebert"),XRo=o(" \u2014 "),QG=a("a"),zRo=o("MobileBertForSequenceClassification"),WRo=o(" (MobileBERT model)"),QRo=l(),Mb=a("li"),$me=a("strong"),HRo=o("mpnet"),URo=o(" \u2014 "),HG=a("a"),JRo=o("MPNetForSequenceClassification"),YRo=o(" (MPNet model)"),KRo=l(),Eb=a("li"),kme=a("strong"),ZRo=o("nystromformer"),ePo=o(" \u2014 "),UG=a("a"),oPo=o("NystromformerForSequenceClassification"),rPo=o(" (Nystromformer model)"),tPo=l(),Cb=a("li"),Sme=a("strong"),aPo=o("openai-gpt"),nPo=o(" \u2014 "),JG=a("a"),sPo=o("OpenAIGPTForSequenceClassification"),lPo=o(" (OpenAI GPT model)"),iPo=l(),wb=a("li"),Rme=a("strong"),dPo=o("perceiver"),cPo=o(" \u2014 "),YG=a("a"),fPo=o("PerceiverForSequenceClassification"),mPo=o(" (Perceiver model)"),gPo=l(),Ab=a("li"),Pme=a("strong"),hPo=o("plbart"),pPo=o(" \u2014 "),KG=a("a"),_Po=o("PLBartForSequenceClassification"),uPo=o(" (PLBart model)"),bPo=l(),yb=a("li"),Bme=a("strong"),vPo=o("qdqbert"),FPo=o(" \u2014 "),ZG=a("a"),TPo=o("QDQBertForSequenceClassification"),MPo=o(" (QDQBert model)"),EPo=l(),Lb=a("li"),Ime=a("strong"),CPo=o("reformer"),wPo=o(" \u2014 "),eO=a("a"),APo=o("ReformerForSequenceClassification"),yPo=o(" (Reformer model)"),LPo=l(),xb=a("li"),Nme=a("strong"),xPo=o("rembert"),$Po=o(" \u2014 "),oO=a("a"),kPo=o("RemBertForSequenceClassification"),SPo=o(" (RemBERT model)"),RPo=l(),$b=a("li"),qme=a("strong"),PPo=o("roberta"),BPo=o(" \u2014 "),rO=a("a"),IPo=o("RobertaForSequenceClassification"),NPo=o(" (RoBERTa model)"),qPo=l(),kb=a("li"),jme=a("strong"),jPo=o("roformer"),DPo=o(" \u2014 "),tO=a("a"),GPo=o("RoFormerForSequenceClassification"),OPo=o(" (RoFormer model)"),VPo=l(),Sb=a("li"),Dme=a("strong"),XPo=o("squeezebert"),zPo=o(" \u2014 "),aO=a("a"),WPo=o("SqueezeBertForSequenceClassification"),QPo=o(" (SqueezeBERT model)"),HPo=l(),Rb=a("li"),Gme=a("strong"),UPo=o("tapas"),JPo=o(" \u2014 "),nO=a("a"),YPo=o("TapasForSequenceClassification"),KPo=o(" (TAPAS model)"),ZPo=l(),Pb=a("li"),Ome=a("strong"),eBo=o("transfo-xl"),oBo=o(" \u2014 "),sO=a("a"),rBo=o("TransfoXLForSequenceClassification"),tBo=o(" (Transformer-XL model)"),aBo=l(),Bb=a("li"),Vme=a("strong"),nBo=o("xlm"),sBo=o(" \u2014 "),lO=a("a"),lBo=o("XLMForSequenceClassification"),iBo=o(" (XLM model)"),dBo=l(),Ib=a("li"),Xme=a("strong"),cBo=o("xlm-roberta"),fBo=o(" \u2014 "),iO=a("a"),mBo=o("XLMRobertaForSequenceClassification"),gBo=o(" (XLM-RoBERTa model)"),hBo=l(),Nb=a("li"),zme=a("strong"),pBo=o("xlm-roberta-xl"),_Bo=o(" \u2014 "),dO=a("a"),uBo=o("XLMRobertaXLForSequenceClassification"),bBo=o(" (XLM-RoBERTa-XL model)"),vBo=l(),qb=a("li"),Wme=a("strong"),FBo=o("xlnet"),TBo=o(" \u2014 "),cO=a("a"),MBo=o("XLNetForSequenceClassification"),EBo=o(" (XLNet model)"),CBo=l(),jb=a("li"),Qme=a("strong"),wBo=o("yoso"),ABo=o(" \u2014 "),fO=a("a"),yBo=o("YosoForSequenceClassification"),LBo=o(" (YOSO model)"),xBo=l(),Db=a("p"),$Bo=o("The model is set in evaluation mode by default using "),Hme=a("code"),kBo=o("model.eval()"),SBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ume=a("code"),RBo=o("model.train()"),PBo=l(),F(Gb.$$.fragment),Dqe=l(),Xi=a("h2"),Ob=a("a"),Jme=a("span"),F(Ry.$$.fragment),BBo=l(),Yme=a("span"),IBo=o("AutoModelForMultipleChoice"),Gqe=l(),Po=a("div"),F(Py.$$.fragment),NBo=l(),zi=a("p"),qBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),mO=a("a"),jBo=o("from_pretrained()"),DBo=o(" class method or the "),gO=a("a"),GBo=o("from_config()"),OBo=o(` class
method.`),VBo=l(),By=a("p"),XBo=o("This class cannot be instantiated directly using "),Kme=a("code"),zBo=o("__init__()"),WBo=o(" (throws an error)."),QBo=l(),dt=a("div"),F(Iy.$$.fragment),HBo=l(),Zme=a("p"),UBo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),JBo=l(),Wi=a("p"),YBo=o(`Note:
Loading a model from its configuration file does `),ege=a("strong"),KBo=o("not"),ZBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=a("a"),eIo=o("from_pretrained()"),oIo=o(" to load the model weights."),rIo=l(),F(Vb.$$.fragment),tIo=l(),ro=a("div"),F(Ny.$$.fragment),aIo=l(),oge=a("p"),nIo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),sIo=l(),Pa=a("p"),lIo=o("The model class to instantiate is selected based on the "),rge=a("code"),iIo=o("model_type"),dIo=o(` property of the config object (either
passed as an argument or loaded from `),tge=a("code"),cIo=o("pretrained_model_name_or_path"),fIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),age=a("code"),mIo=o("pretrained_model_name_or_path"),gIo=o(":"),hIo=l(),K=a("ul"),Xb=a("li"),nge=a("strong"),pIo=o("albert"),_Io=o(" \u2014 "),pO=a("a"),uIo=o("AlbertForMultipleChoice"),bIo=o(" (ALBERT model)"),vIo=l(),zb=a("li"),sge=a("strong"),FIo=o("bert"),TIo=o(" \u2014 "),_O=a("a"),MIo=o("BertForMultipleChoice"),EIo=o(" (BERT model)"),CIo=l(),Wb=a("li"),lge=a("strong"),wIo=o("big_bird"),AIo=o(" \u2014 "),uO=a("a"),yIo=o("BigBirdForMultipleChoice"),LIo=o(" (BigBird model)"),xIo=l(),Qb=a("li"),ige=a("strong"),$Io=o("camembert"),kIo=o(" \u2014 "),bO=a("a"),SIo=o("CamembertForMultipleChoice"),RIo=o(" (CamemBERT model)"),PIo=l(),Hb=a("li"),dge=a("strong"),BIo=o("canine"),IIo=o(" \u2014 "),vO=a("a"),NIo=o("CanineForMultipleChoice"),qIo=o(" (Canine model)"),jIo=l(),Ub=a("li"),cge=a("strong"),DIo=o("convbert"),GIo=o(" \u2014 "),FO=a("a"),OIo=o("ConvBertForMultipleChoice"),VIo=o(" (ConvBERT model)"),XIo=l(),Jb=a("li"),fge=a("strong"),zIo=o("data2vec-text"),WIo=o(" \u2014 "),TO=a("a"),QIo=o("Data2VecTextForMultipleChoice"),HIo=o(" (Data2VecText model)"),UIo=l(),Yb=a("li"),mge=a("strong"),JIo=o("deberta-v2"),YIo=o(" \u2014 "),MO=a("a"),KIo=o("DebertaV2ForMultipleChoice"),ZIo=o(" (DeBERTa-v2 model)"),eNo=l(),Kb=a("li"),gge=a("strong"),oNo=o("distilbert"),rNo=o(" \u2014 "),EO=a("a"),tNo=o("DistilBertForMultipleChoice"),aNo=o(" (DistilBERT model)"),nNo=l(),Zb=a("li"),hge=a("strong"),sNo=o("electra"),lNo=o(" \u2014 "),CO=a("a"),iNo=o("ElectraForMultipleChoice"),dNo=o(" (ELECTRA model)"),cNo=l(),e2=a("li"),pge=a("strong"),fNo=o("flaubert"),mNo=o(" \u2014 "),wO=a("a"),gNo=o("FlaubertForMultipleChoice"),hNo=o(" (FlauBERT model)"),pNo=l(),o2=a("li"),_ge=a("strong"),_No=o("fnet"),uNo=o(" \u2014 "),AO=a("a"),bNo=o("FNetForMultipleChoice"),vNo=o(" (FNet model)"),FNo=l(),r2=a("li"),uge=a("strong"),TNo=o("funnel"),MNo=o(" \u2014 "),yO=a("a"),ENo=o("FunnelForMultipleChoice"),CNo=o(" (Funnel Transformer model)"),wNo=l(),t2=a("li"),bge=a("strong"),ANo=o("ibert"),yNo=o(" \u2014 "),LO=a("a"),LNo=o("IBertForMultipleChoice"),xNo=o(" (I-BERT model)"),$No=l(),a2=a("li"),vge=a("strong"),kNo=o("longformer"),SNo=o(" \u2014 "),xO=a("a"),RNo=o("LongformerForMultipleChoice"),PNo=o(" (Longformer model)"),BNo=l(),n2=a("li"),Fge=a("strong"),INo=o("megatron-bert"),NNo=o(" \u2014 "),$O=a("a"),qNo=o("MegatronBertForMultipleChoice"),jNo=o(" (MegatronBert model)"),DNo=l(),s2=a("li"),Tge=a("strong"),GNo=o("mobilebert"),ONo=o(" \u2014 "),kO=a("a"),VNo=o("MobileBertForMultipleChoice"),XNo=o(" (MobileBERT model)"),zNo=l(),l2=a("li"),Mge=a("strong"),WNo=o("mpnet"),QNo=o(" \u2014 "),SO=a("a"),HNo=o("MPNetForMultipleChoice"),UNo=o(" (MPNet model)"),JNo=l(),i2=a("li"),Ege=a("strong"),YNo=o("nystromformer"),KNo=o(" \u2014 "),RO=a("a"),ZNo=o("NystromformerForMultipleChoice"),eqo=o(" (Nystromformer model)"),oqo=l(),d2=a("li"),Cge=a("strong"),rqo=o("qdqbert"),tqo=o(" \u2014 "),PO=a("a"),aqo=o("QDQBertForMultipleChoice"),nqo=o(" (QDQBert model)"),sqo=l(),c2=a("li"),wge=a("strong"),lqo=o("rembert"),iqo=o(" \u2014 "),BO=a("a"),dqo=o("RemBertForMultipleChoice"),cqo=o(" (RemBERT model)"),fqo=l(),f2=a("li"),Age=a("strong"),mqo=o("roberta"),gqo=o(" \u2014 "),IO=a("a"),hqo=o("RobertaForMultipleChoice"),pqo=o(" (RoBERTa model)"),_qo=l(),m2=a("li"),yge=a("strong"),uqo=o("roformer"),bqo=o(" \u2014 "),NO=a("a"),vqo=o("RoFormerForMultipleChoice"),Fqo=o(" (RoFormer model)"),Tqo=l(),g2=a("li"),Lge=a("strong"),Mqo=o("squeezebert"),Eqo=o(" \u2014 "),qO=a("a"),Cqo=o("SqueezeBertForMultipleChoice"),wqo=o(" (SqueezeBERT model)"),Aqo=l(),h2=a("li"),xge=a("strong"),yqo=o("xlm"),Lqo=o(" \u2014 "),jO=a("a"),xqo=o("XLMForMultipleChoice"),$qo=o(" (XLM model)"),kqo=l(),p2=a("li"),$ge=a("strong"),Sqo=o("xlm-roberta"),Rqo=o(" \u2014 "),DO=a("a"),Pqo=o("XLMRobertaForMultipleChoice"),Bqo=o(" (XLM-RoBERTa model)"),Iqo=l(),_2=a("li"),kge=a("strong"),Nqo=o("xlm-roberta-xl"),qqo=o(" \u2014 "),GO=a("a"),jqo=o("XLMRobertaXLForMultipleChoice"),Dqo=o(" (XLM-RoBERTa-XL model)"),Gqo=l(),u2=a("li"),Sge=a("strong"),Oqo=o("xlnet"),Vqo=o(" \u2014 "),OO=a("a"),Xqo=o("XLNetForMultipleChoice"),zqo=o(" (XLNet model)"),Wqo=l(),b2=a("li"),Rge=a("strong"),Qqo=o("yoso"),Hqo=o(" \u2014 "),VO=a("a"),Uqo=o("YosoForMultipleChoice"),Jqo=o(" (YOSO model)"),Yqo=l(),v2=a("p"),Kqo=o("The model is set in evaluation mode by default using "),Pge=a("code"),Zqo=o("model.eval()"),ejo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bge=a("code"),ojo=o("model.train()"),rjo=l(),F(F2.$$.fragment),Oqe=l(),Qi=a("h2"),T2=a("a"),Ige=a("span"),F(qy.$$.fragment),tjo=l(),Nge=a("span"),ajo=o("AutoModelForNextSentencePrediction"),Vqe=l(),Bo=a("div"),F(jy.$$.fragment),njo=l(),Hi=a("p"),sjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),XO=a("a"),ljo=o("from_pretrained()"),ijo=o(" class method or the "),zO=a("a"),djo=o("from_config()"),cjo=o(` class
method.`),fjo=l(),Dy=a("p"),mjo=o("This class cannot be instantiated directly using "),qge=a("code"),gjo=o("__init__()"),hjo=o(" (throws an error)."),pjo=l(),ct=a("div"),F(Gy.$$.fragment),_jo=l(),jge=a("p"),ujo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),bjo=l(),Ui=a("p"),vjo=o(`Note:
Loading a model from its configuration file does `),Dge=a("strong"),Fjo=o("not"),Tjo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WO=a("a"),Mjo=o("from_pretrained()"),Ejo=o(" to load the model weights."),Cjo=l(),F(M2.$$.fragment),wjo=l(),to=a("div"),F(Oy.$$.fragment),Ajo=l(),Gge=a("p"),yjo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Ljo=l(),Ba=a("p"),xjo=o("The model class to instantiate is selected based on the "),Oge=a("code"),$jo=o("model_type"),kjo=o(` property of the config object (either
passed as an argument or loaded from `),Vge=a("code"),Sjo=o("pretrained_model_name_or_path"),Rjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xge=a("code"),Pjo=o("pretrained_model_name_or_path"),Bjo=o(":"),Ijo=l(),Yr=a("ul"),E2=a("li"),zge=a("strong"),Njo=o("bert"),qjo=o(" \u2014 "),QO=a("a"),jjo=o("BertForNextSentencePrediction"),Djo=o(" (BERT model)"),Gjo=l(),C2=a("li"),Wge=a("strong"),Ojo=o("fnet"),Vjo=o(" \u2014 "),HO=a("a"),Xjo=o("FNetForNextSentencePrediction"),zjo=o(" (FNet model)"),Wjo=l(),w2=a("li"),Qge=a("strong"),Qjo=o("megatron-bert"),Hjo=o(" \u2014 "),UO=a("a"),Ujo=o("MegatronBertForNextSentencePrediction"),Jjo=o(" (MegatronBert model)"),Yjo=l(),A2=a("li"),Hge=a("strong"),Kjo=o("mobilebert"),Zjo=o(" \u2014 "),JO=a("a"),eDo=o("MobileBertForNextSentencePrediction"),oDo=o(" (MobileBERT model)"),rDo=l(),y2=a("li"),Uge=a("strong"),tDo=o("qdqbert"),aDo=o(" \u2014 "),YO=a("a"),nDo=o("QDQBertForNextSentencePrediction"),sDo=o(" (QDQBert model)"),lDo=l(),L2=a("p"),iDo=o("The model is set in evaluation mode by default using "),Jge=a("code"),dDo=o("model.eval()"),cDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yge=a("code"),fDo=o("model.train()"),mDo=l(),F(x2.$$.fragment),Xqe=l(),Ji=a("h2"),$2=a("a"),Kge=a("span"),F(Vy.$$.fragment),gDo=l(),Zge=a("span"),hDo=o("AutoModelForTokenClassification"),zqe=l(),Io=a("div"),F(Xy.$$.fragment),pDo=l(),Yi=a("p"),_Do=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),KO=a("a"),uDo=o("from_pretrained()"),bDo=o(" class method or the "),ZO=a("a"),vDo=o("from_config()"),FDo=o(` class
method.`),TDo=l(),zy=a("p"),MDo=o("This class cannot be instantiated directly using "),ehe=a("code"),EDo=o("__init__()"),CDo=o(" (throws an error)."),wDo=l(),ft=a("div"),F(Wy.$$.fragment),ADo=l(),ohe=a("p"),yDo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),LDo=l(),Ki=a("p"),xDo=o(`Note:
Loading a model from its configuration file does `),rhe=a("strong"),$Do=o("not"),kDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eV=a("a"),SDo=o("from_pretrained()"),RDo=o(" to load the model weights."),PDo=l(),F(k2.$$.fragment),BDo=l(),ao=a("div"),F(Qy.$$.fragment),IDo=l(),the=a("p"),NDo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),qDo=l(),Ia=a("p"),jDo=o("The model class to instantiate is selected based on the "),ahe=a("code"),DDo=o("model_type"),GDo=o(` property of the config object (either
passed as an argument or loaded from `),nhe=a("code"),ODo=o("pretrained_model_name_or_path"),VDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),she=a("code"),XDo=o("pretrained_model_name_or_path"),zDo=o(":"),WDo=l(),H=a("ul"),S2=a("li"),lhe=a("strong"),QDo=o("albert"),HDo=o(" \u2014 "),oV=a("a"),UDo=o("AlbertForTokenClassification"),JDo=o(" (ALBERT model)"),YDo=l(),R2=a("li"),ihe=a("strong"),KDo=o("bert"),ZDo=o(" \u2014 "),rV=a("a"),eGo=o("BertForTokenClassification"),oGo=o(" (BERT model)"),rGo=l(),P2=a("li"),dhe=a("strong"),tGo=o("big_bird"),aGo=o(" \u2014 "),tV=a("a"),nGo=o("BigBirdForTokenClassification"),sGo=o(" (BigBird model)"),lGo=l(),B2=a("li"),che=a("strong"),iGo=o("camembert"),dGo=o(" \u2014 "),aV=a("a"),cGo=o("CamembertForTokenClassification"),fGo=o(" (CamemBERT model)"),mGo=l(),I2=a("li"),fhe=a("strong"),gGo=o("canine"),hGo=o(" \u2014 "),nV=a("a"),pGo=o("CanineForTokenClassification"),_Go=o(" (Canine model)"),uGo=l(),N2=a("li"),mhe=a("strong"),bGo=o("convbert"),vGo=o(" \u2014 "),sV=a("a"),FGo=o("ConvBertForTokenClassification"),TGo=o(" (ConvBERT model)"),MGo=l(),q2=a("li"),ghe=a("strong"),EGo=o("data2vec-text"),CGo=o(" \u2014 "),lV=a("a"),wGo=o("Data2VecTextForTokenClassification"),AGo=o(" (Data2VecText model)"),yGo=l(),j2=a("li"),hhe=a("strong"),LGo=o("deberta"),xGo=o(" \u2014 "),iV=a("a"),$Go=o("DebertaForTokenClassification"),kGo=o(" (DeBERTa model)"),SGo=l(),D2=a("li"),phe=a("strong"),RGo=o("deberta-v2"),PGo=o(" \u2014 "),dV=a("a"),BGo=o("DebertaV2ForTokenClassification"),IGo=o(" (DeBERTa-v2 model)"),NGo=l(),G2=a("li"),_he=a("strong"),qGo=o("distilbert"),jGo=o(" \u2014 "),cV=a("a"),DGo=o("DistilBertForTokenClassification"),GGo=o(" (DistilBERT model)"),OGo=l(),O2=a("li"),uhe=a("strong"),VGo=o("electra"),XGo=o(" \u2014 "),fV=a("a"),zGo=o("ElectraForTokenClassification"),WGo=o(" (ELECTRA model)"),QGo=l(),V2=a("li"),bhe=a("strong"),HGo=o("flaubert"),UGo=o(" \u2014 "),mV=a("a"),JGo=o("FlaubertForTokenClassification"),YGo=o(" (FlauBERT model)"),KGo=l(),X2=a("li"),vhe=a("strong"),ZGo=o("fnet"),eOo=o(" \u2014 "),gV=a("a"),oOo=o("FNetForTokenClassification"),rOo=o(" (FNet model)"),tOo=l(),z2=a("li"),Fhe=a("strong"),aOo=o("funnel"),nOo=o(" \u2014 "),hV=a("a"),sOo=o("FunnelForTokenClassification"),lOo=o(" (Funnel Transformer model)"),iOo=l(),W2=a("li"),The=a("strong"),dOo=o("gpt2"),cOo=o(" \u2014 "),pV=a("a"),fOo=o("GPT2ForTokenClassification"),mOo=o(" (OpenAI GPT-2 model)"),gOo=l(),Q2=a("li"),Mhe=a("strong"),hOo=o("ibert"),pOo=o(" \u2014 "),_V=a("a"),_Oo=o("IBertForTokenClassification"),uOo=o(" (I-BERT model)"),bOo=l(),H2=a("li"),Ehe=a("strong"),vOo=o("layoutlm"),FOo=o(" \u2014 "),uV=a("a"),TOo=o("LayoutLMForTokenClassification"),MOo=o(" (LayoutLM model)"),EOo=l(),U2=a("li"),Che=a("strong"),COo=o("layoutlmv2"),wOo=o(" \u2014 "),bV=a("a"),AOo=o("LayoutLMv2ForTokenClassification"),yOo=o(" (LayoutLMv2 model)"),LOo=l(),J2=a("li"),whe=a("strong"),xOo=o("layoutlmv3"),$Oo=o(" \u2014 "),vV=a("a"),kOo=o("LayoutLMv3ForTokenClassification"),SOo=o(" (LayoutLMv3 model)"),ROo=l(),Y2=a("li"),Ahe=a("strong"),POo=o("longformer"),BOo=o(" \u2014 "),FV=a("a"),IOo=o("LongformerForTokenClassification"),NOo=o(" (Longformer model)"),qOo=l(),K2=a("li"),yhe=a("strong"),jOo=o("megatron-bert"),DOo=o(" \u2014 "),TV=a("a"),GOo=o("MegatronBertForTokenClassification"),OOo=o(" (MegatronBert model)"),VOo=l(),Z2=a("li"),Lhe=a("strong"),XOo=o("mobilebert"),zOo=o(" \u2014 "),MV=a("a"),WOo=o("MobileBertForTokenClassification"),QOo=o(" (MobileBERT model)"),HOo=l(),ev=a("li"),xhe=a("strong"),UOo=o("mpnet"),JOo=o(" \u2014 "),EV=a("a"),YOo=o("MPNetForTokenClassification"),KOo=o(" (MPNet model)"),ZOo=l(),ov=a("li"),$he=a("strong"),eVo=o("nystromformer"),oVo=o(" \u2014 "),CV=a("a"),rVo=o("NystromformerForTokenClassification"),tVo=o(" (Nystromformer model)"),aVo=l(),rv=a("li"),khe=a("strong"),nVo=o("qdqbert"),sVo=o(" \u2014 "),wV=a("a"),lVo=o("QDQBertForTokenClassification"),iVo=o(" (QDQBert model)"),dVo=l(),tv=a("li"),She=a("strong"),cVo=o("rembert"),fVo=o(" \u2014 "),AV=a("a"),mVo=o("RemBertForTokenClassification"),gVo=o(" (RemBERT model)"),hVo=l(),av=a("li"),Rhe=a("strong"),pVo=o("roberta"),_Vo=o(" \u2014 "),yV=a("a"),uVo=o("RobertaForTokenClassification"),bVo=o(" (RoBERTa model)"),vVo=l(),nv=a("li"),Phe=a("strong"),FVo=o("roformer"),TVo=o(" \u2014 "),LV=a("a"),MVo=o("RoFormerForTokenClassification"),EVo=o(" (RoFormer model)"),CVo=l(),sv=a("li"),Bhe=a("strong"),wVo=o("squeezebert"),AVo=o(" \u2014 "),xV=a("a"),yVo=o("SqueezeBertForTokenClassification"),LVo=o(" (SqueezeBERT model)"),xVo=l(),lv=a("li"),Ihe=a("strong"),$Vo=o("xlm"),kVo=o(" \u2014 "),$V=a("a"),SVo=o("XLMForTokenClassification"),RVo=o(" (XLM model)"),PVo=l(),iv=a("li"),Nhe=a("strong"),BVo=o("xlm-roberta"),IVo=o(" \u2014 "),kV=a("a"),NVo=o("XLMRobertaForTokenClassification"),qVo=o(" (XLM-RoBERTa model)"),jVo=l(),dv=a("li"),qhe=a("strong"),DVo=o("xlm-roberta-xl"),GVo=o(" \u2014 "),SV=a("a"),OVo=o("XLMRobertaXLForTokenClassification"),VVo=o(" (XLM-RoBERTa-XL model)"),XVo=l(),cv=a("li"),jhe=a("strong"),zVo=o("xlnet"),WVo=o(" \u2014 "),RV=a("a"),QVo=o("XLNetForTokenClassification"),HVo=o(" (XLNet model)"),UVo=l(),fv=a("li"),Dhe=a("strong"),JVo=o("yoso"),YVo=o(" \u2014 "),PV=a("a"),KVo=o("YosoForTokenClassification"),ZVo=o(" (YOSO model)"),eXo=l(),mv=a("p"),oXo=o("The model is set in evaluation mode by default using "),Ghe=a("code"),rXo=o("model.eval()"),tXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ohe=a("code"),aXo=o("model.train()"),nXo=l(),F(gv.$$.fragment),Wqe=l(),Zi=a("h2"),hv=a("a"),Vhe=a("span"),F(Hy.$$.fragment),sXo=l(),Xhe=a("span"),lXo=o("AutoModelForQuestionAnswering"),Qqe=l(),No=a("div"),F(Uy.$$.fragment),iXo=l(),ed=a("p"),dXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),BV=a("a"),cXo=o("from_pretrained()"),fXo=o(" class method or the "),IV=a("a"),mXo=o("from_config()"),gXo=o(` class
method.`),hXo=l(),Jy=a("p"),pXo=o("This class cannot be instantiated directly using "),zhe=a("code"),_Xo=o("__init__()"),uXo=o(" (throws an error)."),bXo=l(),mt=a("div"),F(Yy.$$.fragment),vXo=l(),Whe=a("p"),FXo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),TXo=l(),od=a("p"),MXo=o(`Note:
Loading a model from its configuration file does `),Qhe=a("strong"),EXo=o("not"),CXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NV=a("a"),wXo=o("from_pretrained()"),AXo=o(" to load the model weights."),yXo=l(),F(pv.$$.fragment),LXo=l(),no=a("div"),F(Ky.$$.fragment),xXo=l(),Hhe=a("p"),$Xo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),kXo=l(),Na=a("p"),SXo=o("The model class to instantiate is selected based on the "),Uhe=a("code"),RXo=o("model_type"),PXo=o(` property of the config object (either
passed as an argument or loaded from `),Jhe=a("code"),BXo=o("pretrained_model_name_or_path"),IXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yhe=a("code"),NXo=o("pretrained_model_name_or_path"),qXo=o(":"),jXo=l(),V=a("ul"),_v=a("li"),Khe=a("strong"),DXo=o("albert"),GXo=o(" \u2014 "),qV=a("a"),OXo=o("AlbertForQuestionAnswering"),VXo=o(" (ALBERT model)"),XXo=l(),uv=a("li"),Zhe=a("strong"),zXo=o("bart"),WXo=o(" \u2014 "),jV=a("a"),QXo=o("BartForQuestionAnswering"),HXo=o(" (BART model)"),UXo=l(),bv=a("li"),epe=a("strong"),JXo=o("bert"),YXo=o(" \u2014 "),DV=a("a"),KXo=o("BertForQuestionAnswering"),ZXo=o(" (BERT model)"),ezo=l(),vv=a("li"),ope=a("strong"),ozo=o("big_bird"),rzo=o(" \u2014 "),GV=a("a"),tzo=o("BigBirdForQuestionAnswering"),azo=o(" (BigBird model)"),nzo=l(),Fv=a("li"),rpe=a("strong"),szo=o("bigbird_pegasus"),lzo=o(" \u2014 "),OV=a("a"),izo=o("BigBirdPegasusForQuestionAnswering"),dzo=o(" (BigBirdPegasus model)"),czo=l(),Tv=a("li"),tpe=a("strong"),fzo=o("camembert"),mzo=o(" \u2014 "),VV=a("a"),gzo=o("CamembertForQuestionAnswering"),hzo=o(" (CamemBERT model)"),pzo=l(),Mv=a("li"),ape=a("strong"),_zo=o("canine"),uzo=o(" \u2014 "),XV=a("a"),bzo=o("CanineForQuestionAnswering"),vzo=o(" (Canine model)"),Fzo=l(),Ev=a("li"),npe=a("strong"),Tzo=o("convbert"),Mzo=o(" \u2014 "),zV=a("a"),Ezo=o("ConvBertForQuestionAnswering"),Czo=o(" (ConvBERT model)"),wzo=l(),Cv=a("li"),spe=a("strong"),Azo=o("data2vec-text"),yzo=o(" \u2014 "),WV=a("a"),Lzo=o("Data2VecTextForQuestionAnswering"),xzo=o(" (Data2VecText model)"),$zo=l(),wv=a("li"),lpe=a("strong"),kzo=o("deberta"),Szo=o(" \u2014 "),QV=a("a"),Rzo=o("DebertaForQuestionAnswering"),Pzo=o(" (DeBERTa model)"),Bzo=l(),Av=a("li"),ipe=a("strong"),Izo=o("deberta-v2"),Nzo=o(" \u2014 "),HV=a("a"),qzo=o("DebertaV2ForQuestionAnswering"),jzo=o(" (DeBERTa-v2 model)"),Dzo=l(),yv=a("li"),dpe=a("strong"),Gzo=o("distilbert"),Ozo=o(" \u2014 "),UV=a("a"),Vzo=o("DistilBertForQuestionAnswering"),Xzo=o(" (DistilBERT model)"),zzo=l(),Lv=a("li"),cpe=a("strong"),Wzo=o("electra"),Qzo=o(" \u2014 "),JV=a("a"),Hzo=o("ElectraForQuestionAnswering"),Uzo=o(" (ELECTRA model)"),Jzo=l(),xv=a("li"),fpe=a("strong"),Yzo=o("flaubert"),Kzo=o(" \u2014 "),YV=a("a"),Zzo=o("FlaubertForQuestionAnsweringSimple"),eWo=o(" (FlauBERT model)"),oWo=l(),$v=a("li"),mpe=a("strong"),rWo=o("fnet"),tWo=o(" \u2014 "),KV=a("a"),aWo=o("FNetForQuestionAnswering"),nWo=o(" (FNet model)"),sWo=l(),kv=a("li"),gpe=a("strong"),lWo=o("funnel"),iWo=o(" \u2014 "),ZV=a("a"),dWo=o("FunnelForQuestionAnswering"),cWo=o(" (Funnel Transformer model)"),fWo=l(),Sv=a("li"),hpe=a("strong"),mWo=o("gptj"),gWo=o(" \u2014 "),eX=a("a"),hWo=o("GPTJForQuestionAnswering"),pWo=o(" (GPT-J model)"),_Wo=l(),Rv=a("li"),ppe=a("strong"),uWo=o("ibert"),bWo=o(" \u2014 "),oX=a("a"),vWo=o("IBertForQuestionAnswering"),FWo=o(" (I-BERT model)"),TWo=l(),Pv=a("li"),_pe=a("strong"),MWo=o("layoutlmv2"),EWo=o(" \u2014 "),rX=a("a"),CWo=o("LayoutLMv2ForQuestionAnswering"),wWo=o(" (LayoutLMv2 model)"),AWo=l(),Bv=a("li"),upe=a("strong"),yWo=o("layoutlmv3"),LWo=o(" \u2014 "),tX=a("a"),xWo=o("LayoutLMv3ForQuestionAnswering"),$Wo=o(" (LayoutLMv3 model)"),kWo=l(),Iv=a("li"),bpe=a("strong"),SWo=o("led"),RWo=o(" \u2014 "),aX=a("a"),PWo=o("LEDForQuestionAnswering"),BWo=o(" (LED model)"),IWo=l(),Nv=a("li"),vpe=a("strong"),NWo=o("longformer"),qWo=o(" \u2014 "),nX=a("a"),jWo=o("LongformerForQuestionAnswering"),DWo=o(" (Longformer model)"),GWo=l(),qv=a("li"),Fpe=a("strong"),OWo=o("lxmert"),VWo=o(" \u2014 "),sX=a("a"),XWo=o("LxmertForQuestionAnswering"),zWo=o(" (LXMERT model)"),WWo=l(),jv=a("li"),Tpe=a("strong"),QWo=o("mbart"),HWo=o(" \u2014 "),lX=a("a"),UWo=o("MBartForQuestionAnswering"),JWo=o(" (mBART model)"),YWo=l(),Dv=a("li"),Mpe=a("strong"),KWo=o("megatron-bert"),ZWo=o(" \u2014 "),iX=a("a"),eQo=o("MegatronBertForQuestionAnswering"),oQo=o(" (MegatronBert model)"),rQo=l(),Gv=a("li"),Epe=a("strong"),tQo=o("mobilebert"),aQo=o(" \u2014 "),dX=a("a"),nQo=o("MobileBertForQuestionAnswering"),sQo=o(" (MobileBERT model)"),lQo=l(),Ov=a("li"),Cpe=a("strong"),iQo=o("mpnet"),dQo=o(" \u2014 "),cX=a("a"),cQo=o("MPNetForQuestionAnswering"),fQo=o(" (MPNet model)"),mQo=l(),Vv=a("li"),wpe=a("strong"),gQo=o("nystromformer"),hQo=o(" \u2014 "),fX=a("a"),pQo=o("NystromformerForQuestionAnswering"),_Qo=o(" (Nystromformer model)"),uQo=l(),Xv=a("li"),Ape=a("strong"),bQo=o("qdqbert"),vQo=o(" \u2014 "),mX=a("a"),FQo=o("QDQBertForQuestionAnswering"),TQo=o(" (QDQBert model)"),MQo=l(),zv=a("li"),ype=a("strong"),EQo=o("reformer"),CQo=o(" \u2014 "),gX=a("a"),wQo=o("ReformerForQuestionAnswering"),AQo=o(" (Reformer model)"),yQo=l(),Wv=a("li"),Lpe=a("strong"),LQo=o("rembert"),xQo=o(" \u2014 "),hX=a("a"),$Qo=o("RemBertForQuestionAnswering"),kQo=o(" (RemBERT model)"),SQo=l(),Qv=a("li"),xpe=a("strong"),RQo=o("roberta"),PQo=o(" \u2014 "),pX=a("a"),BQo=o("RobertaForQuestionAnswering"),IQo=o(" (RoBERTa model)"),NQo=l(),Hv=a("li"),$pe=a("strong"),qQo=o("roformer"),jQo=o(" \u2014 "),_X=a("a"),DQo=o("RoFormerForQuestionAnswering"),GQo=o(" (RoFormer model)"),OQo=l(),Uv=a("li"),kpe=a("strong"),VQo=o("splinter"),XQo=o(" \u2014 "),uX=a("a"),zQo=o("SplinterForQuestionAnswering"),WQo=o(" (Splinter model)"),QQo=l(),Jv=a("li"),Spe=a("strong"),HQo=o("squeezebert"),UQo=o(" \u2014 "),bX=a("a"),JQo=o("SqueezeBertForQuestionAnswering"),YQo=o(" (SqueezeBERT model)"),KQo=l(),Yv=a("li"),Rpe=a("strong"),ZQo=o("xlm"),eHo=o(" \u2014 "),vX=a("a"),oHo=o("XLMForQuestionAnsweringSimple"),rHo=o(" (XLM model)"),tHo=l(),Kv=a("li"),Ppe=a("strong"),aHo=o("xlm-roberta"),nHo=o(" \u2014 "),FX=a("a"),sHo=o("XLMRobertaForQuestionAnswering"),lHo=o(" (XLM-RoBERTa model)"),iHo=l(),Zv=a("li"),Bpe=a("strong"),dHo=o("xlm-roberta-xl"),cHo=o(" \u2014 "),TX=a("a"),fHo=o("XLMRobertaXLForQuestionAnswering"),mHo=o(" (XLM-RoBERTa-XL model)"),gHo=l(),e3=a("li"),Ipe=a("strong"),hHo=o("xlnet"),pHo=o(" \u2014 "),MX=a("a"),_Ho=o("XLNetForQuestionAnsweringSimple"),uHo=o(" (XLNet model)"),bHo=l(),o3=a("li"),Npe=a("strong"),vHo=o("yoso"),FHo=o(" \u2014 "),EX=a("a"),THo=o("YosoForQuestionAnswering"),MHo=o(" (YOSO model)"),EHo=l(),r3=a("p"),CHo=o("The model is set in evaluation mode by default using "),qpe=a("code"),wHo=o("model.eval()"),AHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jpe=a("code"),yHo=o("model.train()"),LHo=l(),F(t3.$$.fragment),Hqe=l(),rd=a("h2"),a3=a("a"),Dpe=a("span"),F(Zy.$$.fragment),xHo=l(),Gpe=a("span"),$Ho=o("AutoModelForTableQuestionAnswering"),Uqe=l(),qo=a("div"),F(eL.$$.fragment),kHo=l(),td=a("p"),SHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),CX=a("a"),RHo=o("from_pretrained()"),PHo=o(" class method or the "),wX=a("a"),BHo=o("from_config()"),IHo=o(` class
method.`),NHo=l(),oL=a("p"),qHo=o("This class cannot be instantiated directly using "),Ope=a("code"),jHo=o("__init__()"),DHo=o(" (throws an error)."),GHo=l(),gt=a("div"),F(rL.$$.fragment),OHo=l(),Vpe=a("p"),VHo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),XHo=l(),ad=a("p"),zHo=o(`Note:
Loading a model from its configuration file does `),Xpe=a("strong"),WHo=o("not"),QHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AX=a("a"),HHo=o("from_pretrained()"),UHo=o(" to load the model weights."),JHo=l(),F(n3.$$.fragment),YHo=l(),so=a("div"),F(tL.$$.fragment),KHo=l(),zpe=a("p"),ZHo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),eUo=l(),qa=a("p"),oUo=o("The model class to instantiate is selected based on the "),Wpe=a("code"),rUo=o("model_type"),tUo=o(` property of the config object (either
passed as an argument or loaded from `),Qpe=a("code"),aUo=o("pretrained_model_name_or_path"),nUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hpe=a("code"),sUo=o("pretrained_model_name_or_path"),lUo=o(":"),iUo=l(),Upe=a("ul"),s3=a("li"),Jpe=a("strong"),dUo=o("tapas"),cUo=o(" \u2014 "),yX=a("a"),fUo=o("TapasForQuestionAnswering"),mUo=o(" (TAPAS model)"),gUo=l(),l3=a("p"),hUo=o("The model is set in evaluation mode by default using "),Ype=a("code"),pUo=o("model.eval()"),_Uo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kpe=a("code"),uUo=o("model.train()"),bUo=l(),F(i3.$$.fragment),Jqe=l(),nd=a("h2"),d3=a("a"),Zpe=a("span"),F(aL.$$.fragment),vUo=l(),e_e=a("span"),FUo=o("AutoModelForImageClassification"),Yqe=l(),jo=a("div"),F(nL.$$.fragment),TUo=l(),sd=a("p"),MUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),LX=a("a"),EUo=o("from_pretrained()"),CUo=o(" class method or the "),xX=a("a"),wUo=o("from_config()"),AUo=o(` class
method.`),yUo=l(),sL=a("p"),LUo=o("This class cannot be instantiated directly using "),o_e=a("code"),xUo=o("__init__()"),$Uo=o(" (throws an error)."),kUo=l(),ht=a("div"),F(lL.$$.fragment),SUo=l(),r_e=a("p"),RUo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),PUo=l(),ld=a("p"),BUo=o(`Note:
Loading a model from its configuration file does `),t_e=a("strong"),IUo=o("not"),NUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$X=a("a"),qUo=o("from_pretrained()"),jUo=o(" to load the model weights."),DUo=l(),F(c3.$$.fragment),GUo=l(),lo=a("div"),F(iL.$$.fragment),OUo=l(),a_e=a("p"),VUo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),XUo=l(),ja=a("p"),zUo=o("The model class to instantiate is selected based on the "),n_e=a("code"),WUo=o("model_type"),QUo=o(` property of the config object (either
passed as an argument or loaded from `),s_e=a("code"),HUo=o("pretrained_model_name_or_path"),UUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l_e=a("code"),JUo=o("pretrained_model_name_or_path"),YUo=o(":"),KUo=l(),Fe=a("ul"),f3=a("li"),i_e=a("strong"),ZUo=o("beit"),eJo=o(" \u2014 "),kX=a("a"),oJo=o("BeitForImageClassification"),rJo=o(" (BEiT model)"),tJo=l(),m3=a("li"),d_e=a("strong"),aJo=o("convnext"),nJo=o(" \u2014 "),SX=a("a"),sJo=o("ConvNextForImageClassification"),lJo=o(" (ConvNext model)"),iJo=l(),g3=a("li"),c_e=a("strong"),dJo=o("cvt"),cJo=o(" \u2014 "),RX=a("a"),fJo=o("CvtForImageClassification"),mJo=o(" (CvT model)"),gJo=l(),h3=a("li"),f_e=a("strong"),hJo=o("data2vec-vision"),pJo=o(" \u2014 "),PX=a("a"),_Jo=o("Data2VecVisionForImageClassification"),uJo=o(" (Data2VecVision model)"),bJo=l(),Is=a("li"),m_e=a("strong"),vJo=o("deit"),FJo=o(" \u2014 "),BX=a("a"),TJo=o("DeiTForImageClassification"),MJo=o(" or "),IX=a("a"),EJo=o("DeiTForImageClassificationWithTeacher"),CJo=o(" (DeiT model)"),wJo=l(),p3=a("li"),g_e=a("strong"),AJo=o("imagegpt"),yJo=o(" \u2014 "),NX=a("a"),LJo=o("ImageGPTForImageClassification"),xJo=o(" (ImageGPT model)"),$Jo=l(),pt=a("li"),h_e=a("strong"),kJo=o("perceiver"),SJo=o(" \u2014 "),qX=a("a"),RJo=o("PerceiverForImageClassificationLearned"),PJo=o(" or "),jX=a("a"),BJo=o("PerceiverForImageClassificationFourier"),IJo=o(" or "),DX=a("a"),NJo=o("PerceiverForImageClassificationConvProcessing"),qJo=o(" (Perceiver model)"),jJo=l(),_3=a("li"),p_e=a("strong"),DJo=o("poolformer"),GJo=o(" \u2014 "),GX=a("a"),OJo=o("PoolFormerForImageClassification"),VJo=o(" (PoolFormer model)"),XJo=l(),u3=a("li"),__e=a("strong"),zJo=o("regnet"),WJo=o(" \u2014 "),OX=a("a"),QJo=o("RegNetForImageClassification"),HJo=o(" (RegNet model)"),UJo=l(),b3=a("li"),u_e=a("strong"),JJo=o("resnet"),YJo=o(" \u2014 "),VX=a("a"),KJo=o("ResNetForImageClassification"),ZJo=o(" (ResNet model)"),eYo=l(),v3=a("li"),b_e=a("strong"),oYo=o("segformer"),rYo=o(" \u2014 "),XX=a("a"),tYo=o("SegformerForImageClassification"),aYo=o(" (SegFormer model)"),nYo=l(),F3=a("li"),v_e=a("strong"),sYo=o("swin"),lYo=o(" \u2014 "),zX=a("a"),iYo=o("SwinForImageClassification"),dYo=o(" (Swin model)"),cYo=l(),T3=a("li"),F_e=a("strong"),fYo=o("van"),mYo=o(" \u2014 "),WX=a("a"),gYo=o("VanForImageClassification"),hYo=o(" (VAN model)"),pYo=l(),M3=a("li"),T_e=a("strong"),_Yo=o("vit"),uYo=o(" \u2014 "),QX=a("a"),bYo=o("ViTForImageClassification"),vYo=o(" (ViT model)"),FYo=l(),E3=a("p"),TYo=o("The model is set in evaluation mode by default using "),M_e=a("code"),MYo=o("model.eval()"),EYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E_e=a("code"),CYo=o("model.train()"),wYo=l(),F(C3.$$.fragment),Kqe=l(),id=a("h2"),w3=a("a"),C_e=a("span"),F(dL.$$.fragment),AYo=l(),w_e=a("span"),yYo=o("AutoModelForVision2Seq"),Zqe=l(),Do=a("div"),F(cL.$$.fragment),LYo=l(),dd=a("p"),xYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),HX=a("a"),$Yo=o("from_pretrained()"),kYo=o(" class method or the "),UX=a("a"),SYo=o("from_config()"),RYo=o(` class
method.`),PYo=l(),fL=a("p"),BYo=o("This class cannot be instantiated directly using "),A_e=a("code"),IYo=o("__init__()"),NYo=o(" (throws an error)."),qYo=l(),_t=a("div"),F(mL.$$.fragment),jYo=l(),y_e=a("p"),DYo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),GYo=l(),cd=a("p"),OYo=o(`Note:
Loading a model from its configuration file does `),L_e=a("strong"),VYo=o("not"),XYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=a("a"),zYo=o("from_pretrained()"),WYo=o(" to load the model weights."),QYo=l(),F(A3.$$.fragment),HYo=l(),io=a("div"),F(gL.$$.fragment),UYo=l(),x_e=a("p"),JYo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),YYo=l(),Da=a("p"),KYo=o("The model class to instantiate is selected based on the "),$_e=a("code"),ZYo=o("model_type"),eKo=o(` property of the config object (either
passed as an argument or loaded from `),k_e=a("code"),oKo=o("pretrained_model_name_or_path"),rKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S_e=a("code"),tKo=o("pretrained_model_name_or_path"),aKo=o(":"),nKo=l(),R_e=a("ul"),y3=a("li"),P_e=a("strong"),sKo=o("vision-encoder-decoder"),lKo=o(" \u2014 "),YX=a("a"),iKo=o("VisionEncoderDecoderModel"),dKo=o(" (Vision Encoder decoder model)"),cKo=l(),L3=a("p"),fKo=o("The model is set in evaluation mode by default using "),B_e=a("code"),mKo=o("model.eval()"),gKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I_e=a("code"),hKo=o("model.train()"),pKo=l(),F(x3.$$.fragment),eje=l(),fd=a("h2"),$3=a("a"),N_e=a("span"),F(hL.$$.fragment),_Ko=l(),q_e=a("span"),uKo=o("AutoModelForAudioClassification"),oje=l(),Go=a("div"),F(pL.$$.fragment),bKo=l(),md=a("p"),vKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),KX=a("a"),FKo=o("from_pretrained()"),TKo=o(" class method or the "),ZX=a("a"),MKo=o("from_config()"),EKo=o(` class
method.`),CKo=l(),_L=a("p"),wKo=o("This class cannot be instantiated directly using "),j_e=a("code"),AKo=o("__init__()"),yKo=o(" (throws an error)."),LKo=l(),ut=a("div"),F(uL.$$.fragment),xKo=l(),D_e=a("p"),$Ko=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),kKo=l(),gd=a("p"),SKo=o(`Note:
Loading a model from its configuration file does `),G_e=a("strong"),RKo=o("not"),PKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ez=a("a"),BKo=o("from_pretrained()"),IKo=o(" to load the model weights."),NKo=l(),F(k3.$$.fragment),qKo=l(),co=a("div"),F(bL.$$.fragment),jKo=l(),O_e=a("p"),DKo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),GKo=l(),Ga=a("p"),OKo=o("The model class to instantiate is selected based on the "),V_e=a("code"),VKo=o("model_type"),XKo=o(` property of the config object (either
passed as an argument or loaded from `),X_e=a("code"),zKo=o("pretrained_model_name_or_path"),WKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z_e=a("code"),QKo=o("pretrained_model_name_or_path"),HKo=o(":"),UKo=l(),ke=a("ul"),S3=a("li"),W_e=a("strong"),JKo=o("data2vec-audio"),YKo=o(" \u2014 "),oz=a("a"),KKo=o("Data2VecAudioForSequenceClassification"),ZKo=o(" (Data2VecAudio model)"),eZo=l(),R3=a("li"),Q_e=a("strong"),oZo=o("hubert"),rZo=o(" \u2014 "),rz=a("a"),tZo=o("HubertForSequenceClassification"),aZo=o(" (Hubert model)"),nZo=l(),P3=a("li"),H_e=a("strong"),sZo=o("sew"),lZo=o(" \u2014 "),tz=a("a"),iZo=o("SEWForSequenceClassification"),dZo=o(" (SEW model)"),cZo=l(),B3=a("li"),U_e=a("strong"),fZo=o("sew-d"),mZo=o(" \u2014 "),az=a("a"),gZo=o("SEWDForSequenceClassification"),hZo=o(" (SEW-D model)"),pZo=l(),I3=a("li"),J_e=a("strong"),_Zo=o("unispeech"),uZo=o(" \u2014 "),nz=a("a"),bZo=o("UniSpeechForSequenceClassification"),vZo=o(" (UniSpeech model)"),FZo=l(),N3=a("li"),Y_e=a("strong"),TZo=o("unispeech-sat"),MZo=o(" \u2014 "),sz=a("a"),EZo=o("UniSpeechSatForSequenceClassification"),CZo=o(" (UniSpeechSat model)"),wZo=l(),q3=a("li"),K_e=a("strong"),AZo=o("wav2vec2"),yZo=o(" \u2014 "),lz=a("a"),LZo=o("Wav2Vec2ForSequenceClassification"),xZo=o(" (Wav2Vec2 model)"),$Zo=l(),j3=a("li"),Z_e=a("strong"),kZo=o("wav2vec2-conformer"),SZo=o(" \u2014 "),iz=a("a"),RZo=o("Wav2Vec2ConformerForSequenceClassification"),PZo=o(" (Wav2Vec2-Conformer model)"),BZo=l(),D3=a("li"),eue=a("strong"),IZo=o("wavlm"),NZo=o(" \u2014 "),dz=a("a"),qZo=o("WavLMForSequenceClassification"),jZo=o(" (WavLM model)"),DZo=l(),G3=a("p"),GZo=o("The model is set in evaluation mode by default using "),oue=a("code"),OZo=o("model.eval()"),VZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rue=a("code"),XZo=o("model.train()"),zZo=l(),F(O3.$$.fragment),rje=l(),hd=a("h2"),V3=a("a"),tue=a("span"),F(vL.$$.fragment),WZo=l(),aue=a("span"),QZo=o("AutoModelForAudioFrameClassification"),tje=l(),Oo=a("div"),F(FL.$$.fragment),HZo=l(),pd=a("p"),UZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),cz=a("a"),JZo=o("from_pretrained()"),YZo=o(" class method or the "),fz=a("a"),KZo=o("from_config()"),ZZo=o(` class
method.`),eer=l(),TL=a("p"),oer=o("This class cannot be instantiated directly using "),nue=a("code"),rer=o("__init__()"),ter=o(" (throws an error)."),aer=l(),bt=a("div"),F(ML.$$.fragment),ner=l(),sue=a("p"),ser=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),ler=l(),_d=a("p"),ier=o(`Note:
Loading a model from its configuration file does `),lue=a("strong"),der=o("not"),cer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mz=a("a"),fer=o("from_pretrained()"),mer=o(" to load the model weights."),ger=l(),F(X3.$$.fragment),her=l(),fo=a("div"),F(EL.$$.fragment),per=l(),iue=a("p"),_er=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),uer=l(),Oa=a("p"),ber=o("The model class to instantiate is selected based on the "),due=a("code"),ver=o("model_type"),Fer=o(` property of the config object (either
passed as an argument or loaded from `),cue=a("code"),Ter=o("pretrained_model_name_or_path"),Mer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fue=a("code"),Eer=o("pretrained_model_name_or_path"),Cer=o(":"),wer=l(),Kr=a("ul"),z3=a("li"),mue=a("strong"),Aer=o("data2vec-audio"),yer=o(" \u2014 "),gz=a("a"),Ler=o("Data2VecAudioForAudioFrameClassification"),xer=o(" (Data2VecAudio model)"),$er=l(),W3=a("li"),gue=a("strong"),ker=o("unispeech-sat"),Ser=o(" \u2014 "),hz=a("a"),Rer=o("UniSpeechSatForAudioFrameClassification"),Per=o(" (UniSpeechSat model)"),Ber=l(),Q3=a("li"),hue=a("strong"),Ier=o("wav2vec2"),Ner=o(" \u2014 "),pz=a("a"),qer=o("Wav2Vec2ForAudioFrameClassification"),jer=o(" (Wav2Vec2 model)"),Der=l(),H3=a("li"),pue=a("strong"),Ger=o("wav2vec2-conformer"),Oer=o(" \u2014 "),_z=a("a"),Ver=o("Wav2Vec2ConformerForAudioFrameClassification"),Xer=o(" (Wav2Vec2-Conformer model)"),zer=l(),U3=a("li"),_ue=a("strong"),Wer=o("wavlm"),Qer=o(" \u2014 "),uz=a("a"),Her=o("WavLMForAudioFrameClassification"),Uer=o(" (WavLM model)"),Jer=l(),J3=a("p"),Yer=o("The model is set in evaluation mode by default using "),uue=a("code"),Ker=o("model.eval()"),Zer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bue=a("code"),eor=o("model.train()"),oor=l(),F(Y3.$$.fragment),aje=l(),ud=a("h2"),K3=a("a"),vue=a("span"),F(CL.$$.fragment),ror=l(),Fue=a("span"),tor=o("AutoModelForCTC"),nje=l(),Vo=a("div"),F(wL.$$.fragment),aor=l(),bd=a("p"),nor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),bz=a("a"),sor=o("from_pretrained()"),lor=o(" class method or the "),vz=a("a"),ior=o("from_config()"),dor=o(` class
method.`),cor=l(),AL=a("p"),mor=o("This class cannot be instantiated directly using "),Tue=a("code"),gor=o("__init__()"),hor=o(" (throws an error)."),por=l(),vt=a("div"),F(yL.$$.fragment),_or=l(),Mue=a("p"),uor=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),bor=l(),vd=a("p"),vor=o(`Note:
Loading a model from its configuration file does `),Eue=a("strong"),For=o("not"),Tor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=a("a"),Mor=o("from_pretrained()"),Eor=o(" to load the model weights."),Cor=l(),F(Z3.$$.fragment),wor=l(),mo=a("div"),F(LL.$$.fragment),Aor=l(),Cue=a("p"),yor=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Lor=l(),Va=a("p"),xor=o("The model class to instantiate is selected based on the "),wue=a("code"),$or=o("model_type"),kor=o(` property of the config object (either
passed as an argument or loaded from `),Aue=a("code"),Sor=o("pretrained_model_name_or_path"),Ror=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yue=a("code"),Por=o("pretrained_model_name_or_path"),Bor=o(":"),Ior=l(),Se=a("ul"),eF=a("li"),Lue=a("strong"),Nor=o("data2vec-audio"),qor=o(" \u2014 "),Tz=a("a"),jor=o("Data2VecAudioForCTC"),Dor=o(" (Data2VecAudio model)"),Gor=l(),oF=a("li"),xue=a("strong"),Oor=o("hubert"),Vor=o(" \u2014 "),Mz=a("a"),Xor=o("HubertForCTC"),zor=o(" (Hubert model)"),Wor=l(),rF=a("li"),$ue=a("strong"),Qor=o("sew"),Hor=o(" \u2014 "),Ez=a("a"),Uor=o("SEWForCTC"),Jor=o(" (SEW model)"),Yor=l(),tF=a("li"),kue=a("strong"),Kor=o("sew-d"),Zor=o(" \u2014 "),Cz=a("a"),err=o("SEWDForCTC"),orr=o(" (SEW-D model)"),rrr=l(),aF=a("li"),Sue=a("strong"),trr=o("unispeech"),arr=o(" \u2014 "),wz=a("a"),nrr=o("UniSpeechForCTC"),srr=o(" (UniSpeech model)"),lrr=l(),nF=a("li"),Rue=a("strong"),irr=o("unispeech-sat"),drr=o(" \u2014 "),Az=a("a"),crr=o("UniSpeechSatForCTC"),frr=o(" (UniSpeechSat model)"),mrr=l(),sF=a("li"),Pue=a("strong"),grr=o("wav2vec2"),hrr=o(" \u2014 "),yz=a("a"),prr=o("Wav2Vec2ForCTC"),_rr=o(" (Wav2Vec2 model)"),urr=l(),lF=a("li"),Bue=a("strong"),brr=o("wav2vec2-conformer"),vrr=o(" \u2014 "),Lz=a("a"),Frr=o("Wav2Vec2ConformerForCTC"),Trr=o(" (Wav2Vec2-Conformer model)"),Mrr=l(),iF=a("li"),Iue=a("strong"),Err=o("wavlm"),Crr=o(" \u2014 "),xz=a("a"),wrr=o("WavLMForCTC"),Arr=o(" (WavLM model)"),yrr=l(),dF=a("p"),Lrr=o("The model is set in evaluation mode by default using "),Nue=a("code"),xrr=o("model.eval()"),$rr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),que=a("code"),krr=o("model.train()"),Srr=l(),F(cF.$$.fragment),sje=l(),Fd=a("h2"),fF=a("a"),jue=a("span"),F(xL.$$.fragment),Rrr=l(),Due=a("span"),Prr=o("AutoModelForSpeechSeq2Seq"),lje=l(),Xo=a("div"),F($L.$$.fragment),Brr=l(),Td=a("p"),Irr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$z=a("a"),Nrr=o("from_pretrained()"),qrr=o(" class method or the "),kz=a("a"),jrr=o("from_config()"),Drr=o(` class
method.`),Grr=l(),kL=a("p"),Orr=o("This class cannot be instantiated directly using "),Gue=a("code"),Vrr=o("__init__()"),Xrr=o(" (throws an error)."),zrr=l(),Ft=a("div"),F(SL.$$.fragment),Wrr=l(),Oue=a("p"),Qrr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Hrr=l(),Md=a("p"),Urr=o(`Note:
Loading a model from its configuration file does `),Vue=a("strong"),Jrr=o("not"),Yrr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sz=a("a"),Krr=o("from_pretrained()"),Zrr=o(" to load the model weights."),etr=l(),F(mF.$$.fragment),otr=l(),go=a("div"),F(RL.$$.fragment),rtr=l(),Xue=a("p"),ttr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),atr=l(),Xa=a("p"),ntr=o("The model class to instantiate is selected based on the "),zue=a("code"),str=o("model_type"),ltr=o(` property of the config object (either
passed as an argument or loaded from `),Wue=a("code"),itr=o("pretrained_model_name_or_path"),dtr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Que=a("code"),ctr=o("pretrained_model_name_or_path"),ftr=o(":"),mtr=l(),PL=a("ul"),gF=a("li"),Hue=a("strong"),gtr=o("speech-encoder-decoder"),htr=o(" \u2014 "),Rz=a("a"),ptr=o("SpeechEncoderDecoderModel"),_tr=o(" (Speech Encoder decoder model)"),utr=l(),hF=a("li"),Uue=a("strong"),btr=o("speech_to_text"),vtr=o(" \u2014 "),Pz=a("a"),Ftr=o("Speech2TextForConditionalGeneration"),Ttr=o(" (Speech2Text model)"),Mtr=l(),pF=a("p"),Etr=o("The model is set in evaluation mode by default using "),Jue=a("code"),Ctr=o("model.eval()"),wtr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yue=a("code"),Atr=o("model.train()"),ytr=l(),F(_F.$$.fragment),ije=l(),Ed=a("h2"),uF=a("a"),Kue=a("span"),F(BL.$$.fragment),Ltr=l(),Zue=a("span"),xtr=o("AutoModelForAudioXVector"),dje=l(),zo=a("div"),F(IL.$$.fragment),$tr=l(),Cd=a("p"),ktr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Bz=a("a"),Str=o("from_pretrained()"),Rtr=o(" class method or the "),Iz=a("a"),Ptr=o("from_config()"),Btr=o(` class
method.`),Itr=l(),NL=a("p"),Ntr=o("This class cannot be instantiated directly using "),e4e=a("code"),qtr=o("__init__()"),jtr=o(" (throws an error)."),Dtr=l(),Tt=a("div"),F(qL.$$.fragment),Gtr=l(),o4e=a("p"),Otr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Vtr=l(),wd=a("p"),Xtr=o(`Note:
Loading a model from its configuration file does `),r4e=a("strong"),ztr=o("not"),Wtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nz=a("a"),Qtr=o("from_pretrained()"),Htr=o(" to load the model weights."),Utr=l(),F(bF.$$.fragment),Jtr=l(),ho=a("div"),F(jL.$$.fragment),Ytr=l(),t4e=a("p"),Ktr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Ztr=l(),za=a("p"),ear=o("The model class to instantiate is selected based on the "),a4e=a("code"),oar=o("model_type"),rar=o(` property of the config object (either
passed as an argument or loaded from `),n4e=a("code"),tar=o("pretrained_model_name_or_path"),aar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s4e=a("code"),nar=o("pretrained_model_name_or_path"),sar=o(":"),lar=l(),Zr=a("ul"),vF=a("li"),l4e=a("strong"),iar=o("data2vec-audio"),dar=o(" \u2014 "),qz=a("a"),car=o("Data2VecAudioForXVector"),far=o(" (Data2VecAudio model)"),mar=l(),FF=a("li"),i4e=a("strong"),gar=o("unispeech-sat"),har=o(" \u2014 "),jz=a("a"),par=o("UniSpeechSatForXVector"),_ar=o(" (UniSpeechSat model)"),uar=l(),TF=a("li"),d4e=a("strong"),bar=o("wav2vec2"),Far=o(" \u2014 "),Dz=a("a"),Tar=o("Wav2Vec2ForXVector"),Mar=o(" (Wav2Vec2 model)"),Ear=l(),MF=a("li"),c4e=a("strong"),Car=o("wav2vec2-conformer"),war=o(" \u2014 "),Gz=a("a"),Aar=o("Wav2Vec2ConformerForXVector"),yar=o(" (Wav2Vec2-Conformer model)"),Lar=l(),EF=a("li"),f4e=a("strong"),xar=o("wavlm"),$ar=o(" \u2014 "),Oz=a("a"),kar=o("WavLMForXVector"),Sar=o(" (WavLM model)"),Rar=l(),CF=a("p"),Par=o("The model is set in evaluation mode by default using "),m4e=a("code"),Bar=o("model.eval()"),Iar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g4e=a("code"),Nar=o("model.train()"),qar=l(),F(wF.$$.fragment),cje=l(),Ad=a("h2"),AF=a("a"),h4e=a("span"),F(DL.$$.fragment),jar=l(),p4e=a("span"),Dar=o("AutoModelForMaskedImageModeling"),fje=l(),Wo=a("div"),F(GL.$$.fragment),Gar=l(),yd=a("p"),Oar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Vz=a("a"),Var=o("from_pretrained()"),Xar=o(" class method or the "),Xz=a("a"),zar=o("from_config()"),War=o(` class
method.`),Qar=l(),OL=a("p"),Har=o("This class cannot be instantiated directly using "),_4e=a("code"),Uar=o("__init__()"),Jar=o(" (throws an error)."),Yar=l(),Mt=a("div"),F(VL.$$.fragment),Kar=l(),u4e=a("p"),Zar=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),enr=l(),Ld=a("p"),onr=o(`Note:
Loading a model from its configuration file does `),b4e=a("strong"),rnr=o("not"),tnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zz=a("a"),anr=o("from_pretrained()"),nnr=o(" to load the model weights."),snr=l(),F(yF.$$.fragment),lnr=l(),po=a("div"),F(XL.$$.fragment),inr=l(),v4e=a("p"),dnr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),cnr=l(),Wa=a("p"),fnr=o("The model class to instantiate is selected based on the "),F4e=a("code"),mnr=o("model_type"),gnr=o(` property of the config object (either
passed as an argument or loaded from `),T4e=a("code"),hnr=o("pretrained_model_name_or_path"),pnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M4e=a("code"),_nr=o("pretrained_model_name_or_path"),unr=o(":"),bnr=l(),xd=a("ul"),LF=a("li"),E4e=a("strong"),vnr=o("deit"),Fnr=o(" \u2014 "),Wz=a("a"),Tnr=o("DeiTForMaskedImageModeling"),Mnr=o(" (DeiT model)"),Enr=l(),xF=a("li"),C4e=a("strong"),Cnr=o("swin"),wnr=o(" \u2014 "),Qz=a("a"),Anr=o("SwinForMaskedImageModeling"),ynr=o(" (Swin model)"),Lnr=l(),$F=a("li"),w4e=a("strong"),xnr=o("vit"),$nr=o(" \u2014 "),Hz=a("a"),knr=o("ViTForMaskedImageModeling"),Snr=o(" (ViT model)"),Rnr=l(),kF=a("p"),Pnr=o("The model is set in evaluation mode by default using "),A4e=a("code"),Bnr=o("model.eval()"),Inr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y4e=a("code"),Nnr=o("model.train()"),qnr=l(),F(SF.$$.fragment),mje=l(),$d=a("h2"),RF=a("a"),L4e=a("span"),F(zL.$$.fragment),jnr=l(),x4e=a("span"),Dnr=o("AutoModelForObjectDetection"),gje=l(),Qo=a("div"),F(WL.$$.fragment),Gnr=l(),kd=a("p"),Onr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Uz=a("a"),Vnr=o("from_pretrained()"),Xnr=o(" class method or the "),Jz=a("a"),znr=o("from_config()"),Wnr=o(` class
method.`),Qnr=l(),QL=a("p"),Hnr=o("This class cannot be instantiated directly using "),$4e=a("code"),Unr=o("__init__()"),Jnr=o(" (throws an error)."),Ynr=l(),Et=a("div"),F(HL.$$.fragment),Knr=l(),k4e=a("p"),Znr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),esr=l(),Sd=a("p"),osr=o(`Note:
Loading a model from its configuration file does `),S4e=a("strong"),rsr=o("not"),tsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yz=a("a"),asr=o("from_pretrained()"),nsr=o(" to load the model weights."),ssr=l(),F(PF.$$.fragment),lsr=l(),_o=a("div"),F(UL.$$.fragment),isr=l(),R4e=a("p"),dsr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),csr=l(),Qa=a("p"),fsr=o("The model class to instantiate is selected based on the "),P4e=a("code"),msr=o("model_type"),gsr=o(` property of the config object (either
passed as an argument or loaded from `),B4e=a("code"),hsr=o("pretrained_model_name_or_path"),psr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=a("code"),_sr=o("pretrained_model_name_or_path"),usr=o(":"),bsr=l(),JL=a("ul"),BF=a("li"),N4e=a("strong"),vsr=o("detr"),Fsr=o(" \u2014 "),Kz=a("a"),Tsr=o("DetrForObjectDetection"),Msr=o(" (DETR model)"),Esr=l(),IF=a("li"),q4e=a("strong"),Csr=o("yolos"),wsr=o(" \u2014 "),Zz=a("a"),Asr=o("YolosForObjectDetection"),ysr=o(" (YOLOS model)"),Lsr=l(),NF=a("p"),xsr=o("The model is set in evaluation mode by default using "),j4e=a("code"),$sr=o("model.eval()"),ksr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D4e=a("code"),Ssr=o("model.train()"),Rsr=l(),F(qF.$$.fragment),hje=l(),Rd=a("h2"),jF=a("a"),G4e=a("span"),F(YL.$$.fragment),Psr=l(),O4e=a("span"),Bsr=o("AutoModelForImageSegmentation"),pje=l(),Ho=a("div"),F(KL.$$.fragment),Isr=l(),Pd=a("p"),Nsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),eW=a("a"),qsr=o("from_pretrained()"),jsr=o(" class method or the "),oW=a("a"),Dsr=o("from_config()"),Gsr=o(` class
method.`),Osr=l(),ZL=a("p"),Vsr=o("This class cannot be instantiated directly using "),V4e=a("code"),Xsr=o("__init__()"),zsr=o(" (throws an error)."),Wsr=l(),Ct=a("div"),F(e8.$$.fragment),Qsr=l(),X4e=a("p"),Hsr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Usr=l(),Bd=a("p"),Jsr=o(`Note:
Loading a model from its configuration file does `),z4e=a("strong"),Ysr=o("not"),Ksr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=a("a"),Zsr=o("from_pretrained()"),elr=o(" to load the model weights."),olr=l(),F(DF.$$.fragment),rlr=l(),uo=a("div"),F(o8.$$.fragment),tlr=l(),W4e=a("p"),alr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),nlr=l(),Ha=a("p"),slr=o("The model class to instantiate is selected based on the "),Q4e=a("code"),llr=o("model_type"),ilr=o(` property of the config object (either
passed as an argument or loaded from `),H4e=a("code"),dlr=o("pretrained_model_name_or_path"),clr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U4e=a("code"),flr=o("pretrained_model_name_or_path"),mlr=o(":"),glr=l(),J4e=a("ul"),GF=a("li"),Y4e=a("strong"),hlr=o("detr"),plr=o(" \u2014 "),tW=a("a"),_lr=o("DetrForSegmentation"),ulr=o(" (DETR model)"),blr=l(),OF=a("p"),vlr=o("The model is set in evaluation mode by default using "),K4e=a("code"),Flr=o("model.eval()"),Tlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z4e=a("code"),Mlr=o("model.train()"),Elr=l(),F(VF.$$.fragment),_je=l(),Id=a("h2"),XF=a("a"),e1e=a("span"),F(r8.$$.fragment),Clr=l(),o1e=a("span"),wlr=o("AutoModelForSemanticSegmentation"),uje=l(),Uo=a("div"),F(t8.$$.fragment),Alr=l(),Nd=a("p"),ylr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),aW=a("a"),Llr=o("from_pretrained()"),xlr=o(" class method or the "),nW=a("a"),$lr=o("from_config()"),klr=o(` class
method.`),Slr=l(),a8=a("p"),Rlr=o("This class cannot be instantiated directly using "),r1e=a("code"),Plr=o("__init__()"),Blr=o(" (throws an error)."),Ilr=l(),wt=a("div"),F(n8.$$.fragment),Nlr=l(),t1e=a("p"),qlr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),jlr=l(),qd=a("p"),Dlr=o(`Note:
Loading a model from its configuration file does `),a1e=a("strong"),Glr=o("not"),Olr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=a("a"),Vlr=o("from_pretrained()"),Xlr=o(" to load the model weights."),zlr=l(),F(zF.$$.fragment),Wlr=l(),bo=a("div"),F(s8.$$.fragment),Qlr=l(),n1e=a("p"),Hlr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Ulr=l(),Ua=a("p"),Jlr=o("The model class to instantiate is selected based on the "),s1e=a("code"),Ylr=o("model_type"),Klr=o(` property of the config object (either
passed as an argument or loaded from `),l1e=a("code"),Zlr=o("pretrained_model_name_or_path"),eir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i1e=a("code"),oir=o("pretrained_model_name_or_path"),rir=o(":"),tir=l(),Ja=a("ul"),WF=a("li"),d1e=a("strong"),air=o("beit"),nir=o(" \u2014 "),lW=a("a"),sir=o("BeitForSemanticSegmentation"),lir=o(" (BEiT model)"),iir=l(),QF=a("li"),c1e=a("strong"),dir=o("data2vec-vision"),cir=o(" \u2014 "),iW=a("a"),fir=o("Data2VecVisionForSemanticSegmentation"),mir=o(" (Data2VecVision model)"),gir=l(),HF=a("li"),f1e=a("strong"),hir=o("dpt"),pir=o(" \u2014 "),dW=a("a"),_ir=o("DPTForSemanticSegmentation"),uir=o(" (DPT model)"),bir=l(),UF=a("li"),m1e=a("strong"),vir=o("segformer"),Fir=o(" \u2014 "),cW=a("a"),Tir=o("SegformerForSemanticSegmentation"),Mir=o(" (SegFormer model)"),Eir=l(),JF=a("p"),Cir=o("The model is set in evaluation mode by default using "),g1e=a("code"),wir=o("model.eval()"),Air=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h1e=a("code"),yir=o("model.train()"),Lir=l(),F(YF.$$.fragment),bje=l(),jd=a("h2"),KF=a("a"),p1e=a("span"),F(l8.$$.fragment),xir=l(),_1e=a("span"),$ir=o("AutoModelForInstanceSegmentation"),vje=l(),Jo=a("div"),F(i8.$$.fragment),kir=l(),Dd=a("p"),Sir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),fW=a("a"),Rir=o("from_pretrained()"),Pir=o(" class method or the "),mW=a("a"),Bir=o("from_config()"),Iir=o(` class
method.`),Nir=l(),d8=a("p"),qir=o("This class cannot be instantiated directly using "),u1e=a("code"),jir=o("__init__()"),Dir=o(" (throws an error)."),Gir=l(),At=a("div"),F(c8.$$.fragment),Oir=l(),b1e=a("p"),Vir=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Xir=l(),Gd=a("p"),zir=o(`Note:
Loading a model from its configuration file does `),v1e=a("strong"),Wir=o("not"),Qir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gW=a("a"),Hir=o("from_pretrained()"),Uir=o(" to load the model weights."),Jir=l(),F(ZF.$$.fragment),Yir=l(),vo=a("div"),F(f8.$$.fragment),Kir=l(),F1e=a("p"),Zir=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),edr=l(),Ya=a("p"),odr=o("The model class to instantiate is selected based on the "),T1e=a("code"),rdr=o("model_type"),tdr=o(` property of the config object (either
passed as an argument or loaded from `),M1e=a("code"),adr=o("pretrained_model_name_or_path"),ndr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E1e=a("code"),sdr=o("pretrained_model_name_or_path"),ldr=o(":"),idr=l(),C1e=a("ul"),eT=a("li"),w1e=a("strong"),ddr=o("maskformer"),cdr=o(" \u2014 "),hW=a("a"),fdr=o("MaskFormerForInstanceSegmentation"),mdr=o(" (MaskFormer model)"),gdr=l(),oT=a("p"),hdr=o("The model is set in evaluation mode by default using "),A1e=a("code"),pdr=o("model.eval()"),_dr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y1e=a("code"),udr=o("model.train()"),bdr=l(),F(rT.$$.fragment),Fje=l(),Od=a("h2"),tT=a("a"),L1e=a("span"),F(m8.$$.fragment),vdr=l(),x1e=a("span"),Fdr=o("TFAutoModel"),Tje=l(),Yo=a("div"),F(g8.$$.fragment),Tdr=l(),Vd=a("p"),Mdr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),pW=a("a"),Edr=o("from_pretrained()"),Cdr=o(" class method or the "),_W=a("a"),wdr=o("from_config()"),Adr=o(` class
method.`),ydr=l(),h8=a("p"),Ldr=o("This class cannot be instantiated directly using "),$1e=a("code"),xdr=o("__init__()"),$dr=o(" (throws an error)."),kdr=l(),yt=a("div"),F(p8.$$.fragment),Sdr=l(),k1e=a("p"),Rdr=o("Instantiates one of the base model classes of the library from a configuration."),Pdr=l(),Xd=a("p"),Bdr=o(`Note:
Loading a model from its configuration file does `),S1e=a("strong"),Idr=o("not"),Ndr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uW=a("a"),qdr=o("from_pretrained()"),jdr=o(" to load the model weights."),Ddr=l(),F(aT.$$.fragment),Gdr=l(),wr=a("div"),F(_8.$$.fragment),Odr=l(),R1e=a("p"),Vdr=o("Instantiate one of the base model classes of the library from a pretrained model."),Xdr=l(),Ka=a("p"),zdr=o("The model class to instantiate is selected based on the "),P1e=a("code"),Wdr=o("model_type"),Qdr=o(` property of the config object (either
passed as an argument or loaded from `),B1e=a("code"),Hdr=o("pretrained_model_name_or_path"),Udr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=a("code"),Jdr=o("pretrained_model_name_or_path"),Ydr=o(":"),Kdr=l(),q=a("ul"),nT=a("li"),N1e=a("strong"),Zdr=o("albert"),ecr=o(" \u2014 "),bW=a("a"),ocr=o("TFAlbertModel"),rcr=o(" (ALBERT model)"),tcr=l(),sT=a("li"),q1e=a("strong"),acr=o("bart"),ncr=o(" \u2014 "),vW=a("a"),scr=o("TFBartModel"),lcr=o(" (BART model)"),icr=l(),lT=a("li"),j1e=a("strong"),dcr=o("bert"),ccr=o(" \u2014 "),FW=a("a"),fcr=o("TFBertModel"),mcr=o(" (BERT model)"),gcr=l(),iT=a("li"),D1e=a("strong"),hcr=o("blenderbot"),pcr=o(" \u2014 "),TW=a("a"),_cr=o("TFBlenderbotModel"),ucr=o(" (Blenderbot model)"),bcr=l(),dT=a("li"),G1e=a("strong"),vcr=o("blenderbot-small"),Fcr=o(" \u2014 "),MW=a("a"),Tcr=o("TFBlenderbotSmallModel"),Mcr=o(" (BlenderbotSmall model)"),Ecr=l(),cT=a("li"),O1e=a("strong"),Ccr=o("camembert"),wcr=o(" \u2014 "),EW=a("a"),Acr=o("TFCamembertModel"),ycr=o(" (CamemBERT model)"),Lcr=l(),fT=a("li"),V1e=a("strong"),xcr=o("clip"),$cr=o(" \u2014 "),CW=a("a"),kcr=o("TFCLIPModel"),Scr=o(" (CLIP model)"),Rcr=l(),mT=a("li"),X1e=a("strong"),Pcr=o("convbert"),Bcr=o(" \u2014 "),wW=a("a"),Icr=o("TFConvBertModel"),Ncr=o(" (ConvBERT model)"),qcr=l(),gT=a("li"),z1e=a("strong"),jcr=o("convnext"),Dcr=o(" \u2014 "),AW=a("a"),Gcr=o("TFConvNextModel"),Ocr=o(" (ConvNext model)"),Vcr=l(),hT=a("li"),W1e=a("strong"),Xcr=o("ctrl"),zcr=o(" \u2014 "),yW=a("a"),Wcr=o("TFCTRLModel"),Qcr=o(" (CTRL model)"),Hcr=l(),pT=a("li"),Q1e=a("strong"),Ucr=o("data2vec-vision"),Jcr=o(" \u2014 "),LW=a("a"),Ycr=o("TFData2VecVisionModel"),Kcr=o(" (Data2VecVision model)"),Zcr=l(),_T=a("li"),H1e=a("strong"),efr=o("deberta"),ofr=o(" \u2014 "),xW=a("a"),rfr=o("TFDebertaModel"),tfr=o(" (DeBERTa model)"),afr=l(),uT=a("li"),U1e=a("strong"),nfr=o("deberta-v2"),sfr=o(" \u2014 "),$W=a("a"),lfr=o("TFDebertaV2Model"),ifr=o(" (DeBERTa-v2 model)"),dfr=l(),bT=a("li"),J1e=a("strong"),cfr=o("distilbert"),ffr=o(" \u2014 "),kW=a("a"),mfr=o("TFDistilBertModel"),gfr=o(" (DistilBERT model)"),hfr=l(),vT=a("li"),Y1e=a("strong"),pfr=o("dpr"),_fr=o(" \u2014 "),SW=a("a"),ufr=o("TFDPRQuestionEncoder"),bfr=o(" (DPR model)"),vfr=l(),FT=a("li"),K1e=a("strong"),Ffr=o("electra"),Tfr=o(" \u2014 "),RW=a("a"),Mfr=o("TFElectraModel"),Efr=o(" (ELECTRA model)"),Cfr=l(),TT=a("li"),Z1e=a("strong"),wfr=o("flaubert"),Afr=o(" \u2014 "),PW=a("a"),yfr=o("TFFlaubertModel"),Lfr=o(" (FlauBERT model)"),xfr=l(),Ns=a("li"),ebe=a("strong"),$fr=o("funnel"),kfr=o(" \u2014 "),BW=a("a"),Sfr=o("TFFunnelModel"),Rfr=o(" or "),IW=a("a"),Pfr=o("TFFunnelBaseModel"),Bfr=o(" (Funnel Transformer model)"),Ifr=l(),MT=a("li"),obe=a("strong"),Nfr=o("gpt2"),qfr=o(" \u2014 "),NW=a("a"),jfr=o("TFGPT2Model"),Dfr=o(" (OpenAI GPT-2 model)"),Gfr=l(),ET=a("li"),rbe=a("strong"),Ofr=o("gptj"),Vfr=o(" \u2014 "),qW=a("a"),Xfr=o("TFGPTJModel"),zfr=o(" (GPT-J model)"),Wfr=l(),CT=a("li"),tbe=a("strong"),Qfr=o("hubert"),Hfr=o(" \u2014 "),jW=a("a"),Ufr=o("TFHubertModel"),Jfr=o(" (Hubert model)"),Yfr=l(),wT=a("li"),abe=a("strong"),Kfr=o("layoutlm"),Zfr=o(" \u2014 "),DW=a("a"),emr=o("TFLayoutLMModel"),omr=o(" (LayoutLM model)"),rmr=l(),AT=a("li"),nbe=a("strong"),tmr=o("led"),amr=o(" \u2014 "),GW=a("a"),nmr=o("TFLEDModel"),smr=o(" (LED model)"),lmr=l(),yT=a("li"),sbe=a("strong"),imr=o("longformer"),dmr=o(" \u2014 "),OW=a("a"),cmr=o("TFLongformerModel"),fmr=o(" (Longformer model)"),mmr=l(),LT=a("li"),lbe=a("strong"),gmr=o("lxmert"),hmr=o(" \u2014 "),VW=a("a"),pmr=o("TFLxmertModel"),_mr=o(" (LXMERT model)"),umr=l(),xT=a("li"),ibe=a("strong"),bmr=o("marian"),vmr=o(" \u2014 "),XW=a("a"),Fmr=o("TFMarianModel"),Tmr=o(" (Marian model)"),Mmr=l(),$T=a("li"),dbe=a("strong"),Emr=o("mbart"),Cmr=o(" \u2014 "),zW=a("a"),wmr=o("TFMBartModel"),Amr=o(" (mBART model)"),ymr=l(),kT=a("li"),cbe=a("strong"),Lmr=o("mobilebert"),xmr=o(" \u2014 "),WW=a("a"),$mr=o("TFMobileBertModel"),kmr=o(" (MobileBERT model)"),Smr=l(),ST=a("li"),fbe=a("strong"),Rmr=o("mpnet"),Pmr=o(" \u2014 "),QW=a("a"),Bmr=o("TFMPNetModel"),Imr=o(" (MPNet model)"),Nmr=l(),RT=a("li"),mbe=a("strong"),qmr=o("mt5"),jmr=o(" \u2014 "),HW=a("a"),Dmr=o("TFMT5Model"),Gmr=o(" (mT5 model)"),Omr=l(),PT=a("li"),gbe=a("strong"),Vmr=o("openai-gpt"),Xmr=o(" \u2014 "),UW=a("a"),zmr=o("TFOpenAIGPTModel"),Wmr=o(" (OpenAI GPT model)"),Qmr=l(),BT=a("li"),hbe=a("strong"),Hmr=o("pegasus"),Umr=o(" \u2014 "),JW=a("a"),Jmr=o("TFPegasusModel"),Ymr=o(" (Pegasus model)"),Kmr=l(),IT=a("li"),pbe=a("strong"),Zmr=o("rembert"),egr=o(" \u2014 "),YW=a("a"),ogr=o("TFRemBertModel"),rgr=o(" (RemBERT model)"),tgr=l(),NT=a("li"),_be=a("strong"),agr=o("roberta"),ngr=o(" \u2014 "),KW=a("a"),sgr=o("TFRobertaModel"),lgr=o(" (RoBERTa model)"),igr=l(),qT=a("li"),ube=a("strong"),dgr=o("roformer"),cgr=o(" \u2014 "),ZW=a("a"),fgr=o("TFRoFormerModel"),mgr=o(" (RoFormer model)"),ggr=l(),jT=a("li"),bbe=a("strong"),hgr=o("speech_to_text"),pgr=o(" \u2014 "),eQ=a("a"),_gr=o("TFSpeech2TextModel"),ugr=o(" (Speech2Text model)"),bgr=l(),DT=a("li"),vbe=a("strong"),vgr=o("swin"),Fgr=o(" \u2014 "),oQ=a("a"),Tgr=o("TFSwinModel"),Mgr=o(" (Swin model)"),Egr=l(),GT=a("li"),Fbe=a("strong"),Cgr=o("t5"),wgr=o(" \u2014 "),rQ=a("a"),Agr=o("TFT5Model"),ygr=o(" (T5 model)"),Lgr=l(),OT=a("li"),Tbe=a("strong"),xgr=o("tapas"),$gr=o(" \u2014 "),tQ=a("a"),kgr=o("TFTapasModel"),Sgr=o(" (TAPAS model)"),Rgr=l(),VT=a("li"),Mbe=a("strong"),Pgr=o("transfo-xl"),Bgr=o(" \u2014 "),aQ=a("a"),Igr=o("TFTransfoXLModel"),Ngr=o(" (Transformer-XL model)"),qgr=l(),XT=a("li"),Ebe=a("strong"),jgr=o("vit"),Dgr=o(" \u2014 "),nQ=a("a"),Ggr=o("TFViTModel"),Ogr=o(" (ViT model)"),Vgr=l(),zT=a("li"),Cbe=a("strong"),Xgr=o("vit_mae"),zgr=o(" \u2014 "),sQ=a("a"),Wgr=o("TFViTMAEModel"),Qgr=o(" (ViTMAE model)"),Hgr=l(),WT=a("li"),wbe=a("strong"),Ugr=o("wav2vec2"),Jgr=o(" \u2014 "),lQ=a("a"),Ygr=o("TFWav2Vec2Model"),Kgr=o(" (Wav2Vec2 model)"),Zgr=l(),QT=a("li"),Abe=a("strong"),ehr=o("xlm"),ohr=o(" \u2014 "),iQ=a("a"),rhr=o("TFXLMModel"),thr=o(" (XLM model)"),ahr=l(),HT=a("li"),ybe=a("strong"),nhr=o("xlm-roberta"),shr=o(" \u2014 "),dQ=a("a"),lhr=o("TFXLMRobertaModel"),ihr=o(" (XLM-RoBERTa model)"),dhr=l(),UT=a("li"),Lbe=a("strong"),chr=o("xlnet"),fhr=o(" \u2014 "),cQ=a("a"),mhr=o("TFXLNetModel"),ghr=o(" (XLNet model)"),hhr=l(),F(JT.$$.fragment),Mje=l(),zd=a("h2"),YT=a("a"),xbe=a("span"),F(u8.$$.fragment),phr=l(),$be=a("span"),_hr=o("TFAutoModelForPreTraining"),Eje=l(),Ko=a("div"),F(b8.$$.fragment),uhr=l(),Wd=a("p"),bhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),fQ=a("a"),vhr=o("from_pretrained()"),Fhr=o(" class method or the "),mQ=a("a"),Thr=o("from_config()"),Mhr=o(` class
method.`),Ehr=l(),v8=a("p"),Chr=o("This class cannot be instantiated directly using "),kbe=a("code"),whr=o("__init__()"),Ahr=o(" (throws an error)."),yhr=l(),Lt=a("div"),F(F8.$$.fragment),Lhr=l(),Sbe=a("p"),xhr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$hr=l(),Qd=a("p"),khr=o(`Note:
Loading a model from its configuration file does `),Rbe=a("strong"),Shr=o("not"),Rhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gQ=a("a"),Phr=o("from_pretrained()"),Bhr=o(" to load the model weights."),Ihr=l(),F(KT.$$.fragment),Nhr=l(),Ar=a("div"),F(T8.$$.fragment),qhr=l(),Pbe=a("p"),jhr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Dhr=l(),Za=a("p"),Ghr=o("The model class to instantiate is selected based on the "),Bbe=a("code"),Ohr=o("model_type"),Vhr=o(` property of the config object (either
passed as an argument or loaded from `),Ibe=a("code"),Xhr=o("pretrained_model_name_or_path"),zhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nbe=a("code"),Whr=o("pretrained_model_name_or_path"),Qhr=o(":"),Hhr=l(),se=a("ul"),ZT=a("li"),qbe=a("strong"),Uhr=o("albert"),Jhr=o(" \u2014 "),hQ=a("a"),Yhr=o("TFAlbertForPreTraining"),Khr=o(" (ALBERT model)"),Zhr=l(),e7=a("li"),jbe=a("strong"),epr=o("bart"),opr=o(" \u2014 "),pQ=a("a"),rpr=o("TFBartForConditionalGeneration"),tpr=o(" (BART model)"),apr=l(),o7=a("li"),Dbe=a("strong"),npr=o("bert"),spr=o(" \u2014 "),_Q=a("a"),lpr=o("TFBertForPreTraining"),ipr=o(" (BERT model)"),dpr=l(),r7=a("li"),Gbe=a("strong"),cpr=o("camembert"),fpr=o(" \u2014 "),uQ=a("a"),mpr=o("TFCamembertForMaskedLM"),gpr=o(" (CamemBERT model)"),hpr=l(),t7=a("li"),Obe=a("strong"),ppr=o("ctrl"),_pr=o(" \u2014 "),bQ=a("a"),upr=o("TFCTRLLMHeadModel"),bpr=o(" (CTRL model)"),vpr=l(),a7=a("li"),Vbe=a("strong"),Fpr=o("distilbert"),Tpr=o(" \u2014 "),vQ=a("a"),Mpr=o("TFDistilBertForMaskedLM"),Epr=o(" (DistilBERT model)"),Cpr=l(),n7=a("li"),Xbe=a("strong"),wpr=o("electra"),Apr=o(" \u2014 "),FQ=a("a"),ypr=o("TFElectraForPreTraining"),Lpr=o(" (ELECTRA model)"),xpr=l(),s7=a("li"),zbe=a("strong"),$pr=o("flaubert"),kpr=o(" \u2014 "),TQ=a("a"),Spr=o("TFFlaubertWithLMHeadModel"),Rpr=o(" (FlauBERT model)"),Ppr=l(),l7=a("li"),Wbe=a("strong"),Bpr=o("funnel"),Ipr=o(" \u2014 "),MQ=a("a"),Npr=o("TFFunnelForPreTraining"),qpr=o(" (Funnel Transformer model)"),jpr=l(),i7=a("li"),Qbe=a("strong"),Dpr=o("gpt2"),Gpr=o(" \u2014 "),EQ=a("a"),Opr=o("TFGPT2LMHeadModel"),Vpr=o(" (OpenAI GPT-2 model)"),Xpr=l(),d7=a("li"),Hbe=a("strong"),zpr=o("layoutlm"),Wpr=o(" \u2014 "),CQ=a("a"),Qpr=o("TFLayoutLMForMaskedLM"),Hpr=o(" (LayoutLM model)"),Upr=l(),c7=a("li"),Ube=a("strong"),Jpr=o("lxmert"),Ypr=o(" \u2014 "),wQ=a("a"),Kpr=o("TFLxmertForPreTraining"),Zpr=o(" (LXMERT model)"),e_r=l(),f7=a("li"),Jbe=a("strong"),o_r=o("mobilebert"),r_r=o(" \u2014 "),AQ=a("a"),t_r=o("TFMobileBertForPreTraining"),a_r=o(" (MobileBERT model)"),n_r=l(),m7=a("li"),Ybe=a("strong"),s_r=o("mpnet"),l_r=o(" \u2014 "),yQ=a("a"),i_r=o("TFMPNetForMaskedLM"),d_r=o(" (MPNet model)"),c_r=l(),g7=a("li"),Kbe=a("strong"),f_r=o("openai-gpt"),m_r=o(" \u2014 "),LQ=a("a"),g_r=o("TFOpenAIGPTLMHeadModel"),h_r=o(" (OpenAI GPT model)"),p_r=l(),h7=a("li"),Zbe=a("strong"),__r=o("roberta"),u_r=o(" \u2014 "),xQ=a("a"),b_r=o("TFRobertaForMaskedLM"),v_r=o(" (RoBERTa model)"),F_r=l(),p7=a("li"),e2e=a("strong"),T_r=o("t5"),M_r=o(" \u2014 "),$Q=a("a"),E_r=o("TFT5ForConditionalGeneration"),C_r=o(" (T5 model)"),w_r=l(),_7=a("li"),o2e=a("strong"),A_r=o("tapas"),y_r=o(" \u2014 "),kQ=a("a"),L_r=o("TFTapasForMaskedLM"),x_r=o(" (TAPAS model)"),$_r=l(),u7=a("li"),r2e=a("strong"),k_r=o("transfo-xl"),S_r=o(" \u2014 "),SQ=a("a"),R_r=o("TFTransfoXLLMHeadModel"),P_r=o(" (Transformer-XL model)"),B_r=l(),b7=a("li"),t2e=a("strong"),I_r=o("vit_mae"),N_r=o(" \u2014 "),RQ=a("a"),q_r=o("TFViTMAEForPreTraining"),j_r=o(" (ViTMAE model)"),D_r=l(),v7=a("li"),a2e=a("strong"),G_r=o("xlm"),O_r=o(" \u2014 "),PQ=a("a"),V_r=o("TFXLMWithLMHeadModel"),X_r=o(" (XLM model)"),z_r=l(),F7=a("li"),n2e=a("strong"),W_r=o("xlm-roberta"),Q_r=o(" \u2014 "),BQ=a("a"),H_r=o("TFXLMRobertaForMaskedLM"),U_r=o(" (XLM-RoBERTa model)"),J_r=l(),T7=a("li"),s2e=a("strong"),Y_r=o("xlnet"),K_r=o(" \u2014 "),IQ=a("a"),Z_r=o("TFXLNetLMHeadModel"),eur=o(" (XLNet model)"),our=l(),F(M7.$$.fragment),Cje=l(),Hd=a("h2"),E7=a("a"),l2e=a("span"),F(M8.$$.fragment),rur=l(),i2e=a("span"),tur=o("TFAutoModelForCausalLM"),wje=l(),Zo=a("div"),F(E8.$$.fragment),aur=l(),Ud=a("p"),nur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),NQ=a("a"),sur=o("from_pretrained()"),lur=o(" class method or the "),qQ=a("a"),iur=o("from_config()"),dur=o(` class
method.`),cur=l(),C8=a("p"),fur=o("This class cannot be instantiated directly using "),d2e=a("code"),mur=o("__init__()"),gur=o(" (throws an error)."),hur=l(),xt=a("div"),F(w8.$$.fragment),pur=l(),c2e=a("p"),_ur=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),uur=l(),Jd=a("p"),bur=o(`Note:
Loading a model from its configuration file does `),f2e=a("strong"),vur=o("not"),Fur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jQ=a("a"),Tur=o("from_pretrained()"),Mur=o(" to load the model weights."),Eur=l(),F(C7.$$.fragment),Cur=l(),yr=a("div"),F(A8.$$.fragment),wur=l(),m2e=a("p"),Aur=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),yur=l(),en=a("p"),Lur=o("The model class to instantiate is selected based on the "),g2e=a("code"),xur=o("model_type"),$ur=o(` property of the config object (either
passed as an argument or loaded from `),h2e=a("code"),kur=o("pretrained_model_name_or_path"),Sur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p2e=a("code"),Rur=o("pretrained_model_name_or_path"),Pur=o(":"),Bur=l(),Me=a("ul"),w7=a("li"),_2e=a("strong"),Iur=o("bert"),Nur=o(" \u2014 "),DQ=a("a"),qur=o("TFBertLMHeadModel"),jur=o(" (BERT model)"),Dur=l(),A7=a("li"),u2e=a("strong"),Gur=o("camembert"),Our=o(" \u2014 "),GQ=a("a"),Vur=o("TFCamembertForCausalLM"),Xur=o(" (CamemBERT model)"),zur=l(),y7=a("li"),b2e=a("strong"),Wur=o("ctrl"),Qur=o(" \u2014 "),OQ=a("a"),Hur=o("TFCTRLLMHeadModel"),Uur=o(" (CTRL model)"),Jur=l(),L7=a("li"),v2e=a("strong"),Yur=o("gpt2"),Kur=o(" \u2014 "),VQ=a("a"),Zur=o("TFGPT2LMHeadModel"),e4r=o(" (OpenAI GPT-2 model)"),o4r=l(),x7=a("li"),F2e=a("strong"),r4r=o("gptj"),t4r=o(" \u2014 "),XQ=a("a"),a4r=o("TFGPTJForCausalLM"),n4r=o(" (GPT-J model)"),s4r=l(),$7=a("li"),T2e=a("strong"),l4r=o("openai-gpt"),i4r=o(" \u2014 "),zQ=a("a"),d4r=o("TFOpenAIGPTLMHeadModel"),c4r=o(" (OpenAI GPT model)"),f4r=l(),k7=a("li"),M2e=a("strong"),m4r=o("rembert"),g4r=o(" \u2014 "),WQ=a("a"),h4r=o("TFRemBertForCausalLM"),p4r=o(" (RemBERT model)"),_4r=l(),S7=a("li"),E2e=a("strong"),u4r=o("roberta"),b4r=o(" \u2014 "),QQ=a("a"),v4r=o("TFRobertaForCausalLM"),F4r=o(" (RoBERTa model)"),T4r=l(),R7=a("li"),C2e=a("strong"),M4r=o("roformer"),E4r=o(" \u2014 "),HQ=a("a"),C4r=o("TFRoFormerForCausalLM"),w4r=o(" (RoFormer model)"),A4r=l(),P7=a("li"),w2e=a("strong"),y4r=o("transfo-xl"),L4r=o(" \u2014 "),UQ=a("a"),x4r=o("TFTransfoXLLMHeadModel"),$4r=o(" (Transformer-XL model)"),k4r=l(),B7=a("li"),A2e=a("strong"),S4r=o("xlm"),R4r=o(" \u2014 "),JQ=a("a"),P4r=o("TFXLMWithLMHeadModel"),B4r=o(" (XLM model)"),I4r=l(),I7=a("li"),y2e=a("strong"),N4r=o("xlnet"),q4r=o(" \u2014 "),YQ=a("a"),j4r=o("TFXLNetLMHeadModel"),D4r=o(" (XLNet model)"),G4r=l(),F(N7.$$.fragment),Aje=l(),Yd=a("h2"),q7=a("a"),L2e=a("span"),F(y8.$$.fragment),O4r=l(),x2e=a("span"),V4r=o("TFAutoModelForImageClassification"),yje=l(),er=a("div"),F(L8.$$.fragment),X4r=l(),Kd=a("p"),z4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),KQ=a("a"),W4r=o("from_pretrained()"),Q4r=o(" class method or the "),ZQ=a("a"),H4r=o("from_config()"),U4r=o(` class
method.`),J4r=l(),x8=a("p"),Y4r=o("This class cannot be instantiated directly using "),$2e=a("code"),K4r=o("__init__()"),Z4r=o(" (throws an error)."),e1r=l(),$t=a("div"),F($8.$$.fragment),o1r=l(),k2e=a("p"),r1r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),t1r=l(),Zd=a("p"),a1r=o(`Note:
Loading a model from its configuration file does `),S2e=a("strong"),n1r=o("not"),s1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=a("a"),l1r=o("from_pretrained()"),i1r=o(" to load the model weights."),d1r=l(),F(j7.$$.fragment),c1r=l(),Lr=a("div"),F(k8.$$.fragment),f1r=l(),R2e=a("p"),m1r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),g1r=l(),on=a("p"),h1r=o("The model class to instantiate is selected based on the "),P2e=a("code"),p1r=o("model_type"),_1r=o(` property of the config object (either
passed as an argument or loaded from `),B2e=a("code"),u1r=o("pretrained_model_name_or_path"),b1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=a("code"),v1r=o("pretrained_model_name_or_path"),F1r=o(":"),T1r=l(),rn=a("ul"),D7=a("li"),N2e=a("strong"),M1r=o("convnext"),E1r=o(" \u2014 "),oH=a("a"),C1r=o("TFConvNextForImageClassification"),w1r=o(" (ConvNext model)"),A1r=l(),G7=a("li"),q2e=a("strong"),y1r=o("data2vec-vision"),L1r=o(" \u2014 "),rH=a("a"),x1r=o("TFData2VecVisionForImageClassification"),$1r=o(" (Data2VecVision model)"),k1r=l(),O7=a("li"),j2e=a("strong"),S1r=o("swin"),R1r=o(" \u2014 "),tH=a("a"),P1r=o("TFSwinForImageClassification"),B1r=o(" (Swin model)"),I1r=l(),V7=a("li"),D2e=a("strong"),N1r=o("vit"),q1r=o(" \u2014 "),aH=a("a"),j1r=o("TFViTForImageClassification"),D1r=o(" (ViT model)"),G1r=l(),F(X7.$$.fragment),Lje=l(),ec=a("h2"),z7=a("a"),G2e=a("span"),F(S8.$$.fragment),O1r=l(),O2e=a("span"),V1r=o("TFAutoModelForMaskedLM"),xje=l(),or=a("div"),F(R8.$$.fragment),X1r=l(),oc=a("p"),z1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),nH=a("a"),W1r=o("from_pretrained()"),Q1r=o(" class method or the "),sH=a("a"),H1r=o("from_config()"),U1r=o(` class
method.`),J1r=l(),P8=a("p"),Y1r=o("This class cannot be instantiated directly using "),V2e=a("code"),K1r=o("__init__()"),Z1r=o(" (throws an error)."),ebr=l(),kt=a("div"),F(B8.$$.fragment),obr=l(),X2e=a("p"),rbr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),tbr=l(),rc=a("p"),abr=o(`Note:
Loading a model from its configuration file does `),z2e=a("strong"),nbr=o("not"),sbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lH=a("a"),lbr=o("from_pretrained()"),ibr=o(" to load the model weights."),dbr=l(),F(W7.$$.fragment),cbr=l(),xr=a("div"),F(I8.$$.fragment),fbr=l(),W2e=a("p"),mbr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),gbr=l(),tn=a("p"),hbr=o("The model class to instantiate is selected based on the "),Q2e=a("code"),pbr=o("model_type"),_br=o(` property of the config object (either
passed as an argument or loaded from `),H2e=a("code"),ubr=o("pretrained_model_name_or_path"),bbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U2e=a("code"),vbr=o("pretrained_model_name_or_path"),Fbr=o(":"),Tbr=l(),ie=a("ul"),Q7=a("li"),J2e=a("strong"),Mbr=o("albert"),Ebr=o(" \u2014 "),iH=a("a"),Cbr=o("TFAlbertForMaskedLM"),wbr=o(" (ALBERT model)"),Abr=l(),H7=a("li"),Y2e=a("strong"),ybr=o("bert"),Lbr=o(" \u2014 "),dH=a("a"),xbr=o("TFBertForMaskedLM"),$br=o(" (BERT model)"),kbr=l(),U7=a("li"),K2e=a("strong"),Sbr=o("camembert"),Rbr=o(" \u2014 "),cH=a("a"),Pbr=o("TFCamembertForMaskedLM"),Bbr=o(" (CamemBERT model)"),Ibr=l(),J7=a("li"),Z2e=a("strong"),Nbr=o("convbert"),qbr=o(" \u2014 "),fH=a("a"),jbr=o("TFConvBertForMaskedLM"),Dbr=o(" (ConvBERT model)"),Gbr=l(),Y7=a("li"),eve=a("strong"),Obr=o("deberta"),Vbr=o(" \u2014 "),mH=a("a"),Xbr=o("TFDebertaForMaskedLM"),zbr=o(" (DeBERTa model)"),Wbr=l(),K7=a("li"),ove=a("strong"),Qbr=o("deberta-v2"),Hbr=o(" \u2014 "),gH=a("a"),Ubr=o("TFDebertaV2ForMaskedLM"),Jbr=o(" (DeBERTa-v2 model)"),Ybr=l(),Z7=a("li"),rve=a("strong"),Kbr=o("distilbert"),Zbr=o(" \u2014 "),hH=a("a"),e2r=o("TFDistilBertForMaskedLM"),o2r=o(" (DistilBERT model)"),r2r=l(),eM=a("li"),tve=a("strong"),t2r=o("electra"),a2r=o(" \u2014 "),pH=a("a"),n2r=o("TFElectraForMaskedLM"),s2r=o(" (ELECTRA model)"),l2r=l(),oM=a("li"),ave=a("strong"),i2r=o("flaubert"),d2r=o(" \u2014 "),_H=a("a"),c2r=o("TFFlaubertWithLMHeadModel"),f2r=o(" (FlauBERT model)"),m2r=l(),rM=a("li"),nve=a("strong"),g2r=o("funnel"),h2r=o(" \u2014 "),uH=a("a"),p2r=o("TFFunnelForMaskedLM"),_2r=o(" (Funnel Transformer model)"),u2r=l(),tM=a("li"),sve=a("strong"),b2r=o("layoutlm"),v2r=o(" \u2014 "),bH=a("a"),F2r=o("TFLayoutLMForMaskedLM"),T2r=o(" (LayoutLM model)"),M2r=l(),aM=a("li"),lve=a("strong"),E2r=o("longformer"),C2r=o(" \u2014 "),vH=a("a"),w2r=o("TFLongformerForMaskedLM"),A2r=o(" (Longformer model)"),y2r=l(),nM=a("li"),ive=a("strong"),L2r=o("mobilebert"),x2r=o(" \u2014 "),FH=a("a"),$2r=o("TFMobileBertForMaskedLM"),k2r=o(" (MobileBERT model)"),S2r=l(),sM=a("li"),dve=a("strong"),R2r=o("mpnet"),P2r=o(" \u2014 "),TH=a("a"),B2r=o("TFMPNetForMaskedLM"),I2r=o(" (MPNet model)"),N2r=l(),lM=a("li"),cve=a("strong"),q2r=o("rembert"),j2r=o(" \u2014 "),MH=a("a"),D2r=o("TFRemBertForMaskedLM"),G2r=o(" (RemBERT model)"),O2r=l(),iM=a("li"),fve=a("strong"),V2r=o("roberta"),X2r=o(" \u2014 "),EH=a("a"),z2r=o("TFRobertaForMaskedLM"),W2r=o(" (RoBERTa model)"),Q2r=l(),dM=a("li"),mve=a("strong"),H2r=o("roformer"),U2r=o(" \u2014 "),CH=a("a"),J2r=o("TFRoFormerForMaskedLM"),Y2r=o(" (RoFormer model)"),K2r=l(),cM=a("li"),gve=a("strong"),Z2r=o("tapas"),evr=o(" \u2014 "),wH=a("a"),ovr=o("TFTapasForMaskedLM"),rvr=o(" (TAPAS model)"),tvr=l(),fM=a("li"),hve=a("strong"),avr=o("xlm"),nvr=o(" \u2014 "),AH=a("a"),svr=o("TFXLMWithLMHeadModel"),lvr=o(" (XLM model)"),ivr=l(),mM=a("li"),pve=a("strong"),dvr=o("xlm-roberta"),cvr=o(" \u2014 "),yH=a("a"),fvr=o("TFXLMRobertaForMaskedLM"),mvr=o(" (XLM-RoBERTa model)"),gvr=l(),F(gM.$$.fragment),$je=l(),tc=a("h2"),hM=a("a"),_ve=a("span"),F(N8.$$.fragment),hvr=l(),uve=a("span"),pvr=o("TFAutoModelForSeq2SeqLM"),kje=l(),rr=a("div"),F(q8.$$.fragment),_vr=l(),ac=a("p"),uvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),LH=a("a"),bvr=o("from_pretrained()"),vvr=o(" class method or the "),xH=a("a"),Fvr=o("from_config()"),Tvr=o(` class
method.`),Mvr=l(),j8=a("p"),Evr=o("This class cannot be instantiated directly using "),bve=a("code"),Cvr=o("__init__()"),wvr=o(" (throws an error)."),Avr=l(),St=a("div"),F(D8.$$.fragment),yvr=l(),vve=a("p"),Lvr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),xvr=l(),nc=a("p"),$vr=o(`Note:
Loading a model from its configuration file does `),Fve=a("strong"),kvr=o("not"),Svr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=a("a"),Rvr=o("from_pretrained()"),Pvr=o(" to load the model weights."),Bvr=l(),F(pM.$$.fragment),Ivr=l(),$r=a("div"),F(G8.$$.fragment),Nvr=l(),Tve=a("p"),qvr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),jvr=l(),an=a("p"),Dvr=o("The model class to instantiate is selected based on the "),Mve=a("code"),Gvr=o("model_type"),Ovr=o(` property of the config object (either
passed as an argument or loaded from `),Eve=a("code"),Vvr=o("pretrained_model_name_or_path"),Xvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cve=a("code"),zvr=o("pretrained_model_name_or_path"),Wvr=o(":"),Qvr=l(),ye=a("ul"),_M=a("li"),wve=a("strong"),Hvr=o("bart"),Uvr=o(" \u2014 "),kH=a("a"),Jvr=o("TFBartForConditionalGeneration"),Yvr=o(" (BART model)"),Kvr=l(),uM=a("li"),Ave=a("strong"),Zvr=o("blenderbot"),e3r=o(" \u2014 "),SH=a("a"),o3r=o("TFBlenderbotForConditionalGeneration"),r3r=o(" (Blenderbot model)"),t3r=l(),bM=a("li"),yve=a("strong"),a3r=o("blenderbot-small"),n3r=o(" \u2014 "),RH=a("a"),s3r=o("TFBlenderbotSmallForConditionalGeneration"),l3r=o(" (BlenderbotSmall model)"),i3r=l(),vM=a("li"),Lve=a("strong"),d3r=o("encoder-decoder"),c3r=o(" \u2014 "),PH=a("a"),f3r=o("TFEncoderDecoderModel"),m3r=o(" (Encoder decoder model)"),g3r=l(),FM=a("li"),xve=a("strong"),h3r=o("led"),p3r=o(" \u2014 "),BH=a("a"),_3r=o("TFLEDForConditionalGeneration"),u3r=o(" (LED model)"),b3r=l(),TM=a("li"),$ve=a("strong"),v3r=o("marian"),F3r=o(" \u2014 "),IH=a("a"),T3r=o("TFMarianMTModel"),M3r=o(" (Marian model)"),E3r=l(),MM=a("li"),kve=a("strong"),C3r=o("mbart"),w3r=o(" \u2014 "),NH=a("a"),A3r=o("TFMBartForConditionalGeneration"),y3r=o(" (mBART model)"),L3r=l(),EM=a("li"),Sve=a("strong"),x3r=o("mt5"),$3r=o(" \u2014 "),qH=a("a"),k3r=o("TFMT5ForConditionalGeneration"),S3r=o(" (mT5 model)"),R3r=l(),CM=a("li"),Rve=a("strong"),P3r=o("pegasus"),B3r=o(" \u2014 "),jH=a("a"),I3r=o("TFPegasusForConditionalGeneration"),N3r=o(" (Pegasus model)"),q3r=l(),wM=a("li"),Pve=a("strong"),j3r=o("t5"),D3r=o(" \u2014 "),DH=a("a"),G3r=o("TFT5ForConditionalGeneration"),O3r=o(" (T5 model)"),V3r=l(),F(AM.$$.fragment),Sje=l(),sc=a("h2"),yM=a("a"),Bve=a("span"),F(O8.$$.fragment),X3r=l(),Ive=a("span"),z3r=o("TFAutoModelForSequenceClassification"),Rje=l(),tr=a("div"),F(V8.$$.fragment),W3r=l(),lc=a("p"),Q3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),GH=a("a"),H3r=o("from_pretrained()"),U3r=o(" class method or the "),OH=a("a"),J3r=o("from_config()"),Y3r=o(` class
method.`),K3r=l(),X8=a("p"),Z3r=o("This class cannot be instantiated directly using "),Nve=a("code"),eFr=o("__init__()"),oFr=o(" (throws an error)."),rFr=l(),Rt=a("div"),F(z8.$$.fragment),tFr=l(),qve=a("p"),aFr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),nFr=l(),ic=a("p"),sFr=o(`Note:
Loading a model from its configuration file does `),jve=a("strong"),lFr=o("not"),iFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VH=a("a"),dFr=o("from_pretrained()"),cFr=o(" to load the model weights."),fFr=l(),F(LM.$$.fragment),mFr=l(),kr=a("div"),F(W8.$$.fragment),gFr=l(),Dve=a("p"),hFr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),pFr=l(),nn=a("p"),_Fr=o("The model class to instantiate is selected based on the "),Gve=a("code"),uFr=o("model_type"),bFr=o(` property of the config object (either
passed as an argument or loaded from `),Ove=a("code"),vFr=o("pretrained_model_name_or_path"),FFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vve=a("code"),TFr=o("pretrained_model_name_or_path"),MFr=o(":"),EFr=l(),oe=a("ul"),xM=a("li"),Xve=a("strong"),CFr=o("albert"),wFr=o(" \u2014 "),XH=a("a"),AFr=o("TFAlbertForSequenceClassification"),yFr=o(" (ALBERT model)"),LFr=l(),$M=a("li"),zve=a("strong"),xFr=o("bert"),$Fr=o(" \u2014 "),zH=a("a"),kFr=o("TFBertForSequenceClassification"),SFr=o(" (BERT model)"),RFr=l(),kM=a("li"),Wve=a("strong"),PFr=o("camembert"),BFr=o(" \u2014 "),WH=a("a"),IFr=o("TFCamembertForSequenceClassification"),NFr=o(" (CamemBERT model)"),qFr=l(),SM=a("li"),Qve=a("strong"),jFr=o("convbert"),DFr=o(" \u2014 "),QH=a("a"),GFr=o("TFConvBertForSequenceClassification"),OFr=o(" (ConvBERT model)"),VFr=l(),RM=a("li"),Hve=a("strong"),XFr=o("ctrl"),zFr=o(" \u2014 "),HH=a("a"),WFr=o("TFCTRLForSequenceClassification"),QFr=o(" (CTRL model)"),HFr=l(),PM=a("li"),Uve=a("strong"),UFr=o("deberta"),JFr=o(" \u2014 "),UH=a("a"),YFr=o("TFDebertaForSequenceClassification"),KFr=o(" (DeBERTa model)"),ZFr=l(),BM=a("li"),Jve=a("strong"),eTr=o("deberta-v2"),oTr=o(" \u2014 "),JH=a("a"),rTr=o("TFDebertaV2ForSequenceClassification"),tTr=o(" (DeBERTa-v2 model)"),aTr=l(),IM=a("li"),Yve=a("strong"),nTr=o("distilbert"),sTr=o(" \u2014 "),YH=a("a"),lTr=o("TFDistilBertForSequenceClassification"),iTr=o(" (DistilBERT model)"),dTr=l(),NM=a("li"),Kve=a("strong"),cTr=o("electra"),fTr=o(" \u2014 "),KH=a("a"),mTr=o("TFElectraForSequenceClassification"),gTr=o(" (ELECTRA model)"),hTr=l(),qM=a("li"),Zve=a("strong"),pTr=o("flaubert"),_Tr=o(" \u2014 "),ZH=a("a"),uTr=o("TFFlaubertForSequenceClassification"),bTr=o(" (FlauBERT model)"),vTr=l(),jM=a("li"),e3e=a("strong"),FTr=o("funnel"),TTr=o(" \u2014 "),eU=a("a"),MTr=o("TFFunnelForSequenceClassification"),ETr=o(" (Funnel Transformer model)"),CTr=l(),DM=a("li"),o3e=a("strong"),wTr=o("gpt2"),ATr=o(" \u2014 "),oU=a("a"),yTr=o("TFGPT2ForSequenceClassification"),LTr=o(" (OpenAI GPT-2 model)"),xTr=l(),GM=a("li"),r3e=a("strong"),$Tr=o("gptj"),kTr=o(" \u2014 "),rU=a("a"),STr=o("TFGPTJForSequenceClassification"),RTr=o(" (GPT-J model)"),PTr=l(),OM=a("li"),t3e=a("strong"),BTr=o("layoutlm"),ITr=o(" \u2014 "),tU=a("a"),NTr=o("TFLayoutLMForSequenceClassification"),qTr=o(" (LayoutLM model)"),jTr=l(),VM=a("li"),a3e=a("strong"),DTr=o("longformer"),GTr=o(" \u2014 "),aU=a("a"),OTr=o("TFLongformerForSequenceClassification"),VTr=o(" (Longformer model)"),XTr=l(),XM=a("li"),n3e=a("strong"),zTr=o("mobilebert"),WTr=o(" \u2014 "),nU=a("a"),QTr=o("TFMobileBertForSequenceClassification"),HTr=o(" (MobileBERT model)"),UTr=l(),zM=a("li"),s3e=a("strong"),JTr=o("mpnet"),YTr=o(" \u2014 "),sU=a("a"),KTr=o("TFMPNetForSequenceClassification"),ZTr=o(" (MPNet model)"),e7r=l(),WM=a("li"),l3e=a("strong"),o7r=o("openai-gpt"),r7r=o(" \u2014 "),lU=a("a"),t7r=o("TFOpenAIGPTForSequenceClassification"),a7r=o(" (OpenAI GPT model)"),n7r=l(),QM=a("li"),i3e=a("strong"),s7r=o("rembert"),l7r=o(" \u2014 "),iU=a("a"),i7r=o("TFRemBertForSequenceClassification"),d7r=o(" (RemBERT model)"),c7r=l(),HM=a("li"),d3e=a("strong"),f7r=o("roberta"),m7r=o(" \u2014 "),dU=a("a"),g7r=o("TFRobertaForSequenceClassification"),h7r=o(" (RoBERTa model)"),p7r=l(),UM=a("li"),c3e=a("strong"),_7r=o("roformer"),u7r=o(" \u2014 "),cU=a("a"),b7r=o("TFRoFormerForSequenceClassification"),v7r=o(" (RoFormer model)"),F7r=l(),JM=a("li"),f3e=a("strong"),T7r=o("tapas"),M7r=o(" \u2014 "),fU=a("a"),E7r=o("TFTapasForSequenceClassification"),C7r=o(" (TAPAS model)"),w7r=l(),YM=a("li"),m3e=a("strong"),A7r=o("transfo-xl"),y7r=o(" \u2014 "),mU=a("a"),L7r=o("TFTransfoXLForSequenceClassification"),x7r=o(" (Transformer-XL model)"),$7r=l(),KM=a("li"),g3e=a("strong"),k7r=o("xlm"),S7r=o(" \u2014 "),gU=a("a"),R7r=o("TFXLMForSequenceClassification"),P7r=o(" (XLM model)"),B7r=l(),ZM=a("li"),h3e=a("strong"),I7r=o("xlm-roberta"),N7r=o(" \u2014 "),hU=a("a"),q7r=o("TFXLMRobertaForSequenceClassification"),j7r=o(" (XLM-RoBERTa model)"),D7r=l(),eE=a("li"),p3e=a("strong"),G7r=o("xlnet"),O7r=o(" \u2014 "),pU=a("a"),V7r=o("TFXLNetForSequenceClassification"),X7r=o(" (XLNet model)"),z7r=l(),F(oE.$$.fragment),Pje=l(),dc=a("h2"),rE=a("a"),_3e=a("span"),F(Q8.$$.fragment),W7r=l(),u3e=a("span"),Q7r=o("TFAutoModelForMultipleChoice"),Bje=l(),ar=a("div"),F(H8.$$.fragment),H7r=l(),cc=a("p"),U7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),_U=a("a"),J7r=o("from_pretrained()"),Y7r=o(" class method or the "),uU=a("a"),K7r=o("from_config()"),Z7r=o(` class
method.`),eMr=l(),U8=a("p"),oMr=o("This class cannot be instantiated directly using "),b3e=a("code"),rMr=o("__init__()"),tMr=o(" (throws an error)."),aMr=l(),Pt=a("div"),F(J8.$$.fragment),nMr=l(),v3e=a("p"),sMr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),lMr=l(),fc=a("p"),iMr=o(`Note:
Loading a model from its configuration file does `),F3e=a("strong"),dMr=o("not"),cMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bU=a("a"),fMr=o("from_pretrained()"),mMr=o(" to load the model weights."),gMr=l(),F(tE.$$.fragment),hMr=l(),Sr=a("div"),F(Y8.$$.fragment),pMr=l(),T3e=a("p"),_Mr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),uMr=l(),sn=a("p"),bMr=o("The model class to instantiate is selected based on the "),M3e=a("code"),vMr=o("model_type"),FMr=o(` property of the config object (either
passed as an argument or loaded from `),E3e=a("code"),TMr=o("pretrained_model_name_or_path"),MMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C3e=a("code"),EMr=o("pretrained_model_name_or_path"),CMr=o(":"),wMr=l(),pe=a("ul"),aE=a("li"),w3e=a("strong"),AMr=o("albert"),yMr=o(" \u2014 "),vU=a("a"),LMr=o("TFAlbertForMultipleChoice"),xMr=o(" (ALBERT model)"),$Mr=l(),nE=a("li"),A3e=a("strong"),kMr=o("bert"),SMr=o(" \u2014 "),FU=a("a"),RMr=o("TFBertForMultipleChoice"),PMr=o(" (BERT model)"),BMr=l(),sE=a("li"),y3e=a("strong"),IMr=o("camembert"),NMr=o(" \u2014 "),TU=a("a"),qMr=o("TFCamembertForMultipleChoice"),jMr=o(" (CamemBERT model)"),DMr=l(),lE=a("li"),L3e=a("strong"),GMr=o("convbert"),OMr=o(" \u2014 "),MU=a("a"),VMr=o("TFConvBertForMultipleChoice"),XMr=o(" (ConvBERT model)"),zMr=l(),iE=a("li"),x3e=a("strong"),WMr=o("distilbert"),QMr=o(" \u2014 "),EU=a("a"),HMr=o("TFDistilBertForMultipleChoice"),UMr=o(" (DistilBERT model)"),JMr=l(),dE=a("li"),$3e=a("strong"),YMr=o("electra"),KMr=o(" \u2014 "),CU=a("a"),ZMr=o("TFElectraForMultipleChoice"),eEr=o(" (ELECTRA model)"),oEr=l(),cE=a("li"),k3e=a("strong"),rEr=o("flaubert"),tEr=o(" \u2014 "),wU=a("a"),aEr=o("TFFlaubertForMultipleChoice"),nEr=o(" (FlauBERT model)"),sEr=l(),fE=a("li"),S3e=a("strong"),lEr=o("funnel"),iEr=o(" \u2014 "),AU=a("a"),dEr=o("TFFunnelForMultipleChoice"),cEr=o(" (Funnel Transformer model)"),fEr=l(),mE=a("li"),R3e=a("strong"),mEr=o("longformer"),gEr=o(" \u2014 "),yU=a("a"),hEr=o("TFLongformerForMultipleChoice"),pEr=o(" (Longformer model)"),_Er=l(),gE=a("li"),P3e=a("strong"),uEr=o("mobilebert"),bEr=o(" \u2014 "),LU=a("a"),vEr=o("TFMobileBertForMultipleChoice"),FEr=o(" (MobileBERT model)"),TEr=l(),hE=a("li"),B3e=a("strong"),MEr=o("mpnet"),EEr=o(" \u2014 "),xU=a("a"),CEr=o("TFMPNetForMultipleChoice"),wEr=o(" (MPNet model)"),AEr=l(),pE=a("li"),I3e=a("strong"),yEr=o("rembert"),LEr=o(" \u2014 "),$U=a("a"),xEr=o("TFRemBertForMultipleChoice"),$Er=o(" (RemBERT model)"),kEr=l(),_E=a("li"),N3e=a("strong"),SEr=o("roberta"),REr=o(" \u2014 "),kU=a("a"),PEr=o("TFRobertaForMultipleChoice"),BEr=o(" (RoBERTa model)"),IEr=l(),uE=a("li"),q3e=a("strong"),NEr=o("roformer"),qEr=o(" \u2014 "),SU=a("a"),jEr=o("TFRoFormerForMultipleChoice"),DEr=o(" (RoFormer model)"),GEr=l(),bE=a("li"),j3e=a("strong"),OEr=o("xlm"),VEr=o(" \u2014 "),RU=a("a"),XEr=o("TFXLMForMultipleChoice"),zEr=o(" (XLM model)"),WEr=l(),vE=a("li"),D3e=a("strong"),QEr=o("xlm-roberta"),HEr=o(" \u2014 "),PU=a("a"),UEr=o("TFXLMRobertaForMultipleChoice"),JEr=o(" (XLM-RoBERTa model)"),YEr=l(),FE=a("li"),G3e=a("strong"),KEr=o("xlnet"),ZEr=o(" \u2014 "),BU=a("a"),eCr=o("TFXLNetForMultipleChoice"),oCr=o(" (XLNet model)"),rCr=l(),F(TE.$$.fragment),Ije=l(),mc=a("h2"),ME=a("a"),O3e=a("span"),F(K8.$$.fragment),tCr=l(),V3e=a("span"),aCr=o("TFAutoModelForNextSentencePrediction"),Nje=l(),nr=a("div"),F(Z8.$$.fragment),nCr=l(),gc=a("p"),sCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),IU=a("a"),lCr=o("from_pretrained()"),iCr=o(" class method or the "),NU=a("a"),dCr=o("from_config()"),cCr=o(` class
method.`),fCr=l(),e9=a("p"),mCr=o("This class cannot be instantiated directly using "),X3e=a("code"),gCr=o("__init__()"),hCr=o(" (throws an error)."),pCr=l(),Bt=a("div"),F(o9.$$.fragment),_Cr=l(),z3e=a("p"),uCr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),bCr=l(),hc=a("p"),vCr=o(`Note:
Loading a model from its configuration file does `),W3e=a("strong"),FCr=o("not"),TCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qU=a("a"),MCr=o("from_pretrained()"),ECr=o(" to load the model weights."),CCr=l(),F(EE.$$.fragment),wCr=l(),Rr=a("div"),F(r9.$$.fragment),ACr=l(),Q3e=a("p"),yCr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),LCr=l(),ln=a("p"),xCr=o("The model class to instantiate is selected based on the "),H3e=a("code"),$Cr=o("model_type"),kCr=o(` property of the config object (either
passed as an argument or loaded from `),U3e=a("code"),SCr=o("pretrained_model_name_or_path"),RCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J3e=a("code"),PCr=o("pretrained_model_name_or_path"),BCr=o(":"),ICr=l(),t9=a("ul"),CE=a("li"),Y3e=a("strong"),NCr=o("bert"),qCr=o(" \u2014 "),jU=a("a"),jCr=o("TFBertForNextSentencePrediction"),DCr=o(" (BERT model)"),GCr=l(),wE=a("li"),K3e=a("strong"),OCr=o("mobilebert"),VCr=o(" \u2014 "),DU=a("a"),XCr=o("TFMobileBertForNextSentencePrediction"),zCr=o(" (MobileBERT model)"),WCr=l(),F(AE.$$.fragment),qje=l(),pc=a("h2"),yE=a("a"),Z3e=a("span"),F(a9.$$.fragment),QCr=l(),eFe=a("span"),HCr=o("TFAutoModelForTableQuestionAnswering"),jje=l(),sr=a("div"),F(n9.$$.fragment),UCr=l(),_c=a("p"),JCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),GU=a("a"),YCr=o("from_pretrained()"),KCr=o(" class method or the "),OU=a("a"),ZCr=o("from_config()"),e5r=o(` class
method.`),o5r=l(),s9=a("p"),r5r=o("This class cannot be instantiated directly using "),oFe=a("code"),t5r=o("__init__()"),a5r=o(" (throws an error)."),n5r=l(),It=a("div"),F(l9.$$.fragment),s5r=l(),rFe=a("p"),l5r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),i5r=l(),uc=a("p"),d5r=o(`Note:
Loading a model from its configuration file does `),tFe=a("strong"),c5r=o("not"),f5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=a("a"),m5r=o("from_pretrained()"),g5r=o(" to load the model weights."),h5r=l(),F(LE.$$.fragment),p5r=l(),Pr=a("div"),F(i9.$$.fragment),_5r=l(),aFe=a("p"),u5r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),b5r=l(),dn=a("p"),v5r=o("The model class to instantiate is selected based on the "),nFe=a("code"),F5r=o("model_type"),T5r=o(` property of the config object (either
passed as an argument or loaded from `),sFe=a("code"),M5r=o("pretrained_model_name_or_path"),E5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lFe=a("code"),C5r=o("pretrained_model_name_or_path"),w5r=o(":"),A5r=l(),iFe=a("ul"),xE=a("li"),dFe=a("strong"),y5r=o("tapas"),L5r=o(" \u2014 "),XU=a("a"),x5r=o("TFTapasForQuestionAnswering"),$5r=o(" (TAPAS model)"),k5r=l(),F($E.$$.fragment),Dje=l(),bc=a("h2"),kE=a("a"),cFe=a("span"),F(d9.$$.fragment),S5r=l(),fFe=a("span"),R5r=o("TFAutoModelForTokenClassification"),Gje=l(),lr=a("div"),F(c9.$$.fragment),P5r=l(),vc=a("p"),B5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),zU=a("a"),I5r=o("from_pretrained()"),N5r=o(" class method or the "),WU=a("a"),q5r=o("from_config()"),j5r=o(` class
method.`),D5r=l(),f9=a("p"),G5r=o("This class cannot be instantiated directly using "),mFe=a("code"),O5r=o("__init__()"),V5r=o(" (throws an error)."),X5r=l(),Nt=a("div"),F(m9.$$.fragment),z5r=l(),gFe=a("p"),W5r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Q5r=l(),Fc=a("p"),H5r=o(`Note:
Loading a model from its configuration file does `),hFe=a("strong"),U5r=o("not"),J5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QU=a("a"),Y5r=o("from_pretrained()"),K5r=o(" to load the model weights."),Z5r=l(),F(SE.$$.fragment),ewr=l(),Br=a("div"),F(g9.$$.fragment),owr=l(),pFe=a("p"),rwr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),twr=l(),cn=a("p"),awr=o("The model class to instantiate is selected based on the "),_Fe=a("code"),nwr=o("model_type"),swr=o(` property of the config object (either
passed as an argument or loaded from `),uFe=a("code"),lwr=o("pretrained_model_name_or_path"),iwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bFe=a("code"),dwr=o("pretrained_model_name_or_path"),cwr=o(":"),fwr=l(),de=a("ul"),RE=a("li"),vFe=a("strong"),mwr=o("albert"),gwr=o(" \u2014 "),HU=a("a"),hwr=o("TFAlbertForTokenClassification"),pwr=o(" (ALBERT model)"),_wr=l(),PE=a("li"),FFe=a("strong"),uwr=o("bert"),bwr=o(" \u2014 "),UU=a("a"),vwr=o("TFBertForTokenClassification"),Fwr=o(" (BERT model)"),Twr=l(),BE=a("li"),TFe=a("strong"),Mwr=o("camembert"),Ewr=o(" \u2014 "),JU=a("a"),Cwr=o("TFCamembertForTokenClassification"),wwr=o(" (CamemBERT model)"),Awr=l(),IE=a("li"),MFe=a("strong"),ywr=o("convbert"),Lwr=o(" \u2014 "),YU=a("a"),xwr=o("TFConvBertForTokenClassification"),$wr=o(" (ConvBERT model)"),kwr=l(),NE=a("li"),EFe=a("strong"),Swr=o("deberta"),Rwr=o(" \u2014 "),KU=a("a"),Pwr=o("TFDebertaForTokenClassification"),Bwr=o(" (DeBERTa model)"),Iwr=l(),qE=a("li"),CFe=a("strong"),Nwr=o("deberta-v2"),qwr=o(" \u2014 "),ZU=a("a"),jwr=o("TFDebertaV2ForTokenClassification"),Dwr=o(" (DeBERTa-v2 model)"),Gwr=l(),jE=a("li"),wFe=a("strong"),Owr=o("distilbert"),Vwr=o(" \u2014 "),eJ=a("a"),Xwr=o("TFDistilBertForTokenClassification"),zwr=o(" (DistilBERT model)"),Wwr=l(),DE=a("li"),AFe=a("strong"),Qwr=o("electra"),Hwr=o(" \u2014 "),oJ=a("a"),Uwr=o("TFElectraForTokenClassification"),Jwr=o(" (ELECTRA model)"),Ywr=l(),GE=a("li"),yFe=a("strong"),Kwr=o("flaubert"),Zwr=o(" \u2014 "),rJ=a("a"),e0r=o("TFFlaubertForTokenClassification"),o0r=o(" (FlauBERT model)"),r0r=l(),OE=a("li"),LFe=a("strong"),t0r=o("funnel"),a0r=o(" \u2014 "),tJ=a("a"),n0r=o("TFFunnelForTokenClassification"),s0r=o(" (Funnel Transformer model)"),l0r=l(),VE=a("li"),xFe=a("strong"),i0r=o("layoutlm"),d0r=o(" \u2014 "),aJ=a("a"),c0r=o("TFLayoutLMForTokenClassification"),f0r=o(" (LayoutLM model)"),m0r=l(),XE=a("li"),$Fe=a("strong"),g0r=o("longformer"),h0r=o(" \u2014 "),nJ=a("a"),p0r=o("TFLongformerForTokenClassification"),_0r=o(" (Longformer model)"),u0r=l(),zE=a("li"),kFe=a("strong"),b0r=o("mobilebert"),v0r=o(" \u2014 "),sJ=a("a"),F0r=o("TFMobileBertForTokenClassification"),T0r=o(" (MobileBERT model)"),M0r=l(),WE=a("li"),SFe=a("strong"),E0r=o("mpnet"),C0r=o(" \u2014 "),lJ=a("a"),w0r=o("TFMPNetForTokenClassification"),A0r=o(" (MPNet model)"),y0r=l(),QE=a("li"),RFe=a("strong"),L0r=o("rembert"),x0r=o(" \u2014 "),iJ=a("a"),$0r=o("TFRemBertForTokenClassification"),k0r=o(" (RemBERT model)"),S0r=l(),HE=a("li"),PFe=a("strong"),R0r=o("roberta"),P0r=o(" \u2014 "),dJ=a("a"),B0r=o("TFRobertaForTokenClassification"),I0r=o(" (RoBERTa model)"),N0r=l(),UE=a("li"),BFe=a("strong"),q0r=o("roformer"),j0r=o(" \u2014 "),cJ=a("a"),D0r=o("TFRoFormerForTokenClassification"),G0r=o(" (RoFormer model)"),O0r=l(),JE=a("li"),IFe=a("strong"),V0r=o("xlm"),X0r=o(" \u2014 "),fJ=a("a"),z0r=o("TFXLMForTokenClassification"),W0r=o(" (XLM model)"),Q0r=l(),YE=a("li"),NFe=a("strong"),H0r=o("xlm-roberta"),U0r=o(" \u2014 "),mJ=a("a"),J0r=o("TFXLMRobertaForTokenClassification"),Y0r=o(" (XLM-RoBERTa model)"),K0r=l(),KE=a("li"),qFe=a("strong"),Z0r=o("xlnet"),e6r=o(" \u2014 "),gJ=a("a"),o6r=o("TFXLNetForTokenClassification"),r6r=o(" (XLNet model)"),t6r=l(),F(ZE.$$.fragment),Oje=l(),Tc=a("h2"),eC=a("a"),jFe=a("span"),F(h9.$$.fragment),a6r=l(),DFe=a("span"),n6r=o("TFAutoModelForQuestionAnswering"),Vje=l(),ir=a("div"),F(p9.$$.fragment),s6r=l(),Mc=a("p"),l6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hJ=a("a"),i6r=o("from_pretrained()"),d6r=o(" class method or the "),pJ=a("a"),c6r=o("from_config()"),f6r=o(` class
method.`),m6r=l(),_9=a("p"),g6r=o("This class cannot be instantiated directly using "),GFe=a("code"),h6r=o("__init__()"),p6r=o(" (throws an error)."),_6r=l(),qt=a("div"),F(u9.$$.fragment),u6r=l(),OFe=a("p"),b6r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),v6r=l(),Ec=a("p"),F6r=o(`Note:
Loading a model from its configuration file does `),VFe=a("strong"),T6r=o("not"),M6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_J=a("a"),E6r=o("from_pretrained()"),C6r=o(" to load the model weights."),w6r=l(),F(oC.$$.fragment),A6r=l(),Ir=a("div"),F(b9.$$.fragment),y6r=l(),XFe=a("p"),L6r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),x6r=l(),fn=a("p"),$6r=o("The model class to instantiate is selected based on the "),zFe=a("code"),k6r=o("model_type"),S6r=o(` property of the config object (either
passed as an argument or loaded from `),WFe=a("code"),R6r=o("pretrained_model_name_or_path"),P6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QFe=a("code"),B6r=o("pretrained_model_name_or_path"),I6r=o(":"),N6r=l(),ce=a("ul"),rC=a("li"),HFe=a("strong"),q6r=o("albert"),j6r=o(" \u2014 "),uJ=a("a"),D6r=o("TFAlbertForQuestionAnswering"),G6r=o(" (ALBERT model)"),O6r=l(),tC=a("li"),UFe=a("strong"),V6r=o("bert"),X6r=o(" \u2014 "),bJ=a("a"),z6r=o("TFBertForQuestionAnswering"),W6r=o(" (BERT model)"),Q6r=l(),aC=a("li"),JFe=a("strong"),H6r=o("camembert"),U6r=o(" \u2014 "),vJ=a("a"),J6r=o("TFCamembertForQuestionAnswering"),Y6r=o(" (CamemBERT model)"),K6r=l(),nC=a("li"),YFe=a("strong"),Z6r=o("convbert"),eAr=o(" \u2014 "),FJ=a("a"),oAr=o("TFConvBertForQuestionAnswering"),rAr=o(" (ConvBERT model)"),tAr=l(),sC=a("li"),KFe=a("strong"),aAr=o("deberta"),nAr=o(" \u2014 "),TJ=a("a"),sAr=o("TFDebertaForQuestionAnswering"),lAr=o(" (DeBERTa model)"),iAr=l(),lC=a("li"),ZFe=a("strong"),dAr=o("deberta-v2"),cAr=o(" \u2014 "),MJ=a("a"),fAr=o("TFDebertaV2ForQuestionAnswering"),mAr=o(" (DeBERTa-v2 model)"),gAr=l(),iC=a("li"),eTe=a("strong"),hAr=o("distilbert"),pAr=o(" \u2014 "),EJ=a("a"),_Ar=o("TFDistilBertForQuestionAnswering"),uAr=o(" (DistilBERT model)"),bAr=l(),dC=a("li"),oTe=a("strong"),vAr=o("electra"),FAr=o(" \u2014 "),CJ=a("a"),TAr=o("TFElectraForQuestionAnswering"),MAr=o(" (ELECTRA model)"),EAr=l(),cC=a("li"),rTe=a("strong"),CAr=o("flaubert"),wAr=o(" \u2014 "),wJ=a("a"),AAr=o("TFFlaubertForQuestionAnsweringSimple"),yAr=o(" (FlauBERT model)"),LAr=l(),fC=a("li"),tTe=a("strong"),xAr=o("funnel"),$Ar=o(" \u2014 "),AJ=a("a"),kAr=o("TFFunnelForQuestionAnswering"),SAr=o(" (Funnel Transformer model)"),RAr=l(),mC=a("li"),aTe=a("strong"),PAr=o("gptj"),BAr=o(" \u2014 "),yJ=a("a"),IAr=o("TFGPTJForQuestionAnswering"),NAr=o(" (GPT-J model)"),qAr=l(),gC=a("li"),nTe=a("strong"),jAr=o("longformer"),DAr=o(" \u2014 "),LJ=a("a"),GAr=o("TFLongformerForQuestionAnswering"),OAr=o(" (Longformer model)"),VAr=l(),hC=a("li"),sTe=a("strong"),XAr=o("mobilebert"),zAr=o(" \u2014 "),xJ=a("a"),WAr=o("TFMobileBertForQuestionAnswering"),QAr=o(" (MobileBERT model)"),HAr=l(),pC=a("li"),lTe=a("strong"),UAr=o("mpnet"),JAr=o(" \u2014 "),$J=a("a"),YAr=o("TFMPNetForQuestionAnswering"),KAr=o(" (MPNet model)"),ZAr=l(),_C=a("li"),iTe=a("strong"),eyr=o("rembert"),oyr=o(" \u2014 "),kJ=a("a"),ryr=o("TFRemBertForQuestionAnswering"),tyr=o(" (RemBERT model)"),ayr=l(),uC=a("li"),dTe=a("strong"),nyr=o("roberta"),syr=o(" \u2014 "),SJ=a("a"),lyr=o("TFRobertaForQuestionAnswering"),iyr=o(" (RoBERTa model)"),dyr=l(),bC=a("li"),cTe=a("strong"),cyr=o("roformer"),fyr=o(" \u2014 "),RJ=a("a"),myr=o("TFRoFormerForQuestionAnswering"),gyr=o(" (RoFormer model)"),hyr=l(),vC=a("li"),fTe=a("strong"),pyr=o("xlm"),_yr=o(" \u2014 "),PJ=a("a"),uyr=o("TFXLMForQuestionAnsweringSimple"),byr=o(" (XLM model)"),vyr=l(),FC=a("li"),mTe=a("strong"),Fyr=o("xlm-roberta"),Tyr=o(" \u2014 "),BJ=a("a"),Myr=o("TFXLMRobertaForQuestionAnswering"),Eyr=o(" (XLM-RoBERTa model)"),Cyr=l(),TC=a("li"),gTe=a("strong"),wyr=o("xlnet"),Ayr=o(" \u2014 "),IJ=a("a"),yyr=o("TFXLNetForQuestionAnsweringSimple"),Lyr=o(" (XLNet model)"),xyr=l(),F(MC.$$.fragment),Xje=l(),Cc=a("h2"),EC=a("a"),hTe=a("span"),F(v9.$$.fragment),$yr=l(),pTe=a("span"),kyr=o("TFAutoModelForVision2Seq"),zje=l(),dr=a("div"),F(F9.$$.fragment),Syr=l(),wc=a("p"),Ryr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),NJ=a("a"),Pyr=o("from_pretrained()"),Byr=o(" class method or the "),qJ=a("a"),Iyr=o("from_config()"),Nyr=o(` class
method.`),qyr=l(),T9=a("p"),jyr=o("This class cannot be instantiated directly using "),_Te=a("code"),Dyr=o("__init__()"),Gyr=o(" (throws an error)."),Oyr=l(),jt=a("div"),F(M9.$$.fragment),Vyr=l(),uTe=a("p"),Xyr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zyr=l(),Ac=a("p"),Wyr=o(`Note:
Loading a model from its configuration file does `),bTe=a("strong"),Qyr=o("not"),Hyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jJ=a("a"),Uyr=o("from_pretrained()"),Jyr=o(" to load the model weights."),Yyr=l(),F(CC.$$.fragment),Kyr=l(),Nr=a("div"),F(E9.$$.fragment),Zyr=l(),vTe=a("p"),eLr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),oLr=l(),mn=a("p"),rLr=o("The model class to instantiate is selected based on the "),FTe=a("code"),tLr=o("model_type"),aLr=o(` property of the config object (either
passed as an argument or loaded from `),TTe=a("code"),nLr=o("pretrained_model_name_or_path"),sLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=a("code"),lLr=o("pretrained_model_name_or_path"),iLr=o(":"),dLr=l(),ETe=a("ul"),wC=a("li"),CTe=a("strong"),cLr=o("vision-encoder-decoder"),fLr=o(" \u2014 "),DJ=a("a"),mLr=o("TFVisionEncoderDecoderModel"),gLr=o(" (Vision Encoder decoder model)"),hLr=l(),F(AC.$$.fragment),Wje=l(),yc=a("h2"),yC=a("a"),wTe=a("span"),F(C9.$$.fragment),pLr=l(),ATe=a("span"),_Lr=o("TFAutoModelForSpeechSeq2Seq"),Qje=l(),cr=a("div"),F(w9.$$.fragment),uLr=l(),Lc=a("p"),bLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),GJ=a("a"),vLr=o("from_pretrained()"),FLr=o(" class method or the "),OJ=a("a"),TLr=o("from_config()"),MLr=o(` class
method.`),ELr=l(),A9=a("p"),CLr=o("This class cannot be instantiated directly using "),yTe=a("code"),wLr=o("__init__()"),ALr=o(" (throws an error)."),yLr=l(),Dt=a("div"),F(y9.$$.fragment),LLr=l(),LTe=a("p"),xLr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),$Lr=l(),xc=a("p"),kLr=o(`Note:
Loading a model from its configuration file does `),xTe=a("strong"),SLr=o("not"),RLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VJ=a("a"),PLr=o("from_pretrained()"),BLr=o(" to load the model weights."),ILr=l(),F(LC.$$.fragment),NLr=l(),qr=a("div"),F(L9.$$.fragment),qLr=l(),$Te=a("p"),jLr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),DLr=l(),gn=a("p"),GLr=o("The model class to instantiate is selected based on the "),kTe=a("code"),OLr=o("model_type"),VLr=o(` property of the config object (either
passed as an argument or loaded from `),STe=a("code"),XLr=o("pretrained_model_name_or_path"),zLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=a("code"),WLr=o("pretrained_model_name_or_path"),QLr=o(":"),HLr=l(),PTe=a("ul"),xC=a("li"),BTe=a("strong"),ULr=o("speech_to_text"),JLr=o(" \u2014 "),XJ=a("a"),YLr=o("TFSpeech2TextForConditionalGeneration"),KLr=o(" (Speech2Text model)"),ZLr=l(),F($C.$$.fragment),Hje=l(),$c=a("h2"),kC=a("a"),ITe=a("span"),F(x9.$$.fragment),e8r=l(),NTe=a("span"),o8r=o("FlaxAutoModel"),Uje=l(),fr=a("div"),F($9.$$.fragment),r8r=l(),kc=a("p"),t8r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),zJ=a("a"),a8r=o("from_pretrained()"),n8r=o(" class method or the "),WJ=a("a"),s8r=o("from_config()"),l8r=o(` class
method.`),i8r=l(),k9=a("p"),d8r=o("This class cannot be instantiated directly using "),qTe=a("code"),c8r=o("__init__()"),f8r=o(" (throws an error)."),m8r=l(),Gt=a("div"),F(S9.$$.fragment),g8r=l(),jTe=a("p"),h8r=o("Instantiates one of the base model classes of the library from a configuration."),p8r=l(),Sc=a("p"),_8r=o(`Note:
Loading a model from its configuration file does `),DTe=a("strong"),u8r=o("not"),b8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=a("a"),v8r=o("from_pretrained()"),F8r=o(" to load the model weights."),T8r=l(),F(SC.$$.fragment),M8r=l(),jr=a("div"),F(R9.$$.fragment),E8r=l(),GTe=a("p"),C8r=o("Instantiate one of the base model classes of the library from a pretrained model."),w8r=l(),hn=a("p"),A8r=o("The model class to instantiate is selected based on the "),OTe=a("code"),y8r=o("model_type"),L8r=o(` property of the config object (either
passed as an argument or loaded from `),VTe=a("code"),x8r=o("pretrained_model_name_or_path"),$8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XTe=a("code"),k8r=o("pretrained_model_name_or_path"),S8r=o(":"),R8r=l(),te=a("ul"),RC=a("li"),zTe=a("strong"),P8r=o("albert"),B8r=o(" \u2014 "),HJ=a("a"),I8r=o("FlaxAlbertModel"),N8r=o(" (ALBERT model)"),q8r=l(),PC=a("li"),WTe=a("strong"),j8r=o("bart"),D8r=o(" \u2014 "),UJ=a("a"),G8r=o("FlaxBartModel"),O8r=o(" (BART model)"),V8r=l(),BC=a("li"),QTe=a("strong"),X8r=o("beit"),z8r=o(" \u2014 "),JJ=a("a"),W8r=o("FlaxBeitModel"),Q8r=o(" (BEiT model)"),H8r=l(),IC=a("li"),HTe=a("strong"),U8r=o("bert"),J8r=o(" \u2014 "),YJ=a("a"),Y8r=o("FlaxBertModel"),K8r=o(" (BERT model)"),Z8r=l(),NC=a("li"),UTe=a("strong"),e9r=o("big_bird"),o9r=o(" \u2014 "),KJ=a("a"),r9r=o("FlaxBigBirdModel"),t9r=o(" (BigBird model)"),a9r=l(),qC=a("li"),JTe=a("strong"),n9r=o("blenderbot"),s9r=o(" \u2014 "),ZJ=a("a"),l9r=o("FlaxBlenderbotModel"),i9r=o(" (Blenderbot model)"),d9r=l(),jC=a("li"),YTe=a("strong"),c9r=o("blenderbot-small"),f9r=o(" \u2014 "),eY=a("a"),m9r=o("FlaxBlenderbotSmallModel"),g9r=o(" (BlenderbotSmall model)"),h9r=l(),DC=a("li"),KTe=a("strong"),p9r=o("clip"),_9r=o(" \u2014 "),oY=a("a"),u9r=o("FlaxCLIPModel"),b9r=o(" (CLIP model)"),v9r=l(),GC=a("li"),ZTe=a("strong"),F9r=o("distilbert"),T9r=o(" \u2014 "),rY=a("a"),M9r=o("FlaxDistilBertModel"),E9r=o(" (DistilBERT model)"),C9r=l(),OC=a("li"),e7e=a("strong"),w9r=o("electra"),A9r=o(" \u2014 "),tY=a("a"),y9r=o("FlaxElectraModel"),L9r=o(" (ELECTRA model)"),x9r=l(),VC=a("li"),o7e=a("strong"),$9r=o("gpt2"),k9r=o(" \u2014 "),aY=a("a"),S9r=o("FlaxGPT2Model"),R9r=o(" (OpenAI GPT-2 model)"),P9r=l(),XC=a("li"),r7e=a("strong"),B9r=o("gpt_neo"),I9r=o(" \u2014 "),nY=a("a"),N9r=o("FlaxGPTNeoModel"),q9r=o(" (GPT Neo model)"),j9r=l(),zC=a("li"),t7e=a("strong"),D9r=o("gptj"),G9r=o(" \u2014 "),sY=a("a"),O9r=o("FlaxGPTJModel"),V9r=o(" (GPT-J model)"),X9r=l(),WC=a("li"),a7e=a("strong"),z9r=o("marian"),W9r=o(" \u2014 "),lY=a("a"),Q9r=o("FlaxMarianModel"),H9r=o(" (Marian model)"),U9r=l(),QC=a("li"),n7e=a("strong"),J9r=o("mbart"),Y9r=o(" \u2014 "),iY=a("a"),K9r=o("FlaxMBartModel"),Z9r=o(" (mBART model)"),exr=l(),HC=a("li"),s7e=a("strong"),oxr=o("mt5"),rxr=o(" \u2014 "),dY=a("a"),txr=o("FlaxMT5Model"),axr=o(" (mT5 model)"),nxr=l(),UC=a("li"),l7e=a("strong"),sxr=o("pegasus"),lxr=o(" \u2014 "),cY=a("a"),ixr=o("FlaxPegasusModel"),dxr=o(" (Pegasus model)"),cxr=l(),JC=a("li"),i7e=a("strong"),fxr=o("roberta"),mxr=o(" \u2014 "),fY=a("a"),gxr=o("FlaxRobertaModel"),hxr=o(" (RoBERTa model)"),pxr=l(),YC=a("li"),d7e=a("strong"),_xr=o("roformer"),uxr=o(" \u2014 "),mY=a("a"),bxr=o("FlaxRoFormerModel"),vxr=o(" (RoFormer model)"),Fxr=l(),KC=a("li"),c7e=a("strong"),Txr=o("t5"),Mxr=o(" \u2014 "),gY=a("a"),Exr=o("FlaxT5Model"),Cxr=o(" (T5 model)"),wxr=l(),ZC=a("li"),f7e=a("strong"),Axr=o("vision-text-dual-encoder"),yxr=o(" \u2014 "),hY=a("a"),Lxr=o("FlaxVisionTextDualEncoderModel"),xxr=o(" (VisionTextDualEncoder model)"),$xr=l(),e5=a("li"),m7e=a("strong"),kxr=o("vit"),Sxr=o(" \u2014 "),pY=a("a"),Rxr=o("FlaxViTModel"),Pxr=o(" (ViT model)"),Bxr=l(),o5=a("li"),g7e=a("strong"),Ixr=o("wav2vec2"),Nxr=o(" \u2014 "),_Y=a("a"),qxr=o("FlaxWav2Vec2Model"),jxr=o(" (Wav2Vec2 model)"),Dxr=l(),r5=a("li"),h7e=a("strong"),Gxr=o("xglm"),Oxr=o(" \u2014 "),uY=a("a"),Vxr=o("FlaxXGLMModel"),Xxr=o(" (XGLM model)"),zxr=l(),t5=a("li"),p7e=a("strong"),Wxr=o("xlm-roberta"),Qxr=o(" \u2014 "),bY=a("a"),Hxr=o("FlaxXLMRobertaModel"),Uxr=o(" (XLM-RoBERTa model)"),Jxr=l(),F(a5.$$.fragment),Jje=l(),Rc=a("h2"),n5=a("a"),_7e=a("span"),F(P9.$$.fragment),Yxr=l(),u7e=a("span"),Kxr=o("FlaxAutoModelForCausalLM"),Yje=l(),mr=a("div"),F(B9.$$.fragment),Zxr=l(),Pc=a("p"),e$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vY=a("a"),o$r=o("from_pretrained()"),r$r=o(" class method or the "),FY=a("a"),t$r=o("from_config()"),a$r=o(` class
method.`),n$r=l(),I9=a("p"),s$r=o("This class cannot be instantiated directly using "),b7e=a("code"),l$r=o("__init__()"),i$r=o(" (throws an error)."),d$r=l(),Ot=a("div"),F(N9.$$.fragment),c$r=l(),v7e=a("p"),f$r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),m$r=l(),Bc=a("p"),g$r=o(`Note:
Loading a model from its configuration file does `),F7e=a("strong"),h$r=o("not"),p$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TY=a("a"),_$r=o("from_pretrained()"),u$r=o(" to load the model weights."),b$r=l(),F(s5.$$.fragment),v$r=l(),Dr=a("div"),F(q9.$$.fragment),F$r=l(),T7e=a("p"),T$r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),M$r=l(),pn=a("p"),E$r=o("The model class to instantiate is selected based on the "),M7e=a("code"),C$r=o("model_type"),w$r=o(` property of the config object (either
passed as an argument or loaded from `),E7e=a("code"),A$r=o("pretrained_model_name_or_path"),y$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=a("code"),L$r=o("pretrained_model_name_or_path"),x$r=o(":"),$$r=l(),Re=a("ul"),l5=a("li"),w7e=a("strong"),k$r=o("bart"),S$r=o(" \u2014 "),MY=a("a"),R$r=o("FlaxBartForCausalLM"),P$r=o(" (BART model)"),B$r=l(),i5=a("li"),A7e=a("strong"),I$r=o("bert"),N$r=o(" \u2014 "),EY=a("a"),q$r=o("FlaxBertForCausalLM"),j$r=o(" (BERT model)"),D$r=l(),d5=a("li"),y7e=a("strong"),G$r=o("big_bird"),O$r=o(" \u2014 "),CY=a("a"),V$r=o("FlaxBigBirdForCausalLM"),X$r=o(" (BigBird model)"),z$r=l(),c5=a("li"),L7e=a("strong"),W$r=o("electra"),Q$r=o(" \u2014 "),wY=a("a"),H$r=o("FlaxElectraForCausalLM"),U$r=o(" (ELECTRA model)"),J$r=l(),f5=a("li"),x7e=a("strong"),Y$r=o("gpt2"),K$r=o(" \u2014 "),AY=a("a"),Z$r=o("FlaxGPT2LMHeadModel"),ekr=o(" (OpenAI GPT-2 model)"),okr=l(),m5=a("li"),$7e=a("strong"),rkr=o("gpt_neo"),tkr=o(" \u2014 "),yY=a("a"),akr=o("FlaxGPTNeoForCausalLM"),nkr=o(" (GPT Neo model)"),skr=l(),g5=a("li"),k7e=a("strong"),lkr=o("gptj"),ikr=o(" \u2014 "),LY=a("a"),dkr=o("FlaxGPTJForCausalLM"),ckr=o(" (GPT-J model)"),fkr=l(),h5=a("li"),S7e=a("strong"),mkr=o("roberta"),gkr=o(" \u2014 "),xY=a("a"),hkr=o("FlaxRobertaForCausalLM"),pkr=o(" (RoBERTa model)"),_kr=l(),p5=a("li"),R7e=a("strong"),ukr=o("xglm"),bkr=o(" \u2014 "),$Y=a("a"),vkr=o("FlaxXGLMForCausalLM"),Fkr=o(" (XGLM model)"),Tkr=l(),F(_5.$$.fragment),Kje=l(),Ic=a("h2"),u5=a("a"),P7e=a("span"),F(j9.$$.fragment),Mkr=l(),B7e=a("span"),Ekr=o("FlaxAutoModelForPreTraining"),Zje=l(),gr=a("div"),F(D9.$$.fragment),Ckr=l(),Nc=a("p"),wkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),kY=a("a"),Akr=o("from_pretrained()"),ykr=o(" class method or the "),SY=a("a"),Lkr=o("from_config()"),xkr=o(` class
method.`),$kr=l(),G9=a("p"),kkr=o("This class cannot be instantiated directly using "),I7e=a("code"),Skr=o("__init__()"),Rkr=o(" (throws an error)."),Pkr=l(),Vt=a("div"),F(O9.$$.fragment),Bkr=l(),N7e=a("p"),Ikr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Nkr=l(),qc=a("p"),qkr=o(`Note:
Loading a model from its configuration file does `),q7e=a("strong"),jkr=o("not"),Dkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RY=a("a"),Gkr=o("from_pretrained()"),Okr=o(" to load the model weights."),Vkr=l(),F(b5.$$.fragment),Xkr=l(),Gr=a("div"),F(V9.$$.fragment),zkr=l(),j7e=a("p"),Wkr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Qkr=l(),_n=a("p"),Hkr=o("The model class to instantiate is selected based on the "),D7e=a("code"),Ukr=o("model_type"),Jkr=o(` property of the config object (either
passed as an argument or loaded from `),G7e=a("code"),Ykr=o("pretrained_model_name_or_path"),Kkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=a("code"),Zkr=o("pretrained_model_name_or_path"),eSr=o(":"),oSr=l(),Ee=a("ul"),v5=a("li"),V7e=a("strong"),rSr=o("albert"),tSr=o(" \u2014 "),PY=a("a"),aSr=o("FlaxAlbertForPreTraining"),nSr=o(" (ALBERT model)"),sSr=l(),F5=a("li"),X7e=a("strong"),lSr=o("bart"),iSr=o(" \u2014 "),BY=a("a"),dSr=o("FlaxBartForConditionalGeneration"),cSr=o(" (BART model)"),fSr=l(),T5=a("li"),z7e=a("strong"),mSr=o("bert"),gSr=o(" \u2014 "),IY=a("a"),hSr=o("FlaxBertForPreTraining"),pSr=o(" (BERT model)"),_Sr=l(),M5=a("li"),W7e=a("strong"),uSr=o("big_bird"),bSr=o(" \u2014 "),NY=a("a"),vSr=o("FlaxBigBirdForPreTraining"),FSr=o(" (BigBird model)"),TSr=l(),E5=a("li"),Q7e=a("strong"),MSr=o("electra"),ESr=o(" \u2014 "),qY=a("a"),CSr=o("FlaxElectraForPreTraining"),wSr=o(" (ELECTRA model)"),ASr=l(),C5=a("li"),H7e=a("strong"),ySr=o("mbart"),LSr=o(" \u2014 "),jY=a("a"),xSr=o("FlaxMBartForConditionalGeneration"),$Sr=o(" (mBART model)"),kSr=l(),w5=a("li"),U7e=a("strong"),SSr=o("mt5"),RSr=o(" \u2014 "),DY=a("a"),PSr=o("FlaxMT5ForConditionalGeneration"),BSr=o(" (mT5 model)"),ISr=l(),A5=a("li"),J7e=a("strong"),NSr=o("roberta"),qSr=o(" \u2014 "),GY=a("a"),jSr=o("FlaxRobertaForMaskedLM"),DSr=o(" (RoBERTa model)"),GSr=l(),y5=a("li"),Y7e=a("strong"),OSr=o("roformer"),VSr=o(" \u2014 "),OY=a("a"),XSr=o("FlaxRoFormerForMaskedLM"),zSr=o(" (RoFormer model)"),WSr=l(),L5=a("li"),K7e=a("strong"),QSr=o("t5"),HSr=o(" \u2014 "),VY=a("a"),USr=o("FlaxT5ForConditionalGeneration"),JSr=o(" (T5 model)"),YSr=l(),x5=a("li"),Z7e=a("strong"),KSr=o("wav2vec2"),ZSr=o(" \u2014 "),XY=a("a"),eRr=o("FlaxWav2Vec2ForPreTraining"),oRr=o(" (Wav2Vec2 model)"),rRr=l(),$5=a("li"),eMe=a("strong"),tRr=o("xlm-roberta"),aRr=o(" \u2014 "),zY=a("a"),nRr=o("FlaxXLMRobertaForMaskedLM"),sRr=o(" (XLM-RoBERTa model)"),lRr=l(),F(k5.$$.fragment),eDe=l(),jc=a("h2"),S5=a("a"),oMe=a("span"),F(X9.$$.fragment),iRr=l(),rMe=a("span"),dRr=o("FlaxAutoModelForMaskedLM"),oDe=l(),hr=a("div"),F(z9.$$.fragment),cRr=l(),Dc=a("p"),fRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),WY=a("a"),mRr=o("from_pretrained()"),gRr=o(" class method or the "),QY=a("a"),hRr=o("from_config()"),pRr=o(` class
method.`),_Rr=l(),W9=a("p"),uRr=o("This class cannot be instantiated directly using "),tMe=a("code"),bRr=o("__init__()"),vRr=o(" (throws an error)."),FRr=l(),Xt=a("div"),F(Q9.$$.fragment),TRr=l(),aMe=a("p"),MRr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),ERr=l(),Gc=a("p"),CRr=o(`Note:
Loading a model from its configuration file does `),nMe=a("strong"),wRr=o("not"),ARr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HY=a("a"),yRr=o("from_pretrained()"),LRr=o(" to load the model weights."),xRr=l(),F(R5.$$.fragment),$Rr=l(),Or=a("div"),F(H9.$$.fragment),kRr=l(),sMe=a("p"),SRr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),RRr=l(),un=a("p"),PRr=o("The model class to instantiate is selected based on the "),lMe=a("code"),BRr=o("model_type"),IRr=o(` property of the config object (either
passed as an argument or loaded from `),iMe=a("code"),NRr=o("pretrained_model_name_or_path"),qRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dMe=a("code"),jRr=o("pretrained_model_name_or_path"),DRr=o(":"),GRr=l(),Le=a("ul"),P5=a("li"),cMe=a("strong"),ORr=o("albert"),VRr=o(" \u2014 "),UY=a("a"),XRr=o("FlaxAlbertForMaskedLM"),zRr=o(" (ALBERT model)"),WRr=l(),B5=a("li"),fMe=a("strong"),QRr=o("bart"),HRr=o(" \u2014 "),JY=a("a"),URr=o("FlaxBartForConditionalGeneration"),JRr=o(" (BART model)"),YRr=l(),I5=a("li"),mMe=a("strong"),KRr=o("bert"),ZRr=o(" \u2014 "),YY=a("a"),ePr=o("FlaxBertForMaskedLM"),oPr=o(" (BERT model)"),rPr=l(),N5=a("li"),gMe=a("strong"),tPr=o("big_bird"),aPr=o(" \u2014 "),KY=a("a"),nPr=o("FlaxBigBirdForMaskedLM"),sPr=o(" (BigBird model)"),lPr=l(),q5=a("li"),hMe=a("strong"),iPr=o("distilbert"),dPr=o(" \u2014 "),ZY=a("a"),cPr=o("FlaxDistilBertForMaskedLM"),fPr=o(" (DistilBERT model)"),mPr=l(),j5=a("li"),pMe=a("strong"),gPr=o("electra"),hPr=o(" \u2014 "),eK=a("a"),pPr=o("FlaxElectraForMaskedLM"),_Pr=o(" (ELECTRA model)"),uPr=l(),D5=a("li"),_Me=a("strong"),bPr=o("mbart"),vPr=o(" \u2014 "),oK=a("a"),FPr=o("FlaxMBartForConditionalGeneration"),TPr=o(" (mBART model)"),MPr=l(),G5=a("li"),uMe=a("strong"),EPr=o("roberta"),CPr=o(" \u2014 "),rK=a("a"),wPr=o("FlaxRobertaForMaskedLM"),APr=o(" (RoBERTa model)"),yPr=l(),O5=a("li"),bMe=a("strong"),LPr=o("roformer"),xPr=o(" \u2014 "),tK=a("a"),$Pr=o("FlaxRoFormerForMaskedLM"),kPr=o(" (RoFormer model)"),SPr=l(),V5=a("li"),vMe=a("strong"),RPr=o("xlm-roberta"),PPr=o(" \u2014 "),aK=a("a"),BPr=o("FlaxXLMRobertaForMaskedLM"),IPr=o(" (XLM-RoBERTa model)"),NPr=l(),F(X5.$$.fragment),rDe=l(),Oc=a("h2"),z5=a("a"),FMe=a("span"),F(U9.$$.fragment),qPr=l(),TMe=a("span"),jPr=o("FlaxAutoModelForSeq2SeqLM"),tDe=l(),pr=a("div"),F(J9.$$.fragment),DPr=l(),Vc=a("p"),GPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),nK=a("a"),OPr=o("from_pretrained()"),VPr=o(" class method or the "),sK=a("a"),XPr=o("from_config()"),zPr=o(` class
method.`),WPr=l(),Y9=a("p"),QPr=o("This class cannot be instantiated directly using "),MMe=a("code"),HPr=o("__init__()"),UPr=o(" (throws an error)."),JPr=l(),zt=a("div"),F(K9.$$.fragment),YPr=l(),EMe=a("p"),KPr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),ZPr=l(),Xc=a("p"),eBr=o(`Note:
Loading a model from its configuration file does `),CMe=a("strong"),oBr=o("not"),rBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=a("a"),tBr=o("from_pretrained()"),aBr=o(" to load the model weights."),nBr=l(),F(W5.$$.fragment),sBr=l(),Vr=a("div"),F(Z9.$$.fragment),lBr=l(),wMe=a("p"),iBr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),dBr=l(),bn=a("p"),cBr=o("The model class to instantiate is selected based on the "),AMe=a("code"),fBr=o("model_type"),mBr=o(` property of the config object (either
passed as an argument or loaded from `),yMe=a("code"),gBr=o("pretrained_model_name_or_path"),hBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LMe=a("code"),pBr=o("pretrained_model_name_or_path"),_Br=o(":"),uBr=l(),Pe=a("ul"),Q5=a("li"),xMe=a("strong"),bBr=o("bart"),vBr=o(" \u2014 "),iK=a("a"),FBr=o("FlaxBartForConditionalGeneration"),TBr=o(" (BART model)"),MBr=l(),H5=a("li"),$Me=a("strong"),EBr=o("blenderbot"),CBr=o(" \u2014 "),dK=a("a"),wBr=o("FlaxBlenderbotForConditionalGeneration"),ABr=o(" (Blenderbot model)"),yBr=l(),U5=a("li"),kMe=a("strong"),LBr=o("blenderbot-small"),xBr=o(" \u2014 "),cK=a("a"),$Br=o("FlaxBlenderbotSmallForConditionalGeneration"),kBr=o(" (BlenderbotSmall model)"),SBr=l(),J5=a("li"),SMe=a("strong"),RBr=o("encoder-decoder"),PBr=o(" \u2014 "),fK=a("a"),BBr=o("FlaxEncoderDecoderModel"),IBr=o(" (Encoder decoder model)"),NBr=l(),Y5=a("li"),RMe=a("strong"),qBr=o("marian"),jBr=o(" \u2014 "),mK=a("a"),DBr=o("FlaxMarianMTModel"),GBr=o(" (Marian model)"),OBr=l(),K5=a("li"),PMe=a("strong"),VBr=o("mbart"),XBr=o(" \u2014 "),gK=a("a"),zBr=o("FlaxMBartForConditionalGeneration"),WBr=o(" (mBART model)"),QBr=l(),Z5=a("li"),BMe=a("strong"),HBr=o("mt5"),UBr=o(" \u2014 "),hK=a("a"),JBr=o("FlaxMT5ForConditionalGeneration"),YBr=o(" (mT5 model)"),KBr=l(),ew=a("li"),IMe=a("strong"),ZBr=o("pegasus"),eIr=o(" \u2014 "),pK=a("a"),oIr=o("FlaxPegasusForConditionalGeneration"),rIr=o(" (Pegasus model)"),tIr=l(),ow=a("li"),NMe=a("strong"),aIr=o("t5"),nIr=o(" \u2014 "),_K=a("a"),sIr=o("FlaxT5ForConditionalGeneration"),lIr=o(" (T5 model)"),iIr=l(),F(rw.$$.fragment),aDe=l(),zc=a("h2"),tw=a("a"),qMe=a("span"),F(ex.$$.fragment),dIr=l(),jMe=a("span"),cIr=o("FlaxAutoModelForSequenceClassification"),nDe=l(),_r=a("div"),F(ox.$$.fragment),fIr=l(),Wc=a("p"),mIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uK=a("a"),gIr=o("from_pretrained()"),hIr=o(" class method or the "),bK=a("a"),pIr=o("from_config()"),_Ir=o(` class
method.`),uIr=l(),rx=a("p"),bIr=o("This class cannot be instantiated directly using "),DMe=a("code"),vIr=o("__init__()"),FIr=o(" (throws an error)."),TIr=l(),Wt=a("div"),F(tx.$$.fragment),MIr=l(),GMe=a("p"),EIr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),CIr=l(),Qc=a("p"),wIr=o(`Note:
Loading a model from its configuration file does `),OMe=a("strong"),AIr=o("not"),yIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=a("a"),LIr=o("from_pretrained()"),xIr=o(" to load the model weights."),$Ir=l(),F(aw.$$.fragment),kIr=l(),Xr=a("div"),F(ax.$$.fragment),SIr=l(),VMe=a("p"),RIr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),PIr=l(),vn=a("p"),BIr=o("The model class to instantiate is selected based on the "),XMe=a("code"),IIr=o("model_type"),NIr=o(` property of the config object (either
passed as an argument or loaded from `),zMe=a("code"),qIr=o("pretrained_model_name_or_path"),jIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WMe=a("code"),DIr=o("pretrained_model_name_or_path"),GIr=o(":"),OIr=l(),xe=a("ul"),nw=a("li"),QMe=a("strong"),VIr=o("albert"),XIr=o(" \u2014 "),FK=a("a"),zIr=o("FlaxAlbertForSequenceClassification"),WIr=o(" (ALBERT model)"),QIr=l(),sw=a("li"),HMe=a("strong"),HIr=o("bart"),UIr=o(" \u2014 "),TK=a("a"),JIr=o("FlaxBartForSequenceClassification"),YIr=o(" (BART model)"),KIr=l(),lw=a("li"),UMe=a("strong"),ZIr=o("bert"),eNr=o(" \u2014 "),MK=a("a"),oNr=o("FlaxBertForSequenceClassification"),rNr=o(" (BERT model)"),tNr=l(),iw=a("li"),JMe=a("strong"),aNr=o("big_bird"),nNr=o(" \u2014 "),EK=a("a"),sNr=o("FlaxBigBirdForSequenceClassification"),lNr=o(" (BigBird model)"),iNr=l(),dw=a("li"),YMe=a("strong"),dNr=o("distilbert"),cNr=o(" \u2014 "),CK=a("a"),fNr=o("FlaxDistilBertForSequenceClassification"),mNr=o(" (DistilBERT model)"),gNr=l(),cw=a("li"),KMe=a("strong"),hNr=o("electra"),pNr=o(" \u2014 "),wK=a("a"),_Nr=o("FlaxElectraForSequenceClassification"),uNr=o(" (ELECTRA model)"),bNr=l(),fw=a("li"),ZMe=a("strong"),vNr=o("mbart"),FNr=o(" \u2014 "),AK=a("a"),TNr=o("FlaxMBartForSequenceClassification"),MNr=o(" (mBART model)"),ENr=l(),mw=a("li"),eEe=a("strong"),CNr=o("roberta"),wNr=o(" \u2014 "),yK=a("a"),ANr=o("FlaxRobertaForSequenceClassification"),yNr=o(" (RoBERTa model)"),LNr=l(),gw=a("li"),oEe=a("strong"),xNr=o("roformer"),$Nr=o(" \u2014 "),LK=a("a"),kNr=o("FlaxRoFormerForSequenceClassification"),SNr=o(" (RoFormer model)"),RNr=l(),hw=a("li"),rEe=a("strong"),PNr=o("xlm-roberta"),BNr=o(" \u2014 "),xK=a("a"),INr=o("FlaxXLMRobertaForSequenceClassification"),NNr=o(" (XLM-RoBERTa model)"),qNr=l(),F(pw.$$.fragment),sDe=l(),Hc=a("h2"),_w=a("a"),tEe=a("span"),F(nx.$$.fragment),jNr=l(),aEe=a("span"),DNr=o("FlaxAutoModelForQuestionAnswering"),lDe=l(),ur=a("div"),F(sx.$$.fragment),GNr=l(),Uc=a("p"),ONr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$K=a("a"),VNr=o("from_pretrained()"),XNr=o(" class method or the "),kK=a("a"),zNr=o("from_config()"),WNr=o(` class
method.`),QNr=l(),lx=a("p"),HNr=o("This class cannot be instantiated directly using "),nEe=a("code"),UNr=o("__init__()"),JNr=o(" (throws an error)."),YNr=l(),Qt=a("div"),F(ix.$$.fragment),KNr=l(),sEe=a("p"),ZNr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),eqr=l(),Jc=a("p"),oqr=o(`Note:
Loading a model from its configuration file does `),lEe=a("strong"),rqr=o("not"),tqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),aqr=o("from_pretrained()"),nqr=o(" to load the model weights."),sqr=l(),F(uw.$$.fragment),lqr=l(),zr=a("div"),F(dx.$$.fragment),iqr=l(),iEe=a("p"),dqr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),cqr=l(),Fn=a("p"),fqr=o("The model class to instantiate is selected based on the "),dEe=a("code"),mqr=o("model_type"),gqr=o(` property of the config object (either
passed as an argument or loaded from `),cEe=a("code"),hqr=o("pretrained_model_name_or_path"),pqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=a("code"),_qr=o("pretrained_model_name_or_path"),uqr=o(":"),bqr=l(),$e=a("ul"),bw=a("li"),mEe=a("strong"),vqr=o("albert"),Fqr=o(" \u2014 "),RK=a("a"),Tqr=o("FlaxAlbertForQuestionAnswering"),Mqr=o(" (ALBERT model)"),Eqr=l(),vw=a("li"),gEe=a("strong"),Cqr=o("bart"),wqr=o(" \u2014 "),PK=a("a"),Aqr=o("FlaxBartForQuestionAnswering"),yqr=o(" (BART model)"),Lqr=l(),Fw=a("li"),hEe=a("strong"),xqr=o("bert"),$qr=o(" \u2014 "),BK=a("a"),kqr=o("FlaxBertForQuestionAnswering"),Sqr=o(" (BERT model)"),Rqr=l(),Tw=a("li"),pEe=a("strong"),Pqr=o("big_bird"),Bqr=o(" \u2014 "),IK=a("a"),Iqr=o("FlaxBigBirdForQuestionAnswering"),Nqr=o(" (BigBird model)"),qqr=l(),Mw=a("li"),_Ee=a("strong"),jqr=o("distilbert"),Dqr=o(" \u2014 "),NK=a("a"),Gqr=o("FlaxDistilBertForQuestionAnswering"),Oqr=o(" (DistilBERT model)"),Vqr=l(),Ew=a("li"),uEe=a("strong"),Xqr=o("electra"),zqr=o(" \u2014 "),qK=a("a"),Wqr=o("FlaxElectraForQuestionAnswering"),Qqr=o(" (ELECTRA model)"),Hqr=l(),Cw=a("li"),bEe=a("strong"),Uqr=o("mbart"),Jqr=o(" \u2014 "),jK=a("a"),Yqr=o("FlaxMBartForQuestionAnswering"),Kqr=o(" (mBART model)"),Zqr=l(),ww=a("li"),vEe=a("strong"),ejr=o("roberta"),ojr=o(" \u2014 "),DK=a("a"),rjr=o("FlaxRobertaForQuestionAnswering"),tjr=o(" (RoBERTa model)"),ajr=l(),Aw=a("li"),FEe=a("strong"),njr=o("roformer"),sjr=o(" \u2014 "),GK=a("a"),ljr=o("FlaxRoFormerForQuestionAnswering"),ijr=o(" (RoFormer model)"),djr=l(),yw=a("li"),TEe=a("strong"),cjr=o("xlm-roberta"),fjr=o(" \u2014 "),OK=a("a"),mjr=o("FlaxXLMRobertaForQuestionAnswering"),gjr=o(" (XLM-RoBERTa model)"),hjr=l(),F(Lw.$$.fragment),iDe=l(),Yc=a("h2"),xw=a("a"),MEe=a("span"),F(cx.$$.fragment),pjr=l(),EEe=a("span"),_jr=o("FlaxAutoModelForTokenClassification"),dDe=l(),br=a("div"),F(fx.$$.fragment),ujr=l(),Kc=a("p"),bjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),VK=a("a"),vjr=o("from_pretrained()"),Fjr=o(" class method or the "),XK=a("a"),Tjr=o("from_config()"),Mjr=o(` class
method.`),Ejr=l(),mx=a("p"),Cjr=o("This class cannot be instantiated directly using "),CEe=a("code"),wjr=o("__init__()"),Ajr=o(" (throws an error)."),yjr=l(),Ht=a("div"),F(gx.$$.fragment),Ljr=l(),wEe=a("p"),xjr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),$jr=l(),Zc=a("p"),kjr=o(`Note:
Loading a model from its configuration file does `),AEe=a("strong"),Sjr=o("not"),Rjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zK=a("a"),Pjr=o("from_pretrained()"),Bjr=o(" to load the model weights."),Ijr=l(),F($w.$$.fragment),Njr=l(),Wr=a("div"),F(hx.$$.fragment),qjr=l(),yEe=a("p"),jjr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Djr=l(),Tn=a("p"),Gjr=o("The model class to instantiate is selected based on the "),LEe=a("code"),Ojr=o("model_type"),Vjr=o(` property of the config object (either
passed as an argument or loaded from `),xEe=a("code"),Xjr=o("pretrained_model_name_or_path"),zjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ee=a("code"),Wjr=o("pretrained_model_name_or_path"),Qjr=o(":"),Hjr=l(),De=a("ul"),kw=a("li"),kEe=a("strong"),Ujr=o("albert"),Jjr=o(" \u2014 "),WK=a("a"),Yjr=o("FlaxAlbertForTokenClassification"),Kjr=o(" (ALBERT model)"),Zjr=l(),Sw=a("li"),SEe=a("strong"),eDr=o("bert"),oDr=o(" \u2014 "),QK=a("a"),rDr=o("FlaxBertForTokenClassification"),tDr=o(" (BERT model)"),aDr=l(),Rw=a("li"),REe=a("strong"),nDr=o("big_bird"),sDr=o(" \u2014 "),HK=a("a"),lDr=o("FlaxBigBirdForTokenClassification"),iDr=o(" (BigBird model)"),dDr=l(),Pw=a("li"),PEe=a("strong"),cDr=o("distilbert"),fDr=o(" \u2014 "),UK=a("a"),mDr=o("FlaxDistilBertForTokenClassification"),gDr=o(" (DistilBERT model)"),hDr=l(),Bw=a("li"),BEe=a("strong"),pDr=o("electra"),_Dr=o(" \u2014 "),JK=a("a"),uDr=o("FlaxElectraForTokenClassification"),bDr=o(" (ELECTRA model)"),vDr=l(),Iw=a("li"),IEe=a("strong"),FDr=o("roberta"),TDr=o(" \u2014 "),YK=a("a"),MDr=o("FlaxRobertaForTokenClassification"),EDr=o(" (RoBERTa model)"),CDr=l(),Nw=a("li"),NEe=a("strong"),wDr=o("roformer"),ADr=o(" \u2014 "),KK=a("a"),yDr=o("FlaxRoFormerForTokenClassification"),LDr=o(" (RoFormer model)"),xDr=l(),qw=a("li"),qEe=a("strong"),$Dr=o("xlm-roberta"),kDr=o(" \u2014 "),ZK=a("a"),SDr=o("FlaxXLMRobertaForTokenClassification"),RDr=o(" (XLM-RoBERTa model)"),PDr=l(),F(jw.$$.fragment),cDe=l(),ef=a("h2"),Dw=a("a"),jEe=a("span"),F(px.$$.fragment),BDr=l(),DEe=a("span"),IDr=o("FlaxAutoModelForMultipleChoice"),fDe=l(),vr=a("div"),F(_x.$$.fragment),NDr=l(),of=a("p"),qDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),eZ=a("a"),jDr=o("from_pretrained()"),DDr=o(" class method or the "),oZ=a("a"),GDr=o("from_config()"),ODr=o(` class
method.`),VDr=l(),ux=a("p"),XDr=o("This class cannot be instantiated directly using "),GEe=a("code"),zDr=o("__init__()"),WDr=o(" (throws an error)."),QDr=l(),Ut=a("div"),F(bx.$$.fragment),HDr=l(),OEe=a("p"),UDr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),JDr=l(),rf=a("p"),YDr=o(`Note:
Loading a model from its configuration file does `),VEe=a("strong"),KDr=o("not"),ZDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rZ=a("a"),eGr=o("from_pretrained()"),oGr=o(" to load the model weights."),rGr=l(),F(Gw.$$.fragment),tGr=l(),Qr=a("div"),F(vx.$$.fragment),aGr=l(),XEe=a("p"),nGr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),sGr=l(),Mn=a("p"),lGr=o("The model class to instantiate is selected based on the "),zEe=a("code"),iGr=o("model_type"),dGr=o(` property of the config object (either
passed as an argument or loaded from `),WEe=a("code"),cGr=o("pretrained_model_name_or_path"),fGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=a("code"),mGr=o("pretrained_model_name_or_path"),gGr=o(":"),hGr=l(),Ge=a("ul"),Ow=a("li"),HEe=a("strong"),pGr=o("albert"),_Gr=o(" \u2014 "),tZ=a("a"),uGr=o("FlaxAlbertForMultipleChoice"),bGr=o(" (ALBERT model)"),vGr=l(),Vw=a("li"),UEe=a("strong"),FGr=o("bert"),TGr=o(" \u2014 "),aZ=a("a"),MGr=o("FlaxBertForMultipleChoice"),EGr=o(" (BERT model)"),CGr=l(),Xw=a("li"),JEe=a("strong"),wGr=o("big_bird"),AGr=o(" \u2014 "),nZ=a("a"),yGr=o("FlaxBigBirdForMultipleChoice"),LGr=o(" (BigBird model)"),xGr=l(),zw=a("li"),YEe=a("strong"),$Gr=o("distilbert"),kGr=o(" \u2014 "),sZ=a("a"),SGr=o("FlaxDistilBertForMultipleChoice"),RGr=o(" (DistilBERT model)"),PGr=l(),Ww=a("li"),KEe=a("strong"),BGr=o("electra"),IGr=o(" \u2014 "),lZ=a("a"),NGr=o("FlaxElectraForMultipleChoice"),qGr=o(" (ELECTRA model)"),jGr=l(),Qw=a("li"),ZEe=a("strong"),DGr=o("roberta"),GGr=o(" \u2014 "),iZ=a("a"),OGr=o("FlaxRobertaForMultipleChoice"),VGr=o(" (RoBERTa model)"),XGr=l(),Hw=a("li"),eCe=a("strong"),zGr=o("roformer"),WGr=o(" \u2014 "),dZ=a("a"),QGr=o("FlaxRoFormerForMultipleChoice"),HGr=o(" (RoFormer model)"),UGr=l(),Uw=a("li"),oCe=a("strong"),JGr=o("xlm-roberta"),YGr=o(" \u2014 "),cZ=a("a"),KGr=o("FlaxXLMRobertaForMultipleChoice"),ZGr=o(" (XLM-RoBERTa model)"),eOr=l(),F(Jw.$$.fragment),mDe=l(),tf=a("h2"),Yw=a("a"),rCe=a("span"),F(Fx.$$.fragment),oOr=l(),tCe=a("span"),rOr=o("FlaxAutoModelForNextSentencePrediction"),gDe=l(),Fr=a("div"),F(Tx.$$.fragment),tOr=l(),af=a("p"),aOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fZ=a("a"),nOr=o("from_pretrained()"),sOr=o(" class method or the "),mZ=a("a"),lOr=o("from_config()"),iOr=o(` class
method.`),dOr=l(),Mx=a("p"),cOr=o("This class cannot be instantiated directly using "),aCe=a("code"),fOr=o("__init__()"),mOr=o(" (throws an error)."),gOr=l(),Jt=a("div"),F(Ex.$$.fragment),hOr=l(),nCe=a("p"),pOr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),_Or=l(),nf=a("p"),uOr=o(`Note:
Loading a model from its configuration file does `),sCe=a("strong"),bOr=o("not"),vOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=a("a"),FOr=o("from_pretrained()"),TOr=o(" to load the model weights."),MOr=l(),F(Kw.$$.fragment),EOr=l(),Hr=a("div"),F(Cx.$$.fragment),COr=l(),lCe=a("p"),wOr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),AOr=l(),En=a("p"),yOr=o("The model class to instantiate is selected based on the "),iCe=a("code"),LOr=o("model_type"),xOr=o(` property of the config object (either
passed as an argument or loaded from `),dCe=a("code"),$Or=o("pretrained_model_name_or_path"),kOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=a("code"),SOr=o("pretrained_model_name_or_path"),ROr=o(":"),POr=l(),fCe=a("ul"),Zw=a("li"),mCe=a("strong"),BOr=o("bert"),IOr=o(" \u2014 "),hZ=a("a"),NOr=o("FlaxBertForNextSentencePrediction"),qOr=o(" (BERT model)"),jOr=l(),F(e0.$$.fragment),hDe=l(),sf=a("h2"),o0=a("a"),gCe=a("span"),F(wx.$$.fragment),DOr=l(),hCe=a("span"),GOr=o("FlaxAutoModelForImageClassification"),pDe=l(),Tr=a("div"),F(Ax.$$.fragment),OOr=l(),lf=a("p"),VOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),pZ=a("a"),XOr=o("from_pretrained()"),zOr=o(" class method or the "),_Z=a("a"),WOr=o("from_config()"),QOr=o(` class
method.`),HOr=l(),yx=a("p"),UOr=o("This class cannot be instantiated directly using "),pCe=a("code"),JOr=o("__init__()"),YOr=o(" (throws an error)."),KOr=l(),Yt=a("div"),F(Lx.$$.fragment),ZOr=l(),_Ce=a("p"),eVr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),oVr=l(),df=a("p"),rVr=o(`Note:
Loading a model from its configuration file does `),uCe=a("strong"),tVr=o("not"),aVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uZ=a("a"),nVr=o("from_pretrained()"),sVr=o(" to load the model weights."),lVr=l(),F(r0.$$.fragment),iVr=l(),Ur=a("div"),F(xx.$$.fragment),dVr=l(),bCe=a("p"),cVr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),fVr=l(),Cn=a("p"),mVr=o("The model class to instantiate is selected based on the "),vCe=a("code"),gVr=o("model_type"),hVr=o(` property of the config object (either
passed as an argument or loaded from `),FCe=a("code"),pVr=o("pretrained_model_name_or_path"),_Vr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=a("code"),uVr=o("pretrained_model_name_or_path"),bVr=o(":"),vVr=l(),$x=a("ul"),t0=a("li"),MCe=a("strong"),FVr=o("beit"),TVr=o(" \u2014 "),bZ=a("a"),MVr=o("FlaxBeitForImageClassification"),EVr=o(" (BEiT model)"),CVr=l(),a0=a("li"),ECe=a("strong"),wVr=o("vit"),AVr=o(" \u2014 "),vZ=a("a"),yVr=o("FlaxViTForImageClassification"),LVr=o(" (ViT model)"),xVr=l(),F(n0.$$.fragment),_De=l(),cf=a("h2"),s0=a("a"),CCe=a("span"),F(kx.$$.fragment),$Vr=l(),wCe=a("span"),kVr=o("FlaxAutoModelForVision2Seq"),uDe=l(),Mr=a("div"),F(Sx.$$.fragment),SVr=l(),ff=a("p"),RVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),FZ=a("a"),PVr=o("from_pretrained()"),BVr=o(" class method or the "),TZ=a("a"),IVr=o("from_config()"),NVr=o(` class
method.`),qVr=l(),Rx=a("p"),jVr=o("This class cannot be instantiated directly using "),ACe=a("code"),DVr=o("__init__()"),GVr=o(" (throws an error)."),OVr=l(),Kt=a("div"),F(Px.$$.fragment),VVr=l(),yCe=a("p"),XVr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zVr=l(),mf=a("p"),WVr=o(`Note:
Loading a model from its configuration file does `),LCe=a("strong"),QVr=o("not"),HVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MZ=a("a"),UVr=o("from_pretrained()"),JVr=o(" to load the model weights."),YVr=l(),F(l0.$$.fragment),KVr=l(),Jr=a("div"),F(Bx.$$.fragment),ZVr=l(),xCe=a("p"),eXr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),oXr=l(),wn=a("p"),rXr=o("The model class to instantiate is selected based on the "),$Ce=a("code"),tXr=o("model_type"),aXr=o(` property of the config object (either
passed as an argument or loaded from `),kCe=a("code"),nXr=o("pretrained_model_name_or_path"),sXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SCe=a("code"),lXr=o("pretrained_model_name_or_path"),iXr=o(":"),dXr=l(),RCe=a("ul"),i0=a("li"),PCe=a("strong"),cXr=o("vision-encoder-decoder"),fXr=o(" \u2014 "),EZ=a("a"),mXr=o("FlaxVisionEncoderDecoderModel"),gXr=o(" (Vision Encoder decoder model)"),hXr=l(),F(d0.$$.fragment),this.h()},l(f){const u=tkt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var Ix=s(p);m=n(Ix,"A",{id:!0,class:!0,href:!0});var BCe=s(m);_=n(BCe,"SPAN",{});var ICe=s(_);T(d.$$.fragment,ICe),ICe.forEach(t),BCe.forEach(t),h=i(Ix),Mo=n(Ix,"SPAN",{});var NCe=s(Mo);mi=r(NCe,"Auto Classes"),NCe.forEach(t),Ix.forEach(t),_f=i(f),rt=n(f,"P",{});var Nx=s(rt);gi=r(Nx,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),hi=n(Nx,"CODE",{});var qCe=s(hi);yA=r(qCe,"from_pretrained()"),qCe.forEach(t),uf=r(Nx,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Nx.forEach(t),je=i(f),We=n(f,"P",{});var An=s(We);pi=r(An,"Instantiating one of "),yn=n(An,"A",{href:!0});var jCe=s(yn);LA=r(jCe,"AutoConfig"),jCe.forEach(t),Ln=r(An,", "),xn=n(An,"A",{href:!0});var DCe=s(xn);xA=r(DCe,"AutoModel"),DCe.forEach(t),_i=r(An,`, and
`),$n=n(An,"A",{href:!0});var GCe=s($n);$A=r(GCe,"AutoTokenizer"),GCe.forEach(t),ui=r(An," will directly create a class of the relevant architecture. For instance"),An.forEach(t),bf=i(f),T(Ca.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var qx=s(Ae);J$=r(qx,"will create a model that is an instance of "),bi=n(qx,"A",{href:!0});var OCe=s(bi);Y$=r(OCe,"BertModel"),OCe.forEach(t),K$=r(qx,"."),qx.forEach(t),Eo=i(f),wa=n(f,"P",{});var jx=s(wa);Z$=r(jx,"There is one class of "),vf=n(jx,"CODE",{});var VCe=s(vf);ek=r(VCe,"AutoModel"),VCe.forEach(t),AOe=r(jx," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jx.forEach(t),pqe=i(f),vi=n(f,"H2",{class:!0});var Dx=s(vi);Ff=n(Dx,"A",{id:!0,class:!0,href:!0});var XCe=s(Ff);_oe=n(XCe,"SPAN",{});var zCe=s(_oe);T(kA.$$.fragment,zCe),zCe.forEach(t),XCe.forEach(t),yOe=i(Dx),uoe=n(Dx,"SPAN",{});var WCe=s(uoe);LOe=r(WCe,"Extending the Auto Classes"),WCe.forEach(t),Dx.forEach(t),_qe=i(f),kn=n(f,"P",{});var gf=s(kn);xOe=r(gf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),boe=n(gf,"CODE",{});var QCe=s(boe);$Oe=r(QCe,"NewModel"),QCe.forEach(t),kOe=r(gf,", make sure you have a "),voe=n(gf,"CODE",{});var HCe=s(voe);SOe=r(HCe,"NewModelConfig"),HCe.forEach(t),ROe=r(gf,` then you can add those to the auto
classes like this:`),gf.forEach(t),uqe=i(f),T(SA.$$.fragment,f),bqe=i(f),ok=n(f,"P",{});var UCe=s(ok);POe=r(UCe,"You will then be able to use the auto classes like you would usually do!"),UCe.forEach(t),vqe=i(f),T(Tf.$$.fragment,f),Fqe=i(f),Fi=n(f,"H2",{class:!0});var Gx=s(Fi);Mf=n(Gx,"A",{id:!0,class:!0,href:!0});var JCe=s(Mf);Foe=n(JCe,"SPAN",{});var YCe=s(Foe);T(RA.$$.fragment,YCe),YCe.forEach(t),JCe.forEach(t),BOe=i(Gx),Toe=n(Gx,"SPAN",{});var KCe=s(Toe);IOe=r(KCe,"AutoConfig"),KCe.forEach(t),Gx.forEach(t),Tqe=i(f),Co=n(f,"DIV",{class:!0});var et=s(Co);T(PA.$$.fragment,et),NOe=i(et),BA=n(et,"P",{});var Ox=s(BA);qOe=r(Ox,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),rk=n(Ox,"A",{href:!0});var ZCe=s(rk);jOe=r(ZCe,"from_pretrained()"),ZCe.forEach(t),DOe=r(Ox," class method."),Ox.forEach(t),GOe=i(et),IA=n(et,"P",{});var Vx=s(IA);OOe=r(Vx,"This class cannot be instantiated directly using "),Moe=n(Vx,"CODE",{});var e5e=s(Moe);VOe=r(e5e,"__init__()"),e5e.forEach(t),XOe=r(Vx," (throws an error)."),Vx.forEach(t),zOe=i(et),Er=n(et,"DIV",{class:!0});var ot=s(Er);T(NA.$$.fragment,ot),WOe=i(ot),Eoe=n(ot,"P",{});var o5e=s(Eoe);QOe=r(o5e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),o5e.forEach(t),HOe=i(ot),Ti=n(ot,"P",{});var hf=s(Ti);UOe=r(hf,"The configuration class to instantiate is selected based on the "),Coe=n(hf,"CODE",{});var r5e=s(Coe);JOe=r(r5e,"model_type"),r5e.forEach(t),YOe=r(hf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),woe=n(hf,"CODE",{});var t5e=s(woe);KOe=r(t5e,"pretrained_model_name_or_path"),t5e.forEach(t),ZOe=r(hf,":"),hf.forEach(t),eVe=i(ot),A=n(ot,"UL",{});var y=s(A);Ef=n(y,"LI",{});var c0=s(Ef);Aoe=n(c0,"STRONG",{});var a5e=s(Aoe);oVe=r(a5e,"albert"),a5e.forEach(t),rVe=r(c0," \u2014 "),tk=n(c0,"A",{href:!0});var n5e=s(tk);tVe=r(n5e,"AlbertConfig"),n5e.forEach(t),aVe=r(c0," (ALBERT model)"),c0.forEach(t),nVe=i(y),Cf=n(y,"LI",{});var f0=s(Cf);yoe=n(f0,"STRONG",{});var s5e=s(yoe);sVe=r(s5e,"bart"),s5e.forEach(t),lVe=r(f0," \u2014 "),ak=n(f0,"A",{href:!0});var l5e=s(ak);iVe=r(l5e,"BartConfig"),l5e.forEach(t),dVe=r(f0," (BART model)"),f0.forEach(t),cVe=i(y),wf=n(y,"LI",{});var m0=s(wf);Loe=n(m0,"STRONG",{});var i5e=s(Loe);fVe=r(i5e,"beit"),i5e.forEach(t),mVe=r(m0," \u2014 "),nk=n(m0,"A",{href:!0});var d5e=s(nk);gVe=r(d5e,"BeitConfig"),d5e.forEach(t),hVe=r(m0," (BEiT model)"),m0.forEach(t),pVe=i(y),Af=n(y,"LI",{});var g0=s(Af);xoe=n(g0,"STRONG",{});var c5e=s(xoe);_Ve=r(c5e,"bert"),c5e.forEach(t),uVe=r(g0," \u2014 "),sk=n(g0,"A",{href:!0});var f5e=s(sk);bVe=r(f5e,"BertConfig"),f5e.forEach(t),vVe=r(g0," (BERT model)"),g0.forEach(t),FVe=i(y),yf=n(y,"LI",{});var h0=s(yf);$oe=n(h0,"STRONG",{});var m5e=s($oe);TVe=r(m5e,"bert-generation"),m5e.forEach(t),MVe=r(h0," \u2014 "),lk=n(h0,"A",{href:!0});var g5e=s(lk);EVe=r(g5e,"BertGenerationConfig"),g5e.forEach(t),CVe=r(h0," (Bert Generation model)"),h0.forEach(t),wVe=i(y),Lf=n(y,"LI",{});var p0=s(Lf);koe=n(p0,"STRONG",{});var h5e=s(koe);AVe=r(h5e,"big_bird"),h5e.forEach(t),yVe=r(p0," \u2014 "),ik=n(p0,"A",{href:!0});var p5e=s(ik);LVe=r(p5e,"BigBirdConfig"),p5e.forEach(t),xVe=r(p0," (BigBird model)"),p0.forEach(t),$Ve=i(y),xf=n(y,"LI",{});var _0=s(xf);Soe=n(_0,"STRONG",{});var _5e=s(Soe);kVe=r(_5e,"bigbird_pegasus"),_5e.forEach(t),SVe=r(_0," \u2014 "),dk=n(_0,"A",{href:!0});var u5e=s(dk);RVe=r(u5e,"BigBirdPegasusConfig"),u5e.forEach(t),PVe=r(_0," (BigBirdPegasus model)"),_0.forEach(t),BVe=i(y),$f=n(y,"LI",{});var u0=s($f);Roe=n(u0,"STRONG",{});var b5e=s(Roe);IVe=r(b5e,"blenderbot"),b5e.forEach(t),NVe=r(u0," \u2014 "),ck=n(u0,"A",{href:!0});var v5e=s(ck);qVe=r(v5e,"BlenderbotConfig"),v5e.forEach(t),jVe=r(u0," (Blenderbot model)"),u0.forEach(t),DVe=i(y),kf=n(y,"LI",{});var b0=s(kf);Poe=n(b0,"STRONG",{});var F5e=s(Poe);GVe=r(F5e,"blenderbot-small"),F5e.forEach(t),OVe=r(b0," \u2014 "),fk=n(b0,"A",{href:!0});var T5e=s(fk);VVe=r(T5e,"BlenderbotSmallConfig"),T5e.forEach(t),XVe=r(b0," (BlenderbotSmall model)"),b0.forEach(t),zVe=i(y),Sf=n(y,"LI",{});var v0=s(Sf);Boe=n(v0,"STRONG",{});var M5e=s(Boe);WVe=r(M5e,"camembert"),M5e.forEach(t),QVe=r(v0," \u2014 "),mk=n(v0,"A",{href:!0});var E5e=s(mk);HVe=r(E5e,"CamembertConfig"),E5e.forEach(t),UVe=r(v0," (CamemBERT model)"),v0.forEach(t),JVe=i(y),Rf=n(y,"LI",{});var F0=s(Rf);Ioe=n(F0,"STRONG",{});var C5e=s(Ioe);YVe=r(C5e,"canine"),C5e.forEach(t),KVe=r(F0," \u2014 "),gk=n(F0,"A",{href:!0});var w5e=s(gk);ZVe=r(w5e,"CanineConfig"),w5e.forEach(t),eXe=r(F0," (Canine model)"),F0.forEach(t),oXe=i(y),Pf=n(y,"LI",{});var T0=s(Pf);Noe=n(T0,"STRONG",{});var A5e=s(Noe);rXe=r(A5e,"clip"),A5e.forEach(t),tXe=r(T0," \u2014 "),hk=n(T0,"A",{href:!0});var y5e=s(hk);aXe=r(y5e,"CLIPConfig"),y5e.forEach(t),nXe=r(T0," (CLIP model)"),T0.forEach(t),sXe=i(y),Bf=n(y,"LI",{});var M0=s(Bf);qoe=n(M0,"STRONG",{});var L5e=s(qoe);lXe=r(L5e,"codegen"),L5e.forEach(t),iXe=r(M0," \u2014 "),pk=n(M0,"A",{href:!0});var x5e=s(pk);dXe=r(x5e,"CodeGenConfig"),x5e.forEach(t),cXe=r(M0," (CodeGen model)"),M0.forEach(t),fXe=i(y),If=n(y,"LI",{});var E0=s(If);joe=n(E0,"STRONG",{});var $5e=s(joe);mXe=r($5e,"convbert"),$5e.forEach(t),gXe=r(E0," \u2014 "),_k=n(E0,"A",{href:!0});var k5e=s(_k);hXe=r(k5e,"ConvBertConfig"),k5e.forEach(t),pXe=r(E0," (ConvBERT model)"),E0.forEach(t),_Xe=i(y),Nf=n(y,"LI",{});var C0=s(Nf);Doe=n(C0,"STRONG",{});var S5e=s(Doe);uXe=r(S5e,"convnext"),S5e.forEach(t),bXe=r(C0," \u2014 "),uk=n(C0,"A",{href:!0});var R5e=s(uk);vXe=r(R5e,"ConvNextConfig"),R5e.forEach(t),FXe=r(C0," (ConvNext model)"),C0.forEach(t),TXe=i(y),qf=n(y,"LI",{});var w0=s(qf);Goe=n(w0,"STRONG",{});var P5e=s(Goe);MXe=r(P5e,"ctrl"),P5e.forEach(t),EXe=r(w0," \u2014 "),bk=n(w0,"A",{href:!0});var B5e=s(bk);CXe=r(B5e,"CTRLConfig"),B5e.forEach(t),wXe=r(w0," (CTRL model)"),w0.forEach(t),AXe=i(y),jf=n(y,"LI",{});var A0=s(jf);Ooe=n(A0,"STRONG",{});var I5e=s(Ooe);yXe=r(I5e,"cvt"),I5e.forEach(t),LXe=r(A0," \u2014 "),vk=n(A0,"A",{href:!0});var N5e=s(vk);xXe=r(N5e,"CvtConfig"),N5e.forEach(t),$Xe=r(A0," (CvT model)"),A0.forEach(t),kXe=i(y),Df=n(y,"LI",{});var y0=s(Df);Voe=n(y0,"STRONG",{});var q5e=s(Voe);SXe=r(q5e,"data2vec-audio"),q5e.forEach(t),RXe=r(y0," \u2014 "),Fk=n(y0,"A",{href:!0});var j5e=s(Fk);PXe=r(j5e,"Data2VecAudioConfig"),j5e.forEach(t),BXe=r(y0," (Data2VecAudio model)"),y0.forEach(t),IXe=i(y),Gf=n(y,"LI",{});var L0=s(Gf);Xoe=n(L0,"STRONG",{});var D5e=s(Xoe);NXe=r(D5e,"data2vec-text"),D5e.forEach(t),qXe=r(L0," \u2014 "),Tk=n(L0,"A",{href:!0});var G5e=s(Tk);jXe=r(G5e,"Data2VecTextConfig"),G5e.forEach(t),DXe=r(L0," (Data2VecText model)"),L0.forEach(t),GXe=i(y),Of=n(y,"LI",{});var x0=s(Of);zoe=n(x0,"STRONG",{});var O5e=s(zoe);OXe=r(O5e,"data2vec-vision"),O5e.forEach(t),VXe=r(x0," \u2014 "),Mk=n(x0,"A",{href:!0});var V5e=s(Mk);XXe=r(V5e,"Data2VecVisionConfig"),V5e.forEach(t),zXe=r(x0," (Data2VecVision model)"),x0.forEach(t),WXe=i(y),Vf=n(y,"LI",{});var $0=s(Vf);Woe=n($0,"STRONG",{});var X5e=s(Woe);QXe=r(X5e,"deberta"),X5e.forEach(t),HXe=r($0," \u2014 "),Ek=n($0,"A",{href:!0});var z5e=s(Ek);UXe=r(z5e,"DebertaConfig"),z5e.forEach(t),JXe=r($0," (DeBERTa model)"),$0.forEach(t),YXe=i(y),Xf=n(y,"LI",{});var k0=s(Xf);Qoe=n(k0,"STRONG",{});var W5e=s(Qoe);KXe=r(W5e,"deberta-v2"),W5e.forEach(t),ZXe=r(k0," \u2014 "),Ck=n(k0,"A",{href:!0});var Q5e=s(Ck);eze=r(Q5e,"DebertaV2Config"),Q5e.forEach(t),oze=r(k0," (DeBERTa-v2 model)"),k0.forEach(t),rze=i(y),zf=n(y,"LI",{});var S0=s(zf);Hoe=n(S0,"STRONG",{});var H5e=s(Hoe);tze=r(H5e,"decision_transformer"),H5e.forEach(t),aze=r(S0," \u2014 "),wk=n(S0,"A",{href:!0});var _Xr=s(wk);nze=r(_Xr,"DecisionTransformerConfig"),_Xr.forEach(t),sze=r(S0," (Decision Transformer model)"),S0.forEach(t),lze=i(y),Wf=n(y,"LI",{});var U5e=s(Wf);Uoe=n(U5e,"STRONG",{});var uXr=s(Uoe);ize=r(uXr,"deit"),uXr.forEach(t),dze=r(U5e," \u2014 "),Ak=n(U5e,"A",{href:!0});var bXr=s(Ak);cze=r(bXr,"DeiTConfig"),bXr.forEach(t),fze=r(U5e," (DeiT model)"),U5e.forEach(t),mze=i(y),Qf=n(y,"LI",{});var J5e=s(Qf);Joe=n(J5e,"STRONG",{});var vXr=s(Joe);gze=r(vXr,"detr"),vXr.forEach(t),hze=r(J5e," \u2014 "),yk=n(J5e,"A",{href:!0});var FXr=s(yk);pze=r(FXr,"DetrConfig"),FXr.forEach(t),_ze=r(J5e," (DETR model)"),J5e.forEach(t),uze=i(y),Hf=n(y,"LI",{});var Y5e=s(Hf);Yoe=n(Y5e,"STRONG",{});var TXr=s(Yoe);bze=r(TXr,"distilbert"),TXr.forEach(t),vze=r(Y5e," \u2014 "),Lk=n(Y5e,"A",{href:!0});var MXr=s(Lk);Fze=r(MXr,"DistilBertConfig"),MXr.forEach(t),Tze=r(Y5e," (DistilBERT model)"),Y5e.forEach(t),Mze=i(y),Uf=n(y,"LI",{});var K5e=s(Uf);Koe=n(K5e,"STRONG",{});var EXr=s(Koe);Eze=r(EXr,"dpr"),EXr.forEach(t),Cze=r(K5e," \u2014 "),xk=n(K5e,"A",{href:!0});var CXr=s(xk);wze=r(CXr,"DPRConfig"),CXr.forEach(t),Aze=r(K5e," (DPR model)"),K5e.forEach(t),yze=i(y),Jf=n(y,"LI",{});var Z5e=s(Jf);Zoe=n(Z5e,"STRONG",{});var wXr=s(Zoe);Lze=r(wXr,"dpt"),wXr.forEach(t),xze=r(Z5e," \u2014 "),$k=n(Z5e,"A",{href:!0});var AXr=s($k);$ze=r(AXr,"DPTConfig"),AXr.forEach(t),kze=r(Z5e," (DPT model)"),Z5e.forEach(t),Sze=i(y),Yf=n(y,"LI",{});var ewe=s(Yf);ere=n(ewe,"STRONG",{});var yXr=s(ere);Rze=r(yXr,"electra"),yXr.forEach(t),Pze=r(ewe," \u2014 "),kk=n(ewe,"A",{href:!0});var LXr=s(kk);Bze=r(LXr,"ElectraConfig"),LXr.forEach(t),Ize=r(ewe," (ELECTRA model)"),ewe.forEach(t),Nze=i(y),Kf=n(y,"LI",{});var owe=s(Kf);ore=n(owe,"STRONG",{});var xXr=s(ore);qze=r(xXr,"encoder-decoder"),xXr.forEach(t),jze=r(owe," \u2014 "),Sk=n(owe,"A",{href:!0});var $Xr=s(Sk);Dze=r($Xr,"EncoderDecoderConfig"),$Xr.forEach(t),Gze=r(owe," (Encoder decoder model)"),owe.forEach(t),Oze=i(y),Zf=n(y,"LI",{});var rwe=s(Zf);rre=n(rwe,"STRONG",{});var kXr=s(rre);Vze=r(kXr,"flaubert"),kXr.forEach(t),Xze=r(rwe," \u2014 "),Rk=n(rwe,"A",{href:!0});var SXr=s(Rk);zze=r(SXr,"FlaubertConfig"),SXr.forEach(t),Wze=r(rwe," (FlauBERT model)"),rwe.forEach(t),Qze=i(y),em=n(y,"LI",{});var twe=s(em);tre=n(twe,"STRONG",{});var RXr=s(tre);Hze=r(RXr,"flava"),RXr.forEach(t),Uze=r(twe," \u2014 "),Pk=n(twe,"A",{href:!0});var PXr=s(Pk);Jze=r(PXr,"FlavaConfig"),PXr.forEach(t),Yze=r(twe," (Flava model)"),twe.forEach(t),Kze=i(y),om=n(y,"LI",{});var awe=s(om);are=n(awe,"STRONG",{});var BXr=s(are);Zze=r(BXr,"fnet"),BXr.forEach(t),eWe=r(awe," \u2014 "),Bk=n(awe,"A",{href:!0});var IXr=s(Bk);oWe=r(IXr,"FNetConfig"),IXr.forEach(t),rWe=r(awe," (FNet model)"),awe.forEach(t),tWe=i(y),rm=n(y,"LI",{});var nwe=s(rm);nre=n(nwe,"STRONG",{});var NXr=s(nre);aWe=r(NXr,"fsmt"),NXr.forEach(t),nWe=r(nwe," \u2014 "),Ik=n(nwe,"A",{href:!0});var qXr=s(Ik);sWe=r(qXr,"FSMTConfig"),qXr.forEach(t),lWe=r(nwe," (FairSeq Machine-Translation model)"),nwe.forEach(t),iWe=i(y),tm=n(y,"LI",{});var swe=s(tm);sre=n(swe,"STRONG",{});var jXr=s(sre);dWe=r(jXr,"funnel"),jXr.forEach(t),cWe=r(swe," \u2014 "),Nk=n(swe,"A",{href:!0});var DXr=s(Nk);fWe=r(DXr,"FunnelConfig"),DXr.forEach(t),mWe=r(swe," (Funnel Transformer model)"),swe.forEach(t),gWe=i(y),am=n(y,"LI",{});var lwe=s(am);lre=n(lwe,"STRONG",{});var GXr=s(lre);hWe=r(GXr,"glpn"),GXr.forEach(t),pWe=r(lwe," \u2014 "),qk=n(lwe,"A",{href:!0});var OXr=s(qk);_We=r(OXr,"GLPNConfig"),OXr.forEach(t),uWe=r(lwe," (GLPN model)"),lwe.forEach(t),bWe=i(y),nm=n(y,"LI",{});var iwe=s(nm);ire=n(iwe,"STRONG",{});var VXr=s(ire);vWe=r(VXr,"gpt2"),VXr.forEach(t),FWe=r(iwe," \u2014 "),jk=n(iwe,"A",{href:!0});var XXr=s(jk);TWe=r(XXr,"GPT2Config"),XXr.forEach(t),MWe=r(iwe," (OpenAI GPT-2 model)"),iwe.forEach(t),EWe=i(y),sm=n(y,"LI",{});var dwe=s(sm);dre=n(dwe,"STRONG",{});var zXr=s(dre);CWe=r(zXr,"gpt_neo"),zXr.forEach(t),wWe=r(dwe," \u2014 "),Dk=n(dwe,"A",{href:!0});var WXr=s(Dk);AWe=r(WXr,"GPTNeoConfig"),WXr.forEach(t),yWe=r(dwe," (GPT Neo model)"),dwe.forEach(t),LWe=i(y),lm=n(y,"LI",{});var cwe=s(lm);cre=n(cwe,"STRONG",{});var QXr=s(cre);xWe=r(QXr,"gpt_neox"),QXr.forEach(t),$We=r(cwe," \u2014 "),Gk=n(cwe,"A",{href:!0});var HXr=s(Gk);kWe=r(HXr,"GPTNeoXConfig"),HXr.forEach(t),SWe=r(cwe," (GPT NeoX model)"),cwe.forEach(t),RWe=i(y),im=n(y,"LI",{});var fwe=s(im);fre=n(fwe,"STRONG",{});var UXr=s(fre);PWe=r(UXr,"gptj"),UXr.forEach(t),BWe=r(fwe," \u2014 "),Ok=n(fwe,"A",{href:!0});var JXr=s(Ok);IWe=r(JXr,"GPTJConfig"),JXr.forEach(t),NWe=r(fwe," (GPT-J model)"),fwe.forEach(t),qWe=i(y),dm=n(y,"LI",{});var mwe=s(dm);mre=n(mwe,"STRONG",{});var YXr=s(mre);jWe=r(YXr,"hubert"),YXr.forEach(t),DWe=r(mwe," \u2014 "),Vk=n(mwe,"A",{href:!0});var KXr=s(Vk);GWe=r(KXr,"HubertConfig"),KXr.forEach(t),OWe=r(mwe," (Hubert model)"),mwe.forEach(t),VWe=i(y),cm=n(y,"LI",{});var gwe=s(cm);gre=n(gwe,"STRONG",{});var ZXr=s(gre);XWe=r(ZXr,"ibert"),ZXr.forEach(t),zWe=r(gwe," \u2014 "),Xk=n(gwe,"A",{href:!0});var ezr=s(Xk);WWe=r(ezr,"IBertConfig"),ezr.forEach(t),QWe=r(gwe," (I-BERT model)"),gwe.forEach(t),HWe=i(y),fm=n(y,"LI",{});var hwe=s(fm);hre=n(hwe,"STRONG",{});var ozr=s(hre);UWe=r(ozr,"imagegpt"),ozr.forEach(t),JWe=r(hwe," \u2014 "),zk=n(hwe,"A",{href:!0});var rzr=s(zk);YWe=r(rzr,"ImageGPTConfig"),rzr.forEach(t),KWe=r(hwe," (ImageGPT model)"),hwe.forEach(t),ZWe=i(y),mm=n(y,"LI",{});var pwe=s(mm);pre=n(pwe,"STRONG",{});var tzr=s(pre);eQe=r(tzr,"layoutlm"),tzr.forEach(t),oQe=r(pwe," \u2014 "),Wk=n(pwe,"A",{href:!0});var azr=s(Wk);rQe=r(azr,"LayoutLMConfig"),azr.forEach(t),tQe=r(pwe," (LayoutLM model)"),pwe.forEach(t),aQe=i(y),gm=n(y,"LI",{});var _we=s(gm);_re=n(_we,"STRONG",{});var nzr=s(_re);nQe=r(nzr,"layoutlmv2"),nzr.forEach(t),sQe=r(_we," \u2014 "),Qk=n(_we,"A",{href:!0});var szr=s(Qk);lQe=r(szr,"LayoutLMv2Config"),szr.forEach(t),iQe=r(_we," (LayoutLMv2 model)"),_we.forEach(t),dQe=i(y),hm=n(y,"LI",{});var uwe=s(hm);ure=n(uwe,"STRONG",{});var lzr=s(ure);cQe=r(lzr,"layoutlmv3"),lzr.forEach(t),fQe=r(uwe," \u2014 "),Hk=n(uwe,"A",{href:!0});var izr=s(Hk);mQe=r(izr,"LayoutLMv3Config"),izr.forEach(t),gQe=r(uwe," (LayoutLMv3 model)"),uwe.forEach(t),hQe=i(y),pm=n(y,"LI",{});var bwe=s(pm);bre=n(bwe,"STRONG",{});var dzr=s(bre);pQe=r(dzr,"led"),dzr.forEach(t),_Qe=r(bwe," \u2014 "),Uk=n(bwe,"A",{href:!0});var czr=s(Uk);uQe=r(czr,"LEDConfig"),czr.forEach(t),bQe=r(bwe," (LED model)"),bwe.forEach(t),vQe=i(y),_m=n(y,"LI",{});var vwe=s(_m);vre=n(vwe,"STRONG",{});var fzr=s(vre);FQe=r(fzr,"longformer"),fzr.forEach(t),TQe=r(vwe," \u2014 "),Jk=n(vwe,"A",{href:!0});var mzr=s(Jk);MQe=r(mzr,"LongformerConfig"),mzr.forEach(t),EQe=r(vwe," (Longformer model)"),vwe.forEach(t),CQe=i(y),um=n(y,"LI",{});var Fwe=s(um);Fre=n(Fwe,"STRONG",{});var gzr=s(Fre);wQe=r(gzr,"luke"),gzr.forEach(t),AQe=r(Fwe," \u2014 "),Yk=n(Fwe,"A",{href:!0});var hzr=s(Yk);yQe=r(hzr,"LukeConfig"),hzr.forEach(t),LQe=r(Fwe," (LUKE model)"),Fwe.forEach(t),xQe=i(y),bm=n(y,"LI",{});var Twe=s(bm);Tre=n(Twe,"STRONG",{});var pzr=s(Tre);$Qe=r(pzr,"lxmert"),pzr.forEach(t),kQe=r(Twe," \u2014 "),Kk=n(Twe,"A",{href:!0});var _zr=s(Kk);SQe=r(_zr,"LxmertConfig"),_zr.forEach(t),RQe=r(Twe," (LXMERT model)"),Twe.forEach(t),PQe=i(y),vm=n(y,"LI",{});var Mwe=s(vm);Mre=n(Mwe,"STRONG",{});var uzr=s(Mre);BQe=r(uzr,"m2m_100"),uzr.forEach(t),IQe=r(Mwe," \u2014 "),Zk=n(Mwe,"A",{href:!0});var bzr=s(Zk);NQe=r(bzr,"M2M100Config"),bzr.forEach(t),qQe=r(Mwe," (M2M100 model)"),Mwe.forEach(t),jQe=i(y),Fm=n(y,"LI",{});var Ewe=s(Fm);Ere=n(Ewe,"STRONG",{});var vzr=s(Ere);DQe=r(vzr,"marian"),vzr.forEach(t),GQe=r(Ewe," \u2014 "),eS=n(Ewe,"A",{href:!0});var Fzr=s(eS);OQe=r(Fzr,"MarianConfig"),Fzr.forEach(t),VQe=r(Ewe," (Marian model)"),Ewe.forEach(t),XQe=i(y),Tm=n(y,"LI",{});var Cwe=s(Tm);Cre=n(Cwe,"STRONG",{});var Tzr=s(Cre);zQe=r(Tzr,"maskformer"),Tzr.forEach(t),WQe=r(Cwe," \u2014 "),oS=n(Cwe,"A",{href:!0});var Mzr=s(oS);QQe=r(Mzr,"MaskFormerConfig"),Mzr.forEach(t),HQe=r(Cwe," (MaskFormer model)"),Cwe.forEach(t),UQe=i(y),Mm=n(y,"LI",{});var wwe=s(Mm);wre=n(wwe,"STRONG",{});var Ezr=s(wre);JQe=r(Ezr,"mbart"),Ezr.forEach(t),YQe=r(wwe," \u2014 "),rS=n(wwe,"A",{href:!0});var Czr=s(rS);KQe=r(Czr,"MBartConfig"),Czr.forEach(t),ZQe=r(wwe," (mBART model)"),wwe.forEach(t),eHe=i(y),Em=n(y,"LI",{});var Awe=s(Em);Are=n(Awe,"STRONG",{});var wzr=s(Are);oHe=r(wzr,"megatron-bert"),wzr.forEach(t),rHe=r(Awe," \u2014 "),tS=n(Awe,"A",{href:!0});var Azr=s(tS);tHe=r(Azr,"MegatronBertConfig"),Azr.forEach(t),aHe=r(Awe," (MegatronBert model)"),Awe.forEach(t),nHe=i(y),Cm=n(y,"LI",{});var ywe=s(Cm);yre=n(ywe,"STRONG",{});var yzr=s(yre);sHe=r(yzr,"mobilebert"),yzr.forEach(t),lHe=r(ywe," \u2014 "),aS=n(ywe,"A",{href:!0});var Lzr=s(aS);iHe=r(Lzr,"MobileBertConfig"),Lzr.forEach(t),dHe=r(ywe," (MobileBERT model)"),ywe.forEach(t),cHe=i(y),wm=n(y,"LI",{});var Lwe=s(wm);Lre=n(Lwe,"STRONG",{});var xzr=s(Lre);fHe=r(xzr,"mpnet"),xzr.forEach(t),mHe=r(Lwe," \u2014 "),nS=n(Lwe,"A",{href:!0});var $zr=s(nS);gHe=r($zr,"MPNetConfig"),$zr.forEach(t),hHe=r(Lwe," (MPNet model)"),Lwe.forEach(t),pHe=i(y),Am=n(y,"LI",{});var xwe=s(Am);xre=n(xwe,"STRONG",{});var kzr=s(xre);_He=r(kzr,"mt5"),kzr.forEach(t),uHe=r(xwe," \u2014 "),sS=n(xwe,"A",{href:!0});var Szr=s(sS);bHe=r(Szr,"MT5Config"),Szr.forEach(t),vHe=r(xwe," (mT5 model)"),xwe.forEach(t),FHe=i(y),ym=n(y,"LI",{});var $we=s(ym);$re=n($we,"STRONG",{});var Rzr=s($re);THe=r(Rzr,"nystromformer"),Rzr.forEach(t),MHe=r($we," \u2014 "),lS=n($we,"A",{href:!0});var Pzr=s(lS);EHe=r(Pzr,"NystromformerConfig"),Pzr.forEach(t),CHe=r($we," (Nystromformer model)"),$we.forEach(t),wHe=i(y),Lm=n(y,"LI",{});var kwe=s(Lm);kre=n(kwe,"STRONG",{});var Bzr=s(kre);AHe=r(Bzr,"openai-gpt"),Bzr.forEach(t),yHe=r(kwe," \u2014 "),iS=n(kwe,"A",{href:!0});var Izr=s(iS);LHe=r(Izr,"OpenAIGPTConfig"),Izr.forEach(t),xHe=r(kwe," (OpenAI GPT model)"),kwe.forEach(t),$He=i(y),xm=n(y,"LI",{});var Swe=s(xm);Sre=n(Swe,"STRONG",{});var Nzr=s(Sre);kHe=r(Nzr,"opt"),Nzr.forEach(t),SHe=r(Swe," \u2014 "),dS=n(Swe,"A",{href:!0});var qzr=s(dS);RHe=r(qzr,"OPTConfig"),qzr.forEach(t),PHe=r(Swe," (OPT model)"),Swe.forEach(t),BHe=i(y),$m=n(y,"LI",{});var Rwe=s($m);Rre=n(Rwe,"STRONG",{});var jzr=s(Rre);IHe=r(jzr,"pegasus"),jzr.forEach(t),NHe=r(Rwe," \u2014 "),cS=n(Rwe,"A",{href:!0});var Dzr=s(cS);qHe=r(Dzr,"PegasusConfig"),Dzr.forEach(t),jHe=r(Rwe," (Pegasus model)"),Rwe.forEach(t),DHe=i(y),km=n(y,"LI",{});var Pwe=s(km);Pre=n(Pwe,"STRONG",{});var Gzr=s(Pre);GHe=r(Gzr,"perceiver"),Gzr.forEach(t),OHe=r(Pwe," \u2014 "),fS=n(Pwe,"A",{href:!0});var Ozr=s(fS);VHe=r(Ozr,"PerceiverConfig"),Ozr.forEach(t),XHe=r(Pwe," (Perceiver model)"),Pwe.forEach(t),zHe=i(y),Sm=n(y,"LI",{});var Bwe=s(Sm);Bre=n(Bwe,"STRONG",{});var Vzr=s(Bre);WHe=r(Vzr,"plbart"),Vzr.forEach(t),QHe=r(Bwe," \u2014 "),mS=n(Bwe,"A",{href:!0});var Xzr=s(mS);HHe=r(Xzr,"PLBartConfig"),Xzr.forEach(t),UHe=r(Bwe," (PLBart model)"),Bwe.forEach(t),JHe=i(y),Rm=n(y,"LI",{});var Iwe=s(Rm);Ire=n(Iwe,"STRONG",{});var zzr=s(Ire);YHe=r(zzr,"poolformer"),zzr.forEach(t),KHe=r(Iwe," \u2014 "),gS=n(Iwe,"A",{href:!0});var Wzr=s(gS);ZHe=r(Wzr,"PoolFormerConfig"),Wzr.forEach(t),eUe=r(Iwe," (PoolFormer model)"),Iwe.forEach(t),oUe=i(y),Pm=n(y,"LI",{});var Nwe=s(Pm);Nre=n(Nwe,"STRONG",{});var Qzr=s(Nre);rUe=r(Qzr,"prophetnet"),Qzr.forEach(t),tUe=r(Nwe," \u2014 "),hS=n(Nwe,"A",{href:!0});var Hzr=s(hS);aUe=r(Hzr,"ProphetNetConfig"),Hzr.forEach(t),nUe=r(Nwe," (ProphetNet model)"),Nwe.forEach(t),sUe=i(y),Bm=n(y,"LI",{});var qwe=s(Bm);qre=n(qwe,"STRONG",{});var Uzr=s(qre);lUe=r(Uzr,"qdqbert"),Uzr.forEach(t),iUe=r(qwe," \u2014 "),pS=n(qwe,"A",{href:!0});var Jzr=s(pS);dUe=r(Jzr,"QDQBertConfig"),Jzr.forEach(t),cUe=r(qwe," (QDQBert model)"),qwe.forEach(t),fUe=i(y),Im=n(y,"LI",{});var jwe=s(Im);jre=n(jwe,"STRONG",{});var Yzr=s(jre);mUe=r(Yzr,"rag"),Yzr.forEach(t),gUe=r(jwe," \u2014 "),_S=n(jwe,"A",{href:!0});var Kzr=s(_S);hUe=r(Kzr,"RagConfig"),Kzr.forEach(t),pUe=r(jwe," (RAG model)"),jwe.forEach(t),_Ue=i(y),Nm=n(y,"LI",{});var Dwe=s(Nm);Dre=n(Dwe,"STRONG",{});var Zzr=s(Dre);uUe=r(Zzr,"realm"),Zzr.forEach(t),bUe=r(Dwe," \u2014 "),uS=n(Dwe,"A",{href:!0});var eWr=s(uS);vUe=r(eWr,"RealmConfig"),eWr.forEach(t),FUe=r(Dwe," (Realm model)"),Dwe.forEach(t),TUe=i(y),qm=n(y,"LI",{});var Gwe=s(qm);Gre=n(Gwe,"STRONG",{});var oWr=s(Gre);MUe=r(oWr,"reformer"),oWr.forEach(t),EUe=r(Gwe," \u2014 "),bS=n(Gwe,"A",{href:!0});var rWr=s(bS);CUe=r(rWr,"ReformerConfig"),rWr.forEach(t),wUe=r(Gwe," (Reformer model)"),Gwe.forEach(t),AUe=i(y),jm=n(y,"LI",{});var Owe=s(jm);Ore=n(Owe,"STRONG",{});var tWr=s(Ore);yUe=r(tWr,"regnet"),tWr.forEach(t),LUe=r(Owe," \u2014 "),vS=n(Owe,"A",{href:!0});var aWr=s(vS);xUe=r(aWr,"RegNetConfig"),aWr.forEach(t),$Ue=r(Owe," (RegNet model)"),Owe.forEach(t),kUe=i(y),Dm=n(y,"LI",{});var Vwe=s(Dm);Vre=n(Vwe,"STRONG",{});var nWr=s(Vre);SUe=r(nWr,"rembert"),nWr.forEach(t),RUe=r(Vwe," \u2014 "),FS=n(Vwe,"A",{href:!0});var sWr=s(FS);PUe=r(sWr,"RemBertConfig"),sWr.forEach(t),BUe=r(Vwe," (RemBERT model)"),Vwe.forEach(t),IUe=i(y),Gm=n(y,"LI",{});var Xwe=s(Gm);Xre=n(Xwe,"STRONG",{});var lWr=s(Xre);NUe=r(lWr,"resnet"),lWr.forEach(t),qUe=r(Xwe," \u2014 "),TS=n(Xwe,"A",{href:!0});var iWr=s(TS);jUe=r(iWr,"ResNetConfig"),iWr.forEach(t),DUe=r(Xwe," (ResNet model)"),Xwe.forEach(t),GUe=i(y),Om=n(y,"LI",{});var zwe=s(Om);zre=n(zwe,"STRONG",{});var dWr=s(zre);OUe=r(dWr,"retribert"),dWr.forEach(t),VUe=r(zwe," \u2014 "),MS=n(zwe,"A",{href:!0});var cWr=s(MS);XUe=r(cWr,"RetriBertConfig"),cWr.forEach(t),zUe=r(zwe," (RetriBERT model)"),zwe.forEach(t),WUe=i(y),Vm=n(y,"LI",{});var Wwe=s(Vm);Wre=n(Wwe,"STRONG",{});var fWr=s(Wre);QUe=r(fWr,"roberta"),fWr.forEach(t),HUe=r(Wwe," \u2014 "),ES=n(Wwe,"A",{href:!0});var mWr=s(ES);UUe=r(mWr,"RobertaConfig"),mWr.forEach(t),JUe=r(Wwe," (RoBERTa model)"),Wwe.forEach(t),YUe=i(y),Xm=n(y,"LI",{});var Qwe=s(Xm);Qre=n(Qwe,"STRONG",{});var gWr=s(Qre);KUe=r(gWr,"roformer"),gWr.forEach(t),ZUe=r(Qwe," \u2014 "),CS=n(Qwe,"A",{href:!0});var hWr=s(CS);eJe=r(hWr,"RoFormerConfig"),hWr.forEach(t),oJe=r(Qwe," (RoFormer model)"),Qwe.forEach(t),rJe=i(y),zm=n(y,"LI",{});var Hwe=s(zm);Hre=n(Hwe,"STRONG",{});var pWr=s(Hre);tJe=r(pWr,"segformer"),pWr.forEach(t),aJe=r(Hwe," \u2014 "),wS=n(Hwe,"A",{href:!0});var _Wr=s(wS);nJe=r(_Wr,"SegformerConfig"),_Wr.forEach(t),sJe=r(Hwe," (SegFormer model)"),Hwe.forEach(t),lJe=i(y),Wm=n(y,"LI",{});var Uwe=s(Wm);Ure=n(Uwe,"STRONG",{});var uWr=s(Ure);iJe=r(uWr,"sew"),uWr.forEach(t),dJe=r(Uwe," \u2014 "),AS=n(Uwe,"A",{href:!0});var bWr=s(AS);cJe=r(bWr,"SEWConfig"),bWr.forEach(t),fJe=r(Uwe," (SEW model)"),Uwe.forEach(t),mJe=i(y),Qm=n(y,"LI",{});var Jwe=s(Qm);Jre=n(Jwe,"STRONG",{});var vWr=s(Jre);gJe=r(vWr,"sew-d"),vWr.forEach(t),hJe=r(Jwe," \u2014 "),yS=n(Jwe,"A",{href:!0});var FWr=s(yS);pJe=r(FWr,"SEWDConfig"),FWr.forEach(t),_Je=r(Jwe," (SEW-D model)"),Jwe.forEach(t),uJe=i(y),Hm=n(y,"LI",{});var Ywe=s(Hm);Yre=n(Ywe,"STRONG",{});var TWr=s(Yre);bJe=r(TWr,"speech-encoder-decoder"),TWr.forEach(t),vJe=r(Ywe," \u2014 "),LS=n(Ywe,"A",{href:!0});var MWr=s(LS);FJe=r(MWr,"SpeechEncoderDecoderConfig"),MWr.forEach(t),TJe=r(Ywe," (Speech Encoder decoder model)"),Ywe.forEach(t),MJe=i(y),Um=n(y,"LI",{});var Kwe=s(Um);Kre=n(Kwe,"STRONG",{});var EWr=s(Kre);EJe=r(EWr,"speech_to_text"),EWr.forEach(t),CJe=r(Kwe," \u2014 "),xS=n(Kwe,"A",{href:!0});var CWr=s(xS);wJe=r(CWr,"Speech2TextConfig"),CWr.forEach(t),AJe=r(Kwe," (Speech2Text model)"),Kwe.forEach(t),yJe=i(y),Jm=n(y,"LI",{});var Zwe=s(Jm);Zre=n(Zwe,"STRONG",{});var wWr=s(Zre);LJe=r(wWr,"speech_to_text_2"),wWr.forEach(t),xJe=r(Zwe," \u2014 "),$S=n(Zwe,"A",{href:!0});var AWr=s($S);$Je=r(AWr,"Speech2Text2Config"),AWr.forEach(t),kJe=r(Zwe," (Speech2Text2 model)"),Zwe.forEach(t),SJe=i(y),Ym=n(y,"LI",{});var e0e=s(Ym);ete=n(e0e,"STRONG",{});var yWr=s(ete);RJe=r(yWr,"splinter"),yWr.forEach(t),PJe=r(e0e," \u2014 "),kS=n(e0e,"A",{href:!0});var LWr=s(kS);BJe=r(LWr,"SplinterConfig"),LWr.forEach(t),IJe=r(e0e," (Splinter model)"),e0e.forEach(t),NJe=i(y),Km=n(y,"LI",{});var o0e=s(Km);ote=n(o0e,"STRONG",{});var xWr=s(ote);qJe=r(xWr,"squeezebert"),xWr.forEach(t),jJe=r(o0e," \u2014 "),SS=n(o0e,"A",{href:!0});var $Wr=s(SS);DJe=r($Wr,"SqueezeBertConfig"),$Wr.forEach(t),GJe=r(o0e," (SqueezeBERT model)"),o0e.forEach(t),OJe=i(y),Zm=n(y,"LI",{});var r0e=s(Zm);rte=n(r0e,"STRONG",{});var kWr=s(rte);VJe=r(kWr,"swin"),kWr.forEach(t),XJe=r(r0e," \u2014 "),RS=n(r0e,"A",{href:!0});var SWr=s(RS);zJe=r(SWr,"SwinConfig"),SWr.forEach(t),WJe=r(r0e," (Swin model)"),r0e.forEach(t),QJe=i(y),eg=n(y,"LI",{});var t0e=s(eg);tte=n(t0e,"STRONG",{});var RWr=s(tte);HJe=r(RWr,"t5"),RWr.forEach(t),UJe=r(t0e," \u2014 "),PS=n(t0e,"A",{href:!0});var PWr=s(PS);JJe=r(PWr,"T5Config"),PWr.forEach(t),YJe=r(t0e," (T5 model)"),t0e.forEach(t),KJe=i(y),og=n(y,"LI",{});var a0e=s(og);ate=n(a0e,"STRONG",{});var BWr=s(ate);ZJe=r(BWr,"tapas"),BWr.forEach(t),eYe=r(a0e," \u2014 "),BS=n(a0e,"A",{href:!0});var IWr=s(BS);oYe=r(IWr,"TapasConfig"),IWr.forEach(t),rYe=r(a0e," (TAPAS model)"),a0e.forEach(t),tYe=i(y),rg=n(y,"LI",{});var n0e=s(rg);nte=n(n0e,"STRONG",{});var NWr=s(nte);aYe=r(NWr,"trajectory_transformer"),NWr.forEach(t),nYe=r(n0e," \u2014 "),IS=n(n0e,"A",{href:!0});var qWr=s(IS);sYe=r(qWr,"TrajectoryTransformerConfig"),qWr.forEach(t),lYe=r(n0e," (Trajectory Transformer model)"),n0e.forEach(t),iYe=i(y),tg=n(y,"LI",{});var s0e=s(tg);ste=n(s0e,"STRONG",{});var jWr=s(ste);dYe=r(jWr,"transfo-xl"),jWr.forEach(t),cYe=r(s0e," \u2014 "),NS=n(s0e,"A",{href:!0});var DWr=s(NS);fYe=r(DWr,"TransfoXLConfig"),DWr.forEach(t),mYe=r(s0e," (Transformer-XL model)"),s0e.forEach(t),gYe=i(y),ag=n(y,"LI",{});var l0e=s(ag);lte=n(l0e,"STRONG",{});var GWr=s(lte);hYe=r(GWr,"trocr"),GWr.forEach(t),pYe=r(l0e," \u2014 "),qS=n(l0e,"A",{href:!0});var OWr=s(qS);_Ye=r(OWr,"TrOCRConfig"),OWr.forEach(t),uYe=r(l0e," (TrOCR model)"),l0e.forEach(t),bYe=i(y),ng=n(y,"LI",{});var i0e=s(ng);ite=n(i0e,"STRONG",{});var VWr=s(ite);vYe=r(VWr,"unispeech"),VWr.forEach(t),FYe=r(i0e," \u2014 "),jS=n(i0e,"A",{href:!0});var XWr=s(jS);TYe=r(XWr,"UniSpeechConfig"),XWr.forEach(t),MYe=r(i0e," (UniSpeech model)"),i0e.forEach(t),EYe=i(y),sg=n(y,"LI",{});var d0e=s(sg);dte=n(d0e,"STRONG",{});var zWr=s(dte);CYe=r(zWr,"unispeech-sat"),zWr.forEach(t),wYe=r(d0e," \u2014 "),DS=n(d0e,"A",{href:!0});var WWr=s(DS);AYe=r(WWr,"UniSpeechSatConfig"),WWr.forEach(t),yYe=r(d0e," (UniSpeechSat model)"),d0e.forEach(t),LYe=i(y),lg=n(y,"LI",{});var c0e=s(lg);cte=n(c0e,"STRONG",{});var QWr=s(cte);xYe=r(QWr,"van"),QWr.forEach(t),$Ye=r(c0e," \u2014 "),GS=n(c0e,"A",{href:!0});var HWr=s(GS);kYe=r(HWr,"VanConfig"),HWr.forEach(t),SYe=r(c0e," (VAN model)"),c0e.forEach(t),RYe=i(y),ig=n(y,"LI",{});var f0e=s(ig);fte=n(f0e,"STRONG",{});var UWr=s(fte);PYe=r(UWr,"vilt"),UWr.forEach(t),BYe=r(f0e," \u2014 "),OS=n(f0e,"A",{href:!0});var JWr=s(OS);IYe=r(JWr,"ViltConfig"),JWr.forEach(t),NYe=r(f0e," (ViLT model)"),f0e.forEach(t),qYe=i(y),dg=n(y,"LI",{});var m0e=s(dg);mte=n(m0e,"STRONG",{});var YWr=s(mte);jYe=r(YWr,"vision-encoder-decoder"),YWr.forEach(t),DYe=r(m0e," \u2014 "),VS=n(m0e,"A",{href:!0});var KWr=s(VS);GYe=r(KWr,"VisionEncoderDecoderConfig"),KWr.forEach(t),OYe=r(m0e," (Vision Encoder decoder model)"),m0e.forEach(t),VYe=i(y),cg=n(y,"LI",{});var g0e=s(cg);gte=n(g0e,"STRONG",{});var ZWr=s(gte);XYe=r(ZWr,"vision-text-dual-encoder"),ZWr.forEach(t),zYe=r(g0e," \u2014 "),XS=n(g0e,"A",{href:!0});var eQr=s(XS);WYe=r(eQr,"VisionTextDualEncoderConfig"),eQr.forEach(t),QYe=r(g0e," (VisionTextDualEncoder model)"),g0e.forEach(t),HYe=i(y),fg=n(y,"LI",{});var h0e=s(fg);hte=n(h0e,"STRONG",{});var oQr=s(hte);UYe=r(oQr,"visual_bert"),oQr.forEach(t),JYe=r(h0e," \u2014 "),zS=n(h0e,"A",{href:!0});var rQr=s(zS);YYe=r(rQr,"VisualBertConfig"),rQr.forEach(t),KYe=r(h0e," (VisualBert model)"),h0e.forEach(t),ZYe=i(y),mg=n(y,"LI",{});var p0e=s(mg);pte=n(p0e,"STRONG",{});var tQr=s(pte);eKe=r(tQr,"vit"),tQr.forEach(t),oKe=r(p0e," \u2014 "),WS=n(p0e,"A",{href:!0});var aQr=s(WS);rKe=r(aQr,"ViTConfig"),aQr.forEach(t),tKe=r(p0e," (ViT model)"),p0e.forEach(t),aKe=i(y),gg=n(y,"LI",{});var _0e=s(gg);_te=n(_0e,"STRONG",{});var nQr=s(_te);nKe=r(nQr,"vit_mae"),nQr.forEach(t),sKe=r(_0e," \u2014 "),QS=n(_0e,"A",{href:!0});var sQr=s(QS);lKe=r(sQr,"ViTMAEConfig"),sQr.forEach(t),iKe=r(_0e," (ViTMAE model)"),_0e.forEach(t),dKe=i(y),hg=n(y,"LI",{});var u0e=s(hg);ute=n(u0e,"STRONG",{});var lQr=s(ute);cKe=r(lQr,"wav2vec2"),lQr.forEach(t),fKe=r(u0e," \u2014 "),HS=n(u0e,"A",{href:!0});var iQr=s(HS);mKe=r(iQr,"Wav2Vec2Config"),iQr.forEach(t),gKe=r(u0e," (Wav2Vec2 model)"),u0e.forEach(t),hKe=i(y),pg=n(y,"LI",{});var b0e=s(pg);bte=n(b0e,"STRONG",{});var dQr=s(bte);pKe=r(dQr,"wav2vec2-conformer"),dQr.forEach(t),_Ke=r(b0e," \u2014 "),US=n(b0e,"A",{href:!0});var cQr=s(US);uKe=r(cQr,"Wav2Vec2ConformerConfig"),cQr.forEach(t),bKe=r(b0e," (Wav2Vec2-Conformer model)"),b0e.forEach(t),vKe=i(y),_g=n(y,"LI",{});var v0e=s(_g);vte=n(v0e,"STRONG",{});var fQr=s(vte);FKe=r(fQr,"wavlm"),fQr.forEach(t),TKe=r(v0e," \u2014 "),JS=n(v0e,"A",{href:!0});var mQr=s(JS);MKe=r(mQr,"WavLMConfig"),mQr.forEach(t),EKe=r(v0e," (WavLM model)"),v0e.forEach(t),CKe=i(y),ug=n(y,"LI",{});var F0e=s(ug);Fte=n(F0e,"STRONG",{});var gQr=s(Fte);wKe=r(gQr,"xglm"),gQr.forEach(t),AKe=r(F0e," \u2014 "),YS=n(F0e,"A",{href:!0});var hQr=s(YS);yKe=r(hQr,"XGLMConfig"),hQr.forEach(t),LKe=r(F0e," (XGLM model)"),F0e.forEach(t),xKe=i(y),bg=n(y,"LI",{});var T0e=s(bg);Tte=n(T0e,"STRONG",{});var pQr=s(Tte);$Ke=r(pQr,"xlm"),pQr.forEach(t),kKe=r(T0e," \u2014 "),KS=n(T0e,"A",{href:!0});var _Qr=s(KS);SKe=r(_Qr,"XLMConfig"),_Qr.forEach(t),RKe=r(T0e," (XLM model)"),T0e.forEach(t),PKe=i(y),vg=n(y,"LI",{});var M0e=s(vg);Mte=n(M0e,"STRONG",{});var uQr=s(Mte);BKe=r(uQr,"xlm-prophetnet"),uQr.forEach(t),IKe=r(M0e," \u2014 "),ZS=n(M0e,"A",{href:!0});var bQr=s(ZS);NKe=r(bQr,"XLMProphetNetConfig"),bQr.forEach(t),qKe=r(M0e," (XLMProphetNet model)"),M0e.forEach(t),jKe=i(y),Fg=n(y,"LI",{});var E0e=s(Fg);Ete=n(E0e,"STRONG",{});var vQr=s(Ete);DKe=r(vQr,"xlm-roberta"),vQr.forEach(t),GKe=r(E0e," \u2014 "),eR=n(E0e,"A",{href:!0});var FQr=s(eR);OKe=r(FQr,"XLMRobertaConfig"),FQr.forEach(t),VKe=r(E0e," (XLM-RoBERTa model)"),E0e.forEach(t),XKe=i(y),Tg=n(y,"LI",{});var C0e=s(Tg);Cte=n(C0e,"STRONG",{});var TQr=s(Cte);zKe=r(TQr,"xlm-roberta-xl"),TQr.forEach(t),WKe=r(C0e," \u2014 "),oR=n(C0e,"A",{href:!0});var MQr=s(oR);QKe=r(MQr,"XLMRobertaXLConfig"),MQr.forEach(t),HKe=r(C0e," (XLM-RoBERTa-XL model)"),C0e.forEach(t),UKe=i(y),Mg=n(y,"LI",{});var w0e=s(Mg);wte=n(w0e,"STRONG",{});var EQr=s(wte);JKe=r(EQr,"xlnet"),EQr.forEach(t),YKe=r(w0e," \u2014 "),rR=n(w0e,"A",{href:!0});var CQr=s(rR);KKe=r(CQr,"XLNetConfig"),CQr.forEach(t),ZKe=r(w0e," (XLNet model)"),w0e.forEach(t),eZe=i(y),Eg=n(y,"LI",{});var A0e=s(Eg);Ate=n(A0e,"STRONG",{});var wQr=s(Ate);oZe=r(wQr,"yolos"),wQr.forEach(t),rZe=r(A0e," \u2014 "),tR=n(A0e,"A",{href:!0});var AQr=s(tR);tZe=r(AQr,"YolosConfig"),AQr.forEach(t),aZe=r(A0e," (YOLOS model)"),A0e.forEach(t),nZe=i(y),Cg=n(y,"LI",{});var y0e=s(Cg);yte=n(y0e,"STRONG",{});var yQr=s(yte);sZe=r(yQr,"yoso"),yQr.forEach(t),lZe=r(y0e," \u2014 "),aR=n(y0e,"A",{href:!0});var LQr=s(aR);iZe=r(LQr,"YosoConfig"),LQr.forEach(t),dZe=r(y0e," (YOSO model)"),y0e.forEach(t),y.forEach(t),cZe=i(ot),T(wg.$$.fragment,ot),ot.forEach(t),fZe=i(et),Ag=n(et,"DIV",{class:!0});var vDe=s(Ag);T(qA.$$.fragment,vDe),mZe=i(vDe),Lte=n(vDe,"P",{});var xQr=s(Lte);gZe=r(xQr,"Register a new configuration for this class."),xQr.forEach(t),vDe.forEach(t),et.forEach(t),Mqe=i(f),Mi=n(f,"H2",{class:!0});var FDe=s(Mi);yg=n(FDe,"A",{id:!0,class:!0,href:!0});var $Qr=s(yg);xte=n($Qr,"SPAN",{});var kQr=s(xte);T(jA.$$.fragment,kQr),kQr.forEach(t),$Qr.forEach(t),hZe=i(FDe),$te=n(FDe,"SPAN",{});var SQr=s($te);pZe=r(SQr,"AutoTokenizer"),SQr.forEach(t),FDe.forEach(t),Eqe=i(f),wo=n(f,"DIV",{class:!0});var qs=s(wo);T(DA.$$.fragment,qs),_Ze=i(qs),GA=n(qs,"P",{});var TDe=s(GA);uZe=r(TDe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),nR=n(TDe,"A",{href:!0});var RQr=s(nR);bZe=r(RQr,"AutoTokenizer.from_pretrained()"),RQr.forEach(t),vZe=r(TDe," class method."),TDe.forEach(t),FZe=i(qs),OA=n(qs,"P",{});var MDe=s(OA);TZe=r(MDe,"This class cannot be instantiated directly using "),kte=n(MDe,"CODE",{});var PQr=s(kte);MZe=r(PQr,"__init__()"),PQr.forEach(t),EZe=r(MDe," (throws an error)."),MDe.forEach(t),CZe=i(qs),Cr=n(qs,"DIV",{class:!0});var js=s(Cr);T(VA.$$.fragment,js),wZe=i(js),Ste=n(js,"P",{});var BQr=s(Ste);AZe=r(BQr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),BQr.forEach(t),yZe=i(js),Aa=n(js,"P",{});var R0=s(Aa);LZe=r(R0,"The tokenizer class to instantiate is selected based on the "),Rte=n(R0,"CODE",{});var IQr=s(Rte);xZe=r(IQr,"model_type"),IQr.forEach(t),$Ze=r(R0,` property of the config object (either
passed as an argument or loaded from `),Pte=n(R0,"CODE",{});var NQr=s(Pte);kZe=r(NQr,"pretrained_model_name_or_path"),NQr.forEach(t),SZe=r(R0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bte=n(R0,"CODE",{});var qQr=s(Bte);RZe=r(qQr,"pretrained_model_name_or_path"),qQr.forEach(t),PZe=r(R0,":"),R0.forEach(t),BZe=i(js),k=n(js,"UL",{});var S=s(k);Sn=n(S,"LI",{});var Xx=s(Sn);Ite=n(Xx,"STRONG",{});var jQr=s(Ite);IZe=r(jQr,"albert"),jQr.forEach(t),NZe=r(Xx," \u2014 "),sR=n(Xx,"A",{href:!0});var DQr=s(sR);qZe=r(DQr,"AlbertTokenizer"),DQr.forEach(t),jZe=r(Xx," or "),lR=n(Xx,"A",{href:!0});var GQr=s(lR);DZe=r(GQr,"AlbertTokenizerFast"),GQr.forEach(t),GZe=r(Xx," (ALBERT model)"),Xx.forEach(t),OZe=i(S),Rn=n(S,"LI",{});var zx=s(Rn);Nte=n(zx,"STRONG",{});var OQr=s(Nte);VZe=r(OQr,"bart"),OQr.forEach(t),XZe=r(zx," \u2014 "),iR=n(zx,"A",{href:!0});var VQr=s(iR);zZe=r(VQr,"BartTokenizer"),VQr.forEach(t),WZe=r(zx," or "),dR=n(zx,"A",{href:!0});var XQr=s(dR);QZe=r(XQr,"BartTokenizerFast"),XQr.forEach(t),HZe=r(zx," (BART model)"),zx.forEach(t),UZe=i(S),Pn=n(S,"LI",{});var Wx=s(Pn);qte=n(Wx,"STRONG",{});var zQr=s(qte);JZe=r(zQr,"barthez"),zQr.forEach(t),YZe=r(Wx," \u2014 "),cR=n(Wx,"A",{href:!0});var WQr=s(cR);KZe=r(WQr,"BarthezTokenizer"),WQr.forEach(t),ZZe=r(Wx," or "),fR=n(Wx,"A",{href:!0});var QQr=s(fR);eeo=r(QQr,"BarthezTokenizerFast"),QQr.forEach(t),oeo=r(Wx," (BARThez model)"),Wx.forEach(t),reo=i(S),Lg=n(S,"LI",{});var L0e=s(Lg);jte=n(L0e,"STRONG",{});var HQr=s(jte);teo=r(HQr,"bartpho"),HQr.forEach(t),aeo=r(L0e," \u2014 "),mR=n(L0e,"A",{href:!0});var UQr=s(mR);neo=r(UQr,"BartphoTokenizer"),UQr.forEach(t),seo=r(L0e," (BARTpho model)"),L0e.forEach(t),leo=i(S),Bn=n(S,"LI",{});var Qx=s(Bn);Dte=n(Qx,"STRONG",{});var JQr=s(Dte);ieo=r(JQr,"bert"),JQr.forEach(t),deo=r(Qx," \u2014 "),gR=n(Qx,"A",{href:!0});var YQr=s(gR);ceo=r(YQr,"BertTokenizer"),YQr.forEach(t),feo=r(Qx," or "),hR=n(Qx,"A",{href:!0});var KQr=s(hR);meo=r(KQr,"BertTokenizerFast"),KQr.forEach(t),geo=r(Qx," (BERT model)"),Qx.forEach(t),heo=i(S),xg=n(S,"LI",{});var x0e=s(xg);Gte=n(x0e,"STRONG",{});var ZQr=s(Gte);peo=r(ZQr,"bert-generation"),ZQr.forEach(t),_eo=r(x0e," \u2014 "),pR=n(x0e,"A",{href:!0});var eHr=s(pR);ueo=r(eHr,"BertGenerationTokenizer"),eHr.forEach(t),beo=r(x0e," (Bert Generation model)"),x0e.forEach(t),veo=i(S),$g=n(S,"LI",{});var $0e=s($g);Ote=n($0e,"STRONG",{});var oHr=s(Ote);Feo=r(oHr,"bert-japanese"),oHr.forEach(t),Teo=r($0e," \u2014 "),_R=n($0e,"A",{href:!0});var rHr=s(_R);Meo=r(rHr,"BertJapaneseTokenizer"),rHr.forEach(t),Eeo=r($0e," (BertJapanese model)"),$0e.forEach(t),Ceo=i(S),kg=n(S,"LI",{});var k0e=s(kg);Vte=n(k0e,"STRONG",{});var tHr=s(Vte);weo=r(tHr,"bertweet"),tHr.forEach(t),Aeo=r(k0e," \u2014 "),uR=n(k0e,"A",{href:!0});var aHr=s(uR);yeo=r(aHr,"BertweetTokenizer"),aHr.forEach(t),Leo=r(k0e," (Bertweet model)"),k0e.forEach(t),xeo=i(S),In=n(S,"LI",{});var Hx=s(In);Xte=n(Hx,"STRONG",{});var nHr=s(Xte);$eo=r(nHr,"big_bird"),nHr.forEach(t),keo=r(Hx," \u2014 "),bR=n(Hx,"A",{href:!0});var sHr=s(bR);Seo=r(sHr,"BigBirdTokenizer"),sHr.forEach(t),Reo=r(Hx," or "),vR=n(Hx,"A",{href:!0});var lHr=s(vR);Peo=r(lHr,"BigBirdTokenizerFast"),lHr.forEach(t),Beo=r(Hx," (BigBird model)"),Hx.forEach(t),Ieo=i(S),Nn=n(S,"LI",{});var Ux=s(Nn);zte=n(Ux,"STRONG",{});var iHr=s(zte);Neo=r(iHr,"bigbird_pegasus"),iHr.forEach(t),qeo=r(Ux," \u2014 "),FR=n(Ux,"A",{href:!0});var dHr=s(FR);jeo=r(dHr,"PegasusTokenizer"),dHr.forEach(t),Deo=r(Ux," or "),TR=n(Ux,"A",{href:!0});var cHr=s(TR);Geo=r(cHr,"PegasusTokenizerFast"),cHr.forEach(t),Oeo=r(Ux," (BigBirdPegasus model)"),Ux.forEach(t),Veo=i(S),qn=n(S,"LI",{});var Jx=s(qn);Wte=n(Jx,"STRONG",{});var fHr=s(Wte);Xeo=r(fHr,"blenderbot"),fHr.forEach(t),zeo=r(Jx," \u2014 "),MR=n(Jx,"A",{href:!0});var mHr=s(MR);Weo=r(mHr,"BlenderbotTokenizer"),mHr.forEach(t),Qeo=r(Jx," or "),ER=n(Jx,"A",{href:!0});var gHr=s(ER);Heo=r(gHr,"BlenderbotTokenizerFast"),gHr.forEach(t),Ueo=r(Jx," (Blenderbot model)"),Jx.forEach(t),Jeo=i(S),Sg=n(S,"LI",{});var S0e=s(Sg);Qte=n(S0e,"STRONG",{});var hHr=s(Qte);Yeo=r(hHr,"blenderbot-small"),hHr.forEach(t),Keo=r(S0e," \u2014 "),CR=n(S0e,"A",{href:!0});var pHr=s(CR);Zeo=r(pHr,"BlenderbotSmallTokenizer"),pHr.forEach(t),eoo=r(S0e," (BlenderbotSmall model)"),S0e.forEach(t),ooo=i(S),Rg=n(S,"LI",{});var R0e=s(Rg);Hte=n(R0e,"STRONG",{});var _Hr=s(Hte);roo=r(_Hr,"byt5"),_Hr.forEach(t),too=r(R0e," \u2014 "),wR=n(R0e,"A",{href:!0});var uHr=s(wR);aoo=r(uHr,"ByT5Tokenizer"),uHr.forEach(t),noo=r(R0e," (ByT5 model)"),R0e.forEach(t),soo=i(S),jn=n(S,"LI",{});var Yx=s(jn);Ute=n(Yx,"STRONG",{});var bHr=s(Ute);loo=r(bHr,"camembert"),bHr.forEach(t),ioo=r(Yx," \u2014 "),AR=n(Yx,"A",{href:!0});var vHr=s(AR);doo=r(vHr,"CamembertTokenizer"),vHr.forEach(t),coo=r(Yx," or "),yR=n(Yx,"A",{href:!0});var FHr=s(yR);foo=r(FHr,"CamembertTokenizerFast"),FHr.forEach(t),moo=r(Yx," (CamemBERT model)"),Yx.forEach(t),goo=i(S),Pg=n(S,"LI",{});var P0e=s(Pg);Jte=n(P0e,"STRONG",{});var THr=s(Jte);hoo=r(THr,"canine"),THr.forEach(t),poo=r(P0e," \u2014 "),LR=n(P0e,"A",{href:!0});var MHr=s(LR);_oo=r(MHr,"CanineTokenizer"),MHr.forEach(t),uoo=r(P0e," (Canine model)"),P0e.forEach(t),boo=i(S),Dn=n(S,"LI",{});var Kx=s(Dn);Yte=n(Kx,"STRONG",{});var EHr=s(Yte);voo=r(EHr,"clip"),EHr.forEach(t),Foo=r(Kx," \u2014 "),xR=n(Kx,"A",{href:!0});var CHr=s(xR);Too=r(CHr,"CLIPTokenizer"),CHr.forEach(t),Moo=r(Kx," or "),$R=n(Kx,"A",{href:!0});var wHr=s($R);Eoo=r(wHr,"CLIPTokenizerFast"),wHr.forEach(t),Coo=r(Kx," (CLIP model)"),Kx.forEach(t),woo=i(S),Gn=n(S,"LI",{});var Zx=s(Gn);Kte=n(Zx,"STRONG",{});var AHr=s(Kte);Aoo=r(AHr,"codegen"),AHr.forEach(t),yoo=r(Zx," \u2014 "),kR=n(Zx,"A",{href:!0});var yHr=s(kR);Loo=r(yHr,"GPT2Tokenizer"),yHr.forEach(t),xoo=r(Zx," or "),SR=n(Zx,"A",{href:!0});var LHr=s(SR);$oo=r(LHr,"GPT2TokenizerFast"),LHr.forEach(t),koo=r(Zx," (CodeGen model)"),Zx.forEach(t),Soo=i(S),On=n(S,"LI",{});var e$=s(On);Zte=n(e$,"STRONG",{});var xHr=s(Zte);Roo=r(xHr,"convbert"),xHr.forEach(t),Poo=r(e$," \u2014 "),RR=n(e$,"A",{href:!0});var $Hr=s(RR);Boo=r($Hr,"ConvBertTokenizer"),$Hr.forEach(t),Ioo=r(e$," or "),PR=n(e$,"A",{href:!0});var kHr=s(PR);Noo=r(kHr,"ConvBertTokenizerFast"),kHr.forEach(t),qoo=r(e$," (ConvBERT model)"),e$.forEach(t),joo=i(S),Vn=n(S,"LI",{});var o$=s(Vn);eae=n(o$,"STRONG",{});var SHr=s(eae);Doo=r(SHr,"cpm"),SHr.forEach(t),Goo=r(o$," \u2014 "),BR=n(o$,"A",{href:!0});var RHr=s(BR);Ooo=r(RHr,"CpmTokenizer"),RHr.forEach(t),Voo=r(o$," or "),IR=n(o$,"A",{href:!0});var PHr=s(IR);Xoo=r(PHr,"CpmTokenizerFast"),PHr.forEach(t),zoo=r(o$," (CPM model)"),o$.forEach(t),Woo=i(S),Bg=n(S,"LI",{});var B0e=s(Bg);oae=n(B0e,"STRONG",{});var BHr=s(oae);Qoo=r(BHr,"ctrl"),BHr.forEach(t),Hoo=r(B0e," \u2014 "),NR=n(B0e,"A",{href:!0});var IHr=s(NR);Uoo=r(IHr,"CTRLTokenizer"),IHr.forEach(t),Joo=r(B0e," (CTRL model)"),B0e.forEach(t),Yoo=i(S),Xn=n(S,"LI",{});var r$=s(Xn);rae=n(r$,"STRONG",{});var NHr=s(rae);Koo=r(NHr,"data2vec-text"),NHr.forEach(t),Zoo=r(r$," \u2014 "),qR=n(r$,"A",{href:!0});var qHr=s(qR);ero=r(qHr,"RobertaTokenizer"),qHr.forEach(t),oro=r(r$," or "),jR=n(r$,"A",{href:!0});var jHr=s(jR);rro=r(jHr,"RobertaTokenizerFast"),jHr.forEach(t),tro=r(r$," (Data2VecText model)"),r$.forEach(t),aro=i(S),zn=n(S,"LI",{});var t$=s(zn);tae=n(t$,"STRONG",{});var DHr=s(tae);nro=r(DHr,"deberta"),DHr.forEach(t),sro=r(t$," \u2014 "),DR=n(t$,"A",{href:!0});var GHr=s(DR);lro=r(GHr,"DebertaTokenizer"),GHr.forEach(t),iro=r(t$," or "),GR=n(t$,"A",{href:!0});var OHr=s(GR);dro=r(OHr,"DebertaTokenizerFast"),OHr.forEach(t),cro=r(t$," (DeBERTa model)"),t$.forEach(t),fro=i(S),Wn=n(S,"LI",{});var a$=s(Wn);aae=n(a$,"STRONG",{});var VHr=s(aae);mro=r(VHr,"deberta-v2"),VHr.forEach(t),gro=r(a$," \u2014 "),OR=n(a$,"A",{href:!0});var XHr=s(OR);hro=r(XHr,"DebertaV2Tokenizer"),XHr.forEach(t),pro=r(a$," or "),VR=n(a$,"A",{href:!0});var zHr=s(VR);_ro=r(zHr,"DebertaV2TokenizerFast"),zHr.forEach(t),uro=r(a$," (DeBERTa-v2 model)"),a$.forEach(t),bro=i(S),Qn=n(S,"LI",{});var n$=s(Qn);nae=n(n$,"STRONG",{});var WHr=s(nae);vro=r(WHr,"distilbert"),WHr.forEach(t),Fro=r(n$," \u2014 "),XR=n(n$,"A",{href:!0});var QHr=s(XR);Tro=r(QHr,"DistilBertTokenizer"),QHr.forEach(t),Mro=r(n$," or "),zR=n(n$,"A",{href:!0});var HHr=s(zR);Ero=r(HHr,"DistilBertTokenizerFast"),HHr.forEach(t),Cro=r(n$," (DistilBERT model)"),n$.forEach(t),wro=i(S),Hn=n(S,"LI",{});var s$=s(Hn);sae=n(s$,"STRONG",{});var UHr=s(sae);Aro=r(UHr,"dpr"),UHr.forEach(t),yro=r(s$," \u2014 "),WR=n(s$,"A",{href:!0});var JHr=s(WR);Lro=r(JHr,"DPRQuestionEncoderTokenizer"),JHr.forEach(t),xro=r(s$," or "),QR=n(s$,"A",{href:!0});var YHr=s(QR);$ro=r(YHr,"DPRQuestionEncoderTokenizerFast"),YHr.forEach(t),kro=r(s$," (DPR model)"),s$.forEach(t),Sro=i(S),Un=n(S,"LI",{});var l$=s(Un);lae=n(l$,"STRONG",{});var KHr=s(lae);Rro=r(KHr,"electra"),KHr.forEach(t),Pro=r(l$," \u2014 "),HR=n(l$,"A",{href:!0});var ZHr=s(HR);Bro=r(ZHr,"ElectraTokenizer"),ZHr.forEach(t),Iro=r(l$," or "),UR=n(l$,"A",{href:!0});var eUr=s(UR);Nro=r(eUr,"ElectraTokenizerFast"),eUr.forEach(t),qro=r(l$," (ELECTRA model)"),l$.forEach(t),jro=i(S),Ig=n(S,"LI",{});var I0e=s(Ig);iae=n(I0e,"STRONG",{});var oUr=s(iae);Dro=r(oUr,"flaubert"),oUr.forEach(t),Gro=r(I0e," \u2014 "),JR=n(I0e,"A",{href:!0});var rUr=s(JR);Oro=r(rUr,"FlaubertTokenizer"),rUr.forEach(t),Vro=r(I0e," (FlauBERT model)"),I0e.forEach(t),Xro=i(S),Jn=n(S,"LI",{});var i$=s(Jn);dae=n(i$,"STRONG",{});var tUr=s(dae);zro=r(tUr,"fnet"),tUr.forEach(t),Wro=r(i$," \u2014 "),YR=n(i$,"A",{href:!0});var aUr=s(YR);Qro=r(aUr,"FNetTokenizer"),aUr.forEach(t),Hro=r(i$," or "),KR=n(i$,"A",{href:!0});var nUr=s(KR);Uro=r(nUr,"FNetTokenizerFast"),nUr.forEach(t),Jro=r(i$," (FNet model)"),i$.forEach(t),Yro=i(S),Ng=n(S,"LI",{});var N0e=s(Ng);cae=n(N0e,"STRONG",{});var sUr=s(cae);Kro=r(sUr,"fsmt"),sUr.forEach(t),Zro=r(N0e," \u2014 "),ZR=n(N0e,"A",{href:!0});var lUr=s(ZR);eto=r(lUr,"FSMTTokenizer"),lUr.forEach(t),oto=r(N0e," (FairSeq Machine-Translation model)"),N0e.forEach(t),rto=i(S),Yn=n(S,"LI",{});var d$=s(Yn);fae=n(d$,"STRONG",{});var iUr=s(fae);tto=r(iUr,"funnel"),iUr.forEach(t),ato=r(d$," \u2014 "),eP=n(d$,"A",{href:!0});var dUr=s(eP);nto=r(dUr,"FunnelTokenizer"),dUr.forEach(t),sto=r(d$," or "),oP=n(d$,"A",{href:!0});var cUr=s(oP);lto=r(cUr,"FunnelTokenizerFast"),cUr.forEach(t),ito=r(d$," (Funnel Transformer model)"),d$.forEach(t),dto=i(S),Kn=n(S,"LI",{});var c$=s(Kn);mae=n(c$,"STRONG",{});var fUr=s(mae);cto=r(fUr,"gpt2"),fUr.forEach(t),fto=r(c$," \u2014 "),rP=n(c$,"A",{href:!0});var mUr=s(rP);mto=r(mUr,"GPT2Tokenizer"),mUr.forEach(t),gto=r(c$," or "),tP=n(c$,"A",{href:!0});var gUr=s(tP);hto=r(gUr,"GPT2TokenizerFast"),gUr.forEach(t),pto=r(c$," (OpenAI GPT-2 model)"),c$.forEach(t),_to=i(S),Zn=n(S,"LI",{});var f$=s(Zn);gae=n(f$,"STRONG",{});var hUr=s(gae);uto=r(hUr,"gpt_neo"),hUr.forEach(t),bto=r(f$," \u2014 "),aP=n(f$,"A",{href:!0});var pUr=s(aP);vto=r(pUr,"GPT2Tokenizer"),pUr.forEach(t),Fto=r(f$," or "),nP=n(f$,"A",{href:!0});var _Ur=s(nP);Tto=r(_Ur,"GPT2TokenizerFast"),_Ur.forEach(t),Mto=r(f$," (GPT Neo model)"),f$.forEach(t),Eto=i(S),qg=n(S,"LI",{});var q0e=s(qg);hae=n(q0e,"STRONG",{});var uUr=s(hae);Cto=r(uUr,"gpt_neox"),uUr.forEach(t),wto=r(q0e," \u2014 "),sP=n(q0e,"A",{href:!0});var bUr=s(sP);Ato=r(bUr,"GPTNeoXTokenizerFast"),bUr.forEach(t),yto=r(q0e," (GPT NeoX model)"),q0e.forEach(t),Lto=i(S),es=n(S,"LI",{});var m$=s(es);pae=n(m$,"STRONG",{});var vUr=s(pae);xto=r(vUr,"gptj"),vUr.forEach(t),$to=r(m$," \u2014 "),lP=n(m$,"A",{href:!0});var FUr=s(lP);kto=r(FUr,"GPT2Tokenizer"),FUr.forEach(t),Sto=r(m$," or "),iP=n(m$,"A",{href:!0});var TUr=s(iP);Rto=r(TUr,"GPT2TokenizerFast"),TUr.forEach(t),Pto=r(m$," (GPT-J model)"),m$.forEach(t),Bto=i(S),os=n(S,"LI",{});var g$=s(os);_ae=n(g$,"STRONG",{});var MUr=s(_ae);Ito=r(MUr,"herbert"),MUr.forEach(t),Nto=r(g$," \u2014 "),dP=n(g$,"A",{href:!0});var EUr=s(dP);qto=r(EUr,"HerbertTokenizer"),EUr.forEach(t),jto=r(g$," or "),cP=n(g$,"A",{href:!0});var CUr=s(cP);Dto=r(CUr,"HerbertTokenizerFast"),CUr.forEach(t),Gto=r(g$," (HerBERT model)"),g$.forEach(t),Oto=i(S),jg=n(S,"LI",{});var j0e=s(jg);uae=n(j0e,"STRONG",{});var wUr=s(uae);Vto=r(wUr,"hubert"),wUr.forEach(t),Xto=r(j0e," \u2014 "),fP=n(j0e,"A",{href:!0});var AUr=s(fP);zto=r(AUr,"Wav2Vec2CTCTokenizer"),AUr.forEach(t),Wto=r(j0e," (Hubert model)"),j0e.forEach(t),Qto=i(S),rs=n(S,"LI",{});var h$=s(rs);bae=n(h$,"STRONG",{});var yUr=s(bae);Hto=r(yUr,"ibert"),yUr.forEach(t),Uto=r(h$," \u2014 "),mP=n(h$,"A",{href:!0});var LUr=s(mP);Jto=r(LUr,"RobertaTokenizer"),LUr.forEach(t),Yto=r(h$," or "),gP=n(h$,"A",{href:!0});var xUr=s(gP);Kto=r(xUr,"RobertaTokenizerFast"),xUr.forEach(t),Zto=r(h$," (I-BERT model)"),h$.forEach(t),eao=i(S),ts=n(S,"LI",{});var p$=s(ts);vae=n(p$,"STRONG",{});var $Ur=s(vae);oao=r($Ur,"layoutlm"),$Ur.forEach(t),rao=r(p$," \u2014 "),hP=n(p$,"A",{href:!0});var kUr=s(hP);tao=r(kUr,"LayoutLMTokenizer"),kUr.forEach(t),aao=r(p$," or "),pP=n(p$,"A",{href:!0});var SUr=s(pP);nao=r(SUr,"LayoutLMTokenizerFast"),SUr.forEach(t),sao=r(p$," (LayoutLM model)"),p$.forEach(t),lao=i(S),as=n(S,"LI",{});var _$=s(as);Fae=n(_$,"STRONG",{});var RUr=s(Fae);iao=r(RUr,"layoutlmv2"),RUr.forEach(t),dao=r(_$," \u2014 "),_P=n(_$,"A",{href:!0});var PUr=s(_P);cao=r(PUr,"LayoutLMv2Tokenizer"),PUr.forEach(t),fao=r(_$," or "),uP=n(_$,"A",{href:!0});var BUr=s(uP);mao=r(BUr,"LayoutLMv2TokenizerFast"),BUr.forEach(t),gao=r(_$," (LayoutLMv2 model)"),_$.forEach(t),hao=i(S),ns=n(S,"LI",{});var u$=s(ns);Tae=n(u$,"STRONG",{});var IUr=s(Tae);pao=r(IUr,"layoutlmv3"),IUr.forEach(t),_ao=r(u$," \u2014 "),bP=n(u$,"A",{href:!0});var NUr=s(bP);uao=r(NUr,"LayoutLMv3Tokenizer"),NUr.forEach(t),bao=r(u$," or "),vP=n(u$,"A",{href:!0});var qUr=s(vP);vao=r(qUr,"LayoutLMv3TokenizerFast"),qUr.forEach(t),Fao=r(u$," (LayoutLMv3 model)"),u$.forEach(t),Tao=i(S),ss=n(S,"LI",{});var b$=s(ss);Mae=n(b$,"STRONG",{});var jUr=s(Mae);Mao=r(jUr,"layoutxlm"),jUr.forEach(t),Eao=r(b$," \u2014 "),FP=n(b$,"A",{href:!0});var DUr=s(FP);Cao=r(DUr,"LayoutXLMTokenizer"),DUr.forEach(t),wao=r(b$," or "),TP=n(b$,"A",{href:!0});var GUr=s(TP);Aao=r(GUr,"LayoutXLMTokenizerFast"),GUr.forEach(t),yao=r(b$," (LayoutXLM model)"),b$.forEach(t),Lao=i(S),ls=n(S,"LI",{});var v$=s(ls);Eae=n(v$,"STRONG",{});var OUr=s(Eae);xao=r(OUr,"led"),OUr.forEach(t),$ao=r(v$," \u2014 "),MP=n(v$,"A",{href:!0});var VUr=s(MP);kao=r(VUr,"LEDTokenizer"),VUr.forEach(t),Sao=r(v$," or "),EP=n(v$,"A",{href:!0});var XUr=s(EP);Rao=r(XUr,"LEDTokenizerFast"),XUr.forEach(t),Pao=r(v$," (LED model)"),v$.forEach(t),Bao=i(S),is=n(S,"LI",{});var F$=s(is);Cae=n(F$,"STRONG",{});var zUr=s(Cae);Iao=r(zUr,"longformer"),zUr.forEach(t),Nao=r(F$," \u2014 "),CP=n(F$,"A",{href:!0});var WUr=s(CP);qao=r(WUr,"LongformerTokenizer"),WUr.forEach(t),jao=r(F$," or "),wP=n(F$,"A",{href:!0});var QUr=s(wP);Dao=r(QUr,"LongformerTokenizerFast"),QUr.forEach(t),Gao=r(F$," (Longformer model)"),F$.forEach(t),Oao=i(S),Dg=n(S,"LI",{});var D0e=s(Dg);wae=n(D0e,"STRONG",{});var HUr=s(wae);Vao=r(HUr,"luke"),HUr.forEach(t),Xao=r(D0e," \u2014 "),AP=n(D0e,"A",{href:!0});var UUr=s(AP);zao=r(UUr,"LukeTokenizer"),UUr.forEach(t),Wao=r(D0e," (LUKE model)"),D0e.forEach(t),Qao=i(S),ds=n(S,"LI",{});var T$=s(ds);Aae=n(T$,"STRONG",{});var JUr=s(Aae);Hao=r(JUr,"lxmert"),JUr.forEach(t),Uao=r(T$," \u2014 "),yP=n(T$,"A",{href:!0});var YUr=s(yP);Jao=r(YUr,"LxmertTokenizer"),YUr.forEach(t),Yao=r(T$," or "),LP=n(T$,"A",{href:!0});var KUr=s(LP);Kao=r(KUr,"LxmertTokenizerFast"),KUr.forEach(t),Zao=r(T$," (LXMERT model)"),T$.forEach(t),eno=i(S),Gg=n(S,"LI",{});var G0e=s(Gg);yae=n(G0e,"STRONG",{});var ZUr=s(yae);ono=r(ZUr,"m2m_100"),ZUr.forEach(t),rno=r(G0e," \u2014 "),xP=n(G0e,"A",{href:!0});var eJr=s(xP);tno=r(eJr,"M2M100Tokenizer"),eJr.forEach(t),ano=r(G0e," (M2M100 model)"),G0e.forEach(t),nno=i(S),Og=n(S,"LI",{});var O0e=s(Og);Lae=n(O0e,"STRONG",{});var oJr=s(Lae);sno=r(oJr,"marian"),oJr.forEach(t),lno=r(O0e," \u2014 "),$P=n(O0e,"A",{href:!0});var rJr=s($P);ino=r(rJr,"MarianTokenizer"),rJr.forEach(t),dno=r(O0e," (Marian model)"),O0e.forEach(t),cno=i(S),cs=n(S,"LI",{});var M$=s(cs);xae=n(M$,"STRONG",{});var tJr=s(xae);fno=r(tJr,"mbart"),tJr.forEach(t),mno=r(M$," \u2014 "),kP=n(M$,"A",{href:!0});var aJr=s(kP);gno=r(aJr,"MBartTokenizer"),aJr.forEach(t),hno=r(M$," or "),SP=n(M$,"A",{href:!0});var nJr=s(SP);pno=r(nJr,"MBartTokenizerFast"),nJr.forEach(t),_no=r(M$," (mBART model)"),M$.forEach(t),uno=i(S),fs=n(S,"LI",{});var E$=s(fs);$ae=n(E$,"STRONG",{});var sJr=s($ae);bno=r(sJr,"mbart50"),sJr.forEach(t),vno=r(E$," \u2014 "),RP=n(E$,"A",{href:!0});var lJr=s(RP);Fno=r(lJr,"MBart50Tokenizer"),lJr.forEach(t),Tno=r(E$," or "),PP=n(E$,"A",{href:!0});var iJr=s(PP);Mno=r(iJr,"MBart50TokenizerFast"),iJr.forEach(t),Eno=r(E$," (mBART-50 model)"),E$.forEach(t),Cno=i(S),ms=n(S,"LI",{});var C$=s(ms);kae=n(C$,"STRONG",{});var dJr=s(kae);wno=r(dJr,"megatron-bert"),dJr.forEach(t),Ano=r(C$," \u2014 "),BP=n(C$,"A",{href:!0});var cJr=s(BP);yno=r(cJr,"BertTokenizer"),cJr.forEach(t),Lno=r(C$," or "),IP=n(C$,"A",{href:!0});var fJr=s(IP);xno=r(fJr,"BertTokenizerFast"),fJr.forEach(t),$no=r(C$," (MegatronBert model)"),C$.forEach(t),kno=i(S),Vg=n(S,"LI",{});var V0e=s(Vg);Sae=n(V0e,"STRONG",{});var mJr=s(Sae);Sno=r(mJr,"mluke"),mJr.forEach(t),Rno=r(V0e," \u2014 "),NP=n(V0e,"A",{href:!0});var gJr=s(NP);Pno=r(gJr,"MLukeTokenizer"),gJr.forEach(t),Bno=r(V0e," (mLUKE model)"),V0e.forEach(t),Ino=i(S),gs=n(S,"LI",{});var w$=s(gs);Rae=n(w$,"STRONG",{});var hJr=s(Rae);Nno=r(hJr,"mobilebert"),hJr.forEach(t),qno=r(w$," \u2014 "),qP=n(w$,"A",{href:!0});var pJr=s(qP);jno=r(pJr,"MobileBertTokenizer"),pJr.forEach(t),Dno=r(w$," or "),jP=n(w$,"A",{href:!0});var _Jr=s(jP);Gno=r(_Jr,"MobileBertTokenizerFast"),_Jr.forEach(t),Ono=r(w$," (MobileBERT model)"),w$.forEach(t),Vno=i(S),hs=n(S,"LI",{});var A$=s(hs);Pae=n(A$,"STRONG",{});var uJr=s(Pae);Xno=r(uJr,"mpnet"),uJr.forEach(t),zno=r(A$," \u2014 "),DP=n(A$,"A",{href:!0});var bJr=s(DP);Wno=r(bJr,"MPNetTokenizer"),bJr.forEach(t),Qno=r(A$," or "),GP=n(A$,"A",{href:!0});var vJr=s(GP);Hno=r(vJr,"MPNetTokenizerFast"),vJr.forEach(t),Uno=r(A$," (MPNet model)"),A$.forEach(t),Jno=i(S),ps=n(S,"LI",{});var y$=s(ps);Bae=n(y$,"STRONG",{});var FJr=s(Bae);Yno=r(FJr,"mt5"),FJr.forEach(t),Kno=r(y$," \u2014 "),OP=n(y$,"A",{href:!0});var TJr=s(OP);Zno=r(TJr,"MT5Tokenizer"),TJr.forEach(t),eso=r(y$," or "),VP=n(y$,"A",{href:!0});var MJr=s(VP);oso=r(MJr,"MT5TokenizerFast"),MJr.forEach(t),rso=r(y$," (mT5 model)"),y$.forEach(t),tso=i(S),_s=n(S,"LI",{});var L$=s(_s);Iae=n(L$,"STRONG",{});var EJr=s(Iae);aso=r(EJr,"nystromformer"),EJr.forEach(t),nso=r(L$," \u2014 "),XP=n(L$,"A",{href:!0});var CJr=s(XP);sso=r(CJr,"AlbertTokenizer"),CJr.forEach(t),lso=r(L$," or "),zP=n(L$,"A",{href:!0});var wJr=s(zP);iso=r(wJr,"AlbertTokenizerFast"),wJr.forEach(t),dso=r(L$," (Nystromformer model)"),L$.forEach(t),cso=i(S),us=n(S,"LI",{});var x$=s(us);Nae=n(x$,"STRONG",{});var AJr=s(Nae);fso=r(AJr,"openai-gpt"),AJr.forEach(t),mso=r(x$," \u2014 "),WP=n(x$,"A",{href:!0});var yJr=s(WP);gso=r(yJr,"OpenAIGPTTokenizer"),yJr.forEach(t),hso=r(x$," or "),QP=n(x$,"A",{href:!0});var LJr=s(QP);pso=r(LJr,"OpenAIGPTTokenizerFast"),LJr.forEach(t),_so=r(x$," (OpenAI GPT model)"),x$.forEach(t),uso=i(S),Xg=n(S,"LI",{});var X0e=s(Xg);qae=n(X0e,"STRONG",{});var xJr=s(qae);bso=r(xJr,"opt"),xJr.forEach(t),vso=r(X0e," \u2014 "),HP=n(X0e,"A",{href:!0});var $Jr=s(HP);Fso=r($Jr,"GPT2Tokenizer"),$Jr.forEach(t),Tso=r(X0e," (OPT model)"),X0e.forEach(t),Mso=i(S),bs=n(S,"LI",{});var $$=s(bs);jae=n($$,"STRONG",{});var kJr=s(jae);Eso=r(kJr,"pegasus"),kJr.forEach(t),Cso=r($$," \u2014 "),UP=n($$,"A",{href:!0});var SJr=s(UP);wso=r(SJr,"PegasusTokenizer"),SJr.forEach(t),Aso=r($$," or "),JP=n($$,"A",{href:!0});var RJr=s(JP);yso=r(RJr,"PegasusTokenizerFast"),RJr.forEach(t),Lso=r($$," (Pegasus model)"),$$.forEach(t),xso=i(S),zg=n(S,"LI",{});var z0e=s(zg);Dae=n(z0e,"STRONG",{});var PJr=s(Dae);$so=r(PJr,"perceiver"),PJr.forEach(t),kso=r(z0e," \u2014 "),YP=n(z0e,"A",{href:!0});var BJr=s(YP);Sso=r(BJr,"PerceiverTokenizer"),BJr.forEach(t),Rso=r(z0e," (Perceiver model)"),z0e.forEach(t),Pso=i(S),Wg=n(S,"LI",{});var W0e=s(Wg);Gae=n(W0e,"STRONG",{});var IJr=s(Gae);Bso=r(IJr,"phobert"),IJr.forEach(t),Iso=r(W0e," \u2014 "),KP=n(W0e,"A",{href:!0});var NJr=s(KP);Nso=r(NJr,"PhobertTokenizer"),NJr.forEach(t),qso=r(W0e," (PhoBERT model)"),W0e.forEach(t),jso=i(S),Qg=n(S,"LI",{});var Q0e=s(Qg);Oae=n(Q0e,"STRONG",{});var qJr=s(Oae);Dso=r(qJr,"plbart"),qJr.forEach(t),Gso=r(Q0e," \u2014 "),ZP=n(Q0e,"A",{href:!0});var jJr=s(ZP);Oso=r(jJr,"PLBartTokenizer"),jJr.forEach(t),Vso=r(Q0e," (PLBart model)"),Q0e.forEach(t),Xso=i(S),Hg=n(S,"LI",{});var H0e=s(Hg);Vae=n(H0e,"STRONG",{});var DJr=s(Vae);zso=r(DJr,"prophetnet"),DJr.forEach(t),Wso=r(H0e," \u2014 "),eB=n(H0e,"A",{href:!0});var GJr=s(eB);Qso=r(GJr,"ProphetNetTokenizer"),GJr.forEach(t),Hso=r(H0e," (ProphetNet model)"),H0e.forEach(t),Uso=i(S),vs=n(S,"LI",{});var k$=s(vs);Xae=n(k$,"STRONG",{});var OJr=s(Xae);Jso=r(OJr,"qdqbert"),OJr.forEach(t),Yso=r(k$," \u2014 "),oB=n(k$,"A",{href:!0});var VJr=s(oB);Kso=r(VJr,"BertTokenizer"),VJr.forEach(t),Zso=r(k$," or "),rB=n(k$,"A",{href:!0});var XJr=s(rB);elo=r(XJr,"BertTokenizerFast"),XJr.forEach(t),olo=r(k$," (QDQBert model)"),k$.forEach(t),rlo=i(S),Ug=n(S,"LI",{});var U0e=s(Ug);zae=n(U0e,"STRONG",{});var zJr=s(zae);tlo=r(zJr,"rag"),zJr.forEach(t),alo=r(U0e," \u2014 "),tB=n(U0e,"A",{href:!0});var WJr=s(tB);nlo=r(WJr,"RagTokenizer"),WJr.forEach(t),slo=r(U0e," (RAG model)"),U0e.forEach(t),llo=i(S),Fs=n(S,"LI",{});var S$=s(Fs);Wae=n(S$,"STRONG",{});var QJr=s(Wae);ilo=r(QJr,"realm"),QJr.forEach(t),dlo=r(S$," \u2014 "),aB=n(S$,"A",{href:!0});var HJr=s(aB);clo=r(HJr,"RealmTokenizer"),HJr.forEach(t),flo=r(S$," or "),nB=n(S$,"A",{href:!0});var UJr=s(nB);mlo=r(UJr,"RealmTokenizerFast"),UJr.forEach(t),glo=r(S$," (Realm model)"),S$.forEach(t),hlo=i(S),Ts=n(S,"LI",{});var R$=s(Ts);Qae=n(R$,"STRONG",{});var JJr=s(Qae);plo=r(JJr,"reformer"),JJr.forEach(t),_lo=r(R$," \u2014 "),sB=n(R$,"A",{href:!0});var YJr=s(sB);ulo=r(YJr,"ReformerTokenizer"),YJr.forEach(t),blo=r(R$," or "),lB=n(R$,"A",{href:!0});var KJr=s(lB);vlo=r(KJr,"ReformerTokenizerFast"),KJr.forEach(t),Flo=r(R$," (Reformer model)"),R$.forEach(t),Tlo=i(S),Ms=n(S,"LI",{});var P$=s(Ms);Hae=n(P$,"STRONG",{});var ZJr=s(Hae);Mlo=r(ZJr,"rembert"),ZJr.forEach(t),Elo=r(P$," \u2014 "),iB=n(P$,"A",{href:!0});var eYr=s(iB);Clo=r(eYr,"RemBertTokenizer"),eYr.forEach(t),wlo=r(P$," or "),dB=n(P$,"A",{href:!0});var oYr=s(dB);Alo=r(oYr,"RemBertTokenizerFast"),oYr.forEach(t),ylo=r(P$," (RemBERT model)"),P$.forEach(t),Llo=i(S),Es=n(S,"LI",{});var B$=s(Es);Uae=n(B$,"STRONG",{});var rYr=s(Uae);xlo=r(rYr,"retribert"),rYr.forEach(t),$lo=r(B$," \u2014 "),cB=n(B$,"A",{href:!0});var tYr=s(cB);klo=r(tYr,"RetriBertTokenizer"),tYr.forEach(t),Slo=r(B$," or "),fB=n(B$,"A",{href:!0});var aYr=s(fB);Rlo=r(aYr,"RetriBertTokenizerFast"),aYr.forEach(t),Plo=r(B$," (RetriBERT model)"),B$.forEach(t),Blo=i(S),Cs=n(S,"LI",{});var I$=s(Cs);Jae=n(I$,"STRONG",{});var nYr=s(Jae);Ilo=r(nYr,"roberta"),nYr.forEach(t),Nlo=r(I$," \u2014 "),mB=n(I$,"A",{href:!0});var sYr=s(mB);qlo=r(sYr,"RobertaTokenizer"),sYr.forEach(t),jlo=r(I$," or "),gB=n(I$,"A",{href:!0});var lYr=s(gB);Dlo=r(lYr,"RobertaTokenizerFast"),lYr.forEach(t),Glo=r(I$," (RoBERTa model)"),I$.forEach(t),Olo=i(S),ws=n(S,"LI",{});var N$=s(ws);Yae=n(N$,"STRONG",{});var iYr=s(Yae);Vlo=r(iYr,"roformer"),iYr.forEach(t),Xlo=r(N$," \u2014 "),hB=n(N$,"A",{href:!0});var dYr=s(hB);zlo=r(dYr,"RoFormerTokenizer"),dYr.forEach(t),Wlo=r(N$," or "),pB=n(N$,"A",{href:!0});var cYr=s(pB);Qlo=r(cYr,"RoFormerTokenizerFast"),cYr.forEach(t),Hlo=r(N$," (RoFormer model)"),N$.forEach(t),Ulo=i(S),Jg=n(S,"LI",{});var J0e=s(Jg);Kae=n(J0e,"STRONG",{});var fYr=s(Kae);Jlo=r(fYr,"speech_to_text"),fYr.forEach(t),Ylo=r(J0e," \u2014 "),_B=n(J0e,"A",{href:!0});var mYr=s(_B);Klo=r(mYr,"Speech2TextTokenizer"),mYr.forEach(t),Zlo=r(J0e," (Speech2Text model)"),J0e.forEach(t),eio=i(S),Yg=n(S,"LI",{});var Y0e=s(Yg);Zae=n(Y0e,"STRONG",{});var gYr=s(Zae);oio=r(gYr,"speech_to_text_2"),gYr.forEach(t),rio=r(Y0e," \u2014 "),uB=n(Y0e,"A",{href:!0});var hYr=s(uB);tio=r(hYr,"Speech2Text2Tokenizer"),hYr.forEach(t),aio=r(Y0e," (Speech2Text2 model)"),Y0e.forEach(t),nio=i(S),As=n(S,"LI",{});var q$=s(As);ene=n(q$,"STRONG",{});var pYr=s(ene);sio=r(pYr,"splinter"),pYr.forEach(t),lio=r(q$," \u2014 "),bB=n(q$,"A",{href:!0});var _Yr=s(bB);iio=r(_Yr,"SplinterTokenizer"),_Yr.forEach(t),dio=r(q$," or "),vB=n(q$,"A",{href:!0});var uYr=s(vB);cio=r(uYr,"SplinterTokenizerFast"),uYr.forEach(t),fio=r(q$," (Splinter model)"),q$.forEach(t),mio=i(S),ys=n(S,"LI",{});var j$=s(ys);one=n(j$,"STRONG",{});var bYr=s(one);gio=r(bYr,"squeezebert"),bYr.forEach(t),hio=r(j$," \u2014 "),FB=n(j$,"A",{href:!0});var vYr=s(FB);pio=r(vYr,"SqueezeBertTokenizer"),vYr.forEach(t),_io=r(j$," or "),TB=n(j$,"A",{href:!0});var FYr=s(TB);uio=r(FYr,"SqueezeBertTokenizerFast"),FYr.forEach(t),bio=r(j$," (SqueezeBERT model)"),j$.forEach(t),vio=i(S),Ls=n(S,"LI",{});var D$=s(Ls);rne=n(D$,"STRONG",{});var TYr=s(rne);Fio=r(TYr,"t5"),TYr.forEach(t),Tio=r(D$," \u2014 "),MB=n(D$,"A",{href:!0});var MYr=s(MB);Mio=r(MYr,"T5Tokenizer"),MYr.forEach(t),Eio=r(D$," or "),EB=n(D$,"A",{href:!0});var EYr=s(EB);Cio=r(EYr,"T5TokenizerFast"),EYr.forEach(t),wio=r(D$," (T5 model)"),D$.forEach(t),Aio=i(S),Kg=n(S,"LI",{});var K0e=s(Kg);tne=n(K0e,"STRONG",{});var CYr=s(tne);yio=r(CYr,"tapas"),CYr.forEach(t),Lio=r(K0e," \u2014 "),CB=n(K0e,"A",{href:!0});var wYr=s(CB);xio=r(wYr,"TapasTokenizer"),wYr.forEach(t),$io=r(K0e," (TAPAS model)"),K0e.forEach(t),kio=i(S),Zg=n(S,"LI",{});var Z0e=s(Zg);ane=n(Z0e,"STRONG",{});var AYr=s(ane);Sio=r(AYr,"tapex"),AYr.forEach(t),Rio=r(Z0e," \u2014 "),wB=n(Z0e,"A",{href:!0});var yYr=s(wB);Pio=r(yYr,"TapexTokenizer"),yYr.forEach(t),Bio=r(Z0e," (TAPEX model)"),Z0e.forEach(t),Iio=i(S),eh=n(S,"LI",{});var e6e=s(eh);nne=n(e6e,"STRONG",{});var LYr=s(nne);Nio=r(LYr,"transfo-xl"),LYr.forEach(t),qio=r(e6e," \u2014 "),AB=n(e6e,"A",{href:!0});var xYr=s(AB);jio=r(xYr,"TransfoXLTokenizer"),xYr.forEach(t),Dio=r(e6e," (Transformer-XL model)"),e6e.forEach(t),Gio=i(S),xs=n(S,"LI",{});var G$=s(xs);sne=n(G$,"STRONG",{});var $Yr=s(sne);Oio=r($Yr,"visual_bert"),$Yr.forEach(t),Vio=r(G$," \u2014 "),yB=n(G$,"A",{href:!0});var kYr=s(yB);Xio=r(kYr,"BertTokenizer"),kYr.forEach(t),zio=r(G$," or "),LB=n(G$,"A",{href:!0});var SYr=s(LB);Wio=r(SYr,"BertTokenizerFast"),SYr.forEach(t),Qio=r(G$," (VisualBert model)"),G$.forEach(t),Hio=i(S),oh=n(S,"LI",{});var o6e=s(oh);lne=n(o6e,"STRONG",{});var RYr=s(lne);Uio=r(RYr,"wav2vec2"),RYr.forEach(t),Jio=r(o6e," \u2014 "),xB=n(o6e,"A",{href:!0});var PYr=s(xB);Yio=r(PYr,"Wav2Vec2CTCTokenizer"),PYr.forEach(t),Kio=r(o6e," (Wav2Vec2 model)"),o6e.forEach(t),Zio=i(S),rh=n(S,"LI",{});var r6e=s(rh);ine=n(r6e,"STRONG",{});var BYr=s(ine);edo=r(BYr,"wav2vec2-conformer"),BYr.forEach(t),odo=r(r6e," \u2014 "),$B=n(r6e,"A",{href:!0});var IYr=s($B);rdo=r(IYr,"Wav2Vec2CTCTokenizer"),IYr.forEach(t),tdo=r(r6e," (Wav2Vec2-Conformer model)"),r6e.forEach(t),ado=i(S),th=n(S,"LI",{});var t6e=s(th);dne=n(t6e,"STRONG",{});var NYr=s(dne);ndo=r(NYr,"wav2vec2_phoneme"),NYr.forEach(t),sdo=r(t6e," \u2014 "),kB=n(t6e,"A",{href:!0});var qYr=s(kB);ldo=r(qYr,"Wav2Vec2PhonemeCTCTokenizer"),qYr.forEach(t),ido=r(t6e," (Wav2Vec2Phoneme model)"),t6e.forEach(t),ddo=i(S),$s=n(S,"LI",{});var O$=s($s);cne=n(O$,"STRONG",{});var jYr=s(cne);cdo=r(jYr,"xglm"),jYr.forEach(t),fdo=r(O$," \u2014 "),SB=n(O$,"A",{href:!0});var DYr=s(SB);mdo=r(DYr,"XGLMTokenizer"),DYr.forEach(t),gdo=r(O$," or "),RB=n(O$,"A",{href:!0});var GYr=s(RB);hdo=r(GYr,"XGLMTokenizerFast"),GYr.forEach(t),pdo=r(O$," (XGLM model)"),O$.forEach(t),_do=i(S),ah=n(S,"LI",{});var a6e=s(ah);fne=n(a6e,"STRONG",{});var OYr=s(fne);udo=r(OYr,"xlm"),OYr.forEach(t),bdo=r(a6e," \u2014 "),PB=n(a6e,"A",{href:!0});var VYr=s(PB);vdo=r(VYr,"XLMTokenizer"),VYr.forEach(t),Fdo=r(a6e," (XLM model)"),a6e.forEach(t),Tdo=i(S),nh=n(S,"LI",{});var n6e=s(nh);mne=n(n6e,"STRONG",{});var XYr=s(mne);Mdo=r(XYr,"xlm-prophetnet"),XYr.forEach(t),Edo=r(n6e," \u2014 "),BB=n(n6e,"A",{href:!0});var zYr=s(BB);Cdo=r(zYr,"XLMProphetNetTokenizer"),zYr.forEach(t),wdo=r(n6e," (XLMProphetNet model)"),n6e.forEach(t),Ado=i(S),ks=n(S,"LI",{});var V$=s(ks);gne=n(V$,"STRONG",{});var WYr=s(gne);ydo=r(WYr,"xlm-roberta"),WYr.forEach(t),Ldo=r(V$," \u2014 "),IB=n(V$,"A",{href:!0});var QYr=s(IB);xdo=r(QYr,"XLMRobertaTokenizer"),QYr.forEach(t),$do=r(V$," or "),NB=n(V$,"A",{href:!0});var HYr=s(NB);kdo=r(HYr,"XLMRobertaTokenizerFast"),HYr.forEach(t),Sdo=r(V$," (XLM-RoBERTa model)"),V$.forEach(t),Rdo=i(S),Ss=n(S,"LI",{});var X$=s(Ss);hne=n(X$,"STRONG",{});var UYr=s(hne);Pdo=r(UYr,"xlm-roberta-xl"),UYr.forEach(t),Bdo=r(X$," \u2014 "),qB=n(X$,"A",{href:!0});var JYr=s(qB);Ido=r(JYr,"RobertaTokenizer"),JYr.forEach(t),Ndo=r(X$," or "),jB=n(X$,"A",{href:!0});var YYr=s(jB);qdo=r(YYr,"RobertaTokenizerFast"),YYr.forEach(t),jdo=r(X$," (XLM-RoBERTa-XL model)"),X$.forEach(t),Ddo=i(S),Rs=n(S,"LI",{});var z$=s(Rs);pne=n(z$,"STRONG",{});var KYr=s(pne);Gdo=r(KYr,"xlnet"),KYr.forEach(t),Odo=r(z$," \u2014 "),DB=n(z$,"A",{href:!0});var ZYr=s(DB);Vdo=r(ZYr,"XLNetTokenizer"),ZYr.forEach(t),Xdo=r(z$," or "),GB=n(z$,"A",{href:!0});var eKr=s(GB);zdo=r(eKr,"XLNetTokenizerFast"),eKr.forEach(t),Wdo=r(z$," (XLNet model)"),z$.forEach(t),Qdo=i(S),Ps=n(S,"LI",{});var W$=s(Ps);_ne=n(W$,"STRONG",{});var oKr=s(_ne);Hdo=r(oKr,"yoso"),oKr.forEach(t),Udo=r(W$," \u2014 "),OB=n(W$,"A",{href:!0});var rKr=s(OB);Jdo=r(rKr,"AlbertTokenizer"),rKr.forEach(t),Ydo=r(W$," or "),VB=n(W$,"A",{href:!0});var tKr=s(VB);Kdo=r(tKr,"AlbertTokenizerFast"),tKr.forEach(t),Zdo=r(W$," (YOSO model)"),W$.forEach(t),S.forEach(t),eco=i(js),T(sh.$$.fragment,js),js.forEach(t),oco=i(qs),lh=n(qs,"DIV",{class:!0});var EDe=s(lh);T(XA.$$.fragment,EDe),rco=i(EDe),une=n(EDe,"P",{});var aKr=s(une);tco=r(aKr,"Register a new tokenizer in this mapping."),aKr.forEach(t),EDe.forEach(t),qs.forEach(t),Cqe=i(f),Ei=n(f,"H2",{class:!0});var CDe=s(Ei);ih=n(CDe,"A",{id:!0,class:!0,href:!0});var nKr=s(ih);bne=n(nKr,"SPAN",{});var sKr=s(bne);T(zA.$$.fragment,sKr),sKr.forEach(t),nKr.forEach(t),aco=i(CDe),vne=n(CDe,"SPAN",{});var lKr=s(vne);nco=r(lKr,"AutoFeatureExtractor"),lKr.forEach(t),CDe.forEach(t),wqe=i(f),Ao=n(f,"DIV",{class:!0});var Ds=s(Ao);T(WA.$$.fragment,Ds),sco=i(Ds),QA=n(Ds,"P",{});var wDe=s(QA);lco=r(wDe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),XB=n(wDe,"A",{href:!0});var iKr=s(XB);ico=r(iKr,"AutoFeatureExtractor.from_pretrained()"),iKr.forEach(t),dco=r(wDe," class method."),wDe.forEach(t),cco=i(Ds),HA=n(Ds,"P",{});var ADe=s(HA);fco=r(ADe,"This class cannot be instantiated directly using "),Fne=n(ADe,"CODE",{});var dKr=s(Fne);mco=r(dKr,"__init__()"),dKr.forEach(t),gco=r(ADe," (throws an error)."),ADe.forEach(t),hco=i(Ds),He=n(Ds,"DIV",{class:!0});var Zt=s(He);T(UA.$$.fragment,Zt),pco=i(Zt),Tne=n(Zt,"P",{});var cKr=s(Tne);_co=r(cKr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),cKr.forEach(t),uco=i(Zt),ya=n(Zt,"P",{});var P0=s(ya);bco=r(P0,"The feature extractor class to instantiate is selected based on the "),Mne=n(P0,"CODE",{});var fKr=s(Mne);vco=r(fKr,"model_type"),fKr.forEach(t),Fco=r(P0,` property of the config object
(either passed as an argument or loaded from `),Ene=n(P0,"CODE",{});var mKr=s(Ene);Tco=r(mKr,"pretrained_model_name_or_path"),mKr.forEach(t),Mco=r(P0,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Cne=n(P0,"CODE",{});var gKr=s(Cne);Eco=r(gKr,"pretrained_model_name_or_path"),gKr.forEach(t),Cco=r(P0,":"),P0.forEach(t),wco=i(Zt),Y=n(Zt,"UL",{});var Z=s(Y);dh=n(Z,"LI",{});var s6e=s(dh);wne=n(s6e,"STRONG",{});var hKr=s(wne);Aco=r(hKr,"beit"),hKr.forEach(t),yco=r(s6e," \u2014 "),zB=n(s6e,"A",{href:!0});var pKr=s(zB);Lco=r(pKr,"BeitFeatureExtractor"),pKr.forEach(t),xco=r(s6e," (BEiT model)"),s6e.forEach(t),$co=i(Z),ch=n(Z,"LI",{});var l6e=s(ch);Ane=n(l6e,"STRONG",{});var _Kr=s(Ane);kco=r(_Kr,"clip"),_Kr.forEach(t),Sco=r(l6e," \u2014 "),WB=n(l6e,"A",{href:!0});var uKr=s(WB);Rco=r(uKr,"CLIPFeatureExtractor"),uKr.forEach(t),Pco=r(l6e," (CLIP model)"),l6e.forEach(t),Bco=i(Z),fh=n(Z,"LI",{});var i6e=s(fh);yne=n(i6e,"STRONG",{});var bKr=s(yne);Ico=r(bKr,"convnext"),bKr.forEach(t),Nco=r(i6e," \u2014 "),QB=n(i6e,"A",{href:!0});var vKr=s(QB);qco=r(vKr,"ConvNextFeatureExtractor"),vKr.forEach(t),jco=r(i6e," (ConvNext model)"),i6e.forEach(t),Dco=i(Z),mh=n(Z,"LI",{});var d6e=s(mh);Lne=n(d6e,"STRONG",{});var FKr=s(Lne);Gco=r(FKr,"cvt"),FKr.forEach(t),Oco=r(d6e," \u2014 "),HB=n(d6e,"A",{href:!0});var TKr=s(HB);Vco=r(TKr,"ConvNextFeatureExtractor"),TKr.forEach(t),Xco=r(d6e," (CvT model)"),d6e.forEach(t),zco=i(Z),gh=n(Z,"LI",{});var c6e=s(gh);xne=n(c6e,"STRONG",{});var MKr=s(xne);Wco=r(MKr,"data2vec-audio"),MKr.forEach(t),Qco=r(c6e," \u2014 "),UB=n(c6e,"A",{href:!0});var EKr=s(UB);Hco=r(EKr,"Wav2Vec2FeatureExtractor"),EKr.forEach(t),Uco=r(c6e," (Data2VecAudio model)"),c6e.forEach(t),Jco=i(Z),hh=n(Z,"LI",{});var f6e=s(hh);$ne=n(f6e,"STRONG",{});var CKr=s($ne);Yco=r(CKr,"data2vec-vision"),CKr.forEach(t),Kco=r(f6e," \u2014 "),JB=n(f6e,"A",{href:!0});var wKr=s(JB);Zco=r(wKr,"BeitFeatureExtractor"),wKr.forEach(t),efo=r(f6e," (Data2VecVision model)"),f6e.forEach(t),ofo=i(Z),ph=n(Z,"LI",{});var m6e=s(ph);kne=n(m6e,"STRONG",{});var AKr=s(kne);rfo=r(AKr,"deit"),AKr.forEach(t),tfo=r(m6e," \u2014 "),YB=n(m6e,"A",{href:!0});var yKr=s(YB);afo=r(yKr,"DeiTFeatureExtractor"),yKr.forEach(t),nfo=r(m6e," (DeiT model)"),m6e.forEach(t),sfo=i(Z),_h=n(Z,"LI",{});var g6e=s(_h);Sne=n(g6e,"STRONG",{});var LKr=s(Sne);lfo=r(LKr,"detr"),LKr.forEach(t),ifo=r(g6e," \u2014 "),KB=n(g6e,"A",{href:!0});var xKr=s(KB);dfo=r(xKr,"DetrFeatureExtractor"),xKr.forEach(t),cfo=r(g6e," (DETR model)"),g6e.forEach(t),ffo=i(Z),uh=n(Z,"LI",{});var h6e=s(uh);Rne=n(h6e,"STRONG",{});var $Kr=s(Rne);mfo=r($Kr,"dpt"),$Kr.forEach(t),gfo=r(h6e," \u2014 "),ZB=n(h6e,"A",{href:!0});var kKr=s(ZB);hfo=r(kKr,"DPTFeatureExtractor"),kKr.forEach(t),pfo=r(h6e," (DPT model)"),h6e.forEach(t),_fo=i(Z),bh=n(Z,"LI",{});var p6e=s(bh);Pne=n(p6e,"STRONG",{});var SKr=s(Pne);ufo=r(SKr,"flava"),SKr.forEach(t),bfo=r(p6e," \u2014 "),eI=n(p6e,"A",{href:!0});var RKr=s(eI);vfo=r(RKr,"FlavaFeatureExtractor"),RKr.forEach(t),Ffo=r(p6e," (Flava model)"),p6e.forEach(t),Tfo=i(Z),vh=n(Z,"LI",{});var _6e=s(vh);Bne=n(_6e,"STRONG",{});var PKr=s(Bne);Mfo=r(PKr,"glpn"),PKr.forEach(t),Efo=r(_6e," \u2014 "),oI=n(_6e,"A",{href:!0});var BKr=s(oI);Cfo=r(BKr,"GLPNFeatureExtractor"),BKr.forEach(t),wfo=r(_6e," (GLPN model)"),_6e.forEach(t),Afo=i(Z),Fh=n(Z,"LI",{});var u6e=s(Fh);Ine=n(u6e,"STRONG",{});var IKr=s(Ine);yfo=r(IKr,"hubert"),IKr.forEach(t),Lfo=r(u6e," \u2014 "),rI=n(u6e,"A",{href:!0});var NKr=s(rI);xfo=r(NKr,"Wav2Vec2FeatureExtractor"),NKr.forEach(t),$fo=r(u6e," (Hubert model)"),u6e.forEach(t),kfo=i(Z),Th=n(Z,"LI",{});var b6e=s(Th);Nne=n(b6e,"STRONG",{});var qKr=s(Nne);Sfo=r(qKr,"imagegpt"),qKr.forEach(t),Rfo=r(b6e," \u2014 "),tI=n(b6e,"A",{href:!0});var jKr=s(tI);Pfo=r(jKr,"ImageGPTFeatureExtractor"),jKr.forEach(t),Bfo=r(b6e," (ImageGPT model)"),b6e.forEach(t),Ifo=i(Z),Mh=n(Z,"LI",{});var v6e=s(Mh);qne=n(v6e,"STRONG",{});var DKr=s(qne);Nfo=r(DKr,"layoutlmv2"),DKr.forEach(t),qfo=r(v6e," \u2014 "),aI=n(v6e,"A",{href:!0});var GKr=s(aI);jfo=r(GKr,"LayoutLMv2FeatureExtractor"),GKr.forEach(t),Dfo=r(v6e," (LayoutLMv2 model)"),v6e.forEach(t),Gfo=i(Z),Eh=n(Z,"LI",{});var F6e=s(Eh);jne=n(F6e,"STRONG",{});var OKr=s(jne);Ofo=r(OKr,"layoutlmv3"),OKr.forEach(t),Vfo=r(F6e," \u2014 "),nI=n(F6e,"A",{href:!0});var VKr=s(nI);Xfo=r(VKr,"LayoutLMv3FeatureExtractor"),VKr.forEach(t),zfo=r(F6e," (LayoutLMv3 model)"),F6e.forEach(t),Wfo=i(Z),Ch=n(Z,"LI",{});var T6e=s(Ch);Dne=n(T6e,"STRONG",{});var XKr=s(Dne);Qfo=r(XKr,"maskformer"),XKr.forEach(t),Hfo=r(T6e," \u2014 "),sI=n(T6e,"A",{href:!0});var zKr=s(sI);Ufo=r(zKr,"MaskFormerFeatureExtractor"),zKr.forEach(t),Jfo=r(T6e," (MaskFormer model)"),T6e.forEach(t),Yfo=i(Z),wh=n(Z,"LI",{});var M6e=s(wh);Gne=n(M6e,"STRONG",{});var WKr=s(Gne);Kfo=r(WKr,"perceiver"),WKr.forEach(t),Zfo=r(M6e," \u2014 "),lI=n(M6e,"A",{href:!0});var QKr=s(lI);emo=r(QKr,"PerceiverFeatureExtractor"),QKr.forEach(t),omo=r(M6e," (Perceiver model)"),M6e.forEach(t),rmo=i(Z),Ah=n(Z,"LI",{});var E6e=s(Ah);One=n(E6e,"STRONG",{});var HKr=s(One);tmo=r(HKr,"poolformer"),HKr.forEach(t),amo=r(E6e," \u2014 "),iI=n(E6e,"A",{href:!0});var UKr=s(iI);nmo=r(UKr,"PoolFormerFeatureExtractor"),UKr.forEach(t),smo=r(E6e," (PoolFormer model)"),E6e.forEach(t),lmo=i(Z),yh=n(Z,"LI",{});var C6e=s(yh);Vne=n(C6e,"STRONG",{});var JKr=s(Vne);imo=r(JKr,"regnet"),JKr.forEach(t),dmo=r(C6e," \u2014 "),dI=n(C6e,"A",{href:!0});var YKr=s(dI);cmo=r(YKr,"ConvNextFeatureExtractor"),YKr.forEach(t),fmo=r(C6e," (RegNet model)"),C6e.forEach(t),mmo=i(Z),Lh=n(Z,"LI",{});var w6e=s(Lh);Xne=n(w6e,"STRONG",{});var KKr=s(Xne);gmo=r(KKr,"resnet"),KKr.forEach(t),hmo=r(w6e," \u2014 "),cI=n(w6e,"A",{href:!0});var ZKr=s(cI);pmo=r(ZKr,"ConvNextFeatureExtractor"),ZKr.forEach(t),_mo=r(w6e," (ResNet model)"),w6e.forEach(t),umo=i(Z),xh=n(Z,"LI",{});var A6e=s(xh);zne=n(A6e,"STRONG",{});var eZr=s(zne);bmo=r(eZr,"segformer"),eZr.forEach(t),vmo=r(A6e," \u2014 "),fI=n(A6e,"A",{href:!0});var oZr=s(fI);Fmo=r(oZr,"SegformerFeatureExtractor"),oZr.forEach(t),Tmo=r(A6e," (SegFormer model)"),A6e.forEach(t),Mmo=i(Z),$h=n(Z,"LI",{});var y6e=s($h);Wne=n(y6e,"STRONG",{});var rZr=s(Wne);Emo=r(rZr,"speech_to_text"),rZr.forEach(t),Cmo=r(y6e," \u2014 "),mI=n(y6e,"A",{href:!0});var tZr=s(mI);wmo=r(tZr,"Speech2TextFeatureExtractor"),tZr.forEach(t),Amo=r(y6e," (Speech2Text model)"),y6e.forEach(t),ymo=i(Z),kh=n(Z,"LI",{});var L6e=s(kh);Qne=n(L6e,"STRONG",{});var aZr=s(Qne);Lmo=r(aZr,"swin"),aZr.forEach(t),xmo=r(L6e," \u2014 "),gI=n(L6e,"A",{href:!0});var nZr=s(gI);$mo=r(nZr,"ViTFeatureExtractor"),nZr.forEach(t),kmo=r(L6e," (Swin model)"),L6e.forEach(t),Smo=i(Z),Sh=n(Z,"LI",{});var x6e=s(Sh);Hne=n(x6e,"STRONG",{});var sZr=s(Hne);Rmo=r(sZr,"van"),sZr.forEach(t),Pmo=r(x6e," \u2014 "),hI=n(x6e,"A",{href:!0});var lZr=s(hI);Bmo=r(lZr,"ConvNextFeatureExtractor"),lZr.forEach(t),Imo=r(x6e," (VAN model)"),x6e.forEach(t),Nmo=i(Z),Rh=n(Z,"LI",{});var $6e=s(Rh);Une=n($6e,"STRONG",{});var iZr=s(Une);qmo=r(iZr,"vit"),iZr.forEach(t),jmo=r($6e," \u2014 "),pI=n($6e,"A",{href:!0});var dZr=s(pI);Dmo=r(dZr,"ViTFeatureExtractor"),dZr.forEach(t),Gmo=r($6e," (ViT model)"),$6e.forEach(t),Omo=i(Z),Ph=n(Z,"LI",{});var k6e=s(Ph);Jne=n(k6e,"STRONG",{});var cZr=s(Jne);Vmo=r(cZr,"vit_mae"),cZr.forEach(t),Xmo=r(k6e," \u2014 "),_I=n(k6e,"A",{href:!0});var fZr=s(_I);zmo=r(fZr,"ViTFeatureExtractor"),fZr.forEach(t),Wmo=r(k6e," (ViTMAE model)"),k6e.forEach(t),Qmo=i(Z),Bh=n(Z,"LI",{});var S6e=s(Bh);Yne=n(S6e,"STRONG",{});var mZr=s(Yne);Hmo=r(mZr,"wav2vec2"),mZr.forEach(t),Umo=r(S6e," \u2014 "),uI=n(S6e,"A",{href:!0});var gZr=s(uI);Jmo=r(gZr,"Wav2Vec2FeatureExtractor"),gZr.forEach(t),Ymo=r(S6e," (Wav2Vec2 model)"),S6e.forEach(t),Kmo=i(Z),Ih=n(Z,"LI",{});var R6e=s(Ih);Kne=n(R6e,"STRONG",{});var hZr=s(Kne);Zmo=r(hZr,"wav2vec2-conformer"),hZr.forEach(t),ego=r(R6e," \u2014 "),bI=n(R6e,"A",{href:!0});var pZr=s(bI);ogo=r(pZr,"Wav2Vec2FeatureExtractor"),pZr.forEach(t),rgo=r(R6e," (Wav2Vec2-Conformer model)"),R6e.forEach(t),tgo=i(Z),Nh=n(Z,"LI",{});var P6e=s(Nh);Zne=n(P6e,"STRONG",{});var _Zr=s(Zne);ago=r(_Zr,"yolos"),_Zr.forEach(t),ngo=r(P6e," \u2014 "),vI=n(P6e,"A",{href:!0});var uZr=s(vI);sgo=r(uZr,"YolosFeatureExtractor"),uZr.forEach(t),lgo=r(P6e," (YOLOS model)"),P6e.forEach(t),Z.forEach(t),igo=i(Zt),T(qh.$$.fragment,Zt),dgo=i(Zt),T(jh.$$.fragment,Zt),Zt.forEach(t),cgo=i(Ds),Dh=n(Ds,"DIV",{class:!0});var yDe=s(Dh);T(JA.$$.fragment,yDe),fgo=i(yDe),ese=n(yDe,"P",{});var bZr=s(ese);mgo=r(bZr,"Register a new feature extractor for this class."),bZr.forEach(t),yDe.forEach(t),Ds.forEach(t),Aqe=i(f),Ci=n(f,"H2",{class:!0});var LDe=s(Ci);Gh=n(LDe,"A",{id:!0,class:!0,href:!0});var vZr=s(Gh);ose=n(vZr,"SPAN",{});var FZr=s(ose);T(YA.$$.fragment,FZr),FZr.forEach(t),vZr.forEach(t),ggo=i(LDe),rse=n(LDe,"SPAN",{});var TZr=s(rse);hgo=r(TZr,"AutoProcessor"),TZr.forEach(t),LDe.forEach(t),yqe=i(f),yo=n(f,"DIV",{class:!0});var Gs=s(yo);T(KA.$$.fragment,Gs),pgo=i(Gs),ZA=n(Gs,"P",{});var xDe=s(ZA);_go=r(xDe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),FI=n(xDe,"A",{href:!0});var MZr=s(FI);ugo=r(MZr,"AutoProcessor.from_pretrained()"),MZr.forEach(t),bgo=r(xDe," class method."),xDe.forEach(t),vgo=i(Gs),ey=n(Gs,"P",{});var $De=s(ey);Fgo=r($De,"This class cannot be instantiated directly using "),tse=n($De,"CODE",{});var EZr=s(tse);Tgo=r(EZr,"__init__()"),EZr.forEach(t),Mgo=r($De," (throws an error)."),$De.forEach(t),Ego=i(Gs),Ue=n(Gs,"DIV",{class:!0});var ea=s(Ue);T(oy.$$.fragment,ea),Cgo=i(ea),ase=n(ea,"P",{});var CZr=s(ase);wgo=r(CZr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),CZr.forEach(t),Ago=i(ea),wi=n(ea,"P",{});var CZ=s(wi);ygo=r(CZ,"The processor class to instantiate is selected based on the "),nse=n(CZ,"CODE",{});var wZr=s(nse);Lgo=r(wZr,"model_type"),wZr.forEach(t),xgo=r(CZ,` property of the config object (either
passed as an argument or loaded from `),sse=n(CZ,"CODE",{});var AZr=s(sse);$go=r(AZr,"pretrained_model_name_or_path"),AZr.forEach(t),kgo=r(CZ," if possible):"),CZ.forEach(t),Sgo=i(ea),he=n(ea,"UL",{});var ue=s(he);Oh=n(ue,"LI",{});var B6e=s(Oh);lse=n(B6e,"STRONG",{});var yZr=s(lse);Rgo=r(yZr,"clip"),yZr.forEach(t),Pgo=r(B6e," \u2014 "),TI=n(B6e,"A",{href:!0});var LZr=s(TI);Bgo=r(LZr,"CLIPProcessor"),LZr.forEach(t),Igo=r(B6e," (CLIP model)"),B6e.forEach(t),Ngo=i(ue),Vh=n(ue,"LI",{});var I6e=s(Vh);ise=n(I6e,"STRONG",{});var xZr=s(ise);qgo=r(xZr,"flava"),xZr.forEach(t),jgo=r(I6e," \u2014 "),dse=n(I6e,"CODE",{});var $Zr=s(dse);Dgo=r($Zr,"FLAVAProcessor"),$Zr.forEach(t),Ggo=r(I6e," (Flava model)"),I6e.forEach(t),Ogo=i(ue),Xh=n(ue,"LI",{});var N6e=s(Xh);cse=n(N6e,"STRONG",{});var kZr=s(cse);Vgo=r(kZr,"layoutlmv2"),kZr.forEach(t),Xgo=r(N6e," \u2014 "),MI=n(N6e,"A",{href:!0});var SZr=s(MI);zgo=r(SZr,"LayoutLMv2Processor"),SZr.forEach(t),Wgo=r(N6e," (LayoutLMv2 model)"),N6e.forEach(t),Qgo=i(ue),zh=n(ue,"LI",{});var q6e=s(zh);fse=n(q6e,"STRONG",{});var RZr=s(fse);Hgo=r(RZr,"layoutlmv3"),RZr.forEach(t),Ugo=r(q6e," \u2014 "),EI=n(q6e,"A",{href:!0});var PZr=s(EI);Jgo=r(PZr,"LayoutLMv3Processor"),PZr.forEach(t),Ygo=r(q6e," (LayoutLMv3 model)"),q6e.forEach(t),Kgo=i(ue),Wh=n(ue,"LI",{});var j6e=s(Wh);mse=n(j6e,"STRONG",{});var BZr=s(mse);Zgo=r(BZr,"layoutxlm"),BZr.forEach(t),eho=r(j6e," \u2014 "),CI=n(j6e,"A",{href:!0});var IZr=s(CI);oho=r(IZr,"LayoutXLMProcessor"),IZr.forEach(t),rho=r(j6e," (LayoutXLM model)"),j6e.forEach(t),tho=i(ue),Qh=n(ue,"LI",{});var D6e=s(Qh);gse=n(D6e,"STRONG",{});var NZr=s(gse);aho=r(NZr,"sew"),NZr.forEach(t),nho=r(D6e," \u2014 "),wI=n(D6e,"A",{href:!0});var qZr=s(wI);sho=r(qZr,"Wav2Vec2Processor"),qZr.forEach(t),lho=r(D6e," (SEW model)"),D6e.forEach(t),iho=i(ue),Hh=n(ue,"LI",{});var G6e=s(Hh);hse=n(G6e,"STRONG",{});var jZr=s(hse);dho=r(jZr,"sew-d"),jZr.forEach(t),cho=r(G6e," \u2014 "),AI=n(G6e,"A",{href:!0});var DZr=s(AI);fho=r(DZr,"Wav2Vec2Processor"),DZr.forEach(t),mho=r(G6e," (SEW-D model)"),G6e.forEach(t),gho=i(ue),Uh=n(ue,"LI",{});var O6e=s(Uh);pse=n(O6e,"STRONG",{});var GZr=s(pse);hho=r(GZr,"speech_to_text"),GZr.forEach(t),pho=r(O6e," \u2014 "),yI=n(O6e,"A",{href:!0});var OZr=s(yI);_ho=r(OZr,"Speech2TextProcessor"),OZr.forEach(t),uho=r(O6e," (Speech2Text model)"),O6e.forEach(t),bho=i(ue),Jh=n(ue,"LI",{});var V6e=s(Jh);_se=n(V6e,"STRONG",{});var VZr=s(_se);vho=r(VZr,"speech_to_text_2"),VZr.forEach(t),Fho=r(V6e," \u2014 "),LI=n(V6e,"A",{href:!0});var XZr=s(LI);Tho=r(XZr,"Speech2Text2Processor"),XZr.forEach(t),Mho=r(V6e," (Speech2Text2 model)"),V6e.forEach(t),Eho=i(ue),Yh=n(ue,"LI",{});var X6e=s(Yh);use=n(X6e,"STRONG",{});var zZr=s(use);Cho=r(zZr,"trocr"),zZr.forEach(t),who=r(X6e," \u2014 "),xI=n(X6e,"A",{href:!0});var WZr=s(xI);Aho=r(WZr,"TrOCRProcessor"),WZr.forEach(t),yho=r(X6e," (TrOCR model)"),X6e.forEach(t),Lho=i(ue),Kh=n(ue,"LI",{});var z6e=s(Kh);bse=n(z6e,"STRONG",{});var QZr=s(bse);xho=r(QZr,"unispeech"),QZr.forEach(t),$ho=r(z6e," \u2014 "),$I=n(z6e,"A",{href:!0});var HZr=s($I);kho=r(HZr,"Wav2Vec2Processor"),HZr.forEach(t),Sho=r(z6e," (UniSpeech model)"),z6e.forEach(t),Rho=i(ue),Zh=n(ue,"LI",{});var W6e=s(Zh);vse=n(W6e,"STRONG",{});var UZr=s(vse);Pho=r(UZr,"unispeech-sat"),UZr.forEach(t),Bho=r(W6e," \u2014 "),kI=n(W6e,"A",{href:!0});var JZr=s(kI);Iho=r(JZr,"Wav2Vec2Processor"),JZr.forEach(t),Nho=r(W6e," (UniSpeechSat model)"),W6e.forEach(t),qho=i(ue),ep=n(ue,"LI",{});var Q6e=s(ep);Fse=n(Q6e,"STRONG",{});var YZr=s(Fse);jho=r(YZr,"vilt"),YZr.forEach(t),Dho=r(Q6e," \u2014 "),SI=n(Q6e,"A",{href:!0});var KZr=s(SI);Gho=r(KZr,"ViltProcessor"),KZr.forEach(t),Oho=r(Q6e," (ViLT model)"),Q6e.forEach(t),Vho=i(ue),op=n(ue,"LI",{});var H6e=s(op);Tse=n(H6e,"STRONG",{});var ZZr=s(Tse);Xho=r(ZZr,"vision-text-dual-encoder"),ZZr.forEach(t),zho=r(H6e," \u2014 "),RI=n(H6e,"A",{href:!0});var eet=s(RI);Who=r(eet,"VisionTextDualEncoderProcessor"),eet.forEach(t),Qho=r(H6e," (VisionTextDualEncoder model)"),H6e.forEach(t),Hho=i(ue),rp=n(ue,"LI",{});var U6e=s(rp);Mse=n(U6e,"STRONG",{});var oet=s(Mse);Uho=r(oet,"wav2vec2"),oet.forEach(t),Jho=r(U6e," \u2014 "),PI=n(U6e,"A",{href:!0});var ret=s(PI);Yho=r(ret,"Wav2Vec2Processor"),ret.forEach(t),Kho=r(U6e," (Wav2Vec2 model)"),U6e.forEach(t),Zho=i(ue),tp=n(ue,"LI",{});var J6e=s(tp);Ese=n(J6e,"STRONG",{});var tet=s(Ese);epo=r(tet,"wav2vec2-conformer"),tet.forEach(t),opo=r(J6e," \u2014 "),BI=n(J6e,"A",{href:!0});var aet=s(BI);rpo=r(aet,"Wav2Vec2Processor"),aet.forEach(t),tpo=r(J6e," (Wav2Vec2-Conformer model)"),J6e.forEach(t),apo=i(ue),ap=n(ue,"LI",{});var Y6e=s(ap);Cse=n(Y6e,"STRONG",{});var net=s(Cse);npo=r(net,"wavlm"),net.forEach(t),spo=r(Y6e," \u2014 "),II=n(Y6e,"A",{href:!0});var set=s(II);lpo=r(set,"Wav2Vec2Processor"),set.forEach(t),ipo=r(Y6e," (WavLM model)"),Y6e.forEach(t),ue.forEach(t),dpo=i(ea),T(np.$$.fragment,ea),cpo=i(ea),T(sp.$$.fragment,ea),ea.forEach(t),fpo=i(Gs),lp=n(Gs,"DIV",{class:!0});var kDe=s(lp);T(ry.$$.fragment,kDe),mpo=i(kDe),wse=n(kDe,"P",{});var iet=s(wse);gpo=r(iet,"Register a new processor for this class."),iet.forEach(t),kDe.forEach(t),Gs.forEach(t),Lqe=i(f),Ai=n(f,"H2",{class:!0});var SDe=s(Ai);ip=n(SDe,"A",{id:!0,class:!0,href:!0});var det=s(ip);Ase=n(det,"SPAN",{});var cet=s(Ase);T(ty.$$.fragment,cet),cet.forEach(t),det.forEach(t),hpo=i(SDe),yse=n(SDe,"SPAN",{});var fet=s(yse);ppo=r(fet,"AutoModel"),fet.forEach(t),SDe.forEach(t),xqe=i(f),Lo=n(f,"DIV",{class:!0});var Os=s(Lo);T(ay.$$.fragment,Os),_po=i(Os),yi=n(Os,"P",{});var wZ=s(yi);upo=r(wZ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),NI=n(wZ,"A",{href:!0});var met=s(NI);bpo=r(met,"from_pretrained()"),met.forEach(t),vpo=r(wZ," class method or the "),qI=n(wZ,"A",{href:!0});var get=s(qI);Fpo=r(get,"from_config()"),get.forEach(t),Tpo=r(wZ,` class
method.`),wZ.forEach(t),Mpo=i(Os),ny=n(Os,"P",{});var RDe=s(ny);Epo=r(RDe,"This class cannot be instantiated directly using "),Lse=n(RDe,"CODE",{});var het=s(Lse);Cpo=r(het,"__init__()"),het.forEach(t),wpo=r(RDe," (throws an error)."),RDe.forEach(t),Apo=i(Os),tt=n(Os,"DIV",{class:!0});var B0=s(tt);T(sy.$$.fragment,B0),ypo=i(B0),xse=n(B0,"P",{});var pet=s(xse);Lpo=r(pet,"Instantiates one of the base model classes of the library from a configuration."),pet.forEach(t),xpo=i(B0),Li=n(B0,"P",{});var AZ=s(Li);$po=r(AZ,`Note:
Loading a model from its configuration file does `),$se=n(AZ,"STRONG",{});var _et=s($se);kpo=r(_et,"not"),_et.forEach(t),Spo=r(AZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),jI=n(AZ,"A",{href:!0});var uet=s(jI);Rpo=r(uet,"from_pretrained()"),uet.forEach(t),Ppo=r(AZ," to load the model weights."),AZ.forEach(t),Bpo=i(B0),T(dp.$$.fragment,B0),B0.forEach(t),Ipo=i(Os),Je=n(Os,"DIV",{class:!0});var oa=s(Je);T(ly.$$.fragment,oa),Npo=i(oa),kse=n(oa,"P",{});var bet=s(kse);qpo=r(bet,"Instantiate one of the base model classes of the library from a pretrained model."),bet.forEach(t),jpo=i(oa),La=n(oa,"P",{});var I0=s(La);Dpo=r(I0,"The model class to instantiate is selected based on the "),Sse=n(I0,"CODE",{});var vet=s(Sse);Gpo=r(vet,"model_type"),vet.forEach(t),Opo=r(I0,` property of the config object (either
passed as an argument or loaded from `),Rse=n(I0,"CODE",{});var Fet=s(Rse);Vpo=r(Fet,"pretrained_model_name_or_path"),Fet.forEach(t),Xpo=r(I0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pse=n(I0,"CODE",{});var Tet=s(Pse);zpo=r(Tet,"pretrained_model_name_or_path"),Tet.forEach(t),Wpo=r(I0,":"),I0.forEach(t),Qpo=i(oa),x=n(oa,"UL",{});var $=s(x);cp=n($,"LI",{});var K6e=s(cp);Bse=n(K6e,"STRONG",{});var Met=s(Bse);Hpo=r(Met,"albert"),Met.forEach(t),Upo=r(K6e," \u2014 "),DI=n(K6e,"A",{href:!0});var Eet=s(DI);Jpo=r(Eet,"AlbertModel"),Eet.forEach(t),Ypo=r(K6e," (ALBERT model)"),K6e.forEach(t),Kpo=i($),fp=n($,"LI",{});var Z6e=s(fp);Ise=n(Z6e,"STRONG",{});var Cet=s(Ise);Zpo=r(Cet,"bart"),Cet.forEach(t),e_o=r(Z6e," \u2014 "),GI=n(Z6e,"A",{href:!0});var wet=s(GI);o_o=r(wet,"BartModel"),wet.forEach(t),r_o=r(Z6e," (BART model)"),Z6e.forEach(t),t_o=i($),mp=n($,"LI",{});var eAe=s(mp);Nse=n(eAe,"STRONG",{});var Aet=s(Nse);a_o=r(Aet,"beit"),Aet.forEach(t),n_o=r(eAe," \u2014 "),OI=n(eAe,"A",{href:!0});var yet=s(OI);s_o=r(yet,"BeitModel"),yet.forEach(t),l_o=r(eAe," (BEiT model)"),eAe.forEach(t),i_o=i($),gp=n($,"LI",{});var oAe=s(gp);qse=n(oAe,"STRONG",{});var Let=s(qse);d_o=r(Let,"bert"),Let.forEach(t),c_o=r(oAe," \u2014 "),VI=n(oAe,"A",{href:!0});var xet=s(VI);f_o=r(xet,"BertModel"),xet.forEach(t),m_o=r(oAe," (BERT model)"),oAe.forEach(t),g_o=i($),hp=n($,"LI",{});var rAe=s(hp);jse=n(rAe,"STRONG",{});var $et=s(jse);h_o=r($et,"bert-generation"),$et.forEach(t),p_o=r(rAe," \u2014 "),XI=n(rAe,"A",{href:!0});var ket=s(XI);__o=r(ket,"BertGenerationEncoder"),ket.forEach(t),u_o=r(rAe," (Bert Generation model)"),rAe.forEach(t),b_o=i($),pp=n($,"LI",{});var tAe=s(pp);Dse=n(tAe,"STRONG",{});var Set=s(Dse);v_o=r(Set,"big_bird"),Set.forEach(t),F_o=r(tAe," \u2014 "),zI=n(tAe,"A",{href:!0});var Ret=s(zI);T_o=r(Ret,"BigBirdModel"),Ret.forEach(t),M_o=r(tAe," (BigBird model)"),tAe.forEach(t),E_o=i($),_p=n($,"LI",{});var aAe=s(_p);Gse=n(aAe,"STRONG",{});var Pet=s(Gse);C_o=r(Pet,"bigbird_pegasus"),Pet.forEach(t),w_o=r(aAe," \u2014 "),WI=n(aAe,"A",{href:!0});var Bet=s(WI);A_o=r(Bet,"BigBirdPegasusModel"),Bet.forEach(t),y_o=r(aAe," (BigBirdPegasus model)"),aAe.forEach(t),L_o=i($),up=n($,"LI",{});var nAe=s(up);Ose=n(nAe,"STRONG",{});var Iet=s(Ose);x_o=r(Iet,"blenderbot"),Iet.forEach(t),$_o=r(nAe," \u2014 "),QI=n(nAe,"A",{href:!0});var Net=s(QI);k_o=r(Net,"BlenderbotModel"),Net.forEach(t),S_o=r(nAe," (Blenderbot model)"),nAe.forEach(t),R_o=i($),bp=n($,"LI",{});var sAe=s(bp);Vse=n(sAe,"STRONG",{});var qet=s(Vse);P_o=r(qet,"blenderbot-small"),qet.forEach(t),B_o=r(sAe," \u2014 "),HI=n(sAe,"A",{href:!0});var jet=s(HI);I_o=r(jet,"BlenderbotSmallModel"),jet.forEach(t),N_o=r(sAe," (BlenderbotSmall model)"),sAe.forEach(t),q_o=i($),vp=n($,"LI",{});var lAe=s(vp);Xse=n(lAe,"STRONG",{});var Det=s(Xse);j_o=r(Det,"camembert"),Det.forEach(t),D_o=r(lAe," \u2014 "),UI=n(lAe,"A",{href:!0});var Get=s(UI);G_o=r(Get,"CamembertModel"),Get.forEach(t),O_o=r(lAe," (CamemBERT model)"),lAe.forEach(t),V_o=i($),Fp=n($,"LI",{});var iAe=s(Fp);zse=n(iAe,"STRONG",{});var Oet=s(zse);X_o=r(Oet,"canine"),Oet.forEach(t),z_o=r(iAe," \u2014 "),JI=n(iAe,"A",{href:!0});var Vet=s(JI);W_o=r(Vet,"CanineModel"),Vet.forEach(t),Q_o=r(iAe," (Canine model)"),iAe.forEach(t),H_o=i($),Tp=n($,"LI",{});var dAe=s(Tp);Wse=n(dAe,"STRONG",{});var Xet=s(Wse);U_o=r(Xet,"clip"),Xet.forEach(t),J_o=r(dAe," \u2014 "),YI=n(dAe,"A",{href:!0});var zet=s(YI);Y_o=r(zet,"CLIPModel"),zet.forEach(t),K_o=r(dAe," (CLIP model)"),dAe.forEach(t),Z_o=i($),Mp=n($,"LI",{});var cAe=s(Mp);Qse=n(cAe,"STRONG",{});var Wet=s(Qse);euo=r(Wet,"codegen"),Wet.forEach(t),ouo=r(cAe," \u2014 "),KI=n(cAe,"A",{href:!0});var Qet=s(KI);ruo=r(Qet,"CodeGenModel"),Qet.forEach(t),tuo=r(cAe," (CodeGen model)"),cAe.forEach(t),auo=i($),Ep=n($,"LI",{});var fAe=s(Ep);Hse=n(fAe,"STRONG",{});var Het=s(Hse);nuo=r(Het,"convbert"),Het.forEach(t),suo=r(fAe," \u2014 "),ZI=n(fAe,"A",{href:!0});var Uet=s(ZI);luo=r(Uet,"ConvBertModel"),Uet.forEach(t),iuo=r(fAe," (ConvBERT model)"),fAe.forEach(t),duo=i($),Cp=n($,"LI",{});var mAe=s(Cp);Use=n(mAe,"STRONG",{});var Jet=s(Use);cuo=r(Jet,"convnext"),Jet.forEach(t),fuo=r(mAe," \u2014 "),eN=n(mAe,"A",{href:!0});var Yet=s(eN);muo=r(Yet,"ConvNextModel"),Yet.forEach(t),guo=r(mAe," (ConvNext model)"),mAe.forEach(t),huo=i($),wp=n($,"LI",{});var gAe=s(wp);Jse=n(gAe,"STRONG",{});var Ket=s(Jse);puo=r(Ket,"ctrl"),Ket.forEach(t),_uo=r(gAe," \u2014 "),oN=n(gAe,"A",{href:!0});var Zet=s(oN);uuo=r(Zet,"CTRLModel"),Zet.forEach(t),buo=r(gAe," (CTRL model)"),gAe.forEach(t),vuo=i($),Ap=n($,"LI",{});var hAe=s(Ap);Yse=n(hAe,"STRONG",{});var eot=s(Yse);Fuo=r(eot,"cvt"),eot.forEach(t),Tuo=r(hAe," \u2014 "),rN=n(hAe,"A",{href:!0});var oot=s(rN);Muo=r(oot,"CvtModel"),oot.forEach(t),Euo=r(hAe," (CvT model)"),hAe.forEach(t),Cuo=i($),yp=n($,"LI",{});var pAe=s(yp);Kse=n(pAe,"STRONG",{});var rot=s(Kse);wuo=r(rot,"data2vec-audio"),rot.forEach(t),Auo=r(pAe," \u2014 "),tN=n(pAe,"A",{href:!0});var tot=s(tN);yuo=r(tot,"Data2VecAudioModel"),tot.forEach(t),Luo=r(pAe," (Data2VecAudio model)"),pAe.forEach(t),xuo=i($),Lp=n($,"LI",{});var _Ae=s(Lp);Zse=n(_Ae,"STRONG",{});var aot=s(Zse);$uo=r(aot,"data2vec-text"),aot.forEach(t),kuo=r(_Ae," \u2014 "),aN=n(_Ae,"A",{href:!0});var not=s(aN);Suo=r(not,"Data2VecTextModel"),not.forEach(t),Ruo=r(_Ae," (Data2VecText model)"),_Ae.forEach(t),Puo=i($),xp=n($,"LI",{});var uAe=s(xp);ele=n(uAe,"STRONG",{});var sot=s(ele);Buo=r(sot,"data2vec-vision"),sot.forEach(t),Iuo=r(uAe," \u2014 "),nN=n(uAe,"A",{href:!0});var lot=s(nN);Nuo=r(lot,"Data2VecVisionModel"),lot.forEach(t),quo=r(uAe," (Data2VecVision model)"),uAe.forEach(t),juo=i($),$p=n($,"LI",{});var bAe=s($p);ole=n(bAe,"STRONG",{});var iot=s(ole);Duo=r(iot,"deberta"),iot.forEach(t),Guo=r(bAe," \u2014 "),sN=n(bAe,"A",{href:!0});var dot=s(sN);Ouo=r(dot,"DebertaModel"),dot.forEach(t),Vuo=r(bAe," (DeBERTa model)"),bAe.forEach(t),Xuo=i($),kp=n($,"LI",{});var vAe=s(kp);rle=n(vAe,"STRONG",{});var cot=s(rle);zuo=r(cot,"deberta-v2"),cot.forEach(t),Wuo=r(vAe," \u2014 "),lN=n(vAe,"A",{href:!0});var fot=s(lN);Quo=r(fot,"DebertaV2Model"),fot.forEach(t),Huo=r(vAe," (DeBERTa-v2 model)"),vAe.forEach(t),Uuo=i($),Sp=n($,"LI",{});var FAe=s(Sp);tle=n(FAe,"STRONG",{});var mot=s(tle);Juo=r(mot,"decision_transformer"),mot.forEach(t),Yuo=r(FAe," \u2014 "),iN=n(FAe,"A",{href:!0});var got=s(iN);Kuo=r(got,"DecisionTransformerModel"),got.forEach(t),Zuo=r(FAe," (Decision Transformer model)"),FAe.forEach(t),e4o=i($),Rp=n($,"LI",{});var TAe=s(Rp);ale=n(TAe,"STRONG",{});var hot=s(ale);o4o=r(hot,"deit"),hot.forEach(t),r4o=r(TAe," \u2014 "),dN=n(TAe,"A",{href:!0});var pot=s(dN);t4o=r(pot,"DeiTModel"),pot.forEach(t),a4o=r(TAe," (DeiT model)"),TAe.forEach(t),n4o=i($),Pp=n($,"LI",{});var MAe=s(Pp);nle=n(MAe,"STRONG",{});var _ot=s(nle);s4o=r(_ot,"detr"),_ot.forEach(t),l4o=r(MAe," \u2014 "),cN=n(MAe,"A",{href:!0});var uot=s(cN);i4o=r(uot,"DetrModel"),uot.forEach(t),d4o=r(MAe," (DETR model)"),MAe.forEach(t),c4o=i($),Bp=n($,"LI",{});var EAe=s(Bp);sle=n(EAe,"STRONG",{});var bot=s(sle);f4o=r(bot,"distilbert"),bot.forEach(t),m4o=r(EAe," \u2014 "),fN=n(EAe,"A",{href:!0});var vot=s(fN);g4o=r(vot,"DistilBertModel"),vot.forEach(t),h4o=r(EAe," (DistilBERT model)"),EAe.forEach(t),p4o=i($),Ip=n($,"LI",{});var CAe=s(Ip);lle=n(CAe,"STRONG",{});var Fot=s(lle);_4o=r(Fot,"dpr"),Fot.forEach(t),u4o=r(CAe," \u2014 "),mN=n(CAe,"A",{href:!0});var Tot=s(mN);b4o=r(Tot,"DPRQuestionEncoder"),Tot.forEach(t),v4o=r(CAe," (DPR model)"),CAe.forEach(t),F4o=i($),Np=n($,"LI",{});var wAe=s(Np);ile=n(wAe,"STRONG",{});var Mot=s(ile);T4o=r(Mot,"dpt"),Mot.forEach(t),M4o=r(wAe," \u2014 "),gN=n(wAe,"A",{href:!0});var Eot=s(gN);E4o=r(Eot,"DPTModel"),Eot.forEach(t),C4o=r(wAe," (DPT model)"),wAe.forEach(t),w4o=i($),qp=n($,"LI",{});var AAe=s(qp);dle=n(AAe,"STRONG",{});var Cot=s(dle);A4o=r(Cot,"electra"),Cot.forEach(t),y4o=r(AAe," \u2014 "),hN=n(AAe,"A",{href:!0});var wot=s(hN);L4o=r(wot,"ElectraModel"),wot.forEach(t),x4o=r(AAe," (ELECTRA model)"),AAe.forEach(t),$4o=i($),jp=n($,"LI",{});var yAe=s(jp);cle=n(yAe,"STRONG",{});var Aot=s(cle);k4o=r(Aot,"flaubert"),Aot.forEach(t),S4o=r(yAe," \u2014 "),pN=n(yAe,"A",{href:!0});var yot=s(pN);R4o=r(yot,"FlaubertModel"),yot.forEach(t),P4o=r(yAe," (FlauBERT model)"),yAe.forEach(t),B4o=i($),Dp=n($,"LI",{});var LAe=s(Dp);fle=n(LAe,"STRONG",{});var Lot=s(fle);I4o=r(Lot,"flava"),Lot.forEach(t),N4o=r(LAe," \u2014 "),_N=n(LAe,"A",{href:!0});var xot=s(_N);q4o=r(xot,"FlavaModel"),xot.forEach(t),j4o=r(LAe," (Flava model)"),LAe.forEach(t),D4o=i($),Gp=n($,"LI",{});var xAe=s(Gp);mle=n(xAe,"STRONG",{});var $ot=s(mle);G4o=r($ot,"fnet"),$ot.forEach(t),O4o=r(xAe," \u2014 "),uN=n(xAe,"A",{href:!0});var kot=s(uN);V4o=r(kot,"FNetModel"),kot.forEach(t),X4o=r(xAe," (FNet model)"),xAe.forEach(t),z4o=i($),Op=n($,"LI",{});var $Ae=s(Op);gle=n($Ae,"STRONG",{});var Sot=s(gle);W4o=r(Sot,"fsmt"),Sot.forEach(t),Q4o=r($Ae," \u2014 "),bN=n($Ae,"A",{href:!0});var Rot=s(bN);H4o=r(Rot,"FSMTModel"),Rot.forEach(t),U4o=r($Ae," (FairSeq Machine-Translation model)"),$Ae.forEach(t),J4o=i($),Bs=n($,"LI",{});var Q$=s(Bs);hle=n(Q$,"STRONG",{});var Pot=s(hle);Y4o=r(Pot,"funnel"),Pot.forEach(t),K4o=r(Q$," \u2014 "),vN=n(Q$,"A",{href:!0});var Bot=s(vN);Z4o=r(Bot,"FunnelModel"),Bot.forEach(t),e1o=r(Q$," or "),FN=n(Q$,"A",{href:!0});var Iot=s(FN);o1o=r(Iot,"FunnelBaseModel"),Iot.forEach(t),r1o=r(Q$," (Funnel Transformer model)"),Q$.forEach(t),t1o=i($),Vp=n($,"LI",{});var kAe=s(Vp);ple=n(kAe,"STRONG",{});var Not=s(ple);a1o=r(Not,"glpn"),Not.forEach(t),n1o=r(kAe," \u2014 "),TN=n(kAe,"A",{href:!0});var qot=s(TN);s1o=r(qot,"GLPNModel"),qot.forEach(t),l1o=r(kAe," (GLPN model)"),kAe.forEach(t),i1o=i($),Xp=n($,"LI",{});var SAe=s(Xp);_le=n(SAe,"STRONG",{});var jot=s(_le);d1o=r(jot,"gpt2"),jot.forEach(t),c1o=r(SAe," \u2014 "),MN=n(SAe,"A",{href:!0});var Dot=s(MN);f1o=r(Dot,"GPT2Model"),Dot.forEach(t),m1o=r(SAe," (OpenAI GPT-2 model)"),SAe.forEach(t),g1o=i($),zp=n($,"LI",{});var RAe=s(zp);ule=n(RAe,"STRONG",{});var Got=s(ule);h1o=r(Got,"gpt_neo"),Got.forEach(t),p1o=r(RAe," \u2014 "),EN=n(RAe,"A",{href:!0});var Oot=s(EN);_1o=r(Oot,"GPTNeoModel"),Oot.forEach(t),u1o=r(RAe," (GPT Neo model)"),RAe.forEach(t),b1o=i($),Wp=n($,"LI",{});var PAe=s(Wp);ble=n(PAe,"STRONG",{});var Vot=s(ble);v1o=r(Vot,"gpt_neox"),Vot.forEach(t),F1o=r(PAe," \u2014 "),CN=n(PAe,"A",{href:!0});var Xot=s(CN);T1o=r(Xot,"GPTNeoXModel"),Xot.forEach(t),M1o=r(PAe," (GPT NeoX model)"),PAe.forEach(t),E1o=i($),Qp=n($,"LI",{});var BAe=s(Qp);vle=n(BAe,"STRONG",{});var zot=s(vle);C1o=r(zot,"gptj"),zot.forEach(t),w1o=r(BAe," \u2014 "),wN=n(BAe,"A",{href:!0});var Wot=s(wN);A1o=r(Wot,"GPTJModel"),Wot.forEach(t),y1o=r(BAe," (GPT-J model)"),BAe.forEach(t),L1o=i($),Hp=n($,"LI",{});var IAe=s(Hp);Fle=n(IAe,"STRONG",{});var Qot=s(Fle);x1o=r(Qot,"hubert"),Qot.forEach(t),$1o=r(IAe," \u2014 "),AN=n(IAe,"A",{href:!0});var Hot=s(AN);k1o=r(Hot,"HubertModel"),Hot.forEach(t),S1o=r(IAe," (Hubert model)"),IAe.forEach(t),R1o=i($),Up=n($,"LI",{});var NAe=s(Up);Tle=n(NAe,"STRONG",{});var Uot=s(Tle);P1o=r(Uot,"ibert"),Uot.forEach(t),B1o=r(NAe," \u2014 "),yN=n(NAe,"A",{href:!0});var Jot=s(yN);I1o=r(Jot,"IBertModel"),Jot.forEach(t),N1o=r(NAe," (I-BERT model)"),NAe.forEach(t),q1o=i($),Jp=n($,"LI",{});var qAe=s(Jp);Mle=n(qAe,"STRONG",{});var Yot=s(Mle);j1o=r(Yot,"imagegpt"),Yot.forEach(t),D1o=r(qAe," \u2014 "),LN=n(qAe,"A",{href:!0});var Kot=s(LN);G1o=r(Kot,"ImageGPTModel"),Kot.forEach(t),O1o=r(qAe," (ImageGPT model)"),qAe.forEach(t),V1o=i($),Yp=n($,"LI",{});var jAe=s(Yp);Ele=n(jAe,"STRONG",{});var Zot=s(Ele);X1o=r(Zot,"layoutlm"),Zot.forEach(t),z1o=r(jAe," \u2014 "),xN=n(jAe,"A",{href:!0});var ert=s(xN);W1o=r(ert,"LayoutLMModel"),ert.forEach(t),Q1o=r(jAe," (LayoutLM model)"),jAe.forEach(t),H1o=i($),Kp=n($,"LI",{});var DAe=s(Kp);Cle=n(DAe,"STRONG",{});var ort=s(Cle);U1o=r(ort,"layoutlmv2"),ort.forEach(t),J1o=r(DAe," \u2014 "),$N=n(DAe,"A",{href:!0});var rrt=s($N);Y1o=r(rrt,"LayoutLMv2Model"),rrt.forEach(t),K1o=r(DAe," (LayoutLMv2 model)"),DAe.forEach(t),Z1o=i($),Zp=n($,"LI",{});var GAe=s(Zp);wle=n(GAe,"STRONG",{});var trt=s(wle);ebo=r(trt,"layoutlmv3"),trt.forEach(t),obo=r(GAe," \u2014 "),kN=n(GAe,"A",{href:!0});var art=s(kN);rbo=r(art,"LayoutLMv3Model"),art.forEach(t),tbo=r(GAe," (LayoutLMv3 model)"),GAe.forEach(t),abo=i($),e_=n($,"LI",{});var OAe=s(e_);Ale=n(OAe,"STRONG",{});var nrt=s(Ale);nbo=r(nrt,"led"),nrt.forEach(t),sbo=r(OAe," \u2014 "),SN=n(OAe,"A",{href:!0});var srt=s(SN);lbo=r(srt,"LEDModel"),srt.forEach(t),ibo=r(OAe," (LED model)"),OAe.forEach(t),dbo=i($),o_=n($,"LI",{});var VAe=s(o_);yle=n(VAe,"STRONG",{});var lrt=s(yle);cbo=r(lrt,"longformer"),lrt.forEach(t),fbo=r(VAe," \u2014 "),RN=n(VAe,"A",{href:!0});var irt=s(RN);mbo=r(irt,"LongformerModel"),irt.forEach(t),gbo=r(VAe," (Longformer model)"),VAe.forEach(t),hbo=i($),r_=n($,"LI",{});var XAe=s(r_);Lle=n(XAe,"STRONG",{});var drt=s(Lle);pbo=r(drt,"luke"),drt.forEach(t),_bo=r(XAe," \u2014 "),PN=n(XAe,"A",{href:!0});var crt=s(PN);ubo=r(crt,"LukeModel"),crt.forEach(t),bbo=r(XAe," (LUKE model)"),XAe.forEach(t),vbo=i($),t_=n($,"LI",{});var zAe=s(t_);xle=n(zAe,"STRONG",{});var frt=s(xle);Fbo=r(frt,"lxmert"),frt.forEach(t),Tbo=r(zAe," \u2014 "),BN=n(zAe,"A",{href:!0});var mrt=s(BN);Mbo=r(mrt,"LxmertModel"),mrt.forEach(t),Ebo=r(zAe," (LXMERT model)"),zAe.forEach(t),Cbo=i($),a_=n($,"LI",{});var WAe=s(a_);$le=n(WAe,"STRONG",{});var grt=s($le);wbo=r(grt,"m2m_100"),grt.forEach(t),Abo=r(WAe," \u2014 "),IN=n(WAe,"A",{href:!0});var hrt=s(IN);ybo=r(hrt,"M2M100Model"),hrt.forEach(t),Lbo=r(WAe," (M2M100 model)"),WAe.forEach(t),xbo=i($),n_=n($,"LI",{});var QAe=s(n_);kle=n(QAe,"STRONG",{});var prt=s(kle);$bo=r(prt,"marian"),prt.forEach(t),kbo=r(QAe," \u2014 "),NN=n(QAe,"A",{href:!0});var _rt=s(NN);Sbo=r(_rt,"MarianModel"),_rt.forEach(t),Rbo=r(QAe," (Marian model)"),QAe.forEach(t),Pbo=i($),s_=n($,"LI",{});var HAe=s(s_);Sle=n(HAe,"STRONG",{});var urt=s(Sle);Bbo=r(urt,"maskformer"),urt.forEach(t),Ibo=r(HAe," \u2014 "),qN=n(HAe,"A",{href:!0});var brt=s(qN);Nbo=r(brt,"MaskFormerModel"),brt.forEach(t),qbo=r(HAe," (MaskFormer model)"),HAe.forEach(t),jbo=i($),l_=n($,"LI",{});var UAe=s(l_);Rle=n(UAe,"STRONG",{});var vrt=s(Rle);Dbo=r(vrt,"mbart"),vrt.forEach(t),Gbo=r(UAe," \u2014 "),jN=n(UAe,"A",{href:!0});var Frt=s(jN);Obo=r(Frt,"MBartModel"),Frt.forEach(t),Vbo=r(UAe," (mBART model)"),UAe.forEach(t),Xbo=i($),i_=n($,"LI",{});var JAe=s(i_);Ple=n(JAe,"STRONG",{});var Trt=s(Ple);zbo=r(Trt,"megatron-bert"),Trt.forEach(t),Wbo=r(JAe," \u2014 "),DN=n(JAe,"A",{href:!0});var Mrt=s(DN);Qbo=r(Mrt,"MegatronBertModel"),Mrt.forEach(t),Hbo=r(JAe," (MegatronBert model)"),JAe.forEach(t),Ubo=i($),d_=n($,"LI",{});var YAe=s(d_);Ble=n(YAe,"STRONG",{});var Ert=s(Ble);Jbo=r(Ert,"mobilebert"),Ert.forEach(t),Ybo=r(YAe," \u2014 "),GN=n(YAe,"A",{href:!0});var Crt=s(GN);Kbo=r(Crt,"MobileBertModel"),Crt.forEach(t),Zbo=r(YAe," (MobileBERT model)"),YAe.forEach(t),e2o=i($),c_=n($,"LI",{});var KAe=s(c_);Ile=n(KAe,"STRONG",{});var wrt=s(Ile);o2o=r(wrt,"mpnet"),wrt.forEach(t),r2o=r(KAe," \u2014 "),ON=n(KAe,"A",{href:!0});var Art=s(ON);t2o=r(Art,"MPNetModel"),Art.forEach(t),a2o=r(KAe," (MPNet model)"),KAe.forEach(t),n2o=i($),f_=n($,"LI",{});var ZAe=s(f_);Nle=n(ZAe,"STRONG",{});var yrt=s(Nle);s2o=r(yrt,"mt5"),yrt.forEach(t),l2o=r(ZAe," \u2014 "),VN=n(ZAe,"A",{href:!0});var Lrt=s(VN);i2o=r(Lrt,"MT5Model"),Lrt.forEach(t),d2o=r(ZAe," (mT5 model)"),ZAe.forEach(t),c2o=i($),m_=n($,"LI",{});var eye=s(m_);qle=n(eye,"STRONG",{});var xrt=s(qle);f2o=r(xrt,"nystromformer"),xrt.forEach(t),m2o=r(eye," \u2014 "),XN=n(eye,"A",{href:!0});var $rt=s(XN);g2o=r($rt,"NystromformerModel"),$rt.forEach(t),h2o=r(eye," (Nystromformer model)"),eye.forEach(t),p2o=i($),g_=n($,"LI",{});var oye=s(g_);jle=n(oye,"STRONG",{});var krt=s(jle);_2o=r(krt,"openai-gpt"),krt.forEach(t),u2o=r(oye," \u2014 "),zN=n(oye,"A",{href:!0});var Srt=s(zN);b2o=r(Srt,"OpenAIGPTModel"),Srt.forEach(t),v2o=r(oye," (OpenAI GPT model)"),oye.forEach(t),F2o=i($),h_=n($,"LI",{});var rye=s(h_);Dle=n(rye,"STRONG",{});var Rrt=s(Dle);T2o=r(Rrt,"opt"),Rrt.forEach(t),M2o=r(rye," \u2014 "),WN=n(rye,"A",{href:!0});var Prt=s(WN);E2o=r(Prt,"OPTModel"),Prt.forEach(t),C2o=r(rye," (OPT model)"),rye.forEach(t),w2o=i($),p_=n($,"LI",{});var tye=s(p_);Gle=n(tye,"STRONG",{});var Brt=s(Gle);A2o=r(Brt,"pegasus"),Brt.forEach(t),y2o=r(tye," \u2014 "),QN=n(tye,"A",{href:!0});var Irt=s(QN);L2o=r(Irt,"PegasusModel"),Irt.forEach(t),x2o=r(tye," (Pegasus model)"),tye.forEach(t),$2o=i($),__=n($,"LI",{});var aye=s(__);Ole=n(aye,"STRONG",{});var Nrt=s(Ole);k2o=r(Nrt,"perceiver"),Nrt.forEach(t),S2o=r(aye," \u2014 "),HN=n(aye,"A",{href:!0});var qrt=s(HN);R2o=r(qrt,"PerceiverModel"),qrt.forEach(t),P2o=r(aye," (Perceiver model)"),aye.forEach(t),B2o=i($),u_=n($,"LI",{});var nye=s(u_);Vle=n(nye,"STRONG",{});var jrt=s(Vle);I2o=r(jrt,"plbart"),jrt.forEach(t),N2o=r(nye," \u2014 "),UN=n(nye,"A",{href:!0});var Drt=s(UN);q2o=r(Drt,"PLBartModel"),Drt.forEach(t),j2o=r(nye," (PLBart model)"),nye.forEach(t),D2o=i($),b_=n($,"LI",{});var sye=s(b_);Xle=n(sye,"STRONG",{});var Grt=s(Xle);G2o=r(Grt,"poolformer"),Grt.forEach(t),O2o=r(sye," \u2014 "),JN=n(sye,"A",{href:!0});var Ort=s(JN);V2o=r(Ort,"PoolFormerModel"),Ort.forEach(t),X2o=r(sye," (PoolFormer model)"),sye.forEach(t),z2o=i($),v_=n($,"LI",{});var lye=s(v_);zle=n(lye,"STRONG",{});var Vrt=s(zle);W2o=r(Vrt,"prophetnet"),Vrt.forEach(t),Q2o=r(lye," \u2014 "),YN=n(lye,"A",{href:!0});var Xrt=s(YN);H2o=r(Xrt,"ProphetNetModel"),Xrt.forEach(t),U2o=r(lye," (ProphetNet model)"),lye.forEach(t),J2o=i($),F_=n($,"LI",{});var iye=s(F_);Wle=n(iye,"STRONG",{});var zrt=s(Wle);Y2o=r(zrt,"qdqbert"),zrt.forEach(t),K2o=r(iye," \u2014 "),KN=n(iye,"A",{href:!0});var Wrt=s(KN);Z2o=r(Wrt,"QDQBertModel"),Wrt.forEach(t),evo=r(iye," (QDQBert model)"),iye.forEach(t),ovo=i($),T_=n($,"LI",{});var dye=s(T_);Qle=n(dye,"STRONG",{});var Qrt=s(Qle);rvo=r(Qrt,"reformer"),Qrt.forEach(t),tvo=r(dye," \u2014 "),ZN=n(dye,"A",{href:!0});var Hrt=s(ZN);avo=r(Hrt,"ReformerModel"),Hrt.forEach(t),nvo=r(dye," (Reformer model)"),dye.forEach(t),svo=i($),M_=n($,"LI",{});var cye=s(M_);Hle=n(cye,"STRONG",{});var Urt=s(Hle);lvo=r(Urt,"regnet"),Urt.forEach(t),ivo=r(cye," \u2014 "),eq=n(cye,"A",{href:!0});var Jrt=s(eq);dvo=r(Jrt,"RegNetModel"),Jrt.forEach(t),cvo=r(cye," (RegNet model)"),cye.forEach(t),fvo=i($),E_=n($,"LI",{});var fye=s(E_);Ule=n(fye,"STRONG",{});var Yrt=s(Ule);mvo=r(Yrt,"rembert"),Yrt.forEach(t),gvo=r(fye," \u2014 "),oq=n(fye,"A",{href:!0});var Krt=s(oq);hvo=r(Krt,"RemBertModel"),Krt.forEach(t),pvo=r(fye," (RemBERT model)"),fye.forEach(t),_vo=i($),C_=n($,"LI",{});var mye=s(C_);Jle=n(mye,"STRONG",{});var Zrt=s(Jle);uvo=r(Zrt,"resnet"),Zrt.forEach(t),bvo=r(mye," \u2014 "),rq=n(mye,"A",{href:!0});var ett=s(rq);vvo=r(ett,"ResNetModel"),ett.forEach(t),Fvo=r(mye," (ResNet model)"),mye.forEach(t),Tvo=i($),w_=n($,"LI",{});var gye=s(w_);Yle=n(gye,"STRONG",{});var ott=s(Yle);Mvo=r(ott,"retribert"),ott.forEach(t),Evo=r(gye," \u2014 "),tq=n(gye,"A",{href:!0});var rtt=s(tq);Cvo=r(rtt,"RetriBertModel"),rtt.forEach(t),wvo=r(gye," (RetriBERT model)"),gye.forEach(t),Avo=i($),A_=n($,"LI",{});var hye=s(A_);Kle=n(hye,"STRONG",{});var ttt=s(Kle);yvo=r(ttt,"roberta"),ttt.forEach(t),Lvo=r(hye," \u2014 "),aq=n(hye,"A",{href:!0});var att=s(aq);xvo=r(att,"RobertaModel"),att.forEach(t),$vo=r(hye," (RoBERTa model)"),hye.forEach(t),kvo=i($),y_=n($,"LI",{});var pye=s(y_);Zle=n(pye,"STRONG",{});var ntt=s(Zle);Svo=r(ntt,"roformer"),ntt.forEach(t),Rvo=r(pye," \u2014 "),nq=n(pye,"A",{href:!0});var stt=s(nq);Pvo=r(stt,"RoFormerModel"),stt.forEach(t),Bvo=r(pye," (RoFormer model)"),pye.forEach(t),Ivo=i($),L_=n($,"LI",{});var _ye=s(L_);eie=n(_ye,"STRONG",{});var ltt=s(eie);Nvo=r(ltt,"segformer"),ltt.forEach(t),qvo=r(_ye," \u2014 "),sq=n(_ye,"A",{href:!0});var itt=s(sq);jvo=r(itt,"SegformerModel"),itt.forEach(t),Dvo=r(_ye," (SegFormer model)"),_ye.forEach(t),Gvo=i($),x_=n($,"LI",{});var uye=s(x_);oie=n(uye,"STRONG",{});var dtt=s(oie);Ovo=r(dtt,"sew"),dtt.forEach(t),Vvo=r(uye," \u2014 "),lq=n(uye,"A",{href:!0});var ctt=s(lq);Xvo=r(ctt,"SEWModel"),ctt.forEach(t),zvo=r(uye," (SEW model)"),uye.forEach(t),Wvo=i($),$_=n($,"LI",{});var bye=s($_);rie=n(bye,"STRONG",{});var ftt=s(rie);Qvo=r(ftt,"sew-d"),ftt.forEach(t),Hvo=r(bye," \u2014 "),iq=n(bye,"A",{href:!0});var mtt=s(iq);Uvo=r(mtt,"SEWDModel"),mtt.forEach(t),Jvo=r(bye," (SEW-D model)"),bye.forEach(t),Yvo=i($),k_=n($,"LI",{});var vye=s(k_);tie=n(vye,"STRONG",{});var gtt=s(tie);Kvo=r(gtt,"speech_to_text"),gtt.forEach(t),Zvo=r(vye," \u2014 "),dq=n(vye,"A",{href:!0});var htt=s(dq);e3o=r(htt,"Speech2TextModel"),htt.forEach(t),o3o=r(vye," (Speech2Text model)"),vye.forEach(t),r3o=i($),S_=n($,"LI",{});var Fye=s(S_);aie=n(Fye,"STRONG",{});var ptt=s(aie);t3o=r(ptt,"splinter"),ptt.forEach(t),a3o=r(Fye," \u2014 "),cq=n(Fye,"A",{href:!0});var _tt=s(cq);n3o=r(_tt,"SplinterModel"),_tt.forEach(t),s3o=r(Fye," (Splinter model)"),Fye.forEach(t),l3o=i($),R_=n($,"LI",{});var Tye=s(R_);nie=n(Tye,"STRONG",{});var utt=s(nie);i3o=r(utt,"squeezebert"),utt.forEach(t),d3o=r(Tye," \u2014 "),fq=n(Tye,"A",{href:!0});var btt=s(fq);c3o=r(btt,"SqueezeBertModel"),btt.forEach(t),f3o=r(Tye," (SqueezeBERT model)"),Tye.forEach(t),m3o=i($),P_=n($,"LI",{});var Mye=s(P_);sie=n(Mye,"STRONG",{});var vtt=s(sie);g3o=r(vtt,"swin"),vtt.forEach(t),h3o=r(Mye," \u2014 "),mq=n(Mye,"A",{href:!0});var Ftt=s(mq);p3o=r(Ftt,"SwinModel"),Ftt.forEach(t),_3o=r(Mye," (Swin model)"),Mye.forEach(t),u3o=i($),B_=n($,"LI",{});var Eye=s(B_);lie=n(Eye,"STRONG",{});var Ttt=s(lie);b3o=r(Ttt,"t5"),Ttt.forEach(t),v3o=r(Eye," \u2014 "),gq=n(Eye,"A",{href:!0});var Mtt=s(gq);F3o=r(Mtt,"T5Model"),Mtt.forEach(t),T3o=r(Eye," (T5 model)"),Eye.forEach(t),M3o=i($),I_=n($,"LI",{});var Cye=s(I_);iie=n(Cye,"STRONG",{});var Ett=s(iie);E3o=r(Ett,"tapas"),Ett.forEach(t),C3o=r(Cye," \u2014 "),hq=n(Cye,"A",{href:!0});var Ctt=s(hq);w3o=r(Ctt,"TapasModel"),Ctt.forEach(t),A3o=r(Cye," (TAPAS model)"),Cye.forEach(t),y3o=i($),N_=n($,"LI",{});var wye=s(N_);die=n(wye,"STRONG",{});var wtt=s(die);L3o=r(wtt,"trajectory_transformer"),wtt.forEach(t),x3o=r(wye," \u2014 "),pq=n(wye,"A",{href:!0});var Att=s(pq);$3o=r(Att,"TrajectoryTransformerModel"),Att.forEach(t),k3o=r(wye," (Trajectory Transformer model)"),wye.forEach(t),S3o=i($),q_=n($,"LI",{});var Aye=s(q_);cie=n(Aye,"STRONG",{});var ytt=s(cie);R3o=r(ytt,"transfo-xl"),ytt.forEach(t),P3o=r(Aye," \u2014 "),_q=n(Aye,"A",{href:!0});var Ltt=s(_q);B3o=r(Ltt,"TransfoXLModel"),Ltt.forEach(t),I3o=r(Aye," (Transformer-XL model)"),Aye.forEach(t),N3o=i($),j_=n($,"LI",{});var yye=s(j_);fie=n(yye,"STRONG",{});var xtt=s(fie);q3o=r(xtt,"unispeech"),xtt.forEach(t),j3o=r(yye," \u2014 "),uq=n(yye,"A",{href:!0});var $tt=s(uq);D3o=r($tt,"UniSpeechModel"),$tt.forEach(t),G3o=r(yye," (UniSpeech model)"),yye.forEach(t),O3o=i($),D_=n($,"LI",{});var Lye=s(D_);mie=n(Lye,"STRONG",{});var ktt=s(mie);V3o=r(ktt,"unispeech-sat"),ktt.forEach(t),X3o=r(Lye," \u2014 "),bq=n(Lye,"A",{href:!0});var Stt=s(bq);z3o=r(Stt,"UniSpeechSatModel"),Stt.forEach(t),W3o=r(Lye," (UniSpeechSat model)"),Lye.forEach(t),Q3o=i($),G_=n($,"LI",{});var xye=s(G_);gie=n(xye,"STRONG",{});var Rtt=s(gie);H3o=r(Rtt,"van"),Rtt.forEach(t),U3o=r(xye," \u2014 "),vq=n(xye,"A",{href:!0});var Ptt=s(vq);J3o=r(Ptt,"VanModel"),Ptt.forEach(t),Y3o=r(xye," (VAN model)"),xye.forEach(t),K3o=i($),O_=n($,"LI",{});var $ye=s(O_);hie=n($ye,"STRONG",{});var Btt=s(hie);Z3o=r(Btt,"vilt"),Btt.forEach(t),eFo=r($ye," \u2014 "),Fq=n($ye,"A",{href:!0});var Itt=s(Fq);oFo=r(Itt,"ViltModel"),Itt.forEach(t),rFo=r($ye," (ViLT model)"),$ye.forEach(t),tFo=i($),V_=n($,"LI",{});var kye=s(V_);pie=n(kye,"STRONG",{});var Ntt=s(pie);aFo=r(Ntt,"vision-text-dual-encoder"),Ntt.forEach(t),nFo=r(kye," \u2014 "),Tq=n(kye,"A",{href:!0});var qtt=s(Tq);sFo=r(qtt,"VisionTextDualEncoderModel"),qtt.forEach(t),lFo=r(kye," (VisionTextDualEncoder model)"),kye.forEach(t),iFo=i($),X_=n($,"LI",{});var Sye=s(X_);_ie=n(Sye,"STRONG",{});var jtt=s(_ie);dFo=r(jtt,"visual_bert"),jtt.forEach(t),cFo=r(Sye," \u2014 "),Mq=n(Sye,"A",{href:!0});var Dtt=s(Mq);fFo=r(Dtt,"VisualBertModel"),Dtt.forEach(t),mFo=r(Sye," (VisualBert model)"),Sye.forEach(t),gFo=i($),z_=n($,"LI",{});var Rye=s(z_);uie=n(Rye,"STRONG",{});var Gtt=s(uie);hFo=r(Gtt,"vit"),Gtt.forEach(t),pFo=r(Rye," \u2014 "),Eq=n(Rye,"A",{href:!0});var Ott=s(Eq);_Fo=r(Ott,"ViTModel"),Ott.forEach(t),uFo=r(Rye," (ViT model)"),Rye.forEach(t),bFo=i($),W_=n($,"LI",{});var Pye=s(W_);bie=n(Pye,"STRONG",{});var Vtt=s(bie);vFo=r(Vtt,"vit_mae"),Vtt.forEach(t),FFo=r(Pye," \u2014 "),Cq=n(Pye,"A",{href:!0});var Xtt=s(Cq);TFo=r(Xtt,"ViTMAEModel"),Xtt.forEach(t),MFo=r(Pye," (ViTMAE model)"),Pye.forEach(t),EFo=i($),Q_=n($,"LI",{});var Bye=s(Q_);vie=n(Bye,"STRONG",{});var ztt=s(vie);CFo=r(ztt,"wav2vec2"),ztt.forEach(t),wFo=r(Bye," \u2014 "),wq=n(Bye,"A",{href:!0});var Wtt=s(wq);AFo=r(Wtt,"Wav2Vec2Model"),Wtt.forEach(t),yFo=r(Bye," (Wav2Vec2 model)"),Bye.forEach(t),LFo=i($),H_=n($,"LI",{});var Iye=s(H_);Fie=n(Iye,"STRONG",{});var Qtt=s(Fie);xFo=r(Qtt,"wav2vec2-conformer"),Qtt.forEach(t),$Fo=r(Iye," \u2014 "),Aq=n(Iye,"A",{href:!0});var Htt=s(Aq);kFo=r(Htt,"Wav2Vec2ConformerModel"),Htt.forEach(t),SFo=r(Iye," (Wav2Vec2-Conformer model)"),Iye.forEach(t),RFo=i($),U_=n($,"LI",{});var Nye=s(U_);Tie=n(Nye,"STRONG",{});var Utt=s(Tie);PFo=r(Utt,"wavlm"),Utt.forEach(t),BFo=r(Nye," \u2014 "),yq=n(Nye,"A",{href:!0});var Jtt=s(yq);IFo=r(Jtt,"WavLMModel"),Jtt.forEach(t),NFo=r(Nye," (WavLM model)"),Nye.forEach(t),qFo=i($),J_=n($,"LI",{});var qye=s(J_);Mie=n(qye,"STRONG",{});var Ytt=s(Mie);jFo=r(Ytt,"xglm"),Ytt.forEach(t),DFo=r(qye," \u2014 "),Lq=n(qye,"A",{href:!0});var Ktt=s(Lq);GFo=r(Ktt,"XGLMModel"),Ktt.forEach(t),OFo=r(qye," (XGLM model)"),qye.forEach(t),VFo=i($),Y_=n($,"LI",{});var jye=s(Y_);Eie=n(jye,"STRONG",{});var Ztt=s(Eie);XFo=r(Ztt,"xlm"),Ztt.forEach(t),zFo=r(jye," \u2014 "),xq=n(jye,"A",{href:!0});var eat=s(xq);WFo=r(eat,"XLMModel"),eat.forEach(t),QFo=r(jye," (XLM model)"),jye.forEach(t),HFo=i($),K_=n($,"LI",{});var Dye=s(K_);Cie=n(Dye,"STRONG",{});var oat=s(Cie);UFo=r(oat,"xlm-prophetnet"),oat.forEach(t),JFo=r(Dye," \u2014 "),$q=n(Dye,"A",{href:!0});var rat=s($q);YFo=r(rat,"XLMProphetNetModel"),rat.forEach(t),KFo=r(Dye," (XLMProphetNet model)"),Dye.forEach(t),ZFo=i($),Z_=n($,"LI",{});var Gye=s(Z_);wie=n(Gye,"STRONG",{});var tat=s(wie);eTo=r(tat,"xlm-roberta"),tat.forEach(t),oTo=r(Gye," \u2014 "),kq=n(Gye,"A",{href:!0});var aat=s(kq);rTo=r(aat,"XLMRobertaModel"),aat.forEach(t),tTo=r(Gye," (XLM-RoBERTa model)"),Gye.forEach(t),aTo=i($),eu=n($,"LI",{});var Oye=s(eu);Aie=n(Oye,"STRONG",{});var nat=s(Aie);nTo=r(nat,"xlm-roberta-xl"),nat.forEach(t),sTo=r(Oye," \u2014 "),Sq=n(Oye,"A",{href:!0});var sat=s(Sq);lTo=r(sat,"XLMRobertaXLModel"),sat.forEach(t),iTo=r(Oye," (XLM-RoBERTa-XL model)"),Oye.forEach(t),dTo=i($),ou=n($,"LI",{});var Vye=s(ou);yie=n(Vye,"STRONG",{});var lat=s(yie);cTo=r(lat,"xlnet"),lat.forEach(t),fTo=r(Vye," \u2014 "),Rq=n(Vye,"A",{href:!0});var iat=s(Rq);mTo=r(iat,"XLNetModel"),iat.forEach(t),gTo=r(Vye," (XLNet model)"),Vye.forEach(t),hTo=i($),ru=n($,"LI",{});var Xye=s(ru);Lie=n(Xye,"STRONG",{});var dat=s(Lie);pTo=r(dat,"yolos"),dat.forEach(t),_To=r(Xye," \u2014 "),Pq=n(Xye,"A",{href:!0});var cat=s(Pq);uTo=r(cat,"YolosModel"),cat.forEach(t),bTo=r(Xye," (YOLOS model)"),Xye.forEach(t),vTo=i($),tu=n($,"LI",{});var zye=s(tu);xie=n(zye,"STRONG",{});var fat=s(xie);FTo=r(fat,"yoso"),fat.forEach(t),TTo=r(zye," \u2014 "),Bq=n(zye,"A",{href:!0});var mat=s(Bq);MTo=r(mat,"YosoModel"),mat.forEach(t),ETo=r(zye," (YOSO model)"),zye.forEach(t),$.forEach(t),CTo=i(oa),au=n(oa,"P",{});var Wye=s(au);wTo=r(Wye,"The model is set in evaluation mode by default using "),$ie=n(Wye,"CODE",{});var gat=s($ie);ATo=r(gat,"model.eval()"),gat.forEach(t),yTo=r(Wye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kie=n(Wye,"CODE",{});var hat=s(kie);LTo=r(hat,"model.train()"),hat.forEach(t),Wye.forEach(t),xTo=i(oa),T(nu.$$.fragment,oa),oa.forEach(t),Os.forEach(t),$qe=i(f),xi=n(f,"H2",{class:!0});var PDe=s(xi);su=n(PDe,"A",{id:!0,class:!0,href:!0});var pat=s(su);Sie=n(pat,"SPAN",{});var _at=s(Sie);T(iy.$$.fragment,_at),_at.forEach(t),pat.forEach(t),$To=i(PDe),Rie=n(PDe,"SPAN",{});var uat=s(Rie);kTo=r(uat,"AutoModelForPreTraining"),uat.forEach(t),PDe.forEach(t),kqe=i(f),xo=n(f,"DIV",{class:!0});var Vs=s(xo);T(dy.$$.fragment,Vs),STo=i(Vs),$i=n(Vs,"P",{});var yZ=s($i);RTo=r(yZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Iq=n(yZ,"A",{href:!0});var bat=s(Iq);PTo=r(bat,"from_pretrained()"),bat.forEach(t),BTo=r(yZ," class method or the "),Nq=n(yZ,"A",{href:!0});var vat=s(Nq);ITo=r(vat,"from_config()"),vat.forEach(t),NTo=r(yZ,` class
method.`),yZ.forEach(t),qTo=i(Vs),cy=n(Vs,"P",{});var BDe=s(cy);jTo=r(BDe,"This class cannot be instantiated directly using "),Pie=n(BDe,"CODE",{});var Fat=s(Pie);DTo=r(Fat,"__init__()"),Fat.forEach(t),GTo=r(BDe," (throws an error)."),BDe.forEach(t),OTo=i(Vs),at=n(Vs,"DIV",{class:!0});var N0=s(at);T(fy.$$.fragment,N0),VTo=i(N0),Bie=n(N0,"P",{});var Tat=s(Bie);XTo=r(Tat,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Tat.forEach(t),zTo=i(N0),ki=n(N0,"P",{});var LZ=s(ki);WTo=r(LZ,`Note:
Loading a model from its configuration file does `),Iie=n(LZ,"STRONG",{});var Mat=s(Iie);QTo=r(Mat,"not"),Mat.forEach(t),HTo=r(LZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),qq=n(LZ,"A",{href:!0});var Eat=s(qq);UTo=r(Eat,"from_pretrained()"),Eat.forEach(t),JTo=r(LZ," to load the model weights."),LZ.forEach(t),YTo=i(N0),T(lu.$$.fragment,N0),N0.forEach(t),KTo=i(Vs),Ye=n(Vs,"DIV",{class:!0});var ra=s(Ye);T(my.$$.fragment,ra),ZTo=i(ra),Nie=n(ra,"P",{});var Cat=s(Nie);e7o=r(Cat,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Cat.forEach(t),o7o=i(ra),xa=n(ra,"P",{});var q0=s(xa);r7o=r(q0,"The model class to instantiate is selected based on the "),qie=n(q0,"CODE",{});var wat=s(qie);t7o=r(wat,"model_type"),wat.forEach(t),a7o=r(q0,` property of the config object (either
passed as an argument or loaded from `),jie=n(q0,"CODE",{});var Aat=s(jie);n7o=r(Aat,"pretrained_model_name_or_path"),Aat.forEach(t),s7o=r(q0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=n(q0,"CODE",{});var yat=s(Die);l7o=r(yat,"pretrained_model_name_or_path"),yat.forEach(t),i7o=r(q0,":"),q0.forEach(t),d7o=i(ra),G=n(ra,"UL",{});var O=s(G);iu=n(O,"LI",{});var Qye=s(iu);Gie=n(Qye,"STRONG",{});var Lat=s(Gie);c7o=r(Lat,"albert"),Lat.forEach(t),f7o=r(Qye," \u2014 "),jq=n(Qye,"A",{href:!0});var xat=s(jq);m7o=r(xat,"AlbertForPreTraining"),xat.forEach(t),g7o=r(Qye," (ALBERT model)"),Qye.forEach(t),h7o=i(O),du=n(O,"LI",{});var Hye=s(du);Oie=n(Hye,"STRONG",{});var $at=s(Oie);p7o=r($at,"bart"),$at.forEach(t),_7o=r(Hye," \u2014 "),Dq=n(Hye,"A",{href:!0});var kat=s(Dq);u7o=r(kat,"BartForConditionalGeneration"),kat.forEach(t),b7o=r(Hye," (BART model)"),Hye.forEach(t),v7o=i(O),cu=n(O,"LI",{});var Uye=s(cu);Vie=n(Uye,"STRONG",{});var Sat=s(Vie);F7o=r(Sat,"bert"),Sat.forEach(t),T7o=r(Uye," \u2014 "),Gq=n(Uye,"A",{href:!0});var Rat=s(Gq);M7o=r(Rat,"BertForPreTraining"),Rat.forEach(t),E7o=r(Uye," (BERT model)"),Uye.forEach(t),C7o=i(O),fu=n(O,"LI",{});var Jye=s(fu);Xie=n(Jye,"STRONG",{});var Pat=s(Xie);w7o=r(Pat,"big_bird"),Pat.forEach(t),A7o=r(Jye," \u2014 "),Oq=n(Jye,"A",{href:!0});var Bat=s(Oq);y7o=r(Bat,"BigBirdForPreTraining"),Bat.forEach(t),L7o=r(Jye," (BigBird model)"),Jye.forEach(t),x7o=i(O),mu=n(O,"LI",{});var Yye=s(mu);zie=n(Yye,"STRONG",{});var Iat=s(zie);$7o=r(Iat,"camembert"),Iat.forEach(t),k7o=r(Yye," \u2014 "),Vq=n(Yye,"A",{href:!0});var Nat=s(Vq);S7o=r(Nat,"CamembertForMaskedLM"),Nat.forEach(t),R7o=r(Yye," (CamemBERT model)"),Yye.forEach(t),P7o=i(O),gu=n(O,"LI",{});var Kye=s(gu);Wie=n(Kye,"STRONG",{});var qat=s(Wie);B7o=r(qat,"ctrl"),qat.forEach(t),I7o=r(Kye," \u2014 "),Xq=n(Kye,"A",{href:!0});var jat=s(Xq);N7o=r(jat,"CTRLLMHeadModel"),jat.forEach(t),q7o=r(Kye," (CTRL model)"),Kye.forEach(t),j7o=i(O),hu=n(O,"LI",{});var Zye=s(hu);Qie=n(Zye,"STRONG",{});var Dat=s(Qie);D7o=r(Dat,"data2vec-text"),Dat.forEach(t),G7o=r(Zye," \u2014 "),zq=n(Zye,"A",{href:!0});var Gat=s(zq);O7o=r(Gat,"Data2VecTextForMaskedLM"),Gat.forEach(t),V7o=r(Zye," (Data2VecText model)"),Zye.forEach(t),X7o=i(O),pu=n(O,"LI",{});var eLe=s(pu);Hie=n(eLe,"STRONG",{});var Oat=s(Hie);z7o=r(Oat,"deberta"),Oat.forEach(t),W7o=r(eLe," \u2014 "),Wq=n(eLe,"A",{href:!0});var Vat=s(Wq);Q7o=r(Vat,"DebertaForMaskedLM"),Vat.forEach(t),H7o=r(eLe," (DeBERTa model)"),eLe.forEach(t),U7o=i(O),_u=n(O,"LI",{});var oLe=s(_u);Uie=n(oLe,"STRONG",{});var Xat=s(Uie);J7o=r(Xat,"deberta-v2"),Xat.forEach(t),Y7o=r(oLe," \u2014 "),Qq=n(oLe,"A",{href:!0});var zat=s(Qq);K7o=r(zat,"DebertaV2ForMaskedLM"),zat.forEach(t),Z7o=r(oLe," (DeBERTa-v2 model)"),oLe.forEach(t),eMo=i(O),uu=n(O,"LI",{});var rLe=s(uu);Jie=n(rLe,"STRONG",{});var Wat=s(Jie);oMo=r(Wat,"distilbert"),Wat.forEach(t),rMo=r(rLe," \u2014 "),Hq=n(rLe,"A",{href:!0});var Qat=s(Hq);tMo=r(Qat,"DistilBertForMaskedLM"),Qat.forEach(t),aMo=r(rLe," (DistilBERT model)"),rLe.forEach(t),nMo=i(O),bu=n(O,"LI",{});var tLe=s(bu);Yie=n(tLe,"STRONG",{});var Hat=s(Yie);sMo=r(Hat,"electra"),Hat.forEach(t),lMo=r(tLe," \u2014 "),Uq=n(tLe,"A",{href:!0});var Uat=s(Uq);iMo=r(Uat,"ElectraForPreTraining"),Uat.forEach(t),dMo=r(tLe," (ELECTRA model)"),tLe.forEach(t),cMo=i(O),vu=n(O,"LI",{});var aLe=s(vu);Kie=n(aLe,"STRONG",{});var Jat=s(Kie);fMo=r(Jat,"flaubert"),Jat.forEach(t),mMo=r(aLe," \u2014 "),Jq=n(aLe,"A",{href:!0});var Yat=s(Jq);gMo=r(Yat,"FlaubertWithLMHeadModel"),Yat.forEach(t),hMo=r(aLe," (FlauBERT model)"),aLe.forEach(t),pMo=i(O),Fu=n(O,"LI",{});var nLe=s(Fu);Zie=n(nLe,"STRONG",{});var Kat=s(Zie);_Mo=r(Kat,"flava"),Kat.forEach(t),uMo=r(nLe," \u2014 "),Yq=n(nLe,"A",{href:!0});var Zat=s(Yq);bMo=r(Zat,"FlavaForPreTraining"),Zat.forEach(t),vMo=r(nLe," (Flava model)"),nLe.forEach(t),FMo=i(O),Tu=n(O,"LI",{});var sLe=s(Tu);ede=n(sLe,"STRONG",{});var ent=s(ede);TMo=r(ent,"fnet"),ent.forEach(t),MMo=r(sLe," \u2014 "),Kq=n(sLe,"A",{href:!0});var ont=s(Kq);EMo=r(ont,"FNetForPreTraining"),ont.forEach(t),CMo=r(sLe," (FNet model)"),sLe.forEach(t),wMo=i(O),Mu=n(O,"LI",{});var lLe=s(Mu);ode=n(lLe,"STRONG",{});var rnt=s(ode);AMo=r(rnt,"fsmt"),rnt.forEach(t),yMo=r(lLe," \u2014 "),Zq=n(lLe,"A",{href:!0});var tnt=s(Zq);LMo=r(tnt,"FSMTForConditionalGeneration"),tnt.forEach(t),xMo=r(lLe," (FairSeq Machine-Translation model)"),lLe.forEach(t),$Mo=i(O),Eu=n(O,"LI",{});var iLe=s(Eu);rde=n(iLe,"STRONG",{});var ant=s(rde);kMo=r(ant,"funnel"),ant.forEach(t),SMo=r(iLe," \u2014 "),ej=n(iLe,"A",{href:!0});var nnt=s(ej);RMo=r(nnt,"FunnelForPreTraining"),nnt.forEach(t),PMo=r(iLe," (Funnel Transformer model)"),iLe.forEach(t),BMo=i(O),Cu=n(O,"LI",{});var dLe=s(Cu);tde=n(dLe,"STRONG",{});var snt=s(tde);IMo=r(snt,"gpt2"),snt.forEach(t),NMo=r(dLe," \u2014 "),oj=n(dLe,"A",{href:!0});var lnt=s(oj);qMo=r(lnt,"GPT2LMHeadModel"),lnt.forEach(t),jMo=r(dLe," (OpenAI GPT-2 model)"),dLe.forEach(t),DMo=i(O),wu=n(O,"LI",{});var cLe=s(wu);ade=n(cLe,"STRONG",{});var int=s(ade);GMo=r(int,"ibert"),int.forEach(t),OMo=r(cLe," \u2014 "),rj=n(cLe,"A",{href:!0});var dnt=s(rj);VMo=r(dnt,"IBertForMaskedLM"),dnt.forEach(t),XMo=r(cLe," (I-BERT model)"),cLe.forEach(t),zMo=i(O),Au=n(O,"LI",{});var fLe=s(Au);nde=n(fLe,"STRONG",{});var cnt=s(nde);WMo=r(cnt,"layoutlm"),cnt.forEach(t),QMo=r(fLe," \u2014 "),tj=n(fLe,"A",{href:!0});var fnt=s(tj);HMo=r(fnt,"LayoutLMForMaskedLM"),fnt.forEach(t),UMo=r(fLe," (LayoutLM model)"),fLe.forEach(t),JMo=i(O),yu=n(O,"LI",{});var mLe=s(yu);sde=n(mLe,"STRONG",{});var mnt=s(sde);YMo=r(mnt,"longformer"),mnt.forEach(t),KMo=r(mLe," \u2014 "),aj=n(mLe,"A",{href:!0});var gnt=s(aj);ZMo=r(gnt,"LongformerForMaskedLM"),gnt.forEach(t),eEo=r(mLe," (Longformer model)"),mLe.forEach(t),oEo=i(O),Lu=n(O,"LI",{});var gLe=s(Lu);lde=n(gLe,"STRONG",{});var hnt=s(lde);rEo=r(hnt,"lxmert"),hnt.forEach(t),tEo=r(gLe," \u2014 "),nj=n(gLe,"A",{href:!0});var pnt=s(nj);aEo=r(pnt,"LxmertForPreTraining"),pnt.forEach(t),nEo=r(gLe," (LXMERT model)"),gLe.forEach(t),sEo=i(O),xu=n(O,"LI",{});var hLe=s(xu);ide=n(hLe,"STRONG",{});var _nt=s(ide);lEo=r(_nt,"megatron-bert"),_nt.forEach(t),iEo=r(hLe," \u2014 "),sj=n(hLe,"A",{href:!0});var unt=s(sj);dEo=r(unt,"MegatronBertForPreTraining"),unt.forEach(t),cEo=r(hLe," (MegatronBert model)"),hLe.forEach(t),fEo=i(O),$u=n(O,"LI",{});var pLe=s($u);dde=n(pLe,"STRONG",{});var bnt=s(dde);mEo=r(bnt,"mobilebert"),bnt.forEach(t),gEo=r(pLe," \u2014 "),lj=n(pLe,"A",{href:!0});var vnt=s(lj);hEo=r(vnt,"MobileBertForPreTraining"),vnt.forEach(t),pEo=r(pLe," (MobileBERT model)"),pLe.forEach(t),_Eo=i(O),ku=n(O,"LI",{});var _Le=s(ku);cde=n(_Le,"STRONG",{});var Fnt=s(cde);uEo=r(Fnt,"mpnet"),Fnt.forEach(t),bEo=r(_Le," \u2014 "),ij=n(_Le,"A",{href:!0});var Tnt=s(ij);vEo=r(Tnt,"MPNetForMaskedLM"),Tnt.forEach(t),FEo=r(_Le," (MPNet model)"),_Le.forEach(t),TEo=i(O),Su=n(O,"LI",{});var uLe=s(Su);fde=n(uLe,"STRONG",{});var Mnt=s(fde);MEo=r(Mnt,"openai-gpt"),Mnt.forEach(t),EEo=r(uLe," \u2014 "),dj=n(uLe,"A",{href:!0});var Ent=s(dj);CEo=r(Ent,"OpenAIGPTLMHeadModel"),Ent.forEach(t),wEo=r(uLe," (OpenAI GPT model)"),uLe.forEach(t),AEo=i(O),Ru=n(O,"LI",{});var bLe=s(Ru);mde=n(bLe,"STRONG",{});var Cnt=s(mde);yEo=r(Cnt,"retribert"),Cnt.forEach(t),LEo=r(bLe," \u2014 "),cj=n(bLe,"A",{href:!0});var wnt=s(cj);xEo=r(wnt,"RetriBertModel"),wnt.forEach(t),$Eo=r(bLe," (RetriBERT model)"),bLe.forEach(t),kEo=i(O),Pu=n(O,"LI",{});var vLe=s(Pu);gde=n(vLe,"STRONG",{});var Ant=s(gde);SEo=r(Ant,"roberta"),Ant.forEach(t),REo=r(vLe," \u2014 "),fj=n(vLe,"A",{href:!0});var ynt=s(fj);PEo=r(ynt,"RobertaForMaskedLM"),ynt.forEach(t),BEo=r(vLe," (RoBERTa model)"),vLe.forEach(t),IEo=i(O),Bu=n(O,"LI",{});var FLe=s(Bu);hde=n(FLe,"STRONG",{});var Lnt=s(hde);NEo=r(Lnt,"splinter"),Lnt.forEach(t),qEo=r(FLe," \u2014 "),mj=n(FLe,"A",{href:!0});var xnt=s(mj);jEo=r(xnt,"SplinterForPreTraining"),xnt.forEach(t),DEo=r(FLe," (Splinter model)"),FLe.forEach(t),GEo=i(O),Iu=n(O,"LI",{});var TLe=s(Iu);pde=n(TLe,"STRONG",{});var $nt=s(pde);OEo=r($nt,"squeezebert"),$nt.forEach(t),VEo=r(TLe," \u2014 "),gj=n(TLe,"A",{href:!0});var knt=s(gj);XEo=r(knt,"SqueezeBertForMaskedLM"),knt.forEach(t),zEo=r(TLe," (SqueezeBERT model)"),TLe.forEach(t),WEo=i(O),Nu=n(O,"LI",{});var MLe=s(Nu);_de=n(MLe,"STRONG",{});var Snt=s(_de);QEo=r(Snt,"t5"),Snt.forEach(t),HEo=r(MLe," \u2014 "),hj=n(MLe,"A",{href:!0});var Rnt=s(hj);UEo=r(Rnt,"T5ForConditionalGeneration"),Rnt.forEach(t),JEo=r(MLe," (T5 model)"),MLe.forEach(t),YEo=i(O),qu=n(O,"LI",{});var ELe=s(qu);ude=n(ELe,"STRONG",{});var Pnt=s(ude);KEo=r(Pnt,"tapas"),Pnt.forEach(t),ZEo=r(ELe," \u2014 "),pj=n(ELe,"A",{href:!0});var Bnt=s(pj);eCo=r(Bnt,"TapasForMaskedLM"),Bnt.forEach(t),oCo=r(ELe," (TAPAS model)"),ELe.forEach(t),rCo=i(O),ju=n(O,"LI",{});var CLe=s(ju);bde=n(CLe,"STRONG",{});var Int=s(bde);tCo=r(Int,"transfo-xl"),Int.forEach(t),aCo=r(CLe," \u2014 "),_j=n(CLe,"A",{href:!0});var Nnt=s(_j);nCo=r(Nnt,"TransfoXLLMHeadModel"),Nnt.forEach(t),sCo=r(CLe," (Transformer-XL model)"),CLe.forEach(t),lCo=i(O),Du=n(O,"LI",{});var wLe=s(Du);vde=n(wLe,"STRONG",{});var qnt=s(vde);iCo=r(qnt,"unispeech"),qnt.forEach(t),dCo=r(wLe," \u2014 "),uj=n(wLe,"A",{href:!0});var jnt=s(uj);cCo=r(jnt,"UniSpeechForPreTraining"),jnt.forEach(t),fCo=r(wLe," (UniSpeech model)"),wLe.forEach(t),mCo=i(O),Gu=n(O,"LI",{});var ALe=s(Gu);Fde=n(ALe,"STRONG",{});var Dnt=s(Fde);gCo=r(Dnt,"unispeech-sat"),Dnt.forEach(t),hCo=r(ALe," \u2014 "),bj=n(ALe,"A",{href:!0});var Gnt=s(bj);pCo=r(Gnt,"UniSpeechSatForPreTraining"),Gnt.forEach(t),_Co=r(ALe," (UniSpeechSat model)"),ALe.forEach(t),uCo=i(O),Ou=n(O,"LI",{});var yLe=s(Ou);Tde=n(yLe,"STRONG",{});var Ont=s(Tde);bCo=r(Ont,"visual_bert"),Ont.forEach(t),vCo=r(yLe," \u2014 "),vj=n(yLe,"A",{href:!0});var Vnt=s(vj);FCo=r(Vnt,"VisualBertForPreTraining"),Vnt.forEach(t),TCo=r(yLe," (VisualBert model)"),yLe.forEach(t),MCo=i(O),Vu=n(O,"LI",{});var LLe=s(Vu);Mde=n(LLe,"STRONG",{});var Xnt=s(Mde);ECo=r(Xnt,"vit_mae"),Xnt.forEach(t),CCo=r(LLe," \u2014 "),Fj=n(LLe,"A",{href:!0});var znt=s(Fj);wCo=r(znt,"ViTMAEForPreTraining"),znt.forEach(t),ACo=r(LLe," (ViTMAE model)"),LLe.forEach(t),yCo=i(O),Xu=n(O,"LI",{});var xLe=s(Xu);Ede=n(xLe,"STRONG",{});var Wnt=s(Ede);LCo=r(Wnt,"wav2vec2"),Wnt.forEach(t),xCo=r(xLe," \u2014 "),Tj=n(xLe,"A",{href:!0});var Qnt=s(Tj);$Co=r(Qnt,"Wav2Vec2ForPreTraining"),Qnt.forEach(t),kCo=r(xLe," (Wav2Vec2 model)"),xLe.forEach(t),SCo=i(O),zu=n(O,"LI",{});var $Le=s(zu);Cde=n($Le,"STRONG",{});var Hnt=s(Cde);RCo=r(Hnt,"wav2vec2-conformer"),Hnt.forEach(t),PCo=r($Le," \u2014 "),Mj=n($Le,"A",{href:!0});var Unt=s(Mj);BCo=r(Unt,"Wav2Vec2ConformerForPreTraining"),Unt.forEach(t),ICo=r($Le," (Wav2Vec2-Conformer model)"),$Le.forEach(t),NCo=i(O),Wu=n(O,"LI",{});var kLe=s(Wu);wde=n(kLe,"STRONG",{});var Jnt=s(wde);qCo=r(Jnt,"xlm"),Jnt.forEach(t),jCo=r(kLe," \u2014 "),Ej=n(kLe,"A",{href:!0});var Ynt=s(Ej);DCo=r(Ynt,"XLMWithLMHeadModel"),Ynt.forEach(t),GCo=r(kLe," (XLM model)"),kLe.forEach(t),OCo=i(O),Qu=n(O,"LI",{});var SLe=s(Qu);Ade=n(SLe,"STRONG",{});var Knt=s(Ade);VCo=r(Knt,"xlm-roberta"),Knt.forEach(t),XCo=r(SLe," \u2014 "),Cj=n(SLe,"A",{href:!0});var Znt=s(Cj);zCo=r(Znt,"XLMRobertaForMaskedLM"),Znt.forEach(t),WCo=r(SLe," (XLM-RoBERTa model)"),SLe.forEach(t),QCo=i(O),Hu=n(O,"LI",{});var RLe=s(Hu);yde=n(RLe,"STRONG",{});var est=s(yde);HCo=r(est,"xlm-roberta-xl"),est.forEach(t),UCo=r(RLe," \u2014 "),wj=n(RLe,"A",{href:!0});var ost=s(wj);JCo=r(ost,"XLMRobertaXLForMaskedLM"),ost.forEach(t),YCo=r(RLe," (XLM-RoBERTa-XL model)"),RLe.forEach(t),KCo=i(O),Uu=n(O,"LI",{});var PLe=s(Uu);Lde=n(PLe,"STRONG",{});var rst=s(Lde);ZCo=r(rst,"xlnet"),rst.forEach(t),e5o=r(PLe," \u2014 "),Aj=n(PLe,"A",{href:!0});var tst=s(Aj);o5o=r(tst,"XLNetLMHeadModel"),tst.forEach(t),r5o=r(PLe," (XLNet model)"),PLe.forEach(t),O.forEach(t),t5o=i(ra),Ju=n(ra,"P",{});var BLe=s(Ju);a5o=r(BLe,"The model is set in evaluation mode by default using "),xde=n(BLe,"CODE",{});var ast=s(xde);n5o=r(ast,"model.eval()"),ast.forEach(t),s5o=r(BLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$de=n(BLe,"CODE",{});var nst=s($de);l5o=r(nst,"model.train()"),nst.forEach(t),BLe.forEach(t),i5o=i(ra),T(Yu.$$.fragment,ra),ra.forEach(t),Vs.forEach(t),Sqe=i(f),Si=n(f,"H2",{class:!0});var IDe=s(Si);Ku=n(IDe,"A",{id:!0,class:!0,href:!0});var sst=s(Ku);kde=n(sst,"SPAN",{});var lst=s(kde);T(gy.$$.fragment,lst),lst.forEach(t),sst.forEach(t),d5o=i(IDe),Sde=n(IDe,"SPAN",{});var ist=s(Sde);c5o=r(ist,"AutoModelForCausalLM"),ist.forEach(t),IDe.forEach(t),Rqe=i(f),$o=n(f,"DIV",{class:!0});var Xs=s($o);T(hy.$$.fragment,Xs),f5o=i(Xs),Ri=n(Xs,"P",{});var xZ=s(Ri);m5o=r(xZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),yj=n(xZ,"A",{href:!0});var dst=s(yj);g5o=r(dst,"from_pretrained()"),dst.forEach(t),h5o=r(xZ," class method or the "),Lj=n(xZ,"A",{href:!0});var cst=s(Lj);p5o=r(cst,"from_config()"),cst.forEach(t),_5o=r(xZ,` class
method.`),xZ.forEach(t),u5o=i(Xs),py=n(Xs,"P",{});var NDe=s(py);b5o=r(NDe,"This class cannot be instantiated directly using "),Rde=n(NDe,"CODE",{});var fst=s(Rde);v5o=r(fst,"__init__()"),fst.forEach(t),F5o=r(NDe," (throws an error)."),NDe.forEach(t),T5o=i(Xs),nt=n(Xs,"DIV",{class:!0});var j0=s(nt);T(_y.$$.fragment,j0),M5o=i(j0),Pde=n(j0,"P",{});var mst=s(Pde);E5o=r(mst,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),mst.forEach(t),C5o=i(j0),Pi=n(j0,"P",{});var $Z=s(Pi);w5o=r($Z,`Note:
Loading a model from its configuration file does `),Bde=n($Z,"STRONG",{});var gst=s(Bde);A5o=r(gst,"not"),gst.forEach(t),y5o=r($Z,` load the model weights. It only affects the
model\u2019s configuration. Use `),xj=n($Z,"A",{href:!0});var hst=s(xj);L5o=r(hst,"from_pretrained()"),hst.forEach(t),x5o=r($Z," to load the model weights."),$Z.forEach(t),$5o=i(j0),T(Zu.$$.fragment,j0),j0.forEach(t),k5o=i(Xs),Ke=n(Xs,"DIV",{class:!0});var ta=s(Ke);T(uy.$$.fragment,ta),S5o=i(ta),Ide=n(ta,"P",{});var pst=s(Ide);R5o=r(pst,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),pst.forEach(t),P5o=i(ta),$a=n(ta,"P",{});var D0=s($a);B5o=r(D0,"The model class to instantiate is selected based on the "),Nde=n(D0,"CODE",{});var _st=s(Nde);I5o=r(_st,"model_type"),_st.forEach(t),N5o=r(D0,` property of the config object (either
passed as an argument or loaded from `),qde=n(D0,"CODE",{});var ust=s(qde);q5o=r(ust,"pretrained_model_name_or_path"),ust.forEach(t),j5o=r(D0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jde=n(D0,"CODE",{});var bst=s(jde);D5o=r(bst,"pretrained_model_name_or_path"),bst.forEach(t),G5o=r(D0,":"),D0.forEach(t),O5o=i(ta),z=n(ta,"UL",{});var W=s(z);e4=n(W,"LI",{});var ILe=s(e4);Dde=n(ILe,"STRONG",{});var vst=s(Dde);V5o=r(vst,"bart"),vst.forEach(t),X5o=r(ILe," \u2014 "),$j=n(ILe,"A",{href:!0});var Fst=s($j);z5o=r(Fst,"BartForCausalLM"),Fst.forEach(t),W5o=r(ILe," (BART model)"),ILe.forEach(t),Q5o=i(W),o4=n(W,"LI",{});var NLe=s(o4);Gde=n(NLe,"STRONG",{});var Tst=s(Gde);H5o=r(Tst,"bert"),Tst.forEach(t),U5o=r(NLe," \u2014 "),kj=n(NLe,"A",{href:!0});var Mst=s(kj);J5o=r(Mst,"BertLMHeadModel"),Mst.forEach(t),Y5o=r(NLe," (BERT model)"),NLe.forEach(t),K5o=i(W),r4=n(W,"LI",{});var qLe=s(r4);Ode=n(qLe,"STRONG",{});var Est=s(Ode);Z5o=r(Est,"bert-generation"),Est.forEach(t),ewo=r(qLe," \u2014 "),Sj=n(qLe,"A",{href:!0});var Cst=s(Sj);owo=r(Cst,"BertGenerationDecoder"),Cst.forEach(t),rwo=r(qLe," (Bert Generation model)"),qLe.forEach(t),two=i(W),t4=n(W,"LI",{});var jLe=s(t4);Vde=n(jLe,"STRONG",{});var wst=s(Vde);awo=r(wst,"big_bird"),wst.forEach(t),nwo=r(jLe," \u2014 "),Rj=n(jLe,"A",{href:!0});var Ast=s(Rj);swo=r(Ast,"BigBirdForCausalLM"),Ast.forEach(t),lwo=r(jLe," (BigBird model)"),jLe.forEach(t),iwo=i(W),a4=n(W,"LI",{});var DLe=s(a4);Xde=n(DLe,"STRONG",{});var yst=s(Xde);dwo=r(yst,"bigbird_pegasus"),yst.forEach(t),cwo=r(DLe," \u2014 "),Pj=n(DLe,"A",{href:!0});var Lst=s(Pj);fwo=r(Lst,"BigBirdPegasusForCausalLM"),Lst.forEach(t),mwo=r(DLe," (BigBirdPegasus model)"),DLe.forEach(t),gwo=i(W),n4=n(W,"LI",{});var GLe=s(n4);zde=n(GLe,"STRONG",{});var xst=s(zde);hwo=r(xst,"blenderbot"),xst.forEach(t),pwo=r(GLe," \u2014 "),Bj=n(GLe,"A",{href:!0});var $st=s(Bj);_wo=r($st,"BlenderbotForCausalLM"),$st.forEach(t),uwo=r(GLe," (Blenderbot model)"),GLe.forEach(t),bwo=i(W),s4=n(W,"LI",{});var OLe=s(s4);Wde=n(OLe,"STRONG",{});var kst=s(Wde);vwo=r(kst,"blenderbot-small"),kst.forEach(t),Fwo=r(OLe," \u2014 "),Ij=n(OLe,"A",{href:!0});var Sst=s(Ij);Two=r(Sst,"BlenderbotSmallForCausalLM"),Sst.forEach(t),Mwo=r(OLe," (BlenderbotSmall model)"),OLe.forEach(t),Ewo=i(W),l4=n(W,"LI",{});var VLe=s(l4);Qde=n(VLe,"STRONG",{});var Rst=s(Qde);Cwo=r(Rst,"camembert"),Rst.forEach(t),wwo=r(VLe," \u2014 "),Nj=n(VLe,"A",{href:!0});var Pst=s(Nj);Awo=r(Pst,"CamembertForCausalLM"),Pst.forEach(t),ywo=r(VLe," (CamemBERT model)"),VLe.forEach(t),Lwo=i(W),i4=n(W,"LI",{});var XLe=s(i4);Hde=n(XLe,"STRONG",{});var Bst=s(Hde);xwo=r(Bst,"codegen"),Bst.forEach(t),$wo=r(XLe," \u2014 "),qj=n(XLe,"A",{href:!0});var Ist=s(qj);kwo=r(Ist,"CodeGenForCausalLM"),Ist.forEach(t),Swo=r(XLe," (CodeGen model)"),XLe.forEach(t),Rwo=i(W),d4=n(W,"LI",{});var zLe=s(d4);Ude=n(zLe,"STRONG",{});var Nst=s(Ude);Pwo=r(Nst,"ctrl"),Nst.forEach(t),Bwo=r(zLe," \u2014 "),jj=n(zLe,"A",{href:!0});var qst=s(jj);Iwo=r(qst,"CTRLLMHeadModel"),qst.forEach(t),Nwo=r(zLe," (CTRL model)"),zLe.forEach(t),qwo=i(W),c4=n(W,"LI",{});var WLe=s(c4);Jde=n(WLe,"STRONG",{});var jst=s(Jde);jwo=r(jst,"data2vec-text"),jst.forEach(t),Dwo=r(WLe," \u2014 "),Dj=n(WLe,"A",{href:!0});var Dst=s(Dj);Gwo=r(Dst,"Data2VecTextForCausalLM"),Dst.forEach(t),Owo=r(WLe," (Data2VecText model)"),WLe.forEach(t),Vwo=i(W),f4=n(W,"LI",{});var QLe=s(f4);Yde=n(QLe,"STRONG",{});var Gst=s(Yde);Xwo=r(Gst,"electra"),Gst.forEach(t),zwo=r(QLe," \u2014 "),Gj=n(QLe,"A",{href:!0});var Ost=s(Gj);Wwo=r(Ost,"ElectraForCausalLM"),Ost.forEach(t),Qwo=r(QLe," (ELECTRA model)"),QLe.forEach(t),Hwo=i(W),m4=n(W,"LI",{});var HLe=s(m4);Kde=n(HLe,"STRONG",{});var Vst=s(Kde);Uwo=r(Vst,"gpt2"),Vst.forEach(t),Jwo=r(HLe," \u2014 "),Oj=n(HLe,"A",{href:!0});var Xst=s(Oj);Ywo=r(Xst,"GPT2LMHeadModel"),Xst.forEach(t),Kwo=r(HLe," (OpenAI GPT-2 model)"),HLe.forEach(t),Zwo=i(W),g4=n(W,"LI",{});var ULe=s(g4);Zde=n(ULe,"STRONG",{});var zst=s(Zde);e0o=r(zst,"gpt_neo"),zst.forEach(t),o0o=r(ULe," \u2014 "),Vj=n(ULe,"A",{href:!0});var Wst=s(Vj);r0o=r(Wst,"GPTNeoForCausalLM"),Wst.forEach(t),t0o=r(ULe," (GPT Neo model)"),ULe.forEach(t),a0o=i(W),h4=n(W,"LI",{});var JLe=s(h4);ece=n(JLe,"STRONG",{});var Qst=s(ece);n0o=r(Qst,"gpt_neox"),Qst.forEach(t),s0o=r(JLe," \u2014 "),Xj=n(JLe,"A",{href:!0});var Hst=s(Xj);l0o=r(Hst,"GPTNeoXForCausalLM"),Hst.forEach(t),i0o=r(JLe," (GPT NeoX model)"),JLe.forEach(t),d0o=i(W),p4=n(W,"LI",{});var YLe=s(p4);oce=n(YLe,"STRONG",{});var Ust=s(oce);c0o=r(Ust,"gptj"),Ust.forEach(t),f0o=r(YLe," \u2014 "),zj=n(YLe,"A",{href:!0});var Jst=s(zj);m0o=r(Jst,"GPTJForCausalLM"),Jst.forEach(t),g0o=r(YLe," (GPT-J model)"),YLe.forEach(t),h0o=i(W),_4=n(W,"LI",{});var KLe=s(_4);rce=n(KLe,"STRONG",{});var Yst=s(rce);p0o=r(Yst,"marian"),Yst.forEach(t),_0o=r(KLe," \u2014 "),Wj=n(KLe,"A",{href:!0});var Kst=s(Wj);u0o=r(Kst,"MarianForCausalLM"),Kst.forEach(t),b0o=r(KLe," (Marian model)"),KLe.forEach(t),v0o=i(W),u4=n(W,"LI",{});var ZLe=s(u4);tce=n(ZLe,"STRONG",{});var Zst=s(tce);F0o=r(Zst,"mbart"),Zst.forEach(t),T0o=r(ZLe," \u2014 "),Qj=n(ZLe,"A",{href:!0});var elt=s(Qj);M0o=r(elt,"MBartForCausalLM"),elt.forEach(t),E0o=r(ZLe," (mBART model)"),ZLe.forEach(t),C0o=i(W),b4=n(W,"LI",{});var e8e=s(b4);ace=n(e8e,"STRONG",{});var olt=s(ace);w0o=r(olt,"megatron-bert"),olt.forEach(t),A0o=r(e8e," \u2014 "),Hj=n(e8e,"A",{href:!0});var rlt=s(Hj);y0o=r(rlt,"MegatronBertForCausalLM"),rlt.forEach(t),L0o=r(e8e," (MegatronBert model)"),e8e.forEach(t),x0o=i(W),v4=n(W,"LI",{});var o8e=s(v4);nce=n(o8e,"STRONG",{});var tlt=s(nce);$0o=r(tlt,"openai-gpt"),tlt.forEach(t),k0o=r(o8e," \u2014 "),Uj=n(o8e,"A",{href:!0});var alt=s(Uj);S0o=r(alt,"OpenAIGPTLMHeadModel"),alt.forEach(t),R0o=r(o8e," (OpenAI GPT model)"),o8e.forEach(t),P0o=i(W),F4=n(W,"LI",{});var r8e=s(F4);sce=n(r8e,"STRONG",{});var nlt=s(sce);B0o=r(nlt,"opt"),nlt.forEach(t),I0o=r(r8e," \u2014 "),Jj=n(r8e,"A",{href:!0});var slt=s(Jj);N0o=r(slt,"OPTForCausalLM"),slt.forEach(t),q0o=r(r8e," (OPT model)"),r8e.forEach(t),j0o=i(W),T4=n(W,"LI",{});var t8e=s(T4);lce=n(t8e,"STRONG",{});var llt=s(lce);D0o=r(llt,"pegasus"),llt.forEach(t),G0o=r(t8e," \u2014 "),Yj=n(t8e,"A",{href:!0});var ilt=s(Yj);O0o=r(ilt,"PegasusForCausalLM"),ilt.forEach(t),V0o=r(t8e," (Pegasus model)"),t8e.forEach(t),X0o=i(W),M4=n(W,"LI",{});var a8e=s(M4);ice=n(a8e,"STRONG",{});var dlt=s(ice);z0o=r(dlt,"plbart"),dlt.forEach(t),W0o=r(a8e," \u2014 "),Kj=n(a8e,"A",{href:!0});var clt=s(Kj);Q0o=r(clt,"PLBartForCausalLM"),clt.forEach(t),H0o=r(a8e," (PLBart model)"),a8e.forEach(t),U0o=i(W),E4=n(W,"LI",{});var n8e=s(E4);dce=n(n8e,"STRONG",{});var flt=s(dce);J0o=r(flt,"prophetnet"),flt.forEach(t),Y0o=r(n8e," \u2014 "),Zj=n(n8e,"A",{href:!0});var mlt=s(Zj);K0o=r(mlt,"ProphetNetForCausalLM"),mlt.forEach(t),Z0o=r(n8e," (ProphetNet model)"),n8e.forEach(t),e6o=i(W),C4=n(W,"LI",{});var s8e=s(C4);cce=n(s8e,"STRONG",{});var glt=s(cce);o6o=r(glt,"qdqbert"),glt.forEach(t),r6o=r(s8e," \u2014 "),eD=n(s8e,"A",{href:!0});var hlt=s(eD);t6o=r(hlt,"QDQBertLMHeadModel"),hlt.forEach(t),a6o=r(s8e," (QDQBert model)"),s8e.forEach(t),n6o=i(W),w4=n(W,"LI",{});var l8e=s(w4);fce=n(l8e,"STRONG",{});var plt=s(fce);s6o=r(plt,"reformer"),plt.forEach(t),l6o=r(l8e," \u2014 "),oD=n(l8e,"A",{href:!0});var _lt=s(oD);i6o=r(_lt,"ReformerModelWithLMHead"),_lt.forEach(t),d6o=r(l8e," (Reformer model)"),l8e.forEach(t),c6o=i(W),A4=n(W,"LI",{});var i8e=s(A4);mce=n(i8e,"STRONG",{});var ult=s(mce);f6o=r(ult,"rembert"),ult.forEach(t),m6o=r(i8e," \u2014 "),rD=n(i8e,"A",{href:!0});var blt=s(rD);g6o=r(blt,"RemBertForCausalLM"),blt.forEach(t),h6o=r(i8e," (RemBERT model)"),i8e.forEach(t),p6o=i(W),y4=n(W,"LI",{});var d8e=s(y4);gce=n(d8e,"STRONG",{});var vlt=s(gce);_6o=r(vlt,"roberta"),vlt.forEach(t),u6o=r(d8e," \u2014 "),tD=n(d8e,"A",{href:!0});var Flt=s(tD);b6o=r(Flt,"RobertaForCausalLM"),Flt.forEach(t),v6o=r(d8e," (RoBERTa model)"),d8e.forEach(t),F6o=i(W),L4=n(W,"LI",{});var c8e=s(L4);hce=n(c8e,"STRONG",{});var Tlt=s(hce);T6o=r(Tlt,"roformer"),Tlt.forEach(t),M6o=r(c8e," \u2014 "),aD=n(c8e,"A",{href:!0});var Mlt=s(aD);E6o=r(Mlt,"RoFormerForCausalLM"),Mlt.forEach(t),C6o=r(c8e," (RoFormer model)"),c8e.forEach(t),w6o=i(W),x4=n(W,"LI",{});var f8e=s(x4);pce=n(f8e,"STRONG",{});var Elt=s(pce);A6o=r(Elt,"speech_to_text_2"),Elt.forEach(t),y6o=r(f8e," \u2014 "),nD=n(f8e,"A",{href:!0});var Clt=s(nD);L6o=r(Clt,"Speech2Text2ForCausalLM"),Clt.forEach(t),x6o=r(f8e," (Speech2Text2 model)"),f8e.forEach(t),$6o=i(W),$4=n(W,"LI",{});var m8e=s($4);_ce=n(m8e,"STRONG",{});var wlt=s(_ce);k6o=r(wlt,"transfo-xl"),wlt.forEach(t),S6o=r(m8e," \u2014 "),sD=n(m8e,"A",{href:!0});var Alt=s(sD);R6o=r(Alt,"TransfoXLLMHeadModel"),Alt.forEach(t),P6o=r(m8e," (Transformer-XL model)"),m8e.forEach(t),B6o=i(W),k4=n(W,"LI",{});var g8e=s(k4);uce=n(g8e,"STRONG",{});var ylt=s(uce);I6o=r(ylt,"trocr"),ylt.forEach(t),N6o=r(g8e," \u2014 "),lD=n(g8e,"A",{href:!0});var Llt=s(lD);q6o=r(Llt,"TrOCRForCausalLM"),Llt.forEach(t),j6o=r(g8e," (TrOCR model)"),g8e.forEach(t),D6o=i(W),S4=n(W,"LI",{});var h8e=s(S4);bce=n(h8e,"STRONG",{});var xlt=s(bce);G6o=r(xlt,"xglm"),xlt.forEach(t),O6o=r(h8e," \u2014 "),iD=n(h8e,"A",{href:!0});var $lt=s(iD);V6o=r($lt,"XGLMForCausalLM"),$lt.forEach(t),X6o=r(h8e," (XGLM model)"),h8e.forEach(t),z6o=i(W),R4=n(W,"LI",{});var p8e=s(R4);vce=n(p8e,"STRONG",{});var klt=s(vce);W6o=r(klt,"xlm"),klt.forEach(t),Q6o=r(p8e," \u2014 "),dD=n(p8e,"A",{href:!0});var Slt=s(dD);H6o=r(Slt,"XLMWithLMHeadModel"),Slt.forEach(t),U6o=r(p8e," (XLM model)"),p8e.forEach(t),J6o=i(W),P4=n(W,"LI",{});var _8e=s(P4);Fce=n(_8e,"STRONG",{});var Rlt=s(Fce);Y6o=r(Rlt,"xlm-prophetnet"),Rlt.forEach(t),K6o=r(_8e," \u2014 "),cD=n(_8e,"A",{href:!0});var Plt=s(cD);Z6o=r(Plt,"XLMProphetNetForCausalLM"),Plt.forEach(t),eAo=r(_8e," (XLMProphetNet model)"),_8e.forEach(t),oAo=i(W),B4=n(W,"LI",{});var u8e=s(B4);Tce=n(u8e,"STRONG",{});var Blt=s(Tce);rAo=r(Blt,"xlm-roberta"),Blt.forEach(t),tAo=r(u8e," \u2014 "),fD=n(u8e,"A",{href:!0});var Ilt=s(fD);aAo=r(Ilt,"XLMRobertaForCausalLM"),Ilt.forEach(t),nAo=r(u8e," (XLM-RoBERTa model)"),u8e.forEach(t),sAo=i(W),I4=n(W,"LI",{});var b8e=s(I4);Mce=n(b8e,"STRONG",{});var Nlt=s(Mce);lAo=r(Nlt,"xlm-roberta-xl"),Nlt.forEach(t),iAo=r(b8e," \u2014 "),mD=n(b8e,"A",{href:!0});var qlt=s(mD);dAo=r(qlt,"XLMRobertaXLForCausalLM"),qlt.forEach(t),cAo=r(b8e," (XLM-RoBERTa-XL model)"),b8e.forEach(t),fAo=i(W),N4=n(W,"LI",{});var v8e=s(N4);Ece=n(v8e,"STRONG",{});var jlt=s(Ece);mAo=r(jlt,"xlnet"),jlt.forEach(t),gAo=r(v8e," \u2014 "),gD=n(v8e,"A",{href:!0});var Dlt=s(gD);hAo=r(Dlt,"XLNetLMHeadModel"),Dlt.forEach(t),pAo=r(v8e," (XLNet model)"),v8e.forEach(t),W.forEach(t),_Ao=i(ta),q4=n(ta,"P",{});var F8e=s(q4);uAo=r(F8e,"The model is set in evaluation mode by default using "),Cce=n(F8e,"CODE",{});var Glt=s(Cce);bAo=r(Glt,"model.eval()"),Glt.forEach(t),vAo=r(F8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wce=n(F8e,"CODE",{});var Olt=s(wce);FAo=r(Olt,"model.train()"),Olt.forEach(t),F8e.forEach(t),TAo=i(ta),T(j4.$$.fragment,ta),ta.forEach(t),Xs.forEach(t),Pqe=i(f),Bi=n(f,"H2",{class:!0});var qDe=s(Bi);D4=n(qDe,"A",{id:!0,class:!0,href:!0});var Vlt=s(D4);Ace=n(Vlt,"SPAN",{});var Xlt=s(Ace);T(by.$$.fragment,Xlt),Xlt.forEach(t),Vlt.forEach(t),MAo=i(qDe),yce=n(qDe,"SPAN",{});var zlt=s(yce);EAo=r(zlt,"AutoModelForMaskedLM"),zlt.forEach(t),qDe.forEach(t),Bqe=i(f),ko=n(f,"DIV",{class:!0});var zs=s(ko);T(vy.$$.fragment,zs),CAo=i(zs),Ii=n(zs,"P",{});var kZ=s(Ii);wAo=r(kZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),hD=n(kZ,"A",{href:!0});var Wlt=s(hD);AAo=r(Wlt,"from_pretrained()"),Wlt.forEach(t),yAo=r(kZ," class method or the "),pD=n(kZ,"A",{href:!0});var Qlt=s(pD);LAo=r(Qlt,"from_config()"),Qlt.forEach(t),xAo=r(kZ,` class
method.`),kZ.forEach(t),$Ao=i(zs),Fy=n(zs,"P",{});var jDe=s(Fy);kAo=r(jDe,"This class cannot be instantiated directly using "),Lce=n(jDe,"CODE",{});var Hlt=s(Lce);SAo=r(Hlt,"__init__()"),Hlt.forEach(t),RAo=r(jDe," (throws an error)."),jDe.forEach(t),PAo=i(zs),st=n(zs,"DIV",{class:!0});var G0=s(st);T(Ty.$$.fragment,G0),BAo=i(G0),xce=n(G0,"P",{});var Ult=s(xce);IAo=r(Ult,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Ult.forEach(t),NAo=i(G0),Ni=n(G0,"P",{});var SZ=s(Ni);qAo=r(SZ,`Note:
Loading a model from its configuration file does `),$ce=n(SZ,"STRONG",{});var Jlt=s($ce);jAo=r(Jlt,"not"),Jlt.forEach(t),DAo=r(SZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),_D=n(SZ,"A",{href:!0});var Ylt=s(_D);GAo=r(Ylt,"from_pretrained()"),Ylt.forEach(t),OAo=r(SZ," to load the model weights."),SZ.forEach(t),VAo=i(G0),T(G4.$$.fragment,G0),G0.forEach(t),XAo=i(zs),Ze=n(zs,"DIV",{class:!0});var aa=s(Ze);T(My.$$.fragment,aa),zAo=i(aa),kce=n(aa,"P",{});var Klt=s(kce);WAo=r(Klt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Klt.forEach(t),QAo=i(aa),ka=n(aa,"P",{});var O0=s(ka);HAo=r(O0,"The model class to instantiate is selected based on the "),Sce=n(O0,"CODE",{});var Zlt=s(Sce);UAo=r(Zlt,"model_type"),Zlt.forEach(t),JAo=r(O0,` property of the config object (either
passed as an argument or loaded from `),Rce=n(O0,"CODE",{});var eit=s(Rce);YAo=r(eit,"pretrained_model_name_or_path"),eit.forEach(t),KAo=r(O0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pce=n(O0,"CODE",{});var oit=s(Pce);ZAo=r(oit,"pretrained_model_name_or_path"),oit.forEach(t),eyo=r(O0,":"),O0.forEach(t),oyo=i(aa),Q=n(aa,"UL",{});var U=s(Q);O4=n(U,"LI",{});var T8e=s(O4);Bce=n(T8e,"STRONG",{});var rit=s(Bce);ryo=r(rit,"albert"),rit.forEach(t),tyo=r(T8e," \u2014 "),uD=n(T8e,"A",{href:!0});var tit=s(uD);ayo=r(tit,"AlbertForMaskedLM"),tit.forEach(t),nyo=r(T8e," (ALBERT model)"),T8e.forEach(t),syo=i(U),V4=n(U,"LI",{});var M8e=s(V4);Ice=n(M8e,"STRONG",{});var ait=s(Ice);lyo=r(ait,"bart"),ait.forEach(t),iyo=r(M8e," \u2014 "),bD=n(M8e,"A",{href:!0});var nit=s(bD);dyo=r(nit,"BartForConditionalGeneration"),nit.forEach(t),cyo=r(M8e," (BART model)"),M8e.forEach(t),fyo=i(U),X4=n(U,"LI",{});var E8e=s(X4);Nce=n(E8e,"STRONG",{});var sit=s(Nce);myo=r(sit,"bert"),sit.forEach(t),gyo=r(E8e," \u2014 "),vD=n(E8e,"A",{href:!0});var lit=s(vD);hyo=r(lit,"BertForMaskedLM"),lit.forEach(t),pyo=r(E8e," (BERT model)"),E8e.forEach(t),_yo=i(U),z4=n(U,"LI",{});var C8e=s(z4);qce=n(C8e,"STRONG",{});var iit=s(qce);uyo=r(iit,"big_bird"),iit.forEach(t),byo=r(C8e," \u2014 "),FD=n(C8e,"A",{href:!0});var dit=s(FD);vyo=r(dit,"BigBirdForMaskedLM"),dit.forEach(t),Fyo=r(C8e," (BigBird model)"),C8e.forEach(t),Tyo=i(U),W4=n(U,"LI",{});var w8e=s(W4);jce=n(w8e,"STRONG",{});var cit=s(jce);Myo=r(cit,"camembert"),cit.forEach(t),Eyo=r(w8e," \u2014 "),TD=n(w8e,"A",{href:!0});var fit=s(TD);Cyo=r(fit,"CamembertForMaskedLM"),fit.forEach(t),wyo=r(w8e," (CamemBERT model)"),w8e.forEach(t),Ayo=i(U),Q4=n(U,"LI",{});var A8e=s(Q4);Dce=n(A8e,"STRONG",{});var mit=s(Dce);yyo=r(mit,"convbert"),mit.forEach(t),Lyo=r(A8e," \u2014 "),MD=n(A8e,"A",{href:!0});var git=s(MD);xyo=r(git,"ConvBertForMaskedLM"),git.forEach(t),$yo=r(A8e," (ConvBERT model)"),A8e.forEach(t),kyo=i(U),H4=n(U,"LI",{});var y8e=s(H4);Gce=n(y8e,"STRONG",{});var hit=s(Gce);Syo=r(hit,"data2vec-text"),hit.forEach(t),Ryo=r(y8e," \u2014 "),ED=n(y8e,"A",{href:!0});var pit=s(ED);Pyo=r(pit,"Data2VecTextForMaskedLM"),pit.forEach(t),Byo=r(y8e," (Data2VecText model)"),y8e.forEach(t),Iyo=i(U),U4=n(U,"LI",{});var L8e=s(U4);Oce=n(L8e,"STRONG",{});var _it=s(Oce);Nyo=r(_it,"deberta"),_it.forEach(t),qyo=r(L8e," \u2014 "),CD=n(L8e,"A",{href:!0});var uit=s(CD);jyo=r(uit,"DebertaForMaskedLM"),uit.forEach(t),Dyo=r(L8e," (DeBERTa model)"),L8e.forEach(t),Gyo=i(U),J4=n(U,"LI",{});var x8e=s(J4);Vce=n(x8e,"STRONG",{});var bit=s(Vce);Oyo=r(bit,"deberta-v2"),bit.forEach(t),Vyo=r(x8e," \u2014 "),wD=n(x8e,"A",{href:!0});var vit=s(wD);Xyo=r(vit,"DebertaV2ForMaskedLM"),vit.forEach(t),zyo=r(x8e," (DeBERTa-v2 model)"),x8e.forEach(t),Wyo=i(U),Y4=n(U,"LI",{});var $8e=s(Y4);Xce=n($8e,"STRONG",{});var Fit=s(Xce);Qyo=r(Fit,"distilbert"),Fit.forEach(t),Hyo=r($8e," \u2014 "),AD=n($8e,"A",{href:!0});var Tit=s(AD);Uyo=r(Tit,"DistilBertForMaskedLM"),Tit.forEach(t),Jyo=r($8e," (DistilBERT model)"),$8e.forEach(t),Yyo=i(U),K4=n(U,"LI",{});var k8e=s(K4);zce=n(k8e,"STRONG",{});var Mit=s(zce);Kyo=r(Mit,"electra"),Mit.forEach(t),Zyo=r(k8e," \u2014 "),yD=n(k8e,"A",{href:!0});var Eit=s(yD);eLo=r(Eit,"ElectraForMaskedLM"),Eit.forEach(t),oLo=r(k8e," (ELECTRA model)"),k8e.forEach(t),rLo=i(U),Z4=n(U,"LI",{});var S8e=s(Z4);Wce=n(S8e,"STRONG",{});var Cit=s(Wce);tLo=r(Cit,"flaubert"),Cit.forEach(t),aLo=r(S8e," \u2014 "),LD=n(S8e,"A",{href:!0});var wit=s(LD);nLo=r(wit,"FlaubertWithLMHeadModel"),wit.forEach(t),sLo=r(S8e," (FlauBERT model)"),S8e.forEach(t),lLo=i(U),e1=n(U,"LI",{});var R8e=s(e1);Qce=n(R8e,"STRONG",{});var Ait=s(Qce);iLo=r(Ait,"fnet"),Ait.forEach(t),dLo=r(R8e," \u2014 "),xD=n(R8e,"A",{href:!0});var yit=s(xD);cLo=r(yit,"FNetForMaskedLM"),yit.forEach(t),fLo=r(R8e," (FNet model)"),R8e.forEach(t),mLo=i(U),o1=n(U,"LI",{});var P8e=s(o1);Hce=n(P8e,"STRONG",{});var Lit=s(Hce);gLo=r(Lit,"funnel"),Lit.forEach(t),hLo=r(P8e," \u2014 "),$D=n(P8e,"A",{href:!0});var xit=s($D);pLo=r(xit,"FunnelForMaskedLM"),xit.forEach(t),_Lo=r(P8e," (Funnel Transformer model)"),P8e.forEach(t),uLo=i(U),r1=n(U,"LI",{});var B8e=s(r1);Uce=n(B8e,"STRONG",{});var $it=s(Uce);bLo=r($it,"ibert"),$it.forEach(t),vLo=r(B8e," \u2014 "),kD=n(B8e,"A",{href:!0});var kit=s(kD);FLo=r(kit,"IBertForMaskedLM"),kit.forEach(t),TLo=r(B8e," (I-BERT model)"),B8e.forEach(t),MLo=i(U),t1=n(U,"LI",{});var I8e=s(t1);Jce=n(I8e,"STRONG",{});var Sit=s(Jce);ELo=r(Sit,"layoutlm"),Sit.forEach(t),CLo=r(I8e," \u2014 "),SD=n(I8e,"A",{href:!0});var Rit=s(SD);wLo=r(Rit,"LayoutLMForMaskedLM"),Rit.forEach(t),ALo=r(I8e," (LayoutLM model)"),I8e.forEach(t),yLo=i(U),a1=n(U,"LI",{});var N8e=s(a1);Yce=n(N8e,"STRONG",{});var Pit=s(Yce);LLo=r(Pit,"longformer"),Pit.forEach(t),xLo=r(N8e," \u2014 "),RD=n(N8e,"A",{href:!0});var Bit=s(RD);$Lo=r(Bit,"LongformerForMaskedLM"),Bit.forEach(t),kLo=r(N8e," (Longformer model)"),N8e.forEach(t),SLo=i(U),n1=n(U,"LI",{});var q8e=s(n1);Kce=n(q8e,"STRONG",{});var Iit=s(Kce);RLo=r(Iit,"mbart"),Iit.forEach(t),PLo=r(q8e," \u2014 "),PD=n(q8e,"A",{href:!0});var Nit=s(PD);BLo=r(Nit,"MBartForConditionalGeneration"),Nit.forEach(t),ILo=r(q8e," (mBART model)"),q8e.forEach(t),NLo=i(U),s1=n(U,"LI",{});var j8e=s(s1);Zce=n(j8e,"STRONG",{});var qit=s(Zce);qLo=r(qit,"megatron-bert"),qit.forEach(t),jLo=r(j8e," \u2014 "),BD=n(j8e,"A",{href:!0});var jit=s(BD);DLo=r(jit,"MegatronBertForMaskedLM"),jit.forEach(t),GLo=r(j8e," (MegatronBert model)"),j8e.forEach(t),OLo=i(U),l1=n(U,"LI",{});var D8e=s(l1);efe=n(D8e,"STRONG",{});var Dit=s(efe);VLo=r(Dit,"mobilebert"),Dit.forEach(t),XLo=r(D8e," \u2014 "),ID=n(D8e,"A",{href:!0});var Git=s(ID);zLo=r(Git,"MobileBertForMaskedLM"),Git.forEach(t),WLo=r(D8e," (MobileBERT model)"),D8e.forEach(t),QLo=i(U),i1=n(U,"LI",{});var G8e=s(i1);ofe=n(G8e,"STRONG",{});var Oit=s(ofe);HLo=r(Oit,"mpnet"),Oit.forEach(t),ULo=r(G8e," \u2014 "),ND=n(G8e,"A",{href:!0});var Vit=s(ND);JLo=r(Vit,"MPNetForMaskedLM"),Vit.forEach(t),YLo=r(G8e," (MPNet model)"),G8e.forEach(t),KLo=i(U),d1=n(U,"LI",{});var O8e=s(d1);rfe=n(O8e,"STRONG",{});var Xit=s(rfe);ZLo=r(Xit,"nystromformer"),Xit.forEach(t),e8o=r(O8e," \u2014 "),qD=n(O8e,"A",{href:!0});var zit=s(qD);o8o=r(zit,"NystromformerForMaskedLM"),zit.forEach(t),r8o=r(O8e," (Nystromformer model)"),O8e.forEach(t),t8o=i(U),c1=n(U,"LI",{});var V8e=s(c1);tfe=n(V8e,"STRONG",{});var Wit=s(tfe);a8o=r(Wit,"perceiver"),Wit.forEach(t),n8o=r(V8e," \u2014 "),jD=n(V8e,"A",{href:!0});var Qit=s(jD);s8o=r(Qit,"PerceiverForMaskedLM"),Qit.forEach(t),l8o=r(V8e," (Perceiver model)"),V8e.forEach(t),i8o=i(U),f1=n(U,"LI",{});var X8e=s(f1);afe=n(X8e,"STRONG",{});var Hit=s(afe);d8o=r(Hit,"qdqbert"),Hit.forEach(t),c8o=r(X8e," \u2014 "),DD=n(X8e,"A",{href:!0});var Uit=s(DD);f8o=r(Uit,"QDQBertForMaskedLM"),Uit.forEach(t),m8o=r(X8e," (QDQBert model)"),X8e.forEach(t),g8o=i(U),m1=n(U,"LI",{});var z8e=s(m1);nfe=n(z8e,"STRONG",{});var Jit=s(nfe);h8o=r(Jit,"reformer"),Jit.forEach(t),p8o=r(z8e," \u2014 "),GD=n(z8e,"A",{href:!0});var Yit=s(GD);_8o=r(Yit,"ReformerForMaskedLM"),Yit.forEach(t),u8o=r(z8e," (Reformer model)"),z8e.forEach(t),b8o=i(U),g1=n(U,"LI",{});var W8e=s(g1);sfe=n(W8e,"STRONG",{});var Kit=s(sfe);v8o=r(Kit,"rembert"),Kit.forEach(t),F8o=r(W8e," \u2014 "),OD=n(W8e,"A",{href:!0});var Zit=s(OD);T8o=r(Zit,"RemBertForMaskedLM"),Zit.forEach(t),M8o=r(W8e," (RemBERT model)"),W8e.forEach(t),E8o=i(U),h1=n(U,"LI",{});var Q8e=s(h1);lfe=n(Q8e,"STRONG",{});var edt=s(lfe);C8o=r(edt,"roberta"),edt.forEach(t),w8o=r(Q8e," \u2014 "),VD=n(Q8e,"A",{href:!0});var odt=s(VD);A8o=r(odt,"RobertaForMaskedLM"),odt.forEach(t),y8o=r(Q8e," (RoBERTa model)"),Q8e.forEach(t),L8o=i(U),p1=n(U,"LI",{});var H8e=s(p1);ife=n(H8e,"STRONG",{});var rdt=s(ife);x8o=r(rdt,"roformer"),rdt.forEach(t),$8o=r(H8e," \u2014 "),XD=n(H8e,"A",{href:!0});var tdt=s(XD);k8o=r(tdt,"RoFormerForMaskedLM"),tdt.forEach(t),S8o=r(H8e," (RoFormer model)"),H8e.forEach(t),R8o=i(U),_1=n(U,"LI",{});var U8e=s(_1);dfe=n(U8e,"STRONG",{});var adt=s(dfe);P8o=r(adt,"squeezebert"),adt.forEach(t),B8o=r(U8e," \u2014 "),zD=n(U8e,"A",{href:!0});var ndt=s(zD);I8o=r(ndt,"SqueezeBertForMaskedLM"),ndt.forEach(t),N8o=r(U8e," (SqueezeBERT model)"),U8e.forEach(t),q8o=i(U),u1=n(U,"LI",{});var J8e=s(u1);cfe=n(J8e,"STRONG",{});var sdt=s(cfe);j8o=r(sdt,"tapas"),sdt.forEach(t),D8o=r(J8e," \u2014 "),WD=n(J8e,"A",{href:!0});var ldt=s(WD);G8o=r(ldt,"TapasForMaskedLM"),ldt.forEach(t),O8o=r(J8e," (TAPAS model)"),J8e.forEach(t),V8o=i(U),b1=n(U,"LI",{});var Y8e=s(b1);ffe=n(Y8e,"STRONG",{});var idt=s(ffe);X8o=r(idt,"wav2vec2"),idt.forEach(t),z8o=r(Y8e," \u2014 "),mfe=n(Y8e,"CODE",{});var ddt=s(mfe);W8o=r(ddt,"Wav2Vec2ForMaskedLM"),ddt.forEach(t),Q8o=r(Y8e," (Wav2Vec2 model)"),Y8e.forEach(t),H8o=i(U),v1=n(U,"LI",{});var K8e=s(v1);gfe=n(K8e,"STRONG",{});var cdt=s(gfe);U8o=r(cdt,"xlm"),cdt.forEach(t),J8o=r(K8e," \u2014 "),QD=n(K8e,"A",{href:!0});var fdt=s(QD);Y8o=r(fdt,"XLMWithLMHeadModel"),fdt.forEach(t),K8o=r(K8e," (XLM model)"),K8e.forEach(t),Z8o=i(U),F1=n(U,"LI",{});var Z8e=s(F1);hfe=n(Z8e,"STRONG",{});var mdt=s(hfe);e9o=r(mdt,"xlm-roberta"),mdt.forEach(t),o9o=r(Z8e," \u2014 "),HD=n(Z8e,"A",{href:!0});var gdt=s(HD);r9o=r(gdt,"XLMRobertaForMaskedLM"),gdt.forEach(t),t9o=r(Z8e," (XLM-RoBERTa model)"),Z8e.forEach(t),a9o=i(U),T1=n(U,"LI",{});var e9e=s(T1);pfe=n(e9e,"STRONG",{});var hdt=s(pfe);n9o=r(hdt,"xlm-roberta-xl"),hdt.forEach(t),s9o=r(e9e," \u2014 "),UD=n(e9e,"A",{href:!0});var pdt=s(UD);l9o=r(pdt,"XLMRobertaXLForMaskedLM"),pdt.forEach(t),i9o=r(e9e," (XLM-RoBERTa-XL model)"),e9e.forEach(t),d9o=i(U),M1=n(U,"LI",{});var o9e=s(M1);_fe=n(o9e,"STRONG",{});var _dt=s(_fe);c9o=r(_dt,"yoso"),_dt.forEach(t),f9o=r(o9e," \u2014 "),JD=n(o9e,"A",{href:!0});var udt=s(JD);m9o=r(udt,"YosoForMaskedLM"),udt.forEach(t),g9o=r(o9e," (YOSO model)"),o9e.forEach(t),U.forEach(t),h9o=i(aa),E1=n(aa,"P",{});var r9e=s(E1);p9o=r(r9e,"The model is set in evaluation mode by default using "),ufe=n(r9e,"CODE",{});var bdt=s(ufe);_9o=r(bdt,"model.eval()"),bdt.forEach(t),u9o=r(r9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bfe=n(r9e,"CODE",{});var vdt=s(bfe);b9o=r(vdt,"model.train()"),vdt.forEach(t),r9e.forEach(t),v9o=i(aa),T(C1.$$.fragment,aa),aa.forEach(t),zs.forEach(t),Iqe=i(f),qi=n(f,"H2",{class:!0});var DDe=s(qi);w1=n(DDe,"A",{id:!0,class:!0,href:!0});var Fdt=s(w1);vfe=n(Fdt,"SPAN",{});var Tdt=s(vfe);T(Ey.$$.fragment,Tdt),Tdt.forEach(t),Fdt.forEach(t),F9o=i(DDe),Ffe=n(DDe,"SPAN",{});var Mdt=s(Ffe);T9o=r(Mdt,"AutoModelForSeq2SeqLM"),Mdt.forEach(t),DDe.forEach(t),Nqe=i(f),So=n(f,"DIV",{class:!0});var Ws=s(So);T(Cy.$$.fragment,Ws),M9o=i(Ws),ji=n(Ws,"P",{});var RZ=s(ji);E9o=r(RZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),YD=n(RZ,"A",{href:!0});var Edt=s(YD);C9o=r(Edt,"from_pretrained()"),Edt.forEach(t),w9o=r(RZ," class method or the "),KD=n(RZ,"A",{href:!0});var Cdt=s(KD);A9o=r(Cdt,"from_config()"),Cdt.forEach(t),y9o=r(RZ,` class
method.`),RZ.forEach(t),L9o=i(Ws),wy=n(Ws,"P",{});var GDe=s(wy);x9o=r(GDe,"This class cannot be instantiated directly using "),Tfe=n(GDe,"CODE",{});var wdt=s(Tfe);$9o=r(wdt,"__init__()"),wdt.forEach(t),k9o=r(GDe," (throws an error)."),GDe.forEach(t),S9o=i(Ws),lt=n(Ws,"DIV",{class:!0});var V0=s(lt);T(Ay.$$.fragment,V0),R9o=i(V0),Mfe=n(V0,"P",{});var Adt=s(Mfe);P9o=r(Adt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Adt.forEach(t),B9o=i(V0),Di=n(V0,"P",{});var PZ=s(Di);I9o=r(PZ,`Note:
Loading a model from its configuration file does `),Efe=n(PZ,"STRONG",{});var ydt=s(Efe);N9o=r(ydt,"not"),ydt.forEach(t),q9o=r(PZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=n(PZ,"A",{href:!0});var Ldt=s(ZD);j9o=r(Ldt,"from_pretrained()"),Ldt.forEach(t),D9o=r(PZ," to load the model weights."),PZ.forEach(t),G9o=i(V0),T(A1.$$.fragment,V0),V0.forEach(t),O9o=i(Ws),eo=n(Ws,"DIV",{class:!0});var na=s(eo);T(yy.$$.fragment,na),V9o=i(na),Cfe=n(na,"P",{});var xdt=s(Cfe);X9o=r(xdt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xdt.forEach(t),z9o=i(na),Sa=n(na,"P",{});var X0=s(Sa);W9o=r(X0,"The model class to instantiate is selected based on the "),wfe=n(X0,"CODE",{});var $dt=s(wfe);Q9o=r($dt,"model_type"),$dt.forEach(t),H9o=r(X0,` property of the config object (either
passed as an argument or loaded from `),Afe=n(X0,"CODE",{});var kdt=s(Afe);U9o=r(kdt,"pretrained_model_name_or_path"),kdt.forEach(t),J9o=r(X0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yfe=n(X0,"CODE",{});var Sdt=s(yfe);Y9o=r(Sdt,"pretrained_model_name_or_path"),Sdt.forEach(t),K9o=r(X0,":"),X0.forEach(t),Z9o=i(na),_e=n(na,"UL",{});var ve=s(_e);y1=n(ve,"LI",{});var t9e=s(y1);Lfe=n(t9e,"STRONG",{});var Rdt=s(Lfe);exo=r(Rdt,"bart"),Rdt.forEach(t),oxo=r(t9e," \u2014 "),eG=n(t9e,"A",{href:!0});var Pdt=s(eG);rxo=r(Pdt,"BartForConditionalGeneration"),Pdt.forEach(t),txo=r(t9e," (BART model)"),t9e.forEach(t),axo=i(ve),L1=n(ve,"LI",{});var a9e=s(L1);xfe=n(a9e,"STRONG",{});var Bdt=s(xfe);nxo=r(Bdt,"bigbird_pegasus"),Bdt.forEach(t),sxo=r(a9e," \u2014 "),oG=n(a9e,"A",{href:!0});var Idt=s(oG);lxo=r(Idt,"BigBirdPegasusForConditionalGeneration"),Idt.forEach(t),ixo=r(a9e," (BigBirdPegasus model)"),a9e.forEach(t),dxo=i(ve),x1=n(ve,"LI",{});var n9e=s(x1);$fe=n(n9e,"STRONG",{});var Ndt=s($fe);cxo=r(Ndt,"blenderbot"),Ndt.forEach(t),fxo=r(n9e," \u2014 "),rG=n(n9e,"A",{href:!0});var qdt=s(rG);mxo=r(qdt,"BlenderbotForConditionalGeneration"),qdt.forEach(t),gxo=r(n9e," (Blenderbot model)"),n9e.forEach(t),hxo=i(ve),$1=n(ve,"LI",{});var s9e=s($1);kfe=n(s9e,"STRONG",{});var jdt=s(kfe);pxo=r(jdt,"blenderbot-small"),jdt.forEach(t),_xo=r(s9e," \u2014 "),tG=n(s9e,"A",{href:!0});var Ddt=s(tG);uxo=r(Ddt,"BlenderbotSmallForConditionalGeneration"),Ddt.forEach(t),bxo=r(s9e," (BlenderbotSmall model)"),s9e.forEach(t),vxo=i(ve),k1=n(ve,"LI",{});var l9e=s(k1);Sfe=n(l9e,"STRONG",{});var Gdt=s(Sfe);Fxo=r(Gdt,"encoder-decoder"),Gdt.forEach(t),Txo=r(l9e," \u2014 "),aG=n(l9e,"A",{href:!0});var Odt=s(aG);Mxo=r(Odt,"EncoderDecoderModel"),Odt.forEach(t),Exo=r(l9e," (Encoder decoder model)"),l9e.forEach(t),Cxo=i(ve),S1=n(ve,"LI",{});var i9e=s(S1);Rfe=n(i9e,"STRONG",{});var Vdt=s(Rfe);wxo=r(Vdt,"fsmt"),Vdt.forEach(t),Axo=r(i9e," \u2014 "),nG=n(i9e,"A",{href:!0});var Xdt=s(nG);yxo=r(Xdt,"FSMTForConditionalGeneration"),Xdt.forEach(t),Lxo=r(i9e," (FairSeq Machine-Translation model)"),i9e.forEach(t),xxo=i(ve),R1=n(ve,"LI",{});var d9e=s(R1);Pfe=n(d9e,"STRONG",{});var zdt=s(Pfe);$xo=r(zdt,"led"),zdt.forEach(t),kxo=r(d9e," \u2014 "),sG=n(d9e,"A",{href:!0});var Wdt=s(sG);Sxo=r(Wdt,"LEDForConditionalGeneration"),Wdt.forEach(t),Rxo=r(d9e," (LED model)"),d9e.forEach(t),Pxo=i(ve),P1=n(ve,"LI",{});var c9e=s(P1);Bfe=n(c9e,"STRONG",{});var Qdt=s(Bfe);Bxo=r(Qdt,"m2m_100"),Qdt.forEach(t),Ixo=r(c9e," \u2014 "),lG=n(c9e,"A",{href:!0});var Hdt=s(lG);Nxo=r(Hdt,"M2M100ForConditionalGeneration"),Hdt.forEach(t),qxo=r(c9e," (M2M100 model)"),c9e.forEach(t),jxo=i(ve),B1=n(ve,"LI",{});var f9e=s(B1);Ife=n(f9e,"STRONG",{});var Udt=s(Ife);Dxo=r(Udt,"marian"),Udt.forEach(t),Gxo=r(f9e," \u2014 "),iG=n(f9e,"A",{href:!0});var Jdt=s(iG);Oxo=r(Jdt,"MarianMTModel"),Jdt.forEach(t),Vxo=r(f9e," (Marian model)"),f9e.forEach(t),Xxo=i(ve),I1=n(ve,"LI",{});var m9e=s(I1);Nfe=n(m9e,"STRONG",{});var Ydt=s(Nfe);zxo=r(Ydt,"mbart"),Ydt.forEach(t),Wxo=r(m9e," \u2014 "),dG=n(m9e,"A",{href:!0});var Kdt=s(dG);Qxo=r(Kdt,"MBartForConditionalGeneration"),Kdt.forEach(t),Hxo=r(m9e," (mBART model)"),m9e.forEach(t),Uxo=i(ve),N1=n(ve,"LI",{});var g9e=s(N1);qfe=n(g9e,"STRONG",{});var Zdt=s(qfe);Jxo=r(Zdt,"mt5"),Zdt.forEach(t),Yxo=r(g9e," \u2014 "),cG=n(g9e,"A",{href:!0});var ect=s(cG);Kxo=r(ect,"MT5ForConditionalGeneration"),ect.forEach(t),Zxo=r(g9e," (mT5 model)"),g9e.forEach(t),e$o=i(ve),q1=n(ve,"LI",{});var h9e=s(q1);jfe=n(h9e,"STRONG",{});var oct=s(jfe);o$o=r(oct,"pegasus"),oct.forEach(t),r$o=r(h9e," \u2014 "),fG=n(h9e,"A",{href:!0});var rct=s(fG);t$o=r(rct,"PegasusForConditionalGeneration"),rct.forEach(t),a$o=r(h9e," (Pegasus model)"),h9e.forEach(t),n$o=i(ve),j1=n(ve,"LI",{});var p9e=s(j1);Dfe=n(p9e,"STRONG",{});var tct=s(Dfe);s$o=r(tct,"plbart"),tct.forEach(t),l$o=r(p9e," \u2014 "),mG=n(p9e,"A",{href:!0});var act=s(mG);i$o=r(act,"PLBartForConditionalGeneration"),act.forEach(t),d$o=r(p9e," (PLBart model)"),p9e.forEach(t),c$o=i(ve),D1=n(ve,"LI",{});var _9e=s(D1);Gfe=n(_9e,"STRONG",{});var nct=s(Gfe);f$o=r(nct,"prophetnet"),nct.forEach(t),m$o=r(_9e," \u2014 "),gG=n(_9e,"A",{href:!0});var sct=s(gG);g$o=r(sct,"ProphetNetForConditionalGeneration"),sct.forEach(t),h$o=r(_9e," (ProphetNet model)"),_9e.forEach(t),p$o=i(ve),G1=n(ve,"LI",{});var u9e=s(G1);Ofe=n(u9e,"STRONG",{});var lct=s(Ofe);_$o=r(lct,"t5"),lct.forEach(t),u$o=r(u9e," \u2014 "),hG=n(u9e,"A",{href:!0});var ict=s(hG);b$o=r(ict,"T5ForConditionalGeneration"),ict.forEach(t),v$o=r(u9e," (T5 model)"),u9e.forEach(t),F$o=i(ve),O1=n(ve,"LI",{});var b9e=s(O1);Vfe=n(b9e,"STRONG",{});var dct=s(Vfe);T$o=r(dct,"xlm-prophetnet"),dct.forEach(t),M$o=r(b9e," \u2014 "),pG=n(b9e,"A",{href:!0});var cct=s(pG);E$o=r(cct,"XLMProphetNetForConditionalGeneration"),cct.forEach(t),C$o=r(b9e," (XLMProphetNet model)"),b9e.forEach(t),ve.forEach(t),w$o=i(na),V1=n(na,"P",{});var v9e=s(V1);A$o=r(v9e,"The model is set in evaluation mode by default using "),Xfe=n(v9e,"CODE",{});var fct=s(Xfe);y$o=r(fct,"model.eval()"),fct.forEach(t),L$o=r(v9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zfe=n(v9e,"CODE",{});var mct=s(zfe);x$o=r(mct,"model.train()"),mct.forEach(t),v9e.forEach(t),$$o=i(na),T(X1.$$.fragment,na),na.forEach(t),Ws.forEach(t),qqe=i(f),Gi=n(f,"H2",{class:!0});var ODe=s(Gi);z1=n(ODe,"A",{id:!0,class:!0,href:!0});var gct=s(z1);Wfe=n(gct,"SPAN",{});var hct=s(Wfe);T(Ly.$$.fragment,hct),hct.forEach(t),gct.forEach(t),k$o=i(ODe),Qfe=n(ODe,"SPAN",{});var pct=s(Qfe);S$o=r(pct,"AutoModelForSequenceClassification"),pct.forEach(t),ODe.forEach(t),jqe=i(f),Ro=n(f,"DIV",{class:!0});var Qs=s(Ro);T(xy.$$.fragment,Qs),R$o=i(Qs),Oi=n(Qs,"P",{});var BZ=s(Oi);P$o=r(BZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_G=n(BZ,"A",{href:!0});var _ct=s(_G);B$o=r(_ct,"from_pretrained()"),_ct.forEach(t),I$o=r(BZ," class method or the "),uG=n(BZ,"A",{href:!0});var uct=s(uG);N$o=r(uct,"from_config()"),uct.forEach(t),q$o=r(BZ,` class
method.`),BZ.forEach(t),j$o=i(Qs),$y=n(Qs,"P",{});var VDe=s($y);D$o=r(VDe,"This class cannot be instantiated directly using "),Hfe=n(VDe,"CODE",{});var bct=s(Hfe);G$o=r(bct,"__init__()"),bct.forEach(t),O$o=r(VDe," (throws an error)."),VDe.forEach(t),V$o=i(Qs),it=n(Qs,"DIV",{class:!0});var z0=s(it);T(ky.$$.fragment,z0),X$o=i(z0),Ufe=n(z0,"P",{});var vct=s(Ufe);z$o=r(vct,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),vct.forEach(t),W$o=i(z0),Vi=n(z0,"P",{});var IZ=s(Vi);Q$o=r(IZ,`Note:
Loading a model from its configuration file does `),Jfe=n(IZ,"STRONG",{});var Fct=s(Jfe);H$o=r(Fct,"not"),Fct.forEach(t),U$o=r(IZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),bG=n(IZ,"A",{href:!0});var Tct=s(bG);J$o=r(Tct,"from_pretrained()"),Tct.forEach(t),Y$o=r(IZ," to load the model weights."),IZ.forEach(t),K$o=i(z0),T(W1.$$.fragment,z0),z0.forEach(t),Z$o=i(Qs),oo=n(Qs,"DIV",{class:!0});var sa=s(oo);T(Sy.$$.fragment,sa),eko=i(sa),Yfe=n(sa,"P",{});var Mct=s(Yfe);oko=r(Mct,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Mct.forEach(t),rko=i(sa),Ra=n(sa,"P",{});var W0=s(Ra);tko=r(W0,"The model class to instantiate is selected based on the "),Kfe=n(W0,"CODE",{});var Ect=s(Kfe);ako=r(Ect,"model_type"),Ect.forEach(t),nko=r(W0,` property of the config object (either
passed as an argument or loaded from `),Zfe=n(W0,"CODE",{});var Cct=s(Zfe);sko=r(Cct,"pretrained_model_name_or_path"),Cct.forEach(t),lko=r(W0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eme=n(W0,"CODE",{});var wct=s(eme);iko=r(wct,"pretrained_model_name_or_path"),wct.forEach(t),dko=r(W0,":"),W0.forEach(t),cko=i(sa),N=n(sa,"UL",{});var j=s(N);Q1=n(j,"LI",{});var F9e=s(Q1);ome=n(F9e,"STRONG",{});var Act=s(ome);fko=r(Act,"albert"),Act.forEach(t),mko=r(F9e," \u2014 "),vG=n(F9e,"A",{href:!0});var yct=s(vG);gko=r(yct,"AlbertForSequenceClassification"),yct.forEach(t),hko=r(F9e," (ALBERT model)"),F9e.forEach(t),pko=i(j),H1=n(j,"LI",{});var T9e=s(H1);rme=n(T9e,"STRONG",{});var Lct=s(rme);_ko=r(Lct,"bart"),Lct.forEach(t),uko=r(T9e," \u2014 "),FG=n(T9e,"A",{href:!0});var xct=s(FG);bko=r(xct,"BartForSequenceClassification"),xct.forEach(t),vko=r(T9e," (BART model)"),T9e.forEach(t),Fko=i(j),U1=n(j,"LI",{});var M9e=s(U1);tme=n(M9e,"STRONG",{});var $ct=s(tme);Tko=r($ct,"bert"),$ct.forEach(t),Mko=r(M9e," \u2014 "),TG=n(M9e,"A",{href:!0});var kct=s(TG);Eko=r(kct,"BertForSequenceClassification"),kct.forEach(t),Cko=r(M9e," (BERT model)"),M9e.forEach(t),wko=i(j),J1=n(j,"LI",{});var E9e=s(J1);ame=n(E9e,"STRONG",{});var Sct=s(ame);Ako=r(Sct,"big_bird"),Sct.forEach(t),yko=r(E9e," \u2014 "),MG=n(E9e,"A",{href:!0});var Rct=s(MG);Lko=r(Rct,"BigBirdForSequenceClassification"),Rct.forEach(t),xko=r(E9e," (BigBird model)"),E9e.forEach(t),$ko=i(j),Y1=n(j,"LI",{});var C9e=s(Y1);nme=n(C9e,"STRONG",{});var Pct=s(nme);kko=r(Pct,"bigbird_pegasus"),Pct.forEach(t),Sko=r(C9e," \u2014 "),EG=n(C9e,"A",{href:!0});var Bct=s(EG);Rko=r(Bct,"BigBirdPegasusForSequenceClassification"),Bct.forEach(t),Pko=r(C9e," (BigBirdPegasus model)"),C9e.forEach(t),Bko=i(j),K1=n(j,"LI",{});var w9e=s(K1);sme=n(w9e,"STRONG",{});var Ict=s(sme);Iko=r(Ict,"camembert"),Ict.forEach(t),Nko=r(w9e," \u2014 "),CG=n(w9e,"A",{href:!0});var Nct=s(CG);qko=r(Nct,"CamembertForSequenceClassification"),Nct.forEach(t),jko=r(w9e," (CamemBERT model)"),w9e.forEach(t),Dko=i(j),Z1=n(j,"LI",{});var A9e=s(Z1);lme=n(A9e,"STRONG",{});var qct=s(lme);Gko=r(qct,"canine"),qct.forEach(t),Oko=r(A9e," \u2014 "),wG=n(A9e,"A",{href:!0});var jct=s(wG);Vko=r(jct,"CanineForSequenceClassification"),jct.forEach(t),Xko=r(A9e," (Canine model)"),A9e.forEach(t),zko=i(j),eb=n(j,"LI",{});var y9e=s(eb);ime=n(y9e,"STRONG",{});var Dct=s(ime);Wko=r(Dct,"convbert"),Dct.forEach(t),Qko=r(y9e," \u2014 "),AG=n(y9e,"A",{href:!0});var Gct=s(AG);Hko=r(Gct,"ConvBertForSequenceClassification"),Gct.forEach(t),Uko=r(y9e," (ConvBERT model)"),y9e.forEach(t),Jko=i(j),ob=n(j,"LI",{});var L9e=s(ob);dme=n(L9e,"STRONG",{});var Oct=s(dme);Yko=r(Oct,"ctrl"),Oct.forEach(t),Kko=r(L9e," \u2014 "),yG=n(L9e,"A",{href:!0});var Vct=s(yG);Zko=r(Vct,"CTRLForSequenceClassification"),Vct.forEach(t),eSo=r(L9e," (CTRL model)"),L9e.forEach(t),oSo=i(j),rb=n(j,"LI",{});var x9e=s(rb);cme=n(x9e,"STRONG",{});var Xct=s(cme);rSo=r(Xct,"data2vec-text"),Xct.forEach(t),tSo=r(x9e," \u2014 "),LG=n(x9e,"A",{href:!0});var zct=s(LG);aSo=r(zct,"Data2VecTextForSequenceClassification"),zct.forEach(t),nSo=r(x9e," (Data2VecText model)"),x9e.forEach(t),sSo=i(j),tb=n(j,"LI",{});var $9e=s(tb);fme=n($9e,"STRONG",{});var Wct=s(fme);lSo=r(Wct,"deberta"),Wct.forEach(t),iSo=r($9e," \u2014 "),xG=n($9e,"A",{href:!0});var Qct=s(xG);dSo=r(Qct,"DebertaForSequenceClassification"),Qct.forEach(t),cSo=r($9e," (DeBERTa model)"),$9e.forEach(t),fSo=i(j),ab=n(j,"LI",{});var k9e=s(ab);mme=n(k9e,"STRONG",{});var Hct=s(mme);mSo=r(Hct,"deberta-v2"),Hct.forEach(t),gSo=r(k9e," \u2014 "),$G=n(k9e,"A",{href:!0});var Uct=s($G);hSo=r(Uct,"DebertaV2ForSequenceClassification"),Uct.forEach(t),pSo=r(k9e," (DeBERTa-v2 model)"),k9e.forEach(t),_So=i(j),nb=n(j,"LI",{});var S9e=s(nb);gme=n(S9e,"STRONG",{});var Jct=s(gme);uSo=r(Jct,"distilbert"),Jct.forEach(t),bSo=r(S9e," \u2014 "),kG=n(S9e,"A",{href:!0});var Yct=s(kG);vSo=r(Yct,"DistilBertForSequenceClassification"),Yct.forEach(t),FSo=r(S9e," (DistilBERT model)"),S9e.forEach(t),TSo=i(j),sb=n(j,"LI",{});var R9e=s(sb);hme=n(R9e,"STRONG",{});var Kct=s(hme);MSo=r(Kct,"electra"),Kct.forEach(t),ESo=r(R9e," \u2014 "),SG=n(R9e,"A",{href:!0});var Zct=s(SG);CSo=r(Zct,"ElectraForSequenceClassification"),Zct.forEach(t),wSo=r(R9e," (ELECTRA model)"),R9e.forEach(t),ASo=i(j),lb=n(j,"LI",{});var P9e=s(lb);pme=n(P9e,"STRONG",{});var eft=s(pme);ySo=r(eft,"flaubert"),eft.forEach(t),LSo=r(P9e," \u2014 "),RG=n(P9e,"A",{href:!0});var oft=s(RG);xSo=r(oft,"FlaubertForSequenceClassification"),oft.forEach(t),$So=r(P9e," (FlauBERT model)"),P9e.forEach(t),kSo=i(j),ib=n(j,"LI",{});var B9e=s(ib);_me=n(B9e,"STRONG",{});var rft=s(_me);SSo=r(rft,"fnet"),rft.forEach(t),RSo=r(B9e," \u2014 "),PG=n(B9e,"A",{href:!0});var tft=s(PG);PSo=r(tft,"FNetForSequenceClassification"),tft.forEach(t),BSo=r(B9e," (FNet model)"),B9e.forEach(t),ISo=i(j),db=n(j,"LI",{});var I9e=s(db);ume=n(I9e,"STRONG",{});var aft=s(ume);NSo=r(aft,"funnel"),aft.forEach(t),qSo=r(I9e," \u2014 "),BG=n(I9e,"A",{href:!0});var nft=s(BG);jSo=r(nft,"FunnelForSequenceClassification"),nft.forEach(t),DSo=r(I9e," (Funnel Transformer model)"),I9e.forEach(t),GSo=i(j),cb=n(j,"LI",{});var N9e=s(cb);bme=n(N9e,"STRONG",{});var sft=s(bme);OSo=r(sft,"gpt2"),sft.forEach(t),VSo=r(N9e," \u2014 "),IG=n(N9e,"A",{href:!0});var lft=s(IG);XSo=r(lft,"GPT2ForSequenceClassification"),lft.forEach(t),zSo=r(N9e," (OpenAI GPT-2 model)"),N9e.forEach(t),WSo=i(j),fb=n(j,"LI",{});var q9e=s(fb);vme=n(q9e,"STRONG",{});var ift=s(vme);QSo=r(ift,"gpt_neo"),ift.forEach(t),HSo=r(q9e," \u2014 "),NG=n(q9e,"A",{href:!0});var dft=s(NG);USo=r(dft,"GPTNeoForSequenceClassification"),dft.forEach(t),JSo=r(q9e," (GPT Neo model)"),q9e.forEach(t),YSo=i(j),mb=n(j,"LI",{});var j9e=s(mb);Fme=n(j9e,"STRONG",{});var cft=s(Fme);KSo=r(cft,"gptj"),cft.forEach(t),ZSo=r(j9e," \u2014 "),qG=n(j9e,"A",{href:!0});var fft=s(qG);eRo=r(fft,"GPTJForSequenceClassification"),fft.forEach(t),oRo=r(j9e," (GPT-J model)"),j9e.forEach(t),rRo=i(j),gb=n(j,"LI",{});var D9e=s(gb);Tme=n(D9e,"STRONG",{});var mft=s(Tme);tRo=r(mft,"ibert"),mft.forEach(t),aRo=r(D9e," \u2014 "),jG=n(D9e,"A",{href:!0});var gft=s(jG);nRo=r(gft,"IBertForSequenceClassification"),gft.forEach(t),sRo=r(D9e," (I-BERT model)"),D9e.forEach(t),lRo=i(j),hb=n(j,"LI",{});var G9e=s(hb);Mme=n(G9e,"STRONG",{});var hft=s(Mme);iRo=r(hft,"layoutlm"),hft.forEach(t),dRo=r(G9e," \u2014 "),DG=n(G9e,"A",{href:!0});var pft=s(DG);cRo=r(pft,"LayoutLMForSequenceClassification"),pft.forEach(t),fRo=r(G9e," (LayoutLM model)"),G9e.forEach(t),mRo=i(j),pb=n(j,"LI",{});var O9e=s(pb);Eme=n(O9e,"STRONG",{});var _ft=s(Eme);gRo=r(_ft,"layoutlmv2"),_ft.forEach(t),hRo=r(O9e," \u2014 "),GG=n(O9e,"A",{href:!0});var uft=s(GG);pRo=r(uft,"LayoutLMv2ForSequenceClassification"),uft.forEach(t),_Ro=r(O9e," (LayoutLMv2 model)"),O9e.forEach(t),uRo=i(j),_b=n(j,"LI",{});var V9e=s(_b);Cme=n(V9e,"STRONG",{});var bft=s(Cme);bRo=r(bft,"layoutlmv3"),bft.forEach(t),vRo=r(V9e," \u2014 "),OG=n(V9e,"A",{href:!0});var vft=s(OG);FRo=r(vft,"LayoutLMv3ForSequenceClassification"),vft.forEach(t),TRo=r(V9e," (LayoutLMv3 model)"),V9e.forEach(t),MRo=i(j),ub=n(j,"LI",{});var X9e=s(ub);wme=n(X9e,"STRONG",{});var Fft=s(wme);ERo=r(Fft,"led"),Fft.forEach(t),CRo=r(X9e," \u2014 "),VG=n(X9e,"A",{href:!0});var Tft=s(VG);wRo=r(Tft,"LEDForSequenceClassification"),Tft.forEach(t),ARo=r(X9e," (LED model)"),X9e.forEach(t),yRo=i(j),bb=n(j,"LI",{});var z9e=s(bb);Ame=n(z9e,"STRONG",{});var Mft=s(Ame);LRo=r(Mft,"longformer"),Mft.forEach(t),xRo=r(z9e," \u2014 "),XG=n(z9e,"A",{href:!0});var Eft=s(XG);$Ro=r(Eft,"LongformerForSequenceClassification"),Eft.forEach(t),kRo=r(z9e," (Longformer model)"),z9e.forEach(t),SRo=i(j),vb=n(j,"LI",{});var W9e=s(vb);yme=n(W9e,"STRONG",{});var Cft=s(yme);RRo=r(Cft,"mbart"),Cft.forEach(t),PRo=r(W9e," \u2014 "),zG=n(W9e,"A",{href:!0});var wft=s(zG);BRo=r(wft,"MBartForSequenceClassification"),wft.forEach(t),IRo=r(W9e," (mBART model)"),W9e.forEach(t),NRo=i(j),Fb=n(j,"LI",{});var Q9e=s(Fb);Lme=n(Q9e,"STRONG",{});var Aft=s(Lme);qRo=r(Aft,"megatron-bert"),Aft.forEach(t),jRo=r(Q9e," \u2014 "),WG=n(Q9e,"A",{href:!0});var yft=s(WG);DRo=r(yft,"MegatronBertForSequenceClassification"),yft.forEach(t),GRo=r(Q9e," (MegatronBert model)"),Q9e.forEach(t),ORo=i(j),Tb=n(j,"LI",{});var H9e=s(Tb);xme=n(H9e,"STRONG",{});var Lft=s(xme);VRo=r(Lft,"mobilebert"),Lft.forEach(t),XRo=r(H9e," \u2014 "),QG=n(H9e,"A",{href:!0});var xft=s(QG);zRo=r(xft,"MobileBertForSequenceClassification"),xft.forEach(t),WRo=r(H9e," (MobileBERT model)"),H9e.forEach(t),QRo=i(j),Mb=n(j,"LI",{});var U9e=s(Mb);$me=n(U9e,"STRONG",{});var $ft=s($me);HRo=r($ft,"mpnet"),$ft.forEach(t),URo=r(U9e," \u2014 "),HG=n(U9e,"A",{href:!0});var kft=s(HG);JRo=r(kft,"MPNetForSequenceClassification"),kft.forEach(t),YRo=r(U9e," (MPNet model)"),U9e.forEach(t),KRo=i(j),Eb=n(j,"LI",{});var J9e=s(Eb);kme=n(J9e,"STRONG",{});var Sft=s(kme);ZRo=r(Sft,"nystromformer"),Sft.forEach(t),ePo=r(J9e," \u2014 "),UG=n(J9e,"A",{href:!0});var Rft=s(UG);oPo=r(Rft,"NystromformerForSequenceClassification"),Rft.forEach(t),rPo=r(J9e," (Nystromformer model)"),J9e.forEach(t),tPo=i(j),Cb=n(j,"LI",{});var Y9e=s(Cb);Sme=n(Y9e,"STRONG",{});var Pft=s(Sme);aPo=r(Pft,"openai-gpt"),Pft.forEach(t),nPo=r(Y9e," \u2014 "),JG=n(Y9e,"A",{href:!0});var Bft=s(JG);sPo=r(Bft,"OpenAIGPTForSequenceClassification"),Bft.forEach(t),lPo=r(Y9e," (OpenAI GPT model)"),Y9e.forEach(t),iPo=i(j),wb=n(j,"LI",{});var K9e=s(wb);Rme=n(K9e,"STRONG",{});var Ift=s(Rme);dPo=r(Ift,"perceiver"),Ift.forEach(t),cPo=r(K9e," \u2014 "),YG=n(K9e,"A",{href:!0});var Nft=s(YG);fPo=r(Nft,"PerceiverForSequenceClassification"),Nft.forEach(t),mPo=r(K9e," (Perceiver model)"),K9e.forEach(t),gPo=i(j),Ab=n(j,"LI",{});var Z9e=s(Ab);Pme=n(Z9e,"STRONG",{});var qft=s(Pme);hPo=r(qft,"plbart"),qft.forEach(t),pPo=r(Z9e," \u2014 "),KG=n(Z9e,"A",{href:!0});var jft=s(KG);_Po=r(jft,"PLBartForSequenceClassification"),jft.forEach(t),uPo=r(Z9e," (PLBart model)"),Z9e.forEach(t),bPo=i(j),yb=n(j,"LI",{});var exe=s(yb);Bme=n(exe,"STRONG",{});var Dft=s(Bme);vPo=r(Dft,"qdqbert"),Dft.forEach(t),FPo=r(exe," \u2014 "),ZG=n(exe,"A",{href:!0});var Gft=s(ZG);TPo=r(Gft,"QDQBertForSequenceClassification"),Gft.forEach(t),MPo=r(exe," (QDQBert model)"),exe.forEach(t),EPo=i(j),Lb=n(j,"LI",{});var oxe=s(Lb);Ime=n(oxe,"STRONG",{});var Oft=s(Ime);CPo=r(Oft,"reformer"),Oft.forEach(t),wPo=r(oxe," \u2014 "),eO=n(oxe,"A",{href:!0});var Vft=s(eO);APo=r(Vft,"ReformerForSequenceClassification"),Vft.forEach(t),yPo=r(oxe," (Reformer model)"),oxe.forEach(t),LPo=i(j),xb=n(j,"LI",{});var rxe=s(xb);Nme=n(rxe,"STRONG",{});var Xft=s(Nme);xPo=r(Xft,"rembert"),Xft.forEach(t),$Po=r(rxe," \u2014 "),oO=n(rxe,"A",{href:!0});var zft=s(oO);kPo=r(zft,"RemBertForSequenceClassification"),zft.forEach(t),SPo=r(rxe," (RemBERT model)"),rxe.forEach(t),RPo=i(j),$b=n(j,"LI",{});var txe=s($b);qme=n(txe,"STRONG",{});var Wft=s(qme);PPo=r(Wft,"roberta"),Wft.forEach(t),BPo=r(txe," \u2014 "),rO=n(txe,"A",{href:!0});var Qft=s(rO);IPo=r(Qft,"RobertaForSequenceClassification"),Qft.forEach(t),NPo=r(txe," (RoBERTa model)"),txe.forEach(t),qPo=i(j),kb=n(j,"LI",{});var axe=s(kb);jme=n(axe,"STRONG",{});var Hft=s(jme);jPo=r(Hft,"roformer"),Hft.forEach(t),DPo=r(axe," \u2014 "),tO=n(axe,"A",{href:!0});var Uft=s(tO);GPo=r(Uft,"RoFormerForSequenceClassification"),Uft.forEach(t),OPo=r(axe," (RoFormer model)"),axe.forEach(t),VPo=i(j),Sb=n(j,"LI",{});var nxe=s(Sb);Dme=n(nxe,"STRONG",{});var Jft=s(Dme);XPo=r(Jft,"squeezebert"),Jft.forEach(t),zPo=r(nxe," \u2014 "),aO=n(nxe,"A",{href:!0});var Yft=s(aO);WPo=r(Yft,"SqueezeBertForSequenceClassification"),Yft.forEach(t),QPo=r(nxe," (SqueezeBERT model)"),nxe.forEach(t),HPo=i(j),Rb=n(j,"LI",{});var sxe=s(Rb);Gme=n(sxe,"STRONG",{});var Kft=s(Gme);UPo=r(Kft,"tapas"),Kft.forEach(t),JPo=r(sxe," \u2014 "),nO=n(sxe,"A",{href:!0});var Zft=s(nO);YPo=r(Zft,"TapasForSequenceClassification"),Zft.forEach(t),KPo=r(sxe," (TAPAS model)"),sxe.forEach(t),ZPo=i(j),Pb=n(j,"LI",{});var lxe=s(Pb);Ome=n(lxe,"STRONG",{});var emt=s(Ome);eBo=r(emt,"transfo-xl"),emt.forEach(t),oBo=r(lxe," \u2014 "),sO=n(lxe,"A",{href:!0});var omt=s(sO);rBo=r(omt,"TransfoXLForSequenceClassification"),omt.forEach(t),tBo=r(lxe," (Transformer-XL model)"),lxe.forEach(t),aBo=i(j),Bb=n(j,"LI",{});var ixe=s(Bb);Vme=n(ixe,"STRONG",{});var rmt=s(Vme);nBo=r(rmt,"xlm"),rmt.forEach(t),sBo=r(ixe," \u2014 "),lO=n(ixe,"A",{href:!0});var tmt=s(lO);lBo=r(tmt,"XLMForSequenceClassification"),tmt.forEach(t),iBo=r(ixe," (XLM model)"),ixe.forEach(t),dBo=i(j),Ib=n(j,"LI",{});var dxe=s(Ib);Xme=n(dxe,"STRONG",{});var amt=s(Xme);cBo=r(amt,"xlm-roberta"),amt.forEach(t),fBo=r(dxe," \u2014 "),iO=n(dxe,"A",{href:!0});var nmt=s(iO);mBo=r(nmt,"XLMRobertaForSequenceClassification"),nmt.forEach(t),gBo=r(dxe," (XLM-RoBERTa model)"),dxe.forEach(t),hBo=i(j),Nb=n(j,"LI",{});var cxe=s(Nb);zme=n(cxe,"STRONG",{});var smt=s(zme);pBo=r(smt,"xlm-roberta-xl"),smt.forEach(t),_Bo=r(cxe," \u2014 "),dO=n(cxe,"A",{href:!0});var lmt=s(dO);uBo=r(lmt,"XLMRobertaXLForSequenceClassification"),lmt.forEach(t),bBo=r(cxe," (XLM-RoBERTa-XL model)"),cxe.forEach(t),vBo=i(j),qb=n(j,"LI",{});var fxe=s(qb);Wme=n(fxe,"STRONG",{});var imt=s(Wme);FBo=r(imt,"xlnet"),imt.forEach(t),TBo=r(fxe," \u2014 "),cO=n(fxe,"A",{href:!0});var dmt=s(cO);MBo=r(dmt,"XLNetForSequenceClassification"),dmt.forEach(t),EBo=r(fxe," (XLNet model)"),fxe.forEach(t),CBo=i(j),jb=n(j,"LI",{});var mxe=s(jb);Qme=n(mxe,"STRONG",{});var cmt=s(Qme);wBo=r(cmt,"yoso"),cmt.forEach(t),ABo=r(mxe," \u2014 "),fO=n(mxe,"A",{href:!0});var fmt=s(fO);yBo=r(fmt,"YosoForSequenceClassification"),fmt.forEach(t),LBo=r(mxe," (YOSO model)"),mxe.forEach(t),j.forEach(t),xBo=i(sa),Db=n(sa,"P",{});var gxe=s(Db);$Bo=r(gxe,"The model is set in evaluation mode by default using "),Hme=n(gxe,"CODE",{});var mmt=s(Hme);kBo=r(mmt,"model.eval()"),mmt.forEach(t),SBo=r(gxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ume=n(gxe,"CODE",{});var gmt=s(Ume);RBo=r(gmt,"model.train()"),gmt.forEach(t),gxe.forEach(t),PBo=i(sa),T(Gb.$$.fragment,sa),sa.forEach(t),Qs.forEach(t),Dqe=i(f),Xi=n(f,"H2",{class:!0});var XDe=s(Xi);Ob=n(XDe,"A",{id:!0,class:!0,href:!0});var hmt=s(Ob);Jme=n(hmt,"SPAN",{});var pmt=s(Jme);T(Ry.$$.fragment,pmt),pmt.forEach(t),hmt.forEach(t),BBo=i(XDe),Yme=n(XDe,"SPAN",{});var _mt=s(Yme);IBo=r(_mt,"AutoModelForMultipleChoice"),_mt.forEach(t),XDe.forEach(t),Gqe=i(f),Po=n(f,"DIV",{class:!0});var Hs=s(Po);T(Py.$$.fragment,Hs),NBo=i(Hs),zi=n(Hs,"P",{});var NZ=s(zi);qBo=r(NZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),mO=n(NZ,"A",{href:!0});var umt=s(mO);jBo=r(umt,"from_pretrained()"),umt.forEach(t),DBo=r(NZ," class method or the "),gO=n(NZ,"A",{href:!0});var bmt=s(gO);GBo=r(bmt,"from_config()"),bmt.forEach(t),OBo=r(NZ,` class
method.`),NZ.forEach(t),VBo=i(Hs),By=n(Hs,"P",{});var zDe=s(By);XBo=r(zDe,"This class cannot be instantiated directly using "),Kme=n(zDe,"CODE",{});var vmt=s(Kme);zBo=r(vmt,"__init__()"),vmt.forEach(t),WBo=r(zDe," (throws an error)."),zDe.forEach(t),QBo=i(Hs),dt=n(Hs,"DIV",{class:!0});var Q0=s(dt);T(Iy.$$.fragment,Q0),HBo=i(Q0),Zme=n(Q0,"P",{});var Fmt=s(Zme);UBo=r(Fmt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Fmt.forEach(t),JBo=i(Q0),Wi=n(Q0,"P",{});var qZ=s(Wi);YBo=r(qZ,`Note:
Loading a model from its configuration file does `),ege=n(qZ,"STRONG",{});var Tmt=s(ege);KBo=r(Tmt,"not"),Tmt.forEach(t),ZBo=r(qZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=n(qZ,"A",{href:!0});var Mmt=s(hO);eIo=r(Mmt,"from_pretrained()"),Mmt.forEach(t),oIo=r(qZ," to load the model weights."),qZ.forEach(t),rIo=i(Q0),T(Vb.$$.fragment,Q0),Q0.forEach(t),tIo=i(Hs),ro=n(Hs,"DIV",{class:!0});var la=s(ro);T(Ny.$$.fragment,la),aIo=i(la),oge=n(la,"P",{});var Emt=s(oge);nIo=r(Emt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Emt.forEach(t),sIo=i(la),Pa=n(la,"P",{});var H0=s(Pa);lIo=r(H0,"The model class to instantiate is selected based on the "),rge=n(H0,"CODE",{});var Cmt=s(rge);iIo=r(Cmt,"model_type"),Cmt.forEach(t),dIo=r(H0,` property of the config object (either
passed as an argument or loaded from `),tge=n(H0,"CODE",{});var wmt=s(tge);cIo=r(wmt,"pretrained_model_name_or_path"),wmt.forEach(t),fIo=r(H0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),age=n(H0,"CODE",{});var Amt=s(age);mIo=r(Amt,"pretrained_model_name_or_path"),Amt.forEach(t),gIo=r(H0,":"),H0.forEach(t),hIo=i(la),K=n(la,"UL",{});var ee=s(K);Xb=n(ee,"LI",{});var hxe=s(Xb);nge=n(hxe,"STRONG",{});var ymt=s(nge);pIo=r(ymt,"albert"),ymt.forEach(t),_Io=r(hxe," \u2014 "),pO=n(hxe,"A",{href:!0});var Lmt=s(pO);uIo=r(Lmt,"AlbertForMultipleChoice"),Lmt.forEach(t),bIo=r(hxe," (ALBERT model)"),hxe.forEach(t),vIo=i(ee),zb=n(ee,"LI",{});var pxe=s(zb);sge=n(pxe,"STRONG",{});var xmt=s(sge);FIo=r(xmt,"bert"),xmt.forEach(t),TIo=r(pxe," \u2014 "),_O=n(pxe,"A",{href:!0});var $mt=s(_O);MIo=r($mt,"BertForMultipleChoice"),$mt.forEach(t),EIo=r(pxe," (BERT model)"),pxe.forEach(t),CIo=i(ee),Wb=n(ee,"LI",{});var _xe=s(Wb);lge=n(_xe,"STRONG",{});var kmt=s(lge);wIo=r(kmt,"big_bird"),kmt.forEach(t),AIo=r(_xe," \u2014 "),uO=n(_xe,"A",{href:!0});var Smt=s(uO);yIo=r(Smt,"BigBirdForMultipleChoice"),Smt.forEach(t),LIo=r(_xe," (BigBird model)"),_xe.forEach(t),xIo=i(ee),Qb=n(ee,"LI",{});var uxe=s(Qb);ige=n(uxe,"STRONG",{});var Rmt=s(ige);$Io=r(Rmt,"camembert"),Rmt.forEach(t),kIo=r(uxe," \u2014 "),bO=n(uxe,"A",{href:!0});var Pmt=s(bO);SIo=r(Pmt,"CamembertForMultipleChoice"),Pmt.forEach(t),RIo=r(uxe," (CamemBERT model)"),uxe.forEach(t),PIo=i(ee),Hb=n(ee,"LI",{});var bxe=s(Hb);dge=n(bxe,"STRONG",{});var Bmt=s(dge);BIo=r(Bmt,"canine"),Bmt.forEach(t),IIo=r(bxe," \u2014 "),vO=n(bxe,"A",{href:!0});var Imt=s(vO);NIo=r(Imt,"CanineForMultipleChoice"),Imt.forEach(t),qIo=r(bxe," (Canine model)"),bxe.forEach(t),jIo=i(ee),Ub=n(ee,"LI",{});var vxe=s(Ub);cge=n(vxe,"STRONG",{});var Nmt=s(cge);DIo=r(Nmt,"convbert"),Nmt.forEach(t),GIo=r(vxe," \u2014 "),FO=n(vxe,"A",{href:!0});var qmt=s(FO);OIo=r(qmt,"ConvBertForMultipleChoice"),qmt.forEach(t),VIo=r(vxe," (ConvBERT model)"),vxe.forEach(t),XIo=i(ee),Jb=n(ee,"LI",{});var Fxe=s(Jb);fge=n(Fxe,"STRONG",{});var jmt=s(fge);zIo=r(jmt,"data2vec-text"),jmt.forEach(t),WIo=r(Fxe," \u2014 "),TO=n(Fxe,"A",{href:!0});var Dmt=s(TO);QIo=r(Dmt,"Data2VecTextForMultipleChoice"),Dmt.forEach(t),HIo=r(Fxe," (Data2VecText model)"),Fxe.forEach(t),UIo=i(ee),Yb=n(ee,"LI",{});var Txe=s(Yb);mge=n(Txe,"STRONG",{});var Gmt=s(mge);JIo=r(Gmt,"deberta-v2"),Gmt.forEach(t),YIo=r(Txe," \u2014 "),MO=n(Txe,"A",{href:!0});var Omt=s(MO);KIo=r(Omt,"DebertaV2ForMultipleChoice"),Omt.forEach(t),ZIo=r(Txe," (DeBERTa-v2 model)"),Txe.forEach(t),eNo=i(ee),Kb=n(ee,"LI",{});var Mxe=s(Kb);gge=n(Mxe,"STRONG",{});var Vmt=s(gge);oNo=r(Vmt,"distilbert"),Vmt.forEach(t),rNo=r(Mxe," \u2014 "),EO=n(Mxe,"A",{href:!0});var Xmt=s(EO);tNo=r(Xmt,"DistilBertForMultipleChoice"),Xmt.forEach(t),aNo=r(Mxe," (DistilBERT model)"),Mxe.forEach(t),nNo=i(ee),Zb=n(ee,"LI",{});var Exe=s(Zb);hge=n(Exe,"STRONG",{});var zmt=s(hge);sNo=r(zmt,"electra"),zmt.forEach(t),lNo=r(Exe," \u2014 "),CO=n(Exe,"A",{href:!0});var Wmt=s(CO);iNo=r(Wmt,"ElectraForMultipleChoice"),Wmt.forEach(t),dNo=r(Exe," (ELECTRA model)"),Exe.forEach(t),cNo=i(ee),e2=n(ee,"LI",{});var Cxe=s(e2);pge=n(Cxe,"STRONG",{});var Qmt=s(pge);fNo=r(Qmt,"flaubert"),Qmt.forEach(t),mNo=r(Cxe," \u2014 "),wO=n(Cxe,"A",{href:!0});var Hmt=s(wO);gNo=r(Hmt,"FlaubertForMultipleChoice"),Hmt.forEach(t),hNo=r(Cxe," (FlauBERT model)"),Cxe.forEach(t),pNo=i(ee),o2=n(ee,"LI",{});var wxe=s(o2);_ge=n(wxe,"STRONG",{});var Umt=s(_ge);_No=r(Umt,"fnet"),Umt.forEach(t),uNo=r(wxe," \u2014 "),AO=n(wxe,"A",{href:!0});var Jmt=s(AO);bNo=r(Jmt,"FNetForMultipleChoice"),Jmt.forEach(t),vNo=r(wxe," (FNet model)"),wxe.forEach(t),FNo=i(ee),r2=n(ee,"LI",{});var Axe=s(r2);uge=n(Axe,"STRONG",{});var Ymt=s(uge);TNo=r(Ymt,"funnel"),Ymt.forEach(t),MNo=r(Axe," \u2014 "),yO=n(Axe,"A",{href:!0});var Kmt=s(yO);ENo=r(Kmt,"FunnelForMultipleChoice"),Kmt.forEach(t),CNo=r(Axe," (Funnel Transformer model)"),Axe.forEach(t),wNo=i(ee),t2=n(ee,"LI",{});var yxe=s(t2);bge=n(yxe,"STRONG",{});var Zmt=s(bge);ANo=r(Zmt,"ibert"),Zmt.forEach(t),yNo=r(yxe," \u2014 "),LO=n(yxe,"A",{href:!0});var egt=s(LO);LNo=r(egt,"IBertForMultipleChoice"),egt.forEach(t),xNo=r(yxe," (I-BERT model)"),yxe.forEach(t),$No=i(ee),a2=n(ee,"LI",{});var Lxe=s(a2);vge=n(Lxe,"STRONG",{});var ogt=s(vge);kNo=r(ogt,"longformer"),ogt.forEach(t),SNo=r(Lxe," \u2014 "),xO=n(Lxe,"A",{href:!0});var rgt=s(xO);RNo=r(rgt,"LongformerForMultipleChoice"),rgt.forEach(t),PNo=r(Lxe," (Longformer model)"),Lxe.forEach(t),BNo=i(ee),n2=n(ee,"LI",{});var xxe=s(n2);Fge=n(xxe,"STRONG",{});var tgt=s(Fge);INo=r(tgt,"megatron-bert"),tgt.forEach(t),NNo=r(xxe," \u2014 "),$O=n(xxe,"A",{href:!0});var agt=s($O);qNo=r(agt,"MegatronBertForMultipleChoice"),agt.forEach(t),jNo=r(xxe," (MegatronBert model)"),xxe.forEach(t),DNo=i(ee),s2=n(ee,"LI",{});var $xe=s(s2);Tge=n($xe,"STRONG",{});var ngt=s(Tge);GNo=r(ngt,"mobilebert"),ngt.forEach(t),ONo=r($xe," \u2014 "),kO=n($xe,"A",{href:!0});var sgt=s(kO);VNo=r(sgt,"MobileBertForMultipleChoice"),sgt.forEach(t),XNo=r($xe," (MobileBERT model)"),$xe.forEach(t),zNo=i(ee),l2=n(ee,"LI",{});var kxe=s(l2);Mge=n(kxe,"STRONG",{});var lgt=s(Mge);WNo=r(lgt,"mpnet"),lgt.forEach(t),QNo=r(kxe," \u2014 "),SO=n(kxe,"A",{href:!0});var igt=s(SO);HNo=r(igt,"MPNetForMultipleChoice"),igt.forEach(t),UNo=r(kxe," (MPNet model)"),kxe.forEach(t),JNo=i(ee),i2=n(ee,"LI",{});var Sxe=s(i2);Ege=n(Sxe,"STRONG",{});var dgt=s(Ege);YNo=r(dgt,"nystromformer"),dgt.forEach(t),KNo=r(Sxe," \u2014 "),RO=n(Sxe,"A",{href:!0});var cgt=s(RO);ZNo=r(cgt,"NystromformerForMultipleChoice"),cgt.forEach(t),eqo=r(Sxe," (Nystromformer model)"),Sxe.forEach(t),oqo=i(ee),d2=n(ee,"LI",{});var Rxe=s(d2);Cge=n(Rxe,"STRONG",{});var fgt=s(Cge);rqo=r(fgt,"qdqbert"),fgt.forEach(t),tqo=r(Rxe," \u2014 "),PO=n(Rxe,"A",{href:!0});var mgt=s(PO);aqo=r(mgt,"QDQBertForMultipleChoice"),mgt.forEach(t),nqo=r(Rxe," (QDQBert model)"),Rxe.forEach(t),sqo=i(ee),c2=n(ee,"LI",{});var Pxe=s(c2);wge=n(Pxe,"STRONG",{});var ggt=s(wge);lqo=r(ggt,"rembert"),ggt.forEach(t),iqo=r(Pxe," \u2014 "),BO=n(Pxe,"A",{href:!0});var hgt=s(BO);dqo=r(hgt,"RemBertForMultipleChoice"),hgt.forEach(t),cqo=r(Pxe," (RemBERT model)"),Pxe.forEach(t),fqo=i(ee),f2=n(ee,"LI",{});var Bxe=s(f2);Age=n(Bxe,"STRONG",{});var pgt=s(Age);mqo=r(pgt,"roberta"),pgt.forEach(t),gqo=r(Bxe," \u2014 "),IO=n(Bxe,"A",{href:!0});var _gt=s(IO);hqo=r(_gt,"RobertaForMultipleChoice"),_gt.forEach(t),pqo=r(Bxe," (RoBERTa model)"),Bxe.forEach(t),_qo=i(ee),m2=n(ee,"LI",{});var Ixe=s(m2);yge=n(Ixe,"STRONG",{});var ugt=s(yge);uqo=r(ugt,"roformer"),ugt.forEach(t),bqo=r(Ixe," \u2014 "),NO=n(Ixe,"A",{href:!0});var bgt=s(NO);vqo=r(bgt,"RoFormerForMultipleChoice"),bgt.forEach(t),Fqo=r(Ixe," (RoFormer model)"),Ixe.forEach(t),Tqo=i(ee),g2=n(ee,"LI",{});var Nxe=s(g2);Lge=n(Nxe,"STRONG",{});var vgt=s(Lge);Mqo=r(vgt,"squeezebert"),vgt.forEach(t),Eqo=r(Nxe," \u2014 "),qO=n(Nxe,"A",{href:!0});var Fgt=s(qO);Cqo=r(Fgt,"SqueezeBertForMultipleChoice"),Fgt.forEach(t),wqo=r(Nxe," (SqueezeBERT model)"),Nxe.forEach(t),Aqo=i(ee),h2=n(ee,"LI",{});var qxe=s(h2);xge=n(qxe,"STRONG",{});var Tgt=s(xge);yqo=r(Tgt,"xlm"),Tgt.forEach(t),Lqo=r(qxe," \u2014 "),jO=n(qxe,"A",{href:!0});var Mgt=s(jO);xqo=r(Mgt,"XLMForMultipleChoice"),Mgt.forEach(t),$qo=r(qxe," (XLM model)"),qxe.forEach(t),kqo=i(ee),p2=n(ee,"LI",{});var jxe=s(p2);$ge=n(jxe,"STRONG",{});var Egt=s($ge);Sqo=r(Egt,"xlm-roberta"),Egt.forEach(t),Rqo=r(jxe," \u2014 "),DO=n(jxe,"A",{href:!0});var Cgt=s(DO);Pqo=r(Cgt,"XLMRobertaForMultipleChoice"),Cgt.forEach(t),Bqo=r(jxe," (XLM-RoBERTa model)"),jxe.forEach(t),Iqo=i(ee),_2=n(ee,"LI",{});var Dxe=s(_2);kge=n(Dxe,"STRONG",{});var wgt=s(kge);Nqo=r(wgt,"xlm-roberta-xl"),wgt.forEach(t),qqo=r(Dxe," \u2014 "),GO=n(Dxe,"A",{href:!0});var Agt=s(GO);jqo=r(Agt,"XLMRobertaXLForMultipleChoice"),Agt.forEach(t),Dqo=r(Dxe," (XLM-RoBERTa-XL model)"),Dxe.forEach(t),Gqo=i(ee),u2=n(ee,"LI",{});var Gxe=s(u2);Sge=n(Gxe,"STRONG",{});var ygt=s(Sge);Oqo=r(ygt,"xlnet"),ygt.forEach(t),Vqo=r(Gxe," \u2014 "),OO=n(Gxe,"A",{href:!0});var Lgt=s(OO);Xqo=r(Lgt,"XLNetForMultipleChoice"),Lgt.forEach(t),zqo=r(Gxe," (XLNet model)"),Gxe.forEach(t),Wqo=i(ee),b2=n(ee,"LI",{});var Oxe=s(b2);Rge=n(Oxe,"STRONG",{});var xgt=s(Rge);Qqo=r(xgt,"yoso"),xgt.forEach(t),Hqo=r(Oxe," \u2014 "),VO=n(Oxe,"A",{href:!0});var $gt=s(VO);Uqo=r($gt,"YosoForMultipleChoice"),$gt.forEach(t),Jqo=r(Oxe," (YOSO model)"),Oxe.forEach(t),ee.forEach(t),Yqo=i(la),v2=n(la,"P",{});var Vxe=s(v2);Kqo=r(Vxe,"The model is set in evaluation mode by default using "),Pge=n(Vxe,"CODE",{});var kgt=s(Pge);Zqo=r(kgt,"model.eval()"),kgt.forEach(t),ejo=r(Vxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bge=n(Vxe,"CODE",{});var Sgt=s(Bge);ojo=r(Sgt,"model.train()"),Sgt.forEach(t),Vxe.forEach(t),rjo=i(la),T(F2.$$.fragment,la),la.forEach(t),Hs.forEach(t),Oqe=i(f),Qi=n(f,"H2",{class:!0});var WDe=s(Qi);T2=n(WDe,"A",{id:!0,class:!0,href:!0});var Rgt=s(T2);Ige=n(Rgt,"SPAN",{});var Pgt=s(Ige);T(qy.$$.fragment,Pgt),Pgt.forEach(t),Rgt.forEach(t),tjo=i(WDe),Nge=n(WDe,"SPAN",{});var Bgt=s(Nge);ajo=r(Bgt,"AutoModelForNextSentencePrediction"),Bgt.forEach(t),WDe.forEach(t),Vqe=i(f),Bo=n(f,"DIV",{class:!0});var Us=s(Bo);T(jy.$$.fragment,Us),njo=i(Us),Hi=n(Us,"P",{});var jZ=s(Hi);sjo=r(jZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),XO=n(jZ,"A",{href:!0});var Igt=s(XO);ljo=r(Igt,"from_pretrained()"),Igt.forEach(t),ijo=r(jZ," class method or the "),zO=n(jZ,"A",{href:!0});var Ngt=s(zO);djo=r(Ngt,"from_config()"),Ngt.forEach(t),cjo=r(jZ,` class
method.`),jZ.forEach(t),fjo=i(Us),Dy=n(Us,"P",{});var QDe=s(Dy);mjo=r(QDe,"This class cannot be instantiated directly using "),qge=n(QDe,"CODE",{});var qgt=s(qge);gjo=r(qgt,"__init__()"),qgt.forEach(t),hjo=r(QDe," (throws an error)."),QDe.forEach(t),pjo=i(Us),ct=n(Us,"DIV",{class:!0});var U0=s(ct);T(Gy.$$.fragment,U0),_jo=i(U0),jge=n(U0,"P",{});var jgt=s(jge);ujo=r(jgt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),jgt.forEach(t),bjo=i(U0),Ui=n(U0,"P",{});var DZ=s(Ui);vjo=r(DZ,`Note:
Loading a model from its configuration file does `),Dge=n(DZ,"STRONG",{});var Dgt=s(Dge);Fjo=r(Dgt,"not"),Dgt.forEach(t),Tjo=r(DZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),WO=n(DZ,"A",{href:!0});var Ggt=s(WO);Mjo=r(Ggt,"from_pretrained()"),Ggt.forEach(t),Ejo=r(DZ," to load the model weights."),DZ.forEach(t),Cjo=i(U0),T(M2.$$.fragment,U0),U0.forEach(t),wjo=i(Us),to=n(Us,"DIV",{class:!0});var ia=s(to);T(Oy.$$.fragment,ia),Ajo=i(ia),Gge=n(ia,"P",{});var Ogt=s(Gge);yjo=r(Ogt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Ogt.forEach(t),Ljo=i(ia),Ba=n(ia,"P",{});var J0=s(Ba);xjo=r(J0,"The model class to instantiate is selected based on the "),Oge=n(J0,"CODE",{});var Vgt=s(Oge);$jo=r(Vgt,"model_type"),Vgt.forEach(t),kjo=r(J0,` property of the config object (either
passed as an argument or loaded from `),Vge=n(J0,"CODE",{});var Xgt=s(Vge);Sjo=r(Xgt,"pretrained_model_name_or_path"),Xgt.forEach(t),Rjo=r(J0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xge=n(J0,"CODE",{});var zgt=s(Xge);Pjo=r(zgt,"pretrained_model_name_or_path"),zgt.forEach(t),Bjo=r(J0,":"),J0.forEach(t),Ijo=i(ia),Yr=n(ia,"UL",{});var Js=s(Yr);E2=n(Js,"LI",{});var Xxe=s(E2);zge=n(Xxe,"STRONG",{});var Wgt=s(zge);Njo=r(Wgt,"bert"),Wgt.forEach(t),qjo=r(Xxe," \u2014 "),QO=n(Xxe,"A",{href:!0});var Qgt=s(QO);jjo=r(Qgt,"BertForNextSentencePrediction"),Qgt.forEach(t),Djo=r(Xxe," (BERT model)"),Xxe.forEach(t),Gjo=i(Js),C2=n(Js,"LI",{});var zxe=s(C2);Wge=n(zxe,"STRONG",{});var Hgt=s(Wge);Ojo=r(Hgt,"fnet"),Hgt.forEach(t),Vjo=r(zxe," \u2014 "),HO=n(zxe,"A",{href:!0});var Ugt=s(HO);Xjo=r(Ugt,"FNetForNextSentencePrediction"),Ugt.forEach(t),zjo=r(zxe," (FNet model)"),zxe.forEach(t),Wjo=i(Js),w2=n(Js,"LI",{});var Wxe=s(w2);Qge=n(Wxe,"STRONG",{});var Jgt=s(Qge);Qjo=r(Jgt,"megatron-bert"),Jgt.forEach(t),Hjo=r(Wxe," \u2014 "),UO=n(Wxe,"A",{href:!0});var Ygt=s(UO);Ujo=r(Ygt,"MegatronBertForNextSentencePrediction"),Ygt.forEach(t),Jjo=r(Wxe," (MegatronBert model)"),Wxe.forEach(t),Yjo=i(Js),A2=n(Js,"LI",{});var Qxe=s(A2);Hge=n(Qxe,"STRONG",{});var Kgt=s(Hge);Kjo=r(Kgt,"mobilebert"),Kgt.forEach(t),Zjo=r(Qxe," \u2014 "),JO=n(Qxe,"A",{href:!0});var Zgt=s(JO);eDo=r(Zgt,"MobileBertForNextSentencePrediction"),Zgt.forEach(t),oDo=r(Qxe," (MobileBERT model)"),Qxe.forEach(t),rDo=i(Js),y2=n(Js,"LI",{});var Hxe=s(y2);Uge=n(Hxe,"STRONG",{});var eht=s(Uge);tDo=r(eht,"qdqbert"),eht.forEach(t),aDo=r(Hxe," \u2014 "),YO=n(Hxe,"A",{href:!0});var oht=s(YO);nDo=r(oht,"QDQBertForNextSentencePrediction"),oht.forEach(t),sDo=r(Hxe," (QDQBert model)"),Hxe.forEach(t),Js.forEach(t),lDo=i(ia),L2=n(ia,"P",{});var Uxe=s(L2);iDo=r(Uxe,"The model is set in evaluation mode by default using "),Jge=n(Uxe,"CODE",{});var rht=s(Jge);dDo=r(rht,"model.eval()"),rht.forEach(t),cDo=r(Uxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yge=n(Uxe,"CODE",{});var tht=s(Yge);fDo=r(tht,"model.train()"),tht.forEach(t),Uxe.forEach(t),mDo=i(ia),T(x2.$$.fragment,ia),ia.forEach(t),Us.forEach(t),Xqe=i(f),Ji=n(f,"H2",{class:!0});var HDe=s(Ji);$2=n(HDe,"A",{id:!0,class:!0,href:!0});var aht=s($2);Kge=n(aht,"SPAN",{});var nht=s(Kge);T(Vy.$$.fragment,nht),nht.forEach(t),aht.forEach(t),gDo=i(HDe),Zge=n(HDe,"SPAN",{});var sht=s(Zge);hDo=r(sht,"AutoModelForTokenClassification"),sht.forEach(t),HDe.forEach(t),zqe=i(f),Io=n(f,"DIV",{class:!0});var Ys=s(Io);T(Xy.$$.fragment,Ys),pDo=i(Ys),Yi=n(Ys,"P",{});var GZ=s(Yi);_Do=r(GZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),KO=n(GZ,"A",{href:!0});var lht=s(KO);uDo=r(lht,"from_pretrained()"),lht.forEach(t),bDo=r(GZ," class method or the "),ZO=n(GZ,"A",{href:!0});var iht=s(ZO);vDo=r(iht,"from_config()"),iht.forEach(t),FDo=r(GZ,` class
method.`),GZ.forEach(t),TDo=i(Ys),zy=n(Ys,"P",{});var UDe=s(zy);MDo=r(UDe,"This class cannot be instantiated directly using "),ehe=n(UDe,"CODE",{});var dht=s(ehe);EDo=r(dht,"__init__()"),dht.forEach(t),CDo=r(UDe," (throws an error)."),UDe.forEach(t),wDo=i(Ys),ft=n(Ys,"DIV",{class:!0});var Y0=s(ft);T(Wy.$$.fragment,Y0),ADo=i(Y0),ohe=n(Y0,"P",{});var cht=s(ohe);yDo=r(cht,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),cht.forEach(t),LDo=i(Y0),Ki=n(Y0,"P",{});var OZ=s(Ki);xDo=r(OZ,`Note:
Loading a model from its configuration file does `),rhe=n(OZ,"STRONG",{});var fht=s(rhe);$Do=r(fht,"not"),fht.forEach(t),kDo=r(OZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),eV=n(OZ,"A",{href:!0});var mht=s(eV);SDo=r(mht,"from_pretrained()"),mht.forEach(t),RDo=r(OZ," to load the model weights."),OZ.forEach(t),PDo=i(Y0),T(k2.$$.fragment,Y0),Y0.forEach(t),BDo=i(Ys),ao=n(Ys,"DIV",{class:!0});var da=s(ao);T(Qy.$$.fragment,da),IDo=i(da),the=n(da,"P",{});var ght=s(the);NDo=r(ght,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),ght.forEach(t),qDo=i(da),Ia=n(da,"P",{});var K0=s(Ia);jDo=r(K0,"The model class to instantiate is selected based on the "),ahe=n(K0,"CODE",{});var hht=s(ahe);DDo=r(hht,"model_type"),hht.forEach(t),GDo=r(K0,` property of the config object (either
passed as an argument or loaded from `),nhe=n(K0,"CODE",{});var pht=s(nhe);ODo=r(pht,"pretrained_model_name_or_path"),pht.forEach(t),VDo=r(K0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),she=n(K0,"CODE",{});var _ht=s(she);XDo=r(_ht,"pretrained_model_name_or_path"),_ht.forEach(t),zDo=r(K0,":"),K0.forEach(t),WDo=i(da),H=n(da,"UL",{});var J=s(H);S2=n(J,"LI",{});var Jxe=s(S2);lhe=n(Jxe,"STRONG",{});var uht=s(lhe);QDo=r(uht,"albert"),uht.forEach(t),HDo=r(Jxe," \u2014 "),oV=n(Jxe,"A",{href:!0});var bht=s(oV);UDo=r(bht,"AlbertForTokenClassification"),bht.forEach(t),JDo=r(Jxe," (ALBERT model)"),Jxe.forEach(t),YDo=i(J),R2=n(J,"LI",{});var Yxe=s(R2);ihe=n(Yxe,"STRONG",{});var vht=s(ihe);KDo=r(vht,"bert"),vht.forEach(t),ZDo=r(Yxe," \u2014 "),rV=n(Yxe,"A",{href:!0});var Fht=s(rV);eGo=r(Fht,"BertForTokenClassification"),Fht.forEach(t),oGo=r(Yxe," (BERT model)"),Yxe.forEach(t),rGo=i(J),P2=n(J,"LI",{});var Kxe=s(P2);dhe=n(Kxe,"STRONG",{});var Tht=s(dhe);tGo=r(Tht,"big_bird"),Tht.forEach(t),aGo=r(Kxe," \u2014 "),tV=n(Kxe,"A",{href:!0});var Mht=s(tV);nGo=r(Mht,"BigBirdForTokenClassification"),Mht.forEach(t),sGo=r(Kxe," (BigBird model)"),Kxe.forEach(t),lGo=i(J),B2=n(J,"LI",{});var Zxe=s(B2);che=n(Zxe,"STRONG",{});var Eht=s(che);iGo=r(Eht,"camembert"),Eht.forEach(t),dGo=r(Zxe," \u2014 "),aV=n(Zxe,"A",{href:!0});var Cht=s(aV);cGo=r(Cht,"CamembertForTokenClassification"),Cht.forEach(t),fGo=r(Zxe," (CamemBERT model)"),Zxe.forEach(t),mGo=i(J),I2=n(J,"LI",{});var e$e=s(I2);fhe=n(e$e,"STRONG",{});var wht=s(fhe);gGo=r(wht,"canine"),wht.forEach(t),hGo=r(e$e," \u2014 "),nV=n(e$e,"A",{href:!0});var Aht=s(nV);pGo=r(Aht,"CanineForTokenClassification"),Aht.forEach(t),_Go=r(e$e," (Canine model)"),e$e.forEach(t),uGo=i(J),N2=n(J,"LI",{});var o$e=s(N2);mhe=n(o$e,"STRONG",{});var yht=s(mhe);bGo=r(yht,"convbert"),yht.forEach(t),vGo=r(o$e," \u2014 "),sV=n(o$e,"A",{href:!0});var Lht=s(sV);FGo=r(Lht,"ConvBertForTokenClassification"),Lht.forEach(t),TGo=r(o$e," (ConvBERT model)"),o$e.forEach(t),MGo=i(J),q2=n(J,"LI",{});var r$e=s(q2);ghe=n(r$e,"STRONG",{});var xht=s(ghe);EGo=r(xht,"data2vec-text"),xht.forEach(t),CGo=r(r$e," \u2014 "),lV=n(r$e,"A",{href:!0});var $ht=s(lV);wGo=r($ht,"Data2VecTextForTokenClassification"),$ht.forEach(t),AGo=r(r$e," (Data2VecText model)"),r$e.forEach(t),yGo=i(J),j2=n(J,"LI",{});var t$e=s(j2);hhe=n(t$e,"STRONG",{});var kht=s(hhe);LGo=r(kht,"deberta"),kht.forEach(t),xGo=r(t$e," \u2014 "),iV=n(t$e,"A",{href:!0});var Sht=s(iV);$Go=r(Sht,"DebertaForTokenClassification"),Sht.forEach(t),kGo=r(t$e," (DeBERTa model)"),t$e.forEach(t),SGo=i(J),D2=n(J,"LI",{});var a$e=s(D2);phe=n(a$e,"STRONG",{});var Rht=s(phe);RGo=r(Rht,"deberta-v2"),Rht.forEach(t),PGo=r(a$e," \u2014 "),dV=n(a$e,"A",{href:!0});var Pht=s(dV);BGo=r(Pht,"DebertaV2ForTokenClassification"),Pht.forEach(t),IGo=r(a$e," (DeBERTa-v2 model)"),a$e.forEach(t),NGo=i(J),G2=n(J,"LI",{});var n$e=s(G2);_he=n(n$e,"STRONG",{});var Bht=s(_he);qGo=r(Bht,"distilbert"),Bht.forEach(t),jGo=r(n$e," \u2014 "),cV=n(n$e,"A",{href:!0});var Iht=s(cV);DGo=r(Iht,"DistilBertForTokenClassification"),Iht.forEach(t),GGo=r(n$e," (DistilBERT model)"),n$e.forEach(t),OGo=i(J),O2=n(J,"LI",{});var s$e=s(O2);uhe=n(s$e,"STRONG",{});var Nht=s(uhe);VGo=r(Nht,"electra"),Nht.forEach(t),XGo=r(s$e," \u2014 "),fV=n(s$e,"A",{href:!0});var qht=s(fV);zGo=r(qht,"ElectraForTokenClassification"),qht.forEach(t),WGo=r(s$e," (ELECTRA model)"),s$e.forEach(t),QGo=i(J),V2=n(J,"LI",{});var l$e=s(V2);bhe=n(l$e,"STRONG",{});var jht=s(bhe);HGo=r(jht,"flaubert"),jht.forEach(t),UGo=r(l$e," \u2014 "),mV=n(l$e,"A",{href:!0});var Dht=s(mV);JGo=r(Dht,"FlaubertForTokenClassification"),Dht.forEach(t),YGo=r(l$e," (FlauBERT model)"),l$e.forEach(t),KGo=i(J),X2=n(J,"LI",{});var i$e=s(X2);vhe=n(i$e,"STRONG",{});var Ght=s(vhe);ZGo=r(Ght,"fnet"),Ght.forEach(t),eOo=r(i$e," \u2014 "),gV=n(i$e,"A",{href:!0});var Oht=s(gV);oOo=r(Oht,"FNetForTokenClassification"),Oht.forEach(t),rOo=r(i$e," (FNet model)"),i$e.forEach(t),tOo=i(J),z2=n(J,"LI",{});var d$e=s(z2);Fhe=n(d$e,"STRONG",{});var Vht=s(Fhe);aOo=r(Vht,"funnel"),Vht.forEach(t),nOo=r(d$e," \u2014 "),hV=n(d$e,"A",{href:!0});var Xht=s(hV);sOo=r(Xht,"FunnelForTokenClassification"),Xht.forEach(t),lOo=r(d$e," (Funnel Transformer model)"),d$e.forEach(t),iOo=i(J),W2=n(J,"LI",{});var c$e=s(W2);The=n(c$e,"STRONG",{});var zht=s(The);dOo=r(zht,"gpt2"),zht.forEach(t),cOo=r(c$e," \u2014 "),pV=n(c$e,"A",{href:!0});var Wht=s(pV);fOo=r(Wht,"GPT2ForTokenClassification"),Wht.forEach(t),mOo=r(c$e," (OpenAI GPT-2 model)"),c$e.forEach(t),gOo=i(J),Q2=n(J,"LI",{});var f$e=s(Q2);Mhe=n(f$e,"STRONG",{});var Qht=s(Mhe);hOo=r(Qht,"ibert"),Qht.forEach(t),pOo=r(f$e," \u2014 "),_V=n(f$e,"A",{href:!0});var Hht=s(_V);_Oo=r(Hht,"IBertForTokenClassification"),Hht.forEach(t),uOo=r(f$e," (I-BERT model)"),f$e.forEach(t),bOo=i(J),H2=n(J,"LI",{});var m$e=s(H2);Ehe=n(m$e,"STRONG",{});var Uht=s(Ehe);vOo=r(Uht,"layoutlm"),Uht.forEach(t),FOo=r(m$e," \u2014 "),uV=n(m$e,"A",{href:!0});var Jht=s(uV);TOo=r(Jht,"LayoutLMForTokenClassification"),Jht.forEach(t),MOo=r(m$e," (LayoutLM model)"),m$e.forEach(t),EOo=i(J),U2=n(J,"LI",{});var g$e=s(U2);Che=n(g$e,"STRONG",{});var Yht=s(Che);COo=r(Yht,"layoutlmv2"),Yht.forEach(t),wOo=r(g$e," \u2014 "),bV=n(g$e,"A",{href:!0});var Kht=s(bV);AOo=r(Kht,"LayoutLMv2ForTokenClassification"),Kht.forEach(t),yOo=r(g$e," (LayoutLMv2 model)"),g$e.forEach(t),LOo=i(J),J2=n(J,"LI",{});var h$e=s(J2);whe=n(h$e,"STRONG",{});var Zht=s(whe);xOo=r(Zht,"layoutlmv3"),Zht.forEach(t),$Oo=r(h$e," \u2014 "),vV=n(h$e,"A",{href:!0});var ept=s(vV);kOo=r(ept,"LayoutLMv3ForTokenClassification"),ept.forEach(t),SOo=r(h$e," (LayoutLMv3 model)"),h$e.forEach(t),ROo=i(J),Y2=n(J,"LI",{});var p$e=s(Y2);Ahe=n(p$e,"STRONG",{});var opt=s(Ahe);POo=r(opt,"longformer"),opt.forEach(t),BOo=r(p$e," \u2014 "),FV=n(p$e,"A",{href:!0});var rpt=s(FV);IOo=r(rpt,"LongformerForTokenClassification"),rpt.forEach(t),NOo=r(p$e," (Longformer model)"),p$e.forEach(t),qOo=i(J),K2=n(J,"LI",{});var _$e=s(K2);yhe=n(_$e,"STRONG",{});var tpt=s(yhe);jOo=r(tpt,"megatron-bert"),tpt.forEach(t),DOo=r(_$e," \u2014 "),TV=n(_$e,"A",{href:!0});var apt=s(TV);GOo=r(apt,"MegatronBertForTokenClassification"),apt.forEach(t),OOo=r(_$e," (MegatronBert model)"),_$e.forEach(t),VOo=i(J),Z2=n(J,"LI",{});var u$e=s(Z2);Lhe=n(u$e,"STRONG",{});var npt=s(Lhe);XOo=r(npt,"mobilebert"),npt.forEach(t),zOo=r(u$e," \u2014 "),MV=n(u$e,"A",{href:!0});var spt=s(MV);WOo=r(spt,"MobileBertForTokenClassification"),spt.forEach(t),QOo=r(u$e," (MobileBERT model)"),u$e.forEach(t),HOo=i(J),ev=n(J,"LI",{});var b$e=s(ev);xhe=n(b$e,"STRONG",{});var lpt=s(xhe);UOo=r(lpt,"mpnet"),lpt.forEach(t),JOo=r(b$e," \u2014 "),EV=n(b$e,"A",{href:!0});var ipt=s(EV);YOo=r(ipt,"MPNetForTokenClassification"),ipt.forEach(t),KOo=r(b$e," (MPNet model)"),b$e.forEach(t),ZOo=i(J),ov=n(J,"LI",{});var v$e=s(ov);$he=n(v$e,"STRONG",{});var dpt=s($he);eVo=r(dpt,"nystromformer"),dpt.forEach(t),oVo=r(v$e," \u2014 "),CV=n(v$e,"A",{href:!0});var cpt=s(CV);rVo=r(cpt,"NystromformerForTokenClassification"),cpt.forEach(t),tVo=r(v$e," (Nystromformer model)"),v$e.forEach(t),aVo=i(J),rv=n(J,"LI",{});var F$e=s(rv);khe=n(F$e,"STRONG",{});var fpt=s(khe);nVo=r(fpt,"qdqbert"),fpt.forEach(t),sVo=r(F$e," \u2014 "),wV=n(F$e,"A",{href:!0});var mpt=s(wV);lVo=r(mpt,"QDQBertForTokenClassification"),mpt.forEach(t),iVo=r(F$e," (QDQBert model)"),F$e.forEach(t),dVo=i(J),tv=n(J,"LI",{});var T$e=s(tv);She=n(T$e,"STRONG",{});var gpt=s(She);cVo=r(gpt,"rembert"),gpt.forEach(t),fVo=r(T$e," \u2014 "),AV=n(T$e,"A",{href:!0});var hpt=s(AV);mVo=r(hpt,"RemBertForTokenClassification"),hpt.forEach(t),gVo=r(T$e," (RemBERT model)"),T$e.forEach(t),hVo=i(J),av=n(J,"LI",{});var M$e=s(av);Rhe=n(M$e,"STRONG",{});var ppt=s(Rhe);pVo=r(ppt,"roberta"),ppt.forEach(t),_Vo=r(M$e," \u2014 "),yV=n(M$e,"A",{href:!0});var _pt=s(yV);uVo=r(_pt,"RobertaForTokenClassification"),_pt.forEach(t),bVo=r(M$e," (RoBERTa model)"),M$e.forEach(t),vVo=i(J),nv=n(J,"LI",{});var E$e=s(nv);Phe=n(E$e,"STRONG",{});var upt=s(Phe);FVo=r(upt,"roformer"),upt.forEach(t),TVo=r(E$e," \u2014 "),LV=n(E$e,"A",{href:!0});var bpt=s(LV);MVo=r(bpt,"RoFormerForTokenClassification"),bpt.forEach(t),EVo=r(E$e," (RoFormer model)"),E$e.forEach(t),CVo=i(J),sv=n(J,"LI",{});var C$e=s(sv);Bhe=n(C$e,"STRONG",{});var vpt=s(Bhe);wVo=r(vpt,"squeezebert"),vpt.forEach(t),AVo=r(C$e," \u2014 "),xV=n(C$e,"A",{href:!0});var Fpt=s(xV);yVo=r(Fpt,"SqueezeBertForTokenClassification"),Fpt.forEach(t),LVo=r(C$e," (SqueezeBERT model)"),C$e.forEach(t),xVo=i(J),lv=n(J,"LI",{});var w$e=s(lv);Ihe=n(w$e,"STRONG",{});var Tpt=s(Ihe);$Vo=r(Tpt,"xlm"),Tpt.forEach(t),kVo=r(w$e," \u2014 "),$V=n(w$e,"A",{href:!0});var Mpt=s($V);SVo=r(Mpt,"XLMForTokenClassification"),Mpt.forEach(t),RVo=r(w$e," (XLM model)"),w$e.forEach(t),PVo=i(J),iv=n(J,"LI",{});var A$e=s(iv);Nhe=n(A$e,"STRONG",{});var Ept=s(Nhe);BVo=r(Ept,"xlm-roberta"),Ept.forEach(t),IVo=r(A$e," \u2014 "),kV=n(A$e,"A",{href:!0});var Cpt=s(kV);NVo=r(Cpt,"XLMRobertaForTokenClassification"),Cpt.forEach(t),qVo=r(A$e," (XLM-RoBERTa model)"),A$e.forEach(t),jVo=i(J),dv=n(J,"LI",{});var y$e=s(dv);qhe=n(y$e,"STRONG",{});var wpt=s(qhe);DVo=r(wpt,"xlm-roberta-xl"),wpt.forEach(t),GVo=r(y$e," \u2014 "),SV=n(y$e,"A",{href:!0});var Apt=s(SV);OVo=r(Apt,"XLMRobertaXLForTokenClassification"),Apt.forEach(t),VVo=r(y$e," (XLM-RoBERTa-XL model)"),y$e.forEach(t),XVo=i(J),cv=n(J,"LI",{});var L$e=s(cv);jhe=n(L$e,"STRONG",{});var ypt=s(jhe);zVo=r(ypt,"xlnet"),ypt.forEach(t),WVo=r(L$e," \u2014 "),RV=n(L$e,"A",{href:!0});var Lpt=s(RV);QVo=r(Lpt,"XLNetForTokenClassification"),Lpt.forEach(t),HVo=r(L$e," (XLNet model)"),L$e.forEach(t),UVo=i(J),fv=n(J,"LI",{});var x$e=s(fv);Dhe=n(x$e,"STRONG",{});var xpt=s(Dhe);JVo=r(xpt,"yoso"),xpt.forEach(t),YVo=r(x$e," \u2014 "),PV=n(x$e,"A",{href:!0});var $pt=s(PV);KVo=r($pt,"YosoForTokenClassification"),$pt.forEach(t),ZVo=r(x$e," (YOSO model)"),x$e.forEach(t),J.forEach(t),eXo=i(da),mv=n(da,"P",{});var $$e=s(mv);oXo=r($$e,"The model is set in evaluation mode by default using "),Ghe=n($$e,"CODE",{});var kpt=s(Ghe);rXo=r(kpt,"model.eval()"),kpt.forEach(t),tXo=r($$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ohe=n($$e,"CODE",{});var Spt=s(Ohe);aXo=r(Spt,"model.train()"),Spt.forEach(t),$$e.forEach(t),nXo=i(da),T(gv.$$.fragment,da),da.forEach(t),Ys.forEach(t),Wqe=i(f),Zi=n(f,"H2",{class:!0});var JDe=s(Zi);hv=n(JDe,"A",{id:!0,class:!0,href:!0});var Rpt=s(hv);Vhe=n(Rpt,"SPAN",{});var Ppt=s(Vhe);T(Hy.$$.fragment,Ppt),Ppt.forEach(t),Rpt.forEach(t),sXo=i(JDe),Xhe=n(JDe,"SPAN",{});var Bpt=s(Xhe);lXo=r(Bpt,"AutoModelForQuestionAnswering"),Bpt.forEach(t),JDe.forEach(t),Qqe=i(f),No=n(f,"DIV",{class:!0});var Ks=s(No);T(Uy.$$.fragment,Ks),iXo=i(Ks),ed=n(Ks,"P",{});var VZ=s(ed);dXo=r(VZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),BV=n(VZ,"A",{href:!0});var Ipt=s(BV);cXo=r(Ipt,"from_pretrained()"),Ipt.forEach(t),fXo=r(VZ," class method or the "),IV=n(VZ,"A",{href:!0});var Npt=s(IV);mXo=r(Npt,"from_config()"),Npt.forEach(t),gXo=r(VZ,` class
method.`),VZ.forEach(t),hXo=i(Ks),Jy=n(Ks,"P",{});var YDe=s(Jy);pXo=r(YDe,"This class cannot be instantiated directly using "),zhe=n(YDe,"CODE",{});var qpt=s(zhe);_Xo=r(qpt,"__init__()"),qpt.forEach(t),uXo=r(YDe," (throws an error)."),YDe.forEach(t),bXo=i(Ks),mt=n(Ks,"DIV",{class:!0});var Z0=s(mt);T(Yy.$$.fragment,Z0),vXo=i(Z0),Whe=n(Z0,"P",{});var jpt=s(Whe);FXo=r(jpt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),jpt.forEach(t),TXo=i(Z0),od=n(Z0,"P",{});var XZ=s(od);MXo=r(XZ,`Note:
Loading a model from its configuration file does `),Qhe=n(XZ,"STRONG",{});var Dpt=s(Qhe);EXo=r(Dpt,"not"),Dpt.forEach(t),CXo=r(XZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),NV=n(XZ,"A",{href:!0});var Gpt=s(NV);wXo=r(Gpt,"from_pretrained()"),Gpt.forEach(t),AXo=r(XZ," to load the model weights."),XZ.forEach(t),yXo=i(Z0),T(pv.$$.fragment,Z0),Z0.forEach(t),LXo=i(Ks),no=n(Ks,"DIV",{class:!0});var ca=s(no);T(Ky.$$.fragment,ca),xXo=i(ca),Hhe=n(ca,"P",{});var Opt=s(Hhe);$Xo=r(Opt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Opt.forEach(t),kXo=i(ca),Na=n(ca,"P",{});var e6=s(Na);SXo=r(e6,"The model class to instantiate is selected based on the "),Uhe=n(e6,"CODE",{});var Vpt=s(Uhe);RXo=r(Vpt,"model_type"),Vpt.forEach(t),PXo=r(e6,` property of the config object (either
passed as an argument or loaded from `),Jhe=n(e6,"CODE",{});var Xpt=s(Jhe);BXo=r(Xpt,"pretrained_model_name_or_path"),Xpt.forEach(t),IXo=r(e6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yhe=n(e6,"CODE",{});var zpt=s(Yhe);NXo=r(zpt,"pretrained_model_name_or_path"),zpt.forEach(t),qXo=r(e6,":"),e6.forEach(t),jXo=i(ca),V=n(ca,"UL",{});var X=s(V);_v=n(X,"LI",{});var k$e=s(_v);Khe=n(k$e,"STRONG",{});var Wpt=s(Khe);DXo=r(Wpt,"albert"),Wpt.forEach(t),GXo=r(k$e," \u2014 "),qV=n(k$e,"A",{href:!0});var Qpt=s(qV);OXo=r(Qpt,"AlbertForQuestionAnswering"),Qpt.forEach(t),VXo=r(k$e," (ALBERT model)"),k$e.forEach(t),XXo=i(X),uv=n(X,"LI",{});var S$e=s(uv);Zhe=n(S$e,"STRONG",{});var Hpt=s(Zhe);zXo=r(Hpt,"bart"),Hpt.forEach(t),WXo=r(S$e," \u2014 "),jV=n(S$e,"A",{href:!0});var Upt=s(jV);QXo=r(Upt,"BartForQuestionAnswering"),Upt.forEach(t),HXo=r(S$e," (BART model)"),S$e.forEach(t),UXo=i(X),bv=n(X,"LI",{});var R$e=s(bv);epe=n(R$e,"STRONG",{});var Jpt=s(epe);JXo=r(Jpt,"bert"),Jpt.forEach(t),YXo=r(R$e," \u2014 "),DV=n(R$e,"A",{href:!0});var Ypt=s(DV);KXo=r(Ypt,"BertForQuestionAnswering"),Ypt.forEach(t),ZXo=r(R$e," (BERT model)"),R$e.forEach(t),ezo=i(X),vv=n(X,"LI",{});var P$e=s(vv);ope=n(P$e,"STRONG",{});var Kpt=s(ope);ozo=r(Kpt,"big_bird"),Kpt.forEach(t),rzo=r(P$e," \u2014 "),GV=n(P$e,"A",{href:!0});var Zpt=s(GV);tzo=r(Zpt,"BigBirdForQuestionAnswering"),Zpt.forEach(t),azo=r(P$e," (BigBird model)"),P$e.forEach(t),nzo=i(X),Fv=n(X,"LI",{});var B$e=s(Fv);rpe=n(B$e,"STRONG",{});var e_t=s(rpe);szo=r(e_t,"bigbird_pegasus"),e_t.forEach(t),lzo=r(B$e," \u2014 "),OV=n(B$e,"A",{href:!0});var o_t=s(OV);izo=r(o_t,"BigBirdPegasusForQuestionAnswering"),o_t.forEach(t),dzo=r(B$e," (BigBirdPegasus model)"),B$e.forEach(t),czo=i(X),Tv=n(X,"LI",{});var I$e=s(Tv);tpe=n(I$e,"STRONG",{});var r_t=s(tpe);fzo=r(r_t,"camembert"),r_t.forEach(t),mzo=r(I$e," \u2014 "),VV=n(I$e,"A",{href:!0});var t_t=s(VV);gzo=r(t_t,"CamembertForQuestionAnswering"),t_t.forEach(t),hzo=r(I$e," (CamemBERT model)"),I$e.forEach(t),pzo=i(X),Mv=n(X,"LI",{});var N$e=s(Mv);ape=n(N$e,"STRONG",{});var a_t=s(ape);_zo=r(a_t,"canine"),a_t.forEach(t),uzo=r(N$e," \u2014 "),XV=n(N$e,"A",{href:!0});var n_t=s(XV);bzo=r(n_t,"CanineForQuestionAnswering"),n_t.forEach(t),vzo=r(N$e," (Canine model)"),N$e.forEach(t),Fzo=i(X),Ev=n(X,"LI",{});var q$e=s(Ev);npe=n(q$e,"STRONG",{});var s_t=s(npe);Tzo=r(s_t,"convbert"),s_t.forEach(t),Mzo=r(q$e," \u2014 "),zV=n(q$e,"A",{href:!0});var l_t=s(zV);Ezo=r(l_t,"ConvBertForQuestionAnswering"),l_t.forEach(t),Czo=r(q$e," (ConvBERT model)"),q$e.forEach(t),wzo=i(X),Cv=n(X,"LI",{});var j$e=s(Cv);spe=n(j$e,"STRONG",{});var i_t=s(spe);Azo=r(i_t,"data2vec-text"),i_t.forEach(t),yzo=r(j$e," \u2014 "),WV=n(j$e,"A",{href:!0});var d_t=s(WV);Lzo=r(d_t,"Data2VecTextForQuestionAnswering"),d_t.forEach(t),xzo=r(j$e," (Data2VecText model)"),j$e.forEach(t),$zo=i(X),wv=n(X,"LI",{});var D$e=s(wv);lpe=n(D$e,"STRONG",{});var c_t=s(lpe);kzo=r(c_t,"deberta"),c_t.forEach(t),Szo=r(D$e," \u2014 "),QV=n(D$e,"A",{href:!0});var f_t=s(QV);Rzo=r(f_t,"DebertaForQuestionAnswering"),f_t.forEach(t),Pzo=r(D$e," (DeBERTa model)"),D$e.forEach(t),Bzo=i(X),Av=n(X,"LI",{});var G$e=s(Av);ipe=n(G$e,"STRONG",{});var m_t=s(ipe);Izo=r(m_t,"deberta-v2"),m_t.forEach(t),Nzo=r(G$e," \u2014 "),HV=n(G$e,"A",{href:!0});var g_t=s(HV);qzo=r(g_t,"DebertaV2ForQuestionAnswering"),g_t.forEach(t),jzo=r(G$e," (DeBERTa-v2 model)"),G$e.forEach(t),Dzo=i(X),yv=n(X,"LI",{});var O$e=s(yv);dpe=n(O$e,"STRONG",{});var h_t=s(dpe);Gzo=r(h_t,"distilbert"),h_t.forEach(t),Ozo=r(O$e," \u2014 "),UV=n(O$e,"A",{href:!0});var p_t=s(UV);Vzo=r(p_t,"DistilBertForQuestionAnswering"),p_t.forEach(t),Xzo=r(O$e," (DistilBERT model)"),O$e.forEach(t),zzo=i(X),Lv=n(X,"LI",{});var V$e=s(Lv);cpe=n(V$e,"STRONG",{});var __t=s(cpe);Wzo=r(__t,"electra"),__t.forEach(t),Qzo=r(V$e," \u2014 "),JV=n(V$e,"A",{href:!0});var u_t=s(JV);Hzo=r(u_t,"ElectraForQuestionAnswering"),u_t.forEach(t),Uzo=r(V$e," (ELECTRA model)"),V$e.forEach(t),Jzo=i(X),xv=n(X,"LI",{});var X$e=s(xv);fpe=n(X$e,"STRONG",{});var b_t=s(fpe);Yzo=r(b_t,"flaubert"),b_t.forEach(t),Kzo=r(X$e," \u2014 "),YV=n(X$e,"A",{href:!0});var v_t=s(YV);Zzo=r(v_t,"FlaubertForQuestionAnsweringSimple"),v_t.forEach(t),eWo=r(X$e," (FlauBERT model)"),X$e.forEach(t),oWo=i(X),$v=n(X,"LI",{});var z$e=s($v);mpe=n(z$e,"STRONG",{});var F_t=s(mpe);rWo=r(F_t,"fnet"),F_t.forEach(t),tWo=r(z$e," \u2014 "),KV=n(z$e,"A",{href:!0});var T_t=s(KV);aWo=r(T_t,"FNetForQuestionAnswering"),T_t.forEach(t),nWo=r(z$e," (FNet model)"),z$e.forEach(t),sWo=i(X),kv=n(X,"LI",{});var W$e=s(kv);gpe=n(W$e,"STRONG",{});var M_t=s(gpe);lWo=r(M_t,"funnel"),M_t.forEach(t),iWo=r(W$e," \u2014 "),ZV=n(W$e,"A",{href:!0});var E_t=s(ZV);dWo=r(E_t,"FunnelForQuestionAnswering"),E_t.forEach(t),cWo=r(W$e," (Funnel Transformer model)"),W$e.forEach(t),fWo=i(X),Sv=n(X,"LI",{});var Q$e=s(Sv);hpe=n(Q$e,"STRONG",{});var C_t=s(hpe);mWo=r(C_t,"gptj"),C_t.forEach(t),gWo=r(Q$e," \u2014 "),eX=n(Q$e,"A",{href:!0});var w_t=s(eX);hWo=r(w_t,"GPTJForQuestionAnswering"),w_t.forEach(t),pWo=r(Q$e," (GPT-J model)"),Q$e.forEach(t),_Wo=i(X),Rv=n(X,"LI",{});var H$e=s(Rv);ppe=n(H$e,"STRONG",{});var A_t=s(ppe);uWo=r(A_t,"ibert"),A_t.forEach(t),bWo=r(H$e," \u2014 "),oX=n(H$e,"A",{href:!0});var y_t=s(oX);vWo=r(y_t,"IBertForQuestionAnswering"),y_t.forEach(t),FWo=r(H$e," (I-BERT model)"),H$e.forEach(t),TWo=i(X),Pv=n(X,"LI",{});var U$e=s(Pv);_pe=n(U$e,"STRONG",{});var L_t=s(_pe);MWo=r(L_t,"layoutlmv2"),L_t.forEach(t),EWo=r(U$e," \u2014 "),rX=n(U$e,"A",{href:!0});var x_t=s(rX);CWo=r(x_t,"LayoutLMv2ForQuestionAnswering"),x_t.forEach(t),wWo=r(U$e," (LayoutLMv2 model)"),U$e.forEach(t),AWo=i(X),Bv=n(X,"LI",{});var J$e=s(Bv);upe=n(J$e,"STRONG",{});var $_t=s(upe);yWo=r($_t,"layoutlmv3"),$_t.forEach(t),LWo=r(J$e," \u2014 "),tX=n(J$e,"A",{href:!0});var k_t=s(tX);xWo=r(k_t,"LayoutLMv3ForQuestionAnswering"),k_t.forEach(t),$Wo=r(J$e," (LayoutLMv3 model)"),J$e.forEach(t),kWo=i(X),Iv=n(X,"LI",{});var Y$e=s(Iv);bpe=n(Y$e,"STRONG",{});var S_t=s(bpe);SWo=r(S_t,"led"),S_t.forEach(t),RWo=r(Y$e," \u2014 "),aX=n(Y$e,"A",{href:!0});var R_t=s(aX);PWo=r(R_t,"LEDForQuestionAnswering"),R_t.forEach(t),BWo=r(Y$e," (LED model)"),Y$e.forEach(t),IWo=i(X),Nv=n(X,"LI",{});var K$e=s(Nv);vpe=n(K$e,"STRONG",{});var P_t=s(vpe);NWo=r(P_t,"longformer"),P_t.forEach(t),qWo=r(K$e," \u2014 "),nX=n(K$e,"A",{href:!0});var B_t=s(nX);jWo=r(B_t,"LongformerForQuestionAnswering"),B_t.forEach(t),DWo=r(K$e," (Longformer model)"),K$e.forEach(t),GWo=i(X),qv=n(X,"LI",{});var Z$e=s(qv);Fpe=n(Z$e,"STRONG",{});var I_t=s(Fpe);OWo=r(I_t,"lxmert"),I_t.forEach(t),VWo=r(Z$e," \u2014 "),sX=n(Z$e,"A",{href:!0});var N_t=s(sX);XWo=r(N_t,"LxmertForQuestionAnswering"),N_t.forEach(t),zWo=r(Z$e," (LXMERT model)"),Z$e.forEach(t),WWo=i(X),jv=n(X,"LI",{});var eke=s(jv);Tpe=n(eke,"STRONG",{});var q_t=s(Tpe);QWo=r(q_t,"mbart"),q_t.forEach(t),HWo=r(eke," \u2014 "),lX=n(eke,"A",{href:!0});var j_t=s(lX);UWo=r(j_t,"MBartForQuestionAnswering"),j_t.forEach(t),JWo=r(eke," (mBART model)"),eke.forEach(t),YWo=i(X),Dv=n(X,"LI",{});var oke=s(Dv);Mpe=n(oke,"STRONG",{});var D_t=s(Mpe);KWo=r(D_t,"megatron-bert"),D_t.forEach(t),ZWo=r(oke," \u2014 "),iX=n(oke,"A",{href:!0});var G_t=s(iX);eQo=r(G_t,"MegatronBertForQuestionAnswering"),G_t.forEach(t),oQo=r(oke," (MegatronBert model)"),oke.forEach(t),rQo=i(X),Gv=n(X,"LI",{});var rke=s(Gv);Epe=n(rke,"STRONG",{});var O_t=s(Epe);tQo=r(O_t,"mobilebert"),O_t.forEach(t),aQo=r(rke," \u2014 "),dX=n(rke,"A",{href:!0});var V_t=s(dX);nQo=r(V_t,"MobileBertForQuestionAnswering"),V_t.forEach(t),sQo=r(rke," (MobileBERT model)"),rke.forEach(t),lQo=i(X),Ov=n(X,"LI",{});var tke=s(Ov);Cpe=n(tke,"STRONG",{});var X_t=s(Cpe);iQo=r(X_t,"mpnet"),X_t.forEach(t),dQo=r(tke," \u2014 "),cX=n(tke,"A",{href:!0});var z_t=s(cX);cQo=r(z_t,"MPNetForQuestionAnswering"),z_t.forEach(t),fQo=r(tke," (MPNet model)"),tke.forEach(t),mQo=i(X),Vv=n(X,"LI",{});var ake=s(Vv);wpe=n(ake,"STRONG",{});var W_t=s(wpe);gQo=r(W_t,"nystromformer"),W_t.forEach(t),hQo=r(ake," \u2014 "),fX=n(ake,"A",{href:!0});var Q_t=s(fX);pQo=r(Q_t,"NystromformerForQuestionAnswering"),Q_t.forEach(t),_Qo=r(ake," (Nystromformer model)"),ake.forEach(t),uQo=i(X),Xv=n(X,"LI",{});var nke=s(Xv);Ape=n(nke,"STRONG",{});var H_t=s(Ape);bQo=r(H_t,"qdqbert"),H_t.forEach(t),vQo=r(nke," \u2014 "),mX=n(nke,"A",{href:!0});var U_t=s(mX);FQo=r(U_t,"QDQBertForQuestionAnswering"),U_t.forEach(t),TQo=r(nke," (QDQBert model)"),nke.forEach(t),MQo=i(X),zv=n(X,"LI",{});var ske=s(zv);ype=n(ske,"STRONG",{});var J_t=s(ype);EQo=r(J_t,"reformer"),J_t.forEach(t),CQo=r(ske," \u2014 "),gX=n(ske,"A",{href:!0});var Y_t=s(gX);wQo=r(Y_t,"ReformerForQuestionAnswering"),Y_t.forEach(t),AQo=r(ske," (Reformer model)"),ske.forEach(t),yQo=i(X),Wv=n(X,"LI",{});var lke=s(Wv);Lpe=n(lke,"STRONG",{});var K_t=s(Lpe);LQo=r(K_t,"rembert"),K_t.forEach(t),xQo=r(lke," \u2014 "),hX=n(lke,"A",{href:!0});var Z_t=s(hX);$Qo=r(Z_t,"RemBertForQuestionAnswering"),Z_t.forEach(t),kQo=r(lke," (RemBERT model)"),lke.forEach(t),SQo=i(X),Qv=n(X,"LI",{});var ike=s(Qv);xpe=n(ike,"STRONG",{});var eut=s(xpe);RQo=r(eut,"roberta"),eut.forEach(t),PQo=r(ike," \u2014 "),pX=n(ike,"A",{href:!0});var out=s(pX);BQo=r(out,"RobertaForQuestionAnswering"),out.forEach(t),IQo=r(ike," (RoBERTa model)"),ike.forEach(t),NQo=i(X),Hv=n(X,"LI",{});var dke=s(Hv);$pe=n(dke,"STRONG",{});var rut=s($pe);qQo=r(rut,"roformer"),rut.forEach(t),jQo=r(dke," \u2014 "),_X=n(dke,"A",{href:!0});var tut=s(_X);DQo=r(tut,"RoFormerForQuestionAnswering"),tut.forEach(t),GQo=r(dke," (RoFormer model)"),dke.forEach(t),OQo=i(X),Uv=n(X,"LI",{});var cke=s(Uv);kpe=n(cke,"STRONG",{});var aut=s(kpe);VQo=r(aut,"splinter"),aut.forEach(t),XQo=r(cke," \u2014 "),uX=n(cke,"A",{href:!0});var nut=s(uX);zQo=r(nut,"SplinterForQuestionAnswering"),nut.forEach(t),WQo=r(cke," (Splinter model)"),cke.forEach(t),QQo=i(X),Jv=n(X,"LI",{});var fke=s(Jv);Spe=n(fke,"STRONG",{});var sut=s(Spe);HQo=r(sut,"squeezebert"),sut.forEach(t),UQo=r(fke," \u2014 "),bX=n(fke,"A",{href:!0});var lut=s(bX);JQo=r(lut,"SqueezeBertForQuestionAnswering"),lut.forEach(t),YQo=r(fke," (SqueezeBERT model)"),fke.forEach(t),KQo=i(X),Yv=n(X,"LI",{});var mke=s(Yv);Rpe=n(mke,"STRONG",{});var iut=s(Rpe);ZQo=r(iut,"xlm"),iut.forEach(t),eHo=r(mke," \u2014 "),vX=n(mke,"A",{href:!0});var dut=s(vX);oHo=r(dut,"XLMForQuestionAnsweringSimple"),dut.forEach(t),rHo=r(mke," (XLM model)"),mke.forEach(t),tHo=i(X),Kv=n(X,"LI",{});var gke=s(Kv);Ppe=n(gke,"STRONG",{});var cut=s(Ppe);aHo=r(cut,"xlm-roberta"),cut.forEach(t),nHo=r(gke," \u2014 "),FX=n(gke,"A",{href:!0});var fut=s(FX);sHo=r(fut,"XLMRobertaForQuestionAnswering"),fut.forEach(t),lHo=r(gke," (XLM-RoBERTa model)"),gke.forEach(t),iHo=i(X),Zv=n(X,"LI",{});var hke=s(Zv);Bpe=n(hke,"STRONG",{});var mut=s(Bpe);dHo=r(mut,"xlm-roberta-xl"),mut.forEach(t),cHo=r(hke," \u2014 "),TX=n(hke,"A",{href:!0});var gut=s(TX);fHo=r(gut,"XLMRobertaXLForQuestionAnswering"),gut.forEach(t),mHo=r(hke," (XLM-RoBERTa-XL model)"),hke.forEach(t),gHo=i(X),e3=n(X,"LI",{});var pke=s(e3);Ipe=n(pke,"STRONG",{});var hut=s(Ipe);hHo=r(hut,"xlnet"),hut.forEach(t),pHo=r(pke," \u2014 "),MX=n(pke,"A",{href:!0});var put=s(MX);_Ho=r(put,"XLNetForQuestionAnsweringSimple"),put.forEach(t),uHo=r(pke," (XLNet model)"),pke.forEach(t),bHo=i(X),o3=n(X,"LI",{});var _ke=s(o3);Npe=n(_ke,"STRONG",{});var _ut=s(Npe);vHo=r(_ut,"yoso"),_ut.forEach(t),FHo=r(_ke," \u2014 "),EX=n(_ke,"A",{href:!0});var uut=s(EX);THo=r(uut,"YosoForQuestionAnswering"),uut.forEach(t),MHo=r(_ke," (YOSO model)"),_ke.forEach(t),X.forEach(t),EHo=i(ca),r3=n(ca,"P",{});var uke=s(r3);CHo=r(uke,"The model is set in evaluation mode by default using "),qpe=n(uke,"CODE",{});var but=s(qpe);wHo=r(but,"model.eval()"),but.forEach(t),AHo=r(uke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jpe=n(uke,"CODE",{});var vut=s(jpe);yHo=r(vut,"model.train()"),vut.forEach(t),uke.forEach(t),LHo=i(ca),T(t3.$$.fragment,ca),ca.forEach(t),Ks.forEach(t),Hqe=i(f),rd=n(f,"H2",{class:!0});var KDe=s(rd);a3=n(KDe,"A",{id:!0,class:!0,href:!0});var Fut=s(a3);Dpe=n(Fut,"SPAN",{});var Tut=s(Dpe);T(Zy.$$.fragment,Tut),Tut.forEach(t),Fut.forEach(t),xHo=i(KDe),Gpe=n(KDe,"SPAN",{});var Mut=s(Gpe);$Ho=r(Mut,"AutoModelForTableQuestionAnswering"),Mut.forEach(t),KDe.forEach(t),Uqe=i(f),qo=n(f,"DIV",{class:!0});var Zs=s(qo);T(eL.$$.fragment,Zs),kHo=i(Zs),td=n(Zs,"P",{});var zZ=s(td);SHo=r(zZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),CX=n(zZ,"A",{href:!0});var Eut=s(CX);RHo=r(Eut,"from_pretrained()"),Eut.forEach(t),PHo=r(zZ," class method or the "),wX=n(zZ,"A",{href:!0});var Cut=s(wX);BHo=r(Cut,"from_config()"),Cut.forEach(t),IHo=r(zZ,` class
method.`),zZ.forEach(t),NHo=i(Zs),oL=n(Zs,"P",{});var ZDe=s(oL);qHo=r(ZDe,"This class cannot be instantiated directly using "),Ope=n(ZDe,"CODE",{});var wut=s(Ope);jHo=r(wut,"__init__()"),wut.forEach(t),DHo=r(ZDe," (throws an error)."),ZDe.forEach(t),GHo=i(Zs),gt=n(Zs,"DIV",{class:!0});var o6=s(gt);T(rL.$$.fragment,o6),OHo=i(o6),Vpe=n(o6,"P",{});var Aut=s(Vpe);VHo=r(Aut,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Aut.forEach(t),XHo=i(o6),ad=n(o6,"P",{});var WZ=s(ad);zHo=r(WZ,`Note:
Loading a model from its configuration file does `),Xpe=n(WZ,"STRONG",{});var yut=s(Xpe);WHo=r(yut,"not"),yut.forEach(t),QHo=r(WZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),AX=n(WZ,"A",{href:!0});var Lut=s(AX);HHo=r(Lut,"from_pretrained()"),Lut.forEach(t),UHo=r(WZ," to load the model weights."),WZ.forEach(t),JHo=i(o6),T(n3.$$.fragment,o6),o6.forEach(t),YHo=i(Zs),so=n(Zs,"DIV",{class:!0});var fa=s(so);T(tL.$$.fragment,fa),KHo=i(fa),zpe=n(fa,"P",{});var xut=s(zpe);ZHo=r(xut,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),xut.forEach(t),eUo=i(fa),qa=n(fa,"P",{});var r6=s(qa);oUo=r(r6,"The model class to instantiate is selected based on the "),Wpe=n(r6,"CODE",{});var $ut=s(Wpe);rUo=r($ut,"model_type"),$ut.forEach(t),tUo=r(r6,` property of the config object (either
passed as an argument or loaded from `),Qpe=n(r6,"CODE",{});var kut=s(Qpe);aUo=r(kut,"pretrained_model_name_or_path"),kut.forEach(t),nUo=r(r6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hpe=n(r6,"CODE",{});var Sut=s(Hpe);sUo=r(Sut,"pretrained_model_name_or_path"),Sut.forEach(t),lUo=r(r6,":"),r6.forEach(t),iUo=i(fa),Upe=n(fa,"UL",{});var Rut=s(Upe);s3=n(Rut,"LI",{});var bke=s(s3);Jpe=n(bke,"STRONG",{});var Put=s(Jpe);dUo=r(Put,"tapas"),Put.forEach(t),cUo=r(bke," \u2014 "),yX=n(bke,"A",{href:!0});var But=s(yX);fUo=r(But,"TapasForQuestionAnswering"),But.forEach(t),mUo=r(bke," (TAPAS model)"),bke.forEach(t),Rut.forEach(t),gUo=i(fa),l3=n(fa,"P",{});var vke=s(l3);hUo=r(vke,"The model is set in evaluation mode by default using "),Ype=n(vke,"CODE",{});var Iut=s(Ype);pUo=r(Iut,"model.eval()"),Iut.forEach(t),_Uo=r(vke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kpe=n(vke,"CODE",{});var Nut=s(Kpe);uUo=r(Nut,"model.train()"),Nut.forEach(t),vke.forEach(t),bUo=i(fa),T(i3.$$.fragment,fa),fa.forEach(t),Zs.forEach(t),Jqe=i(f),nd=n(f,"H2",{class:!0});var eGe=s(nd);d3=n(eGe,"A",{id:!0,class:!0,href:!0});var qut=s(d3);Zpe=n(qut,"SPAN",{});var jut=s(Zpe);T(aL.$$.fragment,jut),jut.forEach(t),qut.forEach(t),vUo=i(eGe),e_e=n(eGe,"SPAN",{});var Dut=s(e_e);FUo=r(Dut,"AutoModelForImageClassification"),Dut.forEach(t),eGe.forEach(t),Yqe=i(f),jo=n(f,"DIV",{class:!0});var el=s(jo);T(nL.$$.fragment,el),TUo=i(el),sd=n(el,"P",{});var QZ=s(sd);MUo=r(QZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),LX=n(QZ,"A",{href:!0});var Gut=s(LX);EUo=r(Gut,"from_pretrained()"),Gut.forEach(t),CUo=r(QZ," class method or the "),xX=n(QZ,"A",{href:!0});var Out=s(xX);wUo=r(Out,"from_config()"),Out.forEach(t),AUo=r(QZ,` class
method.`),QZ.forEach(t),yUo=i(el),sL=n(el,"P",{});var oGe=s(sL);LUo=r(oGe,"This class cannot be instantiated directly using "),o_e=n(oGe,"CODE",{});var Vut=s(o_e);xUo=r(Vut,"__init__()"),Vut.forEach(t),$Uo=r(oGe," (throws an error)."),oGe.forEach(t),kUo=i(el),ht=n(el,"DIV",{class:!0});var t6=s(ht);T(lL.$$.fragment,t6),SUo=i(t6),r_e=n(t6,"P",{});var Xut=s(r_e);RUo=r(Xut,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Xut.forEach(t),PUo=i(t6),ld=n(t6,"P",{});var HZ=s(ld);BUo=r(HZ,`Note:
Loading a model from its configuration file does `),t_e=n(HZ,"STRONG",{});var zut=s(t_e);IUo=r(zut,"not"),zut.forEach(t),NUo=r(HZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),$X=n(HZ,"A",{href:!0});var Wut=s($X);qUo=r(Wut,"from_pretrained()"),Wut.forEach(t),jUo=r(HZ," to load the model weights."),HZ.forEach(t),DUo=i(t6),T(c3.$$.fragment,t6),t6.forEach(t),GUo=i(el),lo=n(el,"DIV",{class:!0});var ma=s(lo);T(iL.$$.fragment,ma),OUo=i(ma),a_e=n(ma,"P",{});var Qut=s(a_e);VUo=r(Qut,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Qut.forEach(t),XUo=i(ma),ja=n(ma,"P",{});var a6=s(ja);zUo=r(a6,"The model class to instantiate is selected based on the "),n_e=n(a6,"CODE",{});var Hut=s(n_e);WUo=r(Hut,"model_type"),Hut.forEach(t),QUo=r(a6,` property of the config object (either
passed as an argument or loaded from `),s_e=n(a6,"CODE",{});var Uut=s(s_e);HUo=r(Uut,"pretrained_model_name_or_path"),Uut.forEach(t),UUo=r(a6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l_e=n(a6,"CODE",{});var Jut=s(l_e);JUo=r(Jut,"pretrained_model_name_or_path"),Jut.forEach(t),YUo=r(a6,":"),a6.forEach(t),KUo=i(ma),Fe=n(ma,"UL",{});var Te=s(Fe);f3=n(Te,"LI",{});var Fke=s(f3);i_e=n(Fke,"STRONG",{});var Yut=s(i_e);ZUo=r(Yut,"beit"),Yut.forEach(t),eJo=r(Fke," \u2014 "),kX=n(Fke,"A",{href:!0});var Kut=s(kX);oJo=r(Kut,"BeitForImageClassification"),Kut.forEach(t),rJo=r(Fke," (BEiT model)"),Fke.forEach(t),tJo=i(Te),m3=n(Te,"LI",{});var Tke=s(m3);d_e=n(Tke,"STRONG",{});var Zut=s(d_e);aJo=r(Zut,"convnext"),Zut.forEach(t),nJo=r(Tke," \u2014 "),SX=n(Tke,"A",{href:!0});var e4t=s(SX);sJo=r(e4t,"ConvNextForImageClassification"),e4t.forEach(t),lJo=r(Tke," (ConvNext model)"),Tke.forEach(t),iJo=i(Te),g3=n(Te,"LI",{});var Mke=s(g3);c_e=n(Mke,"STRONG",{});var o4t=s(c_e);dJo=r(o4t,"cvt"),o4t.forEach(t),cJo=r(Mke," \u2014 "),RX=n(Mke,"A",{href:!0});var r4t=s(RX);fJo=r(r4t,"CvtForImageClassification"),r4t.forEach(t),mJo=r(Mke," (CvT model)"),Mke.forEach(t),gJo=i(Te),h3=n(Te,"LI",{});var Eke=s(h3);f_e=n(Eke,"STRONG",{});var t4t=s(f_e);hJo=r(t4t,"data2vec-vision"),t4t.forEach(t),pJo=r(Eke," \u2014 "),PX=n(Eke,"A",{href:!0});var a4t=s(PX);_Jo=r(a4t,"Data2VecVisionForImageClassification"),a4t.forEach(t),uJo=r(Eke," (Data2VecVision model)"),Eke.forEach(t),bJo=i(Te),Is=n(Te,"LI",{});var H$=s(Is);m_e=n(H$,"STRONG",{});var n4t=s(m_e);vJo=r(n4t,"deit"),n4t.forEach(t),FJo=r(H$," \u2014 "),BX=n(H$,"A",{href:!0});var s4t=s(BX);TJo=r(s4t,"DeiTForImageClassification"),s4t.forEach(t),MJo=r(H$," or "),IX=n(H$,"A",{href:!0});var l4t=s(IX);EJo=r(l4t,"DeiTForImageClassificationWithTeacher"),l4t.forEach(t),CJo=r(H$," (DeiT model)"),H$.forEach(t),wJo=i(Te),p3=n(Te,"LI",{});var Cke=s(p3);g_e=n(Cke,"STRONG",{});var i4t=s(g_e);AJo=r(i4t,"imagegpt"),i4t.forEach(t),yJo=r(Cke," \u2014 "),NX=n(Cke,"A",{href:!0});var d4t=s(NX);LJo=r(d4t,"ImageGPTForImageClassification"),d4t.forEach(t),xJo=r(Cke," (ImageGPT model)"),Cke.forEach(t),$Jo=i(Te),pt=n(Te,"LI",{});var pf=s(pt);h_e=n(pf,"STRONG",{});var c4t=s(h_e);kJo=r(c4t,"perceiver"),c4t.forEach(t),SJo=r(pf," \u2014 "),qX=n(pf,"A",{href:!0});var f4t=s(qX);RJo=r(f4t,"PerceiverForImageClassificationLearned"),f4t.forEach(t),PJo=r(pf," or "),jX=n(pf,"A",{href:!0});var m4t=s(jX);BJo=r(m4t,"PerceiverForImageClassificationFourier"),m4t.forEach(t),IJo=r(pf," or "),DX=n(pf,"A",{href:!0});var g4t=s(DX);NJo=r(g4t,"PerceiverForImageClassificationConvProcessing"),g4t.forEach(t),qJo=r(pf," (Perceiver model)"),pf.forEach(t),jJo=i(Te),_3=n(Te,"LI",{});var wke=s(_3);p_e=n(wke,"STRONG",{});var h4t=s(p_e);DJo=r(h4t,"poolformer"),h4t.forEach(t),GJo=r(wke," \u2014 "),GX=n(wke,"A",{href:!0});var p4t=s(GX);OJo=r(p4t,"PoolFormerForImageClassification"),p4t.forEach(t),VJo=r(wke," (PoolFormer model)"),wke.forEach(t),XJo=i(Te),u3=n(Te,"LI",{});var Ake=s(u3);__e=n(Ake,"STRONG",{});var _4t=s(__e);zJo=r(_4t,"regnet"),_4t.forEach(t),WJo=r(Ake," \u2014 "),OX=n(Ake,"A",{href:!0});var u4t=s(OX);QJo=r(u4t,"RegNetForImageClassification"),u4t.forEach(t),HJo=r(Ake," (RegNet model)"),Ake.forEach(t),UJo=i(Te),b3=n(Te,"LI",{});var yke=s(b3);u_e=n(yke,"STRONG",{});var b4t=s(u_e);JJo=r(b4t,"resnet"),b4t.forEach(t),YJo=r(yke," \u2014 "),VX=n(yke,"A",{href:!0});var v4t=s(VX);KJo=r(v4t,"ResNetForImageClassification"),v4t.forEach(t),ZJo=r(yke," (ResNet model)"),yke.forEach(t),eYo=i(Te),v3=n(Te,"LI",{});var Lke=s(v3);b_e=n(Lke,"STRONG",{});var F4t=s(b_e);oYo=r(F4t,"segformer"),F4t.forEach(t),rYo=r(Lke," \u2014 "),XX=n(Lke,"A",{href:!0});var T4t=s(XX);tYo=r(T4t,"SegformerForImageClassification"),T4t.forEach(t),aYo=r(Lke," (SegFormer model)"),Lke.forEach(t),nYo=i(Te),F3=n(Te,"LI",{});var xke=s(F3);v_e=n(xke,"STRONG",{});var M4t=s(v_e);sYo=r(M4t,"swin"),M4t.forEach(t),lYo=r(xke," \u2014 "),zX=n(xke,"A",{href:!0});var E4t=s(zX);iYo=r(E4t,"SwinForImageClassification"),E4t.forEach(t),dYo=r(xke," (Swin model)"),xke.forEach(t),cYo=i(Te),T3=n(Te,"LI",{});var $ke=s(T3);F_e=n($ke,"STRONG",{});var C4t=s(F_e);fYo=r(C4t,"van"),C4t.forEach(t),mYo=r($ke," \u2014 "),WX=n($ke,"A",{href:!0});var w4t=s(WX);gYo=r(w4t,"VanForImageClassification"),w4t.forEach(t),hYo=r($ke," (VAN model)"),$ke.forEach(t),pYo=i(Te),M3=n(Te,"LI",{});var kke=s(M3);T_e=n(kke,"STRONG",{});var A4t=s(T_e);_Yo=r(A4t,"vit"),A4t.forEach(t),uYo=r(kke," \u2014 "),QX=n(kke,"A",{href:!0});var y4t=s(QX);bYo=r(y4t,"ViTForImageClassification"),y4t.forEach(t),vYo=r(kke," (ViT model)"),kke.forEach(t),Te.forEach(t),FYo=i(ma),E3=n(ma,"P",{});var Ske=s(E3);TYo=r(Ske,"The model is set in evaluation mode by default using "),M_e=n(Ske,"CODE",{});var L4t=s(M_e);MYo=r(L4t,"model.eval()"),L4t.forEach(t),EYo=r(Ske,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E_e=n(Ske,"CODE",{});var x4t=s(E_e);CYo=r(x4t,"model.train()"),x4t.forEach(t),Ske.forEach(t),wYo=i(ma),T(C3.$$.fragment,ma),ma.forEach(t),el.forEach(t),Kqe=i(f),id=n(f,"H2",{class:!0});var rGe=s(id);w3=n(rGe,"A",{id:!0,class:!0,href:!0});var $4t=s(w3);C_e=n($4t,"SPAN",{});var k4t=s(C_e);T(dL.$$.fragment,k4t),k4t.forEach(t),$4t.forEach(t),AYo=i(rGe),w_e=n(rGe,"SPAN",{});var S4t=s(w_e);yYo=r(S4t,"AutoModelForVision2Seq"),S4t.forEach(t),rGe.forEach(t),Zqe=i(f),Do=n(f,"DIV",{class:!0});var ol=s(Do);T(cL.$$.fragment,ol),LYo=i(ol),dd=n(ol,"P",{});var UZ=s(dd);xYo=r(UZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),HX=n(UZ,"A",{href:!0});var R4t=s(HX);$Yo=r(R4t,"from_pretrained()"),R4t.forEach(t),kYo=r(UZ," class method or the "),UX=n(UZ,"A",{href:!0});var P4t=s(UX);SYo=r(P4t,"from_config()"),P4t.forEach(t),RYo=r(UZ,` class
method.`),UZ.forEach(t),PYo=i(ol),fL=n(ol,"P",{});var tGe=s(fL);BYo=r(tGe,"This class cannot be instantiated directly using "),A_e=n(tGe,"CODE",{});var B4t=s(A_e);IYo=r(B4t,"__init__()"),B4t.forEach(t),NYo=r(tGe," (throws an error)."),tGe.forEach(t),qYo=i(ol),_t=n(ol,"DIV",{class:!0});var n6=s(_t);T(mL.$$.fragment,n6),jYo=i(n6),y_e=n(n6,"P",{});var I4t=s(y_e);DYo=r(I4t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),I4t.forEach(t),GYo=i(n6),cd=n(n6,"P",{});var JZ=s(cd);OYo=r(JZ,`Note:
Loading a model from its configuration file does `),L_e=n(JZ,"STRONG",{});var N4t=s(L_e);VYo=r(N4t,"not"),N4t.forEach(t),XYo=r(JZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=n(JZ,"A",{href:!0});var q4t=s(JX);zYo=r(q4t,"from_pretrained()"),q4t.forEach(t),WYo=r(JZ," to load the model weights."),JZ.forEach(t),QYo=i(n6),T(A3.$$.fragment,n6),n6.forEach(t),HYo=i(ol),io=n(ol,"DIV",{class:!0});var ga=s(io);T(gL.$$.fragment,ga),UYo=i(ga),x_e=n(ga,"P",{});var j4t=s(x_e);JYo=r(j4t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),j4t.forEach(t),YYo=i(ga),Da=n(ga,"P",{});var s6=s(Da);KYo=r(s6,"The model class to instantiate is selected based on the "),$_e=n(s6,"CODE",{});var D4t=s($_e);ZYo=r(D4t,"model_type"),D4t.forEach(t),eKo=r(s6,` property of the config object (either
passed as an argument or loaded from `),k_e=n(s6,"CODE",{});var G4t=s(k_e);oKo=r(G4t,"pretrained_model_name_or_path"),G4t.forEach(t),rKo=r(s6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S_e=n(s6,"CODE",{});var O4t=s(S_e);tKo=r(O4t,"pretrained_model_name_or_path"),O4t.forEach(t),aKo=r(s6,":"),s6.forEach(t),nKo=i(ga),R_e=n(ga,"UL",{});var V4t=s(R_e);y3=n(V4t,"LI",{});var Rke=s(y3);P_e=n(Rke,"STRONG",{});var X4t=s(P_e);sKo=r(X4t,"vision-encoder-decoder"),X4t.forEach(t),lKo=r(Rke," \u2014 "),YX=n(Rke,"A",{href:!0});var z4t=s(YX);iKo=r(z4t,"VisionEncoderDecoderModel"),z4t.forEach(t),dKo=r(Rke," (Vision Encoder decoder model)"),Rke.forEach(t),V4t.forEach(t),cKo=i(ga),L3=n(ga,"P",{});var Pke=s(L3);fKo=r(Pke,"The model is set in evaluation mode by default using "),B_e=n(Pke,"CODE",{});var W4t=s(B_e);mKo=r(W4t,"model.eval()"),W4t.forEach(t),gKo=r(Pke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I_e=n(Pke,"CODE",{});var Q4t=s(I_e);hKo=r(Q4t,"model.train()"),Q4t.forEach(t),Pke.forEach(t),pKo=i(ga),T(x3.$$.fragment,ga),ga.forEach(t),ol.forEach(t),eje=i(f),fd=n(f,"H2",{class:!0});var aGe=s(fd);$3=n(aGe,"A",{id:!0,class:!0,href:!0});var H4t=s($3);N_e=n(H4t,"SPAN",{});var U4t=s(N_e);T(hL.$$.fragment,U4t),U4t.forEach(t),H4t.forEach(t),_Ko=i(aGe),q_e=n(aGe,"SPAN",{});var J4t=s(q_e);uKo=r(J4t,"AutoModelForAudioClassification"),J4t.forEach(t),aGe.forEach(t),oje=i(f),Go=n(f,"DIV",{class:!0});var rl=s(Go);T(pL.$$.fragment,rl),bKo=i(rl),md=n(rl,"P",{});var YZ=s(md);vKo=r(YZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),KX=n(YZ,"A",{href:!0});var Y4t=s(KX);FKo=r(Y4t,"from_pretrained()"),Y4t.forEach(t),TKo=r(YZ," class method or the "),ZX=n(YZ,"A",{href:!0});var K4t=s(ZX);MKo=r(K4t,"from_config()"),K4t.forEach(t),EKo=r(YZ,` class
method.`),YZ.forEach(t),CKo=i(rl),_L=n(rl,"P",{});var nGe=s(_L);wKo=r(nGe,"This class cannot be instantiated directly using "),j_e=n(nGe,"CODE",{});var Z4t=s(j_e);AKo=r(Z4t,"__init__()"),Z4t.forEach(t),yKo=r(nGe," (throws an error)."),nGe.forEach(t),LKo=i(rl),ut=n(rl,"DIV",{class:!0});var l6=s(ut);T(uL.$$.fragment,l6),xKo=i(l6),D_e=n(l6,"P",{});var e1t=s(D_e);$Ko=r(e1t,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),e1t.forEach(t),kKo=i(l6),gd=n(l6,"P",{});var KZ=s(gd);SKo=r(KZ,`Note:
Loading a model from its configuration file does `),G_e=n(KZ,"STRONG",{});var o1t=s(G_e);RKo=r(o1t,"not"),o1t.forEach(t),PKo=r(KZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),ez=n(KZ,"A",{href:!0});var r1t=s(ez);BKo=r(r1t,"from_pretrained()"),r1t.forEach(t),IKo=r(KZ," to load the model weights."),KZ.forEach(t),NKo=i(l6),T(k3.$$.fragment,l6),l6.forEach(t),qKo=i(rl),co=n(rl,"DIV",{class:!0});var ha=s(co);T(bL.$$.fragment,ha),jKo=i(ha),O_e=n(ha,"P",{});var t1t=s(O_e);DKo=r(t1t,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),t1t.forEach(t),GKo=i(ha),Ga=n(ha,"P",{});var i6=s(Ga);OKo=r(i6,"The model class to instantiate is selected based on the "),V_e=n(i6,"CODE",{});var a1t=s(V_e);VKo=r(a1t,"model_type"),a1t.forEach(t),XKo=r(i6,` property of the config object (either
passed as an argument or loaded from `),X_e=n(i6,"CODE",{});var n1t=s(X_e);zKo=r(n1t,"pretrained_model_name_or_path"),n1t.forEach(t),WKo=r(i6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z_e=n(i6,"CODE",{});var s1t=s(z_e);QKo=r(s1t,"pretrained_model_name_or_path"),s1t.forEach(t),HKo=r(i6,":"),i6.forEach(t),UKo=i(ha),ke=n(ha,"UL",{});var Oe=s(ke);S3=n(Oe,"LI",{});var Bke=s(S3);W_e=n(Bke,"STRONG",{});var l1t=s(W_e);JKo=r(l1t,"data2vec-audio"),l1t.forEach(t),YKo=r(Bke," \u2014 "),oz=n(Bke,"A",{href:!0});var i1t=s(oz);KKo=r(i1t,"Data2VecAudioForSequenceClassification"),i1t.forEach(t),ZKo=r(Bke," (Data2VecAudio model)"),Bke.forEach(t),eZo=i(Oe),R3=n(Oe,"LI",{});var Ike=s(R3);Q_e=n(Ike,"STRONG",{});var d1t=s(Q_e);oZo=r(d1t,"hubert"),d1t.forEach(t),rZo=r(Ike," \u2014 "),rz=n(Ike,"A",{href:!0});var c1t=s(rz);tZo=r(c1t,"HubertForSequenceClassification"),c1t.forEach(t),aZo=r(Ike," (Hubert model)"),Ike.forEach(t),nZo=i(Oe),P3=n(Oe,"LI",{});var Nke=s(P3);H_e=n(Nke,"STRONG",{});var f1t=s(H_e);sZo=r(f1t,"sew"),f1t.forEach(t),lZo=r(Nke," \u2014 "),tz=n(Nke,"A",{href:!0});var m1t=s(tz);iZo=r(m1t,"SEWForSequenceClassification"),m1t.forEach(t),dZo=r(Nke," (SEW model)"),Nke.forEach(t),cZo=i(Oe),B3=n(Oe,"LI",{});var qke=s(B3);U_e=n(qke,"STRONG",{});var g1t=s(U_e);fZo=r(g1t,"sew-d"),g1t.forEach(t),mZo=r(qke," \u2014 "),az=n(qke,"A",{href:!0});var h1t=s(az);gZo=r(h1t,"SEWDForSequenceClassification"),h1t.forEach(t),hZo=r(qke," (SEW-D model)"),qke.forEach(t),pZo=i(Oe),I3=n(Oe,"LI",{});var jke=s(I3);J_e=n(jke,"STRONG",{});var p1t=s(J_e);_Zo=r(p1t,"unispeech"),p1t.forEach(t),uZo=r(jke," \u2014 "),nz=n(jke,"A",{href:!0});var _1t=s(nz);bZo=r(_1t,"UniSpeechForSequenceClassification"),_1t.forEach(t),vZo=r(jke," (UniSpeech model)"),jke.forEach(t),FZo=i(Oe),N3=n(Oe,"LI",{});var Dke=s(N3);Y_e=n(Dke,"STRONG",{});var u1t=s(Y_e);TZo=r(u1t,"unispeech-sat"),u1t.forEach(t),MZo=r(Dke," \u2014 "),sz=n(Dke,"A",{href:!0});var b1t=s(sz);EZo=r(b1t,"UniSpeechSatForSequenceClassification"),b1t.forEach(t),CZo=r(Dke," (UniSpeechSat model)"),Dke.forEach(t),wZo=i(Oe),q3=n(Oe,"LI",{});var Gke=s(q3);K_e=n(Gke,"STRONG",{});var v1t=s(K_e);AZo=r(v1t,"wav2vec2"),v1t.forEach(t),yZo=r(Gke," \u2014 "),lz=n(Gke,"A",{href:!0});var F1t=s(lz);LZo=r(F1t,"Wav2Vec2ForSequenceClassification"),F1t.forEach(t),xZo=r(Gke," (Wav2Vec2 model)"),Gke.forEach(t),$Zo=i(Oe),j3=n(Oe,"LI",{});var Oke=s(j3);Z_e=n(Oke,"STRONG",{});var T1t=s(Z_e);kZo=r(T1t,"wav2vec2-conformer"),T1t.forEach(t),SZo=r(Oke," \u2014 "),iz=n(Oke,"A",{href:!0});var M1t=s(iz);RZo=r(M1t,"Wav2Vec2ConformerForSequenceClassification"),M1t.forEach(t),PZo=r(Oke," (Wav2Vec2-Conformer model)"),Oke.forEach(t),BZo=i(Oe),D3=n(Oe,"LI",{});var Vke=s(D3);eue=n(Vke,"STRONG",{});var E1t=s(eue);IZo=r(E1t,"wavlm"),E1t.forEach(t),NZo=r(Vke," \u2014 "),dz=n(Vke,"A",{href:!0});var C1t=s(dz);qZo=r(C1t,"WavLMForSequenceClassification"),C1t.forEach(t),jZo=r(Vke," (WavLM model)"),Vke.forEach(t),Oe.forEach(t),DZo=i(ha),G3=n(ha,"P",{});var Xke=s(G3);GZo=r(Xke,"The model is set in evaluation mode by default using "),oue=n(Xke,"CODE",{});var w1t=s(oue);OZo=r(w1t,"model.eval()"),w1t.forEach(t),VZo=r(Xke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rue=n(Xke,"CODE",{});var A1t=s(rue);XZo=r(A1t,"model.train()"),A1t.forEach(t),Xke.forEach(t),zZo=i(ha),T(O3.$$.fragment,ha),ha.forEach(t),rl.forEach(t),rje=i(f),hd=n(f,"H2",{class:!0});var sGe=s(hd);V3=n(sGe,"A",{id:!0,class:!0,href:!0});var y1t=s(V3);tue=n(y1t,"SPAN",{});var L1t=s(tue);T(vL.$$.fragment,L1t),L1t.forEach(t),y1t.forEach(t),WZo=i(sGe),aue=n(sGe,"SPAN",{});var x1t=s(aue);QZo=r(x1t,"AutoModelForAudioFrameClassification"),x1t.forEach(t),sGe.forEach(t),tje=i(f),Oo=n(f,"DIV",{class:!0});var tl=s(Oo);T(FL.$$.fragment,tl),HZo=i(tl),pd=n(tl,"P",{});var ZZ=s(pd);UZo=r(ZZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),cz=n(ZZ,"A",{href:!0});var $1t=s(cz);JZo=r($1t,"from_pretrained()"),$1t.forEach(t),YZo=r(ZZ," class method or the "),fz=n(ZZ,"A",{href:!0});var k1t=s(fz);KZo=r(k1t,"from_config()"),k1t.forEach(t),ZZo=r(ZZ,` class
method.`),ZZ.forEach(t),eer=i(tl),TL=n(tl,"P",{});var lGe=s(TL);oer=r(lGe,"This class cannot be instantiated directly using "),nue=n(lGe,"CODE",{});var S1t=s(nue);rer=r(S1t,"__init__()"),S1t.forEach(t),ter=r(lGe," (throws an error)."),lGe.forEach(t),aer=i(tl),bt=n(tl,"DIV",{class:!0});var d6=s(bt);T(ML.$$.fragment,d6),ner=i(d6),sue=n(d6,"P",{});var R1t=s(sue);ser=r(R1t,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),R1t.forEach(t),ler=i(d6),_d=n(d6,"P",{});var eee=s(_d);ier=r(eee,`Note:
Loading a model from its configuration file does `),lue=n(eee,"STRONG",{});var P1t=s(lue);der=r(P1t,"not"),P1t.forEach(t),cer=r(eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),mz=n(eee,"A",{href:!0});var B1t=s(mz);fer=r(B1t,"from_pretrained()"),B1t.forEach(t),mer=r(eee," to load the model weights."),eee.forEach(t),ger=i(d6),T(X3.$$.fragment,d6),d6.forEach(t),her=i(tl),fo=n(tl,"DIV",{class:!0});var pa=s(fo);T(EL.$$.fragment,pa),per=i(pa),iue=n(pa,"P",{});var I1t=s(iue);_er=r(I1t,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),I1t.forEach(t),uer=i(pa),Oa=n(pa,"P",{});var c6=s(Oa);ber=r(c6,"The model class to instantiate is selected based on the "),due=n(c6,"CODE",{});var N1t=s(due);ver=r(N1t,"model_type"),N1t.forEach(t),Fer=r(c6,` property of the config object (either
passed as an argument or loaded from `),cue=n(c6,"CODE",{});var q1t=s(cue);Ter=r(q1t,"pretrained_model_name_or_path"),q1t.forEach(t),Mer=r(c6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fue=n(c6,"CODE",{});var j1t=s(fue);Eer=r(j1t,"pretrained_model_name_or_path"),j1t.forEach(t),Cer=r(c6,":"),c6.forEach(t),wer=i(pa),Kr=n(pa,"UL",{});var al=s(Kr);z3=n(al,"LI",{});var zke=s(z3);mue=n(zke,"STRONG",{});var D1t=s(mue);Aer=r(D1t,"data2vec-audio"),D1t.forEach(t),yer=r(zke," \u2014 "),gz=n(zke,"A",{href:!0});var G1t=s(gz);Ler=r(G1t,"Data2VecAudioForAudioFrameClassification"),G1t.forEach(t),xer=r(zke," (Data2VecAudio model)"),zke.forEach(t),$er=i(al),W3=n(al,"LI",{});var Wke=s(W3);gue=n(Wke,"STRONG",{});var O1t=s(gue);ker=r(O1t,"unispeech-sat"),O1t.forEach(t),Ser=r(Wke," \u2014 "),hz=n(Wke,"A",{href:!0});var V1t=s(hz);Rer=r(V1t,"UniSpeechSatForAudioFrameClassification"),V1t.forEach(t),Per=r(Wke," (UniSpeechSat model)"),Wke.forEach(t),Ber=i(al),Q3=n(al,"LI",{});var Qke=s(Q3);hue=n(Qke,"STRONG",{});var X1t=s(hue);Ier=r(X1t,"wav2vec2"),X1t.forEach(t),Ner=r(Qke," \u2014 "),pz=n(Qke,"A",{href:!0});var z1t=s(pz);qer=r(z1t,"Wav2Vec2ForAudioFrameClassification"),z1t.forEach(t),jer=r(Qke," (Wav2Vec2 model)"),Qke.forEach(t),Der=i(al),H3=n(al,"LI",{});var Hke=s(H3);pue=n(Hke,"STRONG",{});var W1t=s(pue);Ger=r(W1t,"wav2vec2-conformer"),W1t.forEach(t),Oer=r(Hke," \u2014 "),_z=n(Hke,"A",{href:!0});var Q1t=s(_z);Ver=r(Q1t,"Wav2Vec2ConformerForAudioFrameClassification"),Q1t.forEach(t),Xer=r(Hke," (Wav2Vec2-Conformer model)"),Hke.forEach(t),zer=i(al),U3=n(al,"LI",{});var Uke=s(U3);_ue=n(Uke,"STRONG",{});var H1t=s(_ue);Wer=r(H1t,"wavlm"),H1t.forEach(t),Qer=r(Uke," \u2014 "),uz=n(Uke,"A",{href:!0});var U1t=s(uz);Her=r(U1t,"WavLMForAudioFrameClassification"),U1t.forEach(t),Uer=r(Uke," (WavLM model)"),Uke.forEach(t),al.forEach(t),Jer=i(pa),J3=n(pa,"P",{});var Jke=s(J3);Yer=r(Jke,"The model is set in evaluation mode by default using "),uue=n(Jke,"CODE",{});var J1t=s(uue);Ker=r(J1t,"model.eval()"),J1t.forEach(t),Zer=r(Jke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bue=n(Jke,"CODE",{});var Y1t=s(bue);eor=r(Y1t,"model.train()"),Y1t.forEach(t),Jke.forEach(t),oor=i(pa),T(Y3.$$.fragment,pa),pa.forEach(t),tl.forEach(t),aje=i(f),ud=n(f,"H2",{class:!0});var iGe=s(ud);K3=n(iGe,"A",{id:!0,class:!0,href:!0});var K1t=s(K3);vue=n(K1t,"SPAN",{});var Z1t=s(vue);T(CL.$$.fragment,Z1t),Z1t.forEach(t),K1t.forEach(t),ror=i(iGe),Fue=n(iGe,"SPAN",{});var ebt=s(Fue);tor=r(ebt,"AutoModelForCTC"),ebt.forEach(t),iGe.forEach(t),nje=i(f),Vo=n(f,"DIV",{class:!0});var nl=s(Vo);T(wL.$$.fragment,nl),aor=i(nl),bd=n(nl,"P",{});var oee=s(bd);nor=r(oee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),bz=n(oee,"A",{href:!0});var obt=s(bz);sor=r(obt,"from_pretrained()"),obt.forEach(t),lor=r(oee," class method or the "),vz=n(oee,"A",{href:!0});var rbt=s(vz);ior=r(rbt,"from_config()"),rbt.forEach(t),dor=r(oee,` class
method.`),oee.forEach(t),cor=i(nl),AL=n(nl,"P",{});var dGe=s(AL);mor=r(dGe,"This class cannot be instantiated directly using "),Tue=n(dGe,"CODE",{});var tbt=s(Tue);gor=r(tbt,"__init__()"),tbt.forEach(t),hor=r(dGe," (throws an error)."),dGe.forEach(t),por=i(nl),vt=n(nl,"DIV",{class:!0});var f6=s(vt);T(yL.$$.fragment,f6),_or=i(f6),Mue=n(f6,"P",{});var abt=s(Mue);uor=r(abt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),abt.forEach(t),bor=i(f6),vd=n(f6,"P",{});var ree=s(vd);vor=r(ree,`Note:
Loading a model from its configuration file does `),Eue=n(ree,"STRONG",{});var nbt=s(Eue);For=r(nbt,"not"),nbt.forEach(t),Tor=r(ree,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=n(ree,"A",{href:!0});var sbt=s(Fz);Mor=r(sbt,"from_pretrained()"),sbt.forEach(t),Eor=r(ree," to load the model weights."),ree.forEach(t),Cor=i(f6),T(Z3.$$.fragment,f6),f6.forEach(t),wor=i(nl),mo=n(nl,"DIV",{class:!0});var _a=s(mo);T(LL.$$.fragment,_a),Aor=i(_a),Cue=n(_a,"P",{});var lbt=s(Cue);yor=r(lbt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),lbt.forEach(t),Lor=i(_a),Va=n(_a,"P",{});var m6=s(Va);xor=r(m6,"The model class to instantiate is selected based on the "),wue=n(m6,"CODE",{});var ibt=s(wue);$or=r(ibt,"model_type"),ibt.forEach(t),kor=r(m6,` property of the config object (either
passed as an argument or loaded from `),Aue=n(m6,"CODE",{});var dbt=s(Aue);Sor=r(dbt,"pretrained_model_name_or_path"),dbt.forEach(t),Ror=r(m6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yue=n(m6,"CODE",{});var cbt=s(yue);Por=r(cbt,"pretrained_model_name_or_path"),cbt.forEach(t),Bor=r(m6,":"),m6.forEach(t),Ior=i(_a),Se=n(_a,"UL",{});var Ve=s(Se);eF=n(Ve,"LI",{});var Yke=s(eF);Lue=n(Yke,"STRONG",{});var fbt=s(Lue);Nor=r(fbt,"data2vec-audio"),fbt.forEach(t),qor=r(Yke," \u2014 "),Tz=n(Yke,"A",{href:!0});var mbt=s(Tz);jor=r(mbt,"Data2VecAudioForCTC"),mbt.forEach(t),Dor=r(Yke," (Data2VecAudio model)"),Yke.forEach(t),Gor=i(Ve),oF=n(Ve,"LI",{});var Kke=s(oF);xue=n(Kke,"STRONG",{});var gbt=s(xue);Oor=r(gbt,"hubert"),gbt.forEach(t),Vor=r(Kke," \u2014 "),Mz=n(Kke,"A",{href:!0});var hbt=s(Mz);Xor=r(hbt,"HubertForCTC"),hbt.forEach(t),zor=r(Kke," (Hubert model)"),Kke.forEach(t),Wor=i(Ve),rF=n(Ve,"LI",{});var Zke=s(rF);$ue=n(Zke,"STRONG",{});var pbt=s($ue);Qor=r(pbt,"sew"),pbt.forEach(t),Hor=r(Zke," \u2014 "),Ez=n(Zke,"A",{href:!0});var _bt=s(Ez);Uor=r(_bt,"SEWForCTC"),_bt.forEach(t),Jor=r(Zke," (SEW model)"),Zke.forEach(t),Yor=i(Ve),tF=n(Ve,"LI",{});var eSe=s(tF);kue=n(eSe,"STRONG",{});var ubt=s(kue);Kor=r(ubt,"sew-d"),ubt.forEach(t),Zor=r(eSe," \u2014 "),Cz=n(eSe,"A",{href:!0});var bbt=s(Cz);err=r(bbt,"SEWDForCTC"),bbt.forEach(t),orr=r(eSe," (SEW-D model)"),eSe.forEach(t),rrr=i(Ve),aF=n(Ve,"LI",{});var oSe=s(aF);Sue=n(oSe,"STRONG",{});var vbt=s(Sue);trr=r(vbt,"unispeech"),vbt.forEach(t),arr=r(oSe," \u2014 "),wz=n(oSe,"A",{href:!0});var Fbt=s(wz);nrr=r(Fbt,"UniSpeechForCTC"),Fbt.forEach(t),srr=r(oSe," (UniSpeech model)"),oSe.forEach(t),lrr=i(Ve),nF=n(Ve,"LI",{});var rSe=s(nF);Rue=n(rSe,"STRONG",{});var Tbt=s(Rue);irr=r(Tbt,"unispeech-sat"),Tbt.forEach(t),drr=r(rSe," \u2014 "),Az=n(rSe,"A",{href:!0});var Mbt=s(Az);crr=r(Mbt,"UniSpeechSatForCTC"),Mbt.forEach(t),frr=r(rSe," (UniSpeechSat model)"),rSe.forEach(t),mrr=i(Ve),sF=n(Ve,"LI",{});var tSe=s(sF);Pue=n(tSe,"STRONG",{});var Ebt=s(Pue);grr=r(Ebt,"wav2vec2"),Ebt.forEach(t),hrr=r(tSe," \u2014 "),yz=n(tSe,"A",{href:!0});var Cbt=s(yz);prr=r(Cbt,"Wav2Vec2ForCTC"),Cbt.forEach(t),_rr=r(tSe," (Wav2Vec2 model)"),tSe.forEach(t),urr=i(Ve),lF=n(Ve,"LI",{});var aSe=s(lF);Bue=n(aSe,"STRONG",{});var wbt=s(Bue);brr=r(wbt,"wav2vec2-conformer"),wbt.forEach(t),vrr=r(aSe," \u2014 "),Lz=n(aSe,"A",{href:!0});var Abt=s(Lz);Frr=r(Abt,"Wav2Vec2ConformerForCTC"),Abt.forEach(t),Trr=r(aSe," (Wav2Vec2-Conformer model)"),aSe.forEach(t),Mrr=i(Ve),iF=n(Ve,"LI",{});var nSe=s(iF);Iue=n(nSe,"STRONG",{});var ybt=s(Iue);Err=r(ybt,"wavlm"),ybt.forEach(t),Crr=r(nSe," \u2014 "),xz=n(nSe,"A",{href:!0});var Lbt=s(xz);wrr=r(Lbt,"WavLMForCTC"),Lbt.forEach(t),Arr=r(nSe," (WavLM model)"),nSe.forEach(t),Ve.forEach(t),yrr=i(_a),dF=n(_a,"P",{});var sSe=s(dF);Lrr=r(sSe,"The model is set in evaluation mode by default using "),Nue=n(sSe,"CODE",{});var xbt=s(Nue);xrr=r(xbt,"model.eval()"),xbt.forEach(t),$rr=r(sSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),que=n(sSe,"CODE",{});var $bt=s(que);krr=r($bt,"model.train()"),$bt.forEach(t),sSe.forEach(t),Srr=i(_a),T(cF.$$.fragment,_a),_a.forEach(t),nl.forEach(t),sje=i(f),Fd=n(f,"H2",{class:!0});var cGe=s(Fd);fF=n(cGe,"A",{id:!0,class:!0,href:!0});var kbt=s(fF);jue=n(kbt,"SPAN",{});var Sbt=s(jue);T(xL.$$.fragment,Sbt),Sbt.forEach(t),kbt.forEach(t),Rrr=i(cGe),Due=n(cGe,"SPAN",{});var Rbt=s(Due);Prr=r(Rbt,"AutoModelForSpeechSeq2Seq"),Rbt.forEach(t),cGe.forEach(t),lje=i(f),Xo=n(f,"DIV",{class:!0});var sl=s(Xo);T($L.$$.fragment,sl),Brr=i(sl),Td=n(sl,"P",{});var tee=s(Td);Irr=r(tee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$z=n(tee,"A",{href:!0});var Pbt=s($z);Nrr=r(Pbt,"from_pretrained()"),Pbt.forEach(t),qrr=r(tee," class method or the "),kz=n(tee,"A",{href:!0});var Bbt=s(kz);jrr=r(Bbt,"from_config()"),Bbt.forEach(t),Drr=r(tee,` class
method.`),tee.forEach(t),Grr=i(sl),kL=n(sl,"P",{});var fGe=s(kL);Orr=r(fGe,"This class cannot be instantiated directly using "),Gue=n(fGe,"CODE",{});var Ibt=s(Gue);Vrr=r(Ibt,"__init__()"),Ibt.forEach(t),Xrr=r(fGe," (throws an error)."),fGe.forEach(t),zrr=i(sl),Ft=n(sl,"DIV",{class:!0});var g6=s(Ft);T(SL.$$.fragment,g6),Wrr=i(g6),Oue=n(g6,"P",{});var Nbt=s(Oue);Qrr=r(Nbt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Nbt.forEach(t),Hrr=i(g6),Md=n(g6,"P",{});var aee=s(Md);Urr=r(aee,`Note:
Loading a model from its configuration file does `),Vue=n(aee,"STRONG",{});var qbt=s(Vue);Jrr=r(qbt,"not"),qbt.forEach(t),Yrr=r(aee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sz=n(aee,"A",{href:!0});var jbt=s(Sz);Krr=r(jbt,"from_pretrained()"),jbt.forEach(t),Zrr=r(aee," to load the model weights."),aee.forEach(t),etr=i(g6),T(mF.$$.fragment,g6),g6.forEach(t),otr=i(sl),go=n(sl,"DIV",{class:!0});var ua=s(go);T(RL.$$.fragment,ua),rtr=i(ua),Xue=n(ua,"P",{});var Dbt=s(Xue);ttr=r(Dbt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Dbt.forEach(t),atr=i(ua),Xa=n(ua,"P",{});var h6=s(Xa);ntr=r(h6,"The model class to instantiate is selected based on the "),zue=n(h6,"CODE",{});var Gbt=s(zue);str=r(Gbt,"model_type"),Gbt.forEach(t),ltr=r(h6,` property of the config object (either
passed as an argument or loaded from `),Wue=n(h6,"CODE",{});var Obt=s(Wue);itr=r(Obt,"pretrained_model_name_or_path"),Obt.forEach(t),dtr=r(h6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Que=n(h6,"CODE",{});var Vbt=s(Que);ctr=r(Vbt,"pretrained_model_name_or_path"),Vbt.forEach(t),ftr=r(h6,":"),h6.forEach(t),mtr=i(ua),PL=n(ua,"UL",{});var mGe=s(PL);gF=n(mGe,"LI",{});var lSe=s(gF);Hue=n(lSe,"STRONG",{});var Xbt=s(Hue);gtr=r(Xbt,"speech-encoder-decoder"),Xbt.forEach(t),htr=r(lSe," \u2014 "),Rz=n(lSe,"A",{href:!0});var zbt=s(Rz);ptr=r(zbt,"SpeechEncoderDecoderModel"),zbt.forEach(t),_tr=r(lSe," (Speech Encoder decoder model)"),lSe.forEach(t),utr=i(mGe),hF=n(mGe,"LI",{});var iSe=s(hF);Uue=n(iSe,"STRONG",{});var Wbt=s(Uue);btr=r(Wbt,"speech_to_text"),Wbt.forEach(t),vtr=r(iSe," \u2014 "),Pz=n(iSe,"A",{href:!0});var Qbt=s(Pz);Ftr=r(Qbt,"Speech2TextForConditionalGeneration"),Qbt.forEach(t),Ttr=r(iSe," (Speech2Text model)"),iSe.forEach(t),mGe.forEach(t),Mtr=i(ua),pF=n(ua,"P",{});var dSe=s(pF);Etr=r(dSe,"The model is set in evaluation mode by default using "),Jue=n(dSe,"CODE",{});var Hbt=s(Jue);Ctr=r(Hbt,"model.eval()"),Hbt.forEach(t),wtr=r(dSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yue=n(dSe,"CODE",{});var Ubt=s(Yue);Atr=r(Ubt,"model.train()"),Ubt.forEach(t),dSe.forEach(t),ytr=i(ua),T(_F.$$.fragment,ua),ua.forEach(t),sl.forEach(t),ije=i(f),Ed=n(f,"H2",{class:!0});var gGe=s(Ed);uF=n(gGe,"A",{id:!0,class:!0,href:!0});var Jbt=s(uF);Kue=n(Jbt,"SPAN",{});var Ybt=s(Kue);T(BL.$$.fragment,Ybt),Ybt.forEach(t),Jbt.forEach(t),Ltr=i(gGe),Zue=n(gGe,"SPAN",{});var Kbt=s(Zue);xtr=r(Kbt,"AutoModelForAudioXVector"),Kbt.forEach(t),gGe.forEach(t),dje=i(f),zo=n(f,"DIV",{class:!0});var ll=s(zo);T(IL.$$.fragment,ll),$tr=i(ll),Cd=n(ll,"P",{});var nee=s(Cd);ktr=r(nee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Bz=n(nee,"A",{href:!0});var Zbt=s(Bz);Str=r(Zbt,"from_pretrained()"),Zbt.forEach(t),Rtr=r(nee," class method or the "),Iz=n(nee,"A",{href:!0});var e2t=s(Iz);Ptr=r(e2t,"from_config()"),e2t.forEach(t),Btr=r(nee,` class
method.`),nee.forEach(t),Itr=i(ll),NL=n(ll,"P",{});var hGe=s(NL);Ntr=r(hGe,"This class cannot be instantiated directly using "),e4e=n(hGe,"CODE",{});var o2t=s(e4e);qtr=r(o2t,"__init__()"),o2t.forEach(t),jtr=r(hGe," (throws an error)."),hGe.forEach(t),Dtr=i(ll),Tt=n(ll,"DIV",{class:!0});var p6=s(Tt);T(qL.$$.fragment,p6),Gtr=i(p6),o4e=n(p6,"P",{});var r2t=s(o4e);Otr=r(r2t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),r2t.forEach(t),Vtr=i(p6),wd=n(p6,"P",{});var see=s(wd);Xtr=r(see,`Note:
Loading a model from its configuration file does `),r4e=n(see,"STRONG",{});var t2t=s(r4e);ztr=r(t2t,"not"),t2t.forEach(t),Wtr=r(see,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nz=n(see,"A",{href:!0});var a2t=s(Nz);Qtr=r(a2t,"from_pretrained()"),a2t.forEach(t),Htr=r(see," to load the model weights."),see.forEach(t),Utr=i(p6),T(bF.$$.fragment,p6),p6.forEach(t),Jtr=i(ll),ho=n(ll,"DIV",{class:!0});var ba=s(ho);T(jL.$$.fragment,ba),Ytr=i(ba),t4e=n(ba,"P",{});var n2t=s(t4e);Ktr=r(n2t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),n2t.forEach(t),Ztr=i(ba),za=n(ba,"P",{});var _6=s(za);ear=r(_6,"The model class to instantiate is selected based on the "),a4e=n(_6,"CODE",{});var s2t=s(a4e);oar=r(s2t,"model_type"),s2t.forEach(t),rar=r(_6,` property of the config object (either
passed as an argument or loaded from `),n4e=n(_6,"CODE",{});var l2t=s(n4e);tar=r(l2t,"pretrained_model_name_or_path"),l2t.forEach(t),aar=r(_6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s4e=n(_6,"CODE",{});var i2t=s(s4e);nar=r(i2t,"pretrained_model_name_or_path"),i2t.forEach(t),sar=r(_6,":"),_6.forEach(t),lar=i(ba),Zr=n(ba,"UL",{});var il=s(Zr);vF=n(il,"LI",{});var cSe=s(vF);l4e=n(cSe,"STRONG",{});var d2t=s(l4e);iar=r(d2t,"data2vec-audio"),d2t.forEach(t),dar=r(cSe," \u2014 "),qz=n(cSe,"A",{href:!0});var c2t=s(qz);car=r(c2t,"Data2VecAudioForXVector"),c2t.forEach(t),far=r(cSe," (Data2VecAudio model)"),cSe.forEach(t),mar=i(il),FF=n(il,"LI",{});var fSe=s(FF);i4e=n(fSe,"STRONG",{});var f2t=s(i4e);gar=r(f2t,"unispeech-sat"),f2t.forEach(t),har=r(fSe," \u2014 "),jz=n(fSe,"A",{href:!0});var m2t=s(jz);par=r(m2t,"UniSpeechSatForXVector"),m2t.forEach(t),_ar=r(fSe," (UniSpeechSat model)"),fSe.forEach(t),uar=i(il),TF=n(il,"LI",{});var mSe=s(TF);d4e=n(mSe,"STRONG",{});var g2t=s(d4e);bar=r(g2t,"wav2vec2"),g2t.forEach(t),Far=r(mSe," \u2014 "),Dz=n(mSe,"A",{href:!0});var h2t=s(Dz);Tar=r(h2t,"Wav2Vec2ForXVector"),h2t.forEach(t),Mar=r(mSe," (Wav2Vec2 model)"),mSe.forEach(t),Ear=i(il),MF=n(il,"LI",{});var gSe=s(MF);c4e=n(gSe,"STRONG",{});var p2t=s(c4e);Car=r(p2t,"wav2vec2-conformer"),p2t.forEach(t),war=r(gSe," \u2014 "),Gz=n(gSe,"A",{href:!0});var _2t=s(Gz);Aar=r(_2t,"Wav2Vec2ConformerForXVector"),_2t.forEach(t),yar=r(gSe," (Wav2Vec2-Conformer model)"),gSe.forEach(t),Lar=i(il),EF=n(il,"LI",{});var hSe=s(EF);f4e=n(hSe,"STRONG",{});var u2t=s(f4e);xar=r(u2t,"wavlm"),u2t.forEach(t),$ar=r(hSe," \u2014 "),Oz=n(hSe,"A",{href:!0});var b2t=s(Oz);kar=r(b2t,"WavLMForXVector"),b2t.forEach(t),Sar=r(hSe," (WavLM model)"),hSe.forEach(t),il.forEach(t),Rar=i(ba),CF=n(ba,"P",{});var pSe=s(CF);Par=r(pSe,"The model is set in evaluation mode by default using "),m4e=n(pSe,"CODE",{});var v2t=s(m4e);Bar=r(v2t,"model.eval()"),v2t.forEach(t),Iar=r(pSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g4e=n(pSe,"CODE",{});var F2t=s(g4e);Nar=r(F2t,"model.train()"),F2t.forEach(t),pSe.forEach(t),qar=i(ba),T(wF.$$.fragment,ba),ba.forEach(t),ll.forEach(t),cje=i(f),Ad=n(f,"H2",{class:!0});var pGe=s(Ad);AF=n(pGe,"A",{id:!0,class:!0,href:!0});var T2t=s(AF);h4e=n(T2t,"SPAN",{});var M2t=s(h4e);T(DL.$$.fragment,M2t),M2t.forEach(t),T2t.forEach(t),jar=i(pGe),p4e=n(pGe,"SPAN",{});var E2t=s(p4e);Dar=r(E2t,"AutoModelForMaskedImageModeling"),E2t.forEach(t),pGe.forEach(t),fje=i(f),Wo=n(f,"DIV",{class:!0});var dl=s(Wo);T(GL.$$.fragment,dl),Gar=i(dl),yd=n(dl,"P",{});var lee=s(yd);Oar=r(lee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Vz=n(lee,"A",{href:!0});var C2t=s(Vz);Var=r(C2t,"from_pretrained()"),C2t.forEach(t),Xar=r(lee," class method or the "),Xz=n(lee,"A",{href:!0});var w2t=s(Xz);zar=r(w2t,"from_config()"),w2t.forEach(t),War=r(lee,` class
method.`),lee.forEach(t),Qar=i(dl),OL=n(dl,"P",{});var _Ge=s(OL);Har=r(_Ge,"This class cannot be instantiated directly using "),_4e=n(_Ge,"CODE",{});var A2t=s(_4e);Uar=r(A2t,"__init__()"),A2t.forEach(t),Jar=r(_Ge," (throws an error)."),_Ge.forEach(t),Yar=i(dl),Mt=n(dl,"DIV",{class:!0});var u6=s(Mt);T(VL.$$.fragment,u6),Kar=i(u6),u4e=n(u6,"P",{});var y2t=s(u4e);Zar=r(y2t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),y2t.forEach(t),enr=i(u6),Ld=n(u6,"P",{});var iee=s(Ld);onr=r(iee,`Note:
Loading a model from its configuration file does `),b4e=n(iee,"STRONG",{});var L2t=s(b4e);rnr=r(L2t,"not"),L2t.forEach(t),tnr=r(iee,` load the model weights. It only affects the
model\u2019s configuration. Use `),zz=n(iee,"A",{href:!0});var x2t=s(zz);anr=r(x2t,"from_pretrained()"),x2t.forEach(t),nnr=r(iee," to load the model weights."),iee.forEach(t),snr=i(u6),T(yF.$$.fragment,u6),u6.forEach(t),lnr=i(dl),po=n(dl,"DIV",{class:!0});var va=s(po);T(XL.$$.fragment,va),inr=i(va),v4e=n(va,"P",{});var $2t=s(v4e);dnr=r($2t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),$2t.forEach(t),cnr=i(va),Wa=n(va,"P",{});var b6=s(Wa);fnr=r(b6,"The model class to instantiate is selected based on the "),F4e=n(b6,"CODE",{});var k2t=s(F4e);mnr=r(k2t,"model_type"),k2t.forEach(t),gnr=r(b6,` property of the config object (either
passed as an argument or loaded from `),T4e=n(b6,"CODE",{});var S2t=s(T4e);hnr=r(S2t,"pretrained_model_name_or_path"),S2t.forEach(t),pnr=r(b6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M4e=n(b6,"CODE",{});var R2t=s(M4e);_nr=r(R2t,"pretrained_model_name_or_path"),R2t.forEach(t),unr=r(b6,":"),b6.forEach(t),bnr=i(va),xd=n(va,"UL",{});var dee=s(xd);LF=n(dee,"LI",{});var _Se=s(LF);E4e=n(_Se,"STRONG",{});var P2t=s(E4e);vnr=r(P2t,"deit"),P2t.forEach(t),Fnr=r(_Se," \u2014 "),Wz=n(_Se,"A",{href:!0});var B2t=s(Wz);Tnr=r(B2t,"DeiTForMaskedImageModeling"),B2t.forEach(t),Mnr=r(_Se," (DeiT model)"),_Se.forEach(t),Enr=i(dee),xF=n(dee,"LI",{});var uSe=s(xF);C4e=n(uSe,"STRONG",{});var I2t=s(C4e);Cnr=r(I2t,"swin"),I2t.forEach(t),wnr=r(uSe," \u2014 "),Qz=n(uSe,"A",{href:!0});var N2t=s(Qz);Anr=r(N2t,"SwinForMaskedImageModeling"),N2t.forEach(t),ynr=r(uSe," (Swin model)"),uSe.forEach(t),Lnr=i(dee),$F=n(dee,"LI",{});var bSe=s($F);w4e=n(bSe,"STRONG",{});var q2t=s(w4e);xnr=r(q2t,"vit"),q2t.forEach(t),$nr=r(bSe," \u2014 "),Hz=n(bSe,"A",{href:!0});var j2t=s(Hz);knr=r(j2t,"ViTForMaskedImageModeling"),j2t.forEach(t),Snr=r(bSe," (ViT model)"),bSe.forEach(t),dee.forEach(t),Rnr=i(va),kF=n(va,"P",{});var vSe=s(kF);Pnr=r(vSe,"The model is set in evaluation mode by default using "),A4e=n(vSe,"CODE",{});var D2t=s(A4e);Bnr=r(D2t,"model.eval()"),D2t.forEach(t),Inr=r(vSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y4e=n(vSe,"CODE",{});var G2t=s(y4e);Nnr=r(G2t,"model.train()"),G2t.forEach(t),vSe.forEach(t),qnr=i(va),T(SF.$$.fragment,va),va.forEach(t),dl.forEach(t),mje=i(f),$d=n(f,"H2",{class:!0});var uGe=s($d);RF=n(uGe,"A",{id:!0,class:!0,href:!0});var O2t=s(RF);L4e=n(O2t,"SPAN",{});var V2t=s(L4e);T(zL.$$.fragment,V2t),V2t.forEach(t),O2t.forEach(t),jnr=i(uGe),x4e=n(uGe,"SPAN",{});var X2t=s(x4e);Dnr=r(X2t,"AutoModelForObjectDetection"),X2t.forEach(t),uGe.forEach(t),gje=i(f),Qo=n(f,"DIV",{class:!0});var cl=s(Qo);T(WL.$$.fragment,cl),Gnr=i(cl),kd=n(cl,"P",{});var cee=s(kd);Onr=r(cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Uz=n(cee,"A",{href:!0});var z2t=s(Uz);Vnr=r(z2t,"from_pretrained()"),z2t.forEach(t),Xnr=r(cee," class method or the "),Jz=n(cee,"A",{href:!0});var W2t=s(Jz);znr=r(W2t,"from_config()"),W2t.forEach(t),Wnr=r(cee,` class
method.`),cee.forEach(t),Qnr=i(cl),QL=n(cl,"P",{});var bGe=s(QL);Hnr=r(bGe,"This class cannot be instantiated directly using "),$4e=n(bGe,"CODE",{});var Q2t=s($4e);Unr=r(Q2t,"__init__()"),Q2t.forEach(t),Jnr=r(bGe," (throws an error)."),bGe.forEach(t),Ynr=i(cl),Et=n(cl,"DIV",{class:!0});var v6=s(Et);T(HL.$$.fragment,v6),Knr=i(v6),k4e=n(v6,"P",{});var H2t=s(k4e);Znr=r(H2t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),H2t.forEach(t),esr=i(v6),Sd=n(v6,"P",{});var fee=s(Sd);osr=r(fee,`Note:
Loading a model from its configuration file does `),S4e=n(fee,"STRONG",{});var U2t=s(S4e);rsr=r(U2t,"not"),U2t.forEach(t),tsr=r(fee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yz=n(fee,"A",{href:!0});var J2t=s(Yz);asr=r(J2t,"from_pretrained()"),J2t.forEach(t),nsr=r(fee," to load the model weights."),fee.forEach(t),ssr=i(v6),T(PF.$$.fragment,v6),v6.forEach(t),lsr=i(cl),_o=n(cl,"DIV",{class:!0});var Fa=s(_o);T(UL.$$.fragment,Fa),isr=i(Fa),R4e=n(Fa,"P",{});var Y2t=s(R4e);dsr=r(Y2t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Y2t.forEach(t),csr=i(Fa),Qa=n(Fa,"P",{});var F6=s(Qa);fsr=r(F6,"The model class to instantiate is selected based on the "),P4e=n(F6,"CODE",{});var K2t=s(P4e);msr=r(K2t,"model_type"),K2t.forEach(t),gsr=r(F6,` property of the config object (either
passed as an argument or loaded from `),B4e=n(F6,"CODE",{});var Z2t=s(B4e);hsr=r(Z2t,"pretrained_model_name_or_path"),Z2t.forEach(t),psr=r(F6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=n(F6,"CODE",{});var evt=s(I4e);_sr=r(evt,"pretrained_model_name_or_path"),evt.forEach(t),usr=r(F6,":"),F6.forEach(t),bsr=i(Fa),JL=n(Fa,"UL",{});var vGe=s(JL);BF=n(vGe,"LI",{});var FSe=s(BF);N4e=n(FSe,"STRONG",{});var ovt=s(N4e);vsr=r(ovt,"detr"),ovt.forEach(t),Fsr=r(FSe," \u2014 "),Kz=n(FSe,"A",{href:!0});var rvt=s(Kz);Tsr=r(rvt,"DetrForObjectDetection"),rvt.forEach(t),Msr=r(FSe," (DETR model)"),FSe.forEach(t),Esr=i(vGe),IF=n(vGe,"LI",{});var TSe=s(IF);q4e=n(TSe,"STRONG",{});var tvt=s(q4e);Csr=r(tvt,"yolos"),tvt.forEach(t),wsr=r(TSe," \u2014 "),Zz=n(TSe,"A",{href:!0});var avt=s(Zz);Asr=r(avt,"YolosForObjectDetection"),avt.forEach(t),ysr=r(TSe," (YOLOS model)"),TSe.forEach(t),vGe.forEach(t),Lsr=i(Fa),NF=n(Fa,"P",{});var MSe=s(NF);xsr=r(MSe,"The model is set in evaluation mode by default using "),j4e=n(MSe,"CODE",{});var nvt=s(j4e);$sr=r(nvt,"model.eval()"),nvt.forEach(t),ksr=r(MSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D4e=n(MSe,"CODE",{});var svt=s(D4e);Ssr=r(svt,"model.train()"),svt.forEach(t),MSe.forEach(t),Rsr=i(Fa),T(qF.$$.fragment,Fa),Fa.forEach(t),cl.forEach(t),hje=i(f),Rd=n(f,"H2",{class:!0});var FGe=s(Rd);jF=n(FGe,"A",{id:!0,class:!0,href:!0});var lvt=s(jF);G4e=n(lvt,"SPAN",{});var ivt=s(G4e);T(YL.$$.fragment,ivt),ivt.forEach(t),lvt.forEach(t),Psr=i(FGe),O4e=n(FGe,"SPAN",{});var dvt=s(O4e);Bsr=r(dvt,"AutoModelForImageSegmentation"),dvt.forEach(t),FGe.forEach(t),pje=i(f),Ho=n(f,"DIV",{class:!0});var fl=s(Ho);T(KL.$$.fragment,fl),Isr=i(fl),Pd=n(fl,"P",{});var mee=s(Pd);Nsr=r(mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),eW=n(mee,"A",{href:!0});var cvt=s(eW);qsr=r(cvt,"from_pretrained()"),cvt.forEach(t),jsr=r(mee," class method or the "),oW=n(mee,"A",{href:!0});var fvt=s(oW);Dsr=r(fvt,"from_config()"),fvt.forEach(t),Gsr=r(mee,` class
method.`),mee.forEach(t),Osr=i(fl),ZL=n(fl,"P",{});var TGe=s(ZL);Vsr=r(TGe,"This class cannot be instantiated directly using "),V4e=n(TGe,"CODE",{});var mvt=s(V4e);Xsr=r(mvt,"__init__()"),mvt.forEach(t),zsr=r(TGe," (throws an error)."),TGe.forEach(t),Wsr=i(fl),Ct=n(fl,"DIV",{class:!0});var T6=s(Ct);T(e8.$$.fragment,T6),Qsr=i(T6),X4e=n(T6,"P",{});var gvt=s(X4e);Hsr=r(gvt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),gvt.forEach(t),Usr=i(T6),Bd=n(T6,"P",{});var gee=s(Bd);Jsr=r(gee,`Note:
Loading a model from its configuration file does `),z4e=n(gee,"STRONG",{});var hvt=s(z4e);Ysr=r(hvt,"not"),hvt.forEach(t),Ksr=r(gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=n(gee,"A",{href:!0});var pvt=s(rW);Zsr=r(pvt,"from_pretrained()"),pvt.forEach(t),elr=r(gee," to load the model weights."),gee.forEach(t),olr=i(T6),T(DF.$$.fragment,T6),T6.forEach(t),rlr=i(fl),uo=n(fl,"DIV",{class:!0});var Ta=s(uo);T(o8.$$.fragment,Ta),tlr=i(Ta),W4e=n(Ta,"P",{});var _vt=s(W4e);alr=r(_vt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),_vt.forEach(t),nlr=i(Ta),Ha=n(Ta,"P",{});var M6=s(Ha);slr=r(M6,"The model class to instantiate is selected based on the "),Q4e=n(M6,"CODE",{});var uvt=s(Q4e);llr=r(uvt,"model_type"),uvt.forEach(t),ilr=r(M6,` property of the config object (either
passed as an argument or loaded from `),H4e=n(M6,"CODE",{});var bvt=s(H4e);dlr=r(bvt,"pretrained_model_name_or_path"),bvt.forEach(t),clr=r(M6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U4e=n(M6,"CODE",{});var vvt=s(U4e);flr=r(vvt,"pretrained_model_name_or_path"),vvt.forEach(t),mlr=r(M6,":"),M6.forEach(t),glr=i(Ta),J4e=n(Ta,"UL",{});var Fvt=s(J4e);GF=n(Fvt,"LI",{});var ESe=s(GF);Y4e=n(ESe,"STRONG",{});var Tvt=s(Y4e);hlr=r(Tvt,"detr"),Tvt.forEach(t),plr=r(ESe," \u2014 "),tW=n(ESe,"A",{href:!0});var Mvt=s(tW);_lr=r(Mvt,"DetrForSegmentation"),Mvt.forEach(t),ulr=r(ESe," (DETR model)"),ESe.forEach(t),Fvt.forEach(t),blr=i(Ta),OF=n(Ta,"P",{});var CSe=s(OF);vlr=r(CSe,"The model is set in evaluation mode by default using "),K4e=n(CSe,"CODE",{});var Evt=s(K4e);Flr=r(Evt,"model.eval()"),Evt.forEach(t),Tlr=r(CSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z4e=n(CSe,"CODE",{});var Cvt=s(Z4e);Mlr=r(Cvt,"model.train()"),Cvt.forEach(t),CSe.forEach(t),Elr=i(Ta),T(VF.$$.fragment,Ta),Ta.forEach(t),fl.forEach(t),_je=i(f),Id=n(f,"H2",{class:!0});var MGe=s(Id);XF=n(MGe,"A",{id:!0,class:!0,href:!0});var wvt=s(XF);e1e=n(wvt,"SPAN",{});var Avt=s(e1e);T(r8.$$.fragment,Avt),Avt.forEach(t),wvt.forEach(t),Clr=i(MGe),o1e=n(MGe,"SPAN",{});var yvt=s(o1e);wlr=r(yvt,"AutoModelForSemanticSegmentation"),yvt.forEach(t),MGe.forEach(t),uje=i(f),Uo=n(f,"DIV",{class:!0});var ml=s(Uo);T(t8.$$.fragment,ml),Alr=i(ml),Nd=n(ml,"P",{});var hee=s(Nd);ylr=r(hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),aW=n(hee,"A",{href:!0});var Lvt=s(aW);Llr=r(Lvt,"from_pretrained()"),Lvt.forEach(t),xlr=r(hee," class method or the "),nW=n(hee,"A",{href:!0});var xvt=s(nW);$lr=r(xvt,"from_config()"),xvt.forEach(t),klr=r(hee,` class
method.`),hee.forEach(t),Slr=i(ml),a8=n(ml,"P",{});var EGe=s(a8);Rlr=r(EGe,"This class cannot be instantiated directly using "),r1e=n(EGe,"CODE",{});var $vt=s(r1e);Plr=r($vt,"__init__()"),$vt.forEach(t),Blr=r(EGe," (throws an error)."),EGe.forEach(t),Ilr=i(ml),wt=n(ml,"DIV",{class:!0});var E6=s(wt);T(n8.$$.fragment,E6),Nlr=i(E6),t1e=n(E6,"P",{});var kvt=s(t1e);qlr=r(kvt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),kvt.forEach(t),jlr=i(E6),qd=n(E6,"P",{});var pee=s(qd);Dlr=r(pee,`Note:
Loading a model from its configuration file does `),a1e=n(pee,"STRONG",{});var Svt=s(a1e);Glr=r(Svt,"not"),Svt.forEach(t),Olr=r(pee,` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=n(pee,"A",{href:!0});var Rvt=s(sW);Vlr=r(Rvt,"from_pretrained()"),Rvt.forEach(t),Xlr=r(pee," to load the model weights."),pee.forEach(t),zlr=i(E6),T(zF.$$.fragment,E6),E6.forEach(t),Wlr=i(ml),bo=n(ml,"DIV",{class:!0});var Ma=s(bo);T(s8.$$.fragment,Ma),Qlr=i(Ma),n1e=n(Ma,"P",{});var Pvt=s(n1e);Hlr=r(Pvt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Pvt.forEach(t),Ulr=i(Ma),Ua=n(Ma,"P",{});var C6=s(Ua);Jlr=r(C6,"The model class to instantiate is selected based on the "),s1e=n(C6,"CODE",{});var Bvt=s(s1e);Ylr=r(Bvt,"model_type"),Bvt.forEach(t),Klr=r(C6,` property of the config object (either
passed as an argument or loaded from `),l1e=n(C6,"CODE",{});var Ivt=s(l1e);Zlr=r(Ivt,"pretrained_model_name_or_path"),Ivt.forEach(t),eir=r(C6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i1e=n(C6,"CODE",{});var Nvt=s(i1e);oir=r(Nvt,"pretrained_model_name_or_path"),Nvt.forEach(t),rir=r(C6,":"),C6.forEach(t),tir=i(Ma),Ja=n(Ma,"UL",{});var w6=s(Ja);WF=n(w6,"LI",{});var wSe=s(WF);d1e=n(wSe,"STRONG",{});var qvt=s(d1e);air=r(qvt,"beit"),qvt.forEach(t),nir=r(wSe," \u2014 "),lW=n(wSe,"A",{href:!0});var jvt=s(lW);sir=r(jvt,"BeitForSemanticSegmentation"),jvt.forEach(t),lir=r(wSe," (BEiT model)"),wSe.forEach(t),iir=i(w6),QF=n(w6,"LI",{});var ASe=s(QF);c1e=n(ASe,"STRONG",{});var Dvt=s(c1e);dir=r(Dvt,"data2vec-vision"),Dvt.forEach(t),cir=r(ASe," \u2014 "),iW=n(ASe,"A",{href:!0});var Gvt=s(iW);fir=r(Gvt,"Data2VecVisionForSemanticSegmentation"),Gvt.forEach(t),mir=r(ASe," (Data2VecVision model)"),ASe.forEach(t),gir=i(w6),HF=n(w6,"LI",{});var ySe=s(HF);f1e=n(ySe,"STRONG",{});var Ovt=s(f1e);hir=r(Ovt,"dpt"),Ovt.forEach(t),pir=r(ySe," \u2014 "),dW=n(ySe,"A",{href:!0});var Vvt=s(dW);_ir=r(Vvt,"DPTForSemanticSegmentation"),Vvt.forEach(t),uir=r(ySe," (DPT model)"),ySe.forEach(t),bir=i(w6),UF=n(w6,"LI",{});var LSe=s(UF);m1e=n(LSe,"STRONG",{});var Xvt=s(m1e);vir=r(Xvt,"segformer"),Xvt.forEach(t),Fir=r(LSe," \u2014 "),cW=n(LSe,"A",{href:!0});var zvt=s(cW);Tir=r(zvt,"SegformerForSemanticSegmentation"),zvt.forEach(t),Mir=r(LSe," (SegFormer model)"),LSe.forEach(t),w6.forEach(t),Eir=i(Ma),JF=n(Ma,"P",{});var xSe=s(JF);Cir=r(xSe,"The model is set in evaluation mode by default using "),g1e=n(xSe,"CODE",{});var Wvt=s(g1e);wir=r(Wvt,"model.eval()"),Wvt.forEach(t),Air=r(xSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h1e=n(xSe,"CODE",{});var Qvt=s(h1e);yir=r(Qvt,"model.train()"),Qvt.forEach(t),xSe.forEach(t),Lir=i(Ma),T(YF.$$.fragment,Ma),Ma.forEach(t),ml.forEach(t),bje=i(f),jd=n(f,"H2",{class:!0});var CGe=s(jd);KF=n(CGe,"A",{id:!0,class:!0,href:!0});var Hvt=s(KF);p1e=n(Hvt,"SPAN",{});var Uvt=s(p1e);T(l8.$$.fragment,Uvt),Uvt.forEach(t),Hvt.forEach(t),xir=i(CGe),_1e=n(CGe,"SPAN",{});var Jvt=s(_1e);$ir=r(Jvt,"AutoModelForInstanceSegmentation"),Jvt.forEach(t),CGe.forEach(t),vje=i(f),Jo=n(f,"DIV",{class:!0});var gl=s(Jo);T(i8.$$.fragment,gl),kir=i(gl),Dd=n(gl,"P",{});var _ee=s(Dd);Sir=r(_ee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),fW=n(_ee,"A",{href:!0});var Yvt=s(fW);Rir=r(Yvt,"from_pretrained()"),Yvt.forEach(t),Pir=r(_ee," class method or the "),mW=n(_ee,"A",{href:!0});var Kvt=s(mW);Bir=r(Kvt,"from_config()"),Kvt.forEach(t),Iir=r(_ee,` class
method.`),_ee.forEach(t),Nir=i(gl),d8=n(gl,"P",{});var wGe=s(d8);qir=r(wGe,"This class cannot be instantiated directly using "),u1e=n(wGe,"CODE",{});var Zvt=s(u1e);jir=r(Zvt,"__init__()"),Zvt.forEach(t),Dir=r(wGe," (throws an error)."),wGe.forEach(t),Gir=i(gl),At=n(gl,"DIV",{class:!0});var A6=s(At);T(c8.$$.fragment,A6),Oir=i(A6),b1e=n(A6,"P",{});var e3t=s(b1e);Vir=r(e3t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),e3t.forEach(t),Xir=i(A6),Gd=n(A6,"P",{});var uee=s(Gd);zir=r(uee,`Note:
Loading a model from its configuration file does `),v1e=n(uee,"STRONG",{});var o3t=s(v1e);Wir=r(o3t,"not"),o3t.forEach(t),Qir=r(uee,` load the model weights. It only affects the
model\u2019s configuration. Use `),gW=n(uee,"A",{href:!0});var r3t=s(gW);Hir=r(r3t,"from_pretrained()"),r3t.forEach(t),Uir=r(uee," to load the model weights."),uee.forEach(t),Jir=i(A6),T(ZF.$$.fragment,A6),A6.forEach(t),Yir=i(gl),vo=n(gl,"DIV",{class:!0});var Ea=s(vo);T(f8.$$.fragment,Ea),Kir=i(Ea),F1e=n(Ea,"P",{});var t3t=s(F1e);Zir=r(t3t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),t3t.forEach(t),edr=i(Ea),Ya=n(Ea,"P",{});var y6=s(Ya);odr=r(y6,"The model class to instantiate is selected based on the "),T1e=n(y6,"CODE",{});var a3t=s(T1e);rdr=r(a3t,"model_type"),a3t.forEach(t),tdr=r(y6,` property of the config object (either
passed as an argument or loaded from `),M1e=n(y6,"CODE",{});var n3t=s(M1e);adr=r(n3t,"pretrained_model_name_or_path"),n3t.forEach(t),ndr=r(y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E1e=n(y6,"CODE",{});var s3t=s(E1e);sdr=r(s3t,"pretrained_model_name_or_path"),s3t.forEach(t),ldr=r(y6,":"),y6.forEach(t),idr=i(Ea),C1e=n(Ea,"UL",{});var l3t=s(C1e);eT=n(l3t,"LI",{});var $Se=s(eT);w1e=n($Se,"STRONG",{});var i3t=s(w1e);ddr=r(i3t,"maskformer"),i3t.forEach(t),cdr=r($Se," \u2014 "),hW=n($Se,"A",{href:!0});var d3t=s(hW);fdr=r(d3t,"MaskFormerForInstanceSegmentation"),d3t.forEach(t),mdr=r($Se," (MaskFormer model)"),$Se.forEach(t),l3t.forEach(t),gdr=i(Ea),oT=n(Ea,"P",{});var kSe=s(oT);hdr=r(kSe,"The model is set in evaluation mode by default using "),A1e=n(kSe,"CODE",{});var c3t=s(A1e);pdr=r(c3t,"model.eval()"),c3t.forEach(t),_dr=r(kSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y1e=n(kSe,"CODE",{});var f3t=s(y1e);udr=r(f3t,"model.train()"),f3t.forEach(t),kSe.forEach(t),bdr=i(Ea),T(rT.$$.fragment,Ea),Ea.forEach(t),gl.forEach(t),Fje=i(f),Od=n(f,"H2",{class:!0});var AGe=s(Od);tT=n(AGe,"A",{id:!0,class:!0,href:!0});var m3t=s(tT);L1e=n(m3t,"SPAN",{});var g3t=s(L1e);T(m8.$$.fragment,g3t),g3t.forEach(t),m3t.forEach(t),vdr=i(AGe),x1e=n(AGe,"SPAN",{});var h3t=s(x1e);Fdr=r(h3t,"TFAutoModel"),h3t.forEach(t),AGe.forEach(t),Tje=i(f),Yo=n(f,"DIV",{class:!0});var hl=s(Yo);T(g8.$$.fragment,hl),Tdr=i(hl),Vd=n(hl,"P",{});var bee=s(Vd);Mdr=r(bee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),pW=n(bee,"A",{href:!0});var p3t=s(pW);Edr=r(p3t,"from_pretrained()"),p3t.forEach(t),Cdr=r(bee," class method or the "),_W=n(bee,"A",{href:!0});var _3t=s(_W);wdr=r(_3t,"from_config()"),_3t.forEach(t),Adr=r(bee,` class
method.`),bee.forEach(t),ydr=i(hl),h8=n(hl,"P",{});var yGe=s(h8);Ldr=r(yGe,"This class cannot be instantiated directly using "),$1e=n(yGe,"CODE",{});var u3t=s($1e);xdr=r(u3t,"__init__()"),u3t.forEach(t),$dr=r(yGe," (throws an error)."),yGe.forEach(t),kdr=i(hl),yt=n(hl,"DIV",{class:!0});var L6=s(yt);T(p8.$$.fragment,L6),Sdr=i(L6),k1e=n(L6,"P",{});var b3t=s(k1e);Rdr=r(b3t,"Instantiates one of the base model classes of the library from a configuration."),b3t.forEach(t),Pdr=i(L6),Xd=n(L6,"P",{});var vee=s(Xd);Bdr=r(vee,`Note:
Loading a model from its configuration file does `),S1e=n(vee,"STRONG",{});var v3t=s(S1e);Idr=r(v3t,"not"),v3t.forEach(t),Ndr=r(vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),uW=n(vee,"A",{href:!0});var F3t=s(uW);qdr=r(F3t,"from_pretrained()"),F3t.forEach(t),jdr=r(vee," to load the model weights."),vee.forEach(t),Ddr=i(L6),T(aT.$$.fragment,L6),L6.forEach(t),Gdr=i(hl),wr=n(hl,"DIV",{class:!0});var pl=s(wr);T(_8.$$.fragment,pl),Odr=i(pl),R1e=n(pl,"P",{});var T3t=s(R1e);Vdr=r(T3t,"Instantiate one of the base model classes of the library from a pretrained model."),T3t.forEach(t),Xdr=i(pl),Ka=n(pl,"P",{});var x6=s(Ka);zdr=r(x6,"The model class to instantiate is selected based on the "),P1e=n(x6,"CODE",{});var M3t=s(P1e);Wdr=r(M3t,"model_type"),M3t.forEach(t),Qdr=r(x6,` property of the config object (either
passed as an argument or loaded from `),B1e=n(x6,"CODE",{});var E3t=s(B1e);Hdr=r(E3t,"pretrained_model_name_or_path"),E3t.forEach(t),Udr=r(x6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=n(x6,"CODE",{});var C3t=s(I1e);Jdr=r(C3t,"pretrained_model_name_or_path"),C3t.forEach(t),Ydr=r(x6,":"),x6.forEach(t),Kdr=i(pl),q=n(pl,"UL",{});var D=s(q);nT=n(D,"LI",{});var SSe=s(nT);N1e=n(SSe,"STRONG",{});var w3t=s(N1e);Zdr=r(w3t,"albert"),w3t.forEach(t),ecr=r(SSe," \u2014 "),bW=n(SSe,"A",{href:!0});var A3t=s(bW);ocr=r(A3t,"TFAlbertModel"),A3t.forEach(t),rcr=r(SSe," (ALBERT model)"),SSe.forEach(t),tcr=i(D),sT=n(D,"LI",{});var RSe=s(sT);q1e=n(RSe,"STRONG",{});var y3t=s(q1e);acr=r(y3t,"bart"),y3t.forEach(t),ncr=r(RSe," \u2014 "),vW=n(RSe,"A",{href:!0});var L3t=s(vW);scr=r(L3t,"TFBartModel"),L3t.forEach(t),lcr=r(RSe," (BART model)"),RSe.forEach(t),icr=i(D),lT=n(D,"LI",{});var PSe=s(lT);j1e=n(PSe,"STRONG",{});var x3t=s(j1e);dcr=r(x3t,"bert"),x3t.forEach(t),ccr=r(PSe," \u2014 "),FW=n(PSe,"A",{href:!0});var $3t=s(FW);fcr=r($3t,"TFBertModel"),$3t.forEach(t),mcr=r(PSe," (BERT model)"),PSe.forEach(t),gcr=i(D),iT=n(D,"LI",{});var BSe=s(iT);D1e=n(BSe,"STRONG",{});var k3t=s(D1e);hcr=r(k3t,"blenderbot"),k3t.forEach(t),pcr=r(BSe," \u2014 "),TW=n(BSe,"A",{href:!0});var S3t=s(TW);_cr=r(S3t,"TFBlenderbotModel"),S3t.forEach(t),ucr=r(BSe," (Blenderbot model)"),BSe.forEach(t),bcr=i(D),dT=n(D,"LI",{});var ISe=s(dT);G1e=n(ISe,"STRONG",{});var R3t=s(G1e);vcr=r(R3t,"blenderbot-small"),R3t.forEach(t),Fcr=r(ISe," \u2014 "),MW=n(ISe,"A",{href:!0});var P3t=s(MW);Tcr=r(P3t,"TFBlenderbotSmallModel"),P3t.forEach(t),Mcr=r(ISe," (BlenderbotSmall model)"),ISe.forEach(t),Ecr=i(D),cT=n(D,"LI",{});var NSe=s(cT);O1e=n(NSe,"STRONG",{});var B3t=s(O1e);Ccr=r(B3t,"camembert"),B3t.forEach(t),wcr=r(NSe," \u2014 "),EW=n(NSe,"A",{href:!0});var I3t=s(EW);Acr=r(I3t,"TFCamembertModel"),I3t.forEach(t),ycr=r(NSe," (CamemBERT model)"),NSe.forEach(t),Lcr=i(D),fT=n(D,"LI",{});var qSe=s(fT);V1e=n(qSe,"STRONG",{});var N3t=s(V1e);xcr=r(N3t,"clip"),N3t.forEach(t),$cr=r(qSe," \u2014 "),CW=n(qSe,"A",{href:!0});var q3t=s(CW);kcr=r(q3t,"TFCLIPModel"),q3t.forEach(t),Scr=r(qSe," (CLIP model)"),qSe.forEach(t),Rcr=i(D),mT=n(D,"LI",{});var jSe=s(mT);X1e=n(jSe,"STRONG",{});var j3t=s(X1e);Pcr=r(j3t,"convbert"),j3t.forEach(t),Bcr=r(jSe," \u2014 "),wW=n(jSe,"A",{href:!0});var D3t=s(wW);Icr=r(D3t,"TFConvBertModel"),D3t.forEach(t),Ncr=r(jSe," (ConvBERT model)"),jSe.forEach(t),qcr=i(D),gT=n(D,"LI",{});var DSe=s(gT);z1e=n(DSe,"STRONG",{});var G3t=s(z1e);jcr=r(G3t,"convnext"),G3t.forEach(t),Dcr=r(DSe," \u2014 "),AW=n(DSe,"A",{href:!0});var O3t=s(AW);Gcr=r(O3t,"TFConvNextModel"),O3t.forEach(t),Ocr=r(DSe," (ConvNext model)"),DSe.forEach(t),Vcr=i(D),hT=n(D,"LI",{});var GSe=s(hT);W1e=n(GSe,"STRONG",{});var V3t=s(W1e);Xcr=r(V3t,"ctrl"),V3t.forEach(t),zcr=r(GSe," \u2014 "),yW=n(GSe,"A",{href:!0});var X3t=s(yW);Wcr=r(X3t,"TFCTRLModel"),X3t.forEach(t),Qcr=r(GSe," (CTRL model)"),GSe.forEach(t),Hcr=i(D),pT=n(D,"LI",{});var OSe=s(pT);Q1e=n(OSe,"STRONG",{});var z3t=s(Q1e);Ucr=r(z3t,"data2vec-vision"),z3t.forEach(t),Jcr=r(OSe," \u2014 "),LW=n(OSe,"A",{href:!0});var W3t=s(LW);Ycr=r(W3t,"TFData2VecVisionModel"),W3t.forEach(t),Kcr=r(OSe," (Data2VecVision model)"),OSe.forEach(t),Zcr=i(D),_T=n(D,"LI",{});var VSe=s(_T);H1e=n(VSe,"STRONG",{});var Q3t=s(H1e);efr=r(Q3t,"deberta"),Q3t.forEach(t),ofr=r(VSe," \u2014 "),xW=n(VSe,"A",{href:!0});var H3t=s(xW);rfr=r(H3t,"TFDebertaModel"),H3t.forEach(t),tfr=r(VSe," (DeBERTa model)"),VSe.forEach(t),afr=i(D),uT=n(D,"LI",{});var XSe=s(uT);U1e=n(XSe,"STRONG",{});var U3t=s(U1e);nfr=r(U3t,"deberta-v2"),U3t.forEach(t),sfr=r(XSe," \u2014 "),$W=n(XSe,"A",{href:!0});var J3t=s($W);lfr=r(J3t,"TFDebertaV2Model"),J3t.forEach(t),ifr=r(XSe," (DeBERTa-v2 model)"),XSe.forEach(t),dfr=i(D),bT=n(D,"LI",{});var zSe=s(bT);J1e=n(zSe,"STRONG",{});var Y3t=s(J1e);cfr=r(Y3t,"distilbert"),Y3t.forEach(t),ffr=r(zSe," \u2014 "),kW=n(zSe,"A",{href:!0});var K3t=s(kW);mfr=r(K3t,"TFDistilBertModel"),K3t.forEach(t),gfr=r(zSe," (DistilBERT model)"),zSe.forEach(t),hfr=i(D),vT=n(D,"LI",{});var WSe=s(vT);Y1e=n(WSe,"STRONG",{});var Z3t=s(Y1e);pfr=r(Z3t,"dpr"),Z3t.forEach(t),_fr=r(WSe," \u2014 "),SW=n(WSe,"A",{href:!0});var eFt=s(SW);ufr=r(eFt,"TFDPRQuestionEncoder"),eFt.forEach(t),bfr=r(WSe," (DPR model)"),WSe.forEach(t),vfr=i(D),FT=n(D,"LI",{});var QSe=s(FT);K1e=n(QSe,"STRONG",{});var oFt=s(K1e);Ffr=r(oFt,"electra"),oFt.forEach(t),Tfr=r(QSe," \u2014 "),RW=n(QSe,"A",{href:!0});var rFt=s(RW);Mfr=r(rFt,"TFElectraModel"),rFt.forEach(t),Efr=r(QSe," (ELECTRA model)"),QSe.forEach(t),Cfr=i(D),TT=n(D,"LI",{});var HSe=s(TT);Z1e=n(HSe,"STRONG",{});var tFt=s(Z1e);wfr=r(tFt,"flaubert"),tFt.forEach(t),Afr=r(HSe," \u2014 "),PW=n(HSe,"A",{href:!0});var aFt=s(PW);yfr=r(aFt,"TFFlaubertModel"),aFt.forEach(t),Lfr=r(HSe," (FlauBERT model)"),HSe.forEach(t),xfr=i(D),Ns=n(D,"LI",{});var U$=s(Ns);ebe=n(U$,"STRONG",{});var nFt=s(ebe);$fr=r(nFt,"funnel"),nFt.forEach(t),kfr=r(U$," \u2014 "),BW=n(U$,"A",{href:!0});var sFt=s(BW);Sfr=r(sFt,"TFFunnelModel"),sFt.forEach(t),Rfr=r(U$," or "),IW=n(U$,"A",{href:!0});var lFt=s(IW);Pfr=r(lFt,"TFFunnelBaseModel"),lFt.forEach(t),Bfr=r(U$," (Funnel Transformer model)"),U$.forEach(t),Ifr=i(D),MT=n(D,"LI",{});var USe=s(MT);obe=n(USe,"STRONG",{});var iFt=s(obe);Nfr=r(iFt,"gpt2"),iFt.forEach(t),qfr=r(USe," \u2014 "),NW=n(USe,"A",{href:!0});var dFt=s(NW);jfr=r(dFt,"TFGPT2Model"),dFt.forEach(t),Dfr=r(USe," (OpenAI GPT-2 model)"),USe.forEach(t),Gfr=i(D),ET=n(D,"LI",{});var JSe=s(ET);rbe=n(JSe,"STRONG",{});var cFt=s(rbe);Ofr=r(cFt,"gptj"),cFt.forEach(t),Vfr=r(JSe," \u2014 "),qW=n(JSe,"A",{href:!0});var fFt=s(qW);Xfr=r(fFt,"TFGPTJModel"),fFt.forEach(t),zfr=r(JSe," (GPT-J model)"),JSe.forEach(t),Wfr=i(D),CT=n(D,"LI",{});var YSe=s(CT);tbe=n(YSe,"STRONG",{});var mFt=s(tbe);Qfr=r(mFt,"hubert"),mFt.forEach(t),Hfr=r(YSe," \u2014 "),jW=n(YSe,"A",{href:!0});var gFt=s(jW);Ufr=r(gFt,"TFHubertModel"),gFt.forEach(t),Jfr=r(YSe," (Hubert model)"),YSe.forEach(t),Yfr=i(D),wT=n(D,"LI",{});var KSe=s(wT);abe=n(KSe,"STRONG",{});var hFt=s(abe);Kfr=r(hFt,"layoutlm"),hFt.forEach(t),Zfr=r(KSe," \u2014 "),DW=n(KSe,"A",{href:!0});var pFt=s(DW);emr=r(pFt,"TFLayoutLMModel"),pFt.forEach(t),omr=r(KSe," (LayoutLM model)"),KSe.forEach(t),rmr=i(D),AT=n(D,"LI",{});var ZSe=s(AT);nbe=n(ZSe,"STRONG",{});var _Ft=s(nbe);tmr=r(_Ft,"led"),_Ft.forEach(t),amr=r(ZSe," \u2014 "),GW=n(ZSe,"A",{href:!0});var uFt=s(GW);nmr=r(uFt,"TFLEDModel"),uFt.forEach(t),smr=r(ZSe," (LED model)"),ZSe.forEach(t),lmr=i(D),yT=n(D,"LI",{});var eRe=s(yT);sbe=n(eRe,"STRONG",{});var bFt=s(sbe);imr=r(bFt,"longformer"),bFt.forEach(t),dmr=r(eRe," \u2014 "),OW=n(eRe,"A",{href:!0});var vFt=s(OW);cmr=r(vFt,"TFLongformerModel"),vFt.forEach(t),fmr=r(eRe," (Longformer model)"),eRe.forEach(t),mmr=i(D),LT=n(D,"LI",{});var oRe=s(LT);lbe=n(oRe,"STRONG",{});var FFt=s(lbe);gmr=r(FFt,"lxmert"),FFt.forEach(t),hmr=r(oRe," \u2014 "),VW=n(oRe,"A",{href:!0});var TFt=s(VW);pmr=r(TFt,"TFLxmertModel"),TFt.forEach(t),_mr=r(oRe," (LXMERT model)"),oRe.forEach(t),umr=i(D),xT=n(D,"LI",{});var rRe=s(xT);ibe=n(rRe,"STRONG",{});var MFt=s(ibe);bmr=r(MFt,"marian"),MFt.forEach(t),vmr=r(rRe," \u2014 "),XW=n(rRe,"A",{href:!0});var EFt=s(XW);Fmr=r(EFt,"TFMarianModel"),EFt.forEach(t),Tmr=r(rRe," (Marian model)"),rRe.forEach(t),Mmr=i(D),$T=n(D,"LI",{});var tRe=s($T);dbe=n(tRe,"STRONG",{});var CFt=s(dbe);Emr=r(CFt,"mbart"),CFt.forEach(t),Cmr=r(tRe," \u2014 "),zW=n(tRe,"A",{href:!0});var wFt=s(zW);wmr=r(wFt,"TFMBartModel"),wFt.forEach(t),Amr=r(tRe," (mBART model)"),tRe.forEach(t),ymr=i(D),kT=n(D,"LI",{});var aRe=s(kT);cbe=n(aRe,"STRONG",{});var AFt=s(cbe);Lmr=r(AFt,"mobilebert"),AFt.forEach(t),xmr=r(aRe," \u2014 "),WW=n(aRe,"A",{href:!0});var yFt=s(WW);$mr=r(yFt,"TFMobileBertModel"),yFt.forEach(t),kmr=r(aRe," (MobileBERT model)"),aRe.forEach(t),Smr=i(D),ST=n(D,"LI",{});var nRe=s(ST);fbe=n(nRe,"STRONG",{});var LFt=s(fbe);Rmr=r(LFt,"mpnet"),LFt.forEach(t),Pmr=r(nRe," \u2014 "),QW=n(nRe,"A",{href:!0});var xFt=s(QW);Bmr=r(xFt,"TFMPNetModel"),xFt.forEach(t),Imr=r(nRe," (MPNet model)"),nRe.forEach(t),Nmr=i(D),RT=n(D,"LI",{});var sRe=s(RT);mbe=n(sRe,"STRONG",{});var $Ft=s(mbe);qmr=r($Ft,"mt5"),$Ft.forEach(t),jmr=r(sRe," \u2014 "),HW=n(sRe,"A",{href:!0});var kFt=s(HW);Dmr=r(kFt,"TFMT5Model"),kFt.forEach(t),Gmr=r(sRe," (mT5 model)"),sRe.forEach(t),Omr=i(D),PT=n(D,"LI",{});var lRe=s(PT);gbe=n(lRe,"STRONG",{});var SFt=s(gbe);Vmr=r(SFt,"openai-gpt"),SFt.forEach(t),Xmr=r(lRe," \u2014 "),UW=n(lRe,"A",{href:!0});var RFt=s(UW);zmr=r(RFt,"TFOpenAIGPTModel"),RFt.forEach(t),Wmr=r(lRe," (OpenAI GPT model)"),lRe.forEach(t),Qmr=i(D),BT=n(D,"LI",{});var iRe=s(BT);hbe=n(iRe,"STRONG",{});var PFt=s(hbe);Hmr=r(PFt,"pegasus"),PFt.forEach(t),Umr=r(iRe," \u2014 "),JW=n(iRe,"A",{href:!0});var BFt=s(JW);Jmr=r(BFt,"TFPegasusModel"),BFt.forEach(t),Ymr=r(iRe," (Pegasus model)"),iRe.forEach(t),Kmr=i(D),IT=n(D,"LI",{});var dRe=s(IT);pbe=n(dRe,"STRONG",{});var IFt=s(pbe);Zmr=r(IFt,"rembert"),IFt.forEach(t),egr=r(dRe," \u2014 "),YW=n(dRe,"A",{href:!0});var NFt=s(YW);ogr=r(NFt,"TFRemBertModel"),NFt.forEach(t),rgr=r(dRe," (RemBERT model)"),dRe.forEach(t),tgr=i(D),NT=n(D,"LI",{});var cRe=s(NT);_be=n(cRe,"STRONG",{});var qFt=s(_be);agr=r(qFt,"roberta"),qFt.forEach(t),ngr=r(cRe," \u2014 "),KW=n(cRe,"A",{href:!0});var jFt=s(KW);sgr=r(jFt,"TFRobertaModel"),jFt.forEach(t),lgr=r(cRe," (RoBERTa model)"),cRe.forEach(t),igr=i(D),qT=n(D,"LI",{});var fRe=s(qT);ube=n(fRe,"STRONG",{});var DFt=s(ube);dgr=r(DFt,"roformer"),DFt.forEach(t),cgr=r(fRe," \u2014 "),ZW=n(fRe,"A",{href:!0});var GFt=s(ZW);fgr=r(GFt,"TFRoFormerModel"),GFt.forEach(t),mgr=r(fRe," (RoFormer model)"),fRe.forEach(t),ggr=i(D),jT=n(D,"LI",{});var mRe=s(jT);bbe=n(mRe,"STRONG",{});var OFt=s(bbe);hgr=r(OFt,"speech_to_text"),OFt.forEach(t),pgr=r(mRe," \u2014 "),eQ=n(mRe,"A",{href:!0});var VFt=s(eQ);_gr=r(VFt,"TFSpeech2TextModel"),VFt.forEach(t),ugr=r(mRe," (Speech2Text model)"),mRe.forEach(t),bgr=i(D),DT=n(D,"LI",{});var gRe=s(DT);vbe=n(gRe,"STRONG",{});var XFt=s(vbe);vgr=r(XFt,"swin"),XFt.forEach(t),Fgr=r(gRe," \u2014 "),oQ=n(gRe,"A",{href:!0});var zFt=s(oQ);Tgr=r(zFt,"TFSwinModel"),zFt.forEach(t),Mgr=r(gRe," (Swin model)"),gRe.forEach(t),Egr=i(D),GT=n(D,"LI",{});var hRe=s(GT);Fbe=n(hRe,"STRONG",{});var WFt=s(Fbe);Cgr=r(WFt,"t5"),WFt.forEach(t),wgr=r(hRe," \u2014 "),rQ=n(hRe,"A",{href:!0});var QFt=s(rQ);Agr=r(QFt,"TFT5Model"),QFt.forEach(t),ygr=r(hRe," (T5 model)"),hRe.forEach(t),Lgr=i(D),OT=n(D,"LI",{});var pRe=s(OT);Tbe=n(pRe,"STRONG",{});var HFt=s(Tbe);xgr=r(HFt,"tapas"),HFt.forEach(t),$gr=r(pRe," \u2014 "),tQ=n(pRe,"A",{href:!0});var UFt=s(tQ);kgr=r(UFt,"TFTapasModel"),UFt.forEach(t),Sgr=r(pRe," (TAPAS model)"),pRe.forEach(t),Rgr=i(D),VT=n(D,"LI",{});var _Re=s(VT);Mbe=n(_Re,"STRONG",{});var JFt=s(Mbe);Pgr=r(JFt,"transfo-xl"),JFt.forEach(t),Bgr=r(_Re," \u2014 "),aQ=n(_Re,"A",{href:!0});var YFt=s(aQ);Igr=r(YFt,"TFTransfoXLModel"),YFt.forEach(t),Ngr=r(_Re," (Transformer-XL model)"),_Re.forEach(t),qgr=i(D),XT=n(D,"LI",{});var uRe=s(XT);Ebe=n(uRe,"STRONG",{});var KFt=s(Ebe);jgr=r(KFt,"vit"),KFt.forEach(t),Dgr=r(uRe," \u2014 "),nQ=n(uRe,"A",{href:!0});var ZFt=s(nQ);Ggr=r(ZFt,"TFViTModel"),ZFt.forEach(t),Ogr=r(uRe," (ViT model)"),uRe.forEach(t),Vgr=i(D),zT=n(D,"LI",{});var bRe=s(zT);Cbe=n(bRe,"STRONG",{});var eTt=s(Cbe);Xgr=r(eTt,"vit_mae"),eTt.forEach(t),zgr=r(bRe," \u2014 "),sQ=n(bRe,"A",{href:!0});var oTt=s(sQ);Wgr=r(oTt,"TFViTMAEModel"),oTt.forEach(t),Qgr=r(bRe," (ViTMAE model)"),bRe.forEach(t),Hgr=i(D),WT=n(D,"LI",{});var vRe=s(WT);wbe=n(vRe,"STRONG",{});var rTt=s(wbe);Ugr=r(rTt,"wav2vec2"),rTt.forEach(t),Jgr=r(vRe," \u2014 "),lQ=n(vRe,"A",{href:!0});var tTt=s(lQ);Ygr=r(tTt,"TFWav2Vec2Model"),tTt.forEach(t),Kgr=r(vRe," (Wav2Vec2 model)"),vRe.forEach(t),Zgr=i(D),QT=n(D,"LI",{});var FRe=s(QT);Abe=n(FRe,"STRONG",{});var aTt=s(Abe);ehr=r(aTt,"xlm"),aTt.forEach(t),ohr=r(FRe," \u2014 "),iQ=n(FRe,"A",{href:!0});var nTt=s(iQ);rhr=r(nTt,"TFXLMModel"),nTt.forEach(t),thr=r(FRe," (XLM model)"),FRe.forEach(t),ahr=i(D),HT=n(D,"LI",{});var TRe=s(HT);ybe=n(TRe,"STRONG",{});var sTt=s(ybe);nhr=r(sTt,"xlm-roberta"),sTt.forEach(t),shr=r(TRe," \u2014 "),dQ=n(TRe,"A",{href:!0});var lTt=s(dQ);lhr=r(lTt,"TFXLMRobertaModel"),lTt.forEach(t),ihr=r(TRe," (XLM-RoBERTa model)"),TRe.forEach(t),dhr=i(D),UT=n(D,"LI",{});var MRe=s(UT);Lbe=n(MRe,"STRONG",{});var iTt=s(Lbe);chr=r(iTt,"xlnet"),iTt.forEach(t),fhr=r(MRe," \u2014 "),cQ=n(MRe,"A",{href:!0});var dTt=s(cQ);mhr=r(dTt,"TFXLNetModel"),dTt.forEach(t),ghr=r(MRe," (XLNet model)"),MRe.forEach(t),D.forEach(t),hhr=i(pl),T(JT.$$.fragment,pl),pl.forEach(t),hl.forEach(t),Mje=i(f),zd=n(f,"H2",{class:!0});var LGe=s(zd);YT=n(LGe,"A",{id:!0,class:!0,href:!0});var cTt=s(YT);xbe=n(cTt,"SPAN",{});var fTt=s(xbe);T(u8.$$.fragment,fTt),fTt.forEach(t),cTt.forEach(t),phr=i(LGe),$be=n(LGe,"SPAN",{});var mTt=s($be);_hr=r(mTt,"TFAutoModelForPreTraining"),mTt.forEach(t),LGe.forEach(t),Eje=i(f),Ko=n(f,"DIV",{class:!0});var _l=s(Ko);T(b8.$$.fragment,_l),uhr=i(_l),Wd=n(_l,"P",{});var Fee=s(Wd);bhr=r(Fee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),fQ=n(Fee,"A",{href:!0});var gTt=s(fQ);vhr=r(gTt,"from_pretrained()"),gTt.forEach(t),Fhr=r(Fee," class method or the "),mQ=n(Fee,"A",{href:!0});var hTt=s(mQ);Thr=r(hTt,"from_config()"),hTt.forEach(t),Mhr=r(Fee,` class
method.`),Fee.forEach(t),Ehr=i(_l),v8=n(_l,"P",{});var xGe=s(v8);Chr=r(xGe,"This class cannot be instantiated directly using "),kbe=n(xGe,"CODE",{});var pTt=s(kbe);whr=r(pTt,"__init__()"),pTt.forEach(t),Ahr=r(xGe," (throws an error)."),xGe.forEach(t),yhr=i(_l),Lt=n(_l,"DIV",{class:!0});var $6=s(Lt);T(F8.$$.fragment,$6),Lhr=i($6),Sbe=n($6,"P",{});var _Tt=s(Sbe);xhr=r(_Tt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),_Tt.forEach(t),$hr=i($6),Qd=n($6,"P",{});var Tee=s(Qd);khr=r(Tee,`Note:
Loading a model from its configuration file does `),Rbe=n(Tee,"STRONG",{});var uTt=s(Rbe);Shr=r(uTt,"not"),uTt.forEach(t),Rhr=r(Tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),gQ=n(Tee,"A",{href:!0});var bTt=s(gQ);Phr=r(bTt,"from_pretrained()"),bTt.forEach(t),Bhr=r(Tee," to load the model weights."),Tee.forEach(t),Ihr=i($6),T(KT.$$.fragment,$6),$6.forEach(t),Nhr=i(_l),Ar=n(_l,"DIV",{class:!0});var ul=s(Ar);T(T8.$$.fragment,ul),qhr=i(ul),Pbe=n(ul,"P",{});var vTt=s(Pbe);jhr=r(vTt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),vTt.forEach(t),Dhr=i(ul),Za=n(ul,"P",{});var k6=s(Za);Ghr=r(k6,"The model class to instantiate is selected based on the "),Bbe=n(k6,"CODE",{});var FTt=s(Bbe);Ohr=r(FTt,"model_type"),FTt.forEach(t),Vhr=r(k6,` property of the config object (either
passed as an argument or loaded from `),Ibe=n(k6,"CODE",{});var TTt=s(Ibe);Xhr=r(TTt,"pretrained_model_name_or_path"),TTt.forEach(t),zhr=r(k6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nbe=n(k6,"CODE",{});var MTt=s(Nbe);Whr=r(MTt,"pretrained_model_name_or_path"),MTt.forEach(t),Qhr=r(k6,":"),k6.forEach(t),Hhr=i(ul),se=n(ul,"UL",{});var le=s(se);ZT=n(le,"LI",{});var ERe=s(ZT);qbe=n(ERe,"STRONG",{});var ETt=s(qbe);Uhr=r(ETt,"albert"),ETt.forEach(t),Jhr=r(ERe," \u2014 "),hQ=n(ERe,"A",{href:!0});var CTt=s(hQ);Yhr=r(CTt,"TFAlbertForPreTraining"),CTt.forEach(t),Khr=r(ERe," (ALBERT model)"),ERe.forEach(t),Zhr=i(le),e7=n(le,"LI",{});var CRe=s(e7);jbe=n(CRe,"STRONG",{});var wTt=s(jbe);epr=r(wTt,"bart"),wTt.forEach(t),opr=r(CRe," \u2014 "),pQ=n(CRe,"A",{href:!0});var ATt=s(pQ);rpr=r(ATt,"TFBartForConditionalGeneration"),ATt.forEach(t),tpr=r(CRe," (BART model)"),CRe.forEach(t),apr=i(le),o7=n(le,"LI",{});var wRe=s(o7);Dbe=n(wRe,"STRONG",{});var yTt=s(Dbe);npr=r(yTt,"bert"),yTt.forEach(t),spr=r(wRe," \u2014 "),_Q=n(wRe,"A",{href:!0});var LTt=s(_Q);lpr=r(LTt,"TFBertForPreTraining"),LTt.forEach(t),ipr=r(wRe," (BERT model)"),wRe.forEach(t),dpr=i(le),r7=n(le,"LI",{});var ARe=s(r7);Gbe=n(ARe,"STRONG",{});var xTt=s(Gbe);cpr=r(xTt,"camembert"),xTt.forEach(t),fpr=r(ARe," \u2014 "),uQ=n(ARe,"A",{href:!0});var $Tt=s(uQ);mpr=r($Tt,"TFCamembertForMaskedLM"),$Tt.forEach(t),gpr=r(ARe," (CamemBERT model)"),ARe.forEach(t),hpr=i(le),t7=n(le,"LI",{});var yRe=s(t7);Obe=n(yRe,"STRONG",{});var kTt=s(Obe);ppr=r(kTt,"ctrl"),kTt.forEach(t),_pr=r(yRe," \u2014 "),bQ=n(yRe,"A",{href:!0});var STt=s(bQ);upr=r(STt,"TFCTRLLMHeadModel"),STt.forEach(t),bpr=r(yRe," (CTRL model)"),yRe.forEach(t),vpr=i(le),a7=n(le,"LI",{});var LRe=s(a7);Vbe=n(LRe,"STRONG",{});var RTt=s(Vbe);Fpr=r(RTt,"distilbert"),RTt.forEach(t),Tpr=r(LRe," \u2014 "),vQ=n(LRe,"A",{href:!0});var PTt=s(vQ);Mpr=r(PTt,"TFDistilBertForMaskedLM"),PTt.forEach(t),Epr=r(LRe," (DistilBERT model)"),LRe.forEach(t),Cpr=i(le),n7=n(le,"LI",{});var xRe=s(n7);Xbe=n(xRe,"STRONG",{});var BTt=s(Xbe);wpr=r(BTt,"electra"),BTt.forEach(t),Apr=r(xRe," \u2014 "),FQ=n(xRe,"A",{href:!0});var ITt=s(FQ);ypr=r(ITt,"TFElectraForPreTraining"),ITt.forEach(t),Lpr=r(xRe," (ELECTRA model)"),xRe.forEach(t),xpr=i(le),s7=n(le,"LI",{});var $Re=s(s7);zbe=n($Re,"STRONG",{});var NTt=s(zbe);$pr=r(NTt,"flaubert"),NTt.forEach(t),kpr=r($Re," \u2014 "),TQ=n($Re,"A",{href:!0});var qTt=s(TQ);Spr=r(qTt,"TFFlaubertWithLMHeadModel"),qTt.forEach(t),Rpr=r($Re," (FlauBERT model)"),$Re.forEach(t),Ppr=i(le),l7=n(le,"LI",{});var kRe=s(l7);Wbe=n(kRe,"STRONG",{});var jTt=s(Wbe);Bpr=r(jTt,"funnel"),jTt.forEach(t),Ipr=r(kRe," \u2014 "),MQ=n(kRe,"A",{href:!0});var DTt=s(MQ);Npr=r(DTt,"TFFunnelForPreTraining"),DTt.forEach(t),qpr=r(kRe," (Funnel Transformer model)"),kRe.forEach(t),jpr=i(le),i7=n(le,"LI",{});var SRe=s(i7);Qbe=n(SRe,"STRONG",{});var GTt=s(Qbe);Dpr=r(GTt,"gpt2"),GTt.forEach(t),Gpr=r(SRe," \u2014 "),EQ=n(SRe,"A",{href:!0});var OTt=s(EQ);Opr=r(OTt,"TFGPT2LMHeadModel"),OTt.forEach(t),Vpr=r(SRe," (OpenAI GPT-2 model)"),SRe.forEach(t),Xpr=i(le),d7=n(le,"LI",{});var RRe=s(d7);Hbe=n(RRe,"STRONG",{});var VTt=s(Hbe);zpr=r(VTt,"layoutlm"),VTt.forEach(t),Wpr=r(RRe," \u2014 "),CQ=n(RRe,"A",{href:!0});var XTt=s(CQ);Qpr=r(XTt,"TFLayoutLMForMaskedLM"),XTt.forEach(t),Hpr=r(RRe," (LayoutLM model)"),RRe.forEach(t),Upr=i(le),c7=n(le,"LI",{});var PRe=s(c7);Ube=n(PRe,"STRONG",{});var zTt=s(Ube);Jpr=r(zTt,"lxmert"),zTt.forEach(t),Ypr=r(PRe," \u2014 "),wQ=n(PRe,"A",{href:!0});var WTt=s(wQ);Kpr=r(WTt,"TFLxmertForPreTraining"),WTt.forEach(t),Zpr=r(PRe," (LXMERT model)"),PRe.forEach(t),e_r=i(le),f7=n(le,"LI",{});var BRe=s(f7);Jbe=n(BRe,"STRONG",{});var QTt=s(Jbe);o_r=r(QTt,"mobilebert"),QTt.forEach(t),r_r=r(BRe," \u2014 "),AQ=n(BRe,"A",{href:!0});var HTt=s(AQ);t_r=r(HTt,"TFMobileBertForPreTraining"),HTt.forEach(t),a_r=r(BRe," (MobileBERT model)"),BRe.forEach(t),n_r=i(le),m7=n(le,"LI",{});var IRe=s(m7);Ybe=n(IRe,"STRONG",{});var UTt=s(Ybe);s_r=r(UTt,"mpnet"),UTt.forEach(t),l_r=r(IRe," \u2014 "),yQ=n(IRe,"A",{href:!0});var JTt=s(yQ);i_r=r(JTt,"TFMPNetForMaskedLM"),JTt.forEach(t),d_r=r(IRe," (MPNet model)"),IRe.forEach(t),c_r=i(le),g7=n(le,"LI",{});var NRe=s(g7);Kbe=n(NRe,"STRONG",{});var YTt=s(Kbe);f_r=r(YTt,"openai-gpt"),YTt.forEach(t),m_r=r(NRe," \u2014 "),LQ=n(NRe,"A",{href:!0});var KTt=s(LQ);g_r=r(KTt,"TFOpenAIGPTLMHeadModel"),KTt.forEach(t),h_r=r(NRe," (OpenAI GPT model)"),NRe.forEach(t),p_r=i(le),h7=n(le,"LI",{});var qRe=s(h7);Zbe=n(qRe,"STRONG",{});var ZTt=s(Zbe);__r=r(ZTt,"roberta"),ZTt.forEach(t),u_r=r(qRe," \u2014 "),xQ=n(qRe,"A",{href:!0});var e7t=s(xQ);b_r=r(e7t,"TFRobertaForMaskedLM"),e7t.forEach(t),v_r=r(qRe," (RoBERTa model)"),qRe.forEach(t),F_r=i(le),p7=n(le,"LI",{});var jRe=s(p7);e2e=n(jRe,"STRONG",{});var o7t=s(e2e);T_r=r(o7t,"t5"),o7t.forEach(t),M_r=r(jRe," \u2014 "),$Q=n(jRe,"A",{href:!0});var r7t=s($Q);E_r=r(r7t,"TFT5ForConditionalGeneration"),r7t.forEach(t),C_r=r(jRe," (T5 model)"),jRe.forEach(t),w_r=i(le),_7=n(le,"LI",{});var DRe=s(_7);o2e=n(DRe,"STRONG",{});var t7t=s(o2e);A_r=r(t7t,"tapas"),t7t.forEach(t),y_r=r(DRe," \u2014 "),kQ=n(DRe,"A",{href:!0});var a7t=s(kQ);L_r=r(a7t,"TFTapasForMaskedLM"),a7t.forEach(t),x_r=r(DRe," (TAPAS model)"),DRe.forEach(t),$_r=i(le),u7=n(le,"LI",{});var GRe=s(u7);r2e=n(GRe,"STRONG",{});var n7t=s(r2e);k_r=r(n7t,"transfo-xl"),n7t.forEach(t),S_r=r(GRe," \u2014 "),SQ=n(GRe,"A",{href:!0});var s7t=s(SQ);R_r=r(s7t,"TFTransfoXLLMHeadModel"),s7t.forEach(t),P_r=r(GRe," (Transformer-XL model)"),GRe.forEach(t),B_r=i(le),b7=n(le,"LI",{});var ORe=s(b7);t2e=n(ORe,"STRONG",{});var l7t=s(t2e);I_r=r(l7t,"vit_mae"),l7t.forEach(t),N_r=r(ORe," \u2014 "),RQ=n(ORe,"A",{href:!0});var i7t=s(RQ);q_r=r(i7t,"TFViTMAEForPreTraining"),i7t.forEach(t),j_r=r(ORe," (ViTMAE model)"),ORe.forEach(t),D_r=i(le),v7=n(le,"LI",{});var VRe=s(v7);a2e=n(VRe,"STRONG",{});var d7t=s(a2e);G_r=r(d7t,"xlm"),d7t.forEach(t),O_r=r(VRe," \u2014 "),PQ=n(VRe,"A",{href:!0});var c7t=s(PQ);V_r=r(c7t,"TFXLMWithLMHeadModel"),c7t.forEach(t),X_r=r(VRe," (XLM model)"),VRe.forEach(t),z_r=i(le),F7=n(le,"LI",{});var XRe=s(F7);n2e=n(XRe,"STRONG",{});var f7t=s(n2e);W_r=r(f7t,"xlm-roberta"),f7t.forEach(t),Q_r=r(XRe," \u2014 "),BQ=n(XRe,"A",{href:!0});var m7t=s(BQ);H_r=r(m7t,"TFXLMRobertaForMaskedLM"),m7t.forEach(t),U_r=r(XRe," (XLM-RoBERTa model)"),XRe.forEach(t),J_r=i(le),T7=n(le,"LI",{});var zRe=s(T7);s2e=n(zRe,"STRONG",{});var g7t=s(s2e);Y_r=r(g7t,"xlnet"),g7t.forEach(t),K_r=r(zRe," \u2014 "),IQ=n(zRe,"A",{href:!0});var h7t=s(IQ);Z_r=r(h7t,"TFXLNetLMHeadModel"),h7t.forEach(t),eur=r(zRe," (XLNet model)"),zRe.forEach(t),le.forEach(t),our=i(ul),T(M7.$$.fragment,ul),ul.forEach(t),_l.forEach(t),Cje=i(f),Hd=n(f,"H2",{class:!0});var $Ge=s(Hd);E7=n($Ge,"A",{id:!0,class:!0,href:!0});var p7t=s(E7);l2e=n(p7t,"SPAN",{});var _7t=s(l2e);T(M8.$$.fragment,_7t),_7t.forEach(t),p7t.forEach(t),rur=i($Ge),i2e=n($Ge,"SPAN",{});var u7t=s(i2e);tur=r(u7t,"TFAutoModelForCausalLM"),u7t.forEach(t),$Ge.forEach(t),wje=i(f),Zo=n(f,"DIV",{class:!0});var bl=s(Zo);T(E8.$$.fragment,bl),aur=i(bl),Ud=n(bl,"P",{});var Mee=s(Ud);nur=r(Mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),NQ=n(Mee,"A",{href:!0});var b7t=s(NQ);sur=r(b7t,"from_pretrained()"),b7t.forEach(t),lur=r(Mee," class method or the "),qQ=n(Mee,"A",{href:!0});var v7t=s(qQ);iur=r(v7t,"from_config()"),v7t.forEach(t),dur=r(Mee,` class
method.`),Mee.forEach(t),cur=i(bl),C8=n(bl,"P",{});var kGe=s(C8);fur=r(kGe,"This class cannot be instantiated directly using "),d2e=n(kGe,"CODE",{});var F7t=s(d2e);mur=r(F7t,"__init__()"),F7t.forEach(t),gur=r(kGe," (throws an error)."),kGe.forEach(t),hur=i(bl),xt=n(bl,"DIV",{class:!0});var S6=s(xt);T(w8.$$.fragment,S6),pur=i(S6),c2e=n(S6,"P",{});var T7t=s(c2e);_ur=r(T7t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),T7t.forEach(t),uur=i(S6),Jd=n(S6,"P",{});var Eee=s(Jd);bur=r(Eee,`Note:
Loading a model from its configuration file does `),f2e=n(Eee,"STRONG",{});var M7t=s(f2e);vur=r(M7t,"not"),M7t.forEach(t),Fur=r(Eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),jQ=n(Eee,"A",{href:!0});var E7t=s(jQ);Tur=r(E7t,"from_pretrained()"),E7t.forEach(t),Mur=r(Eee," to load the model weights."),Eee.forEach(t),Eur=i(S6),T(C7.$$.fragment,S6),S6.forEach(t),Cur=i(bl),yr=n(bl,"DIV",{class:!0});var vl=s(yr);T(A8.$$.fragment,vl),wur=i(vl),m2e=n(vl,"P",{});var C7t=s(m2e);Aur=r(C7t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),C7t.forEach(t),yur=i(vl),en=n(vl,"P",{});var R6=s(en);Lur=r(R6,"The model class to instantiate is selected based on the "),g2e=n(R6,"CODE",{});var w7t=s(g2e);xur=r(w7t,"model_type"),w7t.forEach(t),$ur=r(R6,` property of the config object (either
passed as an argument or loaded from `),h2e=n(R6,"CODE",{});var A7t=s(h2e);kur=r(A7t,"pretrained_model_name_or_path"),A7t.forEach(t),Sur=r(R6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p2e=n(R6,"CODE",{});var y7t=s(p2e);Rur=r(y7t,"pretrained_model_name_or_path"),y7t.forEach(t),Pur=r(R6,":"),R6.forEach(t),Bur=i(vl),Me=n(vl,"UL",{});var Ce=s(Me);w7=n(Ce,"LI",{});var WRe=s(w7);_2e=n(WRe,"STRONG",{});var L7t=s(_2e);Iur=r(L7t,"bert"),L7t.forEach(t),Nur=r(WRe," \u2014 "),DQ=n(WRe,"A",{href:!0});var x7t=s(DQ);qur=r(x7t,"TFBertLMHeadModel"),x7t.forEach(t),jur=r(WRe," (BERT model)"),WRe.forEach(t),Dur=i(Ce),A7=n(Ce,"LI",{});var QRe=s(A7);u2e=n(QRe,"STRONG",{});var $7t=s(u2e);Gur=r($7t,"camembert"),$7t.forEach(t),Our=r(QRe," \u2014 "),GQ=n(QRe,"A",{href:!0});var k7t=s(GQ);Vur=r(k7t,"TFCamembertForCausalLM"),k7t.forEach(t),Xur=r(QRe," (CamemBERT model)"),QRe.forEach(t),zur=i(Ce),y7=n(Ce,"LI",{});var HRe=s(y7);b2e=n(HRe,"STRONG",{});var S7t=s(b2e);Wur=r(S7t,"ctrl"),S7t.forEach(t),Qur=r(HRe," \u2014 "),OQ=n(HRe,"A",{href:!0});var R7t=s(OQ);Hur=r(R7t,"TFCTRLLMHeadModel"),R7t.forEach(t),Uur=r(HRe," (CTRL model)"),HRe.forEach(t),Jur=i(Ce),L7=n(Ce,"LI",{});var URe=s(L7);v2e=n(URe,"STRONG",{});var P7t=s(v2e);Yur=r(P7t,"gpt2"),P7t.forEach(t),Kur=r(URe," \u2014 "),VQ=n(URe,"A",{href:!0});var B7t=s(VQ);Zur=r(B7t,"TFGPT2LMHeadModel"),B7t.forEach(t),e4r=r(URe," (OpenAI GPT-2 model)"),URe.forEach(t),o4r=i(Ce),x7=n(Ce,"LI",{});var JRe=s(x7);F2e=n(JRe,"STRONG",{});var I7t=s(F2e);r4r=r(I7t,"gptj"),I7t.forEach(t),t4r=r(JRe," \u2014 "),XQ=n(JRe,"A",{href:!0});var N7t=s(XQ);a4r=r(N7t,"TFGPTJForCausalLM"),N7t.forEach(t),n4r=r(JRe," (GPT-J model)"),JRe.forEach(t),s4r=i(Ce),$7=n(Ce,"LI",{});var YRe=s($7);T2e=n(YRe,"STRONG",{});var q7t=s(T2e);l4r=r(q7t,"openai-gpt"),q7t.forEach(t),i4r=r(YRe," \u2014 "),zQ=n(YRe,"A",{href:!0});var j7t=s(zQ);d4r=r(j7t,"TFOpenAIGPTLMHeadModel"),j7t.forEach(t),c4r=r(YRe," (OpenAI GPT model)"),YRe.forEach(t),f4r=i(Ce),k7=n(Ce,"LI",{});var KRe=s(k7);M2e=n(KRe,"STRONG",{});var D7t=s(M2e);m4r=r(D7t,"rembert"),D7t.forEach(t),g4r=r(KRe," \u2014 "),WQ=n(KRe,"A",{href:!0});var G7t=s(WQ);h4r=r(G7t,"TFRemBertForCausalLM"),G7t.forEach(t),p4r=r(KRe," (RemBERT model)"),KRe.forEach(t),_4r=i(Ce),S7=n(Ce,"LI",{});var ZRe=s(S7);E2e=n(ZRe,"STRONG",{});var O7t=s(E2e);u4r=r(O7t,"roberta"),O7t.forEach(t),b4r=r(ZRe," \u2014 "),QQ=n(ZRe,"A",{href:!0});var V7t=s(QQ);v4r=r(V7t,"TFRobertaForCausalLM"),V7t.forEach(t),F4r=r(ZRe," (RoBERTa model)"),ZRe.forEach(t),T4r=i(Ce),R7=n(Ce,"LI",{});var ePe=s(R7);C2e=n(ePe,"STRONG",{});var X7t=s(C2e);M4r=r(X7t,"roformer"),X7t.forEach(t),E4r=r(ePe," \u2014 "),HQ=n(ePe,"A",{href:!0});var z7t=s(HQ);C4r=r(z7t,"TFRoFormerForCausalLM"),z7t.forEach(t),w4r=r(ePe," (RoFormer model)"),ePe.forEach(t),A4r=i(Ce),P7=n(Ce,"LI",{});var oPe=s(P7);w2e=n(oPe,"STRONG",{});var W7t=s(w2e);y4r=r(W7t,"transfo-xl"),W7t.forEach(t),L4r=r(oPe," \u2014 "),UQ=n(oPe,"A",{href:!0});var Q7t=s(UQ);x4r=r(Q7t,"TFTransfoXLLMHeadModel"),Q7t.forEach(t),$4r=r(oPe," (Transformer-XL model)"),oPe.forEach(t),k4r=i(Ce),B7=n(Ce,"LI",{});var rPe=s(B7);A2e=n(rPe,"STRONG",{});var H7t=s(A2e);S4r=r(H7t,"xlm"),H7t.forEach(t),R4r=r(rPe," \u2014 "),JQ=n(rPe,"A",{href:!0});var U7t=s(JQ);P4r=r(U7t,"TFXLMWithLMHeadModel"),U7t.forEach(t),B4r=r(rPe," (XLM model)"),rPe.forEach(t),I4r=i(Ce),I7=n(Ce,"LI",{});var tPe=s(I7);y2e=n(tPe,"STRONG",{});var J7t=s(y2e);N4r=r(J7t,"xlnet"),J7t.forEach(t),q4r=r(tPe," \u2014 "),YQ=n(tPe,"A",{href:!0});var Y7t=s(YQ);j4r=r(Y7t,"TFXLNetLMHeadModel"),Y7t.forEach(t),D4r=r(tPe," (XLNet model)"),tPe.forEach(t),Ce.forEach(t),G4r=i(vl),T(N7.$$.fragment,vl),vl.forEach(t),bl.forEach(t),Aje=i(f),Yd=n(f,"H2",{class:!0});var SGe=s(Yd);q7=n(SGe,"A",{id:!0,class:!0,href:!0});var K7t=s(q7);L2e=n(K7t,"SPAN",{});var Z7t=s(L2e);T(y8.$$.fragment,Z7t),Z7t.forEach(t),K7t.forEach(t),O4r=i(SGe),x2e=n(SGe,"SPAN",{});var eMt=s(x2e);V4r=r(eMt,"TFAutoModelForImageClassification"),eMt.forEach(t),SGe.forEach(t),yje=i(f),er=n(f,"DIV",{class:!0});var Fl=s(er);T(L8.$$.fragment,Fl),X4r=i(Fl),Kd=n(Fl,"P",{});var Cee=s(Kd);z4r=r(Cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),KQ=n(Cee,"A",{href:!0});var oMt=s(KQ);W4r=r(oMt,"from_pretrained()"),oMt.forEach(t),Q4r=r(Cee," class method or the "),ZQ=n(Cee,"A",{href:!0});var rMt=s(ZQ);H4r=r(rMt,"from_config()"),rMt.forEach(t),U4r=r(Cee,` class
method.`),Cee.forEach(t),J4r=i(Fl),x8=n(Fl,"P",{});var RGe=s(x8);Y4r=r(RGe,"This class cannot be instantiated directly using "),$2e=n(RGe,"CODE",{});var tMt=s($2e);K4r=r(tMt,"__init__()"),tMt.forEach(t),Z4r=r(RGe," (throws an error)."),RGe.forEach(t),e1r=i(Fl),$t=n(Fl,"DIV",{class:!0});var P6=s($t);T($8.$$.fragment,P6),o1r=i(P6),k2e=n(P6,"P",{});var aMt=s(k2e);r1r=r(aMt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),aMt.forEach(t),t1r=i(P6),Zd=n(P6,"P",{});var wee=s(Zd);a1r=r(wee,`Note:
Loading a model from its configuration file does `),S2e=n(wee,"STRONG",{});var nMt=s(S2e);n1r=r(nMt,"not"),nMt.forEach(t),s1r=r(wee,` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=n(wee,"A",{href:!0});var sMt=s(eH);l1r=r(sMt,"from_pretrained()"),sMt.forEach(t),i1r=r(wee," to load the model weights."),wee.forEach(t),d1r=i(P6),T(j7.$$.fragment,P6),P6.forEach(t),c1r=i(Fl),Lr=n(Fl,"DIV",{class:!0});var Tl=s(Lr);T(k8.$$.fragment,Tl),f1r=i(Tl),R2e=n(Tl,"P",{});var lMt=s(R2e);m1r=r(lMt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),lMt.forEach(t),g1r=i(Tl),on=n(Tl,"P",{});var B6=s(on);h1r=r(B6,"The model class to instantiate is selected based on the "),P2e=n(B6,"CODE",{});var iMt=s(P2e);p1r=r(iMt,"model_type"),iMt.forEach(t),_1r=r(B6,` property of the config object (either
passed as an argument or loaded from `),B2e=n(B6,"CODE",{});var dMt=s(B2e);u1r=r(dMt,"pretrained_model_name_or_path"),dMt.forEach(t),b1r=r(B6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=n(B6,"CODE",{});var cMt=s(I2e);v1r=r(cMt,"pretrained_model_name_or_path"),cMt.forEach(t),F1r=r(B6,":"),B6.forEach(t),T1r=i(Tl),rn=n(Tl,"UL",{});var I6=s(rn);D7=n(I6,"LI",{});var aPe=s(D7);N2e=n(aPe,"STRONG",{});var fMt=s(N2e);M1r=r(fMt,"convnext"),fMt.forEach(t),E1r=r(aPe," \u2014 "),oH=n(aPe,"A",{href:!0});var mMt=s(oH);C1r=r(mMt,"TFConvNextForImageClassification"),mMt.forEach(t),w1r=r(aPe," (ConvNext model)"),aPe.forEach(t),A1r=i(I6),G7=n(I6,"LI",{});var nPe=s(G7);q2e=n(nPe,"STRONG",{});var gMt=s(q2e);y1r=r(gMt,"data2vec-vision"),gMt.forEach(t),L1r=r(nPe," \u2014 "),rH=n(nPe,"A",{href:!0});var hMt=s(rH);x1r=r(hMt,"TFData2VecVisionForImageClassification"),hMt.forEach(t),$1r=r(nPe," (Data2VecVision model)"),nPe.forEach(t),k1r=i(I6),O7=n(I6,"LI",{});var sPe=s(O7);j2e=n(sPe,"STRONG",{});var pMt=s(j2e);S1r=r(pMt,"swin"),pMt.forEach(t),R1r=r(sPe," \u2014 "),tH=n(sPe,"A",{href:!0});var _Mt=s(tH);P1r=r(_Mt,"TFSwinForImageClassification"),_Mt.forEach(t),B1r=r(sPe," (Swin model)"),sPe.forEach(t),I1r=i(I6),V7=n(I6,"LI",{});var lPe=s(V7);D2e=n(lPe,"STRONG",{});var uMt=s(D2e);N1r=r(uMt,"vit"),uMt.forEach(t),q1r=r(lPe," \u2014 "),aH=n(lPe,"A",{href:!0});var bMt=s(aH);j1r=r(bMt,"TFViTForImageClassification"),bMt.forEach(t),D1r=r(lPe," (ViT model)"),lPe.forEach(t),I6.forEach(t),G1r=i(Tl),T(X7.$$.fragment,Tl),Tl.forEach(t),Fl.forEach(t),Lje=i(f),ec=n(f,"H2",{class:!0});var PGe=s(ec);z7=n(PGe,"A",{id:!0,class:!0,href:!0});var vMt=s(z7);G2e=n(vMt,"SPAN",{});var FMt=s(G2e);T(S8.$$.fragment,FMt),FMt.forEach(t),vMt.forEach(t),O1r=i(PGe),O2e=n(PGe,"SPAN",{});var TMt=s(O2e);V1r=r(TMt,"TFAutoModelForMaskedLM"),TMt.forEach(t),PGe.forEach(t),xje=i(f),or=n(f,"DIV",{class:!0});var Ml=s(or);T(R8.$$.fragment,Ml),X1r=i(Ml),oc=n(Ml,"P",{});var Aee=s(oc);z1r=r(Aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),nH=n(Aee,"A",{href:!0});var MMt=s(nH);W1r=r(MMt,"from_pretrained()"),MMt.forEach(t),Q1r=r(Aee," class method or the "),sH=n(Aee,"A",{href:!0});var EMt=s(sH);H1r=r(EMt,"from_config()"),EMt.forEach(t),U1r=r(Aee,` class
method.`),Aee.forEach(t),J1r=i(Ml),P8=n(Ml,"P",{});var BGe=s(P8);Y1r=r(BGe,"This class cannot be instantiated directly using "),V2e=n(BGe,"CODE",{});var CMt=s(V2e);K1r=r(CMt,"__init__()"),CMt.forEach(t),Z1r=r(BGe," (throws an error)."),BGe.forEach(t),ebr=i(Ml),kt=n(Ml,"DIV",{class:!0});var N6=s(kt);T(B8.$$.fragment,N6),obr=i(N6),X2e=n(N6,"P",{});var wMt=s(X2e);rbr=r(wMt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),wMt.forEach(t),tbr=i(N6),rc=n(N6,"P",{});var yee=s(rc);abr=r(yee,`Note:
Loading a model from its configuration file does `),z2e=n(yee,"STRONG",{});var AMt=s(z2e);nbr=r(AMt,"not"),AMt.forEach(t),sbr=r(yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),lH=n(yee,"A",{href:!0});var yMt=s(lH);lbr=r(yMt,"from_pretrained()"),yMt.forEach(t),ibr=r(yee," to load the model weights."),yee.forEach(t),dbr=i(N6),T(W7.$$.fragment,N6),N6.forEach(t),cbr=i(Ml),xr=n(Ml,"DIV",{class:!0});var El=s(xr);T(I8.$$.fragment,El),fbr=i(El),W2e=n(El,"P",{});var LMt=s(W2e);mbr=r(LMt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),LMt.forEach(t),gbr=i(El),tn=n(El,"P",{});var q6=s(tn);hbr=r(q6,"The model class to instantiate is selected based on the "),Q2e=n(q6,"CODE",{});var xMt=s(Q2e);pbr=r(xMt,"model_type"),xMt.forEach(t),_br=r(q6,` property of the config object (either
passed as an argument or loaded from `),H2e=n(q6,"CODE",{});var $Mt=s(H2e);ubr=r($Mt,"pretrained_model_name_or_path"),$Mt.forEach(t),bbr=r(q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U2e=n(q6,"CODE",{});var kMt=s(U2e);vbr=r(kMt,"pretrained_model_name_or_path"),kMt.forEach(t),Fbr=r(q6,":"),q6.forEach(t),Tbr=i(El),ie=n(El,"UL",{});var fe=s(ie);Q7=n(fe,"LI",{});var iPe=s(Q7);J2e=n(iPe,"STRONG",{});var SMt=s(J2e);Mbr=r(SMt,"albert"),SMt.forEach(t),Ebr=r(iPe," \u2014 "),iH=n(iPe,"A",{href:!0});var RMt=s(iH);Cbr=r(RMt,"TFAlbertForMaskedLM"),RMt.forEach(t),wbr=r(iPe," (ALBERT model)"),iPe.forEach(t),Abr=i(fe),H7=n(fe,"LI",{});var dPe=s(H7);Y2e=n(dPe,"STRONG",{});var PMt=s(Y2e);ybr=r(PMt,"bert"),PMt.forEach(t),Lbr=r(dPe," \u2014 "),dH=n(dPe,"A",{href:!0});var BMt=s(dH);xbr=r(BMt,"TFBertForMaskedLM"),BMt.forEach(t),$br=r(dPe," (BERT model)"),dPe.forEach(t),kbr=i(fe),U7=n(fe,"LI",{});var cPe=s(U7);K2e=n(cPe,"STRONG",{});var IMt=s(K2e);Sbr=r(IMt,"camembert"),IMt.forEach(t),Rbr=r(cPe," \u2014 "),cH=n(cPe,"A",{href:!0});var NMt=s(cH);Pbr=r(NMt,"TFCamembertForMaskedLM"),NMt.forEach(t),Bbr=r(cPe," (CamemBERT model)"),cPe.forEach(t),Ibr=i(fe),J7=n(fe,"LI",{});var fPe=s(J7);Z2e=n(fPe,"STRONG",{});var qMt=s(Z2e);Nbr=r(qMt,"convbert"),qMt.forEach(t),qbr=r(fPe," \u2014 "),fH=n(fPe,"A",{href:!0});var jMt=s(fH);jbr=r(jMt,"TFConvBertForMaskedLM"),jMt.forEach(t),Dbr=r(fPe," (ConvBERT model)"),fPe.forEach(t),Gbr=i(fe),Y7=n(fe,"LI",{});var mPe=s(Y7);eve=n(mPe,"STRONG",{});var DMt=s(eve);Obr=r(DMt,"deberta"),DMt.forEach(t),Vbr=r(mPe," \u2014 "),mH=n(mPe,"A",{href:!0});var GMt=s(mH);Xbr=r(GMt,"TFDebertaForMaskedLM"),GMt.forEach(t),zbr=r(mPe," (DeBERTa model)"),mPe.forEach(t),Wbr=i(fe),K7=n(fe,"LI",{});var gPe=s(K7);ove=n(gPe,"STRONG",{});var OMt=s(ove);Qbr=r(OMt,"deberta-v2"),OMt.forEach(t),Hbr=r(gPe," \u2014 "),gH=n(gPe,"A",{href:!0});var VMt=s(gH);Ubr=r(VMt,"TFDebertaV2ForMaskedLM"),VMt.forEach(t),Jbr=r(gPe," (DeBERTa-v2 model)"),gPe.forEach(t),Ybr=i(fe),Z7=n(fe,"LI",{});var hPe=s(Z7);rve=n(hPe,"STRONG",{});var XMt=s(rve);Kbr=r(XMt,"distilbert"),XMt.forEach(t),Zbr=r(hPe," \u2014 "),hH=n(hPe,"A",{href:!0});var zMt=s(hH);e2r=r(zMt,"TFDistilBertForMaskedLM"),zMt.forEach(t),o2r=r(hPe," (DistilBERT model)"),hPe.forEach(t),r2r=i(fe),eM=n(fe,"LI",{});var pPe=s(eM);tve=n(pPe,"STRONG",{});var WMt=s(tve);t2r=r(WMt,"electra"),WMt.forEach(t),a2r=r(pPe," \u2014 "),pH=n(pPe,"A",{href:!0});var QMt=s(pH);n2r=r(QMt,"TFElectraForMaskedLM"),QMt.forEach(t),s2r=r(pPe," (ELECTRA model)"),pPe.forEach(t),l2r=i(fe),oM=n(fe,"LI",{});var _Pe=s(oM);ave=n(_Pe,"STRONG",{});var HMt=s(ave);i2r=r(HMt,"flaubert"),HMt.forEach(t),d2r=r(_Pe," \u2014 "),_H=n(_Pe,"A",{href:!0});var UMt=s(_H);c2r=r(UMt,"TFFlaubertWithLMHeadModel"),UMt.forEach(t),f2r=r(_Pe," (FlauBERT model)"),_Pe.forEach(t),m2r=i(fe),rM=n(fe,"LI",{});var uPe=s(rM);nve=n(uPe,"STRONG",{});var JMt=s(nve);g2r=r(JMt,"funnel"),JMt.forEach(t),h2r=r(uPe," \u2014 "),uH=n(uPe,"A",{href:!0});var YMt=s(uH);p2r=r(YMt,"TFFunnelForMaskedLM"),YMt.forEach(t),_2r=r(uPe," (Funnel Transformer model)"),uPe.forEach(t),u2r=i(fe),tM=n(fe,"LI",{});var bPe=s(tM);sve=n(bPe,"STRONG",{});var KMt=s(sve);b2r=r(KMt,"layoutlm"),KMt.forEach(t),v2r=r(bPe," \u2014 "),bH=n(bPe,"A",{href:!0});var ZMt=s(bH);F2r=r(ZMt,"TFLayoutLMForMaskedLM"),ZMt.forEach(t),T2r=r(bPe," (LayoutLM model)"),bPe.forEach(t),M2r=i(fe),aM=n(fe,"LI",{});var vPe=s(aM);lve=n(vPe,"STRONG",{});var eEt=s(lve);E2r=r(eEt,"longformer"),eEt.forEach(t),C2r=r(vPe," \u2014 "),vH=n(vPe,"A",{href:!0});var oEt=s(vH);w2r=r(oEt,"TFLongformerForMaskedLM"),oEt.forEach(t),A2r=r(vPe," (Longformer model)"),vPe.forEach(t),y2r=i(fe),nM=n(fe,"LI",{});var FPe=s(nM);ive=n(FPe,"STRONG",{});var rEt=s(ive);L2r=r(rEt,"mobilebert"),rEt.forEach(t),x2r=r(FPe," \u2014 "),FH=n(FPe,"A",{href:!0});var tEt=s(FH);$2r=r(tEt,"TFMobileBertForMaskedLM"),tEt.forEach(t),k2r=r(FPe," (MobileBERT model)"),FPe.forEach(t),S2r=i(fe),sM=n(fe,"LI",{});var TPe=s(sM);dve=n(TPe,"STRONG",{});var aEt=s(dve);R2r=r(aEt,"mpnet"),aEt.forEach(t),P2r=r(TPe," \u2014 "),TH=n(TPe,"A",{href:!0});var nEt=s(TH);B2r=r(nEt,"TFMPNetForMaskedLM"),nEt.forEach(t),I2r=r(TPe," (MPNet model)"),TPe.forEach(t),N2r=i(fe),lM=n(fe,"LI",{});var MPe=s(lM);cve=n(MPe,"STRONG",{});var sEt=s(cve);q2r=r(sEt,"rembert"),sEt.forEach(t),j2r=r(MPe," \u2014 "),MH=n(MPe,"A",{href:!0});var lEt=s(MH);D2r=r(lEt,"TFRemBertForMaskedLM"),lEt.forEach(t),G2r=r(MPe," (RemBERT model)"),MPe.forEach(t),O2r=i(fe),iM=n(fe,"LI",{});var EPe=s(iM);fve=n(EPe,"STRONG",{});var iEt=s(fve);V2r=r(iEt,"roberta"),iEt.forEach(t),X2r=r(EPe," \u2014 "),EH=n(EPe,"A",{href:!0});var dEt=s(EH);z2r=r(dEt,"TFRobertaForMaskedLM"),dEt.forEach(t),W2r=r(EPe," (RoBERTa model)"),EPe.forEach(t),Q2r=i(fe),dM=n(fe,"LI",{});var CPe=s(dM);mve=n(CPe,"STRONG",{});var cEt=s(mve);H2r=r(cEt,"roformer"),cEt.forEach(t),U2r=r(CPe," \u2014 "),CH=n(CPe,"A",{href:!0});var fEt=s(CH);J2r=r(fEt,"TFRoFormerForMaskedLM"),fEt.forEach(t),Y2r=r(CPe," (RoFormer model)"),CPe.forEach(t),K2r=i(fe),cM=n(fe,"LI",{});var wPe=s(cM);gve=n(wPe,"STRONG",{});var mEt=s(gve);Z2r=r(mEt,"tapas"),mEt.forEach(t),evr=r(wPe," \u2014 "),wH=n(wPe,"A",{href:!0});var gEt=s(wH);ovr=r(gEt,"TFTapasForMaskedLM"),gEt.forEach(t),rvr=r(wPe," (TAPAS model)"),wPe.forEach(t),tvr=i(fe),fM=n(fe,"LI",{});var APe=s(fM);hve=n(APe,"STRONG",{});var hEt=s(hve);avr=r(hEt,"xlm"),hEt.forEach(t),nvr=r(APe," \u2014 "),AH=n(APe,"A",{href:!0});var pEt=s(AH);svr=r(pEt,"TFXLMWithLMHeadModel"),pEt.forEach(t),lvr=r(APe," (XLM model)"),APe.forEach(t),ivr=i(fe),mM=n(fe,"LI",{});var yPe=s(mM);pve=n(yPe,"STRONG",{});var _Et=s(pve);dvr=r(_Et,"xlm-roberta"),_Et.forEach(t),cvr=r(yPe," \u2014 "),yH=n(yPe,"A",{href:!0});var uEt=s(yH);fvr=r(uEt,"TFXLMRobertaForMaskedLM"),uEt.forEach(t),mvr=r(yPe," (XLM-RoBERTa model)"),yPe.forEach(t),fe.forEach(t),gvr=i(El),T(gM.$$.fragment,El),El.forEach(t),Ml.forEach(t),$je=i(f),tc=n(f,"H2",{class:!0});var IGe=s(tc);hM=n(IGe,"A",{id:!0,class:!0,href:!0});var bEt=s(hM);_ve=n(bEt,"SPAN",{});var vEt=s(_ve);T(N8.$$.fragment,vEt),vEt.forEach(t),bEt.forEach(t),hvr=i(IGe),uve=n(IGe,"SPAN",{});var FEt=s(uve);pvr=r(FEt,"TFAutoModelForSeq2SeqLM"),FEt.forEach(t),IGe.forEach(t),kje=i(f),rr=n(f,"DIV",{class:!0});var Cl=s(rr);T(q8.$$.fragment,Cl),_vr=i(Cl),ac=n(Cl,"P",{});var Lee=s(ac);uvr=r(Lee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),LH=n(Lee,"A",{href:!0});var TEt=s(LH);bvr=r(TEt,"from_pretrained()"),TEt.forEach(t),vvr=r(Lee," class method or the "),xH=n(Lee,"A",{href:!0});var MEt=s(xH);Fvr=r(MEt,"from_config()"),MEt.forEach(t),Tvr=r(Lee,` class
method.`),Lee.forEach(t),Mvr=i(Cl),j8=n(Cl,"P",{});var NGe=s(j8);Evr=r(NGe,"This class cannot be instantiated directly using "),bve=n(NGe,"CODE",{});var EEt=s(bve);Cvr=r(EEt,"__init__()"),EEt.forEach(t),wvr=r(NGe," (throws an error)."),NGe.forEach(t),Avr=i(Cl),St=n(Cl,"DIV",{class:!0});var j6=s(St);T(D8.$$.fragment,j6),yvr=i(j6),vve=n(j6,"P",{});var CEt=s(vve);Lvr=r(CEt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),CEt.forEach(t),xvr=i(j6),nc=n(j6,"P",{});var xee=s(nc);$vr=r(xee,`Note:
Loading a model from its configuration file does `),Fve=n(xee,"STRONG",{});var wEt=s(Fve);kvr=r(wEt,"not"),wEt.forEach(t),Svr=r(xee,` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=n(xee,"A",{href:!0});var AEt=s($H);Rvr=r(AEt,"from_pretrained()"),AEt.forEach(t),Pvr=r(xee," to load the model weights."),xee.forEach(t),Bvr=i(j6),T(pM.$$.fragment,j6),j6.forEach(t),Ivr=i(Cl),$r=n(Cl,"DIV",{class:!0});var wl=s($r);T(G8.$$.fragment,wl),Nvr=i(wl),Tve=n(wl,"P",{});var yEt=s(Tve);qvr=r(yEt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),yEt.forEach(t),jvr=i(wl),an=n(wl,"P",{});var D6=s(an);Dvr=r(D6,"The model class to instantiate is selected based on the "),Mve=n(D6,"CODE",{});var LEt=s(Mve);Gvr=r(LEt,"model_type"),LEt.forEach(t),Ovr=r(D6,` property of the config object (either
passed as an argument or loaded from `),Eve=n(D6,"CODE",{});var xEt=s(Eve);Vvr=r(xEt,"pretrained_model_name_or_path"),xEt.forEach(t),Xvr=r(D6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cve=n(D6,"CODE",{});var $Et=s(Cve);zvr=r($Et,"pretrained_model_name_or_path"),$Et.forEach(t),Wvr=r(D6,":"),D6.forEach(t),Qvr=i(wl),ye=n(wl,"UL",{});var Be=s(ye);_M=n(Be,"LI",{});var LPe=s(_M);wve=n(LPe,"STRONG",{});var kEt=s(wve);Hvr=r(kEt,"bart"),kEt.forEach(t),Uvr=r(LPe," \u2014 "),kH=n(LPe,"A",{href:!0});var SEt=s(kH);Jvr=r(SEt,"TFBartForConditionalGeneration"),SEt.forEach(t),Yvr=r(LPe," (BART model)"),LPe.forEach(t),Kvr=i(Be),uM=n(Be,"LI",{});var xPe=s(uM);Ave=n(xPe,"STRONG",{});var REt=s(Ave);Zvr=r(REt,"blenderbot"),REt.forEach(t),e3r=r(xPe," \u2014 "),SH=n(xPe,"A",{href:!0});var PEt=s(SH);o3r=r(PEt,"TFBlenderbotForConditionalGeneration"),PEt.forEach(t),r3r=r(xPe," (Blenderbot model)"),xPe.forEach(t),t3r=i(Be),bM=n(Be,"LI",{});var $Pe=s(bM);yve=n($Pe,"STRONG",{});var BEt=s(yve);a3r=r(BEt,"blenderbot-small"),BEt.forEach(t),n3r=r($Pe," \u2014 "),RH=n($Pe,"A",{href:!0});var IEt=s(RH);s3r=r(IEt,"TFBlenderbotSmallForConditionalGeneration"),IEt.forEach(t),l3r=r($Pe," (BlenderbotSmall model)"),$Pe.forEach(t),i3r=i(Be),vM=n(Be,"LI",{});var kPe=s(vM);Lve=n(kPe,"STRONG",{});var NEt=s(Lve);d3r=r(NEt,"encoder-decoder"),NEt.forEach(t),c3r=r(kPe," \u2014 "),PH=n(kPe,"A",{href:!0});var qEt=s(PH);f3r=r(qEt,"TFEncoderDecoderModel"),qEt.forEach(t),m3r=r(kPe," (Encoder decoder model)"),kPe.forEach(t),g3r=i(Be),FM=n(Be,"LI",{});var SPe=s(FM);xve=n(SPe,"STRONG",{});var jEt=s(xve);h3r=r(jEt,"led"),jEt.forEach(t),p3r=r(SPe," \u2014 "),BH=n(SPe,"A",{href:!0});var DEt=s(BH);_3r=r(DEt,"TFLEDForConditionalGeneration"),DEt.forEach(t),u3r=r(SPe," (LED model)"),SPe.forEach(t),b3r=i(Be),TM=n(Be,"LI",{});var RPe=s(TM);$ve=n(RPe,"STRONG",{});var GEt=s($ve);v3r=r(GEt,"marian"),GEt.forEach(t),F3r=r(RPe," \u2014 "),IH=n(RPe,"A",{href:!0});var OEt=s(IH);T3r=r(OEt,"TFMarianMTModel"),OEt.forEach(t),M3r=r(RPe," (Marian model)"),RPe.forEach(t),E3r=i(Be),MM=n(Be,"LI",{});var PPe=s(MM);kve=n(PPe,"STRONG",{});var VEt=s(kve);C3r=r(VEt,"mbart"),VEt.forEach(t),w3r=r(PPe," \u2014 "),NH=n(PPe,"A",{href:!0});var XEt=s(NH);A3r=r(XEt,"TFMBartForConditionalGeneration"),XEt.forEach(t),y3r=r(PPe," (mBART model)"),PPe.forEach(t),L3r=i(Be),EM=n(Be,"LI",{});var BPe=s(EM);Sve=n(BPe,"STRONG",{});var zEt=s(Sve);x3r=r(zEt,"mt5"),zEt.forEach(t),$3r=r(BPe," \u2014 "),qH=n(BPe,"A",{href:!0});var WEt=s(qH);k3r=r(WEt,"TFMT5ForConditionalGeneration"),WEt.forEach(t),S3r=r(BPe," (mT5 model)"),BPe.forEach(t),R3r=i(Be),CM=n(Be,"LI",{});var IPe=s(CM);Rve=n(IPe,"STRONG",{});var QEt=s(Rve);P3r=r(QEt,"pegasus"),QEt.forEach(t),B3r=r(IPe," \u2014 "),jH=n(IPe,"A",{href:!0});var HEt=s(jH);I3r=r(HEt,"TFPegasusForConditionalGeneration"),HEt.forEach(t),N3r=r(IPe," (Pegasus model)"),IPe.forEach(t),q3r=i(Be),wM=n(Be,"LI",{});var NPe=s(wM);Pve=n(NPe,"STRONG",{});var UEt=s(Pve);j3r=r(UEt,"t5"),UEt.forEach(t),D3r=r(NPe," \u2014 "),DH=n(NPe,"A",{href:!0});var JEt=s(DH);G3r=r(JEt,"TFT5ForConditionalGeneration"),JEt.forEach(t),O3r=r(NPe," (T5 model)"),NPe.forEach(t),Be.forEach(t),V3r=i(wl),T(AM.$$.fragment,wl),wl.forEach(t),Cl.forEach(t),Sje=i(f),sc=n(f,"H2",{class:!0});var qGe=s(sc);yM=n(qGe,"A",{id:!0,class:!0,href:!0});var YEt=s(yM);Bve=n(YEt,"SPAN",{});var KEt=s(Bve);T(O8.$$.fragment,KEt),KEt.forEach(t),YEt.forEach(t),X3r=i(qGe),Ive=n(qGe,"SPAN",{});var ZEt=s(Ive);z3r=r(ZEt,"TFAutoModelForSequenceClassification"),ZEt.forEach(t),qGe.forEach(t),Rje=i(f),tr=n(f,"DIV",{class:!0});var Al=s(tr);T(V8.$$.fragment,Al),W3r=i(Al),lc=n(Al,"P",{});var $ee=s(lc);Q3r=r($ee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),GH=n($ee,"A",{href:!0});var eCt=s(GH);H3r=r(eCt,"from_pretrained()"),eCt.forEach(t),U3r=r($ee," class method or the "),OH=n($ee,"A",{href:!0});var oCt=s(OH);J3r=r(oCt,"from_config()"),oCt.forEach(t),Y3r=r($ee,` class
method.`),$ee.forEach(t),K3r=i(Al),X8=n(Al,"P",{});var jGe=s(X8);Z3r=r(jGe,"This class cannot be instantiated directly using "),Nve=n(jGe,"CODE",{});var rCt=s(Nve);eFr=r(rCt,"__init__()"),rCt.forEach(t),oFr=r(jGe," (throws an error)."),jGe.forEach(t),rFr=i(Al),Rt=n(Al,"DIV",{class:!0});var G6=s(Rt);T(z8.$$.fragment,G6),tFr=i(G6),qve=n(G6,"P",{});var tCt=s(qve);aFr=r(tCt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),tCt.forEach(t),nFr=i(G6),ic=n(G6,"P",{});var kee=s(ic);sFr=r(kee,`Note:
Loading a model from its configuration file does `),jve=n(kee,"STRONG",{});var aCt=s(jve);lFr=r(aCt,"not"),aCt.forEach(t),iFr=r(kee,` load the model weights. It only affects the
model\u2019s configuration. Use `),VH=n(kee,"A",{href:!0});var nCt=s(VH);dFr=r(nCt,"from_pretrained()"),nCt.forEach(t),cFr=r(kee," to load the model weights."),kee.forEach(t),fFr=i(G6),T(LM.$$.fragment,G6),G6.forEach(t),mFr=i(Al),kr=n(Al,"DIV",{class:!0});var yl=s(kr);T(W8.$$.fragment,yl),gFr=i(yl),Dve=n(yl,"P",{});var sCt=s(Dve);hFr=r(sCt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),sCt.forEach(t),pFr=i(yl),nn=n(yl,"P",{});var O6=s(nn);_Fr=r(O6,"The model class to instantiate is selected based on the "),Gve=n(O6,"CODE",{});var lCt=s(Gve);uFr=r(lCt,"model_type"),lCt.forEach(t),bFr=r(O6,` property of the config object (either
passed as an argument or loaded from `),Ove=n(O6,"CODE",{});var iCt=s(Ove);vFr=r(iCt,"pretrained_model_name_or_path"),iCt.forEach(t),FFr=r(O6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vve=n(O6,"CODE",{});var dCt=s(Vve);TFr=r(dCt,"pretrained_model_name_or_path"),dCt.forEach(t),MFr=r(O6,":"),O6.forEach(t),EFr=i(yl),oe=n(yl,"UL",{});var ae=s(oe);xM=n(ae,"LI",{});var qPe=s(xM);Xve=n(qPe,"STRONG",{});var cCt=s(Xve);CFr=r(cCt,"albert"),cCt.forEach(t),wFr=r(qPe," \u2014 "),XH=n(qPe,"A",{href:!0});var fCt=s(XH);AFr=r(fCt,"TFAlbertForSequenceClassification"),fCt.forEach(t),yFr=r(qPe," (ALBERT model)"),qPe.forEach(t),LFr=i(ae),$M=n(ae,"LI",{});var jPe=s($M);zve=n(jPe,"STRONG",{});var mCt=s(zve);xFr=r(mCt,"bert"),mCt.forEach(t),$Fr=r(jPe," \u2014 "),zH=n(jPe,"A",{href:!0});var gCt=s(zH);kFr=r(gCt,"TFBertForSequenceClassification"),gCt.forEach(t),SFr=r(jPe," (BERT model)"),jPe.forEach(t),RFr=i(ae),kM=n(ae,"LI",{});var DPe=s(kM);Wve=n(DPe,"STRONG",{});var hCt=s(Wve);PFr=r(hCt,"camembert"),hCt.forEach(t),BFr=r(DPe," \u2014 "),WH=n(DPe,"A",{href:!0});var pCt=s(WH);IFr=r(pCt,"TFCamembertForSequenceClassification"),pCt.forEach(t),NFr=r(DPe," (CamemBERT model)"),DPe.forEach(t),qFr=i(ae),SM=n(ae,"LI",{});var GPe=s(SM);Qve=n(GPe,"STRONG",{});var _Ct=s(Qve);jFr=r(_Ct,"convbert"),_Ct.forEach(t),DFr=r(GPe," \u2014 "),QH=n(GPe,"A",{href:!0});var uCt=s(QH);GFr=r(uCt,"TFConvBertForSequenceClassification"),uCt.forEach(t),OFr=r(GPe," (ConvBERT model)"),GPe.forEach(t),VFr=i(ae),RM=n(ae,"LI",{});var OPe=s(RM);Hve=n(OPe,"STRONG",{});var bCt=s(Hve);XFr=r(bCt,"ctrl"),bCt.forEach(t),zFr=r(OPe," \u2014 "),HH=n(OPe,"A",{href:!0});var vCt=s(HH);WFr=r(vCt,"TFCTRLForSequenceClassification"),vCt.forEach(t),QFr=r(OPe," (CTRL model)"),OPe.forEach(t),HFr=i(ae),PM=n(ae,"LI",{});var VPe=s(PM);Uve=n(VPe,"STRONG",{});var FCt=s(Uve);UFr=r(FCt,"deberta"),FCt.forEach(t),JFr=r(VPe," \u2014 "),UH=n(VPe,"A",{href:!0});var TCt=s(UH);YFr=r(TCt,"TFDebertaForSequenceClassification"),TCt.forEach(t),KFr=r(VPe," (DeBERTa model)"),VPe.forEach(t),ZFr=i(ae),BM=n(ae,"LI",{});var XPe=s(BM);Jve=n(XPe,"STRONG",{});var MCt=s(Jve);eTr=r(MCt,"deberta-v2"),MCt.forEach(t),oTr=r(XPe," \u2014 "),JH=n(XPe,"A",{href:!0});var ECt=s(JH);rTr=r(ECt,"TFDebertaV2ForSequenceClassification"),ECt.forEach(t),tTr=r(XPe," (DeBERTa-v2 model)"),XPe.forEach(t),aTr=i(ae),IM=n(ae,"LI",{});var zPe=s(IM);Yve=n(zPe,"STRONG",{});var CCt=s(Yve);nTr=r(CCt,"distilbert"),CCt.forEach(t),sTr=r(zPe," \u2014 "),YH=n(zPe,"A",{href:!0});var wCt=s(YH);lTr=r(wCt,"TFDistilBertForSequenceClassification"),wCt.forEach(t),iTr=r(zPe," (DistilBERT model)"),zPe.forEach(t),dTr=i(ae),NM=n(ae,"LI",{});var WPe=s(NM);Kve=n(WPe,"STRONG",{});var ACt=s(Kve);cTr=r(ACt,"electra"),ACt.forEach(t),fTr=r(WPe," \u2014 "),KH=n(WPe,"A",{href:!0});var yCt=s(KH);mTr=r(yCt,"TFElectraForSequenceClassification"),yCt.forEach(t),gTr=r(WPe," (ELECTRA model)"),WPe.forEach(t),hTr=i(ae),qM=n(ae,"LI",{});var QPe=s(qM);Zve=n(QPe,"STRONG",{});var LCt=s(Zve);pTr=r(LCt,"flaubert"),LCt.forEach(t),_Tr=r(QPe," \u2014 "),ZH=n(QPe,"A",{href:!0});var xCt=s(ZH);uTr=r(xCt,"TFFlaubertForSequenceClassification"),xCt.forEach(t),bTr=r(QPe," (FlauBERT model)"),QPe.forEach(t),vTr=i(ae),jM=n(ae,"LI",{});var HPe=s(jM);e3e=n(HPe,"STRONG",{});var $Ct=s(e3e);FTr=r($Ct,"funnel"),$Ct.forEach(t),TTr=r(HPe," \u2014 "),eU=n(HPe,"A",{href:!0});var kCt=s(eU);MTr=r(kCt,"TFFunnelForSequenceClassification"),kCt.forEach(t),ETr=r(HPe," (Funnel Transformer model)"),HPe.forEach(t),CTr=i(ae),DM=n(ae,"LI",{});var UPe=s(DM);o3e=n(UPe,"STRONG",{});var SCt=s(o3e);wTr=r(SCt,"gpt2"),SCt.forEach(t),ATr=r(UPe," \u2014 "),oU=n(UPe,"A",{href:!0});var RCt=s(oU);yTr=r(RCt,"TFGPT2ForSequenceClassification"),RCt.forEach(t),LTr=r(UPe," (OpenAI GPT-2 model)"),UPe.forEach(t),xTr=i(ae),GM=n(ae,"LI",{});var JPe=s(GM);r3e=n(JPe,"STRONG",{});var PCt=s(r3e);$Tr=r(PCt,"gptj"),PCt.forEach(t),kTr=r(JPe," \u2014 "),rU=n(JPe,"A",{href:!0});var BCt=s(rU);STr=r(BCt,"TFGPTJForSequenceClassification"),BCt.forEach(t),RTr=r(JPe," (GPT-J model)"),JPe.forEach(t),PTr=i(ae),OM=n(ae,"LI",{});var YPe=s(OM);t3e=n(YPe,"STRONG",{});var ICt=s(t3e);BTr=r(ICt,"layoutlm"),ICt.forEach(t),ITr=r(YPe," \u2014 "),tU=n(YPe,"A",{href:!0});var NCt=s(tU);NTr=r(NCt,"TFLayoutLMForSequenceClassification"),NCt.forEach(t),qTr=r(YPe," (LayoutLM model)"),YPe.forEach(t),jTr=i(ae),VM=n(ae,"LI",{});var KPe=s(VM);a3e=n(KPe,"STRONG",{});var qCt=s(a3e);DTr=r(qCt,"longformer"),qCt.forEach(t),GTr=r(KPe," \u2014 "),aU=n(KPe,"A",{href:!0});var jCt=s(aU);OTr=r(jCt,"TFLongformerForSequenceClassification"),jCt.forEach(t),VTr=r(KPe," (Longformer model)"),KPe.forEach(t),XTr=i(ae),XM=n(ae,"LI",{});var ZPe=s(XM);n3e=n(ZPe,"STRONG",{});var DCt=s(n3e);zTr=r(DCt,"mobilebert"),DCt.forEach(t),WTr=r(ZPe," \u2014 "),nU=n(ZPe,"A",{href:!0});var GCt=s(nU);QTr=r(GCt,"TFMobileBertForSequenceClassification"),GCt.forEach(t),HTr=r(ZPe," (MobileBERT model)"),ZPe.forEach(t),UTr=i(ae),zM=n(ae,"LI",{});var eBe=s(zM);s3e=n(eBe,"STRONG",{});var OCt=s(s3e);JTr=r(OCt,"mpnet"),OCt.forEach(t),YTr=r(eBe," \u2014 "),sU=n(eBe,"A",{href:!0});var VCt=s(sU);KTr=r(VCt,"TFMPNetForSequenceClassification"),VCt.forEach(t),ZTr=r(eBe," (MPNet model)"),eBe.forEach(t),e7r=i(ae),WM=n(ae,"LI",{});var oBe=s(WM);l3e=n(oBe,"STRONG",{});var XCt=s(l3e);o7r=r(XCt,"openai-gpt"),XCt.forEach(t),r7r=r(oBe," \u2014 "),lU=n(oBe,"A",{href:!0});var zCt=s(lU);t7r=r(zCt,"TFOpenAIGPTForSequenceClassification"),zCt.forEach(t),a7r=r(oBe," (OpenAI GPT model)"),oBe.forEach(t),n7r=i(ae),QM=n(ae,"LI",{});var rBe=s(QM);i3e=n(rBe,"STRONG",{});var WCt=s(i3e);s7r=r(WCt,"rembert"),WCt.forEach(t),l7r=r(rBe," \u2014 "),iU=n(rBe,"A",{href:!0});var QCt=s(iU);i7r=r(QCt,"TFRemBertForSequenceClassification"),QCt.forEach(t),d7r=r(rBe," (RemBERT model)"),rBe.forEach(t),c7r=i(ae),HM=n(ae,"LI",{});var tBe=s(HM);d3e=n(tBe,"STRONG",{});var HCt=s(d3e);f7r=r(HCt,"roberta"),HCt.forEach(t),m7r=r(tBe," \u2014 "),dU=n(tBe,"A",{href:!0});var UCt=s(dU);g7r=r(UCt,"TFRobertaForSequenceClassification"),UCt.forEach(t),h7r=r(tBe," (RoBERTa model)"),tBe.forEach(t),p7r=i(ae),UM=n(ae,"LI",{});var aBe=s(UM);c3e=n(aBe,"STRONG",{});var JCt=s(c3e);_7r=r(JCt,"roformer"),JCt.forEach(t),u7r=r(aBe," \u2014 "),cU=n(aBe,"A",{href:!0});var YCt=s(cU);b7r=r(YCt,"TFRoFormerForSequenceClassification"),YCt.forEach(t),v7r=r(aBe," (RoFormer model)"),aBe.forEach(t),F7r=i(ae),JM=n(ae,"LI",{});var nBe=s(JM);f3e=n(nBe,"STRONG",{});var KCt=s(f3e);T7r=r(KCt,"tapas"),KCt.forEach(t),M7r=r(nBe," \u2014 "),fU=n(nBe,"A",{href:!0});var ZCt=s(fU);E7r=r(ZCt,"TFTapasForSequenceClassification"),ZCt.forEach(t),C7r=r(nBe," (TAPAS model)"),nBe.forEach(t),w7r=i(ae),YM=n(ae,"LI",{});var sBe=s(YM);m3e=n(sBe,"STRONG",{});var e5t=s(m3e);A7r=r(e5t,"transfo-xl"),e5t.forEach(t),y7r=r(sBe," \u2014 "),mU=n(sBe,"A",{href:!0});var o5t=s(mU);L7r=r(o5t,"TFTransfoXLForSequenceClassification"),o5t.forEach(t),x7r=r(sBe," (Transformer-XL model)"),sBe.forEach(t),$7r=i(ae),KM=n(ae,"LI",{});var lBe=s(KM);g3e=n(lBe,"STRONG",{});var r5t=s(g3e);k7r=r(r5t,"xlm"),r5t.forEach(t),S7r=r(lBe," \u2014 "),gU=n(lBe,"A",{href:!0});var t5t=s(gU);R7r=r(t5t,"TFXLMForSequenceClassification"),t5t.forEach(t),P7r=r(lBe," (XLM model)"),lBe.forEach(t),B7r=i(ae),ZM=n(ae,"LI",{});var iBe=s(ZM);h3e=n(iBe,"STRONG",{});var a5t=s(h3e);I7r=r(a5t,"xlm-roberta"),a5t.forEach(t),N7r=r(iBe," \u2014 "),hU=n(iBe,"A",{href:!0});var n5t=s(hU);q7r=r(n5t,"TFXLMRobertaForSequenceClassification"),n5t.forEach(t),j7r=r(iBe," (XLM-RoBERTa model)"),iBe.forEach(t),D7r=i(ae),eE=n(ae,"LI",{});var dBe=s(eE);p3e=n(dBe,"STRONG",{});var s5t=s(p3e);G7r=r(s5t,"xlnet"),s5t.forEach(t),O7r=r(dBe," \u2014 "),pU=n(dBe,"A",{href:!0});var l5t=s(pU);V7r=r(l5t,"TFXLNetForSequenceClassification"),l5t.forEach(t),X7r=r(dBe," (XLNet model)"),dBe.forEach(t),ae.forEach(t),z7r=i(yl),T(oE.$$.fragment,yl),yl.forEach(t),Al.forEach(t),Pje=i(f),dc=n(f,"H2",{class:!0});var DGe=s(dc);rE=n(DGe,"A",{id:!0,class:!0,href:!0});var i5t=s(rE);_3e=n(i5t,"SPAN",{});var d5t=s(_3e);T(Q8.$$.fragment,d5t),d5t.forEach(t),i5t.forEach(t),W7r=i(DGe),u3e=n(DGe,"SPAN",{});var c5t=s(u3e);Q7r=r(c5t,"TFAutoModelForMultipleChoice"),c5t.forEach(t),DGe.forEach(t),Bje=i(f),ar=n(f,"DIV",{class:!0});var Ll=s(ar);T(H8.$$.fragment,Ll),H7r=i(Ll),cc=n(Ll,"P",{});var See=s(cc);U7r=r(See,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),_U=n(See,"A",{href:!0});var f5t=s(_U);J7r=r(f5t,"from_pretrained()"),f5t.forEach(t),Y7r=r(See," class method or the "),uU=n(See,"A",{href:!0});var m5t=s(uU);K7r=r(m5t,"from_config()"),m5t.forEach(t),Z7r=r(See,` class
method.`),See.forEach(t),eMr=i(Ll),U8=n(Ll,"P",{});var GGe=s(U8);oMr=r(GGe,"This class cannot be instantiated directly using "),b3e=n(GGe,"CODE",{});var g5t=s(b3e);rMr=r(g5t,"__init__()"),g5t.forEach(t),tMr=r(GGe," (throws an error)."),GGe.forEach(t),aMr=i(Ll),Pt=n(Ll,"DIV",{class:!0});var V6=s(Pt);T(J8.$$.fragment,V6),nMr=i(V6),v3e=n(V6,"P",{});var h5t=s(v3e);sMr=r(h5t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),h5t.forEach(t),lMr=i(V6),fc=n(V6,"P",{});var Ree=s(fc);iMr=r(Ree,`Note:
Loading a model from its configuration file does `),F3e=n(Ree,"STRONG",{});var p5t=s(F3e);dMr=r(p5t,"not"),p5t.forEach(t),cMr=r(Ree,` load the model weights. It only affects the
model\u2019s configuration. Use `),bU=n(Ree,"A",{href:!0});var _5t=s(bU);fMr=r(_5t,"from_pretrained()"),_5t.forEach(t),mMr=r(Ree," to load the model weights."),Ree.forEach(t),gMr=i(V6),T(tE.$$.fragment,V6),V6.forEach(t),hMr=i(Ll),Sr=n(Ll,"DIV",{class:!0});var xl=s(Sr);T(Y8.$$.fragment,xl),pMr=i(xl),T3e=n(xl,"P",{});var u5t=s(T3e);_Mr=r(u5t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),u5t.forEach(t),uMr=i(xl),sn=n(xl,"P",{});var X6=s(sn);bMr=r(X6,"The model class to instantiate is selected based on the "),M3e=n(X6,"CODE",{});var b5t=s(M3e);vMr=r(b5t,"model_type"),b5t.forEach(t),FMr=r(X6,` property of the config object (either
passed as an argument or loaded from `),E3e=n(X6,"CODE",{});var v5t=s(E3e);TMr=r(v5t,"pretrained_model_name_or_path"),v5t.forEach(t),MMr=r(X6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C3e=n(X6,"CODE",{});var F5t=s(C3e);EMr=r(F5t,"pretrained_model_name_or_path"),F5t.forEach(t),CMr=r(X6,":"),X6.forEach(t),wMr=i(xl),pe=n(xl,"UL",{});var be=s(pe);aE=n(be,"LI",{});var cBe=s(aE);w3e=n(cBe,"STRONG",{});var T5t=s(w3e);AMr=r(T5t,"albert"),T5t.forEach(t),yMr=r(cBe," \u2014 "),vU=n(cBe,"A",{href:!0});var M5t=s(vU);LMr=r(M5t,"TFAlbertForMultipleChoice"),M5t.forEach(t),xMr=r(cBe," (ALBERT model)"),cBe.forEach(t),$Mr=i(be),nE=n(be,"LI",{});var fBe=s(nE);A3e=n(fBe,"STRONG",{});var E5t=s(A3e);kMr=r(E5t,"bert"),E5t.forEach(t),SMr=r(fBe," \u2014 "),FU=n(fBe,"A",{href:!0});var C5t=s(FU);RMr=r(C5t,"TFBertForMultipleChoice"),C5t.forEach(t),PMr=r(fBe," (BERT model)"),fBe.forEach(t),BMr=i(be),sE=n(be,"LI",{});var mBe=s(sE);y3e=n(mBe,"STRONG",{});var w5t=s(y3e);IMr=r(w5t,"camembert"),w5t.forEach(t),NMr=r(mBe," \u2014 "),TU=n(mBe,"A",{href:!0});var A5t=s(TU);qMr=r(A5t,"TFCamembertForMultipleChoice"),A5t.forEach(t),jMr=r(mBe," (CamemBERT model)"),mBe.forEach(t),DMr=i(be),lE=n(be,"LI",{});var gBe=s(lE);L3e=n(gBe,"STRONG",{});var y5t=s(L3e);GMr=r(y5t,"convbert"),y5t.forEach(t),OMr=r(gBe," \u2014 "),MU=n(gBe,"A",{href:!0});var L5t=s(MU);VMr=r(L5t,"TFConvBertForMultipleChoice"),L5t.forEach(t),XMr=r(gBe," (ConvBERT model)"),gBe.forEach(t),zMr=i(be),iE=n(be,"LI",{});var hBe=s(iE);x3e=n(hBe,"STRONG",{});var x5t=s(x3e);WMr=r(x5t,"distilbert"),x5t.forEach(t),QMr=r(hBe," \u2014 "),EU=n(hBe,"A",{href:!0});var $5t=s(EU);HMr=r($5t,"TFDistilBertForMultipleChoice"),$5t.forEach(t),UMr=r(hBe," (DistilBERT model)"),hBe.forEach(t),JMr=i(be),dE=n(be,"LI",{});var pBe=s(dE);$3e=n(pBe,"STRONG",{});var k5t=s($3e);YMr=r(k5t,"electra"),k5t.forEach(t),KMr=r(pBe," \u2014 "),CU=n(pBe,"A",{href:!0});var S5t=s(CU);ZMr=r(S5t,"TFElectraForMultipleChoice"),S5t.forEach(t),eEr=r(pBe," (ELECTRA model)"),pBe.forEach(t),oEr=i(be),cE=n(be,"LI",{});var _Be=s(cE);k3e=n(_Be,"STRONG",{});var R5t=s(k3e);rEr=r(R5t,"flaubert"),R5t.forEach(t),tEr=r(_Be," \u2014 "),wU=n(_Be,"A",{href:!0});var P5t=s(wU);aEr=r(P5t,"TFFlaubertForMultipleChoice"),P5t.forEach(t),nEr=r(_Be," (FlauBERT model)"),_Be.forEach(t),sEr=i(be),fE=n(be,"LI",{});var uBe=s(fE);S3e=n(uBe,"STRONG",{});var B5t=s(S3e);lEr=r(B5t,"funnel"),B5t.forEach(t),iEr=r(uBe," \u2014 "),AU=n(uBe,"A",{href:!0});var I5t=s(AU);dEr=r(I5t,"TFFunnelForMultipleChoice"),I5t.forEach(t),cEr=r(uBe," (Funnel Transformer model)"),uBe.forEach(t),fEr=i(be),mE=n(be,"LI",{});var bBe=s(mE);R3e=n(bBe,"STRONG",{});var N5t=s(R3e);mEr=r(N5t,"longformer"),N5t.forEach(t),gEr=r(bBe," \u2014 "),yU=n(bBe,"A",{href:!0});var q5t=s(yU);hEr=r(q5t,"TFLongformerForMultipleChoice"),q5t.forEach(t),pEr=r(bBe," (Longformer model)"),bBe.forEach(t),_Er=i(be),gE=n(be,"LI",{});var vBe=s(gE);P3e=n(vBe,"STRONG",{});var j5t=s(P3e);uEr=r(j5t,"mobilebert"),j5t.forEach(t),bEr=r(vBe," \u2014 "),LU=n(vBe,"A",{href:!0});var D5t=s(LU);vEr=r(D5t,"TFMobileBertForMultipleChoice"),D5t.forEach(t),FEr=r(vBe," (MobileBERT model)"),vBe.forEach(t),TEr=i(be),hE=n(be,"LI",{});var FBe=s(hE);B3e=n(FBe,"STRONG",{});var G5t=s(B3e);MEr=r(G5t,"mpnet"),G5t.forEach(t),EEr=r(FBe," \u2014 "),xU=n(FBe,"A",{href:!0});var O5t=s(xU);CEr=r(O5t,"TFMPNetForMultipleChoice"),O5t.forEach(t),wEr=r(FBe," (MPNet model)"),FBe.forEach(t),AEr=i(be),pE=n(be,"LI",{});var TBe=s(pE);I3e=n(TBe,"STRONG",{});var V5t=s(I3e);yEr=r(V5t,"rembert"),V5t.forEach(t),LEr=r(TBe," \u2014 "),$U=n(TBe,"A",{href:!0});var X5t=s($U);xEr=r(X5t,"TFRemBertForMultipleChoice"),X5t.forEach(t),$Er=r(TBe," (RemBERT model)"),TBe.forEach(t),kEr=i(be),_E=n(be,"LI",{});var MBe=s(_E);N3e=n(MBe,"STRONG",{});var z5t=s(N3e);SEr=r(z5t,"roberta"),z5t.forEach(t),REr=r(MBe," \u2014 "),kU=n(MBe,"A",{href:!0});var W5t=s(kU);PEr=r(W5t,"TFRobertaForMultipleChoice"),W5t.forEach(t),BEr=r(MBe," (RoBERTa model)"),MBe.forEach(t),IEr=i(be),uE=n(be,"LI",{});var EBe=s(uE);q3e=n(EBe,"STRONG",{});var Q5t=s(q3e);NEr=r(Q5t,"roformer"),Q5t.forEach(t),qEr=r(EBe," \u2014 "),SU=n(EBe,"A",{href:!0});var H5t=s(SU);jEr=r(H5t,"TFRoFormerForMultipleChoice"),H5t.forEach(t),DEr=r(EBe," (RoFormer model)"),EBe.forEach(t),GEr=i(be),bE=n(be,"LI",{});var CBe=s(bE);j3e=n(CBe,"STRONG",{});var U5t=s(j3e);OEr=r(U5t,"xlm"),U5t.forEach(t),VEr=r(CBe," \u2014 "),RU=n(CBe,"A",{href:!0});var J5t=s(RU);XEr=r(J5t,"TFXLMForMultipleChoice"),J5t.forEach(t),zEr=r(CBe," (XLM model)"),CBe.forEach(t),WEr=i(be),vE=n(be,"LI",{});var wBe=s(vE);D3e=n(wBe,"STRONG",{});var Y5t=s(D3e);QEr=r(Y5t,"xlm-roberta"),Y5t.forEach(t),HEr=r(wBe," \u2014 "),PU=n(wBe,"A",{href:!0});var K5t=s(PU);UEr=r(K5t,"TFXLMRobertaForMultipleChoice"),K5t.forEach(t),JEr=r(wBe," (XLM-RoBERTa model)"),wBe.forEach(t),YEr=i(be),FE=n(be,"LI",{});var ABe=s(FE);G3e=n(ABe,"STRONG",{});var Z5t=s(G3e);KEr=r(Z5t,"xlnet"),Z5t.forEach(t),ZEr=r(ABe," \u2014 "),BU=n(ABe,"A",{href:!0});var ewt=s(BU);eCr=r(ewt,"TFXLNetForMultipleChoice"),ewt.forEach(t),oCr=r(ABe," (XLNet model)"),ABe.forEach(t),be.forEach(t),rCr=i(xl),T(TE.$$.fragment,xl),xl.forEach(t),Ll.forEach(t),Ije=i(f),mc=n(f,"H2",{class:!0});var OGe=s(mc);ME=n(OGe,"A",{id:!0,class:!0,href:!0});var owt=s(ME);O3e=n(owt,"SPAN",{});var rwt=s(O3e);T(K8.$$.fragment,rwt),rwt.forEach(t),owt.forEach(t),tCr=i(OGe),V3e=n(OGe,"SPAN",{});var twt=s(V3e);aCr=r(twt,"TFAutoModelForNextSentencePrediction"),twt.forEach(t),OGe.forEach(t),Nje=i(f),nr=n(f,"DIV",{class:!0});var $l=s(nr);T(Z8.$$.fragment,$l),nCr=i($l),gc=n($l,"P",{});var Pee=s(gc);sCr=r(Pee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),IU=n(Pee,"A",{href:!0});var awt=s(IU);lCr=r(awt,"from_pretrained()"),awt.forEach(t),iCr=r(Pee," class method or the "),NU=n(Pee,"A",{href:!0});var nwt=s(NU);dCr=r(nwt,"from_config()"),nwt.forEach(t),cCr=r(Pee,` class
method.`),Pee.forEach(t),fCr=i($l),e9=n($l,"P",{});var VGe=s(e9);mCr=r(VGe,"This class cannot be instantiated directly using "),X3e=n(VGe,"CODE",{});var swt=s(X3e);gCr=r(swt,"__init__()"),swt.forEach(t),hCr=r(VGe," (throws an error)."),VGe.forEach(t),pCr=i($l),Bt=n($l,"DIV",{class:!0});var z6=s(Bt);T(o9.$$.fragment,z6),_Cr=i(z6),z3e=n(z6,"P",{});var lwt=s(z3e);uCr=r(lwt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),lwt.forEach(t),bCr=i(z6),hc=n(z6,"P",{});var Bee=s(hc);vCr=r(Bee,`Note:
Loading a model from its configuration file does `),W3e=n(Bee,"STRONG",{});var iwt=s(W3e);FCr=r(iwt,"not"),iwt.forEach(t),TCr=r(Bee,` load the model weights. It only affects the
model\u2019s configuration. Use `),qU=n(Bee,"A",{href:!0});var dwt=s(qU);MCr=r(dwt,"from_pretrained()"),dwt.forEach(t),ECr=r(Bee," to load the model weights."),Bee.forEach(t),CCr=i(z6),T(EE.$$.fragment,z6),z6.forEach(t),wCr=i($l),Rr=n($l,"DIV",{class:!0});var kl=s(Rr);T(r9.$$.fragment,kl),ACr=i(kl),Q3e=n(kl,"P",{});var cwt=s(Q3e);yCr=r(cwt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),cwt.forEach(t),LCr=i(kl),ln=n(kl,"P",{});var W6=s(ln);xCr=r(W6,"The model class to instantiate is selected based on the "),H3e=n(W6,"CODE",{});var fwt=s(H3e);$Cr=r(fwt,"model_type"),fwt.forEach(t),kCr=r(W6,` property of the config object (either
passed as an argument or loaded from `),U3e=n(W6,"CODE",{});var mwt=s(U3e);SCr=r(mwt,"pretrained_model_name_or_path"),mwt.forEach(t),RCr=r(W6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J3e=n(W6,"CODE",{});var gwt=s(J3e);PCr=r(gwt,"pretrained_model_name_or_path"),gwt.forEach(t),BCr=r(W6,":"),W6.forEach(t),ICr=i(kl),t9=n(kl,"UL",{});var XGe=s(t9);CE=n(XGe,"LI",{});var yBe=s(CE);Y3e=n(yBe,"STRONG",{});var hwt=s(Y3e);NCr=r(hwt,"bert"),hwt.forEach(t),qCr=r(yBe," \u2014 "),jU=n(yBe,"A",{href:!0});var pwt=s(jU);jCr=r(pwt,"TFBertForNextSentencePrediction"),pwt.forEach(t),DCr=r(yBe," (BERT model)"),yBe.forEach(t),GCr=i(XGe),wE=n(XGe,"LI",{});var LBe=s(wE);K3e=n(LBe,"STRONG",{});var _wt=s(K3e);OCr=r(_wt,"mobilebert"),_wt.forEach(t),VCr=r(LBe," \u2014 "),DU=n(LBe,"A",{href:!0});var uwt=s(DU);XCr=r(uwt,"TFMobileBertForNextSentencePrediction"),uwt.forEach(t),zCr=r(LBe," (MobileBERT model)"),LBe.forEach(t),XGe.forEach(t),WCr=i(kl),T(AE.$$.fragment,kl),kl.forEach(t),$l.forEach(t),qje=i(f),pc=n(f,"H2",{class:!0});var zGe=s(pc);yE=n(zGe,"A",{id:!0,class:!0,href:!0});var bwt=s(yE);Z3e=n(bwt,"SPAN",{});var vwt=s(Z3e);T(a9.$$.fragment,vwt),vwt.forEach(t),bwt.forEach(t),QCr=i(zGe),eFe=n(zGe,"SPAN",{});var Fwt=s(eFe);HCr=r(Fwt,"TFAutoModelForTableQuestionAnswering"),Fwt.forEach(t),zGe.forEach(t),jje=i(f),sr=n(f,"DIV",{class:!0});var Sl=s(sr);T(n9.$$.fragment,Sl),UCr=i(Sl),_c=n(Sl,"P",{});var Iee=s(_c);JCr=r(Iee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),GU=n(Iee,"A",{href:!0});var Twt=s(GU);YCr=r(Twt,"from_pretrained()"),Twt.forEach(t),KCr=r(Iee," class method or the "),OU=n(Iee,"A",{href:!0});var Mwt=s(OU);ZCr=r(Mwt,"from_config()"),Mwt.forEach(t),e5r=r(Iee,` class
method.`),Iee.forEach(t),o5r=i(Sl),s9=n(Sl,"P",{});var WGe=s(s9);r5r=r(WGe,"This class cannot be instantiated directly using "),oFe=n(WGe,"CODE",{});var Ewt=s(oFe);t5r=r(Ewt,"__init__()"),Ewt.forEach(t),a5r=r(WGe," (throws an error)."),WGe.forEach(t),n5r=i(Sl),It=n(Sl,"DIV",{class:!0});var Q6=s(It);T(l9.$$.fragment,Q6),s5r=i(Q6),rFe=n(Q6,"P",{});var Cwt=s(rFe);l5r=r(Cwt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Cwt.forEach(t),i5r=i(Q6),uc=n(Q6,"P",{});var Nee=s(uc);d5r=r(Nee,`Note:
Loading a model from its configuration file does `),tFe=n(Nee,"STRONG",{});var wwt=s(tFe);c5r=r(wwt,"not"),wwt.forEach(t),f5r=r(Nee,` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=n(Nee,"A",{href:!0});var Awt=s(VU);m5r=r(Awt,"from_pretrained()"),Awt.forEach(t),g5r=r(Nee," to load the model weights."),Nee.forEach(t),h5r=i(Q6),T(LE.$$.fragment,Q6),Q6.forEach(t),p5r=i(Sl),Pr=n(Sl,"DIV",{class:!0});var Rl=s(Pr);T(i9.$$.fragment,Rl),_5r=i(Rl),aFe=n(Rl,"P",{});var ywt=s(aFe);u5r=r(ywt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),ywt.forEach(t),b5r=i(Rl),dn=n(Rl,"P",{});var H6=s(dn);v5r=r(H6,"The model class to instantiate is selected based on the "),nFe=n(H6,"CODE",{});var Lwt=s(nFe);F5r=r(Lwt,"model_type"),Lwt.forEach(t),T5r=r(H6,` property of the config object (either
passed as an argument or loaded from `),sFe=n(H6,"CODE",{});var xwt=s(sFe);M5r=r(xwt,"pretrained_model_name_or_path"),xwt.forEach(t),E5r=r(H6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lFe=n(H6,"CODE",{});var $wt=s(lFe);C5r=r($wt,"pretrained_model_name_or_path"),$wt.forEach(t),w5r=r(H6,":"),H6.forEach(t),A5r=i(Rl),iFe=n(Rl,"UL",{});var kwt=s(iFe);xE=n(kwt,"LI",{});var xBe=s(xE);dFe=n(xBe,"STRONG",{});var Swt=s(dFe);y5r=r(Swt,"tapas"),Swt.forEach(t),L5r=r(xBe," \u2014 "),XU=n(xBe,"A",{href:!0});var Rwt=s(XU);x5r=r(Rwt,"TFTapasForQuestionAnswering"),Rwt.forEach(t),$5r=r(xBe," (TAPAS model)"),xBe.forEach(t),kwt.forEach(t),k5r=i(Rl),T($E.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),Dje=i(f),bc=n(f,"H2",{class:!0});var QGe=s(bc);kE=n(QGe,"A",{id:!0,class:!0,href:!0});var Pwt=s(kE);cFe=n(Pwt,"SPAN",{});var Bwt=s(cFe);T(d9.$$.fragment,Bwt),Bwt.forEach(t),Pwt.forEach(t),S5r=i(QGe),fFe=n(QGe,"SPAN",{});var Iwt=s(fFe);R5r=r(Iwt,"TFAutoModelForTokenClassification"),Iwt.forEach(t),QGe.forEach(t),Gje=i(f),lr=n(f,"DIV",{class:!0});var Pl=s(lr);T(c9.$$.fragment,Pl),P5r=i(Pl),vc=n(Pl,"P",{});var qee=s(vc);B5r=r(qee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),zU=n(qee,"A",{href:!0});var Nwt=s(zU);I5r=r(Nwt,"from_pretrained()"),Nwt.forEach(t),N5r=r(qee," class method or the "),WU=n(qee,"A",{href:!0});var qwt=s(WU);q5r=r(qwt,"from_config()"),qwt.forEach(t),j5r=r(qee,` class
method.`),qee.forEach(t),D5r=i(Pl),f9=n(Pl,"P",{});var HGe=s(f9);G5r=r(HGe,"This class cannot be instantiated directly using "),mFe=n(HGe,"CODE",{});var jwt=s(mFe);O5r=r(jwt,"__init__()"),jwt.forEach(t),V5r=r(HGe," (throws an error)."),HGe.forEach(t),X5r=i(Pl),Nt=n(Pl,"DIV",{class:!0});var U6=s(Nt);T(m9.$$.fragment,U6),z5r=i(U6),gFe=n(U6,"P",{});var Dwt=s(gFe);W5r=r(Dwt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Dwt.forEach(t),Q5r=i(U6),Fc=n(U6,"P",{});var jee=s(Fc);H5r=r(jee,`Note:
Loading a model from its configuration file does `),hFe=n(jee,"STRONG",{});var Gwt=s(hFe);U5r=r(Gwt,"not"),Gwt.forEach(t),J5r=r(jee,` load the model weights. It only affects the
model\u2019s configuration. Use `),QU=n(jee,"A",{href:!0});var Owt=s(QU);Y5r=r(Owt,"from_pretrained()"),Owt.forEach(t),K5r=r(jee," to load the model weights."),jee.forEach(t),Z5r=i(U6),T(SE.$$.fragment,U6),U6.forEach(t),ewr=i(Pl),Br=n(Pl,"DIV",{class:!0});var Bl=s(Br);T(g9.$$.fragment,Bl),owr=i(Bl),pFe=n(Bl,"P",{});var Vwt=s(pFe);rwr=r(Vwt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Vwt.forEach(t),twr=i(Bl),cn=n(Bl,"P",{});var J6=s(cn);awr=r(J6,"The model class to instantiate is selected based on the "),_Fe=n(J6,"CODE",{});var Xwt=s(_Fe);nwr=r(Xwt,"model_type"),Xwt.forEach(t),swr=r(J6,` property of the config object (either
passed as an argument or loaded from `),uFe=n(J6,"CODE",{});var zwt=s(uFe);lwr=r(zwt,"pretrained_model_name_or_path"),zwt.forEach(t),iwr=r(J6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bFe=n(J6,"CODE",{});var Wwt=s(bFe);dwr=r(Wwt,"pretrained_model_name_or_path"),Wwt.forEach(t),cwr=r(J6,":"),J6.forEach(t),fwr=i(Bl),de=n(Bl,"UL",{});var me=s(de);RE=n(me,"LI",{});var $Be=s(RE);vFe=n($Be,"STRONG",{});var Qwt=s(vFe);mwr=r(Qwt,"albert"),Qwt.forEach(t),gwr=r($Be," \u2014 "),HU=n($Be,"A",{href:!0});var Hwt=s(HU);hwr=r(Hwt,"TFAlbertForTokenClassification"),Hwt.forEach(t),pwr=r($Be," (ALBERT model)"),$Be.forEach(t),_wr=i(me),PE=n(me,"LI",{});var kBe=s(PE);FFe=n(kBe,"STRONG",{});var Uwt=s(FFe);uwr=r(Uwt,"bert"),Uwt.forEach(t),bwr=r(kBe," \u2014 "),UU=n(kBe,"A",{href:!0});var Jwt=s(UU);vwr=r(Jwt,"TFBertForTokenClassification"),Jwt.forEach(t),Fwr=r(kBe," (BERT model)"),kBe.forEach(t),Twr=i(me),BE=n(me,"LI",{});var SBe=s(BE);TFe=n(SBe,"STRONG",{});var Ywt=s(TFe);Mwr=r(Ywt,"camembert"),Ywt.forEach(t),Ewr=r(SBe," \u2014 "),JU=n(SBe,"A",{href:!0});var Kwt=s(JU);Cwr=r(Kwt,"TFCamembertForTokenClassification"),Kwt.forEach(t),wwr=r(SBe," (CamemBERT model)"),SBe.forEach(t),Awr=i(me),IE=n(me,"LI",{});var RBe=s(IE);MFe=n(RBe,"STRONG",{});var Zwt=s(MFe);ywr=r(Zwt,"convbert"),Zwt.forEach(t),Lwr=r(RBe," \u2014 "),YU=n(RBe,"A",{href:!0});var e0t=s(YU);xwr=r(e0t,"TFConvBertForTokenClassification"),e0t.forEach(t),$wr=r(RBe," (ConvBERT model)"),RBe.forEach(t),kwr=i(me),NE=n(me,"LI",{});var PBe=s(NE);EFe=n(PBe,"STRONG",{});var o0t=s(EFe);Swr=r(o0t,"deberta"),o0t.forEach(t),Rwr=r(PBe," \u2014 "),KU=n(PBe,"A",{href:!0});var r0t=s(KU);Pwr=r(r0t,"TFDebertaForTokenClassification"),r0t.forEach(t),Bwr=r(PBe," (DeBERTa model)"),PBe.forEach(t),Iwr=i(me),qE=n(me,"LI",{});var BBe=s(qE);CFe=n(BBe,"STRONG",{});var t0t=s(CFe);Nwr=r(t0t,"deberta-v2"),t0t.forEach(t),qwr=r(BBe," \u2014 "),ZU=n(BBe,"A",{href:!0});var a0t=s(ZU);jwr=r(a0t,"TFDebertaV2ForTokenClassification"),a0t.forEach(t),Dwr=r(BBe," (DeBERTa-v2 model)"),BBe.forEach(t),Gwr=i(me),jE=n(me,"LI",{});var IBe=s(jE);wFe=n(IBe,"STRONG",{});var n0t=s(wFe);Owr=r(n0t,"distilbert"),n0t.forEach(t),Vwr=r(IBe," \u2014 "),eJ=n(IBe,"A",{href:!0});var s0t=s(eJ);Xwr=r(s0t,"TFDistilBertForTokenClassification"),s0t.forEach(t),zwr=r(IBe," (DistilBERT model)"),IBe.forEach(t),Wwr=i(me),DE=n(me,"LI",{});var NBe=s(DE);AFe=n(NBe,"STRONG",{});var l0t=s(AFe);Qwr=r(l0t,"electra"),l0t.forEach(t),Hwr=r(NBe," \u2014 "),oJ=n(NBe,"A",{href:!0});var i0t=s(oJ);Uwr=r(i0t,"TFElectraForTokenClassification"),i0t.forEach(t),Jwr=r(NBe," (ELECTRA model)"),NBe.forEach(t),Ywr=i(me),GE=n(me,"LI",{});var qBe=s(GE);yFe=n(qBe,"STRONG",{});var d0t=s(yFe);Kwr=r(d0t,"flaubert"),d0t.forEach(t),Zwr=r(qBe," \u2014 "),rJ=n(qBe,"A",{href:!0});var c0t=s(rJ);e0r=r(c0t,"TFFlaubertForTokenClassification"),c0t.forEach(t),o0r=r(qBe," (FlauBERT model)"),qBe.forEach(t),r0r=i(me),OE=n(me,"LI",{});var jBe=s(OE);LFe=n(jBe,"STRONG",{});var f0t=s(LFe);t0r=r(f0t,"funnel"),f0t.forEach(t),a0r=r(jBe," \u2014 "),tJ=n(jBe,"A",{href:!0});var m0t=s(tJ);n0r=r(m0t,"TFFunnelForTokenClassification"),m0t.forEach(t),s0r=r(jBe," (Funnel Transformer model)"),jBe.forEach(t),l0r=i(me),VE=n(me,"LI",{});var DBe=s(VE);xFe=n(DBe,"STRONG",{});var g0t=s(xFe);i0r=r(g0t,"layoutlm"),g0t.forEach(t),d0r=r(DBe," \u2014 "),aJ=n(DBe,"A",{href:!0});var h0t=s(aJ);c0r=r(h0t,"TFLayoutLMForTokenClassification"),h0t.forEach(t),f0r=r(DBe," (LayoutLM model)"),DBe.forEach(t),m0r=i(me),XE=n(me,"LI",{});var GBe=s(XE);$Fe=n(GBe,"STRONG",{});var p0t=s($Fe);g0r=r(p0t,"longformer"),p0t.forEach(t),h0r=r(GBe," \u2014 "),nJ=n(GBe,"A",{href:!0});var _0t=s(nJ);p0r=r(_0t,"TFLongformerForTokenClassification"),_0t.forEach(t),_0r=r(GBe," (Longformer model)"),GBe.forEach(t),u0r=i(me),zE=n(me,"LI",{});var OBe=s(zE);kFe=n(OBe,"STRONG",{});var u0t=s(kFe);b0r=r(u0t,"mobilebert"),u0t.forEach(t),v0r=r(OBe," \u2014 "),sJ=n(OBe,"A",{href:!0});var b0t=s(sJ);F0r=r(b0t,"TFMobileBertForTokenClassification"),b0t.forEach(t),T0r=r(OBe," (MobileBERT model)"),OBe.forEach(t),M0r=i(me),WE=n(me,"LI",{});var VBe=s(WE);SFe=n(VBe,"STRONG",{});var v0t=s(SFe);E0r=r(v0t,"mpnet"),v0t.forEach(t),C0r=r(VBe," \u2014 "),lJ=n(VBe,"A",{href:!0});var F0t=s(lJ);w0r=r(F0t,"TFMPNetForTokenClassification"),F0t.forEach(t),A0r=r(VBe," (MPNet model)"),VBe.forEach(t),y0r=i(me),QE=n(me,"LI",{});var XBe=s(QE);RFe=n(XBe,"STRONG",{});var T0t=s(RFe);L0r=r(T0t,"rembert"),T0t.forEach(t),x0r=r(XBe," \u2014 "),iJ=n(XBe,"A",{href:!0});var M0t=s(iJ);$0r=r(M0t,"TFRemBertForTokenClassification"),M0t.forEach(t),k0r=r(XBe," (RemBERT model)"),XBe.forEach(t),S0r=i(me),HE=n(me,"LI",{});var zBe=s(HE);PFe=n(zBe,"STRONG",{});var E0t=s(PFe);R0r=r(E0t,"roberta"),E0t.forEach(t),P0r=r(zBe," \u2014 "),dJ=n(zBe,"A",{href:!0});var C0t=s(dJ);B0r=r(C0t,"TFRobertaForTokenClassification"),C0t.forEach(t),I0r=r(zBe," (RoBERTa model)"),zBe.forEach(t),N0r=i(me),UE=n(me,"LI",{});var WBe=s(UE);BFe=n(WBe,"STRONG",{});var w0t=s(BFe);q0r=r(w0t,"roformer"),w0t.forEach(t),j0r=r(WBe," \u2014 "),cJ=n(WBe,"A",{href:!0});var A0t=s(cJ);D0r=r(A0t,"TFRoFormerForTokenClassification"),A0t.forEach(t),G0r=r(WBe," (RoFormer model)"),WBe.forEach(t),O0r=i(me),JE=n(me,"LI",{});var QBe=s(JE);IFe=n(QBe,"STRONG",{});var y0t=s(IFe);V0r=r(y0t,"xlm"),y0t.forEach(t),X0r=r(QBe," \u2014 "),fJ=n(QBe,"A",{href:!0});var L0t=s(fJ);z0r=r(L0t,"TFXLMForTokenClassification"),L0t.forEach(t),W0r=r(QBe," (XLM model)"),QBe.forEach(t),Q0r=i(me),YE=n(me,"LI",{});var HBe=s(YE);NFe=n(HBe,"STRONG",{});var x0t=s(NFe);H0r=r(x0t,"xlm-roberta"),x0t.forEach(t),U0r=r(HBe," \u2014 "),mJ=n(HBe,"A",{href:!0});var $0t=s(mJ);J0r=r($0t,"TFXLMRobertaForTokenClassification"),$0t.forEach(t),Y0r=r(HBe," (XLM-RoBERTa model)"),HBe.forEach(t),K0r=i(me),KE=n(me,"LI",{});var UBe=s(KE);qFe=n(UBe,"STRONG",{});var k0t=s(qFe);Z0r=r(k0t,"xlnet"),k0t.forEach(t),e6r=r(UBe," \u2014 "),gJ=n(UBe,"A",{href:!0});var S0t=s(gJ);o6r=r(S0t,"TFXLNetForTokenClassification"),S0t.forEach(t),r6r=r(UBe," (XLNet model)"),UBe.forEach(t),me.forEach(t),t6r=i(Bl),T(ZE.$$.fragment,Bl),Bl.forEach(t),Pl.forEach(t),Oje=i(f),Tc=n(f,"H2",{class:!0});var UGe=s(Tc);eC=n(UGe,"A",{id:!0,class:!0,href:!0});var R0t=s(eC);jFe=n(R0t,"SPAN",{});var P0t=s(jFe);T(h9.$$.fragment,P0t),P0t.forEach(t),R0t.forEach(t),a6r=i(UGe),DFe=n(UGe,"SPAN",{});var B0t=s(DFe);n6r=r(B0t,"TFAutoModelForQuestionAnswering"),B0t.forEach(t),UGe.forEach(t),Vje=i(f),ir=n(f,"DIV",{class:!0});var Il=s(ir);T(p9.$$.fragment,Il),s6r=i(Il),Mc=n(Il,"P",{});var Dee=s(Mc);l6r=r(Dee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hJ=n(Dee,"A",{href:!0});var I0t=s(hJ);i6r=r(I0t,"from_pretrained()"),I0t.forEach(t),d6r=r(Dee," class method or the "),pJ=n(Dee,"A",{href:!0});var N0t=s(pJ);c6r=r(N0t,"from_config()"),N0t.forEach(t),f6r=r(Dee,` class
method.`),Dee.forEach(t),m6r=i(Il),_9=n(Il,"P",{});var JGe=s(_9);g6r=r(JGe,"This class cannot be instantiated directly using "),GFe=n(JGe,"CODE",{});var q0t=s(GFe);h6r=r(q0t,"__init__()"),q0t.forEach(t),p6r=r(JGe," (throws an error)."),JGe.forEach(t),_6r=i(Il),qt=n(Il,"DIV",{class:!0});var Y6=s(qt);T(u9.$$.fragment,Y6),u6r=i(Y6),OFe=n(Y6,"P",{});var j0t=s(OFe);b6r=r(j0t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),j0t.forEach(t),v6r=i(Y6),Ec=n(Y6,"P",{});var Gee=s(Ec);F6r=r(Gee,`Note:
Loading a model from its configuration file does `),VFe=n(Gee,"STRONG",{});var D0t=s(VFe);T6r=r(D0t,"not"),D0t.forEach(t),M6r=r(Gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),_J=n(Gee,"A",{href:!0});var G0t=s(_J);E6r=r(G0t,"from_pretrained()"),G0t.forEach(t),C6r=r(Gee," to load the model weights."),Gee.forEach(t),w6r=i(Y6),T(oC.$$.fragment,Y6),Y6.forEach(t),A6r=i(Il),Ir=n(Il,"DIV",{class:!0});var Nl=s(Ir);T(b9.$$.fragment,Nl),y6r=i(Nl),XFe=n(Nl,"P",{});var O0t=s(XFe);L6r=r(O0t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),O0t.forEach(t),x6r=i(Nl),fn=n(Nl,"P",{});var K6=s(fn);$6r=r(K6,"The model class to instantiate is selected based on the "),zFe=n(K6,"CODE",{});var V0t=s(zFe);k6r=r(V0t,"model_type"),V0t.forEach(t),S6r=r(K6,` property of the config object (either
passed as an argument or loaded from `),WFe=n(K6,"CODE",{});var X0t=s(WFe);R6r=r(X0t,"pretrained_model_name_or_path"),X0t.forEach(t),P6r=r(K6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QFe=n(K6,"CODE",{});var z0t=s(QFe);B6r=r(z0t,"pretrained_model_name_or_path"),z0t.forEach(t),I6r=r(K6,":"),K6.forEach(t),N6r=i(Nl),ce=n(Nl,"UL",{});var ge=s(ce);rC=n(ge,"LI",{});var JBe=s(rC);HFe=n(JBe,"STRONG",{});var W0t=s(HFe);q6r=r(W0t,"albert"),W0t.forEach(t),j6r=r(JBe," \u2014 "),uJ=n(JBe,"A",{href:!0});var Q0t=s(uJ);D6r=r(Q0t,"TFAlbertForQuestionAnswering"),Q0t.forEach(t),G6r=r(JBe," (ALBERT model)"),JBe.forEach(t),O6r=i(ge),tC=n(ge,"LI",{});var YBe=s(tC);UFe=n(YBe,"STRONG",{});var H0t=s(UFe);V6r=r(H0t,"bert"),H0t.forEach(t),X6r=r(YBe," \u2014 "),bJ=n(YBe,"A",{href:!0});var U0t=s(bJ);z6r=r(U0t,"TFBertForQuestionAnswering"),U0t.forEach(t),W6r=r(YBe," (BERT model)"),YBe.forEach(t),Q6r=i(ge),aC=n(ge,"LI",{});var KBe=s(aC);JFe=n(KBe,"STRONG",{});var J0t=s(JFe);H6r=r(J0t,"camembert"),J0t.forEach(t),U6r=r(KBe," \u2014 "),vJ=n(KBe,"A",{href:!0});var Y0t=s(vJ);J6r=r(Y0t,"TFCamembertForQuestionAnswering"),Y0t.forEach(t),Y6r=r(KBe," (CamemBERT model)"),KBe.forEach(t),K6r=i(ge),nC=n(ge,"LI",{});var ZBe=s(nC);YFe=n(ZBe,"STRONG",{});var K0t=s(YFe);Z6r=r(K0t,"convbert"),K0t.forEach(t),eAr=r(ZBe," \u2014 "),FJ=n(ZBe,"A",{href:!0});var Z0t=s(FJ);oAr=r(Z0t,"TFConvBertForQuestionAnswering"),Z0t.forEach(t),rAr=r(ZBe," (ConvBERT model)"),ZBe.forEach(t),tAr=i(ge),sC=n(ge,"LI",{});var eIe=s(sC);KFe=n(eIe,"STRONG",{});var e6t=s(KFe);aAr=r(e6t,"deberta"),e6t.forEach(t),nAr=r(eIe," \u2014 "),TJ=n(eIe,"A",{href:!0});var o6t=s(TJ);sAr=r(o6t,"TFDebertaForQuestionAnswering"),o6t.forEach(t),lAr=r(eIe," (DeBERTa model)"),eIe.forEach(t),iAr=i(ge),lC=n(ge,"LI",{});var oIe=s(lC);ZFe=n(oIe,"STRONG",{});var r6t=s(ZFe);dAr=r(r6t,"deberta-v2"),r6t.forEach(t),cAr=r(oIe," \u2014 "),MJ=n(oIe,"A",{href:!0});var t6t=s(MJ);fAr=r(t6t,"TFDebertaV2ForQuestionAnswering"),t6t.forEach(t),mAr=r(oIe," (DeBERTa-v2 model)"),oIe.forEach(t),gAr=i(ge),iC=n(ge,"LI",{});var rIe=s(iC);eTe=n(rIe,"STRONG",{});var a6t=s(eTe);hAr=r(a6t,"distilbert"),a6t.forEach(t),pAr=r(rIe," \u2014 "),EJ=n(rIe,"A",{href:!0});var n6t=s(EJ);_Ar=r(n6t,"TFDistilBertForQuestionAnswering"),n6t.forEach(t),uAr=r(rIe," (DistilBERT model)"),rIe.forEach(t),bAr=i(ge),dC=n(ge,"LI",{});var tIe=s(dC);oTe=n(tIe,"STRONG",{});var s6t=s(oTe);vAr=r(s6t,"electra"),s6t.forEach(t),FAr=r(tIe," \u2014 "),CJ=n(tIe,"A",{href:!0});var l6t=s(CJ);TAr=r(l6t,"TFElectraForQuestionAnswering"),l6t.forEach(t),MAr=r(tIe," (ELECTRA model)"),tIe.forEach(t),EAr=i(ge),cC=n(ge,"LI",{});var aIe=s(cC);rTe=n(aIe,"STRONG",{});var i6t=s(rTe);CAr=r(i6t,"flaubert"),i6t.forEach(t),wAr=r(aIe," \u2014 "),wJ=n(aIe,"A",{href:!0});var d6t=s(wJ);AAr=r(d6t,"TFFlaubertForQuestionAnsweringSimple"),d6t.forEach(t),yAr=r(aIe," (FlauBERT model)"),aIe.forEach(t),LAr=i(ge),fC=n(ge,"LI",{});var nIe=s(fC);tTe=n(nIe,"STRONG",{});var c6t=s(tTe);xAr=r(c6t,"funnel"),c6t.forEach(t),$Ar=r(nIe," \u2014 "),AJ=n(nIe,"A",{href:!0});var f6t=s(AJ);kAr=r(f6t,"TFFunnelForQuestionAnswering"),f6t.forEach(t),SAr=r(nIe," (Funnel Transformer model)"),nIe.forEach(t),RAr=i(ge),mC=n(ge,"LI",{});var sIe=s(mC);aTe=n(sIe,"STRONG",{});var m6t=s(aTe);PAr=r(m6t,"gptj"),m6t.forEach(t),BAr=r(sIe," \u2014 "),yJ=n(sIe,"A",{href:!0});var g6t=s(yJ);IAr=r(g6t,"TFGPTJForQuestionAnswering"),g6t.forEach(t),NAr=r(sIe," (GPT-J model)"),sIe.forEach(t),qAr=i(ge),gC=n(ge,"LI",{});var lIe=s(gC);nTe=n(lIe,"STRONG",{});var h6t=s(nTe);jAr=r(h6t,"longformer"),h6t.forEach(t),DAr=r(lIe," \u2014 "),LJ=n(lIe,"A",{href:!0});var p6t=s(LJ);GAr=r(p6t,"TFLongformerForQuestionAnswering"),p6t.forEach(t),OAr=r(lIe," (Longformer model)"),lIe.forEach(t),VAr=i(ge),hC=n(ge,"LI",{});var iIe=s(hC);sTe=n(iIe,"STRONG",{});var _6t=s(sTe);XAr=r(_6t,"mobilebert"),_6t.forEach(t),zAr=r(iIe," \u2014 "),xJ=n(iIe,"A",{href:!0});var u6t=s(xJ);WAr=r(u6t,"TFMobileBertForQuestionAnswering"),u6t.forEach(t),QAr=r(iIe," (MobileBERT model)"),iIe.forEach(t),HAr=i(ge),pC=n(ge,"LI",{});var dIe=s(pC);lTe=n(dIe,"STRONG",{});var b6t=s(lTe);UAr=r(b6t,"mpnet"),b6t.forEach(t),JAr=r(dIe," \u2014 "),$J=n(dIe,"A",{href:!0});var v6t=s($J);YAr=r(v6t,"TFMPNetForQuestionAnswering"),v6t.forEach(t),KAr=r(dIe," (MPNet model)"),dIe.forEach(t),ZAr=i(ge),_C=n(ge,"LI",{});var cIe=s(_C);iTe=n(cIe,"STRONG",{});var F6t=s(iTe);eyr=r(F6t,"rembert"),F6t.forEach(t),oyr=r(cIe," \u2014 "),kJ=n(cIe,"A",{href:!0});var T6t=s(kJ);ryr=r(T6t,"TFRemBertForQuestionAnswering"),T6t.forEach(t),tyr=r(cIe," (RemBERT model)"),cIe.forEach(t),ayr=i(ge),uC=n(ge,"LI",{});var fIe=s(uC);dTe=n(fIe,"STRONG",{});var M6t=s(dTe);nyr=r(M6t,"roberta"),M6t.forEach(t),syr=r(fIe," \u2014 "),SJ=n(fIe,"A",{href:!0});var E6t=s(SJ);lyr=r(E6t,"TFRobertaForQuestionAnswering"),E6t.forEach(t),iyr=r(fIe," (RoBERTa model)"),fIe.forEach(t),dyr=i(ge),bC=n(ge,"LI",{});var mIe=s(bC);cTe=n(mIe,"STRONG",{});var C6t=s(cTe);cyr=r(C6t,"roformer"),C6t.forEach(t),fyr=r(mIe," \u2014 "),RJ=n(mIe,"A",{href:!0});var w6t=s(RJ);myr=r(w6t,"TFRoFormerForQuestionAnswering"),w6t.forEach(t),gyr=r(mIe," (RoFormer model)"),mIe.forEach(t),hyr=i(ge),vC=n(ge,"LI",{});var gIe=s(vC);fTe=n(gIe,"STRONG",{});var A6t=s(fTe);pyr=r(A6t,"xlm"),A6t.forEach(t),_yr=r(gIe," \u2014 "),PJ=n(gIe,"A",{href:!0});var y6t=s(PJ);uyr=r(y6t,"TFXLMForQuestionAnsweringSimple"),y6t.forEach(t),byr=r(gIe," (XLM model)"),gIe.forEach(t),vyr=i(ge),FC=n(ge,"LI",{});var hIe=s(FC);mTe=n(hIe,"STRONG",{});var L6t=s(mTe);Fyr=r(L6t,"xlm-roberta"),L6t.forEach(t),Tyr=r(hIe," \u2014 "),BJ=n(hIe,"A",{href:!0});var x6t=s(BJ);Myr=r(x6t,"TFXLMRobertaForQuestionAnswering"),x6t.forEach(t),Eyr=r(hIe," (XLM-RoBERTa model)"),hIe.forEach(t),Cyr=i(ge),TC=n(ge,"LI",{});var pIe=s(TC);gTe=n(pIe,"STRONG",{});var $6t=s(gTe);wyr=r($6t,"xlnet"),$6t.forEach(t),Ayr=r(pIe," \u2014 "),IJ=n(pIe,"A",{href:!0});var k6t=s(IJ);yyr=r(k6t,"TFXLNetForQuestionAnsweringSimple"),k6t.forEach(t),Lyr=r(pIe," (XLNet model)"),pIe.forEach(t),ge.forEach(t),xyr=i(Nl),T(MC.$$.fragment,Nl),Nl.forEach(t),Il.forEach(t),Xje=i(f),Cc=n(f,"H2",{class:!0});var YGe=s(Cc);EC=n(YGe,"A",{id:!0,class:!0,href:!0});var S6t=s(EC);hTe=n(S6t,"SPAN",{});var R6t=s(hTe);T(v9.$$.fragment,R6t),R6t.forEach(t),S6t.forEach(t),$yr=i(YGe),pTe=n(YGe,"SPAN",{});var P6t=s(pTe);kyr=r(P6t,"TFAutoModelForVision2Seq"),P6t.forEach(t),YGe.forEach(t),zje=i(f),dr=n(f,"DIV",{class:!0});var ql=s(dr);T(F9.$$.fragment,ql),Syr=i(ql),wc=n(ql,"P",{});var Oee=s(wc);Ryr=r(Oee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),NJ=n(Oee,"A",{href:!0});var B6t=s(NJ);Pyr=r(B6t,"from_pretrained()"),B6t.forEach(t),Byr=r(Oee," class method or the "),qJ=n(Oee,"A",{href:!0});var I6t=s(qJ);Iyr=r(I6t,"from_config()"),I6t.forEach(t),Nyr=r(Oee,` class
method.`),Oee.forEach(t),qyr=i(ql),T9=n(ql,"P",{});var KGe=s(T9);jyr=r(KGe,"This class cannot be instantiated directly using "),_Te=n(KGe,"CODE",{});var N6t=s(_Te);Dyr=r(N6t,"__init__()"),N6t.forEach(t),Gyr=r(KGe," (throws an error)."),KGe.forEach(t),Oyr=i(ql),jt=n(ql,"DIV",{class:!0});var Z6=s(jt);T(M9.$$.fragment,Z6),Vyr=i(Z6),uTe=n(Z6,"P",{});var q6t=s(uTe);Xyr=r(q6t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),q6t.forEach(t),zyr=i(Z6),Ac=n(Z6,"P",{});var Vee=s(Ac);Wyr=r(Vee,`Note:
Loading a model from its configuration file does `),bTe=n(Vee,"STRONG",{});var j6t=s(bTe);Qyr=r(j6t,"not"),j6t.forEach(t),Hyr=r(Vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),jJ=n(Vee,"A",{href:!0});var D6t=s(jJ);Uyr=r(D6t,"from_pretrained()"),D6t.forEach(t),Jyr=r(Vee," to load the model weights."),Vee.forEach(t),Yyr=i(Z6),T(CC.$$.fragment,Z6),Z6.forEach(t),Kyr=i(ql),Nr=n(ql,"DIV",{class:!0});var jl=s(Nr);T(E9.$$.fragment,jl),Zyr=i(jl),vTe=n(jl,"P",{});var G6t=s(vTe);eLr=r(G6t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),G6t.forEach(t),oLr=i(jl),mn=n(jl,"P",{});var eA=s(mn);rLr=r(eA,"The model class to instantiate is selected based on the "),FTe=n(eA,"CODE",{});var O6t=s(FTe);tLr=r(O6t,"model_type"),O6t.forEach(t),aLr=r(eA,` property of the config object (either
passed as an argument or loaded from `),TTe=n(eA,"CODE",{});var V6t=s(TTe);nLr=r(V6t,"pretrained_model_name_or_path"),V6t.forEach(t),sLr=r(eA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=n(eA,"CODE",{});var X6t=s(MTe);lLr=r(X6t,"pretrained_model_name_or_path"),X6t.forEach(t),iLr=r(eA,":"),eA.forEach(t),dLr=i(jl),ETe=n(jl,"UL",{});var z6t=s(ETe);wC=n(z6t,"LI",{});var _Ie=s(wC);CTe=n(_Ie,"STRONG",{});var W6t=s(CTe);cLr=r(W6t,"vision-encoder-decoder"),W6t.forEach(t),fLr=r(_Ie," \u2014 "),DJ=n(_Ie,"A",{href:!0});var Q6t=s(DJ);mLr=r(Q6t,"TFVisionEncoderDecoderModel"),Q6t.forEach(t),gLr=r(_Ie," (Vision Encoder decoder model)"),_Ie.forEach(t),z6t.forEach(t),hLr=i(jl),T(AC.$$.fragment,jl),jl.forEach(t),ql.forEach(t),Wje=i(f),yc=n(f,"H2",{class:!0});var ZGe=s(yc);yC=n(ZGe,"A",{id:!0,class:!0,href:!0});var H6t=s(yC);wTe=n(H6t,"SPAN",{});var U6t=s(wTe);T(C9.$$.fragment,U6t),U6t.forEach(t),H6t.forEach(t),pLr=i(ZGe),ATe=n(ZGe,"SPAN",{});var J6t=s(ATe);_Lr=r(J6t,"TFAutoModelForSpeechSeq2Seq"),J6t.forEach(t),ZGe.forEach(t),Qje=i(f),cr=n(f,"DIV",{class:!0});var Dl=s(cr);T(w9.$$.fragment,Dl),uLr=i(Dl),Lc=n(Dl,"P",{});var Xee=s(Lc);bLr=r(Xee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),GJ=n(Xee,"A",{href:!0});var Y6t=s(GJ);vLr=r(Y6t,"from_pretrained()"),Y6t.forEach(t),FLr=r(Xee," class method or the "),OJ=n(Xee,"A",{href:!0});var K6t=s(OJ);TLr=r(K6t,"from_config()"),K6t.forEach(t),MLr=r(Xee,` class
method.`),Xee.forEach(t),ELr=i(Dl),A9=n(Dl,"P",{});var eOe=s(A9);CLr=r(eOe,"This class cannot be instantiated directly using "),yTe=n(eOe,"CODE",{});var Z6t=s(yTe);wLr=r(Z6t,"__init__()"),Z6t.forEach(t),ALr=r(eOe," (throws an error)."),eOe.forEach(t),yLr=i(Dl),Dt=n(Dl,"DIV",{class:!0});var oA=s(Dt);T(y9.$$.fragment,oA),LLr=i(oA),LTe=n(oA,"P",{});var eAt=s(LTe);xLr=r(eAt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),eAt.forEach(t),$Lr=i(oA),xc=n(oA,"P",{});var zee=s(xc);kLr=r(zee,`Note:
Loading a model from its configuration file does `),xTe=n(zee,"STRONG",{});var oAt=s(xTe);SLr=r(oAt,"not"),oAt.forEach(t),RLr=r(zee,` load the model weights. It only affects the
model\u2019s configuration. Use `),VJ=n(zee,"A",{href:!0});var rAt=s(VJ);PLr=r(rAt,"from_pretrained()"),rAt.forEach(t),BLr=r(zee," to load the model weights."),zee.forEach(t),ILr=i(oA),T(LC.$$.fragment,oA),oA.forEach(t),NLr=i(Dl),qr=n(Dl,"DIV",{class:!0});var Gl=s(qr);T(L9.$$.fragment,Gl),qLr=i(Gl),$Te=n(Gl,"P",{});var tAt=s($Te);jLr=r(tAt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),tAt.forEach(t),DLr=i(Gl),gn=n(Gl,"P",{});var rA=s(gn);GLr=r(rA,"The model class to instantiate is selected based on the "),kTe=n(rA,"CODE",{});var aAt=s(kTe);OLr=r(aAt,"model_type"),aAt.forEach(t),VLr=r(rA,` property of the config object (either
passed as an argument or loaded from `),STe=n(rA,"CODE",{});var nAt=s(STe);XLr=r(nAt,"pretrained_model_name_or_path"),nAt.forEach(t),zLr=r(rA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=n(rA,"CODE",{});var sAt=s(RTe);WLr=r(sAt,"pretrained_model_name_or_path"),sAt.forEach(t),QLr=r(rA,":"),rA.forEach(t),HLr=i(Gl),PTe=n(Gl,"UL",{});var lAt=s(PTe);xC=n(lAt,"LI",{});var uIe=s(xC);BTe=n(uIe,"STRONG",{});var iAt=s(BTe);ULr=r(iAt,"speech_to_text"),iAt.forEach(t),JLr=r(uIe," \u2014 "),XJ=n(uIe,"A",{href:!0});var dAt=s(XJ);YLr=r(dAt,"TFSpeech2TextForConditionalGeneration"),dAt.forEach(t),KLr=r(uIe," (Speech2Text model)"),uIe.forEach(t),lAt.forEach(t),ZLr=i(Gl),T($C.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),Hje=i(f),$c=n(f,"H2",{class:!0});var oOe=s($c);kC=n(oOe,"A",{id:!0,class:!0,href:!0});var cAt=s(kC);ITe=n(cAt,"SPAN",{});var fAt=s(ITe);T(x9.$$.fragment,fAt),fAt.forEach(t),cAt.forEach(t),e8r=i(oOe),NTe=n(oOe,"SPAN",{});var mAt=s(NTe);o8r=r(mAt,"FlaxAutoModel"),mAt.forEach(t),oOe.forEach(t),Uje=i(f),fr=n(f,"DIV",{class:!0});var Ol=s(fr);T($9.$$.fragment,Ol),r8r=i(Ol),kc=n(Ol,"P",{});var Wee=s(kc);t8r=r(Wee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),zJ=n(Wee,"A",{href:!0});var gAt=s(zJ);a8r=r(gAt,"from_pretrained()"),gAt.forEach(t),n8r=r(Wee," class method or the "),WJ=n(Wee,"A",{href:!0});var hAt=s(WJ);s8r=r(hAt,"from_config()"),hAt.forEach(t),l8r=r(Wee,` class
method.`),Wee.forEach(t),i8r=i(Ol),k9=n(Ol,"P",{});var rOe=s(k9);d8r=r(rOe,"This class cannot be instantiated directly using "),qTe=n(rOe,"CODE",{});var pAt=s(qTe);c8r=r(pAt,"__init__()"),pAt.forEach(t),f8r=r(rOe," (throws an error)."),rOe.forEach(t),m8r=i(Ol),Gt=n(Ol,"DIV",{class:!0});var tA=s(Gt);T(S9.$$.fragment,tA),g8r=i(tA),jTe=n(tA,"P",{});var _At=s(jTe);h8r=r(_At,"Instantiates one of the base model classes of the library from a configuration."),_At.forEach(t),p8r=i(tA),Sc=n(tA,"P",{});var Qee=s(Sc);_8r=r(Qee,`Note:
Loading a model from its configuration file does `),DTe=n(Qee,"STRONG",{});var uAt=s(DTe);u8r=r(uAt,"not"),uAt.forEach(t),b8r=r(Qee,` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=n(Qee,"A",{href:!0});var bAt=s(QJ);v8r=r(bAt,"from_pretrained()"),bAt.forEach(t),F8r=r(Qee," to load the model weights."),Qee.forEach(t),T8r=i(tA),T(SC.$$.fragment,tA),tA.forEach(t),M8r=i(Ol),jr=n(Ol,"DIV",{class:!0});var Vl=s(jr);T(R9.$$.fragment,Vl),E8r=i(Vl),GTe=n(Vl,"P",{});var vAt=s(GTe);C8r=r(vAt,"Instantiate one of the base model classes of the library from a pretrained model."),vAt.forEach(t),w8r=i(Vl),hn=n(Vl,"P",{});var aA=s(hn);A8r=r(aA,"The model class to instantiate is selected based on the "),OTe=n(aA,"CODE",{});var FAt=s(OTe);y8r=r(FAt,"model_type"),FAt.forEach(t),L8r=r(aA,` property of the config object (either
passed as an argument or loaded from `),VTe=n(aA,"CODE",{});var TAt=s(VTe);x8r=r(TAt,"pretrained_model_name_or_path"),TAt.forEach(t),$8r=r(aA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XTe=n(aA,"CODE",{});var MAt=s(XTe);k8r=r(MAt,"pretrained_model_name_or_path"),MAt.forEach(t),S8r=r(aA,":"),aA.forEach(t),R8r=i(Vl),te=n(Vl,"UL",{});var ne=s(te);RC=n(ne,"LI",{});var bIe=s(RC);zTe=n(bIe,"STRONG",{});var EAt=s(zTe);P8r=r(EAt,"albert"),EAt.forEach(t),B8r=r(bIe," \u2014 "),HJ=n(bIe,"A",{href:!0});var CAt=s(HJ);I8r=r(CAt,"FlaxAlbertModel"),CAt.forEach(t),N8r=r(bIe," (ALBERT model)"),bIe.forEach(t),q8r=i(ne),PC=n(ne,"LI",{});var vIe=s(PC);WTe=n(vIe,"STRONG",{});var wAt=s(WTe);j8r=r(wAt,"bart"),wAt.forEach(t),D8r=r(vIe," \u2014 "),UJ=n(vIe,"A",{href:!0});var AAt=s(UJ);G8r=r(AAt,"FlaxBartModel"),AAt.forEach(t),O8r=r(vIe," (BART model)"),vIe.forEach(t),V8r=i(ne),BC=n(ne,"LI",{});var FIe=s(BC);QTe=n(FIe,"STRONG",{});var yAt=s(QTe);X8r=r(yAt,"beit"),yAt.forEach(t),z8r=r(FIe," \u2014 "),JJ=n(FIe,"A",{href:!0});var LAt=s(JJ);W8r=r(LAt,"FlaxBeitModel"),LAt.forEach(t),Q8r=r(FIe," (BEiT model)"),FIe.forEach(t),H8r=i(ne),IC=n(ne,"LI",{});var TIe=s(IC);HTe=n(TIe,"STRONG",{});var xAt=s(HTe);U8r=r(xAt,"bert"),xAt.forEach(t),J8r=r(TIe," \u2014 "),YJ=n(TIe,"A",{href:!0});var $At=s(YJ);Y8r=r($At,"FlaxBertModel"),$At.forEach(t),K8r=r(TIe," (BERT model)"),TIe.forEach(t),Z8r=i(ne),NC=n(ne,"LI",{});var MIe=s(NC);UTe=n(MIe,"STRONG",{});var kAt=s(UTe);e9r=r(kAt,"big_bird"),kAt.forEach(t),o9r=r(MIe," \u2014 "),KJ=n(MIe,"A",{href:!0});var SAt=s(KJ);r9r=r(SAt,"FlaxBigBirdModel"),SAt.forEach(t),t9r=r(MIe," (BigBird model)"),MIe.forEach(t),a9r=i(ne),qC=n(ne,"LI",{});var EIe=s(qC);JTe=n(EIe,"STRONG",{});var RAt=s(JTe);n9r=r(RAt,"blenderbot"),RAt.forEach(t),s9r=r(EIe," \u2014 "),ZJ=n(EIe,"A",{href:!0});var PAt=s(ZJ);l9r=r(PAt,"FlaxBlenderbotModel"),PAt.forEach(t),i9r=r(EIe," (Blenderbot model)"),EIe.forEach(t),d9r=i(ne),jC=n(ne,"LI",{});var CIe=s(jC);YTe=n(CIe,"STRONG",{});var BAt=s(YTe);c9r=r(BAt,"blenderbot-small"),BAt.forEach(t),f9r=r(CIe," \u2014 "),eY=n(CIe,"A",{href:!0});var IAt=s(eY);m9r=r(IAt,"FlaxBlenderbotSmallModel"),IAt.forEach(t),g9r=r(CIe," (BlenderbotSmall model)"),CIe.forEach(t),h9r=i(ne),DC=n(ne,"LI",{});var wIe=s(DC);KTe=n(wIe,"STRONG",{});var NAt=s(KTe);p9r=r(NAt,"clip"),NAt.forEach(t),_9r=r(wIe," \u2014 "),oY=n(wIe,"A",{href:!0});var qAt=s(oY);u9r=r(qAt,"FlaxCLIPModel"),qAt.forEach(t),b9r=r(wIe," (CLIP model)"),wIe.forEach(t),v9r=i(ne),GC=n(ne,"LI",{});var AIe=s(GC);ZTe=n(AIe,"STRONG",{});var jAt=s(ZTe);F9r=r(jAt,"distilbert"),jAt.forEach(t),T9r=r(AIe," \u2014 "),rY=n(AIe,"A",{href:!0});var DAt=s(rY);M9r=r(DAt,"FlaxDistilBertModel"),DAt.forEach(t),E9r=r(AIe," (DistilBERT model)"),AIe.forEach(t),C9r=i(ne),OC=n(ne,"LI",{});var yIe=s(OC);e7e=n(yIe,"STRONG",{});var GAt=s(e7e);w9r=r(GAt,"electra"),GAt.forEach(t),A9r=r(yIe," \u2014 "),tY=n(yIe,"A",{href:!0});var OAt=s(tY);y9r=r(OAt,"FlaxElectraModel"),OAt.forEach(t),L9r=r(yIe," (ELECTRA model)"),yIe.forEach(t),x9r=i(ne),VC=n(ne,"LI",{});var LIe=s(VC);o7e=n(LIe,"STRONG",{});var VAt=s(o7e);$9r=r(VAt,"gpt2"),VAt.forEach(t),k9r=r(LIe," \u2014 "),aY=n(LIe,"A",{href:!0});var XAt=s(aY);S9r=r(XAt,"FlaxGPT2Model"),XAt.forEach(t),R9r=r(LIe," (OpenAI GPT-2 model)"),LIe.forEach(t),P9r=i(ne),XC=n(ne,"LI",{});var xIe=s(XC);r7e=n(xIe,"STRONG",{});var zAt=s(r7e);B9r=r(zAt,"gpt_neo"),zAt.forEach(t),I9r=r(xIe," \u2014 "),nY=n(xIe,"A",{href:!0});var WAt=s(nY);N9r=r(WAt,"FlaxGPTNeoModel"),WAt.forEach(t),q9r=r(xIe," (GPT Neo model)"),xIe.forEach(t),j9r=i(ne),zC=n(ne,"LI",{});var $Ie=s(zC);t7e=n($Ie,"STRONG",{});var QAt=s(t7e);D9r=r(QAt,"gptj"),QAt.forEach(t),G9r=r($Ie," \u2014 "),sY=n($Ie,"A",{href:!0});var HAt=s(sY);O9r=r(HAt,"FlaxGPTJModel"),HAt.forEach(t),V9r=r($Ie," (GPT-J model)"),$Ie.forEach(t),X9r=i(ne),WC=n(ne,"LI",{});var kIe=s(WC);a7e=n(kIe,"STRONG",{});var UAt=s(a7e);z9r=r(UAt,"marian"),UAt.forEach(t),W9r=r(kIe," \u2014 "),lY=n(kIe,"A",{href:!0});var JAt=s(lY);Q9r=r(JAt,"FlaxMarianModel"),JAt.forEach(t),H9r=r(kIe," (Marian model)"),kIe.forEach(t),U9r=i(ne),QC=n(ne,"LI",{});var SIe=s(QC);n7e=n(SIe,"STRONG",{});var YAt=s(n7e);J9r=r(YAt,"mbart"),YAt.forEach(t),Y9r=r(SIe," \u2014 "),iY=n(SIe,"A",{href:!0});var KAt=s(iY);K9r=r(KAt,"FlaxMBartModel"),KAt.forEach(t),Z9r=r(SIe," (mBART model)"),SIe.forEach(t),exr=i(ne),HC=n(ne,"LI",{});var RIe=s(HC);s7e=n(RIe,"STRONG",{});var ZAt=s(s7e);oxr=r(ZAt,"mt5"),ZAt.forEach(t),rxr=r(RIe," \u2014 "),dY=n(RIe,"A",{href:!0});var eyt=s(dY);txr=r(eyt,"FlaxMT5Model"),eyt.forEach(t),axr=r(RIe," (mT5 model)"),RIe.forEach(t),nxr=i(ne),UC=n(ne,"LI",{});var PIe=s(UC);l7e=n(PIe,"STRONG",{});var oyt=s(l7e);sxr=r(oyt,"pegasus"),oyt.forEach(t),lxr=r(PIe," \u2014 "),cY=n(PIe,"A",{href:!0});var ryt=s(cY);ixr=r(ryt,"FlaxPegasusModel"),ryt.forEach(t),dxr=r(PIe," (Pegasus model)"),PIe.forEach(t),cxr=i(ne),JC=n(ne,"LI",{});var BIe=s(JC);i7e=n(BIe,"STRONG",{});var tyt=s(i7e);fxr=r(tyt,"roberta"),tyt.forEach(t),mxr=r(BIe," \u2014 "),fY=n(BIe,"A",{href:!0});var ayt=s(fY);gxr=r(ayt,"FlaxRobertaModel"),ayt.forEach(t),hxr=r(BIe," (RoBERTa model)"),BIe.forEach(t),pxr=i(ne),YC=n(ne,"LI",{});var IIe=s(YC);d7e=n(IIe,"STRONG",{});var nyt=s(d7e);_xr=r(nyt,"roformer"),nyt.forEach(t),uxr=r(IIe," \u2014 "),mY=n(IIe,"A",{href:!0});var syt=s(mY);bxr=r(syt,"FlaxRoFormerModel"),syt.forEach(t),vxr=r(IIe," (RoFormer model)"),IIe.forEach(t),Fxr=i(ne),KC=n(ne,"LI",{});var NIe=s(KC);c7e=n(NIe,"STRONG",{});var lyt=s(c7e);Txr=r(lyt,"t5"),lyt.forEach(t),Mxr=r(NIe," \u2014 "),gY=n(NIe,"A",{href:!0});var iyt=s(gY);Exr=r(iyt,"FlaxT5Model"),iyt.forEach(t),Cxr=r(NIe," (T5 model)"),NIe.forEach(t),wxr=i(ne),ZC=n(ne,"LI",{});var qIe=s(ZC);f7e=n(qIe,"STRONG",{});var dyt=s(f7e);Axr=r(dyt,"vision-text-dual-encoder"),dyt.forEach(t),yxr=r(qIe," \u2014 "),hY=n(qIe,"A",{href:!0});var cyt=s(hY);Lxr=r(cyt,"FlaxVisionTextDualEncoderModel"),cyt.forEach(t),xxr=r(qIe," (VisionTextDualEncoder model)"),qIe.forEach(t),$xr=i(ne),e5=n(ne,"LI",{});var jIe=s(e5);m7e=n(jIe,"STRONG",{});var fyt=s(m7e);kxr=r(fyt,"vit"),fyt.forEach(t),Sxr=r(jIe," \u2014 "),pY=n(jIe,"A",{href:!0});var myt=s(pY);Rxr=r(myt,"FlaxViTModel"),myt.forEach(t),Pxr=r(jIe," (ViT model)"),jIe.forEach(t),Bxr=i(ne),o5=n(ne,"LI",{});var DIe=s(o5);g7e=n(DIe,"STRONG",{});var gyt=s(g7e);Ixr=r(gyt,"wav2vec2"),gyt.forEach(t),Nxr=r(DIe," \u2014 "),_Y=n(DIe,"A",{href:!0});var hyt=s(_Y);qxr=r(hyt,"FlaxWav2Vec2Model"),hyt.forEach(t),jxr=r(DIe," (Wav2Vec2 model)"),DIe.forEach(t),Dxr=i(ne),r5=n(ne,"LI",{});var GIe=s(r5);h7e=n(GIe,"STRONG",{});var pyt=s(h7e);Gxr=r(pyt,"xglm"),pyt.forEach(t),Oxr=r(GIe," \u2014 "),uY=n(GIe,"A",{href:!0});var _yt=s(uY);Vxr=r(_yt,"FlaxXGLMModel"),_yt.forEach(t),Xxr=r(GIe," (XGLM model)"),GIe.forEach(t),zxr=i(ne),t5=n(ne,"LI",{});var OIe=s(t5);p7e=n(OIe,"STRONG",{});var uyt=s(p7e);Wxr=r(uyt,"xlm-roberta"),uyt.forEach(t),Qxr=r(OIe," \u2014 "),bY=n(OIe,"A",{href:!0});var byt=s(bY);Hxr=r(byt,"FlaxXLMRobertaModel"),byt.forEach(t),Uxr=r(OIe," (XLM-RoBERTa model)"),OIe.forEach(t),ne.forEach(t),Jxr=i(Vl),T(a5.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),Jje=i(f),Rc=n(f,"H2",{class:!0});var tOe=s(Rc);n5=n(tOe,"A",{id:!0,class:!0,href:!0});var vyt=s(n5);_7e=n(vyt,"SPAN",{});var Fyt=s(_7e);T(P9.$$.fragment,Fyt),Fyt.forEach(t),vyt.forEach(t),Yxr=i(tOe),u7e=n(tOe,"SPAN",{});var Tyt=s(u7e);Kxr=r(Tyt,"FlaxAutoModelForCausalLM"),Tyt.forEach(t),tOe.forEach(t),Yje=i(f),mr=n(f,"DIV",{class:!0});var Xl=s(mr);T(B9.$$.fragment,Xl),Zxr=i(Xl),Pc=n(Xl,"P",{});var Hee=s(Pc);e$r=r(Hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vY=n(Hee,"A",{href:!0});var Myt=s(vY);o$r=r(Myt,"from_pretrained()"),Myt.forEach(t),r$r=r(Hee," class method or the "),FY=n(Hee,"A",{href:!0});var Eyt=s(FY);t$r=r(Eyt,"from_config()"),Eyt.forEach(t),a$r=r(Hee,` class
method.`),Hee.forEach(t),n$r=i(Xl),I9=n(Xl,"P",{});var aOe=s(I9);s$r=r(aOe,"This class cannot be instantiated directly using "),b7e=n(aOe,"CODE",{});var Cyt=s(b7e);l$r=r(Cyt,"__init__()"),Cyt.forEach(t),i$r=r(aOe," (throws an error)."),aOe.forEach(t),d$r=i(Xl),Ot=n(Xl,"DIV",{class:!0});var nA=s(Ot);T(N9.$$.fragment,nA),c$r=i(nA),v7e=n(nA,"P",{});var wyt=s(v7e);f$r=r(wyt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),wyt.forEach(t),m$r=i(nA),Bc=n(nA,"P",{});var Uee=s(Bc);g$r=r(Uee,`Note:
Loading a model from its configuration file does `),F7e=n(Uee,"STRONG",{});var Ayt=s(F7e);h$r=r(Ayt,"not"),Ayt.forEach(t),p$r=r(Uee,` load the model weights. It only affects the
model\u2019s configuration. Use `),TY=n(Uee,"A",{href:!0});var yyt=s(TY);_$r=r(yyt,"from_pretrained()"),yyt.forEach(t),u$r=r(Uee," to load the model weights."),Uee.forEach(t),b$r=i(nA),T(s5.$$.fragment,nA),nA.forEach(t),v$r=i(Xl),Dr=n(Xl,"DIV",{class:!0});var zl=s(Dr);T(q9.$$.fragment,zl),F$r=i(zl),T7e=n(zl,"P",{});var Lyt=s(T7e);T$r=r(Lyt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Lyt.forEach(t),M$r=i(zl),pn=n(zl,"P",{});var sA=s(pn);E$r=r(sA,"The model class to instantiate is selected based on the "),M7e=n(sA,"CODE",{});var xyt=s(M7e);C$r=r(xyt,"model_type"),xyt.forEach(t),w$r=r(sA,` property of the config object (either
passed as an argument or loaded from `),E7e=n(sA,"CODE",{});var $yt=s(E7e);A$r=r($yt,"pretrained_model_name_or_path"),$yt.forEach(t),y$r=r(sA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=n(sA,"CODE",{});var kyt=s(C7e);L$r=r(kyt,"pretrained_model_name_or_path"),kyt.forEach(t),x$r=r(sA,":"),sA.forEach(t),$$r=i(zl),Re=n(zl,"UL",{});var Xe=s(Re);l5=n(Xe,"LI",{});var VIe=s(l5);w7e=n(VIe,"STRONG",{});var Syt=s(w7e);k$r=r(Syt,"bart"),Syt.forEach(t),S$r=r(VIe," \u2014 "),MY=n(VIe,"A",{href:!0});var Ryt=s(MY);R$r=r(Ryt,"FlaxBartForCausalLM"),Ryt.forEach(t),P$r=r(VIe," (BART model)"),VIe.forEach(t),B$r=i(Xe),i5=n(Xe,"LI",{});var XIe=s(i5);A7e=n(XIe,"STRONG",{});var Pyt=s(A7e);I$r=r(Pyt,"bert"),Pyt.forEach(t),N$r=r(XIe," \u2014 "),EY=n(XIe,"A",{href:!0});var Byt=s(EY);q$r=r(Byt,"FlaxBertForCausalLM"),Byt.forEach(t),j$r=r(XIe," (BERT model)"),XIe.forEach(t),D$r=i(Xe),d5=n(Xe,"LI",{});var zIe=s(d5);y7e=n(zIe,"STRONG",{});var Iyt=s(y7e);G$r=r(Iyt,"big_bird"),Iyt.forEach(t),O$r=r(zIe," \u2014 "),CY=n(zIe,"A",{href:!0});var Nyt=s(CY);V$r=r(Nyt,"FlaxBigBirdForCausalLM"),Nyt.forEach(t),X$r=r(zIe," (BigBird model)"),zIe.forEach(t),z$r=i(Xe),c5=n(Xe,"LI",{});var WIe=s(c5);L7e=n(WIe,"STRONG",{});var qyt=s(L7e);W$r=r(qyt,"electra"),qyt.forEach(t),Q$r=r(WIe," \u2014 "),wY=n(WIe,"A",{href:!0});var jyt=s(wY);H$r=r(jyt,"FlaxElectraForCausalLM"),jyt.forEach(t),U$r=r(WIe," (ELECTRA model)"),WIe.forEach(t),J$r=i(Xe),f5=n(Xe,"LI",{});var QIe=s(f5);x7e=n(QIe,"STRONG",{});var Dyt=s(x7e);Y$r=r(Dyt,"gpt2"),Dyt.forEach(t),K$r=r(QIe," \u2014 "),AY=n(QIe,"A",{href:!0});var Gyt=s(AY);Z$r=r(Gyt,"FlaxGPT2LMHeadModel"),Gyt.forEach(t),ekr=r(QIe," (OpenAI GPT-2 model)"),QIe.forEach(t),okr=i(Xe),m5=n(Xe,"LI",{});var HIe=s(m5);$7e=n(HIe,"STRONG",{});var Oyt=s($7e);rkr=r(Oyt,"gpt_neo"),Oyt.forEach(t),tkr=r(HIe," \u2014 "),yY=n(HIe,"A",{href:!0});var Vyt=s(yY);akr=r(Vyt,"FlaxGPTNeoForCausalLM"),Vyt.forEach(t),nkr=r(HIe," (GPT Neo model)"),HIe.forEach(t),skr=i(Xe),g5=n(Xe,"LI",{});var UIe=s(g5);k7e=n(UIe,"STRONG",{});var Xyt=s(k7e);lkr=r(Xyt,"gptj"),Xyt.forEach(t),ikr=r(UIe," \u2014 "),LY=n(UIe,"A",{href:!0});var zyt=s(LY);dkr=r(zyt,"FlaxGPTJForCausalLM"),zyt.forEach(t),ckr=r(UIe," (GPT-J model)"),UIe.forEach(t),fkr=i(Xe),h5=n(Xe,"LI",{});var JIe=s(h5);S7e=n(JIe,"STRONG",{});var Wyt=s(S7e);mkr=r(Wyt,"roberta"),Wyt.forEach(t),gkr=r(JIe," \u2014 "),xY=n(JIe,"A",{href:!0});var Qyt=s(xY);hkr=r(Qyt,"FlaxRobertaForCausalLM"),Qyt.forEach(t),pkr=r(JIe," (RoBERTa model)"),JIe.forEach(t),_kr=i(Xe),p5=n(Xe,"LI",{});var YIe=s(p5);R7e=n(YIe,"STRONG",{});var Hyt=s(R7e);ukr=r(Hyt,"xglm"),Hyt.forEach(t),bkr=r(YIe," \u2014 "),$Y=n(YIe,"A",{href:!0});var Uyt=s($Y);vkr=r(Uyt,"FlaxXGLMForCausalLM"),Uyt.forEach(t),Fkr=r(YIe," (XGLM model)"),YIe.forEach(t),Xe.forEach(t),Tkr=i(zl),T(_5.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),Kje=i(f),Ic=n(f,"H2",{class:!0});var nOe=s(Ic);u5=n(nOe,"A",{id:!0,class:!0,href:!0});var Jyt=s(u5);P7e=n(Jyt,"SPAN",{});var Yyt=s(P7e);T(j9.$$.fragment,Yyt),Yyt.forEach(t),Jyt.forEach(t),Mkr=i(nOe),B7e=n(nOe,"SPAN",{});var Kyt=s(B7e);Ekr=r(Kyt,"FlaxAutoModelForPreTraining"),Kyt.forEach(t),nOe.forEach(t),Zje=i(f),gr=n(f,"DIV",{class:!0});var Wl=s(gr);T(D9.$$.fragment,Wl),Ckr=i(Wl),Nc=n(Wl,"P",{});var Jee=s(Nc);wkr=r(Jee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),kY=n(Jee,"A",{href:!0});var Zyt=s(kY);Akr=r(Zyt,"from_pretrained()"),Zyt.forEach(t),ykr=r(Jee," class method or the "),SY=n(Jee,"A",{href:!0});var eLt=s(SY);Lkr=r(eLt,"from_config()"),eLt.forEach(t),xkr=r(Jee,` class
method.`),Jee.forEach(t),$kr=i(Wl),G9=n(Wl,"P",{});var sOe=s(G9);kkr=r(sOe,"This class cannot be instantiated directly using "),I7e=n(sOe,"CODE",{});var oLt=s(I7e);Skr=r(oLt,"__init__()"),oLt.forEach(t),Rkr=r(sOe," (throws an error)."),sOe.forEach(t),Pkr=i(Wl),Vt=n(Wl,"DIV",{class:!0});var lA=s(Vt);T(O9.$$.fragment,lA),Bkr=i(lA),N7e=n(lA,"P",{});var rLt=s(N7e);Ikr=r(rLt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),rLt.forEach(t),Nkr=i(lA),qc=n(lA,"P",{});var Yee=s(qc);qkr=r(Yee,`Note:
Loading a model from its configuration file does `),q7e=n(Yee,"STRONG",{});var tLt=s(q7e);jkr=r(tLt,"not"),tLt.forEach(t),Dkr=r(Yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),RY=n(Yee,"A",{href:!0});var aLt=s(RY);Gkr=r(aLt,"from_pretrained()"),aLt.forEach(t),Okr=r(Yee," to load the model weights."),Yee.forEach(t),Vkr=i(lA),T(b5.$$.fragment,lA),lA.forEach(t),Xkr=i(Wl),Gr=n(Wl,"DIV",{class:!0});var Ql=s(Gr);T(V9.$$.fragment,Ql),zkr=i(Ql),j7e=n(Ql,"P",{});var nLt=s(j7e);Wkr=r(nLt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),nLt.forEach(t),Qkr=i(Ql),_n=n(Ql,"P",{});var iA=s(_n);Hkr=r(iA,"The model class to instantiate is selected based on the "),D7e=n(iA,"CODE",{});var sLt=s(D7e);Ukr=r(sLt,"model_type"),sLt.forEach(t),Jkr=r(iA,` property of the config object (either
passed as an argument or loaded from `),G7e=n(iA,"CODE",{});var lLt=s(G7e);Ykr=r(lLt,"pretrained_model_name_or_path"),lLt.forEach(t),Kkr=r(iA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=n(iA,"CODE",{});var iLt=s(O7e);Zkr=r(iLt,"pretrained_model_name_or_path"),iLt.forEach(t),eSr=r(iA,":"),iA.forEach(t),oSr=i(Ql),Ee=n(Ql,"UL",{});var we=s(Ee);v5=n(we,"LI",{});var KIe=s(v5);V7e=n(KIe,"STRONG",{});var dLt=s(V7e);rSr=r(dLt,"albert"),dLt.forEach(t),tSr=r(KIe," \u2014 "),PY=n(KIe,"A",{href:!0});var cLt=s(PY);aSr=r(cLt,"FlaxAlbertForPreTraining"),cLt.forEach(t),nSr=r(KIe," (ALBERT model)"),KIe.forEach(t),sSr=i(we),F5=n(we,"LI",{});var ZIe=s(F5);X7e=n(ZIe,"STRONG",{});var fLt=s(X7e);lSr=r(fLt,"bart"),fLt.forEach(t),iSr=r(ZIe," \u2014 "),BY=n(ZIe,"A",{href:!0});var mLt=s(BY);dSr=r(mLt,"FlaxBartForConditionalGeneration"),mLt.forEach(t),cSr=r(ZIe," (BART model)"),ZIe.forEach(t),fSr=i(we),T5=n(we,"LI",{});var eNe=s(T5);z7e=n(eNe,"STRONG",{});var gLt=s(z7e);mSr=r(gLt,"bert"),gLt.forEach(t),gSr=r(eNe," \u2014 "),IY=n(eNe,"A",{href:!0});var hLt=s(IY);hSr=r(hLt,"FlaxBertForPreTraining"),hLt.forEach(t),pSr=r(eNe," (BERT model)"),eNe.forEach(t),_Sr=i(we),M5=n(we,"LI",{});var oNe=s(M5);W7e=n(oNe,"STRONG",{});var pLt=s(W7e);uSr=r(pLt,"big_bird"),pLt.forEach(t),bSr=r(oNe," \u2014 "),NY=n(oNe,"A",{href:!0});var _Lt=s(NY);vSr=r(_Lt,"FlaxBigBirdForPreTraining"),_Lt.forEach(t),FSr=r(oNe," (BigBird model)"),oNe.forEach(t),TSr=i(we),E5=n(we,"LI",{});var rNe=s(E5);Q7e=n(rNe,"STRONG",{});var uLt=s(Q7e);MSr=r(uLt,"electra"),uLt.forEach(t),ESr=r(rNe," \u2014 "),qY=n(rNe,"A",{href:!0});var bLt=s(qY);CSr=r(bLt,"FlaxElectraForPreTraining"),bLt.forEach(t),wSr=r(rNe," (ELECTRA model)"),rNe.forEach(t),ASr=i(we),C5=n(we,"LI",{});var tNe=s(C5);H7e=n(tNe,"STRONG",{});var vLt=s(H7e);ySr=r(vLt,"mbart"),vLt.forEach(t),LSr=r(tNe," \u2014 "),jY=n(tNe,"A",{href:!0});var FLt=s(jY);xSr=r(FLt,"FlaxMBartForConditionalGeneration"),FLt.forEach(t),$Sr=r(tNe," (mBART model)"),tNe.forEach(t),kSr=i(we),w5=n(we,"LI",{});var aNe=s(w5);U7e=n(aNe,"STRONG",{});var TLt=s(U7e);SSr=r(TLt,"mt5"),TLt.forEach(t),RSr=r(aNe," \u2014 "),DY=n(aNe,"A",{href:!0});var MLt=s(DY);PSr=r(MLt,"FlaxMT5ForConditionalGeneration"),MLt.forEach(t),BSr=r(aNe," (mT5 model)"),aNe.forEach(t),ISr=i(we),A5=n(we,"LI",{});var nNe=s(A5);J7e=n(nNe,"STRONG",{});var ELt=s(J7e);NSr=r(ELt,"roberta"),ELt.forEach(t),qSr=r(nNe," \u2014 "),GY=n(nNe,"A",{href:!0});var CLt=s(GY);jSr=r(CLt,"FlaxRobertaForMaskedLM"),CLt.forEach(t),DSr=r(nNe," (RoBERTa model)"),nNe.forEach(t),GSr=i(we),y5=n(we,"LI",{});var sNe=s(y5);Y7e=n(sNe,"STRONG",{});var wLt=s(Y7e);OSr=r(wLt,"roformer"),wLt.forEach(t),VSr=r(sNe," \u2014 "),OY=n(sNe,"A",{href:!0});var ALt=s(OY);XSr=r(ALt,"FlaxRoFormerForMaskedLM"),ALt.forEach(t),zSr=r(sNe," (RoFormer model)"),sNe.forEach(t),WSr=i(we),L5=n(we,"LI",{});var lNe=s(L5);K7e=n(lNe,"STRONG",{});var yLt=s(K7e);QSr=r(yLt,"t5"),yLt.forEach(t),HSr=r(lNe," \u2014 "),VY=n(lNe,"A",{href:!0});var LLt=s(VY);USr=r(LLt,"FlaxT5ForConditionalGeneration"),LLt.forEach(t),JSr=r(lNe," (T5 model)"),lNe.forEach(t),YSr=i(we),x5=n(we,"LI",{});var iNe=s(x5);Z7e=n(iNe,"STRONG",{});var xLt=s(Z7e);KSr=r(xLt,"wav2vec2"),xLt.forEach(t),ZSr=r(iNe," \u2014 "),XY=n(iNe,"A",{href:!0});var $Lt=s(XY);eRr=r($Lt,"FlaxWav2Vec2ForPreTraining"),$Lt.forEach(t),oRr=r(iNe," (Wav2Vec2 model)"),iNe.forEach(t),rRr=i(we),$5=n(we,"LI",{});var dNe=s($5);eMe=n(dNe,"STRONG",{});var kLt=s(eMe);tRr=r(kLt,"xlm-roberta"),kLt.forEach(t),aRr=r(dNe," \u2014 "),zY=n(dNe,"A",{href:!0});var SLt=s(zY);nRr=r(SLt,"FlaxXLMRobertaForMaskedLM"),SLt.forEach(t),sRr=r(dNe," (XLM-RoBERTa model)"),dNe.forEach(t),we.forEach(t),lRr=i(Ql),T(k5.$$.fragment,Ql),Ql.forEach(t),Wl.forEach(t),eDe=i(f),jc=n(f,"H2",{class:!0});var lOe=s(jc);S5=n(lOe,"A",{id:!0,class:!0,href:!0});var RLt=s(S5);oMe=n(RLt,"SPAN",{});var PLt=s(oMe);T(X9.$$.fragment,PLt),PLt.forEach(t),RLt.forEach(t),iRr=i(lOe),rMe=n(lOe,"SPAN",{});var BLt=s(rMe);dRr=r(BLt,"FlaxAutoModelForMaskedLM"),BLt.forEach(t),lOe.forEach(t),oDe=i(f),hr=n(f,"DIV",{class:!0});var Hl=s(hr);T(z9.$$.fragment,Hl),cRr=i(Hl),Dc=n(Hl,"P",{});var Kee=s(Dc);fRr=r(Kee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),WY=n(Kee,"A",{href:!0});var ILt=s(WY);mRr=r(ILt,"from_pretrained()"),ILt.forEach(t),gRr=r(Kee," class method or the "),QY=n(Kee,"A",{href:!0});var NLt=s(QY);hRr=r(NLt,"from_config()"),NLt.forEach(t),pRr=r(Kee,` class
method.`),Kee.forEach(t),_Rr=i(Hl),W9=n(Hl,"P",{});var iOe=s(W9);uRr=r(iOe,"This class cannot be instantiated directly using "),tMe=n(iOe,"CODE",{});var qLt=s(tMe);bRr=r(qLt,"__init__()"),qLt.forEach(t),vRr=r(iOe," (throws an error)."),iOe.forEach(t),FRr=i(Hl),Xt=n(Hl,"DIV",{class:!0});var dA=s(Xt);T(Q9.$$.fragment,dA),TRr=i(dA),aMe=n(dA,"P",{});var jLt=s(aMe);MRr=r(jLt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),jLt.forEach(t),ERr=i(dA),Gc=n(dA,"P",{});var Zee=s(Gc);CRr=r(Zee,`Note:
Loading a model from its configuration file does `),nMe=n(Zee,"STRONG",{});var DLt=s(nMe);wRr=r(DLt,"not"),DLt.forEach(t),ARr=r(Zee,` load the model weights. It only affects the
model\u2019s configuration. Use `),HY=n(Zee,"A",{href:!0});var GLt=s(HY);yRr=r(GLt,"from_pretrained()"),GLt.forEach(t),LRr=r(Zee," to load the model weights."),Zee.forEach(t),xRr=i(dA),T(R5.$$.fragment,dA),dA.forEach(t),$Rr=i(Hl),Or=n(Hl,"DIV",{class:!0});var Ul=s(Or);T(H9.$$.fragment,Ul),kRr=i(Ul),sMe=n(Ul,"P",{});var OLt=s(sMe);SRr=r(OLt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),OLt.forEach(t),RRr=i(Ul),un=n(Ul,"P",{});var cA=s(un);PRr=r(cA,"The model class to instantiate is selected based on the "),lMe=n(cA,"CODE",{});var VLt=s(lMe);BRr=r(VLt,"model_type"),VLt.forEach(t),IRr=r(cA,` property of the config object (either
passed as an argument or loaded from `),iMe=n(cA,"CODE",{});var XLt=s(iMe);NRr=r(XLt,"pretrained_model_name_or_path"),XLt.forEach(t),qRr=r(cA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dMe=n(cA,"CODE",{});var zLt=s(dMe);jRr=r(zLt,"pretrained_model_name_or_path"),zLt.forEach(t),DRr=r(cA,":"),cA.forEach(t),GRr=i(Ul),Le=n(Ul,"UL",{});var Ie=s(Le);P5=n(Ie,"LI",{});var cNe=s(P5);cMe=n(cNe,"STRONG",{});var WLt=s(cMe);ORr=r(WLt,"albert"),WLt.forEach(t),VRr=r(cNe," \u2014 "),UY=n(cNe,"A",{href:!0});var QLt=s(UY);XRr=r(QLt,"FlaxAlbertForMaskedLM"),QLt.forEach(t),zRr=r(cNe," (ALBERT model)"),cNe.forEach(t),WRr=i(Ie),B5=n(Ie,"LI",{});var fNe=s(B5);fMe=n(fNe,"STRONG",{});var HLt=s(fMe);QRr=r(HLt,"bart"),HLt.forEach(t),HRr=r(fNe," \u2014 "),JY=n(fNe,"A",{href:!0});var ULt=s(JY);URr=r(ULt,"FlaxBartForConditionalGeneration"),ULt.forEach(t),JRr=r(fNe," (BART model)"),fNe.forEach(t),YRr=i(Ie),I5=n(Ie,"LI",{});var mNe=s(I5);mMe=n(mNe,"STRONG",{});var JLt=s(mMe);KRr=r(JLt,"bert"),JLt.forEach(t),ZRr=r(mNe," \u2014 "),YY=n(mNe,"A",{href:!0});var YLt=s(YY);ePr=r(YLt,"FlaxBertForMaskedLM"),YLt.forEach(t),oPr=r(mNe," (BERT model)"),mNe.forEach(t),rPr=i(Ie),N5=n(Ie,"LI",{});var gNe=s(N5);gMe=n(gNe,"STRONG",{});var KLt=s(gMe);tPr=r(KLt,"big_bird"),KLt.forEach(t),aPr=r(gNe," \u2014 "),KY=n(gNe,"A",{href:!0});var ZLt=s(KY);nPr=r(ZLt,"FlaxBigBirdForMaskedLM"),ZLt.forEach(t),sPr=r(gNe," (BigBird model)"),gNe.forEach(t),lPr=i(Ie),q5=n(Ie,"LI",{});var hNe=s(q5);hMe=n(hNe,"STRONG",{});var e8t=s(hMe);iPr=r(e8t,"distilbert"),e8t.forEach(t),dPr=r(hNe," \u2014 "),ZY=n(hNe,"A",{href:!0});var o8t=s(ZY);cPr=r(o8t,"FlaxDistilBertForMaskedLM"),o8t.forEach(t),fPr=r(hNe," (DistilBERT model)"),hNe.forEach(t),mPr=i(Ie),j5=n(Ie,"LI",{});var pNe=s(j5);pMe=n(pNe,"STRONG",{});var r8t=s(pMe);gPr=r(r8t,"electra"),r8t.forEach(t),hPr=r(pNe," \u2014 "),eK=n(pNe,"A",{href:!0});var t8t=s(eK);pPr=r(t8t,"FlaxElectraForMaskedLM"),t8t.forEach(t),_Pr=r(pNe," (ELECTRA model)"),pNe.forEach(t),uPr=i(Ie),D5=n(Ie,"LI",{});var _Ne=s(D5);_Me=n(_Ne,"STRONG",{});var a8t=s(_Me);bPr=r(a8t,"mbart"),a8t.forEach(t),vPr=r(_Ne," \u2014 "),oK=n(_Ne,"A",{href:!0});var n8t=s(oK);FPr=r(n8t,"FlaxMBartForConditionalGeneration"),n8t.forEach(t),TPr=r(_Ne," (mBART model)"),_Ne.forEach(t),MPr=i(Ie),G5=n(Ie,"LI",{});var uNe=s(G5);uMe=n(uNe,"STRONG",{});var s8t=s(uMe);EPr=r(s8t,"roberta"),s8t.forEach(t),CPr=r(uNe," \u2014 "),rK=n(uNe,"A",{href:!0});var l8t=s(rK);wPr=r(l8t,"FlaxRobertaForMaskedLM"),l8t.forEach(t),APr=r(uNe," (RoBERTa model)"),uNe.forEach(t),yPr=i(Ie),O5=n(Ie,"LI",{});var bNe=s(O5);bMe=n(bNe,"STRONG",{});var i8t=s(bMe);LPr=r(i8t,"roformer"),i8t.forEach(t),xPr=r(bNe," \u2014 "),tK=n(bNe,"A",{href:!0});var d8t=s(tK);$Pr=r(d8t,"FlaxRoFormerForMaskedLM"),d8t.forEach(t),kPr=r(bNe," (RoFormer model)"),bNe.forEach(t),SPr=i(Ie),V5=n(Ie,"LI",{});var vNe=s(V5);vMe=n(vNe,"STRONG",{});var c8t=s(vMe);RPr=r(c8t,"xlm-roberta"),c8t.forEach(t),PPr=r(vNe," \u2014 "),aK=n(vNe,"A",{href:!0});var f8t=s(aK);BPr=r(f8t,"FlaxXLMRobertaForMaskedLM"),f8t.forEach(t),IPr=r(vNe," (XLM-RoBERTa model)"),vNe.forEach(t),Ie.forEach(t),NPr=i(Ul),T(X5.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),rDe=i(f),Oc=n(f,"H2",{class:!0});var dOe=s(Oc);z5=n(dOe,"A",{id:!0,class:!0,href:!0});var m8t=s(z5);FMe=n(m8t,"SPAN",{});var g8t=s(FMe);T(U9.$$.fragment,g8t),g8t.forEach(t),m8t.forEach(t),qPr=i(dOe),TMe=n(dOe,"SPAN",{});var h8t=s(TMe);jPr=r(h8t,"FlaxAutoModelForSeq2SeqLM"),h8t.forEach(t),dOe.forEach(t),tDe=i(f),pr=n(f,"DIV",{class:!0});var Jl=s(pr);T(J9.$$.fragment,Jl),DPr=i(Jl),Vc=n(Jl,"P",{});var eoe=s(Vc);GPr=r(eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),nK=n(eoe,"A",{href:!0});var p8t=s(nK);OPr=r(p8t,"from_pretrained()"),p8t.forEach(t),VPr=r(eoe," class method or the "),sK=n(eoe,"A",{href:!0});var _8t=s(sK);XPr=r(_8t,"from_config()"),_8t.forEach(t),zPr=r(eoe,` class
method.`),eoe.forEach(t),WPr=i(Jl),Y9=n(Jl,"P",{});var cOe=s(Y9);QPr=r(cOe,"This class cannot be instantiated directly using "),MMe=n(cOe,"CODE",{});var u8t=s(MMe);HPr=r(u8t,"__init__()"),u8t.forEach(t),UPr=r(cOe," (throws an error)."),cOe.forEach(t),JPr=i(Jl),zt=n(Jl,"DIV",{class:!0});var fA=s(zt);T(K9.$$.fragment,fA),YPr=i(fA),EMe=n(fA,"P",{});var b8t=s(EMe);KPr=r(b8t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),b8t.forEach(t),ZPr=i(fA),Xc=n(fA,"P",{});var ooe=s(Xc);eBr=r(ooe,`Note:
Loading a model from its configuration file does `),CMe=n(ooe,"STRONG",{});var v8t=s(CMe);oBr=r(v8t,"not"),v8t.forEach(t),rBr=r(ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=n(ooe,"A",{href:!0});var F8t=s(lK);tBr=r(F8t,"from_pretrained()"),F8t.forEach(t),aBr=r(ooe," to load the model weights."),ooe.forEach(t),nBr=i(fA),T(W5.$$.fragment,fA),fA.forEach(t),sBr=i(Jl),Vr=n(Jl,"DIV",{class:!0});var Yl=s(Vr);T(Z9.$$.fragment,Yl),lBr=i(Yl),wMe=n(Yl,"P",{});var T8t=s(wMe);iBr=r(T8t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),T8t.forEach(t),dBr=i(Yl),bn=n(Yl,"P",{});var mA=s(bn);cBr=r(mA,"The model class to instantiate is selected based on the "),AMe=n(mA,"CODE",{});var M8t=s(AMe);fBr=r(M8t,"model_type"),M8t.forEach(t),mBr=r(mA,` property of the config object (either
passed as an argument or loaded from `),yMe=n(mA,"CODE",{});var E8t=s(yMe);gBr=r(E8t,"pretrained_model_name_or_path"),E8t.forEach(t),hBr=r(mA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LMe=n(mA,"CODE",{});var C8t=s(LMe);pBr=r(C8t,"pretrained_model_name_or_path"),C8t.forEach(t),_Br=r(mA,":"),mA.forEach(t),uBr=i(Yl),Pe=n(Yl,"UL",{});var ze=s(Pe);Q5=n(ze,"LI",{});var FNe=s(Q5);xMe=n(FNe,"STRONG",{});var w8t=s(xMe);bBr=r(w8t,"bart"),w8t.forEach(t),vBr=r(FNe," \u2014 "),iK=n(FNe,"A",{href:!0});var A8t=s(iK);FBr=r(A8t,"FlaxBartForConditionalGeneration"),A8t.forEach(t),TBr=r(FNe," (BART model)"),FNe.forEach(t),MBr=i(ze),H5=n(ze,"LI",{});var TNe=s(H5);$Me=n(TNe,"STRONG",{});var y8t=s($Me);EBr=r(y8t,"blenderbot"),y8t.forEach(t),CBr=r(TNe," \u2014 "),dK=n(TNe,"A",{href:!0});var L8t=s(dK);wBr=r(L8t,"FlaxBlenderbotForConditionalGeneration"),L8t.forEach(t),ABr=r(TNe," (Blenderbot model)"),TNe.forEach(t),yBr=i(ze),U5=n(ze,"LI",{});var MNe=s(U5);kMe=n(MNe,"STRONG",{});var x8t=s(kMe);LBr=r(x8t,"blenderbot-small"),x8t.forEach(t),xBr=r(MNe," \u2014 "),cK=n(MNe,"A",{href:!0});var $8t=s(cK);$Br=r($8t,"FlaxBlenderbotSmallForConditionalGeneration"),$8t.forEach(t),kBr=r(MNe," (BlenderbotSmall model)"),MNe.forEach(t),SBr=i(ze),J5=n(ze,"LI",{});var ENe=s(J5);SMe=n(ENe,"STRONG",{});var k8t=s(SMe);RBr=r(k8t,"encoder-decoder"),k8t.forEach(t),PBr=r(ENe," \u2014 "),fK=n(ENe,"A",{href:!0});var S8t=s(fK);BBr=r(S8t,"FlaxEncoderDecoderModel"),S8t.forEach(t),IBr=r(ENe," (Encoder decoder model)"),ENe.forEach(t),NBr=i(ze),Y5=n(ze,"LI",{});var CNe=s(Y5);RMe=n(CNe,"STRONG",{});var R8t=s(RMe);qBr=r(R8t,"marian"),R8t.forEach(t),jBr=r(CNe," \u2014 "),mK=n(CNe,"A",{href:!0});var P8t=s(mK);DBr=r(P8t,"FlaxMarianMTModel"),P8t.forEach(t),GBr=r(CNe," (Marian model)"),CNe.forEach(t),OBr=i(ze),K5=n(ze,"LI",{});var wNe=s(K5);PMe=n(wNe,"STRONG",{});var B8t=s(PMe);VBr=r(B8t,"mbart"),B8t.forEach(t),XBr=r(wNe," \u2014 "),gK=n(wNe,"A",{href:!0});var I8t=s(gK);zBr=r(I8t,"FlaxMBartForConditionalGeneration"),I8t.forEach(t),WBr=r(wNe," (mBART model)"),wNe.forEach(t),QBr=i(ze),Z5=n(ze,"LI",{});var ANe=s(Z5);BMe=n(ANe,"STRONG",{});var N8t=s(BMe);HBr=r(N8t,"mt5"),N8t.forEach(t),UBr=r(ANe," \u2014 "),hK=n(ANe,"A",{href:!0});var q8t=s(hK);JBr=r(q8t,"FlaxMT5ForConditionalGeneration"),q8t.forEach(t),YBr=r(ANe," (mT5 model)"),ANe.forEach(t),KBr=i(ze),ew=n(ze,"LI",{});var yNe=s(ew);IMe=n(yNe,"STRONG",{});var j8t=s(IMe);ZBr=r(j8t,"pegasus"),j8t.forEach(t),eIr=r(yNe," \u2014 "),pK=n(yNe,"A",{href:!0});var D8t=s(pK);oIr=r(D8t,"FlaxPegasusForConditionalGeneration"),D8t.forEach(t),rIr=r(yNe," (Pegasus model)"),yNe.forEach(t),tIr=i(ze),ow=n(ze,"LI",{});var LNe=s(ow);NMe=n(LNe,"STRONG",{});var G8t=s(NMe);aIr=r(G8t,"t5"),G8t.forEach(t),nIr=r(LNe," \u2014 "),_K=n(LNe,"A",{href:!0});var O8t=s(_K);sIr=r(O8t,"FlaxT5ForConditionalGeneration"),O8t.forEach(t),lIr=r(LNe," (T5 model)"),LNe.forEach(t),ze.forEach(t),iIr=i(Yl),T(rw.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),aDe=i(f),zc=n(f,"H2",{class:!0});var fOe=s(zc);tw=n(fOe,"A",{id:!0,class:!0,href:!0});var V8t=s(tw);qMe=n(V8t,"SPAN",{});var X8t=s(qMe);T(ex.$$.fragment,X8t),X8t.forEach(t),V8t.forEach(t),dIr=i(fOe),jMe=n(fOe,"SPAN",{});var z8t=s(jMe);cIr=r(z8t,"FlaxAutoModelForSequenceClassification"),z8t.forEach(t),fOe.forEach(t),nDe=i(f),_r=n(f,"DIV",{class:!0});var Kl=s(_r);T(ox.$$.fragment,Kl),fIr=i(Kl),Wc=n(Kl,"P",{});var roe=s(Wc);mIr=r(roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uK=n(roe,"A",{href:!0});var W8t=s(uK);gIr=r(W8t,"from_pretrained()"),W8t.forEach(t),hIr=r(roe," class method or the "),bK=n(roe,"A",{href:!0});var Q8t=s(bK);pIr=r(Q8t,"from_config()"),Q8t.forEach(t),_Ir=r(roe,` class
method.`),roe.forEach(t),uIr=i(Kl),rx=n(Kl,"P",{});var mOe=s(rx);bIr=r(mOe,"This class cannot be instantiated directly using "),DMe=n(mOe,"CODE",{});var H8t=s(DMe);vIr=r(H8t,"__init__()"),H8t.forEach(t),FIr=r(mOe," (throws an error)."),mOe.forEach(t),TIr=i(Kl),Wt=n(Kl,"DIV",{class:!0});var gA=s(Wt);T(tx.$$.fragment,gA),MIr=i(gA),GMe=n(gA,"P",{});var U8t=s(GMe);EIr=r(U8t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),U8t.forEach(t),CIr=i(gA),Qc=n(gA,"P",{});var toe=s(Qc);wIr=r(toe,`Note:
Loading a model from its configuration file does `),OMe=n(toe,"STRONG",{});var J8t=s(OMe);AIr=r(J8t,"not"),J8t.forEach(t),yIr=r(toe,` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=n(toe,"A",{href:!0});var Y8t=s(vK);LIr=r(Y8t,"from_pretrained()"),Y8t.forEach(t),xIr=r(toe," to load the model weights."),toe.forEach(t),$Ir=i(gA),T(aw.$$.fragment,gA),gA.forEach(t),kIr=i(Kl),Xr=n(Kl,"DIV",{class:!0});var Zl=s(Xr);T(ax.$$.fragment,Zl),SIr=i(Zl),VMe=n(Zl,"P",{});var K8t=s(VMe);RIr=r(K8t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),K8t.forEach(t),PIr=i(Zl),vn=n(Zl,"P",{});var hA=s(vn);BIr=r(hA,"The model class to instantiate is selected based on the "),XMe=n(hA,"CODE",{});var Z8t=s(XMe);IIr=r(Z8t,"model_type"),Z8t.forEach(t),NIr=r(hA,` property of the config object (either
passed as an argument or loaded from `),zMe=n(hA,"CODE",{});var e9t=s(zMe);qIr=r(e9t,"pretrained_model_name_or_path"),e9t.forEach(t),jIr=r(hA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WMe=n(hA,"CODE",{});var o9t=s(WMe);DIr=r(o9t,"pretrained_model_name_or_path"),o9t.forEach(t),GIr=r(hA,":"),hA.forEach(t),OIr=i(Zl),xe=n(Zl,"UL",{});var Ne=s(xe);nw=n(Ne,"LI",{});var xNe=s(nw);QMe=n(xNe,"STRONG",{});var r9t=s(QMe);VIr=r(r9t,"albert"),r9t.forEach(t),XIr=r(xNe," \u2014 "),FK=n(xNe,"A",{href:!0});var t9t=s(FK);zIr=r(t9t,"FlaxAlbertForSequenceClassification"),t9t.forEach(t),WIr=r(xNe," (ALBERT model)"),xNe.forEach(t),QIr=i(Ne),sw=n(Ne,"LI",{});var $Ne=s(sw);HMe=n($Ne,"STRONG",{});var a9t=s(HMe);HIr=r(a9t,"bart"),a9t.forEach(t),UIr=r($Ne," \u2014 "),TK=n($Ne,"A",{href:!0});var n9t=s(TK);JIr=r(n9t,"FlaxBartForSequenceClassification"),n9t.forEach(t),YIr=r($Ne," (BART model)"),$Ne.forEach(t),KIr=i(Ne),lw=n(Ne,"LI",{});var kNe=s(lw);UMe=n(kNe,"STRONG",{});var s9t=s(UMe);ZIr=r(s9t,"bert"),s9t.forEach(t),eNr=r(kNe," \u2014 "),MK=n(kNe,"A",{href:!0});var l9t=s(MK);oNr=r(l9t,"FlaxBertForSequenceClassification"),l9t.forEach(t),rNr=r(kNe," (BERT model)"),kNe.forEach(t),tNr=i(Ne),iw=n(Ne,"LI",{});var SNe=s(iw);JMe=n(SNe,"STRONG",{});var i9t=s(JMe);aNr=r(i9t,"big_bird"),i9t.forEach(t),nNr=r(SNe," \u2014 "),EK=n(SNe,"A",{href:!0});var d9t=s(EK);sNr=r(d9t,"FlaxBigBirdForSequenceClassification"),d9t.forEach(t),lNr=r(SNe," (BigBird model)"),SNe.forEach(t),iNr=i(Ne),dw=n(Ne,"LI",{});var RNe=s(dw);YMe=n(RNe,"STRONG",{});var c9t=s(YMe);dNr=r(c9t,"distilbert"),c9t.forEach(t),cNr=r(RNe," \u2014 "),CK=n(RNe,"A",{href:!0});var f9t=s(CK);fNr=r(f9t,"FlaxDistilBertForSequenceClassification"),f9t.forEach(t),mNr=r(RNe," (DistilBERT model)"),RNe.forEach(t),gNr=i(Ne),cw=n(Ne,"LI",{});var PNe=s(cw);KMe=n(PNe,"STRONG",{});var m9t=s(KMe);hNr=r(m9t,"electra"),m9t.forEach(t),pNr=r(PNe," \u2014 "),wK=n(PNe,"A",{href:!0});var g9t=s(wK);_Nr=r(g9t,"FlaxElectraForSequenceClassification"),g9t.forEach(t),uNr=r(PNe," (ELECTRA model)"),PNe.forEach(t),bNr=i(Ne),fw=n(Ne,"LI",{});var BNe=s(fw);ZMe=n(BNe,"STRONG",{});var h9t=s(ZMe);vNr=r(h9t,"mbart"),h9t.forEach(t),FNr=r(BNe," \u2014 "),AK=n(BNe,"A",{href:!0});var p9t=s(AK);TNr=r(p9t,"FlaxMBartForSequenceClassification"),p9t.forEach(t),MNr=r(BNe," (mBART model)"),BNe.forEach(t),ENr=i(Ne),mw=n(Ne,"LI",{});var INe=s(mw);eEe=n(INe,"STRONG",{});var _9t=s(eEe);CNr=r(_9t,"roberta"),_9t.forEach(t),wNr=r(INe," \u2014 "),yK=n(INe,"A",{href:!0});var u9t=s(yK);ANr=r(u9t,"FlaxRobertaForSequenceClassification"),u9t.forEach(t),yNr=r(INe," (RoBERTa model)"),INe.forEach(t),LNr=i(Ne),gw=n(Ne,"LI",{});var NNe=s(gw);oEe=n(NNe,"STRONG",{});var b9t=s(oEe);xNr=r(b9t,"roformer"),b9t.forEach(t),$Nr=r(NNe," \u2014 "),LK=n(NNe,"A",{href:!0});var v9t=s(LK);kNr=r(v9t,"FlaxRoFormerForSequenceClassification"),v9t.forEach(t),SNr=r(NNe," (RoFormer model)"),NNe.forEach(t),RNr=i(Ne),hw=n(Ne,"LI",{});var qNe=s(hw);rEe=n(qNe,"STRONG",{});var F9t=s(rEe);PNr=r(F9t,"xlm-roberta"),F9t.forEach(t),BNr=r(qNe," \u2014 "),xK=n(qNe,"A",{href:!0});var T9t=s(xK);INr=r(T9t,"FlaxXLMRobertaForSequenceClassification"),T9t.forEach(t),NNr=r(qNe," (XLM-RoBERTa model)"),qNe.forEach(t),Ne.forEach(t),qNr=i(Zl),T(pw.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),sDe=i(f),Hc=n(f,"H2",{class:!0});var gOe=s(Hc);_w=n(gOe,"A",{id:!0,class:!0,href:!0});var M9t=s(_w);tEe=n(M9t,"SPAN",{});var E9t=s(tEe);T(nx.$$.fragment,E9t),E9t.forEach(t),M9t.forEach(t),jNr=i(gOe),aEe=n(gOe,"SPAN",{});var C9t=s(aEe);DNr=r(C9t,"FlaxAutoModelForQuestionAnswering"),C9t.forEach(t),gOe.forEach(t),lDe=i(f),ur=n(f,"DIV",{class:!0});var ei=s(ur);T(sx.$$.fragment,ei),GNr=i(ei),Uc=n(ei,"P",{});var aoe=s(Uc);ONr=r(aoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$K=n(aoe,"A",{href:!0});var w9t=s($K);VNr=r(w9t,"from_pretrained()"),w9t.forEach(t),XNr=r(aoe," class method or the "),kK=n(aoe,"A",{href:!0});var A9t=s(kK);zNr=r(A9t,"from_config()"),A9t.forEach(t),WNr=r(aoe,` class
method.`),aoe.forEach(t),QNr=i(ei),lx=n(ei,"P",{});var hOe=s(lx);HNr=r(hOe,"This class cannot be instantiated directly using "),nEe=n(hOe,"CODE",{});var y9t=s(nEe);UNr=r(y9t,"__init__()"),y9t.forEach(t),JNr=r(hOe," (throws an error)."),hOe.forEach(t),YNr=i(ei),Qt=n(ei,"DIV",{class:!0});var pA=s(Qt);T(ix.$$.fragment,pA),KNr=i(pA),sEe=n(pA,"P",{});var L9t=s(sEe);ZNr=r(L9t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),L9t.forEach(t),eqr=i(pA),Jc=n(pA,"P",{});var noe=s(Jc);oqr=r(noe,`Note:
Loading a model from its configuration file does `),lEe=n(noe,"STRONG",{});var x9t=s(lEe);rqr=r(x9t,"not"),x9t.forEach(t),tqr=r(noe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(noe,"A",{href:!0});var $9t=s(SK);aqr=r($9t,"from_pretrained()"),$9t.forEach(t),nqr=r(noe," to load the model weights."),noe.forEach(t),sqr=i(pA),T(uw.$$.fragment,pA),pA.forEach(t),lqr=i(ei),zr=n(ei,"DIV",{class:!0});var oi=s(zr);T(dx.$$.fragment,oi),iqr=i(oi),iEe=n(oi,"P",{});var k9t=s(iEe);dqr=r(k9t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),k9t.forEach(t),cqr=i(oi),Fn=n(oi,"P",{});var _A=s(Fn);fqr=r(_A,"The model class to instantiate is selected based on the "),dEe=n(_A,"CODE",{});var S9t=s(dEe);mqr=r(S9t,"model_type"),S9t.forEach(t),gqr=r(_A,` property of the config object (either
passed as an argument or loaded from `),cEe=n(_A,"CODE",{});var R9t=s(cEe);hqr=r(R9t,"pretrained_model_name_or_path"),R9t.forEach(t),pqr=r(_A,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=n(_A,"CODE",{});var P9t=s(fEe);_qr=r(P9t,"pretrained_model_name_or_path"),P9t.forEach(t),uqr=r(_A,":"),_A.forEach(t),bqr=i(oi),$e=n(oi,"UL",{});var qe=s($e);bw=n(qe,"LI",{});var jNe=s(bw);mEe=n(jNe,"STRONG",{});var B9t=s(mEe);vqr=r(B9t,"albert"),B9t.forEach(t),Fqr=r(jNe," \u2014 "),RK=n(jNe,"A",{href:!0});var I9t=s(RK);Tqr=r(I9t,"FlaxAlbertForQuestionAnswering"),I9t.forEach(t),Mqr=r(jNe," (ALBERT model)"),jNe.forEach(t),Eqr=i(qe),vw=n(qe,"LI",{});var DNe=s(vw);gEe=n(DNe,"STRONG",{});var N9t=s(gEe);Cqr=r(N9t,"bart"),N9t.forEach(t),wqr=r(DNe," \u2014 "),PK=n(DNe,"A",{href:!0});var q9t=s(PK);Aqr=r(q9t,"FlaxBartForQuestionAnswering"),q9t.forEach(t),yqr=r(DNe," (BART model)"),DNe.forEach(t),Lqr=i(qe),Fw=n(qe,"LI",{});var GNe=s(Fw);hEe=n(GNe,"STRONG",{});var j9t=s(hEe);xqr=r(j9t,"bert"),j9t.forEach(t),$qr=r(GNe," \u2014 "),BK=n(GNe,"A",{href:!0});var D9t=s(BK);kqr=r(D9t,"FlaxBertForQuestionAnswering"),D9t.forEach(t),Sqr=r(GNe," (BERT model)"),GNe.forEach(t),Rqr=i(qe),Tw=n(qe,"LI",{});var ONe=s(Tw);pEe=n(ONe,"STRONG",{});var G9t=s(pEe);Pqr=r(G9t,"big_bird"),G9t.forEach(t),Bqr=r(ONe," \u2014 "),IK=n(ONe,"A",{href:!0});var O9t=s(IK);Iqr=r(O9t,"FlaxBigBirdForQuestionAnswering"),O9t.forEach(t),Nqr=r(ONe," (BigBird model)"),ONe.forEach(t),qqr=i(qe),Mw=n(qe,"LI",{});var VNe=s(Mw);_Ee=n(VNe,"STRONG",{});var V9t=s(_Ee);jqr=r(V9t,"distilbert"),V9t.forEach(t),Dqr=r(VNe," \u2014 "),NK=n(VNe,"A",{href:!0});var X9t=s(NK);Gqr=r(X9t,"FlaxDistilBertForQuestionAnswering"),X9t.forEach(t),Oqr=r(VNe," (DistilBERT model)"),VNe.forEach(t),Vqr=i(qe),Ew=n(qe,"LI",{});var XNe=s(Ew);uEe=n(XNe,"STRONG",{});var z9t=s(uEe);Xqr=r(z9t,"electra"),z9t.forEach(t),zqr=r(XNe," \u2014 "),qK=n(XNe,"A",{href:!0});var W9t=s(qK);Wqr=r(W9t,"FlaxElectraForQuestionAnswering"),W9t.forEach(t),Qqr=r(XNe," (ELECTRA model)"),XNe.forEach(t),Hqr=i(qe),Cw=n(qe,"LI",{});var zNe=s(Cw);bEe=n(zNe,"STRONG",{});var Q9t=s(bEe);Uqr=r(Q9t,"mbart"),Q9t.forEach(t),Jqr=r(zNe," \u2014 "),jK=n(zNe,"A",{href:!0});var H9t=s(jK);Yqr=r(H9t,"FlaxMBartForQuestionAnswering"),H9t.forEach(t),Kqr=r(zNe," (mBART model)"),zNe.forEach(t),Zqr=i(qe),ww=n(qe,"LI",{});var WNe=s(ww);vEe=n(WNe,"STRONG",{});var U9t=s(vEe);ejr=r(U9t,"roberta"),U9t.forEach(t),ojr=r(WNe," \u2014 "),DK=n(WNe,"A",{href:!0});var J9t=s(DK);rjr=r(J9t,"FlaxRobertaForQuestionAnswering"),J9t.forEach(t),tjr=r(WNe," (RoBERTa model)"),WNe.forEach(t),ajr=i(qe),Aw=n(qe,"LI",{});var QNe=s(Aw);FEe=n(QNe,"STRONG",{});var Y9t=s(FEe);njr=r(Y9t,"roformer"),Y9t.forEach(t),sjr=r(QNe," \u2014 "),GK=n(QNe,"A",{href:!0});var K9t=s(GK);ljr=r(K9t,"FlaxRoFormerForQuestionAnswering"),K9t.forEach(t),ijr=r(QNe," (RoFormer model)"),QNe.forEach(t),djr=i(qe),yw=n(qe,"LI",{});var HNe=s(yw);TEe=n(HNe,"STRONG",{});var Z9t=s(TEe);cjr=r(Z9t,"xlm-roberta"),Z9t.forEach(t),fjr=r(HNe," \u2014 "),OK=n(HNe,"A",{href:!0});var ext=s(OK);mjr=r(ext,"FlaxXLMRobertaForQuestionAnswering"),ext.forEach(t),gjr=r(HNe," (XLM-RoBERTa model)"),HNe.forEach(t),qe.forEach(t),hjr=i(oi),T(Lw.$$.fragment,oi),oi.forEach(t),ei.forEach(t),iDe=i(f),Yc=n(f,"H2",{class:!0});var pOe=s(Yc);xw=n(pOe,"A",{id:!0,class:!0,href:!0});var oxt=s(xw);MEe=n(oxt,"SPAN",{});var rxt=s(MEe);T(cx.$$.fragment,rxt),rxt.forEach(t),oxt.forEach(t),pjr=i(pOe),EEe=n(pOe,"SPAN",{});var txt=s(EEe);_jr=r(txt,"FlaxAutoModelForTokenClassification"),txt.forEach(t),pOe.forEach(t),dDe=i(f),br=n(f,"DIV",{class:!0});var ri=s(br);T(fx.$$.fragment,ri),ujr=i(ri),Kc=n(ri,"P",{});var soe=s(Kc);bjr=r(soe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),VK=n(soe,"A",{href:!0});var axt=s(VK);vjr=r(axt,"from_pretrained()"),axt.forEach(t),Fjr=r(soe," class method or the "),XK=n(soe,"A",{href:!0});var nxt=s(XK);Tjr=r(nxt,"from_config()"),nxt.forEach(t),Mjr=r(soe,` class
method.`),soe.forEach(t),Ejr=i(ri),mx=n(ri,"P",{});var _Oe=s(mx);Cjr=r(_Oe,"This class cannot be instantiated directly using "),CEe=n(_Oe,"CODE",{});var sxt=s(CEe);wjr=r(sxt,"__init__()"),sxt.forEach(t),Ajr=r(_Oe," (throws an error)."),_Oe.forEach(t),yjr=i(ri),Ht=n(ri,"DIV",{class:!0});var uA=s(Ht);T(gx.$$.fragment,uA),Ljr=i(uA),wEe=n(uA,"P",{});var lxt=s(wEe);xjr=r(lxt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),lxt.forEach(t),$jr=i(uA),Zc=n(uA,"P",{});var loe=s(Zc);kjr=r(loe,`Note:
Loading a model from its configuration file does `),AEe=n(loe,"STRONG",{});var ixt=s(AEe);Sjr=r(ixt,"not"),ixt.forEach(t),Rjr=r(loe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zK=n(loe,"A",{href:!0});var dxt=s(zK);Pjr=r(dxt,"from_pretrained()"),dxt.forEach(t),Bjr=r(loe," to load the model weights."),loe.forEach(t),Ijr=i(uA),T($w.$$.fragment,uA),uA.forEach(t),Njr=i(ri),Wr=n(ri,"DIV",{class:!0});var ti=s(Wr);T(hx.$$.fragment,ti),qjr=i(ti),yEe=n(ti,"P",{});var cxt=s(yEe);jjr=r(cxt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),cxt.forEach(t),Djr=i(ti),Tn=n(ti,"P",{});var bA=s(Tn);Gjr=r(bA,"The model class to instantiate is selected based on the "),LEe=n(bA,"CODE",{});var fxt=s(LEe);Ojr=r(fxt,"model_type"),fxt.forEach(t),Vjr=r(bA,` property of the config object (either
passed as an argument or loaded from `),xEe=n(bA,"CODE",{});var mxt=s(xEe);Xjr=r(mxt,"pretrained_model_name_or_path"),mxt.forEach(t),zjr=r(bA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ee=n(bA,"CODE",{});var gxt=s($Ee);Wjr=r(gxt,"pretrained_model_name_or_path"),gxt.forEach(t),Qjr=r(bA,":"),bA.forEach(t),Hjr=i(ti),De=n(ti,"UL",{});var Fo=s(De);kw=n(Fo,"LI",{});var UNe=s(kw);kEe=n(UNe,"STRONG",{});var hxt=s(kEe);Ujr=r(hxt,"albert"),hxt.forEach(t),Jjr=r(UNe," \u2014 "),WK=n(UNe,"A",{href:!0});var pxt=s(WK);Yjr=r(pxt,"FlaxAlbertForTokenClassification"),pxt.forEach(t),Kjr=r(UNe," (ALBERT model)"),UNe.forEach(t),Zjr=i(Fo),Sw=n(Fo,"LI",{});var JNe=s(Sw);SEe=n(JNe,"STRONG",{});var _xt=s(SEe);eDr=r(_xt,"bert"),_xt.forEach(t),oDr=r(JNe," \u2014 "),QK=n(JNe,"A",{href:!0});var uxt=s(QK);rDr=r(uxt,"FlaxBertForTokenClassification"),uxt.forEach(t),tDr=r(JNe," (BERT model)"),JNe.forEach(t),aDr=i(Fo),Rw=n(Fo,"LI",{});var YNe=s(Rw);REe=n(YNe,"STRONG",{});var bxt=s(REe);nDr=r(bxt,"big_bird"),bxt.forEach(t),sDr=r(YNe," \u2014 "),HK=n(YNe,"A",{href:!0});var vxt=s(HK);lDr=r(vxt,"FlaxBigBirdForTokenClassification"),vxt.forEach(t),iDr=r(YNe," (BigBird model)"),YNe.forEach(t),dDr=i(Fo),Pw=n(Fo,"LI",{});var KNe=s(Pw);PEe=n(KNe,"STRONG",{});var Fxt=s(PEe);cDr=r(Fxt,"distilbert"),Fxt.forEach(t),fDr=r(KNe," \u2014 "),UK=n(KNe,"A",{href:!0});var Txt=s(UK);mDr=r(Txt,"FlaxDistilBertForTokenClassification"),Txt.forEach(t),gDr=r(KNe," (DistilBERT model)"),KNe.forEach(t),hDr=i(Fo),Bw=n(Fo,"LI",{});var ZNe=s(Bw);BEe=n(ZNe,"STRONG",{});var Mxt=s(BEe);pDr=r(Mxt,"electra"),Mxt.forEach(t),_Dr=r(ZNe," \u2014 "),JK=n(ZNe,"A",{href:!0});var Ext=s(JK);uDr=r(Ext,"FlaxElectraForTokenClassification"),Ext.forEach(t),bDr=r(ZNe," (ELECTRA model)"),ZNe.forEach(t),vDr=i(Fo),Iw=n(Fo,"LI",{});var eqe=s(Iw);IEe=n(eqe,"STRONG",{});var Cxt=s(IEe);FDr=r(Cxt,"roberta"),Cxt.forEach(t),TDr=r(eqe," \u2014 "),YK=n(eqe,"A",{href:!0});var wxt=s(YK);MDr=r(wxt,"FlaxRobertaForTokenClassification"),wxt.forEach(t),EDr=r(eqe," (RoBERTa model)"),eqe.forEach(t),CDr=i(Fo),Nw=n(Fo,"LI",{});var oqe=s(Nw);NEe=n(oqe,"STRONG",{});var Axt=s(NEe);wDr=r(Axt,"roformer"),Axt.forEach(t),ADr=r(oqe," \u2014 "),KK=n(oqe,"A",{href:!0});var yxt=s(KK);yDr=r(yxt,"FlaxRoFormerForTokenClassification"),yxt.forEach(t),LDr=r(oqe," (RoFormer model)"),oqe.forEach(t),xDr=i(Fo),qw=n(Fo,"LI",{});var rqe=s(qw);qEe=n(rqe,"STRONG",{});var Lxt=s(qEe);$Dr=r(Lxt,"xlm-roberta"),Lxt.forEach(t),kDr=r(rqe," \u2014 "),ZK=n(rqe,"A",{href:!0});var xxt=s(ZK);SDr=r(xxt,"FlaxXLMRobertaForTokenClassification"),xxt.forEach(t),RDr=r(rqe," (XLM-RoBERTa model)"),rqe.forEach(t),Fo.forEach(t),PDr=i(ti),T(jw.$$.fragment,ti),ti.forEach(t),ri.forEach(t),cDe=i(f),ef=n(f,"H2",{class:!0});var uOe=s(ef);Dw=n(uOe,"A",{id:!0,class:!0,href:!0});var $xt=s(Dw);jEe=n($xt,"SPAN",{});var kxt=s(jEe);T(px.$$.fragment,kxt),kxt.forEach(t),$xt.forEach(t),BDr=i(uOe),DEe=n(uOe,"SPAN",{});var Sxt=s(DEe);IDr=r(Sxt,"FlaxAutoModelForMultipleChoice"),Sxt.forEach(t),uOe.forEach(t),fDe=i(f),vr=n(f,"DIV",{class:!0});var ai=s(vr);T(_x.$$.fragment,ai),NDr=i(ai),of=n(ai,"P",{});var ioe=s(of);qDr=r(ioe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),eZ=n(ioe,"A",{href:!0});var Rxt=s(eZ);jDr=r(Rxt,"from_pretrained()"),Rxt.forEach(t),DDr=r(ioe," class method or the "),oZ=n(ioe,"A",{href:!0});var Pxt=s(oZ);GDr=r(Pxt,"from_config()"),Pxt.forEach(t),ODr=r(ioe,` class
method.`),ioe.forEach(t),VDr=i(ai),ux=n(ai,"P",{});var bOe=s(ux);XDr=r(bOe,"This class cannot be instantiated directly using "),GEe=n(bOe,"CODE",{});var Bxt=s(GEe);zDr=r(Bxt,"__init__()"),Bxt.forEach(t),WDr=r(bOe," (throws an error)."),bOe.forEach(t),QDr=i(ai),Ut=n(ai,"DIV",{class:!0});var vA=s(Ut);T(bx.$$.fragment,vA),HDr=i(vA),OEe=n(vA,"P",{});var Ixt=s(OEe);UDr=r(Ixt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ixt.forEach(t),JDr=i(vA),rf=n(vA,"P",{});var doe=s(rf);YDr=r(doe,`Note:
Loading a model from its configuration file does `),VEe=n(doe,"STRONG",{});var Nxt=s(VEe);KDr=r(Nxt,"not"),Nxt.forEach(t),ZDr=r(doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),rZ=n(doe,"A",{href:!0});var qxt=s(rZ);eGr=r(qxt,"from_pretrained()"),qxt.forEach(t),oGr=r(doe," to load the model weights."),doe.forEach(t),rGr=i(vA),T(Gw.$$.fragment,vA),vA.forEach(t),tGr=i(ai),Qr=n(ai,"DIV",{class:!0});var ni=s(Qr);T(vx.$$.fragment,ni),aGr=i(ni),XEe=n(ni,"P",{});var jxt=s(XEe);nGr=r(jxt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),jxt.forEach(t),sGr=i(ni),Mn=n(ni,"P",{});var FA=s(Mn);lGr=r(FA,"The model class to instantiate is selected based on the "),zEe=n(FA,"CODE",{});var Dxt=s(zEe);iGr=r(Dxt,"model_type"),Dxt.forEach(t),dGr=r(FA,` property of the config object (either
passed as an argument or loaded from `),WEe=n(FA,"CODE",{});var Gxt=s(WEe);cGr=r(Gxt,"pretrained_model_name_or_path"),Gxt.forEach(t),fGr=r(FA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=n(FA,"CODE",{});var Oxt=s(QEe);mGr=r(Oxt,"pretrained_model_name_or_path"),Oxt.forEach(t),gGr=r(FA,":"),FA.forEach(t),hGr=i(ni),Ge=n(ni,"UL",{});var To=s(Ge);Ow=n(To,"LI",{});var tqe=s(Ow);HEe=n(tqe,"STRONG",{});var Vxt=s(HEe);pGr=r(Vxt,"albert"),Vxt.forEach(t),_Gr=r(tqe," \u2014 "),tZ=n(tqe,"A",{href:!0});var Xxt=s(tZ);uGr=r(Xxt,"FlaxAlbertForMultipleChoice"),Xxt.forEach(t),bGr=r(tqe," (ALBERT model)"),tqe.forEach(t),vGr=i(To),Vw=n(To,"LI",{});var aqe=s(Vw);UEe=n(aqe,"STRONG",{});var zxt=s(UEe);FGr=r(zxt,"bert"),zxt.forEach(t),TGr=r(aqe," \u2014 "),aZ=n(aqe,"A",{href:!0});var Wxt=s(aZ);MGr=r(Wxt,"FlaxBertForMultipleChoice"),Wxt.forEach(t),EGr=r(aqe," (BERT model)"),aqe.forEach(t),CGr=i(To),Xw=n(To,"LI",{});var nqe=s(Xw);JEe=n(nqe,"STRONG",{});var Qxt=s(JEe);wGr=r(Qxt,"big_bird"),Qxt.forEach(t),AGr=r(nqe," \u2014 "),nZ=n(nqe,"A",{href:!0});var Hxt=s(nZ);yGr=r(Hxt,"FlaxBigBirdForMultipleChoice"),Hxt.forEach(t),LGr=r(nqe," (BigBird model)"),nqe.forEach(t),xGr=i(To),zw=n(To,"LI",{});var sqe=s(zw);YEe=n(sqe,"STRONG",{});var Uxt=s(YEe);$Gr=r(Uxt,"distilbert"),Uxt.forEach(t),kGr=r(sqe," \u2014 "),sZ=n(sqe,"A",{href:!0});var Jxt=s(sZ);SGr=r(Jxt,"FlaxDistilBertForMultipleChoice"),Jxt.forEach(t),RGr=r(sqe," (DistilBERT model)"),sqe.forEach(t),PGr=i(To),Ww=n(To,"LI",{});var lqe=s(Ww);KEe=n(lqe,"STRONG",{});var Yxt=s(KEe);BGr=r(Yxt,"electra"),Yxt.forEach(t),IGr=r(lqe," \u2014 "),lZ=n(lqe,"A",{href:!0});var Kxt=s(lZ);NGr=r(Kxt,"FlaxElectraForMultipleChoice"),Kxt.forEach(t),qGr=r(lqe," (ELECTRA model)"),lqe.forEach(t),jGr=i(To),Qw=n(To,"LI",{});var iqe=s(Qw);ZEe=n(iqe,"STRONG",{});var Zxt=s(ZEe);DGr=r(Zxt,"roberta"),Zxt.forEach(t),GGr=r(iqe," \u2014 "),iZ=n(iqe,"A",{href:!0});var e$t=s(iZ);OGr=r(e$t,"FlaxRobertaForMultipleChoice"),e$t.forEach(t),VGr=r(iqe," (RoBERTa model)"),iqe.forEach(t),XGr=i(To),Hw=n(To,"LI",{});var dqe=s(Hw);eCe=n(dqe,"STRONG",{});var o$t=s(eCe);zGr=r(o$t,"roformer"),o$t.forEach(t),WGr=r(dqe," \u2014 "),dZ=n(dqe,"A",{href:!0});var r$t=s(dZ);QGr=r(r$t,"FlaxRoFormerForMultipleChoice"),r$t.forEach(t),HGr=r(dqe," (RoFormer model)"),dqe.forEach(t),UGr=i(To),Uw=n(To,"LI",{});var cqe=s(Uw);oCe=n(cqe,"STRONG",{});var t$t=s(oCe);JGr=r(t$t,"xlm-roberta"),t$t.forEach(t),YGr=r(cqe," \u2014 "),cZ=n(cqe,"A",{href:!0});var a$t=s(cZ);KGr=r(a$t,"FlaxXLMRobertaForMultipleChoice"),a$t.forEach(t),ZGr=r(cqe," (XLM-RoBERTa model)"),cqe.forEach(t),To.forEach(t),eOr=i(ni),T(Jw.$$.fragment,ni),ni.forEach(t),ai.forEach(t),mDe=i(f),tf=n(f,"H2",{class:!0});var vOe=s(tf);Yw=n(vOe,"A",{id:!0,class:!0,href:!0});var n$t=s(Yw);rCe=n(n$t,"SPAN",{});var s$t=s(rCe);T(Fx.$$.fragment,s$t),s$t.forEach(t),n$t.forEach(t),oOr=i(vOe),tCe=n(vOe,"SPAN",{});var l$t=s(tCe);rOr=r(l$t,"FlaxAutoModelForNextSentencePrediction"),l$t.forEach(t),vOe.forEach(t),gDe=i(f),Fr=n(f,"DIV",{class:!0});var si=s(Fr);T(Tx.$$.fragment,si),tOr=i(si),af=n(si,"P",{});var coe=s(af);aOr=r(coe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fZ=n(coe,"A",{href:!0});var i$t=s(fZ);nOr=r(i$t,"from_pretrained()"),i$t.forEach(t),sOr=r(coe," class method or the "),mZ=n(coe,"A",{href:!0});var d$t=s(mZ);lOr=r(d$t,"from_config()"),d$t.forEach(t),iOr=r(coe,` class
method.`),coe.forEach(t),dOr=i(si),Mx=n(si,"P",{});var FOe=s(Mx);cOr=r(FOe,"This class cannot be instantiated directly using "),aCe=n(FOe,"CODE",{});var c$t=s(aCe);fOr=r(c$t,"__init__()"),c$t.forEach(t),mOr=r(FOe," (throws an error)."),FOe.forEach(t),gOr=i(si),Jt=n(si,"DIV",{class:!0});var TA=s(Jt);T(Ex.$$.fragment,TA),hOr=i(TA),nCe=n(TA,"P",{});var f$t=s(nCe);pOr=r(f$t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),f$t.forEach(t),_Or=i(TA),nf=n(TA,"P",{});var foe=s(nf);uOr=r(foe,`Note:
Loading a model from its configuration file does `),sCe=n(foe,"STRONG",{});var m$t=s(sCe);bOr=r(m$t,"not"),m$t.forEach(t),vOr=r(foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=n(foe,"A",{href:!0});var g$t=s(gZ);FOr=r(g$t,"from_pretrained()"),g$t.forEach(t),TOr=r(foe," to load the model weights."),foe.forEach(t),MOr=i(TA),T(Kw.$$.fragment,TA),TA.forEach(t),EOr=i(si),Hr=n(si,"DIV",{class:!0});var li=s(Hr);T(Cx.$$.fragment,li),COr=i(li),lCe=n(li,"P",{});var h$t=s(lCe);wOr=r(h$t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),h$t.forEach(t),AOr=i(li),En=n(li,"P",{});var MA=s(En);yOr=r(MA,"The model class to instantiate is selected based on the "),iCe=n(MA,"CODE",{});var p$t=s(iCe);LOr=r(p$t,"model_type"),p$t.forEach(t),xOr=r(MA,` property of the config object (either
passed as an argument or loaded from `),dCe=n(MA,"CODE",{});var _$t=s(dCe);$Or=r(_$t,"pretrained_model_name_or_path"),_$t.forEach(t),kOr=r(MA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=n(MA,"CODE",{});var u$t=s(cCe);SOr=r(u$t,"pretrained_model_name_or_path"),u$t.forEach(t),ROr=r(MA,":"),MA.forEach(t),POr=i(li),fCe=n(li,"UL",{});var b$t=s(fCe);Zw=n(b$t,"LI",{});var fqe=s(Zw);mCe=n(fqe,"STRONG",{});var v$t=s(mCe);BOr=r(v$t,"bert"),v$t.forEach(t),IOr=r(fqe," \u2014 "),hZ=n(fqe,"A",{href:!0});var F$t=s(hZ);NOr=r(F$t,"FlaxBertForNextSentencePrediction"),F$t.forEach(t),qOr=r(fqe," (BERT model)"),fqe.forEach(t),b$t.forEach(t),jOr=i(li),T(e0.$$.fragment,li),li.forEach(t),si.forEach(t),hDe=i(f),sf=n(f,"H2",{class:!0});var TOe=s(sf);o0=n(TOe,"A",{id:!0,class:!0,href:!0});var T$t=s(o0);gCe=n(T$t,"SPAN",{});var M$t=s(gCe);T(wx.$$.fragment,M$t),M$t.forEach(t),T$t.forEach(t),DOr=i(TOe),hCe=n(TOe,"SPAN",{});var E$t=s(hCe);GOr=r(E$t,"FlaxAutoModelForImageClassification"),E$t.forEach(t),TOe.forEach(t),pDe=i(f),Tr=n(f,"DIV",{class:!0});var ii=s(Tr);T(Ax.$$.fragment,ii),OOr=i(ii),lf=n(ii,"P",{});var moe=s(lf);VOr=r(moe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),pZ=n(moe,"A",{href:!0});var C$t=s(pZ);XOr=r(C$t,"from_pretrained()"),C$t.forEach(t),zOr=r(moe," class method or the "),_Z=n(moe,"A",{href:!0});var w$t=s(_Z);WOr=r(w$t,"from_config()"),w$t.forEach(t),QOr=r(moe,` class
method.`),moe.forEach(t),HOr=i(ii),yx=n(ii,"P",{});var MOe=s(yx);UOr=r(MOe,"This class cannot be instantiated directly using "),pCe=n(MOe,"CODE",{});var A$t=s(pCe);JOr=r(A$t,"__init__()"),A$t.forEach(t),YOr=r(MOe," (throws an error)."),MOe.forEach(t),KOr=i(ii),Yt=n(ii,"DIV",{class:!0});var EA=s(Yt);T(Lx.$$.fragment,EA),ZOr=i(EA),_Ce=n(EA,"P",{});var y$t=s(_Ce);eVr=r(y$t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),y$t.forEach(t),oVr=i(EA),df=n(EA,"P",{});var goe=s(df);rVr=r(goe,`Note:
Loading a model from its configuration file does `),uCe=n(goe,"STRONG",{});var L$t=s(uCe);tVr=r(L$t,"not"),L$t.forEach(t),aVr=r(goe,` load the model weights. It only affects the
model\u2019s configuration. Use `),uZ=n(goe,"A",{href:!0});var x$t=s(uZ);nVr=r(x$t,"from_pretrained()"),x$t.forEach(t),sVr=r(goe," to load the model weights."),goe.forEach(t),lVr=i(EA),T(r0.$$.fragment,EA),EA.forEach(t),iVr=i(ii),Ur=n(ii,"DIV",{class:!0});var di=s(Ur);T(xx.$$.fragment,di),dVr=i(di),bCe=n(di,"P",{});var $$t=s(bCe);cVr=r($$t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),$$t.forEach(t),fVr=i(di),Cn=n(di,"P",{});var CA=s(Cn);mVr=r(CA,"The model class to instantiate is selected based on the "),vCe=n(CA,"CODE",{});var k$t=s(vCe);gVr=r(k$t,"model_type"),k$t.forEach(t),hVr=r(CA,` property of the config object (either
passed as an argument or loaded from `),FCe=n(CA,"CODE",{});var S$t=s(FCe);pVr=r(S$t,"pretrained_model_name_or_path"),S$t.forEach(t),_Vr=r(CA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=n(CA,"CODE",{});var R$t=s(TCe);uVr=r(R$t,"pretrained_model_name_or_path"),R$t.forEach(t),bVr=r(CA,":"),CA.forEach(t),vVr=i(di),$x=n(di,"UL",{});var EOe=s($x);t0=n(EOe,"LI",{});var mqe=s(t0);MCe=n(mqe,"STRONG",{});var P$t=s(MCe);FVr=r(P$t,"beit"),P$t.forEach(t),TVr=r(mqe," \u2014 "),bZ=n(mqe,"A",{href:!0});var B$t=s(bZ);MVr=r(B$t,"FlaxBeitForImageClassification"),B$t.forEach(t),EVr=r(mqe," (BEiT model)"),mqe.forEach(t),CVr=i(EOe),a0=n(EOe,"LI",{});var gqe=s(a0);ECe=n(gqe,"STRONG",{});var I$t=s(ECe);wVr=r(I$t,"vit"),I$t.forEach(t),AVr=r(gqe," \u2014 "),vZ=n(gqe,"A",{href:!0});var N$t=s(vZ);yVr=r(N$t,"FlaxViTForImageClassification"),N$t.forEach(t),LVr=r(gqe," (ViT model)"),gqe.forEach(t),EOe.forEach(t),xVr=i(di),T(n0.$$.fragment,di),di.forEach(t),ii.forEach(t),_De=i(f),cf=n(f,"H2",{class:!0});var COe=s(cf);s0=n(COe,"A",{id:!0,class:!0,href:!0});var q$t=s(s0);CCe=n(q$t,"SPAN",{});var j$t=s(CCe);T(kx.$$.fragment,j$t),j$t.forEach(t),q$t.forEach(t),$Vr=i(COe),wCe=n(COe,"SPAN",{});var D$t=s(wCe);kVr=r(D$t,"FlaxAutoModelForVision2Seq"),D$t.forEach(t),COe.forEach(t),uDe=i(f),Mr=n(f,"DIV",{class:!0});var ci=s(Mr);T(Sx.$$.fragment,ci),SVr=i(ci),ff=n(ci,"P",{});var hoe=s(ff);RVr=r(hoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),FZ=n(hoe,"A",{href:!0});var G$t=s(FZ);PVr=r(G$t,"from_pretrained()"),G$t.forEach(t),BVr=r(hoe," class method or the "),TZ=n(hoe,"A",{href:!0});var O$t=s(TZ);IVr=r(O$t,"from_config()"),O$t.forEach(t),NVr=r(hoe,` class
method.`),hoe.forEach(t),qVr=i(ci),Rx=n(ci,"P",{});var wOe=s(Rx);jVr=r(wOe,"This class cannot be instantiated directly using "),ACe=n(wOe,"CODE",{});var V$t=s(ACe);DVr=r(V$t,"__init__()"),V$t.forEach(t),GVr=r(wOe," (throws an error)."),wOe.forEach(t),OVr=i(ci),Kt=n(ci,"DIV",{class:!0});var wA=s(Kt);T(Px.$$.fragment,wA),VVr=i(wA),yCe=n(wA,"P",{});var X$t=s(yCe);XVr=r(X$t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),X$t.forEach(t),zVr=i(wA),mf=n(wA,"P",{});var poe=s(mf);WVr=r(poe,`Note:
Loading a model from its configuration file does `),LCe=n(poe,"STRONG",{});var z$t=s(LCe);QVr=r(z$t,"not"),z$t.forEach(t),HVr=r(poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MZ=n(poe,"A",{href:!0});var W$t=s(MZ);UVr=r(W$t,"from_pretrained()"),W$t.forEach(t),JVr=r(poe," to load the model weights."),poe.forEach(t),YVr=i(wA),T(l0.$$.fragment,wA),wA.forEach(t),KVr=i(ci),Jr=n(ci,"DIV",{class:!0});var fi=s(Jr);T(Bx.$$.fragment,fi),ZVr=i(fi),xCe=n(fi,"P",{});var Q$t=s(xCe);eXr=r(Q$t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Q$t.forEach(t),oXr=i(fi),wn=n(fi,"P",{});var AA=s(wn);rXr=r(AA,"The model class to instantiate is selected based on the "),$Ce=n(AA,"CODE",{});var H$t=s($Ce);tXr=r(H$t,"model_type"),H$t.forEach(t),aXr=r(AA,` property of the config object (either
passed as an argument or loaded from `),kCe=n(AA,"CODE",{});var U$t=s(kCe);nXr=r(U$t,"pretrained_model_name_or_path"),U$t.forEach(t),sXr=r(AA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SCe=n(AA,"CODE",{});var J$t=s(SCe);lXr=r(J$t,"pretrained_model_name_or_path"),J$t.forEach(t),iXr=r(AA,":"),AA.forEach(t),dXr=i(fi),RCe=n(fi,"UL",{});var Y$t=s(RCe);i0=n(Y$t,"LI",{});var hqe=s(i0);PCe=n(hqe,"STRONG",{});var K$t=s(PCe);cXr=r(K$t,"vision-encoder-decoder"),K$t.forEach(t),fXr=r(hqe," \u2014 "),EZ=n(hqe,"A",{href:!0});var Z$t=s(EZ);mXr=r(Z$t,"FlaxVisionEncoderDecoderModel"),Z$t.forEach(t),gXr=r(hqe," (Vision Encoder decoder model)"),hqe.forEach(t),Y$t.forEach(t),hXr=i(fi),T(d0.$$.fragment,fi),fi.forEach(t),ci.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(tRt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(yn,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.AutoConfig"),c(xn,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.AutoModel"),c($n,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.AutoTokenizer"),c(bi,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertModel"),c(Ff,"id","extending-the-auto-classes"),c(Ff,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ff,"href","#extending-the-auto-classes"),c(vi,"class","relative group"),c(Mf,"id","transformers.AutoConfig"),c(Mf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Mf,"href","#transformers.AutoConfig"),c(Fi,"class","relative group"),c(rk,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(tk,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertConfig"),c(ak,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartConfig"),c(nk,"href","/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitConfig"),c(sk,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertConfig"),c(lk,"href","/docs/transformers/pr_17443/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(ik,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdConfig"),c(dk,"href","/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(ck,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(fk,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(mk,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertConfig"),c(gk,"href","/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineConfig"),c(hk,"href","/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPConfig"),c(pk,"href","/docs/transformers/pr_17443/en/model_doc/codegen#transformers.CodeGenConfig"),c(_k,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertConfig"),c(uk,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextConfig"),c(bk,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLConfig"),c(vk,"href","/docs/transformers/pr_17443/en/model_doc/cvt#transformers.CvtConfig"),c(Fk,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(Tk,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(Mk,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(Ek,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaConfig"),c(Ck,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(wk,"href","/docs/transformers/pr_17443/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(Ak,"href","/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTConfig"),c(yk,"href","/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrConfig"),c(Lk,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertConfig"),c(xk,"href","/docs/transformers/pr_17443/en/model_doc/dpr#transformers.DPRConfig"),c($k,"href","/docs/transformers/pr_17443/en/model_doc/dpt#transformers.DPTConfig"),c(kk,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraConfig"),c(Sk,"href","/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(Rk,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertConfig"),c(Pk,"href","/docs/transformers/pr_17443/en/model_doc/flava#transformers.FlavaConfig"),c(Bk,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetConfig"),c(Ik,"href","/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTConfig"),c(Nk,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelConfig"),c(qk,"href","/docs/transformers/pr_17443/en/model_doc/glpn#transformers.GLPNConfig"),c(jk,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Config"),c(Dk,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(Gk,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(Ok,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJConfig"),c(Vk,"href","/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertConfig"),c(Xk,"href","/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertConfig"),c(zk,"href","/docs/transformers/pr_17443/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(Wk,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(Qk,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(Hk,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(Uk,"href","/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDConfig"),c(Jk,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerConfig"),c(Yk,"href","/docs/transformers/pr_17443/en/model_doc/luke#transformers.LukeConfig"),c(Kk,"href","/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertConfig"),c(Zk,"href","/docs/transformers/pr_17443/en/model_doc/m2m_100#transformers.M2M100Config"),c(eS,"href","/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianConfig"),c(oS,"href","/docs/transformers/pr_17443/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(rS,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartConfig"),c(tS,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(aS,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(nS,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetConfig"),c(sS,"href","/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Config"),c(lS,"href","/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(iS,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(dS,"href","/docs/transformers/pr_17443/en/model_doc/opt#transformers.OPTConfig"),c(cS,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusConfig"),c(fS,"href","/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverConfig"),c(mS,"href","/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartConfig"),c(gS,"href","/docs/transformers/pr_17443/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(hS,"href","/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(pS,"href","/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(_S,"href","/docs/transformers/pr_17443/en/model_doc/rag#transformers.RagConfig"),c(uS,"href","/docs/transformers/pr_17443/en/model_doc/realm#transformers.RealmConfig"),c(bS,"href","/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerConfig"),c(vS,"href","/docs/transformers/pr_17443/en/model_doc/regnet#transformers.RegNetConfig"),c(FS,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertConfig"),c(TS,"href","/docs/transformers/pr_17443/en/model_doc/resnet#transformers.ResNetConfig"),c(MS,"href","/docs/transformers/pr_17443/en/model_doc/retribert#transformers.RetriBertConfig"),c(ES,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaConfig"),c(CS,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerConfig"),c(wS,"href","/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerConfig"),c(AS,"href","/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWConfig"),c(yS,"href","/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDConfig"),c(LS,"href","/docs/transformers/pr_17443/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(xS,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c($S,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(kS,"href","/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterConfig"),c(SS,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(RS,"href","/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinConfig"),c(PS,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Config"),c(BS,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasConfig"),c(IS,"href","/docs/transformers/pr_17443/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(NS,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(qS,"href","/docs/transformers/pr_17443/en/model_doc/trocr#transformers.TrOCRConfig"),c(jS,"href","/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(DS,"href","/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(GS,"href","/docs/transformers/pr_17443/en/model_doc/van#transformers.VanConfig"),c(OS,"href","/docs/transformers/pr_17443/en/model_doc/vilt#transformers.ViltConfig"),c(VS,"href","/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(XS,"href","/docs/transformers/pr_17443/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(zS,"href","/docs/transformers/pr_17443/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(WS,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTConfig"),c(QS,"href","/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(HS,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(US,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(JS,"href","/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMConfig"),c(YS,"href","/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMConfig"),c(KS,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMConfig"),c(ZS,"href","/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(eR,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(oR,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(rR,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetConfig"),c(tR,"href","/docs/transformers/pr_17443/en/model_doc/yolos#transformers.YolosConfig"),c(aR,"href","/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoConfig"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ag,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yg,"id","transformers.AutoTokenizer"),c(yg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yg,"href","#transformers.AutoTokenizer"),c(Mi,"class","relative group"),c(nR,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(sR,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertTokenizer"),c(lR,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(iR,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartTokenizer"),c(dR,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartTokenizerFast"),c(cR,"href","/docs/transformers/pr_17443/en/model_doc/barthez#transformers.BarthezTokenizer"),c(fR,"href","/docs/transformers/pr_17443/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(mR,"href","/docs/transformers/pr_17443/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(gR,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertTokenizer"),c(hR,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertTokenizerFast"),c(pR,"href","/docs/transformers/pr_17443/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(_R,"href","/docs/transformers/pr_17443/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(uR,"href","/docs/transformers/pr_17443/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(bR,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(vR,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(FR,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(TR,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(MR,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(ER,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(CR,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(wR,"href","/docs/transformers/pr_17443/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(AR,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertTokenizer"),c(yR,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(LR,"href","/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineTokenizer"),c(xR,"href","/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPTokenizer"),c($R,"href","/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(kR,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(SR,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(RR,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(PR,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(BR,"href","/docs/transformers/pr_17443/en/model_doc/cpm#transformers.CpmTokenizer"),c(IR,"href","/docs/transformers/pr_17443/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(NR,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(qR,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaTokenizer"),c(jR,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(DR,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaTokenizer"),c(GR,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(OR,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(VR,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(XR,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(zR,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(WR,"href","/docs/transformers/pr_17443/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(QR,"href","/docs/transformers/pr_17443/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(HR,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraTokenizer"),c(UR,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(JR,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(YR,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetTokenizer"),c(KR,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(ZR,"href","/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(eP,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelTokenizer"),c(oP,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(rP,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(tP,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(aP,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(nP,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(sP,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(lP,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(iP,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(dP,"href","/docs/transformers/pr_17443/en/model_doc/herbert#transformers.HerbertTokenizer"),c(cP,"href","/docs/transformers/pr_17443/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(fP,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(mP,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaTokenizer"),c(gP,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(hP,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(pP,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(_P,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(uP,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(bP,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(vP,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(FP,"href","/docs/transformers/pr_17443/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(TP,"href","/docs/transformers/pr_17443/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(MP,"href","/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDTokenizer"),c(EP,"href","/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDTokenizerFast"),c(CP,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerTokenizer"),c(wP,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(AP,"href","/docs/transformers/pr_17443/en/model_doc/luke#transformers.LukeTokenizer"),c(yP,"href","/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(LP,"href","/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(xP,"href","/docs/transformers/pr_17443/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c($P,"href","/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianTokenizer"),c(kP,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartTokenizer"),c(SP,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(RP,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(PP,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(BP,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertTokenizer"),c(IP,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertTokenizerFast"),c(NP,"href","/docs/transformers/pr_17443/en/model_doc/mluke#transformers.MLukeTokenizer"),c(qP,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(jP,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(DP,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(GP,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(OP,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Tokenizer"),c(VP,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5TokenizerFast"),c(XP,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertTokenizer"),c(zP,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(WP,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(QP,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(HP,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(UP,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(JP,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(YP,"href","/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(KP,"href","/docs/transformers/pr_17443/en/model_doc/phobert#transformers.PhobertTokenizer"),c(ZP,"href","/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartTokenizer"),c(eB,"href","/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(oB,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertTokenizer"),c(rB,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertTokenizerFast"),c(tB,"href","/docs/transformers/pr_17443/en/model_doc/rag#transformers.RagTokenizer"),c(aB,"href","/docs/transformers/pr_17443/en/model_doc/realm#transformers.RealmTokenizer"),c(nB,"href","/docs/transformers/pr_17443/en/model_doc/realm#transformers.RealmTokenizerFast"),c(sB,"href","/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerTokenizer"),c(lB,"href","/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(iB,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertTokenizer"),c(dB,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(cB,"href","/docs/transformers/pr_17443/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(fB,"href","/docs/transformers/pr_17443/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(mB,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaTokenizer"),c(gB,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(hB,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(pB,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(_B,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(uB,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(bB,"href","/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterTokenizer"),c(vB,"href","/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(FB,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(TB,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(MB,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Tokenizer"),c(EB,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5TokenizerFast"),c(CB,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasTokenizer"),c(wB,"href","/docs/transformers/pr_17443/en/model_doc/tapex#transformers.TapexTokenizer"),c(AB,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(yB,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertTokenizer"),c(LB,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertTokenizerFast"),c(xB,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c($B,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(kB,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(SB,"href","/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMTokenizer"),c(RB,"href","/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(PB,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMTokenizer"),c(BB,"href","/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(IB,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(NB,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(qB,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaTokenizer"),c(jB,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(DB,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(GB,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(OB,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertTokenizer"),c(VB,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ih,"id","transformers.AutoFeatureExtractor"),c(ih,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ih,"href","#transformers.AutoFeatureExtractor"),c(Ei,"class","relative group"),c(XB,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(zB,"href","/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(WB,"href","/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(QB,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(HB,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(UB,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(JB,"href","/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(YB,"href","/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(KB,"href","/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(ZB,"href","/docs/transformers/pr_17443/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(eI,"href","/docs/transformers/pr_17443/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(oI,"href","/docs/transformers/pr_17443/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(rI,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(tI,"href","/docs/transformers/pr_17443/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(aI,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(nI,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(sI,"href","/docs/transformers/pr_17443/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(lI,"href","/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(iI,"href","/docs/transformers/pr_17443/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(dI,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(cI,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(fI,"href","/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(mI,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(gI,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(hI,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(pI,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(_I,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(uI,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(bI,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(vI,"href","/docs/transformers/pr_17443/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gh,"id","transformers.AutoProcessor"),c(Gh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Gh,"href","#transformers.AutoProcessor"),c(Ci,"class","relative group"),c(FI,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(TI,"href","/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPProcessor"),c(MI,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(EI,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(CI,"href","/docs/transformers/pr_17443/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(wI,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(AI,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(yI,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(LI,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(xI,"href","/docs/transformers/pr_17443/en/model_doc/trocr#transformers.TrOCRProcessor"),c($I,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(kI,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(SI,"href","/docs/transformers/pr_17443/en/model_doc/vilt#transformers.ViltProcessor"),c(RI,"href","/docs/transformers/pr_17443/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(PI,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(BI,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(II,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ip,"id","transformers.AutoModel"),c(ip,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ip,"href","#transformers.AutoModel"),c(Ai,"class","relative group"),c(NI,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qI,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jI,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DI,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertModel"),c(GI,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartModel"),c(OI,"href","/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitModel"),c(VI,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertModel"),c(XI,"href","/docs/transformers/pr_17443/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(zI,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdModel"),c(WI,"href","/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(QI,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(HI,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(UI,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertModel"),c(JI,"href","/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineModel"),c(YI,"href","/docs/transformers/pr_17443/en/model_doc/clip#transformers.CLIPModel"),c(KI,"href","/docs/transformers/pr_17443/en/model_doc/codegen#transformers.CodeGenModel"),c(ZI,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertModel"),c(eN,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextModel"),c(oN,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLModel"),c(rN,"href","/docs/transformers/pr_17443/en/model_doc/cvt#transformers.CvtModel"),c(tN,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(aN,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(nN,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(sN,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaModel"),c(lN,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(iN,"href","/docs/transformers/pr_17443/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(dN,"href","/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTModel"),c(cN,"href","/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrModel"),c(fN,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertModel"),c(mN,"href","/docs/transformers/pr_17443/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(gN,"href","/docs/transformers/pr_17443/en/model_doc/dpt#transformers.DPTModel"),c(hN,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraModel"),c(pN,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertModel"),c(_N,"href","/docs/transformers/pr_17443/en/model_doc/flava#transformers.FlavaModel"),c(uN,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetModel"),c(bN,"href","/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTModel"),c(vN,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelModel"),c(FN,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelBaseModel"),c(TN,"href","/docs/transformers/pr_17443/en/model_doc/glpn#transformers.GLPNModel"),c(MN,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2Model"),c(EN,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(CN,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(wN,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJModel"),c(AN,"href","/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertModel"),c(yN,"href","/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertModel"),c(LN,"href","/docs/transformers/pr_17443/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(xN,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMModel"),c($N,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(kN,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(SN,"href","/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDModel"),c(RN,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerModel"),c(PN,"href","/docs/transformers/pr_17443/en/model_doc/luke#transformers.LukeModel"),c(BN,"href","/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertModel"),c(IN,"href","/docs/transformers/pr_17443/en/model_doc/m2m_100#transformers.M2M100Model"),c(NN,"href","/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianModel"),c(qN,"href","/docs/transformers/pr_17443/en/model_doc/maskformer#transformers.MaskFormerModel"),c(jN,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartModel"),c(DN,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(GN,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertModel"),c(ON,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetModel"),c(VN,"href","/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5Model"),c(XN,"href","/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerModel"),c(zN,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(WN,"href","/docs/transformers/pr_17443/en/model_doc/opt#transformers.OPTModel"),c(QN,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusModel"),c(HN,"href","/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverModel"),c(UN,"href","/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartModel"),c(JN,"href","/docs/transformers/pr_17443/en/model_doc/poolformer#transformers.PoolFormerModel"),c(YN,"href","/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(KN,"href","/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertModel"),c(ZN,"href","/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerModel"),c(eq,"href","/docs/transformers/pr_17443/en/model_doc/regnet#transformers.RegNetModel"),c(oq,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertModel"),c(rq,"href","/docs/transformers/pr_17443/en/model_doc/resnet#transformers.ResNetModel"),c(tq,"href","/docs/transformers/pr_17443/en/model_doc/retribert#transformers.RetriBertModel"),c(aq,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaModel"),c(nq,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerModel"),c(sq,"href","/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerModel"),c(lq,"href","/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWModel"),c(iq,"href","/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDModel"),c(dq,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(cq,"href","/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterModel"),c(fq,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(mq,"href","/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinModel"),c(gq,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5Model"),c(hq,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasModel"),c(pq,"href","/docs/transformers/pr_17443/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(_q,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(uq,"href","/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechModel"),c(bq,"href","/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(vq,"href","/docs/transformers/pr_17443/en/model_doc/van#transformers.VanModel"),c(Fq,"href","/docs/transformers/pr_17443/en/model_doc/vilt#transformers.ViltModel"),c(Tq,"href","/docs/transformers/pr_17443/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Mq,"href","/docs/transformers/pr_17443/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Eq,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTModel"),c(Cq,"href","/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(wq,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Aq,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(yq,"href","/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMModel"),c(Lq,"href","/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMModel"),c(xq,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMModel"),c($q,"href","/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(kq,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(Sq,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(Rq,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetModel"),c(Pq,"href","/docs/transformers/pr_17443/en/model_doc/yolos#transformers.YolosModel"),c(Bq,"href","/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(su,"id","transformers.AutoModelForPreTraining"),c(su,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(su,"href","#transformers.AutoModelForPreTraining"),c(xi,"class","relative group"),c(Iq,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nq,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qq,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jq,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForPreTraining"),c(Dq,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Gq,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForPreTraining"),c(Oq,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(Vq,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(Xq,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(zq,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(Wq,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(Qq,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(Hq,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(Uq,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForPreTraining"),c(Jq,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(Yq,"href","/docs/transformers/pr_17443/en/model_doc/flava#transformers.FlavaForPreTraining"),c(Kq,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForPreTraining"),c(Zq,"href","/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(ej,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(oj,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(rj,"href","/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(tj,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(aj,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(nj,"href","/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(sj,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(lj,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(ij,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(dj,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(cj,"href","/docs/transformers/pr_17443/en/model_doc/retribert#transformers.RetriBertModel"),c(fj,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(mj,"href","/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(gj,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(hj,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(pj,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(_j,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(uj,"href","/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(bj,"href","/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(vj,"href","/docs/transformers/pr_17443/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(Fj,"href","/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(Tj,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(Mj,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(Ej,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(Cj,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(wj,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(Aj,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ku,"id","transformers.AutoModelForCausalLM"),c(Ku,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ku,"href","#transformers.AutoModelForCausalLM"),c(Si,"class","relative group"),c(yj,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lj,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xj,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($j,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForCausalLM"),c(kj,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertLMHeadModel"),c(Sj,"href","/docs/transformers/pr_17443/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(Rj,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(Pj,"href","/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(Bj,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(Ij,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(Nj,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(qj,"href","/docs/transformers/pr_17443/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(jj,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Dj,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(Gj,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForCausalLM"),c(Oj,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Vj,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(Xj,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(zj,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(Wj,"href","/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianForCausalLM"),c(Qj,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForCausalLM"),c(Hj,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(Uj,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(Jj,"href","/docs/transformers/pr_17443/en/model_doc/opt#transformers.OPTForCausalLM"),c(Yj,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(Kj,"href","/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(Zj,"href","/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(eD,"href","/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(oD,"href","/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(rD,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(tD,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(aD,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(nD,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(sD,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(lD,"href","/docs/transformers/pr_17443/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(iD,"href","/docs/transformers/pr_17443/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(dD,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(cD,"href","/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(fD,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(mD,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(gD,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D4,"id","transformers.AutoModelForMaskedLM"),c(D4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D4,"href","#transformers.AutoModelForMaskedLM"),c(Bi,"class","relative group"),c(hD,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pD,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_D,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uD,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(bD,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(vD,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForMaskedLM"),c(FD,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(TD,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(MD,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(ED,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(CD,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(wD,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(AD,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(yD,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(LD,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(xD,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForMaskedLM"),c($D,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(kD,"href","/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(SD,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(RD,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(PD,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(BD,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(ID,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(ND,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(qD,"href","/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(jD,"href","/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(DD,"href","/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(GD,"href","/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(OD,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(VD,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(XD,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(zD,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(WD,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(QD,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(HD,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(UD,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(JD,"href","/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w1,"id","transformers.AutoModelForSeq2SeqLM"),c(w1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w1,"href","#transformers.AutoModelForSeq2SeqLM"),c(qi,"class","relative group"),c(YD,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KD,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZD,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eG,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(oG,"href","/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(rG,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(tG,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(aG,"href","/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(nG,"href","/docs/transformers/pr_17443/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(sG,"href","/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(lG,"href","/docs/transformers/pr_17443/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(iG,"href","/docs/transformers/pr_17443/en/model_doc/marian#transformers.MarianMTModel"),c(dG,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(cG,"href","/docs/transformers/pr_17443/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(fG,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(mG,"href","/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(gG,"href","/docs/transformers/pr_17443/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(hG,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(pG,"href","/docs/transformers/pr_17443/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z1,"id","transformers.AutoModelForSequenceClassification"),c(z1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z1,"href","#transformers.AutoModelForSequenceClassification"),c(Gi,"class","relative group"),c(_G,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uG,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bG,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vG,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(FG,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForSequenceClassification"),c(TG,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForSequenceClassification"),c(MG,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(EG,"href","/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(CG,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(wG,"href","/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(AG,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(yG,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(LG,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(xG,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c($G,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(kG,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(SG,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(RG,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(PG,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(BG,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(IG,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(NG,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(qG,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(jG,"href","/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(DG,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(GG,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(OG,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(VG,"href","/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDForSequenceClassification"),c(XG,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(zG,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(WG,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(QG,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(HG,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(UG,"href","/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(JG,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(YG,"href","/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(KG,"href","/docs/transformers/pr_17443/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(ZG,"href","/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(eO,"href","/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(oO,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(rO,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(tO,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(aO,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(nO,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(sO,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(lO,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(iO,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(dO,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(cO,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(fO,"href","/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ob,"id","transformers.AutoModelForMultipleChoice"),c(Ob,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ob,"href","#transformers.AutoModelForMultipleChoice"),c(Xi,"class","relative group"),c(mO,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gO,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hO,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pO,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(_O,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForMultipleChoice"),c(uO,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(bO,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(vO,"href","/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(FO,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(TO,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(MO,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(EO,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(CO,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(wO,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(AO,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(yO,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(LO,"href","/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(xO,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c($O,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(kO,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(SO,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(RO,"href","/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(PO,"href","/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(BO,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(IO,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(NO,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(qO,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(jO,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(DO,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(GO,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(OO,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(VO,"href","/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T2,"id","transformers.AutoModelForNextSentencePrediction"),c(T2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T2,"href","#transformers.AutoModelForNextSentencePrediction"),c(Qi,"class","relative group"),c(XO,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zO,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WO,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QO,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(HO,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(UO,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(JO,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(YO,"href","/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($2,"id","transformers.AutoModelForTokenClassification"),c($2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($2,"href","#transformers.AutoModelForTokenClassification"),c(Ji,"class","relative group"),c(KO,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZO,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eV,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oV,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(rV,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForTokenClassification"),c(tV,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(aV,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(nV,"href","/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineForTokenClassification"),c(sV,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(lV,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(iV,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(dV,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(cV,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(fV,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(mV,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(gV,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(hV,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(pV,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(_V,"href","/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(uV,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(bV,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(vV,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(FV,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(TV,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(MV,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(EV,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(CV,"href","/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(wV,"href","/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(AV,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(yV,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(LV,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(xV,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c($V,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(kV,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(SV,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(RV,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(PV,"href","/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hv,"id","transformers.AutoModelForQuestionAnswering"),c(hv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hv,"href","#transformers.AutoModelForQuestionAnswering"),c(Zi,"class","relative group"),c(BV,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IV,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NV,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qV,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(jV,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(DV,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(GV,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(OV,"href","/docs/transformers/pr_17443/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(VV,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(XV,"href","/docs/transformers/pr_17443/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(zV,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(WV,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(QV,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(HV,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(UV,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(JV,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(YV,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(KV,"href","/docs/transformers/pr_17443/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(ZV,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(eX,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(oX,"href","/docs/transformers/pr_17443/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(rX,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(tX,"href","/docs/transformers/pr_17443/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(aX,"href","/docs/transformers/pr_17443/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(nX,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(sX,"href","/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(lX,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(iX,"href","/docs/transformers/pr_17443/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(dX,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(cX,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(fX,"href","/docs/transformers/pr_17443/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(mX,"href","/docs/transformers/pr_17443/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(gX,"href","/docs/transformers/pr_17443/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(hX,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(pX,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(_X,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(uX,"href","/docs/transformers/pr_17443/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(bX,"href","/docs/transformers/pr_17443/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(vX,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(FX,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(TX,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(MX,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(EX,"href","/docs/transformers/pr_17443/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a3,"id","transformers.AutoModelForTableQuestionAnswering"),c(a3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a3,"href","#transformers.AutoModelForTableQuestionAnswering"),c(rd,"class","relative group"),c(CX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yX,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d3,"id","transformers.AutoModelForImageClassification"),c(d3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d3,"href","#transformers.AutoModelForImageClassification"),c(nd,"class","relative group"),c(LX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($X,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kX,"href","/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitForImageClassification"),c(SX,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(RX,"href","/docs/transformers/pr_17443/en/model_doc/cvt#transformers.CvtForImageClassification"),c(PX,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(BX,"href","/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTForImageClassification"),c(IX,"href","/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(NX,"href","/docs/transformers/pr_17443/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(qX,"href","/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(jX,"href","/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(DX,"href","/docs/transformers/pr_17443/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(GX,"href","/docs/transformers/pr_17443/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(OX,"href","/docs/transformers/pr_17443/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(VX,"href","/docs/transformers/pr_17443/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(XX,"href","/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(zX,"href","/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinForImageClassification"),c(WX,"href","/docs/transformers/pr_17443/en/model_doc/van#transformers.VanForImageClassification"),c(QX,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w3,"id","transformers.AutoModelForVision2Seq"),c(w3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w3,"href","#transformers.AutoModelForVision2Seq"),c(id,"class","relative group"),c(HX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YX,"href","/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($3,"id","transformers.AutoModelForAudioClassification"),c($3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($3,"href","#transformers.AutoModelForAudioClassification"),c(fd,"class","relative group"),c(KX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZX,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ez,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oz,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(rz,"href","/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(tz,"href","/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(az,"href","/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(nz,"href","/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(sz,"href","/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(lz,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(iz,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(dz,"href","/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(V3,"id","transformers.AutoModelForAudioFrameClassification"),c(V3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V3,"href","#transformers.AutoModelForAudioFrameClassification"),c(hd,"class","relative group"),c(cz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gz,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(hz,"href","/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(pz,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(_z,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(uz,"href","/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K3,"id","transformers.AutoModelForCTC"),c(K3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K3,"href","#transformers.AutoModelForCTC"),c(ud,"class","relative group"),c(bz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Fz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tz,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(Mz,"href","/docs/transformers/pr_17443/en/model_doc/hubert#transformers.HubertForCTC"),c(Ez,"href","/docs/transformers/pr_17443/en/model_doc/sew#transformers.SEWForCTC"),c(Cz,"href","/docs/transformers/pr_17443/en/model_doc/sew-d#transformers.SEWDForCTC"),c(wz,"href","/docs/transformers/pr_17443/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(Az,"href","/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(yz,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(Lz,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(xz,"href","/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMForCTC"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fF,"id","transformers.AutoModelForSpeechSeq2Seq"),c(fF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fF,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Fd,"class","relative group"),c($z,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Sz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rz,"href","/docs/transformers/pr_17443/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(Pz,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uF,"id","transformers.AutoModelForAudioXVector"),c(uF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uF,"href","#transformers.AutoModelForAudioXVector"),c(Ed,"class","relative group"),c(Bz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Iz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Nz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qz,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(jz,"href","/docs/transformers/pr_17443/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(Dz,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(Gz,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(Oz,"href","/docs/transformers/pr_17443/en/model_doc/wavlm#transformers.WavLMForXVector"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AF,"id","transformers.AutoModelForMaskedImageModeling"),c(AF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AF,"href","#transformers.AutoModelForMaskedImageModeling"),c(Ad,"class","relative group"),c(Vz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wz,"href","/docs/transformers/pr_17443/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(Qz,"href","/docs/transformers/pr_17443/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(Hz,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RF,"id","transformers.AutoModelForObjectDetection"),c(RF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RF,"href","#transformers.AutoModelForObjectDetection"),c($d,"class","relative group"),c(Uz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yz,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kz,"href","/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrForObjectDetection"),c(Zz,"href","/docs/transformers/pr_17443/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jF,"id","transformers.AutoModelForImageSegmentation"),c(jF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jF,"href","#transformers.AutoModelForImageSegmentation"),c(Rd,"class","relative group"),c(eW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tW,"href","/docs/transformers/pr_17443/en/model_doc/detr#transformers.DetrForSegmentation"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XF,"id","transformers.AutoModelForSemanticSegmentation"),c(XF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XF,"href","#transformers.AutoModelForSemanticSegmentation"),c(Id,"class","relative group"),c(aW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lW,"href","/docs/transformers/pr_17443/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(iW,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(dW,"href","/docs/transformers/pr_17443/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(cW,"href","/docs/transformers/pr_17443/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KF,"id","transformers.AutoModelForInstanceSegmentation"),c(KF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KF,"href","#transformers.AutoModelForInstanceSegmentation"),c(jd,"class","relative group"),c(fW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hW,"href","/docs/transformers/pr_17443/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tT,"id","transformers.TFAutoModel"),c(tT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(tT,"href","#transformers.TFAutoModel"),c(Od,"class","relative group"),c(pW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_W,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uW,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bW,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertModel"),c(vW,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.TFBartModel"),c(FW,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertModel"),c(TW,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(MW,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(EW,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertModel"),c(CW,"href","/docs/transformers/pr_17443/en/model_doc/clip#transformers.TFCLIPModel"),c(wW,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertModel"),c(AW,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.TFConvNextModel"),c(yW,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.TFCTRLModel"),c(LW,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(xW,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaModel"),c($W,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(kW,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(SW,"href","/docs/transformers/pr_17443/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(RW,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraModel"),c(PW,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(BW,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelModel"),c(IW,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(NW,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.TFGPT2Model"),c(qW,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.TFGPTJModel"),c(jW,"href","/docs/transformers/pr_17443/en/model_doc/hubert#transformers.TFHubertModel"),c(DW,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(GW,"href","/docs/transformers/pr_17443/en/model_doc/led#transformers.TFLEDModel"),c(OW,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerModel"),c(VW,"href","/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.TFLxmertModel"),c(XW,"href","/docs/transformers/pr_17443/en/model_doc/marian#transformers.TFMarianModel"),c(zW,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.TFMBartModel"),c(WW,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(QW,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetModel"),c(HW,"href","/docs/transformers/pr_17443/en/model_doc/mt5#transformers.TFMT5Model"),c(UW,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(JW,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.TFPegasusModel"),c(YW,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertModel"),c(KW,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaModel"),c(ZW,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerModel"),c(eQ,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(oQ,"href","/docs/transformers/pr_17443/en/model_doc/swin#transformers.TFSwinModel"),c(rQ,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.TFT5Model"),c(tQ,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasModel"),c(aQ,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(nQ,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.TFViTModel"),c(sQ,"href","/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(lQ,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(iQ,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMModel"),c(dQ,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(cQ,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetModel"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YT,"id","transformers.TFAutoModelForPreTraining"),c(YT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YT,"href","#transformers.TFAutoModelForPreTraining"),c(zd,"class","relative group"),c(fQ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mQ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gQ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hQ,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(pQ,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(_Q,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForPreTraining"),c(uQ,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(bQ,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(vQ,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(FQ,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(TQ,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(MQ,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(EQ,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(CQ,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(wQ,"href","/docs/transformers/pr_17443/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(AQ,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(yQ,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(LQ,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(xQ,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c($Q,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(kQ,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(SQ,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(RQ,"href","/docs/transformers/pr_17443/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(PQ,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(BQ,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(IQ,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E7,"id","transformers.TFAutoModelForCausalLM"),c(E7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E7,"href","#transformers.TFAutoModelForCausalLM"),c(Hd,"class","relative group"),c(NQ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qQ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jQ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DQ,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(GQ,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(OQ,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(VQ,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(XQ,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(zQ,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(WQ,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(QQ,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(HQ,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(UQ,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(JQ,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(YQ,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q7,"id","transformers.TFAutoModelForImageClassification"),c(q7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q7,"href","#transformers.TFAutoModelForImageClassification"),c(Yd,"class","relative group"),c(KQ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZQ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eH,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oH,"href","/docs/transformers/pr_17443/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(rH,"href","/docs/transformers/pr_17443/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(tH,"href","/docs/transformers/pr_17443/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(aH,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z7,"id","transformers.TFAutoModelForMaskedLM"),c(z7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z7,"href","#transformers.TFAutoModelForMaskedLM"),c(ec,"class","relative group"),c(nH,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sH,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lH,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iH,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(dH,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(cH,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(fH,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(mH,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(gH,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(hH,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(pH,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(_H,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(uH,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(bH,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(vH,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(FH,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(TH,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(MH,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(EH,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(CH,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(wH,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(AH,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(yH,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hM,"id","transformers.TFAutoModelForSeq2SeqLM"),c(hM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hM,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(tc,"class","relative group"),c(LH,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xH,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($H,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kH,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(SH,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(RH,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(PH,"href","/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(BH,"href","/docs/transformers/pr_17443/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(IH,"href","/docs/transformers/pr_17443/en/model_doc/marian#transformers.TFMarianMTModel"),c(NH,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(qH,"href","/docs/transformers/pr_17443/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(jH,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(DH,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yM,"id","transformers.TFAutoModelForSequenceClassification"),c(yM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yM,"href","#transformers.TFAutoModelForSequenceClassification"),c(sc,"class","relative group"),c(GH,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OH,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VH,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XH,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(zH,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(WH,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(QH,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(HH,"href","/docs/transformers/pr_17443/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(UH,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(JH,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(YH,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(KH,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(ZH,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(eU,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(oU,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(rU,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(tU,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(aU,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(nU,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(sU,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(lU,"href","/docs/transformers/pr_17443/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(iU,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(dU,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(cU,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(fU,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(mU,"href","/docs/transformers/pr_17443/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(gU,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(hU,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(pU,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rE,"id","transformers.TFAutoModelForMultipleChoice"),c(rE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rE,"href","#transformers.TFAutoModelForMultipleChoice"),c(dc,"class","relative group"),c(_U,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vU,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(FU,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(TU,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(MU,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(EU,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(CU,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(wU,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(AU,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(yU,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(LU,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(xU,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c($U,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(kU,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(SU,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(RU,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(PU,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(BU,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ME,"id","transformers.TFAutoModelForNextSentencePrediction"),c(ME,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ME,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(mc,"class","relative group"),c(IU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jU,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(DU,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yE,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(yE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yE,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(pc,"class","relative group"),c(GU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XU,"href","/docs/transformers/pr_17443/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kE,"id","transformers.TFAutoModelForTokenClassification"),c(kE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kE,"href","#transformers.TFAutoModelForTokenClassification"),c(bc,"class","relative group"),c(zU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QU,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HU,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(UU,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(JU,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(YU,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(KU,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(ZU,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(eJ,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(oJ,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(rJ,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(tJ,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(aJ,"href","/docs/transformers/pr_17443/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(nJ,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(sJ,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(lJ,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(iJ,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(dJ,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(cJ,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(fJ,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(mJ,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(gJ,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eC,"id","transformers.TFAutoModelForQuestionAnswering"),c(eC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eC,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Tc,"class","relative group"),c(hJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_J,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uJ,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(bJ,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(vJ,"href","/docs/transformers/pr_17443/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(FJ,"href","/docs/transformers/pr_17443/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(TJ,"href","/docs/transformers/pr_17443/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(MJ,"href","/docs/transformers/pr_17443/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(EJ,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(CJ,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(wJ,"href","/docs/transformers/pr_17443/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(AJ,"href","/docs/transformers/pr_17443/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(yJ,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(LJ,"href","/docs/transformers/pr_17443/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(xJ,"href","/docs/transformers/pr_17443/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c($J,"href","/docs/transformers/pr_17443/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(kJ,"href","/docs/transformers/pr_17443/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(SJ,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(RJ,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(PJ,"href","/docs/transformers/pr_17443/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(BJ,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(IJ,"href","/docs/transformers/pr_17443/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EC,"id","transformers.TFAutoModelForVision2Seq"),c(EC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EC,"href","#transformers.TFAutoModelForVision2Seq"),c(Cc,"class","relative group"),c(NJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DJ,"href","/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yC,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(yC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yC,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(yc,"class","relative group"),c(GJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XJ,"href","/docs/transformers/pr_17443/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kC,"id","transformers.FlaxAutoModel"),c(kC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kC,"href","#transformers.FlaxAutoModel"),c($c,"class","relative group"),c(zJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QJ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HJ,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertModel"),c(UJ,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartModel"),c(JJ,"href","/docs/transformers/pr_17443/en/model_doc/beit#transformers.FlaxBeitModel"),c(YJ,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertModel"),c(KJ,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(ZJ,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(eY,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(oY,"href","/docs/transformers/pr_17443/en/model_doc/clip#transformers.FlaxCLIPModel"),c(rY,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(tY,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraModel"),c(aY,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(nY,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(sY,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(lY,"href","/docs/transformers/pr_17443/en/model_doc/marian#transformers.FlaxMarianModel"),c(iY,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartModel"),c(dY,"href","/docs/transformers/pr_17443/en/model_doc/mt5#transformers.FlaxMT5Model"),c(cY,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(fY,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(mY,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(gY,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.FlaxT5Model"),c(hY,"href","/docs/transformers/pr_17443/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(pY,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.FlaxViTModel"),c(_Y,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(uY,"href","/docs/transformers/pr_17443/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(bY,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n5,"id","transformers.FlaxAutoModelForCausalLM"),c(n5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n5,"href","#transformers.FlaxAutoModelForCausalLM"),c(Rc,"class","relative group"),c(vY,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FY,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TY,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MY,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(EY,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(CY,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(wY,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(AY,"href","/docs/transformers/pr_17443/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(yY,"href","/docs/transformers/pr_17443/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(LY,"href","/docs/transformers/pr_17443/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(xY,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c($Y,"href","/docs/transformers/pr_17443/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u5,"id","transformers.FlaxAutoModelForPreTraining"),c(u5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u5,"href","#transformers.FlaxAutoModelForPreTraining"),c(Ic,"class","relative group"),c(kY,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SY,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RY,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PY,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(BY,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(IY,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(NY,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(qY,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(jY,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(DY,"href","/docs/transformers/pr_17443/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(GY,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(OY,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(VY,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(XY,"href","/docs/transformers/pr_17443/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(zY,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S5,"id","transformers.FlaxAutoModelForMaskedLM"),c(S5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S5,"href","#transformers.FlaxAutoModelForMaskedLM"),c(jc,"class","relative group"),c(WY,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QY,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HY,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UY,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(JY,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(YY,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(KY,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(ZY,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(eK,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(oK,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(rK,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(tK,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(aK,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z5,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(z5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z5,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Oc,"class","relative group"),c(nK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iK,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(dK,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(cK,"href","/docs/transformers/pr_17443/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(fK,"href","/docs/transformers/pr_17443/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(mK,"href","/docs/transformers/pr_17443/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(gK,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(hK,"href","/docs/transformers/pr_17443/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(pK,"href","/docs/transformers/pr_17443/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(_K,"href","/docs/transformers/pr_17443/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tw,"id","transformers.FlaxAutoModelForSequenceClassification"),c(tw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(tw,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(zc,"class","relative group"),c(uK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FK,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(TK,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(MK,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(EK,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(CK,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(wK,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(AK,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(yK,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(LK,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(xK,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_w,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(_w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_w,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Hc,"class","relative group"),c($K,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(PK,"href","/docs/transformers/pr_17443/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(BK,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(IK,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(NK,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(qK,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(jK,"href","/docs/transformers/pr_17443/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(DK,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(GK,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(OK,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xw,"id","transformers.FlaxAutoModelForTokenClassification"),c(xw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xw,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Yc,"class","relative group"),c(VK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zK,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WK,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(QK,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(HK,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(UK,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(JK,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(YK,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(KK,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(ZK,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dw,"id","transformers.FlaxAutoModelForMultipleChoice"),c(Dw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Dw,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(ef,"class","relative group"),c(eZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tZ,"href","/docs/transformers/pr_17443/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(aZ,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(nZ,"href","/docs/transformers/pr_17443/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(sZ,"href","/docs/transformers/pr_17443/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(lZ,"href","/docs/transformers/pr_17443/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(iZ,"href","/docs/transformers/pr_17443/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(dZ,"href","/docs/transformers/pr_17443/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(cZ,"href","/docs/transformers/pr_17443/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yw,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Yw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yw,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(tf,"class","relative group"),c(fZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hZ,"href","/docs/transformers/pr_17443/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o0,"id","transformers.FlaxAutoModelForImageClassification"),c(o0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o0,"href","#transformers.FlaxAutoModelForImageClassification"),c(sf,"class","relative group"),c(pZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_Z,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bZ,"href","/docs/transformers/pr_17443/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(vZ,"href","/docs/transformers/pr_17443/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s0,"id","transformers.FlaxAutoModelForVision2Seq"),c(s0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s0,"href","#transformers.FlaxAutoModelForVision2Seq"),c(cf,"class","relative group"),c(FZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MZ,"href","/docs/transformers/pr_17443/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EZ,"href","/docs/transformers/pr_17443/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Mo),e(Mo,mi),b(f,_f,u),b(f,rt,u),e(rt,gi),e(rt,hi),e(hi,yA),e(rt,uf),b(f,je,u),b(f,We,u),e(We,pi),e(We,yn),e(yn,LA),e(We,Ln),e(We,xn),e(xn,xA),e(We,_i),e(We,$n),e($n,$A),e(We,ui),b(f,bf,u),M(Ca,f,u),b(f,Qe,u),b(f,Ae,u),e(Ae,J$),e(Ae,bi),e(bi,Y$),e(Ae,K$),b(f,Eo,u),b(f,wa,u),e(wa,Z$),e(wa,vf),e(vf,ek),e(wa,AOe),b(f,pqe,u),b(f,vi,u),e(vi,Ff),e(Ff,_oe),M(kA,_oe,null),e(vi,yOe),e(vi,uoe),e(uoe,LOe),b(f,_qe,u),b(f,kn,u),e(kn,xOe),e(kn,boe),e(boe,$Oe),e(kn,kOe),e(kn,voe),e(voe,SOe),e(kn,ROe),b(f,uqe,u),M(SA,f,u),b(f,bqe,u),b(f,ok,u),e(ok,POe),b(f,vqe,u),M(Tf,f,u),b(f,Fqe,u),b(f,Fi,u),e(Fi,Mf),e(Mf,Foe),M(RA,Foe,null),e(Fi,BOe),e(Fi,Toe),e(Toe,IOe),b(f,Tqe,u),b(f,Co,u),M(PA,Co,null),e(Co,NOe),e(Co,BA),e(BA,qOe),e(BA,rk),e(rk,jOe),e(BA,DOe),e(Co,GOe),e(Co,IA),e(IA,OOe),e(IA,Moe),e(Moe,VOe),e(IA,XOe),e(Co,zOe),e(Co,Er),M(NA,Er,null),e(Er,WOe),e(Er,Eoe),e(Eoe,QOe),e(Er,HOe),e(Er,Ti),e(Ti,UOe),e(Ti,Coe),e(Coe,JOe),e(Ti,YOe),e(Ti,woe),e(woe,KOe),e(Ti,ZOe),e(Er,eVe),e(Er,A),e(A,Ef),e(Ef,Aoe),e(Aoe,oVe),e(Ef,rVe),e(Ef,tk),e(tk,tVe),e(Ef,aVe),e(A,nVe),e(A,Cf),e(Cf,yoe),e(yoe,sVe),e(Cf,lVe),e(Cf,ak),e(ak,iVe),e(Cf,dVe),e(A,cVe),e(A,wf),e(wf,Loe),e(Loe,fVe),e(wf,mVe),e(wf,nk),e(nk,gVe),e(wf,hVe),e(A,pVe),e(A,Af),e(Af,xoe),e(xoe,_Ve),e(Af,uVe),e(Af,sk),e(sk,bVe),e(Af,vVe),e(A,FVe),e(A,yf),e(yf,$oe),e($oe,TVe),e(yf,MVe),e(yf,lk),e(lk,EVe),e(yf,CVe),e(A,wVe),e(A,Lf),e(Lf,koe),e(koe,AVe),e(Lf,yVe),e(Lf,ik),e(ik,LVe),e(Lf,xVe),e(A,$Ve),e(A,xf),e(xf,Soe),e(Soe,kVe),e(xf,SVe),e(xf,dk),e(dk,RVe),e(xf,PVe),e(A,BVe),e(A,$f),e($f,Roe),e(Roe,IVe),e($f,NVe),e($f,ck),e(ck,qVe),e($f,jVe),e(A,DVe),e(A,kf),e(kf,Poe),e(Poe,GVe),e(kf,OVe),e(kf,fk),e(fk,VVe),e(kf,XVe),e(A,zVe),e(A,Sf),e(Sf,Boe),e(Boe,WVe),e(Sf,QVe),e(Sf,mk),e(mk,HVe),e(Sf,UVe),e(A,JVe),e(A,Rf),e(Rf,Ioe),e(Ioe,YVe),e(Rf,KVe),e(Rf,gk),e(gk,ZVe),e(Rf,eXe),e(A,oXe),e(A,Pf),e(Pf,Noe),e(Noe,rXe),e(Pf,tXe),e(Pf,hk),e(hk,aXe),e(Pf,nXe),e(A,sXe),e(A,Bf),e(Bf,qoe),e(qoe,lXe),e(Bf,iXe),e(Bf,pk),e(pk,dXe),e(Bf,cXe),e(A,fXe),e(A,If),e(If,joe),e(joe,mXe),e(If,gXe),e(If,_k),e(_k,hXe),e(If,pXe),e(A,_Xe),e(A,Nf),e(Nf,Doe),e(Doe,uXe),e(Nf,bXe),e(Nf,uk),e(uk,vXe),e(Nf,FXe),e(A,TXe),e(A,qf),e(qf,Goe),e(Goe,MXe),e(qf,EXe),e(qf,bk),e(bk,CXe),e(qf,wXe),e(A,AXe),e(A,jf),e(jf,Ooe),e(Ooe,yXe),e(jf,LXe),e(jf,vk),e(vk,xXe),e(jf,$Xe),e(A,kXe),e(A,Df),e(Df,Voe),e(Voe,SXe),e(Df,RXe),e(Df,Fk),e(Fk,PXe),e(Df,BXe),e(A,IXe),e(A,Gf),e(Gf,Xoe),e(Xoe,NXe),e(Gf,qXe),e(Gf,Tk),e(Tk,jXe),e(Gf,DXe),e(A,GXe),e(A,Of),e(Of,zoe),e(zoe,OXe),e(Of,VXe),e(Of,Mk),e(Mk,XXe),e(Of,zXe),e(A,WXe),e(A,Vf),e(Vf,Woe),e(Woe,QXe),e(Vf,HXe),e(Vf,Ek),e(Ek,UXe),e(Vf,JXe),e(A,YXe),e(A,Xf),e(Xf,Qoe),e(Qoe,KXe),e(Xf,ZXe),e(Xf,Ck),e(Ck,eze),e(Xf,oze),e(A,rze),e(A,zf),e(zf,Hoe),e(Hoe,tze),e(zf,aze),e(zf,wk),e(wk,nze),e(zf,sze),e(A,lze),e(A,Wf),e(Wf,Uoe),e(Uoe,ize),e(Wf,dze),e(Wf,Ak),e(Ak,cze),e(Wf,fze),e(A,mze),e(A,Qf),e(Qf,Joe),e(Joe,gze),e(Qf,hze),e(Qf,yk),e(yk,pze),e(Qf,_ze),e(A,uze),e(A,Hf),e(Hf,Yoe),e(Yoe,bze),e(Hf,vze),e(Hf,Lk),e(Lk,Fze),e(Hf,Tze),e(A,Mze),e(A,Uf),e(Uf,Koe),e(Koe,Eze),e(Uf,Cze),e(Uf,xk),e(xk,wze),e(Uf,Aze),e(A,yze),e(A,Jf),e(Jf,Zoe),e(Zoe,Lze),e(Jf,xze),e(Jf,$k),e($k,$ze),e(Jf,kze),e(A,Sze),e(A,Yf),e(Yf,ere),e(ere,Rze),e(Yf,Pze),e(Yf,kk),e(kk,Bze),e(Yf,Ize),e(A,Nze),e(A,Kf),e(Kf,ore),e(ore,qze),e(Kf,jze),e(Kf,Sk),e(Sk,Dze),e(Kf,Gze),e(A,Oze),e(A,Zf),e(Zf,rre),e(rre,Vze),e(Zf,Xze),e(Zf,Rk),e(Rk,zze),e(Zf,Wze),e(A,Qze),e(A,em),e(em,tre),e(tre,Hze),e(em,Uze),e(em,Pk),e(Pk,Jze),e(em,Yze),e(A,Kze),e(A,om),e(om,are),e(are,Zze),e(om,eWe),e(om,Bk),e(Bk,oWe),e(om,rWe),e(A,tWe),e(A,rm),e(rm,nre),e(nre,aWe),e(rm,nWe),e(rm,Ik),e(Ik,sWe),e(rm,lWe),e(A,iWe),e(A,tm),e(tm,sre),e(sre,dWe),e(tm,cWe),e(tm,Nk),e(Nk,fWe),e(tm,mWe),e(A,gWe),e(A,am),e(am,lre),e(lre,hWe),e(am,pWe),e(am,qk),e(qk,_We),e(am,uWe),e(A,bWe),e(A,nm),e(nm,ire),e(ire,vWe),e(nm,FWe),e(nm,jk),e(jk,TWe),e(nm,MWe),e(A,EWe),e(A,sm),e(sm,dre),e(dre,CWe),e(sm,wWe),e(sm,Dk),e(Dk,AWe),e(sm,yWe),e(A,LWe),e(A,lm),e(lm,cre),e(cre,xWe),e(lm,$We),e(lm,Gk),e(Gk,kWe),e(lm,SWe),e(A,RWe),e(A,im),e(im,fre),e(fre,PWe),e(im,BWe),e(im,Ok),e(Ok,IWe),e(im,NWe),e(A,qWe),e(A,dm),e(dm,mre),e(mre,jWe),e(dm,DWe),e(dm,Vk),e(Vk,GWe),e(dm,OWe),e(A,VWe),e(A,cm),e(cm,gre),e(gre,XWe),e(cm,zWe),e(cm,Xk),e(Xk,WWe),e(cm,QWe),e(A,HWe),e(A,fm),e(fm,hre),e(hre,UWe),e(fm,JWe),e(fm,zk),e(zk,YWe),e(fm,KWe),e(A,ZWe),e(A,mm),e(mm,pre),e(pre,eQe),e(mm,oQe),e(mm,Wk),e(Wk,rQe),e(mm,tQe),e(A,aQe),e(A,gm),e(gm,_re),e(_re,nQe),e(gm,sQe),e(gm,Qk),e(Qk,lQe),e(gm,iQe),e(A,dQe),e(A,hm),e(hm,ure),e(ure,cQe),e(hm,fQe),e(hm,Hk),e(Hk,mQe),e(hm,gQe),e(A,hQe),e(A,pm),e(pm,bre),e(bre,pQe),e(pm,_Qe),e(pm,Uk),e(Uk,uQe),e(pm,bQe),e(A,vQe),e(A,_m),e(_m,vre),e(vre,FQe),e(_m,TQe),e(_m,Jk),e(Jk,MQe),e(_m,EQe),e(A,CQe),e(A,um),e(um,Fre),e(Fre,wQe),e(um,AQe),e(um,Yk),e(Yk,yQe),e(um,LQe),e(A,xQe),e(A,bm),e(bm,Tre),e(Tre,$Qe),e(bm,kQe),e(bm,Kk),e(Kk,SQe),e(bm,RQe),e(A,PQe),e(A,vm),e(vm,Mre),e(Mre,BQe),e(vm,IQe),e(vm,Zk),e(Zk,NQe),e(vm,qQe),e(A,jQe),e(A,Fm),e(Fm,Ere),e(Ere,DQe),e(Fm,GQe),e(Fm,eS),e(eS,OQe),e(Fm,VQe),e(A,XQe),e(A,Tm),e(Tm,Cre),e(Cre,zQe),e(Tm,WQe),e(Tm,oS),e(oS,QQe),e(Tm,HQe),e(A,UQe),e(A,Mm),e(Mm,wre),e(wre,JQe),e(Mm,YQe),e(Mm,rS),e(rS,KQe),e(Mm,ZQe),e(A,eHe),e(A,Em),e(Em,Are),e(Are,oHe),e(Em,rHe),e(Em,tS),e(tS,tHe),e(Em,aHe),e(A,nHe),e(A,Cm),e(Cm,yre),e(yre,sHe),e(Cm,lHe),e(Cm,aS),e(aS,iHe),e(Cm,dHe),e(A,cHe),e(A,wm),e(wm,Lre),e(Lre,fHe),e(wm,mHe),e(wm,nS),e(nS,gHe),e(wm,hHe),e(A,pHe),e(A,Am),e(Am,xre),e(xre,_He),e(Am,uHe),e(Am,sS),e(sS,bHe),e(Am,vHe),e(A,FHe),e(A,ym),e(ym,$re),e($re,THe),e(ym,MHe),e(ym,lS),e(lS,EHe),e(ym,CHe),e(A,wHe),e(A,Lm),e(Lm,kre),e(kre,AHe),e(Lm,yHe),e(Lm,iS),e(iS,LHe),e(Lm,xHe),e(A,$He),e(A,xm),e(xm,Sre),e(Sre,kHe),e(xm,SHe),e(xm,dS),e(dS,RHe),e(xm,PHe),e(A,BHe),e(A,$m),e($m,Rre),e(Rre,IHe),e($m,NHe),e($m,cS),e(cS,qHe),e($m,jHe),e(A,DHe),e(A,km),e(km,Pre),e(Pre,GHe),e(km,OHe),e(km,fS),e(fS,VHe),e(km,XHe),e(A,zHe),e(A,Sm),e(Sm,Bre),e(Bre,WHe),e(Sm,QHe),e(Sm,mS),e(mS,HHe),e(Sm,UHe),e(A,JHe),e(A,Rm),e(Rm,Ire),e(Ire,YHe),e(Rm,KHe),e(Rm,gS),e(gS,ZHe),e(Rm,eUe),e(A,oUe),e(A,Pm),e(Pm,Nre),e(Nre,rUe),e(Pm,tUe),e(Pm,hS),e(hS,aUe),e(Pm,nUe),e(A,sUe),e(A,Bm),e(Bm,qre),e(qre,lUe),e(Bm,iUe),e(Bm,pS),e(pS,dUe),e(Bm,cUe),e(A,fUe),e(A,Im),e(Im,jre),e(jre,mUe),e(Im,gUe),e(Im,_S),e(_S,hUe),e(Im,pUe),e(A,_Ue),e(A,Nm),e(Nm,Dre),e(Dre,uUe),e(Nm,bUe),e(Nm,uS),e(uS,vUe),e(Nm,FUe),e(A,TUe),e(A,qm),e(qm,Gre),e(Gre,MUe),e(qm,EUe),e(qm,bS),e(bS,CUe),e(qm,wUe),e(A,AUe),e(A,jm),e(jm,Ore),e(Ore,yUe),e(jm,LUe),e(jm,vS),e(vS,xUe),e(jm,$Ue),e(A,kUe),e(A,Dm),e(Dm,Vre),e(Vre,SUe),e(Dm,RUe),e(Dm,FS),e(FS,PUe),e(Dm,BUe),e(A,IUe),e(A,Gm),e(Gm,Xre),e(Xre,NUe),e(Gm,qUe),e(Gm,TS),e(TS,jUe),e(Gm,DUe),e(A,GUe),e(A,Om),e(Om,zre),e(zre,OUe),e(Om,VUe),e(Om,MS),e(MS,XUe),e(Om,zUe),e(A,WUe),e(A,Vm),e(Vm,Wre),e(Wre,QUe),e(Vm,HUe),e(Vm,ES),e(ES,UUe),e(Vm,JUe),e(A,YUe),e(A,Xm),e(Xm,Qre),e(Qre,KUe),e(Xm,ZUe),e(Xm,CS),e(CS,eJe),e(Xm,oJe),e(A,rJe),e(A,zm),e(zm,Hre),e(Hre,tJe),e(zm,aJe),e(zm,wS),e(wS,nJe),e(zm,sJe),e(A,lJe),e(A,Wm),e(Wm,Ure),e(Ure,iJe),e(Wm,dJe),e(Wm,AS),e(AS,cJe),e(Wm,fJe),e(A,mJe),e(A,Qm),e(Qm,Jre),e(Jre,gJe),e(Qm,hJe),e(Qm,yS),e(yS,pJe),e(Qm,_Je),e(A,uJe),e(A,Hm),e(Hm,Yre),e(Yre,bJe),e(Hm,vJe),e(Hm,LS),e(LS,FJe),e(Hm,TJe),e(A,MJe),e(A,Um),e(Um,Kre),e(Kre,EJe),e(Um,CJe),e(Um,xS),e(xS,wJe),e(Um,AJe),e(A,yJe),e(A,Jm),e(Jm,Zre),e(Zre,LJe),e(Jm,xJe),e(Jm,$S),e($S,$Je),e(Jm,kJe),e(A,SJe),e(A,Ym),e(Ym,ete),e(ete,RJe),e(Ym,PJe),e(Ym,kS),e(kS,BJe),e(Ym,IJe),e(A,NJe),e(A,Km),e(Km,ote),e(ote,qJe),e(Km,jJe),e(Km,SS),e(SS,DJe),e(Km,GJe),e(A,OJe),e(A,Zm),e(Zm,rte),e(rte,VJe),e(Zm,XJe),e(Zm,RS),e(RS,zJe),e(Zm,WJe),e(A,QJe),e(A,eg),e(eg,tte),e(tte,HJe),e(eg,UJe),e(eg,PS),e(PS,JJe),e(eg,YJe),e(A,KJe),e(A,og),e(og,ate),e(ate,ZJe),e(og,eYe),e(og,BS),e(BS,oYe),e(og,rYe),e(A,tYe),e(A,rg),e(rg,nte),e(nte,aYe),e(rg,nYe),e(rg,IS),e(IS,sYe),e(rg,lYe),e(A,iYe),e(A,tg),e(tg,ste),e(ste,dYe),e(tg,cYe),e(tg,NS),e(NS,fYe),e(tg,mYe),e(A,gYe),e(A,ag),e(ag,lte),e(lte,hYe),e(ag,pYe),e(ag,qS),e(qS,_Ye),e(ag,uYe),e(A,bYe),e(A,ng),e(ng,ite),e(ite,vYe),e(ng,FYe),e(ng,jS),e(jS,TYe),e(ng,MYe),e(A,EYe),e(A,sg),e(sg,dte),e(dte,CYe),e(sg,wYe),e(sg,DS),e(DS,AYe),e(sg,yYe),e(A,LYe),e(A,lg),e(lg,cte),e(cte,xYe),e(lg,$Ye),e(lg,GS),e(GS,kYe),e(lg,SYe),e(A,RYe),e(A,ig),e(ig,fte),e(fte,PYe),e(ig,BYe),e(ig,OS),e(OS,IYe),e(ig,NYe),e(A,qYe),e(A,dg),e(dg,mte),e(mte,jYe),e(dg,DYe),e(dg,VS),e(VS,GYe),e(dg,OYe),e(A,VYe),e(A,cg),e(cg,gte),e(gte,XYe),e(cg,zYe),e(cg,XS),e(XS,WYe),e(cg,QYe),e(A,HYe),e(A,fg),e(fg,hte),e(hte,UYe),e(fg,JYe),e(fg,zS),e(zS,YYe),e(fg,KYe),e(A,ZYe),e(A,mg),e(mg,pte),e(pte,eKe),e(mg,oKe),e(mg,WS),e(WS,rKe),e(mg,tKe),e(A,aKe),e(A,gg),e(gg,_te),e(_te,nKe),e(gg,sKe),e(gg,QS),e(QS,lKe),e(gg,iKe),e(A,dKe),e(A,hg),e(hg,ute),e(ute,cKe),e(hg,fKe),e(hg,HS),e(HS,mKe),e(hg,gKe),e(A,hKe),e(A,pg),e(pg,bte),e(bte,pKe),e(pg,_Ke),e(pg,US),e(US,uKe),e(pg,bKe),e(A,vKe),e(A,_g),e(_g,vte),e(vte,FKe),e(_g,TKe),e(_g,JS),e(JS,MKe),e(_g,EKe),e(A,CKe),e(A,ug),e(ug,Fte),e(Fte,wKe),e(ug,AKe),e(ug,YS),e(YS,yKe),e(ug,LKe),e(A,xKe),e(A,bg),e(bg,Tte),e(Tte,$Ke),e(bg,kKe),e(bg,KS),e(KS,SKe),e(bg,RKe),e(A,PKe),e(A,vg),e(vg,Mte),e(Mte,BKe),e(vg,IKe),e(vg,ZS),e(ZS,NKe),e(vg,qKe),e(A,jKe),e(A,Fg),e(Fg,Ete),e(Ete,DKe),e(Fg,GKe),e(Fg,eR),e(eR,OKe),e(Fg,VKe),e(A,XKe),e(A,Tg),e(Tg,Cte),e(Cte,zKe),e(Tg,WKe),e(Tg,oR),e(oR,QKe),e(Tg,HKe),e(A,UKe),e(A,Mg),e(Mg,wte),e(wte,JKe),e(Mg,YKe),e(Mg,rR),e(rR,KKe),e(Mg,ZKe),e(A,eZe),e(A,Eg),e(Eg,Ate),e(Ate,oZe),e(Eg,rZe),e(Eg,tR),e(tR,tZe),e(Eg,aZe),e(A,nZe),e(A,Cg),e(Cg,yte),e(yte,sZe),e(Cg,lZe),e(Cg,aR),e(aR,iZe),e(Cg,dZe),e(Er,cZe),M(wg,Er,null),e(Co,fZe),e(Co,Ag),M(qA,Ag,null),e(Ag,mZe),e(Ag,Lte),e(Lte,gZe),b(f,Mqe,u),b(f,Mi,u),e(Mi,yg),e(yg,xte),M(jA,xte,null),e(Mi,hZe),e(Mi,$te),e($te,pZe),b(f,Eqe,u),b(f,wo,u),M(DA,wo,null),e(wo,_Ze),e(wo,GA),e(GA,uZe),e(GA,nR),e(nR,bZe),e(GA,vZe),e(wo,FZe),e(wo,OA),e(OA,TZe),e(OA,kte),e(kte,MZe),e(OA,EZe),e(wo,CZe),e(wo,Cr),M(VA,Cr,null),e(Cr,wZe),e(Cr,Ste),e(Ste,AZe),e(Cr,yZe),e(Cr,Aa),e(Aa,LZe),e(Aa,Rte),e(Rte,xZe),e(Aa,$Ze),e(Aa,Pte),e(Pte,kZe),e(Aa,SZe),e(Aa,Bte),e(Bte,RZe),e(Aa,PZe),e(Cr,BZe),e(Cr,k),e(k,Sn),e(Sn,Ite),e(Ite,IZe),e(Sn,NZe),e(Sn,sR),e(sR,qZe),e(Sn,jZe),e(Sn,lR),e(lR,DZe),e(Sn,GZe),e(k,OZe),e(k,Rn),e(Rn,Nte),e(Nte,VZe),e(Rn,XZe),e(Rn,iR),e(iR,zZe),e(Rn,WZe),e(Rn,dR),e(dR,QZe),e(Rn,HZe),e(k,UZe),e(k,Pn),e(Pn,qte),e(qte,JZe),e(Pn,YZe),e(Pn,cR),e(cR,KZe),e(Pn,ZZe),e(Pn,fR),e(fR,eeo),e(Pn,oeo),e(k,reo),e(k,Lg),e(Lg,jte),e(jte,teo),e(Lg,aeo),e(Lg,mR),e(mR,neo),e(Lg,seo),e(k,leo),e(k,Bn),e(Bn,Dte),e(Dte,ieo),e(Bn,deo),e(Bn,gR),e(gR,ceo),e(Bn,feo),e(Bn,hR),e(hR,meo),e(Bn,geo),e(k,heo),e(k,xg),e(xg,Gte),e(Gte,peo),e(xg,_eo),e(xg,pR),e(pR,ueo),e(xg,beo),e(k,veo),e(k,$g),e($g,Ote),e(Ote,Feo),e($g,Teo),e($g,_R),e(_R,Meo),e($g,Eeo),e(k,Ceo),e(k,kg),e(kg,Vte),e(Vte,weo),e(kg,Aeo),e(kg,uR),e(uR,yeo),e(kg,Leo),e(k,xeo),e(k,In),e(In,Xte),e(Xte,$eo),e(In,keo),e(In,bR),e(bR,Seo),e(In,Reo),e(In,vR),e(vR,Peo),e(In,Beo),e(k,Ieo),e(k,Nn),e(Nn,zte),e(zte,Neo),e(Nn,qeo),e(Nn,FR),e(FR,jeo),e(Nn,Deo),e(Nn,TR),e(TR,Geo),e(Nn,Oeo),e(k,Veo),e(k,qn),e(qn,Wte),e(Wte,Xeo),e(qn,zeo),e(qn,MR),e(MR,Weo),e(qn,Qeo),e(qn,ER),e(ER,Heo),e(qn,Ueo),e(k,Jeo),e(k,Sg),e(Sg,Qte),e(Qte,Yeo),e(Sg,Keo),e(Sg,CR),e(CR,Zeo),e(Sg,eoo),e(k,ooo),e(k,Rg),e(Rg,Hte),e(Hte,roo),e(Rg,too),e(Rg,wR),e(wR,aoo),e(Rg,noo),e(k,soo),e(k,jn),e(jn,Ute),e(Ute,loo),e(jn,ioo),e(jn,AR),e(AR,doo),e(jn,coo),e(jn,yR),e(yR,foo),e(jn,moo),e(k,goo),e(k,Pg),e(Pg,Jte),e(Jte,hoo),e(Pg,poo),e(Pg,LR),e(LR,_oo),e(Pg,uoo),e(k,boo),e(k,Dn),e(Dn,Yte),e(Yte,voo),e(Dn,Foo),e(Dn,xR),e(xR,Too),e(Dn,Moo),e(Dn,$R),e($R,Eoo),e(Dn,Coo),e(k,woo),e(k,Gn),e(Gn,Kte),e(Kte,Aoo),e(Gn,yoo),e(Gn,kR),e(kR,Loo),e(Gn,xoo),e(Gn,SR),e(SR,$oo),e(Gn,koo),e(k,Soo),e(k,On),e(On,Zte),e(Zte,Roo),e(On,Poo),e(On,RR),e(RR,Boo),e(On,Ioo),e(On,PR),e(PR,Noo),e(On,qoo),e(k,joo),e(k,Vn),e(Vn,eae),e(eae,Doo),e(Vn,Goo),e(Vn,BR),e(BR,Ooo),e(Vn,Voo),e(Vn,IR),e(IR,Xoo),e(Vn,zoo),e(k,Woo),e(k,Bg),e(Bg,oae),e(oae,Qoo),e(Bg,Hoo),e(Bg,NR),e(NR,Uoo),e(Bg,Joo),e(k,Yoo),e(k,Xn),e(Xn,rae),e(rae,Koo),e(Xn,Zoo),e(Xn,qR),e(qR,ero),e(Xn,oro),e(Xn,jR),e(jR,rro),e(Xn,tro),e(k,aro),e(k,zn),e(zn,tae),e(tae,nro),e(zn,sro),e(zn,DR),e(DR,lro),e(zn,iro),e(zn,GR),e(GR,dro),e(zn,cro),e(k,fro),e(k,Wn),e(Wn,aae),e(aae,mro),e(Wn,gro),e(Wn,OR),e(OR,hro),e(Wn,pro),e(Wn,VR),e(VR,_ro),e(Wn,uro),e(k,bro),e(k,Qn),e(Qn,nae),e(nae,vro),e(Qn,Fro),e(Qn,XR),e(XR,Tro),e(Qn,Mro),e(Qn,zR),e(zR,Ero),e(Qn,Cro),e(k,wro),e(k,Hn),e(Hn,sae),e(sae,Aro),e(Hn,yro),e(Hn,WR),e(WR,Lro),e(Hn,xro),e(Hn,QR),e(QR,$ro),e(Hn,kro),e(k,Sro),e(k,Un),e(Un,lae),e(lae,Rro),e(Un,Pro),e(Un,HR),e(HR,Bro),e(Un,Iro),e(Un,UR),e(UR,Nro),e(Un,qro),e(k,jro),e(k,Ig),e(Ig,iae),e(iae,Dro),e(Ig,Gro),e(Ig,JR),e(JR,Oro),e(Ig,Vro),e(k,Xro),e(k,Jn),e(Jn,dae),e(dae,zro),e(Jn,Wro),e(Jn,YR),e(YR,Qro),e(Jn,Hro),e(Jn,KR),e(KR,Uro),e(Jn,Jro),e(k,Yro),e(k,Ng),e(Ng,cae),e(cae,Kro),e(Ng,Zro),e(Ng,ZR),e(ZR,eto),e(Ng,oto),e(k,rto),e(k,Yn),e(Yn,fae),e(fae,tto),e(Yn,ato),e(Yn,eP),e(eP,nto),e(Yn,sto),e(Yn,oP),e(oP,lto),e(Yn,ito),e(k,dto),e(k,Kn),e(Kn,mae),e(mae,cto),e(Kn,fto),e(Kn,rP),e(rP,mto),e(Kn,gto),e(Kn,tP),e(tP,hto),e(Kn,pto),e(k,_to),e(k,Zn),e(Zn,gae),e(gae,uto),e(Zn,bto),e(Zn,aP),e(aP,vto),e(Zn,Fto),e(Zn,nP),e(nP,Tto),e(Zn,Mto),e(k,Eto),e(k,qg),e(qg,hae),e(hae,Cto),e(qg,wto),e(qg,sP),e(sP,Ato),e(qg,yto),e(k,Lto),e(k,es),e(es,pae),e(pae,xto),e(es,$to),e(es,lP),e(lP,kto),e(es,Sto),e(es,iP),e(iP,Rto),e(es,Pto),e(k,Bto),e(k,os),e(os,_ae),e(_ae,Ito),e(os,Nto),e(os,dP),e(dP,qto),e(os,jto),e(os,cP),e(cP,Dto),e(os,Gto),e(k,Oto),e(k,jg),e(jg,uae),e(uae,Vto),e(jg,Xto),e(jg,fP),e(fP,zto),e(jg,Wto),e(k,Qto),e(k,rs),e(rs,bae),e(bae,Hto),e(rs,Uto),e(rs,mP),e(mP,Jto),e(rs,Yto),e(rs,gP),e(gP,Kto),e(rs,Zto),e(k,eao),e(k,ts),e(ts,vae),e(vae,oao),e(ts,rao),e(ts,hP),e(hP,tao),e(ts,aao),e(ts,pP),e(pP,nao),e(ts,sao),e(k,lao),e(k,as),e(as,Fae),e(Fae,iao),e(as,dao),e(as,_P),e(_P,cao),e(as,fao),e(as,uP),e(uP,mao),e(as,gao),e(k,hao),e(k,ns),e(ns,Tae),e(Tae,pao),e(ns,_ao),e(ns,bP),e(bP,uao),e(ns,bao),e(ns,vP),e(vP,vao),e(ns,Fao),e(k,Tao),e(k,ss),e(ss,Mae),e(Mae,Mao),e(ss,Eao),e(ss,FP),e(FP,Cao),e(ss,wao),e(ss,TP),e(TP,Aao),e(ss,yao),e(k,Lao),e(k,ls),e(ls,Eae),e(Eae,xao),e(ls,$ao),e(ls,MP),e(MP,kao),e(ls,Sao),e(ls,EP),e(EP,Rao),e(ls,Pao),e(k,Bao),e(k,is),e(is,Cae),e(Cae,Iao),e(is,Nao),e(is,CP),e(CP,qao),e(is,jao),e(is,wP),e(wP,Dao),e(is,Gao),e(k,Oao),e(k,Dg),e(Dg,wae),e(wae,Vao),e(Dg,Xao),e(Dg,AP),e(AP,zao),e(Dg,Wao),e(k,Qao),e(k,ds),e(ds,Aae),e(Aae,Hao),e(ds,Uao),e(ds,yP),e(yP,Jao),e(ds,Yao),e(ds,LP),e(LP,Kao),e(ds,Zao),e(k,eno),e(k,Gg),e(Gg,yae),e(yae,ono),e(Gg,rno),e(Gg,xP),e(xP,tno),e(Gg,ano),e(k,nno),e(k,Og),e(Og,Lae),e(Lae,sno),e(Og,lno),e(Og,$P),e($P,ino),e(Og,dno),e(k,cno),e(k,cs),e(cs,xae),e(xae,fno),e(cs,mno),e(cs,kP),e(kP,gno),e(cs,hno),e(cs,SP),e(SP,pno),e(cs,_no),e(k,uno),e(k,fs),e(fs,$ae),e($ae,bno),e(fs,vno),e(fs,RP),e(RP,Fno),e(fs,Tno),e(fs,PP),e(PP,Mno),e(fs,Eno),e(k,Cno),e(k,ms),e(ms,kae),e(kae,wno),e(ms,Ano),e(ms,BP),e(BP,yno),e(ms,Lno),e(ms,IP),e(IP,xno),e(ms,$no),e(k,kno),e(k,Vg),e(Vg,Sae),e(Sae,Sno),e(Vg,Rno),e(Vg,NP),e(NP,Pno),e(Vg,Bno),e(k,Ino),e(k,gs),e(gs,Rae),e(Rae,Nno),e(gs,qno),e(gs,qP),e(qP,jno),e(gs,Dno),e(gs,jP),e(jP,Gno),e(gs,Ono),e(k,Vno),e(k,hs),e(hs,Pae),e(Pae,Xno),e(hs,zno),e(hs,DP),e(DP,Wno),e(hs,Qno),e(hs,GP),e(GP,Hno),e(hs,Uno),e(k,Jno),e(k,ps),e(ps,Bae),e(Bae,Yno),e(ps,Kno),e(ps,OP),e(OP,Zno),e(ps,eso),e(ps,VP),e(VP,oso),e(ps,rso),e(k,tso),e(k,_s),e(_s,Iae),e(Iae,aso),e(_s,nso),e(_s,XP),e(XP,sso),e(_s,lso),e(_s,zP),e(zP,iso),e(_s,dso),e(k,cso),e(k,us),e(us,Nae),e(Nae,fso),e(us,mso),e(us,WP),e(WP,gso),e(us,hso),e(us,QP),e(QP,pso),e(us,_so),e(k,uso),e(k,Xg),e(Xg,qae),e(qae,bso),e(Xg,vso),e(Xg,HP),e(HP,Fso),e(Xg,Tso),e(k,Mso),e(k,bs),e(bs,jae),e(jae,Eso),e(bs,Cso),e(bs,UP),e(UP,wso),e(bs,Aso),e(bs,JP),e(JP,yso),e(bs,Lso),e(k,xso),e(k,zg),e(zg,Dae),e(Dae,$so),e(zg,kso),e(zg,YP),e(YP,Sso),e(zg,Rso),e(k,Pso),e(k,Wg),e(Wg,Gae),e(Gae,Bso),e(Wg,Iso),e(Wg,KP),e(KP,Nso),e(Wg,qso),e(k,jso),e(k,Qg),e(Qg,Oae),e(Oae,Dso),e(Qg,Gso),e(Qg,ZP),e(ZP,Oso),e(Qg,Vso),e(k,Xso),e(k,Hg),e(Hg,Vae),e(Vae,zso),e(Hg,Wso),e(Hg,eB),e(eB,Qso),e(Hg,Hso),e(k,Uso),e(k,vs),e(vs,Xae),e(Xae,Jso),e(vs,Yso),e(vs,oB),e(oB,Kso),e(vs,Zso),e(vs,rB),e(rB,elo),e(vs,olo),e(k,rlo),e(k,Ug),e(Ug,zae),e(zae,tlo),e(Ug,alo),e(Ug,tB),e(tB,nlo),e(Ug,slo),e(k,llo),e(k,Fs),e(Fs,Wae),e(Wae,ilo),e(Fs,dlo),e(Fs,aB),e(aB,clo),e(Fs,flo),e(Fs,nB),e(nB,mlo),e(Fs,glo),e(k,hlo),e(k,Ts),e(Ts,Qae),e(Qae,plo),e(Ts,_lo),e(Ts,sB),e(sB,ulo),e(Ts,blo),e(Ts,lB),e(lB,vlo),e(Ts,Flo),e(k,Tlo),e(k,Ms),e(Ms,Hae),e(Hae,Mlo),e(Ms,Elo),e(Ms,iB),e(iB,Clo),e(Ms,wlo),e(Ms,dB),e(dB,Alo),e(Ms,ylo),e(k,Llo),e(k,Es),e(Es,Uae),e(Uae,xlo),e(Es,$lo),e(Es,cB),e(cB,klo),e(Es,Slo),e(Es,fB),e(fB,Rlo),e(Es,Plo),e(k,Blo),e(k,Cs),e(Cs,Jae),e(Jae,Ilo),e(Cs,Nlo),e(Cs,mB),e(mB,qlo),e(Cs,jlo),e(Cs,gB),e(gB,Dlo),e(Cs,Glo),e(k,Olo),e(k,ws),e(ws,Yae),e(Yae,Vlo),e(ws,Xlo),e(ws,hB),e(hB,zlo),e(ws,Wlo),e(ws,pB),e(pB,Qlo),e(ws,Hlo),e(k,Ulo),e(k,Jg),e(Jg,Kae),e(Kae,Jlo),e(Jg,Ylo),e(Jg,_B),e(_B,Klo),e(Jg,Zlo),e(k,eio),e(k,Yg),e(Yg,Zae),e(Zae,oio),e(Yg,rio),e(Yg,uB),e(uB,tio),e(Yg,aio),e(k,nio),e(k,As),e(As,ene),e(ene,sio),e(As,lio),e(As,bB),e(bB,iio),e(As,dio),e(As,vB),e(vB,cio),e(As,fio),e(k,mio),e(k,ys),e(ys,one),e(one,gio),e(ys,hio),e(ys,FB),e(FB,pio),e(ys,_io),e(ys,TB),e(TB,uio),e(ys,bio),e(k,vio),e(k,Ls),e(Ls,rne),e(rne,Fio),e(Ls,Tio),e(Ls,MB),e(MB,Mio),e(Ls,Eio),e(Ls,EB),e(EB,Cio),e(Ls,wio),e(k,Aio),e(k,Kg),e(Kg,tne),e(tne,yio),e(Kg,Lio),e(Kg,CB),e(CB,xio),e(Kg,$io),e(k,kio),e(k,Zg),e(Zg,ane),e(ane,Sio),e(Zg,Rio),e(Zg,wB),e(wB,Pio),e(Zg,Bio),e(k,Iio),e(k,eh),e(eh,nne),e(nne,Nio),e(eh,qio),e(eh,AB),e(AB,jio),e(eh,Dio),e(k,Gio),e(k,xs),e(xs,sne),e(sne,Oio),e(xs,Vio),e(xs,yB),e(yB,Xio),e(xs,zio),e(xs,LB),e(LB,Wio),e(xs,Qio),e(k,Hio),e(k,oh),e(oh,lne),e(lne,Uio),e(oh,Jio),e(oh,xB),e(xB,Yio),e(oh,Kio),e(k,Zio),e(k,rh),e(rh,ine),e(ine,edo),e(rh,odo),e(rh,$B),e($B,rdo),e(rh,tdo),e(k,ado),e(k,th),e(th,dne),e(dne,ndo),e(th,sdo),e(th,kB),e(kB,ldo),e(th,ido),e(k,ddo),e(k,$s),e($s,cne),e(cne,cdo),e($s,fdo),e($s,SB),e(SB,mdo),e($s,gdo),e($s,RB),e(RB,hdo),e($s,pdo),e(k,_do),e(k,ah),e(ah,fne),e(fne,udo),e(ah,bdo),e(ah,PB),e(PB,vdo),e(ah,Fdo),e(k,Tdo),e(k,nh),e(nh,mne),e(mne,Mdo),e(nh,Edo),e(nh,BB),e(BB,Cdo),e(nh,wdo),e(k,Ado),e(k,ks),e(ks,gne),e(gne,ydo),e(ks,Ldo),e(ks,IB),e(IB,xdo),e(ks,$do),e(ks,NB),e(NB,kdo),e(ks,Sdo),e(k,Rdo),e(k,Ss),e(Ss,hne),e(hne,Pdo),e(Ss,Bdo),e(Ss,qB),e(qB,Ido),e(Ss,Ndo),e(Ss,jB),e(jB,qdo),e(Ss,jdo),e(k,Ddo),e(k,Rs),e(Rs,pne),e(pne,Gdo),e(Rs,Odo),e(Rs,DB),e(DB,Vdo),e(Rs,Xdo),e(Rs,GB),e(GB,zdo),e(Rs,Wdo),e(k,Qdo),e(k,Ps),e(Ps,_ne),e(_ne,Hdo),e(Ps,Udo),e(Ps,OB),e(OB,Jdo),e(Ps,Ydo),e(Ps,VB),e(VB,Kdo),e(Ps,Zdo),e(Cr,eco),M(sh,Cr,null),e(wo,oco),e(wo,lh),M(XA,lh,null),e(lh,rco),e(lh,une),e(une,tco),b(f,Cqe,u),b(f,Ei,u),e(Ei,ih),e(ih,bne),M(zA,bne,null),e(Ei,aco),e(Ei,vne),e(vne,nco),b(f,wqe,u),b(f,Ao,u),M(WA,Ao,null),e(Ao,sco),e(Ao,QA),e(QA,lco),e(QA,XB),e(XB,ico),e(QA,dco),e(Ao,cco),e(Ao,HA),e(HA,fco),e(HA,Fne),e(Fne,mco),e(HA,gco),e(Ao,hco),e(Ao,He),M(UA,He,null),e(He,pco),e(He,Tne),e(Tne,_co),e(He,uco),e(He,ya),e(ya,bco),e(ya,Mne),e(Mne,vco),e(ya,Fco),e(ya,Ene),e(Ene,Tco),e(ya,Mco),e(ya,Cne),e(Cne,Eco),e(ya,Cco),e(He,wco),e(He,Y),e(Y,dh),e(dh,wne),e(wne,Aco),e(dh,yco),e(dh,zB),e(zB,Lco),e(dh,xco),e(Y,$co),e(Y,ch),e(ch,Ane),e(Ane,kco),e(ch,Sco),e(ch,WB),e(WB,Rco),e(ch,Pco),e(Y,Bco),e(Y,fh),e(fh,yne),e(yne,Ico),e(fh,Nco),e(fh,QB),e(QB,qco),e(fh,jco),e(Y,Dco),e(Y,mh),e(mh,Lne),e(Lne,Gco),e(mh,Oco),e(mh,HB),e(HB,Vco),e(mh,Xco),e(Y,zco),e(Y,gh),e(gh,xne),e(xne,Wco),e(gh,Qco),e(gh,UB),e(UB,Hco),e(gh,Uco),e(Y,Jco),e(Y,hh),e(hh,$ne),e($ne,Yco),e(hh,Kco),e(hh,JB),e(JB,Zco),e(hh,efo),e(Y,ofo),e(Y,ph),e(ph,kne),e(kne,rfo),e(ph,tfo),e(ph,YB),e(YB,afo),e(ph,nfo),e(Y,sfo),e(Y,_h),e(_h,Sne),e(Sne,lfo),e(_h,ifo),e(_h,KB),e(KB,dfo),e(_h,cfo),e(Y,ffo),e(Y,uh),e(uh,Rne),e(Rne,mfo),e(uh,gfo),e(uh,ZB),e(ZB,hfo),e(uh,pfo),e(Y,_fo),e(Y,bh),e(bh,Pne),e(Pne,ufo),e(bh,bfo),e(bh,eI),e(eI,vfo),e(bh,Ffo),e(Y,Tfo),e(Y,vh),e(vh,Bne),e(Bne,Mfo),e(vh,Efo),e(vh,oI),e(oI,Cfo),e(vh,wfo),e(Y,Afo),e(Y,Fh),e(Fh,Ine),e(Ine,yfo),e(Fh,Lfo),e(Fh,rI),e(rI,xfo),e(Fh,$fo),e(Y,kfo),e(Y,Th),e(Th,Nne),e(Nne,Sfo),e(Th,Rfo),e(Th,tI),e(tI,Pfo),e(Th,Bfo),e(Y,Ifo),e(Y,Mh),e(Mh,qne),e(qne,Nfo),e(Mh,qfo),e(Mh,aI),e(aI,jfo),e(Mh,Dfo),e(Y,Gfo),e(Y,Eh),e(Eh,jne),e(jne,Ofo),e(Eh,Vfo),e(Eh,nI),e(nI,Xfo),e(Eh,zfo),e(Y,Wfo),e(Y,Ch),e(Ch,Dne),e(Dne,Qfo),e(Ch,Hfo),e(Ch,sI),e(sI,Ufo),e(Ch,Jfo),e(Y,Yfo),e(Y,wh),e(wh,Gne),e(Gne,Kfo),e(wh,Zfo),e(wh,lI),e(lI,emo),e(wh,omo),e(Y,rmo),e(Y,Ah),e(Ah,One),e(One,tmo),e(Ah,amo),e(Ah,iI),e(iI,nmo),e(Ah,smo),e(Y,lmo),e(Y,yh),e(yh,Vne),e(Vne,imo),e(yh,dmo),e(yh,dI),e(dI,cmo),e(yh,fmo),e(Y,mmo),e(Y,Lh),e(Lh,Xne),e(Xne,gmo),e(Lh,hmo),e(Lh,cI),e(cI,pmo),e(Lh,_mo),e(Y,umo),e(Y,xh),e(xh,zne),e(zne,bmo),e(xh,vmo),e(xh,fI),e(fI,Fmo),e(xh,Tmo),e(Y,Mmo),e(Y,$h),e($h,Wne),e(Wne,Emo),e($h,Cmo),e($h,mI),e(mI,wmo),e($h,Amo),e(Y,ymo),e(Y,kh),e(kh,Qne),e(Qne,Lmo),e(kh,xmo),e(kh,gI),e(gI,$mo),e(kh,kmo),e(Y,Smo),e(Y,Sh),e(Sh,Hne),e(Hne,Rmo),e(Sh,Pmo),e(Sh,hI),e(hI,Bmo),e(Sh,Imo),e(Y,Nmo),e(Y,Rh),e(Rh,Une),e(Une,qmo),e(Rh,jmo),e(Rh,pI),e(pI,Dmo),e(Rh,Gmo),e(Y,Omo),e(Y,Ph),e(Ph,Jne),e(Jne,Vmo),e(Ph,Xmo),e(Ph,_I),e(_I,zmo),e(Ph,Wmo),e(Y,Qmo),e(Y,Bh),e(Bh,Yne),e(Yne,Hmo),e(Bh,Umo),e(Bh,uI),e(uI,Jmo),e(Bh,Ymo),e(Y,Kmo),e(Y,Ih),e(Ih,Kne),e(Kne,Zmo),e(Ih,ego),e(Ih,bI),e(bI,ogo),e(Ih,rgo),e(Y,tgo),e(Y,Nh),e(Nh,Zne),e(Zne,ago),e(Nh,ngo),e(Nh,vI),e(vI,sgo),e(Nh,lgo),e(He,igo),M(qh,He,null),e(He,dgo),M(jh,He,null),e(Ao,cgo),e(Ao,Dh),M(JA,Dh,null),e(Dh,fgo),e(Dh,ese),e(ese,mgo),b(f,Aqe,u),b(f,Ci,u),e(Ci,Gh),e(Gh,ose),M(YA,ose,null),e(Ci,ggo),e(Ci,rse),e(rse,hgo),b(f,yqe,u),b(f,yo,u),M(KA,yo,null),e(yo,pgo),e(yo,ZA),e(ZA,_go),e(ZA,FI),e(FI,ugo),e(ZA,bgo),e(yo,vgo),e(yo,ey),e(ey,Fgo),e(ey,tse),e(tse,Tgo),e(ey,Mgo),e(yo,Ego),e(yo,Ue),M(oy,Ue,null),e(Ue,Cgo),e(Ue,ase),e(ase,wgo),e(Ue,Ago),e(Ue,wi),e(wi,ygo),e(wi,nse),e(nse,Lgo),e(wi,xgo),e(wi,sse),e(sse,$go),e(wi,kgo),e(Ue,Sgo),e(Ue,he),e(he,Oh),e(Oh,lse),e(lse,Rgo),e(Oh,Pgo),e(Oh,TI),e(TI,Bgo),e(Oh,Igo),e(he,Ngo),e(he,Vh),e(Vh,ise),e(ise,qgo),e(Vh,jgo),e(Vh,dse),e(dse,Dgo),e(Vh,Ggo),e(he,Ogo),e(he,Xh),e(Xh,cse),e(cse,Vgo),e(Xh,Xgo),e(Xh,MI),e(MI,zgo),e(Xh,Wgo),e(he,Qgo),e(he,zh),e(zh,fse),e(fse,Hgo),e(zh,Ugo),e(zh,EI),e(EI,Jgo),e(zh,Ygo),e(he,Kgo),e(he,Wh),e(Wh,mse),e(mse,Zgo),e(Wh,eho),e(Wh,CI),e(CI,oho),e(Wh,rho),e(he,tho),e(he,Qh),e(Qh,gse),e(gse,aho),e(Qh,nho),e(Qh,wI),e(wI,sho),e(Qh,lho),e(he,iho),e(he,Hh),e(Hh,hse),e(hse,dho),e(Hh,cho),e(Hh,AI),e(AI,fho),e(Hh,mho),e(he,gho),e(he,Uh),e(Uh,pse),e(pse,hho),e(Uh,pho),e(Uh,yI),e(yI,_ho),e(Uh,uho),e(he,bho),e(he,Jh),e(Jh,_se),e(_se,vho),e(Jh,Fho),e(Jh,LI),e(LI,Tho),e(Jh,Mho),e(he,Eho),e(he,Yh),e(Yh,use),e(use,Cho),e(Yh,who),e(Yh,xI),e(xI,Aho),e(Yh,yho),e(he,Lho),e(he,Kh),e(Kh,bse),e(bse,xho),e(Kh,$ho),e(Kh,$I),e($I,kho),e(Kh,Sho),e(he,Rho),e(he,Zh),e(Zh,vse),e(vse,Pho),e(Zh,Bho),e(Zh,kI),e(kI,Iho),e(Zh,Nho),e(he,qho),e(he,ep),e(ep,Fse),e(Fse,jho),e(ep,Dho),e(ep,SI),e(SI,Gho),e(ep,Oho),e(he,Vho),e(he,op),e(op,Tse),e(Tse,Xho),e(op,zho),e(op,RI),e(RI,Who),e(op,Qho),e(he,Hho),e(he,rp),e(rp,Mse),e(Mse,Uho),e(rp,Jho),e(rp,PI),e(PI,Yho),e(rp,Kho),e(he,Zho),e(he,tp),e(tp,Ese),e(Ese,epo),e(tp,opo),e(tp,BI),e(BI,rpo),e(tp,tpo),e(he,apo),e(he,ap),e(ap,Cse),e(Cse,npo),e(ap,spo),e(ap,II),e(II,lpo),e(ap,ipo),e(Ue,dpo),M(np,Ue,null),e(Ue,cpo),M(sp,Ue,null),e(yo,fpo),e(yo,lp),M(ry,lp,null),e(lp,mpo),e(lp,wse),e(wse,gpo),b(f,Lqe,u),b(f,Ai,u),e(Ai,ip),e(ip,Ase),M(ty,Ase,null),e(Ai,hpo),e(Ai,yse),e(yse,ppo),b(f,xqe,u),b(f,Lo,u),M(ay,Lo,null),e(Lo,_po),e(Lo,yi),e(yi,upo),e(yi,NI),e(NI,bpo),e(yi,vpo),e(yi,qI),e(qI,Fpo),e(yi,Tpo),e(Lo,Mpo),e(Lo,ny),e(ny,Epo),e(ny,Lse),e(Lse,Cpo),e(ny,wpo),e(Lo,Apo),e(Lo,tt),M(sy,tt,null),e(tt,ypo),e(tt,xse),e(xse,Lpo),e(tt,xpo),e(tt,Li),e(Li,$po),e(Li,$se),e($se,kpo),e(Li,Spo),e(Li,jI),e(jI,Rpo),e(Li,Ppo),e(tt,Bpo),M(dp,tt,null),e(Lo,Ipo),e(Lo,Je),M(ly,Je,null),e(Je,Npo),e(Je,kse),e(kse,qpo),e(Je,jpo),e(Je,La),e(La,Dpo),e(La,Sse),e(Sse,Gpo),e(La,Opo),e(La,Rse),e(Rse,Vpo),e(La,Xpo),e(La,Pse),e(Pse,zpo),e(La,Wpo),e(Je,Qpo),e(Je,x),e(x,cp),e(cp,Bse),e(Bse,Hpo),e(cp,Upo),e(cp,DI),e(DI,Jpo),e(cp,Ypo),e(x,Kpo),e(x,fp),e(fp,Ise),e(Ise,Zpo),e(fp,e_o),e(fp,GI),e(GI,o_o),e(fp,r_o),e(x,t_o),e(x,mp),e(mp,Nse),e(Nse,a_o),e(mp,n_o),e(mp,OI),e(OI,s_o),e(mp,l_o),e(x,i_o),e(x,gp),e(gp,qse),e(qse,d_o),e(gp,c_o),e(gp,VI),e(VI,f_o),e(gp,m_o),e(x,g_o),e(x,hp),e(hp,jse),e(jse,h_o),e(hp,p_o),e(hp,XI),e(XI,__o),e(hp,u_o),e(x,b_o),e(x,pp),e(pp,Dse),e(Dse,v_o),e(pp,F_o),e(pp,zI),e(zI,T_o),e(pp,M_o),e(x,E_o),e(x,_p),e(_p,Gse),e(Gse,C_o),e(_p,w_o),e(_p,WI),e(WI,A_o),e(_p,y_o),e(x,L_o),e(x,up),e(up,Ose),e(Ose,x_o),e(up,$_o),e(up,QI),e(QI,k_o),e(up,S_o),e(x,R_o),e(x,bp),e(bp,Vse),e(Vse,P_o),e(bp,B_o),e(bp,HI),e(HI,I_o),e(bp,N_o),e(x,q_o),e(x,vp),e(vp,Xse),e(Xse,j_o),e(vp,D_o),e(vp,UI),e(UI,G_o),e(vp,O_o),e(x,V_o),e(x,Fp),e(Fp,zse),e(zse,X_o),e(Fp,z_o),e(Fp,JI),e(JI,W_o),e(Fp,Q_o),e(x,H_o),e(x,Tp),e(Tp,Wse),e(Wse,U_o),e(Tp,J_o),e(Tp,YI),e(YI,Y_o),e(Tp,K_o),e(x,Z_o),e(x,Mp),e(Mp,Qse),e(Qse,euo),e(Mp,ouo),e(Mp,KI),e(KI,ruo),e(Mp,tuo),e(x,auo),e(x,Ep),e(Ep,Hse),e(Hse,nuo),e(Ep,suo),e(Ep,ZI),e(ZI,luo),e(Ep,iuo),e(x,duo),e(x,Cp),e(Cp,Use),e(Use,cuo),e(Cp,fuo),e(Cp,eN),e(eN,muo),e(Cp,guo),e(x,huo),e(x,wp),e(wp,Jse),e(Jse,puo),e(wp,_uo),e(wp,oN),e(oN,uuo),e(wp,buo),e(x,vuo),e(x,Ap),e(Ap,Yse),e(Yse,Fuo),e(Ap,Tuo),e(Ap,rN),e(rN,Muo),e(Ap,Euo),e(x,Cuo),e(x,yp),e(yp,Kse),e(Kse,wuo),e(yp,Auo),e(yp,tN),e(tN,yuo),e(yp,Luo),e(x,xuo),e(x,Lp),e(Lp,Zse),e(Zse,$uo),e(Lp,kuo),e(Lp,aN),e(aN,Suo),e(Lp,Ruo),e(x,Puo),e(x,xp),e(xp,ele),e(ele,Buo),e(xp,Iuo),e(xp,nN),e(nN,Nuo),e(xp,quo),e(x,juo),e(x,$p),e($p,ole),e(ole,Duo),e($p,Guo),e($p,sN),e(sN,Ouo),e($p,Vuo),e(x,Xuo),e(x,kp),e(kp,rle),e(rle,zuo),e(kp,Wuo),e(kp,lN),e(lN,Quo),e(kp,Huo),e(x,Uuo),e(x,Sp),e(Sp,tle),e(tle,Juo),e(Sp,Yuo),e(Sp,iN),e(iN,Kuo),e(Sp,Zuo),e(x,e4o),e(x,Rp),e(Rp,ale),e(ale,o4o),e(Rp,r4o),e(Rp,dN),e(dN,t4o),e(Rp,a4o),e(x,n4o),e(x,Pp),e(Pp,nle),e(nle,s4o),e(Pp,l4o),e(Pp,cN),e(cN,i4o),e(Pp,d4o),e(x,c4o),e(x,Bp),e(Bp,sle),e(sle,f4o),e(Bp,m4o),e(Bp,fN),e(fN,g4o),e(Bp,h4o),e(x,p4o),e(x,Ip),e(Ip,lle),e(lle,_4o),e(Ip,u4o),e(Ip,mN),e(mN,b4o),e(Ip,v4o),e(x,F4o),e(x,Np),e(Np,ile),e(ile,T4o),e(Np,M4o),e(Np,gN),e(gN,E4o),e(Np,C4o),e(x,w4o),e(x,qp),e(qp,dle),e(dle,A4o),e(qp,y4o),e(qp,hN),e(hN,L4o),e(qp,x4o),e(x,$4o),e(x,jp),e(jp,cle),e(cle,k4o),e(jp,S4o),e(jp,pN),e(pN,R4o),e(jp,P4o),e(x,B4o),e(x,Dp),e(Dp,fle),e(fle,I4o),e(Dp,N4o),e(Dp,_N),e(_N,q4o),e(Dp,j4o),e(x,D4o),e(x,Gp),e(Gp,mle),e(mle,G4o),e(Gp,O4o),e(Gp,uN),e(uN,V4o),e(Gp,X4o),e(x,z4o),e(x,Op),e(Op,gle),e(gle,W4o),e(Op,Q4o),e(Op,bN),e(bN,H4o),e(Op,U4o),e(x,J4o),e(x,Bs),e(Bs,hle),e(hle,Y4o),e(Bs,K4o),e(Bs,vN),e(vN,Z4o),e(Bs,e1o),e(Bs,FN),e(FN,o1o),e(Bs,r1o),e(x,t1o),e(x,Vp),e(Vp,ple),e(ple,a1o),e(Vp,n1o),e(Vp,TN),e(TN,s1o),e(Vp,l1o),e(x,i1o),e(x,Xp),e(Xp,_le),e(_le,d1o),e(Xp,c1o),e(Xp,MN),e(MN,f1o),e(Xp,m1o),e(x,g1o),e(x,zp),e(zp,ule),e(ule,h1o),e(zp,p1o),e(zp,EN),e(EN,_1o),e(zp,u1o),e(x,b1o),e(x,Wp),e(Wp,ble),e(ble,v1o),e(Wp,F1o),e(Wp,CN),e(CN,T1o),e(Wp,M1o),e(x,E1o),e(x,Qp),e(Qp,vle),e(vle,C1o),e(Qp,w1o),e(Qp,wN),e(wN,A1o),e(Qp,y1o),e(x,L1o),e(x,Hp),e(Hp,Fle),e(Fle,x1o),e(Hp,$1o),e(Hp,AN),e(AN,k1o),e(Hp,S1o),e(x,R1o),e(x,Up),e(Up,Tle),e(Tle,P1o),e(Up,B1o),e(Up,yN),e(yN,I1o),e(Up,N1o),e(x,q1o),e(x,Jp),e(Jp,Mle),e(Mle,j1o),e(Jp,D1o),e(Jp,LN),e(LN,G1o),e(Jp,O1o),e(x,V1o),e(x,Yp),e(Yp,Ele),e(Ele,X1o),e(Yp,z1o),e(Yp,xN),e(xN,W1o),e(Yp,Q1o),e(x,H1o),e(x,Kp),e(Kp,Cle),e(Cle,U1o),e(Kp,J1o),e(Kp,$N),e($N,Y1o),e(Kp,K1o),e(x,Z1o),e(x,Zp),e(Zp,wle),e(wle,ebo),e(Zp,obo),e(Zp,kN),e(kN,rbo),e(Zp,tbo),e(x,abo),e(x,e_),e(e_,Ale),e(Ale,nbo),e(e_,sbo),e(e_,SN),e(SN,lbo),e(e_,ibo),e(x,dbo),e(x,o_),e(o_,yle),e(yle,cbo),e(o_,fbo),e(o_,RN),e(RN,mbo),e(o_,gbo),e(x,hbo),e(x,r_),e(r_,Lle),e(Lle,pbo),e(r_,_bo),e(r_,PN),e(PN,ubo),e(r_,bbo),e(x,vbo),e(x,t_),e(t_,xle),e(xle,Fbo),e(t_,Tbo),e(t_,BN),e(BN,Mbo),e(t_,Ebo),e(x,Cbo),e(x,a_),e(a_,$le),e($le,wbo),e(a_,Abo),e(a_,IN),e(IN,ybo),e(a_,Lbo),e(x,xbo),e(x,n_),e(n_,kle),e(kle,$bo),e(n_,kbo),e(n_,NN),e(NN,Sbo),e(n_,Rbo),e(x,Pbo),e(x,s_),e(s_,Sle),e(Sle,Bbo),e(s_,Ibo),e(s_,qN),e(qN,Nbo),e(s_,qbo),e(x,jbo),e(x,l_),e(l_,Rle),e(Rle,Dbo),e(l_,Gbo),e(l_,jN),e(jN,Obo),e(l_,Vbo),e(x,Xbo),e(x,i_),e(i_,Ple),e(Ple,zbo),e(i_,Wbo),e(i_,DN),e(DN,Qbo),e(i_,Hbo),e(x,Ubo),e(x,d_),e(d_,Ble),e(Ble,Jbo),e(d_,Ybo),e(d_,GN),e(GN,Kbo),e(d_,Zbo),e(x,e2o),e(x,c_),e(c_,Ile),e(Ile,o2o),e(c_,r2o),e(c_,ON),e(ON,t2o),e(c_,a2o),e(x,n2o),e(x,f_),e(f_,Nle),e(Nle,s2o),e(f_,l2o),e(f_,VN),e(VN,i2o),e(f_,d2o),e(x,c2o),e(x,m_),e(m_,qle),e(qle,f2o),e(m_,m2o),e(m_,XN),e(XN,g2o),e(m_,h2o),e(x,p2o),e(x,g_),e(g_,jle),e(jle,_2o),e(g_,u2o),e(g_,zN),e(zN,b2o),e(g_,v2o),e(x,F2o),e(x,h_),e(h_,Dle),e(Dle,T2o),e(h_,M2o),e(h_,WN),e(WN,E2o),e(h_,C2o),e(x,w2o),e(x,p_),e(p_,Gle),e(Gle,A2o),e(p_,y2o),e(p_,QN),e(QN,L2o),e(p_,x2o),e(x,$2o),e(x,__),e(__,Ole),e(Ole,k2o),e(__,S2o),e(__,HN),e(HN,R2o),e(__,P2o),e(x,B2o),e(x,u_),e(u_,Vle),e(Vle,I2o),e(u_,N2o),e(u_,UN),e(UN,q2o),e(u_,j2o),e(x,D2o),e(x,b_),e(b_,Xle),e(Xle,G2o),e(b_,O2o),e(b_,JN),e(JN,V2o),e(b_,X2o),e(x,z2o),e(x,v_),e(v_,zle),e(zle,W2o),e(v_,Q2o),e(v_,YN),e(YN,H2o),e(v_,U2o),e(x,J2o),e(x,F_),e(F_,Wle),e(Wle,Y2o),e(F_,K2o),e(F_,KN),e(KN,Z2o),e(F_,evo),e(x,ovo),e(x,T_),e(T_,Qle),e(Qle,rvo),e(T_,tvo),e(T_,ZN),e(ZN,avo),e(T_,nvo),e(x,svo),e(x,M_),e(M_,Hle),e(Hle,lvo),e(M_,ivo),e(M_,eq),e(eq,dvo),e(M_,cvo),e(x,fvo),e(x,E_),e(E_,Ule),e(Ule,mvo),e(E_,gvo),e(E_,oq),e(oq,hvo),e(E_,pvo),e(x,_vo),e(x,C_),e(C_,Jle),e(Jle,uvo),e(C_,bvo),e(C_,rq),e(rq,vvo),e(C_,Fvo),e(x,Tvo),e(x,w_),e(w_,Yle),e(Yle,Mvo),e(w_,Evo),e(w_,tq),e(tq,Cvo),e(w_,wvo),e(x,Avo),e(x,A_),e(A_,Kle),e(Kle,yvo),e(A_,Lvo),e(A_,aq),e(aq,xvo),e(A_,$vo),e(x,kvo),e(x,y_),e(y_,Zle),e(Zle,Svo),e(y_,Rvo),e(y_,nq),e(nq,Pvo),e(y_,Bvo),e(x,Ivo),e(x,L_),e(L_,eie),e(eie,Nvo),e(L_,qvo),e(L_,sq),e(sq,jvo),e(L_,Dvo),e(x,Gvo),e(x,x_),e(x_,oie),e(oie,Ovo),e(x_,Vvo),e(x_,lq),e(lq,Xvo),e(x_,zvo),e(x,Wvo),e(x,$_),e($_,rie),e(rie,Qvo),e($_,Hvo),e($_,iq),e(iq,Uvo),e($_,Jvo),e(x,Yvo),e(x,k_),e(k_,tie),e(tie,Kvo),e(k_,Zvo),e(k_,dq),e(dq,e3o),e(k_,o3o),e(x,r3o),e(x,S_),e(S_,aie),e(aie,t3o),e(S_,a3o),e(S_,cq),e(cq,n3o),e(S_,s3o),e(x,l3o),e(x,R_),e(R_,nie),e(nie,i3o),e(R_,d3o),e(R_,fq),e(fq,c3o),e(R_,f3o),e(x,m3o),e(x,P_),e(P_,sie),e(sie,g3o),e(P_,h3o),e(P_,mq),e(mq,p3o),e(P_,_3o),e(x,u3o),e(x,B_),e(B_,lie),e(lie,b3o),e(B_,v3o),e(B_,gq),e(gq,F3o),e(B_,T3o),e(x,M3o),e(x,I_),e(I_,iie),e(iie,E3o),e(I_,C3o),e(I_,hq),e(hq,w3o),e(I_,A3o),e(x,y3o),e(x,N_),e(N_,die),e(die,L3o),e(N_,x3o),e(N_,pq),e(pq,$3o),e(N_,k3o),e(x,S3o),e(x,q_),e(q_,cie),e(cie,R3o),e(q_,P3o),e(q_,_q),e(_q,B3o),e(q_,I3o),e(x,N3o),e(x,j_),e(j_,fie),e(fie,q3o),e(j_,j3o),e(j_,uq),e(uq,D3o),e(j_,G3o),e(x,O3o),e(x,D_),e(D_,mie),e(mie,V3o),e(D_,X3o),e(D_,bq),e(bq,z3o),e(D_,W3o),e(x,Q3o),e(x,G_),e(G_,gie),e(gie,H3o),e(G_,U3o),e(G_,vq),e(vq,J3o),e(G_,Y3o),e(x,K3o),e(x,O_),e(O_,hie),e(hie,Z3o),e(O_,eFo),e(O_,Fq),e(Fq,oFo),e(O_,rFo),e(x,tFo),e(x,V_),e(V_,pie),e(pie,aFo),e(V_,nFo),e(V_,Tq),e(Tq,sFo),e(V_,lFo),e(x,iFo),e(x,X_),e(X_,_ie),e(_ie,dFo),e(X_,cFo),e(X_,Mq),e(Mq,fFo),e(X_,mFo),e(x,gFo),e(x,z_),e(z_,uie),e(uie,hFo),e(z_,pFo),e(z_,Eq),e(Eq,_Fo),e(z_,uFo),e(x,bFo),e(x,W_),e(W_,bie),e(bie,vFo),e(W_,FFo),e(W_,Cq),e(Cq,TFo),e(W_,MFo),e(x,EFo),e(x,Q_),e(Q_,vie),e(vie,CFo),e(Q_,wFo),e(Q_,wq),e(wq,AFo),e(Q_,yFo),e(x,LFo),e(x,H_),e(H_,Fie),e(Fie,xFo),e(H_,$Fo),e(H_,Aq),e(Aq,kFo),e(H_,SFo),e(x,RFo),e(x,U_),e(U_,Tie),e(Tie,PFo),e(U_,BFo),e(U_,yq),e(yq,IFo),e(U_,NFo),e(x,qFo),e(x,J_),e(J_,Mie),e(Mie,jFo),e(J_,DFo),e(J_,Lq),e(Lq,GFo),e(J_,OFo),e(x,VFo),e(x,Y_),e(Y_,Eie),e(Eie,XFo),e(Y_,zFo),e(Y_,xq),e(xq,WFo),e(Y_,QFo),e(x,HFo),e(x,K_),e(K_,Cie),e(Cie,UFo),e(K_,JFo),e(K_,$q),e($q,YFo),e(K_,KFo),e(x,ZFo),e(x,Z_),e(Z_,wie),e(wie,eTo),e(Z_,oTo),e(Z_,kq),e(kq,rTo),e(Z_,tTo),e(x,aTo),e(x,eu),e(eu,Aie),e(Aie,nTo),e(eu,sTo),e(eu,Sq),e(Sq,lTo),e(eu,iTo),e(x,dTo),e(x,ou),e(ou,yie),e(yie,cTo),e(ou,fTo),e(ou,Rq),e(Rq,mTo),e(ou,gTo),e(x,hTo),e(x,ru),e(ru,Lie),e(Lie,pTo),e(ru,_To),e(ru,Pq),e(Pq,uTo),e(ru,bTo),e(x,vTo),e(x,tu),e(tu,xie),e(xie,FTo),e(tu,TTo),e(tu,Bq),e(Bq,MTo),e(tu,ETo),e(Je,CTo),e(Je,au),e(au,wTo),e(au,$ie),e($ie,ATo),e(au,yTo),e(au,kie),e(kie,LTo),e(Je,xTo),M(nu,Je,null),b(f,$qe,u),b(f,xi,u),e(xi,su),e(su,Sie),M(iy,Sie,null),e(xi,$To),e(xi,Rie),e(Rie,kTo),b(f,kqe,u),b(f,xo,u),M(dy,xo,null),e(xo,STo),e(xo,$i),e($i,RTo),e($i,Iq),e(Iq,PTo),e($i,BTo),e($i,Nq),e(Nq,ITo),e($i,NTo),e(xo,qTo),e(xo,cy),e(cy,jTo),e(cy,Pie),e(Pie,DTo),e(cy,GTo),e(xo,OTo),e(xo,at),M(fy,at,null),e(at,VTo),e(at,Bie),e(Bie,XTo),e(at,zTo),e(at,ki),e(ki,WTo),e(ki,Iie),e(Iie,QTo),e(ki,HTo),e(ki,qq),e(qq,UTo),e(ki,JTo),e(at,YTo),M(lu,at,null),e(xo,KTo),e(xo,Ye),M(my,Ye,null),e(Ye,ZTo),e(Ye,Nie),e(Nie,e7o),e(Ye,o7o),e(Ye,xa),e(xa,r7o),e(xa,qie),e(qie,t7o),e(xa,a7o),e(xa,jie),e(jie,n7o),e(xa,s7o),e(xa,Die),e(Die,l7o),e(xa,i7o),e(Ye,d7o),e(Ye,G),e(G,iu),e(iu,Gie),e(Gie,c7o),e(iu,f7o),e(iu,jq),e(jq,m7o),e(iu,g7o),e(G,h7o),e(G,du),e(du,Oie),e(Oie,p7o),e(du,_7o),e(du,Dq),e(Dq,u7o),e(du,b7o),e(G,v7o),e(G,cu),e(cu,Vie),e(Vie,F7o),e(cu,T7o),e(cu,Gq),e(Gq,M7o),e(cu,E7o),e(G,C7o),e(G,fu),e(fu,Xie),e(Xie,w7o),e(fu,A7o),e(fu,Oq),e(Oq,y7o),e(fu,L7o),e(G,x7o),e(G,mu),e(mu,zie),e(zie,$7o),e(mu,k7o),e(mu,Vq),e(Vq,S7o),e(mu,R7o),e(G,P7o),e(G,gu),e(gu,Wie),e(Wie,B7o),e(gu,I7o),e(gu,Xq),e(Xq,N7o),e(gu,q7o),e(G,j7o),e(G,hu),e(hu,Qie),e(Qie,D7o),e(hu,G7o),e(hu,zq),e(zq,O7o),e(hu,V7o),e(G,X7o),e(G,pu),e(pu,Hie),e(Hie,z7o),e(pu,W7o),e(pu,Wq),e(Wq,Q7o),e(pu,H7o),e(G,U7o),e(G,_u),e(_u,Uie),e(Uie,J7o),e(_u,Y7o),e(_u,Qq),e(Qq,K7o),e(_u,Z7o),e(G,eMo),e(G,uu),e(uu,Jie),e(Jie,oMo),e(uu,rMo),e(uu,Hq),e(Hq,tMo),e(uu,aMo),e(G,nMo),e(G,bu),e(bu,Yie),e(Yie,sMo),e(bu,lMo),e(bu,Uq),e(Uq,iMo),e(bu,dMo),e(G,cMo),e(G,vu),e(vu,Kie),e(Kie,fMo),e(vu,mMo),e(vu,Jq),e(Jq,gMo),e(vu,hMo),e(G,pMo),e(G,Fu),e(Fu,Zie),e(Zie,_Mo),e(Fu,uMo),e(Fu,Yq),e(Yq,bMo),e(Fu,vMo),e(G,FMo),e(G,Tu),e(Tu,ede),e(ede,TMo),e(Tu,MMo),e(Tu,Kq),e(Kq,EMo),e(Tu,CMo),e(G,wMo),e(G,Mu),e(Mu,ode),e(ode,AMo),e(Mu,yMo),e(Mu,Zq),e(Zq,LMo),e(Mu,xMo),e(G,$Mo),e(G,Eu),e(Eu,rde),e(rde,kMo),e(Eu,SMo),e(Eu,ej),e(ej,RMo),e(Eu,PMo),e(G,BMo),e(G,Cu),e(Cu,tde),e(tde,IMo),e(Cu,NMo),e(Cu,oj),e(oj,qMo),e(Cu,jMo),e(G,DMo),e(G,wu),e(wu,ade),e(ade,GMo),e(wu,OMo),e(wu,rj),e(rj,VMo),e(wu,XMo),e(G,zMo),e(G,Au),e(Au,nde),e(nde,WMo),e(Au,QMo),e(Au,tj),e(tj,HMo),e(Au,UMo),e(G,JMo),e(G,yu),e(yu,sde),e(sde,YMo),e(yu,KMo),e(yu,aj),e(aj,ZMo),e(yu,eEo),e(G,oEo),e(G,Lu),e(Lu,lde),e(lde,rEo),e(Lu,tEo),e(Lu,nj),e(nj,aEo),e(Lu,nEo),e(G,sEo),e(G,xu),e(xu,ide),e(ide,lEo),e(xu,iEo),e(xu,sj),e(sj,dEo),e(xu,cEo),e(G,fEo),e(G,$u),e($u,dde),e(dde,mEo),e($u,gEo),e($u,lj),e(lj,hEo),e($u,pEo),e(G,_Eo),e(G,ku),e(ku,cde),e(cde,uEo),e(ku,bEo),e(ku,ij),e(ij,vEo),e(ku,FEo),e(G,TEo),e(G,Su),e(Su,fde),e(fde,MEo),e(Su,EEo),e(Su,dj),e(dj,CEo),e(Su,wEo),e(G,AEo),e(G,Ru),e(Ru,mde),e(mde,yEo),e(Ru,LEo),e(Ru,cj),e(cj,xEo),e(Ru,$Eo),e(G,kEo),e(G,Pu),e(Pu,gde),e(gde,SEo),e(Pu,REo),e(Pu,fj),e(fj,PEo),e(Pu,BEo),e(G,IEo),e(G,Bu),e(Bu,hde),e(hde,NEo),e(Bu,qEo),e(Bu,mj),e(mj,jEo),e(Bu,DEo),e(G,GEo),e(G,Iu),e(Iu,pde),e(pde,OEo),e(Iu,VEo),e(Iu,gj),e(gj,XEo),e(Iu,zEo),e(G,WEo),e(G,Nu),e(Nu,_de),e(_de,QEo),e(Nu,HEo),e(Nu,hj),e(hj,UEo),e(Nu,JEo),e(G,YEo),e(G,qu),e(qu,ude),e(ude,KEo),e(qu,ZEo),e(qu,pj),e(pj,eCo),e(qu,oCo),e(G,rCo),e(G,ju),e(ju,bde),e(bde,tCo),e(ju,aCo),e(ju,_j),e(_j,nCo),e(ju,sCo),e(G,lCo),e(G,Du),e(Du,vde),e(vde,iCo),e(Du,dCo),e(Du,uj),e(uj,cCo),e(Du,fCo),e(G,mCo),e(G,Gu),e(Gu,Fde),e(Fde,gCo),e(Gu,hCo),e(Gu,bj),e(bj,pCo),e(Gu,_Co),e(G,uCo),e(G,Ou),e(Ou,Tde),e(Tde,bCo),e(Ou,vCo),e(Ou,vj),e(vj,FCo),e(Ou,TCo),e(G,MCo),e(G,Vu),e(Vu,Mde),e(Mde,ECo),e(Vu,CCo),e(Vu,Fj),e(Fj,wCo),e(Vu,ACo),e(G,yCo),e(G,Xu),e(Xu,Ede),e(Ede,LCo),e(Xu,xCo),e(Xu,Tj),e(Tj,$Co),e(Xu,kCo),e(G,SCo),e(G,zu),e(zu,Cde),e(Cde,RCo),e(zu,PCo),e(zu,Mj),e(Mj,BCo),e(zu,ICo),e(G,NCo),e(G,Wu),e(Wu,wde),e(wde,qCo),e(Wu,jCo),e(Wu,Ej),e(Ej,DCo),e(Wu,GCo),e(G,OCo),e(G,Qu),e(Qu,Ade),e(Ade,VCo),e(Qu,XCo),e(Qu,Cj),e(Cj,zCo),e(Qu,WCo),e(G,QCo),e(G,Hu),e(Hu,yde),e(yde,HCo),e(Hu,UCo),e(Hu,wj),e(wj,JCo),e(Hu,YCo),e(G,KCo),e(G,Uu),e(Uu,Lde),e(Lde,ZCo),e(Uu,e5o),e(Uu,Aj),e(Aj,o5o),e(Uu,r5o),e(Ye,t5o),e(Ye,Ju),e(Ju,a5o),e(Ju,xde),e(xde,n5o),e(Ju,s5o),e(Ju,$de),e($de,l5o),e(Ye,i5o),M(Yu,Ye,null),b(f,Sqe,u),b(f,Si,u),e(Si,Ku),e(Ku,kde),M(gy,kde,null),e(Si,d5o),e(Si,Sde),e(Sde,c5o),b(f,Rqe,u),b(f,$o,u),M(hy,$o,null),e($o,f5o),e($o,Ri),e(Ri,m5o),e(Ri,yj),e(yj,g5o),e(Ri,h5o),e(Ri,Lj),e(Lj,p5o),e(Ri,_5o),e($o,u5o),e($o,py),e(py,b5o),e(py,Rde),e(Rde,v5o),e(py,F5o),e($o,T5o),e($o,nt),M(_y,nt,null),e(nt,M5o),e(nt,Pde),e(Pde,E5o),e(nt,C5o),e(nt,Pi),e(Pi,w5o),e(Pi,Bde),e(Bde,A5o),e(Pi,y5o),e(Pi,xj),e(xj,L5o),e(Pi,x5o),e(nt,$5o),M(Zu,nt,null),e($o,k5o),e($o,Ke),M(uy,Ke,null),e(Ke,S5o),e(Ke,Ide),e(Ide,R5o),e(Ke,P5o),e(Ke,$a),e($a,B5o),e($a,Nde),e(Nde,I5o),e($a,N5o),e($a,qde),e(qde,q5o),e($a,j5o),e($a,jde),e(jde,D5o),e($a,G5o),e(Ke,O5o),e(Ke,z),e(z,e4),e(e4,Dde),e(Dde,V5o),e(e4,X5o),e(e4,$j),e($j,z5o),e(e4,W5o),e(z,Q5o),e(z,o4),e(o4,Gde),e(Gde,H5o),e(o4,U5o),e(o4,kj),e(kj,J5o),e(o4,Y5o),e(z,K5o),e(z,r4),e(r4,Ode),e(Ode,Z5o),e(r4,ewo),e(r4,Sj),e(Sj,owo),e(r4,rwo),e(z,two),e(z,t4),e(t4,Vde),e(Vde,awo),e(t4,nwo),e(t4,Rj),e(Rj,swo),e(t4,lwo),e(z,iwo),e(z,a4),e(a4,Xde),e(Xde,dwo),e(a4,cwo),e(a4,Pj),e(Pj,fwo),e(a4,mwo),e(z,gwo),e(z,n4),e(n4,zde),e(zde,hwo),e(n4,pwo),e(n4,Bj),e(Bj,_wo),e(n4,uwo),e(z,bwo),e(z,s4),e(s4,Wde),e(Wde,vwo),e(s4,Fwo),e(s4,Ij),e(Ij,Two),e(s4,Mwo),e(z,Ewo),e(z,l4),e(l4,Qde),e(Qde,Cwo),e(l4,wwo),e(l4,Nj),e(Nj,Awo),e(l4,ywo),e(z,Lwo),e(z,i4),e(i4,Hde),e(Hde,xwo),e(i4,$wo),e(i4,qj),e(qj,kwo),e(i4,Swo),e(z,Rwo),e(z,d4),e(d4,Ude),e(Ude,Pwo),e(d4,Bwo),e(d4,jj),e(jj,Iwo),e(d4,Nwo),e(z,qwo),e(z,c4),e(c4,Jde),e(Jde,jwo),e(c4,Dwo),e(c4,Dj),e(Dj,Gwo),e(c4,Owo),e(z,Vwo),e(z,f4),e(f4,Yde),e(Yde,Xwo),e(f4,zwo),e(f4,Gj),e(Gj,Wwo),e(f4,Qwo),e(z,Hwo),e(z,m4),e(m4,Kde),e(Kde,Uwo),e(m4,Jwo),e(m4,Oj),e(Oj,Ywo),e(m4,Kwo),e(z,Zwo),e(z,g4),e(g4,Zde),e(Zde,e0o),e(g4,o0o),e(g4,Vj),e(Vj,r0o),e(g4,t0o),e(z,a0o),e(z,h4),e(h4,ece),e(ece,n0o),e(h4,s0o),e(h4,Xj),e(Xj,l0o),e(h4,i0o),e(z,d0o),e(z,p4),e(p4,oce),e(oce,c0o),e(p4,f0o),e(p4,zj),e(zj,m0o),e(p4,g0o),e(z,h0o),e(z,_4),e(_4,rce),e(rce,p0o),e(_4,_0o),e(_4,Wj),e(Wj,u0o),e(_4,b0o),e(z,v0o),e(z,u4),e(u4,tce),e(tce,F0o),e(u4,T0o),e(u4,Qj),e(Qj,M0o),e(u4,E0o),e(z,C0o),e(z,b4),e(b4,ace),e(ace,w0o),e(b4,A0o),e(b4,Hj),e(Hj,y0o),e(b4,L0o),e(z,x0o),e(z,v4),e(v4,nce),e(nce,$0o),e(v4,k0o),e(v4,Uj),e(Uj,S0o),e(v4,R0o),e(z,P0o),e(z,F4),e(F4,sce),e(sce,B0o),e(F4,I0o),e(F4,Jj),e(Jj,N0o),e(F4,q0o),e(z,j0o),e(z,T4),e(T4,lce),e(lce,D0o),e(T4,G0o),e(T4,Yj),e(Yj,O0o),e(T4,V0o),e(z,X0o),e(z,M4),e(M4,ice),e(ice,z0o),e(M4,W0o),e(M4,Kj),e(Kj,Q0o),e(M4,H0o),e(z,U0o),e(z,E4),e(E4,dce),e(dce,J0o),e(E4,Y0o),e(E4,Zj),e(Zj,K0o),e(E4,Z0o),e(z,e6o),e(z,C4),e(C4,cce),e(cce,o6o),e(C4,r6o),e(C4,eD),e(eD,t6o),e(C4,a6o),e(z,n6o),e(z,w4),e(w4,fce),e(fce,s6o),e(w4,l6o),e(w4,oD),e(oD,i6o),e(w4,d6o),e(z,c6o),e(z,A4),e(A4,mce),e(mce,f6o),e(A4,m6o),e(A4,rD),e(rD,g6o),e(A4,h6o),e(z,p6o),e(z,y4),e(y4,gce),e(gce,_6o),e(y4,u6o),e(y4,tD),e(tD,b6o),e(y4,v6o),e(z,F6o),e(z,L4),e(L4,hce),e(hce,T6o),e(L4,M6o),e(L4,aD),e(aD,E6o),e(L4,C6o),e(z,w6o),e(z,x4),e(x4,pce),e(pce,A6o),e(x4,y6o),e(x4,nD),e(nD,L6o),e(x4,x6o),e(z,$6o),e(z,$4),e($4,_ce),e(_ce,k6o),e($4,S6o),e($4,sD),e(sD,R6o),e($4,P6o),e(z,B6o),e(z,k4),e(k4,uce),e(uce,I6o),e(k4,N6o),e(k4,lD),e(lD,q6o),e(k4,j6o),e(z,D6o),e(z,S4),e(S4,bce),e(bce,G6o),e(S4,O6o),e(S4,iD),e(iD,V6o),e(S4,X6o),e(z,z6o),e(z,R4),e(R4,vce),e(vce,W6o),e(R4,Q6o),e(R4,dD),e(dD,H6o),e(R4,U6o),e(z,J6o),e(z,P4),e(P4,Fce),e(Fce,Y6o),e(P4,K6o),e(P4,cD),e(cD,Z6o),e(P4,eAo),e(z,oAo),e(z,B4),e(B4,Tce),e(Tce,rAo),e(B4,tAo),e(B4,fD),e(fD,aAo),e(B4,nAo),e(z,sAo),e(z,I4),e(I4,Mce),e(Mce,lAo),e(I4,iAo),e(I4,mD),e(mD,dAo),e(I4,cAo),e(z,fAo),e(z,N4),e(N4,Ece),e(Ece,mAo),e(N4,gAo),e(N4,gD),e(gD,hAo),e(N4,pAo),e(Ke,_Ao),e(Ke,q4),e(q4,uAo),e(q4,Cce),e(Cce,bAo),e(q4,vAo),e(q4,wce),e(wce,FAo),e(Ke,TAo),M(j4,Ke,null),b(f,Pqe,u),b(f,Bi,u),e(Bi,D4),e(D4,Ace),M(by,Ace,null),e(Bi,MAo),e(Bi,yce),e(yce,EAo),b(f,Bqe,u),b(f,ko,u),M(vy,ko,null),e(ko,CAo),e(ko,Ii),e(Ii,wAo),e(Ii,hD),e(hD,AAo),e(Ii,yAo),e(Ii,pD),e(pD,LAo),e(Ii,xAo),e(ko,$Ao),e(ko,Fy),e(Fy,kAo),e(Fy,Lce),e(Lce,SAo),e(Fy,RAo),e(ko,PAo),e(ko,st),M(Ty,st,null),e(st,BAo),e(st,xce),e(xce,IAo),e(st,NAo),e(st,Ni),e(Ni,qAo),e(Ni,$ce),e($ce,jAo),e(Ni,DAo),e(Ni,_D),e(_D,GAo),e(Ni,OAo),e(st,VAo),M(G4,st,null),e(ko,XAo),e(ko,Ze),M(My,Ze,null),e(Ze,zAo),e(Ze,kce),e(kce,WAo),e(Ze,QAo),e(Ze,ka),e(ka,HAo),e(ka,Sce),e(Sce,UAo),e(ka,JAo),e(ka,Rce),e(Rce,YAo),e(ka,KAo),e(ka,Pce),e(Pce,ZAo),e(ka,eyo),e(Ze,oyo),e(Ze,Q),e(Q,O4),e(O4,Bce),e(Bce,ryo),e(O4,tyo),e(O4,uD),e(uD,ayo),e(O4,nyo),e(Q,syo),e(Q,V4),e(V4,Ice),e(Ice,lyo),e(V4,iyo),e(V4,bD),e(bD,dyo),e(V4,cyo),e(Q,fyo),e(Q,X4),e(X4,Nce),e(Nce,myo),e(X4,gyo),e(X4,vD),e(vD,hyo),e(X4,pyo),e(Q,_yo),e(Q,z4),e(z4,qce),e(qce,uyo),e(z4,byo),e(z4,FD),e(FD,vyo),e(z4,Fyo),e(Q,Tyo),e(Q,W4),e(W4,jce),e(jce,Myo),e(W4,Eyo),e(W4,TD),e(TD,Cyo),e(W4,wyo),e(Q,Ayo),e(Q,Q4),e(Q4,Dce),e(Dce,yyo),e(Q4,Lyo),e(Q4,MD),e(MD,xyo),e(Q4,$yo),e(Q,kyo),e(Q,H4),e(H4,Gce),e(Gce,Syo),e(H4,Ryo),e(H4,ED),e(ED,Pyo),e(H4,Byo),e(Q,Iyo),e(Q,U4),e(U4,Oce),e(Oce,Nyo),e(U4,qyo),e(U4,CD),e(CD,jyo),e(U4,Dyo),e(Q,Gyo),e(Q,J4),e(J4,Vce),e(Vce,Oyo),e(J4,Vyo),e(J4,wD),e(wD,Xyo),e(J4,zyo),e(Q,Wyo),e(Q,Y4),e(Y4,Xce),e(Xce,Qyo),e(Y4,Hyo),e(Y4,AD),e(AD,Uyo),e(Y4,Jyo),e(Q,Yyo),e(Q,K4),e(K4,zce),e(zce,Kyo),e(K4,Zyo),e(K4,yD),e(yD,eLo),e(K4,oLo),e(Q,rLo),e(Q,Z4),e(Z4,Wce),e(Wce,tLo),e(Z4,aLo),e(Z4,LD),e(LD,nLo),e(Z4,sLo),e(Q,lLo),e(Q,e1),e(e1,Qce),e(Qce,iLo),e(e1,dLo),e(e1,xD),e(xD,cLo),e(e1,fLo),e(Q,mLo),e(Q,o1),e(o1,Hce),e(Hce,gLo),e(o1,hLo),e(o1,$D),e($D,pLo),e(o1,_Lo),e(Q,uLo),e(Q,r1),e(r1,Uce),e(Uce,bLo),e(r1,vLo),e(r1,kD),e(kD,FLo),e(r1,TLo),e(Q,MLo),e(Q,t1),e(t1,Jce),e(Jce,ELo),e(t1,CLo),e(t1,SD),e(SD,wLo),e(t1,ALo),e(Q,yLo),e(Q,a1),e(a1,Yce),e(Yce,LLo),e(a1,xLo),e(a1,RD),e(RD,$Lo),e(a1,kLo),e(Q,SLo),e(Q,n1),e(n1,Kce),e(Kce,RLo),e(n1,PLo),e(n1,PD),e(PD,BLo),e(n1,ILo),e(Q,NLo),e(Q,s1),e(s1,Zce),e(Zce,qLo),e(s1,jLo),e(s1,BD),e(BD,DLo),e(s1,GLo),e(Q,OLo),e(Q,l1),e(l1,efe),e(efe,VLo),e(l1,XLo),e(l1,ID),e(ID,zLo),e(l1,WLo),e(Q,QLo),e(Q,i1),e(i1,ofe),e(ofe,HLo),e(i1,ULo),e(i1,ND),e(ND,JLo),e(i1,YLo),e(Q,KLo),e(Q,d1),e(d1,rfe),e(rfe,ZLo),e(d1,e8o),e(d1,qD),e(qD,o8o),e(d1,r8o),e(Q,t8o),e(Q,c1),e(c1,tfe),e(tfe,a8o),e(c1,n8o),e(c1,jD),e(jD,s8o),e(c1,l8o),e(Q,i8o),e(Q,f1),e(f1,afe),e(afe,d8o),e(f1,c8o),e(f1,DD),e(DD,f8o),e(f1,m8o),e(Q,g8o),e(Q,m1),e(m1,nfe),e(nfe,h8o),e(m1,p8o),e(m1,GD),e(GD,_8o),e(m1,u8o),e(Q,b8o),e(Q,g1),e(g1,sfe),e(sfe,v8o),e(g1,F8o),e(g1,OD),e(OD,T8o),e(g1,M8o),e(Q,E8o),e(Q,h1),e(h1,lfe),e(lfe,C8o),e(h1,w8o),e(h1,VD),e(VD,A8o),e(h1,y8o),e(Q,L8o),e(Q,p1),e(p1,ife),e(ife,x8o),e(p1,$8o),e(p1,XD),e(XD,k8o),e(p1,S8o),e(Q,R8o),e(Q,_1),e(_1,dfe),e(dfe,P8o),e(_1,B8o),e(_1,zD),e(zD,I8o),e(_1,N8o),e(Q,q8o),e(Q,u1),e(u1,cfe),e(cfe,j8o),e(u1,D8o),e(u1,WD),e(WD,G8o),e(u1,O8o),e(Q,V8o),e(Q,b1),e(b1,ffe),e(ffe,X8o),e(b1,z8o),e(b1,mfe),e(mfe,W8o),e(b1,Q8o),e(Q,H8o),e(Q,v1),e(v1,gfe),e(gfe,U8o),e(v1,J8o),e(v1,QD),e(QD,Y8o),e(v1,K8o),e(Q,Z8o),e(Q,F1),e(F1,hfe),e(hfe,e9o),e(F1,o9o),e(F1,HD),e(HD,r9o),e(F1,t9o),e(Q,a9o),e(Q,T1),e(T1,pfe),e(pfe,n9o),e(T1,s9o),e(T1,UD),e(UD,l9o),e(T1,i9o),e(Q,d9o),e(Q,M1),e(M1,_fe),e(_fe,c9o),e(M1,f9o),e(M1,JD),e(JD,m9o),e(M1,g9o),e(Ze,h9o),e(Ze,E1),e(E1,p9o),e(E1,ufe),e(ufe,_9o),e(E1,u9o),e(E1,bfe),e(bfe,b9o),e(Ze,v9o),M(C1,Ze,null),b(f,Iqe,u),b(f,qi,u),e(qi,w1),e(w1,vfe),M(Ey,vfe,null),e(qi,F9o),e(qi,Ffe),e(Ffe,T9o),b(f,Nqe,u),b(f,So,u),M(Cy,So,null),e(So,M9o),e(So,ji),e(ji,E9o),e(ji,YD),e(YD,C9o),e(ji,w9o),e(ji,KD),e(KD,A9o),e(ji,y9o),e(So,L9o),e(So,wy),e(wy,x9o),e(wy,Tfe),e(Tfe,$9o),e(wy,k9o),e(So,S9o),e(So,lt),M(Ay,lt,null),e(lt,R9o),e(lt,Mfe),e(Mfe,P9o),e(lt,B9o),e(lt,Di),e(Di,I9o),e(Di,Efe),e(Efe,N9o),e(Di,q9o),e(Di,ZD),e(ZD,j9o),e(Di,D9o),e(lt,G9o),M(A1,lt,null),e(So,O9o),e(So,eo),M(yy,eo,null),e(eo,V9o),e(eo,Cfe),e(Cfe,X9o),e(eo,z9o),e(eo,Sa),e(Sa,W9o),e(Sa,wfe),e(wfe,Q9o),e(Sa,H9o),e(Sa,Afe),e(Afe,U9o),e(Sa,J9o),e(Sa,yfe),e(yfe,Y9o),e(Sa,K9o),e(eo,Z9o),e(eo,_e),e(_e,y1),e(y1,Lfe),e(Lfe,exo),e(y1,oxo),e(y1,eG),e(eG,rxo),e(y1,txo),e(_e,axo),e(_e,L1),e(L1,xfe),e(xfe,nxo),e(L1,sxo),e(L1,oG),e(oG,lxo),e(L1,ixo),e(_e,dxo),e(_e,x1),e(x1,$fe),e($fe,cxo),e(x1,fxo),e(x1,rG),e(rG,mxo),e(x1,gxo),e(_e,hxo),e(_e,$1),e($1,kfe),e(kfe,pxo),e($1,_xo),e($1,tG),e(tG,uxo),e($1,bxo),e(_e,vxo),e(_e,k1),e(k1,Sfe),e(Sfe,Fxo),e(k1,Txo),e(k1,aG),e(aG,Mxo),e(k1,Exo),e(_e,Cxo),e(_e,S1),e(S1,Rfe),e(Rfe,wxo),e(S1,Axo),e(S1,nG),e(nG,yxo),e(S1,Lxo),e(_e,xxo),e(_e,R1),e(R1,Pfe),e(Pfe,$xo),e(R1,kxo),e(R1,sG),e(sG,Sxo),e(R1,Rxo),e(_e,Pxo),e(_e,P1),e(P1,Bfe),e(Bfe,Bxo),e(P1,Ixo),e(P1,lG),e(lG,Nxo),e(P1,qxo),e(_e,jxo),e(_e,B1),e(B1,Ife),e(Ife,Dxo),e(B1,Gxo),e(B1,iG),e(iG,Oxo),e(B1,Vxo),e(_e,Xxo),e(_e,I1),e(I1,Nfe),e(Nfe,zxo),e(I1,Wxo),e(I1,dG),e(dG,Qxo),e(I1,Hxo),e(_e,Uxo),e(_e,N1),e(N1,qfe),e(qfe,Jxo),e(N1,Yxo),e(N1,cG),e(cG,Kxo),e(N1,Zxo),e(_e,e$o),e(_e,q1),e(q1,jfe),e(jfe,o$o),e(q1,r$o),e(q1,fG),e(fG,t$o),e(q1,a$o),e(_e,n$o),e(_e,j1),e(j1,Dfe),e(Dfe,s$o),e(j1,l$o),e(j1,mG),e(mG,i$o),e(j1,d$o),e(_e,c$o),e(_e,D1),e(D1,Gfe),e(Gfe,f$o),e(D1,m$o),e(D1,gG),e(gG,g$o),e(D1,h$o),e(_e,p$o),e(_e,G1),e(G1,Ofe),e(Ofe,_$o),e(G1,u$o),e(G1,hG),e(hG,b$o),e(G1,v$o),e(_e,F$o),e(_e,O1),e(O1,Vfe),e(Vfe,T$o),e(O1,M$o),e(O1,pG),e(pG,E$o),e(O1,C$o),e(eo,w$o),e(eo,V1),e(V1,A$o),e(V1,Xfe),e(Xfe,y$o),e(V1,L$o),e(V1,zfe),e(zfe,x$o),e(eo,$$o),M(X1,eo,null),b(f,qqe,u),b(f,Gi,u),e(Gi,z1),e(z1,Wfe),M(Ly,Wfe,null),e(Gi,k$o),e(Gi,Qfe),e(Qfe,S$o),b(f,jqe,u),b(f,Ro,u),M(xy,Ro,null),e(Ro,R$o),e(Ro,Oi),e(Oi,P$o),e(Oi,_G),e(_G,B$o),e(Oi,I$o),e(Oi,uG),e(uG,N$o),e(Oi,q$o),e(Ro,j$o),e(Ro,$y),e($y,D$o),e($y,Hfe),e(Hfe,G$o),e($y,O$o),e(Ro,V$o),e(Ro,it),M(ky,it,null),e(it,X$o),e(it,Ufe),e(Ufe,z$o),e(it,W$o),e(it,Vi),e(Vi,Q$o),e(Vi,Jfe),e(Jfe,H$o),e(Vi,U$o),e(Vi,bG),e(bG,J$o),e(Vi,Y$o),e(it,K$o),M(W1,it,null),e(Ro,Z$o),e(Ro,oo),M(Sy,oo,null),e(oo,eko),e(oo,Yfe),e(Yfe,oko),e(oo,rko),e(oo,Ra),e(Ra,tko),e(Ra,Kfe),e(Kfe,ako),e(Ra,nko),e(Ra,Zfe),e(Zfe,sko),e(Ra,lko),e(Ra,eme),e(eme,iko),e(Ra,dko),e(oo,cko),e(oo,N),e(N,Q1),e(Q1,ome),e(ome,fko),e(Q1,mko),e(Q1,vG),e(vG,gko),e(Q1,hko),e(N,pko),e(N,H1),e(H1,rme),e(rme,_ko),e(H1,uko),e(H1,FG),e(FG,bko),e(H1,vko),e(N,Fko),e(N,U1),e(U1,tme),e(tme,Tko),e(U1,Mko),e(U1,TG),e(TG,Eko),e(U1,Cko),e(N,wko),e(N,J1),e(J1,ame),e(ame,Ako),e(J1,yko),e(J1,MG),e(MG,Lko),e(J1,xko),e(N,$ko),e(N,Y1),e(Y1,nme),e(nme,kko),e(Y1,Sko),e(Y1,EG),e(EG,Rko),e(Y1,Pko),e(N,Bko),e(N,K1),e(K1,sme),e(sme,Iko),e(K1,Nko),e(K1,CG),e(CG,qko),e(K1,jko),e(N,Dko),e(N,Z1),e(Z1,lme),e(lme,Gko),e(Z1,Oko),e(Z1,wG),e(wG,Vko),e(Z1,Xko),e(N,zko),e(N,eb),e(eb,ime),e(ime,Wko),e(eb,Qko),e(eb,AG),e(AG,Hko),e(eb,Uko),e(N,Jko),e(N,ob),e(ob,dme),e(dme,Yko),e(ob,Kko),e(ob,yG),e(yG,Zko),e(ob,eSo),e(N,oSo),e(N,rb),e(rb,cme),e(cme,rSo),e(rb,tSo),e(rb,LG),e(LG,aSo),e(rb,nSo),e(N,sSo),e(N,tb),e(tb,fme),e(fme,lSo),e(tb,iSo),e(tb,xG),e(xG,dSo),e(tb,cSo),e(N,fSo),e(N,ab),e(ab,mme),e(mme,mSo),e(ab,gSo),e(ab,$G),e($G,hSo),e(ab,pSo),e(N,_So),e(N,nb),e(nb,gme),e(gme,uSo),e(nb,bSo),e(nb,kG),e(kG,vSo),e(nb,FSo),e(N,TSo),e(N,sb),e(sb,hme),e(hme,MSo),e(sb,ESo),e(sb,SG),e(SG,CSo),e(sb,wSo),e(N,ASo),e(N,lb),e(lb,pme),e(pme,ySo),e(lb,LSo),e(lb,RG),e(RG,xSo),e(lb,$So),e(N,kSo),e(N,ib),e(ib,_me),e(_me,SSo),e(ib,RSo),e(ib,PG),e(PG,PSo),e(ib,BSo),e(N,ISo),e(N,db),e(db,ume),e(ume,NSo),e(db,qSo),e(db,BG),e(BG,jSo),e(db,DSo),e(N,GSo),e(N,cb),e(cb,bme),e(bme,OSo),e(cb,VSo),e(cb,IG),e(IG,XSo),e(cb,zSo),e(N,WSo),e(N,fb),e(fb,vme),e(vme,QSo),e(fb,HSo),e(fb,NG),e(NG,USo),e(fb,JSo),e(N,YSo),e(N,mb),e(mb,Fme),e(Fme,KSo),e(mb,ZSo),e(mb,qG),e(qG,eRo),e(mb,oRo),e(N,rRo),e(N,gb),e(gb,Tme),e(Tme,tRo),e(gb,aRo),e(gb,jG),e(jG,nRo),e(gb,sRo),e(N,lRo),e(N,hb),e(hb,Mme),e(Mme,iRo),e(hb,dRo),e(hb,DG),e(DG,cRo),e(hb,fRo),e(N,mRo),e(N,pb),e(pb,Eme),e(Eme,gRo),e(pb,hRo),e(pb,GG),e(GG,pRo),e(pb,_Ro),e(N,uRo),e(N,_b),e(_b,Cme),e(Cme,bRo),e(_b,vRo),e(_b,OG),e(OG,FRo),e(_b,TRo),e(N,MRo),e(N,ub),e(ub,wme),e(wme,ERo),e(ub,CRo),e(ub,VG),e(VG,wRo),e(ub,ARo),e(N,yRo),e(N,bb),e(bb,Ame),e(Ame,LRo),e(bb,xRo),e(bb,XG),e(XG,$Ro),e(bb,kRo),e(N,SRo),e(N,vb),e(vb,yme),e(yme,RRo),e(vb,PRo),e(vb,zG),e(zG,BRo),e(vb,IRo),e(N,NRo),e(N,Fb),e(Fb,Lme),e(Lme,qRo),e(Fb,jRo),e(Fb,WG),e(WG,DRo),e(Fb,GRo),e(N,ORo),e(N,Tb),e(Tb,xme),e(xme,VRo),e(Tb,XRo),e(Tb,QG),e(QG,zRo),e(Tb,WRo),e(N,QRo),e(N,Mb),e(Mb,$me),e($me,HRo),e(Mb,URo),e(Mb,HG),e(HG,JRo),e(Mb,YRo),e(N,KRo),e(N,Eb),e(Eb,kme),e(kme,ZRo),e(Eb,ePo),e(Eb,UG),e(UG,oPo),e(Eb,rPo),e(N,tPo),e(N,Cb),e(Cb,Sme),e(Sme,aPo),e(Cb,nPo),e(Cb,JG),e(JG,sPo),e(Cb,lPo),e(N,iPo),e(N,wb),e(wb,Rme),e(Rme,dPo),e(wb,cPo),e(wb,YG),e(YG,fPo),e(wb,mPo),e(N,gPo),e(N,Ab),e(Ab,Pme),e(Pme,hPo),e(Ab,pPo),e(Ab,KG),e(KG,_Po),e(Ab,uPo),e(N,bPo),e(N,yb),e(yb,Bme),e(Bme,vPo),e(yb,FPo),e(yb,ZG),e(ZG,TPo),e(yb,MPo),e(N,EPo),e(N,Lb),e(Lb,Ime),e(Ime,CPo),e(Lb,wPo),e(Lb,eO),e(eO,APo),e(Lb,yPo),e(N,LPo),e(N,xb),e(xb,Nme),e(Nme,xPo),e(xb,$Po),e(xb,oO),e(oO,kPo),e(xb,SPo),e(N,RPo),e(N,$b),e($b,qme),e(qme,PPo),e($b,BPo),e($b,rO),e(rO,IPo),e($b,NPo),e(N,qPo),e(N,kb),e(kb,jme),e(jme,jPo),e(kb,DPo),e(kb,tO),e(tO,GPo),e(kb,OPo),e(N,VPo),e(N,Sb),e(Sb,Dme),e(Dme,XPo),e(Sb,zPo),e(Sb,aO),e(aO,WPo),e(Sb,QPo),e(N,HPo),e(N,Rb),e(Rb,Gme),e(Gme,UPo),e(Rb,JPo),e(Rb,nO),e(nO,YPo),e(Rb,KPo),e(N,ZPo),e(N,Pb),e(Pb,Ome),e(Ome,eBo),e(Pb,oBo),e(Pb,sO),e(sO,rBo),e(Pb,tBo),e(N,aBo),e(N,Bb),e(Bb,Vme),e(Vme,nBo),e(Bb,sBo),e(Bb,lO),e(lO,lBo),e(Bb,iBo),e(N,dBo),e(N,Ib),e(Ib,Xme),e(Xme,cBo),e(Ib,fBo),e(Ib,iO),e(iO,mBo),e(Ib,gBo),e(N,hBo),e(N,Nb),e(Nb,zme),e(zme,pBo),e(Nb,_Bo),e(Nb,dO),e(dO,uBo),e(Nb,bBo),e(N,vBo),e(N,qb),e(qb,Wme),e(Wme,FBo),e(qb,TBo),e(qb,cO),e(cO,MBo),e(qb,EBo),e(N,CBo),e(N,jb),e(jb,Qme),e(Qme,wBo),e(jb,ABo),e(jb,fO),e(fO,yBo),e(jb,LBo),e(oo,xBo),e(oo,Db),e(Db,$Bo),e(Db,Hme),e(Hme,kBo),e(Db,SBo),e(Db,Ume),e(Ume,RBo),e(oo,PBo),M(Gb,oo,null),b(f,Dqe,u),b(f,Xi,u),e(Xi,Ob),e(Ob,Jme),M(Ry,Jme,null),e(Xi,BBo),e(Xi,Yme),e(Yme,IBo),b(f,Gqe,u),b(f,Po,u),M(Py,Po,null),e(Po,NBo),e(Po,zi),e(zi,qBo),e(zi,mO),e(mO,jBo),e(zi,DBo),e(zi,gO),e(gO,GBo),e(zi,OBo),e(Po,VBo),e(Po,By),e(By,XBo),e(By,Kme),e(Kme,zBo),e(By,WBo),e(Po,QBo),e(Po,dt),M(Iy,dt,null),e(dt,HBo),e(dt,Zme),e(Zme,UBo),e(dt,JBo),e(dt,Wi),e(Wi,YBo),e(Wi,ege),e(ege,KBo),e(Wi,ZBo),e(Wi,hO),e(hO,eIo),e(Wi,oIo),e(dt,rIo),M(Vb,dt,null),e(Po,tIo),e(Po,ro),M(Ny,ro,null),e(ro,aIo),e(ro,oge),e(oge,nIo),e(ro,sIo),e(ro,Pa),e(Pa,lIo),e(Pa,rge),e(rge,iIo),e(Pa,dIo),e(Pa,tge),e(tge,cIo),e(Pa,fIo),e(Pa,age),e(age,mIo),e(Pa,gIo),e(ro,hIo),e(ro,K),e(K,Xb),e(Xb,nge),e(nge,pIo),e(Xb,_Io),e(Xb,pO),e(pO,uIo),e(Xb,bIo),e(K,vIo),e(K,zb),e(zb,sge),e(sge,FIo),e(zb,TIo),e(zb,_O),e(_O,MIo),e(zb,EIo),e(K,CIo),e(K,Wb),e(Wb,lge),e(lge,wIo),e(Wb,AIo),e(Wb,uO),e(uO,yIo),e(Wb,LIo),e(K,xIo),e(K,Qb),e(Qb,ige),e(ige,$Io),e(Qb,kIo),e(Qb,bO),e(bO,SIo),e(Qb,RIo),e(K,PIo),e(K,Hb),e(Hb,dge),e(dge,BIo),e(Hb,IIo),e(Hb,vO),e(vO,NIo),e(Hb,qIo),e(K,jIo),e(K,Ub),e(Ub,cge),e(cge,DIo),e(Ub,GIo),e(Ub,FO),e(FO,OIo),e(Ub,VIo),e(K,XIo),e(K,Jb),e(Jb,fge),e(fge,zIo),e(Jb,WIo),e(Jb,TO),e(TO,QIo),e(Jb,HIo),e(K,UIo),e(K,Yb),e(Yb,mge),e(mge,JIo),e(Yb,YIo),e(Yb,MO),e(MO,KIo),e(Yb,ZIo),e(K,eNo),e(K,Kb),e(Kb,gge),e(gge,oNo),e(Kb,rNo),e(Kb,EO),e(EO,tNo),e(Kb,aNo),e(K,nNo),e(K,Zb),e(Zb,hge),e(hge,sNo),e(Zb,lNo),e(Zb,CO),e(CO,iNo),e(Zb,dNo),e(K,cNo),e(K,e2),e(e2,pge),e(pge,fNo),e(e2,mNo),e(e2,wO),e(wO,gNo),e(e2,hNo),e(K,pNo),e(K,o2),e(o2,_ge),e(_ge,_No),e(o2,uNo),e(o2,AO),e(AO,bNo),e(o2,vNo),e(K,FNo),e(K,r2),e(r2,uge),e(uge,TNo),e(r2,MNo),e(r2,yO),e(yO,ENo),e(r2,CNo),e(K,wNo),e(K,t2),e(t2,bge),e(bge,ANo),e(t2,yNo),e(t2,LO),e(LO,LNo),e(t2,xNo),e(K,$No),e(K,a2),e(a2,vge),e(vge,kNo),e(a2,SNo),e(a2,xO),e(xO,RNo),e(a2,PNo),e(K,BNo),e(K,n2),e(n2,Fge),e(Fge,INo),e(n2,NNo),e(n2,$O),e($O,qNo),e(n2,jNo),e(K,DNo),e(K,s2),e(s2,Tge),e(Tge,GNo),e(s2,ONo),e(s2,kO),e(kO,VNo),e(s2,XNo),e(K,zNo),e(K,l2),e(l2,Mge),e(Mge,WNo),e(l2,QNo),e(l2,SO),e(SO,HNo),e(l2,UNo),e(K,JNo),e(K,i2),e(i2,Ege),e(Ege,YNo),e(i2,KNo),e(i2,RO),e(RO,ZNo),e(i2,eqo),e(K,oqo),e(K,d2),e(d2,Cge),e(Cge,rqo),e(d2,tqo),e(d2,PO),e(PO,aqo),e(d2,nqo),e(K,sqo),e(K,c2),e(c2,wge),e(wge,lqo),e(c2,iqo),e(c2,BO),e(BO,dqo),e(c2,cqo),e(K,fqo),e(K,f2),e(f2,Age),e(Age,mqo),e(f2,gqo),e(f2,IO),e(IO,hqo),e(f2,pqo),e(K,_qo),e(K,m2),e(m2,yge),e(yge,uqo),e(m2,bqo),e(m2,NO),e(NO,vqo),e(m2,Fqo),e(K,Tqo),e(K,g2),e(g2,Lge),e(Lge,Mqo),e(g2,Eqo),e(g2,qO),e(qO,Cqo),e(g2,wqo),e(K,Aqo),e(K,h2),e(h2,xge),e(xge,yqo),e(h2,Lqo),e(h2,jO),e(jO,xqo),e(h2,$qo),e(K,kqo),e(K,p2),e(p2,$ge),e($ge,Sqo),e(p2,Rqo),e(p2,DO),e(DO,Pqo),e(p2,Bqo),e(K,Iqo),e(K,_2),e(_2,kge),e(kge,Nqo),e(_2,qqo),e(_2,GO),e(GO,jqo),e(_2,Dqo),e(K,Gqo),e(K,u2),e(u2,Sge),e(Sge,Oqo),e(u2,Vqo),e(u2,OO),e(OO,Xqo),e(u2,zqo),e(K,Wqo),e(K,b2),e(b2,Rge),e(Rge,Qqo),e(b2,Hqo),e(b2,VO),e(VO,Uqo),e(b2,Jqo),e(ro,Yqo),e(ro,v2),e(v2,Kqo),e(v2,Pge),e(Pge,Zqo),e(v2,ejo),e(v2,Bge),e(Bge,ojo),e(ro,rjo),M(F2,ro,null),b(f,Oqe,u),b(f,Qi,u),e(Qi,T2),e(T2,Ige),M(qy,Ige,null),e(Qi,tjo),e(Qi,Nge),e(Nge,ajo),b(f,Vqe,u),b(f,Bo,u),M(jy,Bo,null),e(Bo,njo),e(Bo,Hi),e(Hi,sjo),e(Hi,XO),e(XO,ljo),e(Hi,ijo),e(Hi,zO),e(zO,djo),e(Hi,cjo),e(Bo,fjo),e(Bo,Dy),e(Dy,mjo),e(Dy,qge),e(qge,gjo),e(Dy,hjo),e(Bo,pjo),e(Bo,ct),M(Gy,ct,null),e(ct,_jo),e(ct,jge),e(jge,ujo),e(ct,bjo),e(ct,Ui),e(Ui,vjo),e(Ui,Dge),e(Dge,Fjo),e(Ui,Tjo),e(Ui,WO),e(WO,Mjo),e(Ui,Ejo),e(ct,Cjo),M(M2,ct,null),e(Bo,wjo),e(Bo,to),M(Oy,to,null),e(to,Ajo),e(to,Gge),e(Gge,yjo),e(to,Ljo),e(to,Ba),e(Ba,xjo),e(Ba,Oge),e(Oge,$jo),e(Ba,kjo),e(Ba,Vge),e(Vge,Sjo),e(Ba,Rjo),e(Ba,Xge),e(Xge,Pjo),e(Ba,Bjo),e(to,Ijo),e(to,Yr),e(Yr,E2),e(E2,zge),e(zge,Njo),e(E2,qjo),e(E2,QO),e(QO,jjo),e(E2,Djo),e(Yr,Gjo),e(Yr,C2),e(C2,Wge),e(Wge,Ojo),e(C2,Vjo),e(C2,HO),e(HO,Xjo),e(C2,zjo),e(Yr,Wjo),e(Yr,w2),e(w2,Qge),e(Qge,Qjo),e(w2,Hjo),e(w2,UO),e(UO,Ujo),e(w2,Jjo),e(Yr,Yjo),e(Yr,A2),e(A2,Hge),e(Hge,Kjo),e(A2,Zjo),e(A2,JO),e(JO,eDo),e(A2,oDo),e(Yr,rDo),e(Yr,y2),e(y2,Uge),e(Uge,tDo),e(y2,aDo),e(y2,YO),e(YO,nDo),e(y2,sDo),e(to,lDo),e(to,L2),e(L2,iDo),e(L2,Jge),e(Jge,dDo),e(L2,cDo),e(L2,Yge),e(Yge,fDo),e(to,mDo),M(x2,to,null),b(f,Xqe,u),b(f,Ji,u),e(Ji,$2),e($2,Kge),M(Vy,Kge,null),e(Ji,gDo),e(Ji,Zge),e(Zge,hDo),b(f,zqe,u),b(f,Io,u),M(Xy,Io,null),e(Io,pDo),e(Io,Yi),e(Yi,_Do),e(Yi,KO),e(KO,uDo),e(Yi,bDo),e(Yi,ZO),e(ZO,vDo),e(Yi,FDo),e(Io,TDo),e(Io,zy),e(zy,MDo),e(zy,ehe),e(ehe,EDo),e(zy,CDo),e(Io,wDo),e(Io,ft),M(Wy,ft,null),e(ft,ADo),e(ft,ohe),e(ohe,yDo),e(ft,LDo),e(ft,Ki),e(Ki,xDo),e(Ki,rhe),e(rhe,$Do),e(Ki,kDo),e(Ki,eV),e(eV,SDo),e(Ki,RDo),e(ft,PDo),M(k2,ft,null),e(Io,BDo),e(Io,ao),M(Qy,ao,null),e(ao,IDo),e(ao,the),e(the,NDo),e(ao,qDo),e(ao,Ia),e(Ia,jDo),e(Ia,ahe),e(ahe,DDo),e(Ia,GDo),e(Ia,nhe),e(nhe,ODo),e(Ia,VDo),e(Ia,she),e(she,XDo),e(Ia,zDo),e(ao,WDo),e(ao,H),e(H,S2),e(S2,lhe),e(lhe,QDo),e(S2,HDo),e(S2,oV),e(oV,UDo),e(S2,JDo),e(H,YDo),e(H,R2),e(R2,ihe),e(ihe,KDo),e(R2,ZDo),e(R2,rV),e(rV,eGo),e(R2,oGo),e(H,rGo),e(H,P2),e(P2,dhe),e(dhe,tGo),e(P2,aGo),e(P2,tV),e(tV,nGo),e(P2,sGo),e(H,lGo),e(H,B2),e(B2,che),e(che,iGo),e(B2,dGo),e(B2,aV),e(aV,cGo),e(B2,fGo),e(H,mGo),e(H,I2),e(I2,fhe),e(fhe,gGo),e(I2,hGo),e(I2,nV),e(nV,pGo),e(I2,_Go),e(H,uGo),e(H,N2),e(N2,mhe),e(mhe,bGo),e(N2,vGo),e(N2,sV),e(sV,FGo),e(N2,TGo),e(H,MGo),e(H,q2),e(q2,ghe),e(ghe,EGo),e(q2,CGo),e(q2,lV),e(lV,wGo),e(q2,AGo),e(H,yGo),e(H,j2),e(j2,hhe),e(hhe,LGo),e(j2,xGo),e(j2,iV),e(iV,$Go),e(j2,kGo),e(H,SGo),e(H,D2),e(D2,phe),e(phe,RGo),e(D2,PGo),e(D2,dV),e(dV,BGo),e(D2,IGo),e(H,NGo),e(H,G2),e(G2,_he),e(_he,qGo),e(G2,jGo),e(G2,cV),e(cV,DGo),e(G2,GGo),e(H,OGo),e(H,O2),e(O2,uhe),e(uhe,VGo),e(O2,XGo),e(O2,fV),e(fV,zGo),e(O2,WGo),e(H,QGo),e(H,V2),e(V2,bhe),e(bhe,HGo),e(V2,UGo),e(V2,mV),e(mV,JGo),e(V2,YGo),e(H,KGo),e(H,X2),e(X2,vhe),e(vhe,ZGo),e(X2,eOo),e(X2,gV),e(gV,oOo),e(X2,rOo),e(H,tOo),e(H,z2),e(z2,Fhe),e(Fhe,aOo),e(z2,nOo),e(z2,hV),e(hV,sOo),e(z2,lOo),e(H,iOo),e(H,W2),e(W2,The),e(The,dOo),e(W2,cOo),e(W2,pV),e(pV,fOo),e(W2,mOo),e(H,gOo),e(H,Q2),e(Q2,Mhe),e(Mhe,hOo),e(Q2,pOo),e(Q2,_V),e(_V,_Oo),e(Q2,uOo),e(H,bOo),e(H,H2),e(H2,Ehe),e(Ehe,vOo),e(H2,FOo),e(H2,uV),e(uV,TOo),e(H2,MOo),e(H,EOo),e(H,U2),e(U2,Che),e(Che,COo),e(U2,wOo),e(U2,bV),e(bV,AOo),e(U2,yOo),e(H,LOo),e(H,J2),e(J2,whe),e(whe,xOo),e(J2,$Oo),e(J2,vV),e(vV,kOo),e(J2,SOo),e(H,ROo),e(H,Y2),e(Y2,Ahe),e(Ahe,POo),e(Y2,BOo),e(Y2,FV),e(FV,IOo),e(Y2,NOo),e(H,qOo),e(H,K2),e(K2,yhe),e(yhe,jOo),e(K2,DOo),e(K2,TV),e(TV,GOo),e(K2,OOo),e(H,VOo),e(H,Z2),e(Z2,Lhe),e(Lhe,XOo),e(Z2,zOo),e(Z2,MV),e(MV,WOo),e(Z2,QOo),e(H,HOo),e(H,ev),e(ev,xhe),e(xhe,UOo),e(ev,JOo),e(ev,EV),e(EV,YOo),e(ev,KOo),e(H,ZOo),e(H,ov),e(ov,$he),e($he,eVo),e(ov,oVo),e(ov,CV),e(CV,rVo),e(ov,tVo),e(H,aVo),e(H,rv),e(rv,khe),e(khe,nVo),e(rv,sVo),e(rv,wV),e(wV,lVo),e(rv,iVo),e(H,dVo),e(H,tv),e(tv,She),e(She,cVo),e(tv,fVo),e(tv,AV),e(AV,mVo),e(tv,gVo),e(H,hVo),e(H,av),e(av,Rhe),e(Rhe,pVo),e(av,_Vo),e(av,yV),e(yV,uVo),e(av,bVo),e(H,vVo),e(H,nv),e(nv,Phe),e(Phe,FVo),e(nv,TVo),e(nv,LV),e(LV,MVo),e(nv,EVo),e(H,CVo),e(H,sv),e(sv,Bhe),e(Bhe,wVo),e(sv,AVo),e(sv,xV),e(xV,yVo),e(sv,LVo),e(H,xVo),e(H,lv),e(lv,Ihe),e(Ihe,$Vo),e(lv,kVo),e(lv,$V),e($V,SVo),e(lv,RVo),e(H,PVo),e(H,iv),e(iv,Nhe),e(Nhe,BVo),e(iv,IVo),e(iv,kV),e(kV,NVo),e(iv,qVo),e(H,jVo),e(H,dv),e(dv,qhe),e(qhe,DVo),e(dv,GVo),e(dv,SV),e(SV,OVo),e(dv,VVo),e(H,XVo),e(H,cv),e(cv,jhe),e(jhe,zVo),e(cv,WVo),e(cv,RV),e(RV,QVo),e(cv,HVo),e(H,UVo),e(H,fv),e(fv,Dhe),e(Dhe,JVo),e(fv,YVo),e(fv,PV),e(PV,KVo),e(fv,ZVo),e(ao,eXo),e(ao,mv),e(mv,oXo),e(mv,Ghe),e(Ghe,rXo),e(mv,tXo),e(mv,Ohe),e(Ohe,aXo),e(ao,nXo),M(gv,ao,null),b(f,Wqe,u),b(f,Zi,u),e(Zi,hv),e(hv,Vhe),M(Hy,Vhe,null),e(Zi,sXo),e(Zi,Xhe),e(Xhe,lXo),b(f,Qqe,u),b(f,No,u),M(Uy,No,null),e(No,iXo),e(No,ed),e(ed,dXo),e(ed,BV),e(BV,cXo),e(ed,fXo),e(ed,IV),e(IV,mXo),e(ed,gXo),e(No,hXo),e(No,Jy),e(Jy,pXo),e(Jy,zhe),e(zhe,_Xo),e(Jy,uXo),e(No,bXo),e(No,mt),M(Yy,mt,null),e(mt,vXo),e(mt,Whe),e(Whe,FXo),e(mt,TXo),e(mt,od),e(od,MXo),e(od,Qhe),e(Qhe,EXo),e(od,CXo),e(od,NV),e(NV,wXo),e(od,AXo),e(mt,yXo),M(pv,mt,null),e(No,LXo),e(No,no),M(Ky,no,null),e(no,xXo),e(no,Hhe),e(Hhe,$Xo),e(no,kXo),e(no,Na),e(Na,SXo),e(Na,Uhe),e(Uhe,RXo),e(Na,PXo),e(Na,Jhe),e(Jhe,BXo),e(Na,IXo),e(Na,Yhe),e(Yhe,NXo),e(Na,qXo),e(no,jXo),e(no,V),e(V,_v),e(_v,Khe),e(Khe,DXo),e(_v,GXo),e(_v,qV),e(qV,OXo),e(_v,VXo),e(V,XXo),e(V,uv),e(uv,Zhe),e(Zhe,zXo),e(uv,WXo),e(uv,jV),e(jV,QXo),e(uv,HXo),e(V,UXo),e(V,bv),e(bv,epe),e(epe,JXo),e(bv,YXo),e(bv,DV),e(DV,KXo),e(bv,ZXo),e(V,ezo),e(V,vv),e(vv,ope),e(ope,ozo),e(vv,rzo),e(vv,GV),e(GV,tzo),e(vv,azo),e(V,nzo),e(V,Fv),e(Fv,rpe),e(rpe,szo),e(Fv,lzo),e(Fv,OV),e(OV,izo),e(Fv,dzo),e(V,czo),e(V,Tv),e(Tv,tpe),e(tpe,fzo),e(Tv,mzo),e(Tv,VV),e(VV,gzo),e(Tv,hzo),e(V,pzo),e(V,Mv),e(Mv,ape),e(ape,_zo),e(Mv,uzo),e(Mv,XV),e(XV,bzo),e(Mv,vzo),e(V,Fzo),e(V,Ev),e(Ev,npe),e(npe,Tzo),e(Ev,Mzo),e(Ev,zV),e(zV,Ezo),e(Ev,Czo),e(V,wzo),e(V,Cv),e(Cv,spe),e(spe,Azo),e(Cv,yzo),e(Cv,WV),e(WV,Lzo),e(Cv,xzo),e(V,$zo),e(V,wv),e(wv,lpe),e(lpe,kzo),e(wv,Szo),e(wv,QV),e(QV,Rzo),e(wv,Pzo),e(V,Bzo),e(V,Av),e(Av,ipe),e(ipe,Izo),e(Av,Nzo),e(Av,HV),e(HV,qzo),e(Av,jzo),e(V,Dzo),e(V,yv),e(yv,dpe),e(dpe,Gzo),e(yv,Ozo),e(yv,UV),e(UV,Vzo),e(yv,Xzo),e(V,zzo),e(V,Lv),e(Lv,cpe),e(cpe,Wzo),e(Lv,Qzo),e(Lv,JV),e(JV,Hzo),e(Lv,Uzo),e(V,Jzo),e(V,xv),e(xv,fpe),e(fpe,Yzo),e(xv,Kzo),e(xv,YV),e(YV,Zzo),e(xv,eWo),e(V,oWo),e(V,$v),e($v,mpe),e(mpe,rWo),e($v,tWo),e($v,KV),e(KV,aWo),e($v,nWo),e(V,sWo),e(V,kv),e(kv,gpe),e(gpe,lWo),e(kv,iWo),e(kv,ZV),e(ZV,dWo),e(kv,cWo),e(V,fWo),e(V,Sv),e(Sv,hpe),e(hpe,mWo),e(Sv,gWo),e(Sv,eX),e(eX,hWo),e(Sv,pWo),e(V,_Wo),e(V,Rv),e(Rv,ppe),e(ppe,uWo),e(Rv,bWo),e(Rv,oX),e(oX,vWo),e(Rv,FWo),e(V,TWo),e(V,Pv),e(Pv,_pe),e(_pe,MWo),e(Pv,EWo),e(Pv,rX),e(rX,CWo),e(Pv,wWo),e(V,AWo),e(V,Bv),e(Bv,upe),e(upe,yWo),e(Bv,LWo),e(Bv,tX),e(tX,xWo),e(Bv,$Wo),e(V,kWo),e(V,Iv),e(Iv,bpe),e(bpe,SWo),e(Iv,RWo),e(Iv,aX),e(aX,PWo),e(Iv,BWo),e(V,IWo),e(V,Nv),e(Nv,vpe),e(vpe,NWo),e(Nv,qWo),e(Nv,nX),e(nX,jWo),e(Nv,DWo),e(V,GWo),e(V,qv),e(qv,Fpe),e(Fpe,OWo),e(qv,VWo),e(qv,sX),e(sX,XWo),e(qv,zWo),e(V,WWo),e(V,jv),e(jv,Tpe),e(Tpe,QWo),e(jv,HWo),e(jv,lX),e(lX,UWo),e(jv,JWo),e(V,YWo),e(V,Dv),e(Dv,Mpe),e(Mpe,KWo),e(Dv,ZWo),e(Dv,iX),e(iX,eQo),e(Dv,oQo),e(V,rQo),e(V,Gv),e(Gv,Epe),e(Epe,tQo),e(Gv,aQo),e(Gv,dX),e(dX,nQo),e(Gv,sQo),e(V,lQo),e(V,Ov),e(Ov,Cpe),e(Cpe,iQo),e(Ov,dQo),e(Ov,cX),e(cX,cQo),e(Ov,fQo),e(V,mQo),e(V,Vv),e(Vv,wpe),e(wpe,gQo),e(Vv,hQo),e(Vv,fX),e(fX,pQo),e(Vv,_Qo),e(V,uQo),e(V,Xv),e(Xv,Ape),e(Ape,bQo),e(Xv,vQo),e(Xv,mX),e(mX,FQo),e(Xv,TQo),e(V,MQo),e(V,zv),e(zv,ype),e(ype,EQo),e(zv,CQo),e(zv,gX),e(gX,wQo),e(zv,AQo),e(V,yQo),e(V,Wv),e(Wv,Lpe),e(Lpe,LQo),e(Wv,xQo),e(Wv,hX),e(hX,$Qo),e(Wv,kQo),e(V,SQo),e(V,Qv),e(Qv,xpe),e(xpe,RQo),e(Qv,PQo),e(Qv,pX),e(pX,BQo),e(Qv,IQo),e(V,NQo),e(V,Hv),e(Hv,$pe),e($pe,qQo),e(Hv,jQo),e(Hv,_X),e(_X,DQo),e(Hv,GQo),e(V,OQo),e(V,Uv),e(Uv,kpe),e(kpe,VQo),e(Uv,XQo),e(Uv,uX),e(uX,zQo),e(Uv,WQo),e(V,QQo),e(V,Jv),e(Jv,Spe),e(Spe,HQo),e(Jv,UQo),e(Jv,bX),e(bX,JQo),e(Jv,YQo),e(V,KQo),e(V,Yv),e(Yv,Rpe),e(Rpe,ZQo),e(Yv,eHo),e(Yv,vX),e(vX,oHo),e(Yv,rHo),e(V,tHo),e(V,Kv),e(Kv,Ppe),e(Ppe,aHo),e(Kv,nHo),e(Kv,FX),e(FX,sHo),e(Kv,lHo),e(V,iHo),e(V,Zv),e(Zv,Bpe),e(Bpe,dHo),e(Zv,cHo),e(Zv,TX),e(TX,fHo),e(Zv,mHo),e(V,gHo),e(V,e3),e(e3,Ipe),e(Ipe,hHo),e(e3,pHo),e(e3,MX),e(MX,_Ho),e(e3,uHo),e(V,bHo),e(V,o3),e(o3,Npe),e(Npe,vHo),e(o3,FHo),e(o3,EX),e(EX,THo),e(o3,MHo),e(no,EHo),e(no,r3),e(r3,CHo),e(r3,qpe),e(qpe,wHo),e(r3,AHo),e(r3,jpe),e(jpe,yHo),e(no,LHo),M(t3,no,null),b(f,Hqe,u),b(f,rd,u),e(rd,a3),e(a3,Dpe),M(Zy,Dpe,null),e(rd,xHo),e(rd,Gpe),e(Gpe,$Ho),b(f,Uqe,u),b(f,qo,u),M(eL,qo,null),e(qo,kHo),e(qo,td),e(td,SHo),e(td,CX),e(CX,RHo),e(td,PHo),e(td,wX),e(wX,BHo),e(td,IHo),e(qo,NHo),e(qo,oL),e(oL,qHo),e(oL,Ope),e(Ope,jHo),e(oL,DHo),e(qo,GHo),e(qo,gt),M(rL,gt,null),e(gt,OHo),e(gt,Vpe),e(Vpe,VHo),e(gt,XHo),e(gt,ad),e(ad,zHo),e(ad,Xpe),e(Xpe,WHo),e(ad,QHo),e(ad,AX),e(AX,HHo),e(ad,UHo),e(gt,JHo),M(n3,gt,null),e(qo,YHo),e(qo,so),M(tL,so,null),e(so,KHo),e(so,zpe),e(zpe,ZHo),e(so,eUo),e(so,qa),e(qa,oUo),e(qa,Wpe),e(Wpe,rUo),e(qa,tUo),e(qa,Qpe),e(Qpe,aUo),e(qa,nUo),e(qa,Hpe),e(Hpe,sUo),e(qa,lUo),e(so,iUo),e(so,Upe),e(Upe,s3),e(s3,Jpe),e(Jpe,dUo),e(s3,cUo),e(s3,yX),e(yX,fUo),e(s3,mUo),e(so,gUo),e(so,l3),e(l3,hUo),e(l3,Ype),e(Ype,pUo),e(l3,_Uo),e(l3,Kpe),e(Kpe,uUo),e(so,bUo),M(i3,so,null),b(f,Jqe,u),b(f,nd,u),e(nd,d3),e(d3,Zpe),M(aL,Zpe,null),e(nd,vUo),e(nd,e_e),e(e_e,FUo),b(f,Yqe,u),b(f,jo,u),M(nL,jo,null),e(jo,TUo),e(jo,sd),e(sd,MUo),e(sd,LX),e(LX,EUo),e(sd,CUo),e(sd,xX),e(xX,wUo),e(sd,AUo),e(jo,yUo),e(jo,sL),e(sL,LUo),e(sL,o_e),e(o_e,xUo),e(sL,$Uo),e(jo,kUo),e(jo,ht),M(lL,ht,null),e(ht,SUo),e(ht,r_e),e(r_e,RUo),e(ht,PUo),e(ht,ld),e(ld,BUo),e(ld,t_e),e(t_e,IUo),e(ld,NUo),e(ld,$X),e($X,qUo),e(ld,jUo),e(ht,DUo),M(c3,ht,null),e(jo,GUo),e(jo,lo),M(iL,lo,null),e(lo,OUo),e(lo,a_e),e(a_e,VUo),e(lo,XUo),e(lo,ja),e(ja,zUo),e(ja,n_e),e(n_e,WUo),e(ja,QUo),e(ja,s_e),e(s_e,HUo),e(ja,UUo),e(ja,l_e),e(l_e,JUo),e(ja,YUo),e(lo,KUo),e(lo,Fe),e(Fe,f3),e(f3,i_e),e(i_e,ZUo),e(f3,eJo),e(f3,kX),e(kX,oJo),e(f3,rJo),e(Fe,tJo),e(Fe,m3),e(m3,d_e),e(d_e,aJo),e(m3,nJo),e(m3,SX),e(SX,sJo),e(m3,lJo),e(Fe,iJo),e(Fe,g3),e(g3,c_e),e(c_e,dJo),e(g3,cJo),e(g3,RX),e(RX,fJo),e(g3,mJo),e(Fe,gJo),e(Fe,h3),e(h3,f_e),e(f_e,hJo),e(h3,pJo),e(h3,PX),e(PX,_Jo),e(h3,uJo),e(Fe,bJo),e(Fe,Is),e(Is,m_e),e(m_e,vJo),e(Is,FJo),e(Is,BX),e(BX,TJo),e(Is,MJo),e(Is,IX),e(IX,EJo),e(Is,CJo),e(Fe,wJo),e(Fe,p3),e(p3,g_e),e(g_e,AJo),e(p3,yJo),e(p3,NX),e(NX,LJo),e(p3,xJo),e(Fe,$Jo),e(Fe,pt),e(pt,h_e),e(h_e,kJo),e(pt,SJo),e(pt,qX),e(qX,RJo),e(pt,PJo),e(pt,jX),e(jX,BJo),e(pt,IJo),e(pt,DX),e(DX,NJo),e(pt,qJo),e(Fe,jJo),e(Fe,_3),e(_3,p_e),e(p_e,DJo),e(_3,GJo),e(_3,GX),e(GX,OJo),e(_3,VJo),e(Fe,XJo),e(Fe,u3),e(u3,__e),e(__e,zJo),e(u3,WJo),e(u3,OX),e(OX,QJo),e(u3,HJo),e(Fe,UJo),e(Fe,b3),e(b3,u_e),e(u_e,JJo),e(b3,YJo),e(b3,VX),e(VX,KJo),e(b3,ZJo),e(Fe,eYo),e(Fe,v3),e(v3,b_e),e(b_e,oYo),e(v3,rYo),e(v3,XX),e(XX,tYo),e(v3,aYo),e(Fe,nYo),e(Fe,F3),e(F3,v_e),e(v_e,sYo),e(F3,lYo),e(F3,zX),e(zX,iYo),e(F3,dYo),e(Fe,cYo),e(Fe,T3),e(T3,F_e),e(F_e,fYo),e(T3,mYo),e(T3,WX),e(WX,gYo),e(T3,hYo),e(Fe,pYo),e(Fe,M3),e(M3,T_e),e(T_e,_Yo),e(M3,uYo),e(M3,QX),e(QX,bYo),e(M3,vYo),e(lo,FYo),e(lo,E3),e(E3,TYo),e(E3,M_e),e(M_e,MYo),e(E3,EYo),e(E3,E_e),e(E_e,CYo),e(lo,wYo),M(C3,lo,null),b(f,Kqe,u),b(f,id,u),e(id,w3),e(w3,C_e),M(dL,C_e,null),e(id,AYo),e(id,w_e),e(w_e,yYo),b(f,Zqe,u),b(f,Do,u),M(cL,Do,null),e(Do,LYo),e(Do,dd),e(dd,xYo),e(dd,HX),e(HX,$Yo),e(dd,kYo),e(dd,UX),e(UX,SYo),e(dd,RYo),e(Do,PYo),e(Do,fL),e(fL,BYo),e(fL,A_e),e(A_e,IYo),e(fL,NYo),e(Do,qYo),e(Do,_t),M(mL,_t,null),e(_t,jYo),e(_t,y_e),e(y_e,DYo),e(_t,GYo),e(_t,cd),e(cd,OYo),e(cd,L_e),e(L_e,VYo),e(cd,XYo),e(cd,JX),e(JX,zYo),e(cd,WYo),e(_t,QYo),M(A3,_t,null),e(Do,HYo),e(Do,io),M(gL,io,null),e(io,UYo),e(io,x_e),e(x_e,JYo),e(io,YYo),e(io,Da),e(Da,KYo),e(Da,$_e),e($_e,ZYo),e(Da,eKo),e(Da,k_e),e(k_e,oKo),e(Da,rKo),e(Da,S_e),e(S_e,tKo),e(Da,aKo),e(io,nKo),e(io,R_e),e(R_e,y3),e(y3,P_e),e(P_e,sKo),e(y3,lKo),e(y3,YX),e(YX,iKo),e(y3,dKo),e(io,cKo),e(io,L3),e(L3,fKo),e(L3,B_e),e(B_e,mKo),e(L3,gKo),e(L3,I_e),e(I_e,hKo),e(io,pKo),M(x3,io,null),b(f,eje,u),b(f,fd,u),e(fd,$3),e($3,N_e),M(hL,N_e,null),e(fd,_Ko),e(fd,q_e),e(q_e,uKo),b(f,oje,u),b(f,Go,u),M(pL,Go,null),e(Go,bKo),e(Go,md),e(md,vKo),e(md,KX),e(KX,FKo),e(md,TKo),e(md,ZX),e(ZX,MKo),e(md,EKo),e(Go,CKo),e(Go,_L),e(_L,wKo),e(_L,j_e),e(j_e,AKo),e(_L,yKo),e(Go,LKo),e(Go,ut),M(uL,ut,null),e(ut,xKo),e(ut,D_e),e(D_e,$Ko),e(ut,kKo),e(ut,gd),e(gd,SKo),e(gd,G_e),e(G_e,RKo),e(gd,PKo),e(gd,ez),e(ez,BKo),e(gd,IKo),e(ut,NKo),M(k3,ut,null),e(Go,qKo),e(Go,co),M(bL,co,null),e(co,jKo),e(co,O_e),e(O_e,DKo),e(co,GKo),e(co,Ga),e(Ga,OKo),e(Ga,V_e),e(V_e,VKo),e(Ga,XKo),e(Ga,X_e),e(X_e,zKo),e(Ga,WKo),e(Ga,z_e),e(z_e,QKo),e(Ga,HKo),e(co,UKo),e(co,ke),e(ke,S3),e(S3,W_e),e(W_e,JKo),e(S3,YKo),e(S3,oz),e(oz,KKo),e(S3,ZKo),e(ke,eZo),e(ke,R3),e(R3,Q_e),e(Q_e,oZo),e(R3,rZo),e(R3,rz),e(rz,tZo),e(R3,aZo),e(ke,nZo),e(ke,P3),e(P3,H_e),e(H_e,sZo),e(P3,lZo),e(P3,tz),e(tz,iZo),e(P3,dZo),e(ke,cZo),e(ke,B3),e(B3,U_e),e(U_e,fZo),e(B3,mZo),e(B3,az),e(az,gZo),e(B3,hZo),e(ke,pZo),e(ke,I3),e(I3,J_e),e(J_e,_Zo),e(I3,uZo),e(I3,nz),e(nz,bZo),e(I3,vZo),e(ke,FZo),e(ke,N3),e(N3,Y_e),e(Y_e,TZo),e(N3,MZo),e(N3,sz),e(sz,EZo),e(N3,CZo),e(ke,wZo),e(ke,q3),e(q3,K_e),e(K_e,AZo),e(q3,yZo),e(q3,lz),e(lz,LZo),e(q3,xZo),e(ke,$Zo),e(ke,j3),e(j3,Z_e),e(Z_e,kZo),e(j3,SZo),e(j3,iz),e(iz,RZo),e(j3,PZo),e(ke,BZo),e(ke,D3),e(D3,eue),e(eue,IZo),e(D3,NZo),e(D3,dz),e(dz,qZo),e(D3,jZo),e(co,DZo),e(co,G3),e(G3,GZo),e(G3,oue),e(oue,OZo),e(G3,VZo),e(G3,rue),e(rue,XZo),e(co,zZo),M(O3,co,null),b(f,rje,u),b(f,hd,u),e(hd,V3),e(V3,tue),M(vL,tue,null),e(hd,WZo),e(hd,aue),e(aue,QZo),b(f,tje,u),b(f,Oo,u),M(FL,Oo,null),e(Oo,HZo),e(Oo,pd),e(pd,UZo),e(pd,cz),e(cz,JZo),e(pd,YZo),e(pd,fz),e(fz,KZo),e(pd,ZZo),e(Oo,eer),e(Oo,TL),e(TL,oer),e(TL,nue),e(nue,rer),e(TL,ter),e(Oo,aer),e(Oo,bt),M(ML,bt,null),e(bt,ner),e(bt,sue),e(sue,ser),e(bt,ler),e(bt,_d),e(_d,ier),e(_d,lue),e(lue,der),e(_d,cer),e(_d,mz),e(mz,fer),e(_d,mer),e(bt,ger),M(X3,bt,null),e(Oo,her),e(Oo,fo),M(EL,fo,null),e(fo,per),e(fo,iue),e(iue,_er),e(fo,uer),e(fo,Oa),e(Oa,ber),e(Oa,due),e(due,ver),e(Oa,Fer),e(Oa,cue),e(cue,Ter),e(Oa,Mer),e(Oa,fue),e(fue,Eer),e(Oa,Cer),e(fo,wer),e(fo,Kr),e(Kr,z3),e(z3,mue),e(mue,Aer),e(z3,yer),e(z3,gz),e(gz,Ler),e(z3,xer),e(Kr,$er),e(Kr,W3),e(W3,gue),e(gue,ker),e(W3,Ser),e(W3,hz),e(hz,Rer),e(W3,Per),e(Kr,Ber),e(Kr,Q3),e(Q3,hue),e(hue,Ier),e(Q3,Ner),e(Q3,pz),e(pz,qer),e(Q3,jer),e(Kr,Der),e(Kr,H3),e(H3,pue),e(pue,Ger),e(H3,Oer),e(H3,_z),e(_z,Ver),e(H3,Xer),e(Kr,zer),e(Kr,U3),e(U3,_ue),e(_ue,Wer),e(U3,Qer),e(U3,uz),e(uz,Her),e(U3,Uer),e(fo,Jer),e(fo,J3),e(J3,Yer),e(J3,uue),e(uue,Ker),e(J3,Zer),e(J3,bue),e(bue,eor),e(fo,oor),M(Y3,fo,null),b(f,aje,u),b(f,ud,u),e(ud,K3),e(K3,vue),M(CL,vue,null),e(ud,ror),e(ud,Fue),e(Fue,tor),b(f,nje,u),b(f,Vo,u),M(wL,Vo,null),e(Vo,aor),e(Vo,bd),e(bd,nor),e(bd,bz),e(bz,sor),e(bd,lor),e(bd,vz),e(vz,ior),e(bd,dor),e(Vo,cor),e(Vo,AL),e(AL,mor),e(AL,Tue),e(Tue,gor),e(AL,hor),e(Vo,por),e(Vo,vt),M(yL,vt,null),e(vt,_or),e(vt,Mue),e(Mue,uor),e(vt,bor),e(vt,vd),e(vd,vor),e(vd,Eue),e(Eue,For),e(vd,Tor),e(vd,Fz),e(Fz,Mor),e(vd,Eor),e(vt,Cor),M(Z3,vt,null),e(Vo,wor),e(Vo,mo),M(LL,mo,null),e(mo,Aor),e(mo,Cue),e(Cue,yor),e(mo,Lor),e(mo,Va),e(Va,xor),e(Va,wue),e(wue,$or),e(Va,kor),e(Va,Aue),e(Aue,Sor),e(Va,Ror),e(Va,yue),e(yue,Por),e(Va,Bor),e(mo,Ior),e(mo,Se),e(Se,eF),e(eF,Lue),e(Lue,Nor),e(eF,qor),e(eF,Tz),e(Tz,jor),e(eF,Dor),e(Se,Gor),e(Se,oF),e(oF,xue),e(xue,Oor),e(oF,Vor),e(oF,Mz),e(Mz,Xor),e(oF,zor),e(Se,Wor),e(Se,rF),e(rF,$ue),e($ue,Qor),e(rF,Hor),e(rF,Ez),e(Ez,Uor),e(rF,Jor),e(Se,Yor),e(Se,tF),e(tF,kue),e(kue,Kor),e(tF,Zor),e(tF,Cz),e(Cz,err),e(tF,orr),e(Se,rrr),e(Se,aF),e(aF,Sue),e(Sue,trr),e(aF,arr),e(aF,wz),e(wz,nrr),e(aF,srr),e(Se,lrr),e(Se,nF),e(nF,Rue),e(Rue,irr),e(nF,drr),e(nF,Az),e(Az,crr),e(nF,frr),e(Se,mrr),e(Se,sF),e(sF,Pue),e(Pue,grr),e(sF,hrr),e(sF,yz),e(yz,prr),e(sF,_rr),e(Se,urr),e(Se,lF),e(lF,Bue),e(Bue,brr),e(lF,vrr),e(lF,Lz),e(Lz,Frr),e(lF,Trr),e(Se,Mrr),e(Se,iF),e(iF,Iue),e(Iue,Err),e(iF,Crr),e(iF,xz),e(xz,wrr),e(iF,Arr),e(mo,yrr),e(mo,dF),e(dF,Lrr),e(dF,Nue),e(Nue,xrr),e(dF,$rr),e(dF,que),e(que,krr),e(mo,Srr),M(cF,mo,null),b(f,sje,u),b(f,Fd,u),e(Fd,fF),e(fF,jue),M(xL,jue,null),e(Fd,Rrr),e(Fd,Due),e(Due,Prr),b(f,lje,u),b(f,Xo,u),M($L,Xo,null),e(Xo,Brr),e(Xo,Td),e(Td,Irr),e(Td,$z),e($z,Nrr),e(Td,qrr),e(Td,kz),e(kz,jrr),e(Td,Drr),e(Xo,Grr),e(Xo,kL),e(kL,Orr),e(kL,Gue),e(Gue,Vrr),e(kL,Xrr),e(Xo,zrr),e(Xo,Ft),M(SL,Ft,null),e(Ft,Wrr),e(Ft,Oue),e(Oue,Qrr),e(Ft,Hrr),e(Ft,Md),e(Md,Urr),e(Md,Vue),e(Vue,Jrr),e(Md,Yrr),e(Md,Sz),e(Sz,Krr),e(Md,Zrr),e(Ft,etr),M(mF,Ft,null),e(Xo,otr),e(Xo,go),M(RL,go,null),e(go,rtr),e(go,Xue),e(Xue,ttr),e(go,atr),e(go,Xa),e(Xa,ntr),e(Xa,zue),e(zue,str),e(Xa,ltr),e(Xa,Wue),e(Wue,itr),e(Xa,dtr),e(Xa,Que),e(Que,ctr),e(Xa,ftr),e(go,mtr),e(go,PL),e(PL,gF),e(gF,Hue),e(Hue,gtr),e(gF,htr),e(gF,Rz),e(Rz,ptr),e(gF,_tr),e(PL,utr),e(PL,hF),e(hF,Uue),e(Uue,btr),e(hF,vtr),e(hF,Pz),e(Pz,Ftr),e(hF,Ttr),e(go,Mtr),e(go,pF),e(pF,Etr),e(pF,Jue),e(Jue,Ctr),e(pF,wtr),e(pF,Yue),e(Yue,Atr),e(go,ytr),M(_F,go,null),b(f,ije,u),b(f,Ed,u),e(Ed,uF),e(uF,Kue),M(BL,Kue,null),e(Ed,Ltr),e(Ed,Zue),e(Zue,xtr),b(f,dje,u),b(f,zo,u),M(IL,zo,null),e(zo,$tr),e(zo,Cd),e(Cd,ktr),e(Cd,Bz),e(Bz,Str),e(Cd,Rtr),e(Cd,Iz),e(Iz,Ptr),e(Cd,Btr),e(zo,Itr),e(zo,NL),e(NL,Ntr),e(NL,e4e),e(e4e,qtr),e(NL,jtr),e(zo,Dtr),e(zo,Tt),M(qL,Tt,null),e(Tt,Gtr),e(Tt,o4e),e(o4e,Otr),e(Tt,Vtr),e(Tt,wd),e(wd,Xtr),e(wd,r4e),e(r4e,ztr),e(wd,Wtr),e(wd,Nz),e(Nz,Qtr),e(wd,Htr),e(Tt,Utr),M(bF,Tt,null),e(zo,Jtr),e(zo,ho),M(jL,ho,null),e(ho,Ytr),e(ho,t4e),e(t4e,Ktr),e(ho,Ztr),e(ho,za),e(za,ear),e(za,a4e),e(a4e,oar),e(za,rar),e(za,n4e),e(n4e,tar),e(za,aar),e(za,s4e),e(s4e,nar),e(za,sar),e(ho,lar),e(ho,Zr),e(Zr,vF),e(vF,l4e),e(l4e,iar),e(vF,dar),e(vF,qz),e(qz,car),e(vF,far),e(Zr,mar),e(Zr,FF),e(FF,i4e),e(i4e,gar),e(FF,har),e(FF,jz),e(jz,par),e(FF,_ar),e(Zr,uar),e(Zr,TF),e(TF,d4e),e(d4e,bar),e(TF,Far),e(TF,Dz),e(Dz,Tar),e(TF,Mar),e(Zr,Ear),e(Zr,MF),e(MF,c4e),e(c4e,Car),e(MF,war),e(MF,Gz),e(Gz,Aar),e(MF,yar),e(Zr,Lar),e(Zr,EF),e(EF,f4e),e(f4e,xar),e(EF,$ar),e(EF,Oz),e(Oz,kar),e(EF,Sar),e(ho,Rar),e(ho,CF),e(CF,Par),e(CF,m4e),e(m4e,Bar),e(CF,Iar),e(CF,g4e),e(g4e,Nar),e(ho,qar),M(wF,ho,null),b(f,cje,u),b(f,Ad,u),e(Ad,AF),e(AF,h4e),M(DL,h4e,null),e(Ad,jar),e(Ad,p4e),e(p4e,Dar),b(f,fje,u),b(f,Wo,u),M(GL,Wo,null),e(Wo,Gar),e(Wo,yd),e(yd,Oar),e(yd,Vz),e(Vz,Var),e(yd,Xar),e(yd,Xz),e(Xz,zar),e(yd,War),e(Wo,Qar),e(Wo,OL),e(OL,Har),e(OL,_4e),e(_4e,Uar),e(OL,Jar),e(Wo,Yar),e(Wo,Mt),M(VL,Mt,null),e(Mt,Kar),e(Mt,u4e),e(u4e,Zar),e(Mt,enr),e(Mt,Ld),e(Ld,onr),e(Ld,b4e),e(b4e,rnr),e(Ld,tnr),e(Ld,zz),e(zz,anr),e(Ld,nnr),e(Mt,snr),M(yF,Mt,null),e(Wo,lnr),e(Wo,po),M(XL,po,null),e(po,inr),e(po,v4e),e(v4e,dnr),e(po,cnr),e(po,Wa),e(Wa,fnr),e(Wa,F4e),e(F4e,mnr),e(Wa,gnr),e(Wa,T4e),e(T4e,hnr),e(Wa,pnr),e(Wa,M4e),e(M4e,_nr),e(Wa,unr),e(po,bnr),e(po,xd),e(xd,LF),e(LF,E4e),e(E4e,vnr),e(LF,Fnr),e(LF,Wz),e(Wz,Tnr),e(LF,Mnr),e(xd,Enr),e(xd,xF),e(xF,C4e),e(C4e,Cnr),e(xF,wnr),e(xF,Qz),e(Qz,Anr),e(xF,ynr),e(xd,Lnr),e(xd,$F),e($F,w4e),e(w4e,xnr),e($F,$nr),e($F,Hz),e(Hz,knr),e($F,Snr),e(po,Rnr),e(po,kF),e(kF,Pnr),e(kF,A4e),e(A4e,Bnr),e(kF,Inr),e(kF,y4e),e(y4e,Nnr),e(po,qnr),M(SF,po,null),b(f,mje,u),b(f,$d,u),e($d,RF),e(RF,L4e),M(zL,L4e,null),e($d,jnr),e($d,x4e),e(x4e,Dnr),b(f,gje,u),b(f,Qo,u),M(WL,Qo,null),e(Qo,Gnr),e(Qo,kd),e(kd,Onr),e(kd,Uz),e(Uz,Vnr),e(kd,Xnr),e(kd,Jz),e(Jz,znr),e(kd,Wnr),e(Qo,Qnr),e(Qo,QL),e(QL,Hnr),e(QL,$4e),e($4e,Unr),e(QL,Jnr),e(Qo,Ynr),e(Qo,Et),M(HL,Et,null),e(Et,Knr),e(Et,k4e),e(k4e,Znr),e(Et,esr),e(Et,Sd),e(Sd,osr),e(Sd,S4e),e(S4e,rsr),e(Sd,tsr),e(Sd,Yz),e(Yz,asr),e(Sd,nsr),e(Et,ssr),M(PF,Et,null),e(Qo,lsr),e(Qo,_o),M(UL,_o,null),e(_o,isr),e(_o,R4e),e(R4e,dsr),e(_o,csr),e(_o,Qa),e(Qa,fsr),e(Qa,P4e),e(P4e,msr),e(Qa,gsr),e(Qa,B4e),e(B4e,hsr),e(Qa,psr),e(Qa,I4e),e(I4e,_sr),e(Qa,usr),e(_o,bsr),e(_o,JL),e(JL,BF),e(BF,N4e),e(N4e,vsr),e(BF,Fsr),e(BF,Kz),e(Kz,Tsr),e(BF,Msr),e(JL,Esr),e(JL,IF),e(IF,q4e),e(q4e,Csr),e(IF,wsr),e(IF,Zz),e(Zz,Asr),e(IF,ysr),e(_o,Lsr),e(_o,NF),e(NF,xsr),e(NF,j4e),e(j4e,$sr),e(NF,ksr),e(NF,D4e),e(D4e,Ssr),e(_o,Rsr),M(qF,_o,null),b(f,hje,u),b(f,Rd,u),e(Rd,jF),e(jF,G4e),M(YL,G4e,null),e(Rd,Psr),e(Rd,O4e),e(O4e,Bsr),b(f,pje,u),b(f,Ho,u),M(KL,Ho,null),e(Ho,Isr),e(Ho,Pd),e(Pd,Nsr),e(Pd,eW),e(eW,qsr),e(Pd,jsr),e(Pd,oW),e(oW,Dsr),e(Pd,Gsr),e(Ho,Osr),e(Ho,ZL),e(ZL,Vsr),e(ZL,V4e),e(V4e,Xsr),e(ZL,zsr),e(Ho,Wsr),e(Ho,Ct),M(e8,Ct,null),e(Ct,Qsr),e(Ct,X4e),e(X4e,Hsr),e(Ct,Usr),e(Ct,Bd),e(Bd,Jsr),e(Bd,z4e),e(z4e,Ysr),e(Bd,Ksr),e(Bd,rW),e(rW,Zsr),e(Bd,elr),e(Ct,olr),M(DF,Ct,null),e(Ho,rlr),e(Ho,uo),M(o8,uo,null),e(uo,tlr),e(uo,W4e),e(W4e,alr),e(uo,nlr),e(uo,Ha),e(Ha,slr),e(Ha,Q4e),e(Q4e,llr),e(Ha,ilr),e(Ha,H4e),e(H4e,dlr),e(Ha,clr),e(Ha,U4e),e(U4e,flr),e(Ha,mlr),e(uo,glr),e(uo,J4e),e(J4e,GF),e(GF,Y4e),e(Y4e,hlr),e(GF,plr),e(GF,tW),e(tW,_lr),e(GF,ulr),e(uo,blr),e(uo,OF),e(OF,vlr),e(OF,K4e),e(K4e,Flr),e(OF,Tlr),e(OF,Z4e),e(Z4e,Mlr),e(uo,Elr),M(VF,uo,null),b(f,_je,u),b(f,Id,u),e(Id,XF),e(XF,e1e),M(r8,e1e,null),e(Id,Clr),e(Id,o1e),e(o1e,wlr),b(f,uje,u),b(f,Uo,u),M(t8,Uo,null),e(Uo,Alr),e(Uo,Nd),e(Nd,ylr),e(Nd,aW),e(aW,Llr),e(Nd,xlr),e(Nd,nW),e(nW,$lr),e(Nd,klr),e(Uo,Slr),e(Uo,a8),e(a8,Rlr),e(a8,r1e),e(r1e,Plr),e(a8,Blr),e(Uo,Ilr),e(Uo,wt),M(n8,wt,null),e(wt,Nlr),e(wt,t1e),e(t1e,qlr),e(wt,jlr),e(wt,qd),e(qd,Dlr),e(qd,a1e),e(a1e,Glr),e(qd,Olr),e(qd,sW),e(sW,Vlr),e(qd,Xlr),e(wt,zlr),M(zF,wt,null),e(Uo,Wlr),e(Uo,bo),M(s8,bo,null),e(bo,Qlr),e(bo,n1e),e(n1e,Hlr),e(bo,Ulr),e(bo,Ua),e(Ua,Jlr),e(Ua,s1e),e(s1e,Ylr),e(Ua,Klr),e(Ua,l1e),e(l1e,Zlr),e(Ua,eir),e(Ua,i1e),e(i1e,oir),e(Ua,rir),e(bo,tir),e(bo,Ja),e(Ja,WF),e(WF,d1e),e(d1e,air),e(WF,nir),e(WF,lW),e(lW,sir),e(WF,lir),e(Ja,iir),e(Ja,QF),e(QF,c1e),e(c1e,dir),e(QF,cir),e(QF,iW),e(iW,fir),e(QF,mir),e(Ja,gir),e(Ja,HF),e(HF,f1e),e(f1e,hir),e(HF,pir),e(HF,dW),e(dW,_ir),e(HF,uir),e(Ja,bir),e(Ja,UF),e(UF,m1e),e(m1e,vir),e(UF,Fir),e(UF,cW),e(cW,Tir),e(UF,Mir),e(bo,Eir),e(bo,JF),e(JF,Cir),e(JF,g1e),e(g1e,wir),e(JF,Air),e(JF,h1e),e(h1e,yir),e(bo,Lir),M(YF,bo,null),b(f,bje,u),b(f,jd,u),e(jd,KF),e(KF,p1e),M(l8,p1e,null),e(jd,xir),e(jd,_1e),e(_1e,$ir),b(f,vje,u),b(f,Jo,u),M(i8,Jo,null),e(Jo,kir),e(Jo,Dd),e(Dd,Sir),e(Dd,fW),e(fW,Rir),e(Dd,Pir),e(Dd,mW),e(mW,Bir),e(Dd,Iir),e(Jo,Nir),e(Jo,d8),e(d8,qir),e(d8,u1e),e(u1e,jir),e(d8,Dir),e(Jo,Gir),e(Jo,At),M(c8,At,null),e(At,Oir),e(At,b1e),e(b1e,Vir),e(At,Xir),e(At,Gd),e(Gd,zir),e(Gd,v1e),e(v1e,Wir),e(Gd,Qir),e(Gd,gW),e(gW,Hir),e(Gd,Uir),e(At,Jir),M(ZF,At,null),e(Jo,Yir),e(Jo,vo),M(f8,vo,null),e(vo,Kir),e(vo,F1e),e(F1e,Zir),e(vo,edr),e(vo,Ya),e(Ya,odr),e(Ya,T1e),e(T1e,rdr),e(Ya,tdr),e(Ya,M1e),e(M1e,adr),e(Ya,ndr),e(Ya,E1e),e(E1e,sdr),e(Ya,ldr),e(vo,idr),e(vo,C1e),e(C1e,eT),e(eT,w1e),e(w1e,ddr),e(eT,cdr),e(eT,hW),e(hW,fdr),e(eT,mdr),e(vo,gdr),e(vo,oT),e(oT,hdr),e(oT,A1e),e(A1e,pdr),e(oT,_dr),e(oT,y1e),e(y1e,udr),e(vo,bdr),M(rT,vo,null),b(f,Fje,u),b(f,Od,u),e(Od,tT),e(tT,L1e),M(m8,L1e,null),e(Od,vdr),e(Od,x1e),e(x1e,Fdr),b(f,Tje,u),b(f,Yo,u),M(g8,Yo,null),e(Yo,Tdr),e(Yo,Vd),e(Vd,Mdr),e(Vd,pW),e(pW,Edr),e(Vd,Cdr),e(Vd,_W),e(_W,wdr),e(Vd,Adr),e(Yo,ydr),e(Yo,h8),e(h8,Ldr),e(h8,$1e),e($1e,xdr),e(h8,$dr),e(Yo,kdr),e(Yo,yt),M(p8,yt,null),e(yt,Sdr),e(yt,k1e),e(k1e,Rdr),e(yt,Pdr),e(yt,Xd),e(Xd,Bdr),e(Xd,S1e),e(S1e,Idr),e(Xd,Ndr),e(Xd,uW),e(uW,qdr),e(Xd,jdr),e(yt,Ddr),M(aT,yt,null),e(Yo,Gdr),e(Yo,wr),M(_8,wr,null),e(wr,Odr),e(wr,R1e),e(R1e,Vdr),e(wr,Xdr),e(wr,Ka),e(Ka,zdr),e(Ka,P1e),e(P1e,Wdr),e(Ka,Qdr),e(Ka,B1e),e(B1e,Hdr),e(Ka,Udr),e(Ka,I1e),e(I1e,Jdr),e(Ka,Ydr),e(wr,Kdr),e(wr,q),e(q,nT),e(nT,N1e),e(N1e,Zdr),e(nT,ecr),e(nT,bW),e(bW,ocr),e(nT,rcr),e(q,tcr),e(q,sT),e(sT,q1e),e(q1e,acr),e(sT,ncr),e(sT,vW),e(vW,scr),e(sT,lcr),e(q,icr),e(q,lT),e(lT,j1e),e(j1e,dcr),e(lT,ccr),e(lT,FW),e(FW,fcr),e(lT,mcr),e(q,gcr),e(q,iT),e(iT,D1e),e(D1e,hcr),e(iT,pcr),e(iT,TW),e(TW,_cr),e(iT,ucr),e(q,bcr),e(q,dT),e(dT,G1e),e(G1e,vcr),e(dT,Fcr),e(dT,MW),e(MW,Tcr),e(dT,Mcr),e(q,Ecr),e(q,cT),e(cT,O1e),e(O1e,Ccr),e(cT,wcr),e(cT,EW),e(EW,Acr),e(cT,ycr),e(q,Lcr),e(q,fT),e(fT,V1e),e(V1e,xcr),e(fT,$cr),e(fT,CW),e(CW,kcr),e(fT,Scr),e(q,Rcr),e(q,mT),e(mT,X1e),e(X1e,Pcr),e(mT,Bcr),e(mT,wW),e(wW,Icr),e(mT,Ncr),e(q,qcr),e(q,gT),e(gT,z1e),e(z1e,jcr),e(gT,Dcr),e(gT,AW),e(AW,Gcr),e(gT,Ocr),e(q,Vcr),e(q,hT),e(hT,W1e),e(W1e,Xcr),e(hT,zcr),e(hT,yW),e(yW,Wcr),e(hT,Qcr),e(q,Hcr),e(q,pT),e(pT,Q1e),e(Q1e,Ucr),e(pT,Jcr),e(pT,LW),e(LW,Ycr),e(pT,Kcr),e(q,Zcr),e(q,_T),e(_T,H1e),e(H1e,efr),e(_T,ofr),e(_T,xW),e(xW,rfr),e(_T,tfr),e(q,afr),e(q,uT),e(uT,U1e),e(U1e,nfr),e(uT,sfr),e(uT,$W),e($W,lfr),e(uT,ifr),e(q,dfr),e(q,bT),e(bT,J1e),e(J1e,cfr),e(bT,ffr),e(bT,kW),e(kW,mfr),e(bT,gfr),e(q,hfr),e(q,vT),e(vT,Y1e),e(Y1e,pfr),e(vT,_fr),e(vT,SW),e(SW,ufr),e(vT,bfr),e(q,vfr),e(q,FT),e(FT,K1e),e(K1e,Ffr),e(FT,Tfr),e(FT,RW),e(RW,Mfr),e(FT,Efr),e(q,Cfr),e(q,TT),e(TT,Z1e),e(Z1e,wfr),e(TT,Afr),e(TT,PW),e(PW,yfr),e(TT,Lfr),e(q,xfr),e(q,Ns),e(Ns,ebe),e(ebe,$fr),e(Ns,kfr),e(Ns,BW),e(BW,Sfr),e(Ns,Rfr),e(Ns,IW),e(IW,Pfr),e(Ns,Bfr),e(q,Ifr),e(q,MT),e(MT,obe),e(obe,Nfr),e(MT,qfr),e(MT,NW),e(NW,jfr),e(MT,Dfr),e(q,Gfr),e(q,ET),e(ET,rbe),e(rbe,Ofr),e(ET,Vfr),e(ET,qW),e(qW,Xfr),e(ET,zfr),e(q,Wfr),e(q,CT),e(CT,tbe),e(tbe,Qfr),e(CT,Hfr),e(CT,jW),e(jW,Ufr),e(CT,Jfr),e(q,Yfr),e(q,wT),e(wT,abe),e(abe,Kfr),e(wT,Zfr),e(wT,DW),e(DW,emr),e(wT,omr),e(q,rmr),e(q,AT),e(AT,nbe),e(nbe,tmr),e(AT,amr),e(AT,GW),e(GW,nmr),e(AT,smr),e(q,lmr),e(q,yT),e(yT,sbe),e(sbe,imr),e(yT,dmr),e(yT,OW),e(OW,cmr),e(yT,fmr),e(q,mmr),e(q,LT),e(LT,lbe),e(lbe,gmr),e(LT,hmr),e(LT,VW),e(VW,pmr),e(LT,_mr),e(q,umr),e(q,xT),e(xT,ibe),e(ibe,bmr),e(xT,vmr),e(xT,XW),e(XW,Fmr),e(xT,Tmr),e(q,Mmr),e(q,$T),e($T,dbe),e(dbe,Emr),e($T,Cmr),e($T,zW),e(zW,wmr),e($T,Amr),e(q,ymr),e(q,kT),e(kT,cbe),e(cbe,Lmr),e(kT,xmr),e(kT,WW),e(WW,$mr),e(kT,kmr),e(q,Smr),e(q,ST),e(ST,fbe),e(fbe,Rmr),e(ST,Pmr),e(ST,QW),e(QW,Bmr),e(ST,Imr),e(q,Nmr),e(q,RT),e(RT,mbe),e(mbe,qmr),e(RT,jmr),e(RT,HW),e(HW,Dmr),e(RT,Gmr),e(q,Omr),e(q,PT),e(PT,gbe),e(gbe,Vmr),e(PT,Xmr),e(PT,UW),e(UW,zmr),e(PT,Wmr),e(q,Qmr),e(q,BT),e(BT,hbe),e(hbe,Hmr),e(BT,Umr),e(BT,JW),e(JW,Jmr),e(BT,Ymr),e(q,Kmr),e(q,IT),e(IT,pbe),e(pbe,Zmr),e(IT,egr),e(IT,YW),e(YW,ogr),e(IT,rgr),e(q,tgr),e(q,NT),e(NT,_be),e(_be,agr),e(NT,ngr),e(NT,KW),e(KW,sgr),e(NT,lgr),e(q,igr),e(q,qT),e(qT,ube),e(ube,dgr),e(qT,cgr),e(qT,ZW),e(ZW,fgr),e(qT,mgr),e(q,ggr),e(q,jT),e(jT,bbe),e(bbe,hgr),e(jT,pgr),e(jT,eQ),e(eQ,_gr),e(jT,ugr),e(q,bgr),e(q,DT),e(DT,vbe),e(vbe,vgr),e(DT,Fgr),e(DT,oQ),e(oQ,Tgr),e(DT,Mgr),e(q,Egr),e(q,GT),e(GT,Fbe),e(Fbe,Cgr),e(GT,wgr),e(GT,rQ),e(rQ,Agr),e(GT,ygr),e(q,Lgr),e(q,OT),e(OT,Tbe),e(Tbe,xgr),e(OT,$gr),e(OT,tQ),e(tQ,kgr),e(OT,Sgr),e(q,Rgr),e(q,VT),e(VT,Mbe),e(Mbe,Pgr),e(VT,Bgr),e(VT,aQ),e(aQ,Igr),e(VT,Ngr),e(q,qgr),e(q,XT),e(XT,Ebe),e(Ebe,jgr),e(XT,Dgr),e(XT,nQ),e(nQ,Ggr),e(XT,Ogr),e(q,Vgr),e(q,zT),e(zT,Cbe),e(Cbe,Xgr),e(zT,zgr),e(zT,sQ),e(sQ,Wgr),e(zT,Qgr),e(q,Hgr),e(q,WT),e(WT,wbe),e(wbe,Ugr),e(WT,Jgr),e(WT,lQ),e(lQ,Ygr),e(WT,Kgr),e(q,Zgr),e(q,QT),e(QT,Abe),e(Abe,ehr),e(QT,ohr),e(QT,iQ),e(iQ,rhr),e(QT,thr),e(q,ahr),e(q,HT),e(HT,ybe),e(ybe,nhr),e(HT,shr),e(HT,dQ),e(dQ,lhr),e(HT,ihr),e(q,dhr),e(q,UT),e(UT,Lbe),e(Lbe,chr),e(UT,fhr),e(UT,cQ),e(cQ,mhr),e(UT,ghr),e(wr,hhr),M(JT,wr,null),b(f,Mje,u),b(f,zd,u),e(zd,YT),e(YT,xbe),M(u8,xbe,null),e(zd,phr),e(zd,$be),e($be,_hr),b(f,Eje,u),b(f,Ko,u),M(b8,Ko,null),e(Ko,uhr),e(Ko,Wd),e(Wd,bhr),e(Wd,fQ),e(fQ,vhr),e(Wd,Fhr),e(Wd,mQ),e(mQ,Thr),e(Wd,Mhr),e(Ko,Ehr),e(Ko,v8),e(v8,Chr),e(v8,kbe),e(kbe,whr),e(v8,Ahr),e(Ko,yhr),e(Ko,Lt),M(F8,Lt,null),e(Lt,Lhr),e(Lt,Sbe),e(Sbe,xhr),e(Lt,$hr),e(Lt,Qd),e(Qd,khr),e(Qd,Rbe),e(Rbe,Shr),e(Qd,Rhr),e(Qd,gQ),e(gQ,Phr),e(Qd,Bhr),e(Lt,Ihr),M(KT,Lt,null),e(Ko,Nhr),e(Ko,Ar),M(T8,Ar,null),e(Ar,qhr),e(Ar,Pbe),e(Pbe,jhr),e(Ar,Dhr),e(Ar,Za),e(Za,Ghr),e(Za,Bbe),e(Bbe,Ohr),e(Za,Vhr),e(Za,Ibe),e(Ibe,Xhr),e(Za,zhr),e(Za,Nbe),e(Nbe,Whr),e(Za,Qhr),e(Ar,Hhr),e(Ar,se),e(se,ZT),e(ZT,qbe),e(qbe,Uhr),e(ZT,Jhr),e(ZT,hQ),e(hQ,Yhr),e(ZT,Khr),e(se,Zhr),e(se,e7),e(e7,jbe),e(jbe,epr),e(e7,opr),e(e7,pQ),e(pQ,rpr),e(e7,tpr),e(se,apr),e(se,o7),e(o7,Dbe),e(Dbe,npr),e(o7,spr),e(o7,_Q),e(_Q,lpr),e(o7,ipr),e(se,dpr),e(se,r7),e(r7,Gbe),e(Gbe,cpr),e(r7,fpr),e(r7,uQ),e(uQ,mpr),e(r7,gpr),e(se,hpr),e(se,t7),e(t7,Obe),e(Obe,ppr),e(t7,_pr),e(t7,bQ),e(bQ,upr),e(t7,bpr),e(se,vpr),e(se,a7),e(a7,Vbe),e(Vbe,Fpr),e(a7,Tpr),e(a7,vQ),e(vQ,Mpr),e(a7,Epr),e(se,Cpr),e(se,n7),e(n7,Xbe),e(Xbe,wpr),e(n7,Apr),e(n7,FQ),e(FQ,ypr),e(n7,Lpr),e(se,xpr),e(se,s7),e(s7,zbe),e(zbe,$pr),e(s7,kpr),e(s7,TQ),e(TQ,Spr),e(s7,Rpr),e(se,Ppr),e(se,l7),e(l7,Wbe),e(Wbe,Bpr),e(l7,Ipr),e(l7,MQ),e(MQ,Npr),e(l7,qpr),e(se,jpr),e(se,i7),e(i7,Qbe),e(Qbe,Dpr),e(i7,Gpr),e(i7,EQ),e(EQ,Opr),e(i7,Vpr),e(se,Xpr),e(se,d7),e(d7,Hbe),e(Hbe,zpr),e(d7,Wpr),e(d7,CQ),e(CQ,Qpr),e(d7,Hpr),e(se,Upr),e(se,c7),e(c7,Ube),e(Ube,Jpr),e(c7,Ypr),e(c7,wQ),e(wQ,Kpr),e(c7,Zpr),e(se,e_r),e(se,f7),e(f7,Jbe),e(Jbe,o_r),e(f7,r_r),e(f7,AQ),e(AQ,t_r),e(f7,a_r),e(se,n_r),e(se,m7),e(m7,Ybe),e(Ybe,s_r),e(m7,l_r),e(m7,yQ),e(yQ,i_r),e(m7,d_r),e(se,c_r),e(se,g7),e(g7,Kbe),e(Kbe,f_r),e(g7,m_r),e(g7,LQ),e(LQ,g_r),e(g7,h_r),e(se,p_r),e(se,h7),e(h7,Zbe),e(Zbe,__r),e(h7,u_r),e(h7,xQ),e(xQ,b_r),e(h7,v_r),e(se,F_r),e(se,p7),e(p7,e2e),e(e2e,T_r),e(p7,M_r),e(p7,$Q),e($Q,E_r),e(p7,C_r),e(se,w_r),e(se,_7),e(_7,o2e),e(o2e,A_r),e(_7,y_r),e(_7,kQ),e(kQ,L_r),e(_7,x_r),e(se,$_r),e(se,u7),e(u7,r2e),e(r2e,k_r),e(u7,S_r),e(u7,SQ),e(SQ,R_r),e(u7,P_r),e(se,B_r),e(se,b7),e(b7,t2e),e(t2e,I_r),e(b7,N_r),e(b7,RQ),e(RQ,q_r),e(b7,j_r),e(se,D_r),e(se,v7),e(v7,a2e),e(a2e,G_r),e(v7,O_r),e(v7,PQ),e(PQ,V_r),e(v7,X_r),e(se,z_r),e(se,F7),e(F7,n2e),e(n2e,W_r),e(F7,Q_r),e(F7,BQ),e(BQ,H_r),e(F7,U_r),e(se,J_r),e(se,T7),e(T7,s2e),e(s2e,Y_r),e(T7,K_r),e(T7,IQ),e(IQ,Z_r),e(T7,eur),e(Ar,our),M(M7,Ar,null),b(f,Cje,u),b(f,Hd,u),e(Hd,E7),e(E7,l2e),M(M8,l2e,null),e(Hd,rur),e(Hd,i2e),e(i2e,tur),b(f,wje,u),b(f,Zo,u),M(E8,Zo,null),e(Zo,aur),e(Zo,Ud),e(Ud,nur),e(Ud,NQ),e(NQ,sur),e(Ud,lur),e(Ud,qQ),e(qQ,iur),e(Ud,dur),e(Zo,cur),e(Zo,C8),e(C8,fur),e(C8,d2e),e(d2e,mur),e(C8,gur),e(Zo,hur),e(Zo,xt),M(w8,xt,null),e(xt,pur),e(xt,c2e),e(c2e,_ur),e(xt,uur),e(xt,Jd),e(Jd,bur),e(Jd,f2e),e(f2e,vur),e(Jd,Fur),e(Jd,jQ),e(jQ,Tur),e(Jd,Mur),e(xt,Eur),M(C7,xt,null),e(Zo,Cur),e(Zo,yr),M(A8,yr,null),e(yr,wur),e(yr,m2e),e(m2e,Aur),e(yr,yur),e(yr,en),e(en,Lur),e(en,g2e),e(g2e,xur),e(en,$ur),e(en,h2e),e(h2e,kur),e(en,Sur),e(en,p2e),e(p2e,Rur),e(en,Pur),e(yr,Bur),e(yr,Me),e(Me,w7),e(w7,_2e),e(_2e,Iur),e(w7,Nur),e(w7,DQ),e(DQ,qur),e(w7,jur),e(Me,Dur),e(Me,A7),e(A7,u2e),e(u2e,Gur),e(A7,Our),e(A7,GQ),e(GQ,Vur),e(A7,Xur),e(Me,zur),e(Me,y7),e(y7,b2e),e(b2e,Wur),e(y7,Qur),e(y7,OQ),e(OQ,Hur),e(y7,Uur),e(Me,Jur),e(Me,L7),e(L7,v2e),e(v2e,Yur),e(L7,Kur),e(L7,VQ),e(VQ,Zur),e(L7,e4r),e(Me,o4r),e(Me,x7),e(x7,F2e),e(F2e,r4r),e(x7,t4r),e(x7,XQ),e(XQ,a4r),e(x7,n4r),e(Me,s4r),e(Me,$7),e($7,T2e),e(T2e,l4r),e($7,i4r),e($7,zQ),e(zQ,d4r),e($7,c4r),e(Me,f4r),e(Me,k7),e(k7,M2e),e(M2e,m4r),e(k7,g4r),e(k7,WQ),e(WQ,h4r),e(k7,p4r),e(Me,_4r),e(Me,S7),e(S7,E2e),e(E2e,u4r),e(S7,b4r),e(S7,QQ),e(QQ,v4r),e(S7,F4r),e(Me,T4r),e(Me,R7),e(R7,C2e),e(C2e,M4r),e(R7,E4r),e(R7,HQ),e(HQ,C4r),e(R7,w4r),e(Me,A4r),e(Me,P7),e(P7,w2e),e(w2e,y4r),e(P7,L4r),e(P7,UQ),e(UQ,x4r),e(P7,$4r),e(Me,k4r),e(Me,B7),e(B7,A2e),e(A2e,S4r),e(B7,R4r),e(B7,JQ),e(JQ,P4r),e(B7,B4r),e(Me,I4r),e(Me,I7),e(I7,y2e),e(y2e,N4r),e(I7,q4r),e(I7,YQ),e(YQ,j4r),e(I7,D4r),e(yr,G4r),M(N7,yr,null),b(f,Aje,u),b(f,Yd,u),e(Yd,q7),e(q7,L2e),M(y8,L2e,null),e(Yd,O4r),e(Yd,x2e),e(x2e,V4r),b(f,yje,u),b(f,er,u),M(L8,er,null),e(er,X4r),e(er,Kd),e(Kd,z4r),e(Kd,KQ),e(KQ,W4r),e(Kd,Q4r),e(Kd,ZQ),e(ZQ,H4r),e(Kd,U4r),e(er,J4r),e(er,x8),e(x8,Y4r),e(x8,$2e),e($2e,K4r),e(x8,Z4r),e(er,e1r),e(er,$t),M($8,$t,null),e($t,o1r),e($t,k2e),e(k2e,r1r),e($t,t1r),e($t,Zd),e(Zd,a1r),e(Zd,S2e),e(S2e,n1r),e(Zd,s1r),e(Zd,eH),e(eH,l1r),e(Zd,i1r),e($t,d1r),M(j7,$t,null),e(er,c1r),e(er,Lr),M(k8,Lr,null),e(Lr,f1r),e(Lr,R2e),e(R2e,m1r),e(Lr,g1r),e(Lr,on),e(on,h1r),e(on,P2e),e(P2e,p1r),e(on,_1r),e(on,B2e),e(B2e,u1r),e(on,b1r),e(on,I2e),e(I2e,v1r),e(on,F1r),e(Lr,T1r),e(Lr,rn),e(rn,D7),e(D7,N2e),e(N2e,M1r),e(D7,E1r),e(D7,oH),e(oH,C1r),e(D7,w1r),e(rn,A1r),e(rn,G7),e(G7,q2e),e(q2e,y1r),e(G7,L1r),e(G7,rH),e(rH,x1r),e(G7,$1r),e(rn,k1r),e(rn,O7),e(O7,j2e),e(j2e,S1r),e(O7,R1r),e(O7,tH),e(tH,P1r),e(O7,B1r),e(rn,I1r),e(rn,V7),e(V7,D2e),e(D2e,N1r),e(V7,q1r),e(V7,aH),e(aH,j1r),e(V7,D1r),e(Lr,G1r),M(X7,Lr,null),b(f,Lje,u),b(f,ec,u),e(ec,z7),e(z7,G2e),M(S8,G2e,null),e(ec,O1r),e(ec,O2e),e(O2e,V1r),b(f,xje,u),b(f,or,u),M(R8,or,null),e(or,X1r),e(or,oc),e(oc,z1r),e(oc,nH),e(nH,W1r),e(oc,Q1r),e(oc,sH),e(sH,H1r),e(oc,U1r),e(or,J1r),e(or,P8),e(P8,Y1r),e(P8,V2e),e(V2e,K1r),e(P8,Z1r),e(or,ebr),e(or,kt),M(B8,kt,null),e(kt,obr),e(kt,X2e),e(X2e,rbr),e(kt,tbr),e(kt,rc),e(rc,abr),e(rc,z2e),e(z2e,nbr),e(rc,sbr),e(rc,lH),e(lH,lbr),e(rc,ibr),e(kt,dbr),M(W7,kt,null),e(or,cbr),e(or,xr),M(I8,xr,null),e(xr,fbr),e(xr,W2e),e(W2e,mbr),e(xr,gbr),e(xr,tn),e(tn,hbr),e(tn,Q2e),e(Q2e,pbr),e(tn,_br),e(tn,H2e),e(H2e,ubr),e(tn,bbr),e(tn,U2e),e(U2e,vbr),e(tn,Fbr),e(xr,Tbr),e(xr,ie),e(ie,Q7),e(Q7,J2e),e(J2e,Mbr),e(Q7,Ebr),e(Q7,iH),e(iH,Cbr),e(Q7,wbr),e(ie,Abr),e(ie,H7),e(H7,Y2e),e(Y2e,ybr),e(H7,Lbr),e(H7,dH),e(dH,xbr),e(H7,$br),e(ie,kbr),e(ie,U7),e(U7,K2e),e(K2e,Sbr),e(U7,Rbr),e(U7,cH),e(cH,Pbr),e(U7,Bbr),e(ie,Ibr),e(ie,J7),e(J7,Z2e),e(Z2e,Nbr),e(J7,qbr),e(J7,fH),e(fH,jbr),e(J7,Dbr),e(ie,Gbr),e(ie,Y7),e(Y7,eve),e(eve,Obr),e(Y7,Vbr),e(Y7,mH),e(mH,Xbr),e(Y7,zbr),e(ie,Wbr),e(ie,K7),e(K7,ove),e(ove,Qbr),e(K7,Hbr),e(K7,gH),e(gH,Ubr),e(K7,Jbr),e(ie,Ybr),e(ie,Z7),e(Z7,rve),e(rve,Kbr),e(Z7,Zbr),e(Z7,hH),e(hH,e2r),e(Z7,o2r),e(ie,r2r),e(ie,eM),e(eM,tve),e(tve,t2r),e(eM,a2r),e(eM,pH),e(pH,n2r),e(eM,s2r),e(ie,l2r),e(ie,oM),e(oM,ave),e(ave,i2r),e(oM,d2r),e(oM,_H),e(_H,c2r),e(oM,f2r),e(ie,m2r),e(ie,rM),e(rM,nve),e(nve,g2r),e(rM,h2r),e(rM,uH),e(uH,p2r),e(rM,_2r),e(ie,u2r),e(ie,tM),e(tM,sve),e(sve,b2r),e(tM,v2r),e(tM,bH),e(bH,F2r),e(tM,T2r),e(ie,M2r),e(ie,aM),e(aM,lve),e(lve,E2r),e(aM,C2r),e(aM,vH),e(vH,w2r),e(aM,A2r),e(ie,y2r),e(ie,nM),e(nM,ive),e(ive,L2r),e(nM,x2r),e(nM,FH),e(FH,$2r),e(nM,k2r),e(ie,S2r),e(ie,sM),e(sM,dve),e(dve,R2r),e(sM,P2r),e(sM,TH),e(TH,B2r),e(sM,I2r),e(ie,N2r),e(ie,lM),e(lM,cve),e(cve,q2r),e(lM,j2r),e(lM,MH),e(MH,D2r),e(lM,G2r),e(ie,O2r),e(ie,iM),e(iM,fve),e(fve,V2r),e(iM,X2r),e(iM,EH),e(EH,z2r),e(iM,W2r),e(ie,Q2r),e(ie,dM),e(dM,mve),e(mve,H2r),e(dM,U2r),e(dM,CH),e(CH,J2r),e(dM,Y2r),e(ie,K2r),e(ie,cM),e(cM,gve),e(gve,Z2r),e(cM,evr),e(cM,wH),e(wH,ovr),e(cM,rvr),e(ie,tvr),e(ie,fM),e(fM,hve),e(hve,avr),e(fM,nvr),e(fM,AH),e(AH,svr),e(fM,lvr),e(ie,ivr),e(ie,mM),e(mM,pve),e(pve,dvr),e(mM,cvr),e(mM,yH),e(yH,fvr),e(mM,mvr),e(xr,gvr),M(gM,xr,null),b(f,$je,u),b(f,tc,u),e(tc,hM),e(hM,_ve),M(N8,_ve,null),e(tc,hvr),e(tc,uve),e(uve,pvr),b(f,kje,u),b(f,rr,u),M(q8,rr,null),e(rr,_vr),e(rr,ac),e(ac,uvr),e(ac,LH),e(LH,bvr),e(ac,vvr),e(ac,xH),e(xH,Fvr),e(ac,Tvr),e(rr,Mvr),e(rr,j8),e(j8,Evr),e(j8,bve),e(bve,Cvr),e(j8,wvr),e(rr,Avr),e(rr,St),M(D8,St,null),e(St,yvr),e(St,vve),e(vve,Lvr),e(St,xvr),e(St,nc),e(nc,$vr),e(nc,Fve),e(Fve,kvr),e(nc,Svr),e(nc,$H),e($H,Rvr),e(nc,Pvr),e(St,Bvr),M(pM,St,null),e(rr,Ivr),e(rr,$r),M(G8,$r,null),e($r,Nvr),e($r,Tve),e(Tve,qvr),e($r,jvr),e($r,an),e(an,Dvr),e(an,Mve),e(Mve,Gvr),e(an,Ovr),e(an,Eve),e(Eve,Vvr),e(an,Xvr),e(an,Cve),e(Cve,zvr),e(an,Wvr),e($r,Qvr),e($r,ye),e(ye,_M),e(_M,wve),e(wve,Hvr),e(_M,Uvr),e(_M,kH),e(kH,Jvr),e(_M,Yvr),e(ye,Kvr),e(ye,uM),e(uM,Ave),e(Ave,Zvr),e(uM,e3r),e(uM,SH),e(SH,o3r),e(uM,r3r),e(ye,t3r),e(ye,bM),e(bM,yve),e(yve,a3r),e(bM,n3r),e(bM,RH),e(RH,s3r),e(bM,l3r),e(ye,i3r),e(ye,vM),e(vM,Lve),e(Lve,d3r),e(vM,c3r),e(vM,PH),e(PH,f3r),e(vM,m3r),e(ye,g3r),e(ye,FM),e(FM,xve),e(xve,h3r),e(FM,p3r),e(FM,BH),e(BH,_3r),e(FM,u3r),e(ye,b3r),e(ye,TM),e(TM,$ve),e($ve,v3r),e(TM,F3r),e(TM,IH),e(IH,T3r),e(TM,M3r),e(ye,E3r),e(ye,MM),e(MM,kve),e(kve,C3r),e(MM,w3r),e(MM,NH),e(NH,A3r),e(MM,y3r),e(ye,L3r),e(ye,EM),e(EM,Sve),e(Sve,x3r),e(EM,$3r),e(EM,qH),e(qH,k3r),e(EM,S3r),e(ye,R3r),e(ye,CM),e(CM,Rve),e(Rve,P3r),e(CM,B3r),e(CM,jH),e(jH,I3r),e(CM,N3r),e(ye,q3r),e(ye,wM),e(wM,Pve),e(Pve,j3r),e(wM,D3r),e(wM,DH),e(DH,G3r),e(wM,O3r),e($r,V3r),M(AM,$r,null),b(f,Sje,u),b(f,sc,u),e(sc,yM),e(yM,Bve),M(O8,Bve,null),e(sc,X3r),e(sc,Ive),e(Ive,z3r),b(f,Rje,u),b(f,tr,u),M(V8,tr,null),e(tr,W3r),e(tr,lc),e(lc,Q3r),e(lc,GH),e(GH,H3r),e(lc,U3r),e(lc,OH),e(OH,J3r),e(lc,Y3r),e(tr,K3r),e(tr,X8),e(X8,Z3r),e(X8,Nve),e(Nve,eFr),e(X8,oFr),e(tr,rFr),e(tr,Rt),M(z8,Rt,null),e(Rt,tFr),e(Rt,qve),e(qve,aFr),e(Rt,nFr),e(Rt,ic),e(ic,sFr),e(ic,jve),e(jve,lFr),e(ic,iFr),e(ic,VH),e(VH,dFr),e(ic,cFr),e(Rt,fFr),M(LM,Rt,null),e(tr,mFr),e(tr,kr),M(W8,kr,null),e(kr,gFr),e(kr,Dve),e(Dve,hFr),e(kr,pFr),e(kr,nn),e(nn,_Fr),e(nn,Gve),e(Gve,uFr),e(nn,bFr),e(nn,Ove),e(Ove,vFr),e(nn,FFr),e(nn,Vve),e(Vve,TFr),e(nn,MFr),e(kr,EFr),e(kr,oe),e(oe,xM),e(xM,Xve),e(Xve,CFr),e(xM,wFr),e(xM,XH),e(XH,AFr),e(xM,yFr),e(oe,LFr),e(oe,$M),e($M,zve),e(zve,xFr),e($M,$Fr),e($M,zH),e(zH,kFr),e($M,SFr),e(oe,RFr),e(oe,kM),e(kM,Wve),e(Wve,PFr),e(kM,BFr),e(kM,WH),e(WH,IFr),e(kM,NFr),e(oe,qFr),e(oe,SM),e(SM,Qve),e(Qve,jFr),e(SM,DFr),e(SM,QH),e(QH,GFr),e(SM,OFr),e(oe,VFr),e(oe,RM),e(RM,Hve),e(Hve,XFr),e(RM,zFr),e(RM,HH),e(HH,WFr),e(RM,QFr),e(oe,HFr),e(oe,PM),e(PM,Uve),e(Uve,UFr),e(PM,JFr),e(PM,UH),e(UH,YFr),e(PM,KFr),e(oe,ZFr),e(oe,BM),e(BM,Jve),e(Jve,eTr),e(BM,oTr),e(BM,JH),e(JH,rTr),e(BM,tTr),e(oe,aTr),e(oe,IM),e(IM,Yve),e(Yve,nTr),e(IM,sTr),e(IM,YH),e(YH,lTr),e(IM,iTr),e(oe,dTr),e(oe,NM),e(NM,Kve),e(Kve,cTr),e(NM,fTr),e(NM,KH),e(KH,mTr),e(NM,gTr),e(oe,hTr),e(oe,qM),e(qM,Zve),e(Zve,pTr),e(qM,_Tr),e(qM,ZH),e(ZH,uTr),e(qM,bTr),e(oe,vTr),e(oe,jM),e(jM,e3e),e(e3e,FTr),e(jM,TTr),e(jM,eU),e(eU,MTr),e(jM,ETr),e(oe,CTr),e(oe,DM),e(DM,o3e),e(o3e,wTr),e(DM,ATr),e(DM,oU),e(oU,yTr),e(DM,LTr),e(oe,xTr),e(oe,GM),e(GM,r3e),e(r3e,$Tr),e(GM,kTr),e(GM,rU),e(rU,STr),e(GM,RTr),e(oe,PTr),e(oe,OM),e(OM,t3e),e(t3e,BTr),e(OM,ITr),e(OM,tU),e(tU,NTr),e(OM,qTr),e(oe,jTr),e(oe,VM),e(VM,a3e),e(a3e,DTr),e(VM,GTr),e(VM,aU),e(aU,OTr),e(VM,VTr),e(oe,XTr),e(oe,XM),e(XM,n3e),e(n3e,zTr),e(XM,WTr),e(XM,nU),e(nU,QTr),e(XM,HTr),e(oe,UTr),e(oe,zM),e(zM,s3e),e(s3e,JTr),e(zM,YTr),e(zM,sU),e(sU,KTr),e(zM,ZTr),e(oe,e7r),e(oe,WM),e(WM,l3e),e(l3e,o7r),e(WM,r7r),e(WM,lU),e(lU,t7r),e(WM,a7r),e(oe,n7r),e(oe,QM),e(QM,i3e),e(i3e,s7r),e(QM,l7r),e(QM,iU),e(iU,i7r),e(QM,d7r),e(oe,c7r),e(oe,HM),e(HM,d3e),e(d3e,f7r),e(HM,m7r),e(HM,dU),e(dU,g7r),e(HM,h7r),e(oe,p7r),e(oe,UM),e(UM,c3e),e(c3e,_7r),e(UM,u7r),e(UM,cU),e(cU,b7r),e(UM,v7r),e(oe,F7r),e(oe,JM),e(JM,f3e),e(f3e,T7r),e(JM,M7r),e(JM,fU),e(fU,E7r),e(JM,C7r),e(oe,w7r),e(oe,YM),e(YM,m3e),e(m3e,A7r),e(YM,y7r),e(YM,mU),e(mU,L7r),e(YM,x7r),e(oe,$7r),e(oe,KM),e(KM,g3e),e(g3e,k7r),e(KM,S7r),e(KM,gU),e(gU,R7r),e(KM,P7r),e(oe,B7r),e(oe,ZM),e(ZM,h3e),e(h3e,I7r),e(ZM,N7r),e(ZM,hU),e(hU,q7r),e(ZM,j7r),e(oe,D7r),e(oe,eE),e(eE,p3e),e(p3e,G7r),e(eE,O7r),e(eE,pU),e(pU,V7r),e(eE,X7r),e(kr,z7r),M(oE,kr,null),b(f,Pje,u),b(f,dc,u),e(dc,rE),e(rE,_3e),M(Q8,_3e,null),e(dc,W7r),e(dc,u3e),e(u3e,Q7r),b(f,Bje,u),b(f,ar,u),M(H8,ar,null),e(ar,H7r),e(ar,cc),e(cc,U7r),e(cc,_U),e(_U,J7r),e(cc,Y7r),e(cc,uU),e(uU,K7r),e(cc,Z7r),e(ar,eMr),e(ar,U8),e(U8,oMr),e(U8,b3e),e(b3e,rMr),e(U8,tMr),e(ar,aMr),e(ar,Pt),M(J8,Pt,null),e(Pt,nMr),e(Pt,v3e),e(v3e,sMr),e(Pt,lMr),e(Pt,fc),e(fc,iMr),e(fc,F3e),e(F3e,dMr),e(fc,cMr),e(fc,bU),e(bU,fMr),e(fc,mMr),e(Pt,gMr),M(tE,Pt,null),e(ar,hMr),e(ar,Sr),M(Y8,Sr,null),e(Sr,pMr),e(Sr,T3e),e(T3e,_Mr),e(Sr,uMr),e(Sr,sn),e(sn,bMr),e(sn,M3e),e(M3e,vMr),e(sn,FMr),e(sn,E3e),e(E3e,TMr),e(sn,MMr),e(sn,C3e),e(C3e,EMr),e(sn,CMr),e(Sr,wMr),e(Sr,pe),e(pe,aE),e(aE,w3e),e(w3e,AMr),e(aE,yMr),e(aE,vU),e(vU,LMr),e(aE,xMr),e(pe,$Mr),e(pe,nE),e(nE,A3e),e(A3e,kMr),e(nE,SMr),e(nE,FU),e(FU,RMr),e(nE,PMr),e(pe,BMr),e(pe,sE),e(sE,y3e),e(y3e,IMr),e(sE,NMr),e(sE,TU),e(TU,qMr),e(sE,jMr),e(pe,DMr),e(pe,lE),e(lE,L3e),e(L3e,GMr),e(lE,OMr),e(lE,MU),e(MU,VMr),e(lE,XMr),e(pe,zMr),e(pe,iE),e(iE,x3e),e(x3e,WMr),e(iE,QMr),e(iE,EU),e(EU,HMr),e(iE,UMr),e(pe,JMr),e(pe,dE),e(dE,$3e),e($3e,YMr),e(dE,KMr),e(dE,CU),e(CU,ZMr),e(dE,eEr),e(pe,oEr),e(pe,cE),e(cE,k3e),e(k3e,rEr),e(cE,tEr),e(cE,wU),e(wU,aEr),e(cE,nEr),e(pe,sEr),e(pe,fE),e(fE,S3e),e(S3e,lEr),e(fE,iEr),e(fE,AU),e(AU,dEr),e(fE,cEr),e(pe,fEr),e(pe,mE),e(mE,R3e),e(R3e,mEr),e(mE,gEr),e(mE,yU),e(yU,hEr),e(mE,pEr),e(pe,_Er),e(pe,gE),e(gE,P3e),e(P3e,uEr),e(gE,bEr),e(gE,LU),e(LU,vEr),e(gE,FEr),e(pe,TEr),e(pe,hE),e(hE,B3e),e(B3e,MEr),e(hE,EEr),e(hE,xU),e(xU,CEr),e(hE,wEr),e(pe,AEr),e(pe,pE),e(pE,I3e),e(I3e,yEr),e(pE,LEr),e(pE,$U),e($U,xEr),e(pE,$Er),e(pe,kEr),e(pe,_E),e(_E,N3e),e(N3e,SEr),e(_E,REr),e(_E,kU),e(kU,PEr),e(_E,BEr),e(pe,IEr),e(pe,uE),e(uE,q3e),e(q3e,NEr),e(uE,qEr),e(uE,SU),e(SU,jEr),e(uE,DEr),e(pe,GEr),e(pe,bE),e(bE,j3e),e(j3e,OEr),e(bE,VEr),e(bE,RU),e(RU,XEr),e(bE,zEr),e(pe,WEr),e(pe,vE),e(vE,D3e),e(D3e,QEr),e(vE,HEr),e(vE,PU),e(PU,UEr),e(vE,JEr),e(pe,YEr),e(pe,FE),e(FE,G3e),e(G3e,KEr),e(FE,ZEr),e(FE,BU),e(BU,eCr),e(FE,oCr),e(Sr,rCr),M(TE,Sr,null),b(f,Ije,u),b(f,mc,u),e(mc,ME),e(ME,O3e),M(K8,O3e,null),e(mc,tCr),e(mc,V3e),e(V3e,aCr),b(f,Nje,u),b(f,nr,u),M(Z8,nr,null),e(nr,nCr),e(nr,gc),e(gc,sCr),e(gc,IU),e(IU,lCr),e(gc,iCr),e(gc,NU),e(NU,dCr),e(gc,cCr),e(nr,fCr),e(nr,e9),e(e9,mCr),e(e9,X3e),e(X3e,gCr),e(e9,hCr),e(nr,pCr),e(nr,Bt),M(o9,Bt,null),e(Bt,_Cr),e(Bt,z3e),e(z3e,uCr),e(Bt,bCr),e(Bt,hc),e(hc,vCr),e(hc,W3e),e(W3e,FCr),e(hc,TCr),e(hc,qU),e(qU,MCr),e(hc,ECr),e(Bt,CCr),M(EE,Bt,null),e(nr,wCr),e(nr,Rr),M(r9,Rr,null),e(Rr,ACr),e(Rr,Q3e),e(Q3e,yCr),e(Rr,LCr),e(Rr,ln),e(ln,xCr),e(ln,H3e),e(H3e,$Cr),e(ln,kCr),e(ln,U3e),e(U3e,SCr),e(ln,RCr),e(ln,J3e),e(J3e,PCr),e(ln,BCr),e(Rr,ICr),e(Rr,t9),e(t9,CE),e(CE,Y3e),e(Y3e,NCr),e(CE,qCr),e(CE,jU),e(jU,jCr),e(CE,DCr),e(t9,GCr),e(t9,wE),e(wE,K3e),e(K3e,OCr),e(wE,VCr),e(wE,DU),e(DU,XCr),e(wE,zCr),e(Rr,WCr),M(AE,Rr,null),b(f,qje,u),b(f,pc,u),e(pc,yE),e(yE,Z3e),M(a9,Z3e,null),e(pc,QCr),e(pc,eFe),e(eFe,HCr),b(f,jje,u),b(f,sr,u),M(n9,sr,null),e(sr,UCr),e(sr,_c),e(_c,JCr),e(_c,GU),e(GU,YCr),e(_c,KCr),e(_c,OU),e(OU,ZCr),e(_c,e5r),e(sr,o5r),e(sr,s9),e(s9,r5r),e(s9,oFe),e(oFe,t5r),e(s9,a5r),e(sr,n5r),e(sr,It),M(l9,It,null),e(It,s5r),e(It,rFe),e(rFe,l5r),e(It,i5r),e(It,uc),e(uc,d5r),e(uc,tFe),e(tFe,c5r),e(uc,f5r),e(uc,VU),e(VU,m5r),e(uc,g5r),e(It,h5r),M(LE,It,null),e(sr,p5r),e(sr,Pr),M(i9,Pr,null),e(Pr,_5r),e(Pr,aFe),e(aFe,u5r),e(Pr,b5r),e(Pr,dn),e(dn,v5r),e(dn,nFe),e(nFe,F5r),e(dn,T5r),e(dn,sFe),e(sFe,M5r),e(dn,E5r),e(dn,lFe),e(lFe,C5r),e(dn,w5r),e(Pr,A5r),e(Pr,iFe),e(iFe,xE),e(xE,dFe),e(dFe,y5r),e(xE,L5r),e(xE,XU),e(XU,x5r),e(xE,$5r),e(Pr,k5r),M($E,Pr,null),b(f,Dje,u),b(f,bc,u),e(bc,kE),e(kE,cFe),M(d9,cFe,null),e(bc,S5r),e(bc,fFe),e(fFe,R5r),b(f,Gje,u),b(f,lr,u),M(c9,lr,null),e(lr,P5r),e(lr,vc),e(vc,B5r),e(vc,zU),e(zU,I5r),e(vc,N5r),e(vc,WU),e(WU,q5r),e(vc,j5r),e(lr,D5r),e(lr,f9),e(f9,G5r),e(f9,mFe),e(mFe,O5r),e(f9,V5r),e(lr,X5r),e(lr,Nt),M(m9,Nt,null),e(Nt,z5r),e(Nt,gFe),e(gFe,W5r),e(Nt,Q5r),e(Nt,Fc),e(Fc,H5r),e(Fc,hFe),e(hFe,U5r),e(Fc,J5r),e(Fc,QU),e(QU,Y5r),e(Fc,K5r),e(Nt,Z5r),M(SE,Nt,null),e(lr,ewr),e(lr,Br),M(g9,Br,null),e(Br,owr),e(Br,pFe),e(pFe,rwr),e(Br,twr),e(Br,cn),e(cn,awr),e(cn,_Fe),e(_Fe,nwr),e(cn,swr),e(cn,uFe),e(uFe,lwr),e(cn,iwr),e(cn,bFe),e(bFe,dwr),e(cn,cwr),e(Br,fwr),e(Br,de),e(de,RE),e(RE,vFe),e(vFe,mwr),e(RE,gwr),e(RE,HU),e(HU,hwr),e(RE,pwr),e(de,_wr),e(de,PE),e(PE,FFe),e(FFe,uwr),e(PE,bwr),e(PE,UU),e(UU,vwr),e(PE,Fwr),e(de,Twr),e(de,BE),e(BE,TFe),e(TFe,Mwr),e(BE,Ewr),e(BE,JU),e(JU,Cwr),e(BE,wwr),e(de,Awr),e(de,IE),e(IE,MFe),e(MFe,ywr),e(IE,Lwr),e(IE,YU),e(YU,xwr),e(IE,$wr),e(de,kwr),e(de,NE),e(NE,EFe),e(EFe,Swr),e(NE,Rwr),e(NE,KU),e(KU,Pwr),e(NE,Bwr),e(de,Iwr),e(de,qE),e(qE,CFe),e(CFe,Nwr),e(qE,qwr),e(qE,ZU),e(ZU,jwr),e(qE,Dwr),e(de,Gwr),e(de,jE),e(jE,wFe),e(wFe,Owr),e(jE,Vwr),e(jE,eJ),e(eJ,Xwr),e(jE,zwr),e(de,Wwr),e(de,DE),e(DE,AFe),e(AFe,Qwr),e(DE,Hwr),e(DE,oJ),e(oJ,Uwr),e(DE,Jwr),e(de,Ywr),e(de,GE),e(GE,yFe),e(yFe,Kwr),e(GE,Zwr),e(GE,rJ),e(rJ,e0r),e(GE,o0r),e(de,r0r),e(de,OE),e(OE,LFe),e(LFe,t0r),e(OE,a0r),e(OE,tJ),e(tJ,n0r),e(OE,s0r),e(de,l0r),e(de,VE),e(VE,xFe),e(xFe,i0r),e(VE,d0r),e(VE,aJ),e(aJ,c0r),e(VE,f0r),e(de,m0r),e(de,XE),e(XE,$Fe),e($Fe,g0r),e(XE,h0r),e(XE,nJ),e(nJ,p0r),e(XE,_0r),e(de,u0r),e(de,zE),e(zE,kFe),e(kFe,b0r),e(zE,v0r),e(zE,sJ),e(sJ,F0r),e(zE,T0r),e(de,M0r),e(de,WE),e(WE,SFe),e(SFe,E0r),e(WE,C0r),e(WE,lJ),e(lJ,w0r),e(WE,A0r),e(de,y0r),e(de,QE),e(QE,RFe),e(RFe,L0r),e(QE,x0r),e(QE,iJ),e(iJ,$0r),e(QE,k0r),e(de,S0r),e(de,HE),e(HE,PFe),e(PFe,R0r),e(HE,P0r),e(HE,dJ),e(dJ,B0r),e(HE,I0r),e(de,N0r),e(de,UE),e(UE,BFe),e(BFe,q0r),e(UE,j0r),e(UE,cJ),e(cJ,D0r),e(UE,G0r),e(de,O0r),e(de,JE),e(JE,IFe),e(IFe,V0r),e(JE,X0r),e(JE,fJ),e(fJ,z0r),e(JE,W0r),e(de,Q0r),e(de,YE),e(YE,NFe),e(NFe,H0r),e(YE,U0r),e(YE,mJ),e(mJ,J0r),e(YE,Y0r),e(de,K0r),e(de,KE),e(KE,qFe),e(qFe,Z0r),e(KE,e6r),e(KE,gJ),e(gJ,o6r),e(KE,r6r),e(Br,t6r),M(ZE,Br,null),b(f,Oje,u),b(f,Tc,u),e(Tc,eC),e(eC,jFe),M(h9,jFe,null),e(Tc,a6r),e(Tc,DFe),e(DFe,n6r),b(f,Vje,u),b(f,ir,u),M(p9,ir,null),e(ir,s6r),e(ir,Mc),e(Mc,l6r),e(Mc,hJ),e(hJ,i6r),e(Mc,d6r),e(Mc,pJ),e(pJ,c6r),e(Mc,f6r),e(ir,m6r),e(ir,_9),e(_9,g6r),e(_9,GFe),e(GFe,h6r),e(_9,p6r),e(ir,_6r),e(ir,qt),M(u9,qt,null),e(qt,u6r),e(qt,OFe),e(OFe,b6r),e(qt,v6r),e(qt,Ec),e(Ec,F6r),e(Ec,VFe),e(VFe,T6r),e(Ec,M6r),e(Ec,_J),e(_J,E6r),e(Ec,C6r),e(qt,w6r),M(oC,qt,null),e(ir,A6r),e(ir,Ir),M(b9,Ir,null),e(Ir,y6r),e(Ir,XFe),e(XFe,L6r),e(Ir,x6r),e(Ir,fn),e(fn,$6r),e(fn,zFe),e(zFe,k6r),e(fn,S6r),e(fn,WFe),e(WFe,R6r),e(fn,P6r),e(fn,QFe),e(QFe,B6r),e(fn,I6r),e(Ir,N6r),e(Ir,ce),e(ce,rC),e(rC,HFe),e(HFe,q6r),e(rC,j6r),e(rC,uJ),e(uJ,D6r),e(rC,G6r),e(ce,O6r),e(ce,tC),e(tC,UFe),e(UFe,V6r),e(tC,X6r),e(tC,bJ),e(bJ,z6r),e(tC,W6r),e(ce,Q6r),e(ce,aC),e(aC,JFe),e(JFe,H6r),e(aC,U6r),e(aC,vJ),e(vJ,J6r),e(aC,Y6r),e(ce,K6r),e(ce,nC),e(nC,YFe),e(YFe,Z6r),e(nC,eAr),e(nC,FJ),e(FJ,oAr),e(nC,rAr),e(ce,tAr),e(ce,sC),e(sC,KFe),e(KFe,aAr),e(sC,nAr),e(sC,TJ),e(TJ,sAr),e(sC,lAr),e(ce,iAr),e(ce,lC),e(lC,ZFe),e(ZFe,dAr),e(lC,cAr),e(lC,MJ),e(MJ,fAr),e(lC,mAr),e(ce,gAr),e(ce,iC),e(iC,eTe),e(eTe,hAr),e(iC,pAr),e(iC,EJ),e(EJ,_Ar),e(iC,uAr),e(ce,bAr),e(ce,dC),e(dC,oTe),e(oTe,vAr),e(dC,FAr),e(dC,CJ),e(CJ,TAr),e(dC,MAr),e(ce,EAr),e(ce,cC),e(cC,rTe),e(rTe,CAr),e(cC,wAr),e(cC,wJ),e(wJ,AAr),e(cC,yAr),e(ce,LAr),e(ce,fC),e(fC,tTe),e(tTe,xAr),e(fC,$Ar),e(fC,AJ),e(AJ,kAr),e(fC,SAr),e(ce,RAr),e(ce,mC),e(mC,aTe),e(aTe,PAr),e(mC,BAr),e(mC,yJ),e(yJ,IAr),e(mC,NAr),e(ce,qAr),e(ce,gC),e(gC,nTe),e(nTe,jAr),e(gC,DAr),e(gC,LJ),e(LJ,GAr),e(gC,OAr),e(ce,VAr),e(ce,hC),e(hC,sTe),e(sTe,XAr),e(hC,zAr),e(hC,xJ),e(xJ,WAr),e(hC,QAr),e(ce,HAr),e(ce,pC),e(pC,lTe),e(lTe,UAr),e(pC,JAr),e(pC,$J),e($J,YAr),e(pC,KAr),e(ce,ZAr),e(ce,_C),e(_C,iTe),e(iTe,eyr),e(_C,oyr),e(_C,kJ),e(kJ,ryr),e(_C,tyr),e(ce,ayr),e(ce,uC),e(uC,dTe),e(dTe,nyr),e(uC,syr),e(uC,SJ),e(SJ,lyr),e(uC,iyr),e(ce,dyr),e(ce,bC),e(bC,cTe),e(cTe,cyr),e(bC,fyr),e(bC,RJ),e(RJ,myr),e(bC,gyr),e(ce,hyr),e(ce,vC),e(vC,fTe),e(fTe,pyr),e(vC,_yr),e(vC,PJ),e(PJ,uyr),e(vC,byr),e(ce,vyr),e(ce,FC),e(FC,mTe),e(mTe,Fyr),e(FC,Tyr),e(FC,BJ),e(BJ,Myr),e(FC,Eyr),e(ce,Cyr),e(ce,TC),e(TC,gTe),e(gTe,wyr),e(TC,Ayr),e(TC,IJ),e(IJ,yyr),e(TC,Lyr),e(Ir,xyr),M(MC,Ir,null),b(f,Xje,u),b(f,Cc,u),e(Cc,EC),e(EC,hTe),M(v9,hTe,null),e(Cc,$yr),e(Cc,pTe),e(pTe,kyr),b(f,zje,u),b(f,dr,u),M(F9,dr,null),e(dr,Syr),e(dr,wc),e(wc,Ryr),e(wc,NJ),e(NJ,Pyr),e(wc,Byr),e(wc,qJ),e(qJ,Iyr),e(wc,Nyr),e(dr,qyr),e(dr,T9),e(T9,jyr),e(T9,_Te),e(_Te,Dyr),e(T9,Gyr),e(dr,Oyr),e(dr,jt),M(M9,jt,null),e(jt,Vyr),e(jt,uTe),e(uTe,Xyr),e(jt,zyr),e(jt,Ac),e(Ac,Wyr),e(Ac,bTe),e(bTe,Qyr),e(Ac,Hyr),e(Ac,jJ),e(jJ,Uyr),e(Ac,Jyr),e(jt,Yyr),M(CC,jt,null),e(dr,Kyr),e(dr,Nr),M(E9,Nr,null),e(Nr,Zyr),e(Nr,vTe),e(vTe,eLr),e(Nr,oLr),e(Nr,mn),e(mn,rLr),e(mn,FTe),e(FTe,tLr),e(mn,aLr),e(mn,TTe),e(TTe,nLr),e(mn,sLr),e(mn,MTe),e(MTe,lLr),e(mn,iLr),e(Nr,dLr),e(Nr,ETe),e(ETe,wC),e(wC,CTe),e(CTe,cLr),e(wC,fLr),e(wC,DJ),e(DJ,mLr),e(wC,gLr),e(Nr,hLr),M(AC,Nr,null),b(f,Wje,u),b(f,yc,u),e(yc,yC),e(yC,wTe),M(C9,wTe,null),e(yc,pLr),e(yc,ATe),e(ATe,_Lr),b(f,Qje,u),b(f,cr,u),M(w9,cr,null),e(cr,uLr),e(cr,Lc),e(Lc,bLr),e(Lc,GJ),e(GJ,vLr),e(Lc,FLr),e(Lc,OJ),e(OJ,TLr),e(Lc,MLr),e(cr,ELr),e(cr,A9),e(A9,CLr),e(A9,yTe),e(yTe,wLr),e(A9,ALr),e(cr,yLr),e(cr,Dt),M(y9,Dt,null),e(Dt,LLr),e(Dt,LTe),e(LTe,xLr),e(Dt,$Lr),e(Dt,xc),e(xc,kLr),e(xc,xTe),e(xTe,SLr),e(xc,RLr),e(xc,VJ),e(VJ,PLr),e(xc,BLr),e(Dt,ILr),M(LC,Dt,null),e(cr,NLr),e(cr,qr),M(L9,qr,null),e(qr,qLr),e(qr,$Te),e($Te,jLr),e(qr,DLr),e(qr,gn),e(gn,GLr),e(gn,kTe),e(kTe,OLr),e(gn,VLr),e(gn,STe),e(STe,XLr),e(gn,zLr),e(gn,RTe),e(RTe,WLr),e(gn,QLr),e(qr,HLr),e(qr,PTe),e(PTe,xC),e(xC,BTe),e(BTe,ULr),e(xC,JLr),e(xC,XJ),e(XJ,YLr),e(xC,KLr),e(qr,ZLr),M($C,qr,null),b(f,Hje,u),b(f,$c,u),e($c,kC),e(kC,ITe),M(x9,ITe,null),e($c,e8r),e($c,NTe),e(NTe,o8r),b(f,Uje,u),b(f,fr,u),M($9,fr,null),e(fr,r8r),e(fr,kc),e(kc,t8r),e(kc,zJ),e(zJ,a8r),e(kc,n8r),e(kc,WJ),e(WJ,s8r),e(kc,l8r),e(fr,i8r),e(fr,k9),e(k9,d8r),e(k9,qTe),e(qTe,c8r),e(k9,f8r),e(fr,m8r),e(fr,Gt),M(S9,Gt,null),e(Gt,g8r),e(Gt,jTe),e(jTe,h8r),e(Gt,p8r),e(Gt,Sc),e(Sc,_8r),e(Sc,DTe),e(DTe,u8r),e(Sc,b8r),e(Sc,QJ),e(QJ,v8r),e(Sc,F8r),e(Gt,T8r),M(SC,Gt,null),e(fr,M8r),e(fr,jr),M(R9,jr,null),e(jr,E8r),e(jr,GTe),e(GTe,C8r),e(jr,w8r),e(jr,hn),e(hn,A8r),e(hn,OTe),e(OTe,y8r),e(hn,L8r),e(hn,VTe),e(VTe,x8r),e(hn,$8r),e(hn,XTe),e(XTe,k8r),e(hn,S8r),e(jr,R8r),e(jr,te),e(te,RC),e(RC,zTe),e(zTe,P8r),e(RC,B8r),e(RC,HJ),e(HJ,I8r),e(RC,N8r),e(te,q8r),e(te,PC),e(PC,WTe),e(WTe,j8r),e(PC,D8r),e(PC,UJ),e(UJ,G8r),e(PC,O8r),e(te,V8r),e(te,BC),e(BC,QTe),e(QTe,X8r),e(BC,z8r),e(BC,JJ),e(JJ,W8r),e(BC,Q8r),e(te,H8r),e(te,IC),e(IC,HTe),e(HTe,U8r),e(IC,J8r),e(IC,YJ),e(YJ,Y8r),e(IC,K8r),e(te,Z8r),e(te,NC),e(NC,UTe),e(UTe,e9r),e(NC,o9r),e(NC,KJ),e(KJ,r9r),e(NC,t9r),e(te,a9r),e(te,qC),e(qC,JTe),e(JTe,n9r),e(qC,s9r),e(qC,ZJ),e(ZJ,l9r),e(qC,i9r),e(te,d9r),e(te,jC),e(jC,YTe),e(YTe,c9r),e(jC,f9r),e(jC,eY),e(eY,m9r),e(jC,g9r),e(te,h9r),e(te,DC),e(DC,KTe),e(KTe,p9r),e(DC,_9r),e(DC,oY),e(oY,u9r),e(DC,b9r),e(te,v9r),e(te,GC),e(GC,ZTe),e(ZTe,F9r),e(GC,T9r),e(GC,rY),e(rY,M9r),e(GC,E9r),e(te,C9r),e(te,OC),e(OC,e7e),e(e7e,w9r),e(OC,A9r),e(OC,tY),e(tY,y9r),e(OC,L9r),e(te,x9r),e(te,VC),e(VC,o7e),e(o7e,$9r),e(VC,k9r),e(VC,aY),e(aY,S9r),e(VC,R9r),e(te,P9r),e(te,XC),e(XC,r7e),e(r7e,B9r),e(XC,I9r),e(XC,nY),e(nY,N9r),e(XC,q9r),e(te,j9r),e(te,zC),e(zC,t7e),e(t7e,D9r),e(zC,G9r),e(zC,sY),e(sY,O9r),e(zC,V9r),e(te,X9r),e(te,WC),e(WC,a7e),e(a7e,z9r),e(WC,W9r),e(WC,lY),e(lY,Q9r),e(WC,H9r),e(te,U9r),e(te,QC),e(QC,n7e),e(n7e,J9r),e(QC,Y9r),e(QC,iY),e(iY,K9r),e(QC,Z9r),e(te,exr),e(te,HC),e(HC,s7e),e(s7e,oxr),e(HC,rxr),e(HC,dY),e(dY,txr),e(HC,axr),e(te,nxr),e(te,UC),e(UC,l7e),e(l7e,sxr),e(UC,lxr),e(UC,cY),e(cY,ixr),e(UC,dxr),e(te,cxr),e(te,JC),e(JC,i7e),e(i7e,fxr),e(JC,mxr),e(JC,fY),e(fY,gxr),e(JC,hxr),e(te,pxr),e(te,YC),e(YC,d7e),e(d7e,_xr),e(YC,uxr),e(YC,mY),e(mY,bxr),e(YC,vxr),e(te,Fxr),e(te,KC),e(KC,c7e),e(c7e,Txr),e(KC,Mxr),e(KC,gY),e(gY,Exr),e(KC,Cxr),e(te,wxr),e(te,ZC),e(ZC,f7e),e(f7e,Axr),e(ZC,yxr),e(ZC,hY),e(hY,Lxr),e(ZC,xxr),e(te,$xr),e(te,e5),e(e5,m7e),e(m7e,kxr),e(e5,Sxr),e(e5,pY),e(pY,Rxr),e(e5,Pxr),e(te,Bxr),e(te,o5),e(o5,g7e),e(g7e,Ixr),e(o5,Nxr),e(o5,_Y),e(_Y,qxr),e(o5,jxr),e(te,Dxr),e(te,r5),e(r5,h7e),e(h7e,Gxr),e(r5,Oxr),e(r5,uY),e(uY,Vxr),e(r5,Xxr),e(te,zxr),e(te,t5),e(t5,p7e),e(p7e,Wxr),e(t5,Qxr),e(t5,bY),e(bY,Hxr),e(t5,Uxr),e(jr,Jxr),M(a5,jr,null),b(f,Jje,u),b(f,Rc,u),e(Rc,n5),e(n5,_7e),M(P9,_7e,null),e(Rc,Yxr),e(Rc,u7e),e(u7e,Kxr),b(f,Yje,u),b(f,mr,u),M(B9,mr,null),e(mr,Zxr),e(mr,Pc),e(Pc,e$r),e(Pc,vY),e(vY,o$r),e(Pc,r$r),e(Pc,FY),e(FY,t$r),e(Pc,a$r),e(mr,n$r),e(mr,I9),e(I9,s$r),e(I9,b7e),e(b7e,l$r),e(I9,i$r),e(mr,d$r),e(mr,Ot),M(N9,Ot,null),e(Ot,c$r),e(Ot,v7e),e(v7e,f$r),e(Ot,m$r),e(Ot,Bc),e(Bc,g$r),e(Bc,F7e),e(F7e,h$r),e(Bc,p$r),e(Bc,TY),e(TY,_$r),e(Bc,u$r),e(Ot,b$r),M(s5,Ot,null),e(mr,v$r),e(mr,Dr),M(q9,Dr,null),e(Dr,F$r),e(Dr,T7e),e(T7e,T$r),e(Dr,M$r),e(Dr,pn),e(pn,E$r),e(pn,M7e),e(M7e,C$r),e(pn,w$r),e(pn,E7e),e(E7e,A$r),e(pn,y$r),e(pn,C7e),e(C7e,L$r),e(pn,x$r),e(Dr,$$r),e(Dr,Re),e(Re,l5),e(l5,w7e),e(w7e,k$r),e(l5,S$r),e(l5,MY),e(MY,R$r),e(l5,P$r),e(Re,B$r),e(Re,i5),e(i5,A7e),e(A7e,I$r),e(i5,N$r),e(i5,EY),e(EY,q$r),e(i5,j$r),e(Re,D$r),e(Re,d5),e(d5,y7e),e(y7e,G$r),e(d5,O$r),e(d5,CY),e(CY,V$r),e(d5,X$r),e(Re,z$r),e(Re,c5),e(c5,L7e),e(L7e,W$r),e(c5,Q$r),e(c5,wY),e(wY,H$r),e(c5,U$r),e(Re,J$r),e(Re,f5),e(f5,x7e),e(x7e,Y$r),e(f5,K$r),e(f5,AY),e(AY,Z$r),e(f5,ekr),e(Re,okr),e(Re,m5),e(m5,$7e),e($7e,rkr),e(m5,tkr),e(m5,yY),e(yY,akr),e(m5,nkr),e(Re,skr),e(Re,g5),e(g5,k7e),e(k7e,lkr),e(g5,ikr),e(g5,LY),e(LY,dkr),e(g5,ckr),e(Re,fkr),e(Re,h5),e(h5,S7e),e(S7e,mkr),e(h5,gkr),e(h5,xY),e(xY,hkr),e(h5,pkr),e(Re,_kr),e(Re,p5),e(p5,R7e),e(R7e,ukr),e(p5,bkr),e(p5,$Y),e($Y,vkr),e(p5,Fkr),e(Dr,Tkr),M(_5,Dr,null),b(f,Kje,u),b(f,Ic,u),e(Ic,u5),e(u5,P7e),M(j9,P7e,null),e(Ic,Mkr),e(Ic,B7e),e(B7e,Ekr),b(f,Zje,u),b(f,gr,u),M(D9,gr,null),e(gr,Ckr),e(gr,Nc),e(Nc,wkr),e(Nc,kY),e(kY,Akr),e(Nc,ykr),e(Nc,SY),e(SY,Lkr),e(Nc,xkr),e(gr,$kr),e(gr,G9),e(G9,kkr),e(G9,I7e),e(I7e,Skr),e(G9,Rkr),e(gr,Pkr),e(gr,Vt),M(O9,Vt,null),e(Vt,Bkr),e(Vt,N7e),e(N7e,Ikr),e(Vt,Nkr),e(Vt,qc),e(qc,qkr),e(qc,q7e),e(q7e,jkr),e(qc,Dkr),e(qc,RY),e(RY,Gkr),e(qc,Okr),e(Vt,Vkr),M(b5,Vt,null),e(gr,Xkr),e(gr,Gr),M(V9,Gr,null),e(Gr,zkr),e(Gr,j7e),e(j7e,Wkr),e(Gr,Qkr),e(Gr,_n),e(_n,Hkr),e(_n,D7e),e(D7e,Ukr),e(_n,Jkr),e(_n,G7e),e(G7e,Ykr),e(_n,Kkr),e(_n,O7e),e(O7e,Zkr),e(_n,eSr),e(Gr,oSr),e(Gr,Ee),e(Ee,v5),e(v5,V7e),e(V7e,rSr),e(v5,tSr),e(v5,PY),e(PY,aSr),e(v5,nSr),e(Ee,sSr),e(Ee,F5),e(F5,X7e),e(X7e,lSr),e(F5,iSr),e(F5,BY),e(BY,dSr),e(F5,cSr),e(Ee,fSr),e(Ee,T5),e(T5,z7e),e(z7e,mSr),e(T5,gSr),e(T5,IY),e(IY,hSr),e(T5,pSr),e(Ee,_Sr),e(Ee,M5),e(M5,W7e),e(W7e,uSr),e(M5,bSr),e(M5,NY),e(NY,vSr),e(M5,FSr),e(Ee,TSr),e(Ee,E5),e(E5,Q7e),e(Q7e,MSr),e(E5,ESr),e(E5,qY),e(qY,CSr),e(E5,wSr),e(Ee,ASr),e(Ee,C5),e(C5,H7e),e(H7e,ySr),e(C5,LSr),e(C5,jY),e(jY,xSr),e(C5,$Sr),e(Ee,kSr),e(Ee,w5),e(w5,U7e),e(U7e,SSr),e(w5,RSr),e(w5,DY),e(DY,PSr),e(w5,BSr),e(Ee,ISr),e(Ee,A5),e(A5,J7e),e(J7e,NSr),e(A5,qSr),e(A5,GY),e(GY,jSr),e(A5,DSr),e(Ee,GSr),e(Ee,y5),e(y5,Y7e),e(Y7e,OSr),e(y5,VSr),e(y5,OY),e(OY,XSr),e(y5,zSr),e(Ee,WSr),e(Ee,L5),e(L5,K7e),e(K7e,QSr),e(L5,HSr),e(L5,VY),e(VY,USr),e(L5,JSr),e(Ee,YSr),e(Ee,x5),e(x5,Z7e),e(Z7e,KSr),e(x5,ZSr),e(x5,XY),e(XY,eRr),e(x5,oRr),e(Ee,rRr),e(Ee,$5),e($5,eMe),e(eMe,tRr),e($5,aRr),e($5,zY),e(zY,nRr),e($5,sRr),e(Gr,lRr),M(k5,Gr,null),b(f,eDe,u),b(f,jc,u),e(jc,S5),e(S5,oMe),M(X9,oMe,null),e(jc,iRr),e(jc,rMe),e(rMe,dRr),b(f,oDe,u),b(f,hr,u),M(z9,hr,null),e(hr,cRr),e(hr,Dc),e(Dc,fRr),e(Dc,WY),e(WY,mRr),e(Dc,gRr),e(Dc,QY),e(QY,hRr),e(Dc,pRr),e(hr,_Rr),e(hr,W9),e(W9,uRr),e(W9,tMe),e(tMe,bRr),e(W9,vRr),e(hr,FRr),e(hr,Xt),M(Q9,Xt,null),e(Xt,TRr),e(Xt,aMe),e(aMe,MRr),e(Xt,ERr),e(Xt,Gc),e(Gc,CRr),e(Gc,nMe),e(nMe,wRr),e(Gc,ARr),e(Gc,HY),e(HY,yRr),e(Gc,LRr),e(Xt,xRr),M(R5,Xt,null),e(hr,$Rr),e(hr,Or),M(H9,Or,null),e(Or,kRr),e(Or,sMe),e(sMe,SRr),e(Or,RRr),e(Or,un),e(un,PRr),e(un,lMe),e(lMe,BRr),e(un,IRr),e(un,iMe),e(iMe,NRr),e(un,qRr),e(un,dMe),e(dMe,jRr),e(un,DRr),e(Or,GRr),e(Or,Le),e(Le,P5),e(P5,cMe),e(cMe,ORr),e(P5,VRr),e(P5,UY),e(UY,XRr),e(P5,zRr),e(Le,WRr),e(Le,B5),e(B5,fMe),e(fMe,QRr),e(B5,HRr),e(B5,JY),e(JY,URr),e(B5,JRr),e(Le,YRr),e(Le,I5),e(I5,mMe),e(mMe,KRr),e(I5,ZRr),e(I5,YY),e(YY,ePr),e(I5,oPr),e(Le,rPr),e(Le,N5),e(N5,gMe),e(gMe,tPr),e(N5,aPr),e(N5,KY),e(KY,nPr),e(N5,sPr),e(Le,lPr),e(Le,q5),e(q5,hMe),e(hMe,iPr),e(q5,dPr),e(q5,ZY),e(ZY,cPr),e(q5,fPr),e(Le,mPr),e(Le,j5),e(j5,pMe),e(pMe,gPr),e(j5,hPr),e(j5,eK),e(eK,pPr),e(j5,_Pr),e(Le,uPr),e(Le,D5),e(D5,_Me),e(_Me,bPr),e(D5,vPr),e(D5,oK),e(oK,FPr),e(D5,TPr),e(Le,MPr),e(Le,G5),e(G5,uMe),e(uMe,EPr),e(G5,CPr),e(G5,rK),e(rK,wPr),e(G5,APr),e(Le,yPr),e(Le,O5),e(O5,bMe),e(bMe,LPr),e(O5,xPr),e(O5,tK),e(tK,$Pr),e(O5,kPr),e(Le,SPr),e(Le,V5),e(V5,vMe),e(vMe,RPr),e(V5,PPr),e(V5,aK),e(aK,BPr),e(V5,IPr),e(Or,NPr),M(X5,Or,null),b(f,rDe,u),b(f,Oc,u),e(Oc,z5),e(z5,FMe),M(U9,FMe,null),e(Oc,qPr),e(Oc,TMe),e(TMe,jPr),b(f,tDe,u),b(f,pr,u),M(J9,pr,null),e(pr,DPr),e(pr,Vc),e(Vc,GPr),e(Vc,nK),e(nK,OPr),e(Vc,VPr),e(Vc,sK),e(sK,XPr),e(Vc,zPr),e(pr,WPr),e(pr,Y9),e(Y9,QPr),e(Y9,MMe),e(MMe,HPr),e(Y9,UPr),e(pr,JPr),e(pr,zt),M(K9,zt,null),e(zt,YPr),e(zt,EMe),e(EMe,KPr),e(zt,ZPr),e(zt,Xc),e(Xc,eBr),e(Xc,CMe),e(CMe,oBr),e(Xc,rBr),e(Xc,lK),e(lK,tBr),e(Xc,aBr),e(zt,nBr),M(W5,zt,null),e(pr,sBr),e(pr,Vr),M(Z9,Vr,null),e(Vr,lBr),e(Vr,wMe),e(wMe,iBr),e(Vr,dBr),e(Vr,bn),e(bn,cBr),e(bn,AMe),e(AMe,fBr),e(bn,mBr),e(bn,yMe),e(yMe,gBr),e(bn,hBr),e(bn,LMe),e(LMe,pBr),e(bn,_Br),e(Vr,uBr),e(Vr,Pe),e(Pe,Q5),e(Q5,xMe),e(xMe,bBr),e(Q5,vBr),e(Q5,iK),e(iK,FBr),e(Q5,TBr),e(Pe,MBr),e(Pe,H5),e(H5,$Me),e($Me,EBr),e(H5,CBr),e(H5,dK),e(dK,wBr),e(H5,ABr),e(Pe,yBr),e(Pe,U5),e(U5,kMe),e(kMe,LBr),e(U5,xBr),e(U5,cK),e(cK,$Br),e(U5,kBr),e(Pe,SBr),e(Pe,J5),e(J5,SMe),e(SMe,RBr),e(J5,PBr),e(J5,fK),e(fK,BBr),e(J5,IBr),e(Pe,NBr),e(Pe,Y5),e(Y5,RMe),e(RMe,qBr),e(Y5,jBr),e(Y5,mK),e(mK,DBr),e(Y5,GBr),e(Pe,OBr),e(Pe,K5),e(K5,PMe),e(PMe,VBr),e(K5,XBr),e(K5,gK),e(gK,zBr),e(K5,WBr),e(Pe,QBr),e(Pe,Z5),e(Z5,BMe),e(BMe,HBr),e(Z5,UBr),e(Z5,hK),e(hK,JBr),e(Z5,YBr),e(Pe,KBr),e(Pe,ew),e(ew,IMe),e(IMe,ZBr),e(ew,eIr),e(ew,pK),e(pK,oIr),e(ew,rIr),e(Pe,tIr),e(Pe,ow),e(ow,NMe),e(NMe,aIr),e(ow,nIr),e(ow,_K),e(_K,sIr),e(ow,lIr),e(Vr,iIr),M(rw,Vr,null),b(f,aDe,u),b(f,zc,u),e(zc,tw),e(tw,qMe),M(ex,qMe,null),e(zc,dIr),e(zc,jMe),e(jMe,cIr),b(f,nDe,u),b(f,_r,u),M(ox,_r,null),e(_r,fIr),e(_r,Wc),e(Wc,mIr),e(Wc,uK),e(uK,gIr),e(Wc,hIr),e(Wc,bK),e(bK,pIr),e(Wc,_Ir),e(_r,uIr),e(_r,rx),e(rx,bIr),e(rx,DMe),e(DMe,vIr),e(rx,FIr),e(_r,TIr),e(_r,Wt),M(tx,Wt,null),e(Wt,MIr),e(Wt,GMe),e(GMe,EIr),e(Wt,CIr),e(Wt,Qc),e(Qc,wIr),e(Qc,OMe),e(OMe,AIr),e(Qc,yIr),e(Qc,vK),e(vK,LIr),e(Qc,xIr),e(Wt,$Ir),M(aw,Wt,null),e(_r,kIr),e(_r,Xr),M(ax,Xr,null),e(Xr,SIr),e(Xr,VMe),e(VMe,RIr),e(Xr,PIr),e(Xr,vn),e(vn,BIr),e(vn,XMe),e(XMe,IIr),e(vn,NIr),e(vn,zMe),e(zMe,qIr),e(vn,jIr),e(vn,WMe),e(WMe,DIr),e(vn,GIr),e(Xr,OIr),e(Xr,xe),e(xe,nw),e(nw,QMe),e(QMe,VIr),e(nw,XIr),e(nw,FK),e(FK,zIr),e(nw,WIr),e(xe,QIr),e(xe,sw),e(sw,HMe),e(HMe,HIr),e(sw,UIr),e(sw,TK),e(TK,JIr),e(sw,YIr),e(xe,KIr),e(xe,lw),e(lw,UMe),e(UMe,ZIr),e(lw,eNr),e(lw,MK),e(MK,oNr),e(lw,rNr),e(xe,tNr),e(xe,iw),e(iw,JMe),e(JMe,aNr),e(iw,nNr),e(iw,EK),e(EK,sNr),e(iw,lNr),e(xe,iNr),e(xe,dw),e(dw,YMe),e(YMe,dNr),e(dw,cNr),e(dw,CK),e(CK,fNr),e(dw,mNr),e(xe,gNr),e(xe,cw),e(cw,KMe),e(KMe,hNr),e(cw,pNr),e(cw,wK),e(wK,_Nr),e(cw,uNr),e(xe,bNr),e(xe,fw),e(fw,ZMe),e(ZMe,vNr),e(fw,FNr),e(fw,AK),e(AK,TNr),e(fw,MNr),e(xe,ENr),e(xe,mw),e(mw,eEe),e(eEe,CNr),e(mw,wNr),e(mw,yK),e(yK,ANr),e(mw,yNr),e(xe,LNr),e(xe,gw),e(gw,oEe),e(oEe,xNr),e(gw,$Nr),e(gw,LK),e(LK,kNr),e(gw,SNr),e(xe,RNr),e(xe,hw),e(hw,rEe),e(rEe,PNr),e(hw,BNr),e(hw,xK),e(xK,INr),e(hw,NNr),e(Xr,qNr),M(pw,Xr,null),b(f,sDe,u),b(f,Hc,u),e(Hc,_w),e(_w,tEe),M(nx,tEe,null),e(Hc,jNr),e(Hc,aEe),e(aEe,DNr),b(f,lDe,u),b(f,ur,u),M(sx,ur,null),e(ur,GNr),e(ur,Uc),e(Uc,ONr),e(Uc,$K),e($K,VNr),e(Uc,XNr),e(Uc,kK),e(kK,zNr),e(Uc,WNr),e(ur,QNr),e(ur,lx),e(lx,HNr),e(lx,nEe),e(nEe,UNr),e(lx,JNr),e(ur,YNr),e(ur,Qt),M(ix,Qt,null),e(Qt,KNr),e(Qt,sEe),e(sEe,ZNr),e(Qt,eqr),e(Qt,Jc),e(Jc,oqr),e(Jc,lEe),e(lEe,rqr),e(Jc,tqr),e(Jc,SK),e(SK,aqr),e(Jc,nqr),e(Qt,sqr),M(uw,Qt,null),e(ur,lqr),e(ur,zr),M(dx,zr,null),e(zr,iqr),e(zr,iEe),e(iEe,dqr),e(zr,cqr),e(zr,Fn),e(Fn,fqr),e(Fn,dEe),e(dEe,mqr),e(Fn,gqr),e(Fn,cEe),e(cEe,hqr),e(Fn,pqr),e(Fn,fEe),e(fEe,_qr),e(Fn,uqr),e(zr,bqr),e(zr,$e),e($e,bw),e(bw,mEe),e(mEe,vqr),e(bw,Fqr),e(bw,RK),e(RK,Tqr),e(bw,Mqr),e($e,Eqr),e($e,vw),e(vw,gEe),e(gEe,Cqr),e(vw,wqr),e(vw,PK),e(PK,Aqr),e(vw,yqr),e($e,Lqr),e($e,Fw),e(Fw,hEe),e(hEe,xqr),e(Fw,$qr),e(Fw,BK),e(BK,kqr),e(Fw,Sqr),e($e,Rqr),e($e,Tw),e(Tw,pEe),e(pEe,Pqr),e(Tw,Bqr),e(Tw,IK),e(IK,Iqr),e(Tw,Nqr),e($e,qqr),e($e,Mw),e(Mw,_Ee),e(_Ee,jqr),e(Mw,Dqr),e(Mw,NK),e(NK,Gqr),e(Mw,Oqr),e($e,Vqr),e($e,Ew),e(Ew,uEe),e(uEe,Xqr),e(Ew,zqr),e(Ew,qK),e(qK,Wqr),e(Ew,Qqr),e($e,Hqr),e($e,Cw),e(Cw,bEe),e(bEe,Uqr),e(Cw,Jqr),e(Cw,jK),e(jK,Yqr),e(Cw,Kqr),e($e,Zqr),e($e,ww),e(ww,vEe),e(vEe,ejr),e(ww,ojr),e(ww,DK),e(DK,rjr),e(ww,tjr),e($e,ajr),e($e,Aw),e(Aw,FEe),e(FEe,njr),e(Aw,sjr),e(Aw,GK),e(GK,ljr),e(Aw,ijr),e($e,djr),e($e,yw),e(yw,TEe),e(TEe,cjr),e(yw,fjr),e(yw,OK),e(OK,mjr),e(yw,gjr),e(zr,hjr),M(Lw,zr,null),b(f,iDe,u),b(f,Yc,u),e(Yc,xw),e(xw,MEe),M(cx,MEe,null),e(Yc,pjr),e(Yc,EEe),e(EEe,_jr),b(f,dDe,u),b(f,br,u),M(fx,br,null),e(br,ujr),e(br,Kc),e(Kc,bjr),e(Kc,VK),e(VK,vjr),e(Kc,Fjr),e(Kc,XK),e(XK,Tjr),e(Kc,Mjr),e(br,Ejr),e(br,mx),e(mx,Cjr),e(mx,CEe),e(CEe,wjr),e(mx,Ajr),e(br,yjr),e(br,Ht),M(gx,Ht,null),e(Ht,Ljr),e(Ht,wEe),e(wEe,xjr),e(Ht,$jr),e(Ht,Zc),e(Zc,kjr),e(Zc,AEe),e(AEe,Sjr),e(Zc,Rjr),e(Zc,zK),e(zK,Pjr),e(Zc,Bjr),e(Ht,Ijr),M($w,Ht,null),e(br,Njr),e(br,Wr),M(hx,Wr,null),e(Wr,qjr),e(Wr,yEe),e(yEe,jjr),e(Wr,Djr),e(Wr,Tn),e(Tn,Gjr),e(Tn,LEe),e(LEe,Ojr),e(Tn,Vjr),e(Tn,xEe),e(xEe,Xjr),e(Tn,zjr),e(Tn,$Ee),e($Ee,Wjr),e(Tn,Qjr),e(Wr,Hjr),e(Wr,De),e(De,kw),e(kw,kEe),e(kEe,Ujr),e(kw,Jjr),e(kw,WK),e(WK,Yjr),e(kw,Kjr),e(De,Zjr),e(De,Sw),e(Sw,SEe),e(SEe,eDr),e(Sw,oDr),e(Sw,QK),e(QK,rDr),e(Sw,tDr),e(De,aDr),e(De,Rw),e(Rw,REe),e(REe,nDr),e(Rw,sDr),e(Rw,HK),e(HK,lDr),e(Rw,iDr),e(De,dDr),e(De,Pw),e(Pw,PEe),e(PEe,cDr),e(Pw,fDr),e(Pw,UK),e(UK,mDr),e(Pw,gDr),e(De,hDr),e(De,Bw),e(Bw,BEe),e(BEe,pDr),e(Bw,_Dr),e(Bw,JK),e(JK,uDr),e(Bw,bDr),e(De,vDr),e(De,Iw),e(Iw,IEe),e(IEe,FDr),e(Iw,TDr),e(Iw,YK),e(YK,MDr),e(Iw,EDr),e(De,CDr),e(De,Nw),e(Nw,NEe),e(NEe,wDr),e(Nw,ADr),e(Nw,KK),e(KK,yDr),e(Nw,LDr),e(De,xDr),e(De,qw),e(qw,qEe),e(qEe,$Dr),e(qw,kDr),e(qw,ZK),e(ZK,SDr),e(qw,RDr),e(Wr,PDr),M(jw,Wr,null),b(f,cDe,u),b(f,ef,u),e(ef,Dw),e(Dw,jEe),M(px,jEe,null),e(ef,BDr),e(ef,DEe),e(DEe,IDr),b(f,fDe,u),b(f,vr,u),M(_x,vr,null),e(vr,NDr),e(vr,of),e(of,qDr),e(of,eZ),e(eZ,jDr),e(of,DDr),e(of,oZ),e(oZ,GDr),e(of,ODr),e(vr,VDr),e(vr,ux),e(ux,XDr),e(ux,GEe),e(GEe,zDr),e(ux,WDr),e(vr,QDr),e(vr,Ut),M(bx,Ut,null),e(Ut,HDr),e(Ut,OEe),e(OEe,UDr),e(Ut,JDr),e(Ut,rf),e(rf,YDr),e(rf,VEe),e(VEe,KDr),e(rf,ZDr),e(rf,rZ),e(rZ,eGr),e(rf,oGr),e(Ut,rGr),M(Gw,Ut,null),e(vr,tGr),e(vr,Qr),M(vx,Qr,null),e(Qr,aGr),e(Qr,XEe),e(XEe,nGr),e(Qr,sGr),e(Qr,Mn),e(Mn,lGr),e(Mn,zEe),e(zEe,iGr),e(Mn,dGr),e(Mn,WEe),e(WEe,cGr),e(Mn,fGr),e(Mn,QEe),e(QEe,mGr),e(Mn,gGr),e(Qr,hGr),e(Qr,Ge),e(Ge,Ow),e(Ow,HEe),e(HEe,pGr),e(Ow,_Gr),e(Ow,tZ),e(tZ,uGr),e(Ow,bGr),e(Ge,vGr),e(Ge,Vw),e(Vw,UEe),e(UEe,FGr),e(Vw,TGr),e(Vw,aZ),e(aZ,MGr),e(Vw,EGr),e(Ge,CGr),e(Ge,Xw),e(Xw,JEe),e(JEe,wGr),e(Xw,AGr),e(Xw,nZ),e(nZ,yGr),e(Xw,LGr),e(Ge,xGr),e(Ge,zw),e(zw,YEe),e(YEe,$Gr),e(zw,kGr),e(zw,sZ),e(sZ,SGr),e(zw,RGr),e(Ge,PGr),e(Ge,Ww),e(Ww,KEe),e(KEe,BGr),e(Ww,IGr),e(Ww,lZ),e(lZ,NGr),e(Ww,qGr),e(Ge,jGr),e(Ge,Qw),e(Qw,ZEe),e(ZEe,DGr),e(Qw,GGr),e(Qw,iZ),e(iZ,OGr),e(Qw,VGr),e(Ge,XGr),e(Ge,Hw),e(Hw,eCe),e(eCe,zGr),e(Hw,WGr),e(Hw,dZ),e(dZ,QGr),e(Hw,HGr),e(Ge,UGr),e(Ge,Uw),e(Uw,oCe),e(oCe,JGr),e(Uw,YGr),e(Uw,cZ),e(cZ,KGr),e(Uw,ZGr),e(Qr,eOr),M(Jw,Qr,null),b(f,mDe,u),b(f,tf,u),e(tf,Yw),e(Yw,rCe),M(Fx,rCe,null),e(tf,oOr),e(tf,tCe),e(tCe,rOr),b(f,gDe,u),b(f,Fr,u),M(Tx,Fr,null),e(Fr,tOr),e(Fr,af),e(af,aOr),e(af,fZ),e(fZ,nOr),e(af,sOr),e(af,mZ),e(mZ,lOr),e(af,iOr),e(Fr,dOr),e(Fr,Mx),e(Mx,cOr),e(Mx,aCe),e(aCe,fOr),e(Mx,mOr),e(Fr,gOr),e(Fr,Jt),M(Ex,Jt,null),e(Jt,hOr),e(Jt,nCe),e(nCe,pOr),e(Jt,_Or),e(Jt,nf),e(nf,uOr),e(nf,sCe),e(sCe,bOr),e(nf,vOr),e(nf,gZ),e(gZ,FOr),e(nf,TOr),e(Jt,MOr),M(Kw,Jt,null),e(Fr,EOr),e(Fr,Hr),M(Cx,Hr,null),e(Hr,COr),e(Hr,lCe),e(lCe,wOr),e(Hr,AOr),e(Hr,En),e(En,yOr),e(En,iCe),e(iCe,LOr),e(En,xOr),e(En,dCe),e(dCe,$Or),e(En,kOr),e(En,cCe),e(cCe,SOr),e(En,ROr),e(Hr,POr),e(Hr,fCe),e(fCe,Zw),e(Zw,mCe),e(mCe,BOr),e(Zw,IOr),e(Zw,hZ),e(hZ,NOr),e(Zw,qOr),e(Hr,jOr),M(e0,Hr,null),b(f,hDe,u),b(f,sf,u),e(sf,o0),e(o0,gCe),M(wx,gCe,null),e(sf,DOr),e(sf,hCe),e(hCe,GOr),b(f,pDe,u),b(f,Tr,u),M(Ax,Tr,null),e(Tr,OOr),e(Tr,lf),e(lf,VOr),e(lf,pZ),e(pZ,XOr),e(lf,zOr),e(lf,_Z),e(_Z,WOr),e(lf,QOr),e(Tr,HOr),e(Tr,yx),e(yx,UOr),e(yx,pCe),e(pCe,JOr),e(yx,YOr),e(Tr,KOr),e(Tr,Yt),M(Lx,Yt,null),e(Yt,ZOr),e(Yt,_Ce),e(_Ce,eVr),e(Yt,oVr),e(Yt,df),e(df,rVr),e(df,uCe),e(uCe,tVr),e(df,aVr),e(df,uZ),e(uZ,nVr),e(df,sVr),e(Yt,lVr),M(r0,Yt,null),e(Tr,iVr),e(Tr,Ur),M(xx,Ur,null),e(Ur,dVr),e(Ur,bCe),e(bCe,cVr),e(Ur,fVr),e(Ur,Cn),e(Cn,mVr),e(Cn,vCe),e(vCe,gVr),e(Cn,hVr),e(Cn,FCe),e(FCe,pVr),e(Cn,_Vr),e(Cn,TCe),e(TCe,uVr),e(Cn,bVr),e(Ur,vVr),e(Ur,$x),e($x,t0),e(t0,MCe),e(MCe,FVr),e(t0,TVr),e(t0,bZ),e(bZ,MVr),e(t0,EVr),e($x,CVr),e($x,a0),e(a0,ECe),e(ECe,wVr),e(a0,AVr),e(a0,vZ),e(vZ,yVr),e(a0,LVr),e(Ur,xVr),M(n0,Ur,null),b(f,_De,u),b(f,cf,u),e(cf,s0),e(s0,CCe),M(kx,CCe,null),e(cf,$Vr),e(cf,wCe),e(wCe,kVr),b(f,uDe,u),b(f,Mr,u),M(Sx,Mr,null),e(Mr,SVr),e(Mr,ff),e(ff,RVr),e(ff,FZ),e(FZ,PVr),e(ff,BVr),e(ff,TZ),e(TZ,IVr),e(ff,NVr),e(Mr,qVr),e(Mr,Rx),e(Rx,jVr),e(Rx,ACe),e(ACe,DVr),e(Rx,GVr),e(Mr,OVr),e(Mr,Kt),M(Px,Kt,null),e(Kt,VVr),e(Kt,yCe),e(yCe,XVr),e(Kt,zVr),e(Kt,mf),e(mf,WVr),e(mf,LCe),e(LCe,QVr),e(mf,HVr),e(mf,MZ),e(MZ,UVr),e(mf,JVr),e(Kt,YVr),M(l0,Kt,null),e(Mr,KVr),e(Mr,Jr),M(Bx,Jr,null),e(Jr,ZVr),e(Jr,xCe),e(xCe,eXr),e(Jr,oXr),e(Jr,wn),e(wn,rXr),e(wn,$Ce),e($Ce,tXr),e(wn,aXr),e(wn,kCe),e(kCe,nXr),e(wn,sXr),e(wn,SCe),e(SCe,lXr),e(wn,iXr),e(Jr,dXr),e(Jr,RCe),e(RCe,i0),e(i0,PCe),e(PCe,cXr),e(i0,fXr),e(i0,EZ),e(EZ,mXr),e(i0,gXr),e(Jr,hXr),M(d0,Jr,null),bDe=!0},p(f,[u]){const Ix={};u&2&&(Ix.$$scope={dirty:u,ctx:f}),Tf.$set(Ix);const BCe={};u&2&&(BCe.$$scope={dirty:u,ctx:f}),wg.$set(BCe);const ICe={};u&2&&(ICe.$$scope={dirty:u,ctx:f}),sh.$set(ICe);const NCe={};u&2&&(NCe.$$scope={dirty:u,ctx:f}),qh.$set(NCe);const Nx={};u&2&&(Nx.$$scope={dirty:u,ctx:f}),jh.$set(Nx);const qCe={};u&2&&(qCe.$$scope={dirty:u,ctx:f}),np.$set(qCe);const An={};u&2&&(An.$$scope={dirty:u,ctx:f}),sp.$set(An);const jCe={};u&2&&(jCe.$$scope={dirty:u,ctx:f}),dp.$set(jCe);const DCe={};u&2&&(DCe.$$scope={dirty:u,ctx:f}),nu.$set(DCe);const GCe={};u&2&&(GCe.$$scope={dirty:u,ctx:f}),lu.$set(GCe);const qx={};u&2&&(qx.$$scope={dirty:u,ctx:f}),Yu.$set(qx);const OCe={};u&2&&(OCe.$$scope={dirty:u,ctx:f}),Zu.$set(OCe);const jx={};u&2&&(jx.$$scope={dirty:u,ctx:f}),j4.$set(jx);const VCe={};u&2&&(VCe.$$scope={dirty:u,ctx:f}),G4.$set(VCe);const Dx={};u&2&&(Dx.$$scope={dirty:u,ctx:f}),C1.$set(Dx);const XCe={};u&2&&(XCe.$$scope={dirty:u,ctx:f}),A1.$set(XCe);const zCe={};u&2&&(zCe.$$scope={dirty:u,ctx:f}),X1.$set(zCe);const WCe={};u&2&&(WCe.$$scope={dirty:u,ctx:f}),W1.$set(WCe);const gf={};u&2&&(gf.$$scope={dirty:u,ctx:f}),Gb.$set(gf);const QCe={};u&2&&(QCe.$$scope={dirty:u,ctx:f}),Vb.$set(QCe);const HCe={};u&2&&(HCe.$$scope={dirty:u,ctx:f}),F2.$set(HCe);const UCe={};u&2&&(UCe.$$scope={dirty:u,ctx:f}),M2.$set(UCe);const Gx={};u&2&&(Gx.$$scope={dirty:u,ctx:f}),x2.$set(Gx);const JCe={};u&2&&(JCe.$$scope={dirty:u,ctx:f}),k2.$set(JCe);const YCe={};u&2&&(YCe.$$scope={dirty:u,ctx:f}),gv.$set(YCe);const KCe={};u&2&&(KCe.$$scope={dirty:u,ctx:f}),pv.$set(KCe);const et={};u&2&&(et.$$scope={dirty:u,ctx:f}),t3.$set(et);const Ox={};u&2&&(Ox.$$scope={dirty:u,ctx:f}),n3.$set(Ox);const ZCe={};u&2&&(ZCe.$$scope={dirty:u,ctx:f}),i3.$set(ZCe);const Vx={};u&2&&(Vx.$$scope={dirty:u,ctx:f}),c3.$set(Vx);const e5e={};u&2&&(e5e.$$scope={dirty:u,ctx:f}),C3.$set(e5e);const ot={};u&2&&(ot.$$scope={dirty:u,ctx:f}),A3.$set(ot);const o5e={};u&2&&(o5e.$$scope={dirty:u,ctx:f}),x3.$set(o5e);const hf={};u&2&&(hf.$$scope={dirty:u,ctx:f}),k3.$set(hf);const r5e={};u&2&&(r5e.$$scope={dirty:u,ctx:f}),O3.$set(r5e);const t5e={};u&2&&(t5e.$$scope={dirty:u,ctx:f}),X3.$set(t5e);const y={};u&2&&(y.$$scope={dirty:u,ctx:f}),Y3.$set(y);const c0={};u&2&&(c0.$$scope={dirty:u,ctx:f}),Z3.$set(c0);const a5e={};u&2&&(a5e.$$scope={dirty:u,ctx:f}),cF.$set(a5e);const n5e={};u&2&&(n5e.$$scope={dirty:u,ctx:f}),mF.$set(n5e);const f0={};u&2&&(f0.$$scope={dirty:u,ctx:f}),_F.$set(f0);const s5e={};u&2&&(s5e.$$scope={dirty:u,ctx:f}),bF.$set(s5e);const l5e={};u&2&&(l5e.$$scope={dirty:u,ctx:f}),wF.$set(l5e);const m0={};u&2&&(m0.$$scope={dirty:u,ctx:f}),yF.$set(m0);const i5e={};u&2&&(i5e.$$scope={dirty:u,ctx:f}),SF.$set(i5e);const d5e={};u&2&&(d5e.$$scope={dirty:u,ctx:f}),PF.$set(d5e);const g0={};u&2&&(g0.$$scope={dirty:u,ctx:f}),qF.$set(g0);const c5e={};u&2&&(c5e.$$scope={dirty:u,ctx:f}),DF.$set(c5e);const f5e={};u&2&&(f5e.$$scope={dirty:u,ctx:f}),VF.$set(f5e);const h0={};u&2&&(h0.$$scope={dirty:u,ctx:f}),zF.$set(h0);const m5e={};u&2&&(m5e.$$scope={dirty:u,ctx:f}),YF.$set(m5e);const g5e={};u&2&&(g5e.$$scope={dirty:u,ctx:f}),ZF.$set(g5e);const p0={};u&2&&(p0.$$scope={dirty:u,ctx:f}),rT.$set(p0);const h5e={};u&2&&(h5e.$$scope={dirty:u,ctx:f}),aT.$set(h5e);const p5e={};u&2&&(p5e.$$scope={dirty:u,ctx:f}),JT.$set(p5e);const _0={};u&2&&(_0.$$scope={dirty:u,ctx:f}),KT.$set(_0);const _5e={};u&2&&(_5e.$$scope={dirty:u,ctx:f}),M7.$set(_5e);const u5e={};u&2&&(u5e.$$scope={dirty:u,ctx:f}),C7.$set(u5e);const u0={};u&2&&(u0.$$scope={dirty:u,ctx:f}),N7.$set(u0);const b5e={};u&2&&(b5e.$$scope={dirty:u,ctx:f}),j7.$set(b5e);const v5e={};u&2&&(v5e.$$scope={dirty:u,ctx:f}),X7.$set(v5e);const b0={};u&2&&(b0.$$scope={dirty:u,ctx:f}),W7.$set(b0);const F5e={};u&2&&(F5e.$$scope={dirty:u,ctx:f}),gM.$set(F5e);const T5e={};u&2&&(T5e.$$scope={dirty:u,ctx:f}),pM.$set(T5e);const v0={};u&2&&(v0.$$scope={dirty:u,ctx:f}),AM.$set(v0);const M5e={};u&2&&(M5e.$$scope={dirty:u,ctx:f}),LM.$set(M5e);const E5e={};u&2&&(E5e.$$scope={dirty:u,ctx:f}),oE.$set(E5e);const F0={};u&2&&(F0.$$scope={dirty:u,ctx:f}),tE.$set(F0);const C5e={};u&2&&(C5e.$$scope={dirty:u,ctx:f}),TE.$set(C5e);const w5e={};u&2&&(w5e.$$scope={dirty:u,ctx:f}),EE.$set(w5e);const T0={};u&2&&(T0.$$scope={dirty:u,ctx:f}),AE.$set(T0);const A5e={};u&2&&(A5e.$$scope={dirty:u,ctx:f}),LE.$set(A5e);const y5e={};u&2&&(y5e.$$scope={dirty:u,ctx:f}),$E.$set(y5e);const M0={};u&2&&(M0.$$scope={dirty:u,ctx:f}),SE.$set(M0);const L5e={};u&2&&(L5e.$$scope={dirty:u,ctx:f}),ZE.$set(L5e);const x5e={};u&2&&(x5e.$$scope={dirty:u,ctx:f}),oC.$set(x5e);const E0={};u&2&&(E0.$$scope={dirty:u,ctx:f}),MC.$set(E0);const $5e={};u&2&&($5e.$$scope={dirty:u,ctx:f}),CC.$set($5e);const k5e={};u&2&&(k5e.$$scope={dirty:u,ctx:f}),AC.$set(k5e);const C0={};u&2&&(C0.$$scope={dirty:u,ctx:f}),LC.$set(C0);const S5e={};u&2&&(S5e.$$scope={dirty:u,ctx:f}),$C.$set(S5e);const R5e={};u&2&&(R5e.$$scope={dirty:u,ctx:f}),SC.$set(R5e);const w0={};u&2&&(w0.$$scope={dirty:u,ctx:f}),a5.$set(w0);const P5e={};u&2&&(P5e.$$scope={dirty:u,ctx:f}),s5.$set(P5e);const B5e={};u&2&&(B5e.$$scope={dirty:u,ctx:f}),_5.$set(B5e);const A0={};u&2&&(A0.$$scope={dirty:u,ctx:f}),b5.$set(A0);const I5e={};u&2&&(I5e.$$scope={dirty:u,ctx:f}),k5.$set(I5e);const N5e={};u&2&&(N5e.$$scope={dirty:u,ctx:f}),R5.$set(N5e);const y0={};u&2&&(y0.$$scope={dirty:u,ctx:f}),X5.$set(y0);const q5e={};u&2&&(q5e.$$scope={dirty:u,ctx:f}),W5.$set(q5e);const j5e={};u&2&&(j5e.$$scope={dirty:u,ctx:f}),rw.$set(j5e);const L0={};u&2&&(L0.$$scope={dirty:u,ctx:f}),aw.$set(L0);const D5e={};u&2&&(D5e.$$scope={dirty:u,ctx:f}),pw.$set(D5e);const G5e={};u&2&&(G5e.$$scope={dirty:u,ctx:f}),uw.$set(G5e);const x0={};u&2&&(x0.$$scope={dirty:u,ctx:f}),Lw.$set(x0);const O5e={};u&2&&(O5e.$$scope={dirty:u,ctx:f}),$w.$set(O5e);const V5e={};u&2&&(V5e.$$scope={dirty:u,ctx:f}),jw.$set(V5e);const $0={};u&2&&($0.$$scope={dirty:u,ctx:f}),Gw.$set($0);const X5e={};u&2&&(X5e.$$scope={dirty:u,ctx:f}),Jw.$set(X5e);const z5e={};u&2&&(z5e.$$scope={dirty:u,ctx:f}),Kw.$set(z5e);const k0={};u&2&&(k0.$$scope={dirty:u,ctx:f}),e0.$set(k0);const W5e={};u&2&&(W5e.$$scope={dirty:u,ctx:f}),r0.$set(W5e);const Q5e={};u&2&&(Q5e.$$scope={dirty:u,ctx:f}),n0.$set(Q5e);const S0={};u&2&&(S0.$$scope={dirty:u,ctx:f}),l0.$set(S0);const H5e={};u&2&&(H5e.$$scope={dirty:u,ctx:f}),d0.$set(H5e)},i(f){bDe||(E(d.$$.fragment,f),E(Ca.$$.fragment,f),E(kA.$$.fragment,f),E(SA.$$.fragment,f),E(Tf.$$.fragment,f),E(RA.$$.fragment,f),E(PA.$$.fragment,f),E(NA.$$.fragment,f),E(wg.$$.fragment,f),E(qA.$$.fragment,f),E(jA.$$.fragment,f),E(DA.$$.fragment,f),E(VA.$$.fragment,f),E(sh.$$.fragment,f),E(XA.$$.fragment,f),E(zA.$$.fragment,f),E(WA.$$.fragment,f),E(UA.$$.fragment,f),E(qh.$$.fragment,f),E(jh.$$.fragment,f),E(JA.$$.fragment,f),E(YA.$$.fragment,f),E(KA.$$.fragment,f),E(oy.$$.fragment,f),E(np.$$.fragment,f),E(sp.$$.fragment,f),E(ry.$$.fragment,f),E(ty.$$.fragment,f),E(ay.$$.fragment,f),E(sy.$$.fragment,f),E(dp.$$.fragment,f),E(ly.$$.fragment,f),E(nu.$$.fragment,f),E(iy.$$.fragment,f),E(dy.$$.fragment,f),E(fy.$$.fragment,f),E(lu.$$.fragment,f),E(my.$$.fragment,f),E(Yu.$$.fragment,f),E(gy.$$.fragment,f),E(hy.$$.fragment,f),E(_y.$$.fragment,f),E(Zu.$$.fragment,f),E(uy.$$.fragment,f),E(j4.$$.fragment,f),E(by.$$.fragment,f),E(vy.$$.fragment,f),E(Ty.$$.fragment,f),E(G4.$$.fragment,f),E(My.$$.fragment,f),E(C1.$$.fragment,f),E(Ey.$$.fragment,f),E(Cy.$$.fragment,f),E(Ay.$$.fragment,f),E(A1.$$.fragment,f),E(yy.$$.fragment,f),E(X1.$$.fragment,f),E(Ly.$$.fragment,f),E(xy.$$.fragment,f),E(ky.$$.fragment,f),E(W1.$$.fragment,f),E(Sy.$$.fragment,f),E(Gb.$$.fragment,f),E(Ry.$$.fragment,f),E(Py.$$.fragment,f),E(Iy.$$.fragment,f),E(Vb.$$.fragment,f),E(Ny.$$.fragment,f),E(F2.$$.fragment,f),E(qy.$$.fragment,f),E(jy.$$.fragment,f),E(Gy.$$.fragment,f),E(M2.$$.fragment,f),E(Oy.$$.fragment,f),E(x2.$$.fragment,f),E(Vy.$$.fragment,f),E(Xy.$$.fragment,f),E(Wy.$$.fragment,f),E(k2.$$.fragment,f),E(Qy.$$.fragment,f),E(gv.$$.fragment,f),E(Hy.$$.fragment,f),E(Uy.$$.fragment,f),E(Yy.$$.fragment,f),E(pv.$$.fragment,f),E(Ky.$$.fragment,f),E(t3.$$.fragment,f),E(Zy.$$.fragment,f),E(eL.$$.fragment,f),E(rL.$$.fragment,f),E(n3.$$.fragment,f),E(tL.$$.fragment,f),E(i3.$$.fragment,f),E(aL.$$.fragment,f),E(nL.$$.fragment,f),E(lL.$$.fragment,f),E(c3.$$.fragment,f),E(iL.$$.fragment,f),E(C3.$$.fragment,f),E(dL.$$.fragment,f),E(cL.$$.fragment,f),E(mL.$$.fragment,f),E(A3.$$.fragment,f),E(gL.$$.fragment,f),E(x3.$$.fragment,f),E(hL.$$.fragment,f),E(pL.$$.fragment,f),E(uL.$$.fragment,f),E(k3.$$.fragment,f),E(bL.$$.fragment,f),E(O3.$$.fragment,f),E(vL.$$.fragment,f),E(FL.$$.fragment,f),E(ML.$$.fragment,f),E(X3.$$.fragment,f),E(EL.$$.fragment,f),E(Y3.$$.fragment,f),E(CL.$$.fragment,f),E(wL.$$.fragment,f),E(yL.$$.fragment,f),E(Z3.$$.fragment,f),E(LL.$$.fragment,f),E(cF.$$.fragment,f),E(xL.$$.fragment,f),E($L.$$.fragment,f),E(SL.$$.fragment,f),E(mF.$$.fragment,f),E(RL.$$.fragment,f),E(_F.$$.fragment,f),E(BL.$$.fragment,f),E(IL.$$.fragment,f),E(qL.$$.fragment,f),E(bF.$$.fragment,f),E(jL.$$.fragment,f),E(wF.$$.fragment,f),E(DL.$$.fragment,f),E(GL.$$.fragment,f),E(VL.$$.fragment,f),E(yF.$$.fragment,f),E(XL.$$.fragment,f),E(SF.$$.fragment,f),E(zL.$$.fragment,f),E(WL.$$.fragment,f),E(HL.$$.fragment,f),E(PF.$$.fragment,f),E(UL.$$.fragment,f),E(qF.$$.fragment,f),E(YL.$$.fragment,f),E(KL.$$.fragment,f),E(e8.$$.fragment,f),E(DF.$$.fragment,f),E(o8.$$.fragment,f),E(VF.$$.fragment,f),E(r8.$$.fragment,f),E(t8.$$.fragment,f),E(n8.$$.fragment,f),E(zF.$$.fragment,f),E(s8.$$.fragment,f),E(YF.$$.fragment,f),E(l8.$$.fragment,f),E(i8.$$.fragment,f),E(c8.$$.fragment,f),E(ZF.$$.fragment,f),E(f8.$$.fragment,f),E(rT.$$.fragment,f),E(m8.$$.fragment,f),E(g8.$$.fragment,f),E(p8.$$.fragment,f),E(aT.$$.fragment,f),E(_8.$$.fragment,f),E(JT.$$.fragment,f),E(u8.$$.fragment,f),E(b8.$$.fragment,f),E(F8.$$.fragment,f),E(KT.$$.fragment,f),E(T8.$$.fragment,f),E(M7.$$.fragment,f),E(M8.$$.fragment,f),E(E8.$$.fragment,f),E(w8.$$.fragment,f),E(C7.$$.fragment,f),E(A8.$$.fragment,f),E(N7.$$.fragment,f),E(y8.$$.fragment,f),E(L8.$$.fragment,f),E($8.$$.fragment,f),E(j7.$$.fragment,f),E(k8.$$.fragment,f),E(X7.$$.fragment,f),E(S8.$$.fragment,f),E(R8.$$.fragment,f),E(B8.$$.fragment,f),E(W7.$$.fragment,f),E(I8.$$.fragment,f),E(gM.$$.fragment,f),E(N8.$$.fragment,f),E(q8.$$.fragment,f),E(D8.$$.fragment,f),E(pM.$$.fragment,f),E(G8.$$.fragment,f),E(AM.$$.fragment,f),E(O8.$$.fragment,f),E(V8.$$.fragment,f),E(z8.$$.fragment,f),E(LM.$$.fragment,f),E(W8.$$.fragment,f),E(oE.$$.fragment,f),E(Q8.$$.fragment,f),E(H8.$$.fragment,f),E(J8.$$.fragment,f),E(tE.$$.fragment,f),E(Y8.$$.fragment,f),E(TE.$$.fragment,f),E(K8.$$.fragment,f),E(Z8.$$.fragment,f),E(o9.$$.fragment,f),E(EE.$$.fragment,f),E(r9.$$.fragment,f),E(AE.$$.fragment,f),E(a9.$$.fragment,f),E(n9.$$.fragment,f),E(l9.$$.fragment,f),E(LE.$$.fragment,f),E(i9.$$.fragment,f),E($E.$$.fragment,f),E(d9.$$.fragment,f),E(c9.$$.fragment,f),E(m9.$$.fragment,f),E(SE.$$.fragment,f),E(g9.$$.fragment,f),E(ZE.$$.fragment,f),E(h9.$$.fragment,f),E(p9.$$.fragment,f),E(u9.$$.fragment,f),E(oC.$$.fragment,f),E(b9.$$.fragment,f),E(MC.$$.fragment,f),E(v9.$$.fragment,f),E(F9.$$.fragment,f),E(M9.$$.fragment,f),E(CC.$$.fragment,f),E(E9.$$.fragment,f),E(AC.$$.fragment,f),E(C9.$$.fragment,f),E(w9.$$.fragment,f),E(y9.$$.fragment,f),E(LC.$$.fragment,f),E(L9.$$.fragment,f),E($C.$$.fragment,f),E(x9.$$.fragment,f),E($9.$$.fragment,f),E(S9.$$.fragment,f),E(SC.$$.fragment,f),E(R9.$$.fragment,f),E(a5.$$.fragment,f),E(P9.$$.fragment,f),E(B9.$$.fragment,f),E(N9.$$.fragment,f),E(s5.$$.fragment,f),E(q9.$$.fragment,f),E(_5.$$.fragment,f),E(j9.$$.fragment,f),E(D9.$$.fragment,f),E(O9.$$.fragment,f),E(b5.$$.fragment,f),E(V9.$$.fragment,f),E(k5.$$.fragment,f),E(X9.$$.fragment,f),E(z9.$$.fragment,f),E(Q9.$$.fragment,f),E(R5.$$.fragment,f),E(H9.$$.fragment,f),E(X5.$$.fragment,f),E(U9.$$.fragment,f),E(J9.$$.fragment,f),E(K9.$$.fragment,f),E(W5.$$.fragment,f),E(Z9.$$.fragment,f),E(rw.$$.fragment,f),E(ex.$$.fragment,f),E(ox.$$.fragment,f),E(tx.$$.fragment,f),E(aw.$$.fragment,f),E(ax.$$.fragment,f),E(pw.$$.fragment,f),E(nx.$$.fragment,f),E(sx.$$.fragment,f),E(ix.$$.fragment,f),E(uw.$$.fragment,f),E(dx.$$.fragment,f),E(Lw.$$.fragment,f),E(cx.$$.fragment,f),E(fx.$$.fragment,f),E(gx.$$.fragment,f),E($w.$$.fragment,f),E(hx.$$.fragment,f),E(jw.$$.fragment,f),E(px.$$.fragment,f),E(_x.$$.fragment,f),E(bx.$$.fragment,f),E(Gw.$$.fragment,f),E(vx.$$.fragment,f),E(Jw.$$.fragment,f),E(Fx.$$.fragment,f),E(Tx.$$.fragment,f),E(Ex.$$.fragment,f),E(Kw.$$.fragment,f),E(Cx.$$.fragment,f),E(e0.$$.fragment,f),E(wx.$$.fragment,f),E(Ax.$$.fragment,f),E(Lx.$$.fragment,f),E(r0.$$.fragment,f),E(xx.$$.fragment,f),E(n0.$$.fragment,f),E(kx.$$.fragment,f),E(Sx.$$.fragment,f),E(Px.$$.fragment,f),E(l0.$$.fragment,f),E(Bx.$$.fragment,f),E(d0.$$.fragment,f),bDe=!0)},o(f){C(d.$$.fragment,f),C(Ca.$$.fragment,f),C(kA.$$.fragment,f),C(SA.$$.fragment,f),C(Tf.$$.fragment,f),C(RA.$$.fragment,f),C(PA.$$.fragment,f),C(NA.$$.fragment,f),C(wg.$$.fragment,f),C(qA.$$.fragment,f),C(jA.$$.fragment,f),C(DA.$$.fragment,f),C(VA.$$.fragment,f),C(sh.$$.fragment,f),C(XA.$$.fragment,f),C(zA.$$.fragment,f),C(WA.$$.fragment,f),C(UA.$$.fragment,f),C(qh.$$.fragment,f),C(jh.$$.fragment,f),C(JA.$$.fragment,f),C(YA.$$.fragment,f),C(KA.$$.fragment,f),C(oy.$$.fragment,f),C(np.$$.fragment,f),C(sp.$$.fragment,f),C(ry.$$.fragment,f),C(ty.$$.fragment,f),C(ay.$$.fragment,f),C(sy.$$.fragment,f),C(dp.$$.fragment,f),C(ly.$$.fragment,f),C(nu.$$.fragment,f),C(iy.$$.fragment,f),C(dy.$$.fragment,f),C(fy.$$.fragment,f),C(lu.$$.fragment,f),C(my.$$.fragment,f),C(Yu.$$.fragment,f),C(gy.$$.fragment,f),C(hy.$$.fragment,f),C(_y.$$.fragment,f),C(Zu.$$.fragment,f),C(uy.$$.fragment,f),C(j4.$$.fragment,f),C(by.$$.fragment,f),C(vy.$$.fragment,f),C(Ty.$$.fragment,f),C(G4.$$.fragment,f),C(My.$$.fragment,f),C(C1.$$.fragment,f),C(Ey.$$.fragment,f),C(Cy.$$.fragment,f),C(Ay.$$.fragment,f),C(A1.$$.fragment,f),C(yy.$$.fragment,f),C(X1.$$.fragment,f),C(Ly.$$.fragment,f),C(xy.$$.fragment,f),C(ky.$$.fragment,f),C(W1.$$.fragment,f),C(Sy.$$.fragment,f),C(Gb.$$.fragment,f),C(Ry.$$.fragment,f),C(Py.$$.fragment,f),C(Iy.$$.fragment,f),C(Vb.$$.fragment,f),C(Ny.$$.fragment,f),C(F2.$$.fragment,f),C(qy.$$.fragment,f),C(jy.$$.fragment,f),C(Gy.$$.fragment,f),C(M2.$$.fragment,f),C(Oy.$$.fragment,f),C(x2.$$.fragment,f),C(Vy.$$.fragment,f),C(Xy.$$.fragment,f),C(Wy.$$.fragment,f),C(k2.$$.fragment,f),C(Qy.$$.fragment,f),C(gv.$$.fragment,f),C(Hy.$$.fragment,f),C(Uy.$$.fragment,f),C(Yy.$$.fragment,f),C(pv.$$.fragment,f),C(Ky.$$.fragment,f),C(t3.$$.fragment,f),C(Zy.$$.fragment,f),C(eL.$$.fragment,f),C(rL.$$.fragment,f),C(n3.$$.fragment,f),C(tL.$$.fragment,f),C(i3.$$.fragment,f),C(aL.$$.fragment,f),C(nL.$$.fragment,f),C(lL.$$.fragment,f),C(c3.$$.fragment,f),C(iL.$$.fragment,f),C(C3.$$.fragment,f),C(dL.$$.fragment,f),C(cL.$$.fragment,f),C(mL.$$.fragment,f),C(A3.$$.fragment,f),C(gL.$$.fragment,f),C(x3.$$.fragment,f),C(hL.$$.fragment,f),C(pL.$$.fragment,f),C(uL.$$.fragment,f),C(k3.$$.fragment,f),C(bL.$$.fragment,f),C(O3.$$.fragment,f),C(vL.$$.fragment,f),C(FL.$$.fragment,f),C(ML.$$.fragment,f),C(X3.$$.fragment,f),C(EL.$$.fragment,f),C(Y3.$$.fragment,f),C(CL.$$.fragment,f),C(wL.$$.fragment,f),C(yL.$$.fragment,f),C(Z3.$$.fragment,f),C(LL.$$.fragment,f),C(cF.$$.fragment,f),C(xL.$$.fragment,f),C($L.$$.fragment,f),C(SL.$$.fragment,f),C(mF.$$.fragment,f),C(RL.$$.fragment,f),C(_F.$$.fragment,f),C(BL.$$.fragment,f),C(IL.$$.fragment,f),C(qL.$$.fragment,f),C(bF.$$.fragment,f),C(jL.$$.fragment,f),C(wF.$$.fragment,f),C(DL.$$.fragment,f),C(GL.$$.fragment,f),C(VL.$$.fragment,f),C(yF.$$.fragment,f),C(XL.$$.fragment,f),C(SF.$$.fragment,f),C(zL.$$.fragment,f),C(WL.$$.fragment,f),C(HL.$$.fragment,f),C(PF.$$.fragment,f),C(UL.$$.fragment,f),C(qF.$$.fragment,f),C(YL.$$.fragment,f),C(KL.$$.fragment,f),C(e8.$$.fragment,f),C(DF.$$.fragment,f),C(o8.$$.fragment,f),C(VF.$$.fragment,f),C(r8.$$.fragment,f),C(t8.$$.fragment,f),C(n8.$$.fragment,f),C(zF.$$.fragment,f),C(s8.$$.fragment,f),C(YF.$$.fragment,f),C(l8.$$.fragment,f),C(i8.$$.fragment,f),C(c8.$$.fragment,f),C(ZF.$$.fragment,f),C(f8.$$.fragment,f),C(rT.$$.fragment,f),C(m8.$$.fragment,f),C(g8.$$.fragment,f),C(p8.$$.fragment,f),C(aT.$$.fragment,f),C(_8.$$.fragment,f),C(JT.$$.fragment,f),C(u8.$$.fragment,f),C(b8.$$.fragment,f),C(F8.$$.fragment,f),C(KT.$$.fragment,f),C(T8.$$.fragment,f),C(M7.$$.fragment,f),C(M8.$$.fragment,f),C(E8.$$.fragment,f),C(w8.$$.fragment,f),C(C7.$$.fragment,f),C(A8.$$.fragment,f),C(N7.$$.fragment,f),C(y8.$$.fragment,f),C(L8.$$.fragment,f),C($8.$$.fragment,f),C(j7.$$.fragment,f),C(k8.$$.fragment,f),C(X7.$$.fragment,f),C(S8.$$.fragment,f),C(R8.$$.fragment,f),C(B8.$$.fragment,f),C(W7.$$.fragment,f),C(I8.$$.fragment,f),C(gM.$$.fragment,f),C(N8.$$.fragment,f),C(q8.$$.fragment,f),C(D8.$$.fragment,f),C(pM.$$.fragment,f),C(G8.$$.fragment,f),C(AM.$$.fragment,f),C(O8.$$.fragment,f),C(V8.$$.fragment,f),C(z8.$$.fragment,f),C(LM.$$.fragment,f),C(W8.$$.fragment,f),C(oE.$$.fragment,f),C(Q8.$$.fragment,f),C(H8.$$.fragment,f),C(J8.$$.fragment,f),C(tE.$$.fragment,f),C(Y8.$$.fragment,f),C(TE.$$.fragment,f),C(K8.$$.fragment,f),C(Z8.$$.fragment,f),C(o9.$$.fragment,f),C(EE.$$.fragment,f),C(r9.$$.fragment,f),C(AE.$$.fragment,f),C(a9.$$.fragment,f),C(n9.$$.fragment,f),C(l9.$$.fragment,f),C(LE.$$.fragment,f),C(i9.$$.fragment,f),C($E.$$.fragment,f),C(d9.$$.fragment,f),C(c9.$$.fragment,f),C(m9.$$.fragment,f),C(SE.$$.fragment,f),C(g9.$$.fragment,f),C(ZE.$$.fragment,f),C(h9.$$.fragment,f),C(p9.$$.fragment,f),C(u9.$$.fragment,f),C(oC.$$.fragment,f),C(b9.$$.fragment,f),C(MC.$$.fragment,f),C(v9.$$.fragment,f),C(F9.$$.fragment,f),C(M9.$$.fragment,f),C(CC.$$.fragment,f),C(E9.$$.fragment,f),C(AC.$$.fragment,f),C(C9.$$.fragment,f),C(w9.$$.fragment,f),C(y9.$$.fragment,f),C(LC.$$.fragment,f),C(L9.$$.fragment,f),C($C.$$.fragment,f),C(x9.$$.fragment,f),C($9.$$.fragment,f),C(S9.$$.fragment,f),C(SC.$$.fragment,f),C(R9.$$.fragment,f),C(a5.$$.fragment,f),C(P9.$$.fragment,f),C(B9.$$.fragment,f),C(N9.$$.fragment,f),C(s5.$$.fragment,f),C(q9.$$.fragment,f),C(_5.$$.fragment,f),C(j9.$$.fragment,f),C(D9.$$.fragment,f),C(O9.$$.fragment,f),C(b5.$$.fragment,f),C(V9.$$.fragment,f),C(k5.$$.fragment,f),C(X9.$$.fragment,f),C(z9.$$.fragment,f),C(Q9.$$.fragment,f),C(R5.$$.fragment,f),C(H9.$$.fragment,f),C(X5.$$.fragment,f),C(U9.$$.fragment,f),C(J9.$$.fragment,f),C(K9.$$.fragment,f),C(W5.$$.fragment,f),C(Z9.$$.fragment,f),C(rw.$$.fragment,f),C(ex.$$.fragment,f),C(ox.$$.fragment,f),C(tx.$$.fragment,f),C(aw.$$.fragment,f),C(ax.$$.fragment,f),C(pw.$$.fragment,f),C(nx.$$.fragment,f),C(sx.$$.fragment,f),C(ix.$$.fragment,f),C(uw.$$.fragment,f),C(dx.$$.fragment,f),C(Lw.$$.fragment,f),C(cx.$$.fragment,f),C(fx.$$.fragment,f),C(gx.$$.fragment,f),C($w.$$.fragment,f),C(hx.$$.fragment,f),C(jw.$$.fragment,f),C(px.$$.fragment,f),C(_x.$$.fragment,f),C(bx.$$.fragment,f),C(Gw.$$.fragment,f),C(vx.$$.fragment,f),C(Jw.$$.fragment,f),C(Fx.$$.fragment,f),C(Tx.$$.fragment,f),C(Ex.$$.fragment,f),C(Kw.$$.fragment,f),C(Cx.$$.fragment,f),C(e0.$$.fragment,f),C(wx.$$.fragment,f),C(Ax.$$.fragment,f),C(Lx.$$.fragment,f),C(r0.$$.fragment,f),C(xx.$$.fragment,f),C(n0.$$.fragment,f),C(kx.$$.fragment,f),C(Sx.$$.fragment,f),C(Px.$$.fragment,f),C(l0.$$.fragment,f),C(Bx.$$.fragment,f),C(d0.$$.fragment,f),bDe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(_f),f&&t(rt),f&&t(je),f&&t(We),f&&t(bf),w(Ca,f),f&&t(Qe),f&&t(Ae),f&&t(Eo),f&&t(wa),f&&t(pqe),f&&t(vi),w(kA),f&&t(_qe),f&&t(kn),f&&t(uqe),w(SA,f),f&&t(bqe),f&&t(ok),f&&t(vqe),w(Tf,f),f&&t(Fqe),f&&t(Fi),w(RA),f&&t(Tqe),f&&t(Co),w(PA),w(NA),w(wg),w(qA),f&&t(Mqe),f&&t(Mi),w(jA),f&&t(Eqe),f&&t(wo),w(DA),w(VA),w(sh),w(XA),f&&t(Cqe),f&&t(Ei),w(zA),f&&t(wqe),f&&t(Ao),w(WA),w(UA),w(qh),w(jh),w(JA),f&&t(Aqe),f&&t(Ci),w(YA),f&&t(yqe),f&&t(yo),w(KA),w(oy),w(np),w(sp),w(ry),f&&t(Lqe),f&&t(Ai),w(ty),f&&t(xqe),f&&t(Lo),w(ay),w(sy),w(dp),w(ly),w(nu),f&&t($qe),f&&t(xi),w(iy),f&&t(kqe),f&&t(xo),w(dy),w(fy),w(lu),w(my),w(Yu),f&&t(Sqe),f&&t(Si),w(gy),f&&t(Rqe),f&&t($o),w(hy),w(_y),w(Zu),w(uy),w(j4),f&&t(Pqe),f&&t(Bi),w(by),f&&t(Bqe),f&&t(ko),w(vy),w(Ty),w(G4),w(My),w(C1),f&&t(Iqe),f&&t(qi),w(Ey),f&&t(Nqe),f&&t(So),w(Cy),w(Ay),w(A1),w(yy),w(X1),f&&t(qqe),f&&t(Gi),w(Ly),f&&t(jqe),f&&t(Ro),w(xy),w(ky),w(W1),w(Sy),w(Gb),f&&t(Dqe),f&&t(Xi),w(Ry),f&&t(Gqe),f&&t(Po),w(Py),w(Iy),w(Vb),w(Ny),w(F2),f&&t(Oqe),f&&t(Qi),w(qy),f&&t(Vqe),f&&t(Bo),w(jy),w(Gy),w(M2),w(Oy),w(x2),f&&t(Xqe),f&&t(Ji),w(Vy),f&&t(zqe),f&&t(Io),w(Xy),w(Wy),w(k2),w(Qy),w(gv),f&&t(Wqe),f&&t(Zi),w(Hy),f&&t(Qqe),f&&t(No),w(Uy),w(Yy),w(pv),w(Ky),w(t3),f&&t(Hqe),f&&t(rd),w(Zy),f&&t(Uqe),f&&t(qo),w(eL),w(rL),w(n3),w(tL),w(i3),f&&t(Jqe),f&&t(nd),w(aL),f&&t(Yqe),f&&t(jo),w(nL),w(lL),w(c3),w(iL),w(C3),f&&t(Kqe),f&&t(id),w(dL),f&&t(Zqe),f&&t(Do),w(cL),w(mL),w(A3),w(gL),w(x3),f&&t(eje),f&&t(fd),w(hL),f&&t(oje),f&&t(Go),w(pL),w(uL),w(k3),w(bL),w(O3),f&&t(rje),f&&t(hd),w(vL),f&&t(tje),f&&t(Oo),w(FL),w(ML),w(X3),w(EL),w(Y3),f&&t(aje),f&&t(ud),w(CL),f&&t(nje),f&&t(Vo),w(wL),w(yL),w(Z3),w(LL),w(cF),f&&t(sje),f&&t(Fd),w(xL),f&&t(lje),f&&t(Xo),w($L),w(SL),w(mF),w(RL),w(_F),f&&t(ije),f&&t(Ed),w(BL),f&&t(dje),f&&t(zo),w(IL),w(qL),w(bF),w(jL),w(wF),f&&t(cje),f&&t(Ad),w(DL),f&&t(fje),f&&t(Wo),w(GL),w(VL),w(yF),w(XL),w(SF),f&&t(mje),f&&t($d),w(zL),f&&t(gje),f&&t(Qo),w(WL),w(HL),w(PF),w(UL),w(qF),f&&t(hje),f&&t(Rd),w(YL),f&&t(pje),f&&t(Ho),w(KL),w(e8),w(DF),w(o8),w(VF),f&&t(_je),f&&t(Id),w(r8),f&&t(uje),f&&t(Uo),w(t8),w(n8),w(zF),w(s8),w(YF),f&&t(bje),f&&t(jd),w(l8),f&&t(vje),f&&t(Jo),w(i8),w(c8),w(ZF),w(f8),w(rT),f&&t(Fje),f&&t(Od),w(m8),f&&t(Tje),f&&t(Yo),w(g8),w(p8),w(aT),w(_8),w(JT),f&&t(Mje),f&&t(zd),w(u8),f&&t(Eje),f&&t(Ko),w(b8),w(F8),w(KT),w(T8),w(M7),f&&t(Cje),f&&t(Hd),w(M8),f&&t(wje),f&&t(Zo),w(E8),w(w8),w(C7),w(A8),w(N7),f&&t(Aje),f&&t(Yd),w(y8),f&&t(yje),f&&t(er),w(L8),w($8),w(j7),w(k8),w(X7),f&&t(Lje),f&&t(ec),w(S8),f&&t(xje),f&&t(or),w(R8),w(B8),w(W7),w(I8),w(gM),f&&t($je),f&&t(tc),w(N8),f&&t(kje),f&&t(rr),w(q8),w(D8),w(pM),w(G8),w(AM),f&&t(Sje),f&&t(sc),w(O8),f&&t(Rje),f&&t(tr),w(V8),w(z8),w(LM),w(W8),w(oE),f&&t(Pje),f&&t(dc),w(Q8),f&&t(Bje),f&&t(ar),w(H8),w(J8),w(tE),w(Y8),w(TE),f&&t(Ije),f&&t(mc),w(K8),f&&t(Nje),f&&t(nr),w(Z8),w(o9),w(EE),w(r9),w(AE),f&&t(qje),f&&t(pc),w(a9),f&&t(jje),f&&t(sr),w(n9),w(l9),w(LE),w(i9),w($E),f&&t(Dje),f&&t(bc),w(d9),f&&t(Gje),f&&t(lr),w(c9),w(m9),w(SE),w(g9),w(ZE),f&&t(Oje),f&&t(Tc),w(h9),f&&t(Vje),f&&t(ir),w(p9),w(u9),w(oC),w(b9),w(MC),f&&t(Xje),f&&t(Cc),w(v9),f&&t(zje),f&&t(dr),w(F9),w(M9),w(CC),w(E9),w(AC),f&&t(Wje),f&&t(yc),w(C9),f&&t(Qje),f&&t(cr),w(w9),w(y9),w(LC),w(L9),w($C),f&&t(Hje),f&&t($c),w(x9),f&&t(Uje),f&&t(fr),w($9),w(S9),w(SC),w(R9),w(a5),f&&t(Jje),f&&t(Rc),w(P9),f&&t(Yje),f&&t(mr),w(B9),w(N9),w(s5),w(q9),w(_5),f&&t(Kje),f&&t(Ic),w(j9),f&&t(Zje),f&&t(gr),w(D9),w(O9),w(b5),w(V9),w(k5),f&&t(eDe),f&&t(jc),w(X9),f&&t(oDe),f&&t(hr),w(z9),w(Q9),w(R5),w(H9),w(X5),f&&t(rDe),f&&t(Oc),w(U9),f&&t(tDe),f&&t(pr),w(J9),w(K9),w(W5),w(Z9),w(rw),f&&t(aDe),f&&t(zc),w(ex),f&&t(nDe),f&&t(_r),w(ox),w(tx),w(aw),w(ax),w(pw),f&&t(sDe),f&&t(Hc),w(nx),f&&t(lDe),f&&t(ur),w(sx),w(ix),w(uw),w(dx),w(Lw),f&&t(iDe),f&&t(Yc),w(cx),f&&t(dDe),f&&t(br),w(fx),w(gx),w($w),w(hx),w(jw),f&&t(cDe),f&&t(ef),w(px),f&&t(fDe),f&&t(vr),w(_x),w(bx),w(Gw),w(vx),w(Jw),f&&t(mDe),f&&t(tf),w(Fx),f&&t(gDe),f&&t(Fr),w(Tx),w(Ex),w(Kw),w(Cx),w(e0),f&&t(hDe),f&&t(sf),w(wx),f&&t(pDe),f&&t(Tr),w(Ax),w(Lx),w(r0),w(xx),w(n0),f&&t(_De),f&&t(cf),w(kx),f&&t(uDe),f&&t(Mr),w(Sx),w(Px),w(l0),w(Bx),w(d0)}}}const tRt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function aRt(L){return akt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class fRt extends ekt{constructor(g){super();okt(this,g,aRt,rRt,rkt,{})}}export{fRt as default,tRt as metadata};
