import{S as vDt,i as FDt,s as TDt,e as a,k as l,w as F,t as o,M as MDt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as EDt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as KYr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function CDt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,wA,xf,Oe,Qe,Ci,Rn,AA,Pn,Bn,LA,wi,In,yA,Ai,$f,xa;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Ti=a("code"),yf=o("model_type"),at=o(" attribute is set to the same key you use when registering the config (here "),Mi=a("code"),Ei=o('"new-model"'),wA=o(")."),xf=l(),Oe=a("p"),Qe=o("Likewise, if your "),Ci=a("code"),Rn=o("NewModel"),AA=o(" is a subclass of "),Pn=a("a"),Bn=o("PreTrainedModel"),LA=o(`, make sure its
`),wi=a("code"),In=o("config_class"),yA=o(` attribute is set to the same class you use when registering the model (here
`),Ai=a("code"),$f=o("NewModelConfig"),xa=o(")."),this.h()},l(We){g=n(We,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var rS=s(p);m=r(rS,"NewModelConfig"),rS.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Li=s(d);h=r(Li,"PretrainedConfig"),Li.forEach(t),Eo=r(Ae,`, make sure its
`),Ti=n(Ae,"CODE",{});var tS=s(Ti);yf=r(tS,"model_type"),tS.forEach(t),at=r(Ae," attribute is set to the same key you use when registering the config (here "),Mi=n(Ae,"CODE",{});var aS=s(Mi);Ei=r(aS,'"new-model"'),aS.forEach(t),wA=r(Ae,")."),Ae.forEach(t),xf=i(We),Oe=n(We,"P",{});var Co=s(Oe);Qe=r(Co,"Likewise, if your "),Ci=n(Co,"CODE",{});var $a=s(Ci);Rn=r($a,"NewModel"),$a.forEach(t),AA=r(Co," is a subclass of "),Pn=n(Co,"A",{href:!0});var nS=s(Pn);Bn=r(nS,"PreTrainedModel"),nS.forEach(t),LA=r(Co,`, make sure its
`),wi=n(Co,"CODE",{});var kf=s(wi);In=r(kf,"config_class"),kf.forEach(t),yA=r(Co,` attribute is set to the same class you use when registering the model (here
`),Ai=n(Co,"CODE",{});var sS=s(Ai);$f=r(sS,"NewModelConfig"),sS.forEach(t),xa=r(Co,")."),Co.forEach(t),this.h()},h(){c(Pn,"href","/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel")},m(We,Ae){b(We,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Eo),e(g,Ti),e(Ti,yf),e(g,at),e(g,Mi),e(Mi,Ei),e(g,wA),b(We,xf,Ae),b(We,Oe,Ae),e(Oe,Qe),e(Oe,Ci),e(Ci,Rn),e(Oe,AA),e(Oe,Pn),e(Pn,Bn),e(Oe,LA),e(Oe,wi),e(wi,In),e(Oe,yA),e(Oe,Ai),e(Ai,$f),e(Oe,xa)},d(We){We&&t(g),We&&t(xf),We&&t(Oe)}}}function wDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ADt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LDt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function yDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xDt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function $Dt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ODt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Ot(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EOt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,wA,xf,Oe,Qe,Ci,Rn,AA,Pn,Bn,LA,wi,In,yA,Ai,$f,xa,We,Ae,rS,Li,tS,aS,Co,$a,nS,kf,sS,eQe,jGe,yi,Sf,mte,xA,oQe,gte,rQe,DGe,Nn,tQe,hte,aQe,nQe,pte,sQe,lQe,GGe,$A,OGe,lS,iQe,VGe,Rf,XGe,xi,Pf,_te,kA,dQe,ute,cQe,zGe,wo,SA,fQe,RA,mQe,iS,gQe,hQe,pQe,PA,_Qe,bte,uQe,bQe,vQe,Ar,BA,FQe,vte,TQe,MQe,$i,EQe,Fte,CQe,wQe,Tte,AQe,LQe,yQe,A,Bf,Mte,xQe,$Qe,dS,kQe,SQe,RQe,If,Ete,PQe,BQe,cS,IQe,NQe,qQe,Nf,Cte,jQe,DQe,fS,GQe,OQe,VQe,qf,wte,XQe,zQe,mS,QQe,WQe,HQe,jf,Ate,UQe,JQe,gS,YQe,KQe,ZQe,Df,Lte,eWe,oWe,hS,rWe,tWe,aWe,Gf,yte,nWe,sWe,pS,lWe,iWe,dWe,Of,xte,cWe,fWe,_S,mWe,gWe,hWe,Vf,$te,pWe,_We,uS,uWe,bWe,vWe,Xf,kte,FWe,TWe,bS,MWe,EWe,CWe,zf,Ste,wWe,AWe,vS,LWe,yWe,xWe,Qf,Rte,$We,kWe,FS,SWe,RWe,PWe,Wf,Pte,BWe,IWe,TS,NWe,qWe,jWe,Hf,Bte,DWe,GWe,MS,OWe,VWe,XWe,Uf,Ite,zWe,QWe,ES,WWe,HWe,UWe,Jf,Nte,JWe,YWe,CS,KWe,ZWe,eHe,Yf,qte,oHe,rHe,wS,tHe,aHe,nHe,Kf,jte,sHe,lHe,AS,iHe,dHe,cHe,Zf,Dte,fHe,mHe,LS,gHe,hHe,pHe,em,Gte,_He,uHe,yS,bHe,vHe,FHe,om,Ote,THe,MHe,xS,EHe,CHe,wHe,rm,Vte,AHe,LHe,$S,yHe,xHe,$He,tm,Xte,kHe,SHe,kS,RHe,PHe,BHe,am,zte,IHe,NHe,SS,qHe,jHe,DHe,nm,Qte,GHe,OHe,RS,VHe,XHe,zHe,sm,Wte,QHe,WHe,PS,HHe,UHe,JHe,lm,Hte,YHe,KHe,BS,ZHe,eUe,oUe,im,Ute,rUe,tUe,IS,aUe,nUe,sUe,dm,Jte,lUe,iUe,NS,dUe,cUe,fUe,cm,Yte,mUe,gUe,qS,hUe,pUe,_Ue,fm,Kte,uUe,bUe,jS,vUe,FUe,TUe,mm,Zte,MUe,EUe,DS,CUe,wUe,AUe,gm,eae,LUe,yUe,GS,xUe,$Ue,kUe,hm,oae,SUe,RUe,OS,PUe,BUe,IUe,pm,rae,NUe,qUe,VS,jUe,DUe,GUe,_m,tae,OUe,VUe,XS,XUe,zUe,QUe,um,aae,WUe,HUe,zS,UUe,JUe,YUe,bm,nae,KUe,ZUe,QS,eJe,oJe,rJe,vm,sae,tJe,aJe,WS,nJe,sJe,lJe,Fm,lae,iJe,dJe,HS,cJe,fJe,mJe,Tm,iae,gJe,hJe,US,pJe,_Je,uJe,Mm,dae,bJe,vJe,JS,FJe,TJe,MJe,Em,cae,EJe,CJe,YS,wJe,AJe,LJe,Cm,fae,yJe,xJe,KS,$Je,kJe,SJe,wm,mae,RJe,PJe,ZS,BJe,IJe,NJe,Am,gae,qJe,jJe,eR,DJe,GJe,OJe,Lm,hae,VJe,XJe,oR,zJe,QJe,WJe,ym,pae,HJe,UJe,rR,JJe,YJe,KJe,xm,_ae,ZJe,eYe,tR,oYe,rYe,tYe,$m,uae,aYe,nYe,aR,sYe,lYe,iYe,km,bae,dYe,cYe,nR,fYe,mYe,gYe,Sm,vae,hYe,pYe,sR,_Ye,uYe,bYe,Rm,Fae,vYe,FYe,lR,TYe,MYe,EYe,Pm,Tae,CYe,wYe,iR,AYe,LYe,yYe,Bm,Mae,xYe,$Ye,dR,kYe,SYe,RYe,Im,Eae,PYe,BYe,cR,IYe,NYe,qYe,Nm,Cae,jYe,DYe,fR,GYe,OYe,VYe,qm,wae,XYe,zYe,mR,QYe,WYe,HYe,jm,Aae,UYe,JYe,gR,YYe,KYe,ZYe,Dm,Lae,eKe,oKe,hR,rKe,tKe,aKe,Gm,yae,nKe,sKe,pR,lKe,iKe,dKe,Om,xae,cKe,fKe,_R,mKe,gKe,hKe,Vm,$ae,pKe,_Ke,uR,uKe,bKe,vKe,Xm,kae,FKe,TKe,bR,MKe,EKe,CKe,zm,Sae,wKe,AKe,vR,LKe,yKe,xKe,Qm,Rae,$Ke,kKe,FR,SKe,RKe,PKe,Wm,Pae,BKe,IKe,TR,NKe,qKe,jKe,Hm,Bae,DKe,GKe,MR,OKe,VKe,XKe,Um,Iae,zKe,QKe,ER,WKe,HKe,UKe,Jm,Nae,JKe,YKe,CR,KKe,ZKe,eZe,Ym,qae,oZe,rZe,wR,tZe,aZe,nZe,Km,jae,sZe,lZe,AR,iZe,dZe,cZe,Zm,Dae,fZe,mZe,LR,gZe,hZe,pZe,eg,Gae,_Ze,uZe,yR,bZe,vZe,FZe,og,Oae,TZe,MZe,xR,EZe,CZe,wZe,rg,Vae,AZe,LZe,$R,yZe,xZe,$Ze,tg,Xae,kZe,SZe,kR,RZe,PZe,BZe,ag,zae,IZe,NZe,SR,qZe,jZe,DZe,ng,Qae,GZe,OZe,RR,VZe,XZe,zZe,sg,Wae,QZe,WZe,PR,HZe,UZe,JZe,lg,Hae,YZe,KZe,BR,ZZe,eeo,oeo,ig,Uae,reo,teo,IR,aeo,neo,seo,dg,Jae,leo,ieo,NR,deo,ceo,feo,cg,Yae,meo,geo,qR,heo,peo,_eo,fg,Kae,ueo,beo,jR,veo,Feo,Teo,mg,Zae,Meo,Eeo,DR,Ceo,weo,Aeo,gg,ene,Leo,yeo,GR,xeo,$eo,keo,hg,one,Seo,Reo,OR,Peo,Beo,Ieo,pg,rne,Neo,qeo,VR,jeo,Deo,Geo,_g,tne,Oeo,Veo,XR,Xeo,zeo,Qeo,ug,ane,Weo,Heo,zR,Ueo,Jeo,Yeo,bg,nne,Keo,Zeo,QR,eoo,ooo,roo,vg,sne,too,aoo,WR,noo,soo,loo,Fg,lne,ioo,doo,HR,coo,foo,moo,Tg,ine,goo,hoo,UR,poo,_oo,uoo,Mg,dne,boo,voo,JR,Foo,Too,Moo,Eg,cne,Eoo,Coo,YR,woo,Aoo,Loo,Cg,fne,yoo,xoo,KR,$oo,koo,Soo,wg,mne,Roo,Poo,ZR,Boo,Ioo,Noo,Ag,gne,qoo,joo,eP,Doo,Goo,Ooo,Lg,hne,Voo,Xoo,oP,zoo,Qoo,Woo,yg,pne,Hoo,Uoo,rP,Joo,Yoo,Koo,xg,_ne,Zoo,ero,tP,oro,rro,tro,$g,une,aro,nro,aP,sro,lro,iro,kg,bne,dro,cro,nP,fro,mro,gro,Sg,vne,hro,pro,sP,_ro,uro,bro,Rg,Fne,vro,Fro,lP,Tro,Mro,Ero,Pg,Tne,Cro,wro,iP,Aro,Lro,yro,Bg,Mne,xro,$ro,dP,kro,Sro,Rro,Ig,Ene,Pro,Bro,cP,Iro,Nro,qro,Ng,Cne,jro,Dro,fP,Gro,Oro,Vro,qg,wne,Xro,zro,mP,Qro,Wro,Hro,jg,Ane,Uro,Jro,gP,Yro,Kro,Zro,Dg,Lne,eto,oto,hP,rto,tto,ato,Gg,nto,Og,IA,sto,yne,lto,QGe,ki,Vg,xne,NA,ito,$ne,dto,WGe,Ao,qA,cto,jA,fto,pP,mto,gto,hto,DA,pto,kne,_to,uto,bto,Lr,GA,vto,Sne,Fto,Tto,ka,Mto,Rne,Eto,Cto,Pne,wto,Ato,Bne,Lto,yto,xto,k,qn,Ine,$to,kto,_P,Sto,Rto,uP,Pto,Bto,Ito,jn,Nne,Nto,qto,bP,jto,Dto,vP,Gto,Oto,Vto,Dn,qne,Xto,zto,FP,Qto,Wto,TP,Hto,Uto,Jto,Xg,jne,Yto,Kto,MP,Zto,eao,oao,Gn,Dne,rao,tao,EP,aao,nao,CP,sao,lao,iao,zg,Gne,dao,cao,wP,fao,mao,gao,Qg,One,hao,pao,AP,_ao,uao,bao,Wg,Vne,vao,Fao,LP,Tao,Mao,Eao,On,Xne,Cao,wao,yP,Aao,Lao,xP,yao,xao,$ao,Vn,zne,kao,Sao,$P,Rao,Pao,kP,Bao,Iao,Nao,Xn,Qne,qao,jao,SP,Dao,Gao,RP,Oao,Vao,Xao,Hg,Wne,zao,Qao,PP,Wao,Hao,Uao,Ug,Hne,Jao,Yao,BP,Kao,Zao,eno,Jg,Une,ono,rno,IP,tno,ano,nno,zn,Jne,sno,lno,NP,ino,dno,qP,cno,fno,mno,Yg,Yne,gno,hno,jP,pno,_no,uno,Qn,Kne,bno,vno,DP,Fno,Tno,GP,Mno,Eno,Cno,Wn,Zne,wno,Ano,OP,Lno,yno,VP,xno,$no,kno,Hn,ese,Sno,Rno,XP,Pno,Bno,zP,Ino,Nno,qno,Kg,ose,jno,Dno,QP,Gno,Ono,Vno,Un,rse,Xno,zno,WP,Qno,Wno,HP,Hno,Uno,Jno,Jn,tse,Yno,Kno,UP,Zno,eso,JP,oso,rso,tso,Yn,ase,aso,nso,YP,sso,lso,KP,iso,dso,cso,Kn,nse,fso,mso,ZP,gso,hso,eB,pso,_so,uso,Zn,sse,bso,vso,oB,Fso,Tso,rB,Mso,Eso,Cso,es,lse,wso,Aso,tB,Lso,yso,aB,xso,$so,kso,Zg,ise,Sso,Rso,nB,Pso,Bso,Iso,os,dse,Nso,qso,sB,jso,Dso,lB,Gso,Oso,Vso,eh,cse,Xso,zso,iB,Qso,Wso,Hso,rs,fse,Uso,Jso,dB,Yso,Kso,cB,Zso,elo,olo,ts,mse,rlo,tlo,fB,alo,nlo,mB,slo,llo,ilo,as,gse,dlo,clo,gB,flo,mlo,hB,glo,hlo,plo,oh,hse,_lo,ulo,pB,blo,vlo,Flo,ns,pse,Tlo,Mlo,_B,Elo,Clo,uB,wlo,Alo,Llo,ss,_se,ylo,xlo,bB,$lo,klo,vB,Slo,Rlo,Plo,rh,use,Blo,Ilo,FB,Nlo,qlo,jlo,ls,bse,Dlo,Glo,TB,Olo,Vlo,MB,Xlo,zlo,Qlo,is,vse,Wlo,Hlo,EB,Ulo,Jlo,CB,Ylo,Klo,Zlo,ds,Fse,eio,oio,wB,rio,tio,AB,aio,nio,sio,cs,Tse,lio,iio,LB,dio,cio,yB,fio,mio,gio,fs,Mse,hio,pio,xB,_io,uio,$B,bio,vio,Fio,ms,Ese,Tio,Mio,kB,Eio,Cio,SB,wio,Aio,Lio,gs,Cse,yio,xio,RB,$io,kio,PB,Sio,Rio,Pio,hs,wse,Bio,Iio,BB,Nio,qio,IB,jio,Dio,Gio,th,Ase,Oio,Vio,NB,Xio,zio,Qio,ps,Lse,Wio,Hio,qB,Uio,Jio,jB,Yio,Kio,Zio,ah,yse,edo,odo,DB,rdo,tdo,ado,nh,xse,ndo,sdo,GB,ldo,ido,ddo,_s,$se,cdo,fdo,OB,mdo,gdo,VB,hdo,pdo,_do,us,kse,udo,bdo,XB,vdo,Fdo,zB,Tdo,Mdo,Edo,bs,Sse,Cdo,wdo,QB,Ado,Ldo,WB,ydo,xdo,$do,sh,Rse,kdo,Sdo,HB,Rdo,Pdo,Bdo,vs,Pse,Ido,Ndo,UB,qdo,jdo,JB,Ddo,Gdo,Odo,Fs,Bse,Vdo,Xdo,YB,zdo,Qdo,KB,Wdo,Hdo,Udo,Ts,Ise,Jdo,Ydo,ZB,Kdo,Zdo,eI,eco,oco,rco,Ms,Nse,tco,aco,oI,nco,sco,rI,lco,ico,dco,Es,qse,cco,fco,tI,mco,gco,aI,hco,pco,_co,Cs,jse,uco,bco,nI,vco,Fco,sI,Tco,Mco,Eco,lh,Dse,Cco,wco,lI,Aco,Lco,yco,ws,Gse,xco,$co,iI,kco,Sco,dI,Rco,Pco,Bco,ih,Ose,Ico,Nco,cI,qco,jco,Dco,dh,Vse,Gco,Oco,fI,Vco,Xco,zco,ch,Xse,Qco,Wco,mI,Hco,Uco,Jco,fh,zse,Yco,Kco,gI,Zco,efo,ofo,As,Qse,rfo,tfo,hI,afo,nfo,pI,sfo,lfo,ifo,mh,Wse,dfo,cfo,_I,ffo,mfo,gfo,Ls,Hse,hfo,pfo,uI,_fo,ufo,bI,bfo,vfo,Ffo,ys,Use,Tfo,Mfo,vI,Efo,Cfo,FI,wfo,Afo,Lfo,xs,Jse,yfo,xfo,TI,$fo,kfo,MI,Sfo,Rfo,Pfo,$s,Yse,Bfo,Ifo,EI,Nfo,qfo,CI,jfo,Dfo,Gfo,ks,Kse,Ofo,Vfo,wI,Xfo,zfo,AI,Qfo,Wfo,Hfo,Ss,Zse,Ufo,Jfo,LI,Yfo,Kfo,yI,Zfo,emo,omo,gh,ele,rmo,tmo,xI,amo,nmo,smo,hh,ole,lmo,imo,$I,dmo,cmo,fmo,Rs,rle,mmo,gmo,kI,hmo,pmo,SI,_mo,umo,bmo,Ps,tle,vmo,Fmo,RI,Tmo,Mmo,PI,Emo,Cmo,wmo,Bs,ale,Amo,Lmo,BI,ymo,xmo,II,$mo,kmo,Smo,ph,nle,Rmo,Pmo,NI,Bmo,Imo,Nmo,_h,sle,qmo,jmo,qI,Dmo,Gmo,Omo,uh,lle,Vmo,Xmo,jI,zmo,Qmo,Wmo,Is,ile,Hmo,Umo,DI,Jmo,Ymo,GI,Kmo,Zmo,ego,Ns,dle,ogo,rgo,OI,tgo,ago,VI,ngo,sgo,lgo,bh,cle,igo,dgo,XI,cgo,fgo,mgo,vh,fle,ggo,hgo,zI,pgo,_go,ugo,Fh,mle,bgo,vgo,QI,Fgo,Tgo,Mgo,qs,gle,Ego,Cgo,WI,wgo,Ago,HI,Lgo,ygo,xgo,Th,hle,$go,kgo,UI,Sgo,Rgo,Pgo,Mh,ple,Bgo,Igo,JI,Ngo,qgo,jgo,js,_le,Dgo,Ggo,YI,Ogo,Vgo,KI,Xgo,zgo,Qgo,Ds,ule,Wgo,Hgo,ZI,Ugo,Jgo,eN,Ygo,Kgo,Zgo,Gs,ble,eho,oho,oN,rho,tho,rN,aho,nho,sho,Os,vle,lho,iho,tN,dho,cho,aN,fho,mho,gho,Eh,hho,Ch,OA,pho,Fle,_ho,HGe,Si,wh,Tle,VA,uho,Mle,bho,UGe,Lo,XA,vho,zA,Fho,nN,Tho,Mho,Eho,QA,Cho,Ele,who,Aho,Lho,He,WA,yho,Cle,xho,$ho,Sa,kho,wle,Sho,Rho,Ale,Pho,Bho,Lle,Iho,Nho,qho,Y,Ah,yle,jho,Dho,sN,Gho,Oho,Vho,Lh,xle,Xho,zho,lN,Qho,Who,Hho,yh,$le,Uho,Jho,iN,Yho,Kho,Zho,xh,kle,epo,opo,dN,rpo,tpo,apo,$h,Sle,npo,spo,cN,lpo,ipo,dpo,kh,Rle,cpo,fpo,fN,mpo,gpo,hpo,Sh,Ple,ppo,_po,mN,upo,bpo,vpo,Rh,Ble,Fpo,Tpo,gN,Mpo,Epo,Cpo,Ph,Ile,wpo,Apo,hN,Lpo,ypo,xpo,Bh,Nle,$po,kpo,pN,Spo,Rpo,Ppo,Ih,qle,Bpo,Ipo,_N,Npo,qpo,jpo,Nh,jle,Dpo,Gpo,uN,Opo,Vpo,Xpo,qh,Dle,zpo,Qpo,bN,Wpo,Hpo,Upo,jh,Gle,Jpo,Ypo,vN,Kpo,Zpo,e_o,Dh,Ole,o_o,r_o,FN,t_o,a_o,n_o,Gh,Vle,s_o,l_o,TN,i_o,d_o,c_o,Oh,Xle,f_o,m_o,MN,g_o,h_o,p_o,Vh,zle,__o,u_o,EN,b_o,v_o,F_o,Xh,Qle,T_o,M_o,CN,E_o,C_o,w_o,zh,Wle,A_o,L_o,wN,y_o,x_o,$_o,Qh,Hle,k_o,S_o,AN,R_o,P_o,B_o,Wh,Ule,I_o,N_o,LN,q_o,j_o,D_o,Hh,Jle,G_o,O_o,yN,V_o,X_o,z_o,Uh,Yle,Q_o,W_o,xN,H_o,U_o,J_o,Jh,Kle,Y_o,K_o,$N,Z_o,euo,ouo,Yh,Zle,ruo,tuo,kN,auo,nuo,suo,Kh,eie,luo,iuo,SN,duo,cuo,fuo,Zh,oie,muo,guo,RN,huo,puo,_uo,ep,rie,uuo,buo,PN,vuo,Fuo,Tuo,op,tie,Muo,Euo,BN,Cuo,wuo,Auo,rp,aie,Luo,yuo,IN,xuo,$uo,kuo,tp,nie,Suo,Ruo,NN,Puo,Buo,Iuo,ap,Nuo,np,quo,sp,HA,juo,sie,Duo,JGe,Ri,lp,lie,UA,Guo,iie,Ouo,YGe,yo,JA,Vuo,YA,Xuo,qN,zuo,Quo,Wuo,KA,Huo,die,Uuo,Juo,Yuo,Ue,ZA,Kuo,cie,Zuo,e1o,Pi,o1o,fie,r1o,t1o,mie,a1o,n1o,s1o,he,ip,gie,l1o,i1o,jN,d1o,c1o,f1o,dp,hie,m1o,g1o,pie,h1o,p1o,_1o,cp,_ie,u1o,b1o,DN,v1o,F1o,T1o,fp,uie,M1o,E1o,GN,C1o,w1o,A1o,mp,bie,L1o,y1o,ON,x1o,$1o,k1o,gp,vie,S1o,R1o,VN,P1o,B1o,I1o,hp,Fie,N1o,q1o,XN,j1o,D1o,G1o,pp,Tie,O1o,V1o,zN,X1o,z1o,Q1o,_p,Mie,W1o,H1o,QN,U1o,J1o,Y1o,up,Eie,K1o,Z1o,WN,e2o,o2o,r2o,bp,Cie,t2o,a2o,HN,n2o,s2o,l2o,vp,wie,i2o,d2o,UN,c2o,f2o,m2o,Fp,Aie,g2o,h2o,JN,p2o,_2o,u2o,Tp,Lie,b2o,v2o,YN,F2o,T2o,M2o,Mp,yie,E2o,C2o,KN,w2o,A2o,L2o,Ep,xie,y2o,x2o,ZN,$2o,k2o,S2o,Cp,$ie,R2o,P2o,eq,B2o,I2o,N2o,wp,q2o,Ap,j2o,Lp,eL,D2o,kie,G2o,KGe,Bi,yp,Sie,oL,O2o,Rie,V2o,ZGe,xo,rL,X2o,Ii,z2o,oq,Q2o,W2o,rq,H2o,U2o,J2o,tL,Y2o,Pie,K2o,Z2o,ebo,nt,aL,obo,Bie,rbo,tbo,Ni,abo,Iie,nbo,sbo,tq,lbo,ibo,dbo,xp,cbo,Je,nL,fbo,Nie,mbo,gbo,Ra,hbo,qie,pbo,_bo,jie,ubo,bbo,Die,vbo,Fbo,Tbo,y,$p,Gie,Mbo,Ebo,aq,Cbo,wbo,Abo,kp,Oie,Lbo,ybo,nq,xbo,$bo,kbo,Sp,Vie,Sbo,Rbo,sq,Pbo,Bbo,Ibo,Rp,Xie,Nbo,qbo,lq,jbo,Dbo,Gbo,Pp,zie,Obo,Vbo,iq,Xbo,zbo,Qbo,Bp,Qie,Wbo,Hbo,dq,Ubo,Jbo,Ybo,Ip,Wie,Kbo,Zbo,cq,e4o,o4o,r4o,Np,Hie,t4o,a4o,fq,n4o,s4o,l4o,qp,Uie,i4o,d4o,mq,c4o,f4o,m4o,jp,Jie,g4o,h4o,gq,p4o,_4o,u4o,Dp,Yie,b4o,v4o,hq,F4o,T4o,M4o,Gp,Kie,E4o,C4o,pq,w4o,A4o,L4o,Op,Zie,y4o,x4o,_q,$4o,k4o,S4o,Vp,ede,R4o,P4o,uq,B4o,I4o,N4o,Xp,ode,q4o,j4o,bq,D4o,G4o,O4o,zp,rde,V4o,X4o,vq,z4o,Q4o,W4o,Qp,tde,H4o,U4o,Fq,J4o,Y4o,K4o,Wp,ade,Z4o,evo,Tq,ovo,rvo,tvo,Hp,nde,avo,nvo,Mq,svo,lvo,ivo,Up,sde,dvo,cvo,Eq,fvo,mvo,gvo,Jp,lde,hvo,pvo,Cq,_vo,uvo,bvo,Yp,ide,vvo,Fvo,wq,Tvo,Mvo,Evo,Kp,dde,Cvo,wvo,Aq,Avo,Lvo,yvo,Zp,cde,xvo,$vo,Lq,kvo,Svo,Rvo,e_,fde,Pvo,Bvo,yq,Ivo,Nvo,qvo,o_,mde,jvo,Dvo,xq,Gvo,Ovo,Vvo,r_,gde,Xvo,zvo,$q,Qvo,Wvo,Hvo,t_,hde,Uvo,Jvo,kq,Yvo,Kvo,Zvo,a_,pde,eFo,oFo,Sq,rFo,tFo,aFo,n_,_de,nFo,sFo,Rq,lFo,iFo,dFo,s_,ude,cFo,fFo,Pq,mFo,gFo,hFo,l_,bde,pFo,_Fo,Bq,uFo,bFo,vFo,i_,vde,FFo,TFo,Iq,MFo,EFo,CFo,Vs,Fde,wFo,AFo,Nq,LFo,yFo,qq,xFo,$Fo,kFo,d_,Tde,SFo,RFo,jq,PFo,BFo,IFo,c_,Mde,NFo,qFo,Dq,jFo,DFo,GFo,f_,Ede,OFo,VFo,Gq,XFo,zFo,QFo,m_,Cde,WFo,HFo,Oq,UFo,JFo,YFo,g_,wde,KFo,ZFo,Vq,e6o,o6o,r6o,h_,Ade,t6o,a6o,Xq,n6o,s6o,l6o,p_,Lde,i6o,d6o,zq,c6o,f6o,m6o,__,yde,g6o,h6o,Qq,p6o,_6o,u6o,u_,xde,b6o,v6o,Wq,F6o,T6o,M6o,b_,$de,E6o,C6o,Hq,w6o,A6o,L6o,v_,kde,y6o,x6o,Uq,$6o,k6o,S6o,F_,Sde,R6o,P6o,Jq,B6o,I6o,N6o,T_,Rde,q6o,j6o,Yq,D6o,G6o,O6o,M_,Pde,V6o,X6o,Kq,z6o,Q6o,W6o,E_,Bde,H6o,U6o,Zq,J6o,Y6o,K6o,C_,Ide,Z6o,eTo,ej,oTo,rTo,tTo,w_,Nde,aTo,nTo,oj,sTo,lTo,iTo,A_,qde,dTo,cTo,rj,fTo,mTo,gTo,L_,jde,hTo,pTo,tj,_To,uTo,bTo,y_,Dde,vTo,FTo,aj,TTo,MTo,ETo,x_,Gde,CTo,wTo,nj,ATo,LTo,yTo,$_,Ode,xTo,$To,sj,kTo,STo,RTo,k_,Vde,PTo,BTo,lj,ITo,NTo,qTo,S_,Xde,jTo,DTo,ij,GTo,OTo,VTo,R_,zde,XTo,zTo,dj,QTo,WTo,HTo,P_,Qde,UTo,JTo,cj,YTo,KTo,ZTo,B_,Wde,e7o,o7o,fj,r7o,t7o,a7o,I_,Hde,n7o,s7o,mj,l7o,i7o,d7o,N_,Ude,c7o,f7o,gj,m7o,g7o,h7o,q_,Jde,p7o,_7o,hj,u7o,b7o,v7o,j_,Yde,F7o,T7o,pj,M7o,E7o,C7o,D_,Kde,w7o,A7o,_j,L7o,y7o,x7o,G_,Zde,$7o,k7o,uj,S7o,R7o,P7o,O_,ece,B7o,I7o,bj,N7o,q7o,j7o,V_,oce,D7o,G7o,vj,O7o,V7o,X7o,X_,rce,z7o,Q7o,Fj,W7o,H7o,U7o,z_,tce,J7o,Y7o,Tj,K7o,Z7o,e8o,Q_,ace,o8o,r8o,Mj,t8o,a8o,n8o,W_,nce,s8o,l8o,Ej,i8o,d8o,c8o,H_,sce,f8o,m8o,Cj,g8o,h8o,p8o,U_,lce,_8o,u8o,wj,b8o,v8o,F8o,J_,ice,T8o,M8o,Aj,E8o,C8o,w8o,Y_,dce,A8o,L8o,Lj,y8o,x8o,$8o,K_,cce,k8o,S8o,yj,R8o,P8o,B8o,Z_,fce,I8o,N8o,xj,q8o,j8o,D8o,eu,mce,G8o,O8o,$j,V8o,X8o,z8o,ou,gce,Q8o,W8o,kj,H8o,U8o,J8o,ru,hce,Y8o,K8o,Sj,Z8o,eMo,oMo,tu,pce,rMo,tMo,Rj,aMo,nMo,sMo,au,_ce,lMo,iMo,Pj,dMo,cMo,fMo,nu,uce,mMo,gMo,Bj,hMo,pMo,_Mo,su,bce,uMo,bMo,Ij,vMo,FMo,TMo,lu,vce,MMo,EMo,Nj,CMo,wMo,AMo,iu,Fce,LMo,yMo,qj,xMo,$Mo,kMo,du,Tce,SMo,RMo,jj,PMo,BMo,IMo,cu,Mce,NMo,qMo,Dj,jMo,DMo,GMo,fu,Ece,OMo,VMo,Gj,XMo,zMo,QMo,mu,Cce,WMo,HMo,Oj,UMo,JMo,YMo,gu,wce,KMo,ZMo,Vj,eEo,oEo,rEo,hu,Ace,tEo,aEo,Xj,nEo,sEo,lEo,pu,Lce,iEo,dEo,zj,cEo,fEo,mEo,_u,yce,gEo,hEo,Qj,pEo,_Eo,uEo,uu,xce,bEo,vEo,Wj,FEo,TEo,MEo,bu,$ce,EEo,CEo,Hj,wEo,AEo,LEo,vu,kce,yEo,xEo,Uj,$Eo,kEo,SEo,Fu,Sce,REo,PEo,Jj,BEo,IEo,NEo,Tu,Rce,qEo,jEo,Yj,DEo,GEo,OEo,Mu,Pce,VEo,XEo,Kj,zEo,QEo,WEo,Eu,Bce,HEo,UEo,Zj,JEo,YEo,KEo,Cu,Ice,ZEo,eCo,eD,oCo,rCo,tCo,wu,Nce,aCo,nCo,oD,sCo,lCo,iCo,Au,qce,dCo,cCo,rD,fCo,mCo,gCo,Lu,jce,hCo,pCo,tD,_Co,uCo,bCo,yu,vCo,Dce,FCo,TCo,Gce,MCo,ECo,xu,eOe,qi,$u,Oce,sL,CCo,Vce,wCo,oOe,$o,lL,ACo,ji,LCo,aD,yCo,xCo,nD,$Co,kCo,SCo,iL,RCo,Xce,PCo,BCo,ICo,st,dL,NCo,zce,qCo,jCo,Di,DCo,Qce,GCo,OCo,sD,VCo,XCo,zCo,ku,QCo,Ye,cL,WCo,Wce,HCo,UCo,Pa,JCo,Hce,YCo,KCo,Uce,ZCo,e5o,Jce,o5o,r5o,t5o,G,Su,Yce,a5o,n5o,lD,s5o,l5o,i5o,Ru,Kce,d5o,c5o,iD,f5o,m5o,g5o,Pu,Zce,h5o,p5o,dD,_5o,u5o,b5o,Bu,efe,v5o,F5o,cD,T5o,M5o,E5o,Iu,ofe,C5o,w5o,fD,A5o,L5o,y5o,Nu,rfe,x5o,$5o,mD,k5o,S5o,R5o,qu,tfe,P5o,B5o,gD,I5o,N5o,q5o,ju,afe,j5o,D5o,hD,G5o,O5o,V5o,Du,nfe,X5o,z5o,pD,Q5o,W5o,H5o,Gu,sfe,U5o,J5o,_D,Y5o,K5o,Z5o,Ou,lfe,e3o,o3o,uD,r3o,t3o,a3o,Vu,ife,n3o,s3o,bD,l3o,i3o,d3o,Xu,dfe,c3o,f3o,vD,m3o,g3o,h3o,zu,cfe,p3o,_3o,FD,u3o,b3o,v3o,Qu,ffe,F3o,T3o,TD,M3o,E3o,C3o,Wu,mfe,w3o,A3o,MD,L3o,y3o,x3o,Hu,gfe,$3o,k3o,ED,S3o,R3o,P3o,Uu,hfe,B3o,I3o,CD,N3o,q3o,j3o,Ju,pfe,D3o,G3o,wD,O3o,V3o,X3o,Yu,_fe,z3o,Q3o,AD,W3o,H3o,U3o,Ku,ufe,J3o,Y3o,LD,K3o,Z3o,e0o,Zu,bfe,o0o,r0o,yD,t0o,a0o,n0o,e1,vfe,s0o,l0o,xD,i0o,d0o,c0o,o1,Ffe,f0o,m0o,$D,g0o,h0o,p0o,r1,Tfe,_0o,u0o,kD,b0o,v0o,F0o,t1,Mfe,T0o,M0o,SD,E0o,C0o,w0o,a1,Efe,A0o,L0o,RD,y0o,x0o,$0o,n1,Cfe,k0o,S0o,PD,R0o,P0o,B0o,s1,wfe,I0o,N0o,BD,q0o,j0o,D0o,l1,Afe,G0o,O0o,ID,V0o,X0o,z0o,i1,Lfe,Q0o,W0o,ND,H0o,U0o,J0o,d1,yfe,Y0o,K0o,qD,Z0o,ewo,owo,c1,xfe,rwo,two,jD,awo,nwo,swo,f1,$fe,lwo,iwo,DD,dwo,cwo,fwo,m1,kfe,mwo,gwo,GD,hwo,pwo,_wo,g1,Sfe,uwo,bwo,OD,vwo,Fwo,Two,h1,Rfe,Mwo,Ewo,VD,Cwo,wwo,Awo,p1,Pfe,Lwo,ywo,XD,xwo,$wo,kwo,_1,Bfe,Swo,Rwo,zD,Pwo,Bwo,Iwo,u1,Ife,Nwo,qwo,QD,jwo,Dwo,Gwo,b1,Nfe,Owo,Vwo,WD,Xwo,zwo,Qwo,v1,qfe,Wwo,Hwo,HD,Uwo,Jwo,Ywo,F1,jfe,Kwo,Zwo,UD,eAo,oAo,rAo,T1,Dfe,tAo,aAo,JD,nAo,sAo,lAo,M1,iAo,Gfe,dAo,cAo,Ofe,fAo,mAo,E1,rOe,Gi,C1,Vfe,fL,gAo,Xfe,hAo,tOe,ko,mL,pAo,Oi,_Ao,YD,uAo,bAo,KD,vAo,FAo,TAo,gL,MAo,zfe,EAo,CAo,wAo,lt,hL,AAo,Qfe,LAo,yAo,Vi,xAo,Wfe,$Ao,kAo,ZD,SAo,RAo,PAo,w1,BAo,Ke,pL,IAo,Hfe,NAo,qAo,Ba,jAo,Ufe,DAo,GAo,Jfe,OAo,VAo,Yfe,XAo,zAo,QAo,z,A1,Kfe,WAo,HAo,eG,UAo,JAo,YAo,L1,Zfe,KAo,ZAo,oG,eLo,oLo,rLo,y1,eme,tLo,aLo,rG,nLo,sLo,lLo,x1,ome,iLo,dLo,tG,cLo,fLo,mLo,$1,rme,gLo,hLo,aG,pLo,_Lo,uLo,k1,tme,bLo,vLo,nG,FLo,TLo,MLo,S1,ame,ELo,CLo,sG,wLo,ALo,LLo,R1,nme,yLo,xLo,lG,$Lo,kLo,SLo,P1,sme,RLo,PLo,iG,BLo,ILo,NLo,B1,lme,qLo,jLo,dG,DLo,GLo,OLo,I1,ime,VLo,XLo,cG,zLo,QLo,WLo,N1,dme,HLo,ULo,fG,JLo,YLo,KLo,q1,cme,ZLo,eyo,mG,oyo,ryo,tyo,j1,fme,ayo,nyo,gG,syo,lyo,iyo,D1,mme,dyo,cyo,hG,fyo,myo,gyo,G1,gme,hyo,pyo,pG,_yo,uyo,byo,O1,hme,vyo,Fyo,_G,Tyo,Myo,Eyo,V1,pme,Cyo,wyo,uG,Ayo,Lyo,yyo,X1,_me,xyo,$yo,bG,kyo,Syo,Ryo,z1,ume,Pyo,Byo,vG,Iyo,Nyo,qyo,Q1,bme,jyo,Dyo,FG,Gyo,Oyo,Vyo,W1,vme,Xyo,zyo,TG,Qyo,Wyo,Hyo,H1,Fme,Uyo,Jyo,MG,Yyo,Kyo,Zyo,U1,Tme,e9o,o9o,EG,r9o,t9o,a9o,J1,Mme,n9o,s9o,CG,l9o,i9o,d9o,Y1,Eme,c9o,f9o,wG,m9o,g9o,h9o,K1,Cme,p9o,_9o,AG,u9o,b9o,v9o,Z1,wme,F9o,T9o,LG,M9o,E9o,C9o,e2,Ame,w9o,A9o,yG,L9o,y9o,x9o,o2,Lme,$9o,k9o,xG,S9o,R9o,P9o,r2,yme,B9o,I9o,$G,N9o,q9o,j9o,t2,xme,D9o,G9o,kG,O9o,V9o,X9o,a2,$me,z9o,Q9o,SG,W9o,H9o,U9o,n2,kme,J9o,Y9o,RG,K9o,Z9o,exo,s2,Sme,oxo,rxo,PG,txo,axo,nxo,l2,Rme,sxo,lxo,BG,ixo,dxo,cxo,i2,Pme,fxo,mxo,IG,gxo,hxo,pxo,d2,Bme,_xo,uxo,NG,bxo,vxo,Fxo,c2,Txo,Ime,Mxo,Exo,Nme,Cxo,wxo,f2,aOe,Xi,m2,qme,_L,Axo,jme,Lxo,nOe,So,uL,yxo,zi,xxo,qG,$xo,kxo,jG,Sxo,Rxo,Pxo,bL,Bxo,Dme,Ixo,Nxo,qxo,it,vL,jxo,Gme,Dxo,Gxo,Qi,Oxo,Ome,Vxo,Xxo,DG,zxo,Qxo,Wxo,g2,Hxo,Ze,FL,Uxo,Vme,Jxo,Yxo,Ia,Kxo,Xme,Zxo,e$o,zme,o$o,r$o,Qme,t$o,a$o,n$o,Q,h2,Wme,s$o,l$o,GG,i$o,d$o,c$o,p2,Hme,f$o,m$o,OG,g$o,h$o,p$o,_2,Ume,_$o,u$o,VG,b$o,v$o,F$o,u2,Jme,T$o,M$o,XG,E$o,C$o,w$o,b2,Yme,A$o,L$o,zG,y$o,x$o,$$o,v2,Kme,k$o,S$o,QG,R$o,P$o,B$o,F2,Zme,I$o,N$o,WG,q$o,j$o,D$o,T2,ege,G$o,O$o,HG,V$o,X$o,z$o,M2,oge,Q$o,W$o,UG,H$o,U$o,J$o,E2,rge,Y$o,K$o,JG,Z$o,eko,oko,C2,tge,rko,tko,YG,ako,nko,sko,w2,age,lko,iko,KG,dko,cko,fko,A2,nge,mko,gko,ZG,hko,pko,_ko,L2,sge,uko,bko,eO,vko,Fko,Tko,y2,lge,Mko,Eko,oO,Cko,wko,Ako,x2,ige,Lko,yko,rO,xko,$ko,kko,$2,dge,Sko,Rko,tO,Pko,Bko,Iko,k2,cge,Nko,qko,aO,jko,Dko,Gko,S2,fge,Oko,Vko,nO,Xko,zko,Qko,R2,mge,Wko,Hko,sO,Uko,Jko,Yko,P2,gge,Kko,Zko,lO,eSo,oSo,rSo,B2,hge,tSo,aSo,iO,nSo,sSo,lSo,I2,pge,iSo,dSo,dO,cSo,fSo,mSo,N2,_ge,gSo,hSo,cO,pSo,_So,uSo,q2,uge,bSo,vSo,fO,FSo,TSo,MSo,j2,bge,ESo,CSo,mO,wSo,ASo,LSo,D2,vge,ySo,xSo,gO,$So,kSo,SSo,G2,Fge,RSo,PSo,hO,BSo,ISo,NSo,O2,Tge,qSo,jSo,pO,DSo,GSo,OSo,V2,Mge,VSo,XSo,_O,zSo,QSo,WSo,X2,Ege,HSo,USo,uO,JSo,YSo,KSo,z2,Cge,ZSo,eRo,bO,oRo,rRo,tRo,Q2,wge,aRo,nRo,Age,sRo,lRo,iRo,W2,Lge,dRo,cRo,vO,fRo,mRo,gRo,H2,yge,hRo,pRo,FO,_Ro,uRo,bRo,U2,xge,vRo,FRo,TO,TRo,MRo,ERo,J2,$ge,CRo,wRo,MO,ARo,LRo,yRo,Y2,xRo,kge,$Ro,kRo,Sge,SRo,RRo,K2,sOe,Wi,Z2,Rge,TL,PRo,Pge,BRo,lOe,Ro,ML,IRo,Hi,NRo,EO,qRo,jRo,CO,DRo,GRo,ORo,EL,VRo,Bge,XRo,zRo,QRo,dt,CL,WRo,Ige,HRo,URo,Ui,JRo,Nge,YRo,KRo,wO,ZRo,ePo,oPo,eb,rPo,eo,wL,tPo,qge,aPo,nPo,Na,sPo,jge,lPo,iPo,Dge,dPo,cPo,Gge,fPo,mPo,gPo,pe,ob,Oge,hPo,pPo,AO,_Po,uPo,bPo,rb,Vge,vPo,FPo,LO,TPo,MPo,EPo,tb,Xge,CPo,wPo,yO,APo,LPo,yPo,ab,zge,xPo,$Po,xO,kPo,SPo,RPo,nb,Qge,PPo,BPo,$O,IPo,NPo,qPo,sb,Wge,jPo,DPo,kO,GPo,OPo,VPo,lb,Hge,XPo,zPo,SO,QPo,WPo,HPo,ib,Uge,UPo,JPo,RO,YPo,KPo,ZPo,db,Jge,eBo,oBo,PO,rBo,tBo,aBo,cb,Yge,nBo,sBo,BO,lBo,iBo,dBo,fb,Kge,cBo,fBo,IO,mBo,gBo,hBo,mb,Zge,pBo,_Bo,NO,uBo,bBo,vBo,gb,ehe,FBo,TBo,qO,MBo,EBo,CBo,hb,ohe,wBo,ABo,jO,LBo,yBo,xBo,pb,rhe,$Bo,kBo,DO,SBo,RBo,PBo,_b,the,BBo,IBo,GO,NBo,qBo,jBo,ub,ahe,DBo,GBo,OO,OBo,VBo,XBo,bb,zBo,nhe,QBo,WBo,she,HBo,UBo,vb,iOe,Ji,Fb,lhe,AL,JBo,ihe,YBo,dOe,Po,LL,KBo,Yi,ZBo,VO,eIo,oIo,XO,rIo,tIo,aIo,yL,nIo,dhe,sIo,lIo,iIo,ct,xL,dIo,che,cIo,fIo,Ki,mIo,fhe,gIo,hIo,zO,pIo,_Io,uIo,Tb,bIo,oo,$L,vIo,mhe,FIo,TIo,qa,MIo,ghe,EIo,CIo,hhe,wIo,AIo,phe,LIo,yIo,xIo,N,Mb,_he,$Io,kIo,QO,SIo,RIo,PIo,Eb,uhe,BIo,IIo,WO,NIo,qIo,jIo,Cb,bhe,DIo,GIo,HO,OIo,VIo,XIo,wb,vhe,zIo,QIo,UO,WIo,HIo,UIo,Ab,Fhe,JIo,YIo,JO,KIo,ZIo,eNo,Lb,The,oNo,rNo,YO,tNo,aNo,nNo,yb,Mhe,sNo,lNo,KO,iNo,dNo,cNo,xb,Ehe,fNo,mNo,ZO,gNo,hNo,pNo,$b,Che,_No,uNo,eV,bNo,vNo,FNo,kb,whe,TNo,MNo,oV,ENo,CNo,wNo,Sb,Ahe,ANo,LNo,rV,yNo,xNo,$No,Rb,Lhe,kNo,SNo,tV,RNo,PNo,BNo,Pb,yhe,INo,NNo,aV,qNo,jNo,DNo,Bb,xhe,GNo,ONo,nV,VNo,XNo,zNo,Ib,$he,QNo,WNo,sV,HNo,UNo,JNo,Nb,khe,YNo,KNo,lV,ZNo,eqo,oqo,qb,She,rqo,tqo,iV,aqo,nqo,sqo,jb,Rhe,lqo,iqo,dV,dqo,cqo,fqo,Db,Phe,mqo,gqo,cV,hqo,pqo,_qo,Gb,Bhe,uqo,bqo,fV,vqo,Fqo,Tqo,Ob,Ihe,Mqo,Eqo,mV,Cqo,wqo,Aqo,Vb,Nhe,Lqo,yqo,gV,xqo,$qo,kqo,Xb,qhe,Sqo,Rqo,hV,Pqo,Bqo,Iqo,zb,jhe,Nqo,qqo,pV,jqo,Dqo,Gqo,Qb,Dhe,Oqo,Vqo,_V,Xqo,zqo,Qqo,Wb,Ghe,Wqo,Hqo,uV,Uqo,Jqo,Yqo,Hb,Ohe,Kqo,Zqo,bV,ejo,ojo,rjo,Ub,Vhe,tjo,ajo,vV,njo,sjo,ljo,Jb,Xhe,ijo,djo,FV,cjo,fjo,mjo,Yb,zhe,gjo,hjo,TV,pjo,_jo,ujo,Kb,Qhe,bjo,vjo,MV,Fjo,Tjo,Mjo,Zb,Whe,Ejo,Cjo,EV,wjo,Ajo,Ljo,e4,Hhe,yjo,xjo,CV,$jo,kjo,Sjo,o4,Uhe,Rjo,Pjo,wV,Bjo,Ijo,Njo,r4,Jhe,qjo,jjo,AV,Djo,Gjo,Ojo,t4,Yhe,Vjo,Xjo,LV,zjo,Qjo,Wjo,a4,Khe,Hjo,Ujo,yV,Jjo,Yjo,Kjo,n4,Zhe,Zjo,eDo,xV,oDo,rDo,tDo,s4,epe,aDo,nDo,$V,sDo,lDo,iDo,l4,ope,dDo,cDo,kV,fDo,mDo,gDo,i4,rpe,hDo,pDo,SV,_Do,uDo,bDo,d4,tpe,vDo,FDo,RV,TDo,MDo,EDo,c4,ape,CDo,wDo,PV,ADo,LDo,yDo,f4,npe,xDo,$Do,BV,kDo,SDo,RDo,m4,spe,PDo,BDo,IV,IDo,NDo,qDo,g4,lpe,jDo,DDo,NV,GDo,ODo,VDo,h4,ipe,XDo,zDo,qV,QDo,WDo,HDo,p4,dpe,UDo,JDo,jV,YDo,KDo,ZDo,_4,cpe,eGo,oGo,DV,rGo,tGo,aGo,u4,nGo,fpe,sGo,lGo,mpe,iGo,dGo,b4,cOe,Zi,v4,gpe,kL,cGo,hpe,fGo,fOe,Bo,SL,mGo,ed,gGo,GV,hGo,pGo,OV,_Go,uGo,bGo,RL,vGo,ppe,FGo,TGo,MGo,ft,PL,EGo,_pe,CGo,wGo,od,AGo,upe,LGo,yGo,VV,xGo,$Go,kGo,F4,SGo,ro,BL,RGo,bpe,PGo,BGo,ja,IGo,vpe,NGo,qGo,Fpe,jGo,DGo,Tpe,GGo,OGo,VGo,Z,T4,Mpe,XGo,zGo,XV,QGo,WGo,HGo,M4,Epe,UGo,JGo,zV,YGo,KGo,ZGo,E4,Cpe,eOo,oOo,QV,rOo,tOo,aOo,C4,wpe,nOo,sOo,WV,lOo,iOo,dOo,w4,Ape,cOo,fOo,HV,mOo,gOo,hOo,A4,Lpe,pOo,_Oo,UV,uOo,bOo,vOo,L4,ype,FOo,TOo,JV,MOo,EOo,COo,y4,xpe,wOo,AOo,YV,LOo,yOo,xOo,x4,$pe,$Oo,kOo,KV,SOo,ROo,POo,$4,kpe,BOo,IOo,ZV,NOo,qOo,jOo,k4,Spe,DOo,GOo,eX,OOo,VOo,XOo,S4,Rpe,zOo,QOo,oX,WOo,HOo,UOo,R4,Ppe,JOo,YOo,rX,KOo,ZOo,eVo,P4,Bpe,oVo,rVo,tX,tVo,aVo,nVo,B4,Ipe,sVo,lVo,aX,iVo,dVo,cVo,I4,Npe,fVo,mVo,nX,gVo,hVo,pVo,N4,qpe,_Vo,uVo,sX,bVo,vVo,FVo,q4,jpe,TVo,MVo,lX,EVo,CVo,wVo,j4,Dpe,AVo,LVo,iX,yVo,xVo,$Vo,D4,Gpe,kVo,SVo,dX,RVo,PVo,BVo,G4,Ope,IVo,NVo,cX,qVo,jVo,DVo,O4,Vpe,GVo,OVo,fX,VVo,XVo,zVo,V4,Xpe,QVo,WVo,mX,HVo,UVo,JVo,X4,zpe,YVo,KVo,gX,ZVo,eXo,oXo,z4,Qpe,rXo,tXo,hX,aXo,nXo,sXo,Q4,Wpe,lXo,iXo,pX,dXo,cXo,fXo,W4,Hpe,mXo,gXo,_X,hXo,pXo,_Xo,H4,Upe,uXo,bXo,uX,vXo,FXo,TXo,U4,Jpe,MXo,EXo,bX,CXo,wXo,AXo,J4,Ype,LXo,yXo,vX,xXo,$Xo,kXo,Y4,SXo,Kpe,RXo,PXo,Zpe,BXo,IXo,K4,mOe,rd,Z4,e_e,IL,NXo,o_e,qXo,gOe,Io,NL,jXo,td,DXo,FX,GXo,OXo,TX,VXo,XXo,zXo,qL,QXo,r_e,WXo,HXo,UXo,mt,jL,JXo,t_e,YXo,KXo,ad,ZXo,a_e,ezo,ozo,MX,rzo,tzo,azo,ev,nzo,to,DL,szo,n_e,lzo,izo,Da,dzo,s_e,czo,fzo,l_e,mzo,gzo,i_e,hzo,pzo,_zo,No,ov,d_e,uzo,bzo,EX,vzo,Fzo,Tzo,rv,c_e,Mzo,Ezo,CX,Czo,wzo,Azo,tv,f_e,Lzo,yzo,wX,xzo,$zo,kzo,av,m_e,Szo,Rzo,AX,Pzo,Bzo,Izo,nv,g_e,Nzo,qzo,LX,jzo,Dzo,Gzo,sv,h_e,Ozo,Vzo,yX,Xzo,zzo,Qzo,lv,Wzo,p_e,Hzo,Uzo,__e,Jzo,Yzo,iv,hOe,nd,dv,u_e,GL,Kzo,b_e,Zzo,pOe,qo,OL,eQo,sd,oQo,xX,rQo,tQo,$X,aQo,nQo,sQo,VL,lQo,v_e,iQo,dQo,cQo,gt,XL,fQo,F_e,mQo,gQo,ld,hQo,T_e,pQo,_Qo,kX,uQo,bQo,vQo,cv,FQo,ao,zL,TQo,M_e,MQo,EQo,Ga,CQo,E_e,wQo,AQo,C_e,LQo,yQo,w_e,xQo,$Qo,kQo,H,fv,A_e,SQo,RQo,SX,PQo,BQo,IQo,mv,L_e,NQo,qQo,RX,jQo,DQo,GQo,gv,y_e,OQo,VQo,PX,XQo,zQo,QQo,hv,x_e,WQo,HQo,BX,UQo,JQo,YQo,pv,$_e,KQo,ZQo,IX,eWo,oWo,rWo,_v,k_e,tWo,aWo,NX,nWo,sWo,lWo,uv,S_e,iWo,dWo,qX,cWo,fWo,mWo,bv,R_e,gWo,hWo,jX,pWo,_Wo,uWo,vv,P_e,bWo,vWo,DX,FWo,TWo,MWo,Fv,B_e,EWo,CWo,GX,wWo,AWo,LWo,Tv,I_e,yWo,xWo,OX,$Wo,kWo,SWo,Mv,N_e,RWo,PWo,VX,BWo,IWo,NWo,Ev,q_e,qWo,jWo,XX,DWo,GWo,OWo,Cv,j_e,VWo,XWo,zX,zWo,QWo,WWo,wv,D_e,HWo,UWo,QX,JWo,YWo,KWo,Av,G_e,ZWo,eHo,WX,oHo,rHo,tHo,Lv,O_e,aHo,nHo,HX,sHo,lHo,iHo,yv,V_e,dHo,cHo,UX,fHo,mHo,gHo,xv,X_e,hHo,pHo,JX,_Ho,uHo,bHo,$v,z_e,vHo,FHo,YX,THo,MHo,EHo,kv,Q_e,CHo,wHo,KX,AHo,LHo,yHo,Sv,W_e,xHo,$Ho,ZX,kHo,SHo,RHo,Rv,H_e,PHo,BHo,ez,IHo,NHo,qHo,Pv,U_e,jHo,DHo,oz,GHo,OHo,VHo,Bv,J_e,XHo,zHo,rz,QHo,WHo,HHo,Iv,Y_e,UHo,JHo,tz,YHo,KHo,ZHo,Nv,K_e,eUo,oUo,az,rUo,tUo,aUo,qv,Z_e,nUo,sUo,nz,lUo,iUo,dUo,jv,eue,cUo,fUo,sz,mUo,gUo,hUo,Dv,oue,pUo,_Uo,lz,uUo,bUo,vUo,Gv,rue,FUo,TUo,iz,MUo,EUo,CUo,Ov,tue,wUo,AUo,dz,LUo,yUo,xUo,Vv,aue,$Uo,kUo,cz,SUo,RUo,PUo,Xv,nue,BUo,IUo,fz,NUo,qUo,jUo,zv,sue,DUo,GUo,mz,OUo,VUo,XUo,Qv,lue,zUo,QUo,gz,WUo,HUo,UUo,Wv,JUo,iue,YUo,KUo,due,ZUo,eJo,Hv,_Oe,id,Uv,cue,QL,oJo,fue,rJo,uOe,jo,WL,tJo,dd,aJo,hz,nJo,sJo,pz,lJo,iJo,dJo,HL,cJo,mue,fJo,mJo,gJo,ht,UL,hJo,gue,pJo,_Jo,cd,uJo,hue,bJo,vJo,_z,FJo,TJo,MJo,Jv,EJo,no,JL,CJo,pue,wJo,AJo,Oa,LJo,_ue,yJo,xJo,uue,$Jo,kJo,bue,SJo,RJo,PJo,V,Yv,vue,BJo,IJo,uz,NJo,qJo,jJo,Kv,Fue,DJo,GJo,bz,OJo,VJo,XJo,Zv,Tue,zJo,QJo,vz,WJo,HJo,UJo,eF,Mue,JJo,YJo,Fz,KJo,ZJo,eYo,oF,Eue,oYo,rYo,Tz,tYo,aYo,nYo,rF,Cue,sYo,lYo,Mz,iYo,dYo,cYo,tF,wue,fYo,mYo,Ez,gYo,hYo,pYo,aF,Aue,_Yo,uYo,Cz,bYo,vYo,FYo,nF,Lue,TYo,MYo,wz,EYo,CYo,wYo,sF,yue,AYo,LYo,Az,yYo,xYo,$Yo,lF,xue,kYo,SYo,Lz,RYo,PYo,BYo,iF,$ue,IYo,NYo,yz,qYo,jYo,DYo,dF,kue,GYo,OYo,xz,VYo,XYo,zYo,cF,Sue,QYo,WYo,$z,HYo,UYo,JYo,fF,Rue,YYo,KYo,kz,ZYo,eKo,oKo,mF,Pue,rKo,tKo,Sz,aKo,nKo,sKo,gF,Bue,lKo,iKo,Rz,dKo,cKo,fKo,hF,Iue,mKo,gKo,Pz,hKo,pKo,_Ko,pF,Nue,uKo,bKo,Bz,vKo,FKo,TKo,_F,que,MKo,EKo,Iz,CKo,wKo,AKo,uF,jue,LKo,yKo,Nz,xKo,$Ko,kKo,bF,Due,SKo,RKo,qz,PKo,BKo,IKo,vF,Gue,NKo,qKo,jz,jKo,DKo,GKo,FF,Oue,OKo,VKo,Dz,XKo,zKo,QKo,TF,Vue,WKo,HKo,Gz,UKo,JKo,YKo,MF,Xue,KKo,ZKo,Oz,eZo,oZo,rZo,EF,zue,tZo,aZo,Vz,nZo,sZo,lZo,CF,Que,iZo,dZo,Xz,cZo,fZo,mZo,wF,Wue,gZo,hZo,zz,pZo,_Zo,uZo,AF,Hue,bZo,vZo,Qz,FZo,TZo,MZo,LF,Uue,EZo,CZo,Wz,wZo,AZo,LZo,yF,Jue,yZo,xZo,Hz,$Zo,kZo,SZo,xF,Yue,RZo,PZo,Uz,BZo,IZo,NZo,$F,Kue,qZo,jZo,Jz,DZo,GZo,OZo,kF,Zue,VZo,XZo,Yz,zZo,QZo,WZo,SF,e1e,HZo,UZo,Kz,JZo,YZo,KZo,RF,o1e,ZZo,eer,Zz,oer,rer,ter,PF,r1e,aer,ner,eQ,ser,ler,ier,BF,t1e,der,cer,oQ,fer,mer,ger,IF,a1e,her,per,rQ,_er,uer,ber,NF,n1e,ver,Fer,tQ,Ter,Mer,Eer,qF,Cer,s1e,wer,Aer,l1e,Ler,yer,jF,bOe,fd,DF,i1e,YL,xer,d1e,$er,vOe,Do,KL,ker,md,Ser,aQ,Rer,Per,nQ,Ber,Ier,Ner,ZL,qer,c1e,jer,Der,Ger,pt,ey,Oer,f1e,Ver,Xer,gd,zer,m1e,Qer,Wer,sQ,Her,Uer,Jer,GF,Yer,so,oy,Ker,g1e,Zer,eor,Va,oor,h1e,ror,tor,p1e,aor,nor,_1e,sor,lor,ior,u1e,OF,b1e,dor,cor,lQ,mor,gor,hor,VF,por,v1e,_or,uor,F1e,bor,vor,XF,FOe,hd,zF,T1e,ry,For,M1e,Tor,TOe,Go,ty,Mor,pd,Eor,iQ,Cor,wor,dQ,Aor,Lor,yor,ay,xor,E1e,$or,kor,Sor,_t,ny,Ror,C1e,Por,Bor,_d,Ior,w1e,Nor,qor,cQ,jor,Dor,Gor,QF,Oor,lo,sy,Vor,A1e,Xor,zor,Xa,Qor,L1e,Wor,Hor,y1e,Uor,Jor,x1e,Yor,Kor,Zor,Fe,WF,$1e,err,orr,fQ,rrr,trr,arr,HF,k1e,nrr,srr,mQ,lrr,irr,drr,UF,S1e,crr,frr,gQ,mrr,grr,hrr,JF,R1e,prr,_rr,hQ,urr,brr,vrr,Xs,P1e,Frr,Trr,pQ,Mrr,Err,_Q,Crr,wrr,Arr,YF,B1e,Lrr,yrr,uQ,xrr,$rr,krr,zs,I1e,Srr,Rrr,bQ,Prr,Brr,vQ,Irr,Nrr,qrr,ut,N1e,jrr,Drr,FQ,Grr,Orr,TQ,Vrr,Xrr,MQ,zrr,Qrr,Wrr,KF,q1e,Hrr,Urr,EQ,Jrr,Yrr,Krr,ZF,j1e,Zrr,etr,CQ,otr,rtr,ttr,e6,D1e,atr,ntr,wQ,str,ltr,itr,o6,G1e,dtr,ctr,AQ,ftr,mtr,gtr,r6,O1e,htr,ptr,LQ,_tr,utr,btr,t6,V1e,vtr,Ftr,yQ,Ttr,Mtr,Etr,a6,X1e,Ctr,wtr,xQ,Atr,Ltr,ytr,n6,xtr,z1e,$tr,ktr,Q1e,Str,Rtr,s6,MOe,ud,l6,W1e,ly,Ptr,H1e,Btr,EOe,Oo,iy,Itr,bd,Ntr,$Q,qtr,jtr,kQ,Dtr,Gtr,Otr,dy,Vtr,U1e,Xtr,ztr,Qtr,bt,cy,Wtr,J1e,Htr,Utr,vd,Jtr,Y1e,Ytr,Ktr,SQ,Ztr,ear,oar,i6,rar,io,fy,tar,K1e,aar,nar,za,sar,Z1e,lar,iar,e2e,dar,car,o2e,far,mar,gar,r2e,d6,t2e,har,par,RQ,_ar,uar,bar,c6,Far,a2e,Tar,Mar,n2e,Ear,Car,f6,COe,Fd,m6,s2e,my,war,l2e,Aar,wOe,Vo,gy,Lar,Td,yar,PQ,xar,$ar,BQ,kar,Sar,Rar,hy,Par,i2e,Bar,Iar,Nar,vt,py,qar,d2e,jar,Dar,Md,Gar,c2e,Oar,Var,IQ,Xar,zar,Qar,g6,War,co,_y,Har,f2e,Uar,Jar,Qa,Yar,m2e,Kar,Zar,g2e,enr,onr,h2e,rnr,tnr,anr,p2e,h6,_2e,nnr,snr,NQ,lnr,inr,dnr,p6,cnr,u2e,fnr,mnr,b2e,gnr,hnr,_6,AOe,Ed,u6,v2e,uy,pnr,F2e,_nr,LOe,Xo,by,unr,Cd,bnr,qQ,vnr,Fnr,jQ,Tnr,Mnr,Enr,vy,Cnr,T2e,wnr,Anr,Lnr,Ft,Fy,ynr,M2e,xnr,$nr,wd,knr,E2e,Snr,Rnr,DQ,Pnr,Bnr,Inr,b6,Nnr,fo,Ty,qnr,C2e,jnr,Dnr,Wa,Gnr,w2e,Onr,Vnr,A2e,Xnr,znr,L2e,Qnr,Wnr,Hnr,Pe,v6,y2e,Unr,Jnr,GQ,Ynr,Knr,Znr,F6,x2e,esr,osr,OQ,rsr,tsr,asr,T6,$2e,nsr,ssr,VQ,lsr,isr,dsr,M6,k2e,csr,fsr,XQ,msr,gsr,hsr,E6,S2e,psr,_sr,zQ,usr,bsr,vsr,C6,R2e,Fsr,Tsr,QQ,Msr,Esr,Csr,w6,P2e,wsr,Asr,WQ,Lsr,ysr,xsr,A6,B2e,$sr,ksr,HQ,Ssr,Rsr,Psr,L6,I2e,Bsr,Isr,UQ,Nsr,qsr,jsr,y6,Dsr,N2e,Gsr,Osr,q2e,Vsr,Xsr,x6,yOe,Ad,$6,j2e,My,zsr,D2e,Qsr,xOe,zo,Ey,Wsr,Ld,Hsr,JQ,Usr,Jsr,YQ,Ysr,Ksr,Zsr,Cy,elr,G2e,olr,rlr,tlr,Tt,wy,alr,O2e,nlr,slr,yd,llr,V2e,ilr,dlr,KQ,clr,flr,mlr,k6,glr,mo,Ay,hlr,X2e,plr,_lr,Ha,ulr,z2e,blr,vlr,Q2e,Flr,Tlr,W2e,Mlr,Elr,Clr,et,S6,H2e,wlr,Alr,ZQ,Llr,ylr,xlr,R6,U2e,$lr,klr,eW,Slr,Rlr,Plr,P6,J2e,Blr,Ilr,oW,Nlr,qlr,jlr,B6,Y2e,Dlr,Glr,rW,Olr,Vlr,Xlr,I6,K2e,zlr,Qlr,tW,Wlr,Hlr,Ulr,N6,Jlr,Z2e,Ylr,Klr,ebe,Zlr,eir,q6,$Oe,xd,j6,obe,Ly,oir,rbe,rir,kOe,Qo,yy,tir,$d,air,aW,nir,sir,nW,lir,iir,dir,xy,cir,tbe,fir,mir,gir,Mt,$y,hir,abe,pir,_ir,kd,uir,nbe,bir,vir,sW,Fir,Tir,Mir,D6,Eir,go,ky,Cir,sbe,wir,Air,Ua,Lir,lbe,yir,xir,ibe,$ir,kir,dbe,Sir,Rir,Pir,Le,G6,cbe,Bir,Iir,lW,Nir,qir,jir,O6,fbe,Dir,Gir,iW,Oir,Vir,Xir,V6,mbe,zir,Qir,dW,Wir,Hir,Uir,X6,gbe,Jir,Yir,cW,Kir,Zir,edr,z6,hbe,odr,rdr,fW,tdr,adr,ndr,Q6,pbe,sdr,ldr,mW,idr,ddr,cdr,W6,_be,fdr,mdr,gW,gdr,hdr,pdr,H6,ube,_dr,udr,hW,bdr,vdr,Fdr,U6,bbe,Tdr,Mdr,pW,Edr,Cdr,wdr,J6,vbe,Adr,Ldr,_W,ydr,xdr,$dr,Y6,kdr,Fbe,Sdr,Rdr,Tbe,Pdr,Bdr,K6,SOe,Sd,Z6,Mbe,Sy,Idr,Ebe,Ndr,ROe,Wo,Ry,qdr,Rd,jdr,uW,Ddr,Gdr,bW,Odr,Vdr,Xdr,Py,zdr,Cbe,Qdr,Wdr,Hdr,Et,By,Udr,wbe,Jdr,Ydr,Pd,Kdr,Abe,Zdr,ecr,vW,ocr,rcr,tcr,eT,acr,ho,Iy,ncr,Lbe,scr,lcr,Ja,icr,ybe,dcr,ccr,xbe,fcr,mcr,$be,gcr,hcr,pcr,Ny,oT,kbe,_cr,ucr,FW,bcr,vcr,Fcr,rT,Sbe,Tcr,Mcr,TW,Ecr,Ccr,wcr,tT,Acr,Rbe,Lcr,ycr,Pbe,xcr,$cr,aT,POe,Bd,nT,Bbe,qy,kcr,Ibe,Scr,BOe,Ho,jy,Rcr,Id,Pcr,MW,Bcr,Icr,EW,Ncr,qcr,jcr,Dy,Dcr,Nbe,Gcr,Ocr,Vcr,Ct,Gy,Xcr,qbe,zcr,Qcr,Nd,Wcr,jbe,Hcr,Ucr,CW,Jcr,Ycr,Kcr,sT,Zcr,po,Oy,efr,Dbe,ofr,rfr,Ya,tfr,Gbe,afr,nfr,Obe,sfr,lfr,Vbe,ifr,dfr,cfr,ot,lT,Xbe,ffr,mfr,wW,gfr,hfr,pfr,iT,zbe,_fr,ufr,AW,bfr,vfr,Ffr,dT,Qbe,Tfr,Mfr,LW,Efr,Cfr,wfr,cT,Wbe,Afr,Lfr,yW,yfr,xfr,$fr,fT,Hbe,kfr,Sfr,xW,Rfr,Pfr,Bfr,mT,Ifr,Ube,Nfr,qfr,Jbe,jfr,Dfr,gT,IOe,qd,hT,Ybe,Vy,Gfr,Kbe,Ofr,NOe,Uo,Xy,Vfr,jd,Xfr,$W,zfr,Qfr,kW,Wfr,Hfr,Ufr,zy,Jfr,Zbe,Yfr,Kfr,Zfr,wt,Qy,emr,e4e,omr,rmr,Dd,tmr,o4e,amr,nmr,SW,smr,lmr,imr,pT,dmr,_o,Wy,cmr,r4e,fmr,mmr,Ka,gmr,t4e,hmr,pmr,a4e,_mr,umr,n4e,bmr,vmr,Fmr,Gd,_T,s4e,Tmr,Mmr,RW,Emr,Cmr,wmr,uT,l4e,Amr,Lmr,PW,ymr,xmr,$mr,bT,i4e,kmr,Smr,BW,Rmr,Pmr,Bmr,vT,Imr,d4e,Nmr,qmr,c4e,jmr,Dmr,FT,qOe,Od,TT,f4e,Hy,Gmr,m4e,Omr,jOe,Jo,Uy,Vmr,Vd,Xmr,IW,zmr,Qmr,NW,Wmr,Hmr,Umr,Jy,Jmr,g4e,Ymr,Kmr,Zmr,At,Yy,egr,h4e,ogr,rgr,Xd,tgr,p4e,agr,ngr,qW,sgr,lgr,igr,MT,dgr,uo,Ky,cgr,_4e,fgr,mgr,Za,ggr,u4e,hgr,pgr,b4e,_gr,ugr,v4e,bgr,vgr,Fgr,Zy,ET,F4e,Tgr,Mgr,jW,Egr,Cgr,wgr,CT,T4e,Agr,Lgr,DW,ygr,xgr,$gr,wT,kgr,M4e,Sgr,Rgr,E4e,Pgr,Bgr,AT,DOe,zd,LT,C4e,e9,Igr,w4e,Ngr,GOe,Yo,o9,qgr,Qd,jgr,GW,Dgr,Ggr,OW,Ogr,Vgr,Xgr,r9,zgr,A4e,Qgr,Wgr,Hgr,Lt,t9,Ugr,L4e,Jgr,Ygr,Wd,Kgr,y4e,Zgr,ehr,VW,ohr,rhr,thr,yT,ahr,bo,a9,nhr,x4e,shr,lhr,en,ihr,$4e,dhr,chr,k4e,fhr,mhr,S4e,ghr,hhr,phr,R4e,xT,P4e,_hr,uhr,XW,bhr,vhr,Fhr,$T,Thr,B4e,Mhr,Ehr,I4e,Chr,whr,kT,OOe,Hd,ST,N4e,n9,Ahr,q4e,Lhr,VOe,Ko,s9,yhr,Ud,xhr,zW,$hr,khr,QW,Shr,Rhr,Phr,l9,Bhr,j4e,Ihr,Nhr,qhr,yt,i9,jhr,D4e,Dhr,Ghr,Jd,Ohr,G4e,Vhr,Xhr,WW,zhr,Qhr,Whr,RT,Hhr,vo,d9,Uhr,O4e,Jhr,Yhr,on,Khr,V4e,Zhr,epr,X4e,opr,rpr,z4e,tpr,apr,npr,rn,PT,Q4e,spr,lpr,HW,ipr,dpr,cpr,BT,W4e,fpr,mpr,UW,gpr,hpr,ppr,IT,H4e,_pr,upr,JW,bpr,vpr,Fpr,NT,U4e,Tpr,Mpr,YW,Epr,Cpr,wpr,qT,Apr,J4e,Lpr,ypr,Y4e,xpr,$pr,jT,XOe,Yd,DT,K4e,c9,kpr,Z4e,Spr,zOe,Zo,f9,Rpr,Kd,Ppr,KW,Bpr,Ipr,ZW,Npr,qpr,jpr,m9,Dpr,eve,Gpr,Opr,Vpr,xt,g9,Xpr,ove,zpr,Qpr,Zd,Wpr,rve,Hpr,Upr,eH,Jpr,Ypr,Kpr,GT,Zpr,Fo,h9,e_r,tve,o_r,r_r,tn,t_r,ave,a_r,n_r,nve,s_r,l_r,sve,i_r,d_r,c_r,lve,OT,ive,f_r,m_r,oH,g_r,h_r,p_r,VT,__r,dve,u_r,b_r,cve,v_r,F_r,XT,QOe,ec,zT,fve,p9,T_r,mve,M_r,WOe,er,_9,E_r,oc,C_r,rH,w_r,A_r,tH,L_r,y_r,x_r,u9,$_r,gve,k_r,S_r,R_r,$t,b9,P_r,hve,B_r,I_r,rc,N_r,pve,q_r,j_r,aH,D_r,G_r,O_r,QT,V_r,yr,v9,X_r,_ve,z_r,Q_r,an,W_r,uve,H_r,U_r,bve,J_r,Y_r,vve,K_r,Z_r,eur,j,WT,Fve,our,rur,nH,tur,aur,nur,HT,Tve,sur,lur,sH,iur,dur,cur,UT,Mve,fur,mur,lH,gur,hur,pur,JT,Eve,_ur,uur,iH,bur,vur,Fur,YT,Cve,Tur,Mur,dH,Eur,Cur,wur,KT,wve,Aur,Lur,cH,yur,xur,$ur,ZT,Ave,kur,Sur,fH,Rur,Pur,Bur,e7,Lve,Iur,Nur,mH,qur,jur,Dur,o7,yve,Gur,Our,gH,Vur,Xur,zur,r7,xve,Qur,Wur,hH,Hur,Uur,Jur,t7,$ve,Yur,Kur,pH,Zur,e1r,o1r,a7,kve,r1r,t1r,_H,a1r,n1r,s1r,n7,Sve,l1r,i1r,uH,d1r,c1r,f1r,s7,Rve,m1r,g1r,bH,h1r,p1r,_1r,l7,Pve,u1r,b1r,vH,v1r,F1r,T1r,i7,Bve,M1r,E1r,FH,C1r,w1r,A1r,d7,Ive,L1r,y1r,TH,x1r,$1r,k1r,Qs,Nve,S1r,R1r,MH,P1r,B1r,EH,I1r,N1r,q1r,c7,qve,j1r,D1r,CH,G1r,O1r,V1r,f7,jve,X1r,z1r,wH,Q1r,W1r,H1r,m7,Dve,U1r,J1r,AH,Y1r,K1r,Z1r,g7,Gve,e2r,o2r,LH,r2r,t2r,a2r,h7,Ove,n2r,s2r,yH,l2r,i2r,d2r,p7,Vve,c2r,f2r,xH,m2r,g2r,h2r,_7,Xve,p2r,_2r,$H,u2r,b2r,v2r,u7,zve,F2r,T2r,kH,M2r,E2r,C2r,b7,Qve,w2r,A2r,SH,L2r,y2r,x2r,v7,Wve,$2r,k2r,RH,S2r,R2r,P2r,F7,Hve,B2r,I2r,PH,N2r,q2r,j2r,T7,Uve,D2r,G2r,BH,O2r,V2r,X2r,M7,Jve,z2r,Q2r,IH,W2r,H2r,U2r,E7,Yve,J2r,Y2r,NH,K2r,Z2r,ebr,C7,Kve,obr,rbr,qH,tbr,abr,nbr,w7,Zve,sbr,lbr,jH,ibr,dbr,cbr,A7,eFe,fbr,mbr,DH,gbr,hbr,pbr,L7,oFe,_br,ubr,GH,bbr,vbr,Fbr,y7,rFe,Tbr,Mbr,OH,Ebr,Cbr,wbr,x7,tFe,Abr,Lbr,VH,ybr,xbr,$br,$7,aFe,kbr,Sbr,XH,Rbr,Pbr,Bbr,k7,nFe,Ibr,Nbr,zH,qbr,jbr,Dbr,S7,sFe,Gbr,Obr,QH,Vbr,Xbr,zbr,R7,lFe,Qbr,Wbr,WH,Hbr,Ubr,Jbr,P7,iFe,Ybr,Kbr,HH,Zbr,e4r,o4r,B7,dFe,r4r,t4r,UH,a4r,n4r,s4r,I7,cFe,l4r,i4r,JH,d4r,c4r,f4r,N7,fFe,m4r,g4r,YH,h4r,p4r,_4r,q7,mFe,u4r,b4r,KH,v4r,F4r,T4r,j7,HOe,tc,D7,gFe,F9,M4r,hFe,E4r,UOe,or,T9,C4r,ac,w4r,ZH,A4r,L4r,eU,y4r,x4r,$4r,M9,k4r,pFe,S4r,R4r,P4r,kt,E9,B4r,_Fe,I4r,N4r,nc,q4r,uFe,j4r,D4r,oU,G4r,O4r,V4r,G7,X4r,xr,C9,z4r,bFe,Q4r,W4r,nn,H4r,vFe,U4r,J4r,FFe,Y4r,K4r,TFe,Z4r,evr,ovr,se,O7,MFe,rvr,tvr,rU,avr,nvr,svr,V7,EFe,lvr,ivr,tU,dvr,cvr,fvr,X7,CFe,mvr,gvr,aU,hvr,pvr,_vr,z7,wFe,uvr,bvr,nU,vvr,Fvr,Tvr,Q7,AFe,Mvr,Evr,sU,Cvr,wvr,Avr,W7,LFe,Lvr,yvr,lU,xvr,$vr,kvr,H7,yFe,Svr,Rvr,iU,Pvr,Bvr,Ivr,U7,xFe,Nvr,qvr,dU,jvr,Dvr,Gvr,J7,$Fe,Ovr,Vvr,cU,Xvr,zvr,Qvr,Y7,kFe,Wvr,Hvr,fU,Uvr,Jvr,Yvr,K7,SFe,Kvr,Zvr,mU,eFr,oFr,rFr,Z7,RFe,tFr,aFr,gU,nFr,sFr,lFr,e8,PFe,iFr,dFr,hU,cFr,fFr,mFr,o8,BFe,gFr,hFr,pU,pFr,_Fr,uFr,r8,IFe,bFr,vFr,_U,FFr,TFr,MFr,t8,NFe,EFr,CFr,uU,wFr,AFr,LFr,a8,qFe,yFr,xFr,bU,$Fr,kFr,SFr,n8,jFe,RFr,PFr,vU,BFr,IFr,NFr,s8,DFe,qFr,jFr,FU,DFr,GFr,OFr,l8,GFe,VFr,XFr,TU,zFr,QFr,WFr,i8,OFe,HFr,UFr,MU,JFr,YFr,KFr,d8,VFe,ZFr,e6r,EU,o6r,r6r,t6r,c8,XFe,a6r,n6r,CU,s6r,l6r,i6r,f8,JOe,sc,m8,zFe,w9,d6r,QFe,c6r,YOe,rr,A9,f6r,lc,m6r,wU,g6r,h6r,AU,p6r,_6r,u6r,L9,b6r,WFe,v6r,F6r,T6r,St,y9,M6r,HFe,E6r,C6r,ic,w6r,UFe,A6r,L6r,LU,y6r,x6r,$6r,g8,k6r,$r,x9,S6r,JFe,R6r,P6r,sn,B6r,YFe,I6r,N6r,KFe,q6r,j6r,ZFe,D6r,G6r,O6r,Me,h8,e6e,V6r,X6r,yU,z6r,Q6r,W6r,p8,o6e,H6r,U6r,xU,J6r,Y6r,K6r,_8,r6e,Z6r,eTr,$U,oTr,rTr,tTr,u8,t6e,aTr,nTr,kU,sTr,lTr,iTr,b8,a6e,dTr,cTr,SU,fTr,mTr,gTr,v8,n6e,hTr,pTr,RU,_Tr,uTr,bTr,F8,s6e,vTr,FTr,PU,TTr,MTr,ETr,T8,l6e,CTr,wTr,BU,ATr,LTr,yTr,M8,i6e,xTr,$Tr,IU,kTr,STr,RTr,E8,d6e,PTr,BTr,NU,ITr,NTr,qTr,C8,c6e,jTr,DTr,qU,GTr,OTr,VTr,w8,f6e,XTr,zTr,jU,QTr,WTr,HTr,A8,m6e,UTr,JTr,DU,YTr,KTr,ZTr,L8,KOe,dc,y8,g6e,$9,e7r,h6e,o7r,ZOe,tr,k9,r7r,cc,t7r,GU,a7r,n7r,OU,s7r,l7r,i7r,S9,d7r,p6e,c7r,f7r,m7r,Rt,R9,g7r,_6e,h7r,p7r,fc,_7r,u6e,u7r,b7r,VU,v7r,F7r,T7r,x8,M7r,kr,P9,E7r,b6e,C7r,w7r,ln,A7r,v6e,L7r,y7r,F6e,x7r,$7r,T6e,k7r,S7r,R7r,dn,$8,M6e,P7r,B7r,XU,I7r,N7r,q7r,k8,E6e,j7r,D7r,zU,G7r,O7r,V7r,S8,C6e,X7r,z7r,QU,Q7r,W7r,H7r,R8,w6e,U7r,J7r,WU,Y7r,K7r,Z7r,P8,eVe,mc,B8,A6e,B9,e8r,L6e,o8r,oVe,ar,I9,r8r,gc,t8r,HU,a8r,n8r,UU,s8r,l8r,i8r,N9,d8r,y6e,c8r,f8r,m8r,Pt,q9,g8r,x6e,h8r,p8r,hc,_8r,$6e,u8r,b8r,JU,v8r,F8r,T8r,I8,M8r,Sr,j9,E8r,k6e,C8r,w8r,cn,A8r,S6e,L8r,y8r,R6e,x8r,$8r,P6e,k8r,S8r,R8r,ie,N8,B6e,P8r,B8r,YU,I8r,N8r,q8r,q8,I6e,j8r,D8r,KU,G8r,O8r,V8r,j8,N6e,X8r,z8r,ZU,Q8r,W8r,H8r,D8,q6e,U8r,J8r,eJ,Y8r,K8r,Z8r,G8,j6e,eMr,oMr,oJ,rMr,tMr,aMr,O8,D6e,nMr,sMr,rJ,lMr,iMr,dMr,V8,G6e,cMr,fMr,tJ,mMr,gMr,hMr,X8,O6e,pMr,_Mr,aJ,uMr,bMr,vMr,z8,V6e,FMr,TMr,nJ,MMr,EMr,CMr,Q8,X6e,wMr,AMr,sJ,LMr,yMr,xMr,W8,z6e,$Mr,kMr,lJ,SMr,RMr,PMr,H8,Q6e,BMr,IMr,iJ,NMr,qMr,jMr,U8,W6e,DMr,GMr,dJ,OMr,VMr,XMr,J8,H6e,zMr,QMr,cJ,WMr,HMr,UMr,Y8,U6e,JMr,YMr,fJ,KMr,ZMr,eEr,K8,J6e,oEr,rEr,mJ,tEr,aEr,nEr,Z8,Y6e,sEr,lEr,gJ,iEr,dEr,cEr,eM,K6e,fEr,mEr,hJ,gEr,hEr,pEr,oM,Z6e,_Er,uEr,pJ,bEr,vEr,FEr,rM,eTe,TEr,MEr,_J,EEr,CEr,wEr,tM,rVe,pc,aM,oTe,D9,AEr,rTe,LEr,tVe,nr,G9,yEr,_c,xEr,uJ,$Er,kEr,bJ,SEr,REr,PEr,O9,BEr,tTe,IEr,NEr,qEr,Bt,V9,jEr,aTe,DEr,GEr,uc,OEr,nTe,VEr,XEr,vJ,zEr,QEr,WEr,nM,HEr,Rr,X9,UEr,sTe,JEr,YEr,fn,KEr,lTe,ZEr,eCr,iTe,oCr,rCr,dTe,tCr,aCr,nCr,ye,sM,cTe,sCr,lCr,FJ,iCr,dCr,cCr,lM,fTe,fCr,mCr,TJ,gCr,hCr,pCr,iM,mTe,_Cr,uCr,MJ,bCr,vCr,FCr,dM,gTe,TCr,MCr,EJ,ECr,CCr,wCr,cM,hTe,ACr,LCr,CJ,yCr,xCr,$Cr,fM,pTe,kCr,SCr,wJ,RCr,PCr,BCr,mM,_Te,ICr,NCr,AJ,qCr,jCr,DCr,gM,uTe,GCr,OCr,LJ,VCr,XCr,zCr,hM,bTe,QCr,WCr,yJ,HCr,UCr,JCr,pM,vTe,YCr,KCr,xJ,ZCr,e5r,o5r,_M,aVe,bc,uM,FTe,z9,r5r,TTe,t5r,nVe,sr,Q9,a5r,vc,n5r,$J,s5r,l5r,kJ,i5r,d5r,c5r,W9,f5r,MTe,m5r,g5r,h5r,It,H9,p5r,ETe,_5r,u5r,Fc,b5r,CTe,v5r,F5r,SJ,T5r,M5r,E5r,bM,C5r,Pr,U9,w5r,wTe,A5r,L5r,mn,y5r,ATe,x5r,$5r,LTe,k5r,S5r,yTe,R5r,P5r,B5r,te,vM,xTe,I5r,N5r,RJ,q5r,j5r,D5r,FM,$Te,G5r,O5r,PJ,V5r,X5r,z5r,TM,kTe,Q5r,W5r,BJ,H5r,U5r,J5r,MM,STe,Y5r,K5r,IJ,Z5r,e3r,o3r,EM,RTe,r3r,t3r,NJ,a3r,n3r,s3r,CM,PTe,l3r,i3r,qJ,d3r,c3r,f3r,wM,BTe,m3r,g3r,jJ,h3r,p3r,_3r,AM,ITe,u3r,b3r,DJ,v3r,F3r,T3r,LM,NTe,M3r,E3r,GJ,C3r,w3r,A3r,yM,qTe,L3r,y3r,OJ,x3r,$3r,k3r,xM,jTe,S3r,R3r,VJ,P3r,B3r,I3r,$M,DTe,N3r,q3r,XJ,j3r,D3r,G3r,kM,GTe,O3r,V3r,zJ,X3r,z3r,Q3r,SM,OTe,W3r,H3r,QJ,U3r,J3r,Y3r,RM,VTe,K3r,Z3r,WJ,e0r,o0r,r0r,PM,XTe,t0r,a0r,HJ,n0r,s0r,l0r,BM,zTe,i0r,d0r,UJ,c0r,f0r,m0r,IM,QTe,g0r,h0r,JJ,p0r,_0r,u0r,NM,WTe,b0r,v0r,YJ,F0r,T0r,M0r,qM,HTe,E0r,C0r,KJ,w0r,A0r,L0r,jM,UTe,y0r,x0r,ZJ,$0r,k0r,S0r,DM,JTe,R0r,P0r,eY,B0r,I0r,N0r,GM,YTe,q0r,j0r,oY,D0r,G0r,O0r,OM,KTe,V0r,X0r,rY,z0r,Q0r,W0r,VM,ZTe,H0r,U0r,tY,J0r,Y0r,K0r,XM,e7e,Z0r,ewr,aY,owr,rwr,twr,zM,sVe,Tc,QM,o7e,J9,awr,r7e,nwr,lVe,lr,Y9,swr,Mc,lwr,nY,iwr,dwr,sY,cwr,fwr,mwr,K9,gwr,t7e,hwr,pwr,_wr,Nt,Z9,uwr,a7e,bwr,vwr,Ec,Fwr,n7e,Twr,Mwr,lY,Ewr,Cwr,wwr,WM,Awr,Br,ex,Lwr,s7e,ywr,xwr,gn,$wr,l7e,kwr,Swr,i7e,Rwr,Pwr,d7e,Bwr,Iwr,Nwr,_e,HM,c7e,qwr,jwr,iY,Dwr,Gwr,Owr,UM,f7e,Vwr,Xwr,dY,zwr,Qwr,Wwr,JM,m7e,Hwr,Uwr,cY,Jwr,Ywr,Kwr,YM,g7e,Zwr,eAr,fY,oAr,rAr,tAr,KM,h7e,aAr,nAr,mY,sAr,lAr,iAr,ZM,p7e,dAr,cAr,gY,fAr,mAr,gAr,eE,_7e,hAr,pAr,hY,_Ar,uAr,bAr,oE,u7e,vAr,FAr,pY,TAr,MAr,EAr,rE,b7e,CAr,wAr,_Y,AAr,LAr,yAr,tE,v7e,xAr,$Ar,uY,kAr,SAr,RAr,aE,F7e,PAr,BAr,bY,IAr,NAr,qAr,nE,T7e,jAr,DAr,vY,GAr,OAr,VAr,sE,M7e,XAr,zAr,FY,QAr,WAr,HAr,lE,E7e,UAr,JAr,TY,YAr,KAr,ZAr,iE,C7e,eLr,oLr,MY,rLr,tLr,aLr,dE,w7e,nLr,sLr,EY,lLr,iLr,dLr,cE,A7e,cLr,fLr,CY,mLr,gLr,hLr,fE,iVe,Cc,mE,L7e,ox,pLr,y7e,_Lr,dVe,ir,rx,uLr,wc,bLr,wY,vLr,FLr,AY,TLr,MLr,ELr,tx,CLr,x7e,wLr,ALr,LLr,qt,ax,yLr,$7e,xLr,$Lr,Ac,kLr,k7e,SLr,RLr,LY,PLr,BLr,ILr,gE,NLr,Ir,nx,qLr,S7e,jLr,DLr,hn,GLr,R7e,OLr,VLr,P7e,XLr,zLr,B7e,QLr,WLr,HLr,sx,hE,I7e,ULr,JLr,yY,YLr,KLr,ZLr,pE,N7e,eyr,oyr,xY,ryr,tyr,ayr,_E,cVe,Lc,uE,q7e,lx,nyr,j7e,syr,fVe,dr,ix,lyr,yc,iyr,$Y,dyr,cyr,kY,fyr,myr,gyr,dx,hyr,D7e,pyr,_yr,uyr,jt,cx,byr,G7e,vyr,Fyr,xc,Tyr,O7e,Myr,Eyr,SY,Cyr,wyr,Ayr,bE,Lyr,Nr,fx,yyr,V7e,xyr,$yr,pn,kyr,X7e,Syr,Ryr,z7e,Pyr,Byr,Q7e,Iyr,Nyr,qyr,W7e,vE,H7e,jyr,Dyr,RY,Gyr,Oyr,Vyr,FE,mVe,$c,TE,U7e,mx,Xyr,J7e,zyr,gVe,cr,gx,Qyr,kc,Wyr,PY,Hyr,Uyr,BY,Jyr,Yyr,Kyr,hx,Zyr,Y7e,e9r,o9r,r9r,Dt,px,t9r,K7e,a9r,n9r,Sc,s9r,Z7e,l9r,i9r,IY,d9r,c9r,f9r,ME,m9r,qr,_x,g9r,e8e,h9r,p9r,_n,_9r,o8e,u9r,b9r,r8e,v9r,F9r,t8e,T9r,M9r,E9r,de,EE,a8e,C9r,w9r,NY,A9r,L9r,y9r,CE,n8e,x9r,$9r,qY,k9r,S9r,R9r,wE,s8e,P9r,B9r,jY,I9r,N9r,q9r,AE,l8e,j9r,D9r,DY,G9r,O9r,V9r,LE,i8e,X9r,z9r,GY,Q9r,W9r,H9r,yE,d8e,U9r,J9r,OY,Y9r,K9r,Z9r,xE,c8e,exr,oxr,VY,rxr,txr,axr,$E,f8e,nxr,sxr,XY,lxr,ixr,dxr,kE,m8e,cxr,fxr,zY,mxr,gxr,hxr,SE,g8e,pxr,_xr,QY,uxr,bxr,vxr,RE,h8e,Fxr,Txr,WY,Mxr,Exr,Cxr,PE,p8e,wxr,Axr,HY,Lxr,yxr,xxr,BE,_8e,$xr,kxr,UY,Sxr,Rxr,Pxr,IE,u8e,Bxr,Ixr,JY,Nxr,qxr,jxr,NE,b8e,Dxr,Gxr,YY,Oxr,Vxr,Xxr,qE,v8e,zxr,Qxr,KY,Wxr,Hxr,Uxr,jE,F8e,Jxr,Yxr,ZY,Kxr,Zxr,e$r,DE,T8e,o$r,r$r,eK,t$r,a$r,n$r,GE,M8e,s$r,l$r,oK,i$r,d$r,c$r,OE,E8e,f$r,m$r,rK,g$r,h$r,p$r,VE,hVe,Rc,XE,C8e,ux,_$r,w8e,u$r,pVe,fr,bx,b$r,Pc,v$r,tK,F$r,T$r,aK,M$r,E$r,C$r,vx,w$r,A8e,A$r,L$r,y$r,Gt,Fx,x$r,L8e,$$r,k$r,Bc,S$r,y8e,R$r,P$r,nK,B$r,I$r,N$r,zE,q$r,jr,Tx,j$r,x8e,D$r,G$r,un,O$r,$8e,V$r,X$r,k8e,z$r,Q$r,S8e,W$r,H$r,U$r,ce,QE,R8e,J$r,Y$r,sK,K$r,Z$r,ekr,WE,P8e,okr,rkr,lK,tkr,akr,nkr,HE,B8e,skr,lkr,iK,ikr,dkr,ckr,UE,I8e,fkr,mkr,dK,gkr,hkr,pkr,JE,N8e,_kr,ukr,cK,bkr,vkr,Fkr,YE,q8e,Tkr,Mkr,fK,Ekr,Ckr,wkr,KE,j8e,Akr,Lkr,mK,ykr,xkr,$kr,ZE,D8e,kkr,Skr,gK,Rkr,Pkr,Bkr,eC,G8e,Ikr,Nkr,hK,qkr,jkr,Dkr,oC,O8e,Gkr,Okr,pK,Vkr,Xkr,zkr,rC,V8e,Qkr,Wkr,_K,Hkr,Ukr,Jkr,tC,X8e,Ykr,Kkr,uK,Zkr,eSr,oSr,aC,z8e,rSr,tSr,bK,aSr,nSr,sSr,nC,Q8e,lSr,iSr,vK,dSr,cSr,fSr,sC,W8e,mSr,gSr,FK,hSr,pSr,_Sr,lC,H8e,uSr,bSr,TK,vSr,FSr,TSr,iC,U8e,MSr,ESr,MK,CSr,wSr,ASr,dC,J8e,LSr,ySr,EK,xSr,$Sr,kSr,cC,Y8e,SSr,RSr,CK,PSr,BSr,ISr,fC,K8e,NSr,qSr,wK,jSr,DSr,GSr,mC,_Ve,Ic,gC,Z8e,Mx,OSr,eMe,VSr,uVe,mr,Ex,XSr,Nc,zSr,AK,QSr,WSr,LK,HSr,USr,JSr,Cx,YSr,oMe,KSr,ZSr,eRr,Ot,wx,oRr,rMe,rRr,tRr,qc,aRr,tMe,nRr,sRr,yK,lRr,iRr,dRr,hC,cRr,Dr,Ax,fRr,aMe,mRr,gRr,bn,hRr,nMe,pRr,_Rr,sMe,uRr,bRr,lMe,vRr,FRr,TRr,iMe,pC,dMe,MRr,ERr,xK,CRr,wRr,ARr,_C,bVe,jc,uC,cMe,Lx,LRr,fMe,yRr,vVe,gr,yx,xRr,Dc,$Rr,$K,kRr,SRr,kK,RRr,PRr,BRr,xx,IRr,mMe,NRr,qRr,jRr,Vt,$x,DRr,gMe,GRr,ORr,Gc,VRr,hMe,XRr,zRr,SK,QRr,WRr,HRr,bC,URr,Gr,kx,JRr,pMe,YRr,KRr,vn,ZRr,_Me,ePr,oPr,uMe,rPr,tPr,bMe,aPr,nPr,sPr,vMe,vC,FMe,lPr,iPr,RK,dPr,cPr,fPr,FC,FVe,Oc,TC,TMe,Sx,mPr,MMe,gPr,TVe,hr,Rx,hPr,Vc,pPr,PK,_Pr,uPr,BK,bPr,vPr,FPr,Px,TPr,EMe,MPr,EPr,CPr,Xt,Bx,wPr,CMe,APr,LPr,Xc,yPr,wMe,xPr,$Pr,IK,kPr,SPr,RPr,MC,PPr,Or,Ix,BPr,AMe,IPr,NPr,Fn,qPr,LMe,jPr,DPr,yMe,GPr,OPr,xMe,VPr,XPr,zPr,oe,EC,$Me,QPr,WPr,NK,HPr,UPr,JPr,CC,kMe,YPr,KPr,qK,ZPr,eBr,oBr,wC,SMe,rBr,tBr,jK,aBr,nBr,sBr,AC,RMe,lBr,iBr,DK,dBr,cBr,fBr,LC,PMe,mBr,gBr,GK,hBr,pBr,_Br,yC,BMe,uBr,bBr,OK,vBr,FBr,TBr,xC,IMe,MBr,EBr,VK,CBr,wBr,ABr,$C,NMe,LBr,yBr,XK,xBr,$Br,kBr,kC,qMe,SBr,RBr,zK,PBr,BBr,IBr,SC,jMe,NBr,qBr,QK,jBr,DBr,GBr,RC,DMe,OBr,VBr,WK,XBr,zBr,QBr,PC,GMe,WBr,HBr,HK,UBr,JBr,YBr,BC,OMe,KBr,ZBr,UK,eIr,oIr,rIr,IC,VMe,tIr,aIr,JK,nIr,sIr,lIr,NC,XMe,iIr,dIr,YK,cIr,fIr,mIr,qC,zMe,gIr,hIr,KK,pIr,_Ir,uIr,jC,QMe,bIr,vIr,ZK,FIr,TIr,MIr,DC,WMe,EIr,CIr,eZ,wIr,AIr,LIr,GC,HMe,yIr,xIr,oZ,$Ir,kIr,SIr,OC,UMe,RIr,PIr,rZ,BIr,IIr,NIr,VC,JMe,qIr,jIr,tZ,DIr,GIr,OIr,XC,YMe,VIr,XIr,aZ,zIr,QIr,WIr,zC,KMe,HIr,UIr,nZ,JIr,YIr,KIr,QC,ZMe,ZIr,eNr,sZ,oNr,rNr,tNr,WC,eEe,aNr,nNr,lZ,sNr,lNr,iNr,HC,oEe,dNr,cNr,iZ,fNr,mNr,gNr,UC,rEe,hNr,pNr,dZ,_Nr,uNr,bNr,JC,MVe,zc,YC,tEe,Nx,vNr,aEe,FNr,EVe,pr,qx,TNr,Qc,MNr,cZ,ENr,CNr,fZ,wNr,ANr,LNr,jx,yNr,nEe,xNr,$Nr,kNr,zt,Dx,SNr,sEe,RNr,PNr,Wc,BNr,lEe,INr,NNr,mZ,qNr,jNr,DNr,KC,GNr,Vr,Gx,ONr,iEe,VNr,XNr,Tn,zNr,dEe,QNr,WNr,cEe,HNr,UNr,fEe,JNr,YNr,KNr,xe,ZC,mEe,ZNr,eqr,gZ,oqr,rqr,tqr,e5,gEe,aqr,nqr,hZ,sqr,lqr,iqr,o5,hEe,dqr,cqr,pZ,fqr,mqr,gqr,r5,pEe,hqr,pqr,_Z,_qr,uqr,bqr,t5,_Ee,vqr,Fqr,uZ,Tqr,Mqr,Eqr,a5,uEe,Cqr,wqr,bZ,Aqr,Lqr,yqr,n5,bEe,xqr,$qr,vZ,kqr,Sqr,Rqr,s5,vEe,Pqr,Bqr,FZ,Iqr,Nqr,qqr,l5,FEe,jqr,Dqr,TZ,Gqr,Oqr,Vqr,i5,TEe,Xqr,zqr,MZ,Qqr,Wqr,Hqr,d5,CVe,Hc,c5,MEe,Ox,Uqr,EEe,Jqr,wVe,_r,Vx,Yqr,Uc,Kqr,EZ,Zqr,ejr,CZ,ojr,rjr,tjr,Xx,ajr,CEe,njr,sjr,ljr,Qt,zx,ijr,wEe,djr,cjr,Jc,fjr,AEe,mjr,gjr,wZ,hjr,pjr,_jr,f5,ujr,Xr,Qx,bjr,LEe,vjr,Fjr,Mn,Tjr,yEe,Mjr,Ejr,xEe,Cjr,wjr,$Ee,Ajr,Ljr,yjr,Ee,m5,kEe,xjr,$jr,AZ,kjr,Sjr,Rjr,g5,SEe,Pjr,Bjr,LZ,Ijr,Njr,qjr,h5,REe,jjr,Djr,yZ,Gjr,Ojr,Vjr,p5,PEe,Xjr,zjr,xZ,Qjr,Wjr,Hjr,_5,BEe,Ujr,Jjr,$Z,Yjr,Kjr,Zjr,u5,IEe,eDr,oDr,kZ,rDr,tDr,aDr,b5,NEe,nDr,sDr,SZ,lDr,iDr,dDr,v5,qEe,cDr,fDr,RZ,mDr,gDr,hDr,F5,jEe,pDr,_Dr,PZ,uDr,bDr,vDr,T5,DEe,FDr,TDr,BZ,MDr,EDr,CDr,M5,GEe,wDr,ADr,IZ,LDr,yDr,xDr,E5,OEe,$Dr,kDr,NZ,SDr,RDr,PDr,C5,VEe,BDr,IDr,qZ,NDr,qDr,jDr,w5,AVe,Yc,A5,XEe,Wx,DDr,zEe,GDr,LVe,ur,Hx,ODr,Kc,VDr,jZ,XDr,zDr,DZ,QDr,WDr,HDr,Ux,UDr,QEe,JDr,YDr,KDr,Wt,Jx,ZDr,WEe,eGr,oGr,Zc,rGr,HEe,tGr,aGr,GZ,nGr,sGr,lGr,L5,iGr,zr,Yx,dGr,UEe,cGr,fGr,En,mGr,JEe,gGr,hGr,YEe,pGr,_Gr,KEe,uGr,bGr,vGr,$e,y5,ZEe,FGr,TGr,OZ,MGr,EGr,CGr,x5,eCe,wGr,AGr,VZ,LGr,yGr,xGr,$5,oCe,$Gr,kGr,XZ,SGr,RGr,PGr,k5,rCe,BGr,IGr,zZ,NGr,qGr,jGr,S5,tCe,DGr,GGr,QZ,OGr,VGr,XGr,R5,aCe,zGr,QGr,WZ,WGr,HGr,UGr,P5,nCe,JGr,YGr,HZ,KGr,ZGr,eOr,B5,sCe,oOr,rOr,UZ,tOr,aOr,nOr,I5,lCe,sOr,lOr,JZ,iOr,dOr,cOr,N5,iCe,fOr,mOr,YZ,gOr,hOr,pOr,q5,yVe,ef,j5,dCe,Kx,_Or,cCe,uOr,xVe,br,Zx,bOr,of,vOr,KZ,FOr,TOr,ZZ,MOr,EOr,COr,e$,wOr,fCe,AOr,LOr,yOr,Ht,o$,xOr,mCe,$Or,kOr,rf,SOr,gCe,ROr,POr,eee,BOr,IOr,NOr,D5,qOr,Qr,r$,jOr,hCe,DOr,GOr,Cn,OOr,pCe,VOr,XOr,_Ce,zOr,QOr,uCe,WOr,HOr,UOr,ke,G5,bCe,JOr,YOr,oee,KOr,ZOr,eVr,O5,vCe,oVr,rVr,ree,tVr,aVr,nVr,V5,FCe,sVr,lVr,tee,iVr,dVr,cVr,X5,TCe,fVr,mVr,aee,gVr,hVr,pVr,z5,MCe,_Vr,uVr,nee,bVr,vVr,FVr,Q5,ECe,TVr,MVr,see,EVr,CVr,wVr,W5,CCe,AVr,LVr,lee,yVr,xVr,$Vr,H5,wCe,kVr,SVr,iee,RVr,PVr,BVr,U5,ACe,IVr,NVr,dee,qVr,jVr,DVr,J5,LCe,GVr,OVr,cee,VVr,XVr,zVr,Y5,$Ve,tf,K5,yCe,t$,QVr,xCe,WVr,kVe,vr,a$,HVr,af,UVr,fee,JVr,YVr,mee,KVr,ZVr,eXr,n$,oXr,$Ce,rXr,tXr,aXr,Ut,s$,nXr,kCe,sXr,lXr,nf,iXr,SCe,dXr,cXr,gee,fXr,mXr,gXr,Z5,hXr,Wr,l$,pXr,RCe,_Xr,uXr,wn,bXr,PCe,vXr,FXr,BCe,TXr,MXr,ICe,EXr,CXr,wXr,Se,e3,NCe,AXr,LXr,hee,yXr,xXr,$Xr,o3,qCe,kXr,SXr,pee,RXr,PXr,BXr,r3,jCe,IXr,NXr,_ee,qXr,jXr,DXr,t3,DCe,GXr,OXr,uee,VXr,XXr,zXr,a3,GCe,QXr,WXr,bee,HXr,UXr,JXr,n3,OCe,YXr,KXr,vee,ZXr,ezr,ozr,s3,VCe,rzr,tzr,Fee,azr,nzr,szr,l3,XCe,lzr,izr,Tee,dzr,czr,fzr,i3,zCe,mzr,gzr,Mee,hzr,pzr,_zr,d3,QCe,uzr,bzr,Eee,vzr,Fzr,Tzr,c3,SVe,sf,f3,WCe,i$,Mzr,HCe,Ezr,RVe,Fr,d$,Czr,lf,wzr,Cee,Azr,Lzr,wee,yzr,xzr,$zr,c$,kzr,UCe,Szr,Rzr,Pzr,Jt,f$,Bzr,JCe,Izr,Nzr,df,qzr,YCe,jzr,Dzr,Aee,Gzr,Ozr,Vzr,m3,Xzr,Hr,m$,zzr,KCe,Qzr,Wzr,An,Hzr,ZCe,Uzr,Jzr,e5e,Yzr,Kzr,o5e,Zzr,eQr,oQr,Re,g3,r5e,rQr,tQr,Lee,aQr,nQr,sQr,h3,t5e,lQr,iQr,yee,dQr,cQr,fQr,p3,a5e,mQr,gQr,xee,hQr,pQr,_Qr,_3,n5e,uQr,bQr,$ee,vQr,FQr,TQr,u3,s5e,MQr,EQr,kee,CQr,wQr,AQr,b3,l5e,LQr,yQr,See,xQr,$Qr,kQr,v3,i5e,SQr,RQr,Ree,PQr,BQr,IQr,F3,d5e,NQr,qQr,Pee,jQr,DQr,GQr,T3,c5e,OQr,VQr,Bee,XQr,zQr,QQr,M3,f5e,WQr,HQr,Iee,UQr,JQr,YQr,E3,PVe,cf,C3,m5e,g$,KQr,g5e,ZQr,BVe,Tr,h$,eWr,ff,oWr,Nee,rWr,tWr,qee,aWr,nWr,sWr,p$,lWr,h5e,iWr,dWr,cWr,Yt,_$,fWr,p5e,mWr,gWr,mf,hWr,_5e,pWr,_Wr,jee,uWr,bWr,vWr,w3,FWr,Ur,u$,TWr,u5e,MWr,EWr,Ln,CWr,b5e,wWr,AWr,v5e,LWr,yWr,F5e,xWr,$Wr,kWr,Ve,A3,T5e,SWr,RWr,Dee,PWr,BWr,IWr,L3,M5e,NWr,qWr,Gee,jWr,DWr,GWr,y3,E5e,OWr,VWr,Oee,XWr,zWr,QWr,x3,C5e,WWr,HWr,Vee,UWr,JWr,YWr,$3,w5e,KWr,ZWr,Xee,eHr,oHr,rHr,k3,A5e,tHr,aHr,zee,nHr,sHr,lHr,S3,L5e,iHr,dHr,Qee,cHr,fHr,mHr,R3,y5e,gHr,hHr,Wee,pHr,_Hr,uHr,P3,IVe,gf,B3,x5e,b$,bHr,$5e,vHr,NVe,Mr,v$,FHr,hf,THr,Hee,MHr,EHr,Uee,CHr,wHr,AHr,F$,LHr,k5e,yHr,xHr,$Hr,Kt,T$,kHr,S5e,SHr,RHr,pf,PHr,R5e,BHr,IHr,Jee,NHr,qHr,jHr,I3,DHr,Jr,M$,GHr,P5e,OHr,VHr,yn,XHr,B5e,zHr,QHr,I5e,WHr,HHr,N5e,UHr,JHr,YHr,Xe,N3,q5e,KHr,ZHr,Yee,eUr,oUr,rUr,q3,j5e,tUr,aUr,Kee,nUr,sUr,lUr,j3,D5e,iUr,dUr,Zee,cUr,fUr,mUr,D3,G5e,gUr,hUr,eoe,pUr,_Ur,uUr,G3,O5e,bUr,vUr,ooe,FUr,TUr,MUr,O3,V5e,EUr,CUr,roe,wUr,AUr,LUr,V3,X5e,yUr,xUr,toe,$Ur,kUr,SUr,X3,z5e,RUr,PUr,aoe,BUr,IUr,NUr,z3,qVe,_f,Q3,Q5e,E$,qUr,W5e,jUr,jVe,Er,C$,DUr,uf,GUr,noe,OUr,VUr,soe,XUr,zUr,QUr,w$,WUr,H5e,HUr,UUr,JUr,Zt,A$,YUr,U5e,KUr,ZUr,bf,eJr,J5e,oJr,rJr,loe,tJr,aJr,nJr,W3,sJr,Yr,L$,lJr,Y5e,iJr,dJr,xn,cJr,K5e,fJr,mJr,Z5e,gJr,hJr,e3e,pJr,_Jr,uJr,o3e,H3,r3e,bJr,vJr,ioe,FJr,TJr,MJr,U3,DVe,vf,J3,t3e,y$,EJr,a3e,CJr,GVe,Cr,x$,wJr,Ff,AJr,doe,LJr,yJr,coe,xJr,$Jr,kJr,$$,SJr,n3e,RJr,PJr,BJr,ea,k$,IJr,s3e,NJr,qJr,Tf,jJr,l3e,DJr,GJr,foe,OJr,VJr,XJr,Y3,zJr,Kr,S$,QJr,i3e,WJr,HJr,$n,UJr,d3e,JJr,YJr,c3e,KJr,ZJr,f3e,eYr,oYr,rYr,R$,K3,m3e,tYr,aYr,moe,nYr,sYr,lYr,Z3,g3e,iYr,dYr,goe,cYr,fYr,mYr,e0,OVe,Mf,o0,h3e,P$,gYr,p3e,hYr,VVe,wr,B$,pYr,Ef,_Yr,hoe,uYr,bYr,poe,vYr,FYr,TYr,I$,MYr,_3e,EYr,CYr,wYr,oa,N$,AYr,u3e,LYr,yYr,Cf,xYr,b3e,$Yr,kYr,_oe,SYr,RYr,PYr,r0,BYr,Zr,q$,IYr,v3e,NYr,qYr,kn,jYr,F3e,DYr,GYr,T3e,OYr,VYr,M3e,XYr,zYr,QYr,E3e,t0,C3e,WYr,HYr,uoe,UYr,JYr,YYr,a0,XVe;return d=new re({}),xa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),xA=new re({}),$A=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Rf=new KYr({props:{warning:!0,$$slots:{default:[CDt]},$$scope:{ctx:x}}}),kA=new re({}),SA=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/configuration_auto.py#L598"}}),BA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/configuration_auto.py#L621"}}),Gg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[wDt]},$$scope:{ctx:x}}}),IA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/configuration_auto.py#L744"}}),NA=new re({}),qA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/tokenization_auto.py#L400"}}),GA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17864/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/tokenization_auto.py#L414"}}),Eh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[ADt]},$$scope:{ctx:x}}}),OA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/tokenization_auto.py#L613"}}),VA=new re({}),XA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/feature_extraction_auto.py#L193"}}),WA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17864/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/feature_extraction_auto.py#L207"}}),ap=new KYr({props:{$$slots:{default:[LDt]},$$scope:{ctx:x}}}),np=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[yDt]},$$scope:{ctx:x}}}),HA=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/feature_extraction_auto.py#L334"}}),UA=new re({}),JA=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/processing_auto.py#L88"}}),ZA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/processing_auto.py#L102"}}),wp=new KYr({props:{$$slots:{default:[xDt]},$$scope:{ctx:x}}}),Ap=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[$Dt]},$$scope:{ctx:x}}}),eL=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/processing_auto.py#L255"}}),oL=new re({}),rL=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L767"}}),aL=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),xp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[kDt]},$$scope:{ctx:x}}}),nL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),xu=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[SDt]},$$scope:{ctx:x}}}),sL=new re({}),lL=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L774"}}),dL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),ku=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[RDt]},$$scope:{ctx:x}}}),cL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),E1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[PDt]},$$scope:{ctx:x}}}),fL=new re({}),mL=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L789"}}),hL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),w1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[BDt]},$$scope:{ctx:x}}}),pL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),f2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[IDt]},$$scope:{ctx:x}}}),_L=new re({}),uL=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L796"}}),vL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),g2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[NDt]},$$scope:{ctx:x}}}),FL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),K2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[qDt]},$$scope:{ctx:x}}}),TL=new re({}),ML=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L803"}}),CL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),eb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[jDt]},$$scope:{ctx:x}}}),wL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),vb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[DDt]},$$scope:{ctx:x}}}),AL=new re({}),LL=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L812"}}),xL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),Tb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[GDt]},$$scope:{ctx:x}}}),$L=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),b4=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[ODt]},$$scope:{ctx:x}}}),kL=new re({}),SL=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L857"}}),PL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),F4=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[VDt]},$$scope:{ctx:x}}}),BL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),K4=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[XDt]},$$scope:{ctx:x}}}),IL=new re({}),NL=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L864"}}),jL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),ev=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[zDt]},$$scope:{ctx:x}}}),DL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),iv=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[QDt]},$$scope:{ctx:x}}}),GL=new re({}),OL=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L850"}}),XL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),cv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[WDt]},$$scope:{ctx:x}}}),zL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),Hv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[HDt]},$$scope:{ctx:x}}}),QL=new re({}),WL=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L821"}}),UL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),Jv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[UDt]},$$scope:{ctx:x}}}),JL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),jF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[JDt]},$$scope:{ctx:x}}}),YL=new re({}),KL=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L828"}}),ey=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),GF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[YDt]},$$scope:{ctx:x}}}),oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),XF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[KDt]},$$scope:{ctx:x}}}),ry=new re({}),ty=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L873"}}),ny=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),QF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[ZDt]},$$scope:{ctx:x}}}),sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),s6=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[eGt]},$$scope:{ctx:x}}}),ly=new re({}),iy=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L912"}}),cy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),i6=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[oGt]},$$scope:{ctx:x}}}),fy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),f6=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[rGt]},$$scope:{ctx:x}}}),my=new re({}),gy=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L839"}}),py=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),g6=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[tGt]},$$scope:{ctx:x}}}),_y=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),_6=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[aGt]},$$scope:{ctx:x}}}),uy=new re({}),by=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L919"}}),Fy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),b6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[nGt]},$$scope:{ctx:x}}}),Ty=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),x6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[sGt]},$$scope:{ctx:x}}}),My=new re({}),Ey=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L942"}}),wy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),k6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[lGt]},$$scope:{ctx:x}}}),Ay=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),q6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[iGt]},$$scope:{ctx:x}}}),Ly=new re({}),yy=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L926"}}),$y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),D6=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[dGt]},$$scope:{ctx:x}}}),ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),K6=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[cGt]},$$scope:{ctx:x}}}),Sy=new re({}),Ry=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L933"}}),By=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),eT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[fGt]},$$scope:{ctx:x}}}),Iy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),aT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[mGt]},$$scope:{ctx:x}}}),qy=new re({}),jy=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L951"}}),Gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),sT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[gGt]},$$scope:{ctx:x}}}),Oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),gT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[hGt]},$$scope:{ctx:x}}}),Vy=new re({}),Xy=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L958"}}),Qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),pT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[pGt]},$$scope:{ctx:x}}}),Wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),FT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[_Gt]},$$scope:{ctx:x}}}),Hy=new re({}),Uy=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L905"}}),Yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),MT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[uGt]},$$scope:{ctx:x}}}),Ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),AT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[bGt]},$$scope:{ctx:x}}}),e9=new re({}),o9=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L880"}}),t9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),yT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[vGt]},$$scope:{ctx:x}}}),a9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),kT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[FGt]},$$scope:{ctx:x}}}),n9=new re({}),s9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L887"}}),i9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),RT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[TGt]},$$scope:{ctx:x}}}),d9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),jT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[MGt]},$$scope:{ctx:x}}}),c9=new re({}),f9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_auto.py#L896"}}),g9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),GT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[EGt]},$$scope:{ctx:x}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),XT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[CGt]},$$scope:{ctx:x}}}),p9=new re({}),_9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L406"}}),b9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),QT=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[wGt]},$$scope:{ctx:x}}}),v9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),j7=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[AGt]},$$scope:{ctx:x}}}),F9=new re({}),T9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L413"}}),E9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),G7=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[LGt]},$$scope:{ctx:x}}}),C9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),f8=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[yGt]},$$scope:{ctx:x}}}),w9=new re({}),A9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),g8=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[xGt]},$$scope:{ctx:x}}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),L8=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[$Gt]},$$scope:{ctx:x}}}),$9=new re({}),k9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),R9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),x8=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[kGt]},$$scope:{ctx:x}}}),P9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),P8=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[SGt]},$$scope:{ctx:x}}}),B9=new re({}),I9=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),q9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),I8=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[RGt]},$$scope:{ctx:x}}}),j9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),tM=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[PGt]},$$scope:{ctx:x}}}),D9=new re({}),G9=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),V9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),nM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[BGt]},$$scope:{ctx:x}}}),X9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),_M=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[IGt]},$$scope:{ctx:x}}}),z9=new re({}),Q9=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),H9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),bM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[NGt]},$$scope:{ctx:x}}}),U9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),zM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[qGt]},$$scope:{ctx:x}}}),J9=new re({}),Y9=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),Z9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),WM=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[jGt]},$$scope:{ctx:x}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),fE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[DGt]},$$scope:{ctx:x}}}),ox=new re({}),rx=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),ax=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),gE=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[GGt]},$$scope:{ctx:x}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),_E=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[OGt]},$$scope:{ctx:x}}}),lx=new re({}),ix=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),cx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),bE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[VGt]},$$scope:{ctx:x}}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),FE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[XGt]},$$scope:{ctx:x}}}),mx=new re({}),gx=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),px=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),ME=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[zGt]},$$scope:{ctx:x}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),VE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[QGt]},$$scope:{ctx:x}}}),ux=new re({}),bx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L494"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),zE=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[WGt]},$$scope:{ctx:x}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),mC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[HGt]},$$scope:{ctx:x}}}),Mx=new re({}),Ex=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),hC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[UGt]},$$scope:{ctx:x}}}),Ax=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),_C=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[JGt]},$$scope:{ctx:x}}}),Lx=new re({}),yx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_tf_auto.py#L537"}}),$x=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),bC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[YGt]},$$scope:{ctx:x}}}),kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),FC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[KGt]},$$scope:{ctx:x}}}),Sx=new re({}),Rx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),Bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),MC=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[ZGt]},$$scope:{ctx:x}}}),Ix=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),JC=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[eOt]},$$scope:{ctx:x}}}),Nx=new re({}),qx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Dx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),KC=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[oOt]},$$scope:{ctx:x}}}),Gx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),d5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[rOt]},$$scope:{ctx:x}}}),Ox=new re({}),Vx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),f5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[tOt]},$$scope:{ctx:x}}}),Qx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),w5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[aOt]},$$scope:{ctx:x}}}),Wx=new re({}),Hx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),Jx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),L5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[nOt]},$$scope:{ctx:x}}}),Yx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),q5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[sOt]},$$scope:{ctx:x}}}),Kx=new re({}),Zx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),o$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),D5=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[lOt]},$$scope:{ctx:x}}}),r$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),Y5=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[iOt]},$$scope:{ctx:x}}}),t$=new re({}),a$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),s$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),Z5=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[dOt]},$$scope:{ctx:x}}}),l$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),c3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[cOt]},$$scope:{ctx:x}}}),i$=new re({}),d$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),f$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),m3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[fOt]},$$scope:{ctx:x}}}),m$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),E3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[mOt]},$$scope:{ctx:x}}}),g$=new re({}),h$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),_$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),w3=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[gOt]},$$scope:{ctx:x}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),P3=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[hOt]},$$scope:{ctx:x}}}),b$=new re({}),v$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),T$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),I3=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[pOt]},$$scope:{ctx:x}}}),M$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),z3=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[_Ot]},$$scope:{ctx:x}}}),E$=new re({}),C$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),A$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),W3=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[uOt]},$$scope:{ctx:x}}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),U3=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[bOt]},$$scope:{ctx:x}}}),y$=new re({}),x$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),k$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),Y3=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[vOt]},$$scope:{ctx:x}}}),S$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),e0=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[FOt]},$$scope:{ctx:x}}}),P$=new re({}),B$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),N$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L389"}}),r0=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[TOt]},$$scope:{ctx:x}}}),q$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17864/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17864/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17864/src/transformers/models/auto/auto_factory.py#L417"}}),a0=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[MOt]},$$scope:{ctx:x}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Ti=o("Auto Classes"),yf=l(),at=a("p"),Mi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=a("code"),wA=o("from_pretrained()"),xf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),Ci=o("Instantiating one of "),Rn=a("a"),AA=o("AutoConfig"),Pn=o(", "),Bn=a("a"),LA=o("AutoModel"),wi=o(`, and
`),In=a("a"),yA=o("AutoTokenizer"),Ai=o(" will directly create a class of the relevant architecture. For instance"),$f=l(),F(xa.$$.fragment),We=l(),Ae=a("p"),rS=o("will create a model that is an instance of "),Li=a("a"),tS=o("BertModel"),aS=o("."),Co=l(),$a=a("p"),nS=o("There is one class of "),kf=a("code"),sS=o("AutoModel"),eQe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jGe=l(),yi=a("h2"),Sf=a("a"),mte=a("span"),F(xA.$$.fragment),oQe=l(),gte=a("span"),rQe=o("Extending the Auto Classes"),DGe=l(),Nn=a("p"),tQe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=a("code"),aQe=o("NewModel"),nQe=o(", make sure you have a "),pte=a("code"),sQe=o("NewModelConfig"),lQe=o(` then you can add those to the auto
classes like this:`),GGe=l(),F($A.$$.fragment),OGe=l(),lS=a("p"),iQe=o("You will then be able to use the auto classes like you would usually do!"),VGe=l(),F(Rf.$$.fragment),XGe=l(),xi=a("h2"),Pf=a("a"),_te=a("span"),F(kA.$$.fragment),dQe=l(),ute=a("span"),cQe=o("AutoConfig"),zGe=l(),wo=a("div"),F(SA.$$.fragment),fQe=l(),RA=a("p"),mQe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=a("a"),gQe=o("from_pretrained()"),hQe=o(" class method."),pQe=l(),PA=a("p"),_Qe=o("This class cannot be instantiated directly using "),bte=a("code"),uQe=o("__init__()"),bQe=o(" (throws an error)."),vQe=l(),Ar=a("div"),F(BA.$$.fragment),FQe=l(),vte=a("p"),TQe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),MQe=l(),$i=a("p"),EQe=o("The configuration class to instantiate is selected based on the "),Fte=a("code"),CQe=o("model_type"),wQe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=a("code"),AQe=o("pretrained_model_name_or_path"),LQe=o(":"),yQe=l(),A=a("ul"),Bf=a("li"),Mte=a("strong"),xQe=o("albert"),$Qe=o(" \u2014 "),dS=a("a"),kQe=o("AlbertConfig"),SQe=o(" (ALBERT model)"),RQe=l(),If=a("li"),Ete=a("strong"),PQe=o("bart"),BQe=o(" \u2014 "),cS=a("a"),IQe=o("BartConfig"),NQe=o(" (BART model)"),qQe=l(),Nf=a("li"),Cte=a("strong"),jQe=o("beit"),DQe=o(" \u2014 "),fS=a("a"),GQe=o("BeitConfig"),OQe=o(" (BEiT model)"),VQe=l(),qf=a("li"),wte=a("strong"),XQe=o("bert"),zQe=o(" \u2014 "),mS=a("a"),QQe=o("BertConfig"),WQe=o(" (BERT model)"),HQe=l(),jf=a("li"),Ate=a("strong"),UQe=o("bert-generation"),JQe=o(" \u2014 "),gS=a("a"),YQe=o("BertGenerationConfig"),KQe=o(" (Bert Generation model)"),ZQe=l(),Df=a("li"),Lte=a("strong"),eWe=o("big_bird"),oWe=o(" \u2014 "),hS=a("a"),rWe=o("BigBirdConfig"),tWe=o(" (BigBird model)"),aWe=l(),Gf=a("li"),yte=a("strong"),nWe=o("bigbird_pegasus"),sWe=o(" \u2014 "),pS=a("a"),lWe=o("BigBirdPegasusConfig"),iWe=o(" (BigBird-Pegasus model)"),dWe=l(),Of=a("li"),xte=a("strong"),cWe=o("blenderbot"),fWe=o(" \u2014 "),_S=a("a"),mWe=o("BlenderbotConfig"),gWe=o(" (Blenderbot model)"),hWe=l(),Vf=a("li"),$te=a("strong"),pWe=o("blenderbot-small"),_We=o(" \u2014 "),uS=a("a"),uWe=o("BlenderbotSmallConfig"),bWe=o(" (BlenderbotSmall model)"),vWe=l(),Xf=a("li"),kte=a("strong"),FWe=o("bloom"),TWe=o(" \u2014 "),bS=a("a"),MWe=o("BloomConfig"),EWe=o(" (BLOOM model)"),CWe=l(),zf=a("li"),Ste=a("strong"),wWe=o("camembert"),AWe=o(" \u2014 "),vS=a("a"),LWe=o("CamembertConfig"),yWe=o(" (CamemBERT model)"),xWe=l(),Qf=a("li"),Rte=a("strong"),$We=o("canine"),kWe=o(" \u2014 "),FS=a("a"),SWe=o("CanineConfig"),RWe=o(" (CANINE model)"),PWe=l(),Wf=a("li"),Pte=a("strong"),BWe=o("clip"),IWe=o(" \u2014 "),TS=a("a"),NWe=o("CLIPConfig"),qWe=o(" (CLIP model)"),jWe=l(),Hf=a("li"),Bte=a("strong"),DWe=o("convbert"),GWe=o(" \u2014 "),MS=a("a"),OWe=o("ConvBertConfig"),VWe=o(" (ConvBERT model)"),XWe=l(),Uf=a("li"),Ite=a("strong"),zWe=o("convnext"),QWe=o(" \u2014 "),ES=a("a"),WWe=o("ConvNextConfig"),HWe=o(" (ConvNeXT model)"),UWe=l(),Jf=a("li"),Nte=a("strong"),JWe=o("ctrl"),YWe=o(" \u2014 "),CS=a("a"),KWe=o("CTRLConfig"),ZWe=o(" (CTRL model)"),eHe=l(),Yf=a("li"),qte=a("strong"),oHe=o("cvt"),rHe=o(" \u2014 "),wS=a("a"),tHe=o("CvtConfig"),aHe=o(" (CvT model)"),nHe=l(),Kf=a("li"),jte=a("strong"),sHe=o("data2vec-audio"),lHe=o(" \u2014 "),AS=a("a"),iHe=o("Data2VecAudioConfig"),dHe=o(" (Data2VecAudio model)"),cHe=l(),Zf=a("li"),Dte=a("strong"),fHe=o("data2vec-text"),mHe=o(" \u2014 "),LS=a("a"),gHe=o("Data2VecTextConfig"),hHe=o(" (Data2VecText model)"),pHe=l(),em=a("li"),Gte=a("strong"),_He=o("data2vec-vision"),uHe=o(" \u2014 "),yS=a("a"),bHe=o("Data2VecVisionConfig"),vHe=o(" (Data2VecVision model)"),FHe=l(),om=a("li"),Ote=a("strong"),THe=o("deberta"),MHe=o(" \u2014 "),xS=a("a"),EHe=o("DebertaConfig"),CHe=o(" (DeBERTa model)"),wHe=l(),rm=a("li"),Vte=a("strong"),AHe=o("deberta-v2"),LHe=o(" \u2014 "),$S=a("a"),yHe=o("DebertaV2Config"),xHe=o(" (DeBERTa-v2 model)"),$He=l(),tm=a("li"),Xte=a("strong"),kHe=o("decision_transformer"),SHe=o(" \u2014 "),kS=a("a"),RHe=o("DecisionTransformerConfig"),PHe=o(" (Decision Transformer model)"),BHe=l(),am=a("li"),zte=a("strong"),IHe=o("deit"),NHe=o(" \u2014 "),SS=a("a"),qHe=o("DeiTConfig"),jHe=o(" (DeiT model)"),DHe=l(),nm=a("li"),Qte=a("strong"),GHe=o("detr"),OHe=o(" \u2014 "),RS=a("a"),VHe=o("DetrConfig"),XHe=o(" (DETR model)"),zHe=l(),sm=a("li"),Wte=a("strong"),QHe=o("distilbert"),WHe=o(" \u2014 "),PS=a("a"),HHe=o("DistilBertConfig"),UHe=o(" (DistilBERT model)"),JHe=l(),lm=a("li"),Hte=a("strong"),YHe=o("dpr"),KHe=o(" \u2014 "),BS=a("a"),ZHe=o("DPRConfig"),eUe=o(" (DPR model)"),oUe=l(),im=a("li"),Ute=a("strong"),rUe=o("dpt"),tUe=o(" \u2014 "),IS=a("a"),aUe=o("DPTConfig"),nUe=o(" (DPT model)"),sUe=l(),dm=a("li"),Jte=a("strong"),lUe=o("electra"),iUe=o(" \u2014 "),NS=a("a"),dUe=o("ElectraConfig"),cUe=o(" (ELECTRA model)"),fUe=l(),cm=a("li"),Yte=a("strong"),mUe=o("encoder-decoder"),gUe=o(" \u2014 "),qS=a("a"),hUe=o("EncoderDecoderConfig"),pUe=o(" (Encoder decoder model)"),_Ue=l(),fm=a("li"),Kte=a("strong"),uUe=o("flaubert"),bUe=o(" \u2014 "),jS=a("a"),vUe=o("FlaubertConfig"),FUe=o(" (FlauBERT model)"),TUe=l(),mm=a("li"),Zte=a("strong"),MUe=o("flava"),EUe=o(" \u2014 "),DS=a("a"),CUe=o("FlavaConfig"),wUe=o(" (FLAVA model)"),AUe=l(),gm=a("li"),eae=a("strong"),LUe=o("fnet"),yUe=o(" \u2014 "),GS=a("a"),xUe=o("FNetConfig"),$Ue=o(" (FNet model)"),kUe=l(),hm=a("li"),oae=a("strong"),SUe=o("fsmt"),RUe=o(" \u2014 "),OS=a("a"),PUe=o("FSMTConfig"),BUe=o(" (FairSeq Machine-Translation model)"),IUe=l(),pm=a("li"),rae=a("strong"),NUe=o("funnel"),qUe=o(" \u2014 "),VS=a("a"),jUe=o("FunnelConfig"),DUe=o(" (Funnel Transformer model)"),GUe=l(),_m=a("li"),tae=a("strong"),OUe=o("glpn"),VUe=o(" \u2014 "),XS=a("a"),XUe=o("GLPNConfig"),zUe=o(" (GLPN model)"),QUe=l(),um=a("li"),aae=a("strong"),WUe=o("gpt2"),HUe=o(" \u2014 "),zS=a("a"),UUe=o("GPT2Config"),JUe=o(" (OpenAI GPT-2 model)"),YUe=l(),bm=a("li"),nae=a("strong"),KUe=o("gpt_neo"),ZUe=o(" \u2014 "),QS=a("a"),eJe=o("GPTNeoConfig"),oJe=o(" (GPT Neo model)"),rJe=l(),vm=a("li"),sae=a("strong"),tJe=o("gpt_neox"),aJe=o(" \u2014 "),WS=a("a"),nJe=o("GPTNeoXConfig"),sJe=o(" (GPT NeoX model)"),lJe=l(),Fm=a("li"),lae=a("strong"),iJe=o("gptj"),dJe=o(" \u2014 "),HS=a("a"),cJe=o("GPTJConfig"),fJe=o(" (GPT-J model)"),mJe=l(),Tm=a("li"),iae=a("strong"),gJe=o("hubert"),hJe=o(" \u2014 "),US=a("a"),pJe=o("HubertConfig"),_Je=o(" (Hubert model)"),uJe=l(),Mm=a("li"),dae=a("strong"),bJe=o("ibert"),vJe=o(" \u2014 "),JS=a("a"),FJe=o("IBertConfig"),TJe=o(" (I-BERT model)"),MJe=l(),Em=a("li"),cae=a("strong"),EJe=o("imagegpt"),CJe=o(" \u2014 "),YS=a("a"),wJe=o("ImageGPTConfig"),AJe=o(" (ImageGPT model)"),LJe=l(),Cm=a("li"),fae=a("strong"),yJe=o("layoutlm"),xJe=o(" \u2014 "),KS=a("a"),$Je=o("LayoutLMConfig"),kJe=o(" (LayoutLM model)"),SJe=l(),wm=a("li"),mae=a("strong"),RJe=o("layoutlmv2"),PJe=o(" \u2014 "),ZS=a("a"),BJe=o("LayoutLMv2Config"),IJe=o(" (LayoutLMv2 model)"),NJe=l(),Am=a("li"),gae=a("strong"),qJe=o("layoutlmv3"),jJe=o(" \u2014 "),eR=a("a"),DJe=o("LayoutLMv3Config"),GJe=o(" (LayoutLMv3 model)"),OJe=l(),Lm=a("li"),hae=a("strong"),VJe=o("led"),XJe=o(" \u2014 "),oR=a("a"),zJe=o("LEDConfig"),QJe=o(" (LED model)"),WJe=l(),ym=a("li"),pae=a("strong"),HJe=o("levit"),UJe=o(" \u2014 "),rR=a("a"),JJe=o("LevitConfig"),YJe=o(" (LeViT model)"),KJe=l(),xm=a("li"),_ae=a("strong"),ZJe=o("longformer"),eYe=o(" \u2014 "),tR=a("a"),oYe=o("LongformerConfig"),rYe=o(" (Longformer model)"),tYe=l(),$m=a("li"),uae=a("strong"),aYe=o("longt5"),nYe=o(" \u2014 "),aR=a("a"),sYe=o("LongT5Config"),lYe=o(" (LongT5 model)"),iYe=l(),km=a("li"),bae=a("strong"),dYe=o("luke"),cYe=o(" \u2014 "),nR=a("a"),fYe=o("LukeConfig"),mYe=o(" (LUKE model)"),gYe=l(),Sm=a("li"),vae=a("strong"),hYe=o("lxmert"),pYe=o(" \u2014 "),sR=a("a"),_Ye=o("LxmertConfig"),uYe=o(" (LXMERT model)"),bYe=l(),Rm=a("li"),Fae=a("strong"),vYe=o("m2m_100"),FYe=o(" \u2014 "),lR=a("a"),TYe=o("M2M100Config"),MYe=o(" (M2M100 model)"),EYe=l(),Pm=a("li"),Tae=a("strong"),CYe=o("marian"),wYe=o(" \u2014 "),iR=a("a"),AYe=o("MarianConfig"),LYe=o(" (Marian model)"),yYe=l(),Bm=a("li"),Mae=a("strong"),xYe=o("maskformer"),$Ye=o(" \u2014 "),dR=a("a"),kYe=o("MaskFormerConfig"),SYe=o(" (MaskFormer model)"),RYe=l(),Im=a("li"),Eae=a("strong"),PYe=o("mbart"),BYe=o(" \u2014 "),cR=a("a"),IYe=o("MBartConfig"),NYe=o(" (mBART model)"),qYe=l(),Nm=a("li"),Cae=a("strong"),jYe=o("mctct"),DYe=o(" \u2014 "),fR=a("a"),GYe=o("MCTCTConfig"),OYe=o(" (M-CTC-T model)"),VYe=l(),qm=a("li"),wae=a("strong"),XYe=o("megatron-bert"),zYe=o(" \u2014 "),mR=a("a"),QYe=o("MegatronBertConfig"),WYe=o(" (Megatron-BERT model)"),HYe=l(),jm=a("li"),Aae=a("strong"),UYe=o("mobilebert"),JYe=o(" \u2014 "),gR=a("a"),YYe=o("MobileBertConfig"),KYe=o(" (MobileBERT model)"),ZYe=l(),Dm=a("li"),Lae=a("strong"),eKe=o("mpnet"),oKe=o(" \u2014 "),hR=a("a"),rKe=o("MPNetConfig"),tKe=o(" (MPNet model)"),aKe=l(),Gm=a("li"),yae=a("strong"),nKe=o("mt5"),sKe=o(" \u2014 "),pR=a("a"),lKe=o("MT5Config"),iKe=o(" (MT5 model)"),dKe=l(),Om=a("li"),xae=a("strong"),cKe=o("nezha"),fKe=o(" \u2014 "),_R=a("a"),mKe=o("NezhaConfig"),gKe=o(" (Nezha model)"),hKe=l(),Vm=a("li"),$ae=a("strong"),pKe=o("nystromformer"),_Ke=o(" \u2014 "),uR=a("a"),uKe=o("NystromformerConfig"),bKe=o(" (Nystr\xF6mformer model)"),vKe=l(),Xm=a("li"),kae=a("strong"),FKe=o("openai-gpt"),TKe=o(" \u2014 "),bR=a("a"),MKe=o("OpenAIGPTConfig"),EKe=o(" (OpenAI GPT model)"),CKe=l(),zm=a("li"),Sae=a("strong"),wKe=o("opt"),AKe=o(" \u2014 "),vR=a("a"),LKe=o("OPTConfig"),yKe=o(" (OPT model)"),xKe=l(),Qm=a("li"),Rae=a("strong"),$Ke=o("pegasus"),kKe=o(" \u2014 "),FR=a("a"),SKe=o("PegasusConfig"),RKe=o(" (Pegasus model)"),PKe=l(),Wm=a("li"),Pae=a("strong"),BKe=o("perceiver"),IKe=o(" \u2014 "),TR=a("a"),NKe=o("PerceiverConfig"),qKe=o(" (Perceiver model)"),jKe=l(),Hm=a("li"),Bae=a("strong"),DKe=o("plbart"),GKe=o(" \u2014 "),MR=a("a"),OKe=o("PLBartConfig"),VKe=o(" (PLBart model)"),XKe=l(),Um=a("li"),Iae=a("strong"),zKe=o("poolformer"),QKe=o(" \u2014 "),ER=a("a"),WKe=o("PoolFormerConfig"),HKe=o(" (PoolFormer model)"),UKe=l(),Jm=a("li"),Nae=a("strong"),JKe=o("prophetnet"),YKe=o(" \u2014 "),CR=a("a"),KKe=o("ProphetNetConfig"),ZKe=o(" (ProphetNet model)"),eZe=l(),Ym=a("li"),qae=a("strong"),oZe=o("qdqbert"),rZe=o(" \u2014 "),wR=a("a"),tZe=o("QDQBertConfig"),aZe=o(" (QDQBert model)"),nZe=l(),Km=a("li"),jae=a("strong"),sZe=o("rag"),lZe=o(" \u2014 "),AR=a("a"),iZe=o("RagConfig"),dZe=o(" (RAG model)"),cZe=l(),Zm=a("li"),Dae=a("strong"),fZe=o("realm"),mZe=o(" \u2014 "),LR=a("a"),gZe=o("RealmConfig"),hZe=o(" (REALM model)"),pZe=l(),eg=a("li"),Gae=a("strong"),_Ze=o("reformer"),uZe=o(" \u2014 "),yR=a("a"),bZe=o("ReformerConfig"),vZe=o(" (Reformer model)"),FZe=l(),og=a("li"),Oae=a("strong"),TZe=o("regnet"),MZe=o(" \u2014 "),xR=a("a"),EZe=o("RegNetConfig"),CZe=o(" (RegNet model)"),wZe=l(),rg=a("li"),Vae=a("strong"),AZe=o("rembert"),LZe=o(" \u2014 "),$R=a("a"),yZe=o("RemBertConfig"),xZe=o(" (RemBERT model)"),$Ze=l(),tg=a("li"),Xae=a("strong"),kZe=o("resnet"),SZe=o(" \u2014 "),kR=a("a"),RZe=o("ResNetConfig"),PZe=o(" (ResNet model)"),BZe=l(),ag=a("li"),zae=a("strong"),IZe=o("retribert"),NZe=o(" \u2014 "),SR=a("a"),qZe=o("RetriBertConfig"),jZe=o(" (RetriBERT model)"),DZe=l(),ng=a("li"),Qae=a("strong"),GZe=o("roberta"),OZe=o(" \u2014 "),RR=a("a"),VZe=o("RobertaConfig"),XZe=o(" (RoBERTa model)"),zZe=l(),sg=a("li"),Wae=a("strong"),QZe=o("roformer"),WZe=o(" \u2014 "),PR=a("a"),HZe=o("RoFormerConfig"),UZe=o(" (RoFormer model)"),JZe=l(),lg=a("li"),Hae=a("strong"),YZe=o("segformer"),KZe=o(" \u2014 "),BR=a("a"),ZZe=o("SegformerConfig"),eeo=o(" (SegFormer model)"),oeo=l(),ig=a("li"),Uae=a("strong"),reo=o("sew"),teo=o(" \u2014 "),IR=a("a"),aeo=o("SEWConfig"),neo=o(" (SEW model)"),seo=l(),dg=a("li"),Jae=a("strong"),leo=o("sew-d"),ieo=o(" \u2014 "),NR=a("a"),deo=o("SEWDConfig"),ceo=o(" (SEW-D model)"),feo=l(),cg=a("li"),Yae=a("strong"),meo=o("speech-encoder-decoder"),geo=o(" \u2014 "),qR=a("a"),heo=o("SpeechEncoderDecoderConfig"),peo=o(" (Speech Encoder decoder model)"),_eo=l(),fg=a("li"),Kae=a("strong"),ueo=o("speech_to_text"),beo=o(" \u2014 "),jR=a("a"),veo=o("Speech2TextConfig"),Feo=o(" (Speech2Text model)"),Teo=l(),mg=a("li"),Zae=a("strong"),Meo=o("speech_to_text_2"),Eeo=o(" \u2014 "),DR=a("a"),Ceo=o("Speech2Text2Config"),weo=o(" (Speech2Text2 model)"),Aeo=l(),gg=a("li"),ene=a("strong"),Leo=o("splinter"),yeo=o(" \u2014 "),GR=a("a"),xeo=o("SplinterConfig"),$eo=o(" (Splinter model)"),keo=l(),hg=a("li"),one=a("strong"),Seo=o("squeezebert"),Reo=o(" \u2014 "),OR=a("a"),Peo=o("SqueezeBertConfig"),Beo=o(" (SqueezeBERT model)"),Ieo=l(),pg=a("li"),rne=a("strong"),Neo=o("swin"),qeo=o(" \u2014 "),VR=a("a"),jeo=o("SwinConfig"),Deo=o(" (Swin Transformer model)"),Geo=l(),_g=a("li"),tne=a("strong"),Oeo=o("t5"),Veo=o(" \u2014 "),XR=a("a"),Xeo=o("T5Config"),zeo=o(" (T5 model)"),Qeo=l(),ug=a("li"),ane=a("strong"),Weo=o("tapas"),Heo=o(" \u2014 "),zR=a("a"),Ueo=o("TapasConfig"),Jeo=o(" (TAPAS model)"),Yeo=l(),bg=a("li"),nne=a("strong"),Keo=o("trajectory_transformer"),Zeo=o(" \u2014 "),QR=a("a"),eoo=o("TrajectoryTransformerConfig"),ooo=o(" (Trajectory Transformer model)"),roo=l(),vg=a("li"),sne=a("strong"),too=o("transfo-xl"),aoo=o(" \u2014 "),WR=a("a"),noo=o("TransfoXLConfig"),soo=o(" (Transformer-XL model)"),loo=l(),Fg=a("li"),lne=a("strong"),ioo=o("trocr"),doo=o(" \u2014 "),HR=a("a"),coo=o("TrOCRConfig"),foo=o(" (TrOCR model)"),moo=l(),Tg=a("li"),ine=a("strong"),goo=o("unispeech"),hoo=o(" \u2014 "),UR=a("a"),poo=o("UniSpeechConfig"),_oo=o(" (UniSpeech model)"),uoo=l(),Mg=a("li"),dne=a("strong"),boo=o("unispeech-sat"),voo=o(" \u2014 "),JR=a("a"),Foo=o("UniSpeechSatConfig"),Too=o(" (UniSpeechSat model)"),Moo=l(),Eg=a("li"),cne=a("strong"),Eoo=o("van"),Coo=o(" \u2014 "),YR=a("a"),woo=o("VanConfig"),Aoo=o(" (VAN model)"),Loo=l(),Cg=a("li"),fne=a("strong"),yoo=o("vilt"),xoo=o(" \u2014 "),KR=a("a"),$oo=o("ViltConfig"),koo=o(" (ViLT model)"),Soo=l(),wg=a("li"),mne=a("strong"),Roo=o("vision-encoder-decoder"),Poo=o(" \u2014 "),ZR=a("a"),Boo=o("VisionEncoderDecoderConfig"),Ioo=o(" (Vision Encoder decoder model)"),Noo=l(),Ag=a("li"),gne=a("strong"),qoo=o("vision-text-dual-encoder"),joo=o(" \u2014 "),eP=a("a"),Doo=o("VisionTextDualEncoderConfig"),Goo=o(" (VisionTextDualEncoder model)"),Ooo=l(),Lg=a("li"),hne=a("strong"),Voo=o("visual_bert"),Xoo=o(" \u2014 "),oP=a("a"),zoo=o("VisualBertConfig"),Qoo=o(" (VisualBERT model)"),Woo=l(),yg=a("li"),pne=a("strong"),Hoo=o("vit"),Uoo=o(" \u2014 "),rP=a("a"),Joo=o("ViTConfig"),Yoo=o(" (ViT model)"),Koo=l(),xg=a("li"),_ne=a("strong"),Zoo=o("vit_mae"),ero=o(" \u2014 "),tP=a("a"),oro=o("ViTMAEConfig"),rro=o(" (ViTMAE model)"),tro=l(),$g=a("li"),une=a("strong"),aro=o("wav2vec2"),nro=o(" \u2014 "),aP=a("a"),sro=o("Wav2Vec2Config"),lro=o(" (Wav2Vec2 model)"),iro=l(),kg=a("li"),bne=a("strong"),dro=o("wav2vec2-conformer"),cro=o(" \u2014 "),nP=a("a"),fro=o("Wav2Vec2ConformerConfig"),mro=o(" (Wav2Vec2-Conformer model)"),gro=l(),Sg=a("li"),vne=a("strong"),hro=o("wavlm"),pro=o(" \u2014 "),sP=a("a"),_ro=o("WavLMConfig"),uro=o(" (WavLM model)"),bro=l(),Rg=a("li"),Fne=a("strong"),vro=o("xglm"),Fro=o(" \u2014 "),lP=a("a"),Tro=o("XGLMConfig"),Mro=o(" (XGLM model)"),Ero=l(),Pg=a("li"),Tne=a("strong"),Cro=o("xlm"),wro=o(" \u2014 "),iP=a("a"),Aro=o("XLMConfig"),Lro=o(" (XLM model)"),yro=l(),Bg=a("li"),Mne=a("strong"),xro=o("xlm-prophetnet"),$ro=o(" \u2014 "),dP=a("a"),kro=o("XLMProphetNetConfig"),Sro=o(" (XLM-ProphetNet model)"),Rro=l(),Ig=a("li"),Ene=a("strong"),Pro=o("xlm-roberta"),Bro=o(" \u2014 "),cP=a("a"),Iro=o("XLMRobertaConfig"),Nro=o(" (XLM-RoBERTa model)"),qro=l(),Ng=a("li"),Cne=a("strong"),jro=o("xlm-roberta-xl"),Dro=o(" \u2014 "),fP=a("a"),Gro=o("XLMRobertaXLConfig"),Oro=o(" (XLM-RoBERTa-XL model)"),Vro=l(),qg=a("li"),wne=a("strong"),Xro=o("xlnet"),zro=o(" \u2014 "),mP=a("a"),Qro=o("XLNetConfig"),Wro=o(" (XLNet model)"),Hro=l(),jg=a("li"),Ane=a("strong"),Uro=o("yolos"),Jro=o(" \u2014 "),gP=a("a"),Yro=o("YolosConfig"),Kro=o(" (YOLOS model)"),Zro=l(),Dg=a("li"),Lne=a("strong"),eto=o("yoso"),oto=o(" \u2014 "),hP=a("a"),rto=o("YosoConfig"),tto=o(" (YOSO model)"),ato=l(),F(Gg.$$.fragment),nto=l(),Og=a("div"),F(IA.$$.fragment),sto=l(),yne=a("p"),lto=o("Register a new configuration for this class."),QGe=l(),ki=a("h2"),Vg=a("a"),xne=a("span"),F(NA.$$.fragment),ito=l(),$ne=a("span"),dto=o("AutoTokenizer"),WGe=l(),Ao=a("div"),F(qA.$$.fragment),cto=l(),jA=a("p"),fto=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),pP=a("a"),mto=o("AutoTokenizer.from_pretrained()"),gto=o(" class method."),hto=l(),DA=a("p"),pto=o("This class cannot be instantiated directly using "),kne=a("code"),_to=o("__init__()"),uto=o(" (throws an error)."),bto=l(),Lr=a("div"),F(GA.$$.fragment),vto=l(),Sne=a("p"),Fto=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Tto=l(),ka=a("p"),Mto=o("The tokenizer class to instantiate is selected based on the "),Rne=a("code"),Eto=o("model_type"),Cto=o(` property of the config object (either
passed as an argument or loaded from `),Pne=a("code"),wto=o("pretrained_model_name_or_path"),Ato=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=a("code"),Lto=o("pretrained_model_name_or_path"),yto=o(":"),xto=l(),k=a("ul"),qn=a("li"),Ine=a("strong"),$to=o("albert"),kto=o(" \u2014 "),_P=a("a"),Sto=o("AlbertTokenizer"),Rto=o(" or "),uP=a("a"),Pto=o("AlbertTokenizerFast"),Bto=o(" (ALBERT model)"),Ito=l(),jn=a("li"),Nne=a("strong"),Nto=o("bart"),qto=o(" \u2014 "),bP=a("a"),jto=o("BartTokenizer"),Dto=o(" or "),vP=a("a"),Gto=o("BartTokenizerFast"),Oto=o(" (BART model)"),Vto=l(),Dn=a("li"),qne=a("strong"),Xto=o("barthez"),zto=o(" \u2014 "),FP=a("a"),Qto=o("BarthezTokenizer"),Wto=o(" or "),TP=a("a"),Hto=o("BarthezTokenizerFast"),Uto=o(" (BARThez model)"),Jto=l(),Xg=a("li"),jne=a("strong"),Yto=o("bartpho"),Kto=o(" \u2014 "),MP=a("a"),Zto=o("BartphoTokenizer"),eao=o(" (BARTpho model)"),oao=l(),Gn=a("li"),Dne=a("strong"),rao=o("bert"),tao=o(" \u2014 "),EP=a("a"),aao=o("BertTokenizer"),nao=o(" or "),CP=a("a"),sao=o("BertTokenizerFast"),lao=o(" (BERT model)"),iao=l(),zg=a("li"),Gne=a("strong"),dao=o("bert-generation"),cao=o(" \u2014 "),wP=a("a"),fao=o("BertGenerationTokenizer"),mao=o(" (Bert Generation model)"),gao=l(),Qg=a("li"),One=a("strong"),hao=o("bert-japanese"),pao=o(" \u2014 "),AP=a("a"),_ao=o("BertJapaneseTokenizer"),uao=o(" (BertJapanese model)"),bao=l(),Wg=a("li"),Vne=a("strong"),vao=o("bertweet"),Fao=o(" \u2014 "),LP=a("a"),Tao=o("BertweetTokenizer"),Mao=o(" (BERTweet model)"),Eao=l(),On=a("li"),Xne=a("strong"),Cao=o("big_bird"),wao=o(" \u2014 "),yP=a("a"),Aao=o("BigBirdTokenizer"),Lao=o(" or "),xP=a("a"),yao=o("BigBirdTokenizerFast"),xao=o(" (BigBird model)"),$ao=l(),Vn=a("li"),zne=a("strong"),kao=o("bigbird_pegasus"),Sao=o(" \u2014 "),$P=a("a"),Rao=o("PegasusTokenizer"),Pao=o(" or "),kP=a("a"),Bao=o("PegasusTokenizerFast"),Iao=o(" (BigBird-Pegasus model)"),Nao=l(),Xn=a("li"),Qne=a("strong"),qao=o("blenderbot"),jao=o(" \u2014 "),SP=a("a"),Dao=o("BlenderbotTokenizer"),Gao=o(" or "),RP=a("a"),Oao=o("BlenderbotTokenizerFast"),Vao=o(" (Blenderbot model)"),Xao=l(),Hg=a("li"),Wne=a("strong"),zao=o("blenderbot-small"),Qao=o(" \u2014 "),PP=a("a"),Wao=o("BlenderbotSmallTokenizer"),Hao=o(" (BlenderbotSmall model)"),Uao=l(),Ug=a("li"),Hne=a("strong"),Jao=o("bloom"),Yao=o(" \u2014 "),BP=a("a"),Kao=o("BloomTokenizerFast"),Zao=o(" (BLOOM model)"),eno=l(),Jg=a("li"),Une=a("strong"),ono=o("byt5"),rno=o(" \u2014 "),IP=a("a"),tno=o("ByT5Tokenizer"),ano=o(" (ByT5 model)"),nno=l(),zn=a("li"),Jne=a("strong"),sno=o("camembert"),lno=o(" \u2014 "),NP=a("a"),ino=o("CamembertTokenizer"),dno=o(" or "),qP=a("a"),cno=o("CamembertTokenizerFast"),fno=o(" (CamemBERT model)"),mno=l(),Yg=a("li"),Yne=a("strong"),gno=o("canine"),hno=o(" \u2014 "),jP=a("a"),pno=o("CanineTokenizer"),_no=o(" (CANINE model)"),uno=l(),Qn=a("li"),Kne=a("strong"),bno=o("clip"),vno=o(" \u2014 "),DP=a("a"),Fno=o("CLIPTokenizer"),Tno=o(" or "),GP=a("a"),Mno=o("CLIPTokenizerFast"),Eno=o(" (CLIP model)"),Cno=l(),Wn=a("li"),Zne=a("strong"),wno=o("convbert"),Ano=o(" \u2014 "),OP=a("a"),Lno=o("ConvBertTokenizer"),yno=o(" or "),VP=a("a"),xno=o("ConvBertTokenizerFast"),$no=o(" (ConvBERT model)"),kno=l(),Hn=a("li"),ese=a("strong"),Sno=o("cpm"),Rno=o(" \u2014 "),XP=a("a"),Pno=o("CpmTokenizer"),Bno=o(" or "),zP=a("a"),Ino=o("CpmTokenizerFast"),Nno=o(" (CPM model)"),qno=l(),Kg=a("li"),ose=a("strong"),jno=o("ctrl"),Dno=o(" \u2014 "),QP=a("a"),Gno=o("CTRLTokenizer"),Ono=o(" (CTRL model)"),Vno=l(),Un=a("li"),rse=a("strong"),Xno=o("data2vec-text"),zno=o(" \u2014 "),WP=a("a"),Qno=o("RobertaTokenizer"),Wno=o(" or "),HP=a("a"),Hno=o("RobertaTokenizerFast"),Uno=o(" (Data2VecText model)"),Jno=l(),Jn=a("li"),tse=a("strong"),Yno=o("deberta"),Kno=o(" \u2014 "),UP=a("a"),Zno=o("DebertaTokenizer"),eso=o(" or "),JP=a("a"),oso=o("DebertaTokenizerFast"),rso=o(" (DeBERTa model)"),tso=l(),Yn=a("li"),ase=a("strong"),aso=o("deberta-v2"),nso=o(" \u2014 "),YP=a("a"),sso=o("DebertaV2Tokenizer"),lso=o(" or "),KP=a("a"),iso=o("DebertaV2TokenizerFast"),dso=o(" (DeBERTa-v2 model)"),cso=l(),Kn=a("li"),nse=a("strong"),fso=o("distilbert"),mso=o(" \u2014 "),ZP=a("a"),gso=o("DistilBertTokenizer"),hso=o(" or "),eB=a("a"),pso=o("DistilBertTokenizerFast"),_so=o(" (DistilBERT model)"),uso=l(),Zn=a("li"),sse=a("strong"),bso=o("dpr"),vso=o(" \u2014 "),oB=a("a"),Fso=o("DPRQuestionEncoderTokenizer"),Tso=o(" or "),rB=a("a"),Mso=o("DPRQuestionEncoderTokenizerFast"),Eso=o(" (DPR model)"),Cso=l(),es=a("li"),lse=a("strong"),wso=o("electra"),Aso=o(" \u2014 "),tB=a("a"),Lso=o("ElectraTokenizer"),yso=o(" or "),aB=a("a"),xso=o("ElectraTokenizerFast"),$so=o(" (ELECTRA model)"),kso=l(),Zg=a("li"),ise=a("strong"),Sso=o("flaubert"),Rso=o(" \u2014 "),nB=a("a"),Pso=o("FlaubertTokenizer"),Bso=o(" (FlauBERT model)"),Iso=l(),os=a("li"),dse=a("strong"),Nso=o("fnet"),qso=o(" \u2014 "),sB=a("a"),jso=o("FNetTokenizer"),Dso=o(" or "),lB=a("a"),Gso=o("FNetTokenizerFast"),Oso=o(" (FNet model)"),Vso=l(),eh=a("li"),cse=a("strong"),Xso=o("fsmt"),zso=o(" \u2014 "),iB=a("a"),Qso=o("FSMTTokenizer"),Wso=o(" (FairSeq Machine-Translation model)"),Hso=l(),rs=a("li"),fse=a("strong"),Uso=o("funnel"),Jso=o(" \u2014 "),dB=a("a"),Yso=o("FunnelTokenizer"),Kso=o(" or "),cB=a("a"),Zso=o("FunnelTokenizerFast"),elo=o(" (Funnel Transformer model)"),olo=l(),ts=a("li"),mse=a("strong"),rlo=o("gpt2"),tlo=o(" \u2014 "),fB=a("a"),alo=o("GPT2Tokenizer"),nlo=o(" or "),mB=a("a"),slo=o("GPT2TokenizerFast"),llo=o(" (OpenAI GPT-2 model)"),ilo=l(),as=a("li"),gse=a("strong"),dlo=o("gpt_neo"),clo=o(" \u2014 "),gB=a("a"),flo=o("GPT2Tokenizer"),mlo=o(" or "),hB=a("a"),glo=o("GPT2TokenizerFast"),hlo=o(" (GPT Neo model)"),plo=l(),oh=a("li"),hse=a("strong"),_lo=o("gpt_neox"),ulo=o(" \u2014 "),pB=a("a"),blo=o("GPTNeoXTokenizerFast"),vlo=o(" (GPT NeoX model)"),Flo=l(),ns=a("li"),pse=a("strong"),Tlo=o("gptj"),Mlo=o(" \u2014 "),_B=a("a"),Elo=o("GPT2Tokenizer"),Clo=o(" or "),uB=a("a"),wlo=o("GPT2TokenizerFast"),Alo=o(" (GPT-J model)"),Llo=l(),ss=a("li"),_se=a("strong"),ylo=o("herbert"),xlo=o(" \u2014 "),bB=a("a"),$lo=o("HerbertTokenizer"),klo=o(" or "),vB=a("a"),Slo=o("HerbertTokenizerFast"),Rlo=o(" (HerBERT model)"),Plo=l(),rh=a("li"),use=a("strong"),Blo=o("hubert"),Ilo=o(" \u2014 "),FB=a("a"),Nlo=o("Wav2Vec2CTCTokenizer"),qlo=o(" (Hubert model)"),jlo=l(),ls=a("li"),bse=a("strong"),Dlo=o("ibert"),Glo=o(" \u2014 "),TB=a("a"),Olo=o("RobertaTokenizer"),Vlo=o(" or "),MB=a("a"),Xlo=o("RobertaTokenizerFast"),zlo=o(" (I-BERT model)"),Qlo=l(),is=a("li"),vse=a("strong"),Wlo=o("layoutlm"),Hlo=o(" \u2014 "),EB=a("a"),Ulo=o("LayoutLMTokenizer"),Jlo=o(" or "),CB=a("a"),Ylo=o("LayoutLMTokenizerFast"),Klo=o(" (LayoutLM model)"),Zlo=l(),ds=a("li"),Fse=a("strong"),eio=o("layoutlmv2"),oio=o(" \u2014 "),wB=a("a"),rio=o("LayoutLMv2Tokenizer"),tio=o(" or "),AB=a("a"),aio=o("LayoutLMv2TokenizerFast"),nio=o(" (LayoutLMv2 model)"),sio=l(),cs=a("li"),Tse=a("strong"),lio=o("layoutlmv3"),iio=o(" \u2014 "),LB=a("a"),dio=o("LayoutLMv3Tokenizer"),cio=o(" or "),yB=a("a"),fio=o("LayoutLMv3TokenizerFast"),mio=o(" (LayoutLMv3 model)"),gio=l(),fs=a("li"),Mse=a("strong"),hio=o("layoutxlm"),pio=o(" \u2014 "),xB=a("a"),_io=o("LayoutXLMTokenizer"),uio=o(" or "),$B=a("a"),bio=o("LayoutXLMTokenizerFast"),vio=o(" (LayoutXLM model)"),Fio=l(),ms=a("li"),Ese=a("strong"),Tio=o("led"),Mio=o(" \u2014 "),kB=a("a"),Eio=o("LEDTokenizer"),Cio=o(" or "),SB=a("a"),wio=o("LEDTokenizerFast"),Aio=o(" (LED model)"),Lio=l(),gs=a("li"),Cse=a("strong"),yio=o("longformer"),xio=o(" \u2014 "),RB=a("a"),$io=o("LongformerTokenizer"),kio=o(" or "),PB=a("a"),Sio=o("LongformerTokenizerFast"),Rio=o(" (Longformer model)"),Pio=l(),hs=a("li"),wse=a("strong"),Bio=o("longt5"),Iio=o(" \u2014 "),BB=a("a"),Nio=o("T5Tokenizer"),qio=o(" or "),IB=a("a"),jio=o("T5TokenizerFast"),Dio=o(" (LongT5 model)"),Gio=l(),th=a("li"),Ase=a("strong"),Oio=o("luke"),Vio=o(" \u2014 "),NB=a("a"),Xio=o("LukeTokenizer"),zio=o(" (LUKE model)"),Qio=l(),ps=a("li"),Lse=a("strong"),Wio=o("lxmert"),Hio=o(" \u2014 "),qB=a("a"),Uio=o("LxmertTokenizer"),Jio=o(" or "),jB=a("a"),Yio=o("LxmertTokenizerFast"),Kio=o(" (LXMERT model)"),Zio=l(),ah=a("li"),yse=a("strong"),edo=o("m2m_100"),odo=o(" \u2014 "),DB=a("a"),rdo=o("M2M100Tokenizer"),tdo=o(" (M2M100 model)"),ado=l(),nh=a("li"),xse=a("strong"),ndo=o("marian"),sdo=o(" \u2014 "),GB=a("a"),ldo=o("MarianTokenizer"),ido=o(" (Marian model)"),ddo=l(),_s=a("li"),$se=a("strong"),cdo=o("mbart"),fdo=o(" \u2014 "),OB=a("a"),mdo=o("MBartTokenizer"),gdo=o(" or "),VB=a("a"),hdo=o("MBartTokenizerFast"),pdo=o(" (mBART model)"),_do=l(),us=a("li"),kse=a("strong"),udo=o("mbart50"),bdo=o(" \u2014 "),XB=a("a"),vdo=o("MBart50Tokenizer"),Fdo=o(" or "),zB=a("a"),Tdo=o("MBart50TokenizerFast"),Mdo=o(" (mBART-50 model)"),Edo=l(),bs=a("li"),Sse=a("strong"),Cdo=o("megatron-bert"),wdo=o(" \u2014 "),QB=a("a"),Ado=o("BertTokenizer"),Ldo=o(" or "),WB=a("a"),ydo=o("BertTokenizerFast"),xdo=o(" (Megatron-BERT model)"),$do=l(),sh=a("li"),Rse=a("strong"),kdo=o("mluke"),Sdo=o(" \u2014 "),HB=a("a"),Rdo=o("MLukeTokenizer"),Pdo=o(" (mLUKE model)"),Bdo=l(),vs=a("li"),Pse=a("strong"),Ido=o("mobilebert"),Ndo=o(" \u2014 "),UB=a("a"),qdo=o("MobileBertTokenizer"),jdo=o(" or "),JB=a("a"),Ddo=o("MobileBertTokenizerFast"),Gdo=o(" (MobileBERT model)"),Odo=l(),Fs=a("li"),Bse=a("strong"),Vdo=o("mpnet"),Xdo=o(" \u2014 "),YB=a("a"),zdo=o("MPNetTokenizer"),Qdo=o(" or "),KB=a("a"),Wdo=o("MPNetTokenizerFast"),Hdo=o(" (MPNet model)"),Udo=l(),Ts=a("li"),Ise=a("strong"),Jdo=o("mt5"),Ydo=o(" \u2014 "),ZB=a("a"),Kdo=o("MT5Tokenizer"),Zdo=o(" or "),eI=a("a"),eco=o("MT5TokenizerFast"),oco=o(" (MT5 model)"),rco=l(),Ms=a("li"),Nse=a("strong"),tco=o("nezha"),aco=o(" \u2014 "),oI=a("a"),nco=o("BertTokenizer"),sco=o(" or "),rI=a("a"),lco=o("BertTokenizerFast"),ico=o(" (Nezha model)"),dco=l(),Es=a("li"),qse=a("strong"),cco=o("nystromformer"),fco=o(" \u2014 "),tI=a("a"),mco=o("AlbertTokenizer"),gco=o(" or "),aI=a("a"),hco=o("AlbertTokenizerFast"),pco=o(" (Nystr\xF6mformer model)"),_co=l(),Cs=a("li"),jse=a("strong"),uco=o("openai-gpt"),bco=o(" \u2014 "),nI=a("a"),vco=o("OpenAIGPTTokenizer"),Fco=o(" or "),sI=a("a"),Tco=o("OpenAIGPTTokenizerFast"),Mco=o(" (OpenAI GPT model)"),Eco=l(),lh=a("li"),Dse=a("strong"),Cco=o("opt"),wco=o(" \u2014 "),lI=a("a"),Aco=o("GPT2Tokenizer"),Lco=o(" (OPT model)"),yco=l(),ws=a("li"),Gse=a("strong"),xco=o("pegasus"),$co=o(" \u2014 "),iI=a("a"),kco=o("PegasusTokenizer"),Sco=o(" or "),dI=a("a"),Rco=o("PegasusTokenizerFast"),Pco=o(" (Pegasus model)"),Bco=l(),ih=a("li"),Ose=a("strong"),Ico=o("perceiver"),Nco=o(" \u2014 "),cI=a("a"),qco=o("PerceiverTokenizer"),jco=o(" (Perceiver model)"),Dco=l(),dh=a("li"),Vse=a("strong"),Gco=o("phobert"),Oco=o(" \u2014 "),fI=a("a"),Vco=o("PhobertTokenizer"),Xco=o(" (PhoBERT model)"),zco=l(),ch=a("li"),Xse=a("strong"),Qco=o("plbart"),Wco=o(" \u2014 "),mI=a("a"),Hco=o("PLBartTokenizer"),Uco=o(" (PLBart model)"),Jco=l(),fh=a("li"),zse=a("strong"),Yco=o("prophetnet"),Kco=o(" \u2014 "),gI=a("a"),Zco=o("ProphetNetTokenizer"),efo=o(" (ProphetNet model)"),ofo=l(),As=a("li"),Qse=a("strong"),rfo=o("qdqbert"),tfo=o(" \u2014 "),hI=a("a"),afo=o("BertTokenizer"),nfo=o(" or "),pI=a("a"),sfo=o("BertTokenizerFast"),lfo=o(" (QDQBert model)"),ifo=l(),mh=a("li"),Wse=a("strong"),dfo=o("rag"),cfo=o(" \u2014 "),_I=a("a"),ffo=o("RagTokenizer"),mfo=o(" (RAG model)"),gfo=l(),Ls=a("li"),Hse=a("strong"),hfo=o("realm"),pfo=o(" \u2014 "),uI=a("a"),_fo=o("RealmTokenizer"),ufo=o(" or "),bI=a("a"),bfo=o("RealmTokenizerFast"),vfo=o(" (REALM model)"),Ffo=l(),ys=a("li"),Use=a("strong"),Tfo=o("reformer"),Mfo=o(" \u2014 "),vI=a("a"),Efo=o("ReformerTokenizer"),Cfo=o(" or "),FI=a("a"),wfo=o("ReformerTokenizerFast"),Afo=o(" (Reformer model)"),Lfo=l(),xs=a("li"),Jse=a("strong"),yfo=o("rembert"),xfo=o(" \u2014 "),TI=a("a"),$fo=o("RemBertTokenizer"),kfo=o(" or "),MI=a("a"),Sfo=o("RemBertTokenizerFast"),Rfo=o(" (RemBERT model)"),Pfo=l(),$s=a("li"),Yse=a("strong"),Bfo=o("retribert"),Ifo=o(" \u2014 "),EI=a("a"),Nfo=o("RetriBertTokenizer"),qfo=o(" or "),CI=a("a"),jfo=o("RetriBertTokenizerFast"),Dfo=o(" (RetriBERT model)"),Gfo=l(),ks=a("li"),Kse=a("strong"),Ofo=o("roberta"),Vfo=o(" \u2014 "),wI=a("a"),Xfo=o("RobertaTokenizer"),zfo=o(" or "),AI=a("a"),Qfo=o("RobertaTokenizerFast"),Wfo=o(" (RoBERTa model)"),Hfo=l(),Ss=a("li"),Zse=a("strong"),Ufo=o("roformer"),Jfo=o(" \u2014 "),LI=a("a"),Yfo=o("RoFormerTokenizer"),Kfo=o(" or "),yI=a("a"),Zfo=o("RoFormerTokenizerFast"),emo=o(" (RoFormer model)"),omo=l(),gh=a("li"),ele=a("strong"),rmo=o("speech_to_text"),tmo=o(" \u2014 "),xI=a("a"),amo=o("Speech2TextTokenizer"),nmo=o(" (Speech2Text model)"),smo=l(),hh=a("li"),ole=a("strong"),lmo=o("speech_to_text_2"),imo=o(" \u2014 "),$I=a("a"),dmo=o("Speech2Text2Tokenizer"),cmo=o(" (Speech2Text2 model)"),fmo=l(),Rs=a("li"),rle=a("strong"),mmo=o("splinter"),gmo=o(" \u2014 "),kI=a("a"),hmo=o("SplinterTokenizer"),pmo=o(" or "),SI=a("a"),_mo=o("SplinterTokenizerFast"),umo=o(" (Splinter model)"),bmo=l(),Ps=a("li"),tle=a("strong"),vmo=o("squeezebert"),Fmo=o(" \u2014 "),RI=a("a"),Tmo=o("SqueezeBertTokenizer"),Mmo=o(" or "),PI=a("a"),Emo=o("SqueezeBertTokenizerFast"),Cmo=o(" (SqueezeBERT model)"),wmo=l(),Bs=a("li"),ale=a("strong"),Amo=o("t5"),Lmo=o(" \u2014 "),BI=a("a"),ymo=o("T5Tokenizer"),xmo=o(" or "),II=a("a"),$mo=o("T5TokenizerFast"),kmo=o(" (T5 model)"),Smo=l(),ph=a("li"),nle=a("strong"),Rmo=o("tapas"),Pmo=o(" \u2014 "),NI=a("a"),Bmo=o("TapasTokenizer"),Imo=o(" (TAPAS model)"),Nmo=l(),_h=a("li"),sle=a("strong"),qmo=o("tapex"),jmo=o(" \u2014 "),qI=a("a"),Dmo=o("TapexTokenizer"),Gmo=o(" (TAPEX model)"),Omo=l(),uh=a("li"),lle=a("strong"),Vmo=o("transfo-xl"),Xmo=o(" \u2014 "),jI=a("a"),zmo=o("TransfoXLTokenizer"),Qmo=o(" (Transformer-XL model)"),Wmo=l(),Is=a("li"),ile=a("strong"),Hmo=o("vilt"),Umo=o(" \u2014 "),DI=a("a"),Jmo=o("BertTokenizer"),Ymo=o(" or "),GI=a("a"),Kmo=o("BertTokenizerFast"),Zmo=o(" (ViLT model)"),ego=l(),Ns=a("li"),dle=a("strong"),ogo=o("visual_bert"),rgo=o(" \u2014 "),OI=a("a"),tgo=o("BertTokenizer"),ago=o(" or "),VI=a("a"),ngo=o("BertTokenizerFast"),sgo=o(" (VisualBERT model)"),lgo=l(),bh=a("li"),cle=a("strong"),igo=o("wav2vec2"),dgo=o(" \u2014 "),XI=a("a"),cgo=o("Wav2Vec2CTCTokenizer"),fgo=o(" (Wav2Vec2 model)"),mgo=l(),vh=a("li"),fle=a("strong"),ggo=o("wav2vec2-conformer"),hgo=o(" \u2014 "),zI=a("a"),pgo=o("Wav2Vec2CTCTokenizer"),_go=o(" (Wav2Vec2-Conformer model)"),ugo=l(),Fh=a("li"),mle=a("strong"),bgo=o("wav2vec2_phoneme"),vgo=o(" \u2014 "),QI=a("a"),Fgo=o("Wav2Vec2PhonemeCTCTokenizer"),Tgo=o(" (Wav2Vec2Phoneme model)"),Mgo=l(),qs=a("li"),gle=a("strong"),Ego=o("xglm"),Cgo=o(" \u2014 "),WI=a("a"),wgo=o("XGLMTokenizer"),Ago=o(" or "),HI=a("a"),Lgo=o("XGLMTokenizerFast"),ygo=o(" (XGLM model)"),xgo=l(),Th=a("li"),hle=a("strong"),$go=o("xlm"),kgo=o(" \u2014 "),UI=a("a"),Sgo=o("XLMTokenizer"),Rgo=o(" (XLM model)"),Pgo=l(),Mh=a("li"),ple=a("strong"),Bgo=o("xlm-prophetnet"),Igo=o(" \u2014 "),JI=a("a"),Ngo=o("XLMProphetNetTokenizer"),qgo=o(" (XLM-ProphetNet model)"),jgo=l(),js=a("li"),_le=a("strong"),Dgo=o("xlm-roberta"),Ggo=o(" \u2014 "),YI=a("a"),Ogo=o("XLMRobertaTokenizer"),Vgo=o(" or "),KI=a("a"),Xgo=o("XLMRobertaTokenizerFast"),zgo=o(" (XLM-RoBERTa model)"),Qgo=l(),Ds=a("li"),ule=a("strong"),Wgo=o("xlm-roberta-xl"),Hgo=o(" \u2014 "),ZI=a("a"),Ugo=o("RobertaTokenizer"),Jgo=o(" or "),eN=a("a"),Ygo=o("RobertaTokenizerFast"),Kgo=o(" (XLM-RoBERTa-XL model)"),Zgo=l(),Gs=a("li"),ble=a("strong"),eho=o("xlnet"),oho=o(" \u2014 "),oN=a("a"),rho=o("XLNetTokenizer"),tho=o(" or "),rN=a("a"),aho=o("XLNetTokenizerFast"),nho=o(" (XLNet model)"),sho=l(),Os=a("li"),vle=a("strong"),lho=o("yoso"),iho=o(" \u2014 "),tN=a("a"),dho=o("AlbertTokenizer"),cho=o(" or "),aN=a("a"),fho=o("AlbertTokenizerFast"),mho=o(" (YOSO model)"),gho=l(),F(Eh.$$.fragment),hho=l(),Ch=a("div"),F(OA.$$.fragment),pho=l(),Fle=a("p"),_ho=o("Register a new tokenizer in this mapping."),HGe=l(),Si=a("h2"),wh=a("a"),Tle=a("span"),F(VA.$$.fragment),uho=l(),Mle=a("span"),bho=o("AutoFeatureExtractor"),UGe=l(),Lo=a("div"),F(XA.$$.fragment),vho=l(),zA=a("p"),Fho=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=a("a"),Tho=o("AutoFeatureExtractor.from_pretrained()"),Mho=o(" class method."),Eho=l(),QA=a("p"),Cho=o("This class cannot be instantiated directly using "),Ele=a("code"),who=o("__init__()"),Aho=o(" (throws an error)."),Lho=l(),He=a("div"),F(WA.$$.fragment),yho=l(),Cle=a("p"),xho=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),$ho=l(),Sa=a("p"),kho=o("The feature extractor class to instantiate is selected based on the "),wle=a("code"),Sho=o("model_type"),Rho=o(` property of the config object
(either passed as an argument or loaded from `),Ale=a("code"),Pho=o("pretrained_model_name_or_path"),Bho=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=a("code"),Iho=o("pretrained_model_name_or_path"),Nho=o(":"),qho=l(),Y=a("ul"),Ah=a("li"),yle=a("strong"),jho=o("beit"),Dho=o(" \u2014 "),sN=a("a"),Gho=o("BeitFeatureExtractor"),Oho=o(" (BEiT model)"),Vho=l(),Lh=a("li"),xle=a("strong"),Xho=o("clip"),zho=o(" \u2014 "),lN=a("a"),Qho=o("CLIPFeatureExtractor"),Who=o(" (CLIP model)"),Hho=l(),yh=a("li"),$le=a("strong"),Uho=o("convnext"),Jho=o(" \u2014 "),iN=a("a"),Yho=o("ConvNextFeatureExtractor"),Kho=o(" (ConvNeXT model)"),Zho=l(),xh=a("li"),kle=a("strong"),epo=o("cvt"),opo=o(" \u2014 "),dN=a("a"),rpo=o("ConvNextFeatureExtractor"),tpo=o(" (CvT model)"),apo=l(),$h=a("li"),Sle=a("strong"),npo=o("data2vec-audio"),spo=o(" \u2014 "),cN=a("a"),lpo=o("Wav2Vec2FeatureExtractor"),ipo=o(" (Data2VecAudio model)"),dpo=l(),kh=a("li"),Rle=a("strong"),cpo=o("data2vec-vision"),fpo=o(" \u2014 "),fN=a("a"),mpo=o("BeitFeatureExtractor"),gpo=o(" (Data2VecVision model)"),hpo=l(),Sh=a("li"),Ple=a("strong"),ppo=o("deit"),_po=o(" \u2014 "),mN=a("a"),upo=o("DeiTFeatureExtractor"),bpo=o(" (DeiT model)"),vpo=l(),Rh=a("li"),Ble=a("strong"),Fpo=o("detr"),Tpo=o(" \u2014 "),gN=a("a"),Mpo=o("DetrFeatureExtractor"),Epo=o(" (DETR model)"),Cpo=l(),Ph=a("li"),Ile=a("strong"),wpo=o("dpt"),Apo=o(" \u2014 "),hN=a("a"),Lpo=o("DPTFeatureExtractor"),ypo=o(" (DPT model)"),xpo=l(),Bh=a("li"),Nle=a("strong"),$po=o("flava"),kpo=o(" \u2014 "),pN=a("a"),Spo=o("FlavaFeatureExtractor"),Rpo=o(" (FLAVA model)"),Ppo=l(),Ih=a("li"),qle=a("strong"),Bpo=o("glpn"),Ipo=o(" \u2014 "),_N=a("a"),Npo=o("GLPNFeatureExtractor"),qpo=o(" (GLPN model)"),jpo=l(),Nh=a("li"),jle=a("strong"),Dpo=o("hubert"),Gpo=o(" \u2014 "),uN=a("a"),Opo=o("Wav2Vec2FeatureExtractor"),Vpo=o(" (Hubert model)"),Xpo=l(),qh=a("li"),Dle=a("strong"),zpo=o("imagegpt"),Qpo=o(" \u2014 "),bN=a("a"),Wpo=o("ImageGPTFeatureExtractor"),Hpo=o(" (ImageGPT model)"),Upo=l(),jh=a("li"),Gle=a("strong"),Jpo=o("layoutlmv2"),Ypo=o(" \u2014 "),vN=a("a"),Kpo=o("LayoutLMv2FeatureExtractor"),Zpo=o(" (LayoutLMv2 model)"),e_o=l(),Dh=a("li"),Ole=a("strong"),o_o=o("layoutlmv3"),r_o=o(" \u2014 "),FN=a("a"),t_o=o("LayoutLMv3FeatureExtractor"),a_o=o(" (LayoutLMv3 model)"),n_o=l(),Gh=a("li"),Vle=a("strong"),s_o=o("levit"),l_o=o(" \u2014 "),TN=a("a"),i_o=o("LevitFeatureExtractor"),d_o=o(" (LeViT model)"),c_o=l(),Oh=a("li"),Xle=a("strong"),f_o=o("maskformer"),m_o=o(" \u2014 "),MN=a("a"),g_o=o("MaskFormerFeatureExtractor"),h_o=o(" (MaskFormer model)"),p_o=l(),Vh=a("li"),zle=a("strong"),__o=o("mctct"),u_o=o(" \u2014 "),EN=a("a"),b_o=o("MCTCTFeatureExtractor"),v_o=o(" (M-CTC-T model)"),F_o=l(),Xh=a("li"),Qle=a("strong"),T_o=o("perceiver"),M_o=o(" \u2014 "),CN=a("a"),E_o=o("PerceiverFeatureExtractor"),C_o=o(" (Perceiver model)"),w_o=l(),zh=a("li"),Wle=a("strong"),A_o=o("poolformer"),L_o=o(" \u2014 "),wN=a("a"),y_o=o("PoolFormerFeatureExtractor"),x_o=o(" (PoolFormer model)"),$_o=l(),Qh=a("li"),Hle=a("strong"),k_o=o("regnet"),S_o=o(" \u2014 "),AN=a("a"),R_o=o("ConvNextFeatureExtractor"),P_o=o(" (RegNet model)"),B_o=l(),Wh=a("li"),Ule=a("strong"),I_o=o("resnet"),N_o=o(" \u2014 "),LN=a("a"),q_o=o("ConvNextFeatureExtractor"),j_o=o(" (ResNet model)"),D_o=l(),Hh=a("li"),Jle=a("strong"),G_o=o("segformer"),O_o=o(" \u2014 "),yN=a("a"),V_o=o("SegformerFeatureExtractor"),X_o=o(" (SegFormer model)"),z_o=l(),Uh=a("li"),Yle=a("strong"),Q_o=o("speech_to_text"),W_o=o(" \u2014 "),xN=a("a"),H_o=o("Speech2TextFeatureExtractor"),U_o=o(" (Speech2Text model)"),J_o=l(),Jh=a("li"),Kle=a("strong"),Y_o=o("swin"),K_o=o(" \u2014 "),$N=a("a"),Z_o=o("ViTFeatureExtractor"),euo=o(" (Swin Transformer model)"),ouo=l(),Yh=a("li"),Zle=a("strong"),ruo=o("van"),tuo=o(" \u2014 "),kN=a("a"),auo=o("ConvNextFeatureExtractor"),nuo=o(" (VAN model)"),suo=l(),Kh=a("li"),eie=a("strong"),luo=o("vilt"),iuo=o(" \u2014 "),SN=a("a"),duo=o("ViltFeatureExtractor"),cuo=o(" (ViLT model)"),fuo=l(),Zh=a("li"),oie=a("strong"),muo=o("vit"),guo=o(" \u2014 "),RN=a("a"),huo=o("ViTFeatureExtractor"),puo=o(" (ViT model)"),_uo=l(),ep=a("li"),rie=a("strong"),uuo=o("vit_mae"),buo=o(" \u2014 "),PN=a("a"),vuo=o("ViTFeatureExtractor"),Fuo=o(" (ViTMAE model)"),Tuo=l(),op=a("li"),tie=a("strong"),Muo=o("wav2vec2"),Euo=o(" \u2014 "),BN=a("a"),Cuo=o("Wav2Vec2FeatureExtractor"),wuo=o(" (Wav2Vec2 model)"),Auo=l(),rp=a("li"),aie=a("strong"),Luo=o("wav2vec2-conformer"),yuo=o(" \u2014 "),IN=a("a"),xuo=o("Wav2Vec2FeatureExtractor"),$uo=o(" (Wav2Vec2-Conformer model)"),kuo=l(),tp=a("li"),nie=a("strong"),Suo=o("yolos"),Ruo=o(" \u2014 "),NN=a("a"),Puo=o("YolosFeatureExtractor"),Buo=o(" (YOLOS model)"),Iuo=l(),F(ap.$$.fragment),Nuo=l(),F(np.$$.fragment),quo=l(),sp=a("div"),F(HA.$$.fragment),juo=l(),sie=a("p"),Duo=o("Register a new feature extractor for this class."),JGe=l(),Ri=a("h2"),lp=a("a"),lie=a("span"),F(UA.$$.fragment),Guo=l(),iie=a("span"),Ouo=o("AutoProcessor"),YGe=l(),yo=a("div"),F(JA.$$.fragment),Vuo=l(),YA=a("p"),Xuo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=a("a"),zuo=o("AutoProcessor.from_pretrained()"),Quo=o(" class method."),Wuo=l(),KA=a("p"),Huo=o("This class cannot be instantiated directly using "),die=a("code"),Uuo=o("__init__()"),Juo=o(" (throws an error)."),Yuo=l(),Ue=a("div"),F(ZA.$$.fragment),Kuo=l(),cie=a("p"),Zuo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),e1o=l(),Pi=a("p"),o1o=o("The processor class to instantiate is selected based on the "),fie=a("code"),r1o=o("model_type"),t1o=o(` property of the config object (either
passed as an argument or loaded from `),mie=a("code"),a1o=o("pretrained_model_name_or_path"),n1o=o(" if possible):"),s1o=l(),he=a("ul"),ip=a("li"),gie=a("strong"),l1o=o("clip"),i1o=o(" \u2014 "),jN=a("a"),d1o=o("CLIPProcessor"),c1o=o(" (CLIP model)"),f1o=l(),dp=a("li"),hie=a("strong"),m1o=o("flava"),g1o=o(" \u2014 "),pie=a("code"),h1o=o("FLAVAProcessor"),p1o=o(" (FLAVA model)"),_1o=l(),cp=a("li"),_ie=a("strong"),u1o=o("layoutlmv2"),b1o=o(" \u2014 "),DN=a("a"),v1o=o("LayoutLMv2Processor"),F1o=o(" (LayoutLMv2 model)"),T1o=l(),fp=a("li"),uie=a("strong"),M1o=o("layoutlmv3"),E1o=o(" \u2014 "),GN=a("a"),C1o=o("LayoutLMv3Processor"),w1o=o(" (LayoutLMv3 model)"),A1o=l(),mp=a("li"),bie=a("strong"),L1o=o("layoutxlm"),y1o=o(" \u2014 "),ON=a("a"),x1o=o("LayoutXLMProcessor"),$1o=o(" (LayoutXLM model)"),k1o=l(),gp=a("li"),vie=a("strong"),S1o=o("sew"),R1o=o(" \u2014 "),VN=a("a"),P1o=o("Wav2Vec2Processor"),B1o=o(" (SEW model)"),I1o=l(),hp=a("li"),Fie=a("strong"),N1o=o("sew-d"),q1o=o(" \u2014 "),XN=a("a"),j1o=o("Wav2Vec2Processor"),D1o=o(" (SEW-D model)"),G1o=l(),pp=a("li"),Tie=a("strong"),O1o=o("speech_to_text"),V1o=o(" \u2014 "),zN=a("a"),X1o=o("Speech2TextProcessor"),z1o=o(" (Speech2Text model)"),Q1o=l(),_p=a("li"),Mie=a("strong"),W1o=o("speech_to_text_2"),H1o=o(" \u2014 "),QN=a("a"),U1o=o("Speech2Text2Processor"),J1o=o(" (Speech2Text2 model)"),Y1o=l(),up=a("li"),Eie=a("strong"),K1o=o("trocr"),Z1o=o(" \u2014 "),WN=a("a"),e2o=o("TrOCRProcessor"),o2o=o(" (TrOCR model)"),r2o=l(),bp=a("li"),Cie=a("strong"),t2o=o("unispeech"),a2o=o(" \u2014 "),HN=a("a"),n2o=o("Wav2Vec2Processor"),s2o=o(" (UniSpeech model)"),l2o=l(),vp=a("li"),wie=a("strong"),i2o=o("unispeech-sat"),d2o=o(" \u2014 "),UN=a("a"),c2o=o("Wav2Vec2Processor"),f2o=o(" (UniSpeechSat model)"),m2o=l(),Fp=a("li"),Aie=a("strong"),g2o=o("vilt"),h2o=o(" \u2014 "),JN=a("a"),p2o=o("ViltProcessor"),_2o=o(" (ViLT model)"),u2o=l(),Tp=a("li"),Lie=a("strong"),b2o=o("vision-text-dual-encoder"),v2o=o(" \u2014 "),YN=a("a"),F2o=o("VisionTextDualEncoderProcessor"),T2o=o(" (VisionTextDualEncoder model)"),M2o=l(),Mp=a("li"),yie=a("strong"),E2o=o("wav2vec2"),C2o=o(" \u2014 "),KN=a("a"),w2o=o("Wav2Vec2Processor"),A2o=o(" (Wav2Vec2 model)"),L2o=l(),Ep=a("li"),xie=a("strong"),y2o=o("wav2vec2-conformer"),x2o=o(" \u2014 "),ZN=a("a"),$2o=o("Wav2Vec2Processor"),k2o=o(" (Wav2Vec2-Conformer model)"),S2o=l(),Cp=a("li"),$ie=a("strong"),R2o=o("wavlm"),P2o=o(" \u2014 "),eq=a("a"),B2o=o("Wav2Vec2Processor"),I2o=o(" (WavLM model)"),N2o=l(),F(wp.$$.fragment),q2o=l(),F(Ap.$$.fragment),j2o=l(),Lp=a("div"),F(eL.$$.fragment),D2o=l(),kie=a("p"),G2o=o("Register a new processor for this class."),KGe=l(),Bi=a("h2"),yp=a("a"),Sie=a("span"),F(oL.$$.fragment),O2o=l(),Rie=a("span"),V2o=o("AutoModel"),ZGe=l(),xo=a("div"),F(rL.$$.fragment),X2o=l(),Ii=a("p"),z2o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=a("a"),Q2o=o("from_pretrained()"),W2o=o(" class method or the "),rq=a("a"),H2o=o("from_config()"),U2o=o(` class
method.`),J2o=l(),tL=a("p"),Y2o=o("This class cannot be instantiated directly using "),Pie=a("code"),K2o=o("__init__()"),Z2o=o(" (throws an error)."),ebo=l(),nt=a("div"),F(aL.$$.fragment),obo=l(),Bie=a("p"),rbo=o("Instantiates one of the base model classes of the library from a configuration."),tbo=l(),Ni=a("p"),abo=o(`Note:
Loading a model from its configuration file does `),Iie=a("strong"),nbo=o("not"),sbo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=a("a"),lbo=o("from_pretrained()"),ibo=o(" to load the model weights."),dbo=l(),F(xp.$$.fragment),cbo=l(),Je=a("div"),F(nL.$$.fragment),fbo=l(),Nie=a("p"),mbo=o("Instantiate one of the base model classes of the library from a pretrained model."),gbo=l(),Ra=a("p"),hbo=o("The model class to instantiate is selected based on the "),qie=a("code"),pbo=o("model_type"),_bo=o(` property of the config object (either
passed as an argument or loaded from `),jie=a("code"),ubo=o("pretrained_model_name_or_path"),bbo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=a("code"),vbo=o("pretrained_model_name_or_path"),Fbo=o(":"),Tbo=l(),y=a("ul"),$p=a("li"),Gie=a("strong"),Mbo=o("albert"),Ebo=o(" \u2014 "),aq=a("a"),Cbo=o("AlbertModel"),wbo=o(" (ALBERT model)"),Abo=l(),kp=a("li"),Oie=a("strong"),Lbo=o("bart"),ybo=o(" \u2014 "),nq=a("a"),xbo=o("BartModel"),$bo=o(" (BART model)"),kbo=l(),Sp=a("li"),Vie=a("strong"),Sbo=o("beit"),Rbo=o(" \u2014 "),sq=a("a"),Pbo=o("BeitModel"),Bbo=o(" (BEiT model)"),Ibo=l(),Rp=a("li"),Xie=a("strong"),Nbo=o("bert"),qbo=o(" \u2014 "),lq=a("a"),jbo=o("BertModel"),Dbo=o(" (BERT model)"),Gbo=l(),Pp=a("li"),zie=a("strong"),Obo=o("bert-generation"),Vbo=o(" \u2014 "),iq=a("a"),Xbo=o("BertGenerationEncoder"),zbo=o(" (Bert Generation model)"),Qbo=l(),Bp=a("li"),Qie=a("strong"),Wbo=o("big_bird"),Hbo=o(" \u2014 "),dq=a("a"),Ubo=o("BigBirdModel"),Jbo=o(" (BigBird model)"),Ybo=l(),Ip=a("li"),Wie=a("strong"),Kbo=o("bigbird_pegasus"),Zbo=o(" \u2014 "),cq=a("a"),e4o=o("BigBirdPegasusModel"),o4o=o(" (BigBird-Pegasus model)"),r4o=l(),Np=a("li"),Hie=a("strong"),t4o=o("blenderbot"),a4o=o(" \u2014 "),fq=a("a"),n4o=o("BlenderbotModel"),s4o=o(" (Blenderbot model)"),l4o=l(),qp=a("li"),Uie=a("strong"),i4o=o("blenderbot-small"),d4o=o(" \u2014 "),mq=a("a"),c4o=o("BlenderbotSmallModel"),f4o=o(" (BlenderbotSmall model)"),m4o=l(),jp=a("li"),Jie=a("strong"),g4o=o("bloom"),h4o=o(" \u2014 "),gq=a("a"),p4o=o("BloomModel"),_4o=o(" (BLOOM model)"),u4o=l(),Dp=a("li"),Yie=a("strong"),b4o=o("camembert"),v4o=o(" \u2014 "),hq=a("a"),F4o=o("CamembertModel"),T4o=o(" (CamemBERT model)"),M4o=l(),Gp=a("li"),Kie=a("strong"),E4o=o("canine"),C4o=o(" \u2014 "),pq=a("a"),w4o=o("CanineModel"),A4o=o(" (CANINE model)"),L4o=l(),Op=a("li"),Zie=a("strong"),y4o=o("clip"),x4o=o(" \u2014 "),_q=a("a"),$4o=o("CLIPModel"),k4o=o(" (CLIP model)"),S4o=l(),Vp=a("li"),ede=a("strong"),R4o=o("convbert"),P4o=o(" \u2014 "),uq=a("a"),B4o=o("ConvBertModel"),I4o=o(" (ConvBERT model)"),N4o=l(),Xp=a("li"),ode=a("strong"),q4o=o("convnext"),j4o=o(" \u2014 "),bq=a("a"),D4o=o("ConvNextModel"),G4o=o(" (ConvNeXT model)"),O4o=l(),zp=a("li"),rde=a("strong"),V4o=o("ctrl"),X4o=o(" \u2014 "),vq=a("a"),z4o=o("CTRLModel"),Q4o=o(" (CTRL model)"),W4o=l(),Qp=a("li"),tde=a("strong"),H4o=o("cvt"),U4o=o(" \u2014 "),Fq=a("a"),J4o=o("CvtModel"),Y4o=o(" (CvT model)"),K4o=l(),Wp=a("li"),ade=a("strong"),Z4o=o("data2vec-audio"),evo=o(" \u2014 "),Tq=a("a"),ovo=o("Data2VecAudioModel"),rvo=o(" (Data2VecAudio model)"),tvo=l(),Hp=a("li"),nde=a("strong"),avo=o("data2vec-text"),nvo=o(" \u2014 "),Mq=a("a"),svo=o("Data2VecTextModel"),lvo=o(" (Data2VecText model)"),ivo=l(),Up=a("li"),sde=a("strong"),dvo=o("data2vec-vision"),cvo=o(" \u2014 "),Eq=a("a"),fvo=o("Data2VecVisionModel"),mvo=o(" (Data2VecVision model)"),gvo=l(),Jp=a("li"),lde=a("strong"),hvo=o("deberta"),pvo=o(" \u2014 "),Cq=a("a"),_vo=o("DebertaModel"),uvo=o(" (DeBERTa model)"),bvo=l(),Yp=a("li"),ide=a("strong"),vvo=o("deberta-v2"),Fvo=o(" \u2014 "),wq=a("a"),Tvo=o("DebertaV2Model"),Mvo=o(" (DeBERTa-v2 model)"),Evo=l(),Kp=a("li"),dde=a("strong"),Cvo=o("decision_transformer"),wvo=o(" \u2014 "),Aq=a("a"),Avo=o("DecisionTransformerModel"),Lvo=o(" (Decision Transformer model)"),yvo=l(),Zp=a("li"),cde=a("strong"),xvo=o("deit"),$vo=o(" \u2014 "),Lq=a("a"),kvo=o("DeiTModel"),Svo=o(" (DeiT model)"),Rvo=l(),e_=a("li"),fde=a("strong"),Pvo=o("detr"),Bvo=o(" \u2014 "),yq=a("a"),Ivo=o("DetrModel"),Nvo=o(" (DETR model)"),qvo=l(),o_=a("li"),mde=a("strong"),jvo=o("distilbert"),Dvo=o(" \u2014 "),xq=a("a"),Gvo=o("DistilBertModel"),Ovo=o(" (DistilBERT model)"),Vvo=l(),r_=a("li"),gde=a("strong"),Xvo=o("dpr"),zvo=o(" \u2014 "),$q=a("a"),Qvo=o("DPRQuestionEncoder"),Wvo=o(" (DPR model)"),Hvo=l(),t_=a("li"),hde=a("strong"),Uvo=o("dpt"),Jvo=o(" \u2014 "),kq=a("a"),Yvo=o("DPTModel"),Kvo=o(" (DPT model)"),Zvo=l(),a_=a("li"),pde=a("strong"),eFo=o("electra"),oFo=o(" \u2014 "),Sq=a("a"),rFo=o("ElectraModel"),tFo=o(" (ELECTRA model)"),aFo=l(),n_=a("li"),_de=a("strong"),nFo=o("flaubert"),sFo=o(" \u2014 "),Rq=a("a"),lFo=o("FlaubertModel"),iFo=o(" (FlauBERT model)"),dFo=l(),s_=a("li"),ude=a("strong"),cFo=o("flava"),fFo=o(" \u2014 "),Pq=a("a"),mFo=o("FlavaModel"),gFo=o(" (FLAVA model)"),hFo=l(),l_=a("li"),bde=a("strong"),pFo=o("fnet"),_Fo=o(" \u2014 "),Bq=a("a"),uFo=o("FNetModel"),bFo=o(" (FNet model)"),vFo=l(),i_=a("li"),vde=a("strong"),FFo=o("fsmt"),TFo=o(" \u2014 "),Iq=a("a"),MFo=o("FSMTModel"),EFo=o(" (FairSeq Machine-Translation model)"),CFo=l(),Vs=a("li"),Fde=a("strong"),wFo=o("funnel"),AFo=o(" \u2014 "),Nq=a("a"),LFo=o("FunnelModel"),yFo=o(" or "),qq=a("a"),xFo=o("FunnelBaseModel"),$Fo=o(" (Funnel Transformer model)"),kFo=l(),d_=a("li"),Tde=a("strong"),SFo=o("glpn"),RFo=o(" \u2014 "),jq=a("a"),PFo=o("GLPNModel"),BFo=o(" (GLPN model)"),IFo=l(),c_=a("li"),Mde=a("strong"),NFo=o("gpt2"),qFo=o(" \u2014 "),Dq=a("a"),jFo=o("GPT2Model"),DFo=o(" (OpenAI GPT-2 model)"),GFo=l(),f_=a("li"),Ede=a("strong"),OFo=o("gpt_neo"),VFo=o(" \u2014 "),Gq=a("a"),XFo=o("GPTNeoModel"),zFo=o(" (GPT Neo model)"),QFo=l(),m_=a("li"),Cde=a("strong"),WFo=o("gpt_neox"),HFo=o(" \u2014 "),Oq=a("a"),UFo=o("GPTNeoXModel"),JFo=o(" (GPT NeoX model)"),YFo=l(),g_=a("li"),wde=a("strong"),KFo=o("gptj"),ZFo=o(" \u2014 "),Vq=a("a"),e6o=o("GPTJModel"),o6o=o(" (GPT-J model)"),r6o=l(),h_=a("li"),Ade=a("strong"),t6o=o("hubert"),a6o=o(" \u2014 "),Xq=a("a"),n6o=o("HubertModel"),s6o=o(" (Hubert model)"),l6o=l(),p_=a("li"),Lde=a("strong"),i6o=o("ibert"),d6o=o(" \u2014 "),zq=a("a"),c6o=o("IBertModel"),f6o=o(" (I-BERT model)"),m6o=l(),__=a("li"),yde=a("strong"),g6o=o("imagegpt"),h6o=o(" \u2014 "),Qq=a("a"),p6o=o("ImageGPTModel"),_6o=o(" (ImageGPT model)"),u6o=l(),u_=a("li"),xde=a("strong"),b6o=o("layoutlm"),v6o=o(" \u2014 "),Wq=a("a"),F6o=o("LayoutLMModel"),T6o=o(" (LayoutLM model)"),M6o=l(),b_=a("li"),$de=a("strong"),E6o=o("layoutlmv2"),C6o=o(" \u2014 "),Hq=a("a"),w6o=o("LayoutLMv2Model"),A6o=o(" (LayoutLMv2 model)"),L6o=l(),v_=a("li"),kde=a("strong"),y6o=o("layoutlmv3"),x6o=o(" \u2014 "),Uq=a("a"),$6o=o("LayoutLMv3Model"),k6o=o(" (LayoutLMv3 model)"),S6o=l(),F_=a("li"),Sde=a("strong"),R6o=o("led"),P6o=o(" \u2014 "),Jq=a("a"),B6o=o("LEDModel"),I6o=o(" (LED model)"),N6o=l(),T_=a("li"),Rde=a("strong"),q6o=o("levit"),j6o=o(" \u2014 "),Yq=a("a"),D6o=o("LevitModel"),G6o=o(" (LeViT model)"),O6o=l(),M_=a("li"),Pde=a("strong"),V6o=o("longformer"),X6o=o(" \u2014 "),Kq=a("a"),z6o=o("LongformerModel"),Q6o=o(" (Longformer model)"),W6o=l(),E_=a("li"),Bde=a("strong"),H6o=o("longt5"),U6o=o(" \u2014 "),Zq=a("a"),J6o=o("LongT5Model"),Y6o=o(" (LongT5 model)"),K6o=l(),C_=a("li"),Ide=a("strong"),Z6o=o("luke"),eTo=o(" \u2014 "),ej=a("a"),oTo=o("LukeModel"),rTo=o(" (LUKE model)"),tTo=l(),w_=a("li"),Nde=a("strong"),aTo=o("lxmert"),nTo=o(" \u2014 "),oj=a("a"),sTo=o("LxmertModel"),lTo=o(" (LXMERT model)"),iTo=l(),A_=a("li"),qde=a("strong"),dTo=o("m2m_100"),cTo=o(" \u2014 "),rj=a("a"),fTo=o("M2M100Model"),mTo=o(" (M2M100 model)"),gTo=l(),L_=a("li"),jde=a("strong"),hTo=o("marian"),pTo=o(" \u2014 "),tj=a("a"),_To=o("MarianModel"),uTo=o(" (Marian model)"),bTo=l(),y_=a("li"),Dde=a("strong"),vTo=o("maskformer"),FTo=o(" \u2014 "),aj=a("a"),TTo=o("MaskFormerModel"),MTo=o(" (MaskFormer model)"),ETo=l(),x_=a("li"),Gde=a("strong"),CTo=o("mbart"),wTo=o(" \u2014 "),nj=a("a"),ATo=o("MBartModel"),LTo=o(" (mBART model)"),yTo=l(),$_=a("li"),Ode=a("strong"),xTo=o("mctct"),$To=o(" \u2014 "),sj=a("a"),kTo=o("MCTCTModel"),STo=o(" (M-CTC-T model)"),RTo=l(),k_=a("li"),Vde=a("strong"),PTo=o("megatron-bert"),BTo=o(" \u2014 "),lj=a("a"),ITo=o("MegatronBertModel"),NTo=o(" (Megatron-BERT model)"),qTo=l(),S_=a("li"),Xde=a("strong"),jTo=o("mobilebert"),DTo=o(" \u2014 "),ij=a("a"),GTo=o("MobileBertModel"),OTo=o(" (MobileBERT model)"),VTo=l(),R_=a("li"),zde=a("strong"),XTo=o("mpnet"),zTo=o(" \u2014 "),dj=a("a"),QTo=o("MPNetModel"),WTo=o(" (MPNet model)"),HTo=l(),P_=a("li"),Qde=a("strong"),UTo=o("mt5"),JTo=o(" \u2014 "),cj=a("a"),YTo=o("MT5Model"),KTo=o(" (MT5 model)"),ZTo=l(),B_=a("li"),Wde=a("strong"),e7o=o("nezha"),o7o=o(" \u2014 "),fj=a("a"),r7o=o("NezhaModel"),t7o=o(" (Nezha model)"),a7o=l(),I_=a("li"),Hde=a("strong"),n7o=o("nystromformer"),s7o=o(" \u2014 "),mj=a("a"),l7o=o("NystromformerModel"),i7o=o(" (Nystr\xF6mformer model)"),d7o=l(),N_=a("li"),Ude=a("strong"),c7o=o("openai-gpt"),f7o=o(" \u2014 "),gj=a("a"),m7o=o("OpenAIGPTModel"),g7o=o(" (OpenAI GPT model)"),h7o=l(),q_=a("li"),Jde=a("strong"),p7o=o("opt"),_7o=o(" \u2014 "),hj=a("a"),u7o=o("OPTModel"),b7o=o(" (OPT model)"),v7o=l(),j_=a("li"),Yde=a("strong"),F7o=o("pegasus"),T7o=o(" \u2014 "),pj=a("a"),M7o=o("PegasusModel"),E7o=o(" (Pegasus model)"),C7o=l(),D_=a("li"),Kde=a("strong"),w7o=o("perceiver"),A7o=o(" \u2014 "),_j=a("a"),L7o=o("PerceiverModel"),y7o=o(" (Perceiver model)"),x7o=l(),G_=a("li"),Zde=a("strong"),$7o=o("plbart"),k7o=o(" \u2014 "),uj=a("a"),S7o=o("PLBartModel"),R7o=o(" (PLBart model)"),P7o=l(),O_=a("li"),ece=a("strong"),B7o=o("poolformer"),I7o=o(" \u2014 "),bj=a("a"),N7o=o("PoolFormerModel"),q7o=o(" (PoolFormer model)"),j7o=l(),V_=a("li"),oce=a("strong"),D7o=o("prophetnet"),G7o=o(" \u2014 "),vj=a("a"),O7o=o("ProphetNetModel"),V7o=o(" (ProphetNet model)"),X7o=l(),X_=a("li"),rce=a("strong"),z7o=o("qdqbert"),Q7o=o(" \u2014 "),Fj=a("a"),W7o=o("QDQBertModel"),H7o=o(" (QDQBert model)"),U7o=l(),z_=a("li"),tce=a("strong"),J7o=o("reformer"),Y7o=o(" \u2014 "),Tj=a("a"),K7o=o("ReformerModel"),Z7o=o(" (Reformer model)"),e8o=l(),Q_=a("li"),ace=a("strong"),o8o=o("regnet"),r8o=o(" \u2014 "),Mj=a("a"),t8o=o("RegNetModel"),a8o=o(" (RegNet model)"),n8o=l(),W_=a("li"),nce=a("strong"),s8o=o("rembert"),l8o=o(" \u2014 "),Ej=a("a"),i8o=o("RemBertModel"),d8o=o(" (RemBERT model)"),c8o=l(),H_=a("li"),sce=a("strong"),f8o=o("resnet"),m8o=o(" \u2014 "),Cj=a("a"),g8o=o("ResNetModel"),h8o=o(" (ResNet model)"),p8o=l(),U_=a("li"),lce=a("strong"),_8o=o("retribert"),u8o=o(" \u2014 "),wj=a("a"),b8o=o("RetriBertModel"),v8o=o(" (RetriBERT model)"),F8o=l(),J_=a("li"),ice=a("strong"),T8o=o("roberta"),M8o=o(" \u2014 "),Aj=a("a"),E8o=o("RobertaModel"),C8o=o(" (RoBERTa model)"),w8o=l(),Y_=a("li"),dce=a("strong"),A8o=o("roformer"),L8o=o(" \u2014 "),Lj=a("a"),y8o=o("RoFormerModel"),x8o=o(" (RoFormer model)"),$8o=l(),K_=a("li"),cce=a("strong"),k8o=o("segformer"),S8o=o(" \u2014 "),yj=a("a"),R8o=o("SegformerModel"),P8o=o(" (SegFormer model)"),B8o=l(),Z_=a("li"),fce=a("strong"),I8o=o("sew"),N8o=o(" \u2014 "),xj=a("a"),q8o=o("SEWModel"),j8o=o(" (SEW model)"),D8o=l(),eu=a("li"),mce=a("strong"),G8o=o("sew-d"),O8o=o(" \u2014 "),$j=a("a"),V8o=o("SEWDModel"),X8o=o(" (SEW-D model)"),z8o=l(),ou=a("li"),gce=a("strong"),Q8o=o("speech_to_text"),W8o=o(" \u2014 "),kj=a("a"),H8o=o("Speech2TextModel"),U8o=o(" (Speech2Text model)"),J8o=l(),ru=a("li"),hce=a("strong"),Y8o=o("splinter"),K8o=o(" \u2014 "),Sj=a("a"),Z8o=o("SplinterModel"),eMo=o(" (Splinter model)"),oMo=l(),tu=a("li"),pce=a("strong"),rMo=o("squeezebert"),tMo=o(" \u2014 "),Rj=a("a"),aMo=o("SqueezeBertModel"),nMo=o(" (SqueezeBERT model)"),sMo=l(),au=a("li"),_ce=a("strong"),lMo=o("swin"),iMo=o(" \u2014 "),Pj=a("a"),dMo=o("SwinModel"),cMo=o(" (Swin Transformer model)"),fMo=l(),nu=a("li"),uce=a("strong"),mMo=o("t5"),gMo=o(" \u2014 "),Bj=a("a"),hMo=o("T5Model"),pMo=o(" (T5 model)"),_Mo=l(),su=a("li"),bce=a("strong"),uMo=o("tapas"),bMo=o(" \u2014 "),Ij=a("a"),vMo=o("TapasModel"),FMo=o(" (TAPAS model)"),TMo=l(),lu=a("li"),vce=a("strong"),MMo=o("trajectory_transformer"),EMo=o(" \u2014 "),Nj=a("a"),CMo=o("TrajectoryTransformerModel"),wMo=o(" (Trajectory Transformer model)"),AMo=l(),iu=a("li"),Fce=a("strong"),LMo=o("transfo-xl"),yMo=o(" \u2014 "),qj=a("a"),xMo=o("TransfoXLModel"),$Mo=o(" (Transformer-XL model)"),kMo=l(),du=a("li"),Tce=a("strong"),SMo=o("unispeech"),RMo=o(" \u2014 "),jj=a("a"),PMo=o("UniSpeechModel"),BMo=o(" (UniSpeech model)"),IMo=l(),cu=a("li"),Mce=a("strong"),NMo=o("unispeech-sat"),qMo=o(" \u2014 "),Dj=a("a"),jMo=o("UniSpeechSatModel"),DMo=o(" (UniSpeechSat model)"),GMo=l(),fu=a("li"),Ece=a("strong"),OMo=o("van"),VMo=o(" \u2014 "),Gj=a("a"),XMo=o("VanModel"),zMo=o(" (VAN model)"),QMo=l(),mu=a("li"),Cce=a("strong"),WMo=o("vilt"),HMo=o(" \u2014 "),Oj=a("a"),UMo=o("ViltModel"),JMo=o(" (ViLT model)"),YMo=l(),gu=a("li"),wce=a("strong"),KMo=o("vision-text-dual-encoder"),ZMo=o(" \u2014 "),Vj=a("a"),eEo=o("VisionTextDualEncoderModel"),oEo=o(" (VisionTextDualEncoder model)"),rEo=l(),hu=a("li"),Ace=a("strong"),tEo=o("visual_bert"),aEo=o(" \u2014 "),Xj=a("a"),nEo=o("VisualBertModel"),sEo=o(" (VisualBERT model)"),lEo=l(),pu=a("li"),Lce=a("strong"),iEo=o("vit"),dEo=o(" \u2014 "),zj=a("a"),cEo=o("ViTModel"),fEo=o(" (ViT model)"),mEo=l(),_u=a("li"),yce=a("strong"),gEo=o("vit_mae"),hEo=o(" \u2014 "),Qj=a("a"),pEo=o("ViTMAEModel"),_Eo=o(" (ViTMAE model)"),uEo=l(),uu=a("li"),xce=a("strong"),bEo=o("wav2vec2"),vEo=o(" \u2014 "),Wj=a("a"),FEo=o("Wav2Vec2Model"),TEo=o(" (Wav2Vec2 model)"),MEo=l(),bu=a("li"),$ce=a("strong"),EEo=o("wav2vec2-conformer"),CEo=o(" \u2014 "),Hj=a("a"),wEo=o("Wav2Vec2ConformerModel"),AEo=o(" (Wav2Vec2-Conformer model)"),LEo=l(),vu=a("li"),kce=a("strong"),yEo=o("wavlm"),xEo=o(" \u2014 "),Uj=a("a"),$Eo=o("WavLMModel"),kEo=o(" (WavLM model)"),SEo=l(),Fu=a("li"),Sce=a("strong"),REo=o("xglm"),PEo=o(" \u2014 "),Jj=a("a"),BEo=o("XGLMModel"),IEo=o(" (XGLM model)"),NEo=l(),Tu=a("li"),Rce=a("strong"),qEo=o("xlm"),jEo=o(" \u2014 "),Yj=a("a"),DEo=o("XLMModel"),GEo=o(" (XLM model)"),OEo=l(),Mu=a("li"),Pce=a("strong"),VEo=o("xlm-prophetnet"),XEo=o(" \u2014 "),Kj=a("a"),zEo=o("XLMProphetNetModel"),QEo=o(" (XLM-ProphetNet model)"),WEo=l(),Eu=a("li"),Bce=a("strong"),HEo=o("xlm-roberta"),UEo=o(" \u2014 "),Zj=a("a"),JEo=o("XLMRobertaModel"),YEo=o(" (XLM-RoBERTa model)"),KEo=l(),Cu=a("li"),Ice=a("strong"),ZEo=o("xlm-roberta-xl"),eCo=o(" \u2014 "),eD=a("a"),oCo=o("XLMRobertaXLModel"),rCo=o(" (XLM-RoBERTa-XL model)"),tCo=l(),wu=a("li"),Nce=a("strong"),aCo=o("xlnet"),nCo=o(" \u2014 "),oD=a("a"),sCo=o("XLNetModel"),lCo=o(" (XLNet model)"),iCo=l(),Au=a("li"),qce=a("strong"),dCo=o("yolos"),cCo=o(" \u2014 "),rD=a("a"),fCo=o("YolosModel"),mCo=o(" (YOLOS model)"),gCo=l(),Lu=a("li"),jce=a("strong"),hCo=o("yoso"),pCo=o(" \u2014 "),tD=a("a"),_Co=o("YosoModel"),uCo=o(" (YOSO model)"),bCo=l(),yu=a("p"),vCo=o("The model is set in evaluation mode by default using "),Dce=a("code"),FCo=o("model.eval()"),TCo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=a("code"),MCo=o("model.train()"),ECo=l(),F(xu.$$.fragment),eOe=l(),qi=a("h2"),$u=a("a"),Oce=a("span"),F(sL.$$.fragment),CCo=l(),Vce=a("span"),wCo=o("AutoModelForPreTraining"),oOe=l(),$o=a("div"),F(lL.$$.fragment),ACo=l(),ji=a("p"),LCo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=a("a"),yCo=o("from_pretrained()"),xCo=o(" class method or the "),nD=a("a"),$Co=o("from_config()"),kCo=o(` class
method.`),SCo=l(),iL=a("p"),RCo=o("This class cannot be instantiated directly using "),Xce=a("code"),PCo=o("__init__()"),BCo=o(" (throws an error)."),ICo=l(),st=a("div"),F(dL.$$.fragment),NCo=l(),zce=a("p"),qCo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),jCo=l(),Di=a("p"),DCo=o(`Note:
Loading a model from its configuration file does `),Qce=a("strong"),GCo=o("not"),OCo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=a("a"),VCo=o("from_pretrained()"),XCo=o(" to load the model weights."),zCo=l(),F(ku.$$.fragment),QCo=l(),Ye=a("div"),F(cL.$$.fragment),WCo=l(),Wce=a("p"),HCo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),UCo=l(),Pa=a("p"),JCo=o("The model class to instantiate is selected based on the "),Hce=a("code"),YCo=o("model_type"),KCo=o(` property of the config object (either
passed as an argument or loaded from `),Uce=a("code"),ZCo=o("pretrained_model_name_or_path"),e5o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=a("code"),o5o=o("pretrained_model_name_or_path"),r5o=o(":"),t5o=l(),G=a("ul"),Su=a("li"),Yce=a("strong"),a5o=o("albert"),n5o=o(" \u2014 "),lD=a("a"),s5o=o("AlbertForPreTraining"),l5o=o(" (ALBERT model)"),i5o=l(),Ru=a("li"),Kce=a("strong"),d5o=o("bart"),c5o=o(" \u2014 "),iD=a("a"),f5o=o("BartForConditionalGeneration"),m5o=o(" (BART model)"),g5o=l(),Pu=a("li"),Zce=a("strong"),h5o=o("bert"),p5o=o(" \u2014 "),dD=a("a"),_5o=o("BertForPreTraining"),u5o=o(" (BERT model)"),b5o=l(),Bu=a("li"),efe=a("strong"),v5o=o("big_bird"),F5o=o(" \u2014 "),cD=a("a"),T5o=o("BigBirdForPreTraining"),M5o=o(" (BigBird model)"),E5o=l(),Iu=a("li"),ofe=a("strong"),C5o=o("bloom"),w5o=o(" \u2014 "),fD=a("a"),A5o=o("BloomForCausalLM"),L5o=o(" (BLOOM model)"),y5o=l(),Nu=a("li"),rfe=a("strong"),x5o=o("camembert"),$5o=o(" \u2014 "),mD=a("a"),k5o=o("CamembertForMaskedLM"),S5o=o(" (CamemBERT model)"),R5o=l(),qu=a("li"),tfe=a("strong"),P5o=o("ctrl"),B5o=o(" \u2014 "),gD=a("a"),I5o=o("CTRLLMHeadModel"),N5o=o(" (CTRL model)"),q5o=l(),ju=a("li"),afe=a("strong"),j5o=o("data2vec-text"),D5o=o(" \u2014 "),hD=a("a"),G5o=o("Data2VecTextForMaskedLM"),O5o=o(" (Data2VecText model)"),V5o=l(),Du=a("li"),nfe=a("strong"),X5o=o("deberta"),z5o=o(" \u2014 "),pD=a("a"),Q5o=o("DebertaForMaskedLM"),W5o=o(" (DeBERTa model)"),H5o=l(),Gu=a("li"),sfe=a("strong"),U5o=o("deberta-v2"),J5o=o(" \u2014 "),_D=a("a"),Y5o=o("DebertaV2ForMaskedLM"),K5o=o(" (DeBERTa-v2 model)"),Z5o=l(),Ou=a("li"),lfe=a("strong"),e3o=o("distilbert"),o3o=o(" \u2014 "),uD=a("a"),r3o=o("DistilBertForMaskedLM"),t3o=o(" (DistilBERT model)"),a3o=l(),Vu=a("li"),ife=a("strong"),n3o=o("electra"),s3o=o(" \u2014 "),bD=a("a"),l3o=o("ElectraForPreTraining"),i3o=o(" (ELECTRA model)"),d3o=l(),Xu=a("li"),dfe=a("strong"),c3o=o("flaubert"),f3o=o(" \u2014 "),vD=a("a"),m3o=o("FlaubertWithLMHeadModel"),g3o=o(" (FlauBERT model)"),h3o=l(),zu=a("li"),cfe=a("strong"),p3o=o("flava"),_3o=o(" \u2014 "),FD=a("a"),u3o=o("FlavaForPreTraining"),b3o=o(" (FLAVA model)"),v3o=l(),Qu=a("li"),ffe=a("strong"),F3o=o("fnet"),T3o=o(" \u2014 "),TD=a("a"),M3o=o("FNetForPreTraining"),E3o=o(" (FNet model)"),C3o=l(),Wu=a("li"),mfe=a("strong"),w3o=o("fsmt"),A3o=o(" \u2014 "),MD=a("a"),L3o=o("FSMTForConditionalGeneration"),y3o=o(" (FairSeq Machine-Translation model)"),x3o=l(),Hu=a("li"),gfe=a("strong"),$3o=o("funnel"),k3o=o(" \u2014 "),ED=a("a"),S3o=o("FunnelForPreTraining"),R3o=o(" (Funnel Transformer model)"),P3o=l(),Uu=a("li"),hfe=a("strong"),B3o=o("gpt2"),I3o=o(" \u2014 "),CD=a("a"),N3o=o("GPT2LMHeadModel"),q3o=o(" (OpenAI GPT-2 model)"),j3o=l(),Ju=a("li"),pfe=a("strong"),D3o=o("ibert"),G3o=o(" \u2014 "),wD=a("a"),O3o=o("IBertForMaskedLM"),V3o=o(" (I-BERT model)"),X3o=l(),Yu=a("li"),_fe=a("strong"),z3o=o("layoutlm"),Q3o=o(" \u2014 "),AD=a("a"),W3o=o("LayoutLMForMaskedLM"),H3o=o(" (LayoutLM model)"),U3o=l(),Ku=a("li"),ufe=a("strong"),J3o=o("longformer"),Y3o=o(" \u2014 "),LD=a("a"),K3o=o("LongformerForMaskedLM"),Z3o=o(" (Longformer model)"),e0o=l(),Zu=a("li"),bfe=a("strong"),o0o=o("lxmert"),r0o=o(" \u2014 "),yD=a("a"),t0o=o("LxmertForPreTraining"),a0o=o(" (LXMERT model)"),n0o=l(),e1=a("li"),vfe=a("strong"),s0o=o("megatron-bert"),l0o=o(" \u2014 "),xD=a("a"),i0o=o("MegatronBertForPreTraining"),d0o=o(" (Megatron-BERT model)"),c0o=l(),o1=a("li"),Ffe=a("strong"),f0o=o("mobilebert"),m0o=o(" \u2014 "),$D=a("a"),g0o=o("MobileBertForPreTraining"),h0o=o(" (MobileBERT model)"),p0o=l(),r1=a("li"),Tfe=a("strong"),_0o=o("mpnet"),u0o=o(" \u2014 "),kD=a("a"),b0o=o("MPNetForMaskedLM"),v0o=o(" (MPNet model)"),F0o=l(),t1=a("li"),Mfe=a("strong"),T0o=o("nezha"),M0o=o(" \u2014 "),SD=a("a"),E0o=o("NezhaForPreTraining"),C0o=o(" (Nezha model)"),w0o=l(),a1=a("li"),Efe=a("strong"),A0o=o("openai-gpt"),L0o=o(" \u2014 "),RD=a("a"),y0o=o("OpenAIGPTLMHeadModel"),x0o=o(" (OpenAI GPT model)"),$0o=l(),n1=a("li"),Cfe=a("strong"),k0o=o("retribert"),S0o=o(" \u2014 "),PD=a("a"),R0o=o("RetriBertModel"),P0o=o(" (RetriBERT model)"),B0o=l(),s1=a("li"),wfe=a("strong"),I0o=o("roberta"),N0o=o(" \u2014 "),BD=a("a"),q0o=o("RobertaForMaskedLM"),j0o=o(" (RoBERTa model)"),D0o=l(),l1=a("li"),Afe=a("strong"),G0o=o("splinter"),O0o=o(" \u2014 "),ID=a("a"),V0o=o("SplinterForPreTraining"),X0o=o(" (Splinter model)"),z0o=l(),i1=a("li"),Lfe=a("strong"),Q0o=o("squeezebert"),W0o=o(" \u2014 "),ND=a("a"),H0o=o("SqueezeBertForMaskedLM"),U0o=o(" (SqueezeBERT model)"),J0o=l(),d1=a("li"),yfe=a("strong"),Y0o=o("t5"),K0o=o(" \u2014 "),qD=a("a"),Z0o=o("T5ForConditionalGeneration"),ewo=o(" (T5 model)"),owo=l(),c1=a("li"),xfe=a("strong"),rwo=o("tapas"),two=o(" \u2014 "),jD=a("a"),awo=o("TapasForMaskedLM"),nwo=o(" (TAPAS model)"),swo=l(),f1=a("li"),$fe=a("strong"),lwo=o("transfo-xl"),iwo=o(" \u2014 "),DD=a("a"),dwo=o("TransfoXLLMHeadModel"),cwo=o(" (Transformer-XL model)"),fwo=l(),m1=a("li"),kfe=a("strong"),mwo=o("unispeech"),gwo=o(" \u2014 "),GD=a("a"),hwo=o("UniSpeechForPreTraining"),pwo=o(" (UniSpeech model)"),_wo=l(),g1=a("li"),Sfe=a("strong"),uwo=o("unispeech-sat"),bwo=o(" \u2014 "),OD=a("a"),vwo=o("UniSpeechSatForPreTraining"),Fwo=o(" (UniSpeechSat model)"),Two=l(),h1=a("li"),Rfe=a("strong"),Mwo=o("visual_bert"),Ewo=o(" \u2014 "),VD=a("a"),Cwo=o("VisualBertForPreTraining"),wwo=o(" (VisualBERT model)"),Awo=l(),p1=a("li"),Pfe=a("strong"),Lwo=o("vit_mae"),ywo=o(" \u2014 "),XD=a("a"),xwo=o("ViTMAEForPreTraining"),$wo=o(" (ViTMAE model)"),kwo=l(),_1=a("li"),Bfe=a("strong"),Swo=o("wav2vec2"),Rwo=o(" \u2014 "),zD=a("a"),Pwo=o("Wav2Vec2ForPreTraining"),Bwo=o(" (Wav2Vec2 model)"),Iwo=l(),u1=a("li"),Ife=a("strong"),Nwo=o("wav2vec2-conformer"),qwo=o(" \u2014 "),QD=a("a"),jwo=o("Wav2Vec2ConformerForPreTraining"),Dwo=o(" (Wav2Vec2-Conformer model)"),Gwo=l(),b1=a("li"),Nfe=a("strong"),Owo=o("xlm"),Vwo=o(" \u2014 "),WD=a("a"),Xwo=o("XLMWithLMHeadModel"),zwo=o(" (XLM model)"),Qwo=l(),v1=a("li"),qfe=a("strong"),Wwo=o("xlm-roberta"),Hwo=o(" \u2014 "),HD=a("a"),Uwo=o("XLMRobertaForMaskedLM"),Jwo=o(" (XLM-RoBERTa model)"),Ywo=l(),F1=a("li"),jfe=a("strong"),Kwo=o("xlm-roberta-xl"),Zwo=o(" \u2014 "),UD=a("a"),eAo=o("XLMRobertaXLForMaskedLM"),oAo=o(" (XLM-RoBERTa-XL model)"),rAo=l(),T1=a("li"),Dfe=a("strong"),tAo=o("xlnet"),aAo=o(" \u2014 "),JD=a("a"),nAo=o("XLNetLMHeadModel"),sAo=o(" (XLNet model)"),lAo=l(),M1=a("p"),iAo=o("The model is set in evaluation mode by default using "),Gfe=a("code"),dAo=o("model.eval()"),cAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=a("code"),fAo=o("model.train()"),mAo=l(),F(E1.$$.fragment),rOe=l(),Gi=a("h2"),C1=a("a"),Vfe=a("span"),F(fL.$$.fragment),gAo=l(),Xfe=a("span"),hAo=o("AutoModelForCausalLM"),tOe=l(),ko=a("div"),F(mL.$$.fragment),pAo=l(),Oi=a("p"),_Ao=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=a("a"),uAo=o("from_pretrained()"),bAo=o(" class method or the "),KD=a("a"),vAo=o("from_config()"),FAo=o(` class
method.`),TAo=l(),gL=a("p"),MAo=o("This class cannot be instantiated directly using "),zfe=a("code"),EAo=o("__init__()"),CAo=o(" (throws an error)."),wAo=l(),lt=a("div"),F(hL.$$.fragment),AAo=l(),Qfe=a("p"),LAo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yAo=l(),Vi=a("p"),xAo=o(`Note:
Loading a model from its configuration file does `),Wfe=a("strong"),$Ao=o("not"),kAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=a("a"),SAo=o("from_pretrained()"),RAo=o(" to load the model weights."),PAo=l(),F(w1.$$.fragment),BAo=l(),Ke=a("div"),F(pL.$$.fragment),IAo=l(),Hfe=a("p"),NAo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),qAo=l(),Ba=a("p"),jAo=o("The model class to instantiate is selected based on the "),Ufe=a("code"),DAo=o("model_type"),GAo=o(` property of the config object (either
passed as an argument or loaded from `),Jfe=a("code"),OAo=o("pretrained_model_name_or_path"),VAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=a("code"),XAo=o("pretrained_model_name_or_path"),zAo=o(":"),QAo=l(),z=a("ul"),A1=a("li"),Kfe=a("strong"),WAo=o("bart"),HAo=o(" \u2014 "),eG=a("a"),UAo=o("BartForCausalLM"),JAo=o(" (BART model)"),YAo=l(),L1=a("li"),Zfe=a("strong"),KAo=o("bert"),ZAo=o(" \u2014 "),oG=a("a"),eLo=o("BertLMHeadModel"),oLo=o(" (BERT model)"),rLo=l(),y1=a("li"),eme=a("strong"),tLo=o("bert-generation"),aLo=o(" \u2014 "),rG=a("a"),nLo=o("BertGenerationDecoder"),sLo=o(" (Bert Generation model)"),lLo=l(),x1=a("li"),ome=a("strong"),iLo=o("big_bird"),dLo=o(" \u2014 "),tG=a("a"),cLo=o("BigBirdForCausalLM"),fLo=o(" (BigBird model)"),mLo=l(),$1=a("li"),rme=a("strong"),gLo=o("bigbird_pegasus"),hLo=o(" \u2014 "),aG=a("a"),pLo=o("BigBirdPegasusForCausalLM"),_Lo=o(" (BigBird-Pegasus model)"),uLo=l(),k1=a("li"),tme=a("strong"),bLo=o("blenderbot"),vLo=o(" \u2014 "),nG=a("a"),FLo=o("BlenderbotForCausalLM"),TLo=o(" (Blenderbot model)"),MLo=l(),S1=a("li"),ame=a("strong"),ELo=o("blenderbot-small"),CLo=o(" \u2014 "),sG=a("a"),wLo=o("BlenderbotSmallForCausalLM"),ALo=o(" (BlenderbotSmall model)"),LLo=l(),R1=a("li"),nme=a("strong"),yLo=o("bloom"),xLo=o(" \u2014 "),lG=a("a"),$Lo=o("BloomForCausalLM"),kLo=o(" (BLOOM model)"),SLo=l(),P1=a("li"),sme=a("strong"),RLo=o("camembert"),PLo=o(" \u2014 "),iG=a("a"),BLo=o("CamembertForCausalLM"),ILo=o(" (CamemBERT model)"),NLo=l(),B1=a("li"),lme=a("strong"),qLo=o("ctrl"),jLo=o(" \u2014 "),dG=a("a"),DLo=o("CTRLLMHeadModel"),GLo=o(" (CTRL model)"),OLo=l(),I1=a("li"),ime=a("strong"),VLo=o("data2vec-text"),XLo=o(" \u2014 "),cG=a("a"),zLo=o("Data2VecTextForCausalLM"),QLo=o(" (Data2VecText model)"),WLo=l(),N1=a("li"),dme=a("strong"),HLo=o("electra"),ULo=o(" \u2014 "),fG=a("a"),JLo=o("ElectraForCausalLM"),YLo=o(" (ELECTRA model)"),KLo=l(),q1=a("li"),cme=a("strong"),ZLo=o("gpt2"),eyo=o(" \u2014 "),mG=a("a"),oyo=o("GPT2LMHeadModel"),ryo=o(" (OpenAI GPT-2 model)"),tyo=l(),j1=a("li"),fme=a("strong"),ayo=o("gpt_neo"),nyo=o(" \u2014 "),gG=a("a"),syo=o("GPTNeoForCausalLM"),lyo=o(" (GPT Neo model)"),iyo=l(),D1=a("li"),mme=a("strong"),dyo=o("gpt_neox"),cyo=o(" \u2014 "),hG=a("a"),fyo=o("GPTNeoXForCausalLM"),myo=o(" (GPT NeoX model)"),gyo=l(),G1=a("li"),gme=a("strong"),hyo=o("gptj"),pyo=o(" \u2014 "),pG=a("a"),_yo=o("GPTJForCausalLM"),uyo=o(" (GPT-J model)"),byo=l(),O1=a("li"),hme=a("strong"),vyo=o("marian"),Fyo=o(" \u2014 "),_G=a("a"),Tyo=o("MarianForCausalLM"),Myo=o(" (Marian model)"),Eyo=l(),V1=a("li"),pme=a("strong"),Cyo=o("mbart"),wyo=o(" \u2014 "),uG=a("a"),Ayo=o("MBartForCausalLM"),Lyo=o(" (mBART model)"),yyo=l(),X1=a("li"),_me=a("strong"),xyo=o("megatron-bert"),$yo=o(" \u2014 "),bG=a("a"),kyo=o("MegatronBertForCausalLM"),Syo=o(" (Megatron-BERT model)"),Ryo=l(),z1=a("li"),ume=a("strong"),Pyo=o("openai-gpt"),Byo=o(" \u2014 "),vG=a("a"),Iyo=o("OpenAIGPTLMHeadModel"),Nyo=o(" (OpenAI GPT model)"),qyo=l(),Q1=a("li"),bme=a("strong"),jyo=o("opt"),Dyo=o(" \u2014 "),FG=a("a"),Gyo=o("OPTForCausalLM"),Oyo=o(" (OPT model)"),Vyo=l(),W1=a("li"),vme=a("strong"),Xyo=o("pegasus"),zyo=o(" \u2014 "),TG=a("a"),Qyo=o("PegasusForCausalLM"),Wyo=o(" (Pegasus model)"),Hyo=l(),H1=a("li"),Fme=a("strong"),Uyo=o("plbart"),Jyo=o(" \u2014 "),MG=a("a"),Yyo=o("PLBartForCausalLM"),Kyo=o(" (PLBart model)"),Zyo=l(),U1=a("li"),Tme=a("strong"),e9o=o("prophetnet"),o9o=o(" \u2014 "),EG=a("a"),r9o=o("ProphetNetForCausalLM"),t9o=o(" (ProphetNet model)"),a9o=l(),J1=a("li"),Mme=a("strong"),n9o=o("qdqbert"),s9o=o(" \u2014 "),CG=a("a"),l9o=o("QDQBertLMHeadModel"),i9o=o(" (QDQBert model)"),d9o=l(),Y1=a("li"),Eme=a("strong"),c9o=o("reformer"),f9o=o(" \u2014 "),wG=a("a"),m9o=o("ReformerModelWithLMHead"),g9o=o(" (Reformer model)"),h9o=l(),K1=a("li"),Cme=a("strong"),p9o=o("rembert"),_9o=o(" \u2014 "),AG=a("a"),u9o=o("RemBertForCausalLM"),b9o=o(" (RemBERT model)"),v9o=l(),Z1=a("li"),wme=a("strong"),F9o=o("roberta"),T9o=o(" \u2014 "),LG=a("a"),M9o=o("RobertaForCausalLM"),E9o=o(" (RoBERTa model)"),C9o=l(),e2=a("li"),Ame=a("strong"),w9o=o("roformer"),A9o=o(" \u2014 "),yG=a("a"),L9o=o("RoFormerForCausalLM"),y9o=o(" (RoFormer model)"),x9o=l(),o2=a("li"),Lme=a("strong"),$9o=o("speech_to_text_2"),k9o=o(" \u2014 "),xG=a("a"),S9o=o("Speech2Text2ForCausalLM"),R9o=o(" (Speech2Text2 model)"),P9o=l(),r2=a("li"),yme=a("strong"),B9o=o("transfo-xl"),I9o=o(" \u2014 "),$G=a("a"),N9o=o("TransfoXLLMHeadModel"),q9o=o(" (Transformer-XL model)"),j9o=l(),t2=a("li"),xme=a("strong"),D9o=o("trocr"),G9o=o(" \u2014 "),kG=a("a"),O9o=o("TrOCRForCausalLM"),V9o=o(" (TrOCR model)"),X9o=l(),a2=a("li"),$me=a("strong"),z9o=o("xglm"),Q9o=o(" \u2014 "),SG=a("a"),W9o=o("XGLMForCausalLM"),H9o=o(" (XGLM model)"),U9o=l(),n2=a("li"),kme=a("strong"),J9o=o("xlm"),Y9o=o(" \u2014 "),RG=a("a"),K9o=o("XLMWithLMHeadModel"),Z9o=o(" (XLM model)"),exo=l(),s2=a("li"),Sme=a("strong"),oxo=o("xlm-prophetnet"),rxo=o(" \u2014 "),PG=a("a"),txo=o("XLMProphetNetForCausalLM"),axo=o(" (XLM-ProphetNet model)"),nxo=l(),l2=a("li"),Rme=a("strong"),sxo=o("xlm-roberta"),lxo=o(" \u2014 "),BG=a("a"),ixo=o("XLMRobertaForCausalLM"),dxo=o(" (XLM-RoBERTa model)"),cxo=l(),i2=a("li"),Pme=a("strong"),fxo=o("xlm-roberta-xl"),mxo=o(" \u2014 "),IG=a("a"),gxo=o("XLMRobertaXLForCausalLM"),hxo=o(" (XLM-RoBERTa-XL model)"),pxo=l(),d2=a("li"),Bme=a("strong"),_xo=o("xlnet"),uxo=o(" \u2014 "),NG=a("a"),bxo=o("XLNetLMHeadModel"),vxo=o(" (XLNet model)"),Fxo=l(),c2=a("p"),Txo=o("The model is set in evaluation mode by default using "),Ime=a("code"),Mxo=o("model.eval()"),Exo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=a("code"),Cxo=o("model.train()"),wxo=l(),F(f2.$$.fragment),aOe=l(),Xi=a("h2"),m2=a("a"),qme=a("span"),F(_L.$$.fragment),Axo=l(),jme=a("span"),Lxo=o("AutoModelForMaskedLM"),nOe=l(),So=a("div"),F(uL.$$.fragment),yxo=l(),zi=a("p"),xxo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=a("a"),$xo=o("from_pretrained()"),kxo=o(" class method or the "),jG=a("a"),Sxo=o("from_config()"),Rxo=o(` class
method.`),Pxo=l(),bL=a("p"),Bxo=o("This class cannot be instantiated directly using "),Dme=a("code"),Ixo=o("__init__()"),Nxo=o(" (throws an error)."),qxo=l(),it=a("div"),F(vL.$$.fragment),jxo=l(),Gme=a("p"),Dxo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gxo=l(),Qi=a("p"),Oxo=o(`Note:
Loading a model from its configuration file does `),Ome=a("strong"),Vxo=o("not"),Xxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=a("a"),zxo=o("from_pretrained()"),Qxo=o(" to load the model weights."),Wxo=l(),F(g2.$$.fragment),Hxo=l(),Ze=a("div"),F(FL.$$.fragment),Uxo=l(),Vme=a("p"),Jxo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Yxo=l(),Ia=a("p"),Kxo=o("The model class to instantiate is selected based on the "),Xme=a("code"),Zxo=o("model_type"),e$o=o(` property of the config object (either
passed as an argument or loaded from `),zme=a("code"),o$o=o("pretrained_model_name_or_path"),r$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=a("code"),t$o=o("pretrained_model_name_or_path"),a$o=o(":"),n$o=l(),Q=a("ul"),h2=a("li"),Wme=a("strong"),s$o=o("albert"),l$o=o(" \u2014 "),GG=a("a"),i$o=o("AlbertForMaskedLM"),d$o=o(" (ALBERT model)"),c$o=l(),p2=a("li"),Hme=a("strong"),f$o=o("bart"),m$o=o(" \u2014 "),OG=a("a"),g$o=o("BartForConditionalGeneration"),h$o=o(" (BART model)"),p$o=l(),_2=a("li"),Ume=a("strong"),_$o=o("bert"),u$o=o(" \u2014 "),VG=a("a"),b$o=o("BertForMaskedLM"),v$o=o(" (BERT model)"),F$o=l(),u2=a("li"),Jme=a("strong"),T$o=o("big_bird"),M$o=o(" \u2014 "),XG=a("a"),E$o=o("BigBirdForMaskedLM"),C$o=o(" (BigBird model)"),w$o=l(),b2=a("li"),Yme=a("strong"),A$o=o("camembert"),L$o=o(" \u2014 "),zG=a("a"),y$o=o("CamembertForMaskedLM"),x$o=o(" (CamemBERT model)"),$$o=l(),v2=a("li"),Kme=a("strong"),k$o=o("convbert"),S$o=o(" \u2014 "),QG=a("a"),R$o=o("ConvBertForMaskedLM"),P$o=o(" (ConvBERT model)"),B$o=l(),F2=a("li"),Zme=a("strong"),I$o=o("data2vec-text"),N$o=o(" \u2014 "),WG=a("a"),q$o=o("Data2VecTextForMaskedLM"),j$o=o(" (Data2VecText model)"),D$o=l(),T2=a("li"),ege=a("strong"),G$o=o("deberta"),O$o=o(" \u2014 "),HG=a("a"),V$o=o("DebertaForMaskedLM"),X$o=o(" (DeBERTa model)"),z$o=l(),M2=a("li"),oge=a("strong"),Q$o=o("deberta-v2"),W$o=o(" \u2014 "),UG=a("a"),H$o=o("DebertaV2ForMaskedLM"),U$o=o(" (DeBERTa-v2 model)"),J$o=l(),E2=a("li"),rge=a("strong"),Y$o=o("distilbert"),K$o=o(" \u2014 "),JG=a("a"),Z$o=o("DistilBertForMaskedLM"),eko=o(" (DistilBERT model)"),oko=l(),C2=a("li"),tge=a("strong"),rko=o("electra"),tko=o(" \u2014 "),YG=a("a"),ako=o("ElectraForMaskedLM"),nko=o(" (ELECTRA model)"),sko=l(),w2=a("li"),age=a("strong"),lko=o("flaubert"),iko=o(" \u2014 "),KG=a("a"),dko=o("FlaubertWithLMHeadModel"),cko=o(" (FlauBERT model)"),fko=l(),A2=a("li"),nge=a("strong"),mko=o("fnet"),gko=o(" \u2014 "),ZG=a("a"),hko=o("FNetForMaskedLM"),pko=o(" (FNet model)"),_ko=l(),L2=a("li"),sge=a("strong"),uko=o("funnel"),bko=o(" \u2014 "),eO=a("a"),vko=o("FunnelForMaskedLM"),Fko=o(" (Funnel Transformer model)"),Tko=l(),y2=a("li"),lge=a("strong"),Mko=o("ibert"),Eko=o(" \u2014 "),oO=a("a"),Cko=o("IBertForMaskedLM"),wko=o(" (I-BERT model)"),Ako=l(),x2=a("li"),ige=a("strong"),Lko=o("layoutlm"),yko=o(" \u2014 "),rO=a("a"),xko=o("LayoutLMForMaskedLM"),$ko=o(" (LayoutLM model)"),kko=l(),$2=a("li"),dge=a("strong"),Sko=o("longformer"),Rko=o(" \u2014 "),tO=a("a"),Pko=o("LongformerForMaskedLM"),Bko=o(" (Longformer model)"),Iko=l(),k2=a("li"),cge=a("strong"),Nko=o("luke"),qko=o(" \u2014 "),aO=a("a"),jko=o("LukeForMaskedLM"),Dko=o(" (LUKE model)"),Gko=l(),S2=a("li"),fge=a("strong"),Oko=o("mbart"),Vko=o(" \u2014 "),nO=a("a"),Xko=o("MBartForConditionalGeneration"),zko=o(" (mBART model)"),Qko=l(),R2=a("li"),mge=a("strong"),Wko=o("megatron-bert"),Hko=o(" \u2014 "),sO=a("a"),Uko=o("MegatronBertForMaskedLM"),Jko=o(" (Megatron-BERT model)"),Yko=l(),P2=a("li"),gge=a("strong"),Kko=o("mobilebert"),Zko=o(" \u2014 "),lO=a("a"),eSo=o("MobileBertForMaskedLM"),oSo=o(" (MobileBERT model)"),rSo=l(),B2=a("li"),hge=a("strong"),tSo=o("mpnet"),aSo=o(" \u2014 "),iO=a("a"),nSo=o("MPNetForMaskedLM"),sSo=o(" (MPNet model)"),lSo=l(),I2=a("li"),pge=a("strong"),iSo=o("nezha"),dSo=o(" \u2014 "),dO=a("a"),cSo=o("NezhaForMaskedLM"),fSo=o(" (Nezha model)"),mSo=l(),N2=a("li"),_ge=a("strong"),gSo=o("nystromformer"),hSo=o(" \u2014 "),cO=a("a"),pSo=o("NystromformerForMaskedLM"),_So=o(" (Nystr\xF6mformer model)"),uSo=l(),q2=a("li"),uge=a("strong"),bSo=o("perceiver"),vSo=o(" \u2014 "),fO=a("a"),FSo=o("PerceiverForMaskedLM"),TSo=o(" (Perceiver model)"),MSo=l(),j2=a("li"),bge=a("strong"),ESo=o("qdqbert"),CSo=o(" \u2014 "),mO=a("a"),wSo=o("QDQBertForMaskedLM"),ASo=o(" (QDQBert model)"),LSo=l(),D2=a("li"),vge=a("strong"),ySo=o("reformer"),xSo=o(" \u2014 "),gO=a("a"),$So=o("ReformerForMaskedLM"),kSo=o(" (Reformer model)"),SSo=l(),G2=a("li"),Fge=a("strong"),RSo=o("rembert"),PSo=o(" \u2014 "),hO=a("a"),BSo=o("RemBertForMaskedLM"),ISo=o(" (RemBERT model)"),NSo=l(),O2=a("li"),Tge=a("strong"),qSo=o("roberta"),jSo=o(" \u2014 "),pO=a("a"),DSo=o("RobertaForMaskedLM"),GSo=o(" (RoBERTa model)"),OSo=l(),V2=a("li"),Mge=a("strong"),VSo=o("roformer"),XSo=o(" \u2014 "),_O=a("a"),zSo=o("RoFormerForMaskedLM"),QSo=o(" (RoFormer model)"),WSo=l(),X2=a("li"),Ege=a("strong"),HSo=o("squeezebert"),USo=o(" \u2014 "),uO=a("a"),JSo=o("SqueezeBertForMaskedLM"),YSo=o(" (SqueezeBERT model)"),KSo=l(),z2=a("li"),Cge=a("strong"),ZSo=o("tapas"),eRo=o(" \u2014 "),bO=a("a"),oRo=o("TapasForMaskedLM"),rRo=o(" (TAPAS model)"),tRo=l(),Q2=a("li"),wge=a("strong"),aRo=o("wav2vec2"),nRo=o(" \u2014 "),Age=a("code"),sRo=o("Wav2Vec2ForMaskedLM"),lRo=o(" (Wav2Vec2 model)"),iRo=l(),W2=a("li"),Lge=a("strong"),dRo=o("xlm"),cRo=o(" \u2014 "),vO=a("a"),fRo=o("XLMWithLMHeadModel"),mRo=o(" (XLM model)"),gRo=l(),H2=a("li"),yge=a("strong"),hRo=o("xlm-roberta"),pRo=o(" \u2014 "),FO=a("a"),_Ro=o("XLMRobertaForMaskedLM"),uRo=o(" (XLM-RoBERTa model)"),bRo=l(),U2=a("li"),xge=a("strong"),vRo=o("xlm-roberta-xl"),FRo=o(" \u2014 "),TO=a("a"),TRo=o("XLMRobertaXLForMaskedLM"),MRo=o(" (XLM-RoBERTa-XL model)"),ERo=l(),J2=a("li"),$ge=a("strong"),CRo=o("yoso"),wRo=o(" \u2014 "),MO=a("a"),ARo=o("YosoForMaskedLM"),LRo=o(" (YOSO model)"),yRo=l(),Y2=a("p"),xRo=o("The model is set in evaluation mode by default using "),kge=a("code"),$Ro=o("model.eval()"),kRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=a("code"),SRo=o("model.train()"),RRo=l(),F(K2.$$.fragment),sOe=l(),Wi=a("h2"),Z2=a("a"),Rge=a("span"),F(TL.$$.fragment),PRo=l(),Pge=a("span"),BRo=o("AutoModelForSeq2SeqLM"),lOe=l(),Ro=a("div"),F(ML.$$.fragment),IRo=l(),Hi=a("p"),NRo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=a("a"),qRo=o("from_pretrained()"),jRo=o(" class method or the "),CO=a("a"),DRo=o("from_config()"),GRo=o(` class
method.`),ORo=l(),EL=a("p"),VRo=o("This class cannot be instantiated directly using "),Bge=a("code"),XRo=o("__init__()"),zRo=o(" (throws an error)."),QRo=l(),dt=a("div"),F(CL.$$.fragment),WRo=l(),Ige=a("p"),HRo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),URo=l(),Ui=a("p"),JRo=o(`Note:
Loading a model from its configuration file does `),Nge=a("strong"),YRo=o("not"),KRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=a("a"),ZRo=o("from_pretrained()"),ePo=o(" to load the model weights."),oPo=l(),F(eb.$$.fragment),rPo=l(),eo=a("div"),F(wL.$$.fragment),tPo=l(),qge=a("p"),aPo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nPo=l(),Na=a("p"),sPo=o("The model class to instantiate is selected based on the "),jge=a("code"),lPo=o("model_type"),iPo=o(` property of the config object (either
passed as an argument or loaded from `),Dge=a("code"),dPo=o("pretrained_model_name_or_path"),cPo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=a("code"),fPo=o("pretrained_model_name_or_path"),mPo=o(":"),gPo=l(),pe=a("ul"),ob=a("li"),Oge=a("strong"),hPo=o("bart"),pPo=o(" \u2014 "),AO=a("a"),_Po=o("BartForConditionalGeneration"),uPo=o(" (BART model)"),bPo=l(),rb=a("li"),Vge=a("strong"),vPo=o("bigbird_pegasus"),FPo=o(" \u2014 "),LO=a("a"),TPo=o("BigBirdPegasusForConditionalGeneration"),MPo=o(" (BigBird-Pegasus model)"),EPo=l(),tb=a("li"),Xge=a("strong"),CPo=o("blenderbot"),wPo=o(" \u2014 "),yO=a("a"),APo=o("BlenderbotForConditionalGeneration"),LPo=o(" (Blenderbot model)"),yPo=l(),ab=a("li"),zge=a("strong"),xPo=o("blenderbot-small"),$Po=o(" \u2014 "),xO=a("a"),kPo=o("BlenderbotSmallForConditionalGeneration"),SPo=o(" (BlenderbotSmall model)"),RPo=l(),nb=a("li"),Qge=a("strong"),PPo=o("encoder-decoder"),BPo=o(" \u2014 "),$O=a("a"),IPo=o("EncoderDecoderModel"),NPo=o(" (Encoder decoder model)"),qPo=l(),sb=a("li"),Wge=a("strong"),jPo=o("fsmt"),DPo=o(" \u2014 "),kO=a("a"),GPo=o("FSMTForConditionalGeneration"),OPo=o(" (FairSeq Machine-Translation model)"),VPo=l(),lb=a("li"),Hge=a("strong"),XPo=o("led"),zPo=o(" \u2014 "),SO=a("a"),QPo=o("LEDForConditionalGeneration"),WPo=o(" (LED model)"),HPo=l(),ib=a("li"),Uge=a("strong"),UPo=o("longt5"),JPo=o(" \u2014 "),RO=a("a"),YPo=o("LongT5ForConditionalGeneration"),KPo=o(" (LongT5 model)"),ZPo=l(),db=a("li"),Jge=a("strong"),eBo=o("m2m_100"),oBo=o(" \u2014 "),PO=a("a"),rBo=o("M2M100ForConditionalGeneration"),tBo=o(" (M2M100 model)"),aBo=l(),cb=a("li"),Yge=a("strong"),nBo=o("marian"),sBo=o(" \u2014 "),BO=a("a"),lBo=o("MarianMTModel"),iBo=o(" (Marian model)"),dBo=l(),fb=a("li"),Kge=a("strong"),cBo=o("mbart"),fBo=o(" \u2014 "),IO=a("a"),mBo=o("MBartForConditionalGeneration"),gBo=o(" (mBART model)"),hBo=l(),mb=a("li"),Zge=a("strong"),pBo=o("mt5"),_Bo=o(" \u2014 "),NO=a("a"),uBo=o("MT5ForConditionalGeneration"),bBo=o(" (MT5 model)"),vBo=l(),gb=a("li"),ehe=a("strong"),FBo=o("pegasus"),TBo=o(" \u2014 "),qO=a("a"),MBo=o("PegasusForConditionalGeneration"),EBo=o(" (Pegasus model)"),CBo=l(),hb=a("li"),ohe=a("strong"),wBo=o("plbart"),ABo=o(" \u2014 "),jO=a("a"),LBo=o("PLBartForConditionalGeneration"),yBo=o(" (PLBart model)"),xBo=l(),pb=a("li"),rhe=a("strong"),$Bo=o("prophetnet"),kBo=o(" \u2014 "),DO=a("a"),SBo=o("ProphetNetForConditionalGeneration"),RBo=o(" (ProphetNet model)"),PBo=l(),_b=a("li"),the=a("strong"),BBo=o("t5"),IBo=o(" \u2014 "),GO=a("a"),NBo=o("T5ForConditionalGeneration"),qBo=o(" (T5 model)"),jBo=l(),ub=a("li"),ahe=a("strong"),DBo=o("xlm-prophetnet"),GBo=o(" \u2014 "),OO=a("a"),OBo=o("XLMProphetNetForConditionalGeneration"),VBo=o(" (XLM-ProphetNet model)"),XBo=l(),bb=a("p"),zBo=o("The model is set in evaluation mode by default using "),nhe=a("code"),QBo=o("model.eval()"),WBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=a("code"),HBo=o("model.train()"),UBo=l(),F(vb.$$.fragment),iOe=l(),Ji=a("h2"),Fb=a("a"),lhe=a("span"),F(AL.$$.fragment),JBo=l(),ihe=a("span"),YBo=o("AutoModelForSequenceClassification"),dOe=l(),Po=a("div"),F(LL.$$.fragment),KBo=l(),Yi=a("p"),ZBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=a("a"),eIo=o("from_pretrained()"),oIo=o(" class method or the "),XO=a("a"),rIo=o("from_config()"),tIo=o(` class
method.`),aIo=l(),yL=a("p"),nIo=o("This class cannot be instantiated directly using "),dhe=a("code"),sIo=o("__init__()"),lIo=o(" (throws an error)."),iIo=l(),ct=a("div"),F(xL.$$.fragment),dIo=l(),che=a("p"),cIo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),fIo=l(),Ki=a("p"),mIo=o(`Note:
Loading a model from its configuration file does `),fhe=a("strong"),gIo=o("not"),hIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=a("a"),pIo=o("from_pretrained()"),_Io=o(" to load the model weights."),uIo=l(),F(Tb.$$.fragment),bIo=l(),oo=a("div"),F($L.$$.fragment),vIo=l(),mhe=a("p"),FIo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),TIo=l(),qa=a("p"),MIo=o("The model class to instantiate is selected based on the "),ghe=a("code"),EIo=o("model_type"),CIo=o(` property of the config object (either
passed as an argument or loaded from `),hhe=a("code"),wIo=o("pretrained_model_name_or_path"),AIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=a("code"),LIo=o("pretrained_model_name_or_path"),yIo=o(":"),xIo=l(),N=a("ul"),Mb=a("li"),_he=a("strong"),$Io=o("albert"),kIo=o(" \u2014 "),QO=a("a"),SIo=o("AlbertForSequenceClassification"),RIo=o(" (ALBERT model)"),PIo=l(),Eb=a("li"),uhe=a("strong"),BIo=o("bart"),IIo=o(" \u2014 "),WO=a("a"),NIo=o("BartForSequenceClassification"),qIo=o(" (BART model)"),jIo=l(),Cb=a("li"),bhe=a("strong"),DIo=o("bert"),GIo=o(" \u2014 "),HO=a("a"),OIo=o("BertForSequenceClassification"),VIo=o(" (BERT model)"),XIo=l(),wb=a("li"),vhe=a("strong"),zIo=o("big_bird"),QIo=o(" \u2014 "),UO=a("a"),WIo=o("BigBirdForSequenceClassification"),HIo=o(" (BigBird model)"),UIo=l(),Ab=a("li"),Fhe=a("strong"),JIo=o("bigbird_pegasus"),YIo=o(" \u2014 "),JO=a("a"),KIo=o("BigBirdPegasusForSequenceClassification"),ZIo=o(" (BigBird-Pegasus model)"),eNo=l(),Lb=a("li"),The=a("strong"),oNo=o("bloom"),rNo=o(" \u2014 "),YO=a("a"),tNo=o("BloomForSequenceClassification"),aNo=o(" (BLOOM model)"),nNo=l(),yb=a("li"),Mhe=a("strong"),sNo=o("camembert"),lNo=o(" \u2014 "),KO=a("a"),iNo=o("CamembertForSequenceClassification"),dNo=o(" (CamemBERT model)"),cNo=l(),xb=a("li"),Ehe=a("strong"),fNo=o("canine"),mNo=o(" \u2014 "),ZO=a("a"),gNo=o("CanineForSequenceClassification"),hNo=o(" (CANINE model)"),pNo=l(),$b=a("li"),Che=a("strong"),_No=o("convbert"),uNo=o(" \u2014 "),eV=a("a"),bNo=o("ConvBertForSequenceClassification"),vNo=o(" (ConvBERT model)"),FNo=l(),kb=a("li"),whe=a("strong"),TNo=o("ctrl"),MNo=o(" \u2014 "),oV=a("a"),ENo=o("CTRLForSequenceClassification"),CNo=o(" (CTRL model)"),wNo=l(),Sb=a("li"),Ahe=a("strong"),ANo=o("data2vec-text"),LNo=o(" \u2014 "),rV=a("a"),yNo=o("Data2VecTextForSequenceClassification"),xNo=o(" (Data2VecText model)"),$No=l(),Rb=a("li"),Lhe=a("strong"),kNo=o("deberta"),SNo=o(" \u2014 "),tV=a("a"),RNo=o("DebertaForSequenceClassification"),PNo=o(" (DeBERTa model)"),BNo=l(),Pb=a("li"),yhe=a("strong"),INo=o("deberta-v2"),NNo=o(" \u2014 "),aV=a("a"),qNo=o("DebertaV2ForSequenceClassification"),jNo=o(" (DeBERTa-v2 model)"),DNo=l(),Bb=a("li"),xhe=a("strong"),GNo=o("distilbert"),ONo=o(" \u2014 "),nV=a("a"),VNo=o("DistilBertForSequenceClassification"),XNo=o(" (DistilBERT model)"),zNo=l(),Ib=a("li"),$he=a("strong"),QNo=o("electra"),WNo=o(" \u2014 "),sV=a("a"),HNo=o("ElectraForSequenceClassification"),UNo=o(" (ELECTRA model)"),JNo=l(),Nb=a("li"),khe=a("strong"),YNo=o("flaubert"),KNo=o(" \u2014 "),lV=a("a"),ZNo=o("FlaubertForSequenceClassification"),eqo=o(" (FlauBERT model)"),oqo=l(),qb=a("li"),She=a("strong"),rqo=o("fnet"),tqo=o(" \u2014 "),iV=a("a"),aqo=o("FNetForSequenceClassification"),nqo=o(" (FNet model)"),sqo=l(),jb=a("li"),Rhe=a("strong"),lqo=o("funnel"),iqo=o(" \u2014 "),dV=a("a"),dqo=o("FunnelForSequenceClassification"),cqo=o(" (Funnel Transformer model)"),fqo=l(),Db=a("li"),Phe=a("strong"),mqo=o("gpt2"),gqo=o(" \u2014 "),cV=a("a"),hqo=o("GPT2ForSequenceClassification"),pqo=o(" (OpenAI GPT-2 model)"),_qo=l(),Gb=a("li"),Bhe=a("strong"),uqo=o("gpt_neo"),bqo=o(" \u2014 "),fV=a("a"),vqo=o("GPTNeoForSequenceClassification"),Fqo=o(" (GPT Neo model)"),Tqo=l(),Ob=a("li"),Ihe=a("strong"),Mqo=o("gptj"),Eqo=o(" \u2014 "),mV=a("a"),Cqo=o("GPTJForSequenceClassification"),wqo=o(" (GPT-J model)"),Aqo=l(),Vb=a("li"),Nhe=a("strong"),Lqo=o("ibert"),yqo=o(" \u2014 "),gV=a("a"),xqo=o("IBertForSequenceClassification"),$qo=o(" (I-BERT model)"),kqo=l(),Xb=a("li"),qhe=a("strong"),Sqo=o("layoutlm"),Rqo=o(" \u2014 "),hV=a("a"),Pqo=o("LayoutLMForSequenceClassification"),Bqo=o(" (LayoutLM model)"),Iqo=l(),zb=a("li"),jhe=a("strong"),Nqo=o("layoutlmv2"),qqo=o(" \u2014 "),pV=a("a"),jqo=o("LayoutLMv2ForSequenceClassification"),Dqo=o(" (LayoutLMv2 model)"),Gqo=l(),Qb=a("li"),Dhe=a("strong"),Oqo=o("layoutlmv3"),Vqo=o(" \u2014 "),_V=a("a"),Xqo=o("LayoutLMv3ForSequenceClassification"),zqo=o(" (LayoutLMv3 model)"),Qqo=l(),Wb=a("li"),Ghe=a("strong"),Wqo=o("led"),Hqo=o(" \u2014 "),uV=a("a"),Uqo=o("LEDForSequenceClassification"),Jqo=o(" (LED model)"),Yqo=l(),Hb=a("li"),Ohe=a("strong"),Kqo=o("longformer"),Zqo=o(" \u2014 "),bV=a("a"),ejo=o("LongformerForSequenceClassification"),ojo=o(" (Longformer model)"),rjo=l(),Ub=a("li"),Vhe=a("strong"),tjo=o("mbart"),ajo=o(" \u2014 "),vV=a("a"),njo=o("MBartForSequenceClassification"),sjo=o(" (mBART model)"),ljo=l(),Jb=a("li"),Xhe=a("strong"),ijo=o("megatron-bert"),djo=o(" \u2014 "),FV=a("a"),cjo=o("MegatronBertForSequenceClassification"),fjo=o(" (Megatron-BERT model)"),mjo=l(),Yb=a("li"),zhe=a("strong"),gjo=o("mobilebert"),hjo=o(" \u2014 "),TV=a("a"),pjo=o("MobileBertForSequenceClassification"),_jo=o(" (MobileBERT model)"),ujo=l(),Kb=a("li"),Qhe=a("strong"),bjo=o("mpnet"),vjo=o(" \u2014 "),MV=a("a"),Fjo=o("MPNetForSequenceClassification"),Tjo=o(" (MPNet model)"),Mjo=l(),Zb=a("li"),Whe=a("strong"),Ejo=o("nezha"),Cjo=o(" \u2014 "),EV=a("a"),wjo=o("NezhaForSequenceClassification"),Ajo=o(" (Nezha model)"),Ljo=l(),e4=a("li"),Hhe=a("strong"),yjo=o("nystromformer"),xjo=o(" \u2014 "),CV=a("a"),$jo=o("NystromformerForSequenceClassification"),kjo=o(" (Nystr\xF6mformer model)"),Sjo=l(),o4=a("li"),Uhe=a("strong"),Rjo=o("openai-gpt"),Pjo=o(" \u2014 "),wV=a("a"),Bjo=o("OpenAIGPTForSequenceClassification"),Ijo=o(" (OpenAI GPT model)"),Njo=l(),r4=a("li"),Jhe=a("strong"),qjo=o("perceiver"),jjo=o(" \u2014 "),AV=a("a"),Djo=o("PerceiverForSequenceClassification"),Gjo=o(" (Perceiver model)"),Ojo=l(),t4=a("li"),Yhe=a("strong"),Vjo=o("plbart"),Xjo=o(" \u2014 "),LV=a("a"),zjo=o("PLBartForSequenceClassification"),Qjo=o(" (PLBart model)"),Wjo=l(),a4=a("li"),Khe=a("strong"),Hjo=o("qdqbert"),Ujo=o(" \u2014 "),yV=a("a"),Jjo=o("QDQBertForSequenceClassification"),Yjo=o(" (QDQBert model)"),Kjo=l(),n4=a("li"),Zhe=a("strong"),Zjo=o("reformer"),eDo=o(" \u2014 "),xV=a("a"),oDo=o("ReformerForSequenceClassification"),rDo=o(" (Reformer model)"),tDo=l(),s4=a("li"),epe=a("strong"),aDo=o("rembert"),nDo=o(" \u2014 "),$V=a("a"),sDo=o("RemBertForSequenceClassification"),lDo=o(" (RemBERT model)"),iDo=l(),l4=a("li"),ope=a("strong"),dDo=o("roberta"),cDo=o(" \u2014 "),kV=a("a"),fDo=o("RobertaForSequenceClassification"),mDo=o(" (RoBERTa model)"),gDo=l(),i4=a("li"),rpe=a("strong"),hDo=o("roformer"),pDo=o(" \u2014 "),SV=a("a"),_Do=o("RoFormerForSequenceClassification"),uDo=o(" (RoFormer model)"),bDo=l(),d4=a("li"),tpe=a("strong"),vDo=o("squeezebert"),FDo=o(" \u2014 "),RV=a("a"),TDo=o("SqueezeBertForSequenceClassification"),MDo=o(" (SqueezeBERT model)"),EDo=l(),c4=a("li"),ape=a("strong"),CDo=o("tapas"),wDo=o(" \u2014 "),PV=a("a"),ADo=o("TapasForSequenceClassification"),LDo=o(" (TAPAS model)"),yDo=l(),f4=a("li"),npe=a("strong"),xDo=o("transfo-xl"),$Do=o(" \u2014 "),BV=a("a"),kDo=o("TransfoXLForSequenceClassification"),SDo=o(" (Transformer-XL model)"),RDo=l(),m4=a("li"),spe=a("strong"),PDo=o("xlm"),BDo=o(" \u2014 "),IV=a("a"),IDo=o("XLMForSequenceClassification"),NDo=o(" (XLM model)"),qDo=l(),g4=a("li"),lpe=a("strong"),jDo=o("xlm-roberta"),DDo=o(" \u2014 "),NV=a("a"),GDo=o("XLMRobertaForSequenceClassification"),ODo=o(" (XLM-RoBERTa model)"),VDo=l(),h4=a("li"),ipe=a("strong"),XDo=o("xlm-roberta-xl"),zDo=o(" \u2014 "),qV=a("a"),QDo=o("XLMRobertaXLForSequenceClassification"),WDo=o(" (XLM-RoBERTa-XL model)"),HDo=l(),p4=a("li"),dpe=a("strong"),UDo=o("xlnet"),JDo=o(" \u2014 "),jV=a("a"),YDo=o("XLNetForSequenceClassification"),KDo=o(" (XLNet model)"),ZDo=l(),_4=a("li"),cpe=a("strong"),eGo=o("yoso"),oGo=o(" \u2014 "),DV=a("a"),rGo=o("YosoForSequenceClassification"),tGo=o(" (YOSO model)"),aGo=l(),u4=a("p"),nGo=o("The model is set in evaluation mode by default using "),fpe=a("code"),sGo=o("model.eval()"),lGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mpe=a("code"),iGo=o("model.train()"),dGo=l(),F(b4.$$.fragment),cOe=l(),Zi=a("h2"),v4=a("a"),gpe=a("span"),F(kL.$$.fragment),cGo=l(),hpe=a("span"),fGo=o("AutoModelForMultipleChoice"),fOe=l(),Bo=a("div"),F(SL.$$.fragment),mGo=l(),ed=a("p"),gGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=a("a"),hGo=o("from_pretrained()"),pGo=o(" class method or the "),OV=a("a"),_Go=o("from_config()"),uGo=o(` class
method.`),bGo=l(),RL=a("p"),vGo=o("This class cannot be instantiated directly using "),ppe=a("code"),FGo=o("__init__()"),TGo=o(" (throws an error)."),MGo=l(),ft=a("div"),F(PL.$$.fragment),EGo=l(),_pe=a("p"),CGo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wGo=l(),od=a("p"),AGo=o(`Note:
Loading a model from its configuration file does `),upe=a("strong"),LGo=o("not"),yGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=a("a"),xGo=o("from_pretrained()"),$Go=o(" to load the model weights."),kGo=l(),F(F4.$$.fragment),SGo=l(),ro=a("div"),F(BL.$$.fragment),RGo=l(),bpe=a("p"),PGo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),BGo=l(),ja=a("p"),IGo=o("The model class to instantiate is selected based on the "),vpe=a("code"),NGo=o("model_type"),qGo=o(` property of the config object (either
passed as an argument or loaded from `),Fpe=a("code"),jGo=o("pretrained_model_name_or_path"),DGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tpe=a("code"),GGo=o("pretrained_model_name_or_path"),OGo=o(":"),VGo=l(),Z=a("ul"),T4=a("li"),Mpe=a("strong"),XGo=o("albert"),zGo=o(" \u2014 "),XV=a("a"),QGo=o("AlbertForMultipleChoice"),WGo=o(" (ALBERT model)"),HGo=l(),M4=a("li"),Epe=a("strong"),UGo=o("bert"),JGo=o(" \u2014 "),zV=a("a"),YGo=o("BertForMultipleChoice"),KGo=o(" (BERT model)"),ZGo=l(),E4=a("li"),Cpe=a("strong"),eOo=o("big_bird"),oOo=o(" \u2014 "),QV=a("a"),rOo=o("BigBirdForMultipleChoice"),tOo=o(" (BigBird model)"),aOo=l(),C4=a("li"),wpe=a("strong"),nOo=o("camembert"),sOo=o(" \u2014 "),WV=a("a"),lOo=o("CamembertForMultipleChoice"),iOo=o(" (CamemBERT model)"),dOo=l(),w4=a("li"),Ape=a("strong"),cOo=o("canine"),fOo=o(" \u2014 "),HV=a("a"),mOo=o("CanineForMultipleChoice"),gOo=o(" (CANINE model)"),hOo=l(),A4=a("li"),Lpe=a("strong"),pOo=o("convbert"),_Oo=o(" \u2014 "),UV=a("a"),uOo=o("ConvBertForMultipleChoice"),bOo=o(" (ConvBERT model)"),vOo=l(),L4=a("li"),ype=a("strong"),FOo=o("data2vec-text"),TOo=o(" \u2014 "),JV=a("a"),MOo=o("Data2VecTextForMultipleChoice"),EOo=o(" (Data2VecText model)"),COo=l(),y4=a("li"),xpe=a("strong"),wOo=o("deberta-v2"),AOo=o(" \u2014 "),YV=a("a"),LOo=o("DebertaV2ForMultipleChoice"),yOo=o(" (DeBERTa-v2 model)"),xOo=l(),x4=a("li"),$pe=a("strong"),$Oo=o("distilbert"),kOo=o(" \u2014 "),KV=a("a"),SOo=o("DistilBertForMultipleChoice"),ROo=o(" (DistilBERT model)"),POo=l(),$4=a("li"),kpe=a("strong"),BOo=o("electra"),IOo=o(" \u2014 "),ZV=a("a"),NOo=o("ElectraForMultipleChoice"),qOo=o(" (ELECTRA model)"),jOo=l(),k4=a("li"),Spe=a("strong"),DOo=o("flaubert"),GOo=o(" \u2014 "),eX=a("a"),OOo=o("FlaubertForMultipleChoice"),VOo=o(" (FlauBERT model)"),XOo=l(),S4=a("li"),Rpe=a("strong"),zOo=o("fnet"),QOo=o(" \u2014 "),oX=a("a"),WOo=o("FNetForMultipleChoice"),HOo=o(" (FNet model)"),UOo=l(),R4=a("li"),Ppe=a("strong"),JOo=o("funnel"),YOo=o(" \u2014 "),rX=a("a"),KOo=o("FunnelForMultipleChoice"),ZOo=o(" (Funnel Transformer model)"),eVo=l(),P4=a("li"),Bpe=a("strong"),oVo=o("ibert"),rVo=o(" \u2014 "),tX=a("a"),tVo=o("IBertForMultipleChoice"),aVo=o(" (I-BERT model)"),nVo=l(),B4=a("li"),Ipe=a("strong"),sVo=o("longformer"),lVo=o(" \u2014 "),aX=a("a"),iVo=o("LongformerForMultipleChoice"),dVo=o(" (Longformer model)"),cVo=l(),I4=a("li"),Npe=a("strong"),fVo=o("megatron-bert"),mVo=o(" \u2014 "),nX=a("a"),gVo=o("MegatronBertForMultipleChoice"),hVo=o(" (Megatron-BERT model)"),pVo=l(),N4=a("li"),qpe=a("strong"),_Vo=o("mobilebert"),uVo=o(" \u2014 "),sX=a("a"),bVo=o("MobileBertForMultipleChoice"),vVo=o(" (MobileBERT model)"),FVo=l(),q4=a("li"),jpe=a("strong"),TVo=o("mpnet"),MVo=o(" \u2014 "),lX=a("a"),EVo=o("MPNetForMultipleChoice"),CVo=o(" (MPNet model)"),wVo=l(),j4=a("li"),Dpe=a("strong"),AVo=o("nezha"),LVo=o(" \u2014 "),iX=a("a"),yVo=o("NezhaForMultipleChoice"),xVo=o(" (Nezha model)"),$Vo=l(),D4=a("li"),Gpe=a("strong"),kVo=o("nystromformer"),SVo=o(" \u2014 "),dX=a("a"),RVo=o("NystromformerForMultipleChoice"),PVo=o(" (Nystr\xF6mformer model)"),BVo=l(),G4=a("li"),Ope=a("strong"),IVo=o("qdqbert"),NVo=o(" \u2014 "),cX=a("a"),qVo=o("QDQBertForMultipleChoice"),jVo=o(" (QDQBert model)"),DVo=l(),O4=a("li"),Vpe=a("strong"),GVo=o("rembert"),OVo=o(" \u2014 "),fX=a("a"),VVo=o("RemBertForMultipleChoice"),XVo=o(" (RemBERT model)"),zVo=l(),V4=a("li"),Xpe=a("strong"),QVo=o("roberta"),WVo=o(" \u2014 "),mX=a("a"),HVo=o("RobertaForMultipleChoice"),UVo=o(" (RoBERTa model)"),JVo=l(),X4=a("li"),zpe=a("strong"),YVo=o("roformer"),KVo=o(" \u2014 "),gX=a("a"),ZVo=o("RoFormerForMultipleChoice"),eXo=o(" (RoFormer model)"),oXo=l(),z4=a("li"),Qpe=a("strong"),rXo=o("squeezebert"),tXo=o(" \u2014 "),hX=a("a"),aXo=o("SqueezeBertForMultipleChoice"),nXo=o(" (SqueezeBERT model)"),sXo=l(),Q4=a("li"),Wpe=a("strong"),lXo=o("xlm"),iXo=o(" \u2014 "),pX=a("a"),dXo=o("XLMForMultipleChoice"),cXo=o(" (XLM model)"),fXo=l(),W4=a("li"),Hpe=a("strong"),mXo=o("xlm-roberta"),gXo=o(" \u2014 "),_X=a("a"),hXo=o("XLMRobertaForMultipleChoice"),pXo=o(" (XLM-RoBERTa model)"),_Xo=l(),H4=a("li"),Upe=a("strong"),uXo=o("xlm-roberta-xl"),bXo=o(" \u2014 "),uX=a("a"),vXo=o("XLMRobertaXLForMultipleChoice"),FXo=o(" (XLM-RoBERTa-XL model)"),TXo=l(),U4=a("li"),Jpe=a("strong"),MXo=o("xlnet"),EXo=o(" \u2014 "),bX=a("a"),CXo=o("XLNetForMultipleChoice"),wXo=o(" (XLNet model)"),AXo=l(),J4=a("li"),Ype=a("strong"),LXo=o("yoso"),yXo=o(" \u2014 "),vX=a("a"),xXo=o("YosoForMultipleChoice"),$Xo=o(" (YOSO model)"),kXo=l(),Y4=a("p"),SXo=o("The model is set in evaluation mode by default using "),Kpe=a("code"),RXo=o("model.eval()"),PXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=a("code"),BXo=o("model.train()"),IXo=l(),F(K4.$$.fragment),mOe=l(),rd=a("h2"),Z4=a("a"),e_e=a("span"),F(IL.$$.fragment),NXo=l(),o_e=a("span"),qXo=o("AutoModelForNextSentencePrediction"),gOe=l(),Io=a("div"),F(NL.$$.fragment),jXo=l(),td=a("p"),DXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=a("a"),GXo=o("from_pretrained()"),OXo=o(" class method or the "),TX=a("a"),VXo=o("from_config()"),XXo=o(` class
method.`),zXo=l(),qL=a("p"),QXo=o("This class cannot be instantiated directly using "),r_e=a("code"),WXo=o("__init__()"),HXo=o(" (throws an error)."),UXo=l(),mt=a("div"),F(jL.$$.fragment),JXo=l(),t_e=a("p"),YXo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),KXo=l(),ad=a("p"),ZXo=o(`Note:
Loading a model from its configuration file does `),a_e=a("strong"),ezo=o("not"),ozo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=a("a"),rzo=o("from_pretrained()"),tzo=o(" to load the model weights."),azo=l(),F(ev.$$.fragment),nzo=l(),to=a("div"),F(DL.$$.fragment),szo=l(),n_e=a("p"),lzo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),izo=l(),Da=a("p"),dzo=o("The model class to instantiate is selected based on the "),s_e=a("code"),czo=o("model_type"),fzo=o(` property of the config object (either
passed as an argument or loaded from `),l_e=a("code"),mzo=o("pretrained_model_name_or_path"),gzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=a("code"),hzo=o("pretrained_model_name_or_path"),pzo=o(":"),_zo=l(),No=a("ul"),ov=a("li"),d_e=a("strong"),uzo=o("bert"),bzo=o(" \u2014 "),EX=a("a"),vzo=o("BertForNextSentencePrediction"),Fzo=o(" (BERT model)"),Tzo=l(),rv=a("li"),c_e=a("strong"),Mzo=o("fnet"),Ezo=o(" \u2014 "),CX=a("a"),Czo=o("FNetForNextSentencePrediction"),wzo=o(" (FNet model)"),Azo=l(),tv=a("li"),f_e=a("strong"),Lzo=o("megatron-bert"),yzo=o(" \u2014 "),wX=a("a"),xzo=o("MegatronBertForNextSentencePrediction"),$zo=o(" (Megatron-BERT model)"),kzo=l(),av=a("li"),m_e=a("strong"),Szo=o("mobilebert"),Rzo=o(" \u2014 "),AX=a("a"),Pzo=o("MobileBertForNextSentencePrediction"),Bzo=o(" (MobileBERT model)"),Izo=l(),nv=a("li"),g_e=a("strong"),Nzo=o("nezha"),qzo=o(" \u2014 "),LX=a("a"),jzo=o("NezhaForNextSentencePrediction"),Dzo=o(" (Nezha model)"),Gzo=l(),sv=a("li"),h_e=a("strong"),Ozo=o("qdqbert"),Vzo=o(" \u2014 "),yX=a("a"),Xzo=o("QDQBertForNextSentencePrediction"),zzo=o(" (QDQBert model)"),Qzo=l(),lv=a("p"),Wzo=o("The model is set in evaluation mode by default using "),p_e=a("code"),Hzo=o("model.eval()"),Uzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),__e=a("code"),Jzo=o("model.train()"),Yzo=l(),F(iv.$$.fragment),hOe=l(),nd=a("h2"),dv=a("a"),u_e=a("span"),F(GL.$$.fragment),Kzo=l(),b_e=a("span"),Zzo=o("AutoModelForTokenClassification"),pOe=l(),qo=a("div"),F(OL.$$.fragment),eQo=l(),sd=a("p"),oQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=a("a"),rQo=o("from_pretrained()"),tQo=o(" class method or the "),$X=a("a"),aQo=o("from_config()"),nQo=o(` class
method.`),sQo=l(),VL=a("p"),lQo=o("This class cannot be instantiated directly using "),v_e=a("code"),iQo=o("__init__()"),dQo=o(" (throws an error)."),cQo=l(),gt=a("div"),F(XL.$$.fragment),fQo=l(),F_e=a("p"),mQo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gQo=l(),ld=a("p"),hQo=o(`Note:
Loading a model from its configuration file does `),T_e=a("strong"),pQo=o("not"),_Qo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=a("a"),uQo=o("from_pretrained()"),bQo=o(" to load the model weights."),vQo=l(),F(cv.$$.fragment),FQo=l(),ao=a("div"),F(zL.$$.fragment),TQo=l(),M_e=a("p"),MQo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EQo=l(),Ga=a("p"),CQo=o("The model class to instantiate is selected based on the "),E_e=a("code"),wQo=o("model_type"),AQo=o(` property of the config object (either
passed as an argument or loaded from `),C_e=a("code"),LQo=o("pretrained_model_name_or_path"),yQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=a("code"),xQo=o("pretrained_model_name_or_path"),$Qo=o(":"),kQo=l(),H=a("ul"),fv=a("li"),A_e=a("strong"),SQo=o("albert"),RQo=o(" \u2014 "),SX=a("a"),PQo=o("AlbertForTokenClassification"),BQo=o(" (ALBERT model)"),IQo=l(),mv=a("li"),L_e=a("strong"),NQo=o("bert"),qQo=o(" \u2014 "),RX=a("a"),jQo=o("BertForTokenClassification"),DQo=o(" (BERT model)"),GQo=l(),gv=a("li"),y_e=a("strong"),OQo=o("big_bird"),VQo=o(" \u2014 "),PX=a("a"),XQo=o("BigBirdForTokenClassification"),zQo=o(" (BigBird model)"),QQo=l(),hv=a("li"),x_e=a("strong"),WQo=o("bloom"),HQo=o(" \u2014 "),BX=a("a"),UQo=o("BloomForTokenClassification"),JQo=o(" (BLOOM model)"),YQo=l(),pv=a("li"),$_e=a("strong"),KQo=o("camembert"),ZQo=o(" \u2014 "),IX=a("a"),eWo=o("CamembertForTokenClassification"),oWo=o(" (CamemBERT model)"),rWo=l(),_v=a("li"),k_e=a("strong"),tWo=o("canine"),aWo=o(" \u2014 "),NX=a("a"),nWo=o("CanineForTokenClassification"),sWo=o(" (CANINE model)"),lWo=l(),uv=a("li"),S_e=a("strong"),iWo=o("convbert"),dWo=o(" \u2014 "),qX=a("a"),cWo=o("ConvBertForTokenClassification"),fWo=o(" (ConvBERT model)"),mWo=l(),bv=a("li"),R_e=a("strong"),gWo=o("data2vec-text"),hWo=o(" \u2014 "),jX=a("a"),pWo=o("Data2VecTextForTokenClassification"),_Wo=o(" (Data2VecText model)"),uWo=l(),vv=a("li"),P_e=a("strong"),bWo=o("deberta"),vWo=o(" \u2014 "),DX=a("a"),FWo=o("DebertaForTokenClassification"),TWo=o(" (DeBERTa model)"),MWo=l(),Fv=a("li"),B_e=a("strong"),EWo=o("deberta-v2"),CWo=o(" \u2014 "),GX=a("a"),wWo=o("DebertaV2ForTokenClassification"),AWo=o(" (DeBERTa-v2 model)"),LWo=l(),Tv=a("li"),I_e=a("strong"),yWo=o("distilbert"),xWo=o(" \u2014 "),OX=a("a"),$Wo=o("DistilBertForTokenClassification"),kWo=o(" (DistilBERT model)"),SWo=l(),Mv=a("li"),N_e=a("strong"),RWo=o("electra"),PWo=o(" \u2014 "),VX=a("a"),BWo=o("ElectraForTokenClassification"),IWo=o(" (ELECTRA model)"),NWo=l(),Ev=a("li"),q_e=a("strong"),qWo=o("flaubert"),jWo=o(" \u2014 "),XX=a("a"),DWo=o("FlaubertForTokenClassification"),GWo=o(" (FlauBERT model)"),OWo=l(),Cv=a("li"),j_e=a("strong"),VWo=o("fnet"),XWo=o(" \u2014 "),zX=a("a"),zWo=o("FNetForTokenClassification"),QWo=o(" (FNet model)"),WWo=l(),wv=a("li"),D_e=a("strong"),HWo=o("funnel"),UWo=o(" \u2014 "),QX=a("a"),JWo=o("FunnelForTokenClassification"),YWo=o(" (Funnel Transformer model)"),KWo=l(),Av=a("li"),G_e=a("strong"),ZWo=o("gpt2"),eHo=o(" \u2014 "),WX=a("a"),oHo=o("GPT2ForTokenClassification"),rHo=o(" (OpenAI GPT-2 model)"),tHo=l(),Lv=a("li"),O_e=a("strong"),aHo=o("ibert"),nHo=o(" \u2014 "),HX=a("a"),sHo=o("IBertForTokenClassification"),lHo=o(" (I-BERT model)"),iHo=l(),yv=a("li"),V_e=a("strong"),dHo=o("layoutlm"),cHo=o(" \u2014 "),UX=a("a"),fHo=o("LayoutLMForTokenClassification"),mHo=o(" (LayoutLM model)"),gHo=l(),xv=a("li"),X_e=a("strong"),hHo=o("layoutlmv2"),pHo=o(" \u2014 "),JX=a("a"),_Ho=o("LayoutLMv2ForTokenClassification"),uHo=o(" (LayoutLMv2 model)"),bHo=l(),$v=a("li"),z_e=a("strong"),vHo=o("layoutlmv3"),FHo=o(" \u2014 "),YX=a("a"),THo=o("LayoutLMv3ForTokenClassification"),MHo=o(" (LayoutLMv3 model)"),EHo=l(),kv=a("li"),Q_e=a("strong"),CHo=o("longformer"),wHo=o(" \u2014 "),KX=a("a"),AHo=o("LongformerForTokenClassification"),LHo=o(" (Longformer model)"),yHo=l(),Sv=a("li"),W_e=a("strong"),xHo=o("megatron-bert"),$Ho=o(" \u2014 "),ZX=a("a"),kHo=o("MegatronBertForTokenClassification"),SHo=o(" (Megatron-BERT model)"),RHo=l(),Rv=a("li"),H_e=a("strong"),PHo=o("mobilebert"),BHo=o(" \u2014 "),ez=a("a"),IHo=o("MobileBertForTokenClassification"),NHo=o(" (MobileBERT model)"),qHo=l(),Pv=a("li"),U_e=a("strong"),jHo=o("mpnet"),DHo=o(" \u2014 "),oz=a("a"),GHo=o("MPNetForTokenClassification"),OHo=o(" (MPNet model)"),VHo=l(),Bv=a("li"),J_e=a("strong"),XHo=o("nezha"),zHo=o(" \u2014 "),rz=a("a"),QHo=o("NezhaForTokenClassification"),WHo=o(" (Nezha model)"),HHo=l(),Iv=a("li"),Y_e=a("strong"),UHo=o("nystromformer"),JHo=o(" \u2014 "),tz=a("a"),YHo=o("NystromformerForTokenClassification"),KHo=o(" (Nystr\xF6mformer model)"),ZHo=l(),Nv=a("li"),K_e=a("strong"),eUo=o("qdqbert"),oUo=o(" \u2014 "),az=a("a"),rUo=o("QDQBertForTokenClassification"),tUo=o(" (QDQBert model)"),aUo=l(),qv=a("li"),Z_e=a("strong"),nUo=o("rembert"),sUo=o(" \u2014 "),nz=a("a"),lUo=o("RemBertForTokenClassification"),iUo=o(" (RemBERT model)"),dUo=l(),jv=a("li"),eue=a("strong"),cUo=o("roberta"),fUo=o(" \u2014 "),sz=a("a"),mUo=o("RobertaForTokenClassification"),gUo=o(" (RoBERTa model)"),hUo=l(),Dv=a("li"),oue=a("strong"),pUo=o("roformer"),_Uo=o(" \u2014 "),lz=a("a"),uUo=o("RoFormerForTokenClassification"),bUo=o(" (RoFormer model)"),vUo=l(),Gv=a("li"),rue=a("strong"),FUo=o("squeezebert"),TUo=o(" \u2014 "),iz=a("a"),MUo=o("SqueezeBertForTokenClassification"),EUo=o(" (SqueezeBERT model)"),CUo=l(),Ov=a("li"),tue=a("strong"),wUo=o("xlm"),AUo=o(" \u2014 "),dz=a("a"),LUo=o("XLMForTokenClassification"),yUo=o(" (XLM model)"),xUo=l(),Vv=a("li"),aue=a("strong"),$Uo=o("xlm-roberta"),kUo=o(" \u2014 "),cz=a("a"),SUo=o("XLMRobertaForTokenClassification"),RUo=o(" (XLM-RoBERTa model)"),PUo=l(),Xv=a("li"),nue=a("strong"),BUo=o("xlm-roberta-xl"),IUo=o(" \u2014 "),fz=a("a"),NUo=o("XLMRobertaXLForTokenClassification"),qUo=o(" (XLM-RoBERTa-XL model)"),jUo=l(),zv=a("li"),sue=a("strong"),DUo=o("xlnet"),GUo=o(" \u2014 "),mz=a("a"),OUo=o("XLNetForTokenClassification"),VUo=o(" (XLNet model)"),XUo=l(),Qv=a("li"),lue=a("strong"),zUo=o("yoso"),QUo=o(" \u2014 "),gz=a("a"),WUo=o("YosoForTokenClassification"),HUo=o(" (YOSO model)"),UUo=l(),Wv=a("p"),JUo=o("The model is set in evaluation mode by default using "),iue=a("code"),YUo=o("model.eval()"),KUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),due=a("code"),ZUo=o("model.train()"),eJo=l(),F(Hv.$$.fragment),_Oe=l(),id=a("h2"),Uv=a("a"),cue=a("span"),F(QL.$$.fragment),oJo=l(),fue=a("span"),rJo=o("AutoModelForQuestionAnswering"),uOe=l(),jo=a("div"),F(WL.$$.fragment),tJo=l(),dd=a("p"),aJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=a("a"),nJo=o("from_pretrained()"),sJo=o(" class method or the "),pz=a("a"),lJo=o("from_config()"),iJo=o(` class
method.`),dJo=l(),HL=a("p"),cJo=o("This class cannot be instantiated directly using "),mue=a("code"),fJo=o("__init__()"),mJo=o(" (throws an error)."),gJo=l(),ht=a("div"),F(UL.$$.fragment),hJo=l(),gue=a("p"),pJo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),_Jo=l(),cd=a("p"),uJo=o(`Note:
Loading a model from its configuration file does `),hue=a("strong"),bJo=o("not"),vJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_z=a("a"),FJo=o("from_pretrained()"),TJo=o(" to load the model weights."),MJo=l(),F(Jv.$$.fragment),EJo=l(),no=a("div"),F(JL.$$.fragment),CJo=l(),pue=a("p"),wJo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),AJo=l(),Oa=a("p"),LJo=o("The model class to instantiate is selected based on the "),_ue=a("code"),yJo=o("model_type"),xJo=o(` property of the config object (either
passed as an argument or loaded from `),uue=a("code"),$Jo=o("pretrained_model_name_or_path"),kJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=a("code"),SJo=o("pretrained_model_name_or_path"),RJo=o(":"),PJo=l(),V=a("ul"),Yv=a("li"),vue=a("strong"),BJo=o("albert"),IJo=o(" \u2014 "),uz=a("a"),NJo=o("AlbertForQuestionAnswering"),qJo=o(" (ALBERT model)"),jJo=l(),Kv=a("li"),Fue=a("strong"),DJo=o("bart"),GJo=o(" \u2014 "),bz=a("a"),OJo=o("BartForQuestionAnswering"),VJo=o(" (BART model)"),XJo=l(),Zv=a("li"),Tue=a("strong"),zJo=o("bert"),QJo=o(" \u2014 "),vz=a("a"),WJo=o("BertForQuestionAnswering"),HJo=o(" (BERT model)"),UJo=l(),eF=a("li"),Mue=a("strong"),JJo=o("big_bird"),YJo=o(" \u2014 "),Fz=a("a"),KJo=o("BigBirdForQuestionAnswering"),ZJo=o(" (BigBird model)"),eYo=l(),oF=a("li"),Eue=a("strong"),oYo=o("bigbird_pegasus"),rYo=o(" \u2014 "),Tz=a("a"),tYo=o("BigBirdPegasusForQuestionAnswering"),aYo=o(" (BigBird-Pegasus model)"),nYo=l(),rF=a("li"),Cue=a("strong"),sYo=o("camembert"),lYo=o(" \u2014 "),Mz=a("a"),iYo=o("CamembertForQuestionAnswering"),dYo=o(" (CamemBERT model)"),cYo=l(),tF=a("li"),wue=a("strong"),fYo=o("canine"),mYo=o(" \u2014 "),Ez=a("a"),gYo=o("CanineForQuestionAnswering"),hYo=o(" (CANINE model)"),pYo=l(),aF=a("li"),Aue=a("strong"),_Yo=o("convbert"),uYo=o(" \u2014 "),Cz=a("a"),bYo=o("ConvBertForQuestionAnswering"),vYo=o(" (ConvBERT model)"),FYo=l(),nF=a("li"),Lue=a("strong"),TYo=o("data2vec-text"),MYo=o(" \u2014 "),wz=a("a"),EYo=o("Data2VecTextForQuestionAnswering"),CYo=o(" (Data2VecText model)"),wYo=l(),sF=a("li"),yue=a("strong"),AYo=o("deberta"),LYo=o(" \u2014 "),Az=a("a"),yYo=o("DebertaForQuestionAnswering"),xYo=o(" (DeBERTa model)"),$Yo=l(),lF=a("li"),xue=a("strong"),kYo=o("deberta-v2"),SYo=o(" \u2014 "),Lz=a("a"),RYo=o("DebertaV2ForQuestionAnswering"),PYo=o(" (DeBERTa-v2 model)"),BYo=l(),iF=a("li"),$ue=a("strong"),IYo=o("distilbert"),NYo=o(" \u2014 "),yz=a("a"),qYo=o("DistilBertForQuestionAnswering"),jYo=o(" (DistilBERT model)"),DYo=l(),dF=a("li"),kue=a("strong"),GYo=o("electra"),OYo=o(" \u2014 "),xz=a("a"),VYo=o("ElectraForQuestionAnswering"),XYo=o(" (ELECTRA model)"),zYo=l(),cF=a("li"),Sue=a("strong"),QYo=o("flaubert"),WYo=o(" \u2014 "),$z=a("a"),HYo=o("FlaubertForQuestionAnsweringSimple"),UYo=o(" (FlauBERT model)"),JYo=l(),fF=a("li"),Rue=a("strong"),YYo=o("fnet"),KYo=o(" \u2014 "),kz=a("a"),ZYo=o("FNetForQuestionAnswering"),eKo=o(" (FNet model)"),oKo=l(),mF=a("li"),Pue=a("strong"),rKo=o("funnel"),tKo=o(" \u2014 "),Sz=a("a"),aKo=o("FunnelForQuestionAnswering"),nKo=o(" (Funnel Transformer model)"),sKo=l(),gF=a("li"),Bue=a("strong"),lKo=o("gptj"),iKo=o(" \u2014 "),Rz=a("a"),dKo=o("GPTJForQuestionAnswering"),cKo=o(" (GPT-J model)"),fKo=l(),hF=a("li"),Iue=a("strong"),mKo=o("ibert"),gKo=o(" \u2014 "),Pz=a("a"),hKo=o("IBertForQuestionAnswering"),pKo=o(" (I-BERT model)"),_Ko=l(),pF=a("li"),Nue=a("strong"),uKo=o("layoutlmv2"),bKo=o(" \u2014 "),Bz=a("a"),vKo=o("LayoutLMv2ForQuestionAnswering"),FKo=o(" (LayoutLMv2 model)"),TKo=l(),_F=a("li"),que=a("strong"),MKo=o("layoutlmv3"),EKo=o(" \u2014 "),Iz=a("a"),CKo=o("LayoutLMv3ForQuestionAnswering"),wKo=o(" (LayoutLMv3 model)"),AKo=l(),uF=a("li"),jue=a("strong"),LKo=o("led"),yKo=o(" \u2014 "),Nz=a("a"),xKo=o("LEDForQuestionAnswering"),$Ko=o(" (LED model)"),kKo=l(),bF=a("li"),Due=a("strong"),SKo=o("longformer"),RKo=o(" \u2014 "),qz=a("a"),PKo=o("LongformerForQuestionAnswering"),BKo=o(" (Longformer model)"),IKo=l(),vF=a("li"),Gue=a("strong"),NKo=o("lxmert"),qKo=o(" \u2014 "),jz=a("a"),jKo=o("LxmertForQuestionAnswering"),DKo=o(" (LXMERT model)"),GKo=l(),FF=a("li"),Oue=a("strong"),OKo=o("mbart"),VKo=o(" \u2014 "),Dz=a("a"),XKo=o("MBartForQuestionAnswering"),zKo=o(" (mBART model)"),QKo=l(),TF=a("li"),Vue=a("strong"),WKo=o("megatron-bert"),HKo=o(" \u2014 "),Gz=a("a"),UKo=o("MegatronBertForQuestionAnswering"),JKo=o(" (Megatron-BERT model)"),YKo=l(),MF=a("li"),Xue=a("strong"),KKo=o("mobilebert"),ZKo=o(" \u2014 "),Oz=a("a"),eZo=o("MobileBertForQuestionAnswering"),oZo=o(" (MobileBERT model)"),rZo=l(),EF=a("li"),zue=a("strong"),tZo=o("mpnet"),aZo=o(" \u2014 "),Vz=a("a"),nZo=o("MPNetForQuestionAnswering"),sZo=o(" (MPNet model)"),lZo=l(),CF=a("li"),Que=a("strong"),iZo=o("nezha"),dZo=o(" \u2014 "),Xz=a("a"),cZo=o("NezhaForQuestionAnswering"),fZo=o(" (Nezha model)"),mZo=l(),wF=a("li"),Wue=a("strong"),gZo=o("nystromformer"),hZo=o(" \u2014 "),zz=a("a"),pZo=o("NystromformerForQuestionAnswering"),_Zo=o(" (Nystr\xF6mformer model)"),uZo=l(),AF=a("li"),Hue=a("strong"),bZo=o("qdqbert"),vZo=o(" \u2014 "),Qz=a("a"),FZo=o("QDQBertForQuestionAnswering"),TZo=o(" (QDQBert model)"),MZo=l(),LF=a("li"),Uue=a("strong"),EZo=o("reformer"),CZo=o(" \u2014 "),Wz=a("a"),wZo=o("ReformerForQuestionAnswering"),AZo=o(" (Reformer model)"),LZo=l(),yF=a("li"),Jue=a("strong"),yZo=o("rembert"),xZo=o(" \u2014 "),Hz=a("a"),$Zo=o("RemBertForQuestionAnswering"),kZo=o(" (RemBERT model)"),SZo=l(),xF=a("li"),Yue=a("strong"),RZo=o("roberta"),PZo=o(" \u2014 "),Uz=a("a"),BZo=o("RobertaForQuestionAnswering"),IZo=o(" (RoBERTa model)"),NZo=l(),$F=a("li"),Kue=a("strong"),qZo=o("roformer"),jZo=o(" \u2014 "),Jz=a("a"),DZo=o("RoFormerForQuestionAnswering"),GZo=o(" (RoFormer model)"),OZo=l(),kF=a("li"),Zue=a("strong"),VZo=o("splinter"),XZo=o(" \u2014 "),Yz=a("a"),zZo=o("SplinterForQuestionAnswering"),QZo=o(" (Splinter model)"),WZo=l(),SF=a("li"),e1e=a("strong"),HZo=o("squeezebert"),UZo=o(" \u2014 "),Kz=a("a"),JZo=o("SqueezeBertForQuestionAnswering"),YZo=o(" (SqueezeBERT model)"),KZo=l(),RF=a("li"),o1e=a("strong"),ZZo=o("xlm"),eer=o(" \u2014 "),Zz=a("a"),oer=o("XLMForQuestionAnsweringSimple"),rer=o(" (XLM model)"),ter=l(),PF=a("li"),r1e=a("strong"),aer=o("xlm-roberta"),ner=o(" \u2014 "),eQ=a("a"),ser=o("XLMRobertaForQuestionAnswering"),ler=o(" (XLM-RoBERTa model)"),ier=l(),BF=a("li"),t1e=a("strong"),der=o("xlm-roberta-xl"),cer=o(" \u2014 "),oQ=a("a"),fer=o("XLMRobertaXLForQuestionAnswering"),mer=o(" (XLM-RoBERTa-XL model)"),ger=l(),IF=a("li"),a1e=a("strong"),her=o("xlnet"),per=o(" \u2014 "),rQ=a("a"),_er=o("XLNetForQuestionAnsweringSimple"),uer=o(" (XLNet model)"),ber=l(),NF=a("li"),n1e=a("strong"),ver=o("yoso"),Fer=o(" \u2014 "),tQ=a("a"),Ter=o("YosoForQuestionAnswering"),Mer=o(" (YOSO model)"),Eer=l(),qF=a("p"),Cer=o("The model is set in evaluation mode by default using "),s1e=a("code"),wer=o("model.eval()"),Aer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l1e=a("code"),Ler=o("model.train()"),yer=l(),F(jF.$$.fragment),bOe=l(),fd=a("h2"),DF=a("a"),i1e=a("span"),F(YL.$$.fragment),xer=l(),d1e=a("span"),$er=o("AutoModelForTableQuestionAnswering"),vOe=l(),Do=a("div"),F(KL.$$.fragment),ker=l(),md=a("p"),Ser=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=a("a"),Rer=o("from_pretrained()"),Per=o(" class method or the "),nQ=a("a"),Ber=o("from_config()"),Ier=o(` class
method.`),Ner=l(),ZL=a("p"),qer=o("This class cannot be instantiated directly using "),c1e=a("code"),jer=o("__init__()"),Der=o(" (throws an error)."),Ger=l(),pt=a("div"),F(ey.$$.fragment),Oer=l(),f1e=a("p"),Ver=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Xer=l(),gd=a("p"),zer=o(`Note:
Loading a model from its configuration file does `),m1e=a("strong"),Qer=o("not"),Wer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=a("a"),Her=o("from_pretrained()"),Uer=o(" to load the model weights."),Jer=l(),F(GF.$$.fragment),Yer=l(),so=a("div"),F(oy.$$.fragment),Ker=l(),g1e=a("p"),Zer=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),eor=l(),Va=a("p"),oor=o("The model class to instantiate is selected based on the "),h1e=a("code"),ror=o("model_type"),tor=o(` property of the config object (either
passed as an argument or loaded from `),p1e=a("code"),aor=o("pretrained_model_name_or_path"),nor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_1e=a("code"),sor=o("pretrained_model_name_or_path"),lor=o(":"),ior=l(),u1e=a("ul"),OF=a("li"),b1e=a("strong"),dor=o("tapas"),cor=o(" \u2014 "),lQ=a("a"),mor=o("TapasForQuestionAnswering"),gor=o(" (TAPAS model)"),hor=l(),VF=a("p"),por=o("The model is set in evaluation mode by default using "),v1e=a("code"),_or=o("model.eval()"),uor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F1e=a("code"),bor=o("model.train()"),vor=l(),F(XF.$$.fragment),FOe=l(),hd=a("h2"),zF=a("a"),T1e=a("span"),F(ry.$$.fragment),For=l(),M1e=a("span"),Tor=o("AutoModelForImageClassification"),TOe=l(),Go=a("div"),F(ty.$$.fragment),Mor=l(),pd=a("p"),Eor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=a("a"),Cor=o("from_pretrained()"),wor=o(" class method or the "),dQ=a("a"),Aor=o("from_config()"),Lor=o(` class
method.`),yor=l(),ay=a("p"),xor=o("This class cannot be instantiated directly using "),E1e=a("code"),$or=o("__init__()"),kor=o(" (throws an error)."),Sor=l(),_t=a("div"),F(ny.$$.fragment),Ror=l(),C1e=a("p"),Por=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Bor=l(),_d=a("p"),Ior=o(`Note:
Loading a model from its configuration file does `),w1e=a("strong"),Nor=o("not"),qor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),jor=o("from_pretrained()"),Dor=o(" to load the model weights."),Gor=l(),F(QF.$$.fragment),Oor=l(),lo=a("div"),F(sy.$$.fragment),Vor=l(),A1e=a("p"),Xor=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),zor=l(),Xa=a("p"),Qor=o("The model class to instantiate is selected based on the "),L1e=a("code"),Wor=o("model_type"),Hor=o(` property of the config object (either
passed as an argument or loaded from `),y1e=a("code"),Uor=o("pretrained_model_name_or_path"),Jor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x1e=a("code"),Yor=o("pretrained_model_name_or_path"),Kor=o(":"),Zor=l(),Fe=a("ul"),WF=a("li"),$1e=a("strong"),err=o("beit"),orr=o(" \u2014 "),fQ=a("a"),rrr=o("BeitForImageClassification"),trr=o(" (BEiT model)"),arr=l(),HF=a("li"),k1e=a("strong"),nrr=o("convnext"),srr=o(" \u2014 "),mQ=a("a"),lrr=o("ConvNextForImageClassification"),irr=o(" (ConvNeXT model)"),drr=l(),UF=a("li"),S1e=a("strong"),crr=o("cvt"),frr=o(" \u2014 "),gQ=a("a"),mrr=o("CvtForImageClassification"),grr=o(" (CvT model)"),hrr=l(),JF=a("li"),R1e=a("strong"),prr=o("data2vec-vision"),_rr=o(" \u2014 "),hQ=a("a"),urr=o("Data2VecVisionForImageClassification"),brr=o(" (Data2VecVision model)"),vrr=l(),Xs=a("li"),P1e=a("strong"),Frr=o("deit"),Trr=o(" \u2014 "),pQ=a("a"),Mrr=o("DeiTForImageClassification"),Err=o(" or "),_Q=a("a"),Crr=o("DeiTForImageClassificationWithTeacher"),wrr=o(" (DeiT model)"),Arr=l(),YF=a("li"),B1e=a("strong"),Lrr=o("imagegpt"),yrr=o(" \u2014 "),uQ=a("a"),xrr=o("ImageGPTForImageClassification"),$rr=o(" (ImageGPT model)"),krr=l(),zs=a("li"),I1e=a("strong"),Srr=o("levit"),Rrr=o(" \u2014 "),bQ=a("a"),Prr=o("LevitForImageClassification"),Brr=o(" or "),vQ=a("a"),Irr=o("LevitForImageClassificationWithTeacher"),Nrr=o(" (LeViT model)"),qrr=l(),ut=a("li"),N1e=a("strong"),jrr=o("perceiver"),Drr=o(" \u2014 "),FQ=a("a"),Grr=o("PerceiverForImageClassificationLearned"),Orr=o(" or "),TQ=a("a"),Vrr=o("PerceiverForImageClassificationFourier"),Xrr=o(" or "),MQ=a("a"),zrr=o("PerceiverForImageClassificationConvProcessing"),Qrr=o(" (Perceiver model)"),Wrr=l(),KF=a("li"),q1e=a("strong"),Hrr=o("poolformer"),Urr=o(" \u2014 "),EQ=a("a"),Jrr=o("PoolFormerForImageClassification"),Yrr=o(" (PoolFormer model)"),Krr=l(),ZF=a("li"),j1e=a("strong"),Zrr=o("regnet"),etr=o(" \u2014 "),CQ=a("a"),otr=o("RegNetForImageClassification"),rtr=o(" (RegNet model)"),ttr=l(),e6=a("li"),D1e=a("strong"),atr=o("resnet"),ntr=o(" \u2014 "),wQ=a("a"),str=o("ResNetForImageClassification"),ltr=o(" (ResNet model)"),itr=l(),o6=a("li"),G1e=a("strong"),dtr=o("segformer"),ctr=o(" \u2014 "),AQ=a("a"),ftr=o("SegformerForImageClassification"),mtr=o(" (SegFormer model)"),gtr=l(),r6=a("li"),O1e=a("strong"),htr=o("swin"),ptr=o(" \u2014 "),LQ=a("a"),_tr=o("SwinForImageClassification"),utr=o(" (Swin Transformer model)"),btr=l(),t6=a("li"),V1e=a("strong"),vtr=o("van"),Ftr=o(" \u2014 "),yQ=a("a"),Ttr=o("VanForImageClassification"),Mtr=o(" (VAN model)"),Etr=l(),a6=a("li"),X1e=a("strong"),Ctr=o("vit"),wtr=o(" \u2014 "),xQ=a("a"),Atr=o("ViTForImageClassification"),Ltr=o(" (ViT model)"),ytr=l(),n6=a("p"),xtr=o("The model is set in evaluation mode by default using "),z1e=a("code"),$tr=o("model.eval()"),ktr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q1e=a("code"),Str=o("model.train()"),Rtr=l(),F(s6.$$.fragment),MOe=l(),ud=a("h2"),l6=a("a"),W1e=a("span"),F(ly.$$.fragment),Ptr=l(),H1e=a("span"),Btr=o("AutoModelForVision2Seq"),EOe=l(),Oo=a("div"),F(iy.$$.fragment),Itr=l(),bd=a("p"),Ntr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=a("a"),qtr=o("from_pretrained()"),jtr=o(" class method or the "),kQ=a("a"),Dtr=o("from_config()"),Gtr=o(` class
method.`),Otr=l(),dy=a("p"),Vtr=o("This class cannot be instantiated directly using "),U1e=a("code"),Xtr=o("__init__()"),ztr=o(" (throws an error)."),Qtr=l(),bt=a("div"),F(cy.$$.fragment),Wtr=l(),J1e=a("p"),Htr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Utr=l(),vd=a("p"),Jtr=o(`Note:
Loading a model from its configuration file does `),Y1e=a("strong"),Ytr=o("not"),Ktr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=a("a"),Ztr=o("from_pretrained()"),ear=o(" to load the model weights."),oar=l(),F(i6.$$.fragment),rar=l(),io=a("div"),F(fy.$$.fragment),tar=l(),K1e=a("p"),aar=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nar=l(),za=a("p"),sar=o("The model class to instantiate is selected based on the "),Z1e=a("code"),lar=o("model_type"),iar=o(` property of the config object (either
passed as an argument or loaded from `),e2e=a("code"),dar=o("pretrained_model_name_or_path"),car=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o2e=a("code"),far=o("pretrained_model_name_or_path"),mar=o(":"),gar=l(),r2e=a("ul"),d6=a("li"),t2e=a("strong"),har=o("vision-encoder-decoder"),par=o(" \u2014 "),RQ=a("a"),_ar=o("VisionEncoderDecoderModel"),uar=o(" (Vision Encoder decoder model)"),bar=l(),c6=a("p"),Far=o("The model is set in evaluation mode by default using "),a2e=a("code"),Tar=o("model.eval()"),Mar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n2e=a("code"),Ear=o("model.train()"),Car=l(),F(f6.$$.fragment),COe=l(),Fd=a("h2"),m6=a("a"),s2e=a("span"),F(my.$$.fragment),war=l(),l2e=a("span"),Aar=o("AutoModelForVisualQuestionAnswering"),wOe=l(),Vo=a("div"),F(gy.$$.fragment),Lar=l(),Td=a("p"),yar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=a("a"),xar=o("from_pretrained()"),$ar=o(" class method or the "),BQ=a("a"),kar=o("from_config()"),Sar=o(` class
method.`),Rar=l(),hy=a("p"),Par=o("This class cannot be instantiated directly using "),i2e=a("code"),Bar=o("__init__()"),Iar=o(" (throws an error)."),Nar=l(),vt=a("div"),F(py.$$.fragment),qar=l(),d2e=a("p"),jar=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Dar=l(),Md=a("p"),Gar=o(`Note:
Loading a model from its configuration file does `),c2e=a("strong"),Oar=o("not"),Var=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=a("a"),Xar=o("from_pretrained()"),zar=o(" to load the model weights."),Qar=l(),F(g6.$$.fragment),War=l(),co=a("div"),F(_y.$$.fragment),Har=l(),f2e=a("p"),Uar=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Jar=l(),Qa=a("p"),Yar=o("The model class to instantiate is selected based on the "),m2e=a("code"),Kar=o("model_type"),Zar=o(` property of the config object (either
passed as an argument or loaded from `),g2e=a("code"),enr=o("pretrained_model_name_or_path"),onr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h2e=a("code"),rnr=o("pretrained_model_name_or_path"),tnr=o(":"),anr=l(),p2e=a("ul"),h6=a("li"),_2e=a("strong"),nnr=o("vilt"),snr=o(" \u2014 "),NQ=a("a"),lnr=o("ViltForQuestionAnswering"),inr=o(" (ViLT model)"),dnr=l(),p6=a("p"),cnr=o("The model is set in evaluation mode by default using "),u2e=a("code"),fnr=o("model.eval()"),mnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b2e=a("code"),gnr=o("model.train()"),hnr=l(),F(_6.$$.fragment),AOe=l(),Ed=a("h2"),u6=a("a"),v2e=a("span"),F(uy.$$.fragment),pnr=l(),F2e=a("span"),_nr=o("AutoModelForAudioClassification"),LOe=l(),Xo=a("div"),F(by.$$.fragment),unr=l(),Cd=a("p"),bnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=a("a"),vnr=o("from_pretrained()"),Fnr=o(" class method or the "),jQ=a("a"),Tnr=o("from_config()"),Mnr=o(` class
method.`),Enr=l(),vy=a("p"),Cnr=o("This class cannot be instantiated directly using "),T2e=a("code"),wnr=o("__init__()"),Anr=o(" (throws an error)."),Lnr=l(),Ft=a("div"),F(Fy.$$.fragment),ynr=l(),M2e=a("p"),xnr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),$nr=l(),wd=a("p"),knr=o(`Note:
Loading a model from its configuration file does `),E2e=a("strong"),Snr=o("not"),Rnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=a("a"),Pnr=o("from_pretrained()"),Bnr=o(" to load the model weights."),Inr=l(),F(b6.$$.fragment),Nnr=l(),fo=a("div"),F(Ty.$$.fragment),qnr=l(),C2e=a("p"),jnr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Dnr=l(),Wa=a("p"),Gnr=o("The model class to instantiate is selected based on the "),w2e=a("code"),Onr=o("model_type"),Vnr=o(` property of the config object (either
passed as an argument or loaded from `),A2e=a("code"),Xnr=o("pretrained_model_name_or_path"),znr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=a("code"),Qnr=o("pretrained_model_name_or_path"),Wnr=o(":"),Hnr=l(),Pe=a("ul"),v6=a("li"),y2e=a("strong"),Unr=o("data2vec-audio"),Jnr=o(" \u2014 "),GQ=a("a"),Ynr=o("Data2VecAudioForSequenceClassification"),Knr=o(" (Data2VecAudio model)"),Znr=l(),F6=a("li"),x2e=a("strong"),esr=o("hubert"),osr=o(" \u2014 "),OQ=a("a"),rsr=o("HubertForSequenceClassification"),tsr=o(" (Hubert model)"),asr=l(),T6=a("li"),$2e=a("strong"),nsr=o("sew"),ssr=o(" \u2014 "),VQ=a("a"),lsr=o("SEWForSequenceClassification"),isr=o(" (SEW model)"),dsr=l(),M6=a("li"),k2e=a("strong"),csr=o("sew-d"),fsr=o(" \u2014 "),XQ=a("a"),msr=o("SEWDForSequenceClassification"),gsr=o(" (SEW-D model)"),hsr=l(),E6=a("li"),S2e=a("strong"),psr=o("unispeech"),_sr=o(" \u2014 "),zQ=a("a"),usr=o("UniSpeechForSequenceClassification"),bsr=o(" (UniSpeech model)"),vsr=l(),C6=a("li"),R2e=a("strong"),Fsr=o("unispeech-sat"),Tsr=o(" \u2014 "),QQ=a("a"),Msr=o("UniSpeechSatForSequenceClassification"),Esr=o(" (UniSpeechSat model)"),Csr=l(),w6=a("li"),P2e=a("strong"),wsr=o("wav2vec2"),Asr=o(" \u2014 "),WQ=a("a"),Lsr=o("Wav2Vec2ForSequenceClassification"),ysr=o(" (Wav2Vec2 model)"),xsr=l(),A6=a("li"),B2e=a("strong"),$sr=o("wav2vec2-conformer"),ksr=o(" \u2014 "),HQ=a("a"),Ssr=o("Wav2Vec2ConformerForSequenceClassification"),Rsr=o(" (Wav2Vec2-Conformer model)"),Psr=l(),L6=a("li"),I2e=a("strong"),Bsr=o("wavlm"),Isr=o(" \u2014 "),UQ=a("a"),Nsr=o("WavLMForSequenceClassification"),qsr=o(" (WavLM model)"),jsr=l(),y6=a("p"),Dsr=o("The model is set in evaluation mode by default using "),N2e=a("code"),Gsr=o("model.eval()"),Osr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q2e=a("code"),Vsr=o("model.train()"),Xsr=l(),F(x6.$$.fragment),yOe=l(),Ad=a("h2"),$6=a("a"),j2e=a("span"),F(My.$$.fragment),zsr=l(),D2e=a("span"),Qsr=o("AutoModelForAudioFrameClassification"),xOe=l(),zo=a("div"),F(Ey.$$.fragment),Wsr=l(),Ld=a("p"),Hsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=a("a"),Usr=o("from_pretrained()"),Jsr=o(" class method or the "),YQ=a("a"),Ysr=o("from_config()"),Ksr=o(` class
method.`),Zsr=l(),Cy=a("p"),elr=o("This class cannot be instantiated directly using "),G2e=a("code"),olr=o("__init__()"),rlr=o(" (throws an error)."),tlr=l(),Tt=a("div"),F(wy.$$.fragment),alr=l(),O2e=a("p"),nlr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),slr=l(),yd=a("p"),llr=o(`Note:
Loading a model from its configuration file does `),V2e=a("strong"),ilr=o("not"),dlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=a("a"),clr=o("from_pretrained()"),flr=o(" to load the model weights."),mlr=l(),F(k6.$$.fragment),glr=l(),mo=a("div"),F(Ay.$$.fragment),hlr=l(),X2e=a("p"),plr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),_lr=l(),Ha=a("p"),ulr=o("The model class to instantiate is selected based on the "),z2e=a("code"),blr=o("model_type"),vlr=o(` property of the config object (either
passed as an argument or loaded from `),Q2e=a("code"),Flr=o("pretrained_model_name_or_path"),Tlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W2e=a("code"),Mlr=o("pretrained_model_name_or_path"),Elr=o(":"),Clr=l(),et=a("ul"),S6=a("li"),H2e=a("strong"),wlr=o("data2vec-audio"),Alr=o(" \u2014 "),ZQ=a("a"),Llr=o("Data2VecAudioForAudioFrameClassification"),ylr=o(" (Data2VecAudio model)"),xlr=l(),R6=a("li"),U2e=a("strong"),$lr=o("unispeech-sat"),klr=o(" \u2014 "),eW=a("a"),Slr=o("UniSpeechSatForAudioFrameClassification"),Rlr=o(" (UniSpeechSat model)"),Plr=l(),P6=a("li"),J2e=a("strong"),Blr=o("wav2vec2"),Ilr=o(" \u2014 "),oW=a("a"),Nlr=o("Wav2Vec2ForAudioFrameClassification"),qlr=o(" (Wav2Vec2 model)"),jlr=l(),B6=a("li"),Y2e=a("strong"),Dlr=o("wav2vec2-conformer"),Glr=o(" \u2014 "),rW=a("a"),Olr=o("Wav2Vec2ConformerForAudioFrameClassification"),Vlr=o(" (Wav2Vec2-Conformer model)"),Xlr=l(),I6=a("li"),K2e=a("strong"),zlr=o("wavlm"),Qlr=o(" \u2014 "),tW=a("a"),Wlr=o("WavLMForAudioFrameClassification"),Hlr=o(" (WavLM model)"),Ulr=l(),N6=a("p"),Jlr=o("The model is set in evaluation mode by default using "),Z2e=a("code"),Ylr=o("model.eval()"),Klr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ebe=a("code"),Zlr=o("model.train()"),eir=l(),F(q6.$$.fragment),$Oe=l(),xd=a("h2"),j6=a("a"),obe=a("span"),F(Ly.$$.fragment),oir=l(),rbe=a("span"),rir=o("AutoModelForCTC"),kOe=l(),Qo=a("div"),F(yy.$$.fragment),tir=l(),$d=a("p"),air=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=a("a"),nir=o("from_pretrained()"),sir=o(" class method or the "),nW=a("a"),lir=o("from_config()"),iir=o(` class
method.`),dir=l(),xy=a("p"),cir=o("This class cannot be instantiated directly using "),tbe=a("code"),fir=o("__init__()"),mir=o(" (throws an error)."),gir=l(),Mt=a("div"),F($y.$$.fragment),hir=l(),abe=a("p"),pir=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),_ir=l(),kd=a("p"),uir=o(`Note:
Loading a model from its configuration file does `),nbe=a("strong"),bir=o("not"),vir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=a("a"),Fir=o("from_pretrained()"),Tir=o(" to load the model weights."),Mir=l(),F(D6.$$.fragment),Eir=l(),go=a("div"),F(ky.$$.fragment),Cir=l(),sbe=a("p"),wir=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Air=l(),Ua=a("p"),Lir=o("The model class to instantiate is selected based on the "),lbe=a("code"),yir=o("model_type"),xir=o(` property of the config object (either
passed as an argument or loaded from `),ibe=a("code"),$ir=o("pretrained_model_name_or_path"),kir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dbe=a("code"),Sir=o("pretrained_model_name_or_path"),Rir=o(":"),Pir=l(),Le=a("ul"),G6=a("li"),cbe=a("strong"),Bir=o("data2vec-audio"),Iir=o(" \u2014 "),lW=a("a"),Nir=o("Data2VecAudioForCTC"),qir=o(" (Data2VecAudio model)"),jir=l(),O6=a("li"),fbe=a("strong"),Dir=o("hubert"),Gir=o(" \u2014 "),iW=a("a"),Oir=o("HubertForCTC"),Vir=o(" (Hubert model)"),Xir=l(),V6=a("li"),mbe=a("strong"),zir=o("mctct"),Qir=o(" \u2014 "),dW=a("a"),Wir=o("MCTCTForCTC"),Hir=o(" (M-CTC-T model)"),Uir=l(),X6=a("li"),gbe=a("strong"),Jir=o("sew"),Yir=o(" \u2014 "),cW=a("a"),Kir=o("SEWForCTC"),Zir=o(" (SEW model)"),edr=l(),z6=a("li"),hbe=a("strong"),odr=o("sew-d"),rdr=o(" \u2014 "),fW=a("a"),tdr=o("SEWDForCTC"),adr=o(" (SEW-D model)"),ndr=l(),Q6=a("li"),pbe=a("strong"),sdr=o("unispeech"),ldr=o(" \u2014 "),mW=a("a"),idr=o("UniSpeechForCTC"),ddr=o(" (UniSpeech model)"),cdr=l(),W6=a("li"),_be=a("strong"),fdr=o("unispeech-sat"),mdr=o(" \u2014 "),gW=a("a"),gdr=o("UniSpeechSatForCTC"),hdr=o(" (UniSpeechSat model)"),pdr=l(),H6=a("li"),ube=a("strong"),_dr=o("wav2vec2"),udr=o(" \u2014 "),hW=a("a"),bdr=o("Wav2Vec2ForCTC"),vdr=o(" (Wav2Vec2 model)"),Fdr=l(),U6=a("li"),bbe=a("strong"),Tdr=o("wav2vec2-conformer"),Mdr=o(" \u2014 "),pW=a("a"),Edr=o("Wav2Vec2ConformerForCTC"),Cdr=o(" (Wav2Vec2-Conformer model)"),wdr=l(),J6=a("li"),vbe=a("strong"),Adr=o("wavlm"),Ldr=o(" \u2014 "),_W=a("a"),ydr=o("WavLMForCTC"),xdr=o(" (WavLM model)"),$dr=l(),Y6=a("p"),kdr=o("The model is set in evaluation mode by default using "),Fbe=a("code"),Sdr=o("model.eval()"),Rdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tbe=a("code"),Pdr=o("model.train()"),Bdr=l(),F(K6.$$.fragment),SOe=l(),Sd=a("h2"),Z6=a("a"),Mbe=a("span"),F(Sy.$$.fragment),Idr=l(),Ebe=a("span"),Ndr=o("AutoModelForSpeechSeq2Seq"),ROe=l(),Wo=a("div"),F(Ry.$$.fragment),qdr=l(),Rd=a("p"),jdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uW=a("a"),Ddr=o("from_pretrained()"),Gdr=o(" class method or the "),bW=a("a"),Odr=o("from_config()"),Vdr=o(` class
method.`),Xdr=l(),Py=a("p"),zdr=o("This class cannot be instantiated directly using "),Cbe=a("code"),Qdr=o("__init__()"),Wdr=o(" (throws an error)."),Hdr=l(),Et=a("div"),F(By.$$.fragment),Udr=l(),wbe=a("p"),Jdr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ydr=l(),Pd=a("p"),Kdr=o(`Note:
Loading a model from its configuration file does `),Abe=a("strong"),Zdr=o("not"),ecr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=a("a"),ocr=o("from_pretrained()"),rcr=o(" to load the model weights."),tcr=l(),F(eT.$$.fragment),acr=l(),ho=a("div"),F(Iy.$$.fragment),ncr=l(),Lbe=a("p"),scr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),lcr=l(),Ja=a("p"),icr=o("The model class to instantiate is selected based on the "),ybe=a("code"),dcr=o("model_type"),ccr=o(` property of the config object (either
passed as an argument or loaded from `),xbe=a("code"),fcr=o("pretrained_model_name_or_path"),mcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$be=a("code"),gcr=o("pretrained_model_name_or_path"),hcr=o(":"),pcr=l(),Ny=a("ul"),oT=a("li"),kbe=a("strong"),_cr=o("speech-encoder-decoder"),ucr=o(" \u2014 "),FW=a("a"),bcr=o("SpeechEncoderDecoderModel"),vcr=o(" (Speech Encoder decoder model)"),Fcr=l(),rT=a("li"),Sbe=a("strong"),Tcr=o("speech_to_text"),Mcr=o(" \u2014 "),TW=a("a"),Ecr=o("Speech2TextForConditionalGeneration"),Ccr=o(" (Speech2Text model)"),wcr=l(),tT=a("p"),Acr=o("The model is set in evaluation mode by default using "),Rbe=a("code"),Lcr=o("model.eval()"),ycr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pbe=a("code"),xcr=o("model.train()"),$cr=l(),F(aT.$$.fragment),POe=l(),Bd=a("h2"),nT=a("a"),Bbe=a("span"),F(qy.$$.fragment),kcr=l(),Ibe=a("span"),Scr=o("AutoModelForAudioXVector"),BOe=l(),Ho=a("div"),F(jy.$$.fragment),Rcr=l(),Id=a("p"),Pcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=a("a"),Bcr=o("from_pretrained()"),Icr=o(" class method or the "),EW=a("a"),Ncr=o("from_config()"),qcr=o(` class
method.`),jcr=l(),Dy=a("p"),Dcr=o("This class cannot be instantiated directly using "),Nbe=a("code"),Gcr=o("__init__()"),Ocr=o(" (throws an error)."),Vcr=l(),Ct=a("div"),F(Gy.$$.fragment),Xcr=l(),qbe=a("p"),zcr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Qcr=l(),Nd=a("p"),Wcr=o(`Note:
Loading a model from its configuration file does `),jbe=a("strong"),Hcr=o("not"),Ucr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=a("a"),Jcr=o("from_pretrained()"),Ycr=o(" to load the model weights."),Kcr=l(),F(sT.$$.fragment),Zcr=l(),po=a("div"),F(Oy.$$.fragment),efr=l(),Dbe=a("p"),ofr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),rfr=l(),Ya=a("p"),tfr=o("The model class to instantiate is selected based on the "),Gbe=a("code"),afr=o("model_type"),nfr=o(` property of the config object (either
passed as an argument or loaded from `),Obe=a("code"),sfr=o("pretrained_model_name_or_path"),lfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vbe=a("code"),ifr=o("pretrained_model_name_or_path"),dfr=o(":"),cfr=l(),ot=a("ul"),lT=a("li"),Xbe=a("strong"),ffr=o("data2vec-audio"),mfr=o(" \u2014 "),wW=a("a"),gfr=o("Data2VecAudioForXVector"),hfr=o(" (Data2VecAudio model)"),pfr=l(),iT=a("li"),zbe=a("strong"),_fr=o("unispeech-sat"),ufr=o(" \u2014 "),AW=a("a"),bfr=o("UniSpeechSatForXVector"),vfr=o(" (UniSpeechSat model)"),Ffr=l(),dT=a("li"),Qbe=a("strong"),Tfr=o("wav2vec2"),Mfr=o(" \u2014 "),LW=a("a"),Efr=o("Wav2Vec2ForXVector"),Cfr=o(" (Wav2Vec2 model)"),wfr=l(),cT=a("li"),Wbe=a("strong"),Afr=o("wav2vec2-conformer"),Lfr=o(" \u2014 "),yW=a("a"),yfr=o("Wav2Vec2ConformerForXVector"),xfr=o(" (Wav2Vec2-Conformer model)"),$fr=l(),fT=a("li"),Hbe=a("strong"),kfr=o("wavlm"),Sfr=o(" \u2014 "),xW=a("a"),Rfr=o("WavLMForXVector"),Pfr=o(" (WavLM model)"),Bfr=l(),mT=a("p"),Ifr=o("The model is set in evaluation mode by default using "),Ube=a("code"),Nfr=o("model.eval()"),qfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=a("code"),jfr=o("model.train()"),Dfr=l(),F(gT.$$.fragment),IOe=l(),qd=a("h2"),hT=a("a"),Ybe=a("span"),F(Vy.$$.fragment),Gfr=l(),Kbe=a("span"),Ofr=o("AutoModelForMaskedImageModeling"),NOe=l(),Uo=a("div"),F(Xy.$$.fragment),Vfr=l(),jd=a("p"),Xfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=a("a"),zfr=o("from_pretrained()"),Qfr=o(" class method or the "),kW=a("a"),Wfr=o("from_config()"),Hfr=o(` class
method.`),Ufr=l(),zy=a("p"),Jfr=o("This class cannot be instantiated directly using "),Zbe=a("code"),Yfr=o("__init__()"),Kfr=o(" (throws an error)."),Zfr=l(),wt=a("div"),F(Qy.$$.fragment),emr=l(),e4e=a("p"),omr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),rmr=l(),Dd=a("p"),tmr=o(`Note:
Loading a model from its configuration file does `),o4e=a("strong"),amr=o("not"),nmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=a("a"),smr=o("from_pretrained()"),lmr=o(" to load the model weights."),imr=l(),F(pT.$$.fragment),dmr=l(),_o=a("div"),F(Wy.$$.fragment),cmr=l(),r4e=a("p"),fmr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),mmr=l(),Ka=a("p"),gmr=o("The model class to instantiate is selected based on the "),t4e=a("code"),hmr=o("model_type"),pmr=o(` property of the config object (either
passed as an argument or loaded from `),a4e=a("code"),_mr=o("pretrained_model_name_or_path"),umr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n4e=a("code"),bmr=o("pretrained_model_name_or_path"),vmr=o(":"),Fmr=l(),Gd=a("ul"),_T=a("li"),s4e=a("strong"),Tmr=o("deit"),Mmr=o(" \u2014 "),RW=a("a"),Emr=o("DeiTForMaskedImageModeling"),Cmr=o(" (DeiT model)"),wmr=l(),uT=a("li"),l4e=a("strong"),Amr=o("swin"),Lmr=o(" \u2014 "),PW=a("a"),ymr=o("SwinForMaskedImageModeling"),xmr=o(" (Swin Transformer model)"),$mr=l(),bT=a("li"),i4e=a("strong"),kmr=o("vit"),Smr=o(" \u2014 "),BW=a("a"),Rmr=o("ViTForMaskedImageModeling"),Pmr=o(" (ViT model)"),Bmr=l(),vT=a("p"),Imr=o("The model is set in evaluation mode by default using "),d4e=a("code"),Nmr=o("model.eval()"),qmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c4e=a("code"),jmr=o("model.train()"),Dmr=l(),F(FT.$$.fragment),qOe=l(),Od=a("h2"),TT=a("a"),f4e=a("span"),F(Hy.$$.fragment),Gmr=l(),m4e=a("span"),Omr=o("AutoModelForObjectDetection"),jOe=l(),Jo=a("div"),F(Uy.$$.fragment),Vmr=l(),Vd=a("p"),Xmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=a("a"),zmr=o("from_pretrained()"),Qmr=o(" class method or the "),NW=a("a"),Wmr=o("from_config()"),Hmr=o(` class
method.`),Umr=l(),Jy=a("p"),Jmr=o("This class cannot be instantiated directly using "),g4e=a("code"),Ymr=o("__init__()"),Kmr=o(" (throws an error)."),Zmr=l(),At=a("div"),F(Yy.$$.fragment),egr=l(),h4e=a("p"),ogr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),rgr=l(),Xd=a("p"),tgr=o(`Note:
Loading a model from its configuration file does `),p4e=a("strong"),agr=o("not"),ngr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=a("a"),sgr=o("from_pretrained()"),lgr=o(" to load the model weights."),igr=l(),F(MT.$$.fragment),dgr=l(),uo=a("div"),F(Ky.$$.fragment),cgr=l(),_4e=a("p"),fgr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),mgr=l(),Za=a("p"),ggr=o("The model class to instantiate is selected based on the "),u4e=a("code"),hgr=o("model_type"),pgr=o(` property of the config object (either
passed as an argument or loaded from `),b4e=a("code"),_gr=o("pretrained_model_name_or_path"),ugr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v4e=a("code"),bgr=o("pretrained_model_name_or_path"),vgr=o(":"),Fgr=l(),Zy=a("ul"),ET=a("li"),F4e=a("strong"),Tgr=o("detr"),Mgr=o(" \u2014 "),jW=a("a"),Egr=o("DetrForObjectDetection"),Cgr=o(" (DETR model)"),wgr=l(),CT=a("li"),T4e=a("strong"),Agr=o("yolos"),Lgr=o(" \u2014 "),DW=a("a"),ygr=o("YolosForObjectDetection"),xgr=o(" (YOLOS model)"),$gr=l(),wT=a("p"),kgr=o("The model is set in evaluation mode by default using "),M4e=a("code"),Sgr=o("model.eval()"),Rgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E4e=a("code"),Pgr=o("model.train()"),Bgr=l(),F(AT.$$.fragment),DOe=l(),zd=a("h2"),LT=a("a"),C4e=a("span"),F(e9.$$.fragment),Igr=l(),w4e=a("span"),Ngr=o("AutoModelForImageSegmentation"),GOe=l(),Yo=a("div"),F(o9.$$.fragment),qgr=l(),Qd=a("p"),jgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=a("a"),Dgr=o("from_pretrained()"),Ggr=o(" class method or the "),OW=a("a"),Ogr=o("from_config()"),Vgr=o(` class
method.`),Xgr=l(),r9=a("p"),zgr=o("This class cannot be instantiated directly using "),A4e=a("code"),Qgr=o("__init__()"),Wgr=o(" (throws an error)."),Hgr=l(),Lt=a("div"),F(t9.$$.fragment),Ugr=l(),L4e=a("p"),Jgr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Ygr=l(),Wd=a("p"),Kgr=o(`Note:
Loading a model from its configuration file does `),y4e=a("strong"),Zgr=o("not"),ehr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=a("a"),ohr=o("from_pretrained()"),rhr=o(" to load the model weights."),thr=l(),F(yT.$$.fragment),ahr=l(),bo=a("div"),F(a9.$$.fragment),nhr=l(),x4e=a("p"),shr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),lhr=l(),en=a("p"),ihr=o("The model class to instantiate is selected based on the "),$4e=a("code"),dhr=o("model_type"),chr=o(` property of the config object (either
passed as an argument or loaded from `),k4e=a("code"),fhr=o("pretrained_model_name_or_path"),mhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S4e=a("code"),ghr=o("pretrained_model_name_or_path"),hhr=o(":"),phr=l(),R4e=a("ul"),xT=a("li"),P4e=a("strong"),_hr=o("detr"),uhr=o(" \u2014 "),XW=a("a"),bhr=o("DetrForSegmentation"),vhr=o(" (DETR model)"),Fhr=l(),$T=a("p"),Thr=o("The model is set in evaluation mode by default using "),B4e=a("code"),Mhr=o("model.eval()"),Ehr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I4e=a("code"),Chr=o("model.train()"),whr=l(),F(kT.$$.fragment),OOe=l(),Hd=a("h2"),ST=a("a"),N4e=a("span"),F(n9.$$.fragment),Ahr=l(),q4e=a("span"),Lhr=o("AutoModelForSemanticSegmentation"),VOe=l(),Ko=a("div"),F(s9.$$.fragment),yhr=l(),Ud=a("p"),xhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=a("a"),$hr=o("from_pretrained()"),khr=o(" class method or the "),QW=a("a"),Shr=o("from_config()"),Rhr=o(` class
method.`),Phr=l(),l9=a("p"),Bhr=o("This class cannot be instantiated directly using "),j4e=a("code"),Ihr=o("__init__()"),Nhr=o(" (throws an error)."),qhr=l(),yt=a("div"),F(i9.$$.fragment),jhr=l(),D4e=a("p"),Dhr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Ghr=l(),Jd=a("p"),Ohr=o(`Note:
Loading a model from its configuration file does `),G4e=a("strong"),Vhr=o("not"),Xhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=a("a"),zhr=o("from_pretrained()"),Qhr=o(" to load the model weights."),Whr=l(),F(RT.$$.fragment),Hhr=l(),vo=a("div"),F(d9.$$.fragment),Uhr=l(),O4e=a("p"),Jhr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Yhr=l(),on=a("p"),Khr=o("The model class to instantiate is selected based on the "),V4e=a("code"),Zhr=o("model_type"),epr=o(` property of the config object (either
passed as an argument or loaded from `),X4e=a("code"),opr=o("pretrained_model_name_or_path"),rpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z4e=a("code"),tpr=o("pretrained_model_name_or_path"),apr=o(":"),npr=l(),rn=a("ul"),PT=a("li"),Q4e=a("strong"),spr=o("beit"),lpr=o(" \u2014 "),HW=a("a"),ipr=o("BeitForSemanticSegmentation"),dpr=o(" (BEiT model)"),cpr=l(),BT=a("li"),W4e=a("strong"),fpr=o("data2vec-vision"),mpr=o(" \u2014 "),UW=a("a"),gpr=o("Data2VecVisionForSemanticSegmentation"),hpr=o(" (Data2VecVision model)"),ppr=l(),IT=a("li"),H4e=a("strong"),_pr=o("dpt"),upr=o(" \u2014 "),JW=a("a"),bpr=o("DPTForSemanticSegmentation"),vpr=o(" (DPT model)"),Fpr=l(),NT=a("li"),U4e=a("strong"),Tpr=o("segformer"),Mpr=o(" \u2014 "),YW=a("a"),Epr=o("SegformerForSemanticSegmentation"),Cpr=o(" (SegFormer model)"),wpr=l(),qT=a("p"),Apr=o("The model is set in evaluation mode by default using "),J4e=a("code"),Lpr=o("model.eval()"),ypr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y4e=a("code"),xpr=o("model.train()"),$pr=l(),F(jT.$$.fragment),XOe=l(),Yd=a("h2"),DT=a("a"),K4e=a("span"),F(c9.$$.fragment),kpr=l(),Z4e=a("span"),Spr=o("AutoModelForInstanceSegmentation"),zOe=l(),Zo=a("div"),F(f9.$$.fragment),Rpr=l(),Kd=a("p"),Ppr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=a("a"),Bpr=o("from_pretrained()"),Ipr=o(" class method or the "),ZW=a("a"),Npr=o("from_config()"),qpr=o(` class
method.`),jpr=l(),m9=a("p"),Dpr=o("This class cannot be instantiated directly using "),eve=a("code"),Gpr=o("__init__()"),Opr=o(" (throws an error)."),Vpr=l(),xt=a("div"),F(g9.$$.fragment),Xpr=l(),ove=a("p"),zpr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Qpr=l(),Zd=a("p"),Wpr=o(`Note:
Loading a model from its configuration file does `),rve=a("strong"),Hpr=o("not"),Upr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=a("a"),Jpr=o("from_pretrained()"),Ypr=o(" to load the model weights."),Kpr=l(),F(GT.$$.fragment),Zpr=l(),Fo=a("div"),F(h9.$$.fragment),e_r=l(),tve=a("p"),o_r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),r_r=l(),tn=a("p"),t_r=o("The model class to instantiate is selected based on the "),ave=a("code"),a_r=o("model_type"),n_r=o(` property of the config object (either
passed as an argument or loaded from `),nve=a("code"),s_r=o("pretrained_model_name_or_path"),l_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sve=a("code"),i_r=o("pretrained_model_name_or_path"),d_r=o(":"),c_r=l(),lve=a("ul"),OT=a("li"),ive=a("strong"),f_r=o("maskformer"),m_r=o(" \u2014 "),oH=a("a"),g_r=o("MaskFormerForInstanceSegmentation"),h_r=o(" (MaskFormer model)"),p_r=l(),VT=a("p"),__r=o("The model is set in evaluation mode by default using "),dve=a("code"),u_r=o("model.eval()"),b_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cve=a("code"),v_r=o("model.train()"),F_r=l(),F(XT.$$.fragment),QOe=l(),ec=a("h2"),zT=a("a"),fve=a("span"),F(p9.$$.fragment),T_r=l(),mve=a("span"),M_r=o("TFAutoModel"),WOe=l(),er=a("div"),F(_9.$$.fragment),E_r=l(),oc=a("p"),C_r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=a("a"),w_r=o("from_pretrained()"),A_r=o(" class method or the "),tH=a("a"),L_r=o("from_config()"),y_r=o(` class
method.`),x_r=l(),u9=a("p"),$_r=o("This class cannot be instantiated directly using "),gve=a("code"),k_r=o("__init__()"),S_r=o(" (throws an error)."),R_r=l(),$t=a("div"),F(b9.$$.fragment),P_r=l(),hve=a("p"),B_r=o("Instantiates one of the base model classes of the library from a configuration."),I_r=l(),rc=a("p"),N_r=o(`Note:
Loading a model from its configuration file does `),pve=a("strong"),q_r=o("not"),j_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=a("a"),D_r=o("from_pretrained()"),G_r=o(" to load the model weights."),O_r=l(),F(QT.$$.fragment),V_r=l(),yr=a("div"),F(v9.$$.fragment),X_r=l(),_ve=a("p"),z_r=o("Instantiate one of the base model classes of the library from a pretrained model."),Q_r=l(),an=a("p"),W_r=o("The model class to instantiate is selected based on the "),uve=a("code"),H_r=o("model_type"),U_r=o(` property of the config object (either
passed as an argument or loaded from `),bve=a("code"),J_r=o("pretrained_model_name_or_path"),Y_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vve=a("code"),K_r=o("pretrained_model_name_or_path"),Z_r=o(":"),eur=l(),j=a("ul"),WT=a("li"),Fve=a("strong"),our=o("albert"),rur=o(" \u2014 "),nH=a("a"),tur=o("TFAlbertModel"),aur=o(" (ALBERT model)"),nur=l(),HT=a("li"),Tve=a("strong"),sur=o("bart"),lur=o(" \u2014 "),sH=a("a"),iur=o("TFBartModel"),dur=o(" (BART model)"),cur=l(),UT=a("li"),Mve=a("strong"),fur=o("bert"),mur=o(" \u2014 "),lH=a("a"),gur=o("TFBertModel"),hur=o(" (BERT model)"),pur=l(),JT=a("li"),Eve=a("strong"),_ur=o("blenderbot"),uur=o(" \u2014 "),iH=a("a"),bur=o("TFBlenderbotModel"),vur=o(" (Blenderbot model)"),Fur=l(),YT=a("li"),Cve=a("strong"),Tur=o("blenderbot-small"),Mur=o(" \u2014 "),dH=a("a"),Eur=o("TFBlenderbotSmallModel"),Cur=o(" (BlenderbotSmall model)"),wur=l(),KT=a("li"),wve=a("strong"),Aur=o("camembert"),Lur=o(" \u2014 "),cH=a("a"),yur=o("TFCamembertModel"),xur=o(" (CamemBERT model)"),$ur=l(),ZT=a("li"),Ave=a("strong"),kur=o("clip"),Sur=o(" \u2014 "),fH=a("a"),Rur=o("TFCLIPModel"),Pur=o(" (CLIP model)"),Bur=l(),e7=a("li"),Lve=a("strong"),Iur=o("convbert"),Nur=o(" \u2014 "),mH=a("a"),qur=o("TFConvBertModel"),jur=o(" (ConvBERT model)"),Dur=l(),o7=a("li"),yve=a("strong"),Gur=o("convnext"),Our=o(" \u2014 "),gH=a("a"),Vur=o("TFConvNextModel"),Xur=o(" (ConvNeXT model)"),zur=l(),r7=a("li"),xve=a("strong"),Qur=o("ctrl"),Wur=o(" \u2014 "),hH=a("a"),Hur=o("TFCTRLModel"),Uur=o(" (CTRL model)"),Jur=l(),t7=a("li"),$ve=a("strong"),Yur=o("data2vec-vision"),Kur=o(" \u2014 "),pH=a("a"),Zur=o("TFData2VecVisionModel"),e1r=o(" (Data2VecVision model)"),o1r=l(),a7=a("li"),kve=a("strong"),r1r=o("deberta"),t1r=o(" \u2014 "),_H=a("a"),a1r=o("TFDebertaModel"),n1r=o(" (DeBERTa model)"),s1r=l(),n7=a("li"),Sve=a("strong"),l1r=o("deberta-v2"),i1r=o(" \u2014 "),uH=a("a"),d1r=o("TFDebertaV2Model"),c1r=o(" (DeBERTa-v2 model)"),f1r=l(),s7=a("li"),Rve=a("strong"),m1r=o("distilbert"),g1r=o(" \u2014 "),bH=a("a"),h1r=o("TFDistilBertModel"),p1r=o(" (DistilBERT model)"),_1r=l(),l7=a("li"),Pve=a("strong"),u1r=o("dpr"),b1r=o(" \u2014 "),vH=a("a"),v1r=o("TFDPRQuestionEncoder"),F1r=o(" (DPR model)"),T1r=l(),i7=a("li"),Bve=a("strong"),M1r=o("electra"),E1r=o(" \u2014 "),FH=a("a"),C1r=o("TFElectraModel"),w1r=o(" (ELECTRA model)"),A1r=l(),d7=a("li"),Ive=a("strong"),L1r=o("flaubert"),y1r=o(" \u2014 "),TH=a("a"),x1r=o("TFFlaubertModel"),$1r=o(" (FlauBERT model)"),k1r=l(),Qs=a("li"),Nve=a("strong"),S1r=o("funnel"),R1r=o(" \u2014 "),MH=a("a"),P1r=o("TFFunnelModel"),B1r=o(" or "),EH=a("a"),I1r=o("TFFunnelBaseModel"),N1r=o(" (Funnel Transformer model)"),q1r=l(),c7=a("li"),qve=a("strong"),j1r=o("gpt2"),D1r=o(" \u2014 "),CH=a("a"),G1r=o("TFGPT2Model"),O1r=o(" (OpenAI GPT-2 model)"),V1r=l(),f7=a("li"),jve=a("strong"),X1r=o("gptj"),z1r=o(" \u2014 "),wH=a("a"),Q1r=o("TFGPTJModel"),W1r=o(" (GPT-J model)"),H1r=l(),m7=a("li"),Dve=a("strong"),U1r=o("hubert"),J1r=o(" \u2014 "),AH=a("a"),Y1r=o("TFHubertModel"),K1r=o(" (Hubert model)"),Z1r=l(),g7=a("li"),Gve=a("strong"),e2r=o("layoutlm"),o2r=o(" \u2014 "),LH=a("a"),r2r=o("TFLayoutLMModel"),t2r=o(" (LayoutLM model)"),a2r=l(),h7=a("li"),Ove=a("strong"),n2r=o("led"),s2r=o(" \u2014 "),yH=a("a"),l2r=o("TFLEDModel"),i2r=o(" (LED model)"),d2r=l(),p7=a("li"),Vve=a("strong"),c2r=o("longformer"),f2r=o(" \u2014 "),xH=a("a"),m2r=o("TFLongformerModel"),g2r=o(" (Longformer model)"),h2r=l(),_7=a("li"),Xve=a("strong"),p2r=o("lxmert"),_2r=o(" \u2014 "),$H=a("a"),u2r=o("TFLxmertModel"),b2r=o(" (LXMERT model)"),v2r=l(),u7=a("li"),zve=a("strong"),F2r=o("marian"),T2r=o(" \u2014 "),kH=a("a"),M2r=o("TFMarianModel"),E2r=o(" (Marian model)"),C2r=l(),b7=a("li"),Qve=a("strong"),w2r=o("mbart"),A2r=o(" \u2014 "),SH=a("a"),L2r=o("TFMBartModel"),y2r=o(" (mBART model)"),x2r=l(),v7=a("li"),Wve=a("strong"),$2r=o("mobilebert"),k2r=o(" \u2014 "),RH=a("a"),S2r=o("TFMobileBertModel"),R2r=o(" (MobileBERT model)"),P2r=l(),F7=a("li"),Hve=a("strong"),B2r=o("mpnet"),I2r=o(" \u2014 "),PH=a("a"),N2r=o("TFMPNetModel"),q2r=o(" (MPNet model)"),j2r=l(),T7=a("li"),Uve=a("strong"),D2r=o("mt5"),G2r=o(" \u2014 "),BH=a("a"),O2r=o("TFMT5Model"),V2r=o(" (MT5 model)"),X2r=l(),M7=a("li"),Jve=a("strong"),z2r=o("openai-gpt"),Q2r=o(" \u2014 "),IH=a("a"),W2r=o("TFOpenAIGPTModel"),H2r=o(" (OpenAI GPT model)"),U2r=l(),E7=a("li"),Yve=a("strong"),J2r=o("opt"),Y2r=o(" \u2014 "),NH=a("a"),K2r=o("TFOPTModel"),Z2r=o(" (OPT model)"),ebr=l(),C7=a("li"),Kve=a("strong"),obr=o("pegasus"),rbr=o(" \u2014 "),qH=a("a"),tbr=o("TFPegasusModel"),abr=o(" (Pegasus model)"),nbr=l(),w7=a("li"),Zve=a("strong"),sbr=o("rembert"),lbr=o(" \u2014 "),jH=a("a"),ibr=o("TFRemBertModel"),dbr=o(" (RemBERT model)"),cbr=l(),A7=a("li"),eFe=a("strong"),fbr=o("roberta"),mbr=o(" \u2014 "),DH=a("a"),gbr=o("TFRobertaModel"),hbr=o(" (RoBERTa model)"),pbr=l(),L7=a("li"),oFe=a("strong"),_br=o("roformer"),ubr=o(" \u2014 "),GH=a("a"),bbr=o("TFRoFormerModel"),vbr=o(" (RoFormer model)"),Fbr=l(),y7=a("li"),rFe=a("strong"),Tbr=o("speech_to_text"),Mbr=o(" \u2014 "),OH=a("a"),Ebr=o("TFSpeech2TextModel"),Cbr=o(" (Speech2Text model)"),wbr=l(),x7=a("li"),tFe=a("strong"),Abr=o("swin"),Lbr=o(" \u2014 "),VH=a("a"),ybr=o("TFSwinModel"),xbr=o(" (Swin Transformer model)"),$br=l(),$7=a("li"),aFe=a("strong"),kbr=o("t5"),Sbr=o(" \u2014 "),XH=a("a"),Rbr=o("TFT5Model"),Pbr=o(" (T5 model)"),Bbr=l(),k7=a("li"),nFe=a("strong"),Ibr=o("tapas"),Nbr=o(" \u2014 "),zH=a("a"),qbr=o("TFTapasModel"),jbr=o(" (TAPAS model)"),Dbr=l(),S7=a("li"),sFe=a("strong"),Gbr=o("transfo-xl"),Obr=o(" \u2014 "),QH=a("a"),Vbr=o("TFTransfoXLModel"),Xbr=o(" (Transformer-XL model)"),zbr=l(),R7=a("li"),lFe=a("strong"),Qbr=o("vit"),Wbr=o(" \u2014 "),WH=a("a"),Hbr=o("TFViTModel"),Ubr=o(" (ViT model)"),Jbr=l(),P7=a("li"),iFe=a("strong"),Ybr=o("vit_mae"),Kbr=o(" \u2014 "),HH=a("a"),Zbr=o("TFViTMAEModel"),e4r=o(" (ViTMAE model)"),o4r=l(),B7=a("li"),dFe=a("strong"),r4r=o("wav2vec2"),t4r=o(" \u2014 "),UH=a("a"),a4r=o("TFWav2Vec2Model"),n4r=o(" (Wav2Vec2 model)"),s4r=l(),I7=a("li"),cFe=a("strong"),l4r=o("xlm"),i4r=o(" \u2014 "),JH=a("a"),d4r=o("TFXLMModel"),c4r=o(" (XLM model)"),f4r=l(),N7=a("li"),fFe=a("strong"),m4r=o("xlm-roberta"),g4r=o(" \u2014 "),YH=a("a"),h4r=o("TFXLMRobertaModel"),p4r=o(" (XLM-RoBERTa model)"),_4r=l(),q7=a("li"),mFe=a("strong"),u4r=o("xlnet"),b4r=o(" \u2014 "),KH=a("a"),v4r=o("TFXLNetModel"),F4r=o(" (XLNet model)"),T4r=l(),F(j7.$$.fragment),HOe=l(),tc=a("h2"),D7=a("a"),gFe=a("span"),F(F9.$$.fragment),M4r=l(),hFe=a("span"),E4r=o("TFAutoModelForPreTraining"),UOe=l(),or=a("div"),F(T9.$$.fragment),C4r=l(),ac=a("p"),w4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=a("a"),A4r=o("from_pretrained()"),L4r=o(" class method or the "),eU=a("a"),y4r=o("from_config()"),x4r=o(` class
method.`),$4r=l(),M9=a("p"),k4r=o("This class cannot be instantiated directly using "),pFe=a("code"),S4r=o("__init__()"),R4r=o(" (throws an error)."),P4r=l(),kt=a("div"),F(E9.$$.fragment),B4r=l(),_Fe=a("p"),I4r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),N4r=l(),nc=a("p"),q4r=o(`Note:
Loading a model from its configuration file does `),uFe=a("strong"),j4r=o("not"),D4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=a("a"),G4r=o("from_pretrained()"),O4r=o(" to load the model weights."),V4r=l(),F(G7.$$.fragment),X4r=l(),xr=a("div"),F(C9.$$.fragment),z4r=l(),bFe=a("p"),Q4r=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),W4r=l(),nn=a("p"),H4r=o("The model class to instantiate is selected based on the "),vFe=a("code"),U4r=o("model_type"),J4r=o(` property of the config object (either
passed as an argument or loaded from `),FFe=a("code"),Y4r=o("pretrained_model_name_or_path"),K4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TFe=a("code"),Z4r=o("pretrained_model_name_or_path"),evr=o(":"),ovr=l(),se=a("ul"),O7=a("li"),MFe=a("strong"),rvr=o("albert"),tvr=o(" \u2014 "),rU=a("a"),avr=o("TFAlbertForPreTraining"),nvr=o(" (ALBERT model)"),svr=l(),V7=a("li"),EFe=a("strong"),lvr=o("bart"),ivr=o(" \u2014 "),tU=a("a"),dvr=o("TFBartForConditionalGeneration"),cvr=o(" (BART model)"),fvr=l(),X7=a("li"),CFe=a("strong"),mvr=o("bert"),gvr=o(" \u2014 "),aU=a("a"),hvr=o("TFBertForPreTraining"),pvr=o(" (BERT model)"),_vr=l(),z7=a("li"),wFe=a("strong"),uvr=o("camembert"),bvr=o(" \u2014 "),nU=a("a"),vvr=o("TFCamembertForMaskedLM"),Fvr=o(" (CamemBERT model)"),Tvr=l(),Q7=a("li"),AFe=a("strong"),Mvr=o("ctrl"),Evr=o(" \u2014 "),sU=a("a"),Cvr=o("TFCTRLLMHeadModel"),wvr=o(" (CTRL model)"),Avr=l(),W7=a("li"),LFe=a("strong"),Lvr=o("distilbert"),yvr=o(" \u2014 "),lU=a("a"),xvr=o("TFDistilBertForMaskedLM"),$vr=o(" (DistilBERT model)"),kvr=l(),H7=a("li"),yFe=a("strong"),Svr=o("electra"),Rvr=o(" \u2014 "),iU=a("a"),Pvr=o("TFElectraForPreTraining"),Bvr=o(" (ELECTRA model)"),Ivr=l(),U7=a("li"),xFe=a("strong"),Nvr=o("flaubert"),qvr=o(" \u2014 "),dU=a("a"),jvr=o("TFFlaubertWithLMHeadModel"),Dvr=o(" (FlauBERT model)"),Gvr=l(),J7=a("li"),$Fe=a("strong"),Ovr=o("funnel"),Vvr=o(" \u2014 "),cU=a("a"),Xvr=o("TFFunnelForPreTraining"),zvr=o(" (Funnel Transformer model)"),Qvr=l(),Y7=a("li"),kFe=a("strong"),Wvr=o("gpt2"),Hvr=o(" \u2014 "),fU=a("a"),Uvr=o("TFGPT2LMHeadModel"),Jvr=o(" (OpenAI GPT-2 model)"),Yvr=l(),K7=a("li"),SFe=a("strong"),Kvr=o("layoutlm"),Zvr=o(" \u2014 "),mU=a("a"),eFr=o("TFLayoutLMForMaskedLM"),oFr=o(" (LayoutLM model)"),rFr=l(),Z7=a("li"),RFe=a("strong"),tFr=o("lxmert"),aFr=o(" \u2014 "),gU=a("a"),nFr=o("TFLxmertForPreTraining"),sFr=o(" (LXMERT model)"),lFr=l(),e8=a("li"),PFe=a("strong"),iFr=o("mobilebert"),dFr=o(" \u2014 "),hU=a("a"),cFr=o("TFMobileBertForPreTraining"),fFr=o(" (MobileBERT model)"),mFr=l(),o8=a("li"),BFe=a("strong"),gFr=o("mpnet"),hFr=o(" \u2014 "),pU=a("a"),pFr=o("TFMPNetForMaskedLM"),_Fr=o(" (MPNet model)"),uFr=l(),r8=a("li"),IFe=a("strong"),bFr=o("openai-gpt"),vFr=o(" \u2014 "),_U=a("a"),FFr=o("TFOpenAIGPTLMHeadModel"),TFr=o(" (OpenAI GPT model)"),MFr=l(),t8=a("li"),NFe=a("strong"),EFr=o("roberta"),CFr=o(" \u2014 "),uU=a("a"),wFr=o("TFRobertaForMaskedLM"),AFr=o(" (RoBERTa model)"),LFr=l(),a8=a("li"),qFe=a("strong"),yFr=o("t5"),xFr=o(" \u2014 "),bU=a("a"),$Fr=o("TFT5ForConditionalGeneration"),kFr=o(" (T5 model)"),SFr=l(),n8=a("li"),jFe=a("strong"),RFr=o("tapas"),PFr=o(" \u2014 "),vU=a("a"),BFr=o("TFTapasForMaskedLM"),IFr=o(" (TAPAS model)"),NFr=l(),s8=a("li"),DFe=a("strong"),qFr=o("transfo-xl"),jFr=o(" \u2014 "),FU=a("a"),DFr=o("TFTransfoXLLMHeadModel"),GFr=o(" (Transformer-XL model)"),OFr=l(),l8=a("li"),GFe=a("strong"),VFr=o("vit_mae"),XFr=o(" \u2014 "),TU=a("a"),zFr=o("TFViTMAEForPreTraining"),QFr=o(" (ViTMAE model)"),WFr=l(),i8=a("li"),OFe=a("strong"),HFr=o("xlm"),UFr=o(" \u2014 "),MU=a("a"),JFr=o("TFXLMWithLMHeadModel"),YFr=o(" (XLM model)"),KFr=l(),d8=a("li"),VFe=a("strong"),ZFr=o("xlm-roberta"),e6r=o(" \u2014 "),EU=a("a"),o6r=o("TFXLMRobertaForMaskedLM"),r6r=o(" (XLM-RoBERTa model)"),t6r=l(),c8=a("li"),XFe=a("strong"),a6r=o("xlnet"),n6r=o(" \u2014 "),CU=a("a"),s6r=o("TFXLNetLMHeadModel"),l6r=o(" (XLNet model)"),i6r=l(),F(f8.$$.fragment),JOe=l(),sc=a("h2"),m8=a("a"),zFe=a("span"),F(w9.$$.fragment),d6r=l(),QFe=a("span"),c6r=o("TFAutoModelForCausalLM"),YOe=l(),rr=a("div"),F(A9.$$.fragment),f6r=l(),lc=a("p"),m6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=a("a"),g6r=o("from_pretrained()"),h6r=o(" class method or the "),AU=a("a"),p6r=o("from_config()"),_6r=o(` class
method.`),u6r=l(),L9=a("p"),b6r=o("This class cannot be instantiated directly using "),WFe=a("code"),v6r=o("__init__()"),F6r=o(" (throws an error)."),T6r=l(),St=a("div"),F(y9.$$.fragment),M6r=l(),HFe=a("p"),E6r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),C6r=l(),ic=a("p"),w6r=o(`Note:
Loading a model from its configuration file does `),UFe=a("strong"),A6r=o("not"),L6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=a("a"),y6r=o("from_pretrained()"),x6r=o(" to load the model weights."),$6r=l(),F(g8.$$.fragment),k6r=l(),$r=a("div"),F(x9.$$.fragment),S6r=l(),JFe=a("p"),R6r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),P6r=l(),sn=a("p"),B6r=o("The model class to instantiate is selected based on the "),YFe=a("code"),I6r=o("model_type"),N6r=o(` property of the config object (either
passed as an argument or loaded from `),KFe=a("code"),q6r=o("pretrained_model_name_or_path"),j6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZFe=a("code"),D6r=o("pretrained_model_name_or_path"),G6r=o(":"),O6r=l(),Me=a("ul"),h8=a("li"),e6e=a("strong"),V6r=o("bert"),X6r=o(" \u2014 "),yU=a("a"),z6r=o("TFBertLMHeadModel"),Q6r=o(" (BERT model)"),W6r=l(),p8=a("li"),o6e=a("strong"),H6r=o("camembert"),U6r=o(" \u2014 "),xU=a("a"),J6r=o("TFCamembertForCausalLM"),Y6r=o(" (CamemBERT model)"),K6r=l(),_8=a("li"),r6e=a("strong"),Z6r=o("ctrl"),eTr=o(" \u2014 "),$U=a("a"),oTr=o("TFCTRLLMHeadModel"),rTr=o(" (CTRL model)"),tTr=l(),u8=a("li"),t6e=a("strong"),aTr=o("gpt2"),nTr=o(" \u2014 "),kU=a("a"),sTr=o("TFGPT2LMHeadModel"),lTr=o(" (OpenAI GPT-2 model)"),iTr=l(),b8=a("li"),a6e=a("strong"),dTr=o("gptj"),cTr=o(" \u2014 "),SU=a("a"),fTr=o("TFGPTJForCausalLM"),mTr=o(" (GPT-J model)"),gTr=l(),v8=a("li"),n6e=a("strong"),hTr=o("openai-gpt"),pTr=o(" \u2014 "),RU=a("a"),_Tr=o("TFOpenAIGPTLMHeadModel"),uTr=o(" (OpenAI GPT model)"),bTr=l(),F8=a("li"),s6e=a("strong"),vTr=o("opt"),FTr=o(" \u2014 "),PU=a("a"),TTr=o("TFOPTForCausalLM"),MTr=o(" (OPT model)"),ETr=l(),T8=a("li"),l6e=a("strong"),CTr=o("rembert"),wTr=o(" \u2014 "),BU=a("a"),ATr=o("TFRemBertForCausalLM"),LTr=o(" (RemBERT model)"),yTr=l(),M8=a("li"),i6e=a("strong"),xTr=o("roberta"),$Tr=o(" \u2014 "),IU=a("a"),kTr=o("TFRobertaForCausalLM"),STr=o(" (RoBERTa model)"),RTr=l(),E8=a("li"),d6e=a("strong"),PTr=o("roformer"),BTr=o(" \u2014 "),NU=a("a"),ITr=o("TFRoFormerForCausalLM"),NTr=o(" (RoFormer model)"),qTr=l(),C8=a("li"),c6e=a("strong"),jTr=o("transfo-xl"),DTr=o(" \u2014 "),qU=a("a"),GTr=o("TFTransfoXLLMHeadModel"),OTr=o(" (Transformer-XL model)"),VTr=l(),w8=a("li"),f6e=a("strong"),XTr=o("xlm"),zTr=o(" \u2014 "),jU=a("a"),QTr=o("TFXLMWithLMHeadModel"),WTr=o(" (XLM model)"),HTr=l(),A8=a("li"),m6e=a("strong"),UTr=o("xlnet"),JTr=o(" \u2014 "),DU=a("a"),YTr=o("TFXLNetLMHeadModel"),KTr=o(" (XLNet model)"),ZTr=l(),F(L8.$$.fragment),KOe=l(),dc=a("h2"),y8=a("a"),g6e=a("span"),F($9.$$.fragment),e7r=l(),h6e=a("span"),o7r=o("TFAutoModelForImageClassification"),ZOe=l(),tr=a("div"),F(k9.$$.fragment),r7r=l(),cc=a("p"),t7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=a("a"),a7r=o("from_pretrained()"),n7r=o(" class method or the "),OU=a("a"),s7r=o("from_config()"),l7r=o(` class
method.`),i7r=l(),S9=a("p"),d7r=o("This class cannot be instantiated directly using "),p6e=a("code"),c7r=o("__init__()"),f7r=o(" (throws an error)."),m7r=l(),Rt=a("div"),F(R9.$$.fragment),g7r=l(),_6e=a("p"),h7r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),p7r=l(),fc=a("p"),_7r=o(`Note:
Loading a model from its configuration file does `),u6e=a("strong"),u7r=o("not"),b7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=a("a"),v7r=o("from_pretrained()"),F7r=o(" to load the model weights."),T7r=l(),F(x8.$$.fragment),M7r=l(),kr=a("div"),F(P9.$$.fragment),E7r=l(),b6e=a("p"),C7r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),w7r=l(),ln=a("p"),A7r=o("The model class to instantiate is selected based on the "),v6e=a("code"),L7r=o("model_type"),y7r=o(` property of the config object (either
passed as an argument or loaded from `),F6e=a("code"),x7r=o("pretrained_model_name_or_path"),$7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=a("code"),k7r=o("pretrained_model_name_or_path"),S7r=o(":"),R7r=l(),dn=a("ul"),$8=a("li"),M6e=a("strong"),P7r=o("convnext"),B7r=o(" \u2014 "),XU=a("a"),I7r=o("TFConvNextForImageClassification"),N7r=o(" (ConvNeXT model)"),q7r=l(),k8=a("li"),E6e=a("strong"),j7r=o("data2vec-vision"),D7r=o(" \u2014 "),zU=a("a"),G7r=o("TFData2VecVisionForImageClassification"),O7r=o(" (Data2VecVision model)"),V7r=l(),S8=a("li"),C6e=a("strong"),X7r=o("swin"),z7r=o(" \u2014 "),QU=a("a"),Q7r=o("TFSwinForImageClassification"),W7r=o(" (Swin Transformer model)"),H7r=l(),R8=a("li"),w6e=a("strong"),U7r=o("vit"),J7r=o(" \u2014 "),WU=a("a"),Y7r=o("TFViTForImageClassification"),K7r=o(" (ViT model)"),Z7r=l(),F(P8.$$.fragment),eVe=l(),mc=a("h2"),B8=a("a"),A6e=a("span"),F(B9.$$.fragment),e8r=l(),L6e=a("span"),o8r=o("TFAutoModelForMaskedLM"),oVe=l(),ar=a("div"),F(I9.$$.fragment),r8r=l(),gc=a("p"),t8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=a("a"),a8r=o("from_pretrained()"),n8r=o(" class method or the "),UU=a("a"),s8r=o("from_config()"),l8r=o(` class
method.`),i8r=l(),N9=a("p"),d8r=o("This class cannot be instantiated directly using "),y6e=a("code"),c8r=o("__init__()"),f8r=o(" (throws an error)."),m8r=l(),Pt=a("div"),F(q9.$$.fragment),g8r=l(),x6e=a("p"),h8r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),p8r=l(),hc=a("p"),_8r=o(`Note:
Loading a model from its configuration file does `),$6e=a("strong"),u8r=o("not"),b8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=a("a"),v8r=o("from_pretrained()"),F8r=o(" to load the model weights."),T8r=l(),F(I8.$$.fragment),M8r=l(),Sr=a("div"),F(j9.$$.fragment),E8r=l(),k6e=a("p"),C8r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),w8r=l(),cn=a("p"),A8r=o("The model class to instantiate is selected based on the "),S6e=a("code"),L8r=o("model_type"),y8r=o(` property of the config object (either
passed as an argument or loaded from `),R6e=a("code"),x8r=o("pretrained_model_name_or_path"),$8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P6e=a("code"),k8r=o("pretrained_model_name_or_path"),S8r=o(":"),R8r=l(),ie=a("ul"),N8=a("li"),B6e=a("strong"),P8r=o("albert"),B8r=o(" \u2014 "),YU=a("a"),I8r=o("TFAlbertForMaskedLM"),N8r=o(" (ALBERT model)"),q8r=l(),q8=a("li"),I6e=a("strong"),j8r=o("bert"),D8r=o(" \u2014 "),KU=a("a"),G8r=o("TFBertForMaskedLM"),O8r=o(" (BERT model)"),V8r=l(),j8=a("li"),N6e=a("strong"),X8r=o("camembert"),z8r=o(" \u2014 "),ZU=a("a"),Q8r=o("TFCamembertForMaskedLM"),W8r=o(" (CamemBERT model)"),H8r=l(),D8=a("li"),q6e=a("strong"),U8r=o("convbert"),J8r=o(" \u2014 "),eJ=a("a"),Y8r=o("TFConvBertForMaskedLM"),K8r=o(" (ConvBERT model)"),Z8r=l(),G8=a("li"),j6e=a("strong"),eMr=o("deberta"),oMr=o(" \u2014 "),oJ=a("a"),rMr=o("TFDebertaForMaskedLM"),tMr=o(" (DeBERTa model)"),aMr=l(),O8=a("li"),D6e=a("strong"),nMr=o("deberta-v2"),sMr=o(" \u2014 "),rJ=a("a"),lMr=o("TFDebertaV2ForMaskedLM"),iMr=o(" (DeBERTa-v2 model)"),dMr=l(),V8=a("li"),G6e=a("strong"),cMr=o("distilbert"),fMr=o(" \u2014 "),tJ=a("a"),mMr=o("TFDistilBertForMaskedLM"),gMr=o(" (DistilBERT model)"),hMr=l(),X8=a("li"),O6e=a("strong"),pMr=o("electra"),_Mr=o(" \u2014 "),aJ=a("a"),uMr=o("TFElectraForMaskedLM"),bMr=o(" (ELECTRA model)"),vMr=l(),z8=a("li"),V6e=a("strong"),FMr=o("flaubert"),TMr=o(" \u2014 "),nJ=a("a"),MMr=o("TFFlaubertWithLMHeadModel"),EMr=o(" (FlauBERT model)"),CMr=l(),Q8=a("li"),X6e=a("strong"),wMr=o("funnel"),AMr=o(" \u2014 "),sJ=a("a"),LMr=o("TFFunnelForMaskedLM"),yMr=o(" (Funnel Transformer model)"),xMr=l(),W8=a("li"),z6e=a("strong"),$Mr=o("layoutlm"),kMr=o(" \u2014 "),lJ=a("a"),SMr=o("TFLayoutLMForMaskedLM"),RMr=o(" (LayoutLM model)"),PMr=l(),H8=a("li"),Q6e=a("strong"),BMr=o("longformer"),IMr=o(" \u2014 "),iJ=a("a"),NMr=o("TFLongformerForMaskedLM"),qMr=o(" (Longformer model)"),jMr=l(),U8=a("li"),W6e=a("strong"),DMr=o("mobilebert"),GMr=o(" \u2014 "),dJ=a("a"),OMr=o("TFMobileBertForMaskedLM"),VMr=o(" (MobileBERT model)"),XMr=l(),J8=a("li"),H6e=a("strong"),zMr=o("mpnet"),QMr=o(" \u2014 "),cJ=a("a"),WMr=o("TFMPNetForMaskedLM"),HMr=o(" (MPNet model)"),UMr=l(),Y8=a("li"),U6e=a("strong"),JMr=o("rembert"),YMr=o(" \u2014 "),fJ=a("a"),KMr=o("TFRemBertForMaskedLM"),ZMr=o(" (RemBERT model)"),eEr=l(),K8=a("li"),J6e=a("strong"),oEr=o("roberta"),rEr=o(" \u2014 "),mJ=a("a"),tEr=o("TFRobertaForMaskedLM"),aEr=o(" (RoBERTa model)"),nEr=l(),Z8=a("li"),Y6e=a("strong"),sEr=o("roformer"),lEr=o(" \u2014 "),gJ=a("a"),iEr=o("TFRoFormerForMaskedLM"),dEr=o(" (RoFormer model)"),cEr=l(),eM=a("li"),K6e=a("strong"),fEr=o("tapas"),mEr=o(" \u2014 "),hJ=a("a"),gEr=o("TFTapasForMaskedLM"),hEr=o(" (TAPAS model)"),pEr=l(),oM=a("li"),Z6e=a("strong"),_Er=o("xlm"),uEr=o(" \u2014 "),pJ=a("a"),bEr=o("TFXLMWithLMHeadModel"),vEr=o(" (XLM model)"),FEr=l(),rM=a("li"),eTe=a("strong"),TEr=o("xlm-roberta"),MEr=o(" \u2014 "),_J=a("a"),EEr=o("TFXLMRobertaForMaskedLM"),CEr=o(" (XLM-RoBERTa model)"),wEr=l(),F(tM.$$.fragment),rVe=l(),pc=a("h2"),aM=a("a"),oTe=a("span"),F(D9.$$.fragment),AEr=l(),rTe=a("span"),LEr=o("TFAutoModelForSeq2SeqLM"),tVe=l(),nr=a("div"),F(G9.$$.fragment),yEr=l(),_c=a("p"),xEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uJ=a("a"),$Er=o("from_pretrained()"),kEr=o(" class method or the "),bJ=a("a"),SEr=o("from_config()"),REr=o(` class
method.`),PEr=l(),O9=a("p"),BEr=o("This class cannot be instantiated directly using "),tTe=a("code"),IEr=o("__init__()"),NEr=o(" (throws an error)."),qEr=l(),Bt=a("div"),F(V9.$$.fragment),jEr=l(),aTe=a("p"),DEr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),GEr=l(),uc=a("p"),OEr=o(`Note:
Loading a model from its configuration file does `),nTe=a("strong"),VEr=o("not"),XEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=a("a"),zEr=o("from_pretrained()"),QEr=o(" to load the model weights."),WEr=l(),F(nM.$$.fragment),HEr=l(),Rr=a("div"),F(X9.$$.fragment),UEr=l(),sTe=a("p"),JEr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),YEr=l(),fn=a("p"),KEr=o("The model class to instantiate is selected based on the "),lTe=a("code"),ZEr=o("model_type"),eCr=o(` property of the config object (either
passed as an argument or loaded from `),iTe=a("code"),oCr=o("pretrained_model_name_or_path"),rCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dTe=a("code"),tCr=o("pretrained_model_name_or_path"),aCr=o(":"),nCr=l(),ye=a("ul"),sM=a("li"),cTe=a("strong"),sCr=o("bart"),lCr=o(" \u2014 "),FJ=a("a"),iCr=o("TFBartForConditionalGeneration"),dCr=o(" (BART model)"),cCr=l(),lM=a("li"),fTe=a("strong"),fCr=o("blenderbot"),mCr=o(" \u2014 "),TJ=a("a"),gCr=o("TFBlenderbotForConditionalGeneration"),hCr=o(" (Blenderbot model)"),pCr=l(),iM=a("li"),mTe=a("strong"),_Cr=o("blenderbot-small"),uCr=o(" \u2014 "),MJ=a("a"),bCr=o("TFBlenderbotSmallForConditionalGeneration"),vCr=o(" (BlenderbotSmall model)"),FCr=l(),dM=a("li"),gTe=a("strong"),TCr=o("encoder-decoder"),MCr=o(" \u2014 "),EJ=a("a"),ECr=o("TFEncoderDecoderModel"),CCr=o(" (Encoder decoder model)"),wCr=l(),cM=a("li"),hTe=a("strong"),ACr=o("led"),LCr=o(" \u2014 "),CJ=a("a"),yCr=o("TFLEDForConditionalGeneration"),xCr=o(" (LED model)"),$Cr=l(),fM=a("li"),pTe=a("strong"),kCr=o("marian"),SCr=o(" \u2014 "),wJ=a("a"),RCr=o("TFMarianMTModel"),PCr=o(" (Marian model)"),BCr=l(),mM=a("li"),_Te=a("strong"),ICr=o("mbart"),NCr=o(" \u2014 "),AJ=a("a"),qCr=o("TFMBartForConditionalGeneration"),jCr=o(" (mBART model)"),DCr=l(),gM=a("li"),uTe=a("strong"),GCr=o("mt5"),OCr=o(" \u2014 "),LJ=a("a"),VCr=o("TFMT5ForConditionalGeneration"),XCr=o(" (MT5 model)"),zCr=l(),hM=a("li"),bTe=a("strong"),QCr=o("pegasus"),WCr=o(" \u2014 "),yJ=a("a"),HCr=o("TFPegasusForConditionalGeneration"),UCr=o(" (Pegasus model)"),JCr=l(),pM=a("li"),vTe=a("strong"),YCr=o("t5"),KCr=o(" \u2014 "),xJ=a("a"),ZCr=o("TFT5ForConditionalGeneration"),e5r=o(" (T5 model)"),o5r=l(),F(_M.$$.fragment),aVe=l(),bc=a("h2"),uM=a("a"),FTe=a("span"),F(z9.$$.fragment),r5r=l(),TTe=a("span"),t5r=o("TFAutoModelForSequenceClassification"),nVe=l(),sr=a("div"),F(Q9.$$.fragment),a5r=l(),vc=a("p"),n5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=a("a"),s5r=o("from_pretrained()"),l5r=o(" class method or the "),kJ=a("a"),i5r=o("from_config()"),d5r=o(` class
method.`),c5r=l(),W9=a("p"),f5r=o("This class cannot be instantiated directly using "),MTe=a("code"),m5r=o("__init__()"),g5r=o(" (throws an error)."),h5r=l(),It=a("div"),F(H9.$$.fragment),p5r=l(),ETe=a("p"),_5r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),u5r=l(),Fc=a("p"),b5r=o(`Note:
Loading a model from its configuration file does `),CTe=a("strong"),v5r=o("not"),F5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=a("a"),T5r=o("from_pretrained()"),M5r=o(" to load the model weights."),E5r=l(),F(bM.$$.fragment),C5r=l(),Pr=a("div"),F(U9.$$.fragment),w5r=l(),wTe=a("p"),A5r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),L5r=l(),mn=a("p"),y5r=o("The model class to instantiate is selected based on the "),ATe=a("code"),x5r=o("model_type"),$5r=o(` property of the config object (either
passed as an argument or loaded from `),LTe=a("code"),k5r=o("pretrained_model_name_or_path"),S5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yTe=a("code"),R5r=o("pretrained_model_name_or_path"),P5r=o(":"),B5r=l(),te=a("ul"),vM=a("li"),xTe=a("strong"),I5r=o("albert"),N5r=o(" \u2014 "),RJ=a("a"),q5r=o("TFAlbertForSequenceClassification"),j5r=o(" (ALBERT model)"),D5r=l(),FM=a("li"),$Te=a("strong"),G5r=o("bert"),O5r=o(" \u2014 "),PJ=a("a"),V5r=o("TFBertForSequenceClassification"),X5r=o(" (BERT model)"),z5r=l(),TM=a("li"),kTe=a("strong"),Q5r=o("camembert"),W5r=o(" \u2014 "),BJ=a("a"),H5r=o("TFCamembertForSequenceClassification"),U5r=o(" (CamemBERT model)"),J5r=l(),MM=a("li"),STe=a("strong"),Y5r=o("convbert"),K5r=o(" \u2014 "),IJ=a("a"),Z5r=o("TFConvBertForSequenceClassification"),e3r=o(" (ConvBERT model)"),o3r=l(),EM=a("li"),RTe=a("strong"),r3r=o("ctrl"),t3r=o(" \u2014 "),NJ=a("a"),a3r=o("TFCTRLForSequenceClassification"),n3r=o(" (CTRL model)"),s3r=l(),CM=a("li"),PTe=a("strong"),l3r=o("deberta"),i3r=o(" \u2014 "),qJ=a("a"),d3r=o("TFDebertaForSequenceClassification"),c3r=o(" (DeBERTa model)"),f3r=l(),wM=a("li"),BTe=a("strong"),m3r=o("deberta-v2"),g3r=o(" \u2014 "),jJ=a("a"),h3r=o("TFDebertaV2ForSequenceClassification"),p3r=o(" (DeBERTa-v2 model)"),_3r=l(),AM=a("li"),ITe=a("strong"),u3r=o("distilbert"),b3r=o(" \u2014 "),DJ=a("a"),v3r=o("TFDistilBertForSequenceClassification"),F3r=o(" (DistilBERT model)"),T3r=l(),LM=a("li"),NTe=a("strong"),M3r=o("electra"),E3r=o(" \u2014 "),GJ=a("a"),C3r=o("TFElectraForSequenceClassification"),w3r=o(" (ELECTRA model)"),A3r=l(),yM=a("li"),qTe=a("strong"),L3r=o("flaubert"),y3r=o(" \u2014 "),OJ=a("a"),x3r=o("TFFlaubertForSequenceClassification"),$3r=o(" (FlauBERT model)"),k3r=l(),xM=a("li"),jTe=a("strong"),S3r=o("funnel"),R3r=o(" \u2014 "),VJ=a("a"),P3r=o("TFFunnelForSequenceClassification"),B3r=o(" (Funnel Transformer model)"),I3r=l(),$M=a("li"),DTe=a("strong"),N3r=o("gpt2"),q3r=o(" \u2014 "),XJ=a("a"),j3r=o("TFGPT2ForSequenceClassification"),D3r=o(" (OpenAI GPT-2 model)"),G3r=l(),kM=a("li"),GTe=a("strong"),O3r=o("gptj"),V3r=o(" \u2014 "),zJ=a("a"),X3r=o("TFGPTJForSequenceClassification"),z3r=o(" (GPT-J model)"),Q3r=l(),SM=a("li"),OTe=a("strong"),W3r=o("layoutlm"),H3r=o(" \u2014 "),QJ=a("a"),U3r=o("TFLayoutLMForSequenceClassification"),J3r=o(" (LayoutLM model)"),Y3r=l(),RM=a("li"),VTe=a("strong"),K3r=o("longformer"),Z3r=o(" \u2014 "),WJ=a("a"),e0r=o("TFLongformerForSequenceClassification"),o0r=o(" (Longformer model)"),r0r=l(),PM=a("li"),XTe=a("strong"),t0r=o("mobilebert"),a0r=o(" \u2014 "),HJ=a("a"),n0r=o("TFMobileBertForSequenceClassification"),s0r=o(" (MobileBERT model)"),l0r=l(),BM=a("li"),zTe=a("strong"),i0r=o("mpnet"),d0r=o(" \u2014 "),UJ=a("a"),c0r=o("TFMPNetForSequenceClassification"),f0r=o(" (MPNet model)"),m0r=l(),IM=a("li"),QTe=a("strong"),g0r=o("openai-gpt"),h0r=o(" \u2014 "),JJ=a("a"),p0r=o("TFOpenAIGPTForSequenceClassification"),_0r=o(" (OpenAI GPT model)"),u0r=l(),NM=a("li"),WTe=a("strong"),b0r=o("rembert"),v0r=o(" \u2014 "),YJ=a("a"),F0r=o("TFRemBertForSequenceClassification"),T0r=o(" (RemBERT model)"),M0r=l(),qM=a("li"),HTe=a("strong"),E0r=o("roberta"),C0r=o(" \u2014 "),KJ=a("a"),w0r=o("TFRobertaForSequenceClassification"),A0r=o(" (RoBERTa model)"),L0r=l(),jM=a("li"),UTe=a("strong"),y0r=o("roformer"),x0r=o(" \u2014 "),ZJ=a("a"),$0r=o("TFRoFormerForSequenceClassification"),k0r=o(" (RoFormer model)"),S0r=l(),DM=a("li"),JTe=a("strong"),R0r=o("tapas"),P0r=o(" \u2014 "),eY=a("a"),B0r=o("TFTapasForSequenceClassification"),I0r=o(" (TAPAS model)"),N0r=l(),GM=a("li"),YTe=a("strong"),q0r=o("transfo-xl"),j0r=o(" \u2014 "),oY=a("a"),D0r=o("TFTransfoXLForSequenceClassification"),G0r=o(" (Transformer-XL model)"),O0r=l(),OM=a("li"),KTe=a("strong"),V0r=o("xlm"),X0r=o(" \u2014 "),rY=a("a"),z0r=o("TFXLMForSequenceClassification"),Q0r=o(" (XLM model)"),W0r=l(),VM=a("li"),ZTe=a("strong"),H0r=o("xlm-roberta"),U0r=o(" \u2014 "),tY=a("a"),J0r=o("TFXLMRobertaForSequenceClassification"),Y0r=o(" (XLM-RoBERTa model)"),K0r=l(),XM=a("li"),e7e=a("strong"),Z0r=o("xlnet"),ewr=o(" \u2014 "),aY=a("a"),owr=o("TFXLNetForSequenceClassification"),rwr=o(" (XLNet model)"),twr=l(),F(zM.$$.fragment),sVe=l(),Tc=a("h2"),QM=a("a"),o7e=a("span"),F(J9.$$.fragment),awr=l(),r7e=a("span"),nwr=o("TFAutoModelForMultipleChoice"),lVe=l(),lr=a("div"),F(Y9.$$.fragment),swr=l(),Mc=a("p"),lwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=a("a"),iwr=o("from_pretrained()"),dwr=o(" class method or the "),sY=a("a"),cwr=o("from_config()"),fwr=o(` class
method.`),mwr=l(),K9=a("p"),gwr=o("This class cannot be instantiated directly using "),t7e=a("code"),hwr=o("__init__()"),pwr=o(" (throws an error)."),_wr=l(),Nt=a("div"),F(Z9.$$.fragment),uwr=l(),a7e=a("p"),bwr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vwr=l(),Ec=a("p"),Fwr=o(`Note:
Loading a model from its configuration file does `),n7e=a("strong"),Twr=o("not"),Mwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=a("a"),Ewr=o("from_pretrained()"),Cwr=o(" to load the model weights."),wwr=l(),F(WM.$$.fragment),Awr=l(),Br=a("div"),F(ex.$$.fragment),Lwr=l(),s7e=a("p"),ywr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),xwr=l(),gn=a("p"),$wr=o("The model class to instantiate is selected based on the "),l7e=a("code"),kwr=o("model_type"),Swr=o(` property of the config object (either
passed as an argument or loaded from `),i7e=a("code"),Rwr=o("pretrained_model_name_or_path"),Pwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=a("code"),Bwr=o("pretrained_model_name_or_path"),Iwr=o(":"),Nwr=l(),_e=a("ul"),HM=a("li"),c7e=a("strong"),qwr=o("albert"),jwr=o(" \u2014 "),iY=a("a"),Dwr=o("TFAlbertForMultipleChoice"),Gwr=o(" (ALBERT model)"),Owr=l(),UM=a("li"),f7e=a("strong"),Vwr=o("bert"),Xwr=o(" \u2014 "),dY=a("a"),zwr=o("TFBertForMultipleChoice"),Qwr=o(" (BERT model)"),Wwr=l(),JM=a("li"),m7e=a("strong"),Hwr=o("camembert"),Uwr=o(" \u2014 "),cY=a("a"),Jwr=o("TFCamembertForMultipleChoice"),Ywr=o(" (CamemBERT model)"),Kwr=l(),YM=a("li"),g7e=a("strong"),Zwr=o("convbert"),eAr=o(" \u2014 "),fY=a("a"),oAr=o("TFConvBertForMultipleChoice"),rAr=o(" (ConvBERT model)"),tAr=l(),KM=a("li"),h7e=a("strong"),aAr=o("distilbert"),nAr=o(" \u2014 "),mY=a("a"),sAr=o("TFDistilBertForMultipleChoice"),lAr=o(" (DistilBERT model)"),iAr=l(),ZM=a("li"),p7e=a("strong"),dAr=o("electra"),cAr=o(" \u2014 "),gY=a("a"),fAr=o("TFElectraForMultipleChoice"),mAr=o(" (ELECTRA model)"),gAr=l(),eE=a("li"),_7e=a("strong"),hAr=o("flaubert"),pAr=o(" \u2014 "),hY=a("a"),_Ar=o("TFFlaubertForMultipleChoice"),uAr=o(" (FlauBERT model)"),bAr=l(),oE=a("li"),u7e=a("strong"),vAr=o("funnel"),FAr=o(" \u2014 "),pY=a("a"),TAr=o("TFFunnelForMultipleChoice"),MAr=o(" (Funnel Transformer model)"),EAr=l(),rE=a("li"),b7e=a("strong"),CAr=o("longformer"),wAr=o(" \u2014 "),_Y=a("a"),AAr=o("TFLongformerForMultipleChoice"),LAr=o(" (Longformer model)"),yAr=l(),tE=a("li"),v7e=a("strong"),xAr=o("mobilebert"),$Ar=o(" \u2014 "),uY=a("a"),kAr=o("TFMobileBertForMultipleChoice"),SAr=o(" (MobileBERT model)"),RAr=l(),aE=a("li"),F7e=a("strong"),PAr=o("mpnet"),BAr=o(" \u2014 "),bY=a("a"),IAr=o("TFMPNetForMultipleChoice"),NAr=o(" (MPNet model)"),qAr=l(),nE=a("li"),T7e=a("strong"),jAr=o("rembert"),DAr=o(" \u2014 "),vY=a("a"),GAr=o("TFRemBertForMultipleChoice"),OAr=o(" (RemBERT model)"),VAr=l(),sE=a("li"),M7e=a("strong"),XAr=o("roberta"),zAr=o(" \u2014 "),FY=a("a"),QAr=o("TFRobertaForMultipleChoice"),WAr=o(" (RoBERTa model)"),HAr=l(),lE=a("li"),E7e=a("strong"),UAr=o("roformer"),JAr=o(" \u2014 "),TY=a("a"),YAr=o("TFRoFormerForMultipleChoice"),KAr=o(" (RoFormer model)"),ZAr=l(),iE=a("li"),C7e=a("strong"),eLr=o("xlm"),oLr=o(" \u2014 "),MY=a("a"),rLr=o("TFXLMForMultipleChoice"),tLr=o(" (XLM model)"),aLr=l(),dE=a("li"),w7e=a("strong"),nLr=o("xlm-roberta"),sLr=o(" \u2014 "),EY=a("a"),lLr=o("TFXLMRobertaForMultipleChoice"),iLr=o(" (XLM-RoBERTa model)"),dLr=l(),cE=a("li"),A7e=a("strong"),cLr=o("xlnet"),fLr=o(" \u2014 "),CY=a("a"),mLr=o("TFXLNetForMultipleChoice"),gLr=o(" (XLNet model)"),hLr=l(),F(fE.$$.fragment),iVe=l(),Cc=a("h2"),mE=a("a"),L7e=a("span"),F(ox.$$.fragment),pLr=l(),y7e=a("span"),_Lr=o("TFAutoModelForNextSentencePrediction"),dVe=l(),ir=a("div"),F(rx.$$.fragment),uLr=l(),wc=a("p"),bLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=a("a"),vLr=o("from_pretrained()"),FLr=o(" class method or the "),AY=a("a"),TLr=o("from_config()"),MLr=o(` class
method.`),ELr=l(),tx=a("p"),CLr=o("This class cannot be instantiated directly using "),x7e=a("code"),wLr=o("__init__()"),ALr=o(" (throws an error)."),LLr=l(),qt=a("div"),F(ax.$$.fragment),yLr=l(),$7e=a("p"),xLr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$Lr=l(),Ac=a("p"),kLr=o(`Note:
Loading a model from its configuration file does `),k7e=a("strong"),SLr=o("not"),RLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=a("a"),PLr=o("from_pretrained()"),BLr=o(" to load the model weights."),ILr=l(),F(gE.$$.fragment),NLr=l(),Ir=a("div"),F(nx.$$.fragment),qLr=l(),S7e=a("p"),jLr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),DLr=l(),hn=a("p"),GLr=o("The model class to instantiate is selected based on the "),R7e=a("code"),OLr=o("model_type"),VLr=o(` property of the config object (either
passed as an argument or loaded from `),P7e=a("code"),XLr=o("pretrained_model_name_or_path"),zLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B7e=a("code"),QLr=o("pretrained_model_name_or_path"),WLr=o(":"),HLr=l(),sx=a("ul"),hE=a("li"),I7e=a("strong"),ULr=o("bert"),JLr=o(" \u2014 "),yY=a("a"),YLr=o("TFBertForNextSentencePrediction"),KLr=o(" (BERT model)"),ZLr=l(),pE=a("li"),N7e=a("strong"),eyr=o("mobilebert"),oyr=o(" \u2014 "),xY=a("a"),ryr=o("TFMobileBertForNextSentencePrediction"),tyr=o(" (MobileBERT model)"),ayr=l(),F(_E.$$.fragment),cVe=l(),Lc=a("h2"),uE=a("a"),q7e=a("span"),F(lx.$$.fragment),nyr=l(),j7e=a("span"),syr=o("TFAutoModelForTableQuestionAnswering"),fVe=l(),dr=a("div"),F(ix.$$.fragment),lyr=l(),yc=a("p"),iyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=a("a"),dyr=o("from_pretrained()"),cyr=o(" class method or the "),kY=a("a"),fyr=o("from_config()"),myr=o(` class
method.`),gyr=l(),dx=a("p"),hyr=o("This class cannot be instantiated directly using "),D7e=a("code"),pyr=o("__init__()"),_yr=o(" (throws an error)."),uyr=l(),jt=a("div"),F(cx.$$.fragment),byr=l(),G7e=a("p"),vyr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Fyr=l(),xc=a("p"),Tyr=o(`Note:
Loading a model from its configuration file does `),O7e=a("strong"),Myr=o("not"),Eyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=a("a"),Cyr=o("from_pretrained()"),wyr=o(" to load the model weights."),Ayr=l(),F(bE.$$.fragment),Lyr=l(),Nr=a("div"),F(fx.$$.fragment),yyr=l(),V7e=a("p"),xyr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),$yr=l(),pn=a("p"),kyr=o("The model class to instantiate is selected based on the "),X7e=a("code"),Syr=o("model_type"),Ryr=o(` property of the config object (either
passed as an argument or loaded from `),z7e=a("code"),Pyr=o("pretrained_model_name_or_path"),Byr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q7e=a("code"),Iyr=o("pretrained_model_name_or_path"),Nyr=o(":"),qyr=l(),W7e=a("ul"),vE=a("li"),H7e=a("strong"),jyr=o("tapas"),Dyr=o(" \u2014 "),RY=a("a"),Gyr=o("TFTapasForQuestionAnswering"),Oyr=o(" (TAPAS model)"),Vyr=l(),F(FE.$$.fragment),mVe=l(),$c=a("h2"),TE=a("a"),U7e=a("span"),F(mx.$$.fragment),Xyr=l(),J7e=a("span"),zyr=o("TFAutoModelForTokenClassification"),gVe=l(),cr=a("div"),F(gx.$$.fragment),Qyr=l(),kc=a("p"),Wyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=a("a"),Hyr=o("from_pretrained()"),Uyr=o(" class method or the "),BY=a("a"),Jyr=o("from_config()"),Yyr=o(` class
method.`),Kyr=l(),hx=a("p"),Zyr=o("This class cannot be instantiated directly using "),Y7e=a("code"),e9r=o("__init__()"),o9r=o(" (throws an error)."),r9r=l(),Dt=a("div"),F(px.$$.fragment),t9r=l(),K7e=a("p"),a9r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),n9r=l(),Sc=a("p"),s9r=o(`Note:
Loading a model from its configuration file does `),Z7e=a("strong"),l9r=o("not"),i9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),d9r=o("from_pretrained()"),c9r=o(" to load the model weights."),f9r=l(),F(ME.$$.fragment),m9r=l(),qr=a("div"),F(_x.$$.fragment),g9r=l(),e8e=a("p"),h9r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),p9r=l(),_n=a("p"),_9r=o("The model class to instantiate is selected based on the "),o8e=a("code"),u9r=o("model_type"),b9r=o(` property of the config object (either
passed as an argument or loaded from `),r8e=a("code"),v9r=o("pretrained_model_name_or_path"),F9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t8e=a("code"),T9r=o("pretrained_model_name_or_path"),M9r=o(":"),E9r=l(),de=a("ul"),EE=a("li"),a8e=a("strong"),C9r=o("albert"),w9r=o(" \u2014 "),NY=a("a"),A9r=o("TFAlbertForTokenClassification"),L9r=o(" (ALBERT model)"),y9r=l(),CE=a("li"),n8e=a("strong"),x9r=o("bert"),$9r=o(" \u2014 "),qY=a("a"),k9r=o("TFBertForTokenClassification"),S9r=o(" (BERT model)"),R9r=l(),wE=a("li"),s8e=a("strong"),P9r=o("camembert"),B9r=o(" \u2014 "),jY=a("a"),I9r=o("TFCamembertForTokenClassification"),N9r=o(" (CamemBERT model)"),q9r=l(),AE=a("li"),l8e=a("strong"),j9r=o("convbert"),D9r=o(" \u2014 "),DY=a("a"),G9r=o("TFConvBertForTokenClassification"),O9r=o(" (ConvBERT model)"),V9r=l(),LE=a("li"),i8e=a("strong"),X9r=o("deberta"),z9r=o(" \u2014 "),GY=a("a"),Q9r=o("TFDebertaForTokenClassification"),W9r=o(" (DeBERTa model)"),H9r=l(),yE=a("li"),d8e=a("strong"),U9r=o("deberta-v2"),J9r=o(" \u2014 "),OY=a("a"),Y9r=o("TFDebertaV2ForTokenClassification"),K9r=o(" (DeBERTa-v2 model)"),Z9r=l(),xE=a("li"),c8e=a("strong"),exr=o("distilbert"),oxr=o(" \u2014 "),VY=a("a"),rxr=o("TFDistilBertForTokenClassification"),txr=o(" (DistilBERT model)"),axr=l(),$E=a("li"),f8e=a("strong"),nxr=o("electra"),sxr=o(" \u2014 "),XY=a("a"),lxr=o("TFElectraForTokenClassification"),ixr=o(" (ELECTRA model)"),dxr=l(),kE=a("li"),m8e=a("strong"),cxr=o("flaubert"),fxr=o(" \u2014 "),zY=a("a"),mxr=o("TFFlaubertForTokenClassification"),gxr=o(" (FlauBERT model)"),hxr=l(),SE=a("li"),g8e=a("strong"),pxr=o("funnel"),_xr=o(" \u2014 "),QY=a("a"),uxr=o("TFFunnelForTokenClassification"),bxr=o(" (Funnel Transformer model)"),vxr=l(),RE=a("li"),h8e=a("strong"),Fxr=o("layoutlm"),Txr=o(" \u2014 "),WY=a("a"),Mxr=o("TFLayoutLMForTokenClassification"),Exr=o(" (LayoutLM model)"),Cxr=l(),PE=a("li"),p8e=a("strong"),wxr=o("longformer"),Axr=o(" \u2014 "),HY=a("a"),Lxr=o("TFLongformerForTokenClassification"),yxr=o(" (Longformer model)"),xxr=l(),BE=a("li"),_8e=a("strong"),$xr=o("mobilebert"),kxr=o(" \u2014 "),UY=a("a"),Sxr=o("TFMobileBertForTokenClassification"),Rxr=o(" (MobileBERT model)"),Pxr=l(),IE=a("li"),u8e=a("strong"),Bxr=o("mpnet"),Ixr=o(" \u2014 "),JY=a("a"),Nxr=o("TFMPNetForTokenClassification"),qxr=o(" (MPNet model)"),jxr=l(),NE=a("li"),b8e=a("strong"),Dxr=o("rembert"),Gxr=o(" \u2014 "),YY=a("a"),Oxr=o("TFRemBertForTokenClassification"),Vxr=o(" (RemBERT model)"),Xxr=l(),qE=a("li"),v8e=a("strong"),zxr=o("roberta"),Qxr=o(" \u2014 "),KY=a("a"),Wxr=o("TFRobertaForTokenClassification"),Hxr=o(" (RoBERTa model)"),Uxr=l(),jE=a("li"),F8e=a("strong"),Jxr=o("roformer"),Yxr=o(" \u2014 "),ZY=a("a"),Kxr=o("TFRoFormerForTokenClassification"),Zxr=o(" (RoFormer model)"),e$r=l(),DE=a("li"),T8e=a("strong"),o$r=o("xlm"),r$r=o(" \u2014 "),eK=a("a"),t$r=o("TFXLMForTokenClassification"),a$r=o(" (XLM model)"),n$r=l(),GE=a("li"),M8e=a("strong"),s$r=o("xlm-roberta"),l$r=o(" \u2014 "),oK=a("a"),i$r=o("TFXLMRobertaForTokenClassification"),d$r=o(" (XLM-RoBERTa model)"),c$r=l(),OE=a("li"),E8e=a("strong"),f$r=o("xlnet"),m$r=o(" \u2014 "),rK=a("a"),g$r=o("TFXLNetForTokenClassification"),h$r=o(" (XLNet model)"),p$r=l(),F(VE.$$.fragment),hVe=l(),Rc=a("h2"),XE=a("a"),C8e=a("span"),F(ux.$$.fragment),_$r=l(),w8e=a("span"),u$r=o("TFAutoModelForQuestionAnswering"),pVe=l(),fr=a("div"),F(bx.$$.fragment),b$r=l(),Pc=a("p"),v$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=a("a"),F$r=o("from_pretrained()"),T$r=o(" class method or the "),aK=a("a"),M$r=o("from_config()"),E$r=o(` class
method.`),C$r=l(),vx=a("p"),w$r=o("This class cannot be instantiated directly using "),A8e=a("code"),A$r=o("__init__()"),L$r=o(" (throws an error)."),y$r=l(),Gt=a("div"),F(Fx.$$.fragment),x$r=l(),L8e=a("p"),$$r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),k$r=l(),Bc=a("p"),S$r=o(`Note:
Loading a model from its configuration file does `),y8e=a("strong"),R$r=o("not"),P$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),B$r=o("from_pretrained()"),I$r=o(" to load the model weights."),N$r=l(),F(zE.$$.fragment),q$r=l(),jr=a("div"),F(Tx.$$.fragment),j$r=l(),x8e=a("p"),D$r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),G$r=l(),un=a("p"),O$r=o("The model class to instantiate is selected based on the "),$8e=a("code"),V$r=o("model_type"),X$r=o(` property of the config object (either
passed as an argument or loaded from `),k8e=a("code"),z$r=o("pretrained_model_name_or_path"),Q$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S8e=a("code"),W$r=o("pretrained_model_name_or_path"),H$r=o(":"),U$r=l(),ce=a("ul"),QE=a("li"),R8e=a("strong"),J$r=o("albert"),Y$r=o(" \u2014 "),sK=a("a"),K$r=o("TFAlbertForQuestionAnswering"),Z$r=o(" (ALBERT model)"),ekr=l(),WE=a("li"),P8e=a("strong"),okr=o("bert"),rkr=o(" \u2014 "),lK=a("a"),tkr=o("TFBertForQuestionAnswering"),akr=o(" (BERT model)"),nkr=l(),HE=a("li"),B8e=a("strong"),skr=o("camembert"),lkr=o(" \u2014 "),iK=a("a"),ikr=o("TFCamembertForQuestionAnswering"),dkr=o(" (CamemBERT model)"),ckr=l(),UE=a("li"),I8e=a("strong"),fkr=o("convbert"),mkr=o(" \u2014 "),dK=a("a"),gkr=o("TFConvBertForQuestionAnswering"),hkr=o(" (ConvBERT model)"),pkr=l(),JE=a("li"),N8e=a("strong"),_kr=o("deberta"),ukr=o(" \u2014 "),cK=a("a"),bkr=o("TFDebertaForQuestionAnswering"),vkr=o(" (DeBERTa model)"),Fkr=l(),YE=a("li"),q8e=a("strong"),Tkr=o("deberta-v2"),Mkr=o(" \u2014 "),fK=a("a"),Ekr=o("TFDebertaV2ForQuestionAnswering"),Ckr=o(" (DeBERTa-v2 model)"),wkr=l(),KE=a("li"),j8e=a("strong"),Akr=o("distilbert"),Lkr=o(" \u2014 "),mK=a("a"),ykr=o("TFDistilBertForQuestionAnswering"),xkr=o(" (DistilBERT model)"),$kr=l(),ZE=a("li"),D8e=a("strong"),kkr=o("electra"),Skr=o(" \u2014 "),gK=a("a"),Rkr=o("TFElectraForQuestionAnswering"),Pkr=o(" (ELECTRA model)"),Bkr=l(),eC=a("li"),G8e=a("strong"),Ikr=o("flaubert"),Nkr=o(" \u2014 "),hK=a("a"),qkr=o("TFFlaubertForQuestionAnsweringSimple"),jkr=o(" (FlauBERT model)"),Dkr=l(),oC=a("li"),O8e=a("strong"),Gkr=o("funnel"),Okr=o(" \u2014 "),pK=a("a"),Vkr=o("TFFunnelForQuestionAnswering"),Xkr=o(" (Funnel Transformer model)"),zkr=l(),rC=a("li"),V8e=a("strong"),Qkr=o("gptj"),Wkr=o(" \u2014 "),_K=a("a"),Hkr=o("TFGPTJForQuestionAnswering"),Ukr=o(" (GPT-J model)"),Jkr=l(),tC=a("li"),X8e=a("strong"),Ykr=o("longformer"),Kkr=o(" \u2014 "),uK=a("a"),Zkr=o("TFLongformerForQuestionAnswering"),eSr=o(" (Longformer model)"),oSr=l(),aC=a("li"),z8e=a("strong"),rSr=o("mobilebert"),tSr=o(" \u2014 "),bK=a("a"),aSr=o("TFMobileBertForQuestionAnswering"),nSr=o(" (MobileBERT model)"),sSr=l(),nC=a("li"),Q8e=a("strong"),lSr=o("mpnet"),iSr=o(" \u2014 "),vK=a("a"),dSr=o("TFMPNetForQuestionAnswering"),cSr=o(" (MPNet model)"),fSr=l(),sC=a("li"),W8e=a("strong"),mSr=o("rembert"),gSr=o(" \u2014 "),FK=a("a"),hSr=o("TFRemBertForQuestionAnswering"),pSr=o(" (RemBERT model)"),_Sr=l(),lC=a("li"),H8e=a("strong"),uSr=o("roberta"),bSr=o(" \u2014 "),TK=a("a"),vSr=o("TFRobertaForQuestionAnswering"),FSr=o(" (RoBERTa model)"),TSr=l(),iC=a("li"),U8e=a("strong"),MSr=o("roformer"),ESr=o(" \u2014 "),MK=a("a"),CSr=o("TFRoFormerForQuestionAnswering"),wSr=o(" (RoFormer model)"),ASr=l(),dC=a("li"),J8e=a("strong"),LSr=o("xlm"),ySr=o(" \u2014 "),EK=a("a"),xSr=o("TFXLMForQuestionAnsweringSimple"),$Sr=o(" (XLM model)"),kSr=l(),cC=a("li"),Y8e=a("strong"),SSr=o("xlm-roberta"),RSr=o(" \u2014 "),CK=a("a"),PSr=o("TFXLMRobertaForQuestionAnswering"),BSr=o(" (XLM-RoBERTa model)"),ISr=l(),fC=a("li"),K8e=a("strong"),NSr=o("xlnet"),qSr=o(" \u2014 "),wK=a("a"),jSr=o("TFXLNetForQuestionAnsweringSimple"),DSr=o(" (XLNet model)"),GSr=l(),F(mC.$$.fragment),_Ve=l(),Ic=a("h2"),gC=a("a"),Z8e=a("span"),F(Mx.$$.fragment),OSr=l(),eMe=a("span"),VSr=o("TFAutoModelForVision2Seq"),uVe=l(),mr=a("div"),F(Ex.$$.fragment),XSr=l(),Nc=a("p"),zSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=a("a"),QSr=o("from_pretrained()"),WSr=o(" class method or the "),LK=a("a"),HSr=o("from_config()"),USr=o(` class
method.`),JSr=l(),Cx=a("p"),YSr=o("This class cannot be instantiated directly using "),oMe=a("code"),KSr=o("__init__()"),ZSr=o(" (throws an error)."),eRr=l(),Ot=a("div"),F(wx.$$.fragment),oRr=l(),rMe=a("p"),rRr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),tRr=l(),qc=a("p"),aRr=o(`Note:
Loading a model from its configuration file does `),tMe=a("strong"),nRr=o("not"),sRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=a("a"),lRr=o("from_pretrained()"),iRr=o(" to load the model weights."),dRr=l(),F(hC.$$.fragment),cRr=l(),Dr=a("div"),F(Ax.$$.fragment),fRr=l(),aMe=a("p"),mRr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gRr=l(),bn=a("p"),hRr=o("The model class to instantiate is selected based on the "),nMe=a("code"),pRr=o("model_type"),_Rr=o(` property of the config object (either
passed as an argument or loaded from `),sMe=a("code"),uRr=o("pretrained_model_name_or_path"),bRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lMe=a("code"),vRr=o("pretrained_model_name_or_path"),FRr=o(":"),TRr=l(),iMe=a("ul"),pC=a("li"),dMe=a("strong"),MRr=o("vision-encoder-decoder"),ERr=o(" \u2014 "),xK=a("a"),CRr=o("TFVisionEncoderDecoderModel"),wRr=o(" (Vision Encoder decoder model)"),ARr=l(),F(_C.$$.fragment),bVe=l(),jc=a("h2"),uC=a("a"),cMe=a("span"),F(Lx.$$.fragment),LRr=l(),fMe=a("span"),yRr=o("TFAutoModelForSpeechSeq2Seq"),vVe=l(),gr=a("div"),F(yx.$$.fragment),xRr=l(),Dc=a("p"),$Rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=a("a"),kRr=o("from_pretrained()"),SRr=o(" class method or the "),kK=a("a"),RRr=o("from_config()"),PRr=o(` class
method.`),BRr=l(),xx=a("p"),IRr=o("This class cannot be instantiated directly using "),mMe=a("code"),NRr=o("__init__()"),qRr=o(" (throws an error)."),jRr=l(),Vt=a("div"),F($x.$$.fragment),DRr=l(),gMe=a("p"),GRr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ORr=l(),Gc=a("p"),VRr=o(`Note:
Loading a model from its configuration file does `),hMe=a("strong"),XRr=o("not"),zRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),QRr=o("from_pretrained()"),WRr=o(" to load the model weights."),HRr=l(),F(bC.$$.fragment),URr=l(),Gr=a("div"),F(kx.$$.fragment),JRr=l(),pMe=a("p"),YRr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),KRr=l(),vn=a("p"),ZRr=o("The model class to instantiate is selected based on the "),_Me=a("code"),ePr=o("model_type"),oPr=o(` property of the config object (either
passed as an argument or loaded from `),uMe=a("code"),rPr=o("pretrained_model_name_or_path"),tPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bMe=a("code"),aPr=o("pretrained_model_name_or_path"),nPr=o(":"),sPr=l(),vMe=a("ul"),vC=a("li"),FMe=a("strong"),lPr=o("speech_to_text"),iPr=o(" \u2014 "),RK=a("a"),dPr=o("TFSpeech2TextForConditionalGeneration"),cPr=o(" (Speech2Text model)"),fPr=l(),F(FC.$$.fragment),FVe=l(),Oc=a("h2"),TC=a("a"),TMe=a("span"),F(Sx.$$.fragment),mPr=l(),MMe=a("span"),gPr=o("FlaxAutoModel"),TVe=l(),hr=a("div"),F(Rx.$$.fragment),hPr=l(),Vc=a("p"),pPr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=a("a"),_Pr=o("from_pretrained()"),uPr=o(" class method or the "),BK=a("a"),bPr=o("from_config()"),vPr=o(` class
method.`),FPr=l(),Px=a("p"),TPr=o("This class cannot be instantiated directly using "),EMe=a("code"),MPr=o("__init__()"),EPr=o(" (throws an error)."),CPr=l(),Xt=a("div"),F(Bx.$$.fragment),wPr=l(),CMe=a("p"),APr=o("Instantiates one of the base model classes of the library from a configuration."),LPr=l(),Xc=a("p"),yPr=o(`Note:
Loading a model from its configuration file does `),wMe=a("strong"),xPr=o("not"),$Pr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),kPr=o("from_pretrained()"),SPr=o(" to load the model weights."),RPr=l(),F(MC.$$.fragment),PPr=l(),Or=a("div"),F(Ix.$$.fragment),BPr=l(),AMe=a("p"),IPr=o("Instantiate one of the base model classes of the library from a pretrained model."),NPr=l(),Fn=a("p"),qPr=o("The model class to instantiate is selected based on the "),LMe=a("code"),jPr=o("model_type"),DPr=o(` property of the config object (either
passed as an argument or loaded from `),yMe=a("code"),GPr=o("pretrained_model_name_or_path"),OPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=a("code"),VPr=o("pretrained_model_name_or_path"),XPr=o(":"),zPr=l(),oe=a("ul"),EC=a("li"),$Me=a("strong"),QPr=o("albert"),WPr=o(" \u2014 "),NK=a("a"),HPr=o("FlaxAlbertModel"),UPr=o(" (ALBERT model)"),JPr=l(),CC=a("li"),kMe=a("strong"),YPr=o("bart"),KPr=o(" \u2014 "),qK=a("a"),ZPr=o("FlaxBartModel"),eBr=o(" (BART model)"),oBr=l(),wC=a("li"),SMe=a("strong"),rBr=o("beit"),tBr=o(" \u2014 "),jK=a("a"),aBr=o("FlaxBeitModel"),nBr=o(" (BEiT model)"),sBr=l(),AC=a("li"),RMe=a("strong"),lBr=o("bert"),iBr=o(" \u2014 "),DK=a("a"),dBr=o("FlaxBertModel"),cBr=o(" (BERT model)"),fBr=l(),LC=a("li"),PMe=a("strong"),mBr=o("big_bird"),gBr=o(" \u2014 "),GK=a("a"),hBr=o("FlaxBigBirdModel"),pBr=o(" (BigBird model)"),_Br=l(),yC=a("li"),BMe=a("strong"),uBr=o("blenderbot"),bBr=o(" \u2014 "),OK=a("a"),vBr=o("FlaxBlenderbotModel"),FBr=o(" (Blenderbot model)"),TBr=l(),xC=a("li"),IMe=a("strong"),MBr=o("blenderbot-small"),EBr=o(" \u2014 "),VK=a("a"),CBr=o("FlaxBlenderbotSmallModel"),wBr=o(" (BlenderbotSmall model)"),ABr=l(),$C=a("li"),NMe=a("strong"),LBr=o("clip"),yBr=o(" \u2014 "),XK=a("a"),xBr=o("FlaxCLIPModel"),$Br=o(" (CLIP model)"),kBr=l(),kC=a("li"),qMe=a("strong"),SBr=o("distilbert"),RBr=o(" \u2014 "),zK=a("a"),PBr=o("FlaxDistilBertModel"),BBr=o(" (DistilBERT model)"),IBr=l(),SC=a("li"),jMe=a("strong"),NBr=o("electra"),qBr=o(" \u2014 "),QK=a("a"),jBr=o("FlaxElectraModel"),DBr=o(" (ELECTRA model)"),GBr=l(),RC=a("li"),DMe=a("strong"),OBr=o("gpt2"),VBr=o(" \u2014 "),WK=a("a"),XBr=o("FlaxGPT2Model"),zBr=o(" (OpenAI GPT-2 model)"),QBr=l(),PC=a("li"),GMe=a("strong"),WBr=o("gpt_neo"),HBr=o(" \u2014 "),HK=a("a"),UBr=o("FlaxGPTNeoModel"),JBr=o(" (GPT Neo model)"),YBr=l(),BC=a("li"),OMe=a("strong"),KBr=o("gptj"),ZBr=o(" \u2014 "),UK=a("a"),eIr=o("FlaxGPTJModel"),oIr=o(" (GPT-J model)"),rIr=l(),IC=a("li"),VMe=a("strong"),tIr=o("longt5"),aIr=o(" \u2014 "),JK=a("a"),nIr=o("FlaxLongT5Model"),sIr=o(" (LongT5 model)"),lIr=l(),NC=a("li"),XMe=a("strong"),iIr=o("marian"),dIr=o(" \u2014 "),YK=a("a"),cIr=o("FlaxMarianModel"),fIr=o(" (Marian model)"),mIr=l(),qC=a("li"),zMe=a("strong"),gIr=o("mbart"),hIr=o(" \u2014 "),KK=a("a"),pIr=o("FlaxMBartModel"),_Ir=o(" (mBART model)"),uIr=l(),jC=a("li"),QMe=a("strong"),bIr=o("mt5"),vIr=o(" \u2014 "),ZK=a("a"),FIr=o("FlaxMT5Model"),TIr=o(" (MT5 model)"),MIr=l(),DC=a("li"),WMe=a("strong"),EIr=o("opt"),CIr=o(" \u2014 "),eZ=a("a"),wIr=o("FlaxOPTModel"),AIr=o(" (OPT model)"),LIr=l(),GC=a("li"),HMe=a("strong"),yIr=o("pegasus"),xIr=o(" \u2014 "),oZ=a("a"),$Ir=o("FlaxPegasusModel"),kIr=o(" (Pegasus model)"),SIr=l(),OC=a("li"),UMe=a("strong"),RIr=o("roberta"),PIr=o(" \u2014 "),rZ=a("a"),BIr=o("FlaxRobertaModel"),IIr=o(" (RoBERTa model)"),NIr=l(),VC=a("li"),JMe=a("strong"),qIr=o("roformer"),jIr=o(" \u2014 "),tZ=a("a"),DIr=o("FlaxRoFormerModel"),GIr=o(" (RoFormer model)"),OIr=l(),XC=a("li"),YMe=a("strong"),VIr=o("t5"),XIr=o(" \u2014 "),aZ=a("a"),zIr=o("FlaxT5Model"),QIr=o(" (T5 model)"),WIr=l(),zC=a("li"),KMe=a("strong"),HIr=o("vision-text-dual-encoder"),UIr=o(" \u2014 "),nZ=a("a"),JIr=o("FlaxVisionTextDualEncoderModel"),YIr=o(" (VisionTextDualEncoder model)"),KIr=l(),QC=a("li"),ZMe=a("strong"),ZIr=o("vit"),eNr=o(" \u2014 "),sZ=a("a"),oNr=o("FlaxViTModel"),rNr=o(" (ViT model)"),tNr=l(),WC=a("li"),eEe=a("strong"),aNr=o("wav2vec2"),nNr=o(" \u2014 "),lZ=a("a"),sNr=o("FlaxWav2Vec2Model"),lNr=o(" (Wav2Vec2 model)"),iNr=l(),HC=a("li"),oEe=a("strong"),dNr=o("xglm"),cNr=o(" \u2014 "),iZ=a("a"),fNr=o("FlaxXGLMModel"),mNr=o(" (XGLM model)"),gNr=l(),UC=a("li"),rEe=a("strong"),hNr=o("xlm-roberta"),pNr=o(" \u2014 "),dZ=a("a"),_Nr=o("FlaxXLMRobertaModel"),uNr=o(" (XLM-RoBERTa model)"),bNr=l(),F(JC.$$.fragment),MVe=l(),zc=a("h2"),YC=a("a"),tEe=a("span"),F(Nx.$$.fragment),vNr=l(),aEe=a("span"),FNr=o("FlaxAutoModelForCausalLM"),EVe=l(),pr=a("div"),F(qx.$$.fragment),TNr=l(),Qc=a("p"),MNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=a("a"),ENr=o("from_pretrained()"),CNr=o(" class method or the "),fZ=a("a"),wNr=o("from_config()"),ANr=o(` class
method.`),LNr=l(),jx=a("p"),yNr=o("This class cannot be instantiated directly using "),nEe=a("code"),xNr=o("__init__()"),$Nr=o(" (throws an error)."),kNr=l(),zt=a("div"),F(Dx.$$.fragment),SNr=l(),sEe=a("p"),RNr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),PNr=l(),Wc=a("p"),BNr=o(`Note:
Loading a model from its configuration file does `),lEe=a("strong"),INr=o("not"),NNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=a("a"),qNr=o("from_pretrained()"),jNr=o(" to load the model weights."),DNr=l(),F(KC.$$.fragment),GNr=l(),Vr=a("div"),F(Gx.$$.fragment),ONr=l(),iEe=a("p"),VNr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),XNr=l(),Tn=a("p"),zNr=o("The model class to instantiate is selected based on the "),dEe=a("code"),QNr=o("model_type"),WNr=o(` property of the config object (either
passed as an argument or loaded from `),cEe=a("code"),HNr=o("pretrained_model_name_or_path"),UNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=a("code"),JNr=o("pretrained_model_name_or_path"),YNr=o(":"),KNr=l(),xe=a("ul"),ZC=a("li"),mEe=a("strong"),ZNr=o("bart"),eqr=o(" \u2014 "),gZ=a("a"),oqr=o("FlaxBartForCausalLM"),rqr=o(" (BART model)"),tqr=l(),e5=a("li"),gEe=a("strong"),aqr=o("bert"),nqr=o(" \u2014 "),hZ=a("a"),sqr=o("FlaxBertForCausalLM"),lqr=o(" (BERT model)"),iqr=l(),o5=a("li"),hEe=a("strong"),dqr=o("big_bird"),cqr=o(" \u2014 "),pZ=a("a"),fqr=o("FlaxBigBirdForCausalLM"),mqr=o(" (BigBird model)"),gqr=l(),r5=a("li"),pEe=a("strong"),hqr=o("electra"),pqr=o(" \u2014 "),_Z=a("a"),_qr=o("FlaxElectraForCausalLM"),uqr=o(" (ELECTRA model)"),bqr=l(),t5=a("li"),_Ee=a("strong"),vqr=o("gpt2"),Fqr=o(" \u2014 "),uZ=a("a"),Tqr=o("FlaxGPT2LMHeadModel"),Mqr=o(" (OpenAI GPT-2 model)"),Eqr=l(),a5=a("li"),uEe=a("strong"),Cqr=o("gpt_neo"),wqr=o(" \u2014 "),bZ=a("a"),Aqr=o("FlaxGPTNeoForCausalLM"),Lqr=o(" (GPT Neo model)"),yqr=l(),n5=a("li"),bEe=a("strong"),xqr=o("gptj"),$qr=o(" \u2014 "),vZ=a("a"),kqr=o("FlaxGPTJForCausalLM"),Sqr=o(" (GPT-J model)"),Rqr=l(),s5=a("li"),vEe=a("strong"),Pqr=o("opt"),Bqr=o(" \u2014 "),FZ=a("a"),Iqr=o("FlaxOPTForCausalLM"),Nqr=o(" (OPT model)"),qqr=l(),l5=a("li"),FEe=a("strong"),jqr=o("roberta"),Dqr=o(" \u2014 "),TZ=a("a"),Gqr=o("FlaxRobertaForCausalLM"),Oqr=o(" (RoBERTa model)"),Vqr=l(),i5=a("li"),TEe=a("strong"),Xqr=o("xglm"),zqr=o(" \u2014 "),MZ=a("a"),Qqr=o("FlaxXGLMForCausalLM"),Wqr=o(" (XGLM model)"),Hqr=l(),F(d5.$$.fragment),CVe=l(),Hc=a("h2"),c5=a("a"),MEe=a("span"),F(Ox.$$.fragment),Uqr=l(),EEe=a("span"),Jqr=o("FlaxAutoModelForPreTraining"),wVe=l(),_r=a("div"),F(Vx.$$.fragment),Yqr=l(),Uc=a("p"),Kqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=a("a"),Zqr=o("from_pretrained()"),ejr=o(" class method or the "),CZ=a("a"),ojr=o("from_config()"),rjr=o(` class
method.`),tjr=l(),Xx=a("p"),ajr=o("This class cannot be instantiated directly using "),CEe=a("code"),njr=o("__init__()"),sjr=o(" (throws an error)."),ljr=l(),Qt=a("div"),F(zx.$$.fragment),ijr=l(),wEe=a("p"),djr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),cjr=l(),Jc=a("p"),fjr=o(`Note:
Loading a model from its configuration file does `),AEe=a("strong"),mjr=o("not"),gjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=a("a"),hjr=o("from_pretrained()"),pjr=o(" to load the model weights."),_jr=l(),F(f5.$$.fragment),ujr=l(),Xr=a("div"),F(Qx.$$.fragment),bjr=l(),LEe=a("p"),vjr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Fjr=l(),Mn=a("p"),Tjr=o("The model class to instantiate is selected based on the "),yEe=a("code"),Mjr=o("model_type"),Ejr=o(` property of the config object (either
passed as an argument or loaded from `),xEe=a("code"),Cjr=o("pretrained_model_name_or_path"),wjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ee=a("code"),Ajr=o("pretrained_model_name_or_path"),Ljr=o(":"),yjr=l(),Ee=a("ul"),m5=a("li"),kEe=a("strong"),xjr=o("albert"),$jr=o(" \u2014 "),AZ=a("a"),kjr=o("FlaxAlbertForPreTraining"),Sjr=o(" (ALBERT model)"),Rjr=l(),g5=a("li"),SEe=a("strong"),Pjr=o("bart"),Bjr=o(" \u2014 "),LZ=a("a"),Ijr=o("FlaxBartForConditionalGeneration"),Njr=o(" (BART model)"),qjr=l(),h5=a("li"),REe=a("strong"),jjr=o("bert"),Djr=o(" \u2014 "),yZ=a("a"),Gjr=o("FlaxBertForPreTraining"),Ojr=o(" (BERT model)"),Vjr=l(),p5=a("li"),PEe=a("strong"),Xjr=o("big_bird"),zjr=o(" \u2014 "),xZ=a("a"),Qjr=o("FlaxBigBirdForPreTraining"),Wjr=o(" (BigBird model)"),Hjr=l(),_5=a("li"),BEe=a("strong"),Ujr=o("electra"),Jjr=o(" \u2014 "),$Z=a("a"),Yjr=o("FlaxElectraForPreTraining"),Kjr=o(" (ELECTRA model)"),Zjr=l(),u5=a("li"),IEe=a("strong"),eDr=o("longt5"),oDr=o(" \u2014 "),kZ=a("a"),rDr=o("FlaxLongT5ForConditionalGeneration"),tDr=o(" (LongT5 model)"),aDr=l(),b5=a("li"),NEe=a("strong"),nDr=o("mbart"),sDr=o(" \u2014 "),SZ=a("a"),lDr=o("FlaxMBartForConditionalGeneration"),iDr=o(" (mBART model)"),dDr=l(),v5=a("li"),qEe=a("strong"),cDr=o("mt5"),fDr=o(" \u2014 "),RZ=a("a"),mDr=o("FlaxMT5ForConditionalGeneration"),gDr=o(" (MT5 model)"),hDr=l(),F5=a("li"),jEe=a("strong"),pDr=o("roberta"),_Dr=o(" \u2014 "),PZ=a("a"),uDr=o("FlaxRobertaForMaskedLM"),bDr=o(" (RoBERTa model)"),vDr=l(),T5=a("li"),DEe=a("strong"),FDr=o("roformer"),TDr=o(" \u2014 "),BZ=a("a"),MDr=o("FlaxRoFormerForMaskedLM"),EDr=o(" (RoFormer model)"),CDr=l(),M5=a("li"),GEe=a("strong"),wDr=o("t5"),ADr=o(" \u2014 "),IZ=a("a"),LDr=o("FlaxT5ForConditionalGeneration"),yDr=o(" (T5 model)"),xDr=l(),E5=a("li"),OEe=a("strong"),$Dr=o("wav2vec2"),kDr=o(" \u2014 "),NZ=a("a"),SDr=o("FlaxWav2Vec2ForPreTraining"),RDr=o(" (Wav2Vec2 model)"),PDr=l(),C5=a("li"),VEe=a("strong"),BDr=o("xlm-roberta"),IDr=o(" \u2014 "),qZ=a("a"),NDr=o("FlaxXLMRobertaForMaskedLM"),qDr=o(" (XLM-RoBERTa model)"),jDr=l(),F(w5.$$.fragment),AVe=l(),Yc=a("h2"),A5=a("a"),XEe=a("span"),F(Wx.$$.fragment),DDr=l(),zEe=a("span"),GDr=o("FlaxAutoModelForMaskedLM"),LVe=l(),ur=a("div"),F(Hx.$$.fragment),ODr=l(),Kc=a("p"),VDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=a("a"),XDr=o("from_pretrained()"),zDr=o(" class method or the "),DZ=a("a"),QDr=o("from_config()"),WDr=o(` class
method.`),HDr=l(),Ux=a("p"),UDr=o("This class cannot be instantiated directly using "),QEe=a("code"),JDr=o("__init__()"),YDr=o(" (throws an error)."),KDr=l(),Wt=a("div"),F(Jx.$$.fragment),ZDr=l(),WEe=a("p"),eGr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),oGr=l(),Zc=a("p"),rGr=o(`Note:
Loading a model from its configuration file does `),HEe=a("strong"),tGr=o("not"),aGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=a("a"),nGr=o("from_pretrained()"),sGr=o(" to load the model weights."),lGr=l(),F(L5.$$.fragment),iGr=l(),zr=a("div"),F(Yx.$$.fragment),dGr=l(),UEe=a("p"),cGr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fGr=l(),En=a("p"),mGr=o("The model class to instantiate is selected based on the "),JEe=a("code"),gGr=o("model_type"),hGr=o(` property of the config object (either
passed as an argument or loaded from `),YEe=a("code"),pGr=o("pretrained_model_name_or_path"),_Gr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KEe=a("code"),uGr=o("pretrained_model_name_or_path"),bGr=o(":"),vGr=l(),$e=a("ul"),y5=a("li"),ZEe=a("strong"),FGr=o("albert"),TGr=o(" \u2014 "),OZ=a("a"),MGr=o("FlaxAlbertForMaskedLM"),EGr=o(" (ALBERT model)"),CGr=l(),x5=a("li"),eCe=a("strong"),wGr=o("bart"),AGr=o(" \u2014 "),VZ=a("a"),LGr=o("FlaxBartForConditionalGeneration"),yGr=o(" (BART model)"),xGr=l(),$5=a("li"),oCe=a("strong"),$Gr=o("bert"),kGr=o(" \u2014 "),XZ=a("a"),SGr=o("FlaxBertForMaskedLM"),RGr=o(" (BERT model)"),PGr=l(),k5=a("li"),rCe=a("strong"),BGr=o("big_bird"),IGr=o(" \u2014 "),zZ=a("a"),NGr=o("FlaxBigBirdForMaskedLM"),qGr=o(" (BigBird model)"),jGr=l(),S5=a("li"),tCe=a("strong"),DGr=o("distilbert"),GGr=o(" \u2014 "),QZ=a("a"),OGr=o("FlaxDistilBertForMaskedLM"),VGr=o(" (DistilBERT model)"),XGr=l(),R5=a("li"),aCe=a("strong"),zGr=o("electra"),QGr=o(" \u2014 "),WZ=a("a"),WGr=o("FlaxElectraForMaskedLM"),HGr=o(" (ELECTRA model)"),UGr=l(),P5=a("li"),nCe=a("strong"),JGr=o("mbart"),YGr=o(" \u2014 "),HZ=a("a"),KGr=o("FlaxMBartForConditionalGeneration"),ZGr=o(" (mBART model)"),eOr=l(),B5=a("li"),sCe=a("strong"),oOr=o("roberta"),rOr=o(" \u2014 "),UZ=a("a"),tOr=o("FlaxRobertaForMaskedLM"),aOr=o(" (RoBERTa model)"),nOr=l(),I5=a("li"),lCe=a("strong"),sOr=o("roformer"),lOr=o(" \u2014 "),JZ=a("a"),iOr=o("FlaxRoFormerForMaskedLM"),dOr=o(" (RoFormer model)"),cOr=l(),N5=a("li"),iCe=a("strong"),fOr=o("xlm-roberta"),mOr=o(" \u2014 "),YZ=a("a"),gOr=o("FlaxXLMRobertaForMaskedLM"),hOr=o(" (XLM-RoBERTa model)"),pOr=l(),F(q5.$$.fragment),yVe=l(),ef=a("h2"),j5=a("a"),dCe=a("span"),F(Kx.$$.fragment),_Or=l(),cCe=a("span"),uOr=o("FlaxAutoModelForSeq2SeqLM"),xVe=l(),br=a("div"),F(Zx.$$.fragment),bOr=l(),of=a("p"),vOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=a("a"),FOr=o("from_pretrained()"),TOr=o(" class method or the "),ZZ=a("a"),MOr=o("from_config()"),EOr=o(` class
method.`),COr=l(),e$=a("p"),wOr=o("This class cannot be instantiated directly using "),fCe=a("code"),AOr=o("__init__()"),LOr=o(" (throws an error)."),yOr=l(),Ht=a("div"),F(o$.$$.fragment),xOr=l(),mCe=a("p"),$Or=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),kOr=l(),rf=a("p"),SOr=o(`Note:
Loading a model from its configuration file does `),gCe=a("strong"),ROr=o("not"),POr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=a("a"),BOr=o("from_pretrained()"),IOr=o(" to load the model weights."),NOr=l(),F(D5.$$.fragment),qOr=l(),Qr=a("div"),F(r$.$$.fragment),jOr=l(),hCe=a("p"),DOr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),GOr=l(),Cn=a("p"),OOr=o("The model class to instantiate is selected based on the "),pCe=a("code"),VOr=o("model_type"),XOr=o(` property of the config object (either
passed as an argument or loaded from `),_Ce=a("code"),zOr=o("pretrained_model_name_or_path"),QOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=a("code"),WOr=o("pretrained_model_name_or_path"),HOr=o(":"),UOr=l(),ke=a("ul"),G5=a("li"),bCe=a("strong"),JOr=o("bart"),YOr=o(" \u2014 "),oee=a("a"),KOr=o("FlaxBartForConditionalGeneration"),ZOr=o(" (BART model)"),eVr=l(),O5=a("li"),vCe=a("strong"),oVr=o("blenderbot"),rVr=o(" \u2014 "),ree=a("a"),tVr=o("FlaxBlenderbotForConditionalGeneration"),aVr=o(" (Blenderbot model)"),nVr=l(),V5=a("li"),FCe=a("strong"),sVr=o("blenderbot-small"),lVr=o(" \u2014 "),tee=a("a"),iVr=o("FlaxBlenderbotSmallForConditionalGeneration"),dVr=o(" (BlenderbotSmall model)"),cVr=l(),X5=a("li"),TCe=a("strong"),fVr=o("encoder-decoder"),mVr=o(" \u2014 "),aee=a("a"),gVr=o("FlaxEncoderDecoderModel"),hVr=o(" (Encoder decoder model)"),pVr=l(),z5=a("li"),MCe=a("strong"),_Vr=o("longt5"),uVr=o(" \u2014 "),nee=a("a"),bVr=o("FlaxLongT5ForConditionalGeneration"),vVr=o(" (LongT5 model)"),FVr=l(),Q5=a("li"),ECe=a("strong"),TVr=o("marian"),MVr=o(" \u2014 "),see=a("a"),EVr=o("FlaxMarianMTModel"),CVr=o(" (Marian model)"),wVr=l(),W5=a("li"),CCe=a("strong"),AVr=o("mbart"),LVr=o(" \u2014 "),lee=a("a"),yVr=o("FlaxMBartForConditionalGeneration"),xVr=o(" (mBART model)"),$Vr=l(),H5=a("li"),wCe=a("strong"),kVr=o("mt5"),SVr=o(" \u2014 "),iee=a("a"),RVr=o("FlaxMT5ForConditionalGeneration"),PVr=o(" (MT5 model)"),BVr=l(),U5=a("li"),ACe=a("strong"),IVr=o("pegasus"),NVr=o(" \u2014 "),dee=a("a"),qVr=o("FlaxPegasusForConditionalGeneration"),jVr=o(" (Pegasus model)"),DVr=l(),J5=a("li"),LCe=a("strong"),GVr=o("t5"),OVr=o(" \u2014 "),cee=a("a"),VVr=o("FlaxT5ForConditionalGeneration"),XVr=o(" (T5 model)"),zVr=l(),F(Y5.$$.fragment),$Ve=l(),tf=a("h2"),K5=a("a"),yCe=a("span"),F(t$.$$.fragment),QVr=l(),xCe=a("span"),WVr=o("FlaxAutoModelForSequenceClassification"),kVe=l(),vr=a("div"),F(a$.$$.fragment),HVr=l(),af=a("p"),UVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fee=a("a"),JVr=o("from_pretrained()"),YVr=o(" class method or the "),mee=a("a"),KVr=o("from_config()"),ZVr=o(` class
method.`),eXr=l(),n$=a("p"),oXr=o("This class cannot be instantiated directly using "),$Ce=a("code"),rXr=o("__init__()"),tXr=o(" (throws an error)."),aXr=l(),Ut=a("div"),F(s$.$$.fragment),nXr=l(),kCe=a("p"),sXr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lXr=l(),nf=a("p"),iXr=o(`Note:
Loading a model from its configuration file does `),SCe=a("strong"),dXr=o("not"),cXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=a("a"),fXr=o("from_pretrained()"),mXr=o(" to load the model weights."),gXr=l(),F(Z5.$$.fragment),hXr=l(),Wr=a("div"),F(l$.$$.fragment),pXr=l(),RCe=a("p"),_Xr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uXr=l(),wn=a("p"),bXr=o("The model class to instantiate is selected based on the "),PCe=a("code"),vXr=o("model_type"),FXr=o(` property of the config object (either
passed as an argument or loaded from `),BCe=a("code"),TXr=o("pretrained_model_name_or_path"),MXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ICe=a("code"),EXr=o("pretrained_model_name_or_path"),CXr=o(":"),wXr=l(),Se=a("ul"),e3=a("li"),NCe=a("strong"),AXr=o("albert"),LXr=o(" \u2014 "),hee=a("a"),yXr=o("FlaxAlbertForSequenceClassification"),xXr=o(" (ALBERT model)"),$Xr=l(),o3=a("li"),qCe=a("strong"),kXr=o("bart"),SXr=o(" \u2014 "),pee=a("a"),RXr=o("FlaxBartForSequenceClassification"),PXr=o(" (BART model)"),BXr=l(),r3=a("li"),jCe=a("strong"),IXr=o("bert"),NXr=o(" \u2014 "),_ee=a("a"),qXr=o("FlaxBertForSequenceClassification"),jXr=o(" (BERT model)"),DXr=l(),t3=a("li"),DCe=a("strong"),GXr=o("big_bird"),OXr=o(" \u2014 "),uee=a("a"),VXr=o("FlaxBigBirdForSequenceClassification"),XXr=o(" (BigBird model)"),zXr=l(),a3=a("li"),GCe=a("strong"),QXr=o("distilbert"),WXr=o(" \u2014 "),bee=a("a"),HXr=o("FlaxDistilBertForSequenceClassification"),UXr=o(" (DistilBERT model)"),JXr=l(),n3=a("li"),OCe=a("strong"),YXr=o("electra"),KXr=o(" \u2014 "),vee=a("a"),ZXr=o("FlaxElectraForSequenceClassification"),ezr=o(" (ELECTRA model)"),ozr=l(),s3=a("li"),VCe=a("strong"),rzr=o("mbart"),tzr=o(" \u2014 "),Fee=a("a"),azr=o("FlaxMBartForSequenceClassification"),nzr=o(" (mBART model)"),szr=l(),l3=a("li"),XCe=a("strong"),lzr=o("roberta"),izr=o(" \u2014 "),Tee=a("a"),dzr=o("FlaxRobertaForSequenceClassification"),czr=o(" (RoBERTa model)"),fzr=l(),i3=a("li"),zCe=a("strong"),mzr=o("roformer"),gzr=o(" \u2014 "),Mee=a("a"),hzr=o("FlaxRoFormerForSequenceClassification"),pzr=o(" (RoFormer model)"),_zr=l(),d3=a("li"),QCe=a("strong"),uzr=o("xlm-roberta"),bzr=o(" \u2014 "),Eee=a("a"),vzr=o("FlaxXLMRobertaForSequenceClassification"),Fzr=o(" (XLM-RoBERTa model)"),Tzr=l(),F(c3.$$.fragment),SVe=l(),sf=a("h2"),f3=a("a"),WCe=a("span"),F(i$.$$.fragment),Mzr=l(),HCe=a("span"),Ezr=o("FlaxAutoModelForQuestionAnswering"),RVe=l(),Fr=a("div"),F(d$.$$.fragment),Czr=l(),lf=a("p"),wzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=a("a"),Azr=o("from_pretrained()"),Lzr=o(" class method or the "),wee=a("a"),yzr=o("from_config()"),xzr=o(` class
method.`),$zr=l(),c$=a("p"),kzr=o("This class cannot be instantiated directly using "),UCe=a("code"),Szr=o("__init__()"),Rzr=o(" (throws an error)."),Pzr=l(),Jt=a("div"),F(f$.$$.fragment),Bzr=l(),JCe=a("p"),Izr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Nzr=l(),df=a("p"),qzr=o(`Note:
Loading a model from its configuration file does `),YCe=a("strong"),jzr=o("not"),Dzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=a("a"),Gzr=o("from_pretrained()"),Ozr=o(" to load the model weights."),Vzr=l(),F(m3.$$.fragment),Xzr=l(),Hr=a("div"),F(m$.$$.fragment),zzr=l(),KCe=a("p"),Qzr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Wzr=l(),An=a("p"),Hzr=o("The model class to instantiate is selected based on the "),ZCe=a("code"),Uzr=o("model_type"),Jzr=o(` property of the config object (either
passed as an argument or loaded from `),e5e=a("code"),Yzr=o("pretrained_model_name_or_path"),Kzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o5e=a("code"),Zzr=o("pretrained_model_name_or_path"),eQr=o(":"),oQr=l(),Re=a("ul"),g3=a("li"),r5e=a("strong"),rQr=o("albert"),tQr=o(" \u2014 "),Lee=a("a"),aQr=o("FlaxAlbertForQuestionAnswering"),nQr=o(" (ALBERT model)"),sQr=l(),h3=a("li"),t5e=a("strong"),lQr=o("bart"),iQr=o(" \u2014 "),yee=a("a"),dQr=o("FlaxBartForQuestionAnswering"),cQr=o(" (BART model)"),fQr=l(),p3=a("li"),a5e=a("strong"),mQr=o("bert"),gQr=o(" \u2014 "),xee=a("a"),hQr=o("FlaxBertForQuestionAnswering"),pQr=o(" (BERT model)"),_Qr=l(),_3=a("li"),n5e=a("strong"),uQr=o("big_bird"),bQr=o(" \u2014 "),$ee=a("a"),vQr=o("FlaxBigBirdForQuestionAnswering"),FQr=o(" (BigBird model)"),TQr=l(),u3=a("li"),s5e=a("strong"),MQr=o("distilbert"),EQr=o(" \u2014 "),kee=a("a"),CQr=o("FlaxDistilBertForQuestionAnswering"),wQr=o(" (DistilBERT model)"),AQr=l(),b3=a("li"),l5e=a("strong"),LQr=o("electra"),yQr=o(" \u2014 "),See=a("a"),xQr=o("FlaxElectraForQuestionAnswering"),$Qr=o(" (ELECTRA model)"),kQr=l(),v3=a("li"),i5e=a("strong"),SQr=o("mbart"),RQr=o(" \u2014 "),Ree=a("a"),PQr=o("FlaxMBartForQuestionAnswering"),BQr=o(" (mBART model)"),IQr=l(),F3=a("li"),d5e=a("strong"),NQr=o("roberta"),qQr=o(" \u2014 "),Pee=a("a"),jQr=o("FlaxRobertaForQuestionAnswering"),DQr=o(" (RoBERTa model)"),GQr=l(),T3=a("li"),c5e=a("strong"),OQr=o("roformer"),VQr=o(" \u2014 "),Bee=a("a"),XQr=o("FlaxRoFormerForQuestionAnswering"),zQr=o(" (RoFormer model)"),QQr=l(),M3=a("li"),f5e=a("strong"),WQr=o("xlm-roberta"),HQr=o(" \u2014 "),Iee=a("a"),UQr=o("FlaxXLMRobertaForQuestionAnswering"),JQr=o(" (XLM-RoBERTa model)"),YQr=l(),F(E3.$$.fragment),PVe=l(),cf=a("h2"),C3=a("a"),m5e=a("span"),F(g$.$$.fragment),KQr=l(),g5e=a("span"),ZQr=o("FlaxAutoModelForTokenClassification"),BVe=l(),Tr=a("div"),F(h$.$$.fragment),eWr=l(),ff=a("p"),oWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=a("a"),rWr=o("from_pretrained()"),tWr=o(" class method or the "),qee=a("a"),aWr=o("from_config()"),nWr=o(` class
method.`),sWr=l(),p$=a("p"),lWr=o("This class cannot be instantiated directly using "),h5e=a("code"),iWr=o("__init__()"),dWr=o(" (throws an error)."),cWr=l(),Yt=a("div"),F(_$.$$.fragment),fWr=l(),p5e=a("p"),mWr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gWr=l(),mf=a("p"),hWr=o(`Note:
Loading a model from its configuration file does `),_5e=a("strong"),pWr=o("not"),_Wr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=a("a"),uWr=o("from_pretrained()"),bWr=o(" to load the model weights."),vWr=l(),F(w3.$$.fragment),FWr=l(),Ur=a("div"),F(u$.$$.fragment),TWr=l(),u5e=a("p"),MWr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EWr=l(),Ln=a("p"),CWr=o("The model class to instantiate is selected based on the "),b5e=a("code"),wWr=o("model_type"),AWr=o(` property of the config object (either
passed as an argument or loaded from `),v5e=a("code"),LWr=o("pretrained_model_name_or_path"),yWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F5e=a("code"),xWr=o("pretrained_model_name_or_path"),$Wr=o(":"),kWr=l(),Ve=a("ul"),A3=a("li"),T5e=a("strong"),SWr=o("albert"),RWr=o(" \u2014 "),Dee=a("a"),PWr=o("FlaxAlbertForTokenClassification"),BWr=o(" (ALBERT model)"),IWr=l(),L3=a("li"),M5e=a("strong"),NWr=o("bert"),qWr=o(" \u2014 "),Gee=a("a"),jWr=o("FlaxBertForTokenClassification"),DWr=o(" (BERT model)"),GWr=l(),y3=a("li"),E5e=a("strong"),OWr=o("big_bird"),VWr=o(" \u2014 "),Oee=a("a"),XWr=o("FlaxBigBirdForTokenClassification"),zWr=o(" (BigBird model)"),QWr=l(),x3=a("li"),C5e=a("strong"),WWr=o("distilbert"),HWr=o(" \u2014 "),Vee=a("a"),UWr=o("FlaxDistilBertForTokenClassification"),JWr=o(" (DistilBERT model)"),YWr=l(),$3=a("li"),w5e=a("strong"),KWr=o("electra"),ZWr=o(" \u2014 "),Xee=a("a"),eHr=o("FlaxElectraForTokenClassification"),oHr=o(" (ELECTRA model)"),rHr=l(),k3=a("li"),A5e=a("strong"),tHr=o("roberta"),aHr=o(" \u2014 "),zee=a("a"),nHr=o("FlaxRobertaForTokenClassification"),sHr=o(" (RoBERTa model)"),lHr=l(),S3=a("li"),L5e=a("strong"),iHr=o("roformer"),dHr=o(" \u2014 "),Qee=a("a"),cHr=o("FlaxRoFormerForTokenClassification"),fHr=o(" (RoFormer model)"),mHr=l(),R3=a("li"),y5e=a("strong"),gHr=o("xlm-roberta"),hHr=o(" \u2014 "),Wee=a("a"),pHr=o("FlaxXLMRobertaForTokenClassification"),_Hr=o(" (XLM-RoBERTa model)"),uHr=l(),F(P3.$$.fragment),IVe=l(),gf=a("h2"),B3=a("a"),x5e=a("span"),F(b$.$$.fragment),bHr=l(),$5e=a("span"),vHr=o("FlaxAutoModelForMultipleChoice"),NVe=l(),Mr=a("div"),F(v$.$$.fragment),FHr=l(),hf=a("p"),THr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=a("a"),MHr=o("from_pretrained()"),EHr=o(" class method or the "),Uee=a("a"),CHr=o("from_config()"),wHr=o(` class
method.`),AHr=l(),F$=a("p"),LHr=o("This class cannot be instantiated directly using "),k5e=a("code"),yHr=o("__init__()"),xHr=o(" (throws an error)."),$Hr=l(),Kt=a("div"),F(T$.$$.fragment),kHr=l(),S5e=a("p"),SHr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),RHr=l(),pf=a("p"),PHr=o(`Note:
Loading a model from its configuration file does `),R5e=a("strong"),BHr=o("not"),IHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=a("a"),NHr=o("from_pretrained()"),qHr=o(" to load the model weights."),jHr=l(),F(I3.$$.fragment),DHr=l(),Jr=a("div"),F(M$.$$.fragment),GHr=l(),P5e=a("p"),OHr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VHr=l(),yn=a("p"),XHr=o("The model class to instantiate is selected based on the "),B5e=a("code"),zHr=o("model_type"),QHr=o(` property of the config object (either
passed as an argument or loaded from `),I5e=a("code"),WHr=o("pretrained_model_name_or_path"),HHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N5e=a("code"),UHr=o("pretrained_model_name_or_path"),JHr=o(":"),YHr=l(),Xe=a("ul"),N3=a("li"),q5e=a("strong"),KHr=o("albert"),ZHr=o(" \u2014 "),Yee=a("a"),eUr=o("FlaxAlbertForMultipleChoice"),oUr=o(" (ALBERT model)"),rUr=l(),q3=a("li"),j5e=a("strong"),tUr=o("bert"),aUr=o(" \u2014 "),Kee=a("a"),nUr=o("FlaxBertForMultipleChoice"),sUr=o(" (BERT model)"),lUr=l(),j3=a("li"),D5e=a("strong"),iUr=o("big_bird"),dUr=o(" \u2014 "),Zee=a("a"),cUr=o("FlaxBigBirdForMultipleChoice"),fUr=o(" (BigBird model)"),mUr=l(),D3=a("li"),G5e=a("strong"),gUr=o("distilbert"),hUr=o(" \u2014 "),eoe=a("a"),pUr=o("FlaxDistilBertForMultipleChoice"),_Ur=o(" (DistilBERT model)"),uUr=l(),G3=a("li"),O5e=a("strong"),bUr=o("electra"),vUr=o(" \u2014 "),ooe=a("a"),FUr=o("FlaxElectraForMultipleChoice"),TUr=o(" (ELECTRA model)"),MUr=l(),O3=a("li"),V5e=a("strong"),EUr=o("roberta"),CUr=o(" \u2014 "),roe=a("a"),wUr=o("FlaxRobertaForMultipleChoice"),AUr=o(" (RoBERTa model)"),LUr=l(),V3=a("li"),X5e=a("strong"),yUr=o("roformer"),xUr=o(" \u2014 "),toe=a("a"),$Ur=o("FlaxRoFormerForMultipleChoice"),kUr=o(" (RoFormer model)"),SUr=l(),X3=a("li"),z5e=a("strong"),RUr=o("xlm-roberta"),PUr=o(" \u2014 "),aoe=a("a"),BUr=o("FlaxXLMRobertaForMultipleChoice"),IUr=o(" (XLM-RoBERTa model)"),NUr=l(),F(z3.$$.fragment),qVe=l(),_f=a("h2"),Q3=a("a"),Q5e=a("span"),F(E$.$$.fragment),qUr=l(),W5e=a("span"),jUr=o("FlaxAutoModelForNextSentencePrediction"),jVe=l(),Er=a("div"),F(C$.$$.fragment),DUr=l(),uf=a("p"),GUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=a("a"),OUr=o("from_pretrained()"),VUr=o(" class method or the "),soe=a("a"),XUr=o("from_config()"),zUr=o(` class
method.`),QUr=l(),w$=a("p"),WUr=o("This class cannot be instantiated directly using "),H5e=a("code"),HUr=o("__init__()"),UUr=o(" (throws an error)."),JUr=l(),Zt=a("div"),F(A$.$$.fragment),YUr=l(),U5e=a("p"),KUr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ZUr=l(),bf=a("p"),eJr=o(`Note:
Loading a model from its configuration file does `),J5e=a("strong"),oJr=o("not"),rJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=a("a"),tJr=o("from_pretrained()"),aJr=o(" to load the model weights."),nJr=l(),F(W3.$$.fragment),sJr=l(),Yr=a("div"),F(L$.$$.fragment),lJr=l(),Y5e=a("p"),iJr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),dJr=l(),xn=a("p"),cJr=o("The model class to instantiate is selected based on the "),K5e=a("code"),fJr=o("model_type"),mJr=o(` property of the config object (either
passed as an argument or loaded from `),Z5e=a("code"),gJr=o("pretrained_model_name_or_path"),hJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e3e=a("code"),pJr=o("pretrained_model_name_or_path"),_Jr=o(":"),uJr=l(),o3e=a("ul"),H3=a("li"),r3e=a("strong"),bJr=o("bert"),vJr=o(" \u2014 "),ioe=a("a"),FJr=o("FlaxBertForNextSentencePrediction"),TJr=o(" (BERT model)"),MJr=l(),F(U3.$$.fragment),DVe=l(),vf=a("h2"),J3=a("a"),t3e=a("span"),F(y$.$$.fragment),EJr=l(),a3e=a("span"),CJr=o("FlaxAutoModelForImageClassification"),GVe=l(),Cr=a("div"),F(x$.$$.fragment),wJr=l(),Ff=a("p"),AJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=a("a"),LJr=o("from_pretrained()"),yJr=o(" class method or the "),coe=a("a"),xJr=o("from_config()"),$Jr=o(` class
method.`),kJr=l(),$$=a("p"),SJr=o("This class cannot be instantiated directly using "),n3e=a("code"),RJr=o("__init__()"),PJr=o(" (throws an error)."),BJr=l(),ea=a("div"),F(k$.$$.fragment),IJr=l(),s3e=a("p"),NJr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),qJr=l(),Tf=a("p"),jJr=o(`Note:
Loading a model from its configuration file does `),l3e=a("strong"),DJr=o("not"),GJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=a("a"),OJr=o("from_pretrained()"),VJr=o(" to load the model weights."),XJr=l(),F(Y3.$$.fragment),zJr=l(),Kr=a("div"),F(S$.$$.fragment),QJr=l(),i3e=a("p"),WJr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),HJr=l(),$n=a("p"),UJr=o("The model class to instantiate is selected based on the "),d3e=a("code"),JJr=o("model_type"),YJr=o(` property of the config object (either
passed as an argument or loaded from `),c3e=a("code"),KJr=o("pretrained_model_name_or_path"),ZJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f3e=a("code"),eYr=o("pretrained_model_name_or_path"),oYr=o(":"),rYr=l(),R$=a("ul"),K3=a("li"),m3e=a("strong"),tYr=o("beit"),aYr=o(" \u2014 "),moe=a("a"),nYr=o("FlaxBeitForImageClassification"),sYr=o(" (BEiT model)"),lYr=l(),Z3=a("li"),g3e=a("strong"),iYr=o("vit"),dYr=o(" \u2014 "),goe=a("a"),cYr=o("FlaxViTForImageClassification"),fYr=o(" (ViT model)"),mYr=l(),F(e0.$$.fragment),OVe=l(),Mf=a("h2"),o0=a("a"),h3e=a("span"),F(P$.$$.fragment),gYr=l(),p3e=a("span"),hYr=o("FlaxAutoModelForVision2Seq"),VVe=l(),wr=a("div"),F(B$.$$.fragment),pYr=l(),Ef=a("p"),_Yr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=a("a"),uYr=o("from_pretrained()"),bYr=o(" class method or the "),poe=a("a"),vYr=o("from_config()"),FYr=o(` class
method.`),TYr=l(),I$=a("p"),MYr=o("This class cannot be instantiated directly using "),_3e=a("code"),EYr=o("__init__()"),CYr=o(" (throws an error)."),wYr=l(),oa=a("div"),F(N$.$$.fragment),AYr=l(),u3e=a("p"),LYr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),yYr=l(),Cf=a("p"),xYr=o(`Note:
Loading a model from its configuration file does `),b3e=a("strong"),$Yr=o("not"),kYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=a("a"),SYr=o("from_pretrained()"),RYr=o(" to load the model weights."),PYr=l(),F(r0.$$.fragment),BYr=l(),Zr=a("div"),F(q$.$$.fragment),IYr=l(),v3e=a("p"),NYr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),qYr=l(),kn=a("p"),jYr=o("The model class to instantiate is selected based on the "),F3e=a("code"),DYr=o("model_type"),GYr=o(` property of the config object (either
passed as an argument or loaded from `),T3e=a("code"),OYr=o("pretrained_model_name_or_path"),VYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M3e=a("code"),XYr=o("pretrained_model_name_or_path"),zYr=o(":"),QYr=l(),E3e=a("ul"),t0=a("li"),C3e=a("strong"),WYr=o("vision-encoder-decoder"),HYr=o(" \u2014 "),uoe=a("a"),UYr=o("FlaxVisionEncoderDecoderModel"),JYr=o(" (Vision Encoder decoder model)"),YYr=l(),F(a0.$$.fragment),this.h()},l(f){const u=MDt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var j$=s(p);m=n(j$,"A",{id:!0,class:!0,href:!0});var w3e=s(m);_=n(w3e,"SPAN",{});var A3e=s(_);T(d.$$.fragment,A3e),A3e.forEach(t),w3e.forEach(t),h=i(j$),Eo=n(j$,"SPAN",{});var L3e=s(Eo);Ti=r(L3e,"Auto Classes"),L3e.forEach(t),j$.forEach(t),yf=i(f),at=n(f,"P",{});var D$=s(at);Mi=r(D$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=n(D$,"CODE",{});var y3e=s(Ei);wA=r(y3e,"from_pretrained()"),y3e.forEach(t),xf=r(D$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),D$.forEach(t),Oe=i(f),Qe=n(f,"P",{});var Sn=s(Qe);Ci=r(Sn,"Instantiating one of "),Rn=n(Sn,"A",{href:!0});var x3e=s(Rn);AA=r(x3e,"AutoConfig"),x3e.forEach(t),Pn=r(Sn,", "),Bn=n(Sn,"A",{href:!0});var $3e=s(Bn);LA=r($3e,"AutoModel"),$3e.forEach(t),wi=r(Sn,`, and
`),In=n(Sn,"A",{href:!0});var k3e=s(In);yA=r(k3e,"AutoTokenizer"),k3e.forEach(t),Ai=r(Sn," will directly create a class of the relevant architecture. For instance"),Sn.forEach(t),$f=i(f),T(xa.$$.fragment,f),We=i(f),Ae=n(f,"P",{});var G$=s(Ae);rS=r(G$,"will create a model that is an instance of "),Li=n(G$,"A",{href:!0});var S3e=s(Li);tS=r(S3e,"BertModel"),S3e.forEach(t),aS=r(G$,"."),G$.forEach(t),Co=i(f),$a=n(f,"P",{});var O$=s($a);nS=r(O$,"There is one class of "),kf=n(O$,"CODE",{});var R3e=s(kf);sS=r(R3e,"AutoModel"),R3e.forEach(t),eQe=r(O$," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),O$.forEach(t),jGe=i(f),yi=n(f,"H2",{class:!0});var V$=s(yi);Sf=n(V$,"A",{id:!0,class:!0,href:!0});var P3e=s(Sf);mte=n(P3e,"SPAN",{});var B3e=s(mte);T(xA.$$.fragment,B3e),B3e.forEach(t),P3e.forEach(t),oQe=i(V$),gte=n(V$,"SPAN",{});var I3e=s(gte);rQe=r(I3e,"Extending the Auto Classes"),I3e.forEach(t),V$.forEach(t),DGe=i(f),Nn=n(f,"P",{});var wf=s(Nn);tQe=r(wf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=n(wf,"CODE",{});var N3e=s(hte);aQe=r(N3e,"NewModel"),N3e.forEach(t),nQe=r(wf,", make sure you have a "),pte=n(wf,"CODE",{});var q3e=s(pte);sQe=r(q3e,"NewModelConfig"),q3e.forEach(t),lQe=r(wf,` then you can add those to the auto
classes like this:`),wf.forEach(t),GGe=i(f),T($A.$$.fragment,f),OGe=i(f),lS=n(f,"P",{});var j3e=s(lS);iQe=r(j3e,"You will then be able to use the auto classes like you would usually do!"),j3e.forEach(t),VGe=i(f),T(Rf.$$.fragment,f),XGe=i(f),xi=n(f,"H2",{class:!0});var X$=s(xi);Pf=n(X$,"A",{id:!0,class:!0,href:!0});var D3e=s(Pf);_te=n(D3e,"SPAN",{});var G3e=s(_te);T(kA.$$.fragment,G3e),G3e.forEach(t),D3e.forEach(t),dQe=i(X$),ute=n(X$,"SPAN",{});var O3e=s(ute);cQe=r(O3e,"AutoConfig"),O3e.forEach(t),X$.forEach(t),zGe=i(f),wo=n(f,"DIV",{class:!0});var rt=s(wo);T(SA.$$.fragment,rt),fQe=i(rt),RA=n(rt,"P",{});var z$=s(RA);mQe=r(z$,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=n(z$,"A",{href:!0});var V3e=s(iS);gQe=r(V3e,"from_pretrained()"),V3e.forEach(t),hQe=r(z$," class method."),z$.forEach(t),pQe=i(rt),PA=n(rt,"P",{});var Q$=s(PA);_Qe=r(Q$,"This class cannot be instantiated directly using "),bte=n(Q$,"CODE",{});var X3e=s(bte);uQe=r(X3e,"__init__()"),X3e.forEach(t),bQe=r(Q$," (throws an error)."),Q$.forEach(t),vQe=i(rt),Ar=n(rt,"DIV",{class:!0});var tt=s(Ar);T(BA.$$.fragment,tt),FQe=i(tt),vte=n(tt,"P",{});var z3e=s(vte);TQe=r(z3e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),z3e.forEach(t),MQe=i(tt),$i=n(tt,"P",{});var Af=s($i);EQe=r(Af,"The configuration class to instantiate is selected based on the "),Fte=n(Af,"CODE",{});var Q3e=s(Fte);CQe=r(Q3e,"model_type"),Q3e.forEach(t),wQe=r(Af,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=n(Af,"CODE",{});var W3e=s(Tte);AQe=r(W3e,"pretrained_model_name_or_path"),W3e.forEach(t),LQe=r(Af,":"),Af.forEach(t),yQe=i(tt),A=n(tt,"UL",{});var L=s(A);Bf=n(L,"LI",{});var n0=s(Bf);Mte=n(n0,"STRONG",{});var H3e=s(Mte);xQe=r(H3e,"albert"),H3e.forEach(t),$Qe=r(n0," \u2014 "),dS=n(n0,"A",{href:!0});var U3e=s(dS);kQe=r(U3e,"AlbertConfig"),U3e.forEach(t),SQe=r(n0," (ALBERT model)"),n0.forEach(t),RQe=i(L),If=n(L,"LI",{});var s0=s(If);Ete=n(s0,"STRONG",{});var J3e=s(Ete);PQe=r(J3e,"bart"),J3e.forEach(t),BQe=r(s0," \u2014 "),cS=n(s0,"A",{href:!0});var Y3e=s(cS);IQe=r(Y3e,"BartConfig"),Y3e.forEach(t),NQe=r(s0," (BART model)"),s0.forEach(t),qQe=i(L),Nf=n(L,"LI",{});var l0=s(Nf);Cte=n(l0,"STRONG",{});var K3e=s(Cte);jQe=r(K3e,"beit"),K3e.forEach(t),DQe=r(l0," \u2014 "),fS=n(l0,"A",{href:!0});var Z3e=s(fS);GQe=r(Z3e,"BeitConfig"),Z3e.forEach(t),OQe=r(l0," (BEiT model)"),l0.forEach(t),VQe=i(L),qf=n(L,"LI",{});var i0=s(qf);wte=n(i0,"STRONG",{});var e0e=s(wte);XQe=r(e0e,"bert"),e0e.forEach(t),zQe=r(i0," \u2014 "),mS=n(i0,"A",{href:!0});var o0e=s(mS);QQe=r(o0e,"BertConfig"),o0e.forEach(t),WQe=r(i0," (BERT model)"),i0.forEach(t),HQe=i(L),jf=n(L,"LI",{});var d0=s(jf);Ate=n(d0,"STRONG",{});var r0e=s(Ate);UQe=r(r0e,"bert-generation"),r0e.forEach(t),JQe=r(d0," \u2014 "),gS=n(d0,"A",{href:!0});var t0e=s(gS);YQe=r(t0e,"BertGenerationConfig"),t0e.forEach(t),KQe=r(d0," (Bert Generation model)"),d0.forEach(t),ZQe=i(L),Df=n(L,"LI",{});var c0=s(Df);Lte=n(c0,"STRONG",{});var a0e=s(Lte);eWe=r(a0e,"big_bird"),a0e.forEach(t),oWe=r(c0," \u2014 "),hS=n(c0,"A",{href:!0});var n0e=s(hS);rWe=r(n0e,"BigBirdConfig"),n0e.forEach(t),tWe=r(c0," (BigBird model)"),c0.forEach(t),aWe=i(L),Gf=n(L,"LI",{});var f0=s(Gf);yte=n(f0,"STRONG",{});var s0e=s(yte);nWe=r(s0e,"bigbird_pegasus"),s0e.forEach(t),sWe=r(f0," \u2014 "),pS=n(f0,"A",{href:!0});var l0e=s(pS);lWe=r(l0e,"BigBirdPegasusConfig"),l0e.forEach(t),iWe=r(f0," (BigBird-Pegasus model)"),f0.forEach(t),dWe=i(L),Of=n(L,"LI",{});var m0=s(Of);xte=n(m0,"STRONG",{});var i0e=s(xte);cWe=r(i0e,"blenderbot"),i0e.forEach(t),fWe=r(m0," \u2014 "),_S=n(m0,"A",{href:!0});var d0e=s(_S);mWe=r(d0e,"BlenderbotConfig"),d0e.forEach(t),gWe=r(m0," (Blenderbot model)"),m0.forEach(t),hWe=i(L),Vf=n(L,"LI",{});var g0=s(Vf);$te=n(g0,"STRONG",{});var c0e=s($te);pWe=r(c0e,"blenderbot-small"),c0e.forEach(t),_We=r(g0," \u2014 "),uS=n(g0,"A",{href:!0});var f0e=s(uS);uWe=r(f0e,"BlenderbotSmallConfig"),f0e.forEach(t),bWe=r(g0," (BlenderbotSmall model)"),g0.forEach(t),vWe=i(L),Xf=n(L,"LI",{});var h0=s(Xf);kte=n(h0,"STRONG",{});var m0e=s(kte);FWe=r(m0e,"bloom"),m0e.forEach(t),TWe=r(h0," \u2014 "),bS=n(h0,"A",{href:!0});var g0e=s(bS);MWe=r(g0e,"BloomConfig"),g0e.forEach(t),EWe=r(h0," (BLOOM model)"),h0.forEach(t),CWe=i(L),zf=n(L,"LI",{});var p0=s(zf);Ste=n(p0,"STRONG",{});var h0e=s(Ste);wWe=r(h0e,"camembert"),h0e.forEach(t),AWe=r(p0," \u2014 "),vS=n(p0,"A",{href:!0});var p0e=s(vS);LWe=r(p0e,"CamembertConfig"),p0e.forEach(t),yWe=r(p0," (CamemBERT model)"),p0.forEach(t),xWe=i(L),Qf=n(L,"LI",{});var _0=s(Qf);Rte=n(_0,"STRONG",{});var _0e=s(Rte);$We=r(_0e,"canine"),_0e.forEach(t),kWe=r(_0," \u2014 "),FS=n(_0,"A",{href:!0});var u0e=s(FS);SWe=r(u0e,"CanineConfig"),u0e.forEach(t),RWe=r(_0," (CANINE model)"),_0.forEach(t),PWe=i(L),Wf=n(L,"LI",{});var u0=s(Wf);Pte=n(u0,"STRONG",{});var b0e=s(Pte);BWe=r(b0e,"clip"),b0e.forEach(t),IWe=r(u0," \u2014 "),TS=n(u0,"A",{href:!0});var v0e=s(TS);NWe=r(v0e,"CLIPConfig"),v0e.forEach(t),qWe=r(u0," (CLIP model)"),u0.forEach(t),jWe=i(L),Hf=n(L,"LI",{});var b0=s(Hf);Bte=n(b0,"STRONG",{});var F0e=s(Bte);DWe=r(F0e,"convbert"),F0e.forEach(t),GWe=r(b0," \u2014 "),MS=n(b0,"A",{href:!0});var T0e=s(MS);OWe=r(T0e,"ConvBertConfig"),T0e.forEach(t),VWe=r(b0," (ConvBERT model)"),b0.forEach(t),XWe=i(L),Uf=n(L,"LI",{});var v0=s(Uf);Ite=n(v0,"STRONG",{});var M0e=s(Ite);zWe=r(M0e,"convnext"),M0e.forEach(t),QWe=r(v0," \u2014 "),ES=n(v0,"A",{href:!0});var E0e=s(ES);WWe=r(E0e,"ConvNextConfig"),E0e.forEach(t),HWe=r(v0," (ConvNeXT model)"),v0.forEach(t),UWe=i(L),Jf=n(L,"LI",{});var F0=s(Jf);Nte=n(F0,"STRONG",{});var C0e=s(Nte);JWe=r(C0e,"ctrl"),C0e.forEach(t),YWe=r(F0," \u2014 "),CS=n(F0,"A",{href:!0});var w0e=s(CS);KWe=r(w0e,"CTRLConfig"),w0e.forEach(t),ZWe=r(F0," (CTRL model)"),F0.forEach(t),eHe=i(L),Yf=n(L,"LI",{});var T0=s(Yf);qte=n(T0,"STRONG",{});var A0e=s(qte);oHe=r(A0e,"cvt"),A0e.forEach(t),rHe=r(T0," \u2014 "),wS=n(T0,"A",{href:!0});var L0e=s(wS);tHe=r(L0e,"CvtConfig"),L0e.forEach(t),aHe=r(T0," (CvT model)"),T0.forEach(t),nHe=i(L),Kf=n(L,"LI",{});var M0=s(Kf);jte=n(M0,"STRONG",{});var y0e=s(jte);sHe=r(y0e,"data2vec-audio"),y0e.forEach(t),lHe=r(M0," \u2014 "),AS=n(M0,"A",{href:!0});var x0e=s(AS);iHe=r(x0e,"Data2VecAudioConfig"),x0e.forEach(t),dHe=r(M0," (Data2VecAudio model)"),M0.forEach(t),cHe=i(L),Zf=n(L,"LI",{});var E0=s(Zf);Dte=n(E0,"STRONG",{});var $0e=s(Dte);fHe=r($0e,"data2vec-text"),$0e.forEach(t),mHe=r(E0," \u2014 "),LS=n(E0,"A",{href:!0});var k0e=s(LS);gHe=r(k0e,"Data2VecTextConfig"),k0e.forEach(t),hHe=r(E0," (Data2VecText model)"),E0.forEach(t),pHe=i(L),em=n(L,"LI",{});var C0=s(em);Gte=n(C0,"STRONG",{});var S0e=s(Gte);_He=r(S0e,"data2vec-vision"),S0e.forEach(t),uHe=r(C0," \u2014 "),yS=n(C0,"A",{href:!0});var R0e=s(yS);bHe=r(R0e,"Data2VecVisionConfig"),R0e.forEach(t),vHe=r(C0," (Data2VecVision model)"),C0.forEach(t),FHe=i(L),om=n(L,"LI",{});var w0=s(om);Ote=n(w0,"STRONG",{});var P0e=s(Ote);THe=r(P0e,"deberta"),P0e.forEach(t),MHe=r(w0," \u2014 "),xS=n(w0,"A",{href:!0});var B0e=s(xS);EHe=r(B0e,"DebertaConfig"),B0e.forEach(t),CHe=r(w0," (DeBERTa model)"),w0.forEach(t),wHe=i(L),rm=n(L,"LI",{});var A0=s(rm);Vte=n(A0,"STRONG",{});var I0e=s(Vte);AHe=r(I0e,"deberta-v2"),I0e.forEach(t),LHe=r(A0," \u2014 "),$S=n(A0,"A",{href:!0});var N0e=s($S);yHe=r(N0e,"DebertaV2Config"),N0e.forEach(t),xHe=r(A0," (DeBERTa-v2 model)"),A0.forEach(t),$He=i(L),tm=n(L,"LI",{});var L0=s(tm);Xte=n(L0,"STRONG",{});var q0e=s(Xte);kHe=r(q0e,"decision_transformer"),q0e.forEach(t),SHe=r(L0," \u2014 "),kS=n(L0,"A",{href:!0});var j0e=s(kS);RHe=r(j0e,"DecisionTransformerConfig"),j0e.forEach(t),PHe=r(L0," (Decision Transformer model)"),L0.forEach(t),BHe=i(L),am=n(L,"LI",{});var y0=s(am);zte=n(y0,"STRONG",{});var ZYr=s(zte);IHe=r(ZYr,"deit"),ZYr.forEach(t),NHe=r(y0," \u2014 "),SS=n(y0,"A",{href:!0});var eKr=s(SS);qHe=r(eKr,"DeiTConfig"),eKr.forEach(t),jHe=r(y0," (DeiT model)"),y0.forEach(t),DHe=i(L),nm=n(L,"LI",{});var D0e=s(nm);Qte=n(D0e,"STRONG",{});var oKr=s(Qte);GHe=r(oKr,"detr"),oKr.forEach(t),OHe=r(D0e," \u2014 "),RS=n(D0e,"A",{href:!0});var rKr=s(RS);VHe=r(rKr,"DetrConfig"),rKr.forEach(t),XHe=r(D0e," (DETR model)"),D0e.forEach(t),zHe=i(L),sm=n(L,"LI",{});var G0e=s(sm);Wte=n(G0e,"STRONG",{});var tKr=s(Wte);QHe=r(tKr,"distilbert"),tKr.forEach(t),WHe=r(G0e," \u2014 "),PS=n(G0e,"A",{href:!0});var aKr=s(PS);HHe=r(aKr,"DistilBertConfig"),aKr.forEach(t),UHe=r(G0e," (DistilBERT model)"),G0e.forEach(t),JHe=i(L),lm=n(L,"LI",{});var O0e=s(lm);Hte=n(O0e,"STRONG",{});var nKr=s(Hte);YHe=r(nKr,"dpr"),nKr.forEach(t),KHe=r(O0e," \u2014 "),BS=n(O0e,"A",{href:!0});var sKr=s(BS);ZHe=r(sKr,"DPRConfig"),sKr.forEach(t),eUe=r(O0e," (DPR model)"),O0e.forEach(t),oUe=i(L),im=n(L,"LI",{});var V0e=s(im);Ute=n(V0e,"STRONG",{});var lKr=s(Ute);rUe=r(lKr,"dpt"),lKr.forEach(t),tUe=r(V0e," \u2014 "),IS=n(V0e,"A",{href:!0});var iKr=s(IS);aUe=r(iKr,"DPTConfig"),iKr.forEach(t),nUe=r(V0e," (DPT model)"),V0e.forEach(t),sUe=i(L),dm=n(L,"LI",{});var X0e=s(dm);Jte=n(X0e,"STRONG",{});var dKr=s(Jte);lUe=r(dKr,"electra"),dKr.forEach(t),iUe=r(X0e," \u2014 "),NS=n(X0e,"A",{href:!0});var cKr=s(NS);dUe=r(cKr,"ElectraConfig"),cKr.forEach(t),cUe=r(X0e," (ELECTRA model)"),X0e.forEach(t),fUe=i(L),cm=n(L,"LI",{});var z0e=s(cm);Yte=n(z0e,"STRONG",{});var fKr=s(Yte);mUe=r(fKr,"encoder-decoder"),fKr.forEach(t),gUe=r(z0e," \u2014 "),qS=n(z0e,"A",{href:!0});var mKr=s(qS);hUe=r(mKr,"EncoderDecoderConfig"),mKr.forEach(t),pUe=r(z0e," (Encoder decoder model)"),z0e.forEach(t),_Ue=i(L),fm=n(L,"LI",{});var Q0e=s(fm);Kte=n(Q0e,"STRONG",{});var gKr=s(Kte);uUe=r(gKr,"flaubert"),gKr.forEach(t),bUe=r(Q0e," \u2014 "),jS=n(Q0e,"A",{href:!0});var hKr=s(jS);vUe=r(hKr,"FlaubertConfig"),hKr.forEach(t),FUe=r(Q0e," (FlauBERT model)"),Q0e.forEach(t),TUe=i(L),mm=n(L,"LI",{});var W0e=s(mm);Zte=n(W0e,"STRONG",{});var pKr=s(Zte);MUe=r(pKr,"flava"),pKr.forEach(t),EUe=r(W0e," \u2014 "),DS=n(W0e,"A",{href:!0});var _Kr=s(DS);CUe=r(_Kr,"FlavaConfig"),_Kr.forEach(t),wUe=r(W0e," (FLAVA model)"),W0e.forEach(t),AUe=i(L),gm=n(L,"LI",{});var H0e=s(gm);eae=n(H0e,"STRONG",{});var uKr=s(eae);LUe=r(uKr,"fnet"),uKr.forEach(t),yUe=r(H0e," \u2014 "),GS=n(H0e,"A",{href:!0});var bKr=s(GS);xUe=r(bKr,"FNetConfig"),bKr.forEach(t),$Ue=r(H0e," (FNet model)"),H0e.forEach(t),kUe=i(L),hm=n(L,"LI",{});var U0e=s(hm);oae=n(U0e,"STRONG",{});var vKr=s(oae);SUe=r(vKr,"fsmt"),vKr.forEach(t),RUe=r(U0e," \u2014 "),OS=n(U0e,"A",{href:!0});var FKr=s(OS);PUe=r(FKr,"FSMTConfig"),FKr.forEach(t),BUe=r(U0e," (FairSeq Machine-Translation model)"),U0e.forEach(t),IUe=i(L),pm=n(L,"LI",{});var J0e=s(pm);rae=n(J0e,"STRONG",{});var TKr=s(rae);NUe=r(TKr,"funnel"),TKr.forEach(t),qUe=r(J0e," \u2014 "),VS=n(J0e,"A",{href:!0});var MKr=s(VS);jUe=r(MKr,"FunnelConfig"),MKr.forEach(t),DUe=r(J0e," (Funnel Transformer model)"),J0e.forEach(t),GUe=i(L),_m=n(L,"LI",{});var Y0e=s(_m);tae=n(Y0e,"STRONG",{});var EKr=s(tae);OUe=r(EKr,"glpn"),EKr.forEach(t),VUe=r(Y0e," \u2014 "),XS=n(Y0e,"A",{href:!0});var CKr=s(XS);XUe=r(CKr,"GLPNConfig"),CKr.forEach(t),zUe=r(Y0e," (GLPN model)"),Y0e.forEach(t),QUe=i(L),um=n(L,"LI",{});var K0e=s(um);aae=n(K0e,"STRONG",{});var wKr=s(aae);WUe=r(wKr,"gpt2"),wKr.forEach(t),HUe=r(K0e," \u2014 "),zS=n(K0e,"A",{href:!0});var AKr=s(zS);UUe=r(AKr,"GPT2Config"),AKr.forEach(t),JUe=r(K0e," (OpenAI GPT-2 model)"),K0e.forEach(t),YUe=i(L),bm=n(L,"LI",{});var Z0e=s(bm);nae=n(Z0e,"STRONG",{});var LKr=s(nae);KUe=r(LKr,"gpt_neo"),LKr.forEach(t),ZUe=r(Z0e," \u2014 "),QS=n(Z0e,"A",{href:!0});var yKr=s(QS);eJe=r(yKr,"GPTNeoConfig"),yKr.forEach(t),oJe=r(Z0e," (GPT Neo model)"),Z0e.forEach(t),rJe=i(L),vm=n(L,"LI",{});var ewe=s(vm);sae=n(ewe,"STRONG",{});var xKr=s(sae);tJe=r(xKr,"gpt_neox"),xKr.forEach(t),aJe=r(ewe," \u2014 "),WS=n(ewe,"A",{href:!0});var $Kr=s(WS);nJe=r($Kr,"GPTNeoXConfig"),$Kr.forEach(t),sJe=r(ewe," (GPT NeoX model)"),ewe.forEach(t),lJe=i(L),Fm=n(L,"LI",{});var owe=s(Fm);lae=n(owe,"STRONG",{});var kKr=s(lae);iJe=r(kKr,"gptj"),kKr.forEach(t),dJe=r(owe," \u2014 "),HS=n(owe,"A",{href:!0});var SKr=s(HS);cJe=r(SKr,"GPTJConfig"),SKr.forEach(t),fJe=r(owe," (GPT-J model)"),owe.forEach(t),mJe=i(L),Tm=n(L,"LI",{});var rwe=s(Tm);iae=n(rwe,"STRONG",{});var RKr=s(iae);gJe=r(RKr,"hubert"),RKr.forEach(t),hJe=r(rwe," \u2014 "),US=n(rwe,"A",{href:!0});var PKr=s(US);pJe=r(PKr,"HubertConfig"),PKr.forEach(t),_Je=r(rwe," (Hubert model)"),rwe.forEach(t),uJe=i(L),Mm=n(L,"LI",{});var twe=s(Mm);dae=n(twe,"STRONG",{});var BKr=s(dae);bJe=r(BKr,"ibert"),BKr.forEach(t),vJe=r(twe," \u2014 "),JS=n(twe,"A",{href:!0});var IKr=s(JS);FJe=r(IKr,"IBertConfig"),IKr.forEach(t),TJe=r(twe," (I-BERT model)"),twe.forEach(t),MJe=i(L),Em=n(L,"LI",{});var awe=s(Em);cae=n(awe,"STRONG",{});var NKr=s(cae);EJe=r(NKr,"imagegpt"),NKr.forEach(t),CJe=r(awe," \u2014 "),YS=n(awe,"A",{href:!0});var qKr=s(YS);wJe=r(qKr,"ImageGPTConfig"),qKr.forEach(t),AJe=r(awe," (ImageGPT model)"),awe.forEach(t),LJe=i(L),Cm=n(L,"LI",{});var nwe=s(Cm);fae=n(nwe,"STRONG",{});var jKr=s(fae);yJe=r(jKr,"layoutlm"),jKr.forEach(t),xJe=r(nwe," \u2014 "),KS=n(nwe,"A",{href:!0});var DKr=s(KS);$Je=r(DKr,"LayoutLMConfig"),DKr.forEach(t),kJe=r(nwe," (LayoutLM model)"),nwe.forEach(t),SJe=i(L),wm=n(L,"LI",{});var swe=s(wm);mae=n(swe,"STRONG",{});var GKr=s(mae);RJe=r(GKr,"layoutlmv2"),GKr.forEach(t),PJe=r(swe," \u2014 "),ZS=n(swe,"A",{href:!0});var OKr=s(ZS);BJe=r(OKr,"LayoutLMv2Config"),OKr.forEach(t),IJe=r(swe," (LayoutLMv2 model)"),swe.forEach(t),NJe=i(L),Am=n(L,"LI",{});var lwe=s(Am);gae=n(lwe,"STRONG",{});var VKr=s(gae);qJe=r(VKr,"layoutlmv3"),VKr.forEach(t),jJe=r(lwe," \u2014 "),eR=n(lwe,"A",{href:!0});var XKr=s(eR);DJe=r(XKr,"LayoutLMv3Config"),XKr.forEach(t),GJe=r(lwe," (LayoutLMv3 model)"),lwe.forEach(t),OJe=i(L),Lm=n(L,"LI",{});var iwe=s(Lm);hae=n(iwe,"STRONG",{});var zKr=s(hae);VJe=r(zKr,"led"),zKr.forEach(t),XJe=r(iwe," \u2014 "),oR=n(iwe,"A",{href:!0});var QKr=s(oR);zJe=r(QKr,"LEDConfig"),QKr.forEach(t),QJe=r(iwe," (LED model)"),iwe.forEach(t),WJe=i(L),ym=n(L,"LI",{});var dwe=s(ym);pae=n(dwe,"STRONG",{});var WKr=s(pae);HJe=r(WKr,"levit"),WKr.forEach(t),UJe=r(dwe," \u2014 "),rR=n(dwe,"A",{href:!0});var HKr=s(rR);JJe=r(HKr,"LevitConfig"),HKr.forEach(t),YJe=r(dwe," (LeViT model)"),dwe.forEach(t),KJe=i(L),xm=n(L,"LI",{});var cwe=s(xm);_ae=n(cwe,"STRONG",{});var UKr=s(_ae);ZJe=r(UKr,"longformer"),UKr.forEach(t),eYe=r(cwe," \u2014 "),tR=n(cwe,"A",{href:!0});var JKr=s(tR);oYe=r(JKr,"LongformerConfig"),JKr.forEach(t),rYe=r(cwe," (Longformer model)"),cwe.forEach(t),tYe=i(L),$m=n(L,"LI",{});var fwe=s($m);uae=n(fwe,"STRONG",{});var YKr=s(uae);aYe=r(YKr,"longt5"),YKr.forEach(t),nYe=r(fwe," \u2014 "),aR=n(fwe,"A",{href:!0});var KKr=s(aR);sYe=r(KKr,"LongT5Config"),KKr.forEach(t),lYe=r(fwe," (LongT5 model)"),fwe.forEach(t),iYe=i(L),km=n(L,"LI",{});var mwe=s(km);bae=n(mwe,"STRONG",{});var ZKr=s(bae);dYe=r(ZKr,"luke"),ZKr.forEach(t),cYe=r(mwe," \u2014 "),nR=n(mwe,"A",{href:!0});var eZr=s(nR);fYe=r(eZr,"LukeConfig"),eZr.forEach(t),mYe=r(mwe," (LUKE model)"),mwe.forEach(t),gYe=i(L),Sm=n(L,"LI",{});var gwe=s(Sm);vae=n(gwe,"STRONG",{});var oZr=s(vae);hYe=r(oZr,"lxmert"),oZr.forEach(t),pYe=r(gwe," \u2014 "),sR=n(gwe,"A",{href:!0});var rZr=s(sR);_Ye=r(rZr,"LxmertConfig"),rZr.forEach(t),uYe=r(gwe," (LXMERT model)"),gwe.forEach(t),bYe=i(L),Rm=n(L,"LI",{});var hwe=s(Rm);Fae=n(hwe,"STRONG",{});var tZr=s(Fae);vYe=r(tZr,"m2m_100"),tZr.forEach(t),FYe=r(hwe," \u2014 "),lR=n(hwe,"A",{href:!0});var aZr=s(lR);TYe=r(aZr,"M2M100Config"),aZr.forEach(t),MYe=r(hwe," (M2M100 model)"),hwe.forEach(t),EYe=i(L),Pm=n(L,"LI",{});var pwe=s(Pm);Tae=n(pwe,"STRONG",{});var nZr=s(Tae);CYe=r(nZr,"marian"),nZr.forEach(t),wYe=r(pwe," \u2014 "),iR=n(pwe,"A",{href:!0});var sZr=s(iR);AYe=r(sZr,"MarianConfig"),sZr.forEach(t),LYe=r(pwe," (Marian model)"),pwe.forEach(t),yYe=i(L),Bm=n(L,"LI",{});var _we=s(Bm);Mae=n(_we,"STRONG",{});var lZr=s(Mae);xYe=r(lZr,"maskformer"),lZr.forEach(t),$Ye=r(_we," \u2014 "),dR=n(_we,"A",{href:!0});var iZr=s(dR);kYe=r(iZr,"MaskFormerConfig"),iZr.forEach(t),SYe=r(_we," (MaskFormer model)"),_we.forEach(t),RYe=i(L),Im=n(L,"LI",{});var uwe=s(Im);Eae=n(uwe,"STRONG",{});var dZr=s(Eae);PYe=r(dZr,"mbart"),dZr.forEach(t),BYe=r(uwe," \u2014 "),cR=n(uwe,"A",{href:!0});var cZr=s(cR);IYe=r(cZr,"MBartConfig"),cZr.forEach(t),NYe=r(uwe," (mBART model)"),uwe.forEach(t),qYe=i(L),Nm=n(L,"LI",{});var bwe=s(Nm);Cae=n(bwe,"STRONG",{});var fZr=s(Cae);jYe=r(fZr,"mctct"),fZr.forEach(t),DYe=r(bwe," \u2014 "),fR=n(bwe,"A",{href:!0});var mZr=s(fR);GYe=r(mZr,"MCTCTConfig"),mZr.forEach(t),OYe=r(bwe," (M-CTC-T model)"),bwe.forEach(t),VYe=i(L),qm=n(L,"LI",{});var vwe=s(qm);wae=n(vwe,"STRONG",{});var gZr=s(wae);XYe=r(gZr,"megatron-bert"),gZr.forEach(t),zYe=r(vwe," \u2014 "),mR=n(vwe,"A",{href:!0});var hZr=s(mR);QYe=r(hZr,"MegatronBertConfig"),hZr.forEach(t),WYe=r(vwe," (Megatron-BERT model)"),vwe.forEach(t),HYe=i(L),jm=n(L,"LI",{});var Fwe=s(jm);Aae=n(Fwe,"STRONG",{});var pZr=s(Aae);UYe=r(pZr,"mobilebert"),pZr.forEach(t),JYe=r(Fwe," \u2014 "),gR=n(Fwe,"A",{href:!0});var _Zr=s(gR);YYe=r(_Zr,"MobileBertConfig"),_Zr.forEach(t),KYe=r(Fwe," (MobileBERT model)"),Fwe.forEach(t),ZYe=i(L),Dm=n(L,"LI",{});var Twe=s(Dm);Lae=n(Twe,"STRONG",{});var uZr=s(Lae);eKe=r(uZr,"mpnet"),uZr.forEach(t),oKe=r(Twe," \u2014 "),hR=n(Twe,"A",{href:!0});var bZr=s(hR);rKe=r(bZr,"MPNetConfig"),bZr.forEach(t),tKe=r(Twe," (MPNet model)"),Twe.forEach(t),aKe=i(L),Gm=n(L,"LI",{});var Mwe=s(Gm);yae=n(Mwe,"STRONG",{});var vZr=s(yae);nKe=r(vZr,"mt5"),vZr.forEach(t),sKe=r(Mwe," \u2014 "),pR=n(Mwe,"A",{href:!0});var FZr=s(pR);lKe=r(FZr,"MT5Config"),FZr.forEach(t),iKe=r(Mwe," (MT5 model)"),Mwe.forEach(t),dKe=i(L),Om=n(L,"LI",{});var Ewe=s(Om);xae=n(Ewe,"STRONG",{});var TZr=s(xae);cKe=r(TZr,"nezha"),TZr.forEach(t),fKe=r(Ewe," \u2014 "),_R=n(Ewe,"A",{href:!0});var MZr=s(_R);mKe=r(MZr,"NezhaConfig"),MZr.forEach(t),gKe=r(Ewe," (Nezha model)"),Ewe.forEach(t),hKe=i(L),Vm=n(L,"LI",{});var Cwe=s(Vm);$ae=n(Cwe,"STRONG",{});var EZr=s($ae);pKe=r(EZr,"nystromformer"),EZr.forEach(t),_Ke=r(Cwe," \u2014 "),uR=n(Cwe,"A",{href:!0});var CZr=s(uR);uKe=r(CZr,"NystromformerConfig"),CZr.forEach(t),bKe=r(Cwe," (Nystr\xF6mformer model)"),Cwe.forEach(t),vKe=i(L),Xm=n(L,"LI",{});var wwe=s(Xm);kae=n(wwe,"STRONG",{});var wZr=s(kae);FKe=r(wZr,"openai-gpt"),wZr.forEach(t),TKe=r(wwe," \u2014 "),bR=n(wwe,"A",{href:!0});var AZr=s(bR);MKe=r(AZr,"OpenAIGPTConfig"),AZr.forEach(t),EKe=r(wwe," (OpenAI GPT model)"),wwe.forEach(t),CKe=i(L),zm=n(L,"LI",{});var Awe=s(zm);Sae=n(Awe,"STRONG",{});var LZr=s(Sae);wKe=r(LZr,"opt"),LZr.forEach(t),AKe=r(Awe," \u2014 "),vR=n(Awe,"A",{href:!0});var yZr=s(vR);LKe=r(yZr,"OPTConfig"),yZr.forEach(t),yKe=r(Awe," (OPT model)"),Awe.forEach(t),xKe=i(L),Qm=n(L,"LI",{});var Lwe=s(Qm);Rae=n(Lwe,"STRONG",{});var xZr=s(Rae);$Ke=r(xZr,"pegasus"),xZr.forEach(t),kKe=r(Lwe," \u2014 "),FR=n(Lwe,"A",{href:!0});var $Zr=s(FR);SKe=r($Zr,"PegasusConfig"),$Zr.forEach(t),RKe=r(Lwe," (Pegasus model)"),Lwe.forEach(t),PKe=i(L),Wm=n(L,"LI",{});var ywe=s(Wm);Pae=n(ywe,"STRONG",{});var kZr=s(Pae);BKe=r(kZr,"perceiver"),kZr.forEach(t),IKe=r(ywe," \u2014 "),TR=n(ywe,"A",{href:!0});var SZr=s(TR);NKe=r(SZr,"PerceiverConfig"),SZr.forEach(t),qKe=r(ywe," (Perceiver model)"),ywe.forEach(t),jKe=i(L),Hm=n(L,"LI",{});var xwe=s(Hm);Bae=n(xwe,"STRONG",{});var RZr=s(Bae);DKe=r(RZr,"plbart"),RZr.forEach(t),GKe=r(xwe," \u2014 "),MR=n(xwe,"A",{href:!0});var PZr=s(MR);OKe=r(PZr,"PLBartConfig"),PZr.forEach(t),VKe=r(xwe," (PLBart model)"),xwe.forEach(t),XKe=i(L),Um=n(L,"LI",{});var $we=s(Um);Iae=n($we,"STRONG",{});var BZr=s(Iae);zKe=r(BZr,"poolformer"),BZr.forEach(t),QKe=r($we," \u2014 "),ER=n($we,"A",{href:!0});var IZr=s(ER);WKe=r(IZr,"PoolFormerConfig"),IZr.forEach(t),HKe=r($we," (PoolFormer model)"),$we.forEach(t),UKe=i(L),Jm=n(L,"LI",{});var kwe=s(Jm);Nae=n(kwe,"STRONG",{});var NZr=s(Nae);JKe=r(NZr,"prophetnet"),NZr.forEach(t),YKe=r(kwe," \u2014 "),CR=n(kwe,"A",{href:!0});var qZr=s(CR);KKe=r(qZr,"ProphetNetConfig"),qZr.forEach(t),ZKe=r(kwe," (ProphetNet model)"),kwe.forEach(t),eZe=i(L),Ym=n(L,"LI",{});var Swe=s(Ym);qae=n(Swe,"STRONG",{});var jZr=s(qae);oZe=r(jZr,"qdqbert"),jZr.forEach(t),rZe=r(Swe," \u2014 "),wR=n(Swe,"A",{href:!0});var DZr=s(wR);tZe=r(DZr,"QDQBertConfig"),DZr.forEach(t),aZe=r(Swe," (QDQBert model)"),Swe.forEach(t),nZe=i(L),Km=n(L,"LI",{});var Rwe=s(Km);jae=n(Rwe,"STRONG",{});var GZr=s(jae);sZe=r(GZr,"rag"),GZr.forEach(t),lZe=r(Rwe," \u2014 "),AR=n(Rwe,"A",{href:!0});var OZr=s(AR);iZe=r(OZr,"RagConfig"),OZr.forEach(t),dZe=r(Rwe," (RAG model)"),Rwe.forEach(t),cZe=i(L),Zm=n(L,"LI",{});var Pwe=s(Zm);Dae=n(Pwe,"STRONG",{});var VZr=s(Dae);fZe=r(VZr,"realm"),VZr.forEach(t),mZe=r(Pwe," \u2014 "),LR=n(Pwe,"A",{href:!0});var XZr=s(LR);gZe=r(XZr,"RealmConfig"),XZr.forEach(t),hZe=r(Pwe," (REALM model)"),Pwe.forEach(t),pZe=i(L),eg=n(L,"LI",{});var Bwe=s(eg);Gae=n(Bwe,"STRONG",{});var zZr=s(Gae);_Ze=r(zZr,"reformer"),zZr.forEach(t),uZe=r(Bwe," \u2014 "),yR=n(Bwe,"A",{href:!0});var QZr=s(yR);bZe=r(QZr,"ReformerConfig"),QZr.forEach(t),vZe=r(Bwe," (Reformer model)"),Bwe.forEach(t),FZe=i(L),og=n(L,"LI",{});var Iwe=s(og);Oae=n(Iwe,"STRONG",{});var WZr=s(Oae);TZe=r(WZr,"regnet"),WZr.forEach(t),MZe=r(Iwe," \u2014 "),xR=n(Iwe,"A",{href:!0});var HZr=s(xR);EZe=r(HZr,"RegNetConfig"),HZr.forEach(t),CZe=r(Iwe," (RegNet model)"),Iwe.forEach(t),wZe=i(L),rg=n(L,"LI",{});var Nwe=s(rg);Vae=n(Nwe,"STRONG",{});var UZr=s(Vae);AZe=r(UZr,"rembert"),UZr.forEach(t),LZe=r(Nwe," \u2014 "),$R=n(Nwe,"A",{href:!0});var JZr=s($R);yZe=r(JZr,"RemBertConfig"),JZr.forEach(t),xZe=r(Nwe," (RemBERT model)"),Nwe.forEach(t),$Ze=i(L),tg=n(L,"LI",{});var qwe=s(tg);Xae=n(qwe,"STRONG",{});var YZr=s(Xae);kZe=r(YZr,"resnet"),YZr.forEach(t),SZe=r(qwe," \u2014 "),kR=n(qwe,"A",{href:!0});var KZr=s(kR);RZe=r(KZr,"ResNetConfig"),KZr.forEach(t),PZe=r(qwe," (ResNet model)"),qwe.forEach(t),BZe=i(L),ag=n(L,"LI",{});var jwe=s(ag);zae=n(jwe,"STRONG",{});var ZZr=s(zae);IZe=r(ZZr,"retribert"),ZZr.forEach(t),NZe=r(jwe," \u2014 "),SR=n(jwe,"A",{href:!0});var eet=s(SR);qZe=r(eet,"RetriBertConfig"),eet.forEach(t),jZe=r(jwe," (RetriBERT model)"),jwe.forEach(t),DZe=i(L),ng=n(L,"LI",{});var Dwe=s(ng);Qae=n(Dwe,"STRONG",{});var oet=s(Qae);GZe=r(oet,"roberta"),oet.forEach(t),OZe=r(Dwe," \u2014 "),RR=n(Dwe,"A",{href:!0});var ret=s(RR);VZe=r(ret,"RobertaConfig"),ret.forEach(t),XZe=r(Dwe," (RoBERTa model)"),Dwe.forEach(t),zZe=i(L),sg=n(L,"LI",{});var Gwe=s(sg);Wae=n(Gwe,"STRONG",{});var tet=s(Wae);QZe=r(tet,"roformer"),tet.forEach(t),WZe=r(Gwe," \u2014 "),PR=n(Gwe,"A",{href:!0});var aet=s(PR);HZe=r(aet,"RoFormerConfig"),aet.forEach(t),UZe=r(Gwe," (RoFormer model)"),Gwe.forEach(t),JZe=i(L),lg=n(L,"LI",{});var Owe=s(lg);Hae=n(Owe,"STRONG",{});var net=s(Hae);YZe=r(net,"segformer"),net.forEach(t),KZe=r(Owe," \u2014 "),BR=n(Owe,"A",{href:!0});var set=s(BR);ZZe=r(set,"SegformerConfig"),set.forEach(t),eeo=r(Owe," (SegFormer model)"),Owe.forEach(t),oeo=i(L),ig=n(L,"LI",{});var Vwe=s(ig);Uae=n(Vwe,"STRONG",{});var iet=s(Uae);reo=r(iet,"sew"),iet.forEach(t),teo=r(Vwe," \u2014 "),IR=n(Vwe,"A",{href:!0});var det=s(IR);aeo=r(det,"SEWConfig"),det.forEach(t),neo=r(Vwe," (SEW model)"),Vwe.forEach(t),seo=i(L),dg=n(L,"LI",{});var Xwe=s(dg);Jae=n(Xwe,"STRONG",{});var cet=s(Jae);leo=r(cet,"sew-d"),cet.forEach(t),ieo=r(Xwe," \u2014 "),NR=n(Xwe,"A",{href:!0});var fet=s(NR);deo=r(fet,"SEWDConfig"),fet.forEach(t),ceo=r(Xwe," (SEW-D model)"),Xwe.forEach(t),feo=i(L),cg=n(L,"LI",{});var zwe=s(cg);Yae=n(zwe,"STRONG",{});var met=s(Yae);meo=r(met,"speech-encoder-decoder"),met.forEach(t),geo=r(zwe," \u2014 "),qR=n(zwe,"A",{href:!0});var get=s(qR);heo=r(get,"SpeechEncoderDecoderConfig"),get.forEach(t),peo=r(zwe," (Speech Encoder decoder model)"),zwe.forEach(t),_eo=i(L),fg=n(L,"LI",{});var Qwe=s(fg);Kae=n(Qwe,"STRONG",{});var het=s(Kae);ueo=r(het,"speech_to_text"),het.forEach(t),beo=r(Qwe," \u2014 "),jR=n(Qwe,"A",{href:!0});var pet=s(jR);veo=r(pet,"Speech2TextConfig"),pet.forEach(t),Feo=r(Qwe," (Speech2Text model)"),Qwe.forEach(t),Teo=i(L),mg=n(L,"LI",{});var Wwe=s(mg);Zae=n(Wwe,"STRONG",{});var _et=s(Zae);Meo=r(_et,"speech_to_text_2"),_et.forEach(t),Eeo=r(Wwe," \u2014 "),DR=n(Wwe,"A",{href:!0});var uet=s(DR);Ceo=r(uet,"Speech2Text2Config"),uet.forEach(t),weo=r(Wwe," (Speech2Text2 model)"),Wwe.forEach(t),Aeo=i(L),gg=n(L,"LI",{});var Hwe=s(gg);ene=n(Hwe,"STRONG",{});var bet=s(ene);Leo=r(bet,"splinter"),bet.forEach(t),yeo=r(Hwe," \u2014 "),GR=n(Hwe,"A",{href:!0});var vet=s(GR);xeo=r(vet,"SplinterConfig"),vet.forEach(t),$eo=r(Hwe," (Splinter model)"),Hwe.forEach(t),keo=i(L),hg=n(L,"LI",{});var Uwe=s(hg);one=n(Uwe,"STRONG",{});var Fet=s(one);Seo=r(Fet,"squeezebert"),Fet.forEach(t),Reo=r(Uwe," \u2014 "),OR=n(Uwe,"A",{href:!0});var Tet=s(OR);Peo=r(Tet,"SqueezeBertConfig"),Tet.forEach(t),Beo=r(Uwe," (SqueezeBERT model)"),Uwe.forEach(t),Ieo=i(L),pg=n(L,"LI",{});var Jwe=s(pg);rne=n(Jwe,"STRONG",{});var Met=s(rne);Neo=r(Met,"swin"),Met.forEach(t),qeo=r(Jwe," \u2014 "),VR=n(Jwe,"A",{href:!0});var Eet=s(VR);jeo=r(Eet,"SwinConfig"),Eet.forEach(t),Deo=r(Jwe," (Swin Transformer model)"),Jwe.forEach(t),Geo=i(L),_g=n(L,"LI",{});var Ywe=s(_g);tne=n(Ywe,"STRONG",{});var Cet=s(tne);Oeo=r(Cet,"t5"),Cet.forEach(t),Veo=r(Ywe," \u2014 "),XR=n(Ywe,"A",{href:!0});var wet=s(XR);Xeo=r(wet,"T5Config"),wet.forEach(t),zeo=r(Ywe," (T5 model)"),Ywe.forEach(t),Qeo=i(L),ug=n(L,"LI",{});var Kwe=s(ug);ane=n(Kwe,"STRONG",{});var Aet=s(ane);Weo=r(Aet,"tapas"),Aet.forEach(t),Heo=r(Kwe," \u2014 "),zR=n(Kwe,"A",{href:!0});var Let=s(zR);Ueo=r(Let,"TapasConfig"),Let.forEach(t),Jeo=r(Kwe," (TAPAS model)"),Kwe.forEach(t),Yeo=i(L),bg=n(L,"LI",{});var Zwe=s(bg);nne=n(Zwe,"STRONG",{});var yet=s(nne);Keo=r(yet,"trajectory_transformer"),yet.forEach(t),Zeo=r(Zwe," \u2014 "),QR=n(Zwe,"A",{href:!0});var xet=s(QR);eoo=r(xet,"TrajectoryTransformerConfig"),xet.forEach(t),ooo=r(Zwe," (Trajectory Transformer model)"),Zwe.forEach(t),roo=i(L),vg=n(L,"LI",{});var eAe=s(vg);sne=n(eAe,"STRONG",{});var $et=s(sne);too=r($et,"transfo-xl"),$et.forEach(t),aoo=r(eAe," \u2014 "),WR=n(eAe,"A",{href:!0});var ket=s(WR);noo=r(ket,"TransfoXLConfig"),ket.forEach(t),soo=r(eAe," (Transformer-XL model)"),eAe.forEach(t),loo=i(L),Fg=n(L,"LI",{});var oAe=s(Fg);lne=n(oAe,"STRONG",{});var Set=s(lne);ioo=r(Set,"trocr"),Set.forEach(t),doo=r(oAe," \u2014 "),HR=n(oAe,"A",{href:!0});var Ret=s(HR);coo=r(Ret,"TrOCRConfig"),Ret.forEach(t),foo=r(oAe," (TrOCR model)"),oAe.forEach(t),moo=i(L),Tg=n(L,"LI",{});var rAe=s(Tg);ine=n(rAe,"STRONG",{});var Pet=s(ine);goo=r(Pet,"unispeech"),Pet.forEach(t),hoo=r(rAe," \u2014 "),UR=n(rAe,"A",{href:!0});var Bet=s(UR);poo=r(Bet,"UniSpeechConfig"),Bet.forEach(t),_oo=r(rAe," (UniSpeech model)"),rAe.forEach(t),uoo=i(L),Mg=n(L,"LI",{});var tAe=s(Mg);dne=n(tAe,"STRONG",{});var Iet=s(dne);boo=r(Iet,"unispeech-sat"),Iet.forEach(t),voo=r(tAe," \u2014 "),JR=n(tAe,"A",{href:!0});var Net=s(JR);Foo=r(Net,"UniSpeechSatConfig"),Net.forEach(t),Too=r(tAe," (UniSpeechSat model)"),tAe.forEach(t),Moo=i(L),Eg=n(L,"LI",{});var aAe=s(Eg);cne=n(aAe,"STRONG",{});var qet=s(cne);Eoo=r(qet,"van"),qet.forEach(t),Coo=r(aAe," \u2014 "),YR=n(aAe,"A",{href:!0});var jet=s(YR);woo=r(jet,"VanConfig"),jet.forEach(t),Aoo=r(aAe," (VAN model)"),aAe.forEach(t),Loo=i(L),Cg=n(L,"LI",{});var nAe=s(Cg);fne=n(nAe,"STRONG",{});var Det=s(fne);yoo=r(Det,"vilt"),Det.forEach(t),xoo=r(nAe," \u2014 "),KR=n(nAe,"A",{href:!0});var Get=s(KR);$oo=r(Get,"ViltConfig"),Get.forEach(t),koo=r(nAe," (ViLT model)"),nAe.forEach(t),Soo=i(L),wg=n(L,"LI",{});var sAe=s(wg);mne=n(sAe,"STRONG",{});var Oet=s(mne);Roo=r(Oet,"vision-encoder-decoder"),Oet.forEach(t),Poo=r(sAe," \u2014 "),ZR=n(sAe,"A",{href:!0});var Vet=s(ZR);Boo=r(Vet,"VisionEncoderDecoderConfig"),Vet.forEach(t),Ioo=r(sAe," (Vision Encoder decoder model)"),sAe.forEach(t),Noo=i(L),Ag=n(L,"LI",{});var lAe=s(Ag);gne=n(lAe,"STRONG",{});var Xet=s(gne);qoo=r(Xet,"vision-text-dual-encoder"),Xet.forEach(t),joo=r(lAe," \u2014 "),eP=n(lAe,"A",{href:!0});var zet=s(eP);Doo=r(zet,"VisionTextDualEncoderConfig"),zet.forEach(t),Goo=r(lAe," (VisionTextDualEncoder model)"),lAe.forEach(t),Ooo=i(L),Lg=n(L,"LI",{});var iAe=s(Lg);hne=n(iAe,"STRONG",{});var Qet=s(hne);Voo=r(Qet,"visual_bert"),Qet.forEach(t),Xoo=r(iAe," \u2014 "),oP=n(iAe,"A",{href:!0});var Wet=s(oP);zoo=r(Wet,"VisualBertConfig"),Wet.forEach(t),Qoo=r(iAe," (VisualBERT model)"),iAe.forEach(t),Woo=i(L),yg=n(L,"LI",{});var dAe=s(yg);pne=n(dAe,"STRONG",{});var Het=s(pne);Hoo=r(Het,"vit"),Het.forEach(t),Uoo=r(dAe," \u2014 "),rP=n(dAe,"A",{href:!0});var Uet=s(rP);Joo=r(Uet,"ViTConfig"),Uet.forEach(t),Yoo=r(dAe," (ViT model)"),dAe.forEach(t),Koo=i(L),xg=n(L,"LI",{});var cAe=s(xg);_ne=n(cAe,"STRONG",{});var Jet=s(_ne);Zoo=r(Jet,"vit_mae"),Jet.forEach(t),ero=r(cAe," \u2014 "),tP=n(cAe,"A",{href:!0});var Yet=s(tP);oro=r(Yet,"ViTMAEConfig"),Yet.forEach(t),rro=r(cAe," (ViTMAE model)"),cAe.forEach(t),tro=i(L),$g=n(L,"LI",{});var fAe=s($g);une=n(fAe,"STRONG",{});var Ket=s(une);aro=r(Ket,"wav2vec2"),Ket.forEach(t),nro=r(fAe," \u2014 "),aP=n(fAe,"A",{href:!0});var Zet=s(aP);sro=r(Zet,"Wav2Vec2Config"),Zet.forEach(t),lro=r(fAe," (Wav2Vec2 model)"),fAe.forEach(t),iro=i(L),kg=n(L,"LI",{});var mAe=s(kg);bne=n(mAe,"STRONG",{});var eot=s(bne);dro=r(eot,"wav2vec2-conformer"),eot.forEach(t),cro=r(mAe," \u2014 "),nP=n(mAe,"A",{href:!0});var oot=s(nP);fro=r(oot,"Wav2Vec2ConformerConfig"),oot.forEach(t),mro=r(mAe," (Wav2Vec2-Conformer model)"),mAe.forEach(t),gro=i(L),Sg=n(L,"LI",{});var gAe=s(Sg);vne=n(gAe,"STRONG",{});var rot=s(vne);hro=r(rot,"wavlm"),rot.forEach(t),pro=r(gAe," \u2014 "),sP=n(gAe,"A",{href:!0});var tot=s(sP);_ro=r(tot,"WavLMConfig"),tot.forEach(t),uro=r(gAe," (WavLM model)"),gAe.forEach(t),bro=i(L),Rg=n(L,"LI",{});var hAe=s(Rg);Fne=n(hAe,"STRONG",{});var aot=s(Fne);vro=r(aot,"xglm"),aot.forEach(t),Fro=r(hAe," \u2014 "),lP=n(hAe,"A",{href:!0});var not=s(lP);Tro=r(not,"XGLMConfig"),not.forEach(t),Mro=r(hAe," (XGLM model)"),hAe.forEach(t),Ero=i(L),Pg=n(L,"LI",{});var pAe=s(Pg);Tne=n(pAe,"STRONG",{});var sot=s(Tne);Cro=r(sot,"xlm"),sot.forEach(t),wro=r(pAe," \u2014 "),iP=n(pAe,"A",{href:!0});var lot=s(iP);Aro=r(lot,"XLMConfig"),lot.forEach(t),Lro=r(pAe," (XLM model)"),pAe.forEach(t),yro=i(L),Bg=n(L,"LI",{});var _Ae=s(Bg);Mne=n(_Ae,"STRONG",{});var iot=s(Mne);xro=r(iot,"xlm-prophetnet"),iot.forEach(t),$ro=r(_Ae," \u2014 "),dP=n(_Ae,"A",{href:!0});var dot=s(dP);kro=r(dot,"XLMProphetNetConfig"),dot.forEach(t),Sro=r(_Ae," (XLM-ProphetNet model)"),_Ae.forEach(t),Rro=i(L),Ig=n(L,"LI",{});var uAe=s(Ig);Ene=n(uAe,"STRONG",{});var cot=s(Ene);Pro=r(cot,"xlm-roberta"),cot.forEach(t),Bro=r(uAe," \u2014 "),cP=n(uAe,"A",{href:!0});var fot=s(cP);Iro=r(fot,"XLMRobertaConfig"),fot.forEach(t),Nro=r(uAe," (XLM-RoBERTa model)"),uAe.forEach(t),qro=i(L),Ng=n(L,"LI",{});var bAe=s(Ng);Cne=n(bAe,"STRONG",{});var mot=s(Cne);jro=r(mot,"xlm-roberta-xl"),mot.forEach(t),Dro=r(bAe," \u2014 "),fP=n(bAe,"A",{href:!0});var got=s(fP);Gro=r(got,"XLMRobertaXLConfig"),got.forEach(t),Oro=r(bAe," (XLM-RoBERTa-XL model)"),bAe.forEach(t),Vro=i(L),qg=n(L,"LI",{});var vAe=s(qg);wne=n(vAe,"STRONG",{});var hot=s(wne);Xro=r(hot,"xlnet"),hot.forEach(t),zro=r(vAe," \u2014 "),mP=n(vAe,"A",{href:!0});var pot=s(mP);Qro=r(pot,"XLNetConfig"),pot.forEach(t),Wro=r(vAe," (XLNet model)"),vAe.forEach(t),Hro=i(L),jg=n(L,"LI",{});var FAe=s(jg);Ane=n(FAe,"STRONG",{});var _ot=s(Ane);Uro=r(_ot,"yolos"),_ot.forEach(t),Jro=r(FAe," \u2014 "),gP=n(FAe,"A",{href:!0});var uot=s(gP);Yro=r(uot,"YolosConfig"),uot.forEach(t),Kro=r(FAe," (YOLOS model)"),FAe.forEach(t),Zro=i(L),Dg=n(L,"LI",{});var TAe=s(Dg);Lne=n(TAe,"STRONG",{});var bot=s(Lne);eto=r(bot,"yoso"),bot.forEach(t),oto=r(TAe," \u2014 "),hP=n(TAe,"A",{href:!0});var vot=s(hP);rto=r(vot,"YosoConfig"),vot.forEach(t),tto=r(TAe," (YOSO model)"),TAe.forEach(t),L.forEach(t),ato=i(tt),T(Gg.$$.fragment,tt),tt.forEach(t),nto=i(rt),Og=n(rt,"DIV",{class:!0});var zVe=s(Og);T(IA.$$.fragment,zVe),sto=i(zVe),yne=n(zVe,"P",{});var Fot=s(yne);lto=r(Fot,"Register a new configuration for this class."),Fot.forEach(t),zVe.forEach(t),rt.forEach(t),QGe=i(f),ki=n(f,"H2",{class:!0});var QVe=s(ki);Vg=n(QVe,"A",{id:!0,class:!0,href:!0});var Tot=s(Vg);xne=n(Tot,"SPAN",{});var Mot=s(xne);T(NA.$$.fragment,Mot),Mot.forEach(t),Tot.forEach(t),ito=i(QVe),$ne=n(QVe,"SPAN",{});var Eot=s($ne);dto=r(Eot,"AutoTokenizer"),Eot.forEach(t),QVe.forEach(t),WGe=i(f),Ao=n(f,"DIV",{class:!0});var Ws=s(Ao);T(qA.$$.fragment,Ws),cto=i(Ws),jA=n(Ws,"P",{});var WVe=s(jA);fto=r(WVe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),pP=n(WVe,"A",{href:!0});var Cot=s(pP);mto=r(Cot,"AutoTokenizer.from_pretrained()"),Cot.forEach(t),gto=r(WVe," class method."),WVe.forEach(t),hto=i(Ws),DA=n(Ws,"P",{});var HVe=s(DA);pto=r(HVe,"This class cannot be instantiated directly using "),kne=n(HVe,"CODE",{});var wot=s(kne);_to=r(wot,"__init__()"),wot.forEach(t),uto=r(HVe," (throws an error)."),HVe.forEach(t),bto=i(Ws),Lr=n(Ws,"DIV",{class:!0});var Hs=s(Lr);T(GA.$$.fragment,Hs),vto=i(Hs),Sne=n(Hs,"P",{});var Aot=s(Sne);Fto=r(Aot,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Aot.forEach(t),Tto=i(Hs),ka=n(Hs,"P",{});var x0=s(ka);Mto=r(x0,"The tokenizer class to instantiate is selected based on the "),Rne=n(x0,"CODE",{});var Lot=s(Rne);Eto=r(Lot,"model_type"),Lot.forEach(t),Cto=r(x0,` property of the config object (either
passed as an argument or loaded from `),Pne=n(x0,"CODE",{});var yot=s(Pne);wto=r(yot,"pretrained_model_name_or_path"),yot.forEach(t),Ato=r(x0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=n(x0,"CODE",{});var xot=s(Bne);Lto=r(xot,"pretrained_model_name_or_path"),xot.forEach(t),yto=r(x0,":"),x0.forEach(t),xto=i(Hs),k=n(Hs,"UL",{});var S=s(k);qn=n(S,"LI",{});var W$=s(qn);Ine=n(W$,"STRONG",{});var $ot=s(Ine);$to=r($ot,"albert"),$ot.forEach(t),kto=r(W$," \u2014 "),_P=n(W$,"A",{href:!0});var kot=s(_P);Sto=r(kot,"AlbertTokenizer"),kot.forEach(t),Rto=r(W$," or "),uP=n(W$,"A",{href:!0});var Sot=s(uP);Pto=r(Sot,"AlbertTokenizerFast"),Sot.forEach(t),Bto=r(W$," (ALBERT model)"),W$.forEach(t),Ito=i(S),jn=n(S,"LI",{});var H$=s(jn);Nne=n(H$,"STRONG",{});var Rot=s(Nne);Nto=r(Rot,"bart"),Rot.forEach(t),qto=r(H$," \u2014 "),bP=n(H$,"A",{href:!0});var Pot=s(bP);jto=r(Pot,"BartTokenizer"),Pot.forEach(t),Dto=r(H$," or "),vP=n(H$,"A",{href:!0});var Bot=s(vP);Gto=r(Bot,"BartTokenizerFast"),Bot.forEach(t),Oto=r(H$," (BART model)"),H$.forEach(t),Vto=i(S),Dn=n(S,"LI",{});var U$=s(Dn);qne=n(U$,"STRONG",{});var Iot=s(qne);Xto=r(Iot,"barthez"),Iot.forEach(t),zto=r(U$," \u2014 "),FP=n(U$,"A",{href:!0});var Not=s(FP);Qto=r(Not,"BarthezTokenizer"),Not.forEach(t),Wto=r(U$," or "),TP=n(U$,"A",{href:!0});var qot=s(TP);Hto=r(qot,"BarthezTokenizerFast"),qot.forEach(t),Uto=r(U$," (BARThez model)"),U$.forEach(t),Jto=i(S),Xg=n(S,"LI",{});var MAe=s(Xg);jne=n(MAe,"STRONG",{});var jot=s(jne);Yto=r(jot,"bartpho"),jot.forEach(t),Kto=r(MAe," \u2014 "),MP=n(MAe,"A",{href:!0});var Dot=s(MP);Zto=r(Dot,"BartphoTokenizer"),Dot.forEach(t),eao=r(MAe," (BARTpho model)"),MAe.forEach(t),oao=i(S),Gn=n(S,"LI",{});var J$=s(Gn);Dne=n(J$,"STRONG",{});var Got=s(Dne);rao=r(Got,"bert"),Got.forEach(t),tao=r(J$," \u2014 "),EP=n(J$,"A",{href:!0});var Oot=s(EP);aao=r(Oot,"BertTokenizer"),Oot.forEach(t),nao=r(J$," or "),CP=n(J$,"A",{href:!0});var Vot=s(CP);sao=r(Vot,"BertTokenizerFast"),Vot.forEach(t),lao=r(J$," (BERT model)"),J$.forEach(t),iao=i(S),zg=n(S,"LI",{});var EAe=s(zg);Gne=n(EAe,"STRONG",{});var Xot=s(Gne);dao=r(Xot,"bert-generation"),Xot.forEach(t),cao=r(EAe," \u2014 "),wP=n(EAe,"A",{href:!0});var zot=s(wP);fao=r(zot,"BertGenerationTokenizer"),zot.forEach(t),mao=r(EAe," (Bert Generation model)"),EAe.forEach(t),gao=i(S),Qg=n(S,"LI",{});var CAe=s(Qg);One=n(CAe,"STRONG",{});var Qot=s(One);hao=r(Qot,"bert-japanese"),Qot.forEach(t),pao=r(CAe," \u2014 "),AP=n(CAe,"A",{href:!0});var Wot=s(AP);_ao=r(Wot,"BertJapaneseTokenizer"),Wot.forEach(t),uao=r(CAe," (BertJapanese model)"),CAe.forEach(t),bao=i(S),Wg=n(S,"LI",{});var wAe=s(Wg);Vne=n(wAe,"STRONG",{});var Hot=s(Vne);vao=r(Hot,"bertweet"),Hot.forEach(t),Fao=r(wAe," \u2014 "),LP=n(wAe,"A",{href:!0});var Uot=s(LP);Tao=r(Uot,"BertweetTokenizer"),Uot.forEach(t),Mao=r(wAe," (BERTweet model)"),wAe.forEach(t),Eao=i(S),On=n(S,"LI",{});var Y$=s(On);Xne=n(Y$,"STRONG",{});var Jot=s(Xne);Cao=r(Jot,"big_bird"),Jot.forEach(t),wao=r(Y$," \u2014 "),yP=n(Y$,"A",{href:!0});var Yot=s(yP);Aao=r(Yot,"BigBirdTokenizer"),Yot.forEach(t),Lao=r(Y$," or "),xP=n(Y$,"A",{href:!0});var Kot=s(xP);yao=r(Kot,"BigBirdTokenizerFast"),Kot.forEach(t),xao=r(Y$," (BigBird model)"),Y$.forEach(t),$ao=i(S),Vn=n(S,"LI",{});var K$=s(Vn);zne=n(K$,"STRONG",{});var Zot=s(zne);kao=r(Zot,"bigbird_pegasus"),Zot.forEach(t),Sao=r(K$," \u2014 "),$P=n(K$,"A",{href:!0});var ert=s($P);Rao=r(ert,"PegasusTokenizer"),ert.forEach(t),Pao=r(K$," or "),kP=n(K$,"A",{href:!0});var ort=s(kP);Bao=r(ort,"PegasusTokenizerFast"),ort.forEach(t),Iao=r(K$," (BigBird-Pegasus model)"),K$.forEach(t),Nao=i(S),Xn=n(S,"LI",{});var Z$=s(Xn);Qne=n(Z$,"STRONG",{});var rrt=s(Qne);qao=r(rrt,"blenderbot"),rrt.forEach(t),jao=r(Z$," \u2014 "),SP=n(Z$,"A",{href:!0});var trt=s(SP);Dao=r(trt,"BlenderbotTokenizer"),trt.forEach(t),Gao=r(Z$," or "),RP=n(Z$,"A",{href:!0});var art=s(RP);Oao=r(art,"BlenderbotTokenizerFast"),art.forEach(t),Vao=r(Z$," (Blenderbot model)"),Z$.forEach(t),Xao=i(S),Hg=n(S,"LI",{});var AAe=s(Hg);Wne=n(AAe,"STRONG",{});var nrt=s(Wne);zao=r(nrt,"blenderbot-small"),nrt.forEach(t),Qao=r(AAe," \u2014 "),PP=n(AAe,"A",{href:!0});var srt=s(PP);Wao=r(srt,"BlenderbotSmallTokenizer"),srt.forEach(t),Hao=r(AAe," (BlenderbotSmall model)"),AAe.forEach(t),Uao=i(S),Ug=n(S,"LI",{});var LAe=s(Ug);Hne=n(LAe,"STRONG",{});var lrt=s(Hne);Jao=r(lrt,"bloom"),lrt.forEach(t),Yao=r(LAe," \u2014 "),BP=n(LAe,"A",{href:!0});var irt=s(BP);Kao=r(irt,"BloomTokenizerFast"),irt.forEach(t),Zao=r(LAe," (BLOOM model)"),LAe.forEach(t),eno=i(S),Jg=n(S,"LI",{});var yAe=s(Jg);Une=n(yAe,"STRONG",{});var drt=s(Une);ono=r(drt,"byt5"),drt.forEach(t),rno=r(yAe," \u2014 "),IP=n(yAe,"A",{href:!0});var crt=s(IP);tno=r(crt,"ByT5Tokenizer"),crt.forEach(t),ano=r(yAe," (ByT5 model)"),yAe.forEach(t),nno=i(S),zn=n(S,"LI",{});var ek=s(zn);Jne=n(ek,"STRONG",{});var frt=s(Jne);sno=r(frt,"camembert"),frt.forEach(t),lno=r(ek," \u2014 "),NP=n(ek,"A",{href:!0});var mrt=s(NP);ino=r(mrt,"CamembertTokenizer"),mrt.forEach(t),dno=r(ek," or "),qP=n(ek,"A",{href:!0});var grt=s(qP);cno=r(grt,"CamembertTokenizerFast"),grt.forEach(t),fno=r(ek," (CamemBERT model)"),ek.forEach(t),mno=i(S),Yg=n(S,"LI",{});var xAe=s(Yg);Yne=n(xAe,"STRONG",{});var hrt=s(Yne);gno=r(hrt,"canine"),hrt.forEach(t),hno=r(xAe," \u2014 "),jP=n(xAe,"A",{href:!0});var prt=s(jP);pno=r(prt,"CanineTokenizer"),prt.forEach(t),_no=r(xAe," (CANINE model)"),xAe.forEach(t),uno=i(S),Qn=n(S,"LI",{});var ok=s(Qn);Kne=n(ok,"STRONG",{});var _rt=s(Kne);bno=r(_rt,"clip"),_rt.forEach(t),vno=r(ok," \u2014 "),DP=n(ok,"A",{href:!0});var urt=s(DP);Fno=r(urt,"CLIPTokenizer"),urt.forEach(t),Tno=r(ok," or "),GP=n(ok,"A",{href:!0});var brt=s(GP);Mno=r(brt,"CLIPTokenizerFast"),brt.forEach(t),Eno=r(ok," (CLIP model)"),ok.forEach(t),Cno=i(S),Wn=n(S,"LI",{});var rk=s(Wn);Zne=n(rk,"STRONG",{});var vrt=s(Zne);wno=r(vrt,"convbert"),vrt.forEach(t),Ano=r(rk," \u2014 "),OP=n(rk,"A",{href:!0});var Frt=s(OP);Lno=r(Frt,"ConvBertTokenizer"),Frt.forEach(t),yno=r(rk," or "),VP=n(rk,"A",{href:!0});var Trt=s(VP);xno=r(Trt,"ConvBertTokenizerFast"),Trt.forEach(t),$no=r(rk," (ConvBERT model)"),rk.forEach(t),kno=i(S),Hn=n(S,"LI",{});var tk=s(Hn);ese=n(tk,"STRONG",{});var Mrt=s(ese);Sno=r(Mrt,"cpm"),Mrt.forEach(t),Rno=r(tk," \u2014 "),XP=n(tk,"A",{href:!0});var Ert=s(XP);Pno=r(Ert,"CpmTokenizer"),Ert.forEach(t),Bno=r(tk," or "),zP=n(tk,"A",{href:!0});var Crt=s(zP);Ino=r(Crt,"CpmTokenizerFast"),Crt.forEach(t),Nno=r(tk," (CPM model)"),tk.forEach(t),qno=i(S),Kg=n(S,"LI",{});var $Ae=s(Kg);ose=n($Ae,"STRONG",{});var wrt=s(ose);jno=r(wrt,"ctrl"),wrt.forEach(t),Dno=r($Ae," \u2014 "),QP=n($Ae,"A",{href:!0});var Art=s(QP);Gno=r(Art,"CTRLTokenizer"),Art.forEach(t),Ono=r($Ae," (CTRL model)"),$Ae.forEach(t),Vno=i(S),Un=n(S,"LI",{});var ak=s(Un);rse=n(ak,"STRONG",{});var Lrt=s(rse);Xno=r(Lrt,"data2vec-text"),Lrt.forEach(t),zno=r(ak," \u2014 "),WP=n(ak,"A",{href:!0});var yrt=s(WP);Qno=r(yrt,"RobertaTokenizer"),yrt.forEach(t),Wno=r(ak," or "),HP=n(ak,"A",{href:!0});var xrt=s(HP);Hno=r(xrt,"RobertaTokenizerFast"),xrt.forEach(t),Uno=r(ak," (Data2VecText model)"),ak.forEach(t),Jno=i(S),Jn=n(S,"LI",{});var nk=s(Jn);tse=n(nk,"STRONG",{});var $rt=s(tse);Yno=r($rt,"deberta"),$rt.forEach(t),Kno=r(nk," \u2014 "),UP=n(nk,"A",{href:!0});var krt=s(UP);Zno=r(krt,"DebertaTokenizer"),krt.forEach(t),eso=r(nk," or "),JP=n(nk,"A",{href:!0});var Srt=s(JP);oso=r(Srt,"DebertaTokenizerFast"),Srt.forEach(t),rso=r(nk," (DeBERTa model)"),nk.forEach(t),tso=i(S),Yn=n(S,"LI",{});var sk=s(Yn);ase=n(sk,"STRONG",{});var Rrt=s(ase);aso=r(Rrt,"deberta-v2"),Rrt.forEach(t),nso=r(sk," \u2014 "),YP=n(sk,"A",{href:!0});var Prt=s(YP);sso=r(Prt,"DebertaV2Tokenizer"),Prt.forEach(t),lso=r(sk," or "),KP=n(sk,"A",{href:!0});var Brt=s(KP);iso=r(Brt,"DebertaV2TokenizerFast"),Brt.forEach(t),dso=r(sk," (DeBERTa-v2 model)"),sk.forEach(t),cso=i(S),Kn=n(S,"LI",{});var lk=s(Kn);nse=n(lk,"STRONG",{});var Irt=s(nse);fso=r(Irt,"distilbert"),Irt.forEach(t),mso=r(lk," \u2014 "),ZP=n(lk,"A",{href:!0});var Nrt=s(ZP);gso=r(Nrt,"DistilBertTokenizer"),Nrt.forEach(t),hso=r(lk," or "),eB=n(lk,"A",{href:!0});var qrt=s(eB);pso=r(qrt,"DistilBertTokenizerFast"),qrt.forEach(t),_so=r(lk," (DistilBERT model)"),lk.forEach(t),uso=i(S),Zn=n(S,"LI",{});var ik=s(Zn);sse=n(ik,"STRONG",{});var jrt=s(sse);bso=r(jrt,"dpr"),jrt.forEach(t),vso=r(ik," \u2014 "),oB=n(ik,"A",{href:!0});var Drt=s(oB);Fso=r(Drt,"DPRQuestionEncoderTokenizer"),Drt.forEach(t),Tso=r(ik," or "),rB=n(ik,"A",{href:!0});var Grt=s(rB);Mso=r(Grt,"DPRQuestionEncoderTokenizerFast"),Grt.forEach(t),Eso=r(ik," (DPR model)"),ik.forEach(t),Cso=i(S),es=n(S,"LI",{});var dk=s(es);lse=n(dk,"STRONG",{});var Ort=s(lse);wso=r(Ort,"electra"),Ort.forEach(t),Aso=r(dk," \u2014 "),tB=n(dk,"A",{href:!0});var Vrt=s(tB);Lso=r(Vrt,"ElectraTokenizer"),Vrt.forEach(t),yso=r(dk," or "),aB=n(dk,"A",{href:!0});var Xrt=s(aB);xso=r(Xrt,"ElectraTokenizerFast"),Xrt.forEach(t),$so=r(dk," (ELECTRA model)"),dk.forEach(t),kso=i(S),Zg=n(S,"LI",{});var kAe=s(Zg);ise=n(kAe,"STRONG",{});var zrt=s(ise);Sso=r(zrt,"flaubert"),zrt.forEach(t),Rso=r(kAe," \u2014 "),nB=n(kAe,"A",{href:!0});var Qrt=s(nB);Pso=r(Qrt,"FlaubertTokenizer"),Qrt.forEach(t),Bso=r(kAe," (FlauBERT model)"),kAe.forEach(t),Iso=i(S),os=n(S,"LI",{});var ck=s(os);dse=n(ck,"STRONG",{});var Wrt=s(dse);Nso=r(Wrt,"fnet"),Wrt.forEach(t),qso=r(ck," \u2014 "),sB=n(ck,"A",{href:!0});var Hrt=s(sB);jso=r(Hrt,"FNetTokenizer"),Hrt.forEach(t),Dso=r(ck," or "),lB=n(ck,"A",{href:!0});var Urt=s(lB);Gso=r(Urt,"FNetTokenizerFast"),Urt.forEach(t),Oso=r(ck," (FNet model)"),ck.forEach(t),Vso=i(S),eh=n(S,"LI",{});var SAe=s(eh);cse=n(SAe,"STRONG",{});var Jrt=s(cse);Xso=r(Jrt,"fsmt"),Jrt.forEach(t),zso=r(SAe," \u2014 "),iB=n(SAe,"A",{href:!0});var Yrt=s(iB);Qso=r(Yrt,"FSMTTokenizer"),Yrt.forEach(t),Wso=r(SAe," (FairSeq Machine-Translation model)"),SAe.forEach(t),Hso=i(S),rs=n(S,"LI",{});var fk=s(rs);fse=n(fk,"STRONG",{});var Krt=s(fse);Uso=r(Krt,"funnel"),Krt.forEach(t),Jso=r(fk," \u2014 "),dB=n(fk,"A",{href:!0});var Zrt=s(dB);Yso=r(Zrt,"FunnelTokenizer"),Zrt.forEach(t),Kso=r(fk," or "),cB=n(fk,"A",{href:!0});var ett=s(cB);Zso=r(ett,"FunnelTokenizerFast"),ett.forEach(t),elo=r(fk," (Funnel Transformer model)"),fk.forEach(t),olo=i(S),ts=n(S,"LI",{});var mk=s(ts);mse=n(mk,"STRONG",{});var ott=s(mse);rlo=r(ott,"gpt2"),ott.forEach(t),tlo=r(mk," \u2014 "),fB=n(mk,"A",{href:!0});var rtt=s(fB);alo=r(rtt,"GPT2Tokenizer"),rtt.forEach(t),nlo=r(mk," or "),mB=n(mk,"A",{href:!0});var ttt=s(mB);slo=r(ttt,"GPT2TokenizerFast"),ttt.forEach(t),llo=r(mk," (OpenAI GPT-2 model)"),mk.forEach(t),ilo=i(S),as=n(S,"LI",{});var gk=s(as);gse=n(gk,"STRONG",{});var att=s(gse);dlo=r(att,"gpt_neo"),att.forEach(t),clo=r(gk," \u2014 "),gB=n(gk,"A",{href:!0});var ntt=s(gB);flo=r(ntt,"GPT2Tokenizer"),ntt.forEach(t),mlo=r(gk," or "),hB=n(gk,"A",{href:!0});var stt=s(hB);glo=r(stt,"GPT2TokenizerFast"),stt.forEach(t),hlo=r(gk," (GPT Neo model)"),gk.forEach(t),plo=i(S),oh=n(S,"LI",{});var RAe=s(oh);hse=n(RAe,"STRONG",{});var ltt=s(hse);_lo=r(ltt,"gpt_neox"),ltt.forEach(t),ulo=r(RAe," \u2014 "),pB=n(RAe,"A",{href:!0});var itt=s(pB);blo=r(itt,"GPTNeoXTokenizerFast"),itt.forEach(t),vlo=r(RAe," (GPT NeoX model)"),RAe.forEach(t),Flo=i(S),ns=n(S,"LI",{});var hk=s(ns);pse=n(hk,"STRONG",{});var dtt=s(pse);Tlo=r(dtt,"gptj"),dtt.forEach(t),Mlo=r(hk," \u2014 "),_B=n(hk,"A",{href:!0});var ctt=s(_B);Elo=r(ctt,"GPT2Tokenizer"),ctt.forEach(t),Clo=r(hk," or "),uB=n(hk,"A",{href:!0});var ftt=s(uB);wlo=r(ftt,"GPT2TokenizerFast"),ftt.forEach(t),Alo=r(hk," (GPT-J model)"),hk.forEach(t),Llo=i(S),ss=n(S,"LI",{});var pk=s(ss);_se=n(pk,"STRONG",{});var mtt=s(_se);ylo=r(mtt,"herbert"),mtt.forEach(t),xlo=r(pk," \u2014 "),bB=n(pk,"A",{href:!0});var gtt=s(bB);$lo=r(gtt,"HerbertTokenizer"),gtt.forEach(t),klo=r(pk," or "),vB=n(pk,"A",{href:!0});var htt=s(vB);Slo=r(htt,"HerbertTokenizerFast"),htt.forEach(t),Rlo=r(pk," (HerBERT model)"),pk.forEach(t),Plo=i(S),rh=n(S,"LI",{});var PAe=s(rh);use=n(PAe,"STRONG",{});var ptt=s(use);Blo=r(ptt,"hubert"),ptt.forEach(t),Ilo=r(PAe," \u2014 "),FB=n(PAe,"A",{href:!0});var _tt=s(FB);Nlo=r(_tt,"Wav2Vec2CTCTokenizer"),_tt.forEach(t),qlo=r(PAe," (Hubert model)"),PAe.forEach(t),jlo=i(S),ls=n(S,"LI",{});var _k=s(ls);bse=n(_k,"STRONG",{});var utt=s(bse);Dlo=r(utt,"ibert"),utt.forEach(t),Glo=r(_k," \u2014 "),TB=n(_k,"A",{href:!0});var btt=s(TB);Olo=r(btt,"RobertaTokenizer"),btt.forEach(t),Vlo=r(_k," or "),MB=n(_k,"A",{href:!0});var vtt=s(MB);Xlo=r(vtt,"RobertaTokenizerFast"),vtt.forEach(t),zlo=r(_k," (I-BERT model)"),_k.forEach(t),Qlo=i(S),is=n(S,"LI",{});var uk=s(is);vse=n(uk,"STRONG",{});var Ftt=s(vse);Wlo=r(Ftt,"layoutlm"),Ftt.forEach(t),Hlo=r(uk," \u2014 "),EB=n(uk,"A",{href:!0});var Ttt=s(EB);Ulo=r(Ttt,"LayoutLMTokenizer"),Ttt.forEach(t),Jlo=r(uk," or "),CB=n(uk,"A",{href:!0});var Mtt=s(CB);Ylo=r(Mtt,"LayoutLMTokenizerFast"),Mtt.forEach(t),Klo=r(uk," (LayoutLM model)"),uk.forEach(t),Zlo=i(S),ds=n(S,"LI",{});var bk=s(ds);Fse=n(bk,"STRONG",{});var Ett=s(Fse);eio=r(Ett,"layoutlmv2"),Ett.forEach(t),oio=r(bk," \u2014 "),wB=n(bk,"A",{href:!0});var Ctt=s(wB);rio=r(Ctt,"LayoutLMv2Tokenizer"),Ctt.forEach(t),tio=r(bk," or "),AB=n(bk,"A",{href:!0});var wtt=s(AB);aio=r(wtt,"LayoutLMv2TokenizerFast"),wtt.forEach(t),nio=r(bk," (LayoutLMv2 model)"),bk.forEach(t),sio=i(S),cs=n(S,"LI",{});var vk=s(cs);Tse=n(vk,"STRONG",{});var Att=s(Tse);lio=r(Att,"layoutlmv3"),Att.forEach(t),iio=r(vk," \u2014 "),LB=n(vk,"A",{href:!0});var Ltt=s(LB);dio=r(Ltt,"LayoutLMv3Tokenizer"),Ltt.forEach(t),cio=r(vk," or "),yB=n(vk,"A",{href:!0});var ytt=s(yB);fio=r(ytt,"LayoutLMv3TokenizerFast"),ytt.forEach(t),mio=r(vk," (LayoutLMv3 model)"),vk.forEach(t),gio=i(S),fs=n(S,"LI",{});var Fk=s(fs);Mse=n(Fk,"STRONG",{});var xtt=s(Mse);hio=r(xtt,"layoutxlm"),xtt.forEach(t),pio=r(Fk," \u2014 "),xB=n(Fk,"A",{href:!0});var $tt=s(xB);_io=r($tt,"LayoutXLMTokenizer"),$tt.forEach(t),uio=r(Fk," or "),$B=n(Fk,"A",{href:!0});var ktt=s($B);bio=r(ktt,"LayoutXLMTokenizerFast"),ktt.forEach(t),vio=r(Fk," (LayoutXLM model)"),Fk.forEach(t),Fio=i(S),ms=n(S,"LI",{});var Tk=s(ms);Ese=n(Tk,"STRONG",{});var Stt=s(Ese);Tio=r(Stt,"led"),Stt.forEach(t),Mio=r(Tk," \u2014 "),kB=n(Tk,"A",{href:!0});var Rtt=s(kB);Eio=r(Rtt,"LEDTokenizer"),Rtt.forEach(t),Cio=r(Tk," or "),SB=n(Tk,"A",{href:!0});var Ptt=s(SB);wio=r(Ptt,"LEDTokenizerFast"),Ptt.forEach(t),Aio=r(Tk," (LED model)"),Tk.forEach(t),Lio=i(S),gs=n(S,"LI",{});var Mk=s(gs);Cse=n(Mk,"STRONG",{});var Btt=s(Cse);yio=r(Btt,"longformer"),Btt.forEach(t),xio=r(Mk," \u2014 "),RB=n(Mk,"A",{href:!0});var Itt=s(RB);$io=r(Itt,"LongformerTokenizer"),Itt.forEach(t),kio=r(Mk," or "),PB=n(Mk,"A",{href:!0});var Ntt=s(PB);Sio=r(Ntt,"LongformerTokenizerFast"),Ntt.forEach(t),Rio=r(Mk," (Longformer model)"),Mk.forEach(t),Pio=i(S),hs=n(S,"LI",{});var Ek=s(hs);wse=n(Ek,"STRONG",{});var qtt=s(wse);Bio=r(qtt,"longt5"),qtt.forEach(t),Iio=r(Ek," \u2014 "),BB=n(Ek,"A",{href:!0});var jtt=s(BB);Nio=r(jtt,"T5Tokenizer"),jtt.forEach(t),qio=r(Ek," or "),IB=n(Ek,"A",{href:!0});var Dtt=s(IB);jio=r(Dtt,"T5TokenizerFast"),Dtt.forEach(t),Dio=r(Ek," (LongT5 model)"),Ek.forEach(t),Gio=i(S),th=n(S,"LI",{});var BAe=s(th);Ase=n(BAe,"STRONG",{});var Gtt=s(Ase);Oio=r(Gtt,"luke"),Gtt.forEach(t),Vio=r(BAe," \u2014 "),NB=n(BAe,"A",{href:!0});var Ott=s(NB);Xio=r(Ott,"LukeTokenizer"),Ott.forEach(t),zio=r(BAe," (LUKE model)"),BAe.forEach(t),Qio=i(S),ps=n(S,"LI",{});var Ck=s(ps);Lse=n(Ck,"STRONG",{});var Vtt=s(Lse);Wio=r(Vtt,"lxmert"),Vtt.forEach(t),Hio=r(Ck," \u2014 "),qB=n(Ck,"A",{href:!0});var Xtt=s(qB);Uio=r(Xtt,"LxmertTokenizer"),Xtt.forEach(t),Jio=r(Ck," or "),jB=n(Ck,"A",{href:!0});var ztt=s(jB);Yio=r(ztt,"LxmertTokenizerFast"),ztt.forEach(t),Kio=r(Ck," (LXMERT model)"),Ck.forEach(t),Zio=i(S),ah=n(S,"LI",{});var IAe=s(ah);yse=n(IAe,"STRONG",{});var Qtt=s(yse);edo=r(Qtt,"m2m_100"),Qtt.forEach(t),odo=r(IAe," \u2014 "),DB=n(IAe,"A",{href:!0});var Wtt=s(DB);rdo=r(Wtt,"M2M100Tokenizer"),Wtt.forEach(t),tdo=r(IAe," (M2M100 model)"),IAe.forEach(t),ado=i(S),nh=n(S,"LI",{});var NAe=s(nh);xse=n(NAe,"STRONG",{});var Htt=s(xse);ndo=r(Htt,"marian"),Htt.forEach(t),sdo=r(NAe," \u2014 "),GB=n(NAe,"A",{href:!0});var Utt=s(GB);ldo=r(Utt,"MarianTokenizer"),Utt.forEach(t),ido=r(NAe," (Marian model)"),NAe.forEach(t),ddo=i(S),_s=n(S,"LI",{});var wk=s(_s);$se=n(wk,"STRONG",{});var Jtt=s($se);cdo=r(Jtt,"mbart"),Jtt.forEach(t),fdo=r(wk," \u2014 "),OB=n(wk,"A",{href:!0});var Ytt=s(OB);mdo=r(Ytt,"MBartTokenizer"),Ytt.forEach(t),gdo=r(wk," or "),VB=n(wk,"A",{href:!0});var Ktt=s(VB);hdo=r(Ktt,"MBartTokenizerFast"),Ktt.forEach(t),pdo=r(wk," (mBART model)"),wk.forEach(t),_do=i(S),us=n(S,"LI",{});var Ak=s(us);kse=n(Ak,"STRONG",{});var Ztt=s(kse);udo=r(Ztt,"mbart50"),Ztt.forEach(t),bdo=r(Ak," \u2014 "),XB=n(Ak,"A",{href:!0});var eat=s(XB);vdo=r(eat,"MBart50Tokenizer"),eat.forEach(t),Fdo=r(Ak," or "),zB=n(Ak,"A",{href:!0});var oat=s(zB);Tdo=r(oat,"MBart50TokenizerFast"),oat.forEach(t),Mdo=r(Ak," (mBART-50 model)"),Ak.forEach(t),Edo=i(S),bs=n(S,"LI",{});var Lk=s(bs);Sse=n(Lk,"STRONG",{});var rat=s(Sse);Cdo=r(rat,"megatron-bert"),rat.forEach(t),wdo=r(Lk," \u2014 "),QB=n(Lk,"A",{href:!0});var tat=s(QB);Ado=r(tat,"BertTokenizer"),tat.forEach(t),Ldo=r(Lk," or "),WB=n(Lk,"A",{href:!0});var aat=s(WB);ydo=r(aat,"BertTokenizerFast"),aat.forEach(t),xdo=r(Lk," (Megatron-BERT model)"),Lk.forEach(t),$do=i(S),sh=n(S,"LI",{});var qAe=s(sh);Rse=n(qAe,"STRONG",{});var nat=s(Rse);kdo=r(nat,"mluke"),nat.forEach(t),Sdo=r(qAe," \u2014 "),HB=n(qAe,"A",{href:!0});var sat=s(HB);Rdo=r(sat,"MLukeTokenizer"),sat.forEach(t),Pdo=r(qAe," (mLUKE model)"),qAe.forEach(t),Bdo=i(S),vs=n(S,"LI",{});var yk=s(vs);Pse=n(yk,"STRONG",{});var lat=s(Pse);Ido=r(lat,"mobilebert"),lat.forEach(t),Ndo=r(yk," \u2014 "),UB=n(yk,"A",{href:!0});var iat=s(UB);qdo=r(iat,"MobileBertTokenizer"),iat.forEach(t),jdo=r(yk," or "),JB=n(yk,"A",{href:!0});var dat=s(JB);Ddo=r(dat,"MobileBertTokenizerFast"),dat.forEach(t),Gdo=r(yk," (MobileBERT model)"),yk.forEach(t),Odo=i(S),Fs=n(S,"LI",{});var xk=s(Fs);Bse=n(xk,"STRONG",{});var cat=s(Bse);Vdo=r(cat,"mpnet"),cat.forEach(t),Xdo=r(xk," \u2014 "),YB=n(xk,"A",{href:!0});var fat=s(YB);zdo=r(fat,"MPNetTokenizer"),fat.forEach(t),Qdo=r(xk," or "),KB=n(xk,"A",{href:!0});var mat=s(KB);Wdo=r(mat,"MPNetTokenizerFast"),mat.forEach(t),Hdo=r(xk," (MPNet model)"),xk.forEach(t),Udo=i(S),Ts=n(S,"LI",{});var $k=s(Ts);Ise=n($k,"STRONG",{});var gat=s(Ise);Jdo=r(gat,"mt5"),gat.forEach(t),Ydo=r($k," \u2014 "),ZB=n($k,"A",{href:!0});var hat=s(ZB);Kdo=r(hat,"MT5Tokenizer"),hat.forEach(t),Zdo=r($k," or "),eI=n($k,"A",{href:!0});var pat=s(eI);eco=r(pat,"MT5TokenizerFast"),pat.forEach(t),oco=r($k," (MT5 model)"),$k.forEach(t),rco=i(S),Ms=n(S,"LI",{});var kk=s(Ms);Nse=n(kk,"STRONG",{});var _at=s(Nse);tco=r(_at,"nezha"),_at.forEach(t),aco=r(kk," \u2014 "),oI=n(kk,"A",{href:!0});var uat=s(oI);nco=r(uat,"BertTokenizer"),uat.forEach(t),sco=r(kk," or "),rI=n(kk,"A",{href:!0});var bat=s(rI);lco=r(bat,"BertTokenizerFast"),bat.forEach(t),ico=r(kk," (Nezha model)"),kk.forEach(t),dco=i(S),Es=n(S,"LI",{});var Sk=s(Es);qse=n(Sk,"STRONG",{});var vat=s(qse);cco=r(vat,"nystromformer"),vat.forEach(t),fco=r(Sk," \u2014 "),tI=n(Sk,"A",{href:!0});var Fat=s(tI);mco=r(Fat,"AlbertTokenizer"),Fat.forEach(t),gco=r(Sk," or "),aI=n(Sk,"A",{href:!0});var Tat=s(aI);hco=r(Tat,"AlbertTokenizerFast"),Tat.forEach(t),pco=r(Sk," (Nystr\xF6mformer model)"),Sk.forEach(t),_co=i(S),Cs=n(S,"LI",{});var Rk=s(Cs);jse=n(Rk,"STRONG",{});var Mat=s(jse);uco=r(Mat,"openai-gpt"),Mat.forEach(t),bco=r(Rk," \u2014 "),nI=n(Rk,"A",{href:!0});var Eat=s(nI);vco=r(Eat,"OpenAIGPTTokenizer"),Eat.forEach(t),Fco=r(Rk," or "),sI=n(Rk,"A",{href:!0});var Cat=s(sI);Tco=r(Cat,"OpenAIGPTTokenizerFast"),Cat.forEach(t),Mco=r(Rk," (OpenAI GPT model)"),Rk.forEach(t),Eco=i(S),lh=n(S,"LI",{});var jAe=s(lh);Dse=n(jAe,"STRONG",{});var wat=s(Dse);Cco=r(wat,"opt"),wat.forEach(t),wco=r(jAe," \u2014 "),lI=n(jAe,"A",{href:!0});var Aat=s(lI);Aco=r(Aat,"GPT2Tokenizer"),Aat.forEach(t),Lco=r(jAe," (OPT model)"),jAe.forEach(t),yco=i(S),ws=n(S,"LI",{});var Pk=s(ws);Gse=n(Pk,"STRONG",{});var Lat=s(Gse);xco=r(Lat,"pegasus"),Lat.forEach(t),$co=r(Pk," \u2014 "),iI=n(Pk,"A",{href:!0});var yat=s(iI);kco=r(yat,"PegasusTokenizer"),yat.forEach(t),Sco=r(Pk," or "),dI=n(Pk,"A",{href:!0});var xat=s(dI);Rco=r(xat,"PegasusTokenizerFast"),xat.forEach(t),Pco=r(Pk," (Pegasus model)"),Pk.forEach(t),Bco=i(S),ih=n(S,"LI",{});var DAe=s(ih);Ose=n(DAe,"STRONG",{});var $at=s(Ose);Ico=r($at,"perceiver"),$at.forEach(t),Nco=r(DAe," \u2014 "),cI=n(DAe,"A",{href:!0});var kat=s(cI);qco=r(kat,"PerceiverTokenizer"),kat.forEach(t),jco=r(DAe," (Perceiver model)"),DAe.forEach(t),Dco=i(S),dh=n(S,"LI",{});var GAe=s(dh);Vse=n(GAe,"STRONG",{});var Sat=s(Vse);Gco=r(Sat,"phobert"),Sat.forEach(t),Oco=r(GAe," \u2014 "),fI=n(GAe,"A",{href:!0});var Rat=s(fI);Vco=r(Rat,"PhobertTokenizer"),Rat.forEach(t),Xco=r(GAe," (PhoBERT model)"),GAe.forEach(t),zco=i(S),ch=n(S,"LI",{});var OAe=s(ch);Xse=n(OAe,"STRONG",{});var Pat=s(Xse);Qco=r(Pat,"plbart"),Pat.forEach(t),Wco=r(OAe," \u2014 "),mI=n(OAe,"A",{href:!0});var Bat=s(mI);Hco=r(Bat,"PLBartTokenizer"),Bat.forEach(t),Uco=r(OAe," (PLBart model)"),OAe.forEach(t),Jco=i(S),fh=n(S,"LI",{});var VAe=s(fh);zse=n(VAe,"STRONG",{});var Iat=s(zse);Yco=r(Iat,"prophetnet"),Iat.forEach(t),Kco=r(VAe," \u2014 "),gI=n(VAe,"A",{href:!0});var Nat=s(gI);Zco=r(Nat,"ProphetNetTokenizer"),Nat.forEach(t),efo=r(VAe," (ProphetNet model)"),VAe.forEach(t),ofo=i(S),As=n(S,"LI",{});var Bk=s(As);Qse=n(Bk,"STRONG",{});var qat=s(Qse);rfo=r(qat,"qdqbert"),qat.forEach(t),tfo=r(Bk," \u2014 "),hI=n(Bk,"A",{href:!0});var jat=s(hI);afo=r(jat,"BertTokenizer"),jat.forEach(t),nfo=r(Bk," or "),pI=n(Bk,"A",{href:!0});var Dat=s(pI);sfo=r(Dat,"BertTokenizerFast"),Dat.forEach(t),lfo=r(Bk," (QDQBert model)"),Bk.forEach(t),ifo=i(S),mh=n(S,"LI",{});var XAe=s(mh);Wse=n(XAe,"STRONG",{});var Gat=s(Wse);dfo=r(Gat,"rag"),Gat.forEach(t),cfo=r(XAe," \u2014 "),_I=n(XAe,"A",{href:!0});var Oat=s(_I);ffo=r(Oat,"RagTokenizer"),Oat.forEach(t),mfo=r(XAe," (RAG model)"),XAe.forEach(t),gfo=i(S),Ls=n(S,"LI",{});var Ik=s(Ls);Hse=n(Ik,"STRONG",{});var Vat=s(Hse);hfo=r(Vat,"realm"),Vat.forEach(t),pfo=r(Ik," \u2014 "),uI=n(Ik,"A",{href:!0});var Xat=s(uI);_fo=r(Xat,"RealmTokenizer"),Xat.forEach(t),ufo=r(Ik," or "),bI=n(Ik,"A",{href:!0});var zat=s(bI);bfo=r(zat,"RealmTokenizerFast"),zat.forEach(t),vfo=r(Ik," (REALM model)"),Ik.forEach(t),Ffo=i(S),ys=n(S,"LI",{});var Nk=s(ys);Use=n(Nk,"STRONG",{});var Qat=s(Use);Tfo=r(Qat,"reformer"),Qat.forEach(t),Mfo=r(Nk," \u2014 "),vI=n(Nk,"A",{href:!0});var Wat=s(vI);Efo=r(Wat,"ReformerTokenizer"),Wat.forEach(t),Cfo=r(Nk," or "),FI=n(Nk,"A",{href:!0});var Hat=s(FI);wfo=r(Hat,"ReformerTokenizerFast"),Hat.forEach(t),Afo=r(Nk," (Reformer model)"),Nk.forEach(t),Lfo=i(S),xs=n(S,"LI",{});var qk=s(xs);Jse=n(qk,"STRONG",{});var Uat=s(Jse);yfo=r(Uat,"rembert"),Uat.forEach(t),xfo=r(qk," \u2014 "),TI=n(qk,"A",{href:!0});var Jat=s(TI);$fo=r(Jat,"RemBertTokenizer"),Jat.forEach(t),kfo=r(qk," or "),MI=n(qk,"A",{href:!0});var Yat=s(MI);Sfo=r(Yat,"RemBertTokenizerFast"),Yat.forEach(t),Rfo=r(qk," (RemBERT model)"),qk.forEach(t),Pfo=i(S),$s=n(S,"LI",{});var jk=s($s);Yse=n(jk,"STRONG",{});var Kat=s(Yse);Bfo=r(Kat,"retribert"),Kat.forEach(t),Ifo=r(jk," \u2014 "),EI=n(jk,"A",{href:!0});var Zat=s(EI);Nfo=r(Zat,"RetriBertTokenizer"),Zat.forEach(t),qfo=r(jk," or "),CI=n(jk,"A",{href:!0});var ent=s(CI);jfo=r(ent,"RetriBertTokenizerFast"),ent.forEach(t),Dfo=r(jk," (RetriBERT model)"),jk.forEach(t),Gfo=i(S),ks=n(S,"LI",{});var Dk=s(ks);Kse=n(Dk,"STRONG",{});var ont=s(Kse);Ofo=r(ont,"roberta"),ont.forEach(t),Vfo=r(Dk," \u2014 "),wI=n(Dk,"A",{href:!0});var rnt=s(wI);Xfo=r(rnt,"RobertaTokenizer"),rnt.forEach(t),zfo=r(Dk," or "),AI=n(Dk,"A",{href:!0});var tnt=s(AI);Qfo=r(tnt,"RobertaTokenizerFast"),tnt.forEach(t),Wfo=r(Dk," (RoBERTa model)"),Dk.forEach(t),Hfo=i(S),Ss=n(S,"LI",{});var Gk=s(Ss);Zse=n(Gk,"STRONG",{});var ant=s(Zse);Ufo=r(ant,"roformer"),ant.forEach(t),Jfo=r(Gk," \u2014 "),LI=n(Gk,"A",{href:!0});var nnt=s(LI);Yfo=r(nnt,"RoFormerTokenizer"),nnt.forEach(t),Kfo=r(Gk," or "),yI=n(Gk,"A",{href:!0});var snt=s(yI);Zfo=r(snt,"RoFormerTokenizerFast"),snt.forEach(t),emo=r(Gk," (RoFormer model)"),Gk.forEach(t),omo=i(S),gh=n(S,"LI",{});var zAe=s(gh);ele=n(zAe,"STRONG",{});var lnt=s(ele);rmo=r(lnt,"speech_to_text"),lnt.forEach(t),tmo=r(zAe," \u2014 "),xI=n(zAe,"A",{href:!0});var int=s(xI);amo=r(int,"Speech2TextTokenizer"),int.forEach(t),nmo=r(zAe," (Speech2Text model)"),zAe.forEach(t),smo=i(S),hh=n(S,"LI",{});var QAe=s(hh);ole=n(QAe,"STRONG",{});var dnt=s(ole);lmo=r(dnt,"speech_to_text_2"),dnt.forEach(t),imo=r(QAe," \u2014 "),$I=n(QAe,"A",{href:!0});var cnt=s($I);dmo=r(cnt,"Speech2Text2Tokenizer"),cnt.forEach(t),cmo=r(QAe," (Speech2Text2 model)"),QAe.forEach(t),fmo=i(S),Rs=n(S,"LI",{});var Ok=s(Rs);rle=n(Ok,"STRONG",{});var fnt=s(rle);mmo=r(fnt,"splinter"),fnt.forEach(t),gmo=r(Ok," \u2014 "),kI=n(Ok,"A",{href:!0});var mnt=s(kI);hmo=r(mnt,"SplinterTokenizer"),mnt.forEach(t),pmo=r(Ok," or "),SI=n(Ok,"A",{href:!0});var gnt=s(SI);_mo=r(gnt,"SplinterTokenizerFast"),gnt.forEach(t),umo=r(Ok," (Splinter model)"),Ok.forEach(t),bmo=i(S),Ps=n(S,"LI",{});var Vk=s(Ps);tle=n(Vk,"STRONG",{});var hnt=s(tle);vmo=r(hnt,"squeezebert"),hnt.forEach(t),Fmo=r(Vk," \u2014 "),RI=n(Vk,"A",{href:!0});var pnt=s(RI);Tmo=r(pnt,"SqueezeBertTokenizer"),pnt.forEach(t),Mmo=r(Vk," or "),PI=n(Vk,"A",{href:!0});var _nt=s(PI);Emo=r(_nt,"SqueezeBertTokenizerFast"),_nt.forEach(t),Cmo=r(Vk," (SqueezeBERT model)"),Vk.forEach(t),wmo=i(S),Bs=n(S,"LI",{});var Xk=s(Bs);ale=n(Xk,"STRONG",{});var unt=s(ale);Amo=r(unt,"t5"),unt.forEach(t),Lmo=r(Xk," \u2014 "),BI=n(Xk,"A",{href:!0});var bnt=s(BI);ymo=r(bnt,"T5Tokenizer"),bnt.forEach(t),xmo=r(Xk," or "),II=n(Xk,"A",{href:!0});var vnt=s(II);$mo=r(vnt,"T5TokenizerFast"),vnt.forEach(t),kmo=r(Xk," (T5 model)"),Xk.forEach(t),Smo=i(S),ph=n(S,"LI",{});var WAe=s(ph);nle=n(WAe,"STRONG",{});var Fnt=s(nle);Rmo=r(Fnt,"tapas"),Fnt.forEach(t),Pmo=r(WAe," \u2014 "),NI=n(WAe,"A",{href:!0});var Tnt=s(NI);Bmo=r(Tnt,"TapasTokenizer"),Tnt.forEach(t),Imo=r(WAe," (TAPAS model)"),WAe.forEach(t),Nmo=i(S),_h=n(S,"LI",{});var HAe=s(_h);sle=n(HAe,"STRONG",{});var Mnt=s(sle);qmo=r(Mnt,"tapex"),Mnt.forEach(t),jmo=r(HAe," \u2014 "),qI=n(HAe,"A",{href:!0});var Ent=s(qI);Dmo=r(Ent,"TapexTokenizer"),Ent.forEach(t),Gmo=r(HAe," (TAPEX model)"),HAe.forEach(t),Omo=i(S),uh=n(S,"LI",{});var UAe=s(uh);lle=n(UAe,"STRONG",{});var Cnt=s(lle);Vmo=r(Cnt,"transfo-xl"),Cnt.forEach(t),Xmo=r(UAe," \u2014 "),jI=n(UAe,"A",{href:!0});var wnt=s(jI);zmo=r(wnt,"TransfoXLTokenizer"),wnt.forEach(t),Qmo=r(UAe," (Transformer-XL model)"),UAe.forEach(t),Wmo=i(S),Is=n(S,"LI",{});var zk=s(Is);ile=n(zk,"STRONG",{});var Ant=s(ile);Hmo=r(Ant,"vilt"),Ant.forEach(t),Umo=r(zk," \u2014 "),DI=n(zk,"A",{href:!0});var Lnt=s(DI);Jmo=r(Lnt,"BertTokenizer"),Lnt.forEach(t),Ymo=r(zk," or "),GI=n(zk,"A",{href:!0});var ynt=s(GI);Kmo=r(ynt,"BertTokenizerFast"),ynt.forEach(t),Zmo=r(zk," (ViLT model)"),zk.forEach(t),ego=i(S),Ns=n(S,"LI",{});var Qk=s(Ns);dle=n(Qk,"STRONG",{});var xnt=s(dle);ogo=r(xnt,"visual_bert"),xnt.forEach(t),rgo=r(Qk," \u2014 "),OI=n(Qk,"A",{href:!0});var $nt=s(OI);tgo=r($nt,"BertTokenizer"),$nt.forEach(t),ago=r(Qk," or "),VI=n(Qk,"A",{href:!0});var knt=s(VI);ngo=r(knt,"BertTokenizerFast"),knt.forEach(t),sgo=r(Qk," (VisualBERT model)"),Qk.forEach(t),lgo=i(S),bh=n(S,"LI",{});var JAe=s(bh);cle=n(JAe,"STRONG",{});var Snt=s(cle);igo=r(Snt,"wav2vec2"),Snt.forEach(t),dgo=r(JAe," \u2014 "),XI=n(JAe,"A",{href:!0});var Rnt=s(XI);cgo=r(Rnt,"Wav2Vec2CTCTokenizer"),Rnt.forEach(t),fgo=r(JAe," (Wav2Vec2 model)"),JAe.forEach(t),mgo=i(S),vh=n(S,"LI",{});var YAe=s(vh);fle=n(YAe,"STRONG",{});var Pnt=s(fle);ggo=r(Pnt,"wav2vec2-conformer"),Pnt.forEach(t),hgo=r(YAe," \u2014 "),zI=n(YAe,"A",{href:!0});var Bnt=s(zI);pgo=r(Bnt,"Wav2Vec2CTCTokenizer"),Bnt.forEach(t),_go=r(YAe," (Wav2Vec2-Conformer model)"),YAe.forEach(t),ugo=i(S),Fh=n(S,"LI",{});var KAe=s(Fh);mle=n(KAe,"STRONG",{});var Int=s(mle);bgo=r(Int,"wav2vec2_phoneme"),Int.forEach(t),vgo=r(KAe," \u2014 "),QI=n(KAe,"A",{href:!0});var Nnt=s(QI);Fgo=r(Nnt,"Wav2Vec2PhonemeCTCTokenizer"),Nnt.forEach(t),Tgo=r(KAe," (Wav2Vec2Phoneme model)"),KAe.forEach(t),Mgo=i(S),qs=n(S,"LI",{});var Wk=s(qs);gle=n(Wk,"STRONG",{});var qnt=s(gle);Ego=r(qnt,"xglm"),qnt.forEach(t),Cgo=r(Wk," \u2014 "),WI=n(Wk,"A",{href:!0});var jnt=s(WI);wgo=r(jnt,"XGLMTokenizer"),jnt.forEach(t),Ago=r(Wk," or "),HI=n(Wk,"A",{href:!0});var Dnt=s(HI);Lgo=r(Dnt,"XGLMTokenizerFast"),Dnt.forEach(t),ygo=r(Wk," (XGLM model)"),Wk.forEach(t),xgo=i(S),Th=n(S,"LI",{});var ZAe=s(Th);hle=n(ZAe,"STRONG",{});var Gnt=s(hle);$go=r(Gnt,"xlm"),Gnt.forEach(t),kgo=r(ZAe," \u2014 "),UI=n(ZAe,"A",{href:!0});var Ont=s(UI);Sgo=r(Ont,"XLMTokenizer"),Ont.forEach(t),Rgo=r(ZAe," (XLM model)"),ZAe.forEach(t),Pgo=i(S),Mh=n(S,"LI",{});var eLe=s(Mh);ple=n(eLe,"STRONG",{});var Vnt=s(ple);Bgo=r(Vnt,"xlm-prophetnet"),Vnt.forEach(t),Igo=r(eLe," \u2014 "),JI=n(eLe,"A",{href:!0});var Xnt=s(JI);Ngo=r(Xnt,"XLMProphetNetTokenizer"),Xnt.forEach(t),qgo=r(eLe," (XLM-ProphetNet model)"),eLe.forEach(t),jgo=i(S),js=n(S,"LI",{});var Hk=s(js);_le=n(Hk,"STRONG",{});var znt=s(_le);Dgo=r(znt,"xlm-roberta"),znt.forEach(t),Ggo=r(Hk," \u2014 "),YI=n(Hk,"A",{href:!0});var Qnt=s(YI);Ogo=r(Qnt,"XLMRobertaTokenizer"),Qnt.forEach(t),Vgo=r(Hk," or "),KI=n(Hk,"A",{href:!0});var Wnt=s(KI);Xgo=r(Wnt,"XLMRobertaTokenizerFast"),Wnt.forEach(t),zgo=r(Hk," (XLM-RoBERTa model)"),Hk.forEach(t),Qgo=i(S),Ds=n(S,"LI",{});var Uk=s(Ds);ule=n(Uk,"STRONG",{});var Hnt=s(ule);Wgo=r(Hnt,"xlm-roberta-xl"),Hnt.forEach(t),Hgo=r(Uk," \u2014 "),ZI=n(Uk,"A",{href:!0});var Unt=s(ZI);Ugo=r(Unt,"RobertaTokenizer"),Unt.forEach(t),Jgo=r(Uk," or "),eN=n(Uk,"A",{href:!0});var Jnt=s(eN);Ygo=r(Jnt,"RobertaTokenizerFast"),Jnt.forEach(t),Kgo=r(Uk," (XLM-RoBERTa-XL model)"),Uk.forEach(t),Zgo=i(S),Gs=n(S,"LI",{});var Jk=s(Gs);ble=n(Jk,"STRONG",{});var Ynt=s(ble);eho=r(Ynt,"xlnet"),Ynt.forEach(t),oho=r(Jk," \u2014 "),oN=n(Jk,"A",{href:!0});var Knt=s(oN);rho=r(Knt,"XLNetTokenizer"),Knt.forEach(t),tho=r(Jk," or "),rN=n(Jk,"A",{href:!0});var Znt=s(rN);aho=r(Znt,"XLNetTokenizerFast"),Znt.forEach(t),nho=r(Jk," (XLNet model)"),Jk.forEach(t),sho=i(S),Os=n(S,"LI",{});var Yk=s(Os);vle=n(Yk,"STRONG",{});var est=s(vle);lho=r(est,"yoso"),est.forEach(t),iho=r(Yk," \u2014 "),tN=n(Yk,"A",{href:!0});var ost=s(tN);dho=r(ost,"AlbertTokenizer"),ost.forEach(t),cho=r(Yk," or "),aN=n(Yk,"A",{href:!0});var rst=s(aN);fho=r(rst,"AlbertTokenizerFast"),rst.forEach(t),mho=r(Yk," (YOSO model)"),Yk.forEach(t),S.forEach(t),gho=i(Hs),T(Eh.$$.fragment,Hs),Hs.forEach(t),hho=i(Ws),Ch=n(Ws,"DIV",{class:!0});var UVe=s(Ch);T(OA.$$.fragment,UVe),pho=i(UVe),Fle=n(UVe,"P",{});var tst=s(Fle);_ho=r(tst,"Register a new tokenizer in this mapping."),tst.forEach(t),UVe.forEach(t),Ws.forEach(t),HGe=i(f),Si=n(f,"H2",{class:!0});var JVe=s(Si);wh=n(JVe,"A",{id:!0,class:!0,href:!0});var ast=s(wh);Tle=n(ast,"SPAN",{});var nst=s(Tle);T(VA.$$.fragment,nst),nst.forEach(t),ast.forEach(t),uho=i(JVe),Mle=n(JVe,"SPAN",{});var sst=s(Mle);bho=r(sst,"AutoFeatureExtractor"),sst.forEach(t),JVe.forEach(t),UGe=i(f),Lo=n(f,"DIV",{class:!0});var Us=s(Lo);T(XA.$$.fragment,Us),vho=i(Us),zA=n(Us,"P",{});var YVe=s(zA);Fho=r(YVe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=n(YVe,"A",{href:!0});var lst=s(nN);Tho=r(lst,"AutoFeatureExtractor.from_pretrained()"),lst.forEach(t),Mho=r(YVe," class method."),YVe.forEach(t),Eho=i(Us),QA=n(Us,"P",{});var KVe=s(QA);Cho=r(KVe,"This class cannot be instantiated directly using "),Ele=n(KVe,"CODE",{});var ist=s(Ele);who=r(ist,"__init__()"),ist.forEach(t),Aho=r(KVe," (throws an error)."),KVe.forEach(t),Lho=i(Us),He=n(Us,"DIV",{class:!0});var ra=s(He);T(WA.$$.fragment,ra),yho=i(ra),Cle=n(ra,"P",{});var dst=s(Cle);xho=r(dst,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),dst.forEach(t),$ho=i(ra),Sa=n(ra,"P",{});var $0=s(Sa);kho=r($0,"The feature extractor class to instantiate is selected based on the "),wle=n($0,"CODE",{});var cst=s(wle);Sho=r(cst,"model_type"),cst.forEach(t),Rho=r($0,` property of the config object
(either passed as an argument or loaded from `),Ale=n($0,"CODE",{});var fst=s(Ale);Pho=r(fst,"pretrained_model_name_or_path"),fst.forEach(t),Bho=r($0,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=n($0,"CODE",{});var mst=s(Lle);Iho=r(mst,"pretrained_model_name_or_path"),mst.forEach(t),Nho=r($0,":"),$0.forEach(t),qho=i(ra),Y=n(ra,"UL",{});var K=s(Y);Ah=n(K,"LI",{});var oLe=s(Ah);yle=n(oLe,"STRONG",{});var gst=s(yle);jho=r(gst,"beit"),gst.forEach(t),Dho=r(oLe," \u2014 "),sN=n(oLe,"A",{href:!0});var hst=s(sN);Gho=r(hst,"BeitFeatureExtractor"),hst.forEach(t),Oho=r(oLe," (BEiT model)"),oLe.forEach(t),Vho=i(K),Lh=n(K,"LI",{});var rLe=s(Lh);xle=n(rLe,"STRONG",{});var pst=s(xle);Xho=r(pst,"clip"),pst.forEach(t),zho=r(rLe," \u2014 "),lN=n(rLe,"A",{href:!0});var _st=s(lN);Qho=r(_st,"CLIPFeatureExtractor"),_st.forEach(t),Who=r(rLe," (CLIP model)"),rLe.forEach(t),Hho=i(K),yh=n(K,"LI",{});var tLe=s(yh);$le=n(tLe,"STRONG",{});var ust=s($le);Uho=r(ust,"convnext"),ust.forEach(t),Jho=r(tLe," \u2014 "),iN=n(tLe,"A",{href:!0});var bst=s(iN);Yho=r(bst,"ConvNextFeatureExtractor"),bst.forEach(t),Kho=r(tLe," (ConvNeXT model)"),tLe.forEach(t),Zho=i(K),xh=n(K,"LI",{});var aLe=s(xh);kle=n(aLe,"STRONG",{});var vst=s(kle);epo=r(vst,"cvt"),vst.forEach(t),opo=r(aLe," \u2014 "),dN=n(aLe,"A",{href:!0});var Fst=s(dN);rpo=r(Fst,"ConvNextFeatureExtractor"),Fst.forEach(t),tpo=r(aLe," (CvT model)"),aLe.forEach(t),apo=i(K),$h=n(K,"LI",{});var nLe=s($h);Sle=n(nLe,"STRONG",{});var Tst=s(Sle);npo=r(Tst,"data2vec-audio"),Tst.forEach(t),spo=r(nLe," \u2014 "),cN=n(nLe,"A",{href:!0});var Mst=s(cN);lpo=r(Mst,"Wav2Vec2FeatureExtractor"),Mst.forEach(t),ipo=r(nLe," (Data2VecAudio model)"),nLe.forEach(t),dpo=i(K),kh=n(K,"LI",{});var sLe=s(kh);Rle=n(sLe,"STRONG",{});var Est=s(Rle);cpo=r(Est,"data2vec-vision"),Est.forEach(t),fpo=r(sLe," \u2014 "),fN=n(sLe,"A",{href:!0});var Cst=s(fN);mpo=r(Cst,"BeitFeatureExtractor"),Cst.forEach(t),gpo=r(sLe," (Data2VecVision model)"),sLe.forEach(t),hpo=i(K),Sh=n(K,"LI",{});var lLe=s(Sh);Ple=n(lLe,"STRONG",{});var wst=s(Ple);ppo=r(wst,"deit"),wst.forEach(t),_po=r(lLe," \u2014 "),mN=n(lLe,"A",{href:!0});var Ast=s(mN);upo=r(Ast,"DeiTFeatureExtractor"),Ast.forEach(t),bpo=r(lLe," (DeiT model)"),lLe.forEach(t),vpo=i(K),Rh=n(K,"LI",{});var iLe=s(Rh);Ble=n(iLe,"STRONG",{});var Lst=s(Ble);Fpo=r(Lst,"detr"),Lst.forEach(t),Tpo=r(iLe," \u2014 "),gN=n(iLe,"A",{href:!0});var yst=s(gN);Mpo=r(yst,"DetrFeatureExtractor"),yst.forEach(t),Epo=r(iLe," (DETR model)"),iLe.forEach(t),Cpo=i(K),Ph=n(K,"LI",{});var dLe=s(Ph);Ile=n(dLe,"STRONG",{});var xst=s(Ile);wpo=r(xst,"dpt"),xst.forEach(t),Apo=r(dLe," \u2014 "),hN=n(dLe,"A",{href:!0});var $st=s(hN);Lpo=r($st,"DPTFeatureExtractor"),$st.forEach(t),ypo=r(dLe," (DPT model)"),dLe.forEach(t),xpo=i(K),Bh=n(K,"LI",{});var cLe=s(Bh);Nle=n(cLe,"STRONG",{});var kst=s(Nle);$po=r(kst,"flava"),kst.forEach(t),kpo=r(cLe," \u2014 "),pN=n(cLe,"A",{href:!0});var Sst=s(pN);Spo=r(Sst,"FlavaFeatureExtractor"),Sst.forEach(t),Rpo=r(cLe," (FLAVA model)"),cLe.forEach(t),Ppo=i(K),Ih=n(K,"LI",{});var fLe=s(Ih);qle=n(fLe,"STRONG",{});var Rst=s(qle);Bpo=r(Rst,"glpn"),Rst.forEach(t),Ipo=r(fLe," \u2014 "),_N=n(fLe,"A",{href:!0});var Pst=s(_N);Npo=r(Pst,"GLPNFeatureExtractor"),Pst.forEach(t),qpo=r(fLe," (GLPN model)"),fLe.forEach(t),jpo=i(K),Nh=n(K,"LI",{});var mLe=s(Nh);jle=n(mLe,"STRONG",{});var Bst=s(jle);Dpo=r(Bst,"hubert"),Bst.forEach(t),Gpo=r(mLe," \u2014 "),uN=n(mLe,"A",{href:!0});var Ist=s(uN);Opo=r(Ist,"Wav2Vec2FeatureExtractor"),Ist.forEach(t),Vpo=r(mLe," (Hubert model)"),mLe.forEach(t),Xpo=i(K),qh=n(K,"LI",{});var gLe=s(qh);Dle=n(gLe,"STRONG",{});var Nst=s(Dle);zpo=r(Nst,"imagegpt"),Nst.forEach(t),Qpo=r(gLe," \u2014 "),bN=n(gLe,"A",{href:!0});var qst=s(bN);Wpo=r(qst,"ImageGPTFeatureExtractor"),qst.forEach(t),Hpo=r(gLe," (ImageGPT model)"),gLe.forEach(t),Upo=i(K),jh=n(K,"LI",{});var hLe=s(jh);Gle=n(hLe,"STRONG",{});var jst=s(Gle);Jpo=r(jst,"layoutlmv2"),jst.forEach(t),Ypo=r(hLe," \u2014 "),vN=n(hLe,"A",{href:!0});var Dst=s(vN);Kpo=r(Dst,"LayoutLMv2FeatureExtractor"),Dst.forEach(t),Zpo=r(hLe," (LayoutLMv2 model)"),hLe.forEach(t),e_o=i(K),Dh=n(K,"LI",{});var pLe=s(Dh);Ole=n(pLe,"STRONG",{});var Gst=s(Ole);o_o=r(Gst,"layoutlmv3"),Gst.forEach(t),r_o=r(pLe," \u2014 "),FN=n(pLe,"A",{href:!0});var Ost=s(FN);t_o=r(Ost,"LayoutLMv3FeatureExtractor"),Ost.forEach(t),a_o=r(pLe," (LayoutLMv3 model)"),pLe.forEach(t),n_o=i(K),Gh=n(K,"LI",{});var _Le=s(Gh);Vle=n(_Le,"STRONG",{});var Vst=s(Vle);s_o=r(Vst,"levit"),Vst.forEach(t),l_o=r(_Le," \u2014 "),TN=n(_Le,"A",{href:!0});var Xst=s(TN);i_o=r(Xst,"LevitFeatureExtractor"),Xst.forEach(t),d_o=r(_Le," (LeViT model)"),_Le.forEach(t),c_o=i(K),Oh=n(K,"LI",{});var uLe=s(Oh);Xle=n(uLe,"STRONG",{});var zst=s(Xle);f_o=r(zst,"maskformer"),zst.forEach(t),m_o=r(uLe," \u2014 "),MN=n(uLe,"A",{href:!0});var Qst=s(MN);g_o=r(Qst,"MaskFormerFeatureExtractor"),Qst.forEach(t),h_o=r(uLe," (MaskFormer model)"),uLe.forEach(t),p_o=i(K),Vh=n(K,"LI",{});var bLe=s(Vh);zle=n(bLe,"STRONG",{});var Wst=s(zle);__o=r(Wst,"mctct"),Wst.forEach(t),u_o=r(bLe," \u2014 "),EN=n(bLe,"A",{href:!0});var Hst=s(EN);b_o=r(Hst,"MCTCTFeatureExtractor"),Hst.forEach(t),v_o=r(bLe," (M-CTC-T model)"),bLe.forEach(t),F_o=i(K),Xh=n(K,"LI",{});var vLe=s(Xh);Qle=n(vLe,"STRONG",{});var Ust=s(Qle);T_o=r(Ust,"perceiver"),Ust.forEach(t),M_o=r(vLe," \u2014 "),CN=n(vLe,"A",{href:!0});var Jst=s(CN);E_o=r(Jst,"PerceiverFeatureExtractor"),Jst.forEach(t),C_o=r(vLe," (Perceiver model)"),vLe.forEach(t),w_o=i(K),zh=n(K,"LI",{});var FLe=s(zh);Wle=n(FLe,"STRONG",{});var Yst=s(Wle);A_o=r(Yst,"poolformer"),Yst.forEach(t),L_o=r(FLe," \u2014 "),wN=n(FLe,"A",{href:!0});var Kst=s(wN);y_o=r(Kst,"PoolFormerFeatureExtractor"),Kst.forEach(t),x_o=r(FLe," (PoolFormer model)"),FLe.forEach(t),$_o=i(K),Qh=n(K,"LI",{});var TLe=s(Qh);Hle=n(TLe,"STRONG",{});var Zst=s(Hle);k_o=r(Zst,"regnet"),Zst.forEach(t),S_o=r(TLe," \u2014 "),AN=n(TLe,"A",{href:!0});var elt=s(AN);R_o=r(elt,"ConvNextFeatureExtractor"),elt.forEach(t),P_o=r(TLe," (RegNet model)"),TLe.forEach(t),B_o=i(K),Wh=n(K,"LI",{});var MLe=s(Wh);Ule=n(MLe,"STRONG",{});var olt=s(Ule);I_o=r(olt,"resnet"),olt.forEach(t),N_o=r(MLe," \u2014 "),LN=n(MLe,"A",{href:!0});var rlt=s(LN);q_o=r(rlt,"ConvNextFeatureExtractor"),rlt.forEach(t),j_o=r(MLe," (ResNet model)"),MLe.forEach(t),D_o=i(K),Hh=n(K,"LI",{});var ELe=s(Hh);Jle=n(ELe,"STRONG",{});var tlt=s(Jle);G_o=r(tlt,"segformer"),tlt.forEach(t),O_o=r(ELe," \u2014 "),yN=n(ELe,"A",{href:!0});var alt=s(yN);V_o=r(alt,"SegformerFeatureExtractor"),alt.forEach(t),X_o=r(ELe," (SegFormer model)"),ELe.forEach(t),z_o=i(K),Uh=n(K,"LI",{});var CLe=s(Uh);Yle=n(CLe,"STRONG",{});var nlt=s(Yle);Q_o=r(nlt,"speech_to_text"),nlt.forEach(t),W_o=r(CLe," \u2014 "),xN=n(CLe,"A",{href:!0});var slt=s(xN);H_o=r(slt,"Speech2TextFeatureExtractor"),slt.forEach(t),U_o=r(CLe," (Speech2Text model)"),CLe.forEach(t),J_o=i(K),Jh=n(K,"LI",{});var wLe=s(Jh);Kle=n(wLe,"STRONG",{});var llt=s(Kle);Y_o=r(llt,"swin"),llt.forEach(t),K_o=r(wLe," \u2014 "),$N=n(wLe,"A",{href:!0});var ilt=s($N);Z_o=r(ilt,"ViTFeatureExtractor"),ilt.forEach(t),euo=r(wLe," (Swin Transformer model)"),wLe.forEach(t),ouo=i(K),Yh=n(K,"LI",{});var ALe=s(Yh);Zle=n(ALe,"STRONG",{});var dlt=s(Zle);ruo=r(dlt,"van"),dlt.forEach(t),tuo=r(ALe," \u2014 "),kN=n(ALe,"A",{href:!0});var clt=s(kN);auo=r(clt,"ConvNextFeatureExtractor"),clt.forEach(t),nuo=r(ALe," (VAN model)"),ALe.forEach(t),suo=i(K),Kh=n(K,"LI",{});var LLe=s(Kh);eie=n(LLe,"STRONG",{});var flt=s(eie);luo=r(flt,"vilt"),flt.forEach(t),iuo=r(LLe," \u2014 "),SN=n(LLe,"A",{href:!0});var mlt=s(SN);duo=r(mlt,"ViltFeatureExtractor"),mlt.forEach(t),cuo=r(LLe," (ViLT model)"),LLe.forEach(t),fuo=i(K),Zh=n(K,"LI",{});var yLe=s(Zh);oie=n(yLe,"STRONG",{});var glt=s(oie);muo=r(glt,"vit"),glt.forEach(t),guo=r(yLe," \u2014 "),RN=n(yLe,"A",{href:!0});var hlt=s(RN);huo=r(hlt,"ViTFeatureExtractor"),hlt.forEach(t),puo=r(yLe," (ViT model)"),yLe.forEach(t),_uo=i(K),ep=n(K,"LI",{});var xLe=s(ep);rie=n(xLe,"STRONG",{});var plt=s(rie);uuo=r(plt,"vit_mae"),plt.forEach(t),buo=r(xLe," \u2014 "),PN=n(xLe,"A",{href:!0});var _lt=s(PN);vuo=r(_lt,"ViTFeatureExtractor"),_lt.forEach(t),Fuo=r(xLe," (ViTMAE model)"),xLe.forEach(t),Tuo=i(K),op=n(K,"LI",{});var $Le=s(op);tie=n($Le,"STRONG",{});var ult=s(tie);Muo=r(ult,"wav2vec2"),ult.forEach(t),Euo=r($Le," \u2014 "),BN=n($Le,"A",{href:!0});var blt=s(BN);Cuo=r(blt,"Wav2Vec2FeatureExtractor"),blt.forEach(t),wuo=r($Le," (Wav2Vec2 model)"),$Le.forEach(t),Auo=i(K),rp=n(K,"LI",{});var kLe=s(rp);aie=n(kLe,"STRONG",{});var vlt=s(aie);Luo=r(vlt,"wav2vec2-conformer"),vlt.forEach(t),yuo=r(kLe," \u2014 "),IN=n(kLe,"A",{href:!0});var Flt=s(IN);xuo=r(Flt,"Wav2Vec2FeatureExtractor"),Flt.forEach(t),$uo=r(kLe," (Wav2Vec2-Conformer model)"),kLe.forEach(t),kuo=i(K),tp=n(K,"LI",{});var SLe=s(tp);nie=n(SLe,"STRONG",{});var Tlt=s(nie);Suo=r(Tlt,"yolos"),Tlt.forEach(t),Ruo=r(SLe," \u2014 "),NN=n(SLe,"A",{href:!0});var Mlt=s(NN);Puo=r(Mlt,"YolosFeatureExtractor"),Mlt.forEach(t),Buo=r(SLe," (YOLOS model)"),SLe.forEach(t),K.forEach(t),Iuo=i(ra),T(ap.$$.fragment,ra),Nuo=i(ra),T(np.$$.fragment,ra),ra.forEach(t),quo=i(Us),sp=n(Us,"DIV",{class:!0});var ZVe=s(sp);T(HA.$$.fragment,ZVe),juo=i(ZVe),sie=n(ZVe,"P",{});var Elt=s(sie);Duo=r(Elt,"Register a new feature extractor for this class."),Elt.forEach(t),ZVe.forEach(t),Us.forEach(t),JGe=i(f),Ri=n(f,"H2",{class:!0});var eXe=s(Ri);lp=n(eXe,"A",{id:!0,class:!0,href:!0});var Clt=s(lp);lie=n(Clt,"SPAN",{});var wlt=s(lie);T(UA.$$.fragment,wlt),wlt.forEach(t),Clt.forEach(t),Guo=i(eXe),iie=n(eXe,"SPAN",{});var Alt=s(iie);Ouo=r(Alt,"AutoProcessor"),Alt.forEach(t),eXe.forEach(t),YGe=i(f),yo=n(f,"DIV",{class:!0});var Js=s(yo);T(JA.$$.fragment,Js),Vuo=i(Js),YA=n(Js,"P",{});var oXe=s(YA);Xuo=r(oXe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=n(oXe,"A",{href:!0});var Llt=s(qN);zuo=r(Llt,"AutoProcessor.from_pretrained()"),Llt.forEach(t),Quo=r(oXe," class method."),oXe.forEach(t),Wuo=i(Js),KA=n(Js,"P",{});var rXe=s(KA);Huo=r(rXe,"This class cannot be instantiated directly using "),die=n(rXe,"CODE",{});var ylt=s(die);Uuo=r(ylt,"__init__()"),ylt.forEach(t),Juo=r(rXe," (throws an error)."),rXe.forEach(t),Yuo=i(Js),Ue=n(Js,"DIV",{class:!0});var ta=s(Ue);T(ZA.$$.fragment,ta),Kuo=i(ta),cie=n(ta,"P",{});var xlt=s(cie);Zuo=r(xlt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),xlt.forEach(t),e1o=i(ta),Pi=n(ta,"P",{});var boe=s(Pi);o1o=r(boe,"The processor class to instantiate is selected based on the "),fie=n(boe,"CODE",{});var $lt=s(fie);r1o=r($lt,"model_type"),$lt.forEach(t),t1o=r(boe,` property of the config object (either
passed as an argument or loaded from `),mie=n(boe,"CODE",{});var klt=s(mie);a1o=r(klt,"pretrained_model_name_or_path"),klt.forEach(t),n1o=r(boe," if possible):"),boe.forEach(t),s1o=i(ta),he=n(ta,"UL",{});var ue=s(he);ip=n(ue,"LI",{});var RLe=s(ip);gie=n(RLe,"STRONG",{});var Slt=s(gie);l1o=r(Slt,"clip"),Slt.forEach(t),i1o=r(RLe," \u2014 "),jN=n(RLe,"A",{href:!0});var Rlt=s(jN);d1o=r(Rlt,"CLIPProcessor"),Rlt.forEach(t),c1o=r(RLe," (CLIP model)"),RLe.forEach(t),f1o=i(ue),dp=n(ue,"LI",{});var PLe=s(dp);hie=n(PLe,"STRONG",{});var Plt=s(hie);m1o=r(Plt,"flava"),Plt.forEach(t),g1o=r(PLe," \u2014 "),pie=n(PLe,"CODE",{});var Blt=s(pie);h1o=r(Blt,"FLAVAProcessor"),Blt.forEach(t),p1o=r(PLe," (FLAVA model)"),PLe.forEach(t),_1o=i(ue),cp=n(ue,"LI",{});var BLe=s(cp);_ie=n(BLe,"STRONG",{});var Ilt=s(_ie);u1o=r(Ilt,"layoutlmv2"),Ilt.forEach(t),b1o=r(BLe," \u2014 "),DN=n(BLe,"A",{href:!0});var Nlt=s(DN);v1o=r(Nlt,"LayoutLMv2Processor"),Nlt.forEach(t),F1o=r(BLe," (LayoutLMv2 model)"),BLe.forEach(t),T1o=i(ue),fp=n(ue,"LI",{});var ILe=s(fp);uie=n(ILe,"STRONG",{});var qlt=s(uie);M1o=r(qlt,"layoutlmv3"),qlt.forEach(t),E1o=r(ILe," \u2014 "),GN=n(ILe,"A",{href:!0});var jlt=s(GN);C1o=r(jlt,"LayoutLMv3Processor"),jlt.forEach(t),w1o=r(ILe," (LayoutLMv3 model)"),ILe.forEach(t),A1o=i(ue),mp=n(ue,"LI",{});var NLe=s(mp);bie=n(NLe,"STRONG",{});var Dlt=s(bie);L1o=r(Dlt,"layoutxlm"),Dlt.forEach(t),y1o=r(NLe," \u2014 "),ON=n(NLe,"A",{href:!0});var Glt=s(ON);x1o=r(Glt,"LayoutXLMProcessor"),Glt.forEach(t),$1o=r(NLe," (LayoutXLM model)"),NLe.forEach(t),k1o=i(ue),gp=n(ue,"LI",{});var qLe=s(gp);vie=n(qLe,"STRONG",{});var Olt=s(vie);S1o=r(Olt,"sew"),Olt.forEach(t),R1o=r(qLe," \u2014 "),VN=n(qLe,"A",{href:!0});var Vlt=s(VN);P1o=r(Vlt,"Wav2Vec2Processor"),Vlt.forEach(t),B1o=r(qLe," (SEW model)"),qLe.forEach(t),I1o=i(ue),hp=n(ue,"LI",{});var jLe=s(hp);Fie=n(jLe,"STRONG",{});var Xlt=s(Fie);N1o=r(Xlt,"sew-d"),Xlt.forEach(t),q1o=r(jLe," \u2014 "),XN=n(jLe,"A",{href:!0});var zlt=s(XN);j1o=r(zlt,"Wav2Vec2Processor"),zlt.forEach(t),D1o=r(jLe," (SEW-D model)"),jLe.forEach(t),G1o=i(ue),pp=n(ue,"LI",{});var DLe=s(pp);Tie=n(DLe,"STRONG",{});var Qlt=s(Tie);O1o=r(Qlt,"speech_to_text"),Qlt.forEach(t),V1o=r(DLe," \u2014 "),zN=n(DLe,"A",{href:!0});var Wlt=s(zN);X1o=r(Wlt,"Speech2TextProcessor"),Wlt.forEach(t),z1o=r(DLe," (Speech2Text model)"),DLe.forEach(t),Q1o=i(ue),_p=n(ue,"LI",{});var GLe=s(_p);Mie=n(GLe,"STRONG",{});var Hlt=s(Mie);W1o=r(Hlt,"speech_to_text_2"),Hlt.forEach(t),H1o=r(GLe," \u2014 "),QN=n(GLe,"A",{href:!0});var Ult=s(QN);U1o=r(Ult,"Speech2Text2Processor"),Ult.forEach(t),J1o=r(GLe," (Speech2Text2 model)"),GLe.forEach(t),Y1o=i(ue),up=n(ue,"LI",{});var OLe=s(up);Eie=n(OLe,"STRONG",{});var Jlt=s(Eie);K1o=r(Jlt,"trocr"),Jlt.forEach(t),Z1o=r(OLe," \u2014 "),WN=n(OLe,"A",{href:!0});var Ylt=s(WN);e2o=r(Ylt,"TrOCRProcessor"),Ylt.forEach(t),o2o=r(OLe," (TrOCR model)"),OLe.forEach(t),r2o=i(ue),bp=n(ue,"LI",{});var VLe=s(bp);Cie=n(VLe,"STRONG",{});var Klt=s(Cie);t2o=r(Klt,"unispeech"),Klt.forEach(t),a2o=r(VLe," \u2014 "),HN=n(VLe,"A",{href:!0});var Zlt=s(HN);n2o=r(Zlt,"Wav2Vec2Processor"),Zlt.forEach(t),s2o=r(VLe," (UniSpeech model)"),VLe.forEach(t),l2o=i(ue),vp=n(ue,"LI",{});var XLe=s(vp);wie=n(XLe,"STRONG",{});var eit=s(wie);i2o=r(eit,"unispeech-sat"),eit.forEach(t),d2o=r(XLe," \u2014 "),UN=n(XLe,"A",{href:!0});var oit=s(UN);c2o=r(oit,"Wav2Vec2Processor"),oit.forEach(t),f2o=r(XLe," (UniSpeechSat model)"),XLe.forEach(t),m2o=i(ue),Fp=n(ue,"LI",{});var zLe=s(Fp);Aie=n(zLe,"STRONG",{});var rit=s(Aie);g2o=r(rit,"vilt"),rit.forEach(t),h2o=r(zLe," \u2014 "),JN=n(zLe,"A",{href:!0});var tit=s(JN);p2o=r(tit,"ViltProcessor"),tit.forEach(t),_2o=r(zLe," (ViLT model)"),zLe.forEach(t),u2o=i(ue),Tp=n(ue,"LI",{});var QLe=s(Tp);Lie=n(QLe,"STRONG",{});var ait=s(Lie);b2o=r(ait,"vision-text-dual-encoder"),ait.forEach(t),v2o=r(QLe," \u2014 "),YN=n(QLe,"A",{href:!0});var nit=s(YN);F2o=r(nit,"VisionTextDualEncoderProcessor"),nit.forEach(t),T2o=r(QLe," (VisionTextDualEncoder model)"),QLe.forEach(t),M2o=i(ue),Mp=n(ue,"LI",{});var WLe=s(Mp);yie=n(WLe,"STRONG",{});var sit=s(yie);E2o=r(sit,"wav2vec2"),sit.forEach(t),C2o=r(WLe," \u2014 "),KN=n(WLe,"A",{href:!0});var lit=s(KN);w2o=r(lit,"Wav2Vec2Processor"),lit.forEach(t),A2o=r(WLe," (Wav2Vec2 model)"),WLe.forEach(t),L2o=i(ue),Ep=n(ue,"LI",{});var HLe=s(Ep);xie=n(HLe,"STRONG",{});var iit=s(xie);y2o=r(iit,"wav2vec2-conformer"),iit.forEach(t),x2o=r(HLe," \u2014 "),ZN=n(HLe,"A",{href:!0});var dit=s(ZN);$2o=r(dit,"Wav2Vec2Processor"),dit.forEach(t),k2o=r(HLe," (Wav2Vec2-Conformer model)"),HLe.forEach(t),S2o=i(ue),Cp=n(ue,"LI",{});var ULe=s(Cp);$ie=n(ULe,"STRONG",{});var cit=s($ie);R2o=r(cit,"wavlm"),cit.forEach(t),P2o=r(ULe," \u2014 "),eq=n(ULe,"A",{href:!0});var fit=s(eq);B2o=r(fit,"Wav2Vec2Processor"),fit.forEach(t),I2o=r(ULe," (WavLM model)"),ULe.forEach(t),ue.forEach(t),N2o=i(ta),T(wp.$$.fragment,ta),q2o=i(ta),T(Ap.$$.fragment,ta),ta.forEach(t),j2o=i(Js),Lp=n(Js,"DIV",{class:!0});var tXe=s(Lp);T(eL.$$.fragment,tXe),D2o=i(tXe),kie=n(tXe,"P",{});var mit=s(kie);G2o=r(mit,"Register a new processor for this class."),mit.forEach(t),tXe.forEach(t),Js.forEach(t),KGe=i(f),Bi=n(f,"H2",{class:!0});var aXe=s(Bi);yp=n(aXe,"A",{id:!0,class:!0,href:!0});var git=s(yp);Sie=n(git,"SPAN",{});var hit=s(Sie);T(oL.$$.fragment,hit),hit.forEach(t),git.forEach(t),O2o=i(aXe),Rie=n(aXe,"SPAN",{});var pit=s(Rie);V2o=r(pit,"AutoModel"),pit.forEach(t),aXe.forEach(t),ZGe=i(f),xo=n(f,"DIV",{class:!0});var Ys=s(xo);T(rL.$$.fragment,Ys),X2o=i(Ys),Ii=n(Ys,"P",{});var voe=s(Ii);z2o=r(voe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=n(voe,"A",{href:!0});var _it=s(oq);Q2o=r(_it,"from_pretrained()"),_it.forEach(t),W2o=r(voe," class method or the "),rq=n(voe,"A",{href:!0});var uit=s(rq);H2o=r(uit,"from_config()"),uit.forEach(t),U2o=r(voe,` class
method.`),voe.forEach(t),J2o=i(Ys),tL=n(Ys,"P",{});var nXe=s(tL);Y2o=r(nXe,"This class cannot be instantiated directly using "),Pie=n(nXe,"CODE",{});var bit=s(Pie);K2o=r(bit,"__init__()"),bit.forEach(t),Z2o=r(nXe," (throws an error)."),nXe.forEach(t),ebo=i(Ys),nt=n(Ys,"DIV",{class:!0});var k0=s(nt);T(aL.$$.fragment,k0),obo=i(k0),Bie=n(k0,"P",{});var vit=s(Bie);rbo=r(vit,"Instantiates one of the base model classes of the library from a configuration."),vit.forEach(t),tbo=i(k0),Ni=n(k0,"P",{});var Foe=s(Ni);abo=r(Foe,`Note:
Loading a model from its configuration file does `),Iie=n(Foe,"STRONG",{});var Fit=s(Iie);nbo=r(Fit,"not"),Fit.forEach(t),sbo=r(Foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=n(Foe,"A",{href:!0});var Tit=s(tq);lbo=r(Tit,"from_pretrained()"),Tit.forEach(t),ibo=r(Foe," to load the model weights."),Foe.forEach(t),dbo=i(k0),T(xp.$$.fragment,k0),k0.forEach(t),cbo=i(Ys),Je=n(Ys,"DIV",{class:!0});var aa=s(Je);T(nL.$$.fragment,aa),fbo=i(aa),Nie=n(aa,"P",{});var Mit=s(Nie);mbo=r(Mit,"Instantiate one of the base model classes of the library from a pretrained model."),Mit.forEach(t),gbo=i(aa),Ra=n(aa,"P",{});var S0=s(Ra);hbo=r(S0,"The model class to instantiate is selected based on the "),qie=n(S0,"CODE",{});var Eit=s(qie);pbo=r(Eit,"model_type"),Eit.forEach(t),_bo=r(S0,` property of the config object (either
passed as an argument or loaded from `),jie=n(S0,"CODE",{});var Cit=s(jie);ubo=r(Cit,"pretrained_model_name_or_path"),Cit.forEach(t),bbo=r(S0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=n(S0,"CODE",{});var wit=s(Die);vbo=r(wit,"pretrained_model_name_or_path"),wit.forEach(t),Fbo=r(S0,":"),S0.forEach(t),Tbo=i(aa),y=n(aa,"UL",{});var $=s(y);$p=n($,"LI",{});var JLe=s($p);Gie=n(JLe,"STRONG",{});var Ait=s(Gie);Mbo=r(Ait,"albert"),Ait.forEach(t),Ebo=r(JLe," \u2014 "),aq=n(JLe,"A",{href:!0});var Lit=s(aq);Cbo=r(Lit,"AlbertModel"),Lit.forEach(t),wbo=r(JLe," (ALBERT model)"),JLe.forEach(t),Abo=i($),kp=n($,"LI",{});var YLe=s(kp);Oie=n(YLe,"STRONG",{});var yit=s(Oie);Lbo=r(yit,"bart"),yit.forEach(t),ybo=r(YLe," \u2014 "),nq=n(YLe,"A",{href:!0});var xit=s(nq);xbo=r(xit,"BartModel"),xit.forEach(t),$bo=r(YLe," (BART model)"),YLe.forEach(t),kbo=i($),Sp=n($,"LI",{});var KLe=s(Sp);Vie=n(KLe,"STRONG",{});var $it=s(Vie);Sbo=r($it,"beit"),$it.forEach(t),Rbo=r(KLe," \u2014 "),sq=n(KLe,"A",{href:!0});var kit=s(sq);Pbo=r(kit,"BeitModel"),kit.forEach(t),Bbo=r(KLe," (BEiT model)"),KLe.forEach(t),Ibo=i($),Rp=n($,"LI",{});var ZLe=s(Rp);Xie=n(ZLe,"STRONG",{});var Sit=s(Xie);Nbo=r(Sit,"bert"),Sit.forEach(t),qbo=r(ZLe," \u2014 "),lq=n(ZLe,"A",{href:!0});var Rit=s(lq);jbo=r(Rit,"BertModel"),Rit.forEach(t),Dbo=r(ZLe," (BERT model)"),ZLe.forEach(t),Gbo=i($),Pp=n($,"LI",{});var eye=s(Pp);zie=n(eye,"STRONG",{});var Pit=s(zie);Obo=r(Pit,"bert-generation"),Pit.forEach(t),Vbo=r(eye," \u2014 "),iq=n(eye,"A",{href:!0});var Bit=s(iq);Xbo=r(Bit,"BertGenerationEncoder"),Bit.forEach(t),zbo=r(eye," (Bert Generation model)"),eye.forEach(t),Qbo=i($),Bp=n($,"LI",{});var oye=s(Bp);Qie=n(oye,"STRONG",{});var Iit=s(Qie);Wbo=r(Iit,"big_bird"),Iit.forEach(t),Hbo=r(oye," \u2014 "),dq=n(oye,"A",{href:!0});var Nit=s(dq);Ubo=r(Nit,"BigBirdModel"),Nit.forEach(t),Jbo=r(oye," (BigBird model)"),oye.forEach(t),Ybo=i($),Ip=n($,"LI",{});var rye=s(Ip);Wie=n(rye,"STRONG",{});var qit=s(Wie);Kbo=r(qit,"bigbird_pegasus"),qit.forEach(t),Zbo=r(rye," \u2014 "),cq=n(rye,"A",{href:!0});var jit=s(cq);e4o=r(jit,"BigBirdPegasusModel"),jit.forEach(t),o4o=r(rye," (BigBird-Pegasus model)"),rye.forEach(t),r4o=i($),Np=n($,"LI",{});var tye=s(Np);Hie=n(tye,"STRONG",{});var Dit=s(Hie);t4o=r(Dit,"blenderbot"),Dit.forEach(t),a4o=r(tye," \u2014 "),fq=n(tye,"A",{href:!0});var Git=s(fq);n4o=r(Git,"BlenderbotModel"),Git.forEach(t),s4o=r(tye," (Blenderbot model)"),tye.forEach(t),l4o=i($),qp=n($,"LI",{});var aye=s(qp);Uie=n(aye,"STRONG",{});var Oit=s(Uie);i4o=r(Oit,"blenderbot-small"),Oit.forEach(t),d4o=r(aye," \u2014 "),mq=n(aye,"A",{href:!0});var Vit=s(mq);c4o=r(Vit,"BlenderbotSmallModel"),Vit.forEach(t),f4o=r(aye," (BlenderbotSmall model)"),aye.forEach(t),m4o=i($),jp=n($,"LI",{});var nye=s(jp);Jie=n(nye,"STRONG",{});var Xit=s(Jie);g4o=r(Xit,"bloom"),Xit.forEach(t),h4o=r(nye," \u2014 "),gq=n(nye,"A",{href:!0});var zit=s(gq);p4o=r(zit,"BloomModel"),zit.forEach(t),_4o=r(nye," (BLOOM model)"),nye.forEach(t),u4o=i($),Dp=n($,"LI",{});var sye=s(Dp);Yie=n(sye,"STRONG",{});var Qit=s(Yie);b4o=r(Qit,"camembert"),Qit.forEach(t),v4o=r(sye," \u2014 "),hq=n(sye,"A",{href:!0});var Wit=s(hq);F4o=r(Wit,"CamembertModel"),Wit.forEach(t),T4o=r(sye," (CamemBERT model)"),sye.forEach(t),M4o=i($),Gp=n($,"LI",{});var lye=s(Gp);Kie=n(lye,"STRONG",{});var Hit=s(Kie);E4o=r(Hit,"canine"),Hit.forEach(t),C4o=r(lye," \u2014 "),pq=n(lye,"A",{href:!0});var Uit=s(pq);w4o=r(Uit,"CanineModel"),Uit.forEach(t),A4o=r(lye," (CANINE model)"),lye.forEach(t),L4o=i($),Op=n($,"LI",{});var iye=s(Op);Zie=n(iye,"STRONG",{});var Jit=s(Zie);y4o=r(Jit,"clip"),Jit.forEach(t),x4o=r(iye," \u2014 "),_q=n(iye,"A",{href:!0});var Yit=s(_q);$4o=r(Yit,"CLIPModel"),Yit.forEach(t),k4o=r(iye," (CLIP model)"),iye.forEach(t),S4o=i($),Vp=n($,"LI",{});var dye=s(Vp);ede=n(dye,"STRONG",{});var Kit=s(ede);R4o=r(Kit,"convbert"),Kit.forEach(t),P4o=r(dye," \u2014 "),uq=n(dye,"A",{href:!0});var Zit=s(uq);B4o=r(Zit,"ConvBertModel"),Zit.forEach(t),I4o=r(dye," (ConvBERT model)"),dye.forEach(t),N4o=i($),Xp=n($,"LI",{});var cye=s(Xp);ode=n(cye,"STRONG",{});var edt=s(ode);q4o=r(edt,"convnext"),edt.forEach(t),j4o=r(cye," \u2014 "),bq=n(cye,"A",{href:!0});var odt=s(bq);D4o=r(odt,"ConvNextModel"),odt.forEach(t),G4o=r(cye," (ConvNeXT model)"),cye.forEach(t),O4o=i($),zp=n($,"LI",{});var fye=s(zp);rde=n(fye,"STRONG",{});var rdt=s(rde);V4o=r(rdt,"ctrl"),rdt.forEach(t),X4o=r(fye," \u2014 "),vq=n(fye,"A",{href:!0});var tdt=s(vq);z4o=r(tdt,"CTRLModel"),tdt.forEach(t),Q4o=r(fye," (CTRL model)"),fye.forEach(t),W4o=i($),Qp=n($,"LI",{});var mye=s(Qp);tde=n(mye,"STRONG",{});var adt=s(tde);H4o=r(adt,"cvt"),adt.forEach(t),U4o=r(mye," \u2014 "),Fq=n(mye,"A",{href:!0});var ndt=s(Fq);J4o=r(ndt,"CvtModel"),ndt.forEach(t),Y4o=r(mye," (CvT model)"),mye.forEach(t),K4o=i($),Wp=n($,"LI",{});var gye=s(Wp);ade=n(gye,"STRONG",{});var sdt=s(ade);Z4o=r(sdt,"data2vec-audio"),sdt.forEach(t),evo=r(gye," \u2014 "),Tq=n(gye,"A",{href:!0});var ldt=s(Tq);ovo=r(ldt,"Data2VecAudioModel"),ldt.forEach(t),rvo=r(gye," (Data2VecAudio model)"),gye.forEach(t),tvo=i($),Hp=n($,"LI",{});var hye=s(Hp);nde=n(hye,"STRONG",{});var idt=s(nde);avo=r(idt,"data2vec-text"),idt.forEach(t),nvo=r(hye," \u2014 "),Mq=n(hye,"A",{href:!0});var ddt=s(Mq);svo=r(ddt,"Data2VecTextModel"),ddt.forEach(t),lvo=r(hye," (Data2VecText model)"),hye.forEach(t),ivo=i($),Up=n($,"LI",{});var pye=s(Up);sde=n(pye,"STRONG",{});var cdt=s(sde);dvo=r(cdt,"data2vec-vision"),cdt.forEach(t),cvo=r(pye," \u2014 "),Eq=n(pye,"A",{href:!0});var fdt=s(Eq);fvo=r(fdt,"Data2VecVisionModel"),fdt.forEach(t),mvo=r(pye," (Data2VecVision model)"),pye.forEach(t),gvo=i($),Jp=n($,"LI",{});var _ye=s(Jp);lde=n(_ye,"STRONG",{});var mdt=s(lde);hvo=r(mdt,"deberta"),mdt.forEach(t),pvo=r(_ye," \u2014 "),Cq=n(_ye,"A",{href:!0});var gdt=s(Cq);_vo=r(gdt,"DebertaModel"),gdt.forEach(t),uvo=r(_ye," (DeBERTa model)"),_ye.forEach(t),bvo=i($),Yp=n($,"LI",{});var uye=s(Yp);ide=n(uye,"STRONG",{});var hdt=s(ide);vvo=r(hdt,"deberta-v2"),hdt.forEach(t),Fvo=r(uye," \u2014 "),wq=n(uye,"A",{href:!0});var pdt=s(wq);Tvo=r(pdt,"DebertaV2Model"),pdt.forEach(t),Mvo=r(uye," (DeBERTa-v2 model)"),uye.forEach(t),Evo=i($),Kp=n($,"LI",{});var bye=s(Kp);dde=n(bye,"STRONG",{});var _dt=s(dde);Cvo=r(_dt,"decision_transformer"),_dt.forEach(t),wvo=r(bye," \u2014 "),Aq=n(bye,"A",{href:!0});var udt=s(Aq);Avo=r(udt,"DecisionTransformerModel"),udt.forEach(t),Lvo=r(bye," (Decision Transformer model)"),bye.forEach(t),yvo=i($),Zp=n($,"LI",{});var vye=s(Zp);cde=n(vye,"STRONG",{});var bdt=s(cde);xvo=r(bdt,"deit"),bdt.forEach(t),$vo=r(vye," \u2014 "),Lq=n(vye,"A",{href:!0});var vdt=s(Lq);kvo=r(vdt,"DeiTModel"),vdt.forEach(t),Svo=r(vye," (DeiT model)"),vye.forEach(t),Rvo=i($),e_=n($,"LI",{});var Fye=s(e_);fde=n(Fye,"STRONG",{});var Fdt=s(fde);Pvo=r(Fdt,"detr"),Fdt.forEach(t),Bvo=r(Fye," \u2014 "),yq=n(Fye,"A",{href:!0});var Tdt=s(yq);Ivo=r(Tdt,"DetrModel"),Tdt.forEach(t),Nvo=r(Fye," (DETR model)"),Fye.forEach(t),qvo=i($),o_=n($,"LI",{});var Tye=s(o_);mde=n(Tye,"STRONG",{});var Mdt=s(mde);jvo=r(Mdt,"distilbert"),Mdt.forEach(t),Dvo=r(Tye," \u2014 "),xq=n(Tye,"A",{href:!0});var Edt=s(xq);Gvo=r(Edt,"DistilBertModel"),Edt.forEach(t),Ovo=r(Tye," (DistilBERT model)"),Tye.forEach(t),Vvo=i($),r_=n($,"LI",{});var Mye=s(r_);gde=n(Mye,"STRONG",{});var Cdt=s(gde);Xvo=r(Cdt,"dpr"),Cdt.forEach(t),zvo=r(Mye," \u2014 "),$q=n(Mye,"A",{href:!0});var wdt=s($q);Qvo=r(wdt,"DPRQuestionEncoder"),wdt.forEach(t),Wvo=r(Mye," (DPR model)"),Mye.forEach(t),Hvo=i($),t_=n($,"LI",{});var Eye=s(t_);hde=n(Eye,"STRONG",{});var Adt=s(hde);Uvo=r(Adt,"dpt"),Adt.forEach(t),Jvo=r(Eye," \u2014 "),kq=n(Eye,"A",{href:!0});var Ldt=s(kq);Yvo=r(Ldt,"DPTModel"),Ldt.forEach(t),Kvo=r(Eye," (DPT model)"),Eye.forEach(t),Zvo=i($),a_=n($,"LI",{});var Cye=s(a_);pde=n(Cye,"STRONG",{});var ydt=s(pde);eFo=r(ydt,"electra"),ydt.forEach(t),oFo=r(Cye," \u2014 "),Sq=n(Cye,"A",{href:!0});var xdt=s(Sq);rFo=r(xdt,"ElectraModel"),xdt.forEach(t),tFo=r(Cye," (ELECTRA model)"),Cye.forEach(t),aFo=i($),n_=n($,"LI",{});var wye=s(n_);_de=n(wye,"STRONG",{});var $dt=s(_de);nFo=r($dt,"flaubert"),$dt.forEach(t),sFo=r(wye," \u2014 "),Rq=n(wye,"A",{href:!0});var kdt=s(Rq);lFo=r(kdt,"FlaubertModel"),kdt.forEach(t),iFo=r(wye," (FlauBERT model)"),wye.forEach(t),dFo=i($),s_=n($,"LI",{});var Aye=s(s_);ude=n(Aye,"STRONG",{});var Sdt=s(ude);cFo=r(Sdt,"flava"),Sdt.forEach(t),fFo=r(Aye," \u2014 "),Pq=n(Aye,"A",{href:!0});var Rdt=s(Pq);mFo=r(Rdt,"FlavaModel"),Rdt.forEach(t),gFo=r(Aye," (FLAVA model)"),Aye.forEach(t),hFo=i($),l_=n($,"LI",{});var Lye=s(l_);bde=n(Lye,"STRONG",{});var Pdt=s(bde);pFo=r(Pdt,"fnet"),Pdt.forEach(t),_Fo=r(Lye," \u2014 "),Bq=n(Lye,"A",{href:!0});var Bdt=s(Bq);uFo=r(Bdt,"FNetModel"),Bdt.forEach(t),bFo=r(Lye," (FNet model)"),Lye.forEach(t),vFo=i($),i_=n($,"LI",{});var yye=s(i_);vde=n(yye,"STRONG",{});var Idt=s(vde);FFo=r(Idt,"fsmt"),Idt.forEach(t),TFo=r(yye," \u2014 "),Iq=n(yye,"A",{href:!0});var Ndt=s(Iq);MFo=r(Ndt,"FSMTModel"),Ndt.forEach(t),EFo=r(yye," (FairSeq Machine-Translation model)"),yye.forEach(t),CFo=i($),Vs=n($,"LI",{});var Kk=s(Vs);Fde=n(Kk,"STRONG",{});var qdt=s(Fde);wFo=r(qdt,"funnel"),qdt.forEach(t),AFo=r(Kk," \u2014 "),Nq=n(Kk,"A",{href:!0});var jdt=s(Nq);LFo=r(jdt,"FunnelModel"),jdt.forEach(t),yFo=r(Kk," or "),qq=n(Kk,"A",{href:!0});var Ddt=s(qq);xFo=r(Ddt,"FunnelBaseModel"),Ddt.forEach(t),$Fo=r(Kk," (Funnel Transformer model)"),Kk.forEach(t),kFo=i($),d_=n($,"LI",{});var xye=s(d_);Tde=n(xye,"STRONG",{});var Gdt=s(Tde);SFo=r(Gdt,"glpn"),Gdt.forEach(t),RFo=r(xye," \u2014 "),jq=n(xye,"A",{href:!0});var Odt=s(jq);PFo=r(Odt,"GLPNModel"),Odt.forEach(t),BFo=r(xye," (GLPN model)"),xye.forEach(t),IFo=i($),c_=n($,"LI",{});var $ye=s(c_);Mde=n($ye,"STRONG",{});var Vdt=s(Mde);NFo=r(Vdt,"gpt2"),Vdt.forEach(t),qFo=r($ye," \u2014 "),Dq=n($ye,"A",{href:!0});var Xdt=s(Dq);jFo=r(Xdt,"GPT2Model"),Xdt.forEach(t),DFo=r($ye," (OpenAI GPT-2 model)"),$ye.forEach(t),GFo=i($),f_=n($,"LI",{});var kye=s(f_);Ede=n(kye,"STRONG",{});var zdt=s(Ede);OFo=r(zdt,"gpt_neo"),zdt.forEach(t),VFo=r(kye," \u2014 "),Gq=n(kye,"A",{href:!0});var Qdt=s(Gq);XFo=r(Qdt,"GPTNeoModel"),Qdt.forEach(t),zFo=r(kye," (GPT Neo model)"),kye.forEach(t),QFo=i($),m_=n($,"LI",{});var Sye=s(m_);Cde=n(Sye,"STRONG",{});var Wdt=s(Cde);WFo=r(Wdt,"gpt_neox"),Wdt.forEach(t),HFo=r(Sye," \u2014 "),Oq=n(Sye,"A",{href:!0});var Hdt=s(Oq);UFo=r(Hdt,"GPTNeoXModel"),Hdt.forEach(t),JFo=r(Sye," (GPT NeoX model)"),Sye.forEach(t),YFo=i($),g_=n($,"LI",{});var Rye=s(g_);wde=n(Rye,"STRONG",{});var Udt=s(wde);KFo=r(Udt,"gptj"),Udt.forEach(t),ZFo=r(Rye," \u2014 "),Vq=n(Rye,"A",{href:!0});var Jdt=s(Vq);e6o=r(Jdt,"GPTJModel"),Jdt.forEach(t),o6o=r(Rye," (GPT-J model)"),Rye.forEach(t),r6o=i($),h_=n($,"LI",{});var Pye=s(h_);Ade=n(Pye,"STRONG",{});var Ydt=s(Ade);t6o=r(Ydt,"hubert"),Ydt.forEach(t),a6o=r(Pye," \u2014 "),Xq=n(Pye,"A",{href:!0});var Kdt=s(Xq);n6o=r(Kdt,"HubertModel"),Kdt.forEach(t),s6o=r(Pye," (Hubert model)"),Pye.forEach(t),l6o=i($),p_=n($,"LI",{});var Bye=s(p_);Lde=n(Bye,"STRONG",{});var Zdt=s(Lde);i6o=r(Zdt,"ibert"),Zdt.forEach(t),d6o=r(Bye," \u2014 "),zq=n(Bye,"A",{href:!0});var ect=s(zq);c6o=r(ect,"IBertModel"),ect.forEach(t),f6o=r(Bye," (I-BERT model)"),Bye.forEach(t),m6o=i($),__=n($,"LI",{});var Iye=s(__);yde=n(Iye,"STRONG",{});var oct=s(yde);g6o=r(oct,"imagegpt"),oct.forEach(t),h6o=r(Iye," \u2014 "),Qq=n(Iye,"A",{href:!0});var rct=s(Qq);p6o=r(rct,"ImageGPTModel"),rct.forEach(t),_6o=r(Iye," (ImageGPT model)"),Iye.forEach(t),u6o=i($),u_=n($,"LI",{});var Nye=s(u_);xde=n(Nye,"STRONG",{});var tct=s(xde);b6o=r(tct,"layoutlm"),tct.forEach(t),v6o=r(Nye," \u2014 "),Wq=n(Nye,"A",{href:!0});var act=s(Wq);F6o=r(act,"LayoutLMModel"),act.forEach(t),T6o=r(Nye," (LayoutLM model)"),Nye.forEach(t),M6o=i($),b_=n($,"LI",{});var qye=s(b_);$de=n(qye,"STRONG",{});var nct=s($de);E6o=r(nct,"layoutlmv2"),nct.forEach(t),C6o=r(qye," \u2014 "),Hq=n(qye,"A",{href:!0});var sct=s(Hq);w6o=r(sct,"LayoutLMv2Model"),sct.forEach(t),A6o=r(qye," (LayoutLMv2 model)"),qye.forEach(t),L6o=i($),v_=n($,"LI",{});var jye=s(v_);kde=n(jye,"STRONG",{});var lct=s(kde);y6o=r(lct,"layoutlmv3"),lct.forEach(t),x6o=r(jye," \u2014 "),Uq=n(jye,"A",{href:!0});var ict=s(Uq);$6o=r(ict,"LayoutLMv3Model"),ict.forEach(t),k6o=r(jye," (LayoutLMv3 model)"),jye.forEach(t),S6o=i($),F_=n($,"LI",{});var Dye=s(F_);Sde=n(Dye,"STRONG",{});var dct=s(Sde);R6o=r(dct,"led"),dct.forEach(t),P6o=r(Dye," \u2014 "),Jq=n(Dye,"A",{href:!0});var cct=s(Jq);B6o=r(cct,"LEDModel"),cct.forEach(t),I6o=r(Dye," (LED model)"),Dye.forEach(t),N6o=i($),T_=n($,"LI",{});var Gye=s(T_);Rde=n(Gye,"STRONG",{});var fct=s(Rde);q6o=r(fct,"levit"),fct.forEach(t),j6o=r(Gye," \u2014 "),Yq=n(Gye,"A",{href:!0});var mct=s(Yq);D6o=r(mct,"LevitModel"),mct.forEach(t),G6o=r(Gye," (LeViT model)"),Gye.forEach(t),O6o=i($),M_=n($,"LI",{});var Oye=s(M_);Pde=n(Oye,"STRONG",{});var gct=s(Pde);V6o=r(gct,"longformer"),gct.forEach(t),X6o=r(Oye," \u2014 "),Kq=n(Oye,"A",{href:!0});var hct=s(Kq);z6o=r(hct,"LongformerModel"),hct.forEach(t),Q6o=r(Oye," (Longformer model)"),Oye.forEach(t),W6o=i($),E_=n($,"LI",{});var Vye=s(E_);Bde=n(Vye,"STRONG",{});var pct=s(Bde);H6o=r(pct,"longt5"),pct.forEach(t),U6o=r(Vye," \u2014 "),Zq=n(Vye,"A",{href:!0});var _ct=s(Zq);J6o=r(_ct,"LongT5Model"),_ct.forEach(t),Y6o=r(Vye," (LongT5 model)"),Vye.forEach(t),K6o=i($),C_=n($,"LI",{});var Xye=s(C_);Ide=n(Xye,"STRONG",{});var uct=s(Ide);Z6o=r(uct,"luke"),uct.forEach(t),eTo=r(Xye," \u2014 "),ej=n(Xye,"A",{href:!0});var bct=s(ej);oTo=r(bct,"LukeModel"),bct.forEach(t),rTo=r(Xye," (LUKE model)"),Xye.forEach(t),tTo=i($),w_=n($,"LI",{});var zye=s(w_);Nde=n(zye,"STRONG",{});var vct=s(Nde);aTo=r(vct,"lxmert"),vct.forEach(t),nTo=r(zye," \u2014 "),oj=n(zye,"A",{href:!0});var Fct=s(oj);sTo=r(Fct,"LxmertModel"),Fct.forEach(t),lTo=r(zye," (LXMERT model)"),zye.forEach(t),iTo=i($),A_=n($,"LI",{});var Qye=s(A_);qde=n(Qye,"STRONG",{});var Tct=s(qde);dTo=r(Tct,"m2m_100"),Tct.forEach(t),cTo=r(Qye," \u2014 "),rj=n(Qye,"A",{href:!0});var Mct=s(rj);fTo=r(Mct,"M2M100Model"),Mct.forEach(t),mTo=r(Qye," (M2M100 model)"),Qye.forEach(t),gTo=i($),L_=n($,"LI",{});var Wye=s(L_);jde=n(Wye,"STRONG",{});var Ect=s(jde);hTo=r(Ect,"marian"),Ect.forEach(t),pTo=r(Wye," \u2014 "),tj=n(Wye,"A",{href:!0});var Cct=s(tj);_To=r(Cct,"MarianModel"),Cct.forEach(t),uTo=r(Wye," (Marian model)"),Wye.forEach(t),bTo=i($),y_=n($,"LI",{});var Hye=s(y_);Dde=n(Hye,"STRONG",{});var wct=s(Dde);vTo=r(wct,"maskformer"),wct.forEach(t),FTo=r(Hye," \u2014 "),aj=n(Hye,"A",{href:!0});var Act=s(aj);TTo=r(Act,"MaskFormerModel"),Act.forEach(t),MTo=r(Hye," (MaskFormer model)"),Hye.forEach(t),ETo=i($),x_=n($,"LI",{});var Uye=s(x_);Gde=n(Uye,"STRONG",{});var Lct=s(Gde);CTo=r(Lct,"mbart"),Lct.forEach(t),wTo=r(Uye," \u2014 "),nj=n(Uye,"A",{href:!0});var yct=s(nj);ATo=r(yct,"MBartModel"),yct.forEach(t),LTo=r(Uye," (mBART model)"),Uye.forEach(t),yTo=i($),$_=n($,"LI",{});var Jye=s($_);Ode=n(Jye,"STRONG",{});var xct=s(Ode);xTo=r(xct,"mctct"),xct.forEach(t),$To=r(Jye," \u2014 "),sj=n(Jye,"A",{href:!0});var $ct=s(sj);kTo=r($ct,"MCTCTModel"),$ct.forEach(t),STo=r(Jye," (M-CTC-T model)"),Jye.forEach(t),RTo=i($),k_=n($,"LI",{});var Yye=s(k_);Vde=n(Yye,"STRONG",{});var kct=s(Vde);PTo=r(kct,"megatron-bert"),kct.forEach(t),BTo=r(Yye," \u2014 "),lj=n(Yye,"A",{href:!0});var Sct=s(lj);ITo=r(Sct,"MegatronBertModel"),Sct.forEach(t),NTo=r(Yye," (Megatron-BERT model)"),Yye.forEach(t),qTo=i($),S_=n($,"LI",{});var Kye=s(S_);Xde=n(Kye,"STRONG",{});var Rct=s(Xde);jTo=r(Rct,"mobilebert"),Rct.forEach(t),DTo=r(Kye," \u2014 "),ij=n(Kye,"A",{href:!0});var Pct=s(ij);GTo=r(Pct,"MobileBertModel"),Pct.forEach(t),OTo=r(Kye," (MobileBERT model)"),Kye.forEach(t),VTo=i($),R_=n($,"LI",{});var Zye=s(R_);zde=n(Zye,"STRONG",{});var Bct=s(zde);XTo=r(Bct,"mpnet"),Bct.forEach(t),zTo=r(Zye," \u2014 "),dj=n(Zye,"A",{href:!0});var Ict=s(dj);QTo=r(Ict,"MPNetModel"),Ict.forEach(t),WTo=r(Zye," (MPNet model)"),Zye.forEach(t),HTo=i($),P_=n($,"LI",{});var e9e=s(P_);Qde=n(e9e,"STRONG",{});var Nct=s(Qde);UTo=r(Nct,"mt5"),Nct.forEach(t),JTo=r(e9e," \u2014 "),cj=n(e9e,"A",{href:!0});var qct=s(cj);YTo=r(qct,"MT5Model"),qct.forEach(t),KTo=r(e9e," (MT5 model)"),e9e.forEach(t),ZTo=i($),B_=n($,"LI",{});var o9e=s(B_);Wde=n(o9e,"STRONG",{});var jct=s(Wde);e7o=r(jct,"nezha"),jct.forEach(t),o7o=r(o9e," \u2014 "),fj=n(o9e,"A",{href:!0});var Dct=s(fj);r7o=r(Dct,"NezhaModel"),Dct.forEach(t),t7o=r(o9e," (Nezha model)"),o9e.forEach(t),a7o=i($),I_=n($,"LI",{});var r9e=s(I_);Hde=n(r9e,"STRONG",{});var Gct=s(Hde);n7o=r(Gct,"nystromformer"),Gct.forEach(t),s7o=r(r9e," \u2014 "),mj=n(r9e,"A",{href:!0});var Oct=s(mj);l7o=r(Oct,"NystromformerModel"),Oct.forEach(t),i7o=r(r9e," (Nystr\xF6mformer model)"),r9e.forEach(t),d7o=i($),N_=n($,"LI",{});var t9e=s(N_);Ude=n(t9e,"STRONG",{});var Vct=s(Ude);c7o=r(Vct,"openai-gpt"),Vct.forEach(t),f7o=r(t9e," \u2014 "),gj=n(t9e,"A",{href:!0});var Xct=s(gj);m7o=r(Xct,"OpenAIGPTModel"),Xct.forEach(t),g7o=r(t9e," (OpenAI GPT model)"),t9e.forEach(t),h7o=i($),q_=n($,"LI",{});var a9e=s(q_);Jde=n(a9e,"STRONG",{});var zct=s(Jde);p7o=r(zct,"opt"),zct.forEach(t),_7o=r(a9e," \u2014 "),hj=n(a9e,"A",{href:!0});var Qct=s(hj);u7o=r(Qct,"OPTModel"),Qct.forEach(t),b7o=r(a9e," (OPT model)"),a9e.forEach(t),v7o=i($),j_=n($,"LI",{});var n9e=s(j_);Yde=n(n9e,"STRONG",{});var Wct=s(Yde);F7o=r(Wct,"pegasus"),Wct.forEach(t),T7o=r(n9e," \u2014 "),pj=n(n9e,"A",{href:!0});var Hct=s(pj);M7o=r(Hct,"PegasusModel"),Hct.forEach(t),E7o=r(n9e," (Pegasus model)"),n9e.forEach(t),C7o=i($),D_=n($,"LI",{});var s9e=s(D_);Kde=n(s9e,"STRONG",{});var Uct=s(Kde);w7o=r(Uct,"perceiver"),Uct.forEach(t),A7o=r(s9e," \u2014 "),_j=n(s9e,"A",{href:!0});var Jct=s(_j);L7o=r(Jct,"PerceiverModel"),Jct.forEach(t),y7o=r(s9e," (Perceiver model)"),s9e.forEach(t),x7o=i($),G_=n($,"LI",{});var l9e=s(G_);Zde=n(l9e,"STRONG",{});var Yct=s(Zde);$7o=r(Yct,"plbart"),Yct.forEach(t),k7o=r(l9e," \u2014 "),uj=n(l9e,"A",{href:!0});var Kct=s(uj);S7o=r(Kct,"PLBartModel"),Kct.forEach(t),R7o=r(l9e," (PLBart model)"),l9e.forEach(t),P7o=i($),O_=n($,"LI",{});var i9e=s(O_);ece=n(i9e,"STRONG",{});var Zct=s(ece);B7o=r(Zct,"poolformer"),Zct.forEach(t),I7o=r(i9e," \u2014 "),bj=n(i9e,"A",{href:!0});var eft=s(bj);N7o=r(eft,"PoolFormerModel"),eft.forEach(t),q7o=r(i9e," (PoolFormer model)"),i9e.forEach(t),j7o=i($),V_=n($,"LI",{});var d9e=s(V_);oce=n(d9e,"STRONG",{});var oft=s(oce);D7o=r(oft,"prophetnet"),oft.forEach(t),G7o=r(d9e," \u2014 "),vj=n(d9e,"A",{href:!0});var rft=s(vj);O7o=r(rft,"ProphetNetModel"),rft.forEach(t),V7o=r(d9e," (ProphetNet model)"),d9e.forEach(t),X7o=i($),X_=n($,"LI",{});var c9e=s(X_);rce=n(c9e,"STRONG",{});var tft=s(rce);z7o=r(tft,"qdqbert"),tft.forEach(t),Q7o=r(c9e," \u2014 "),Fj=n(c9e,"A",{href:!0});var aft=s(Fj);W7o=r(aft,"QDQBertModel"),aft.forEach(t),H7o=r(c9e," (QDQBert model)"),c9e.forEach(t),U7o=i($),z_=n($,"LI",{});var f9e=s(z_);tce=n(f9e,"STRONG",{});var nft=s(tce);J7o=r(nft,"reformer"),nft.forEach(t),Y7o=r(f9e," \u2014 "),Tj=n(f9e,"A",{href:!0});var sft=s(Tj);K7o=r(sft,"ReformerModel"),sft.forEach(t),Z7o=r(f9e," (Reformer model)"),f9e.forEach(t),e8o=i($),Q_=n($,"LI",{});var m9e=s(Q_);ace=n(m9e,"STRONG",{});var lft=s(ace);o8o=r(lft,"regnet"),lft.forEach(t),r8o=r(m9e," \u2014 "),Mj=n(m9e,"A",{href:!0});var ift=s(Mj);t8o=r(ift,"RegNetModel"),ift.forEach(t),a8o=r(m9e," (RegNet model)"),m9e.forEach(t),n8o=i($),W_=n($,"LI",{});var g9e=s(W_);nce=n(g9e,"STRONG",{});var dft=s(nce);s8o=r(dft,"rembert"),dft.forEach(t),l8o=r(g9e," \u2014 "),Ej=n(g9e,"A",{href:!0});var cft=s(Ej);i8o=r(cft,"RemBertModel"),cft.forEach(t),d8o=r(g9e," (RemBERT model)"),g9e.forEach(t),c8o=i($),H_=n($,"LI",{});var h9e=s(H_);sce=n(h9e,"STRONG",{});var fft=s(sce);f8o=r(fft,"resnet"),fft.forEach(t),m8o=r(h9e," \u2014 "),Cj=n(h9e,"A",{href:!0});var mft=s(Cj);g8o=r(mft,"ResNetModel"),mft.forEach(t),h8o=r(h9e," (ResNet model)"),h9e.forEach(t),p8o=i($),U_=n($,"LI",{});var p9e=s(U_);lce=n(p9e,"STRONG",{});var gft=s(lce);_8o=r(gft,"retribert"),gft.forEach(t),u8o=r(p9e," \u2014 "),wj=n(p9e,"A",{href:!0});var hft=s(wj);b8o=r(hft,"RetriBertModel"),hft.forEach(t),v8o=r(p9e," (RetriBERT model)"),p9e.forEach(t),F8o=i($),J_=n($,"LI",{});var _9e=s(J_);ice=n(_9e,"STRONG",{});var pft=s(ice);T8o=r(pft,"roberta"),pft.forEach(t),M8o=r(_9e," \u2014 "),Aj=n(_9e,"A",{href:!0});var _ft=s(Aj);E8o=r(_ft,"RobertaModel"),_ft.forEach(t),C8o=r(_9e," (RoBERTa model)"),_9e.forEach(t),w8o=i($),Y_=n($,"LI",{});var u9e=s(Y_);dce=n(u9e,"STRONG",{});var uft=s(dce);A8o=r(uft,"roformer"),uft.forEach(t),L8o=r(u9e," \u2014 "),Lj=n(u9e,"A",{href:!0});var bft=s(Lj);y8o=r(bft,"RoFormerModel"),bft.forEach(t),x8o=r(u9e," (RoFormer model)"),u9e.forEach(t),$8o=i($),K_=n($,"LI",{});var b9e=s(K_);cce=n(b9e,"STRONG",{});var vft=s(cce);k8o=r(vft,"segformer"),vft.forEach(t),S8o=r(b9e," \u2014 "),yj=n(b9e,"A",{href:!0});var Fft=s(yj);R8o=r(Fft,"SegformerModel"),Fft.forEach(t),P8o=r(b9e," (SegFormer model)"),b9e.forEach(t),B8o=i($),Z_=n($,"LI",{});var v9e=s(Z_);fce=n(v9e,"STRONG",{});var Tft=s(fce);I8o=r(Tft,"sew"),Tft.forEach(t),N8o=r(v9e," \u2014 "),xj=n(v9e,"A",{href:!0});var Mft=s(xj);q8o=r(Mft,"SEWModel"),Mft.forEach(t),j8o=r(v9e," (SEW model)"),v9e.forEach(t),D8o=i($),eu=n($,"LI",{});var F9e=s(eu);mce=n(F9e,"STRONG",{});var Eft=s(mce);G8o=r(Eft,"sew-d"),Eft.forEach(t),O8o=r(F9e," \u2014 "),$j=n(F9e,"A",{href:!0});var Cft=s($j);V8o=r(Cft,"SEWDModel"),Cft.forEach(t),X8o=r(F9e," (SEW-D model)"),F9e.forEach(t),z8o=i($),ou=n($,"LI",{});var T9e=s(ou);gce=n(T9e,"STRONG",{});var wft=s(gce);Q8o=r(wft,"speech_to_text"),wft.forEach(t),W8o=r(T9e," \u2014 "),kj=n(T9e,"A",{href:!0});var Aft=s(kj);H8o=r(Aft,"Speech2TextModel"),Aft.forEach(t),U8o=r(T9e," (Speech2Text model)"),T9e.forEach(t),J8o=i($),ru=n($,"LI",{});var M9e=s(ru);hce=n(M9e,"STRONG",{});var Lft=s(hce);Y8o=r(Lft,"splinter"),Lft.forEach(t),K8o=r(M9e," \u2014 "),Sj=n(M9e,"A",{href:!0});var yft=s(Sj);Z8o=r(yft,"SplinterModel"),yft.forEach(t),eMo=r(M9e," (Splinter model)"),M9e.forEach(t),oMo=i($),tu=n($,"LI",{});var E9e=s(tu);pce=n(E9e,"STRONG",{});var xft=s(pce);rMo=r(xft,"squeezebert"),xft.forEach(t),tMo=r(E9e," \u2014 "),Rj=n(E9e,"A",{href:!0});var $ft=s(Rj);aMo=r($ft,"SqueezeBertModel"),$ft.forEach(t),nMo=r(E9e," (SqueezeBERT model)"),E9e.forEach(t),sMo=i($),au=n($,"LI",{});var C9e=s(au);_ce=n(C9e,"STRONG",{});var kft=s(_ce);lMo=r(kft,"swin"),kft.forEach(t),iMo=r(C9e," \u2014 "),Pj=n(C9e,"A",{href:!0});var Sft=s(Pj);dMo=r(Sft,"SwinModel"),Sft.forEach(t),cMo=r(C9e," (Swin Transformer model)"),C9e.forEach(t),fMo=i($),nu=n($,"LI",{});var w9e=s(nu);uce=n(w9e,"STRONG",{});var Rft=s(uce);mMo=r(Rft,"t5"),Rft.forEach(t),gMo=r(w9e," \u2014 "),Bj=n(w9e,"A",{href:!0});var Pft=s(Bj);hMo=r(Pft,"T5Model"),Pft.forEach(t),pMo=r(w9e," (T5 model)"),w9e.forEach(t),_Mo=i($),su=n($,"LI",{});var A9e=s(su);bce=n(A9e,"STRONG",{});var Bft=s(bce);uMo=r(Bft,"tapas"),Bft.forEach(t),bMo=r(A9e," \u2014 "),Ij=n(A9e,"A",{href:!0});var Ift=s(Ij);vMo=r(Ift,"TapasModel"),Ift.forEach(t),FMo=r(A9e," (TAPAS model)"),A9e.forEach(t),TMo=i($),lu=n($,"LI",{});var L9e=s(lu);vce=n(L9e,"STRONG",{});var Nft=s(vce);MMo=r(Nft,"trajectory_transformer"),Nft.forEach(t),EMo=r(L9e," \u2014 "),Nj=n(L9e,"A",{href:!0});var qft=s(Nj);CMo=r(qft,"TrajectoryTransformerModel"),qft.forEach(t),wMo=r(L9e," (Trajectory Transformer model)"),L9e.forEach(t),AMo=i($),iu=n($,"LI",{});var y9e=s(iu);Fce=n(y9e,"STRONG",{});var jft=s(Fce);LMo=r(jft,"transfo-xl"),jft.forEach(t),yMo=r(y9e," \u2014 "),qj=n(y9e,"A",{href:!0});var Dft=s(qj);xMo=r(Dft,"TransfoXLModel"),Dft.forEach(t),$Mo=r(y9e," (Transformer-XL model)"),y9e.forEach(t),kMo=i($),du=n($,"LI",{});var x9e=s(du);Tce=n(x9e,"STRONG",{});var Gft=s(Tce);SMo=r(Gft,"unispeech"),Gft.forEach(t),RMo=r(x9e," \u2014 "),jj=n(x9e,"A",{href:!0});var Oft=s(jj);PMo=r(Oft,"UniSpeechModel"),Oft.forEach(t),BMo=r(x9e," (UniSpeech model)"),x9e.forEach(t),IMo=i($),cu=n($,"LI",{});var $9e=s(cu);Mce=n($9e,"STRONG",{});var Vft=s(Mce);NMo=r(Vft,"unispeech-sat"),Vft.forEach(t),qMo=r($9e," \u2014 "),Dj=n($9e,"A",{href:!0});var Xft=s(Dj);jMo=r(Xft,"UniSpeechSatModel"),Xft.forEach(t),DMo=r($9e," (UniSpeechSat model)"),$9e.forEach(t),GMo=i($),fu=n($,"LI",{});var k9e=s(fu);Ece=n(k9e,"STRONG",{});var zft=s(Ece);OMo=r(zft,"van"),zft.forEach(t),VMo=r(k9e," \u2014 "),Gj=n(k9e,"A",{href:!0});var Qft=s(Gj);XMo=r(Qft,"VanModel"),Qft.forEach(t),zMo=r(k9e," (VAN model)"),k9e.forEach(t),QMo=i($),mu=n($,"LI",{});var S9e=s(mu);Cce=n(S9e,"STRONG",{});var Wft=s(Cce);WMo=r(Wft,"vilt"),Wft.forEach(t),HMo=r(S9e," \u2014 "),Oj=n(S9e,"A",{href:!0});var Hft=s(Oj);UMo=r(Hft,"ViltModel"),Hft.forEach(t),JMo=r(S9e," (ViLT model)"),S9e.forEach(t),YMo=i($),gu=n($,"LI",{});var R9e=s(gu);wce=n(R9e,"STRONG",{});var Uft=s(wce);KMo=r(Uft,"vision-text-dual-encoder"),Uft.forEach(t),ZMo=r(R9e," \u2014 "),Vj=n(R9e,"A",{href:!0});var Jft=s(Vj);eEo=r(Jft,"VisionTextDualEncoderModel"),Jft.forEach(t),oEo=r(R9e," (VisionTextDualEncoder model)"),R9e.forEach(t),rEo=i($),hu=n($,"LI",{});var P9e=s(hu);Ace=n(P9e,"STRONG",{});var Yft=s(Ace);tEo=r(Yft,"visual_bert"),Yft.forEach(t),aEo=r(P9e," \u2014 "),Xj=n(P9e,"A",{href:!0});var Kft=s(Xj);nEo=r(Kft,"VisualBertModel"),Kft.forEach(t),sEo=r(P9e," (VisualBERT model)"),P9e.forEach(t),lEo=i($),pu=n($,"LI",{});var B9e=s(pu);Lce=n(B9e,"STRONG",{});var Zft=s(Lce);iEo=r(Zft,"vit"),Zft.forEach(t),dEo=r(B9e," \u2014 "),zj=n(B9e,"A",{href:!0});var emt=s(zj);cEo=r(emt,"ViTModel"),emt.forEach(t),fEo=r(B9e," (ViT model)"),B9e.forEach(t),mEo=i($),_u=n($,"LI",{});var I9e=s(_u);yce=n(I9e,"STRONG",{});var omt=s(yce);gEo=r(omt,"vit_mae"),omt.forEach(t),hEo=r(I9e," \u2014 "),Qj=n(I9e,"A",{href:!0});var rmt=s(Qj);pEo=r(rmt,"ViTMAEModel"),rmt.forEach(t),_Eo=r(I9e," (ViTMAE model)"),I9e.forEach(t),uEo=i($),uu=n($,"LI",{});var N9e=s(uu);xce=n(N9e,"STRONG",{});var tmt=s(xce);bEo=r(tmt,"wav2vec2"),tmt.forEach(t),vEo=r(N9e," \u2014 "),Wj=n(N9e,"A",{href:!0});var amt=s(Wj);FEo=r(amt,"Wav2Vec2Model"),amt.forEach(t),TEo=r(N9e," (Wav2Vec2 model)"),N9e.forEach(t),MEo=i($),bu=n($,"LI",{});var q9e=s(bu);$ce=n(q9e,"STRONG",{});var nmt=s($ce);EEo=r(nmt,"wav2vec2-conformer"),nmt.forEach(t),CEo=r(q9e," \u2014 "),Hj=n(q9e,"A",{href:!0});var smt=s(Hj);wEo=r(smt,"Wav2Vec2ConformerModel"),smt.forEach(t),AEo=r(q9e," (Wav2Vec2-Conformer model)"),q9e.forEach(t),LEo=i($),vu=n($,"LI",{});var j9e=s(vu);kce=n(j9e,"STRONG",{});var lmt=s(kce);yEo=r(lmt,"wavlm"),lmt.forEach(t),xEo=r(j9e," \u2014 "),Uj=n(j9e,"A",{href:!0});var imt=s(Uj);$Eo=r(imt,"WavLMModel"),imt.forEach(t),kEo=r(j9e," (WavLM model)"),j9e.forEach(t),SEo=i($),Fu=n($,"LI",{});var D9e=s(Fu);Sce=n(D9e,"STRONG",{});var dmt=s(Sce);REo=r(dmt,"xglm"),dmt.forEach(t),PEo=r(D9e," \u2014 "),Jj=n(D9e,"A",{href:!0});var cmt=s(Jj);BEo=r(cmt,"XGLMModel"),cmt.forEach(t),IEo=r(D9e," (XGLM model)"),D9e.forEach(t),NEo=i($),Tu=n($,"LI",{});var G9e=s(Tu);Rce=n(G9e,"STRONG",{});var fmt=s(Rce);qEo=r(fmt,"xlm"),fmt.forEach(t),jEo=r(G9e," \u2014 "),Yj=n(G9e,"A",{href:!0});var mmt=s(Yj);DEo=r(mmt,"XLMModel"),mmt.forEach(t),GEo=r(G9e," (XLM model)"),G9e.forEach(t),OEo=i($),Mu=n($,"LI",{});var O9e=s(Mu);Pce=n(O9e,"STRONG",{});var gmt=s(Pce);VEo=r(gmt,"xlm-prophetnet"),gmt.forEach(t),XEo=r(O9e," \u2014 "),Kj=n(O9e,"A",{href:!0});var hmt=s(Kj);zEo=r(hmt,"XLMProphetNetModel"),hmt.forEach(t),QEo=r(O9e," (XLM-ProphetNet model)"),O9e.forEach(t),WEo=i($),Eu=n($,"LI",{});var V9e=s(Eu);Bce=n(V9e,"STRONG",{});var pmt=s(Bce);HEo=r(pmt,"xlm-roberta"),pmt.forEach(t),UEo=r(V9e," \u2014 "),Zj=n(V9e,"A",{href:!0});var _mt=s(Zj);JEo=r(_mt,"XLMRobertaModel"),_mt.forEach(t),YEo=r(V9e," (XLM-RoBERTa model)"),V9e.forEach(t),KEo=i($),Cu=n($,"LI",{});var X9e=s(Cu);Ice=n(X9e,"STRONG",{});var umt=s(Ice);ZEo=r(umt,"xlm-roberta-xl"),umt.forEach(t),eCo=r(X9e," \u2014 "),eD=n(X9e,"A",{href:!0});var bmt=s(eD);oCo=r(bmt,"XLMRobertaXLModel"),bmt.forEach(t),rCo=r(X9e," (XLM-RoBERTa-XL model)"),X9e.forEach(t),tCo=i($),wu=n($,"LI",{});var z9e=s(wu);Nce=n(z9e,"STRONG",{});var vmt=s(Nce);aCo=r(vmt,"xlnet"),vmt.forEach(t),nCo=r(z9e," \u2014 "),oD=n(z9e,"A",{href:!0});var Fmt=s(oD);sCo=r(Fmt,"XLNetModel"),Fmt.forEach(t),lCo=r(z9e," (XLNet model)"),z9e.forEach(t),iCo=i($),Au=n($,"LI",{});var Q9e=s(Au);qce=n(Q9e,"STRONG",{});var Tmt=s(qce);dCo=r(Tmt,"yolos"),Tmt.forEach(t),cCo=r(Q9e," \u2014 "),rD=n(Q9e,"A",{href:!0});var Mmt=s(rD);fCo=r(Mmt,"YolosModel"),Mmt.forEach(t),mCo=r(Q9e," (YOLOS model)"),Q9e.forEach(t),gCo=i($),Lu=n($,"LI",{});var W9e=s(Lu);jce=n(W9e,"STRONG",{});var Emt=s(jce);hCo=r(Emt,"yoso"),Emt.forEach(t),pCo=r(W9e," \u2014 "),tD=n(W9e,"A",{href:!0});var Cmt=s(tD);_Co=r(Cmt,"YosoModel"),Cmt.forEach(t),uCo=r(W9e," (YOSO model)"),W9e.forEach(t),$.forEach(t),bCo=i(aa),yu=n(aa,"P",{});var H9e=s(yu);vCo=r(H9e,"The model is set in evaluation mode by default using "),Dce=n(H9e,"CODE",{});var wmt=s(Dce);FCo=r(wmt,"model.eval()"),wmt.forEach(t),TCo=r(H9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=n(H9e,"CODE",{});var Amt=s(Gce);MCo=r(Amt,"model.train()"),Amt.forEach(t),H9e.forEach(t),ECo=i(aa),T(xu.$$.fragment,aa),aa.forEach(t),Ys.forEach(t),eOe=i(f),qi=n(f,"H2",{class:!0});var sXe=s(qi);$u=n(sXe,"A",{id:!0,class:!0,href:!0});var Lmt=s($u);Oce=n(Lmt,"SPAN",{});var ymt=s(Oce);T(sL.$$.fragment,ymt),ymt.forEach(t),Lmt.forEach(t),CCo=i(sXe),Vce=n(sXe,"SPAN",{});var xmt=s(Vce);wCo=r(xmt,"AutoModelForPreTraining"),xmt.forEach(t),sXe.forEach(t),oOe=i(f),$o=n(f,"DIV",{class:!0});var Ks=s($o);T(lL.$$.fragment,Ks),ACo=i(Ks),ji=n(Ks,"P",{});var Toe=s(ji);LCo=r(Toe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=n(Toe,"A",{href:!0});var $mt=s(aD);yCo=r($mt,"from_pretrained()"),$mt.forEach(t),xCo=r(Toe," class method or the "),nD=n(Toe,"A",{href:!0});var kmt=s(nD);$Co=r(kmt,"from_config()"),kmt.forEach(t),kCo=r(Toe,` class
method.`),Toe.forEach(t),SCo=i(Ks),iL=n(Ks,"P",{});var lXe=s(iL);RCo=r(lXe,"This class cannot be instantiated directly using "),Xce=n(lXe,"CODE",{});var Smt=s(Xce);PCo=r(Smt,"__init__()"),Smt.forEach(t),BCo=r(lXe," (throws an error)."),lXe.forEach(t),ICo=i(Ks),st=n(Ks,"DIV",{class:!0});var R0=s(st);T(dL.$$.fragment,R0),NCo=i(R0),zce=n(R0,"P",{});var Rmt=s(zce);qCo=r(Rmt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Rmt.forEach(t),jCo=i(R0),Di=n(R0,"P",{});var Moe=s(Di);DCo=r(Moe,`Note:
Loading a model from its configuration file does `),Qce=n(Moe,"STRONG",{});var Pmt=s(Qce);GCo=r(Pmt,"not"),Pmt.forEach(t),OCo=r(Moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=n(Moe,"A",{href:!0});var Bmt=s(sD);VCo=r(Bmt,"from_pretrained()"),Bmt.forEach(t),XCo=r(Moe," to load the model weights."),Moe.forEach(t),zCo=i(R0),T(ku.$$.fragment,R0),R0.forEach(t),QCo=i(Ks),Ye=n(Ks,"DIV",{class:!0});var na=s(Ye);T(cL.$$.fragment,na),WCo=i(na),Wce=n(na,"P",{});var Imt=s(Wce);HCo=r(Imt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Imt.forEach(t),UCo=i(na),Pa=n(na,"P",{});var P0=s(Pa);JCo=r(P0,"The model class to instantiate is selected based on the "),Hce=n(P0,"CODE",{});var Nmt=s(Hce);YCo=r(Nmt,"model_type"),Nmt.forEach(t),KCo=r(P0,` property of the config object (either
passed as an argument or loaded from `),Uce=n(P0,"CODE",{});var qmt=s(Uce);ZCo=r(qmt,"pretrained_model_name_or_path"),qmt.forEach(t),e5o=r(P0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=n(P0,"CODE",{});var jmt=s(Jce);o5o=r(jmt,"pretrained_model_name_or_path"),jmt.forEach(t),r5o=r(P0,":"),P0.forEach(t),t5o=i(na),G=n(na,"UL",{});var O=s(G);Su=n(O,"LI",{});var U9e=s(Su);Yce=n(U9e,"STRONG",{});var Dmt=s(Yce);a5o=r(Dmt,"albert"),Dmt.forEach(t),n5o=r(U9e," \u2014 "),lD=n(U9e,"A",{href:!0});var Gmt=s(lD);s5o=r(Gmt,"AlbertForPreTraining"),Gmt.forEach(t),l5o=r(U9e," (ALBERT model)"),U9e.forEach(t),i5o=i(O),Ru=n(O,"LI",{});var J9e=s(Ru);Kce=n(J9e,"STRONG",{});var Omt=s(Kce);d5o=r(Omt,"bart"),Omt.forEach(t),c5o=r(J9e," \u2014 "),iD=n(J9e,"A",{href:!0});var Vmt=s(iD);f5o=r(Vmt,"BartForConditionalGeneration"),Vmt.forEach(t),m5o=r(J9e," (BART model)"),J9e.forEach(t),g5o=i(O),Pu=n(O,"LI",{});var Y9e=s(Pu);Zce=n(Y9e,"STRONG",{});var Xmt=s(Zce);h5o=r(Xmt,"bert"),Xmt.forEach(t),p5o=r(Y9e," \u2014 "),dD=n(Y9e,"A",{href:!0});var zmt=s(dD);_5o=r(zmt,"BertForPreTraining"),zmt.forEach(t),u5o=r(Y9e," (BERT model)"),Y9e.forEach(t),b5o=i(O),Bu=n(O,"LI",{});var K9e=s(Bu);efe=n(K9e,"STRONG",{});var Qmt=s(efe);v5o=r(Qmt,"big_bird"),Qmt.forEach(t),F5o=r(K9e," \u2014 "),cD=n(K9e,"A",{href:!0});var Wmt=s(cD);T5o=r(Wmt,"BigBirdForPreTraining"),Wmt.forEach(t),M5o=r(K9e," (BigBird model)"),K9e.forEach(t),E5o=i(O),Iu=n(O,"LI",{});var Z9e=s(Iu);ofe=n(Z9e,"STRONG",{});var Hmt=s(ofe);C5o=r(Hmt,"bloom"),Hmt.forEach(t),w5o=r(Z9e," \u2014 "),fD=n(Z9e,"A",{href:!0});var Umt=s(fD);A5o=r(Umt,"BloomForCausalLM"),Umt.forEach(t),L5o=r(Z9e," (BLOOM model)"),Z9e.forEach(t),y5o=i(O),Nu=n(O,"LI",{});var exe=s(Nu);rfe=n(exe,"STRONG",{});var Jmt=s(rfe);x5o=r(Jmt,"camembert"),Jmt.forEach(t),$5o=r(exe," \u2014 "),mD=n(exe,"A",{href:!0});var Ymt=s(mD);k5o=r(Ymt,"CamembertForMaskedLM"),Ymt.forEach(t),S5o=r(exe," (CamemBERT model)"),exe.forEach(t),R5o=i(O),qu=n(O,"LI",{});var oxe=s(qu);tfe=n(oxe,"STRONG",{});var Kmt=s(tfe);P5o=r(Kmt,"ctrl"),Kmt.forEach(t),B5o=r(oxe," \u2014 "),gD=n(oxe,"A",{href:!0});var Zmt=s(gD);I5o=r(Zmt,"CTRLLMHeadModel"),Zmt.forEach(t),N5o=r(oxe," (CTRL model)"),oxe.forEach(t),q5o=i(O),ju=n(O,"LI",{});var rxe=s(ju);afe=n(rxe,"STRONG",{});var egt=s(afe);j5o=r(egt,"data2vec-text"),egt.forEach(t),D5o=r(rxe," \u2014 "),hD=n(rxe,"A",{href:!0});var ogt=s(hD);G5o=r(ogt,"Data2VecTextForMaskedLM"),ogt.forEach(t),O5o=r(rxe," (Data2VecText model)"),rxe.forEach(t),V5o=i(O),Du=n(O,"LI",{});var txe=s(Du);nfe=n(txe,"STRONG",{});var rgt=s(nfe);X5o=r(rgt,"deberta"),rgt.forEach(t),z5o=r(txe," \u2014 "),pD=n(txe,"A",{href:!0});var tgt=s(pD);Q5o=r(tgt,"DebertaForMaskedLM"),tgt.forEach(t),W5o=r(txe," (DeBERTa model)"),txe.forEach(t),H5o=i(O),Gu=n(O,"LI",{});var axe=s(Gu);sfe=n(axe,"STRONG",{});var agt=s(sfe);U5o=r(agt,"deberta-v2"),agt.forEach(t),J5o=r(axe," \u2014 "),_D=n(axe,"A",{href:!0});var ngt=s(_D);Y5o=r(ngt,"DebertaV2ForMaskedLM"),ngt.forEach(t),K5o=r(axe," (DeBERTa-v2 model)"),axe.forEach(t),Z5o=i(O),Ou=n(O,"LI",{});var nxe=s(Ou);lfe=n(nxe,"STRONG",{});var sgt=s(lfe);e3o=r(sgt,"distilbert"),sgt.forEach(t),o3o=r(nxe," \u2014 "),uD=n(nxe,"A",{href:!0});var lgt=s(uD);r3o=r(lgt,"DistilBertForMaskedLM"),lgt.forEach(t),t3o=r(nxe," (DistilBERT model)"),nxe.forEach(t),a3o=i(O),Vu=n(O,"LI",{});var sxe=s(Vu);ife=n(sxe,"STRONG",{});var igt=s(ife);n3o=r(igt,"electra"),igt.forEach(t),s3o=r(sxe," \u2014 "),bD=n(sxe,"A",{href:!0});var dgt=s(bD);l3o=r(dgt,"ElectraForPreTraining"),dgt.forEach(t),i3o=r(sxe," (ELECTRA model)"),sxe.forEach(t),d3o=i(O),Xu=n(O,"LI",{});var lxe=s(Xu);dfe=n(lxe,"STRONG",{});var cgt=s(dfe);c3o=r(cgt,"flaubert"),cgt.forEach(t),f3o=r(lxe," \u2014 "),vD=n(lxe,"A",{href:!0});var fgt=s(vD);m3o=r(fgt,"FlaubertWithLMHeadModel"),fgt.forEach(t),g3o=r(lxe," (FlauBERT model)"),lxe.forEach(t),h3o=i(O),zu=n(O,"LI",{});var ixe=s(zu);cfe=n(ixe,"STRONG",{});var mgt=s(cfe);p3o=r(mgt,"flava"),mgt.forEach(t),_3o=r(ixe," \u2014 "),FD=n(ixe,"A",{href:!0});var ggt=s(FD);u3o=r(ggt,"FlavaForPreTraining"),ggt.forEach(t),b3o=r(ixe," (FLAVA model)"),ixe.forEach(t),v3o=i(O),Qu=n(O,"LI",{});var dxe=s(Qu);ffe=n(dxe,"STRONG",{});var hgt=s(ffe);F3o=r(hgt,"fnet"),hgt.forEach(t),T3o=r(dxe," \u2014 "),TD=n(dxe,"A",{href:!0});var pgt=s(TD);M3o=r(pgt,"FNetForPreTraining"),pgt.forEach(t),E3o=r(dxe," (FNet model)"),dxe.forEach(t),C3o=i(O),Wu=n(O,"LI",{});var cxe=s(Wu);mfe=n(cxe,"STRONG",{});var _gt=s(mfe);w3o=r(_gt,"fsmt"),_gt.forEach(t),A3o=r(cxe," \u2014 "),MD=n(cxe,"A",{href:!0});var ugt=s(MD);L3o=r(ugt,"FSMTForConditionalGeneration"),ugt.forEach(t),y3o=r(cxe," (FairSeq Machine-Translation model)"),cxe.forEach(t),x3o=i(O),Hu=n(O,"LI",{});var fxe=s(Hu);gfe=n(fxe,"STRONG",{});var bgt=s(gfe);$3o=r(bgt,"funnel"),bgt.forEach(t),k3o=r(fxe," \u2014 "),ED=n(fxe,"A",{href:!0});var vgt=s(ED);S3o=r(vgt,"FunnelForPreTraining"),vgt.forEach(t),R3o=r(fxe," (Funnel Transformer model)"),fxe.forEach(t),P3o=i(O),Uu=n(O,"LI",{});var mxe=s(Uu);hfe=n(mxe,"STRONG",{});var Fgt=s(hfe);B3o=r(Fgt,"gpt2"),Fgt.forEach(t),I3o=r(mxe," \u2014 "),CD=n(mxe,"A",{href:!0});var Tgt=s(CD);N3o=r(Tgt,"GPT2LMHeadModel"),Tgt.forEach(t),q3o=r(mxe," (OpenAI GPT-2 model)"),mxe.forEach(t),j3o=i(O),Ju=n(O,"LI",{});var gxe=s(Ju);pfe=n(gxe,"STRONG",{});var Mgt=s(pfe);D3o=r(Mgt,"ibert"),Mgt.forEach(t),G3o=r(gxe," \u2014 "),wD=n(gxe,"A",{href:!0});var Egt=s(wD);O3o=r(Egt,"IBertForMaskedLM"),Egt.forEach(t),V3o=r(gxe," (I-BERT model)"),gxe.forEach(t),X3o=i(O),Yu=n(O,"LI",{});var hxe=s(Yu);_fe=n(hxe,"STRONG",{});var Cgt=s(_fe);z3o=r(Cgt,"layoutlm"),Cgt.forEach(t),Q3o=r(hxe," \u2014 "),AD=n(hxe,"A",{href:!0});var wgt=s(AD);W3o=r(wgt,"LayoutLMForMaskedLM"),wgt.forEach(t),H3o=r(hxe," (LayoutLM model)"),hxe.forEach(t),U3o=i(O),Ku=n(O,"LI",{});var pxe=s(Ku);ufe=n(pxe,"STRONG",{});var Agt=s(ufe);J3o=r(Agt,"longformer"),Agt.forEach(t),Y3o=r(pxe," \u2014 "),LD=n(pxe,"A",{href:!0});var Lgt=s(LD);K3o=r(Lgt,"LongformerForMaskedLM"),Lgt.forEach(t),Z3o=r(pxe," (Longformer model)"),pxe.forEach(t),e0o=i(O),Zu=n(O,"LI",{});var _xe=s(Zu);bfe=n(_xe,"STRONG",{});var ygt=s(bfe);o0o=r(ygt,"lxmert"),ygt.forEach(t),r0o=r(_xe," \u2014 "),yD=n(_xe,"A",{href:!0});var xgt=s(yD);t0o=r(xgt,"LxmertForPreTraining"),xgt.forEach(t),a0o=r(_xe," (LXMERT model)"),_xe.forEach(t),n0o=i(O),e1=n(O,"LI",{});var uxe=s(e1);vfe=n(uxe,"STRONG",{});var $gt=s(vfe);s0o=r($gt,"megatron-bert"),$gt.forEach(t),l0o=r(uxe," \u2014 "),xD=n(uxe,"A",{href:!0});var kgt=s(xD);i0o=r(kgt,"MegatronBertForPreTraining"),kgt.forEach(t),d0o=r(uxe," (Megatron-BERT model)"),uxe.forEach(t),c0o=i(O),o1=n(O,"LI",{});var bxe=s(o1);Ffe=n(bxe,"STRONG",{});var Sgt=s(Ffe);f0o=r(Sgt,"mobilebert"),Sgt.forEach(t),m0o=r(bxe," \u2014 "),$D=n(bxe,"A",{href:!0});var Rgt=s($D);g0o=r(Rgt,"MobileBertForPreTraining"),Rgt.forEach(t),h0o=r(bxe," (MobileBERT model)"),bxe.forEach(t),p0o=i(O),r1=n(O,"LI",{});var vxe=s(r1);Tfe=n(vxe,"STRONG",{});var Pgt=s(Tfe);_0o=r(Pgt,"mpnet"),Pgt.forEach(t),u0o=r(vxe," \u2014 "),kD=n(vxe,"A",{href:!0});var Bgt=s(kD);b0o=r(Bgt,"MPNetForMaskedLM"),Bgt.forEach(t),v0o=r(vxe," (MPNet model)"),vxe.forEach(t),F0o=i(O),t1=n(O,"LI",{});var Fxe=s(t1);Mfe=n(Fxe,"STRONG",{});var Igt=s(Mfe);T0o=r(Igt,"nezha"),Igt.forEach(t),M0o=r(Fxe," \u2014 "),SD=n(Fxe,"A",{href:!0});var Ngt=s(SD);E0o=r(Ngt,"NezhaForPreTraining"),Ngt.forEach(t),C0o=r(Fxe," (Nezha model)"),Fxe.forEach(t),w0o=i(O),a1=n(O,"LI",{});var Txe=s(a1);Efe=n(Txe,"STRONG",{});var qgt=s(Efe);A0o=r(qgt,"openai-gpt"),qgt.forEach(t),L0o=r(Txe," \u2014 "),RD=n(Txe,"A",{href:!0});var jgt=s(RD);y0o=r(jgt,"OpenAIGPTLMHeadModel"),jgt.forEach(t),x0o=r(Txe," (OpenAI GPT model)"),Txe.forEach(t),$0o=i(O),n1=n(O,"LI",{});var Mxe=s(n1);Cfe=n(Mxe,"STRONG",{});var Dgt=s(Cfe);k0o=r(Dgt,"retribert"),Dgt.forEach(t),S0o=r(Mxe," \u2014 "),PD=n(Mxe,"A",{href:!0});var Ggt=s(PD);R0o=r(Ggt,"RetriBertModel"),Ggt.forEach(t),P0o=r(Mxe," (RetriBERT model)"),Mxe.forEach(t),B0o=i(O),s1=n(O,"LI",{});var Exe=s(s1);wfe=n(Exe,"STRONG",{});var Ogt=s(wfe);I0o=r(Ogt,"roberta"),Ogt.forEach(t),N0o=r(Exe," \u2014 "),BD=n(Exe,"A",{href:!0});var Vgt=s(BD);q0o=r(Vgt,"RobertaForMaskedLM"),Vgt.forEach(t),j0o=r(Exe," (RoBERTa model)"),Exe.forEach(t),D0o=i(O),l1=n(O,"LI",{});var Cxe=s(l1);Afe=n(Cxe,"STRONG",{});var Xgt=s(Afe);G0o=r(Xgt,"splinter"),Xgt.forEach(t),O0o=r(Cxe," \u2014 "),ID=n(Cxe,"A",{href:!0});var zgt=s(ID);V0o=r(zgt,"SplinterForPreTraining"),zgt.forEach(t),X0o=r(Cxe," (Splinter model)"),Cxe.forEach(t),z0o=i(O),i1=n(O,"LI",{});var wxe=s(i1);Lfe=n(wxe,"STRONG",{});var Qgt=s(Lfe);Q0o=r(Qgt,"squeezebert"),Qgt.forEach(t),W0o=r(wxe," \u2014 "),ND=n(wxe,"A",{href:!0});var Wgt=s(ND);H0o=r(Wgt,"SqueezeBertForMaskedLM"),Wgt.forEach(t),U0o=r(wxe," (SqueezeBERT model)"),wxe.forEach(t),J0o=i(O),d1=n(O,"LI",{});var Axe=s(d1);yfe=n(Axe,"STRONG",{});var Hgt=s(yfe);Y0o=r(Hgt,"t5"),Hgt.forEach(t),K0o=r(Axe," \u2014 "),qD=n(Axe,"A",{href:!0});var Ugt=s(qD);Z0o=r(Ugt,"T5ForConditionalGeneration"),Ugt.forEach(t),ewo=r(Axe," (T5 model)"),Axe.forEach(t),owo=i(O),c1=n(O,"LI",{});var Lxe=s(c1);xfe=n(Lxe,"STRONG",{});var Jgt=s(xfe);rwo=r(Jgt,"tapas"),Jgt.forEach(t),two=r(Lxe," \u2014 "),jD=n(Lxe,"A",{href:!0});var Ygt=s(jD);awo=r(Ygt,"TapasForMaskedLM"),Ygt.forEach(t),nwo=r(Lxe," (TAPAS model)"),Lxe.forEach(t),swo=i(O),f1=n(O,"LI",{});var yxe=s(f1);$fe=n(yxe,"STRONG",{});var Kgt=s($fe);lwo=r(Kgt,"transfo-xl"),Kgt.forEach(t),iwo=r(yxe," \u2014 "),DD=n(yxe,"A",{href:!0});var Zgt=s(DD);dwo=r(Zgt,"TransfoXLLMHeadModel"),Zgt.forEach(t),cwo=r(yxe," (Transformer-XL model)"),yxe.forEach(t),fwo=i(O),m1=n(O,"LI",{});var xxe=s(m1);kfe=n(xxe,"STRONG",{});var eht=s(kfe);mwo=r(eht,"unispeech"),eht.forEach(t),gwo=r(xxe," \u2014 "),GD=n(xxe,"A",{href:!0});var oht=s(GD);hwo=r(oht,"UniSpeechForPreTraining"),oht.forEach(t),pwo=r(xxe," (UniSpeech model)"),xxe.forEach(t),_wo=i(O),g1=n(O,"LI",{});var $xe=s(g1);Sfe=n($xe,"STRONG",{});var rht=s(Sfe);uwo=r(rht,"unispeech-sat"),rht.forEach(t),bwo=r($xe," \u2014 "),OD=n($xe,"A",{href:!0});var tht=s(OD);vwo=r(tht,"UniSpeechSatForPreTraining"),tht.forEach(t),Fwo=r($xe," (UniSpeechSat model)"),$xe.forEach(t),Two=i(O),h1=n(O,"LI",{});var kxe=s(h1);Rfe=n(kxe,"STRONG",{});var aht=s(Rfe);Mwo=r(aht,"visual_bert"),aht.forEach(t),Ewo=r(kxe," \u2014 "),VD=n(kxe,"A",{href:!0});var nht=s(VD);Cwo=r(nht,"VisualBertForPreTraining"),nht.forEach(t),wwo=r(kxe," (VisualBERT model)"),kxe.forEach(t),Awo=i(O),p1=n(O,"LI",{});var Sxe=s(p1);Pfe=n(Sxe,"STRONG",{});var sht=s(Pfe);Lwo=r(sht,"vit_mae"),sht.forEach(t),ywo=r(Sxe," \u2014 "),XD=n(Sxe,"A",{href:!0});var lht=s(XD);xwo=r(lht,"ViTMAEForPreTraining"),lht.forEach(t),$wo=r(Sxe," (ViTMAE model)"),Sxe.forEach(t),kwo=i(O),_1=n(O,"LI",{});var Rxe=s(_1);Bfe=n(Rxe,"STRONG",{});var iht=s(Bfe);Swo=r(iht,"wav2vec2"),iht.forEach(t),Rwo=r(Rxe," \u2014 "),zD=n(Rxe,"A",{href:!0});var dht=s(zD);Pwo=r(dht,"Wav2Vec2ForPreTraining"),dht.forEach(t),Bwo=r(Rxe," (Wav2Vec2 model)"),Rxe.forEach(t),Iwo=i(O),u1=n(O,"LI",{});var Pxe=s(u1);Ife=n(Pxe,"STRONG",{});var cht=s(Ife);Nwo=r(cht,"wav2vec2-conformer"),cht.forEach(t),qwo=r(Pxe," \u2014 "),QD=n(Pxe,"A",{href:!0});var fht=s(QD);jwo=r(fht,"Wav2Vec2ConformerForPreTraining"),fht.forEach(t),Dwo=r(Pxe," (Wav2Vec2-Conformer model)"),Pxe.forEach(t),Gwo=i(O),b1=n(O,"LI",{});var Bxe=s(b1);Nfe=n(Bxe,"STRONG",{});var mht=s(Nfe);Owo=r(mht,"xlm"),mht.forEach(t),Vwo=r(Bxe," \u2014 "),WD=n(Bxe,"A",{href:!0});var ght=s(WD);Xwo=r(ght,"XLMWithLMHeadModel"),ght.forEach(t),zwo=r(Bxe," (XLM model)"),Bxe.forEach(t),Qwo=i(O),v1=n(O,"LI",{});var Ixe=s(v1);qfe=n(Ixe,"STRONG",{});var hht=s(qfe);Wwo=r(hht,"xlm-roberta"),hht.forEach(t),Hwo=r(Ixe," \u2014 "),HD=n(Ixe,"A",{href:!0});var pht=s(HD);Uwo=r(pht,"XLMRobertaForMaskedLM"),pht.forEach(t),Jwo=r(Ixe," (XLM-RoBERTa model)"),Ixe.forEach(t),Ywo=i(O),F1=n(O,"LI",{});var Nxe=s(F1);jfe=n(Nxe,"STRONG",{});var _ht=s(jfe);Kwo=r(_ht,"xlm-roberta-xl"),_ht.forEach(t),Zwo=r(Nxe," \u2014 "),UD=n(Nxe,"A",{href:!0});var uht=s(UD);eAo=r(uht,"XLMRobertaXLForMaskedLM"),uht.forEach(t),oAo=r(Nxe," (XLM-RoBERTa-XL model)"),Nxe.forEach(t),rAo=i(O),T1=n(O,"LI",{});var qxe=s(T1);Dfe=n(qxe,"STRONG",{});var bht=s(Dfe);tAo=r(bht,"xlnet"),bht.forEach(t),aAo=r(qxe," \u2014 "),JD=n(qxe,"A",{href:!0});var vht=s(JD);nAo=r(vht,"XLNetLMHeadModel"),vht.forEach(t),sAo=r(qxe," (XLNet model)"),qxe.forEach(t),O.forEach(t),lAo=i(na),M1=n(na,"P",{});var jxe=s(M1);iAo=r(jxe,"The model is set in evaluation mode by default using "),Gfe=n(jxe,"CODE",{});var Fht=s(Gfe);dAo=r(Fht,"model.eval()"),Fht.forEach(t),cAo=r(jxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=n(jxe,"CODE",{});var Tht=s(Ofe);fAo=r(Tht,"model.train()"),Tht.forEach(t),jxe.forEach(t),mAo=i(na),T(E1.$$.fragment,na),na.forEach(t),Ks.forEach(t),rOe=i(f),Gi=n(f,"H2",{class:!0});var iXe=s(Gi);C1=n(iXe,"A",{id:!0,class:!0,href:!0});var Mht=s(C1);Vfe=n(Mht,"SPAN",{});var Eht=s(Vfe);T(fL.$$.fragment,Eht),Eht.forEach(t),Mht.forEach(t),gAo=i(iXe),Xfe=n(iXe,"SPAN",{});var Cht=s(Xfe);hAo=r(Cht,"AutoModelForCausalLM"),Cht.forEach(t),iXe.forEach(t),tOe=i(f),ko=n(f,"DIV",{class:!0});var Zs=s(ko);T(mL.$$.fragment,Zs),pAo=i(Zs),Oi=n(Zs,"P",{});var Eoe=s(Oi);_Ao=r(Eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=n(Eoe,"A",{href:!0});var wht=s(YD);uAo=r(wht,"from_pretrained()"),wht.forEach(t),bAo=r(Eoe," class method or the "),KD=n(Eoe,"A",{href:!0});var Aht=s(KD);vAo=r(Aht,"from_config()"),Aht.forEach(t),FAo=r(Eoe,` class
method.`),Eoe.forEach(t),TAo=i(Zs),gL=n(Zs,"P",{});var dXe=s(gL);MAo=r(dXe,"This class cannot be instantiated directly using "),zfe=n(dXe,"CODE",{});var Lht=s(zfe);EAo=r(Lht,"__init__()"),Lht.forEach(t),CAo=r(dXe," (throws an error)."),dXe.forEach(t),wAo=i(Zs),lt=n(Zs,"DIV",{class:!0});var B0=s(lt);T(hL.$$.fragment,B0),AAo=i(B0),Qfe=n(B0,"P",{});var yht=s(Qfe);LAo=r(yht,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yht.forEach(t),yAo=i(B0),Vi=n(B0,"P",{});var Coe=s(Vi);xAo=r(Coe,`Note:
Loading a model from its configuration file does `),Wfe=n(Coe,"STRONG",{});var xht=s(Wfe);$Ao=r(xht,"not"),xht.forEach(t),kAo=r(Coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=n(Coe,"A",{href:!0});var $ht=s(ZD);SAo=r($ht,"from_pretrained()"),$ht.forEach(t),RAo=r(Coe," to load the model weights."),Coe.forEach(t),PAo=i(B0),T(w1.$$.fragment,B0),B0.forEach(t),BAo=i(Zs),Ke=n(Zs,"DIV",{class:!0});var sa=s(Ke);T(pL.$$.fragment,sa),IAo=i(sa),Hfe=n(sa,"P",{});var kht=s(Hfe);NAo=r(kht,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kht.forEach(t),qAo=i(sa),Ba=n(sa,"P",{});var I0=s(Ba);jAo=r(I0,"The model class to instantiate is selected based on the "),Ufe=n(I0,"CODE",{});var Sht=s(Ufe);DAo=r(Sht,"model_type"),Sht.forEach(t),GAo=r(I0,` property of the config object (either
passed as an argument or loaded from `),Jfe=n(I0,"CODE",{});var Rht=s(Jfe);OAo=r(Rht,"pretrained_model_name_or_path"),Rht.forEach(t),VAo=r(I0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=n(I0,"CODE",{});var Pht=s(Yfe);XAo=r(Pht,"pretrained_model_name_or_path"),Pht.forEach(t),zAo=r(I0,":"),I0.forEach(t),QAo=i(sa),z=n(sa,"UL",{});var W=s(z);A1=n(W,"LI",{});var Dxe=s(A1);Kfe=n(Dxe,"STRONG",{});var Bht=s(Kfe);WAo=r(Bht,"bart"),Bht.forEach(t),HAo=r(Dxe," \u2014 "),eG=n(Dxe,"A",{href:!0});var Iht=s(eG);UAo=r(Iht,"BartForCausalLM"),Iht.forEach(t),JAo=r(Dxe," (BART model)"),Dxe.forEach(t),YAo=i(W),L1=n(W,"LI",{});var Gxe=s(L1);Zfe=n(Gxe,"STRONG",{});var Nht=s(Zfe);KAo=r(Nht,"bert"),Nht.forEach(t),ZAo=r(Gxe," \u2014 "),oG=n(Gxe,"A",{href:!0});var qht=s(oG);eLo=r(qht,"BertLMHeadModel"),qht.forEach(t),oLo=r(Gxe," (BERT model)"),Gxe.forEach(t),rLo=i(W),y1=n(W,"LI",{});var Oxe=s(y1);eme=n(Oxe,"STRONG",{});var jht=s(eme);tLo=r(jht,"bert-generation"),jht.forEach(t),aLo=r(Oxe," \u2014 "),rG=n(Oxe,"A",{href:!0});var Dht=s(rG);nLo=r(Dht,"BertGenerationDecoder"),Dht.forEach(t),sLo=r(Oxe," (Bert Generation model)"),Oxe.forEach(t),lLo=i(W),x1=n(W,"LI",{});var Vxe=s(x1);ome=n(Vxe,"STRONG",{});var Ght=s(ome);iLo=r(Ght,"big_bird"),Ght.forEach(t),dLo=r(Vxe," \u2014 "),tG=n(Vxe,"A",{href:!0});var Oht=s(tG);cLo=r(Oht,"BigBirdForCausalLM"),Oht.forEach(t),fLo=r(Vxe," (BigBird model)"),Vxe.forEach(t),mLo=i(W),$1=n(W,"LI",{});var Xxe=s($1);rme=n(Xxe,"STRONG",{});var Vht=s(rme);gLo=r(Vht,"bigbird_pegasus"),Vht.forEach(t),hLo=r(Xxe," \u2014 "),aG=n(Xxe,"A",{href:!0});var Xht=s(aG);pLo=r(Xht,"BigBirdPegasusForCausalLM"),Xht.forEach(t),_Lo=r(Xxe," (BigBird-Pegasus model)"),Xxe.forEach(t),uLo=i(W),k1=n(W,"LI",{});var zxe=s(k1);tme=n(zxe,"STRONG",{});var zht=s(tme);bLo=r(zht,"blenderbot"),zht.forEach(t),vLo=r(zxe," \u2014 "),nG=n(zxe,"A",{href:!0});var Qht=s(nG);FLo=r(Qht,"BlenderbotForCausalLM"),Qht.forEach(t),TLo=r(zxe," (Blenderbot model)"),zxe.forEach(t),MLo=i(W),S1=n(W,"LI",{});var Qxe=s(S1);ame=n(Qxe,"STRONG",{});var Wht=s(ame);ELo=r(Wht,"blenderbot-small"),Wht.forEach(t),CLo=r(Qxe," \u2014 "),sG=n(Qxe,"A",{href:!0});var Hht=s(sG);wLo=r(Hht,"BlenderbotSmallForCausalLM"),Hht.forEach(t),ALo=r(Qxe," (BlenderbotSmall model)"),Qxe.forEach(t),LLo=i(W),R1=n(W,"LI",{});var Wxe=s(R1);nme=n(Wxe,"STRONG",{});var Uht=s(nme);yLo=r(Uht,"bloom"),Uht.forEach(t),xLo=r(Wxe," \u2014 "),lG=n(Wxe,"A",{href:!0});var Jht=s(lG);$Lo=r(Jht,"BloomForCausalLM"),Jht.forEach(t),kLo=r(Wxe," (BLOOM model)"),Wxe.forEach(t),SLo=i(W),P1=n(W,"LI",{});var Hxe=s(P1);sme=n(Hxe,"STRONG",{});var Yht=s(sme);RLo=r(Yht,"camembert"),Yht.forEach(t),PLo=r(Hxe," \u2014 "),iG=n(Hxe,"A",{href:!0});var Kht=s(iG);BLo=r(Kht,"CamembertForCausalLM"),Kht.forEach(t),ILo=r(Hxe," (CamemBERT model)"),Hxe.forEach(t),NLo=i(W),B1=n(W,"LI",{});var Uxe=s(B1);lme=n(Uxe,"STRONG",{});var Zht=s(lme);qLo=r(Zht,"ctrl"),Zht.forEach(t),jLo=r(Uxe," \u2014 "),dG=n(Uxe,"A",{href:!0});var ept=s(dG);DLo=r(ept,"CTRLLMHeadModel"),ept.forEach(t),GLo=r(Uxe," (CTRL model)"),Uxe.forEach(t),OLo=i(W),I1=n(W,"LI",{});var Jxe=s(I1);ime=n(Jxe,"STRONG",{});var opt=s(ime);VLo=r(opt,"data2vec-text"),opt.forEach(t),XLo=r(Jxe," \u2014 "),cG=n(Jxe,"A",{href:!0});var rpt=s(cG);zLo=r(rpt,"Data2VecTextForCausalLM"),rpt.forEach(t),QLo=r(Jxe," (Data2VecText model)"),Jxe.forEach(t),WLo=i(W),N1=n(W,"LI",{});var Yxe=s(N1);dme=n(Yxe,"STRONG",{});var tpt=s(dme);HLo=r(tpt,"electra"),tpt.forEach(t),ULo=r(Yxe," \u2014 "),fG=n(Yxe,"A",{href:!0});var apt=s(fG);JLo=r(apt,"ElectraForCausalLM"),apt.forEach(t),YLo=r(Yxe," (ELECTRA model)"),Yxe.forEach(t),KLo=i(W),q1=n(W,"LI",{});var Kxe=s(q1);cme=n(Kxe,"STRONG",{});var npt=s(cme);ZLo=r(npt,"gpt2"),npt.forEach(t),eyo=r(Kxe," \u2014 "),mG=n(Kxe,"A",{href:!0});var spt=s(mG);oyo=r(spt,"GPT2LMHeadModel"),spt.forEach(t),ryo=r(Kxe," (OpenAI GPT-2 model)"),Kxe.forEach(t),tyo=i(W),j1=n(W,"LI",{});var Zxe=s(j1);fme=n(Zxe,"STRONG",{});var lpt=s(fme);ayo=r(lpt,"gpt_neo"),lpt.forEach(t),nyo=r(Zxe," \u2014 "),gG=n(Zxe,"A",{href:!0});var ipt=s(gG);syo=r(ipt,"GPTNeoForCausalLM"),ipt.forEach(t),lyo=r(Zxe," (GPT Neo model)"),Zxe.forEach(t),iyo=i(W),D1=n(W,"LI",{});var e$e=s(D1);mme=n(e$e,"STRONG",{});var dpt=s(mme);dyo=r(dpt,"gpt_neox"),dpt.forEach(t),cyo=r(e$e," \u2014 "),hG=n(e$e,"A",{href:!0});var cpt=s(hG);fyo=r(cpt,"GPTNeoXForCausalLM"),cpt.forEach(t),myo=r(e$e," (GPT NeoX model)"),e$e.forEach(t),gyo=i(W),G1=n(W,"LI",{});var o$e=s(G1);gme=n(o$e,"STRONG",{});var fpt=s(gme);hyo=r(fpt,"gptj"),fpt.forEach(t),pyo=r(o$e," \u2014 "),pG=n(o$e,"A",{href:!0});var mpt=s(pG);_yo=r(mpt,"GPTJForCausalLM"),mpt.forEach(t),uyo=r(o$e," (GPT-J model)"),o$e.forEach(t),byo=i(W),O1=n(W,"LI",{});var r$e=s(O1);hme=n(r$e,"STRONG",{});var gpt=s(hme);vyo=r(gpt,"marian"),gpt.forEach(t),Fyo=r(r$e," \u2014 "),_G=n(r$e,"A",{href:!0});var hpt=s(_G);Tyo=r(hpt,"MarianForCausalLM"),hpt.forEach(t),Myo=r(r$e," (Marian model)"),r$e.forEach(t),Eyo=i(W),V1=n(W,"LI",{});var t$e=s(V1);pme=n(t$e,"STRONG",{});var ppt=s(pme);Cyo=r(ppt,"mbart"),ppt.forEach(t),wyo=r(t$e," \u2014 "),uG=n(t$e,"A",{href:!0});var _pt=s(uG);Ayo=r(_pt,"MBartForCausalLM"),_pt.forEach(t),Lyo=r(t$e," (mBART model)"),t$e.forEach(t),yyo=i(W),X1=n(W,"LI",{});var a$e=s(X1);_me=n(a$e,"STRONG",{});var upt=s(_me);xyo=r(upt,"megatron-bert"),upt.forEach(t),$yo=r(a$e," \u2014 "),bG=n(a$e,"A",{href:!0});var bpt=s(bG);kyo=r(bpt,"MegatronBertForCausalLM"),bpt.forEach(t),Syo=r(a$e," (Megatron-BERT model)"),a$e.forEach(t),Ryo=i(W),z1=n(W,"LI",{});var n$e=s(z1);ume=n(n$e,"STRONG",{});var vpt=s(ume);Pyo=r(vpt,"openai-gpt"),vpt.forEach(t),Byo=r(n$e," \u2014 "),vG=n(n$e,"A",{href:!0});var Fpt=s(vG);Iyo=r(Fpt,"OpenAIGPTLMHeadModel"),Fpt.forEach(t),Nyo=r(n$e," (OpenAI GPT model)"),n$e.forEach(t),qyo=i(W),Q1=n(W,"LI",{});var s$e=s(Q1);bme=n(s$e,"STRONG",{});var Tpt=s(bme);jyo=r(Tpt,"opt"),Tpt.forEach(t),Dyo=r(s$e," \u2014 "),FG=n(s$e,"A",{href:!0});var Mpt=s(FG);Gyo=r(Mpt,"OPTForCausalLM"),Mpt.forEach(t),Oyo=r(s$e," (OPT model)"),s$e.forEach(t),Vyo=i(W),W1=n(W,"LI",{});var l$e=s(W1);vme=n(l$e,"STRONG",{});var Ept=s(vme);Xyo=r(Ept,"pegasus"),Ept.forEach(t),zyo=r(l$e," \u2014 "),TG=n(l$e,"A",{href:!0});var Cpt=s(TG);Qyo=r(Cpt,"PegasusForCausalLM"),Cpt.forEach(t),Wyo=r(l$e," (Pegasus model)"),l$e.forEach(t),Hyo=i(W),H1=n(W,"LI",{});var i$e=s(H1);Fme=n(i$e,"STRONG",{});var wpt=s(Fme);Uyo=r(wpt,"plbart"),wpt.forEach(t),Jyo=r(i$e," \u2014 "),MG=n(i$e,"A",{href:!0});var Apt=s(MG);Yyo=r(Apt,"PLBartForCausalLM"),Apt.forEach(t),Kyo=r(i$e," (PLBart model)"),i$e.forEach(t),Zyo=i(W),U1=n(W,"LI",{});var d$e=s(U1);Tme=n(d$e,"STRONG",{});var Lpt=s(Tme);e9o=r(Lpt,"prophetnet"),Lpt.forEach(t),o9o=r(d$e," \u2014 "),EG=n(d$e,"A",{href:!0});var ypt=s(EG);r9o=r(ypt,"ProphetNetForCausalLM"),ypt.forEach(t),t9o=r(d$e," (ProphetNet model)"),d$e.forEach(t),a9o=i(W),J1=n(W,"LI",{});var c$e=s(J1);Mme=n(c$e,"STRONG",{});var xpt=s(Mme);n9o=r(xpt,"qdqbert"),xpt.forEach(t),s9o=r(c$e," \u2014 "),CG=n(c$e,"A",{href:!0});var $pt=s(CG);l9o=r($pt,"QDQBertLMHeadModel"),$pt.forEach(t),i9o=r(c$e," (QDQBert model)"),c$e.forEach(t),d9o=i(W),Y1=n(W,"LI",{});var f$e=s(Y1);Eme=n(f$e,"STRONG",{});var kpt=s(Eme);c9o=r(kpt,"reformer"),kpt.forEach(t),f9o=r(f$e," \u2014 "),wG=n(f$e,"A",{href:!0});var Spt=s(wG);m9o=r(Spt,"ReformerModelWithLMHead"),Spt.forEach(t),g9o=r(f$e," (Reformer model)"),f$e.forEach(t),h9o=i(W),K1=n(W,"LI",{});var m$e=s(K1);Cme=n(m$e,"STRONG",{});var Rpt=s(Cme);p9o=r(Rpt,"rembert"),Rpt.forEach(t),_9o=r(m$e," \u2014 "),AG=n(m$e,"A",{href:!0});var Ppt=s(AG);u9o=r(Ppt,"RemBertForCausalLM"),Ppt.forEach(t),b9o=r(m$e," (RemBERT model)"),m$e.forEach(t),v9o=i(W),Z1=n(W,"LI",{});var g$e=s(Z1);wme=n(g$e,"STRONG",{});var Bpt=s(wme);F9o=r(Bpt,"roberta"),Bpt.forEach(t),T9o=r(g$e," \u2014 "),LG=n(g$e,"A",{href:!0});var Ipt=s(LG);M9o=r(Ipt,"RobertaForCausalLM"),Ipt.forEach(t),E9o=r(g$e," (RoBERTa model)"),g$e.forEach(t),C9o=i(W),e2=n(W,"LI",{});var h$e=s(e2);Ame=n(h$e,"STRONG",{});var Npt=s(Ame);w9o=r(Npt,"roformer"),Npt.forEach(t),A9o=r(h$e," \u2014 "),yG=n(h$e,"A",{href:!0});var qpt=s(yG);L9o=r(qpt,"RoFormerForCausalLM"),qpt.forEach(t),y9o=r(h$e," (RoFormer model)"),h$e.forEach(t),x9o=i(W),o2=n(W,"LI",{});var p$e=s(o2);Lme=n(p$e,"STRONG",{});var jpt=s(Lme);$9o=r(jpt,"speech_to_text_2"),jpt.forEach(t),k9o=r(p$e," \u2014 "),xG=n(p$e,"A",{href:!0});var Dpt=s(xG);S9o=r(Dpt,"Speech2Text2ForCausalLM"),Dpt.forEach(t),R9o=r(p$e," (Speech2Text2 model)"),p$e.forEach(t),P9o=i(W),r2=n(W,"LI",{});var _$e=s(r2);yme=n(_$e,"STRONG",{});var Gpt=s(yme);B9o=r(Gpt,"transfo-xl"),Gpt.forEach(t),I9o=r(_$e," \u2014 "),$G=n(_$e,"A",{href:!0});var Opt=s($G);N9o=r(Opt,"TransfoXLLMHeadModel"),Opt.forEach(t),q9o=r(_$e," (Transformer-XL model)"),_$e.forEach(t),j9o=i(W),t2=n(W,"LI",{});var u$e=s(t2);xme=n(u$e,"STRONG",{});var Vpt=s(xme);D9o=r(Vpt,"trocr"),Vpt.forEach(t),G9o=r(u$e," \u2014 "),kG=n(u$e,"A",{href:!0});var Xpt=s(kG);O9o=r(Xpt,"TrOCRForCausalLM"),Xpt.forEach(t),V9o=r(u$e," (TrOCR model)"),u$e.forEach(t),X9o=i(W),a2=n(W,"LI",{});var b$e=s(a2);$me=n(b$e,"STRONG",{});var zpt=s($me);z9o=r(zpt,"xglm"),zpt.forEach(t),Q9o=r(b$e," \u2014 "),SG=n(b$e,"A",{href:!0});var Qpt=s(SG);W9o=r(Qpt,"XGLMForCausalLM"),Qpt.forEach(t),H9o=r(b$e," (XGLM model)"),b$e.forEach(t),U9o=i(W),n2=n(W,"LI",{});var v$e=s(n2);kme=n(v$e,"STRONG",{});var Wpt=s(kme);J9o=r(Wpt,"xlm"),Wpt.forEach(t),Y9o=r(v$e," \u2014 "),RG=n(v$e,"A",{href:!0});var Hpt=s(RG);K9o=r(Hpt,"XLMWithLMHeadModel"),Hpt.forEach(t),Z9o=r(v$e," (XLM model)"),v$e.forEach(t),exo=i(W),s2=n(W,"LI",{});var F$e=s(s2);Sme=n(F$e,"STRONG",{});var Upt=s(Sme);oxo=r(Upt,"xlm-prophetnet"),Upt.forEach(t),rxo=r(F$e," \u2014 "),PG=n(F$e,"A",{href:!0});var Jpt=s(PG);txo=r(Jpt,"XLMProphetNetForCausalLM"),Jpt.forEach(t),axo=r(F$e," (XLM-ProphetNet model)"),F$e.forEach(t),nxo=i(W),l2=n(W,"LI",{});var T$e=s(l2);Rme=n(T$e,"STRONG",{});var Ypt=s(Rme);sxo=r(Ypt,"xlm-roberta"),Ypt.forEach(t),lxo=r(T$e," \u2014 "),BG=n(T$e,"A",{href:!0});var Kpt=s(BG);ixo=r(Kpt,"XLMRobertaForCausalLM"),Kpt.forEach(t),dxo=r(T$e," (XLM-RoBERTa model)"),T$e.forEach(t),cxo=i(W),i2=n(W,"LI",{});var M$e=s(i2);Pme=n(M$e,"STRONG",{});var Zpt=s(Pme);fxo=r(Zpt,"xlm-roberta-xl"),Zpt.forEach(t),mxo=r(M$e," \u2014 "),IG=n(M$e,"A",{href:!0});var e_t=s(IG);gxo=r(e_t,"XLMRobertaXLForCausalLM"),e_t.forEach(t),hxo=r(M$e," (XLM-RoBERTa-XL model)"),M$e.forEach(t),pxo=i(W),d2=n(W,"LI",{});var E$e=s(d2);Bme=n(E$e,"STRONG",{});var o_t=s(Bme);_xo=r(o_t,"xlnet"),o_t.forEach(t),uxo=r(E$e," \u2014 "),NG=n(E$e,"A",{href:!0});var r_t=s(NG);bxo=r(r_t,"XLNetLMHeadModel"),r_t.forEach(t),vxo=r(E$e," (XLNet model)"),E$e.forEach(t),W.forEach(t),Fxo=i(sa),c2=n(sa,"P",{});var C$e=s(c2);Txo=r(C$e,"The model is set in evaluation mode by default using "),Ime=n(C$e,"CODE",{});var t_t=s(Ime);Mxo=r(t_t,"model.eval()"),t_t.forEach(t),Exo=r(C$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=n(C$e,"CODE",{});var a_t=s(Nme);Cxo=r(a_t,"model.train()"),a_t.forEach(t),C$e.forEach(t),wxo=i(sa),T(f2.$$.fragment,sa),sa.forEach(t),Zs.forEach(t),aOe=i(f),Xi=n(f,"H2",{class:!0});var cXe=s(Xi);m2=n(cXe,"A",{id:!0,class:!0,href:!0});var n_t=s(m2);qme=n(n_t,"SPAN",{});var s_t=s(qme);T(_L.$$.fragment,s_t),s_t.forEach(t),n_t.forEach(t),Axo=i(cXe),jme=n(cXe,"SPAN",{});var l_t=s(jme);Lxo=r(l_t,"AutoModelForMaskedLM"),l_t.forEach(t),cXe.forEach(t),nOe=i(f),So=n(f,"DIV",{class:!0});var el=s(So);T(uL.$$.fragment,el),yxo=i(el),zi=n(el,"P",{});var woe=s(zi);xxo=r(woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=n(woe,"A",{href:!0});var i_t=s(qG);$xo=r(i_t,"from_pretrained()"),i_t.forEach(t),kxo=r(woe," class method or the "),jG=n(woe,"A",{href:!0});var d_t=s(jG);Sxo=r(d_t,"from_config()"),d_t.forEach(t),Rxo=r(woe,` class
method.`),woe.forEach(t),Pxo=i(el),bL=n(el,"P",{});var fXe=s(bL);Bxo=r(fXe,"This class cannot be instantiated directly using "),Dme=n(fXe,"CODE",{});var c_t=s(Dme);Ixo=r(c_t,"__init__()"),c_t.forEach(t),Nxo=r(fXe," (throws an error)."),fXe.forEach(t),qxo=i(el),it=n(el,"DIV",{class:!0});var N0=s(it);T(vL.$$.fragment,N0),jxo=i(N0),Gme=n(N0,"P",{});var f_t=s(Gme);Dxo=r(f_t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),f_t.forEach(t),Gxo=i(N0),Qi=n(N0,"P",{});var Aoe=s(Qi);Oxo=r(Aoe,`Note:
Loading a model from its configuration file does `),Ome=n(Aoe,"STRONG",{});var m_t=s(Ome);Vxo=r(m_t,"not"),m_t.forEach(t),Xxo=r(Aoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=n(Aoe,"A",{href:!0});var g_t=s(DG);zxo=r(g_t,"from_pretrained()"),g_t.forEach(t),Qxo=r(Aoe," to load the model weights."),Aoe.forEach(t),Wxo=i(N0),T(g2.$$.fragment,N0),N0.forEach(t),Hxo=i(el),Ze=n(el,"DIV",{class:!0});var la=s(Ze);T(FL.$$.fragment,la),Uxo=i(la),Vme=n(la,"P",{});var h_t=s(Vme);Jxo=r(h_t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),h_t.forEach(t),Yxo=i(la),Ia=n(la,"P",{});var q0=s(Ia);Kxo=r(q0,"The model class to instantiate is selected based on the "),Xme=n(q0,"CODE",{});var p_t=s(Xme);Zxo=r(p_t,"model_type"),p_t.forEach(t),e$o=r(q0,` property of the config object (either
passed as an argument or loaded from `),zme=n(q0,"CODE",{});var __t=s(zme);o$o=r(__t,"pretrained_model_name_or_path"),__t.forEach(t),r$o=r(q0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=n(q0,"CODE",{});var u_t=s(Qme);t$o=r(u_t,"pretrained_model_name_or_path"),u_t.forEach(t),a$o=r(q0,":"),q0.forEach(t),n$o=i(la),Q=n(la,"UL",{});var U=s(Q);h2=n(U,"LI",{});var w$e=s(h2);Wme=n(w$e,"STRONG",{});var b_t=s(Wme);s$o=r(b_t,"albert"),b_t.forEach(t),l$o=r(w$e," \u2014 "),GG=n(w$e,"A",{href:!0});var v_t=s(GG);i$o=r(v_t,"AlbertForMaskedLM"),v_t.forEach(t),d$o=r(w$e," (ALBERT model)"),w$e.forEach(t),c$o=i(U),p2=n(U,"LI",{});var A$e=s(p2);Hme=n(A$e,"STRONG",{});var F_t=s(Hme);f$o=r(F_t,"bart"),F_t.forEach(t),m$o=r(A$e," \u2014 "),OG=n(A$e,"A",{href:!0});var T_t=s(OG);g$o=r(T_t,"BartForConditionalGeneration"),T_t.forEach(t),h$o=r(A$e," (BART model)"),A$e.forEach(t),p$o=i(U),_2=n(U,"LI",{});var L$e=s(_2);Ume=n(L$e,"STRONG",{});var M_t=s(Ume);_$o=r(M_t,"bert"),M_t.forEach(t),u$o=r(L$e," \u2014 "),VG=n(L$e,"A",{href:!0});var E_t=s(VG);b$o=r(E_t,"BertForMaskedLM"),E_t.forEach(t),v$o=r(L$e," (BERT model)"),L$e.forEach(t),F$o=i(U),u2=n(U,"LI",{});var y$e=s(u2);Jme=n(y$e,"STRONG",{});var C_t=s(Jme);T$o=r(C_t,"big_bird"),C_t.forEach(t),M$o=r(y$e," \u2014 "),XG=n(y$e,"A",{href:!0});var w_t=s(XG);E$o=r(w_t,"BigBirdForMaskedLM"),w_t.forEach(t),C$o=r(y$e," (BigBird model)"),y$e.forEach(t),w$o=i(U),b2=n(U,"LI",{});var x$e=s(b2);Yme=n(x$e,"STRONG",{});var A_t=s(Yme);A$o=r(A_t,"camembert"),A_t.forEach(t),L$o=r(x$e," \u2014 "),zG=n(x$e,"A",{href:!0});var L_t=s(zG);y$o=r(L_t,"CamembertForMaskedLM"),L_t.forEach(t),x$o=r(x$e," (CamemBERT model)"),x$e.forEach(t),$$o=i(U),v2=n(U,"LI",{});var $$e=s(v2);Kme=n($$e,"STRONG",{});var y_t=s(Kme);k$o=r(y_t,"convbert"),y_t.forEach(t),S$o=r($$e," \u2014 "),QG=n($$e,"A",{href:!0});var x_t=s(QG);R$o=r(x_t,"ConvBertForMaskedLM"),x_t.forEach(t),P$o=r($$e," (ConvBERT model)"),$$e.forEach(t),B$o=i(U),F2=n(U,"LI",{});var k$e=s(F2);Zme=n(k$e,"STRONG",{});var $_t=s(Zme);I$o=r($_t,"data2vec-text"),$_t.forEach(t),N$o=r(k$e," \u2014 "),WG=n(k$e,"A",{href:!0});var k_t=s(WG);q$o=r(k_t,"Data2VecTextForMaskedLM"),k_t.forEach(t),j$o=r(k$e," (Data2VecText model)"),k$e.forEach(t),D$o=i(U),T2=n(U,"LI",{});var S$e=s(T2);ege=n(S$e,"STRONG",{});var S_t=s(ege);G$o=r(S_t,"deberta"),S_t.forEach(t),O$o=r(S$e," \u2014 "),HG=n(S$e,"A",{href:!0});var R_t=s(HG);V$o=r(R_t,"DebertaForMaskedLM"),R_t.forEach(t),X$o=r(S$e," (DeBERTa model)"),S$e.forEach(t),z$o=i(U),M2=n(U,"LI",{});var R$e=s(M2);oge=n(R$e,"STRONG",{});var P_t=s(oge);Q$o=r(P_t,"deberta-v2"),P_t.forEach(t),W$o=r(R$e," \u2014 "),UG=n(R$e,"A",{href:!0});var B_t=s(UG);H$o=r(B_t,"DebertaV2ForMaskedLM"),B_t.forEach(t),U$o=r(R$e," (DeBERTa-v2 model)"),R$e.forEach(t),J$o=i(U),E2=n(U,"LI",{});var P$e=s(E2);rge=n(P$e,"STRONG",{});var I_t=s(rge);Y$o=r(I_t,"distilbert"),I_t.forEach(t),K$o=r(P$e," \u2014 "),JG=n(P$e,"A",{href:!0});var N_t=s(JG);Z$o=r(N_t,"DistilBertForMaskedLM"),N_t.forEach(t),eko=r(P$e," (DistilBERT model)"),P$e.forEach(t),oko=i(U),C2=n(U,"LI",{});var B$e=s(C2);tge=n(B$e,"STRONG",{});var q_t=s(tge);rko=r(q_t,"electra"),q_t.forEach(t),tko=r(B$e," \u2014 "),YG=n(B$e,"A",{href:!0});var j_t=s(YG);ako=r(j_t,"ElectraForMaskedLM"),j_t.forEach(t),nko=r(B$e," (ELECTRA model)"),B$e.forEach(t),sko=i(U),w2=n(U,"LI",{});var I$e=s(w2);age=n(I$e,"STRONG",{});var D_t=s(age);lko=r(D_t,"flaubert"),D_t.forEach(t),iko=r(I$e," \u2014 "),KG=n(I$e,"A",{href:!0});var G_t=s(KG);dko=r(G_t,"FlaubertWithLMHeadModel"),G_t.forEach(t),cko=r(I$e," (FlauBERT model)"),I$e.forEach(t),fko=i(U),A2=n(U,"LI",{});var N$e=s(A2);nge=n(N$e,"STRONG",{});var O_t=s(nge);mko=r(O_t,"fnet"),O_t.forEach(t),gko=r(N$e," \u2014 "),ZG=n(N$e,"A",{href:!0});var V_t=s(ZG);hko=r(V_t,"FNetForMaskedLM"),V_t.forEach(t),pko=r(N$e," (FNet model)"),N$e.forEach(t),_ko=i(U),L2=n(U,"LI",{});var q$e=s(L2);sge=n(q$e,"STRONG",{});var X_t=s(sge);uko=r(X_t,"funnel"),X_t.forEach(t),bko=r(q$e," \u2014 "),eO=n(q$e,"A",{href:!0});var z_t=s(eO);vko=r(z_t,"FunnelForMaskedLM"),z_t.forEach(t),Fko=r(q$e," (Funnel Transformer model)"),q$e.forEach(t),Tko=i(U),y2=n(U,"LI",{});var j$e=s(y2);lge=n(j$e,"STRONG",{});var Q_t=s(lge);Mko=r(Q_t,"ibert"),Q_t.forEach(t),Eko=r(j$e," \u2014 "),oO=n(j$e,"A",{href:!0});var W_t=s(oO);Cko=r(W_t,"IBertForMaskedLM"),W_t.forEach(t),wko=r(j$e," (I-BERT model)"),j$e.forEach(t),Ako=i(U),x2=n(U,"LI",{});var D$e=s(x2);ige=n(D$e,"STRONG",{});var H_t=s(ige);Lko=r(H_t,"layoutlm"),H_t.forEach(t),yko=r(D$e," \u2014 "),rO=n(D$e,"A",{href:!0});var U_t=s(rO);xko=r(U_t,"LayoutLMForMaskedLM"),U_t.forEach(t),$ko=r(D$e," (LayoutLM model)"),D$e.forEach(t),kko=i(U),$2=n(U,"LI",{});var G$e=s($2);dge=n(G$e,"STRONG",{});var J_t=s(dge);Sko=r(J_t,"longformer"),J_t.forEach(t),Rko=r(G$e," \u2014 "),tO=n(G$e,"A",{href:!0});var Y_t=s(tO);Pko=r(Y_t,"LongformerForMaskedLM"),Y_t.forEach(t),Bko=r(G$e," (Longformer model)"),G$e.forEach(t),Iko=i(U),k2=n(U,"LI",{});var O$e=s(k2);cge=n(O$e,"STRONG",{});var K_t=s(cge);Nko=r(K_t,"luke"),K_t.forEach(t),qko=r(O$e," \u2014 "),aO=n(O$e,"A",{href:!0});var Z_t=s(aO);jko=r(Z_t,"LukeForMaskedLM"),Z_t.forEach(t),Dko=r(O$e," (LUKE model)"),O$e.forEach(t),Gko=i(U),S2=n(U,"LI",{});var V$e=s(S2);fge=n(V$e,"STRONG",{});var eut=s(fge);Oko=r(eut,"mbart"),eut.forEach(t),Vko=r(V$e," \u2014 "),nO=n(V$e,"A",{href:!0});var out=s(nO);Xko=r(out,"MBartForConditionalGeneration"),out.forEach(t),zko=r(V$e," (mBART model)"),V$e.forEach(t),Qko=i(U),R2=n(U,"LI",{});var X$e=s(R2);mge=n(X$e,"STRONG",{});var rut=s(mge);Wko=r(rut,"megatron-bert"),rut.forEach(t),Hko=r(X$e," \u2014 "),sO=n(X$e,"A",{href:!0});var tut=s(sO);Uko=r(tut,"MegatronBertForMaskedLM"),tut.forEach(t),Jko=r(X$e," (Megatron-BERT model)"),X$e.forEach(t),Yko=i(U),P2=n(U,"LI",{});var z$e=s(P2);gge=n(z$e,"STRONG",{});var aut=s(gge);Kko=r(aut,"mobilebert"),aut.forEach(t),Zko=r(z$e," \u2014 "),lO=n(z$e,"A",{href:!0});var nut=s(lO);eSo=r(nut,"MobileBertForMaskedLM"),nut.forEach(t),oSo=r(z$e," (MobileBERT model)"),z$e.forEach(t),rSo=i(U),B2=n(U,"LI",{});var Q$e=s(B2);hge=n(Q$e,"STRONG",{});var sut=s(hge);tSo=r(sut,"mpnet"),sut.forEach(t),aSo=r(Q$e," \u2014 "),iO=n(Q$e,"A",{href:!0});var lut=s(iO);nSo=r(lut,"MPNetForMaskedLM"),lut.forEach(t),sSo=r(Q$e," (MPNet model)"),Q$e.forEach(t),lSo=i(U),I2=n(U,"LI",{});var W$e=s(I2);pge=n(W$e,"STRONG",{});var iut=s(pge);iSo=r(iut,"nezha"),iut.forEach(t),dSo=r(W$e," \u2014 "),dO=n(W$e,"A",{href:!0});var dut=s(dO);cSo=r(dut,"NezhaForMaskedLM"),dut.forEach(t),fSo=r(W$e," (Nezha model)"),W$e.forEach(t),mSo=i(U),N2=n(U,"LI",{});var H$e=s(N2);_ge=n(H$e,"STRONG",{});var cut=s(_ge);gSo=r(cut,"nystromformer"),cut.forEach(t),hSo=r(H$e," \u2014 "),cO=n(H$e,"A",{href:!0});var fut=s(cO);pSo=r(fut,"NystromformerForMaskedLM"),fut.forEach(t),_So=r(H$e," (Nystr\xF6mformer model)"),H$e.forEach(t),uSo=i(U),q2=n(U,"LI",{});var U$e=s(q2);uge=n(U$e,"STRONG",{});var mut=s(uge);bSo=r(mut,"perceiver"),mut.forEach(t),vSo=r(U$e," \u2014 "),fO=n(U$e,"A",{href:!0});var gut=s(fO);FSo=r(gut,"PerceiverForMaskedLM"),gut.forEach(t),TSo=r(U$e," (Perceiver model)"),U$e.forEach(t),MSo=i(U),j2=n(U,"LI",{});var J$e=s(j2);bge=n(J$e,"STRONG",{});var hut=s(bge);ESo=r(hut,"qdqbert"),hut.forEach(t),CSo=r(J$e," \u2014 "),mO=n(J$e,"A",{href:!0});var put=s(mO);wSo=r(put,"QDQBertForMaskedLM"),put.forEach(t),ASo=r(J$e," (QDQBert model)"),J$e.forEach(t),LSo=i(U),D2=n(U,"LI",{});var Y$e=s(D2);vge=n(Y$e,"STRONG",{});var _ut=s(vge);ySo=r(_ut,"reformer"),_ut.forEach(t),xSo=r(Y$e," \u2014 "),gO=n(Y$e,"A",{href:!0});var uut=s(gO);$So=r(uut,"ReformerForMaskedLM"),uut.forEach(t),kSo=r(Y$e," (Reformer model)"),Y$e.forEach(t),SSo=i(U),G2=n(U,"LI",{});var K$e=s(G2);Fge=n(K$e,"STRONG",{});var but=s(Fge);RSo=r(but,"rembert"),but.forEach(t),PSo=r(K$e," \u2014 "),hO=n(K$e,"A",{href:!0});var vut=s(hO);BSo=r(vut,"RemBertForMaskedLM"),vut.forEach(t),ISo=r(K$e," (RemBERT model)"),K$e.forEach(t),NSo=i(U),O2=n(U,"LI",{});var Z$e=s(O2);Tge=n(Z$e,"STRONG",{});var Fut=s(Tge);qSo=r(Fut,"roberta"),Fut.forEach(t),jSo=r(Z$e," \u2014 "),pO=n(Z$e,"A",{href:!0});var Tut=s(pO);DSo=r(Tut,"RobertaForMaskedLM"),Tut.forEach(t),GSo=r(Z$e," (RoBERTa model)"),Z$e.forEach(t),OSo=i(U),V2=n(U,"LI",{});var eke=s(V2);Mge=n(eke,"STRONG",{});var Mut=s(Mge);VSo=r(Mut,"roformer"),Mut.forEach(t),XSo=r(eke," \u2014 "),_O=n(eke,"A",{href:!0});var Eut=s(_O);zSo=r(Eut,"RoFormerForMaskedLM"),Eut.forEach(t),QSo=r(eke," (RoFormer model)"),eke.forEach(t),WSo=i(U),X2=n(U,"LI",{});var oke=s(X2);Ege=n(oke,"STRONG",{});var Cut=s(Ege);HSo=r(Cut,"squeezebert"),Cut.forEach(t),USo=r(oke," \u2014 "),uO=n(oke,"A",{href:!0});var wut=s(uO);JSo=r(wut,"SqueezeBertForMaskedLM"),wut.forEach(t),YSo=r(oke," (SqueezeBERT model)"),oke.forEach(t),KSo=i(U),z2=n(U,"LI",{});var rke=s(z2);Cge=n(rke,"STRONG",{});var Aut=s(Cge);ZSo=r(Aut,"tapas"),Aut.forEach(t),eRo=r(rke," \u2014 "),bO=n(rke,"A",{href:!0});var Lut=s(bO);oRo=r(Lut,"TapasForMaskedLM"),Lut.forEach(t),rRo=r(rke," (TAPAS model)"),rke.forEach(t),tRo=i(U),Q2=n(U,"LI",{});var tke=s(Q2);wge=n(tke,"STRONG",{});var yut=s(wge);aRo=r(yut,"wav2vec2"),yut.forEach(t),nRo=r(tke," \u2014 "),Age=n(tke,"CODE",{});var xut=s(Age);sRo=r(xut,"Wav2Vec2ForMaskedLM"),xut.forEach(t),lRo=r(tke," (Wav2Vec2 model)"),tke.forEach(t),iRo=i(U),W2=n(U,"LI",{});var ake=s(W2);Lge=n(ake,"STRONG",{});var $ut=s(Lge);dRo=r($ut,"xlm"),$ut.forEach(t),cRo=r(ake," \u2014 "),vO=n(ake,"A",{href:!0});var kut=s(vO);fRo=r(kut,"XLMWithLMHeadModel"),kut.forEach(t),mRo=r(ake," (XLM model)"),ake.forEach(t),gRo=i(U),H2=n(U,"LI",{});var nke=s(H2);yge=n(nke,"STRONG",{});var Sut=s(yge);hRo=r(Sut,"xlm-roberta"),Sut.forEach(t),pRo=r(nke," \u2014 "),FO=n(nke,"A",{href:!0});var Rut=s(FO);_Ro=r(Rut,"XLMRobertaForMaskedLM"),Rut.forEach(t),uRo=r(nke," (XLM-RoBERTa model)"),nke.forEach(t),bRo=i(U),U2=n(U,"LI",{});var ske=s(U2);xge=n(ske,"STRONG",{});var Put=s(xge);vRo=r(Put,"xlm-roberta-xl"),Put.forEach(t),FRo=r(ske," \u2014 "),TO=n(ske,"A",{href:!0});var But=s(TO);TRo=r(But,"XLMRobertaXLForMaskedLM"),But.forEach(t),MRo=r(ske," (XLM-RoBERTa-XL model)"),ske.forEach(t),ERo=i(U),J2=n(U,"LI",{});var lke=s(J2);$ge=n(lke,"STRONG",{});var Iut=s($ge);CRo=r(Iut,"yoso"),Iut.forEach(t),wRo=r(lke," \u2014 "),MO=n(lke,"A",{href:!0});var Nut=s(MO);ARo=r(Nut,"YosoForMaskedLM"),Nut.forEach(t),LRo=r(lke," (YOSO model)"),lke.forEach(t),U.forEach(t),yRo=i(la),Y2=n(la,"P",{});var ike=s(Y2);xRo=r(ike,"The model is set in evaluation mode by default using "),kge=n(ike,"CODE",{});var qut=s(kge);$Ro=r(qut,"model.eval()"),qut.forEach(t),kRo=r(ike,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=n(ike,"CODE",{});var jut=s(Sge);SRo=r(jut,"model.train()"),jut.forEach(t),ike.forEach(t),RRo=i(la),T(K2.$$.fragment,la),la.forEach(t),el.forEach(t),sOe=i(f),Wi=n(f,"H2",{class:!0});var mXe=s(Wi);Z2=n(mXe,"A",{id:!0,class:!0,href:!0});var Dut=s(Z2);Rge=n(Dut,"SPAN",{});var Gut=s(Rge);T(TL.$$.fragment,Gut),Gut.forEach(t),Dut.forEach(t),PRo=i(mXe),Pge=n(mXe,"SPAN",{});var Out=s(Pge);BRo=r(Out,"AutoModelForSeq2SeqLM"),Out.forEach(t),mXe.forEach(t),lOe=i(f),Ro=n(f,"DIV",{class:!0});var ol=s(Ro);T(ML.$$.fragment,ol),IRo=i(ol),Hi=n(ol,"P",{});var Loe=s(Hi);NRo=r(Loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=n(Loe,"A",{href:!0});var Vut=s(EO);qRo=r(Vut,"from_pretrained()"),Vut.forEach(t),jRo=r(Loe," class method or the "),CO=n(Loe,"A",{href:!0});var Xut=s(CO);DRo=r(Xut,"from_config()"),Xut.forEach(t),GRo=r(Loe,` class
method.`),Loe.forEach(t),ORo=i(ol),EL=n(ol,"P",{});var gXe=s(EL);VRo=r(gXe,"This class cannot be instantiated directly using "),Bge=n(gXe,"CODE",{});var zut=s(Bge);XRo=r(zut,"__init__()"),zut.forEach(t),zRo=r(gXe," (throws an error)."),gXe.forEach(t),QRo=i(ol),dt=n(ol,"DIV",{class:!0});var j0=s(dt);T(CL.$$.fragment,j0),WRo=i(j0),Ige=n(j0,"P",{});var Qut=s(Ige);HRo=r(Qut,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Qut.forEach(t),URo=i(j0),Ui=n(j0,"P",{});var yoe=s(Ui);JRo=r(yoe,`Note:
Loading a model from its configuration file does `),Nge=n(yoe,"STRONG",{});var Wut=s(Nge);YRo=r(Wut,"not"),Wut.forEach(t),KRo=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=n(yoe,"A",{href:!0});var Hut=s(wO);ZRo=r(Hut,"from_pretrained()"),Hut.forEach(t),ePo=r(yoe," to load the model weights."),yoe.forEach(t),oPo=i(j0),T(eb.$$.fragment,j0),j0.forEach(t),rPo=i(ol),eo=n(ol,"DIV",{class:!0});var ia=s(eo);T(wL.$$.fragment,ia),tPo=i(ia),qge=n(ia,"P",{});var Uut=s(qge);aPo=r(Uut,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Uut.forEach(t),nPo=i(ia),Na=n(ia,"P",{});var D0=s(Na);sPo=r(D0,"The model class to instantiate is selected based on the "),jge=n(D0,"CODE",{});var Jut=s(jge);lPo=r(Jut,"model_type"),Jut.forEach(t),iPo=r(D0,` property of the config object (either
passed as an argument or loaded from `),Dge=n(D0,"CODE",{});var Yut=s(Dge);dPo=r(Yut,"pretrained_model_name_or_path"),Yut.forEach(t),cPo=r(D0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=n(D0,"CODE",{});var Kut=s(Gge);fPo=r(Kut,"pretrained_model_name_or_path"),Kut.forEach(t),mPo=r(D0,":"),D0.forEach(t),gPo=i(ia),pe=n(ia,"UL",{});var be=s(pe);ob=n(be,"LI",{});var dke=s(ob);Oge=n(dke,"STRONG",{});var Zut=s(Oge);hPo=r(Zut,"bart"),Zut.forEach(t),pPo=r(dke," \u2014 "),AO=n(dke,"A",{href:!0});var e1t=s(AO);_Po=r(e1t,"BartForConditionalGeneration"),e1t.forEach(t),uPo=r(dke," (BART model)"),dke.forEach(t),bPo=i(be),rb=n(be,"LI",{});var cke=s(rb);Vge=n(cke,"STRONG",{});var o1t=s(Vge);vPo=r(o1t,"bigbird_pegasus"),o1t.forEach(t),FPo=r(cke," \u2014 "),LO=n(cke,"A",{href:!0});var r1t=s(LO);TPo=r(r1t,"BigBirdPegasusForConditionalGeneration"),r1t.forEach(t),MPo=r(cke," (BigBird-Pegasus model)"),cke.forEach(t),EPo=i(be),tb=n(be,"LI",{});var fke=s(tb);Xge=n(fke,"STRONG",{});var t1t=s(Xge);CPo=r(t1t,"blenderbot"),t1t.forEach(t),wPo=r(fke," \u2014 "),yO=n(fke,"A",{href:!0});var a1t=s(yO);APo=r(a1t,"BlenderbotForConditionalGeneration"),a1t.forEach(t),LPo=r(fke," (Blenderbot model)"),fke.forEach(t),yPo=i(be),ab=n(be,"LI",{});var mke=s(ab);zge=n(mke,"STRONG",{});var n1t=s(zge);xPo=r(n1t,"blenderbot-small"),n1t.forEach(t),$Po=r(mke," \u2014 "),xO=n(mke,"A",{href:!0});var s1t=s(xO);kPo=r(s1t,"BlenderbotSmallForConditionalGeneration"),s1t.forEach(t),SPo=r(mke," (BlenderbotSmall model)"),mke.forEach(t),RPo=i(be),nb=n(be,"LI",{});var gke=s(nb);Qge=n(gke,"STRONG",{});var l1t=s(Qge);PPo=r(l1t,"encoder-decoder"),l1t.forEach(t),BPo=r(gke," \u2014 "),$O=n(gke,"A",{href:!0});var i1t=s($O);IPo=r(i1t,"EncoderDecoderModel"),i1t.forEach(t),NPo=r(gke," (Encoder decoder model)"),gke.forEach(t),qPo=i(be),sb=n(be,"LI",{});var hke=s(sb);Wge=n(hke,"STRONG",{});var d1t=s(Wge);jPo=r(d1t,"fsmt"),d1t.forEach(t),DPo=r(hke," \u2014 "),kO=n(hke,"A",{href:!0});var c1t=s(kO);GPo=r(c1t,"FSMTForConditionalGeneration"),c1t.forEach(t),OPo=r(hke," (FairSeq Machine-Translation model)"),hke.forEach(t),VPo=i(be),lb=n(be,"LI",{});var pke=s(lb);Hge=n(pke,"STRONG",{});var f1t=s(Hge);XPo=r(f1t,"led"),f1t.forEach(t),zPo=r(pke," \u2014 "),SO=n(pke,"A",{href:!0});var m1t=s(SO);QPo=r(m1t,"LEDForConditionalGeneration"),m1t.forEach(t),WPo=r(pke," (LED model)"),pke.forEach(t),HPo=i(be),ib=n(be,"LI",{});var _ke=s(ib);Uge=n(_ke,"STRONG",{});var g1t=s(Uge);UPo=r(g1t,"longt5"),g1t.forEach(t),JPo=r(_ke," \u2014 "),RO=n(_ke,"A",{href:!0});var h1t=s(RO);YPo=r(h1t,"LongT5ForConditionalGeneration"),h1t.forEach(t),KPo=r(_ke," (LongT5 model)"),_ke.forEach(t),ZPo=i(be),db=n(be,"LI",{});var uke=s(db);Jge=n(uke,"STRONG",{});var p1t=s(Jge);eBo=r(p1t,"m2m_100"),p1t.forEach(t),oBo=r(uke," \u2014 "),PO=n(uke,"A",{href:!0});var _1t=s(PO);rBo=r(_1t,"M2M100ForConditionalGeneration"),_1t.forEach(t),tBo=r(uke," (M2M100 model)"),uke.forEach(t),aBo=i(be),cb=n(be,"LI",{});var bke=s(cb);Yge=n(bke,"STRONG",{});var u1t=s(Yge);nBo=r(u1t,"marian"),u1t.forEach(t),sBo=r(bke," \u2014 "),BO=n(bke,"A",{href:!0});var b1t=s(BO);lBo=r(b1t,"MarianMTModel"),b1t.forEach(t),iBo=r(bke," (Marian model)"),bke.forEach(t),dBo=i(be),fb=n(be,"LI",{});var vke=s(fb);Kge=n(vke,"STRONG",{});var v1t=s(Kge);cBo=r(v1t,"mbart"),v1t.forEach(t),fBo=r(vke," \u2014 "),IO=n(vke,"A",{href:!0});var F1t=s(IO);mBo=r(F1t,"MBartForConditionalGeneration"),F1t.forEach(t),gBo=r(vke," (mBART model)"),vke.forEach(t),hBo=i(be),mb=n(be,"LI",{});var Fke=s(mb);Zge=n(Fke,"STRONG",{});var T1t=s(Zge);pBo=r(T1t,"mt5"),T1t.forEach(t),_Bo=r(Fke," \u2014 "),NO=n(Fke,"A",{href:!0});var M1t=s(NO);uBo=r(M1t,"MT5ForConditionalGeneration"),M1t.forEach(t),bBo=r(Fke," (MT5 model)"),Fke.forEach(t),vBo=i(be),gb=n(be,"LI",{});var Tke=s(gb);ehe=n(Tke,"STRONG",{});var E1t=s(ehe);FBo=r(E1t,"pegasus"),E1t.forEach(t),TBo=r(Tke," \u2014 "),qO=n(Tke,"A",{href:!0});var C1t=s(qO);MBo=r(C1t,"PegasusForConditionalGeneration"),C1t.forEach(t),EBo=r(Tke," (Pegasus model)"),Tke.forEach(t),CBo=i(be),hb=n(be,"LI",{});var Mke=s(hb);ohe=n(Mke,"STRONG",{});var w1t=s(ohe);wBo=r(w1t,"plbart"),w1t.forEach(t),ABo=r(Mke," \u2014 "),jO=n(Mke,"A",{href:!0});var A1t=s(jO);LBo=r(A1t,"PLBartForConditionalGeneration"),A1t.forEach(t),yBo=r(Mke," (PLBart model)"),Mke.forEach(t),xBo=i(be),pb=n(be,"LI",{});var Eke=s(pb);rhe=n(Eke,"STRONG",{});var L1t=s(rhe);$Bo=r(L1t,"prophetnet"),L1t.forEach(t),kBo=r(Eke," \u2014 "),DO=n(Eke,"A",{href:!0});var y1t=s(DO);SBo=r(y1t,"ProphetNetForConditionalGeneration"),y1t.forEach(t),RBo=r(Eke," (ProphetNet model)"),Eke.forEach(t),PBo=i(be),_b=n(be,"LI",{});var Cke=s(_b);the=n(Cke,"STRONG",{});var x1t=s(the);BBo=r(x1t,"t5"),x1t.forEach(t),IBo=r(Cke," \u2014 "),GO=n(Cke,"A",{href:!0});var $1t=s(GO);NBo=r($1t,"T5ForConditionalGeneration"),$1t.forEach(t),qBo=r(Cke," (T5 model)"),Cke.forEach(t),jBo=i(be),ub=n(be,"LI",{});var wke=s(ub);ahe=n(wke,"STRONG",{});var k1t=s(ahe);DBo=r(k1t,"xlm-prophetnet"),k1t.forEach(t),GBo=r(wke," \u2014 "),OO=n(wke,"A",{href:!0});var S1t=s(OO);OBo=r(S1t,"XLMProphetNetForConditionalGeneration"),S1t.forEach(t),VBo=r(wke," (XLM-ProphetNet model)"),wke.forEach(t),be.forEach(t),XBo=i(ia),bb=n(ia,"P",{});var Ake=s(bb);zBo=r(Ake,"The model is set in evaluation mode by default using "),nhe=n(Ake,"CODE",{});var R1t=s(nhe);QBo=r(R1t,"model.eval()"),R1t.forEach(t),WBo=r(Ake,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=n(Ake,"CODE",{});var P1t=s(she);HBo=r(P1t,"model.train()"),P1t.forEach(t),Ake.forEach(t),UBo=i(ia),T(vb.$$.fragment,ia),ia.forEach(t),ol.forEach(t),iOe=i(f),Ji=n(f,"H2",{class:!0});var hXe=s(Ji);Fb=n(hXe,"A",{id:!0,class:!0,href:!0});var B1t=s(Fb);lhe=n(B1t,"SPAN",{});var I1t=s(lhe);T(AL.$$.fragment,I1t),I1t.forEach(t),B1t.forEach(t),JBo=i(hXe),ihe=n(hXe,"SPAN",{});var N1t=s(ihe);YBo=r(N1t,"AutoModelForSequenceClassification"),N1t.forEach(t),hXe.forEach(t),dOe=i(f),Po=n(f,"DIV",{class:!0});var rl=s(Po);T(LL.$$.fragment,rl),KBo=i(rl),Yi=n(rl,"P",{});var xoe=s(Yi);ZBo=r(xoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=n(xoe,"A",{href:!0});var q1t=s(VO);eIo=r(q1t,"from_pretrained()"),q1t.forEach(t),oIo=r(xoe," class method or the "),XO=n(xoe,"A",{href:!0});var j1t=s(XO);rIo=r(j1t,"from_config()"),j1t.forEach(t),tIo=r(xoe,` class
method.`),xoe.forEach(t),aIo=i(rl),yL=n(rl,"P",{});var pXe=s(yL);nIo=r(pXe,"This class cannot be instantiated directly using "),dhe=n(pXe,"CODE",{});var D1t=s(dhe);sIo=r(D1t,"__init__()"),D1t.forEach(t),lIo=r(pXe," (throws an error)."),pXe.forEach(t),iIo=i(rl),ct=n(rl,"DIV",{class:!0});var G0=s(ct);T(xL.$$.fragment,G0),dIo=i(G0),che=n(G0,"P",{});var G1t=s(che);cIo=r(G1t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),G1t.forEach(t),fIo=i(G0),Ki=n(G0,"P",{});var $oe=s(Ki);mIo=r($oe,`Note:
Loading a model from its configuration file does `),fhe=n($oe,"STRONG",{});var O1t=s(fhe);gIo=r(O1t,"not"),O1t.forEach(t),hIo=r($oe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=n($oe,"A",{href:!0});var V1t=s(zO);pIo=r(V1t,"from_pretrained()"),V1t.forEach(t),_Io=r($oe," to load the model weights."),$oe.forEach(t),uIo=i(G0),T(Tb.$$.fragment,G0),G0.forEach(t),bIo=i(rl),oo=n(rl,"DIV",{class:!0});var da=s(oo);T($L.$$.fragment,da),vIo=i(da),mhe=n(da,"P",{});var X1t=s(mhe);FIo=r(X1t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),X1t.forEach(t),TIo=i(da),qa=n(da,"P",{});var O0=s(qa);MIo=r(O0,"The model class to instantiate is selected based on the "),ghe=n(O0,"CODE",{});var z1t=s(ghe);EIo=r(z1t,"model_type"),z1t.forEach(t),CIo=r(O0,` property of the config object (either
passed as an argument or loaded from `),hhe=n(O0,"CODE",{});var Q1t=s(hhe);wIo=r(Q1t,"pretrained_model_name_or_path"),Q1t.forEach(t),AIo=r(O0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=n(O0,"CODE",{});var W1t=s(phe);LIo=r(W1t,"pretrained_model_name_or_path"),W1t.forEach(t),yIo=r(O0,":"),O0.forEach(t),xIo=i(da),N=n(da,"UL",{});var q=s(N);Mb=n(q,"LI",{});var Lke=s(Mb);_he=n(Lke,"STRONG",{});var H1t=s(_he);$Io=r(H1t,"albert"),H1t.forEach(t),kIo=r(Lke," \u2014 "),QO=n(Lke,"A",{href:!0});var U1t=s(QO);SIo=r(U1t,"AlbertForSequenceClassification"),U1t.forEach(t),RIo=r(Lke," (ALBERT model)"),Lke.forEach(t),PIo=i(q),Eb=n(q,"LI",{});var yke=s(Eb);uhe=n(yke,"STRONG",{});var J1t=s(uhe);BIo=r(J1t,"bart"),J1t.forEach(t),IIo=r(yke," \u2014 "),WO=n(yke,"A",{href:!0});var Y1t=s(WO);NIo=r(Y1t,"BartForSequenceClassification"),Y1t.forEach(t),qIo=r(yke," (BART model)"),yke.forEach(t),jIo=i(q),Cb=n(q,"LI",{});var xke=s(Cb);bhe=n(xke,"STRONG",{});var K1t=s(bhe);DIo=r(K1t,"bert"),K1t.forEach(t),GIo=r(xke," \u2014 "),HO=n(xke,"A",{href:!0});var Z1t=s(HO);OIo=r(Z1t,"BertForSequenceClassification"),Z1t.forEach(t),VIo=r(xke," (BERT model)"),xke.forEach(t),XIo=i(q),wb=n(q,"LI",{});var $ke=s(wb);vhe=n($ke,"STRONG",{});var e2t=s(vhe);zIo=r(e2t,"big_bird"),e2t.forEach(t),QIo=r($ke," \u2014 "),UO=n($ke,"A",{href:!0});var o2t=s(UO);WIo=r(o2t,"BigBirdForSequenceClassification"),o2t.forEach(t),HIo=r($ke," (BigBird model)"),$ke.forEach(t),UIo=i(q),Ab=n(q,"LI",{});var kke=s(Ab);Fhe=n(kke,"STRONG",{});var r2t=s(Fhe);JIo=r(r2t,"bigbird_pegasus"),r2t.forEach(t),YIo=r(kke," \u2014 "),JO=n(kke,"A",{href:!0});var t2t=s(JO);KIo=r(t2t,"BigBirdPegasusForSequenceClassification"),t2t.forEach(t),ZIo=r(kke," (BigBird-Pegasus model)"),kke.forEach(t),eNo=i(q),Lb=n(q,"LI",{});var Ske=s(Lb);The=n(Ske,"STRONG",{});var a2t=s(The);oNo=r(a2t,"bloom"),a2t.forEach(t),rNo=r(Ske," \u2014 "),YO=n(Ske,"A",{href:!0});var n2t=s(YO);tNo=r(n2t,"BloomForSequenceClassification"),n2t.forEach(t),aNo=r(Ske," (BLOOM model)"),Ske.forEach(t),nNo=i(q),yb=n(q,"LI",{});var Rke=s(yb);Mhe=n(Rke,"STRONG",{});var s2t=s(Mhe);sNo=r(s2t,"camembert"),s2t.forEach(t),lNo=r(Rke," \u2014 "),KO=n(Rke,"A",{href:!0});var l2t=s(KO);iNo=r(l2t,"CamembertForSequenceClassification"),l2t.forEach(t),dNo=r(Rke," (CamemBERT model)"),Rke.forEach(t),cNo=i(q),xb=n(q,"LI",{});var Pke=s(xb);Ehe=n(Pke,"STRONG",{});var i2t=s(Ehe);fNo=r(i2t,"canine"),i2t.forEach(t),mNo=r(Pke," \u2014 "),ZO=n(Pke,"A",{href:!0});var d2t=s(ZO);gNo=r(d2t,"CanineForSequenceClassification"),d2t.forEach(t),hNo=r(Pke," (CANINE model)"),Pke.forEach(t),pNo=i(q),$b=n(q,"LI",{});var Bke=s($b);Che=n(Bke,"STRONG",{});var c2t=s(Che);_No=r(c2t,"convbert"),c2t.forEach(t),uNo=r(Bke," \u2014 "),eV=n(Bke,"A",{href:!0});var f2t=s(eV);bNo=r(f2t,"ConvBertForSequenceClassification"),f2t.forEach(t),vNo=r(Bke," (ConvBERT model)"),Bke.forEach(t),FNo=i(q),kb=n(q,"LI",{});var Ike=s(kb);whe=n(Ike,"STRONG",{});var m2t=s(whe);TNo=r(m2t,"ctrl"),m2t.forEach(t),MNo=r(Ike," \u2014 "),oV=n(Ike,"A",{href:!0});var g2t=s(oV);ENo=r(g2t,"CTRLForSequenceClassification"),g2t.forEach(t),CNo=r(Ike," (CTRL model)"),Ike.forEach(t),wNo=i(q),Sb=n(q,"LI",{});var Nke=s(Sb);Ahe=n(Nke,"STRONG",{});var h2t=s(Ahe);ANo=r(h2t,"data2vec-text"),h2t.forEach(t),LNo=r(Nke," \u2014 "),rV=n(Nke,"A",{href:!0});var p2t=s(rV);yNo=r(p2t,"Data2VecTextForSequenceClassification"),p2t.forEach(t),xNo=r(Nke," (Data2VecText model)"),Nke.forEach(t),$No=i(q),Rb=n(q,"LI",{});var qke=s(Rb);Lhe=n(qke,"STRONG",{});var _2t=s(Lhe);kNo=r(_2t,"deberta"),_2t.forEach(t),SNo=r(qke," \u2014 "),tV=n(qke,"A",{href:!0});var u2t=s(tV);RNo=r(u2t,"DebertaForSequenceClassification"),u2t.forEach(t),PNo=r(qke," (DeBERTa model)"),qke.forEach(t),BNo=i(q),Pb=n(q,"LI",{});var jke=s(Pb);yhe=n(jke,"STRONG",{});var b2t=s(yhe);INo=r(b2t,"deberta-v2"),b2t.forEach(t),NNo=r(jke," \u2014 "),aV=n(jke,"A",{href:!0});var v2t=s(aV);qNo=r(v2t,"DebertaV2ForSequenceClassification"),v2t.forEach(t),jNo=r(jke," (DeBERTa-v2 model)"),jke.forEach(t),DNo=i(q),Bb=n(q,"LI",{});var Dke=s(Bb);xhe=n(Dke,"STRONG",{});var F2t=s(xhe);GNo=r(F2t,"distilbert"),F2t.forEach(t),ONo=r(Dke," \u2014 "),nV=n(Dke,"A",{href:!0});var T2t=s(nV);VNo=r(T2t,"DistilBertForSequenceClassification"),T2t.forEach(t),XNo=r(Dke," (DistilBERT model)"),Dke.forEach(t),zNo=i(q),Ib=n(q,"LI",{});var Gke=s(Ib);$he=n(Gke,"STRONG",{});var M2t=s($he);QNo=r(M2t,"electra"),M2t.forEach(t),WNo=r(Gke," \u2014 "),sV=n(Gke,"A",{href:!0});var E2t=s(sV);HNo=r(E2t,"ElectraForSequenceClassification"),E2t.forEach(t),UNo=r(Gke," (ELECTRA model)"),Gke.forEach(t),JNo=i(q),Nb=n(q,"LI",{});var Oke=s(Nb);khe=n(Oke,"STRONG",{});var C2t=s(khe);YNo=r(C2t,"flaubert"),C2t.forEach(t),KNo=r(Oke," \u2014 "),lV=n(Oke,"A",{href:!0});var w2t=s(lV);ZNo=r(w2t,"FlaubertForSequenceClassification"),w2t.forEach(t),eqo=r(Oke," (FlauBERT model)"),Oke.forEach(t),oqo=i(q),qb=n(q,"LI",{});var Vke=s(qb);She=n(Vke,"STRONG",{});var A2t=s(She);rqo=r(A2t,"fnet"),A2t.forEach(t),tqo=r(Vke," \u2014 "),iV=n(Vke,"A",{href:!0});var L2t=s(iV);aqo=r(L2t,"FNetForSequenceClassification"),L2t.forEach(t),nqo=r(Vke," (FNet model)"),Vke.forEach(t),sqo=i(q),jb=n(q,"LI",{});var Xke=s(jb);Rhe=n(Xke,"STRONG",{});var y2t=s(Rhe);lqo=r(y2t,"funnel"),y2t.forEach(t),iqo=r(Xke," \u2014 "),dV=n(Xke,"A",{href:!0});var x2t=s(dV);dqo=r(x2t,"FunnelForSequenceClassification"),x2t.forEach(t),cqo=r(Xke," (Funnel Transformer model)"),Xke.forEach(t),fqo=i(q),Db=n(q,"LI",{});var zke=s(Db);Phe=n(zke,"STRONG",{});var $2t=s(Phe);mqo=r($2t,"gpt2"),$2t.forEach(t),gqo=r(zke," \u2014 "),cV=n(zke,"A",{href:!0});var k2t=s(cV);hqo=r(k2t,"GPT2ForSequenceClassification"),k2t.forEach(t),pqo=r(zke," (OpenAI GPT-2 model)"),zke.forEach(t),_qo=i(q),Gb=n(q,"LI",{});var Qke=s(Gb);Bhe=n(Qke,"STRONG",{});var S2t=s(Bhe);uqo=r(S2t,"gpt_neo"),S2t.forEach(t),bqo=r(Qke," \u2014 "),fV=n(Qke,"A",{href:!0});var R2t=s(fV);vqo=r(R2t,"GPTNeoForSequenceClassification"),R2t.forEach(t),Fqo=r(Qke," (GPT Neo model)"),Qke.forEach(t),Tqo=i(q),Ob=n(q,"LI",{});var Wke=s(Ob);Ihe=n(Wke,"STRONG",{});var P2t=s(Ihe);Mqo=r(P2t,"gptj"),P2t.forEach(t),Eqo=r(Wke," \u2014 "),mV=n(Wke,"A",{href:!0});var B2t=s(mV);Cqo=r(B2t,"GPTJForSequenceClassification"),B2t.forEach(t),wqo=r(Wke," (GPT-J model)"),Wke.forEach(t),Aqo=i(q),Vb=n(q,"LI",{});var Hke=s(Vb);Nhe=n(Hke,"STRONG",{});var I2t=s(Nhe);Lqo=r(I2t,"ibert"),I2t.forEach(t),yqo=r(Hke," \u2014 "),gV=n(Hke,"A",{href:!0});var N2t=s(gV);xqo=r(N2t,"IBertForSequenceClassification"),N2t.forEach(t),$qo=r(Hke," (I-BERT model)"),Hke.forEach(t),kqo=i(q),Xb=n(q,"LI",{});var Uke=s(Xb);qhe=n(Uke,"STRONG",{});var q2t=s(qhe);Sqo=r(q2t,"layoutlm"),q2t.forEach(t),Rqo=r(Uke," \u2014 "),hV=n(Uke,"A",{href:!0});var j2t=s(hV);Pqo=r(j2t,"LayoutLMForSequenceClassification"),j2t.forEach(t),Bqo=r(Uke," (LayoutLM model)"),Uke.forEach(t),Iqo=i(q),zb=n(q,"LI",{});var Jke=s(zb);jhe=n(Jke,"STRONG",{});var D2t=s(jhe);Nqo=r(D2t,"layoutlmv2"),D2t.forEach(t),qqo=r(Jke," \u2014 "),pV=n(Jke,"A",{href:!0});var G2t=s(pV);jqo=r(G2t,"LayoutLMv2ForSequenceClassification"),G2t.forEach(t),Dqo=r(Jke," (LayoutLMv2 model)"),Jke.forEach(t),Gqo=i(q),Qb=n(q,"LI",{});var Yke=s(Qb);Dhe=n(Yke,"STRONG",{});var O2t=s(Dhe);Oqo=r(O2t,"layoutlmv3"),O2t.forEach(t),Vqo=r(Yke," \u2014 "),_V=n(Yke,"A",{href:!0});var V2t=s(_V);Xqo=r(V2t,"LayoutLMv3ForSequenceClassification"),V2t.forEach(t),zqo=r(Yke," (LayoutLMv3 model)"),Yke.forEach(t),Qqo=i(q),Wb=n(q,"LI",{});var Kke=s(Wb);Ghe=n(Kke,"STRONG",{});var X2t=s(Ghe);Wqo=r(X2t,"led"),X2t.forEach(t),Hqo=r(Kke," \u2014 "),uV=n(Kke,"A",{href:!0});var z2t=s(uV);Uqo=r(z2t,"LEDForSequenceClassification"),z2t.forEach(t),Jqo=r(Kke," (LED model)"),Kke.forEach(t),Yqo=i(q),Hb=n(q,"LI",{});var Zke=s(Hb);Ohe=n(Zke,"STRONG",{});var Q2t=s(Ohe);Kqo=r(Q2t,"longformer"),Q2t.forEach(t),Zqo=r(Zke," \u2014 "),bV=n(Zke,"A",{href:!0});var W2t=s(bV);ejo=r(W2t,"LongformerForSequenceClassification"),W2t.forEach(t),ojo=r(Zke," (Longformer model)"),Zke.forEach(t),rjo=i(q),Ub=n(q,"LI",{});var eSe=s(Ub);Vhe=n(eSe,"STRONG",{});var H2t=s(Vhe);tjo=r(H2t,"mbart"),H2t.forEach(t),ajo=r(eSe," \u2014 "),vV=n(eSe,"A",{href:!0});var U2t=s(vV);njo=r(U2t,"MBartForSequenceClassification"),U2t.forEach(t),sjo=r(eSe," (mBART model)"),eSe.forEach(t),ljo=i(q),Jb=n(q,"LI",{});var oSe=s(Jb);Xhe=n(oSe,"STRONG",{});var J2t=s(Xhe);ijo=r(J2t,"megatron-bert"),J2t.forEach(t),djo=r(oSe," \u2014 "),FV=n(oSe,"A",{href:!0});var Y2t=s(FV);cjo=r(Y2t,"MegatronBertForSequenceClassification"),Y2t.forEach(t),fjo=r(oSe," (Megatron-BERT model)"),oSe.forEach(t),mjo=i(q),Yb=n(q,"LI",{});var rSe=s(Yb);zhe=n(rSe,"STRONG",{});var K2t=s(zhe);gjo=r(K2t,"mobilebert"),K2t.forEach(t),hjo=r(rSe," \u2014 "),TV=n(rSe,"A",{href:!0});var Z2t=s(TV);pjo=r(Z2t,"MobileBertForSequenceClassification"),Z2t.forEach(t),_jo=r(rSe," (MobileBERT model)"),rSe.forEach(t),ujo=i(q),Kb=n(q,"LI",{});var tSe=s(Kb);Qhe=n(tSe,"STRONG",{});var ebt=s(Qhe);bjo=r(ebt,"mpnet"),ebt.forEach(t),vjo=r(tSe," \u2014 "),MV=n(tSe,"A",{href:!0});var obt=s(MV);Fjo=r(obt,"MPNetForSequenceClassification"),obt.forEach(t),Tjo=r(tSe," (MPNet model)"),tSe.forEach(t),Mjo=i(q),Zb=n(q,"LI",{});var aSe=s(Zb);Whe=n(aSe,"STRONG",{});var rbt=s(Whe);Ejo=r(rbt,"nezha"),rbt.forEach(t),Cjo=r(aSe," \u2014 "),EV=n(aSe,"A",{href:!0});var tbt=s(EV);wjo=r(tbt,"NezhaForSequenceClassification"),tbt.forEach(t),Ajo=r(aSe," (Nezha model)"),aSe.forEach(t),Ljo=i(q),e4=n(q,"LI",{});var nSe=s(e4);Hhe=n(nSe,"STRONG",{});var abt=s(Hhe);yjo=r(abt,"nystromformer"),abt.forEach(t),xjo=r(nSe," \u2014 "),CV=n(nSe,"A",{href:!0});var nbt=s(CV);$jo=r(nbt,"NystromformerForSequenceClassification"),nbt.forEach(t),kjo=r(nSe," (Nystr\xF6mformer model)"),nSe.forEach(t),Sjo=i(q),o4=n(q,"LI",{});var sSe=s(o4);Uhe=n(sSe,"STRONG",{});var sbt=s(Uhe);Rjo=r(sbt,"openai-gpt"),sbt.forEach(t),Pjo=r(sSe," \u2014 "),wV=n(sSe,"A",{href:!0});var lbt=s(wV);Bjo=r(lbt,"OpenAIGPTForSequenceClassification"),lbt.forEach(t),Ijo=r(sSe," (OpenAI GPT model)"),sSe.forEach(t),Njo=i(q),r4=n(q,"LI",{});var lSe=s(r4);Jhe=n(lSe,"STRONG",{});var ibt=s(Jhe);qjo=r(ibt,"perceiver"),ibt.forEach(t),jjo=r(lSe," \u2014 "),AV=n(lSe,"A",{href:!0});var dbt=s(AV);Djo=r(dbt,"PerceiverForSequenceClassification"),dbt.forEach(t),Gjo=r(lSe," (Perceiver model)"),lSe.forEach(t),Ojo=i(q),t4=n(q,"LI",{});var iSe=s(t4);Yhe=n(iSe,"STRONG",{});var cbt=s(Yhe);Vjo=r(cbt,"plbart"),cbt.forEach(t),Xjo=r(iSe," \u2014 "),LV=n(iSe,"A",{href:!0});var fbt=s(LV);zjo=r(fbt,"PLBartForSequenceClassification"),fbt.forEach(t),Qjo=r(iSe," (PLBart model)"),iSe.forEach(t),Wjo=i(q),a4=n(q,"LI",{});var dSe=s(a4);Khe=n(dSe,"STRONG",{});var mbt=s(Khe);Hjo=r(mbt,"qdqbert"),mbt.forEach(t),Ujo=r(dSe," \u2014 "),yV=n(dSe,"A",{href:!0});var gbt=s(yV);Jjo=r(gbt,"QDQBertForSequenceClassification"),gbt.forEach(t),Yjo=r(dSe," (QDQBert model)"),dSe.forEach(t),Kjo=i(q),n4=n(q,"LI",{});var cSe=s(n4);Zhe=n(cSe,"STRONG",{});var hbt=s(Zhe);Zjo=r(hbt,"reformer"),hbt.forEach(t),eDo=r(cSe," \u2014 "),xV=n(cSe,"A",{href:!0});var pbt=s(xV);oDo=r(pbt,"ReformerForSequenceClassification"),pbt.forEach(t),rDo=r(cSe," (Reformer model)"),cSe.forEach(t),tDo=i(q),s4=n(q,"LI",{});var fSe=s(s4);epe=n(fSe,"STRONG",{});var _bt=s(epe);aDo=r(_bt,"rembert"),_bt.forEach(t),nDo=r(fSe," \u2014 "),$V=n(fSe,"A",{href:!0});var ubt=s($V);sDo=r(ubt,"RemBertForSequenceClassification"),ubt.forEach(t),lDo=r(fSe," (RemBERT model)"),fSe.forEach(t),iDo=i(q),l4=n(q,"LI",{});var mSe=s(l4);ope=n(mSe,"STRONG",{});var bbt=s(ope);dDo=r(bbt,"roberta"),bbt.forEach(t),cDo=r(mSe," \u2014 "),kV=n(mSe,"A",{href:!0});var vbt=s(kV);fDo=r(vbt,"RobertaForSequenceClassification"),vbt.forEach(t),mDo=r(mSe," (RoBERTa model)"),mSe.forEach(t),gDo=i(q),i4=n(q,"LI",{});var gSe=s(i4);rpe=n(gSe,"STRONG",{});var Fbt=s(rpe);hDo=r(Fbt,"roformer"),Fbt.forEach(t),pDo=r(gSe," \u2014 "),SV=n(gSe,"A",{href:!0});var Tbt=s(SV);_Do=r(Tbt,"RoFormerForSequenceClassification"),Tbt.forEach(t),uDo=r(gSe," (RoFormer model)"),gSe.forEach(t),bDo=i(q),d4=n(q,"LI",{});var hSe=s(d4);tpe=n(hSe,"STRONG",{});var Mbt=s(tpe);vDo=r(Mbt,"squeezebert"),Mbt.forEach(t),FDo=r(hSe," \u2014 "),RV=n(hSe,"A",{href:!0});var Ebt=s(RV);TDo=r(Ebt,"SqueezeBertForSequenceClassification"),Ebt.forEach(t),MDo=r(hSe," (SqueezeBERT model)"),hSe.forEach(t),EDo=i(q),c4=n(q,"LI",{});var pSe=s(c4);ape=n(pSe,"STRONG",{});var Cbt=s(ape);CDo=r(Cbt,"tapas"),Cbt.forEach(t),wDo=r(pSe," \u2014 "),PV=n(pSe,"A",{href:!0});var wbt=s(PV);ADo=r(wbt,"TapasForSequenceClassification"),wbt.forEach(t),LDo=r(pSe," (TAPAS model)"),pSe.forEach(t),yDo=i(q),f4=n(q,"LI",{});var _Se=s(f4);npe=n(_Se,"STRONG",{});var Abt=s(npe);xDo=r(Abt,"transfo-xl"),Abt.forEach(t),$Do=r(_Se," \u2014 "),BV=n(_Se,"A",{href:!0});var Lbt=s(BV);kDo=r(Lbt,"TransfoXLForSequenceClassification"),Lbt.forEach(t),SDo=r(_Se," (Transformer-XL model)"),_Se.forEach(t),RDo=i(q),m4=n(q,"LI",{});var uSe=s(m4);spe=n(uSe,"STRONG",{});var ybt=s(spe);PDo=r(ybt,"xlm"),ybt.forEach(t),BDo=r(uSe," \u2014 "),IV=n(uSe,"A",{href:!0});var xbt=s(IV);IDo=r(xbt,"XLMForSequenceClassification"),xbt.forEach(t),NDo=r(uSe," (XLM model)"),uSe.forEach(t),qDo=i(q),g4=n(q,"LI",{});var bSe=s(g4);lpe=n(bSe,"STRONG",{});var $bt=s(lpe);jDo=r($bt,"xlm-roberta"),$bt.forEach(t),DDo=r(bSe," \u2014 "),NV=n(bSe,"A",{href:!0});var kbt=s(NV);GDo=r(kbt,"XLMRobertaForSequenceClassification"),kbt.forEach(t),ODo=r(bSe," (XLM-RoBERTa model)"),bSe.forEach(t),VDo=i(q),h4=n(q,"LI",{});var vSe=s(h4);ipe=n(vSe,"STRONG",{});var Sbt=s(ipe);XDo=r(Sbt,"xlm-roberta-xl"),Sbt.forEach(t),zDo=r(vSe," \u2014 "),qV=n(vSe,"A",{href:!0});var Rbt=s(qV);QDo=r(Rbt,"XLMRobertaXLForSequenceClassification"),Rbt.forEach(t),WDo=r(vSe," (XLM-RoBERTa-XL model)"),vSe.forEach(t),HDo=i(q),p4=n(q,"LI",{});var FSe=s(p4);dpe=n(FSe,"STRONG",{});var Pbt=s(dpe);UDo=r(Pbt,"xlnet"),Pbt.forEach(t),JDo=r(FSe," \u2014 "),jV=n(FSe,"A",{href:!0});var Bbt=s(jV);YDo=r(Bbt,"XLNetForSequenceClassification"),Bbt.forEach(t),KDo=r(FSe," (XLNet model)"),FSe.forEach(t),ZDo=i(q),_4=n(q,"LI",{});var TSe=s(_4);cpe=n(TSe,"STRONG",{});var Ibt=s(cpe);eGo=r(Ibt,"yoso"),Ibt.forEach(t),oGo=r(TSe," \u2014 "),DV=n(TSe,"A",{href:!0});var Nbt=s(DV);rGo=r(Nbt,"YosoForSequenceClassification"),Nbt.forEach(t),tGo=r(TSe," (YOSO model)"),TSe.forEach(t),q.forEach(t),aGo=i(da),u4=n(da,"P",{});var MSe=s(u4);nGo=r(MSe,"The model is set in evaluation mode by default using "),fpe=n(MSe,"CODE",{});var qbt=s(fpe);sGo=r(qbt,"model.eval()"),qbt.forEach(t),lGo=r(MSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mpe=n(MSe,"CODE",{});var jbt=s(mpe);iGo=r(jbt,"model.train()"),jbt.forEach(t),MSe.forEach(t),dGo=i(da),T(b4.$$.fragment,da),da.forEach(t),rl.forEach(t),cOe=i(f),Zi=n(f,"H2",{class:!0});var _Xe=s(Zi);v4=n(_Xe,"A",{id:!0,class:!0,href:!0});var Dbt=s(v4);gpe=n(Dbt,"SPAN",{});var Gbt=s(gpe);T(kL.$$.fragment,Gbt),Gbt.forEach(t),Dbt.forEach(t),cGo=i(_Xe),hpe=n(_Xe,"SPAN",{});var Obt=s(hpe);fGo=r(Obt,"AutoModelForMultipleChoice"),Obt.forEach(t),_Xe.forEach(t),fOe=i(f),Bo=n(f,"DIV",{class:!0});var tl=s(Bo);T(SL.$$.fragment,tl),mGo=i(tl),ed=n(tl,"P",{});var koe=s(ed);gGo=r(koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=n(koe,"A",{href:!0});var Vbt=s(GV);hGo=r(Vbt,"from_pretrained()"),Vbt.forEach(t),pGo=r(koe," class method or the "),OV=n(koe,"A",{href:!0});var Xbt=s(OV);_Go=r(Xbt,"from_config()"),Xbt.forEach(t),uGo=r(koe,` class
method.`),koe.forEach(t),bGo=i(tl),RL=n(tl,"P",{});var uXe=s(RL);vGo=r(uXe,"This class cannot be instantiated directly using "),ppe=n(uXe,"CODE",{});var zbt=s(ppe);FGo=r(zbt,"__init__()"),zbt.forEach(t),TGo=r(uXe," (throws an error)."),uXe.forEach(t),MGo=i(tl),ft=n(tl,"DIV",{class:!0});var V0=s(ft);T(PL.$$.fragment,V0),EGo=i(V0),_pe=n(V0,"P",{});var Qbt=s(_pe);CGo=r(Qbt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Qbt.forEach(t),wGo=i(V0),od=n(V0,"P",{});var Soe=s(od);AGo=r(Soe,`Note:
Loading a model from its configuration file does `),upe=n(Soe,"STRONG",{});var Wbt=s(upe);LGo=r(Wbt,"not"),Wbt.forEach(t),yGo=r(Soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=n(Soe,"A",{href:!0});var Hbt=s(VV);xGo=r(Hbt,"from_pretrained()"),Hbt.forEach(t),$Go=r(Soe," to load the model weights."),Soe.forEach(t),kGo=i(V0),T(F4.$$.fragment,V0),V0.forEach(t),SGo=i(tl),ro=n(tl,"DIV",{class:!0});var ca=s(ro);T(BL.$$.fragment,ca),RGo=i(ca),bpe=n(ca,"P",{});var Ubt=s(bpe);PGo=r(Ubt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Ubt.forEach(t),BGo=i(ca),ja=n(ca,"P",{});var X0=s(ja);IGo=r(X0,"The model class to instantiate is selected based on the "),vpe=n(X0,"CODE",{});var Jbt=s(vpe);NGo=r(Jbt,"model_type"),Jbt.forEach(t),qGo=r(X0,` property of the config object (either
passed as an argument or loaded from `),Fpe=n(X0,"CODE",{});var Ybt=s(Fpe);jGo=r(Ybt,"pretrained_model_name_or_path"),Ybt.forEach(t),DGo=r(X0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tpe=n(X0,"CODE",{});var Kbt=s(Tpe);GGo=r(Kbt,"pretrained_model_name_or_path"),Kbt.forEach(t),OGo=r(X0,":"),X0.forEach(t),VGo=i(ca),Z=n(ca,"UL",{});var ee=s(Z);T4=n(ee,"LI",{});var ESe=s(T4);Mpe=n(ESe,"STRONG",{});var Zbt=s(Mpe);XGo=r(Zbt,"albert"),Zbt.forEach(t),zGo=r(ESe," \u2014 "),XV=n(ESe,"A",{href:!0});var e4t=s(XV);QGo=r(e4t,"AlbertForMultipleChoice"),e4t.forEach(t),WGo=r(ESe," (ALBERT model)"),ESe.forEach(t),HGo=i(ee),M4=n(ee,"LI",{});var CSe=s(M4);Epe=n(CSe,"STRONG",{});var o4t=s(Epe);UGo=r(o4t,"bert"),o4t.forEach(t),JGo=r(CSe," \u2014 "),zV=n(CSe,"A",{href:!0});var r4t=s(zV);YGo=r(r4t,"BertForMultipleChoice"),r4t.forEach(t),KGo=r(CSe," (BERT model)"),CSe.forEach(t),ZGo=i(ee),E4=n(ee,"LI",{});var wSe=s(E4);Cpe=n(wSe,"STRONG",{});var t4t=s(Cpe);eOo=r(t4t,"big_bird"),t4t.forEach(t),oOo=r(wSe," \u2014 "),QV=n(wSe,"A",{href:!0});var a4t=s(QV);rOo=r(a4t,"BigBirdForMultipleChoice"),a4t.forEach(t),tOo=r(wSe," (BigBird model)"),wSe.forEach(t),aOo=i(ee),C4=n(ee,"LI",{});var ASe=s(C4);wpe=n(ASe,"STRONG",{});var n4t=s(wpe);nOo=r(n4t,"camembert"),n4t.forEach(t),sOo=r(ASe," \u2014 "),WV=n(ASe,"A",{href:!0});var s4t=s(WV);lOo=r(s4t,"CamembertForMultipleChoice"),s4t.forEach(t),iOo=r(ASe," (CamemBERT model)"),ASe.forEach(t),dOo=i(ee),w4=n(ee,"LI",{});var LSe=s(w4);Ape=n(LSe,"STRONG",{});var l4t=s(Ape);cOo=r(l4t,"canine"),l4t.forEach(t),fOo=r(LSe," \u2014 "),HV=n(LSe,"A",{href:!0});var i4t=s(HV);mOo=r(i4t,"CanineForMultipleChoice"),i4t.forEach(t),gOo=r(LSe," (CANINE model)"),LSe.forEach(t),hOo=i(ee),A4=n(ee,"LI",{});var ySe=s(A4);Lpe=n(ySe,"STRONG",{});var d4t=s(Lpe);pOo=r(d4t,"convbert"),d4t.forEach(t),_Oo=r(ySe," \u2014 "),UV=n(ySe,"A",{href:!0});var c4t=s(UV);uOo=r(c4t,"ConvBertForMultipleChoice"),c4t.forEach(t),bOo=r(ySe," (ConvBERT model)"),ySe.forEach(t),vOo=i(ee),L4=n(ee,"LI",{});var xSe=s(L4);ype=n(xSe,"STRONG",{});var f4t=s(ype);FOo=r(f4t,"data2vec-text"),f4t.forEach(t),TOo=r(xSe," \u2014 "),JV=n(xSe,"A",{href:!0});var m4t=s(JV);MOo=r(m4t,"Data2VecTextForMultipleChoice"),m4t.forEach(t),EOo=r(xSe," (Data2VecText model)"),xSe.forEach(t),COo=i(ee),y4=n(ee,"LI",{});var $Se=s(y4);xpe=n($Se,"STRONG",{});var g4t=s(xpe);wOo=r(g4t,"deberta-v2"),g4t.forEach(t),AOo=r($Se," \u2014 "),YV=n($Se,"A",{href:!0});var h4t=s(YV);LOo=r(h4t,"DebertaV2ForMultipleChoice"),h4t.forEach(t),yOo=r($Se," (DeBERTa-v2 model)"),$Se.forEach(t),xOo=i(ee),x4=n(ee,"LI",{});var kSe=s(x4);$pe=n(kSe,"STRONG",{});var p4t=s($pe);$Oo=r(p4t,"distilbert"),p4t.forEach(t),kOo=r(kSe," \u2014 "),KV=n(kSe,"A",{href:!0});var _4t=s(KV);SOo=r(_4t,"DistilBertForMultipleChoice"),_4t.forEach(t),ROo=r(kSe," (DistilBERT model)"),kSe.forEach(t),POo=i(ee),$4=n(ee,"LI",{});var SSe=s($4);kpe=n(SSe,"STRONG",{});var u4t=s(kpe);BOo=r(u4t,"electra"),u4t.forEach(t),IOo=r(SSe," \u2014 "),ZV=n(SSe,"A",{href:!0});var b4t=s(ZV);NOo=r(b4t,"ElectraForMultipleChoice"),b4t.forEach(t),qOo=r(SSe," (ELECTRA model)"),SSe.forEach(t),jOo=i(ee),k4=n(ee,"LI",{});var RSe=s(k4);Spe=n(RSe,"STRONG",{});var v4t=s(Spe);DOo=r(v4t,"flaubert"),v4t.forEach(t),GOo=r(RSe," \u2014 "),eX=n(RSe,"A",{href:!0});var F4t=s(eX);OOo=r(F4t,"FlaubertForMultipleChoice"),F4t.forEach(t),VOo=r(RSe," (FlauBERT model)"),RSe.forEach(t),XOo=i(ee),S4=n(ee,"LI",{});var PSe=s(S4);Rpe=n(PSe,"STRONG",{});var T4t=s(Rpe);zOo=r(T4t,"fnet"),T4t.forEach(t),QOo=r(PSe," \u2014 "),oX=n(PSe,"A",{href:!0});var M4t=s(oX);WOo=r(M4t,"FNetForMultipleChoice"),M4t.forEach(t),HOo=r(PSe," (FNet model)"),PSe.forEach(t),UOo=i(ee),R4=n(ee,"LI",{});var BSe=s(R4);Ppe=n(BSe,"STRONG",{});var E4t=s(Ppe);JOo=r(E4t,"funnel"),E4t.forEach(t),YOo=r(BSe," \u2014 "),rX=n(BSe,"A",{href:!0});var C4t=s(rX);KOo=r(C4t,"FunnelForMultipleChoice"),C4t.forEach(t),ZOo=r(BSe," (Funnel Transformer model)"),BSe.forEach(t),eVo=i(ee),P4=n(ee,"LI",{});var ISe=s(P4);Bpe=n(ISe,"STRONG",{});var w4t=s(Bpe);oVo=r(w4t,"ibert"),w4t.forEach(t),rVo=r(ISe," \u2014 "),tX=n(ISe,"A",{href:!0});var A4t=s(tX);tVo=r(A4t,"IBertForMultipleChoice"),A4t.forEach(t),aVo=r(ISe," (I-BERT model)"),ISe.forEach(t),nVo=i(ee),B4=n(ee,"LI",{});var NSe=s(B4);Ipe=n(NSe,"STRONG",{});var L4t=s(Ipe);sVo=r(L4t,"longformer"),L4t.forEach(t),lVo=r(NSe," \u2014 "),aX=n(NSe,"A",{href:!0});var y4t=s(aX);iVo=r(y4t,"LongformerForMultipleChoice"),y4t.forEach(t),dVo=r(NSe," (Longformer model)"),NSe.forEach(t),cVo=i(ee),I4=n(ee,"LI",{});var qSe=s(I4);Npe=n(qSe,"STRONG",{});var x4t=s(Npe);fVo=r(x4t,"megatron-bert"),x4t.forEach(t),mVo=r(qSe," \u2014 "),nX=n(qSe,"A",{href:!0});var $4t=s(nX);gVo=r($4t,"MegatronBertForMultipleChoice"),$4t.forEach(t),hVo=r(qSe," (Megatron-BERT model)"),qSe.forEach(t),pVo=i(ee),N4=n(ee,"LI",{});var jSe=s(N4);qpe=n(jSe,"STRONG",{});var k4t=s(qpe);_Vo=r(k4t,"mobilebert"),k4t.forEach(t),uVo=r(jSe," \u2014 "),sX=n(jSe,"A",{href:!0});var S4t=s(sX);bVo=r(S4t,"MobileBertForMultipleChoice"),S4t.forEach(t),vVo=r(jSe," (MobileBERT model)"),jSe.forEach(t),FVo=i(ee),q4=n(ee,"LI",{});var DSe=s(q4);jpe=n(DSe,"STRONG",{});var R4t=s(jpe);TVo=r(R4t,"mpnet"),R4t.forEach(t),MVo=r(DSe," \u2014 "),lX=n(DSe,"A",{href:!0});var P4t=s(lX);EVo=r(P4t,"MPNetForMultipleChoice"),P4t.forEach(t),CVo=r(DSe," (MPNet model)"),DSe.forEach(t),wVo=i(ee),j4=n(ee,"LI",{});var GSe=s(j4);Dpe=n(GSe,"STRONG",{});var B4t=s(Dpe);AVo=r(B4t,"nezha"),B4t.forEach(t),LVo=r(GSe," \u2014 "),iX=n(GSe,"A",{href:!0});var I4t=s(iX);yVo=r(I4t,"NezhaForMultipleChoice"),I4t.forEach(t),xVo=r(GSe," (Nezha model)"),GSe.forEach(t),$Vo=i(ee),D4=n(ee,"LI",{});var OSe=s(D4);Gpe=n(OSe,"STRONG",{});var N4t=s(Gpe);kVo=r(N4t,"nystromformer"),N4t.forEach(t),SVo=r(OSe," \u2014 "),dX=n(OSe,"A",{href:!0});var q4t=s(dX);RVo=r(q4t,"NystromformerForMultipleChoice"),q4t.forEach(t),PVo=r(OSe," (Nystr\xF6mformer model)"),OSe.forEach(t),BVo=i(ee),G4=n(ee,"LI",{});var VSe=s(G4);Ope=n(VSe,"STRONG",{});var j4t=s(Ope);IVo=r(j4t,"qdqbert"),j4t.forEach(t),NVo=r(VSe," \u2014 "),cX=n(VSe,"A",{href:!0});var D4t=s(cX);qVo=r(D4t,"QDQBertForMultipleChoice"),D4t.forEach(t),jVo=r(VSe," (QDQBert model)"),VSe.forEach(t),DVo=i(ee),O4=n(ee,"LI",{});var XSe=s(O4);Vpe=n(XSe,"STRONG",{});var G4t=s(Vpe);GVo=r(G4t,"rembert"),G4t.forEach(t),OVo=r(XSe," \u2014 "),fX=n(XSe,"A",{href:!0});var O4t=s(fX);VVo=r(O4t,"RemBertForMultipleChoice"),O4t.forEach(t),XVo=r(XSe," (RemBERT model)"),XSe.forEach(t),zVo=i(ee),V4=n(ee,"LI",{});var zSe=s(V4);Xpe=n(zSe,"STRONG",{});var V4t=s(Xpe);QVo=r(V4t,"roberta"),V4t.forEach(t),WVo=r(zSe," \u2014 "),mX=n(zSe,"A",{href:!0});var X4t=s(mX);HVo=r(X4t,"RobertaForMultipleChoice"),X4t.forEach(t),UVo=r(zSe," (RoBERTa model)"),zSe.forEach(t),JVo=i(ee),X4=n(ee,"LI",{});var QSe=s(X4);zpe=n(QSe,"STRONG",{});var z4t=s(zpe);YVo=r(z4t,"roformer"),z4t.forEach(t),KVo=r(QSe," \u2014 "),gX=n(QSe,"A",{href:!0});var Q4t=s(gX);ZVo=r(Q4t,"RoFormerForMultipleChoice"),Q4t.forEach(t),eXo=r(QSe," (RoFormer model)"),QSe.forEach(t),oXo=i(ee),z4=n(ee,"LI",{});var WSe=s(z4);Qpe=n(WSe,"STRONG",{});var W4t=s(Qpe);rXo=r(W4t,"squeezebert"),W4t.forEach(t),tXo=r(WSe," \u2014 "),hX=n(WSe,"A",{href:!0});var H4t=s(hX);aXo=r(H4t,"SqueezeBertForMultipleChoice"),H4t.forEach(t),nXo=r(WSe," (SqueezeBERT model)"),WSe.forEach(t),sXo=i(ee),Q4=n(ee,"LI",{});var HSe=s(Q4);Wpe=n(HSe,"STRONG",{});var U4t=s(Wpe);lXo=r(U4t,"xlm"),U4t.forEach(t),iXo=r(HSe," \u2014 "),pX=n(HSe,"A",{href:!0});var J4t=s(pX);dXo=r(J4t,"XLMForMultipleChoice"),J4t.forEach(t),cXo=r(HSe," (XLM model)"),HSe.forEach(t),fXo=i(ee),W4=n(ee,"LI",{});var USe=s(W4);Hpe=n(USe,"STRONG",{});var Y4t=s(Hpe);mXo=r(Y4t,"xlm-roberta"),Y4t.forEach(t),gXo=r(USe," \u2014 "),_X=n(USe,"A",{href:!0});var K4t=s(_X);hXo=r(K4t,"XLMRobertaForMultipleChoice"),K4t.forEach(t),pXo=r(USe," (XLM-RoBERTa model)"),USe.forEach(t),_Xo=i(ee),H4=n(ee,"LI",{});var JSe=s(H4);Upe=n(JSe,"STRONG",{});var Z4t=s(Upe);uXo=r(Z4t,"xlm-roberta-xl"),Z4t.forEach(t),bXo=r(JSe," \u2014 "),uX=n(JSe,"A",{href:!0});var evt=s(uX);vXo=r(evt,"XLMRobertaXLForMultipleChoice"),evt.forEach(t),FXo=r(JSe," (XLM-RoBERTa-XL model)"),JSe.forEach(t),TXo=i(ee),U4=n(ee,"LI",{});var YSe=s(U4);Jpe=n(YSe,"STRONG",{});var ovt=s(Jpe);MXo=r(ovt,"xlnet"),ovt.forEach(t),EXo=r(YSe," \u2014 "),bX=n(YSe,"A",{href:!0});var rvt=s(bX);CXo=r(rvt,"XLNetForMultipleChoice"),rvt.forEach(t),wXo=r(YSe," (XLNet model)"),YSe.forEach(t),AXo=i(ee),J4=n(ee,"LI",{});var KSe=s(J4);Ype=n(KSe,"STRONG",{});var tvt=s(Ype);LXo=r(tvt,"yoso"),tvt.forEach(t),yXo=r(KSe," \u2014 "),vX=n(KSe,"A",{href:!0});var avt=s(vX);xXo=r(avt,"YosoForMultipleChoice"),avt.forEach(t),$Xo=r(KSe," (YOSO model)"),KSe.forEach(t),ee.forEach(t),kXo=i(ca),Y4=n(ca,"P",{});var ZSe=s(Y4);SXo=r(ZSe,"The model is set in evaluation mode by default using "),Kpe=n(ZSe,"CODE",{});var nvt=s(Kpe);RXo=r(nvt,"model.eval()"),nvt.forEach(t),PXo=r(ZSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=n(ZSe,"CODE",{});var svt=s(Zpe);BXo=r(svt,"model.train()"),svt.forEach(t),ZSe.forEach(t),IXo=i(ca),T(K4.$$.fragment,ca),ca.forEach(t),tl.forEach(t),mOe=i(f),rd=n(f,"H2",{class:!0});var bXe=s(rd);Z4=n(bXe,"A",{id:!0,class:!0,href:!0});var lvt=s(Z4);e_e=n(lvt,"SPAN",{});var ivt=s(e_e);T(IL.$$.fragment,ivt),ivt.forEach(t),lvt.forEach(t),NXo=i(bXe),o_e=n(bXe,"SPAN",{});var dvt=s(o_e);qXo=r(dvt,"AutoModelForNextSentencePrediction"),dvt.forEach(t),bXe.forEach(t),gOe=i(f),Io=n(f,"DIV",{class:!0});var al=s(Io);T(NL.$$.fragment,al),jXo=i(al),td=n(al,"P",{});var Roe=s(td);DXo=r(Roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=n(Roe,"A",{href:!0});var cvt=s(FX);GXo=r(cvt,"from_pretrained()"),cvt.forEach(t),OXo=r(Roe," class method or the "),TX=n(Roe,"A",{href:!0});var fvt=s(TX);VXo=r(fvt,"from_config()"),fvt.forEach(t),XXo=r(Roe,` class
method.`),Roe.forEach(t),zXo=i(al),qL=n(al,"P",{});var vXe=s(qL);QXo=r(vXe,"This class cannot be instantiated directly using "),r_e=n(vXe,"CODE",{});var mvt=s(r_e);WXo=r(mvt,"__init__()"),mvt.forEach(t),HXo=r(vXe," (throws an error)."),vXe.forEach(t),UXo=i(al),mt=n(al,"DIV",{class:!0});var z0=s(mt);T(jL.$$.fragment,z0),JXo=i(z0),t_e=n(z0,"P",{});var gvt=s(t_e);YXo=r(gvt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),gvt.forEach(t),KXo=i(z0),ad=n(z0,"P",{});var Poe=s(ad);ZXo=r(Poe,`Note:
Loading a model from its configuration file does `),a_e=n(Poe,"STRONG",{});var hvt=s(a_e);ezo=r(hvt,"not"),hvt.forEach(t),ozo=r(Poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=n(Poe,"A",{href:!0});var pvt=s(MX);rzo=r(pvt,"from_pretrained()"),pvt.forEach(t),tzo=r(Poe," to load the model weights."),Poe.forEach(t),azo=i(z0),T(ev.$$.fragment,z0),z0.forEach(t),nzo=i(al),to=n(al,"DIV",{class:!0});var fa=s(to);T(DL.$$.fragment,fa),szo=i(fa),n_e=n(fa,"P",{});var _vt=s(n_e);lzo=r(_vt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),_vt.forEach(t),izo=i(fa),Da=n(fa,"P",{});var Q0=s(Da);dzo=r(Q0,"The model class to instantiate is selected based on the "),s_e=n(Q0,"CODE",{});var uvt=s(s_e);czo=r(uvt,"model_type"),uvt.forEach(t),fzo=r(Q0,` property of the config object (either
passed as an argument or loaded from `),l_e=n(Q0,"CODE",{});var bvt=s(l_e);mzo=r(bvt,"pretrained_model_name_or_path"),bvt.forEach(t),gzo=r(Q0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=n(Q0,"CODE",{});var vvt=s(i_e);hzo=r(vvt,"pretrained_model_name_or_path"),vvt.forEach(t),pzo=r(Q0,":"),Q0.forEach(t),_zo=i(fa),No=n(fa,"UL",{});var ma=s(No);ov=n(ma,"LI",{});var eRe=s(ov);d_e=n(eRe,"STRONG",{});var Fvt=s(d_e);uzo=r(Fvt,"bert"),Fvt.forEach(t),bzo=r(eRe," \u2014 "),EX=n(eRe,"A",{href:!0});var Tvt=s(EX);vzo=r(Tvt,"BertForNextSentencePrediction"),Tvt.forEach(t),Fzo=r(eRe," (BERT model)"),eRe.forEach(t),Tzo=i(ma),rv=n(ma,"LI",{});var oRe=s(rv);c_e=n(oRe,"STRONG",{});var Mvt=s(c_e);Mzo=r(Mvt,"fnet"),Mvt.forEach(t),Ezo=r(oRe," \u2014 "),CX=n(oRe,"A",{href:!0});var Evt=s(CX);Czo=r(Evt,"FNetForNextSentencePrediction"),Evt.forEach(t),wzo=r(oRe," (FNet model)"),oRe.forEach(t),Azo=i(ma),tv=n(ma,"LI",{});var rRe=s(tv);f_e=n(rRe,"STRONG",{});var Cvt=s(f_e);Lzo=r(Cvt,"megatron-bert"),Cvt.forEach(t),yzo=r(rRe," \u2014 "),wX=n(rRe,"A",{href:!0});var wvt=s(wX);xzo=r(wvt,"MegatronBertForNextSentencePrediction"),wvt.forEach(t),$zo=r(rRe," (Megatron-BERT model)"),rRe.forEach(t),kzo=i(ma),av=n(ma,"LI",{});var tRe=s(av);m_e=n(tRe,"STRONG",{});var Avt=s(m_e);Szo=r(Avt,"mobilebert"),Avt.forEach(t),Rzo=r(tRe," \u2014 "),AX=n(tRe,"A",{href:!0});var Lvt=s(AX);Pzo=r(Lvt,"MobileBertForNextSentencePrediction"),Lvt.forEach(t),Bzo=r(tRe," (MobileBERT model)"),tRe.forEach(t),Izo=i(ma),nv=n(ma,"LI",{});var aRe=s(nv);g_e=n(aRe,"STRONG",{});var yvt=s(g_e);Nzo=r(yvt,"nezha"),yvt.forEach(t),qzo=r(aRe," \u2014 "),LX=n(aRe,"A",{href:!0});var xvt=s(LX);jzo=r(xvt,"NezhaForNextSentencePrediction"),xvt.forEach(t),Dzo=r(aRe," (Nezha model)"),aRe.forEach(t),Gzo=i(ma),sv=n(ma,"LI",{});var nRe=s(sv);h_e=n(nRe,"STRONG",{});var $vt=s(h_e);Ozo=r($vt,"qdqbert"),$vt.forEach(t),Vzo=r(nRe," \u2014 "),yX=n(nRe,"A",{href:!0});var kvt=s(yX);Xzo=r(kvt,"QDQBertForNextSentencePrediction"),kvt.forEach(t),zzo=r(nRe," (QDQBert model)"),nRe.forEach(t),ma.forEach(t),Qzo=i(fa),lv=n(fa,"P",{});var sRe=s(lv);Wzo=r(sRe,"The model is set in evaluation mode by default using "),p_e=n(sRe,"CODE",{});var Svt=s(p_e);Hzo=r(Svt,"model.eval()"),Svt.forEach(t),Uzo=r(sRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),__e=n(sRe,"CODE",{});var Rvt=s(__e);Jzo=r(Rvt,"model.train()"),Rvt.forEach(t),sRe.forEach(t),Yzo=i(fa),T(iv.$$.fragment,fa),fa.forEach(t),al.forEach(t),hOe=i(f),nd=n(f,"H2",{class:!0});var FXe=s(nd);dv=n(FXe,"A",{id:!0,class:!0,href:!0});var Pvt=s(dv);u_e=n(Pvt,"SPAN",{});var Bvt=s(u_e);T(GL.$$.fragment,Bvt),Bvt.forEach(t),Pvt.forEach(t),Kzo=i(FXe),b_e=n(FXe,"SPAN",{});var Ivt=s(b_e);Zzo=r(Ivt,"AutoModelForTokenClassification"),Ivt.forEach(t),FXe.forEach(t),pOe=i(f),qo=n(f,"DIV",{class:!0});var nl=s(qo);T(OL.$$.fragment,nl),eQo=i(nl),sd=n(nl,"P",{});var Boe=s(sd);oQo=r(Boe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=n(Boe,"A",{href:!0});var Nvt=s(xX);rQo=r(Nvt,"from_pretrained()"),Nvt.forEach(t),tQo=r(Boe," class method or the "),$X=n(Boe,"A",{href:!0});var qvt=s($X);aQo=r(qvt,"from_config()"),qvt.forEach(t),nQo=r(Boe,` class
method.`),Boe.forEach(t),sQo=i(nl),VL=n(nl,"P",{});var TXe=s(VL);lQo=r(TXe,"This class cannot be instantiated directly using "),v_e=n(TXe,"CODE",{});var jvt=s(v_e);iQo=r(jvt,"__init__()"),jvt.forEach(t),dQo=r(TXe," (throws an error)."),TXe.forEach(t),cQo=i(nl),gt=n(nl,"DIV",{class:!0});var W0=s(gt);T(XL.$$.fragment,W0),fQo=i(W0),F_e=n(W0,"P",{});var Dvt=s(F_e);mQo=r(Dvt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Dvt.forEach(t),gQo=i(W0),ld=n(W0,"P",{});var Ioe=s(ld);hQo=r(Ioe,`Note:
Loading a model from its configuration file does `),T_e=n(Ioe,"STRONG",{});var Gvt=s(T_e);pQo=r(Gvt,"not"),Gvt.forEach(t),_Qo=r(Ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=n(Ioe,"A",{href:!0});var Ovt=s(kX);uQo=r(Ovt,"from_pretrained()"),Ovt.forEach(t),bQo=r(Ioe," to load the model weights."),Ioe.forEach(t),vQo=i(W0),T(cv.$$.fragment,W0),W0.forEach(t),FQo=i(nl),ao=n(nl,"DIV",{class:!0});var ga=s(ao);T(zL.$$.fragment,ga),TQo=i(ga),M_e=n(ga,"P",{});var Vvt=s(M_e);MQo=r(Vvt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Vvt.forEach(t),EQo=i(ga),Ga=n(ga,"P",{});var H0=s(Ga);CQo=r(H0,"The model class to instantiate is selected based on the "),E_e=n(H0,"CODE",{});var Xvt=s(E_e);wQo=r(Xvt,"model_type"),Xvt.forEach(t),AQo=r(H0,` property of the config object (either
passed as an argument or loaded from `),C_e=n(H0,"CODE",{});var zvt=s(C_e);LQo=r(zvt,"pretrained_model_name_or_path"),zvt.forEach(t),yQo=r(H0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=n(H0,"CODE",{});var Qvt=s(w_e);xQo=r(Qvt,"pretrained_model_name_or_path"),Qvt.forEach(t),$Qo=r(H0,":"),H0.forEach(t),kQo=i(ga),H=n(ga,"UL",{});var J=s(H);fv=n(J,"LI",{});var lRe=s(fv);A_e=n(lRe,"STRONG",{});var Wvt=s(A_e);SQo=r(Wvt,"albert"),Wvt.forEach(t),RQo=r(lRe," \u2014 "),SX=n(lRe,"A",{href:!0});var Hvt=s(SX);PQo=r(Hvt,"AlbertForTokenClassification"),Hvt.forEach(t),BQo=r(lRe," (ALBERT model)"),lRe.forEach(t),IQo=i(J),mv=n(J,"LI",{});var iRe=s(mv);L_e=n(iRe,"STRONG",{});var Uvt=s(L_e);NQo=r(Uvt,"bert"),Uvt.forEach(t),qQo=r(iRe," \u2014 "),RX=n(iRe,"A",{href:!0});var Jvt=s(RX);jQo=r(Jvt,"BertForTokenClassification"),Jvt.forEach(t),DQo=r(iRe," (BERT model)"),iRe.forEach(t),GQo=i(J),gv=n(J,"LI",{});var dRe=s(gv);y_e=n(dRe,"STRONG",{});var Yvt=s(y_e);OQo=r(Yvt,"big_bird"),Yvt.forEach(t),VQo=r(dRe," \u2014 "),PX=n(dRe,"A",{href:!0});var Kvt=s(PX);XQo=r(Kvt,"BigBirdForTokenClassification"),Kvt.forEach(t),zQo=r(dRe," (BigBird model)"),dRe.forEach(t),QQo=i(J),hv=n(J,"LI",{});var cRe=s(hv);x_e=n(cRe,"STRONG",{});var Zvt=s(x_e);WQo=r(Zvt,"bloom"),Zvt.forEach(t),HQo=r(cRe," \u2014 "),BX=n(cRe,"A",{href:!0});var eFt=s(BX);UQo=r(eFt,"BloomForTokenClassification"),eFt.forEach(t),JQo=r(cRe," (BLOOM model)"),cRe.forEach(t),YQo=i(J),pv=n(J,"LI",{});var fRe=s(pv);$_e=n(fRe,"STRONG",{});var oFt=s($_e);KQo=r(oFt,"camembert"),oFt.forEach(t),ZQo=r(fRe," \u2014 "),IX=n(fRe,"A",{href:!0});var rFt=s(IX);eWo=r(rFt,"CamembertForTokenClassification"),rFt.forEach(t),oWo=r(fRe," (CamemBERT model)"),fRe.forEach(t),rWo=i(J),_v=n(J,"LI",{});var mRe=s(_v);k_e=n(mRe,"STRONG",{});var tFt=s(k_e);tWo=r(tFt,"canine"),tFt.forEach(t),aWo=r(mRe," \u2014 "),NX=n(mRe,"A",{href:!0});var aFt=s(NX);nWo=r(aFt,"CanineForTokenClassification"),aFt.forEach(t),sWo=r(mRe," (CANINE model)"),mRe.forEach(t),lWo=i(J),uv=n(J,"LI",{});var gRe=s(uv);S_e=n(gRe,"STRONG",{});var nFt=s(S_e);iWo=r(nFt,"convbert"),nFt.forEach(t),dWo=r(gRe," \u2014 "),qX=n(gRe,"A",{href:!0});var sFt=s(qX);cWo=r(sFt,"ConvBertForTokenClassification"),sFt.forEach(t),fWo=r(gRe," (ConvBERT model)"),gRe.forEach(t),mWo=i(J),bv=n(J,"LI",{});var hRe=s(bv);R_e=n(hRe,"STRONG",{});var lFt=s(R_e);gWo=r(lFt,"data2vec-text"),lFt.forEach(t),hWo=r(hRe," \u2014 "),jX=n(hRe,"A",{href:!0});var iFt=s(jX);pWo=r(iFt,"Data2VecTextForTokenClassification"),iFt.forEach(t),_Wo=r(hRe," (Data2VecText model)"),hRe.forEach(t),uWo=i(J),vv=n(J,"LI",{});var pRe=s(vv);P_e=n(pRe,"STRONG",{});var dFt=s(P_e);bWo=r(dFt,"deberta"),dFt.forEach(t),vWo=r(pRe," \u2014 "),DX=n(pRe,"A",{href:!0});var cFt=s(DX);FWo=r(cFt,"DebertaForTokenClassification"),cFt.forEach(t),TWo=r(pRe," (DeBERTa model)"),pRe.forEach(t),MWo=i(J),Fv=n(J,"LI",{});var _Re=s(Fv);B_e=n(_Re,"STRONG",{});var fFt=s(B_e);EWo=r(fFt,"deberta-v2"),fFt.forEach(t),CWo=r(_Re," \u2014 "),GX=n(_Re,"A",{href:!0});var mFt=s(GX);wWo=r(mFt,"DebertaV2ForTokenClassification"),mFt.forEach(t),AWo=r(_Re," (DeBERTa-v2 model)"),_Re.forEach(t),LWo=i(J),Tv=n(J,"LI",{});var uRe=s(Tv);I_e=n(uRe,"STRONG",{});var gFt=s(I_e);yWo=r(gFt,"distilbert"),gFt.forEach(t),xWo=r(uRe," \u2014 "),OX=n(uRe,"A",{href:!0});var hFt=s(OX);$Wo=r(hFt,"DistilBertForTokenClassification"),hFt.forEach(t),kWo=r(uRe," (DistilBERT model)"),uRe.forEach(t),SWo=i(J),Mv=n(J,"LI",{});var bRe=s(Mv);N_e=n(bRe,"STRONG",{});var pFt=s(N_e);RWo=r(pFt,"electra"),pFt.forEach(t),PWo=r(bRe," \u2014 "),VX=n(bRe,"A",{href:!0});var _Ft=s(VX);BWo=r(_Ft,"ElectraForTokenClassification"),_Ft.forEach(t),IWo=r(bRe," (ELECTRA model)"),bRe.forEach(t),NWo=i(J),Ev=n(J,"LI",{});var vRe=s(Ev);q_e=n(vRe,"STRONG",{});var uFt=s(q_e);qWo=r(uFt,"flaubert"),uFt.forEach(t),jWo=r(vRe," \u2014 "),XX=n(vRe,"A",{href:!0});var bFt=s(XX);DWo=r(bFt,"FlaubertForTokenClassification"),bFt.forEach(t),GWo=r(vRe," (FlauBERT model)"),vRe.forEach(t),OWo=i(J),Cv=n(J,"LI",{});var FRe=s(Cv);j_e=n(FRe,"STRONG",{});var vFt=s(j_e);VWo=r(vFt,"fnet"),vFt.forEach(t),XWo=r(FRe," \u2014 "),zX=n(FRe,"A",{href:!0});var FFt=s(zX);zWo=r(FFt,"FNetForTokenClassification"),FFt.forEach(t),QWo=r(FRe," (FNet model)"),FRe.forEach(t),WWo=i(J),wv=n(J,"LI",{});var TRe=s(wv);D_e=n(TRe,"STRONG",{});var TFt=s(D_e);HWo=r(TFt,"funnel"),TFt.forEach(t),UWo=r(TRe," \u2014 "),QX=n(TRe,"A",{href:!0});var MFt=s(QX);JWo=r(MFt,"FunnelForTokenClassification"),MFt.forEach(t),YWo=r(TRe," (Funnel Transformer model)"),TRe.forEach(t),KWo=i(J),Av=n(J,"LI",{});var MRe=s(Av);G_e=n(MRe,"STRONG",{});var EFt=s(G_e);ZWo=r(EFt,"gpt2"),EFt.forEach(t),eHo=r(MRe," \u2014 "),WX=n(MRe,"A",{href:!0});var CFt=s(WX);oHo=r(CFt,"GPT2ForTokenClassification"),CFt.forEach(t),rHo=r(MRe," (OpenAI GPT-2 model)"),MRe.forEach(t),tHo=i(J),Lv=n(J,"LI",{});var ERe=s(Lv);O_e=n(ERe,"STRONG",{});var wFt=s(O_e);aHo=r(wFt,"ibert"),wFt.forEach(t),nHo=r(ERe," \u2014 "),HX=n(ERe,"A",{href:!0});var AFt=s(HX);sHo=r(AFt,"IBertForTokenClassification"),AFt.forEach(t),lHo=r(ERe," (I-BERT model)"),ERe.forEach(t),iHo=i(J),yv=n(J,"LI",{});var CRe=s(yv);V_e=n(CRe,"STRONG",{});var LFt=s(V_e);dHo=r(LFt,"layoutlm"),LFt.forEach(t),cHo=r(CRe," \u2014 "),UX=n(CRe,"A",{href:!0});var yFt=s(UX);fHo=r(yFt,"LayoutLMForTokenClassification"),yFt.forEach(t),mHo=r(CRe," (LayoutLM model)"),CRe.forEach(t),gHo=i(J),xv=n(J,"LI",{});var wRe=s(xv);X_e=n(wRe,"STRONG",{});var xFt=s(X_e);hHo=r(xFt,"layoutlmv2"),xFt.forEach(t),pHo=r(wRe," \u2014 "),JX=n(wRe,"A",{href:!0});var $Ft=s(JX);_Ho=r($Ft,"LayoutLMv2ForTokenClassification"),$Ft.forEach(t),uHo=r(wRe," (LayoutLMv2 model)"),wRe.forEach(t),bHo=i(J),$v=n(J,"LI",{});var ARe=s($v);z_e=n(ARe,"STRONG",{});var kFt=s(z_e);vHo=r(kFt,"layoutlmv3"),kFt.forEach(t),FHo=r(ARe," \u2014 "),YX=n(ARe,"A",{href:!0});var SFt=s(YX);THo=r(SFt,"LayoutLMv3ForTokenClassification"),SFt.forEach(t),MHo=r(ARe," (LayoutLMv3 model)"),ARe.forEach(t),EHo=i(J),kv=n(J,"LI",{});var LRe=s(kv);Q_e=n(LRe,"STRONG",{});var RFt=s(Q_e);CHo=r(RFt,"longformer"),RFt.forEach(t),wHo=r(LRe," \u2014 "),KX=n(LRe,"A",{href:!0});var PFt=s(KX);AHo=r(PFt,"LongformerForTokenClassification"),PFt.forEach(t),LHo=r(LRe," (Longformer model)"),LRe.forEach(t),yHo=i(J),Sv=n(J,"LI",{});var yRe=s(Sv);W_e=n(yRe,"STRONG",{});var BFt=s(W_e);xHo=r(BFt,"megatron-bert"),BFt.forEach(t),$Ho=r(yRe," \u2014 "),ZX=n(yRe,"A",{href:!0});var IFt=s(ZX);kHo=r(IFt,"MegatronBertForTokenClassification"),IFt.forEach(t),SHo=r(yRe," (Megatron-BERT model)"),yRe.forEach(t),RHo=i(J),Rv=n(J,"LI",{});var xRe=s(Rv);H_e=n(xRe,"STRONG",{});var NFt=s(H_e);PHo=r(NFt,"mobilebert"),NFt.forEach(t),BHo=r(xRe," \u2014 "),ez=n(xRe,"A",{href:!0});var qFt=s(ez);IHo=r(qFt,"MobileBertForTokenClassification"),qFt.forEach(t),NHo=r(xRe," (MobileBERT model)"),xRe.forEach(t),qHo=i(J),Pv=n(J,"LI",{});var $Re=s(Pv);U_e=n($Re,"STRONG",{});var jFt=s(U_e);jHo=r(jFt,"mpnet"),jFt.forEach(t),DHo=r($Re," \u2014 "),oz=n($Re,"A",{href:!0});var DFt=s(oz);GHo=r(DFt,"MPNetForTokenClassification"),DFt.forEach(t),OHo=r($Re," (MPNet model)"),$Re.forEach(t),VHo=i(J),Bv=n(J,"LI",{});var kRe=s(Bv);J_e=n(kRe,"STRONG",{});var GFt=s(J_e);XHo=r(GFt,"nezha"),GFt.forEach(t),zHo=r(kRe," \u2014 "),rz=n(kRe,"A",{href:!0});var OFt=s(rz);QHo=r(OFt,"NezhaForTokenClassification"),OFt.forEach(t),WHo=r(kRe," (Nezha model)"),kRe.forEach(t),HHo=i(J),Iv=n(J,"LI",{});var SRe=s(Iv);Y_e=n(SRe,"STRONG",{});var VFt=s(Y_e);UHo=r(VFt,"nystromformer"),VFt.forEach(t),JHo=r(SRe," \u2014 "),tz=n(SRe,"A",{href:!0});var XFt=s(tz);YHo=r(XFt,"NystromformerForTokenClassification"),XFt.forEach(t),KHo=r(SRe," (Nystr\xF6mformer model)"),SRe.forEach(t),ZHo=i(J),Nv=n(J,"LI",{});var RRe=s(Nv);K_e=n(RRe,"STRONG",{});var zFt=s(K_e);eUo=r(zFt,"qdqbert"),zFt.forEach(t),oUo=r(RRe," \u2014 "),az=n(RRe,"A",{href:!0});var QFt=s(az);rUo=r(QFt,"QDQBertForTokenClassification"),QFt.forEach(t),tUo=r(RRe," (QDQBert model)"),RRe.forEach(t),aUo=i(J),qv=n(J,"LI",{});var PRe=s(qv);Z_e=n(PRe,"STRONG",{});var WFt=s(Z_e);nUo=r(WFt,"rembert"),WFt.forEach(t),sUo=r(PRe," \u2014 "),nz=n(PRe,"A",{href:!0});var HFt=s(nz);lUo=r(HFt,"RemBertForTokenClassification"),HFt.forEach(t),iUo=r(PRe," (RemBERT model)"),PRe.forEach(t),dUo=i(J),jv=n(J,"LI",{});var BRe=s(jv);eue=n(BRe,"STRONG",{});var UFt=s(eue);cUo=r(UFt,"roberta"),UFt.forEach(t),fUo=r(BRe," \u2014 "),sz=n(BRe,"A",{href:!0});var JFt=s(sz);mUo=r(JFt,"RobertaForTokenClassification"),JFt.forEach(t),gUo=r(BRe," (RoBERTa model)"),BRe.forEach(t),hUo=i(J),Dv=n(J,"LI",{});var IRe=s(Dv);oue=n(IRe,"STRONG",{});var YFt=s(oue);pUo=r(YFt,"roformer"),YFt.forEach(t),_Uo=r(IRe," \u2014 "),lz=n(IRe,"A",{href:!0});var KFt=s(lz);uUo=r(KFt,"RoFormerForTokenClassification"),KFt.forEach(t),bUo=r(IRe," (RoFormer model)"),IRe.forEach(t),vUo=i(J),Gv=n(J,"LI",{});var NRe=s(Gv);rue=n(NRe,"STRONG",{});var ZFt=s(rue);FUo=r(ZFt,"squeezebert"),ZFt.forEach(t),TUo=r(NRe," \u2014 "),iz=n(NRe,"A",{href:!0});var e6t=s(iz);MUo=r(e6t,"SqueezeBertForTokenClassification"),e6t.forEach(t),EUo=r(NRe," (SqueezeBERT model)"),NRe.forEach(t),CUo=i(J),Ov=n(J,"LI",{});var qRe=s(Ov);tue=n(qRe,"STRONG",{});var o6t=s(tue);wUo=r(o6t,"xlm"),o6t.forEach(t),AUo=r(qRe," \u2014 "),dz=n(qRe,"A",{href:!0});var r6t=s(dz);LUo=r(r6t,"XLMForTokenClassification"),r6t.forEach(t),yUo=r(qRe," (XLM model)"),qRe.forEach(t),xUo=i(J),Vv=n(J,"LI",{});var jRe=s(Vv);aue=n(jRe,"STRONG",{});var t6t=s(aue);$Uo=r(t6t,"xlm-roberta"),t6t.forEach(t),kUo=r(jRe," \u2014 "),cz=n(jRe,"A",{href:!0});var a6t=s(cz);SUo=r(a6t,"XLMRobertaForTokenClassification"),a6t.forEach(t),RUo=r(jRe," (XLM-RoBERTa model)"),jRe.forEach(t),PUo=i(J),Xv=n(J,"LI",{});var DRe=s(Xv);nue=n(DRe,"STRONG",{});var n6t=s(nue);BUo=r(n6t,"xlm-roberta-xl"),n6t.forEach(t),IUo=r(DRe," \u2014 "),fz=n(DRe,"A",{href:!0});var s6t=s(fz);NUo=r(s6t,"XLMRobertaXLForTokenClassification"),s6t.forEach(t),qUo=r(DRe," (XLM-RoBERTa-XL model)"),DRe.forEach(t),jUo=i(J),zv=n(J,"LI",{});var GRe=s(zv);sue=n(GRe,"STRONG",{});var l6t=s(sue);DUo=r(l6t,"xlnet"),l6t.forEach(t),GUo=r(GRe," \u2014 "),mz=n(GRe,"A",{href:!0});var i6t=s(mz);OUo=r(i6t,"XLNetForTokenClassification"),i6t.forEach(t),VUo=r(GRe," (XLNet model)"),GRe.forEach(t),XUo=i(J),Qv=n(J,"LI",{});var ORe=s(Qv);lue=n(ORe,"STRONG",{});var d6t=s(lue);zUo=r(d6t,"yoso"),d6t.forEach(t),QUo=r(ORe," \u2014 "),gz=n(ORe,"A",{href:!0});var c6t=s(gz);WUo=r(c6t,"YosoForTokenClassification"),c6t.forEach(t),HUo=r(ORe," (YOSO model)"),ORe.forEach(t),J.forEach(t),UUo=i(ga),Wv=n(ga,"P",{});var VRe=s(Wv);JUo=r(VRe,"The model is set in evaluation mode by default using "),iue=n(VRe,"CODE",{});var f6t=s(iue);YUo=r(f6t,"model.eval()"),f6t.forEach(t),KUo=r(VRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),due=n(VRe,"CODE",{});var m6t=s(due);ZUo=r(m6t,"model.train()"),m6t.forEach(t),VRe.forEach(t),eJo=i(ga),T(Hv.$$.fragment,ga),ga.forEach(t),nl.forEach(t),_Oe=i(f),id=n(f,"H2",{class:!0});var MXe=s(id);Uv=n(MXe,"A",{id:!0,class:!0,href:!0});var g6t=s(Uv);cue=n(g6t,"SPAN",{});var h6t=s(cue);T(QL.$$.fragment,h6t),h6t.forEach(t),g6t.forEach(t),oJo=i(MXe),fue=n(MXe,"SPAN",{});var p6t=s(fue);rJo=r(p6t,"AutoModelForQuestionAnswering"),p6t.forEach(t),MXe.forEach(t),uOe=i(f),jo=n(f,"DIV",{class:!0});var sl=s(jo);T(WL.$$.fragment,sl),tJo=i(sl),dd=n(sl,"P",{});var Noe=s(dd);aJo=r(Noe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=n(Noe,"A",{href:!0});var _6t=s(hz);nJo=r(_6t,"from_pretrained()"),_6t.forEach(t),sJo=r(Noe," class method or the "),pz=n(Noe,"A",{href:!0});var u6t=s(pz);lJo=r(u6t,"from_config()"),u6t.forEach(t),iJo=r(Noe,` class
method.`),Noe.forEach(t),dJo=i(sl),HL=n(sl,"P",{});var EXe=s(HL);cJo=r(EXe,"This class cannot be instantiated directly using "),mue=n(EXe,"CODE",{});var b6t=s(mue);fJo=r(b6t,"__init__()"),b6t.forEach(t),mJo=r(EXe," (throws an error)."),EXe.forEach(t),gJo=i(sl),ht=n(sl,"DIV",{class:!0});var U0=s(ht);T(UL.$$.fragment,U0),hJo=i(U0),gue=n(U0,"P",{});var v6t=s(gue);pJo=r(v6t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),v6t.forEach(t),_Jo=i(U0),cd=n(U0,"P",{});var qoe=s(cd);uJo=r(qoe,`Note:
Loading a model from its configuration file does `),hue=n(qoe,"STRONG",{});var F6t=s(hue);bJo=r(F6t,"not"),F6t.forEach(t),vJo=r(qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),_z=n(qoe,"A",{href:!0});var T6t=s(_z);FJo=r(T6t,"from_pretrained()"),T6t.forEach(t),TJo=r(qoe," to load the model weights."),qoe.forEach(t),MJo=i(U0),T(Jv.$$.fragment,U0),U0.forEach(t),EJo=i(sl),no=n(sl,"DIV",{class:!0});var ha=s(no);T(JL.$$.fragment,ha),CJo=i(ha),pue=n(ha,"P",{});var M6t=s(pue);wJo=r(M6t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),M6t.forEach(t),AJo=i(ha),Oa=n(ha,"P",{});var J0=s(Oa);LJo=r(J0,"The model class to instantiate is selected based on the "),_ue=n(J0,"CODE",{});var E6t=s(_ue);yJo=r(E6t,"model_type"),E6t.forEach(t),xJo=r(J0,` property of the config object (either
passed as an argument or loaded from `),uue=n(J0,"CODE",{});var C6t=s(uue);$Jo=r(C6t,"pretrained_model_name_or_path"),C6t.forEach(t),kJo=r(J0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=n(J0,"CODE",{});var w6t=s(bue);SJo=r(w6t,"pretrained_model_name_or_path"),w6t.forEach(t),RJo=r(J0,":"),J0.forEach(t),PJo=i(ha),V=n(ha,"UL",{});var X=s(V);Yv=n(X,"LI",{});var XRe=s(Yv);vue=n(XRe,"STRONG",{});var A6t=s(vue);BJo=r(A6t,"albert"),A6t.forEach(t),IJo=r(XRe," \u2014 "),uz=n(XRe,"A",{href:!0});var L6t=s(uz);NJo=r(L6t,"AlbertForQuestionAnswering"),L6t.forEach(t),qJo=r(XRe," (ALBERT model)"),XRe.forEach(t),jJo=i(X),Kv=n(X,"LI",{});var zRe=s(Kv);Fue=n(zRe,"STRONG",{});var y6t=s(Fue);DJo=r(y6t,"bart"),y6t.forEach(t),GJo=r(zRe," \u2014 "),bz=n(zRe,"A",{href:!0});var x6t=s(bz);OJo=r(x6t,"BartForQuestionAnswering"),x6t.forEach(t),VJo=r(zRe," (BART model)"),zRe.forEach(t),XJo=i(X),Zv=n(X,"LI",{});var QRe=s(Zv);Tue=n(QRe,"STRONG",{});var $6t=s(Tue);zJo=r($6t,"bert"),$6t.forEach(t),QJo=r(QRe," \u2014 "),vz=n(QRe,"A",{href:!0});var k6t=s(vz);WJo=r(k6t,"BertForQuestionAnswering"),k6t.forEach(t),HJo=r(QRe," (BERT model)"),QRe.forEach(t),UJo=i(X),eF=n(X,"LI",{});var WRe=s(eF);Mue=n(WRe,"STRONG",{});var S6t=s(Mue);JJo=r(S6t,"big_bird"),S6t.forEach(t),YJo=r(WRe," \u2014 "),Fz=n(WRe,"A",{href:!0});var R6t=s(Fz);KJo=r(R6t,"BigBirdForQuestionAnswering"),R6t.forEach(t),ZJo=r(WRe," (BigBird model)"),WRe.forEach(t),eYo=i(X),oF=n(X,"LI",{});var HRe=s(oF);Eue=n(HRe,"STRONG",{});var P6t=s(Eue);oYo=r(P6t,"bigbird_pegasus"),P6t.forEach(t),rYo=r(HRe," \u2014 "),Tz=n(HRe,"A",{href:!0});var B6t=s(Tz);tYo=r(B6t,"BigBirdPegasusForQuestionAnswering"),B6t.forEach(t),aYo=r(HRe," (BigBird-Pegasus model)"),HRe.forEach(t),nYo=i(X),rF=n(X,"LI",{});var URe=s(rF);Cue=n(URe,"STRONG",{});var I6t=s(Cue);sYo=r(I6t,"camembert"),I6t.forEach(t),lYo=r(URe," \u2014 "),Mz=n(URe,"A",{href:!0});var N6t=s(Mz);iYo=r(N6t,"CamembertForQuestionAnswering"),N6t.forEach(t),dYo=r(URe," (CamemBERT model)"),URe.forEach(t),cYo=i(X),tF=n(X,"LI",{});var JRe=s(tF);wue=n(JRe,"STRONG",{});var q6t=s(wue);fYo=r(q6t,"canine"),q6t.forEach(t),mYo=r(JRe," \u2014 "),Ez=n(JRe,"A",{href:!0});var j6t=s(Ez);gYo=r(j6t,"CanineForQuestionAnswering"),j6t.forEach(t),hYo=r(JRe," (CANINE model)"),JRe.forEach(t),pYo=i(X),aF=n(X,"LI",{});var YRe=s(aF);Aue=n(YRe,"STRONG",{});var D6t=s(Aue);_Yo=r(D6t,"convbert"),D6t.forEach(t),uYo=r(YRe," \u2014 "),Cz=n(YRe,"A",{href:!0});var G6t=s(Cz);bYo=r(G6t,"ConvBertForQuestionAnswering"),G6t.forEach(t),vYo=r(YRe," (ConvBERT model)"),YRe.forEach(t),FYo=i(X),nF=n(X,"LI",{});var KRe=s(nF);Lue=n(KRe,"STRONG",{});var O6t=s(Lue);TYo=r(O6t,"data2vec-text"),O6t.forEach(t),MYo=r(KRe," \u2014 "),wz=n(KRe,"A",{href:!0});var V6t=s(wz);EYo=r(V6t,"Data2VecTextForQuestionAnswering"),V6t.forEach(t),CYo=r(KRe," (Data2VecText model)"),KRe.forEach(t),wYo=i(X),sF=n(X,"LI",{});var ZRe=s(sF);yue=n(ZRe,"STRONG",{});var X6t=s(yue);AYo=r(X6t,"deberta"),X6t.forEach(t),LYo=r(ZRe," \u2014 "),Az=n(ZRe,"A",{href:!0});var z6t=s(Az);yYo=r(z6t,"DebertaForQuestionAnswering"),z6t.forEach(t),xYo=r(ZRe," (DeBERTa model)"),ZRe.forEach(t),$Yo=i(X),lF=n(X,"LI",{});var ePe=s(lF);xue=n(ePe,"STRONG",{});var Q6t=s(xue);kYo=r(Q6t,"deberta-v2"),Q6t.forEach(t),SYo=r(ePe," \u2014 "),Lz=n(ePe,"A",{href:!0});var W6t=s(Lz);RYo=r(W6t,"DebertaV2ForQuestionAnswering"),W6t.forEach(t),PYo=r(ePe," (DeBERTa-v2 model)"),ePe.forEach(t),BYo=i(X),iF=n(X,"LI",{});var oPe=s(iF);$ue=n(oPe,"STRONG",{});var H6t=s($ue);IYo=r(H6t,"distilbert"),H6t.forEach(t),NYo=r(oPe," \u2014 "),yz=n(oPe,"A",{href:!0});var U6t=s(yz);qYo=r(U6t,"DistilBertForQuestionAnswering"),U6t.forEach(t),jYo=r(oPe," (DistilBERT model)"),oPe.forEach(t),DYo=i(X),dF=n(X,"LI",{});var rPe=s(dF);kue=n(rPe,"STRONG",{});var J6t=s(kue);GYo=r(J6t,"electra"),J6t.forEach(t),OYo=r(rPe," \u2014 "),xz=n(rPe,"A",{href:!0});var Y6t=s(xz);VYo=r(Y6t,"ElectraForQuestionAnswering"),Y6t.forEach(t),XYo=r(rPe," (ELECTRA model)"),rPe.forEach(t),zYo=i(X),cF=n(X,"LI",{});var tPe=s(cF);Sue=n(tPe,"STRONG",{});var K6t=s(Sue);QYo=r(K6t,"flaubert"),K6t.forEach(t),WYo=r(tPe," \u2014 "),$z=n(tPe,"A",{href:!0});var Z6t=s($z);HYo=r(Z6t,"FlaubertForQuestionAnsweringSimple"),Z6t.forEach(t),UYo=r(tPe," (FlauBERT model)"),tPe.forEach(t),JYo=i(X),fF=n(X,"LI",{});var aPe=s(fF);Rue=n(aPe,"STRONG",{});var eTt=s(Rue);YYo=r(eTt,"fnet"),eTt.forEach(t),KYo=r(aPe," \u2014 "),kz=n(aPe,"A",{href:!0});var oTt=s(kz);ZYo=r(oTt,"FNetForQuestionAnswering"),oTt.forEach(t),eKo=r(aPe," (FNet model)"),aPe.forEach(t),oKo=i(X),mF=n(X,"LI",{});var nPe=s(mF);Pue=n(nPe,"STRONG",{});var rTt=s(Pue);rKo=r(rTt,"funnel"),rTt.forEach(t),tKo=r(nPe," \u2014 "),Sz=n(nPe,"A",{href:!0});var tTt=s(Sz);aKo=r(tTt,"FunnelForQuestionAnswering"),tTt.forEach(t),nKo=r(nPe," (Funnel Transformer model)"),nPe.forEach(t),sKo=i(X),gF=n(X,"LI",{});var sPe=s(gF);Bue=n(sPe,"STRONG",{});var aTt=s(Bue);lKo=r(aTt,"gptj"),aTt.forEach(t),iKo=r(sPe," \u2014 "),Rz=n(sPe,"A",{href:!0});var nTt=s(Rz);dKo=r(nTt,"GPTJForQuestionAnswering"),nTt.forEach(t),cKo=r(sPe," (GPT-J model)"),sPe.forEach(t),fKo=i(X),hF=n(X,"LI",{});var lPe=s(hF);Iue=n(lPe,"STRONG",{});var sTt=s(Iue);mKo=r(sTt,"ibert"),sTt.forEach(t),gKo=r(lPe," \u2014 "),Pz=n(lPe,"A",{href:!0});var lTt=s(Pz);hKo=r(lTt,"IBertForQuestionAnswering"),lTt.forEach(t),pKo=r(lPe," (I-BERT model)"),lPe.forEach(t),_Ko=i(X),pF=n(X,"LI",{});var iPe=s(pF);Nue=n(iPe,"STRONG",{});var iTt=s(Nue);uKo=r(iTt,"layoutlmv2"),iTt.forEach(t),bKo=r(iPe," \u2014 "),Bz=n(iPe,"A",{href:!0});var dTt=s(Bz);vKo=r(dTt,"LayoutLMv2ForQuestionAnswering"),dTt.forEach(t),FKo=r(iPe," (LayoutLMv2 model)"),iPe.forEach(t),TKo=i(X),_F=n(X,"LI",{});var dPe=s(_F);que=n(dPe,"STRONG",{});var cTt=s(que);MKo=r(cTt,"layoutlmv3"),cTt.forEach(t),EKo=r(dPe," \u2014 "),Iz=n(dPe,"A",{href:!0});var fTt=s(Iz);CKo=r(fTt,"LayoutLMv3ForQuestionAnswering"),fTt.forEach(t),wKo=r(dPe," (LayoutLMv3 model)"),dPe.forEach(t),AKo=i(X),uF=n(X,"LI",{});var cPe=s(uF);jue=n(cPe,"STRONG",{});var mTt=s(jue);LKo=r(mTt,"led"),mTt.forEach(t),yKo=r(cPe," \u2014 "),Nz=n(cPe,"A",{href:!0});var gTt=s(Nz);xKo=r(gTt,"LEDForQuestionAnswering"),gTt.forEach(t),$Ko=r(cPe," (LED model)"),cPe.forEach(t),kKo=i(X),bF=n(X,"LI",{});var fPe=s(bF);Due=n(fPe,"STRONG",{});var hTt=s(Due);SKo=r(hTt,"longformer"),hTt.forEach(t),RKo=r(fPe," \u2014 "),qz=n(fPe,"A",{href:!0});var pTt=s(qz);PKo=r(pTt,"LongformerForQuestionAnswering"),pTt.forEach(t),BKo=r(fPe," (Longformer model)"),fPe.forEach(t),IKo=i(X),vF=n(X,"LI",{});var mPe=s(vF);Gue=n(mPe,"STRONG",{});var _Tt=s(Gue);NKo=r(_Tt,"lxmert"),_Tt.forEach(t),qKo=r(mPe," \u2014 "),jz=n(mPe,"A",{href:!0});var uTt=s(jz);jKo=r(uTt,"LxmertForQuestionAnswering"),uTt.forEach(t),DKo=r(mPe," (LXMERT model)"),mPe.forEach(t),GKo=i(X),FF=n(X,"LI",{});var gPe=s(FF);Oue=n(gPe,"STRONG",{});var bTt=s(Oue);OKo=r(bTt,"mbart"),bTt.forEach(t),VKo=r(gPe," \u2014 "),Dz=n(gPe,"A",{href:!0});var vTt=s(Dz);XKo=r(vTt,"MBartForQuestionAnswering"),vTt.forEach(t),zKo=r(gPe," (mBART model)"),gPe.forEach(t),QKo=i(X),TF=n(X,"LI",{});var hPe=s(TF);Vue=n(hPe,"STRONG",{});var FTt=s(Vue);WKo=r(FTt,"megatron-bert"),FTt.forEach(t),HKo=r(hPe," \u2014 "),Gz=n(hPe,"A",{href:!0});var TTt=s(Gz);UKo=r(TTt,"MegatronBertForQuestionAnswering"),TTt.forEach(t),JKo=r(hPe," (Megatron-BERT model)"),hPe.forEach(t),YKo=i(X),MF=n(X,"LI",{});var pPe=s(MF);Xue=n(pPe,"STRONG",{});var MTt=s(Xue);KKo=r(MTt,"mobilebert"),MTt.forEach(t),ZKo=r(pPe," \u2014 "),Oz=n(pPe,"A",{href:!0});var ETt=s(Oz);eZo=r(ETt,"MobileBertForQuestionAnswering"),ETt.forEach(t),oZo=r(pPe," (MobileBERT model)"),pPe.forEach(t),rZo=i(X),EF=n(X,"LI",{});var _Pe=s(EF);zue=n(_Pe,"STRONG",{});var CTt=s(zue);tZo=r(CTt,"mpnet"),CTt.forEach(t),aZo=r(_Pe," \u2014 "),Vz=n(_Pe,"A",{href:!0});var wTt=s(Vz);nZo=r(wTt,"MPNetForQuestionAnswering"),wTt.forEach(t),sZo=r(_Pe," (MPNet model)"),_Pe.forEach(t),lZo=i(X),CF=n(X,"LI",{});var uPe=s(CF);Que=n(uPe,"STRONG",{});var ATt=s(Que);iZo=r(ATt,"nezha"),ATt.forEach(t),dZo=r(uPe," \u2014 "),Xz=n(uPe,"A",{href:!0});var LTt=s(Xz);cZo=r(LTt,"NezhaForQuestionAnswering"),LTt.forEach(t),fZo=r(uPe," (Nezha model)"),uPe.forEach(t),mZo=i(X),wF=n(X,"LI",{});var bPe=s(wF);Wue=n(bPe,"STRONG",{});var yTt=s(Wue);gZo=r(yTt,"nystromformer"),yTt.forEach(t),hZo=r(bPe," \u2014 "),zz=n(bPe,"A",{href:!0});var xTt=s(zz);pZo=r(xTt,"NystromformerForQuestionAnswering"),xTt.forEach(t),_Zo=r(bPe," (Nystr\xF6mformer model)"),bPe.forEach(t),uZo=i(X),AF=n(X,"LI",{});var vPe=s(AF);Hue=n(vPe,"STRONG",{});var $Tt=s(Hue);bZo=r($Tt,"qdqbert"),$Tt.forEach(t),vZo=r(vPe," \u2014 "),Qz=n(vPe,"A",{href:!0});var kTt=s(Qz);FZo=r(kTt,"QDQBertForQuestionAnswering"),kTt.forEach(t),TZo=r(vPe," (QDQBert model)"),vPe.forEach(t),MZo=i(X),LF=n(X,"LI",{});var FPe=s(LF);Uue=n(FPe,"STRONG",{});var STt=s(Uue);EZo=r(STt,"reformer"),STt.forEach(t),CZo=r(FPe," \u2014 "),Wz=n(FPe,"A",{href:!0});var RTt=s(Wz);wZo=r(RTt,"ReformerForQuestionAnswering"),RTt.forEach(t),AZo=r(FPe," (Reformer model)"),FPe.forEach(t),LZo=i(X),yF=n(X,"LI",{});var TPe=s(yF);Jue=n(TPe,"STRONG",{});var PTt=s(Jue);yZo=r(PTt,"rembert"),PTt.forEach(t),xZo=r(TPe," \u2014 "),Hz=n(TPe,"A",{href:!0});var BTt=s(Hz);$Zo=r(BTt,"RemBertForQuestionAnswering"),BTt.forEach(t),kZo=r(TPe," (RemBERT model)"),TPe.forEach(t),SZo=i(X),xF=n(X,"LI",{});var MPe=s(xF);Yue=n(MPe,"STRONG",{});var ITt=s(Yue);RZo=r(ITt,"roberta"),ITt.forEach(t),PZo=r(MPe," \u2014 "),Uz=n(MPe,"A",{href:!0});var NTt=s(Uz);BZo=r(NTt,"RobertaForQuestionAnswering"),NTt.forEach(t),IZo=r(MPe," (RoBERTa model)"),MPe.forEach(t),NZo=i(X),$F=n(X,"LI",{});var EPe=s($F);Kue=n(EPe,"STRONG",{});var qTt=s(Kue);qZo=r(qTt,"roformer"),qTt.forEach(t),jZo=r(EPe," \u2014 "),Jz=n(EPe,"A",{href:!0});var jTt=s(Jz);DZo=r(jTt,"RoFormerForQuestionAnswering"),jTt.forEach(t),GZo=r(EPe," (RoFormer model)"),EPe.forEach(t),OZo=i(X),kF=n(X,"LI",{});var CPe=s(kF);Zue=n(CPe,"STRONG",{});var DTt=s(Zue);VZo=r(DTt,"splinter"),DTt.forEach(t),XZo=r(CPe," \u2014 "),Yz=n(CPe,"A",{href:!0});var GTt=s(Yz);zZo=r(GTt,"SplinterForQuestionAnswering"),GTt.forEach(t),QZo=r(CPe," (Splinter model)"),CPe.forEach(t),WZo=i(X),SF=n(X,"LI",{});var wPe=s(SF);e1e=n(wPe,"STRONG",{});var OTt=s(e1e);HZo=r(OTt,"squeezebert"),OTt.forEach(t),UZo=r(wPe," \u2014 "),Kz=n(wPe,"A",{href:!0});var VTt=s(Kz);JZo=r(VTt,"SqueezeBertForQuestionAnswering"),VTt.forEach(t),YZo=r(wPe," (SqueezeBERT model)"),wPe.forEach(t),KZo=i(X),RF=n(X,"LI",{});var APe=s(RF);o1e=n(APe,"STRONG",{});var XTt=s(o1e);ZZo=r(XTt,"xlm"),XTt.forEach(t),eer=r(APe," \u2014 "),Zz=n(APe,"A",{href:!0});var zTt=s(Zz);oer=r(zTt,"XLMForQuestionAnsweringSimple"),zTt.forEach(t),rer=r(APe," (XLM model)"),APe.forEach(t),ter=i(X),PF=n(X,"LI",{});var LPe=s(PF);r1e=n(LPe,"STRONG",{});var QTt=s(r1e);aer=r(QTt,"xlm-roberta"),QTt.forEach(t),ner=r(LPe," \u2014 "),eQ=n(LPe,"A",{href:!0});var WTt=s(eQ);ser=r(WTt,"XLMRobertaForQuestionAnswering"),WTt.forEach(t),ler=r(LPe," (XLM-RoBERTa model)"),LPe.forEach(t),ier=i(X),BF=n(X,"LI",{});var yPe=s(BF);t1e=n(yPe,"STRONG",{});var HTt=s(t1e);der=r(HTt,"xlm-roberta-xl"),HTt.forEach(t),cer=r(yPe," \u2014 "),oQ=n(yPe,"A",{href:!0});var UTt=s(oQ);fer=r(UTt,"XLMRobertaXLForQuestionAnswering"),UTt.forEach(t),mer=r(yPe," (XLM-RoBERTa-XL model)"),yPe.forEach(t),ger=i(X),IF=n(X,"LI",{});var xPe=s(IF);a1e=n(xPe,"STRONG",{});var JTt=s(a1e);her=r(JTt,"xlnet"),JTt.forEach(t),per=r(xPe," \u2014 "),rQ=n(xPe,"A",{href:!0});var YTt=s(rQ);_er=r(YTt,"XLNetForQuestionAnsweringSimple"),YTt.forEach(t),uer=r(xPe," (XLNet model)"),xPe.forEach(t),ber=i(X),NF=n(X,"LI",{});var $Pe=s(NF);n1e=n($Pe,"STRONG",{});var KTt=s(n1e);ver=r(KTt,"yoso"),KTt.forEach(t),Fer=r($Pe," \u2014 "),tQ=n($Pe,"A",{href:!0});var ZTt=s(tQ);Ter=r(ZTt,"YosoForQuestionAnswering"),ZTt.forEach(t),Mer=r($Pe," (YOSO model)"),$Pe.forEach(t),X.forEach(t),Eer=i(ha),qF=n(ha,"P",{});var kPe=s(qF);Cer=r(kPe,"The model is set in evaluation mode by default using "),s1e=n(kPe,"CODE",{});var e7t=s(s1e);wer=r(e7t,"model.eval()"),e7t.forEach(t),Aer=r(kPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l1e=n(kPe,"CODE",{});var o7t=s(l1e);Ler=r(o7t,"model.train()"),o7t.forEach(t),kPe.forEach(t),yer=i(ha),T(jF.$$.fragment,ha),ha.forEach(t),sl.forEach(t),bOe=i(f),fd=n(f,"H2",{class:!0});var CXe=s(fd);DF=n(CXe,"A",{id:!0,class:!0,href:!0});var r7t=s(DF);i1e=n(r7t,"SPAN",{});var t7t=s(i1e);T(YL.$$.fragment,t7t),t7t.forEach(t),r7t.forEach(t),xer=i(CXe),d1e=n(CXe,"SPAN",{});var a7t=s(d1e);$er=r(a7t,"AutoModelForTableQuestionAnswering"),a7t.forEach(t),CXe.forEach(t),vOe=i(f),Do=n(f,"DIV",{class:!0});var ll=s(Do);T(KL.$$.fragment,ll),ker=i(ll),md=n(ll,"P",{});var joe=s(md);Ser=r(joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=n(joe,"A",{href:!0});var n7t=s(aQ);Rer=r(n7t,"from_pretrained()"),n7t.forEach(t),Per=r(joe," class method or the "),nQ=n(joe,"A",{href:!0});var s7t=s(nQ);Ber=r(s7t,"from_config()"),s7t.forEach(t),Ier=r(joe,` class
method.`),joe.forEach(t),Ner=i(ll),ZL=n(ll,"P",{});var wXe=s(ZL);qer=r(wXe,"This class cannot be instantiated directly using "),c1e=n(wXe,"CODE",{});var l7t=s(c1e);jer=r(l7t,"__init__()"),l7t.forEach(t),Der=r(wXe," (throws an error)."),wXe.forEach(t),Ger=i(ll),pt=n(ll,"DIV",{class:!0});var Y0=s(pt);T(ey.$$.fragment,Y0),Oer=i(Y0),f1e=n(Y0,"P",{});var i7t=s(f1e);Ver=r(i7t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),i7t.forEach(t),Xer=i(Y0),gd=n(Y0,"P",{});var Doe=s(gd);zer=r(Doe,`Note:
Loading a model from its configuration file does `),m1e=n(Doe,"STRONG",{});var d7t=s(m1e);Qer=r(d7t,"not"),d7t.forEach(t),Wer=r(Doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=n(Doe,"A",{href:!0});var c7t=s(sQ);Her=r(c7t,"from_pretrained()"),c7t.forEach(t),Uer=r(Doe," to load the model weights."),Doe.forEach(t),Jer=i(Y0),T(GF.$$.fragment,Y0),Y0.forEach(t),Yer=i(ll),so=n(ll,"DIV",{class:!0});var pa=s(so);T(oy.$$.fragment,pa),Ker=i(pa),g1e=n(pa,"P",{});var f7t=s(g1e);Zer=r(f7t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),f7t.forEach(t),eor=i(pa),Va=n(pa,"P",{});var K0=s(Va);oor=r(K0,"The model class to instantiate is selected based on the "),h1e=n(K0,"CODE",{});var m7t=s(h1e);ror=r(m7t,"model_type"),m7t.forEach(t),tor=r(K0,` property of the config object (either
passed as an argument or loaded from `),p1e=n(K0,"CODE",{});var g7t=s(p1e);aor=r(g7t,"pretrained_model_name_or_path"),g7t.forEach(t),nor=r(K0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_1e=n(K0,"CODE",{});var h7t=s(_1e);sor=r(h7t,"pretrained_model_name_or_path"),h7t.forEach(t),lor=r(K0,":"),K0.forEach(t),ior=i(pa),u1e=n(pa,"UL",{});var p7t=s(u1e);OF=n(p7t,"LI",{});var SPe=s(OF);b1e=n(SPe,"STRONG",{});var _7t=s(b1e);dor=r(_7t,"tapas"),_7t.forEach(t),cor=r(SPe," \u2014 "),lQ=n(SPe,"A",{href:!0});var u7t=s(lQ);mor=r(u7t,"TapasForQuestionAnswering"),u7t.forEach(t),gor=r(SPe," (TAPAS model)"),SPe.forEach(t),p7t.forEach(t),hor=i(pa),VF=n(pa,"P",{});var RPe=s(VF);por=r(RPe,"The model is set in evaluation mode by default using "),v1e=n(RPe,"CODE",{});var b7t=s(v1e);_or=r(b7t,"model.eval()"),b7t.forEach(t),uor=r(RPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F1e=n(RPe,"CODE",{});var v7t=s(F1e);bor=r(v7t,"model.train()"),v7t.forEach(t),RPe.forEach(t),vor=i(pa),T(XF.$$.fragment,pa),pa.forEach(t),ll.forEach(t),FOe=i(f),hd=n(f,"H2",{class:!0});var AXe=s(hd);zF=n(AXe,"A",{id:!0,class:!0,href:!0});var F7t=s(zF);T1e=n(F7t,"SPAN",{});var T7t=s(T1e);T(ry.$$.fragment,T7t),T7t.forEach(t),F7t.forEach(t),For=i(AXe),M1e=n(AXe,"SPAN",{});var M7t=s(M1e);Tor=r(M7t,"AutoModelForImageClassification"),M7t.forEach(t),AXe.forEach(t),TOe=i(f),Go=n(f,"DIV",{class:!0});var il=s(Go);T(ty.$$.fragment,il),Mor=i(il),pd=n(il,"P",{});var Goe=s(pd);Eor=r(Goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=n(Goe,"A",{href:!0});var E7t=s(iQ);Cor=r(E7t,"from_pretrained()"),E7t.forEach(t),wor=r(Goe," class method or the "),dQ=n(Goe,"A",{href:!0});var C7t=s(dQ);Aor=r(C7t,"from_config()"),C7t.forEach(t),Lor=r(Goe,` class
method.`),Goe.forEach(t),yor=i(il),ay=n(il,"P",{});var LXe=s(ay);xor=r(LXe,"This class cannot be instantiated directly using "),E1e=n(LXe,"CODE",{});var w7t=s(E1e);$or=r(w7t,"__init__()"),w7t.forEach(t),kor=r(LXe," (throws an error)."),LXe.forEach(t),Sor=i(il),_t=n(il,"DIV",{class:!0});var Z0=s(_t);T(ny.$$.fragment,Z0),Ror=i(Z0),C1e=n(Z0,"P",{});var A7t=s(C1e);Por=r(A7t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),A7t.forEach(t),Bor=i(Z0),_d=n(Z0,"P",{});var Ooe=s(_d);Ior=r(Ooe,`Note:
Loading a model from its configuration file does `),w1e=n(Ooe,"STRONG",{});var L7t=s(w1e);Nor=r(L7t,"not"),L7t.forEach(t),qor=r(Ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(Ooe,"A",{href:!0});var y7t=s(cQ);jor=r(y7t,"from_pretrained()"),y7t.forEach(t),Dor=r(Ooe," to load the model weights."),Ooe.forEach(t),Gor=i(Z0),T(QF.$$.fragment,Z0),Z0.forEach(t),Oor=i(il),lo=n(il,"DIV",{class:!0});var _a=s(lo);T(sy.$$.fragment,_a),Vor=i(_a),A1e=n(_a,"P",{});var x7t=s(A1e);Xor=r(x7t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),x7t.forEach(t),zor=i(_a),Xa=n(_a,"P",{});var ew=s(Xa);Qor=r(ew,"The model class to instantiate is selected based on the "),L1e=n(ew,"CODE",{});var $7t=s(L1e);Wor=r($7t,"model_type"),$7t.forEach(t),Hor=r(ew,` property of the config object (either
passed as an argument or loaded from `),y1e=n(ew,"CODE",{});var k7t=s(y1e);Uor=r(k7t,"pretrained_model_name_or_path"),k7t.forEach(t),Jor=r(ew,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x1e=n(ew,"CODE",{});var S7t=s(x1e);Yor=r(S7t,"pretrained_model_name_or_path"),S7t.forEach(t),Kor=r(ew,":"),ew.forEach(t),Zor=i(_a),Fe=n(_a,"UL",{});var Te=s(Fe);WF=n(Te,"LI",{});var PPe=s(WF);$1e=n(PPe,"STRONG",{});var R7t=s($1e);err=r(R7t,"beit"),R7t.forEach(t),orr=r(PPe," \u2014 "),fQ=n(PPe,"A",{href:!0});var P7t=s(fQ);rrr=r(P7t,"BeitForImageClassification"),P7t.forEach(t),trr=r(PPe," (BEiT model)"),PPe.forEach(t),arr=i(Te),HF=n(Te,"LI",{});var BPe=s(HF);k1e=n(BPe,"STRONG",{});var B7t=s(k1e);nrr=r(B7t,"convnext"),B7t.forEach(t),srr=r(BPe," \u2014 "),mQ=n(BPe,"A",{href:!0});var I7t=s(mQ);lrr=r(I7t,"ConvNextForImageClassification"),I7t.forEach(t),irr=r(BPe," (ConvNeXT model)"),BPe.forEach(t),drr=i(Te),UF=n(Te,"LI",{});var IPe=s(UF);S1e=n(IPe,"STRONG",{});var N7t=s(S1e);crr=r(N7t,"cvt"),N7t.forEach(t),frr=r(IPe," \u2014 "),gQ=n(IPe,"A",{href:!0});var q7t=s(gQ);mrr=r(q7t,"CvtForImageClassification"),q7t.forEach(t),grr=r(IPe," (CvT model)"),IPe.forEach(t),hrr=i(Te),JF=n(Te,"LI",{});var NPe=s(JF);R1e=n(NPe,"STRONG",{});var j7t=s(R1e);prr=r(j7t,"data2vec-vision"),j7t.forEach(t),_rr=r(NPe," \u2014 "),hQ=n(NPe,"A",{href:!0});var D7t=s(hQ);urr=r(D7t,"Data2VecVisionForImageClassification"),D7t.forEach(t),brr=r(NPe," (Data2VecVision model)"),NPe.forEach(t),vrr=i(Te),Xs=n(Te,"LI",{});var Zk=s(Xs);P1e=n(Zk,"STRONG",{});var G7t=s(P1e);Frr=r(G7t,"deit"),G7t.forEach(t),Trr=r(Zk," \u2014 "),pQ=n(Zk,"A",{href:!0});var O7t=s(pQ);Mrr=r(O7t,"DeiTForImageClassification"),O7t.forEach(t),Err=r(Zk," or "),_Q=n(Zk,"A",{href:!0});var V7t=s(_Q);Crr=r(V7t,"DeiTForImageClassificationWithTeacher"),V7t.forEach(t),wrr=r(Zk," (DeiT model)"),Zk.forEach(t),Arr=i(Te),YF=n(Te,"LI",{});var qPe=s(YF);B1e=n(qPe,"STRONG",{});var X7t=s(B1e);Lrr=r(X7t,"imagegpt"),X7t.forEach(t),yrr=r(qPe," \u2014 "),uQ=n(qPe,"A",{href:!0});var z7t=s(uQ);xrr=r(z7t,"ImageGPTForImageClassification"),z7t.forEach(t),$rr=r(qPe," (ImageGPT model)"),qPe.forEach(t),krr=i(Te),zs=n(Te,"LI",{});var eS=s(zs);I1e=n(eS,"STRONG",{});var Q7t=s(I1e);Srr=r(Q7t,"levit"),Q7t.forEach(t),Rrr=r(eS," \u2014 "),bQ=n(eS,"A",{href:!0});var W7t=s(bQ);Prr=r(W7t,"LevitForImageClassification"),W7t.forEach(t),Brr=r(eS," or "),vQ=n(eS,"A",{href:!0});var H7t=s(vQ);Irr=r(H7t,"LevitForImageClassificationWithTeacher"),H7t.forEach(t),Nrr=r(eS," (LeViT model)"),eS.forEach(t),qrr=i(Te),ut=n(Te,"LI",{});var Lf=s(ut);N1e=n(Lf,"STRONG",{});var U7t=s(N1e);jrr=r(U7t,"perceiver"),U7t.forEach(t),Drr=r(Lf," \u2014 "),FQ=n(Lf,"A",{href:!0});var J7t=s(FQ);Grr=r(J7t,"PerceiverForImageClassificationLearned"),J7t.forEach(t),Orr=r(Lf," or "),TQ=n(Lf,"A",{href:!0});var Y7t=s(TQ);Vrr=r(Y7t,"PerceiverForImageClassificationFourier"),Y7t.forEach(t),Xrr=r(Lf," or "),MQ=n(Lf,"A",{href:!0});var K7t=s(MQ);zrr=r(K7t,"PerceiverForImageClassificationConvProcessing"),K7t.forEach(t),Qrr=r(Lf," (Perceiver model)"),Lf.forEach(t),Wrr=i(Te),KF=n(Te,"LI",{});var jPe=s(KF);q1e=n(jPe,"STRONG",{});var Z7t=s(q1e);Hrr=r(Z7t,"poolformer"),Z7t.forEach(t),Urr=r(jPe," \u2014 "),EQ=n(jPe,"A",{href:!0});var e8t=s(EQ);Jrr=r(e8t,"PoolFormerForImageClassification"),e8t.forEach(t),Yrr=r(jPe," (PoolFormer model)"),jPe.forEach(t),Krr=i(Te),ZF=n(Te,"LI",{});var DPe=s(ZF);j1e=n(DPe,"STRONG",{});var o8t=s(j1e);Zrr=r(o8t,"regnet"),o8t.forEach(t),etr=r(DPe," \u2014 "),CQ=n(DPe,"A",{href:!0});var r8t=s(CQ);otr=r(r8t,"RegNetForImageClassification"),r8t.forEach(t),rtr=r(DPe," (RegNet model)"),DPe.forEach(t),ttr=i(Te),e6=n(Te,"LI",{});var GPe=s(e6);D1e=n(GPe,"STRONG",{});var t8t=s(D1e);atr=r(t8t,"resnet"),t8t.forEach(t),ntr=r(GPe," \u2014 "),wQ=n(GPe,"A",{href:!0});var a8t=s(wQ);str=r(a8t,"ResNetForImageClassification"),a8t.forEach(t),ltr=r(GPe," (ResNet model)"),GPe.forEach(t),itr=i(Te),o6=n(Te,"LI",{});var OPe=s(o6);G1e=n(OPe,"STRONG",{});var n8t=s(G1e);dtr=r(n8t,"segformer"),n8t.forEach(t),ctr=r(OPe," \u2014 "),AQ=n(OPe,"A",{href:!0});var s8t=s(AQ);ftr=r(s8t,"SegformerForImageClassification"),s8t.forEach(t),mtr=r(OPe," (SegFormer model)"),OPe.forEach(t),gtr=i(Te),r6=n(Te,"LI",{});var VPe=s(r6);O1e=n(VPe,"STRONG",{});var l8t=s(O1e);htr=r(l8t,"swin"),l8t.forEach(t),ptr=r(VPe," \u2014 "),LQ=n(VPe,"A",{href:!0});var i8t=s(LQ);_tr=r(i8t,"SwinForImageClassification"),i8t.forEach(t),utr=r(VPe," (Swin Transformer model)"),VPe.forEach(t),btr=i(Te),t6=n(Te,"LI",{});var XPe=s(t6);V1e=n(XPe,"STRONG",{});var d8t=s(V1e);vtr=r(d8t,"van"),d8t.forEach(t),Ftr=r(XPe," \u2014 "),yQ=n(XPe,"A",{href:!0});var c8t=s(yQ);Ttr=r(c8t,"VanForImageClassification"),c8t.forEach(t),Mtr=r(XPe," (VAN model)"),XPe.forEach(t),Etr=i(Te),a6=n(Te,"LI",{});var zPe=s(a6);X1e=n(zPe,"STRONG",{});var f8t=s(X1e);Ctr=r(f8t,"vit"),f8t.forEach(t),wtr=r(zPe," \u2014 "),xQ=n(zPe,"A",{href:!0});var m8t=s(xQ);Atr=r(m8t,"ViTForImageClassification"),m8t.forEach(t),Ltr=r(zPe," (ViT model)"),zPe.forEach(t),Te.forEach(t),ytr=i(_a),n6=n(_a,"P",{});var QPe=s(n6);xtr=r(QPe,"The model is set in evaluation mode by default using "),z1e=n(QPe,"CODE",{});var g8t=s(z1e);$tr=r(g8t,"model.eval()"),g8t.forEach(t),ktr=r(QPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q1e=n(QPe,"CODE",{});var h8t=s(Q1e);Str=r(h8t,"model.train()"),h8t.forEach(t),QPe.forEach(t),Rtr=i(_a),T(s6.$$.fragment,_a),_a.forEach(t),il.forEach(t),MOe=i(f),ud=n(f,"H2",{class:!0});var yXe=s(ud);l6=n(yXe,"A",{id:!0,class:!0,href:!0});var p8t=s(l6);W1e=n(p8t,"SPAN",{});var _8t=s(W1e);T(ly.$$.fragment,_8t),_8t.forEach(t),p8t.forEach(t),Ptr=i(yXe),H1e=n(yXe,"SPAN",{});var u8t=s(H1e);Btr=r(u8t,"AutoModelForVision2Seq"),u8t.forEach(t),yXe.forEach(t),EOe=i(f),Oo=n(f,"DIV",{class:!0});var dl=s(Oo);T(iy.$$.fragment,dl),Itr=i(dl),bd=n(dl,"P",{});var Voe=s(bd);Ntr=r(Voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=n(Voe,"A",{href:!0});var b8t=s($Q);qtr=r(b8t,"from_pretrained()"),b8t.forEach(t),jtr=r(Voe," class method or the "),kQ=n(Voe,"A",{href:!0});var v8t=s(kQ);Dtr=r(v8t,"from_config()"),v8t.forEach(t),Gtr=r(Voe,` class
method.`),Voe.forEach(t),Otr=i(dl),dy=n(dl,"P",{});var xXe=s(dy);Vtr=r(xXe,"This class cannot be instantiated directly using "),U1e=n(xXe,"CODE",{});var F8t=s(U1e);Xtr=r(F8t,"__init__()"),F8t.forEach(t),ztr=r(xXe," (throws an error)."),xXe.forEach(t),Qtr=i(dl),bt=n(dl,"DIV",{class:!0});var ow=s(bt);T(cy.$$.fragment,ow),Wtr=i(ow),J1e=n(ow,"P",{});var T8t=s(J1e);Htr=r(T8t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),T8t.forEach(t),Utr=i(ow),vd=n(ow,"P",{});var Xoe=s(vd);Jtr=r(Xoe,`Note:
Loading a model from its configuration file does `),Y1e=n(Xoe,"STRONG",{});var M8t=s(Y1e);Ytr=r(M8t,"not"),M8t.forEach(t),Ktr=r(Xoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=n(Xoe,"A",{href:!0});var E8t=s(SQ);Ztr=r(E8t,"from_pretrained()"),E8t.forEach(t),ear=r(Xoe," to load the model weights."),Xoe.forEach(t),oar=i(ow),T(i6.$$.fragment,ow),ow.forEach(t),rar=i(dl),io=n(dl,"DIV",{class:!0});var ua=s(io);T(fy.$$.fragment,ua),tar=i(ua),K1e=n(ua,"P",{});var C8t=s(K1e);aar=r(C8t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),C8t.forEach(t),nar=i(ua),za=n(ua,"P",{});var rw=s(za);sar=r(rw,"The model class to instantiate is selected based on the "),Z1e=n(rw,"CODE",{});var w8t=s(Z1e);lar=r(w8t,"model_type"),w8t.forEach(t),iar=r(rw,` property of the config object (either
passed as an argument or loaded from `),e2e=n(rw,"CODE",{});var A8t=s(e2e);dar=r(A8t,"pretrained_model_name_or_path"),A8t.forEach(t),car=r(rw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o2e=n(rw,"CODE",{});var L8t=s(o2e);far=r(L8t,"pretrained_model_name_or_path"),L8t.forEach(t),mar=r(rw,":"),rw.forEach(t),gar=i(ua),r2e=n(ua,"UL",{});var y8t=s(r2e);d6=n(y8t,"LI",{});var WPe=s(d6);t2e=n(WPe,"STRONG",{});var x8t=s(t2e);har=r(x8t,"vision-encoder-decoder"),x8t.forEach(t),par=r(WPe," \u2014 "),RQ=n(WPe,"A",{href:!0});var $8t=s(RQ);_ar=r($8t,"VisionEncoderDecoderModel"),$8t.forEach(t),uar=r(WPe," (Vision Encoder decoder model)"),WPe.forEach(t),y8t.forEach(t),bar=i(ua),c6=n(ua,"P",{});var HPe=s(c6);Far=r(HPe,"The model is set in evaluation mode by default using "),a2e=n(HPe,"CODE",{});var k8t=s(a2e);Tar=r(k8t,"model.eval()"),k8t.forEach(t),Mar=r(HPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n2e=n(HPe,"CODE",{});var S8t=s(n2e);Ear=r(S8t,"model.train()"),S8t.forEach(t),HPe.forEach(t),Car=i(ua),T(f6.$$.fragment,ua),ua.forEach(t),dl.forEach(t),COe=i(f),Fd=n(f,"H2",{class:!0});var $Xe=s(Fd);m6=n($Xe,"A",{id:!0,class:!0,href:!0});var R8t=s(m6);s2e=n(R8t,"SPAN",{});var P8t=s(s2e);T(my.$$.fragment,P8t),P8t.forEach(t),R8t.forEach(t),war=i($Xe),l2e=n($Xe,"SPAN",{});var B8t=s(l2e);Aar=r(B8t,"AutoModelForVisualQuestionAnswering"),B8t.forEach(t),$Xe.forEach(t),wOe=i(f),Vo=n(f,"DIV",{class:!0});var cl=s(Vo);T(gy.$$.fragment,cl),Lar=i(cl),Td=n(cl,"P",{});var zoe=s(Td);yar=r(zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=n(zoe,"A",{href:!0});var I8t=s(PQ);xar=r(I8t,"from_pretrained()"),I8t.forEach(t),$ar=r(zoe," class method or the "),BQ=n(zoe,"A",{href:!0});var N8t=s(BQ);kar=r(N8t,"from_config()"),N8t.forEach(t),Sar=r(zoe,` class
method.`),zoe.forEach(t),Rar=i(cl),hy=n(cl,"P",{});var kXe=s(hy);Par=r(kXe,"This class cannot be instantiated directly using "),i2e=n(kXe,"CODE",{});var q8t=s(i2e);Bar=r(q8t,"__init__()"),q8t.forEach(t),Iar=r(kXe," (throws an error)."),kXe.forEach(t),Nar=i(cl),vt=n(cl,"DIV",{class:!0});var tw=s(vt);T(py.$$.fragment,tw),qar=i(tw),d2e=n(tw,"P",{});var j8t=s(d2e);jar=r(j8t,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),j8t.forEach(t),Dar=i(tw),Md=n(tw,"P",{});var Qoe=s(Md);Gar=r(Qoe,`Note:
Loading a model from its configuration file does `),c2e=n(Qoe,"STRONG",{});var D8t=s(c2e);Oar=r(D8t,"not"),D8t.forEach(t),Var=r(Qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=n(Qoe,"A",{href:!0});var G8t=s(IQ);Xar=r(G8t,"from_pretrained()"),G8t.forEach(t),zar=r(Qoe," to load the model weights."),Qoe.forEach(t),Qar=i(tw),T(g6.$$.fragment,tw),tw.forEach(t),War=i(cl),co=n(cl,"DIV",{class:!0});var ba=s(co);T(_y.$$.fragment,ba),Har=i(ba),f2e=n(ba,"P",{});var O8t=s(f2e);Uar=r(O8t,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),O8t.forEach(t),Jar=i(ba),Qa=n(ba,"P",{});var aw=s(Qa);Yar=r(aw,"The model class to instantiate is selected based on the "),m2e=n(aw,"CODE",{});var V8t=s(m2e);Kar=r(V8t,"model_type"),V8t.forEach(t),Zar=r(aw,` property of the config object (either
passed as an argument or loaded from `),g2e=n(aw,"CODE",{});var X8t=s(g2e);enr=r(X8t,"pretrained_model_name_or_path"),X8t.forEach(t),onr=r(aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h2e=n(aw,"CODE",{});var z8t=s(h2e);rnr=r(z8t,"pretrained_model_name_or_path"),z8t.forEach(t),tnr=r(aw,":"),aw.forEach(t),anr=i(ba),p2e=n(ba,"UL",{});var Q8t=s(p2e);h6=n(Q8t,"LI",{});var UPe=s(h6);_2e=n(UPe,"STRONG",{});var W8t=s(_2e);nnr=r(W8t,"vilt"),W8t.forEach(t),snr=r(UPe," \u2014 "),NQ=n(UPe,"A",{href:!0});var H8t=s(NQ);lnr=r(H8t,"ViltForQuestionAnswering"),H8t.forEach(t),inr=r(UPe," (ViLT model)"),UPe.forEach(t),Q8t.forEach(t),dnr=i(ba),p6=n(ba,"P",{});var JPe=s(p6);cnr=r(JPe,"The model is set in evaluation mode by default using "),u2e=n(JPe,"CODE",{});var U8t=s(u2e);fnr=r(U8t,"model.eval()"),U8t.forEach(t),mnr=r(JPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b2e=n(JPe,"CODE",{});var J8t=s(b2e);gnr=r(J8t,"model.train()"),J8t.forEach(t),JPe.forEach(t),hnr=i(ba),T(_6.$$.fragment,ba),ba.forEach(t),cl.forEach(t),AOe=i(f),Ed=n(f,"H2",{class:!0});var SXe=s(Ed);u6=n(SXe,"A",{id:!0,class:!0,href:!0});var Y8t=s(u6);v2e=n(Y8t,"SPAN",{});var K8t=s(v2e);T(uy.$$.fragment,K8t),K8t.forEach(t),Y8t.forEach(t),pnr=i(SXe),F2e=n(SXe,"SPAN",{});var Z8t=s(F2e);_nr=r(Z8t,"AutoModelForAudioClassification"),Z8t.forEach(t),SXe.forEach(t),LOe=i(f),Xo=n(f,"DIV",{class:!0});var fl=s(Xo);T(by.$$.fragment,fl),unr=i(fl),Cd=n(fl,"P",{});var Woe=s(Cd);bnr=r(Woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=n(Woe,"A",{href:!0});var eMt=s(qQ);vnr=r(eMt,"from_pretrained()"),eMt.forEach(t),Fnr=r(Woe," class method or the "),jQ=n(Woe,"A",{href:!0});var oMt=s(jQ);Tnr=r(oMt,"from_config()"),oMt.forEach(t),Mnr=r(Woe,` class
method.`),Woe.forEach(t),Enr=i(fl),vy=n(fl,"P",{});var RXe=s(vy);Cnr=r(RXe,"This class cannot be instantiated directly using "),T2e=n(RXe,"CODE",{});var rMt=s(T2e);wnr=r(rMt,"__init__()"),rMt.forEach(t),Anr=r(RXe," (throws an error)."),RXe.forEach(t),Lnr=i(fl),Ft=n(fl,"DIV",{class:!0});var nw=s(Ft);T(Fy.$$.fragment,nw),ynr=i(nw),M2e=n(nw,"P",{});var tMt=s(M2e);xnr=r(tMt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),tMt.forEach(t),$nr=i(nw),wd=n(nw,"P",{});var Hoe=s(wd);knr=r(Hoe,`Note:
Loading a model from its configuration file does `),E2e=n(Hoe,"STRONG",{});var aMt=s(E2e);Snr=r(aMt,"not"),aMt.forEach(t),Rnr=r(Hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=n(Hoe,"A",{href:!0});var nMt=s(DQ);Pnr=r(nMt,"from_pretrained()"),nMt.forEach(t),Bnr=r(Hoe," to load the model weights."),Hoe.forEach(t),Inr=i(nw),T(b6.$$.fragment,nw),nw.forEach(t),Nnr=i(fl),fo=n(fl,"DIV",{class:!0});var va=s(fo);T(Ty.$$.fragment,va),qnr=i(va),C2e=n(va,"P",{});var sMt=s(C2e);jnr=r(sMt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),sMt.forEach(t),Dnr=i(va),Wa=n(va,"P",{});var sw=s(Wa);Gnr=r(sw,"The model class to instantiate is selected based on the "),w2e=n(sw,"CODE",{});var lMt=s(w2e);Onr=r(lMt,"model_type"),lMt.forEach(t),Vnr=r(sw,` property of the config object (either
passed as an argument or loaded from `),A2e=n(sw,"CODE",{});var iMt=s(A2e);Xnr=r(iMt,"pretrained_model_name_or_path"),iMt.forEach(t),znr=r(sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=n(sw,"CODE",{});var dMt=s(L2e);Qnr=r(dMt,"pretrained_model_name_or_path"),dMt.forEach(t),Wnr=r(sw,":"),sw.forEach(t),Hnr=i(va),Pe=n(va,"UL",{});var ze=s(Pe);v6=n(ze,"LI",{});var YPe=s(v6);y2e=n(YPe,"STRONG",{});var cMt=s(y2e);Unr=r(cMt,"data2vec-audio"),cMt.forEach(t),Jnr=r(YPe," \u2014 "),GQ=n(YPe,"A",{href:!0});var fMt=s(GQ);Ynr=r(fMt,"Data2VecAudioForSequenceClassification"),fMt.forEach(t),Knr=r(YPe," (Data2VecAudio model)"),YPe.forEach(t),Znr=i(ze),F6=n(ze,"LI",{});var KPe=s(F6);x2e=n(KPe,"STRONG",{});var mMt=s(x2e);esr=r(mMt,"hubert"),mMt.forEach(t),osr=r(KPe," \u2014 "),OQ=n(KPe,"A",{href:!0});var gMt=s(OQ);rsr=r(gMt,"HubertForSequenceClassification"),gMt.forEach(t),tsr=r(KPe," (Hubert model)"),KPe.forEach(t),asr=i(ze),T6=n(ze,"LI",{});var ZPe=s(T6);$2e=n(ZPe,"STRONG",{});var hMt=s($2e);nsr=r(hMt,"sew"),hMt.forEach(t),ssr=r(ZPe," \u2014 "),VQ=n(ZPe,"A",{href:!0});var pMt=s(VQ);lsr=r(pMt,"SEWForSequenceClassification"),pMt.forEach(t),isr=r(ZPe," (SEW model)"),ZPe.forEach(t),dsr=i(ze),M6=n(ze,"LI",{});var eBe=s(M6);k2e=n(eBe,"STRONG",{});var _Mt=s(k2e);csr=r(_Mt,"sew-d"),_Mt.forEach(t),fsr=r(eBe," \u2014 "),XQ=n(eBe,"A",{href:!0});var uMt=s(XQ);msr=r(uMt,"SEWDForSequenceClassification"),uMt.forEach(t),gsr=r(eBe," (SEW-D model)"),eBe.forEach(t),hsr=i(ze),E6=n(ze,"LI",{});var oBe=s(E6);S2e=n(oBe,"STRONG",{});var bMt=s(S2e);psr=r(bMt,"unispeech"),bMt.forEach(t),_sr=r(oBe," \u2014 "),zQ=n(oBe,"A",{href:!0});var vMt=s(zQ);usr=r(vMt,"UniSpeechForSequenceClassification"),vMt.forEach(t),bsr=r(oBe," (UniSpeech model)"),oBe.forEach(t),vsr=i(ze),C6=n(ze,"LI",{});var rBe=s(C6);R2e=n(rBe,"STRONG",{});var FMt=s(R2e);Fsr=r(FMt,"unispeech-sat"),FMt.forEach(t),Tsr=r(rBe," \u2014 "),QQ=n(rBe,"A",{href:!0});var TMt=s(QQ);Msr=r(TMt,"UniSpeechSatForSequenceClassification"),TMt.forEach(t),Esr=r(rBe," (UniSpeechSat model)"),rBe.forEach(t),Csr=i(ze),w6=n(ze,"LI",{});var tBe=s(w6);P2e=n(tBe,"STRONG",{});var MMt=s(P2e);wsr=r(MMt,"wav2vec2"),MMt.forEach(t),Asr=r(tBe," \u2014 "),WQ=n(tBe,"A",{href:!0});var EMt=s(WQ);Lsr=r(EMt,"Wav2Vec2ForSequenceClassification"),EMt.forEach(t),ysr=r(tBe," (Wav2Vec2 model)"),tBe.forEach(t),xsr=i(ze),A6=n(ze,"LI",{});var aBe=s(A6);B2e=n(aBe,"STRONG",{});var CMt=s(B2e);$sr=r(CMt,"wav2vec2-conformer"),CMt.forEach(t),ksr=r(aBe," \u2014 "),HQ=n(aBe,"A",{href:!0});var wMt=s(HQ);Ssr=r(wMt,"Wav2Vec2ConformerForSequenceClassification"),wMt.forEach(t),Rsr=r(aBe," (Wav2Vec2-Conformer model)"),aBe.forEach(t),Psr=i(ze),L6=n(ze,"LI",{});var nBe=s(L6);I2e=n(nBe,"STRONG",{});var AMt=s(I2e);Bsr=r(AMt,"wavlm"),AMt.forEach(t),Isr=r(nBe," \u2014 "),UQ=n(nBe,"A",{href:!0});var LMt=s(UQ);Nsr=r(LMt,"WavLMForSequenceClassification"),LMt.forEach(t),qsr=r(nBe," (WavLM model)"),nBe.forEach(t),ze.forEach(t),jsr=i(va),y6=n(va,"P",{});var sBe=s(y6);Dsr=r(sBe,"The model is set in evaluation mode by default using "),N2e=n(sBe,"CODE",{});var yMt=s(N2e);Gsr=r(yMt,"model.eval()"),yMt.forEach(t),Osr=r(sBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q2e=n(sBe,"CODE",{});var xMt=s(q2e);Vsr=r(xMt,"model.train()"),xMt.forEach(t),sBe.forEach(t),Xsr=i(va),T(x6.$$.fragment,va),va.forEach(t),fl.forEach(t),yOe=i(f),Ad=n(f,"H2",{class:!0});var PXe=s(Ad);$6=n(PXe,"A",{id:!0,class:!0,href:!0});var $Mt=s($6);j2e=n($Mt,"SPAN",{});var kMt=s(j2e);T(My.$$.fragment,kMt),kMt.forEach(t),$Mt.forEach(t),zsr=i(PXe),D2e=n(PXe,"SPAN",{});var SMt=s(D2e);Qsr=r(SMt,"AutoModelForAudioFrameClassification"),SMt.forEach(t),PXe.forEach(t),xOe=i(f),zo=n(f,"DIV",{class:!0});var ml=s(zo);T(Ey.$$.fragment,ml),Wsr=i(ml),Ld=n(ml,"P",{});var Uoe=s(Ld);Hsr=r(Uoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=n(Uoe,"A",{href:!0});var RMt=s(JQ);Usr=r(RMt,"from_pretrained()"),RMt.forEach(t),Jsr=r(Uoe," class method or the "),YQ=n(Uoe,"A",{href:!0});var PMt=s(YQ);Ysr=r(PMt,"from_config()"),PMt.forEach(t),Ksr=r(Uoe,` class
method.`),Uoe.forEach(t),Zsr=i(ml),Cy=n(ml,"P",{});var BXe=s(Cy);elr=r(BXe,"This class cannot be instantiated directly using "),G2e=n(BXe,"CODE",{});var BMt=s(G2e);olr=r(BMt,"__init__()"),BMt.forEach(t),rlr=r(BXe," (throws an error)."),BXe.forEach(t),tlr=i(ml),Tt=n(ml,"DIV",{class:!0});var lw=s(Tt);T(wy.$$.fragment,lw),alr=i(lw),O2e=n(lw,"P",{});var IMt=s(O2e);nlr=r(IMt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),IMt.forEach(t),slr=i(lw),yd=n(lw,"P",{});var Joe=s(yd);llr=r(Joe,`Note:
Loading a model from its configuration file does `),V2e=n(Joe,"STRONG",{});var NMt=s(V2e);ilr=r(NMt,"not"),NMt.forEach(t),dlr=r(Joe,` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=n(Joe,"A",{href:!0});var qMt=s(KQ);clr=r(qMt,"from_pretrained()"),qMt.forEach(t),flr=r(Joe," to load the model weights."),Joe.forEach(t),mlr=i(lw),T(k6.$$.fragment,lw),lw.forEach(t),glr=i(ml),mo=n(ml,"DIV",{class:!0});var Fa=s(mo);T(Ay.$$.fragment,Fa),hlr=i(Fa),X2e=n(Fa,"P",{});var jMt=s(X2e);plr=r(jMt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),jMt.forEach(t),_lr=i(Fa),Ha=n(Fa,"P",{});var iw=s(Ha);ulr=r(iw,"The model class to instantiate is selected based on the "),z2e=n(iw,"CODE",{});var DMt=s(z2e);blr=r(DMt,"model_type"),DMt.forEach(t),vlr=r(iw,` property of the config object (either
passed as an argument or loaded from `),Q2e=n(iw,"CODE",{});var GMt=s(Q2e);Flr=r(GMt,"pretrained_model_name_or_path"),GMt.forEach(t),Tlr=r(iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W2e=n(iw,"CODE",{});var OMt=s(W2e);Mlr=r(OMt,"pretrained_model_name_or_path"),OMt.forEach(t),Elr=r(iw,":"),iw.forEach(t),Clr=i(Fa),et=n(Fa,"UL",{});var gl=s(et);S6=n(gl,"LI",{});var lBe=s(S6);H2e=n(lBe,"STRONG",{});var VMt=s(H2e);wlr=r(VMt,"data2vec-audio"),VMt.forEach(t),Alr=r(lBe," \u2014 "),ZQ=n(lBe,"A",{href:!0});var XMt=s(ZQ);Llr=r(XMt,"Data2VecAudioForAudioFrameClassification"),XMt.forEach(t),ylr=r(lBe," (Data2VecAudio model)"),lBe.forEach(t),xlr=i(gl),R6=n(gl,"LI",{});var iBe=s(R6);U2e=n(iBe,"STRONG",{});var zMt=s(U2e);$lr=r(zMt,"unispeech-sat"),zMt.forEach(t),klr=r(iBe," \u2014 "),eW=n(iBe,"A",{href:!0});var QMt=s(eW);Slr=r(QMt,"UniSpeechSatForAudioFrameClassification"),QMt.forEach(t),Rlr=r(iBe," (UniSpeechSat model)"),iBe.forEach(t),Plr=i(gl),P6=n(gl,"LI",{});var dBe=s(P6);J2e=n(dBe,"STRONG",{});var WMt=s(J2e);Blr=r(WMt,"wav2vec2"),WMt.forEach(t),Ilr=r(dBe," \u2014 "),oW=n(dBe,"A",{href:!0});var HMt=s(oW);Nlr=r(HMt,"Wav2Vec2ForAudioFrameClassification"),HMt.forEach(t),qlr=r(dBe," (Wav2Vec2 model)"),dBe.forEach(t),jlr=i(gl),B6=n(gl,"LI",{});var cBe=s(B6);Y2e=n(cBe,"STRONG",{});var UMt=s(Y2e);Dlr=r(UMt,"wav2vec2-conformer"),UMt.forEach(t),Glr=r(cBe," \u2014 "),rW=n(cBe,"A",{href:!0});var JMt=s(rW);Olr=r(JMt,"Wav2Vec2ConformerForAudioFrameClassification"),JMt.forEach(t),Vlr=r(cBe," (Wav2Vec2-Conformer model)"),cBe.forEach(t),Xlr=i(gl),I6=n(gl,"LI",{});var fBe=s(I6);K2e=n(fBe,"STRONG",{});var YMt=s(K2e);zlr=r(YMt,"wavlm"),YMt.forEach(t),Qlr=r(fBe," \u2014 "),tW=n(fBe,"A",{href:!0});var KMt=s(tW);Wlr=r(KMt,"WavLMForAudioFrameClassification"),KMt.forEach(t),Hlr=r(fBe," (WavLM model)"),fBe.forEach(t),gl.forEach(t),Ulr=i(Fa),N6=n(Fa,"P",{});var mBe=s(N6);Jlr=r(mBe,"The model is set in evaluation mode by default using "),Z2e=n(mBe,"CODE",{});var ZMt=s(Z2e);Ylr=r(ZMt,"model.eval()"),ZMt.forEach(t),Klr=r(mBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ebe=n(mBe,"CODE",{});var eEt=s(ebe);Zlr=r(eEt,"model.train()"),eEt.forEach(t),mBe.forEach(t),eir=i(Fa),T(q6.$$.fragment,Fa),Fa.forEach(t),ml.forEach(t),$Oe=i(f),xd=n(f,"H2",{class:!0});var IXe=s(xd);j6=n(IXe,"A",{id:!0,class:!0,href:!0});var oEt=s(j6);obe=n(oEt,"SPAN",{});var rEt=s(obe);T(Ly.$$.fragment,rEt),rEt.forEach(t),oEt.forEach(t),oir=i(IXe),rbe=n(IXe,"SPAN",{});var tEt=s(rbe);rir=r(tEt,"AutoModelForCTC"),tEt.forEach(t),IXe.forEach(t),kOe=i(f),Qo=n(f,"DIV",{class:!0});var hl=s(Qo);T(yy.$$.fragment,hl),tir=i(hl),$d=n(hl,"P",{});var Yoe=s($d);air=r(Yoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=n(Yoe,"A",{href:!0});var aEt=s(aW);nir=r(aEt,"from_pretrained()"),aEt.forEach(t),sir=r(Yoe," class method or the "),nW=n(Yoe,"A",{href:!0});var nEt=s(nW);lir=r(nEt,"from_config()"),nEt.forEach(t),iir=r(Yoe,` class
method.`),Yoe.forEach(t),dir=i(hl),xy=n(hl,"P",{});var NXe=s(xy);cir=r(NXe,"This class cannot be instantiated directly using "),tbe=n(NXe,"CODE",{});var sEt=s(tbe);fir=r(sEt,"__init__()"),sEt.forEach(t),mir=r(NXe," (throws an error)."),NXe.forEach(t),gir=i(hl),Mt=n(hl,"DIV",{class:!0});var dw=s(Mt);T($y.$$.fragment,dw),hir=i(dw),abe=n(dw,"P",{});var lEt=s(abe);pir=r(lEt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),lEt.forEach(t),_ir=i(dw),kd=n(dw,"P",{});var Koe=s(kd);uir=r(Koe,`Note:
Loading a model from its configuration file does `),nbe=n(Koe,"STRONG",{});var iEt=s(nbe);bir=r(iEt,"not"),iEt.forEach(t),vir=r(Koe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=n(Koe,"A",{href:!0});var dEt=s(sW);Fir=r(dEt,"from_pretrained()"),dEt.forEach(t),Tir=r(Koe," to load the model weights."),Koe.forEach(t),Mir=i(dw),T(D6.$$.fragment,dw),dw.forEach(t),Eir=i(hl),go=n(hl,"DIV",{class:!0});var Ta=s(go);T(ky.$$.fragment,Ta),Cir=i(Ta),sbe=n(Ta,"P",{});var cEt=s(sbe);wir=r(cEt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),cEt.forEach(t),Air=i(Ta),Ua=n(Ta,"P",{});var cw=s(Ua);Lir=r(cw,"The model class to instantiate is selected based on the "),lbe=n(cw,"CODE",{});var fEt=s(lbe);yir=r(fEt,"model_type"),fEt.forEach(t),xir=r(cw,` property of the config object (either
passed as an argument or loaded from `),ibe=n(cw,"CODE",{});var mEt=s(ibe);$ir=r(mEt,"pretrained_model_name_or_path"),mEt.forEach(t),kir=r(cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dbe=n(cw,"CODE",{});var gEt=s(dbe);Sir=r(gEt,"pretrained_model_name_or_path"),gEt.forEach(t),Rir=r(cw,":"),cw.forEach(t),Pir=i(Ta),Le=n(Ta,"UL",{});var Be=s(Le);G6=n(Be,"LI",{});var gBe=s(G6);cbe=n(gBe,"STRONG",{});var hEt=s(cbe);Bir=r(hEt,"data2vec-audio"),hEt.forEach(t),Iir=r(gBe," \u2014 "),lW=n(gBe,"A",{href:!0});var pEt=s(lW);Nir=r(pEt,"Data2VecAudioForCTC"),pEt.forEach(t),qir=r(gBe," (Data2VecAudio model)"),gBe.forEach(t),jir=i(Be),O6=n(Be,"LI",{});var hBe=s(O6);fbe=n(hBe,"STRONG",{});var _Et=s(fbe);Dir=r(_Et,"hubert"),_Et.forEach(t),Gir=r(hBe," \u2014 "),iW=n(hBe,"A",{href:!0});var uEt=s(iW);Oir=r(uEt,"HubertForCTC"),uEt.forEach(t),Vir=r(hBe," (Hubert model)"),hBe.forEach(t),Xir=i(Be),V6=n(Be,"LI",{});var pBe=s(V6);mbe=n(pBe,"STRONG",{});var bEt=s(mbe);zir=r(bEt,"mctct"),bEt.forEach(t),Qir=r(pBe," \u2014 "),dW=n(pBe,"A",{href:!0});var vEt=s(dW);Wir=r(vEt,"MCTCTForCTC"),vEt.forEach(t),Hir=r(pBe," (M-CTC-T model)"),pBe.forEach(t),Uir=i(Be),X6=n(Be,"LI",{});var _Be=s(X6);gbe=n(_Be,"STRONG",{});var FEt=s(gbe);Jir=r(FEt,"sew"),FEt.forEach(t),Yir=r(_Be," \u2014 "),cW=n(_Be,"A",{href:!0});var TEt=s(cW);Kir=r(TEt,"SEWForCTC"),TEt.forEach(t),Zir=r(_Be," (SEW model)"),_Be.forEach(t),edr=i(Be),z6=n(Be,"LI",{});var uBe=s(z6);hbe=n(uBe,"STRONG",{});var MEt=s(hbe);odr=r(MEt,"sew-d"),MEt.forEach(t),rdr=r(uBe," \u2014 "),fW=n(uBe,"A",{href:!0});var EEt=s(fW);tdr=r(EEt,"SEWDForCTC"),EEt.forEach(t),adr=r(uBe," (SEW-D model)"),uBe.forEach(t),ndr=i(Be),Q6=n(Be,"LI",{});var bBe=s(Q6);pbe=n(bBe,"STRONG",{});var CEt=s(pbe);sdr=r(CEt,"unispeech"),CEt.forEach(t),ldr=r(bBe," \u2014 "),mW=n(bBe,"A",{href:!0});var wEt=s(mW);idr=r(wEt,"UniSpeechForCTC"),wEt.forEach(t),ddr=r(bBe," (UniSpeech model)"),bBe.forEach(t),cdr=i(Be),W6=n(Be,"LI",{});var vBe=s(W6);_be=n(vBe,"STRONG",{});var AEt=s(_be);fdr=r(AEt,"unispeech-sat"),AEt.forEach(t),mdr=r(vBe," \u2014 "),gW=n(vBe,"A",{href:!0});var LEt=s(gW);gdr=r(LEt,"UniSpeechSatForCTC"),LEt.forEach(t),hdr=r(vBe," (UniSpeechSat model)"),vBe.forEach(t),pdr=i(Be),H6=n(Be,"LI",{});var FBe=s(H6);ube=n(FBe,"STRONG",{});var yEt=s(ube);_dr=r(yEt,"wav2vec2"),yEt.forEach(t),udr=r(FBe," \u2014 "),hW=n(FBe,"A",{href:!0});var xEt=s(hW);bdr=r(xEt,"Wav2Vec2ForCTC"),xEt.forEach(t),vdr=r(FBe," (Wav2Vec2 model)"),FBe.forEach(t),Fdr=i(Be),U6=n(Be,"LI",{});var TBe=s(U6);bbe=n(TBe,"STRONG",{});var $Et=s(bbe);Tdr=r($Et,"wav2vec2-conformer"),$Et.forEach(t),Mdr=r(TBe," \u2014 "),pW=n(TBe,"A",{href:!0});var kEt=s(pW);Edr=r(kEt,"Wav2Vec2ConformerForCTC"),kEt.forEach(t),Cdr=r(TBe," (Wav2Vec2-Conformer model)"),TBe.forEach(t),wdr=i(Be),J6=n(Be,"LI",{});var MBe=s(J6);vbe=n(MBe,"STRONG",{});var SEt=s(vbe);Adr=r(SEt,"wavlm"),SEt.forEach(t),Ldr=r(MBe," \u2014 "),_W=n(MBe,"A",{href:!0});var REt=s(_W);ydr=r(REt,"WavLMForCTC"),REt.forEach(t),xdr=r(MBe," (WavLM model)"),MBe.forEach(t),Be.forEach(t),$dr=i(Ta),Y6=n(Ta,"P",{});var EBe=s(Y6);kdr=r(EBe,"The model is set in evaluation mode by default using "),Fbe=n(EBe,"CODE",{});var PEt=s(Fbe);Sdr=r(PEt,"model.eval()"),PEt.forEach(t),Rdr=r(EBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tbe=n(EBe,"CODE",{});var BEt=s(Tbe);Pdr=r(BEt,"model.train()"),BEt.forEach(t),EBe.forEach(t),Bdr=i(Ta),T(K6.$$.fragment,Ta),Ta.forEach(t),hl.forEach(t),SOe=i(f),Sd=n(f,"H2",{class:!0});var qXe=s(Sd);Z6=n(qXe,"A",{id:!0,class:!0,href:!0});var IEt=s(Z6);Mbe=n(IEt,"SPAN",{});var NEt=s(Mbe);T(Sy.$$.fragment,NEt),NEt.forEach(t),IEt.forEach(t),Idr=i(qXe),Ebe=n(qXe,"SPAN",{});var qEt=s(Ebe);Ndr=r(qEt,"AutoModelForSpeechSeq2Seq"),qEt.forEach(t),qXe.forEach(t),ROe=i(f),Wo=n(f,"DIV",{class:!0});var pl=s(Wo);T(Ry.$$.fragment,pl),qdr=i(pl),Rd=n(pl,"P",{});var Zoe=s(Rd);jdr=r(Zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uW=n(Zoe,"A",{href:!0});var jEt=s(uW);Ddr=r(jEt,"from_pretrained()"),jEt.forEach(t),Gdr=r(Zoe," class method or the "),bW=n(Zoe,"A",{href:!0});var DEt=s(bW);Odr=r(DEt,"from_config()"),DEt.forEach(t),Vdr=r(Zoe,` class
method.`),Zoe.forEach(t),Xdr=i(pl),Py=n(pl,"P",{});var jXe=s(Py);zdr=r(jXe,"This class cannot be instantiated directly using "),Cbe=n(jXe,"CODE",{});var GEt=s(Cbe);Qdr=r(GEt,"__init__()"),GEt.forEach(t),Wdr=r(jXe," (throws an error)."),jXe.forEach(t),Hdr=i(pl),Et=n(pl,"DIV",{class:!0});var fw=s(Et);T(By.$$.fragment,fw),Udr=i(fw),wbe=n(fw,"P",{});var OEt=s(wbe);Jdr=r(OEt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),OEt.forEach(t),Ydr=i(fw),Pd=n(fw,"P",{});var ere=s(Pd);Kdr=r(ere,`Note:
Loading a model from its configuration file does `),Abe=n(ere,"STRONG",{});var VEt=s(Abe);Zdr=r(VEt,"not"),VEt.forEach(t),ecr=r(ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=n(ere,"A",{href:!0});var XEt=s(vW);ocr=r(XEt,"from_pretrained()"),XEt.forEach(t),rcr=r(ere," to load the model weights."),ere.forEach(t),tcr=i(fw),T(eT.$$.fragment,fw),fw.forEach(t),acr=i(pl),ho=n(pl,"DIV",{class:!0});var Ma=s(ho);T(Iy.$$.fragment,Ma),ncr=i(Ma),Lbe=n(Ma,"P",{});var zEt=s(Lbe);scr=r(zEt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),zEt.forEach(t),lcr=i(Ma),Ja=n(Ma,"P",{});var mw=s(Ja);icr=r(mw,"The model class to instantiate is selected based on the "),ybe=n(mw,"CODE",{});var QEt=s(ybe);dcr=r(QEt,"model_type"),QEt.forEach(t),ccr=r(mw,` property of the config object (either
passed as an argument or loaded from `),xbe=n(mw,"CODE",{});var WEt=s(xbe);fcr=r(WEt,"pretrained_model_name_or_path"),WEt.forEach(t),mcr=r(mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$be=n(mw,"CODE",{});var HEt=s($be);gcr=r(HEt,"pretrained_model_name_or_path"),HEt.forEach(t),hcr=r(mw,":"),mw.forEach(t),pcr=i(Ma),Ny=n(Ma,"UL",{});var DXe=s(Ny);oT=n(DXe,"LI",{});var CBe=s(oT);kbe=n(CBe,"STRONG",{});var UEt=s(kbe);_cr=r(UEt,"speech-encoder-decoder"),UEt.forEach(t),ucr=r(CBe," \u2014 "),FW=n(CBe,"A",{href:!0});var JEt=s(FW);bcr=r(JEt,"SpeechEncoderDecoderModel"),JEt.forEach(t),vcr=r(CBe," (Speech Encoder decoder model)"),CBe.forEach(t),Fcr=i(DXe),rT=n(DXe,"LI",{});var wBe=s(rT);Sbe=n(wBe,"STRONG",{});var YEt=s(Sbe);Tcr=r(YEt,"speech_to_text"),YEt.forEach(t),Mcr=r(wBe," \u2014 "),TW=n(wBe,"A",{href:!0});var KEt=s(TW);Ecr=r(KEt,"Speech2TextForConditionalGeneration"),KEt.forEach(t),Ccr=r(wBe," (Speech2Text model)"),wBe.forEach(t),DXe.forEach(t),wcr=i(Ma),tT=n(Ma,"P",{});var ABe=s(tT);Acr=r(ABe,"The model is set in evaluation mode by default using "),Rbe=n(ABe,"CODE",{});var ZEt=s(Rbe);Lcr=r(ZEt,"model.eval()"),ZEt.forEach(t),ycr=r(ABe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pbe=n(ABe,"CODE",{});var eCt=s(Pbe);xcr=r(eCt,"model.train()"),eCt.forEach(t),ABe.forEach(t),$cr=i(Ma),T(aT.$$.fragment,Ma),Ma.forEach(t),pl.forEach(t),POe=i(f),Bd=n(f,"H2",{class:!0});var GXe=s(Bd);nT=n(GXe,"A",{id:!0,class:!0,href:!0});var oCt=s(nT);Bbe=n(oCt,"SPAN",{});var rCt=s(Bbe);T(qy.$$.fragment,rCt),rCt.forEach(t),oCt.forEach(t),kcr=i(GXe),Ibe=n(GXe,"SPAN",{});var tCt=s(Ibe);Scr=r(tCt,"AutoModelForAudioXVector"),tCt.forEach(t),GXe.forEach(t),BOe=i(f),Ho=n(f,"DIV",{class:!0});var _l=s(Ho);T(jy.$$.fragment,_l),Rcr=i(_l),Id=n(_l,"P",{});var ore=s(Id);Pcr=r(ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=n(ore,"A",{href:!0});var aCt=s(MW);Bcr=r(aCt,"from_pretrained()"),aCt.forEach(t),Icr=r(ore," class method or the "),EW=n(ore,"A",{href:!0});var nCt=s(EW);Ncr=r(nCt,"from_config()"),nCt.forEach(t),qcr=r(ore,` class
method.`),ore.forEach(t),jcr=i(_l),Dy=n(_l,"P",{});var OXe=s(Dy);Dcr=r(OXe,"This class cannot be instantiated directly using "),Nbe=n(OXe,"CODE",{});var sCt=s(Nbe);Gcr=r(sCt,"__init__()"),sCt.forEach(t),Ocr=r(OXe," (throws an error)."),OXe.forEach(t),Vcr=i(_l),Ct=n(_l,"DIV",{class:!0});var gw=s(Ct);T(Gy.$$.fragment,gw),Xcr=i(gw),qbe=n(gw,"P",{});var lCt=s(qbe);zcr=r(lCt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),lCt.forEach(t),Qcr=i(gw),Nd=n(gw,"P",{});var rre=s(Nd);Wcr=r(rre,`Note:
Loading a model from its configuration file does `),jbe=n(rre,"STRONG",{});var iCt=s(jbe);Hcr=r(iCt,"not"),iCt.forEach(t),Ucr=r(rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=n(rre,"A",{href:!0});var dCt=s(CW);Jcr=r(dCt,"from_pretrained()"),dCt.forEach(t),Ycr=r(rre," to load the model weights."),rre.forEach(t),Kcr=i(gw),T(sT.$$.fragment,gw),gw.forEach(t),Zcr=i(_l),po=n(_l,"DIV",{class:!0});var Ea=s(po);T(Oy.$$.fragment,Ea),efr=i(Ea),Dbe=n(Ea,"P",{});var cCt=s(Dbe);ofr=r(cCt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),cCt.forEach(t),rfr=i(Ea),Ya=n(Ea,"P",{});var hw=s(Ya);tfr=r(hw,"The model class to instantiate is selected based on the "),Gbe=n(hw,"CODE",{});var fCt=s(Gbe);afr=r(fCt,"model_type"),fCt.forEach(t),nfr=r(hw,` property of the config object (either
passed as an argument or loaded from `),Obe=n(hw,"CODE",{});var mCt=s(Obe);sfr=r(mCt,"pretrained_model_name_or_path"),mCt.forEach(t),lfr=r(hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vbe=n(hw,"CODE",{});var gCt=s(Vbe);ifr=r(gCt,"pretrained_model_name_or_path"),gCt.forEach(t),dfr=r(hw,":"),hw.forEach(t),cfr=i(Ea),ot=n(Ea,"UL",{});var ul=s(ot);lT=n(ul,"LI",{});var LBe=s(lT);Xbe=n(LBe,"STRONG",{});var hCt=s(Xbe);ffr=r(hCt,"data2vec-audio"),hCt.forEach(t),mfr=r(LBe," \u2014 "),wW=n(LBe,"A",{href:!0});var pCt=s(wW);gfr=r(pCt,"Data2VecAudioForXVector"),pCt.forEach(t),hfr=r(LBe," (Data2VecAudio model)"),LBe.forEach(t),pfr=i(ul),iT=n(ul,"LI",{});var yBe=s(iT);zbe=n(yBe,"STRONG",{});var _Ct=s(zbe);_fr=r(_Ct,"unispeech-sat"),_Ct.forEach(t),ufr=r(yBe," \u2014 "),AW=n(yBe,"A",{href:!0});var uCt=s(AW);bfr=r(uCt,"UniSpeechSatForXVector"),uCt.forEach(t),vfr=r(yBe," (UniSpeechSat model)"),yBe.forEach(t),Ffr=i(ul),dT=n(ul,"LI",{});var xBe=s(dT);Qbe=n(xBe,"STRONG",{});var bCt=s(Qbe);Tfr=r(bCt,"wav2vec2"),bCt.forEach(t),Mfr=r(xBe," \u2014 "),LW=n(xBe,"A",{href:!0});var vCt=s(LW);Efr=r(vCt,"Wav2Vec2ForXVector"),vCt.forEach(t),Cfr=r(xBe," (Wav2Vec2 model)"),xBe.forEach(t),wfr=i(ul),cT=n(ul,"LI",{});var $Be=s(cT);Wbe=n($Be,"STRONG",{});var FCt=s(Wbe);Afr=r(FCt,"wav2vec2-conformer"),FCt.forEach(t),Lfr=r($Be," \u2014 "),yW=n($Be,"A",{href:!0});var TCt=s(yW);yfr=r(TCt,"Wav2Vec2ConformerForXVector"),TCt.forEach(t),xfr=r($Be," (Wav2Vec2-Conformer model)"),$Be.forEach(t),$fr=i(ul),fT=n(ul,"LI",{});var kBe=s(fT);Hbe=n(kBe,"STRONG",{});var MCt=s(Hbe);kfr=r(MCt,"wavlm"),MCt.forEach(t),Sfr=r(kBe," \u2014 "),xW=n(kBe,"A",{href:!0});var ECt=s(xW);Rfr=r(ECt,"WavLMForXVector"),ECt.forEach(t),Pfr=r(kBe," (WavLM model)"),kBe.forEach(t),ul.forEach(t),Bfr=i(Ea),mT=n(Ea,"P",{});var SBe=s(mT);Ifr=r(SBe,"The model is set in evaluation mode by default using "),Ube=n(SBe,"CODE",{});var CCt=s(Ube);Nfr=r(CCt,"model.eval()"),CCt.forEach(t),qfr=r(SBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=n(SBe,"CODE",{});var wCt=s(Jbe);jfr=r(wCt,"model.train()"),wCt.forEach(t),SBe.forEach(t),Dfr=i(Ea),T(gT.$$.fragment,Ea),Ea.forEach(t),_l.forEach(t),IOe=i(f),qd=n(f,"H2",{class:!0});var VXe=s(qd);hT=n(VXe,"A",{id:!0,class:!0,href:!0});var ACt=s(hT);Ybe=n(ACt,"SPAN",{});var LCt=s(Ybe);T(Vy.$$.fragment,LCt),LCt.forEach(t),ACt.forEach(t),Gfr=i(VXe),Kbe=n(VXe,"SPAN",{});var yCt=s(Kbe);Ofr=r(yCt,"AutoModelForMaskedImageModeling"),yCt.forEach(t),VXe.forEach(t),NOe=i(f),Uo=n(f,"DIV",{class:!0});var bl=s(Uo);T(Xy.$$.fragment,bl),Vfr=i(bl),jd=n(bl,"P",{});var tre=s(jd);Xfr=r(tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=n(tre,"A",{href:!0});var xCt=s($W);zfr=r(xCt,"from_pretrained()"),xCt.forEach(t),Qfr=r(tre," class method or the "),kW=n(tre,"A",{href:!0});var $Ct=s(kW);Wfr=r($Ct,"from_config()"),$Ct.forEach(t),Hfr=r(tre,` class
method.`),tre.forEach(t),Ufr=i(bl),zy=n(bl,"P",{});var XXe=s(zy);Jfr=r(XXe,"This class cannot be instantiated directly using "),Zbe=n(XXe,"CODE",{});var kCt=s(Zbe);Yfr=r(kCt,"__init__()"),kCt.forEach(t),Kfr=r(XXe," (throws an error)."),XXe.forEach(t),Zfr=i(bl),wt=n(bl,"DIV",{class:!0});var pw=s(wt);T(Qy.$$.fragment,pw),emr=i(pw),e4e=n(pw,"P",{});var SCt=s(e4e);omr=r(SCt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),SCt.forEach(t),rmr=i(pw),Dd=n(pw,"P",{});var are=s(Dd);tmr=r(are,`Note:
Loading a model from its configuration file does `),o4e=n(are,"STRONG",{});var RCt=s(o4e);amr=r(RCt,"not"),RCt.forEach(t),nmr=r(are,` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=n(are,"A",{href:!0});var PCt=s(SW);smr=r(PCt,"from_pretrained()"),PCt.forEach(t),lmr=r(are," to load the model weights."),are.forEach(t),imr=i(pw),T(pT.$$.fragment,pw),pw.forEach(t),dmr=i(bl),_o=n(bl,"DIV",{class:!0});var Ca=s(_o);T(Wy.$$.fragment,Ca),cmr=i(Ca),r4e=n(Ca,"P",{});var BCt=s(r4e);fmr=r(BCt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),BCt.forEach(t),mmr=i(Ca),Ka=n(Ca,"P",{});var _w=s(Ka);gmr=r(_w,"The model class to instantiate is selected based on the "),t4e=n(_w,"CODE",{});var ICt=s(t4e);hmr=r(ICt,"model_type"),ICt.forEach(t),pmr=r(_w,` property of the config object (either
passed as an argument or loaded from `),a4e=n(_w,"CODE",{});var NCt=s(a4e);_mr=r(NCt,"pretrained_model_name_or_path"),NCt.forEach(t),umr=r(_w,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n4e=n(_w,"CODE",{});var qCt=s(n4e);bmr=r(qCt,"pretrained_model_name_or_path"),qCt.forEach(t),vmr=r(_w,":"),_w.forEach(t),Fmr=i(Ca),Gd=n(Ca,"UL",{});var nre=s(Gd);_T=n(nre,"LI",{});var RBe=s(_T);s4e=n(RBe,"STRONG",{});var jCt=s(s4e);Tmr=r(jCt,"deit"),jCt.forEach(t),Mmr=r(RBe," \u2014 "),RW=n(RBe,"A",{href:!0});var DCt=s(RW);Emr=r(DCt,"DeiTForMaskedImageModeling"),DCt.forEach(t),Cmr=r(RBe," (DeiT model)"),RBe.forEach(t),wmr=i(nre),uT=n(nre,"LI",{});var PBe=s(uT);l4e=n(PBe,"STRONG",{});var GCt=s(l4e);Amr=r(GCt,"swin"),GCt.forEach(t),Lmr=r(PBe," \u2014 "),PW=n(PBe,"A",{href:!0});var OCt=s(PW);ymr=r(OCt,"SwinForMaskedImageModeling"),OCt.forEach(t),xmr=r(PBe," (Swin Transformer model)"),PBe.forEach(t),$mr=i(nre),bT=n(nre,"LI",{});var BBe=s(bT);i4e=n(BBe,"STRONG",{});var VCt=s(i4e);kmr=r(VCt,"vit"),VCt.forEach(t),Smr=r(BBe," \u2014 "),BW=n(BBe,"A",{href:!0});var XCt=s(BW);Rmr=r(XCt,"ViTForMaskedImageModeling"),XCt.forEach(t),Pmr=r(BBe," (ViT model)"),BBe.forEach(t),nre.forEach(t),Bmr=i(Ca),vT=n(Ca,"P",{});var IBe=s(vT);Imr=r(IBe,"The model is set in evaluation mode by default using "),d4e=n(IBe,"CODE",{});var zCt=s(d4e);Nmr=r(zCt,"model.eval()"),zCt.forEach(t),qmr=r(IBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c4e=n(IBe,"CODE",{});var QCt=s(c4e);jmr=r(QCt,"model.train()"),QCt.forEach(t),IBe.forEach(t),Dmr=i(Ca),T(FT.$$.fragment,Ca),Ca.forEach(t),bl.forEach(t),qOe=i(f),Od=n(f,"H2",{class:!0});var zXe=s(Od);TT=n(zXe,"A",{id:!0,class:!0,href:!0});var WCt=s(TT);f4e=n(WCt,"SPAN",{});var HCt=s(f4e);T(Hy.$$.fragment,HCt),HCt.forEach(t),WCt.forEach(t),Gmr=i(zXe),m4e=n(zXe,"SPAN",{});var UCt=s(m4e);Omr=r(UCt,"AutoModelForObjectDetection"),UCt.forEach(t),zXe.forEach(t),jOe=i(f),Jo=n(f,"DIV",{class:!0});var vl=s(Jo);T(Uy.$$.fragment,vl),Vmr=i(vl),Vd=n(vl,"P",{});var sre=s(Vd);Xmr=r(sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=n(sre,"A",{href:!0});var JCt=s(IW);zmr=r(JCt,"from_pretrained()"),JCt.forEach(t),Qmr=r(sre," class method or the "),NW=n(sre,"A",{href:!0});var YCt=s(NW);Wmr=r(YCt,"from_config()"),YCt.forEach(t),Hmr=r(sre,` class
method.`),sre.forEach(t),Umr=i(vl),Jy=n(vl,"P",{});var QXe=s(Jy);Jmr=r(QXe,"This class cannot be instantiated directly using "),g4e=n(QXe,"CODE",{});var KCt=s(g4e);Ymr=r(KCt,"__init__()"),KCt.forEach(t),Kmr=r(QXe," (throws an error)."),QXe.forEach(t),Zmr=i(vl),At=n(vl,"DIV",{class:!0});var uw=s(At);T(Yy.$$.fragment,uw),egr=i(uw),h4e=n(uw,"P",{});var ZCt=s(h4e);ogr=r(ZCt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),ZCt.forEach(t),rgr=i(uw),Xd=n(uw,"P",{});var lre=s(Xd);tgr=r(lre,`Note:
Loading a model from its configuration file does `),p4e=n(lre,"STRONG",{});var e5t=s(p4e);agr=r(e5t,"not"),e5t.forEach(t),ngr=r(lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=n(lre,"A",{href:!0});var o5t=s(qW);sgr=r(o5t,"from_pretrained()"),o5t.forEach(t),lgr=r(lre," to load the model weights."),lre.forEach(t),igr=i(uw),T(MT.$$.fragment,uw),uw.forEach(t),dgr=i(vl),uo=n(vl,"DIV",{class:!0});var wa=s(uo);T(Ky.$$.fragment,wa),cgr=i(wa),_4e=n(wa,"P",{});var r5t=s(_4e);fgr=r(r5t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),r5t.forEach(t),mgr=i(wa),Za=n(wa,"P",{});var bw=s(Za);ggr=r(bw,"The model class to instantiate is selected based on the "),u4e=n(bw,"CODE",{});var t5t=s(u4e);hgr=r(t5t,"model_type"),t5t.forEach(t),pgr=r(bw,` property of the config object (either
passed as an argument or loaded from `),b4e=n(bw,"CODE",{});var a5t=s(b4e);_gr=r(a5t,"pretrained_model_name_or_path"),a5t.forEach(t),ugr=r(bw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v4e=n(bw,"CODE",{});var n5t=s(v4e);bgr=r(n5t,"pretrained_model_name_or_path"),n5t.forEach(t),vgr=r(bw,":"),bw.forEach(t),Fgr=i(wa),Zy=n(wa,"UL",{});var WXe=s(Zy);ET=n(WXe,"LI",{});var NBe=s(ET);F4e=n(NBe,"STRONG",{});var s5t=s(F4e);Tgr=r(s5t,"detr"),s5t.forEach(t),Mgr=r(NBe," \u2014 "),jW=n(NBe,"A",{href:!0});var l5t=s(jW);Egr=r(l5t,"DetrForObjectDetection"),l5t.forEach(t),Cgr=r(NBe," (DETR model)"),NBe.forEach(t),wgr=i(WXe),CT=n(WXe,"LI",{});var qBe=s(CT);T4e=n(qBe,"STRONG",{});var i5t=s(T4e);Agr=r(i5t,"yolos"),i5t.forEach(t),Lgr=r(qBe," \u2014 "),DW=n(qBe,"A",{href:!0});var d5t=s(DW);ygr=r(d5t,"YolosForObjectDetection"),d5t.forEach(t),xgr=r(qBe," (YOLOS model)"),qBe.forEach(t),WXe.forEach(t),$gr=i(wa),wT=n(wa,"P",{});var jBe=s(wT);kgr=r(jBe,"The model is set in evaluation mode by default using "),M4e=n(jBe,"CODE",{});var c5t=s(M4e);Sgr=r(c5t,"model.eval()"),c5t.forEach(t),Rgr=r(jBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E4e=n(jBe,"CODE",{});var f5t=s(E4e);Pgr=r(f5t,"model.train()"),f5t.forEach(t),jBe.forEach(t),Bgr=i(wa),T(AT.$$.fragment,wa),wa.forEach(t),vl.forEach(t),DOe=i(f),zd=n(f,"H2",{class:!0});var HXe=s(zd);LT=n(HXe,"A",{id:!0,class:!0,href:!0});var m5t=s(LT);C4e=n(m5t,"SPAN",{});var g5t=s(C4e);T(e9.$$.fragment,g5t),g5t.forEach(t),m5t.forEach(t),Igr=i(HXe),w4e=n(HXe,"SPAN",{});var h5t=s(w4e);Ngr=r(h5t,"AutoModelForImageSegmentation"),h5t.forEach(t),HXe.forEach(t),GOe=i(f),Yo=n(f,"DIV",{class:!0});var Fl=s(Yo);T(o9.$$.fragment,Fl),qgr=i(Fl),Qd=n(Fl,"P",{});var ire=s(Qd);jgr=r(ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=n(ire,"A",{href:!0});var p5t=s(GW);Dgr=r(p5t,"from_pretrained()"),p5t.forEach(t),Ggr=r(ire," class method or the "),OW=n(ire,"A",{href:!0});var _5t=s(OW);Ogr=r(_5t,"from_config()"),_5t.forEach(t),Vgr=r(ire,` class
method.`),ire.forEach(t),Xgr=i(Fl),r9=n(Fl,"P",{});var UXe=s(r9);zgr=r(UXe,"This class cannot be instantiated directly using "),A4e=n(UXe,"CODE",{});var u5t=s(A4e);Qgr=r(u5t,"__init__()"),u5t.forEach(t),Wgr=r(UXe," (throws an error)."),UXe.forEach(t),Hgr=i(Fl),Lt=n(Fl,"DIV",{class:!0});var vw=s(Lt);T(t9.$$.fragment,vw),Ugr=i(vw),L4e=n(vw,"P",{});var b5t=s(L4e);Jgr=r(b5t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),b5t.forEach(t),Ygr=i(vw),Wd=n(vw,"P",{});var dre=s(Wd);Kgr=r(dre,`Note:
Loading a model from its configuration file does `),y4e=n(dre,"STRONG",{});var v5t=s(y4e);Zgr=r(v5t,"not"),v5t.forEach(t),ehr=r(dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=n(dre,"A",{href:!0});var F5t=s(VW);ohr=r(F5t,"from_pretrained()"),F5t.forEach(t),rhr=r(dre," to load the model weights."),dre.forEach(t),thr=i(vw),T(yT.$$.fragment,vw),vw.forEach(t),ahr=i(Fl),bo=n(Fl,"DIV",{class:!0});var Aa=s(bo);T(a9.$$.fragment,Aa),nhr=i(Aa),x4e=n(Aa,"P",{});var T5t=s(x4e);shr=r(T5t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),T5t.forEach(t),lhr=i(Aa),en=n(Aa,"P",{});var Fw=s(en);ihr=r(Fw,"The model class to instantiate is selected based on the "),$4e=n(Fw,"CODE",{});var M5t=s($4e);dhr=r(M5t,"model_type"),M5t.forEach(t),chr=r(Fw,` property of the config object (either
passed as an argument or loaded from `),k4e=n(Fw,"CODE",{});var E5t=s(k4e);fhr=r(E5t,"pretrained_model_name_or_path"),E5t.forEach(t),mhr=r(Fw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S4e=n(Fw,"CODE",{});var C5t=s(S4e);ghr=r(C5t,"pretrained_model_name_or_path"),C5t.forEach(t),hhr=r(Fw,":"),Fw.forEach(t),phr=i(Aa),R4e=n(Aa,"UL",{});var w5t=s(R4e);xT=n(w5t,"LI",{});var DBe=s(xT);P4e=n(DBe,"STRONG",{});var A5t=s(P4e);_hr=r(A5t,"detr"),A5t.forEach(t),uhr=r(DBe," \u2014 "),XW=n(DBe,"A",{href:!0});var L5t=s(XW);bhr=r(L5t,"DetrForSegmentation"),L5t.forEach(t),vhr=r(DBe," (DETR model)"),DBe.forEach(t),w5t.forEach(t),Fhr=i(Aa),$T=n(Aa,"P",{});var GBe=s($T);Thr=r(GBe,"The model is set in evaluation mode by default using "),B4e=n(GBe,"CODE",{});var y5t=s(B4e);Mhr=r(y5t,"model.eval()"),y5t.forEach(t),Ehr=r(GBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I4e=n(GBe,"CODE",{});var x5t=s(I4e);Chr=r(x5t,"model.train()"),x5t.forEach(t),GBe.forEach(t),whr=i(Aa),T(kT.$$.fragment,Aa),Aa.forEach(t),Fl.forEach(t),OOe=i(f),Hd=n(f,"H2",{class:!0});var JXe=s(Hd);ST=n(JXe,"A",{id:!0,class:!0,href:!0});var $5t=s(ST);N4e=n($5t,"SPAN",{});var k5t=s(N4e);T(n9.$$.fragment,k5t),k5t.forEach(t),$5t.forEach(t),Ahr=i(JXe),q4e=n(JXe,"SPAN",{});var S5t=s(q4e);Lhr=r(S5t,"AutoModelForSemanticSegmentation"),S5t.forEach(t),JXe.forEach(t),VOe=i(f),Ko=n(f,"DIV",{class:!0});var Tl=s(Ko);T(s9.$$.fragment,Tl),yhr=i(Tl),Ud=n(Tl,"P",{});var cre=s(Ud);xhr=r(cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=n(cre,"A",{href:!0});var R5t=s(zW);$hr=r(R5t,"from_pretrained()"),R5t.forEach(t),khr=r(cre," class method or the "),QW=n(cre,"A",{href:!0});var P5t=s(QW);Shr=r(P5t,"from_config()"),P5t.forEach(t),Rhr=r(cre,` class
method.`),cre.forEach(t),Phr=i(Tl),l9=n(Tl,"P",{});var YXe=s(l9);Bhr=r(YXe,"This class cannot be instantiated directly using "),j4e=n(YXe,"CODE",{});var B5t=s(j4e);Ihr=r(B5t,"__init__()"),B5t.forEach(t),Nhr=r(YXe," (throws an error)."),YXe.forEach(t),qhr=i(Tl),yt=n(Tl,"DIV",{class:!0});var Tw=s(yt);T(i9.$$.fragment,Tw),jhr=i(Tw),D4e=n(Tw,"P",{});var I5t=s(D4e);Dhr=r(I5t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),I5t.forEach(t),Ghr=i(Tw),Jd=n(Tw,"P",{});var fre=s(Jd);Ohr=r(fre,`Note:
Loading a model from its configuration file does `),G4e=n(fre,"STRONG",{});var N5t=s(G4e);Vhr=r(N5t,"not"),N5t.forEach(t),Xhr=r(fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=n(fre,"A",{href:!0});var q5t=s(WW);zhr=r(q5t,"from_pretrained()"),q5t.forEach(t),Qhr=r(fre," to load the model weights."),fre.forEach(t),Whr=i(Tw),T(RT.$$.fragment,Tw),Tw.forEach(t),Hhr=i(Tl),vo=n(Tl,"DIV",{class:!0});var La=s(vo);T(d9.$$.fragment,La),Uhr=i(La),O4e=n(La,"P",{});var j5t=s(O4e);Jhr=r(j5t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),j5t.forEach(t),Yhr=i(La),on=n(La,"P",{});var Mw=s(on);Khr=r(Mw,"The model class to instantiate is selected based on the "),V4e=n(Mw,"CODE",{});var D5t=s(V4e);Zhr=r(D5t,"model_type"),D5t.forEach(t),epr=r(Mw,` property of the config object (either
passed as an argument or loaded from `),X4e=n(Mw,"CODE",{});var G5t=s(X4e);opr=r(G5t,"pretrained_model_name_or_path"),G5t.forEach(t),rpr=r(Mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z4e=n(Mw,"CODE",{});var O5t=s(z4e);tpr=r(O5t,"pretrained_model_name_or_path"),O5t.forEach(t),apr=r(Mw,":"),Mw.forEach(t),npr=i(La),rn=n(La,"UL",{});var Ew=s(rn);PT=n(Ew,"LI",{});var OBe=s(PT);Q4e=n(OBe,"STRONG",{});var V5t=s(Q4e);spr=r(V5t,"beit"),V5t.forEach(t),lpr=r(OBe," \u2014 "),HW=n(OBe,"A",{href:!0});var X5t=s(HW);ipr=r(X5t,"BeitForSemanticSegmentation"),X5t.forEach(t),dpr=r(OBe," (BEiT model)"),OBe.forEach(t),cpr=i(Ew),BT=n(Ew,"LI",{});var VBe=s(BT);W4e=n(VBe,"STRONG",{});var z5t=s(W4e);fpr=r(z5t,"data2vec-vision"),z5t.forEach(t),mpr=r(VBe," \u2014 "),UW=n(VBe,"A",{href:!0});var Q5t=s(UW);gpr=r(Q5t,"Data2VecVisionForSemanticSegmentation"),Q5t.forEach(t),hpr=r(VBe," (Data2VecVision model)"),VBe.forEach(t),ppr=i(Ew),IT=n(Ew,"LI",{});var XBe=s(IT);H4e=n(XBe,"STRONG",{});var W5t=s(H4e);_pr=r(W5t,"dpt"),W5t.forEach(t),upr=r(XBe," \u2014 "),JW=n(XBe,"A",{href:!0});var H5t=s(JW);bpr=r(H5t,"DPTForSemanticSegmentation"),H5t.forEach(t),vpr=r(XBe," (DPT model)"),XBe.forEach(t),Fpr=i(Ew),NT=n(Ew,"LI",{});var zBe=s(NT);U4e=n(zBe,"STRONG",{});var U5t=s(U4e);Tpr=r(U5t,"segformer"),U5t.forEach(t),Mpr=r(zBe," \u2014 "),YW=n(zBe,"A",{href:!0});var J5t=s(YW);Epr=r(J5t,"SegformerForSemanticSegmentation"),J5t.forEach(t),Cpr=r(zBe," (SegFormer model)"),zBe.forEach(t),Ew.forEach(t),wpr=i(La),qT=n(La,"P",{});var QBe=s(qT);Apr=r(QBe,"The model is set in evaluation mode by default using "),J4e=n(QBe,"CODE",{});var Y5t=s(J4e);Lpr=r(Y5t,"model.eval()"),Y5t.forEach(t),ypr=r(QBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y4e=n(QBe,"CODE",{});var K5t=s(Y4e);xpr=r(K5t,"model.train()"),K5t.forEach(t),QBe.forEach(t),$pr=i(La),T(jT.$$.fragment,La),La.forEach(t),Tl.forEach(t),XOe=i(f),Yd=n(f,"H2",{class:!0});var KXe=s(Yd);DT=n(KXe,"A",{id:!0,class:!0,href:!0});var Z5t=s(DT);K4e=n(Z5t,"SPAN",{});var e3t=s(K4e);T(c9.$$.fragment,e3t),e3t.forEach(t),Z5t.forEach(t),kpr=i(KXe),Z4e=n(KXe,"SPAN",{});var o3t=s(Z4e);Spr=r(o3t,"AutoModelForInstanceSegmentation"),o3t.forEach(t),KXe.forEach(t),zOe=i(f),Zo=n(f,"DIV",{class:!0});var Ml=s(Zo);T(f9.$$.fragment,Ml),Rpr=i(Ml),Kd=n(Ml,"P",{});var mre=s(Kd);Ppr=r(mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=n(mre,"A",{href:!0});var r3t=s(KW);Bpr=r(r3t,"from_pretrained()"),r3t.forEach(t),Ipr=r(mre," class method or the "),ZW=n(mre,"A",{href:!0});var t3t=s(ZW);Npr=r(t3t,"from_config()"),t3t.forEach(t),qpr=r(mre,` class
method.`),mre.forEach(t),jpr=i(Ml),m9=n(Ml,"P",{});var ZXe=s(m9);Dpr=r(ZXe,"This class cannot be instantiated directly using "),eve=n(ZXe,"CODE",{});var a3t=s(eve);Gpr=r(a3t,"__init__()"),a3t.forEach(t),Opr=r(ZXe," (throws an error)."),ZXe.forEach(t),Vpr=i(Ml),xt=n(Ml,"DIV",{class:!0});var Cw=s(xt);T(g9.$$.fragment,Cw),Xpr=i(Cw),ove=n(Cw,"P",{});var n3t=s(ove);zpr=r(n3t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),n3t.forEach(t),Qpr=i(Cw),Zd=n(Cw,"P",{});var gre=s(Zd);Wpr=r(gre,`Note:
Loading a model from its configuration file does `),rve=n(gre,"STRONG",{});var s3t=s(rve);Hpr=r(s3t,"not"),s3t.forEach(t),Upr=r(gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=n(gre,"A",{href:!0});var l3t=s(eH);Jpr=r(l3t,"from_pretrained()"),l3t.forEach(t),Ypr=r(gre," to load the model weights."),gre.forEach(t),Kpr=i(Cw),T(GT.$$.fragment,Cw),Cw.forEach(t),Zpr=i(Ml),Fo=n(Ml,"DIV",{class:!0});var ya=s(Fo);T(h9.$$.fragment,ya),e_r=i(ya),tve=n(ya,"P",{});var i3t=s(tve);o_r=r(i3t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),i3t.forEach(t),r_r=i(ya),tn=n(ya,"P",{});var ww=s(tn);t_r=r(ww,"The model class to instantiate is selected based on the "),ave=n(ww,"CODE",{});var d3t=s(ave);a_r=r(d3t,"model_type"),d3t.forEach(t),n_r=r(ww,` property of the config object (either
passed as an argument or loaded from `),nve=n(ww,"CODE",{});var c3t=s(nve);s_r=r(c3t,"pretrained_model_name_or_path"),c3t.forEach(t),l_r=r(ww,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sve=n(ww,"CODE",{});var f3t=s(sve);i_r=r(f3t,"pretrained_model_name_or_path"),f3t.forEach(t),d_r=r(ww,":"),ww.forEach(t),c_r=i(ya),lve=n(ya,"UL",{});var m3t=s(lve);OT=n(m3t,"LI",{});var WBe=s(OT);ive=n(WBe,"STRONG",{});var g3t=s(ive);f_r=r(g3t,"maskformer"),g3t.forEach(t),m_r=r(WBe," \u2014 "),oH=n(WBe,"A",{href:!0});var h3t=s(oH);g_r=r(h3t,"MaskFormerForInstanceSegmentation"),h3t.forEach(t),h_r=r(WBe," (MaskFormer model)"),WBe.forEach(t),m3t.forEach(t),p_r=i(ya),VT=n(ya,"P",{});var HBe=s(VT);__r=r(HBe,"The model is set in evaluation mode by default using "),dve=n(HBe,"CODE",{});var p3t=s(dve);u_r=r(p3t,"model.eval()"),p3t.forEach(t),b_r=r(HBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cve=n(HBe,"CODE",{});var _3t=s(cve);v_r=r(_3t,"model.train()"),_3t.forEach(t),HBe.forEach(t),F_r=i(ya),T(XT.$$.fragment,ya),ya.forEach(t),Ml.forEach(t),QOe=i(f),ec=n(f,"H2",{class:!0});var eze=s(ec);zT=n(eze,"A",{id:!0,class:!0,href:!0});var u3t=s(zT);fve=n(u3t,"SPAN",{});var b3t=s(fve);T(p9.$$.fragment,b3t),b3t.forEach(t),u3t.forEach(t),T_r=i(eze),mve=n(eze,"SPAN",{});var v3t=s(mve);M_r=r(v3t,"TFAutoModel"),v3t.forEach(t),eze.forEach(t),WOe=i(f),er=n(f,"DIV",{class:!0});var El=s(er);T(_9.$$.fragment,El),E_r=i(El),oc=n(El,"P",{});var hre=s(oc);C_r=r(hre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=n(hre,"A",{href:!0});var F3t=s(rH);w_r=r(F3t,"from_pretrained()"),F3t.forEach(t),A_r=r(hre," class method or the "),tH=n(hre,"A",{href:!0});var T3t=s(tH);L_r=r(T3t,"from_config()"),T3t.forEach(t),y_r=r(hre,` class
method.`),hre.forEach(t),x_r=i(El),u9=n(El,"P",{});var oze=s(u9);$_r=r(oze,"This class cannot be instantiated directly using "),gve=n(oze,"CODE",{});var M3t=s(gve);k_r=r(M3t,"__init__()"),M3t.forEach(t),S_r=r(oze," (throws an error)."),oze.forEach(t),R_r=i(El),$t=n(El,"DIV",{class:!0});var Aw=s($t);T(b9.$$.fragment,Aw),P_r=i(Aw),hve=n(Aw,"P",{});var E3t=s(hve);B_r=r(E3t,"Instantiates one of the base model classes of the library from a configuration."),E3t.forEach(t),I_r=i(Aw),rc=n(Aw,"P",{});var pre=s(rc);N_r=r(pre,`Note:
Loading a model from its configuration file does `),pve=n(pre,"STRONG",{});var C3t=s(pve);q_r=r(C3t,"not"),C3t.forEach(t),j_r=r(pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=n(pre,"A",{href:!0});var w3t=s(aH);D_r=r(w3t,"from_pretrained()"),w3t.forEach(t),G_r=r(pre," to load the model weights."),pre.forEach(t),O_r=i(Aw),T(QT.$$.fragment,Aw),Aw.forEach(t),V_r=i(El),yr=n(El,"DIV",{class:!0});var Cl=s(yr);T(v9.$$.fragment,Cl),X_r=i(Cl),_ve=n(Cl,"P",{});var A3t=s(_ve);z_r=r(A3t,"Instantiate one of the base model classes of the library from a pretrained model."),A3t.forEach(t),Q_r=i(Cl),an=n(Cl,"P",{});var Lw=s(an);W_r=r(Lw,"The model class to instantiate is selected based on the "),uve=n(Lw,"CODE",{});var L3t=s(uve);H_r=r(L3t,"model_type"),L3t.forEach(t),U_r=r(Lw,` property of the config object (either
passed as an argument or loaded from `),bve=n(Lw,"CODE",{});var y3t=s(bve);J_r=r(y3t,"pretrained_model_name_or_path"),y3t.forEach(t),Y_r=r(Lw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vve=n(Lw,"CODE",{});var x3t=s(vve);K_r=r(x3t,"pretrained_model_name_or_path"),x3t.forEach(t),Z_r=r(Lw,":"),Lw.forEach(t),eur=i(Cl),j=n(Cl,"UL",{});var D=s(j);WT=n(D,"LI",{});var UBe=s(WT);Fve=n(UBe,"STRONG",{});var $3t=s(Fve);our=r($3t,"albert"),$3t.forEach(t),rur=r(UBe," \u2014 "),nH=n(UBe,"A",{href:!0});var k3t=s(nH);tur=r(k3t,"TFAlbertModel"),k3t.forEach(t),aur=r(UBe," (ALBERT model)"),UBe.forEach(t),nur=i(D),HT=n(D,"LI",{});var JBe=s(HT);Tve=n(JBe,"STRONG",{});var S3t=s(Tve);sur=r(S3t,"bart"),S3t.forEach(t),lur=r(JBe," \u2014 "),sH=n(JBe,"A",{href:!0});var R3t=s(sH);iur=r(R3t,"TFBartModel"),R3t.forEach(t),dur=r(JBe," (BART model)"),JBe.forEach(t),cur=i(D),UT=n(D,"LI",{});var YBe=s(UT);Mve=n(YBe,"STRONG",{});var P3t=s(Mve);fur=r(P3t,"bert"),P3t.forEach(t),mur=r(YBe," \u2014 "),lH=n(YBe,"A",{href:!0});var B3t=s(lH);gur=r(B3t,"TFBertModel"),B3t.forEach(t),hur=r(YBe," (BERT model)"),YBe.forEach(t),pur=i(D),JT=n(D,"LI",{});var KBe=s(JT);Eve=n(KBe,"STRONG",{});var I3t=s(Eve);_ur=r(I3t,"blenderbot"),I3t.forEach(t),uur=r(KBe," \u2014 "),iH=n(KBe,"A",{href:!0});var N3t=s(iH);bur=r(N3t,"TFBlenderbotModel"),N3t.forEach(t),vur=r(KBe," (Blenderbot model)"),KBe.forEach(t),Fur=i(D),YT=n(D,"LI",{});var ZBe=s(YT);Cve=n(ZBe,"STRONG",{});var q3t=s(Cve);Tur=r(q3t,"blenderbot-small"),q3t.forEach(t),Mur=r(ZBe," \u2014 "),dH=n(ZBe,"A",{href:!0});var j3t=s(dH);Eur=r(j3t,"TFBlenderbotSmallModel"),j3t.forEach(t),Cur=r(ZBe," (BlenderbotSmall model)"),ZBe.forEach(t),wur=i(D),KT=n(D,"LI",{});var eIe=s(KT);wve=n(eIe,"STRONG",{});var D3t=s(wve);Aur=r(D3t,"camembert"),D3t.forEach(t),Lur=r(eIe," \u2014 "),cH=n(eIe,"A",{href:!0});var G3t=s(cH);yur=r(G3t,"TFCamembertModel"),G3t.forEach(t),xur=r(eIe," (CamemBERT model)"),eIe.forEach(t),$ur=i(D),ZT=n(D,"LI",{});var oIe=s(ZT);Ave=n(oIe,"STRONG",{});var O3t=s(Ave);kur=r(O3t,"clip"),O3t.forEach(t),Sur=r(oIe," \u2014 "),fH=n(oIe,"A",{href:!0});var V3t=s(fH);Rur=r(V3t,"TFCLIPModel"),V3t.forEach(t),Pur=r(oIe," (CLIP model)"),oIe.forEach(t),Bur=i(D),e7=n(D,"LI",{});var rIe=s(e7);Lve=n(rIe,"STRONG",{});var X3t=s(Lve);Iur=r(X3t,"convbert"),X3t.forEach(t),Nur=r(rIe," \u2014 "),mH=n(rIe,"A",{href:!0});var z3t=s(mH);qur=r(z3t,"TFConvBertModel"),z3t.forEach(t),jur=r(rIe," (ConvBERT model)"),rIe.forEach(t),Dur=i(D),o7=n(D,"LI",{});var tIe=s(o7);yve=n(tIe,"STRONG",{});var Q3t=s(yve);Gur=r(Q3t,"convnext"),Q3t.forEach(t),Our=r(tIe," \u2014 "),gH=n(tIe,"A",{href:!0});var W3t=s(gH);Vur=r(W3t,"TFConvNextModel"),W3t.forEach(t),Xur=r(tIe," (ConvNeXT model)"),tIe.forEach(t),zur=i(D),r7=n(D,"LI",{});var aIe=s(r7);xve=n(aIe,"STRONG",{});var H3t=s(xve);Qur=r(H3t,"ctrl"),H3t.forEach(t),Wur=r(aIe," \u2014 "),hH=n(aIe,"A",{href:!0});var U3t=s(hH);Hur=r(U3t,"TFCTRLModel"),U3t.forEach(t),Uur=r(aIe," (CTRL model)"),aIe.forEach(t),Jur=i(D),t7=n(D,"LI",{});var nIe=s(t7);$ve=n(nIe,"STRONG",{});var J3t=s($ve);Yur=r(J3t,"data2vec-vision"),J3t.forEach(t),Kur=r(nIe," \u2014 "),pH=n(nIe,"A",{href:!0});var Y3t=s(pH);Zur=r(Y3t,"TFData2VecVisionModel"),Y3t.forEach(t),e1r=r(nIe," (Data2VecVision model)"),nIe.forEach(t),o1r=i(D),a7=n(D,"LI",{});var sIe=s(a7);kve=n(sIe,"STRONG",{});var K3t=s(kve);r1r=r(K3t,"deberta"),K3t.forEach(t),t1r=r(sIe," \u2014 "),_H=n(sIe,"A",{href:!0});var Z3t=s(_H);a1r=r(Z3t,"TFDebertaModel"),Z3t.forEach(t),n1r=r(sIe," (DeBERTa model)"),sIe.forEach(t),s1r=i(D),n7=n(D,"LI",{});var lIe=s(n7);Sve=n(lIe,"STRONG",{});var e0t=s(Sve);l1r=r(e0t,"deberta-v2"),e0t.forEach(t),i1r=r(lIe," \u2014 "),uH=n(lIe,"A",{href:!0});var o0t=s(uH);d1r=r(o0t,"TFDebertaV2Model"),o0t.forEach(t),c1r=r(lIe," (DeBERTa-v2 model)"),lIe.forEach(t),f1r=i(D),s7=n(D,"LI",{});var iIe=s(s7);Rve=n(iIe,"STRONG",{});var r0t=s(Rve);m1r=r(r0t,"distilbert"),r0t.forEach(t),g1r=r(iIe," \u2014 "),bH=n(iIe,"A",{href:!0});var t0t=s(bH);h1r=r(t0t,"TFDistilBertModel"),t0t.forEach(t),p1r=r(iIe," (DistilBERT model)"),iIe.forEach(t),_1r=i(D),l7=n(D,"LI",{});var dIe=s(l7);Pve=n(dIe,"STRONG",{});var a0t=s(Pve);u1r=r(a0t,"dpr"),a0t.forEach(t),b1r=r(dIe," \u2014 "),vH=n(dIe,"A",{href:!0});var n0t=s(vH);v1r=r(n0t,"TFDPRQuestionEncoder"),n0t.forEach(t),F1r=r(dIe," (DPR model)"),dIe.forEach(t),T1r=i(D),i7=n(D,"LI",{});var cIe=s(i7);Bve=n(cIe,"STRONG",{});var s0t=s(Bve);M1r=r(s0t,"electra"),s0t.forEach(t),E1r=r(cIe," \u2014 "),FH=n(cIe,"A",{href:!0});var l0t=s(FH);C1r=r(l0t,"TFElectraModel"),l0t.forEach(t),w1r=r(cIe," (ELECTRA model)"),cIe.forEach(t),A1r=i(D),d7=n(D,"LI",{});var fIe=s(d7);Ive=n(fIe,"STRONG",{});var i0t=s(Ive);L1r=r(i0t,"flaubert"),i0t.forEach(t),y1r=r(fIe," \u2014 "),TH=n(fIe,"A",{href:!0});var d0t=s(TH);x1r=r(d0t,"TFFlaubertModel"),d0t.forEach(t),$1r=r(fIe," (FlauBERT model)"),fIe.forEach(t),k1r=i(D),Qs=n(D,"LI",{});var oS=s(Qs);Nve=n(oS,"STRONG",{});var c0t=s(Nve);S1r=r(c0t,"funnel"),c0t.forEach(t),R1r=r(oS," \u2014 "),MH=n(oS,"A",{href:!0});var f0t=s(MH);P1r=r(f0t,"TFFunnelModel"),f0t.forEach(t),B1r=r(oS," or "),EH=n(oS,"A",{href:!0});var m0t=s(EH);I1r=r(m0t,"TFFunnelBaseModel"),m0t.forEach(t),N1r=r(oS," (Funnel Transformer model)"),oS.forEach(t),q1r=i(D),c7=n(D,"LI",{});var mIe=s(c7);qve=n(mIe,"STRONG",{});var g0t=s(qve);j1r=r(g0t,"gpt2"),g0t.forEach(t),D1r=r(mIe," \u2014 "),CH=n(mIe,"A",{href:!0});var h0t=s(CH);G1r=r(h0t,"TFGPT2Model"),h0t.forEach(t),O1r=r(mIe," (OpenAI GPT-2 model)"),mIe.forEach(t),V1r=i(D),f7=n(D,"LI",{});var gIe=s(f7);jve=n(gIe,"STRONG",{});var p0t=s(jve);X1r=r(p0t,"gptj"),p0t.forEach(t),z1r=r(gIe," \u2014 "),wH=n(gIe,"A",{href:!0});var _0t=s(wH);Q1r=r(_0t,"TFGPTJModel"),_0t.forEach(t),W1r=r(gIe," (GPT-J model)"),gIe.forEach(t),H1r=i(D),m7=n(D,"LI",{});var hIe=s(m7);Dve=n(hIe,"STRONG",{});var u0t=s(Dve);U1r=r(u0t,"hubert"),u0t.forEach(t),J1r=r(hIe," \u2014 "),AH=n(hIe,"A",{href:!0});var b0t=s(AH);Y1r=r(b0t,"TFHubertModel"),b0t.forEach(t),K1r=r(hIe," (Hubert model)"),hIe.forEach(t),Z1r=i(D),g7=n(D,"LI",{});var pIe=s(g7);Gve=n(pIe,"STRONG",{});var v0t=s(Gve);e2r=r(v0t,"layoutlm"),v0t.forEach(t),o2r=r(pIe," \u2014 "),LH=n(pIe,"A",{href:!0});var F0t=s(LH);r2r=r(F0t,"TFLayoutLMModel"),F0t.forEach(t),t2r=r(pIe," (LayoutLM model)"),pIe.forEach(t),a2r=i(D),h7=n(D,"LI",{});var _Ie=s(h7);Ove=n(_Ie,"STRONG",{});var T0t=s(Ove);n2r=r(T0t,"led"),T0t.forEach(t),s2r=r(_Ie," \u2014 "),yH=n(_Ie,"A",{href:!0});var M0t=s(yH);l2r=r(M0t,"TFLEDModel"),M0t.forEach(t),i2r=r(_Ie," (LED model)"),_Ie.forEach(t),d2r=i(D),p7=n(D,"LI",{});var uIe=s(p7);Vve=n(uIe,"STRONG",{});var E0t=s(Vve);c2r=r(E0t,"longformer"),E0t.forEach(t),f2r=r(uIe," \u2014 "),xH=n(uIe,"A",{href:!0});var C0t=s(xH);m2r=r(C0t,"TFLongformerModel"),C0t.forEach(t),g2r=r(uIe," (Longformer model)"),uIe.forEach(t),h2r=i(D),_7=n(D,"LI",{});var bIe=s(_7);Xve=n(bIe,"STRONG",{});var w0t=s(Xve);p2r=r(w0t,"lxmert"),w0t.forEach(t),_2r=r(bIe," \u2014 "),$H=n(bIe,"A",{href:!0});var A0t=s($H);u2r=r(A0t,"TFLxmertModel"),A0t.forEach(t),b2r=r(bIe," (LXMERT model)"),bIe.forEach(t),v2r=i(D),u7=n(D,"LI",{});var vIe=s(u7);zve=n(vIe,"STRONG",{});var L0t=s(zve);F2r=r(L0t,"marian"),L0t.forEach(t),T2r=r(vIe," \u2014 "),kH=n(vIe,"A",{href:!0});var y0t=s(kH);M2r=r(y0t,"TFMarianModel"),y0t.forEach(t),E2r=r(vIe," (Marian model)"),vIe.forEach(t),C2r=i(D),b7=n(D,"LI",{});var FIe=s(b7);Qve=n(FIe,"STRONG",{});var x0t=s(Qve);w2r=r(x0t,"mbart"),x0t.forEach(t),A2r=r(FIe," \u2014 "),SH=n(FIe,"A",{href:!0});var $0t=s(SH);L2r=r($0t,"TFMBartModel"),$0t.forEach(t),y2r=r(FIe," (mBART model)"),FIe.forEach(t),x2r=i(D),v7=n(D,"LI",{});var TIe=s(v7);Wve=n(TIe,"STRONG",{});var k0t=s(Wve);$2r=r(k0t,"mobilebert"),k0t.forEach(t),k2r=r(TIe," \u2014 "),RH=n(TIe,"A",{href:!0});var S0t=s(RH);S2r=r(S0t,"TFMobileBertModel"),S0t.forEach(t),R2r=r(TIe," (MobileBERT model)"),TIe.forEach(t),P2r=i(D),F7=n(D,"LI",{});var MIe=s(F7);Hve=n(MIe,"STRONG",{});var R0t=s(Hve);B2r=r(R0t,"mpnet"),R0t.forEach(t),I2r=r(MIe," \u2014 "),PH=n(MIe,"A",{href:!0});var P0t=s(PH);N2r=r(P0t,"TFMPNetModel"),P0t.forEach(t),q2r=r(MIe," (MPNet model)"),MIe.forEach(t),j2r=i(D),T7=n(D,"LI",{});var EIe=s(T7);Uve=n(EIe,"STRONG",{});var B0t=s(Uve);D2r=r(B0t,"mt5"),B0t.forEach(t),G2r=r(EIe," \u2014 "),BH=n(EIe,"A",{href:!0});var I0t=s(BH);O2r=r(I0t,"TFMT5Model"),I0t.forEach(t),V2r=r(EIe," (MT5 model)"),EIe.forEach(t),X2r=i(D),M7=n(D,"LI",{});var CIe=s(M7);Jve=n(CIe,"STRONG",{});var N0t=s(Jve);z2r=r(N0t,"openai-gpt"),N0t.forEach(t),Q2r=r(CIe," \u2014 "),IH=n(CIe,"A",{href:!0});var q0t=s(IH);W2r=r(q0t,"TFOpenAIGPTModel"),q0t.forEach(t),H2r=r(CIe," (OpenAI GPT model)"),CIe.forEach(t),U2r=i(D),E7=n(D,"LI",{});var wIe=s(E7);Yve=n(wIe,"STRONG",{});var j0t=s(Yve);J2r=r(j0t,"opt"),j0t.forEach(t),Y2r=r(wIe," \u2014 "),NH=n(wIe,"A",{href:!0});var D0t=s(NH);K2r=r(D0t,"TFOPTModel"),D0t.forEach(t),Z2r=r(wIe," (OPT model)"),wIe.forEach(t),ebr=i(D),C7=n(D,"LI",{});var AIe=s(C7);Kve=n(AIe,"STRONG",{});var G0t=s(Kve);obr=r(G0t,"pegasus"),G0t.forEach(t),rbr=r(AIe," \u2014 "),qH=n(AIe,"A",{href:!0});var O0t=s(qH);tbr=r(O0t,"TFPegasusModel"),O0t.forEach(t),abr=r(AIe," (Pegasus model)"),AIe.forEach(t),nbr=i(D),w7=n(D,"LI",{});var LIe=s(w7);Zve=n(LIe,"STRONG",{});var V0t=s(Zve);sbr=r(V0t,"rembert"),V0t.forEach(t),lbr=r(LIe," \u2014 "),jH=n(LIe,"A",{href:!0});var X0t=s(jH);ibr=r(X0t,"TFRemBertModel"),X0t.forEach(t),dbr=r(LIe," (RemBERT model)"),LIe.forEach(t),cbr=i(D),A7=n(D,"LI",{});var yIe=s(A7);eFe=n(yIe,"STRONG",{});var z0t=s(eFe);fbr=r(z0t,"roberta"),z0t.forEach(t),mbr=r(yIe," \u2014 "),DH=n(yIe,"A",{href:!0});var Q0t=s(DH);gbr=r(Q0t,"TFRobertaModel"),Q0t.forEach(t),hbr=r(yIe," (RoBERTa model)"),yIe.forEach(t),pbr=i(D),L7=n(D,"LI",{});var xIe=s(L7);oFe=n(xIe,"STRONG",{});var W0t=s(oFe);_br=r(W0t,"roformer"),W0t.forEach(t),ubr=r(xIe," \u2014 "),GH=n(xIe,"A",{href:!0});var H0t=s(GH);bbr=r(H0t,"TFRoFormerModel"),H0t.forEach(t),vbr=r(xIe," (RoFormer model)"),xIe.forEach(t),Fbr=i(D),y7=n(D,"LI",{});var $Ie=s(y7);rFe=n($Ie,"STRONG",{});var U0t=s(rFe);Tbr=r(U0t,"speech_to_text"),U0t.forEach(t),Mbr=r($Ie," \u2014 "),OH=n($Ie,"A",{href:!0});var J0t=s(OH);Ebr=r(J0t,"TFSpeech2TextModel"),J0t.forEach(t),Cbr=r($Ie," (Speech2Text model)"),$Ie.forEach(t),wbr=i(D),x7=n(D,"LI",{});var kIe=s(x7);tFe=n(kIe,"STRONG",{});var Y0t=s(tFe);Abr=r(Y0t,"swin"),Y0t.forEach(t),Lbr=r(kIe," \u2014 "),VH=n(kIe,"A",{href:!0});var K0t=s(VH);ybr=r(K0t,"TFSwinModel"),K0t.forEach(t),xbr=r(kIe," (Swin Transformer model)"),kIe.forEach(t),$br=i(D),$7=n(D,"LI",{});var SIe=s($7);aFe=n(SIe,"STRONG",{});var Z0t=s(aFe);kbr=r(Z0t,"t5"),Z0t.forEach(t),Sbr=r(SIe," \u2014 "),XH=n(SIe,"A",{href:!0});var ewt=s(XH);Rbr=r(ewt,"TFT5Model"),ewt.forEach(t),Pbr=r(SIe," (T5 model)"),SIe.forEach(t),Bbr=i(D),k7=n(D,"LI",{});var RIe=s(k7);nFe=n(RIe,"STRONG",{});var owt=s(nFe);Ibr=r(owt,"tapas"),owt.forEach(t),Nbr=r(RIe," \u2014 "),zH=n(RIe,"A",{href:!0});var rwt=s(zH);qbr=r(rwt,"TFTapasModel"),rwt.forEach(t),jbr=r(RIe," (TAPAS model)"),RIe.forEach(t),Dbr=i(D),S7=n(D,"LI",{});var PIe=s(S7);sFe=n(PIe,"STRONG",{});var twt=s(sFe);Gbr=r(twt,"transfo-xl"),twt.forEach(t),Obr=r(PIe," \u2014 "),QH=n(PIe,"A",{href:!0});var awt=s(QH);Vbr=r(awt,"TFTransfoXLModel"),awt.forEach(t),Xbr=r(PIe," (Transformer-XL model)"),PIe.forEach(t),zbr=i(D),R7=n(D,"LI",{});var BIe=s(R7);lFe=n(BIe,"STRONG",{});var nwt=s(lFe);Qbr=r(nwt,"vit"),nwt.forEach(t),Wbr=r(BIe," \u2014 "),WH=n(BIe,"A",{href:!0});var swt=s(WH);Hbr=r(swt,"TFViTModel"),swt.forEach(t),Ubr=r(BIe," (ViT model)"),BIe.forEach(t),Jbr=i(D),P7=n(D,"LI",{});var IIe=s(P7);iFe=n(IIe,"STRONG",{});var lwt=s(iFe);Ybr=r(lwt,"vit_mae"),lwt.forEach(t),Kbr=r(IIe," \u2014 "),HH=n(IIe,"A",{href:!0});var iwt=s(HH);Zbr=r(iwt,"TFViTMAEModel"),iwt.forEach(t),e4r=r(IIe," (ViTMAE model)"),IIe.forEach(t),o4r=i(D),B7=n(D,"LI",{});var NIe=s(B7);dFe=n(NIe,"STRONG",{});var dwt=s(dFe);r4r=r(dwt,"wav2vec2"),dwt.forEach(t),t4r=r(NIe," \u2014 "),UH=n(NIe,"A",{href:!0});var cwt=s(UH);a4r=r(cwt,"TFWav2Vec2Model"),cwt.forEach(t),n4r=r(NIe," (Wav2Vec2 model)"),NIe.forEach(t),s4r=i(D),I7=n(D,"LI",{});var qIe=s(I7);cFe=n(qIe,"STRONG",{});var fwt=s(cFe);l4r=r(fwt,"xlm"),fwt.forEach(t),i4r=r(qIe," \u2014 "),JH=n(qIe,"A",{href:!0});var mwt=s(JH);d4r=r(mwt,"TFXLMModel"),mwt.forEach(t),c4r=r(qIe," (XLM model)"),qIe.forEach(t),f4r=i(D),N7=n(D,"LI",{});var jIe=s(N7);fFe=n(jIe,"STRONG",{});var gwt=s(fFe);m4r=r(gwt,"xlm-roberta"),gwt.forEach(t),g4r=r(jIe," \u2014 "),YH=n(jIe,"A",{href:!0});var hwt=s(YH);h4r=r(hwt,"TFXLMRobertaModel"),hwt.forEach(t),p4r=r(jIe," (XLM-RoBERTa model)"),jIe.forEach(t),_4r=i(D),q7=n(D,"LI",{});var DIe=s(q7);mFe=n(DIe,"STRONG",{});var pwt=s(mFe);u4r=r(pwt,"xlnet"),pwt.forEach(t),b4r=r(DIe," \u2014 "),KH=n(DIe,"A",{href:!0});var _wt=s(KH);v4r=r(_wt,"TFXLNetModel"),_wt.forEach(t),F4r=r(DIe," (XLNet model)"),DIe.forEach(t),D.forEach(t),T4r=i(Cl),T(j7.$$.fragment,Cl),Cl.forEach(t),El.forEach(t),HOe=i(f),tc=n(f,"H2",{class:!0});var rze=s(tc);D7=n(rze,"A",{id:!0,class:!0,href:!0});var uwt=s(D7);gFe=n(uwt,"SPAN",{});var bwt=s(gFe);T(F9.$$.fragment,bwt),bwt.forEach(t),uwt.forEach(t),M4r=i(rze),hFe=n(rze,"SPAN",{});var vwt=s(hFe);E4r=r(vwt,"TFAutoModelForPreTraining"),vwt.forEach(t),rze.forEach(t),UOe=i(f),or=n(f,"DIV",{class:!0});var wl=s(or);T(T9.$$.fragment,wl),C4r=i(wl),ac=n(wl,"P",{});var _re=s(ac);w4r=r(_re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=n(_re,"A",{href:!0});var Fwt=s(ZH);A4r=r(Fwt,"from_pretrained()"),Fwt.forEach(t),L4r=r(_re," class method or the "),eU=n(_re,"A",{href:!0});var Twt=s(eU);y4r=r(Twt,"from_config()"),Twt.forEach(t),x4r=r(_re,` class
method.`),_re.forEach(t),$4r=i(wl),M9=n(wl,"P",{});var tze=s(M9);k4r=r(tze,"This class cannot be instantiated directly using "),pFe=n(tze,"CODE",{});var Mwt=s(pFe);S4r=r(Mwt,"__init__()"),Mwt.forEach(t),R4r=r(tze," (throws an error)."),tze.forEach(t),P4r=i(wl),kt=n(wl,"DIV",{class:!0});var yw=s(kt);T(E9.$$.fragment,yw),B4r=i(yw),_Fe=n(yw,"P",{});var Ewt=s(_Fe);I4r=r(Ewt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Ewt.forEach(t),N4r=i(yw),nc=n(yw,"P",{});var ure=s(nc);q4r=r(ure,`Note:
Loading a model from its configuration file does `),uFe=n(ure,"STRONG",{});var Cwt=s(uFe);j4r=r(Cwt,"not"),Cwt.forEach(t),D4r=r(ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=n(ure,"A",{href:!0});var wwt=s(oU);G4r=r(wwt,"from_pretrained()"),wwt.forEach(t),O4r=r(ure," to load the model weights."),ure.forEach(t),V4r=i(yw),T(G7.$$.fragment,yw),yw.forEach(t),X4r=i(wl),xr=n(wl,"DIV",{class:!0});var Al=s(xr);T(C9.$$.fragment,Al),z4r=i(Al),bFe=n(Al,"P",{});var Awt=s(bFe);Q4r=r(Awt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Awt.forEach(t),W4r=i(Al),nn=n(Al,"P",{});var xw=s(nn);H4r=r(xw,"The model class to instantiate is selected based on the "),vFe=n(xw,"CODE",{});var Lwt=s(vFe);U4r=r(Lwt,"model_type"),Lwt.forEach(t),J4r=r(xw,` property of the config object (either
passed as an argument or loaded from `),FFe=n(xw,"CODE",{});var ywt=s(FFe);Y4r=r(ywt,"pretrained_model_name_or_path"),ywt.forEach(t),K4r=r(xw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TFe=n(xw,"CODE",{});var xwt=s(TFe);Z4r=r(xwt,"pretrained_model_name_or_path"),xwt.forEach(t),evr=r(xw,":"),xw.forEach(t),ovr=i(Al),se=n(Al,"UL",{});var le=s(se);O7=n(le,"LI",{});var GIe=s(O7);MFe=n(GIe,"STRONG",{});var $wt=s(MFe);rvr=r($wt,"albert"),$wt.forEach(t),tvr=r(GIe," \u2014 "),rU=n(GIe,"A",{href:!0});var kwt=s(rU);avr=r(kwt,"TFAlbertForPreTraining"),kwt.forEach(t),nvr=r(GIe," (ALBERT model)"),GIe.forEach(t),svr=i(le),V7=n(le,"LI",{});var OIe=s(V7);EFe=n(OIe,"STRONG",{});var Swt=s(EFe);lvr=r(Swt,"bart"),Swt.forEach(t),ivr=r(OIe," \u2014 "),tU=n(OIe,"A",{href:!0});var Rwt=s(tU);dvr=r(Rwt,"TFBartForConditionalGeneration"),Rwt.forEach(t),cvr=r(OIe," (BART model)"),OIe.forEach(t),fvr=i(le),X7=n(le,"LI",{});var VIe=s(X7);CFe=n(VIe,"STRONG",{});var Pwt=s(CFe);mvr=r(Pwt,"bert"),Pwt.forEach(t),gvr=r(VIe," \u2014 "),aU=n(VIe,"A",{href:!0});var Bwt=s(aU);hvr=r(Bwt,"TFBertForPreTraining"),Bwt.forEach(t),pvr=r(VIe," (BERT model)"),VIe.forEach(t),_vr=i(le),z7=n(le,"LI",{});var XIe=s(z7);wFe=n(XIe,"STRONG",{});var Iwt=s(wFe);uvr=r(Iwt,"camembert"),Iwt.forEach(t),bvr=r(XIe," \u2014 "),nU=n(XIe,"A",{href:!0});var Nwt=s(nU);vvr=r(Nwt,"TFCamembertForMaskedLM"),Nwt.forEach(t),Fvr=r(XIe," (CamemBERT model)"),XIe.forEach(t),Tvr=i(le),Q7=n(le,"LI",{});var zIe=s(Q7);AFe=n(zIe,"STRONG",{});var qwt=s(AFe);Mvr=r(qwt,"ctrl"),qwt.forEach(t),Evr=r(zIe," \u2014 "),sU=n(zIe,"A",{href:!0});var jwt=s(sU);Cvr=r(jwt,"TFCTRLLMHeadModel"),jwt.forEach(t),wvr=r(zIe," (CTRL model)"),zIe.forEach(t),Avr=i(le),W7=n(le,"LI",{});var QIe=s(W7);LFe=n(QIe,"STRONG",{});var Dwt=s(LFe);Lvr=r(Dwt,"distilbert"),Dwt.forEach(t),yvr=r(QIe," \u2014 "),lU=n(QIe,"A",{href:!0});var Gwt=s(lU);xvr=r(Gwt,"TFDistilBertForMaskedLM"),Gwt.forEach(t),$vr=r(QIe," (DistilBERT model)"),QIe.forEach(t),kvr=i(le),H7=n(le,"LI",{});var WIe=s(H7);yFe=n(WIe,"STRONG",{});var Owt=s(yFe);Svr=r(Owt,"electra"),Owt.forEach(t),Rvr=r(WIe," \u2014 "),iU=n(WIe,"A",{href:!0});var Vwt=s(iU);Pvr=r(Vwt,"TFElectraForPreTraining"),Vwt.forEach(t),Bvr=r(WIe," (ELECTRA model)"),WIe.forEach(t),Ivr=i(le),U7=n(le,"LI",{});var HIe=s(U7);xFe=n(HIe,"STRONG",{});var Xwt=s(xFe);Nvr=r(Xwt,"flaubert"),Xwt.forEach(t),qvr=r(HIe," \u2014 "),dU=n(HIe,"A",{href:!0});var zwt=s(dU);jvr=r(zwt,"TFFlaubertWithLMHeadModel"),zwt.forEach(t),Dvr=r(HIe," (FlauBERT model)"),HIe.forEach(t),Gvr=i(le),J7=n(le,"LI",{});var UIe=s(J7);$Fe=n(UIe,"STRONG",{});var Qwt=s($Fe);Ovr=r(Qwt,"funnel"),Qwt.forEach(t),Vvr=r(UIe," \u2014 "),cU=n(UIe,"A",{href:!0});var Wwt=s(cU);Xvr=r(Wwt,"TFFunnelForPreTraining"),Wwt.forEach(t),zvr=r(UIe," (Funnel Transformer model)"),UIe.forEach(t),Qvr=i(le),Y7=n(le,"LI",{});var JIe=s(Y7);kFe=n(JIe,"STRONG",{});var Hwt=s(kFe);Wvr=r(Hwt,"gpt2"),Hwt.forEach(t),Hvr=r(JIe," \u2014 "),fU=n(JIe,"A",{href:!0});var Uwt=s(fU);Uvr=r(Uwt,"TFGPT2LMHeadModel"),Uwt.forEach(t),Jvr=r(JIe," (OpenAI GPT-2 model)"),JIe.forEach(t),Yvr=i(le),K7=n(le,"LI",{});var YIe=s(K7);SFe=n(YIe,"STRONG",{});var Jwt=s(SFe);Kvr=r(Jwt,"layoutlm"),Jwt.forEach(t),Zvr=r(YIe," \u2014 "),mU=n(YIe,"A",{href:!0});var Ywt=s(mU);eFr=r(Ywt,"TFLayoutLMForMaskedLM"),Ywt.forEach(t),oFr=r(YIe," (LayoutLM model)"),YIe.forEach(t),rFr=i(le),Z7=n(le,"LI",{});var KIe=s(Z7);RFe=n(KIe,"STRONG",{});var Kwt=s(RFe);tFr=r(Kwt,"lxmert"),Kwt.forEach(t),aFr=r(KIe," \u2014 "),gU=n(KIe,"A",{href:!0});var Zwt=s(gU);nFr=r(Zwt,"TFLxmertForPreTraining"),Zwt.forEach(t),sFr=r(KIe," (LXMERT model)"),KIe.forEach(t),lFr=i(le),e8=n(le,"LI",{});var ZIe=s(e8);PFe=n(ZIe,"STRONG",{});var eAt=s(PFe);iFr=r(eAt,"mobilebert"),eAt.forEach(t),dFr=r(ZIe," \u2014 "),hU=n(ZIe,"A",{href:!0});var oAt=s(hU);cFr=r(oAt,"TFMobileBertForPreTraining"),oAt.forEach(t),fFr=r(ZIe," (MobileBERT model)"),ZIe.forEach(t),mFr=i(le),o8=n(le,"LI",{});var eNe=s(o8);BFe=n(eNe,"STRONG",{});var rAt=s(BFe);gFr=r(rAt,"mpnet"),rAt.forEach(t),hFr=r(eNe," \u2014 "),pU=n(eNe,"A",{href:!0});var tAt=s(pU);pFr=r(tAt,"TFMPNetForMaskedLM"),tAt.forEach(t),_Fr=r(eNe," (MPNet model)"),eNe.forEach(t),uFr=i(le),r8=n(le,"LI",{});var oNe=s(r8);IFe=n(oNe,"STRONG",{});var aAt=s(IFe);bFr=r(aAt,"openai-gpt"),aAt.forEach(t),vFr=r(oNe," \u2014 "),_U=n(oNe,"A",{href:!0});var nAt=s(_U);FFr=r(nAt,"TFOpenAIGPTLMHeadModel"),nAt.forEach(t),TFr=r(oNe," (OpenAI GPT model)"),oNe.forEach(t),MFr=i(le),t8=n(le,"LI",{});var rNe=s(t8);NFe=n(rNe,"STRONG",{});var sAt=s(NFe);EFr=r(sAt,"roberta"),sAt.forEach(t),CFr=r(rNe," \u2014 "),uU=n(rNe,"A",{href:!0});var lAt=s(uU);wFr=r(lAt,"TFRobertaForMaskedLM"),lAt.forEach(t),AFr=r(rNe," (RoBERTa model)"),rNe.forEach(t),LFr=i(le),a8=n(le,"LI",{});var tNe=s(a8);qFe=n(tNe,"STRONG",{});var iAt=s(qFe);yFr=r(iAt,"t5"),iAt.forEach(t),xFr=r(tNe," \u2014 "),bU=n(tNe,"A",{href:!0});var dAt=s(bU);$Fr=r(dAt,"TFT5ForConditionalGeneration"),dAt.forEach(t),kFr=r(tNe," (T5 model)"),tNe.forEach(t),SFr=i(le),n8=n(le,"LI",{});var aNe=s(n8);jFe=n(aNe,"STRONG",{});var cAt=s(jFe);RFr=r(cAt,"tapas"),cAt.forEach(t),PFr=r(aNe," \u2014 "),vU=n(aNe,"A",{href:!0});var fAt=s(vU);BFr=r(fAt,"TFTapasForMaskedLM"),fAt.forEach(t),IFr=r(aNe," (TAPAS model)"),aNe.forEach(t),NFr=i(le),s8=n(le,"LI",{});var nNe=s(s8);DFe=n(nNe,"STRONG",{});var mAt=s(DFe);qFr=r(mAt,"transfo-xl"),mAt.forEach(t),jFr=r(nNe," \u2014 "),FU=n(nNe,"A",{href:!0});var gAt=s(FU);DFr=r(gAt,"TFTransfoXLLMHeadModel"),gAt.forEach(t),GFr=r(nNe," (Transformer-XL model)"),nNe.forEach(t),OFr=i(le),l8=n(le,"LI",{});var sNe=s(l8);GFe=n(sNe,"STRONG",{});var hAt=s(GFe);VFr=r(hAt,"vit_mae"),hAt.forEach(t),XFr=r(sNe," \u2014 "),TU=n(sNe,"A",{href:!0});var pAt=s(TU);zFr=r(pAt,"TFViTMAEForPreTraining"),pAt.forEach(t),QFr=r(sNe," (ViTMAE model)"),sNe.forEach(t),WFr=i(le),i8=n(le,"LI",{});var lNe=s(i8);OFe=n(lNe,"STRONG",{});var _At=s(OFe);HFr=r(_At,"xlm"),_At.forEach(t),UFr=r(lNe," \u2014 "),MU=n(lNe,"A",{href:!0});var uAt=s(MU);JFr=r(uAt,"TFXLMWithLMHeadModel"),uAt.forEach(t),YFr=r(lNe," (XLM model)"),lNe.forEach(t),KFr=i(le),d8=n(le,"LI",{});var iNe=s(d8);VFe=n(iNe,"STRONG",{});var bAt=s(VFe);ZFr=r(bAt,"xlm-roberta"),bAt.forEach(t),e6r=r(iNe," \u2014 "),EU=n(iNe,"A",{href:!0});var vAt=s(EU);o6r=r(vAt,"TFXLMRobertaForMaskedLM"),vAt.forEach(t),r6r=r(iNe," (XLM-RoBERTa model)"),iNe.forEach(t),t6r=i(le),c8=n(le,"LI",{});var dNe=s(c8);XFe=n(dNe,"STRONG",{});var FAt=s(XFe);a6r=r(FAt,"xlnet"),FAt.forEach(t),n6r=r(dNe," \u2014 "),CU=n(dNe,"A",{href:!0});var TAt=s(CU);s6r=r(TAt,"TFXLNetLMHeadModel"),TAt.forEach(t),l6r=r(dNe," (XLNet model)"),dNe.forEach(t),le.forEach(t),i6r=i(Al),T(f8.$$.fragment,Al),Al.forEach(t),wl.forEach(t),JOe=i(f),sc=n(f,"H2",{class:!0});var aze=s(sc);m8=n(aze,"A",{id:!0,class:!0,href:!0});var MAt=s(m8);zFe=n(MAt,"SPAN",{});var EAt=s(zFe);T(w9.$$.fragment,EAt),EAt.forEach(t),MAt.forEach(t),d6r=i(aze),QFe=n(aze,"SPAN",{});var CAt=s(QFe);c6r=r(CAt,"TFAutoModelForCausalLM"),CAt.forEach(t),aze.forEach(t),YOe=i(f),rr=n(f,"DIV",{class:!0});var Ll=s(rr);T(A9.$$.fragment,Ll),f6r=i(Ll),lc=n(Ll,"P",{});var bre=s(lc);m6r=r(bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=n(bre,"A",{href:!0});var wAt=s(wU);g6r=r(wAt,"from_pretrained()"),wAt.forEach(t),h6r=r(bre," class method or the "),AU=n(bre,"A",{href:!0});var AAt=s(AU);p6r=r(AAt,"from_config()"),AAt.forEach(t),_6r=r(bre,` class
method.`),bre.forEach(t),u6r=i(Ll),L9=n(Ll,"P",{});var nze=s(L9);b6r=r(nze,"This class cannot be instantiated directly using "),WFe=n(nze,"CODE",{});var LAt=s(WFe);v6r=r(LAt,"__init__()"),LAt.forEach(t),F6r=r(nze," (throws an error)."),nze.forEach(t),T6r=i(Ll),St=n(Ll,"DIV",{class:!0});var $w=s(St);T(y9.$$.fragment,$w),M6r=i($w),HFe=n($w,"P",{});var yAt=s(HFe);E6r=r(yAt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yAt.forEach(t),C6r=i($w),ic=n($w,"P",{});var vre=s(ic);w6r=r(vre,`Note:
Loading a model from its configuration file does `),UFe=n(vre,"STRONG",{});var xAt=s(UFe);A6r=r(xAt,"not"),xAt.forEach(t),L6r=r(vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=n(vre,"A",{href:!0});var $At=s(LU);y6r=r($At,"from_pretrained()"),$At.forEach(t),x6r=r(vre," to load the model weights."),vre.forEach(t),$6r=i($w),T(g8.$$.fragment,$w),$w.forEach(t),k6r=i(Ll),$r=n(Ll,"DIV",{class:!0});var yl=s($r);T(x9.$$.fragment,yl),S6r=i(yl),JFe=n(yl,"P",{});var kAt=s(JFe);R6r=r(kAt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kAt.forEach(t),P6r=i(yl),sn=n(yl,"P",{});var kw=s(sn);B6r=r(kw,"The model class to instantiate is selected based on the "),YFe=n(kw,"CODE",{});var SAt=s(YFe);I6r=r(SAt,"model_type"),SAt.forEach(t),N6r=r(kw,` property of the config object (either
passed as an argument or loaded from `),KFe=n(kw,"CODE",{});var RAt=s(KFe);q6r=r(RAt,"pretrained_model_name_or_path"),RAt.forEach(t),j6r=r(kw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZFe=n(kw,"CODE",{});var PAt=s(ZFe);D6r=r(PAt,"pretrained_model_name_or_path"),PAt.forEach(t),G6r=r(kw,":"),kw.forEach(t),O6r=i(yl),Me=n(yl,"UL",{});var Ce=s(Me);h8=n(Ce,"LI",{});var cNe=s(h8);e6e=n(cNe,"STRONG",{});var BAt=s(e6e);V6r=r(BAt,"bert"),BAt.forEach(t),X6r=r(cNe," \u2014 "),yU=n(cNe,"A",{href:!0});var IAt=s(yU);z6r=r(IAt,"TFBertLMHeadModel"),IAt.forEach(t),Q6r=r(cNe," (BERT model)"),cNe.forEach(t),W6r=i(Ce),p8=n(Ce,"LI",{});var fNe=s(p8);o6e=n(fNe,"STRONG",{});var NAt=s(o6e);H6r=r(NAt,"camembert"),NAt.forEach(t),U6r=r(fNe," \u2014 "),xU=n(fNe,"A",{href:!0});var qAt=s(xU);J6r=r(qAt,"TFCamembertForCausalLM"),qAt.forEach(t),Y6r=r(fNe," (CamemBERT model)"),fNe.forEach(t),K6r=i(Ce),_8=n(Ce,"LI",{});var mNe=s(_8);r6e=n(mNe,"STRONG",{});var jAt=s(r6e);Z6r=r(jAt,"ctrl"),jAt.forEach(t),eTr=r(mNe," \u2014 "),$U=n(mNe,"A",{href:!0});var DAt=s($U);oTr=r(DAt,"TFCTRLLMHeadModel"),DAt.forEach(t),rTr=r(mNe," (CTRL model)"),mNe.forEach(t),tTr=i(Ce),u8=n(Ce,"LI",{});var gNe=s(u8);t6e=n(gNe,"STRONG",{});var GAt=s(t6e);aTr=r(GAt,"gpt2"),GAt.forEach(t),nTr=r(gNe," \u2014 "),kU=n(gNe,"A",{href:!0});var OAt=s(kU);sTr=r(OAt,"TFGPT2LMHeadModel"),OAt.forEach(t),lTr=r(gNe," (OpenAI GPT-2 model)"),gNe.forEach(t),iTr=i(Ce),b8=n(Ce,"LI",{});var hNe=s(b8);a6e=n(hNe,"STRONG",{});var VAt=s(a6e);dTr=r(VAt,"gptj"),VAt.forEach(t),cTr=r(hNe," \u2014 "),SU=n(hNe,"A",{href:!0});var XAt=s(SU);fTr=r(XAt,"TFGPTJForCausalLM"),XAt.forEach(t),mTr=r(hNe," (GPT-J model)"),hNe.forEach(t),gTr=i(Ce),v8=n(Ce,"LI",{});var pNe=s(v8);n6e=n(pNe,"STRONG",{});var zAt=s(n6e);hTr=r(zAt,"openai-gpt"),zAt.forEach(t),pTr=r(pNe," \u2014 "),RU=n(pNe,"A",{href:!0});var QAt=s(RU);_Tr=r(QAt,"TFOpenAIGPTLMHeadModel"),QAt.forEach(t),uTr=r(pNe," (OpenAI GPT model)"),pNe.forEach(t),bTr=i(Ce),F8=n(Ce,"LI",{});var _Ne=s(F8);s6e=n(_Ne,"STRONG",{});var WAt=s(s6e);vTr=r(WAt,"opt"),WAt.forEach(t),FTr=r(_Ne," \u2014 "),PU=n(_Ne,"A",{href:!0});var HAt=s(PU);TTr=r(HAt,"TFOPTForCausalLM"),HAt.forEach(t),MTr=r(_Ne," (OPT model)"),_Ne.forEach(t),ETr=i(Ce),T8=n(Ce,"LI",{});var uNe=s(T8);l6e=n(uNe,"STRONG",{});var UAt=s(l6e);CTr=r(UAt,"rembert"),UAt.forEach(t),wTr=r(uNe," \u2014 "),BU=n(uNe,"A",{href:!0});var JAt=s(BU);ATr=r(JAt,"TFRemBertForCausalLM"),JAt.forEach(t),LTr=r(uNe," (RemBERT model)"),uNe.forEach(t),yTr=i(Ce),M8=n(Ce,"LI",{});var bNe=s(M8);i6e=n(bNe,"STRONG",{});var YAt=s(i6e);xTr=r(YAt,"roberta"),YAt.forEach(t),$Tr=r(bNe," \u2014 "),IU=n(bNe,"A",{href:!0});var KAt=s(IU);kTr=r(KAt,"TFRobertaForCausalLM"),KAt.forEach(t),STr=r(bNe," (RoBERTa model)"),bNe.forEach(t),RTr=i(Ce),E8=n(Ce,"LI",{});var vNe=s(E8);d6e=n(vNe,"STRONG",{});var ZAt=s(d6e);PTr=r(ZAt,"roformer"),ZAt.forEach(t),BTr=r(vNe," \u2014 "),NU=n(vNe,"A",{href:!0});var eLt=s(NU);ITr=r(eLt,"TFRoFormerForCausalLM"),eLt.forEach(t),NTr=r(vNe," (RoFormer model)"),vNe.forEach(t),qTr=i(Ce),C8=n(Ce,"LI",{});var FNe=s(C8);c6e=n(FNe,"STRONG",{});var oLt=s(c6e);jTr=r(oLt,"transfo-xl"),oLt.forEach(t),DTr=r(FNe," \u2014 "),qU=n(FNe,"A",{href:!0});var rLt=s(qU);GTr=r(rLt,"TFTransfoXLLMHeadModel"),rLt.forEach(t),OTr=r(FNe," (Transformer-XL model)"),FNe.forEach(t),VTr=i(Ce),w8=n(Ce,"LI",{});var TNe=s(w8);f6e=n(TNe,"STRONG",{});var tLt=s(f6e);XTr=r(tLt,"xlm"),tLt.forEach(t),zTr=r(TNe," \u2014 "),jU=n(TNe,"A",{href:!0});var aLt=s(jU);QTr=r(aLt,"TFXLMWithLMHeadModel"),aLt.forEach(t),WTr=r(TNe," (XLM model)"),TNe.forEach(t),HTr=i(Ce),A8=n(Ce,"LI",{});var MNe=s(A8);m6e=n(MNe,"STRONG",{});var nLt=s(m6e);UTr=r(nLt,"xlnet"),nLt.forEach(t),JTr=r(MNe," \u2014 "),DU=n(MNe,"A",{href:!0});var sLt=s(DU);YTr=r(sLt,"TFXLNetLMHeadModel"),sLt.forEach(t),KTr=r(MNe," (XLNet model)"),MNe.forEach(t),Ce.forEach(t),ZTr=i(yl),T(L8.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),KOe=i(f),dc=n(f,"H2",{class:!0});var sze=s(dc);y8=n(sze,"A",{id:!0,class:!0,href:!0});var lLt=s(y8);g6e=n(lLt,"SPAN",{});var iLt=s(g6e);T($9.$$.fragment,iLt),iLt.forEach(t),lLt.forEach(t),e7r=i(sze),h6e=n(sze,"SPAN",{});var dLt=s(h6e);o7r=r(dLt,"TFAutoModelForImageClassification"),dLt.forEach(t),sze.forEach(t),ZOe=i(f),tr=n(f,"DIV",{class:!0});var xl=s(tr);T(k9.$$.fragment,xl),r7r=i(xl),cc=n(xl,"P",{});var Fre=s(cc);t7r=r(Fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=n(Fre,"A",{href:!0});var cLt=s(GU);a7r=r(cLt,"from_pretrained()"),cLt.forEach(t),n7r=r(Fre," class method or the "),OU=n(Fre,"A",{href:!0});var fLt=s(OU);s7r=r(fLt,"from_config()"),fLt.forEach(t),l7r=r(Fre,` class
method.`),Fre.forEach(t),i7r=i(xl),S9=n(xl,"P",{});var lze=s(S9);d7r=r(lze,"This class cannot be instantiated directly using "),p6e=n(lze,"CODE",{});var mLt=s(p6e);c7r=r(mLt,"__init__()"),mLt.forEach(t),f7r=r(lze," (throws an error)."),lze.forEach(t),m7r=i(xl),Rt=n(xl,"DIV",{class:!0});var Sw=s(Rt);T(R9.$$.fragment,Sw),g7r=i(Sw),_6e=n(Sw,"P",{});var gLt=s(_6e);h7r=r(gLt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),gLt.forEach(t),p7r=i(Sw),fc=n(Sw,"P",{});var Tre=s(fc);_7r=r(Tre,`Note:
Loading a model from its configuration file does `),u6e=n(Tre,"STRONG",{});var hLt=s(u6e);u7r=r(hLt,"not"),hLt.forEach(t),b7r=r(Tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=n(Tre,"A",{href:!0});var pLt=s(VU);v7r=r(pLt,"from_pretrained()"),pLt.forEach(t),F7r=r(Tre," to load the model weights."),Tre.forEach(t),T7r=i(Sw),T(x8.$$.fragment,Sw),Sw.forEach(t),M7r=i(xl),kr=n(xl,"DIV",{class:!0});var $l=s(kr);T(P9.$$.fragment,$l),E7r=i($l),b6e=n($l,"P",{});var _Lt=s(b6e);C7r=r(_Lt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),_Lt.forEach(t),w7r=i($l),ln=n($l,"P",{});var Rw=s(ln);A7r=r(Rw,"The model class to instantiate is selected based on the "),v6e=n(Rw,"CODE",{});var uLt=s(v6e);L7r=r(uLt,"model_type"),uLt.forEach(t),y7r=r(Rw,` property of the config object (either
passed as an argument or loaded from `),F6e=n(Rw,"CODE",{});var bLt=s(F6e);x7r=r(bLt,"pretrained_model_name_or_path"),bLt.forEach(t),$7r=r(Rw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=n(Rw,"CODE",{});var vLt=s(T6e);k7r=r(vLt,"pretrained_model_name_or_path"),vLt.forEach(t),S7r=r(Rw,":"),Rw.forEach(t),R7r=i($l),dn=n($l,"UL",{});var Pw=s(dn);$8=n(Pw,"LI",{});var ENe=s($8);M6e=n(ENe,"STRONG",{});var FLt=s(M6e);P7r=r(FLt,"convnext"),FLt.forEach(t),B7r=r(ENe," \u2014 "),XU=n(ENe,"A",{href:!0});var TLt=s(XU);I7r=r(TLt,"TFConvNextForImageClassification"),TLt.forEach(t),N7r=r(ENe," (ConvNeXT model)"),ENe.forEach(t),q7r=i(Pw),k8=n(Pw,"LI",{});var CNe=s(k8);E6e=n(CNe,"STRONG",{});var MLt=s(E6e);j7r=r(MLt,"data2vec-vision"),MLt.forEach(t),D7r=r(CNe," \u2014 "),zU=n(CNe,"A",{href:!0});var ELt=s(zU);G7r=r(ELt,"TFData2VecVisionForImageClassification"),ELt.forEach(t),O7r=r(CNe," (Data2VecVision model)"),CNe.forEach(t),V7r=i(Pw),S8=n(Pw,"LI",{});var wNe=s(S8);C6e=n(wNe,"STRONG",{});var CLt=s(C6e);X7r=r(CLt,"swin"),CLt.forEach(t),z7r=r(wNe," \u2014 "),QU=n(wNe,"A",{href:!0});var wLt=s(QU);Q7r=r(wLt,"TFSwinForImageClassification"),wLt.forEach(t),W7r=r(wNe," (Swin Transformer model)"),wNe.forEach(t),H7r=i(Pw),R8=n(Pw,"LI",{});var ANe=s(R8);w6e=n(ANe,"STRONG",{});var ALt=s(w6e);U7r=r(ALt,"vit"),ALt.forEach(t),J7r=r(ANe," \u2014 "),WU=n(ANe,"A",{href:!0});var LLt=s(WU);Y7r=r(LLt,"TFViTForImageClassification"),LLt.forEach(t),K7r=r(ANe," (ViT model)"),ANe.forEach(t),Pw.forEach(t),Z7r=i($l),T(P8.$$.fragment,$l),$l.forEach(t),xl.forEach(t),eVe=i(f),mc=n(f,"H2",{class:!0});var ize=s(mc);B8=n(ize,"A",{id:!0,class:!0,href:!0});var yLt=s(B8);A6e=n(yLt,"SPAN",{});var xLt=s(A6e);T(B9.$$.fragment,xLt),xLt.forEach(t),yLt.forEach(t),e8r=i(ize),L6e=n(ize,"SPAN",{});var $Lt=s(L6e);o8r=r($Lt,"TFAutoModelForMaskedLM"),$Lt.forEach(t),ize.forEach(t),oVe=i(f),ar=n(f,"DIV",{class:!0});var kl=s(ar);T(I9.$$.fragment,kl),r8r=i(kl),gc=n(kl,"P",{});var Mre=s(gc);t8r=r(Mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=n(Mre,"A",{href:!0});var kLt=s(HU);a8r=r(kLt,"from_pretrained()"),kLt.forEach(t),n8r=r(Mre," class method or the "),UU=n(Mre,"A",{href:!0});var SLt=s(UU);s8r=r(SLt,"from_config()"),SLt.forEach(t),l8r=r(Mre,` class
method.`),Mre.forEach(t),i8r=i(kl),N9=n(kl,"P",{});var dze=s(N9);d8r=r(dze,"This class cannot be instantiated directly using "),y6e=n(dze,"CODE",{});var RLt=s(y6e);c8r=r(RLt,"__init__()"),RLt.forEach(t),f8r=r(dze," (throws an error)."),dze.forEach(t),m8r=i(kl),Pt=n(kl,"DIV",{class:!0});var Bw=s(Pt);T(q9.$$.fragment,Bw),g8r=i(Bw),x6e=n(Bw,"P",{});var PLt=s(x6e);h8r=r(PLt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),PLt.forEach(t),p8r=i(Bw),hc=n(Bw,"P",{});var Ere=s(hc);_8r=r(Ere,`Note:
Loading a model from its configuration file does `),$6e=n(Ere,"STRONG",{});var BLt=s($6e);u8r=r(BLt,"not"),BLt.forEach(t),b8r=r(Ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=n(Ere,"A",{href:!0});var ILt=s(JU);v8r=r(ILt,"from_pretrained()"),ILt.forEach(t),F8r=r(Ere," to load the model weights."),Ere.forEach(t),T8r=i(Bw),T(I8.$$.fragment,Bw),Bw.forEach(t),M8r=i(kl),Sr=n(kl,"DIV",{class:!0});var Sl=s(Sr);T(j9.$$.fragment,Sl),E8r=i(Sl),k6e=n(Sl,"P",{});var NLt=s(k6e);C8r=r(NLt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),NLt.forEach(t),w8r=i(Sl),cn=n(Sl,"P",{});var Iw=s(cn);A8r=r(Iw,"The model class to instantiate is selected based on the "),S6e=n(Iw,"CODE",{});var qLt=s(S6e);L8r=r(qLt,"model_type"),qLt.forEach(t),y8r=r(Iw,` property of the config object (either
passed as an argument or loaded from `),R6e=n(Iw,"CODE",{});var jLt=s(R6e);x8r=r(jLt,"pretrained_model_name_or_path"),jLt.forEach(t),$8r=r(Iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P6e=n(Iw,"CODE",{});var DLt=s(P6e);k8r=r(DLt,"pretrained_model_name_or_path"),DLt.forEach(t),S8r=r(Iw,":"),Iw.forEach(t),R8r=i(Sl),ie=n(Sl,"UL",{});var fe=s(ie);N8=n(fe,"LI",{});var LNe=s(N8);B6e=n(LNe,"STRONG",{});var GLt=s(B6e);P8r=r(GLt,"albert"),GLt.forEach(t),B8r=r(LNe," \u2014 "),YU=n(LNe,"A",{href:!0});var OLt=s(YU);I8r=r(OLt,"TFAlbertForMaskedLM"),OLt.forEach(t),N8r=r(LNe," (ALBERT model)"),LNe.forEach(t),q8r=i(fe),q8=n(fe,"LI",{});var yNe=s(q8);I6e=n(yNe,"STRONG",{});var VLt=s(I6e);j8r=r(VLt,"bert"),VLt.forEach(t),D8r=r(yNe," \u2014 "),KU=n(yNe,"A",{href:!0});var XLt=s(KU);G8r=r(XLt,"TFBertForMaskedLM"),XLt.forEach(t),O8r=r(yNe," (BERT model)"),yNe.forEach(t),V8r=i(fe),j8=n(fe,"LI",{});var xNe=s(j8);N6e=n(xNe,"STRONG",{});var zLt=s(N6e);X8r=r(zLt,"camembert"),zLt.forEach(t),z8r=r(xNe," \u2014 "),ZU=n(xNe,"A",{href:!0});var QLt=s(ZU);Q8r=r(QLt,"TFCamembertForMaskedLM"),QLt.forEach(t),W8r=r(xNe," (CamemBERT model)"),xNe.forEach(t),H8r=i(fe),D8=n(fe,"LI",{});var $Ne=s(D8);q6e=n($Ne,"STRONG",{});var WLt=s(q6e);U8r=r(WLt,"convbert"),WLt.forEach(t),J8r=r($Ne," \u2014 "),eJ=n($Ne,"A",{href:!0});var HLt=s(eJ);Y8r=r(HLt,"TFConvBertForMaskedLM"),HLt.forEach(t),K8r=r($Ne," (ConvBERT model)"),$Ne.forEach(t),Z8r=i(fe),G8=n(fe,"LI",{});var kNe=s(G8);j6e=n(kNe,"STRONG",{});var ULt=s(j6e);eMr=r(ULt,"deberta"),ULt.forEach(t),oMr=r(kNe," \u2014 "),oJ=n(kNe,"A",{href:!0});var JLt=s(oJ);rMr=r(JLt,"TFDebertaForMaskedLM"),JLt.forEach(t),tMr=r(kNe," (DeBERTa model)"),kNe.forEach(t),aMr=i(fe),O8=n(fe,"LI",{});var SNe=s(O8);D6e=n(SNe,"STRONG",{});var YLt=s(D6e);nMr=r(YLt,"deberta-v2"),YLt.forEach(t),sMr=r(SNe," \u2014 "),rJ=n(SNe,"A",{href:!0});var KLt=s(rJ);lMr=r(KLt,"TFDebertaV2ForMaskedLM"),KLt.forEach(t),iMr=r(SNe," (DeBERTa-v2 model)"),SNe.forEach(t),dMr=i(fe),V8=n(fe,"LI",{});var RNe=s(V8);G6e=n(RNe,"STRONG",{});var ZLt=s(G6e);cMr=r(ZLt,"distilbert"),ZLt.forEach(t),fMr=r(RNe," \u2014 "),tJ=n(RNe,"A",{href:!0});var eyt=s(tJ);mMr=r(eyt,"TFDistilBertForMaskedLM"),eyt.forEach(t),gMr=r(RNe," (DistilBERT model)"),RNe.forEach(t),hMr=i(fe),X8=n(fe,"LI",{});var PNe=s(X8);O6e=n(PNe,"STRONG",{});var oyt=s(O6e);pMr=r(oyt,"electra"),oyt.forEach(t),_Mr=r(PNe," \u2014 "),aJ=n(PNe,"A",{href:!0});var ryt=s(aJ);uMr=r(ryt,"TFElectraForMaskedLM"),ryt.forEach(t),bMr=r(PNe," (ELECTRA model)"),PNe.forEach(t),vMr=i(fe),z8=n(fe,"LI",{});var BNe=s(z8);V6e=n(BNe,"STRONG",{});var tyt=s(V6e);FMr=r(tyt,"flaubert"),tyt.forEach(t),TMr=r(BNe," \u2014 "),nJ=n(BNe,"A",{href:!0});var ayt=s(nJ);MMr=r(ayt,"TFFlaubertWithLMHeadModel"),ayt.forEach(t),EMr=r(BNe," (FlauBERT model)"),BNe.forEach(t),CMr=i(fe),Q8=n(fe,"LI",{});var INe=s(Q8);X6e=n(INe,"STRONG",{});var nyt=s(X6e);wMr=r(nyt,"funnel"),nyt.forEach(t),AMr=r(INe," \u2014 "),sJ=n(INe,"A",{href:!0});var syt=s(sJ);LMr=r(syt,"TFFunnelForMaskedLM"),syt.forEach(t),yMr=r(INe," (Funnel Transformer model)"),INe.forEach(t),xMr=i(fe),W8=n(fe,"LI",{});var NNe=s(W8);z6e=n(NNe,"STRONG",{});var lyt=s(z6e);$Mr=r(lyt,"layoutlm"),lyt.forEach(t),kMr=r(NNe," \u2014 "),lJ=n(NNe,"A",{href:!0});var iyt=s(lJ);SMr=r(iyt,"TFLayoutLMForMaskedLM"),iyt.forEach(t),RMr=r(NNe," (LayoutLM model)"),NNe.forEach(t),PMr=i(fe),H8=n(fe,"LI",{});var qNe=s(H8);Q6e=n(qNe,"STRONG",{});var dyt=s(Q6e);BMr=r(dyt,"longformer"),dyt.forEach(t),IMr=r(qNe," \u2014 "),iJ=n(qNe,"A",{href:!0});var cyt=s(iJ);NMr=r(cyt,"TFLongformerForMaskedLM"),cyt.forEach(t),qMr=r(qNe," (Longformer model)"),qNe.forEach(t),jMr=i(fe),U8=n(fe,"LI",{});var jNe=s(U8);W6e=n(jNe,"STRONG",{});var fyt=s(W6e);DMr=r(fyt,"mobilebert"),fyt.forEach(t),GMr=r(jNe," \u2014 "),dJ=n(jNe,"A",{href:!0});var myt=s(dJ);OMr=r(myt,"TFMobileBertForMaskedLM"),myt.forEach(t),VMr=r(jNe," (MobileBERT model)"),jNe.forEach(t),XMr=i(fe),J8=n(fe,"LI",{});var DNe=s(J8);H6e=n(DNe,"STRONG",{});var gyt=s(H6e);zMr=r(gyt,"mpnet"),gyt.forEach(t),QMr=r(DNe," \u2014 "),cJ=n(DNe,"A",{href:!0});var hyt=s(cJ);WMr=r(hyt,"TFMPNetForMaskedLM"),hyt.forEach(t),HMr=r(DNe," (MPNet model)"),DNe.forEach(t),UMr=i(fe),Y8=n(fe,"LI",{});var GNe=s(Y8);U6e=n(GNe,"STRONG",{});var pyt=s(U6e);JMr=r(pyt,"rembert"),pyt.forEach(t),YMr=r(GNe," \u2014 "),fJ=n(GNe,"A",{href:!0});var _yt=s(fJ);KMr=r(_yt,"TFRemBertForMaskedLM"),_yt.forEach(t),ZMr=r(GNe," (RemBERT model)"),GNe.forEach(t),eEr=i(fe),K8=n(fe,"LI",{});var ONe=s(K8);J6e=n(ONe,"STRONG",{});var uyt=s(J6e);oEr=r(uyt,"roberta"),uyt.forEach(t),rEr=r(ONe," \u2014 "),mJ=n(ONe,"A",{href:!0});var byt=s(mJ);tEr=r(byt,"TFRobertaForMaskedLM"),byt.forEach(t),aEr=r(ONe," (RoBERTa model)"),ONe.forEach(t),nEr=i(fe),Z8=n(fe,"LI",{});var VNe=s(Z8);Y6e=n(VNe,"STRONG",{});var vyt=s(Y6e);sEr=r(vyt,"roformer"),vyt.forEach(t),lEr=r(VNe," \u2014 "),gJ=n(VNe,"A",{href:!0});var Fyt=s(gJ);iEr=r(Fyt,"TFRoFormerForMaskedLM"),Fyt.forEach(t),dEr=r(VNe," (RoFormer model)"),VNe.forEach(t),cEr=i(fe),eM=n(fe,"LI",{});var XNe=s(eM);K6e=n(XNe,"STRONG",{});var Tyt=s(K6e);fEr=r(Tyt,"tapas"),Tyt.forEach(t),mEr=r(XNe," \u2014 "),hJ=n(XNe,"A",{href:!0});var Myt=s(hJ);gEr=r(Myt,"TFTapasForMaskedLM"),Myt.forEach(t),hEr=r(XNe," (TAPAS model)"),XNe.forEach(t),pEr=i(fe),oM=n(fe,"LI",{});var zNe=s(oM);Z6e=n(zNe,"STRONG",{});var Eyt=s(Z6e);_Er=r(Eyt,"xlm"),Eyt.forEach(t),uEr=r(zNe," \u2014 "),pJ=n(zNe,"A",{href:!0});var Cyt=s(pJ);bEr=r(Cyt,"TFXLMWithLMHeadModel"),Cyt.forEach(t),vEr=r(zNe," (XLM model)"),zNe.forEach(t),FEr=i(fe),rM=n(fe,"LI",{});var QNe=s(rM);eTe=n(QNe,"STRONG",{});var wyt=s(eTe);TEr=r(wyt,"xlm-roberta"),wyt.forEach(t),MEr=r(QNe," \u2014 "),_J=n(QNe,"A",{href:!0});var Ayt=s(_J);EEr=r(Ayt,"TFXLMRobertaForMaskedLM"),Ayt.forEach(t),CEr=r(QNe," (XLM-RoBERTa model)"),QNe.forEach(t),fe.forEach(t),wEr=i(Sl),T(tM.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),rVe=i(f),pc=n(f,"H2",{class:!0});var cze=s(pc);aM=n(cze,"A",{id:!0,class:!0,href:!0});var Lyt=s(aM);oTe=n(Lyt,"SPAN",{});var yyt=s(oTe);T(D9.$$.fragment,yyt),yyt.forEach(t),Lyt.forEach(t),AEr=i(cze),rTe=n(cze,"SPAN",{});var xyt=s(rTe);LEr=r(xyt,"TFAutoModelForSeq2SeqLM"),xyt.forEach(t),cze.forEach(t),tVe=i(f),nr=n(f,"DIV",{class:!0});var Rl=s(nr);T(G9.$$.fragment,Rl),yEr=i(Rl),_c=n(Rl,"P",{});var Cre=s(_c);xEr=r(Cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uJ=n(Cre,"A",{href:!0});var $yt=s(uJ);$Er=r($yt,"from_pretrained()"),$yt.forEach(t),kEr=r(Cre," class method or the "),bJ=n(Cre,"A",{href:!0});var kyt=s(bJ);SEr=r(kyt,"from_config()"),kyt.forEach(t),REr=r(Cre,` class
method.`),Cre.forEach(t),PEr=i(Rl),O9=n(Rl,"P",{});var fze=s(O9);BEr=r(fze,"This class cannot be instantiated directly using "),tTe=n(fze,"CODE",{});var Syt=s(tTe);IEr=r(Syt,"__init__()"),Syt.forEach(t),NEr=r(fze," (throws an error)."),fze.forEach(t),qEr=i(Rl),Bt=n(Rl,"DIV",{class:!0});var Nw=s(Bt);T(V9.$$.fragment,Nw),jEr=i(Nw),aTe=n(Nw,"P",{});var Ryt=s(aTe);DEr=r(Ryt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Ryt.forEach(t),GEr=i(Nw),uc=n(Nw,"P",{});var wre=s(uc);OEr=r(wre,`Note:
Loading a model from its configuration file does `),nTe=n(wre,"STRONG",{});var Pyt=s(nTe);VEr=r(Pyt,"not"),Pyt.forEach(t),XEr=r(wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=n(wre,"A",{href:!0});var Byt=s(vJ);zEr=r(Byt,"from_pretrained()"),Byt.forEach(t),QEr=r(wre," to load the model weights."),wre.forEach(t),WEr=i(Nw),T(nM.$$.fragment,Nw),Nw.forEach(t),HEr=i(Rl),Rr=n(Rl,"DIV",{class:!0});var Pl=s(Rr);T(X9.$$.fragment,Pl),UEr=i(Pl),sTe=n(Pl,"P",{});var Iyt=s(sTe);JEr=r(Iyt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Iyt.forEach(t),YEr=i(Pl),fn=n(Pl,"P",{});var qw=s(fn);KEr=r(qw,"The model class to instantiate is selected based on the "),lTe=n(qw,"CODE",{});var Nyt=s(lTe);ZEr=r(Nyt,"model_type"),Nyt.forEach(t),eCr=r(qw,` property of the config object (either
passed as an argument or loaded from `),iTe=n(qw,"CODE",{});var qyt=s(iTe);oCr=r(qyt,"pretrained_model_name_or_path"),qyt.forEach(t),rCr=r(qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dTe=n(qw,"CODE",{});var jyt=s(dTe);tCr=r(jyt,"pretrained_model_name_or_path"),jyt.forEach(t),aCr=r(qw,":"),qw.forEach(t),nCr=i(Pl),ye=n(Pl,"UL",{});var Ie=s(ye);sM=n(Ie,"LI",{});var WNe=s(sM);cTe=n(WNe,"STRONG",{});var Dyt=s(cTe);sCr=r(Dyt,"bart"),Dyt.forEach(t),lCr=r(WNe," \u2014 "),FJ=n(WNe,"A",{href:!0});var Gyt=s(FJ);iCr=r(Gyt,"TFBartForConditionalGeneration"),Gyt.forEach(t),dCr=r(WNe," (BART model)"),WNe.forEach(t),cCr=i(Ie),lM=n(Ie,"LI",{});var HNe=s(lM);fTe=n(HNe,"STRONG",{});var Oyt=s(fTe);fCr=r(Oyt,"blenderbot"),Oyt.forEach(t),mCr=r(HNe," \u2014 "),TJ=n(HNe,"A",{href:!0});var Vyt=s(TJ);gCr=r(Vyt,"TFBlenderbotForConditionalGeneration"),Vyt.forEach(t),hCr=r(HNe," (Blenderbot model)"),HNe.forEach(t),pCr=i(Ie),iM=n(Ie,"LI",{});var UNe=s(iM);mTe=n(UNe,"STRONG",{});var Xyt=s(mTe);_Cr=r(Xyt,"blenderbot-small"),Xyt.forEach(t),uCr=r(UNe," \u2014 "),MJ=n(UNe,"A",{href:!0});var zyt=s(MJ);bCr=r(zyt,"TFBlenderbotSmallForConditionalGeneration"),zyt.forEach(t),vCr=r(UNe," (BlenderbotSmall model)"),UNe.forEach(t),FCr=i(Ie),dM=n(Ie,"LI",{});var JNe=s(dM);gTe=n(JNe,"STRONG",{});var Qyt=s(gTe);TCr=r(Qyt,"encoder-decoder"),Qyt.forEach(t),MCr=r(JNe," \u2014 "),EJ=n(JNe,"A",{href:!0});var Wyt=s(EJ);ECr=r(Wyt,"TFEncoderDecoderModel"),Wyt.forEach(t),CCr=r(JNe," (Encoder decoder model)"),JNe.forEach(t),wCr=i(Ie),cM=n(Ie,"LI",{});var YNe=s(cM);hTe=n(YNe,"STRONG",{});var Hyt=s(hTe);ACr=r(Hyt,"led"),Hyt.forEach(t),LCr=r(YNe," \u2014 "),CJ=n(YNe,"A",{href:!0});var Uyt=s(CJ);yCr=r(Uyt,"TFLEDForConditionalGeneration"),Uyt.forEach(t),xCr=r(YNe," (LED model)"),YNe.forEach(t),$Cr=i(Ie),fM=n(Ie,"LI",{});var KNe=s(fM);pTe=n(KNe,"STRONG",{});var Jyt=s(pTe);kCr=r(Jyt,"marian"),Jyt.forEach(t),SCr=r(KNe," \u2014 "),wJ=n(KNe,"A",{href:!0});var Yyt=s(wJ);RCr=r(Yyt,"TFMarianMTModel"),Yyt.forEach(t),PCr=r(KNe," (Marian model)"),KNe.forEach(t),BCr=i(Ie),mM=n(Ie,"LI",{});var ZNe=s(mM);_Te=n(ZNe,"STRONG",{});var Kyt=s(_Te);ICr=r(Kyt,"mbart"),Kyt.forEach(t),NCr=r(ZNe," \u2014 "),AJ=n(ZNe,"A",{href:!0});var Zyt=s(AJ);qCr=r(Zyt,"TFMBartForConditionalGeneration"),Zyt.forEach(t),jCr=r(ZNe," (mBART model)"),ZNe.forEach(t),DCr=i(Ie),gM=n(Ie,"LI",{});var eqe=s(gM);uTe=n(eqe,"STRONG",{});var e9t=s(uTe);GCr=r(e9t,"mt5"),e9t.forEach(t),OCr=r(eqe," \u2014 "),LJ=n(eqe,"A",{href:!0});var o9t=s(LJ);VCr=r(o9t,"TFMT5ForConditionalGeneration"),o9t.forEach(t),XCr=r(eqe," (MT5 model)"),eqe.forEach(t),zCr=i(Ie),hM=n(Ie,"LI",{});var oqe=s(hM);bTe=n(oqe,"STRONG",{});var r9t=s(bTe);QCr=r(r9t,"pegasus"),r9t.forEach(t),WCr=r(oqe," \u2014 "),yJ=n(oqe,"A",{href:!0});var t9t=s(yJ);HCr=r(t9t,"TFPegasusForConditionalGeneration"),t9t.forEach(t),UCr=r(oqe," (Pegasus model)"),oqe.forEach(t),JCr=i(Ie),pM=n(Ie,"LI",{});var rqe=s(pM);vTe=n(rqe,"STRONG",{});var a9t=s(vTe);YCr=r(a9t,"t5"),a9t.forEach(t),KCr=r(rqe," \u2014 "),xJ=n(rqe,"A",{href:!0});var n9t=s(xJ);ZCr=r(n9t,"TFT5ForConditionalGeneration"),n9t.forEach(t),e5r=r(rqe," (T5 model)"),rqe.forEach(t),Ie.forEach(t),o5r=i(Pl),T(_M.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),aVe=i(f),bc=n(f,"H2",{class:!0});var mze=s(bc);uM=n(mze,"A",{id:!0,class:!0,href:!0});var s9t=s(uM);FTe=n(s9t,"SPAN",{});var l9t=s(FTe);T(z9.$$.fragment,l9t),l9t.forEach(t),s9t.forEach(t),r5r=i(mze),TTe=n(mze,"SPAN",{});var i9t=s(TTe);t5r=r(i9t,"TFAutoModelForSequenceClassification"),i9t.forEach(t),mze.forEach(t),nVe=i(f),sr=n(f,"DIV",{class:!0});var Bl=s(sr);T(Q9.$$.fragment,Bl),a5r=i(Bl),vc=n(Bl,"P",{});var Are=s(vc);n5r=r(Are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=n(Are,"A",{href:!0});var d9t=s($J);s5r=r(d9t,"from_pretrained()"),d9t.forEach(t),l5r=r(Are," class method or the "),kJ=n(Are,"A",{href:!0});var c9t=s(kJ);i5r=r(c9t,"from_config()"),c9t.forEach(t),d5r=r(Are,` class
method.`),Are.forEach(t),c5r=i(Bl),W9=n(Bl,"P",{});var gze=s(W9);f5r=r(gze,"This class cannot be instantiated directly using "),MTe=n(gze,"CODE",{});var f9t=s(MTe);m5r=r(f9t,"__init__()"),f9t.forEach(t),g5r=r(gze," (throws an error)."),gze.forEach(t),h5r=i(Bl),It=n(Bl,"DIV",{class:!0});var jw=s(It);T(H9.$$.fragment,jw),p5r=i(jw),ETe=n(jw,"P",{});var m9t=s(ETe);_5r=r(m9t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),m9t.forEach(t),u5r=i(jw),Fc=n(jw,"P",{});var Lre=s(Fc);b5r=r(Lre,`Note:
Loading a model from its configuration file does `),CTe=n(Lre,"STRONG",{});var g9t=s(CTe);v5r=r(g9t,"not"),g9t.forEach(t),F5r=r(Lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=n(Lre,"A",{href:!0});var h9t=s(SJ);T5r=r(h9t,"from_pretrained()"),h9t.forEach(t),M5r=r(Lre," to load the model weights."),Lre.forEach(t),E5r=i(jw),T(bM.$$.fragment,jw),jw.forEach(t),C5r=i(Bl),Pr=n(Bl,"DIV",{class:!0});var Il=s(Pr);T(U9.$$.fragment,Il),w5r=i(Il),wTe=n(Il,"P",{});var p9t=s(wTe);A5r=r(p9t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),p9t.forEach(t),L5r=i(Il),mn=n(Il,"P",{});var Dw=s(mn);y5r=r(Dw,"The model class to instantiate is selected based on the "),ATe=n(Dw,"CODE",{});var _9t=s(ATe);x5r=r(_9t,"model_type"),_9t.forEach(t),$5r=r(Dw,` property of the config object (either
passed as an argument or loaded from `),LTe=n(Dw,"CODE",{});var u9t=s(LTe);k5r=r(u9t,"pretrained_model_name_or_path"),u9t.forEach(t),S5r=r(Dw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yTe=n(Dw,"CODE",{});var b9t=s(yTe);R5r=r(b9t,"pretrained_model_name_or_path"),b9t.forEach(t),P5r=r(Dw,":"),Dw.forEach(t),B5r=i(Il),te=n(Il,"UL",{});var ne=s(te);vM=n(ne,"LI",{});var tqe=s(vM);xTe=n(tqe,"STRONG",{});var v9t=s(xTe);I5r=r(v9t,"albert"),v9t.forEach(t),N5r=r(tqe," \u2014 "),RJ=n(tqe,"A",{href:!0});var F9t=s(RJ);q5r=r(F9t,"TFAlbertForSequenceClassification"),F9t.forEach(t),j5r=r(tqe," (ALBERT model)"),tqe.forEach(t),D5r=i(ne),FM=n(ne,"LI",{});var aqe=s(FM);$Te=n(aqe,"STRONG",{});var T9t=s($Te);G5r=r(T9t,"bert"),T9t.forEach(t),O5r=r(aqe," \u2014 "),PJ=n(aqe,"A",{href:!0});var M9t=s(PJ);V5r=r(M9t,"TFBertForSequenceClassification"),M9t.forEach(t),X5r=r(aqe," (BERT model)"),aqe.forEach(t),z5r=i(ne),TM=n(ne,"LI",{});var nqe=s(TM);kTe=n(nqe,"STRONG",{});var E9t=s(kTe);Q5r=r(E9t,"camembert"),E9t.forEach(t),W5r=r(nqe," \u2014 "),BJ=n(nqe,"A",{href:!0});var C9t=s(BJ);H5r=r(C9t,"TFCamembertForSequenceClassification"),C9t.forEach(t),U5r=r(nqe," (CamemBERT model)"),nqe.forEach(t),J5r=i(ne),MM=n(ne,"LI",{});var sqe=s(MM);STe=n(sqe,"STRONG",{});var w9t=s(STe);Y5r=r(w9t,"convbert"),w9t.forEach(t),K5r=r(sqe," \u2014 "),IJ=n(sqe,"A",{href:!0});var A9t=s(IJ);Z5r=r(A9t,"TFConvBertForSequenceClassification"),A9t.forEach(t),e3r=r(sqe," (ConvBERT model)"),sqe.forEach(t),o3r=i(ne),EM=n(ne,"LI",{});var lqe=s(EM);RTe=n(lqe,"STRONG",{});var L9t=s(RTe);r3r=r(L9t,"ctrl"),L9t.forEach(t),t3r=r(lqe," \u2014 "),NJ=n(lqe,"A",{href:!0});var y9t=s(NJ);a3r=r(y9t,"TFCTRLForSequenceClassification"),y9t.forEach(t),n3r=r(lqe," (CTRL model)"),lqe.forEach(t),s3r=i(ne),CM=n(ne,"LI",{});var iqe=s(CM);PTe=n(iqe,"STRONG",{});var x9t=s(PTe);l3r=r(x9t,"deberta"),x9t.forEach(t),i3r=r(iqe," \u2014 "),qJ=n(iqe,"A",{href:!0});var $9t=s(qJ);d3r=r($9t,"TFDebertaForSequenceClassification"),$9t.forEach(t),c3r=r(iqe," (DeBERTa model)"),iqe.forEach(t),f3r=i(ne),wM=n(ne,"LI",{});var dqe=s(wM);BTe=n(dqe,"STRONG",{});var k9t=s(BTe);m3r=r(k9t,"deberta-v2"),k9t.forEach(t),g3r=r(dqe," \u2014 "),jJ=n(dqe,"A",{href:!0});var S9t=s(jJ);h3r=r(S9t,"TFDebertaV2ForSequenceClassification"),S9t.forEach(t),p3r=r(dqe," (DeBERTa-v2 model)"),dqe.forEach(t),_3r=i(ne),AM=n(ne,"LI",{});var cqe=s(AM);ITe=n(cqe,"STRONG",{});var R9t=s(ITe);u3r=r(R9t,"distilbert"),R9t.forEach(t),b3r=r(cqe," \u2014 "),DJ=n(cqe,"A",{href:!0});var P9t=s(DJ);v3r=r(P9t,"TFDistilBertForSequenceClassification"),P9t.forEach(t),F3r=r(cqe," (DistilBERT model)"),cqe.forEach(t),T3r=i(ne),LM=n(ne,"LI",{});var fqe=s(LM);NTe=n(fqe,"STRONG",{});var B9t=s(NTe);M3r=r(B9t,"electra"),B9t.forEach(t),E3r=r(fqe," \u2014 "),GJ=n(fqe,"A",{href:!0});var I9t=s(GJ);C3r=r(I9t,"TFElectraForSequenceClassification"),I9t.forEach(t),w3r=r(fqe," (ELECTRA model)"),fqe.forEach(t),A3r=i(ne),yM=n(ne,"LI",{});var mqe=s(yM);qTe=n(mqe,"STRONG",{});var N9t=s(qTe);L3r=r(N9t,"flaubert"),N9t.forEach(t),y3r=r(mqe," \u2014 "),OJ=n(mqe,"A",{href:!0});var q9t=s(OJ);x3r=r(q9t,"TFFlaubertForSequenceClassification"),q9t.forEach(t),$3r=r(mqe," (FlauBERT model)"),mqe.forEach(t),k3r=i(ne),xM=n(ne,"LI",{});var gqe=s(xM);jTe=n(gqe,"STRONG",{});var j9t=s(jTe);S3r=r(j9t,"funnel"),j9t.forEach(t),R3r=r(gqe," \u2014 "),VJ=n(gqe,"A",{href:!0});var D9t=s(VJ);P3r=r(D9t,"TFFunnelForSequenceClassification"),D9t.forEach(t),B3r=r(gqe," (Funnel Transformer model)"),gqe.forEach(t),I3r=i(ne),$M=n(ne,"LI",{});var hqe=s($M);DTe=n(hqe,"STRONG",{});var G9t=s(DTe);N3r=r(G9t,"gpt2"),G9t.forEach(t),q3r=r(hqe," \u2014 "),XJ=n(hqe,"A",{href:!0});var O9t=s(XJ);j3r=r(O9t,"TFGPT2ForSequenceClassification"),O9t.forEach(t),D3r=r(hqe," (OpenAI GPT-2 model)"),hqe.forEach(t),G3r=i(ne),kM=n(ne,"LI",{});var pqe=s(kM);GTe=n(pqe,"STRONG",{});var V9t=s(GTe);O3r=r(V9t,"gptj"),V9t.forEach(t),V3r=r(pqe," \u2014 "),zJ=n(pqe,"A",{href:!0});var X9t=s(zJ);X3r=r(X9t,"TFGPTJForSequenceClassification"),X9t.forEach(t),z3r=r(pqe," (GPT-J model)"),pqe.forEach(t),Q3r=i(ne),SM=n(ne,"LI",{});var _qe=s(SM);OTe=n(_qe,"STRONG",{});var z9t=s(OTe);W3r=r(z9t,"layoutlm"),z9t.forEach(t),H3r=r(_qe," \u2014 "),QJ=n(_qe,"A",{href:!0});var Q9t=s(QJ);U3r=r(Q9t,"TFLayoutLMForSequenceClassification"),Q9t.forEach(t),J3r=r(_qe," (LayoutLM model)"),_qe.forEach(t),Y3r=i(ne),RM=n(ne,"LI",{});var uqe=s(RM);VTe=n(uqe,"STRONG",{});var W9t=s(VTe);K3r=r(W9t,"longformer"),W9t.forEach(t),Z3r=r(uqe," \u2014 "),WJ=n(uqe,"A",{href:!0});var H9t=s(WJ);e0r=r(H9t,"TFLongformerForSequenceClassification"),H9t.forEach(t),o0r=r(uqe," (Longformer model)"),uqe.forEach(t),r0r=i(ne),PM=n(ne,"LI",{});var bqe=s(PM);XTe=n(bqe,"STRONG",{});var U9t=s(XTe);t0r=r(U9t,"mobilebert"),U9t.forEach(t),a0r=r(bqe," \u2014 "),HJ=n(bqe,"A",{href:!0});var J9t=s(HJ);n0r=r(J9t,"TFMobileBertForSequenceClassification"),J9t.forEach(t),s0r=r(bqe," (MobileBERT model)"),bqe.forEach(t),l0r=i(ne),BM=n(ne,"LI",{});var vqe=s(BM);zTe=n(vqe,"STRONG",{});var Y9t=s(zTe);i0r=r(Y9t,"mpnet"),Y9t.forEach(t),d0r=r(vqe," \u2014 "),UJ=n(vqe,"A",{href:!0});var K9t=s(UJ);c0r=r(K9t,"TFMPNetForSequenceClassification"),K9t.forEach(t),f0r=r(vqe," (MPNet model)"),vqe.forEach(t),m0r=i(ne),IM=n(ne,"LI",{});var Fqe=s(IM);QTe=n(Fqe,"STRONG",{});var Z9t=s(QTe);g0r=r(Z9t,"openai-gpt"),Z9t.forEach(t),h0r=r(Fqe," \u2014 "),JJ=n(Fqe,"A",{href:!0});var ext=s(JJ);p0r=r(ext,"TFOpenAIGPTForSequenceClassification"),ext.forEach(t),_0r=r(Fqe," (OpenAI GPT model)"),Fqe.forEach(t),u0r=i(ne),NM=n(ne,"LI",{});var Tqe=s(NM);WTe=n(Tqe,"STRONG",{});var oxt=s(WTe);b0r=r(oxt,"rembert"),oxt.forEach(t),v0r=r(Tqe," \u2014 "),YJ=n(Tqe,"A",{href:!0});var rxt=s(YJ);F0r=r(rxt,"TFRemBertForSequenceClassification"),rxt.forEach(t),T0r=r(Tqe," (RemBERT model)"),Tqe.forEach(t),M0r=i(ne),qM=n(ne,"LI",{});var Mqe=s(qM);HTe=n(Mqe,"STRONG",{});var txt=s(HTe);E0r=r(txt,"roberta"),txt.forEach(t),C0r=r(Mqe," \u2014 "),KJ=n(Mqe,"A",{href:!0});var axt=s(KJ);w0r=r(axt,"TFRobertaForSequenceClassification"),axt.forEach(t),A0r=r(Mqe," (RoBERTa model)"),Mqe.forEach(t),L0r=i(ne),jM=n(ne,"LI",{});var Eqe=s(jM);UTe=n(Eqe,"STRONG",{});var nxt=s(UTe);y0r=r(nxt,"roformer"),nxt.forEach(t),x0r=r(Eqe," \u2014 "),ZJ=n(Eqe,"A",{href:!0});var sxt=s(ZJ);$0r=r(sxt,"TFRoFormerForSequenceClassification"),sxt.forEach(t),k0r=r(Eqe," (RoFormer model)"),Eqe.forEach(t),S0r=i(ne),DM=n(ne,"LI",{});var Cqe=s(DM);JTe=n(Cqe,"STRONG",{});var lxt=s(JTe);R0r=r(lxt,"tapas"),lxt.forEach(t),P0r=r(Cqe," \u2014 "),eY=n(Cqe,"A",{href:!0});var ixt=s(eY);B0r=r(ixt,"TFTapasForSequenceClassification"),ixt.forEach(t),I0r=r(Cqe," (TAPAS model)"),Cqe.forEach(t),N0r=i(ne),GM=n(ne,"LI",{});var wqe=s(GM);YTe=n(wqe,"STRONG",{});var dxt=s(YTe);q0r=r(dxt,"transfo-xl"),dxt.forEach(t),j0r=r(wqe," \u2014 "),oY=n(wqe,"A",{href:!0});var cxt=s(oY);D0r=r(cxt,"TFTransfoXLForSequenceClassification"),cxt.forEach(t),G0r=r(wqe," (Transformer-XL model)"),wqe.forEach(t),O0r=i(ne),OM=n(ne,"LI",{});var Aqe=s(OM);KTe=n(Aqe,"STRONG",{});var fxt=s(KTe);V0r=r(fxt,"xlm"),fxt.forEach(t),X0r=r(Aqe," \u2014 "),rY=n(Aqe,"A",{href:!0});var mxt=s(rY);z0r=r(mxt,"TFXLMForSequenceClassification"),mxt.forEach(t),Q0r=r(Aqe," (XLM model)"),Aqe.forEach(t),W0r=i(ne),VM=n(ne,"LI",{});var Lqe=s(VM);ZTe=n(Lqe,"STRONG",{});var gxt=s(ZTe);H0r=r(gxt,"xlm-roberta"),gxt.forEach(t),U0r=r(Lqe," \u2014 "),tY=n(Lqe,"A",{href:!0});var hxt=s(tY);J0r=r(hxt,"TFXLMRobertaForSequenceClassification"),hxt.forEach(t),Y0r=r(Lqe," (XLM-RoBERTa model)"),Lqe.forEach(t),K0r=i(ne),XM=n(ne,"LI",{});var yqe=s(XM);e7e=n(yqe,"STRONG",{});var pxt=s(e7e);Z0r=r(pxt,"xlnet"),pxt.forEach(t),ewr=r(yqe," \u2014 "),aY=n(yqe,"A",{href:!0});var _xt=s(aY);owr=r(_xt,"TFXLNetForSequenceClassification"),_xt.forEach(t),rwr=r(yqe," (XLNet model)"),yqe.forEach(t),ne.forEach(t),twr=i(Il),T(zM.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),sVe=i(f),Tc=n(f,"H2",{class:!0});var hze=s(Tc);QM=n(hze,"A",{id:!0,class:!0,href:!0});var uxt=s(QM);o7e=n(uxt,"SPAN",{});var bxt=s(o7e);T(J9.$$.fragment,bxt),bxt.forEach(t),uxt.forEach(t),awr=i(hze),r7e=n(hze,"SPAN",{});var vxt=s(r7e);nwr=r(vxt,"TFAutoModelForMultipleChoice"),vxt.forEach(t),hze.forEach(t),lVe=i(f),lr=n(f,"DIV",{class:!0});var Nl=s(lr);T(Y9.$$.fragment,Nl),swr=i(Nl),Mc=n(Nl,"P",{});var yre=s(Mc);lwr=r(yre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=n(yre,"A",{href:!0});var Fxt=s(nY);iwr=r(Fxt,"from_pretrained()"),Fxt.forEach(t),dwr=r(yre," class method or the "),sY=n(yre,"A",{href:!0});var Txt=s(sY);cwr=r(Txt,"from_config()"),Txt.forEach(t),fwr=r(yre,` class
method.`),yre.forEach(t),mwr=i(Nl),K9=n(Nl,"P",{});var pze=s(K9);gwr=r(pze,"This class cannot be instantiated directly using "),t7e=n(pze,"CODE",{});var Mxt=s(t7e);hwr=r(Mxt,"__init__()"),Mxt.forEach(t),pwr=r(pze," (throws an error)."),pze.forEach(t),_wr=i(Nl),Nt=n(Nl,"DIV",{class:!0});var Gw=s(Nt);T(Z9.$$.fragment,Gw),uwr=i(Gw),a7e=n(Gw,"P",{});var Ext=s(a7e);bwr=r(Ext,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ext.forEach(t),vwr=i(Gw),Ec=n(Gw,"P",{});var xre=s(Ec);Fwr=r(xre,`Note:
Loading a model from its configuration file does `),n7e=n(xre,"STRONG",{});var Cxt=s(n7e);Twr=r(Cxt,"not"),Cxt.forEach(t),Mwr=r(xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=n(xre,"A",{href:!0});var wxt=s(lY);Ewr=r(wxt,"from_pretrained()"),wxt.forEach(t),Cwr=r(xre," to load the model weights."),xre.forEach(t),wwr=i(Gw),T(WM.$$.fragment,Gw),Gw.forEach(t),Awr=i(Nl),Br=n(Nl,"DIV",{class:!0});var ql=s(Br);T(ex.$$.fragment,ql),Lwr=i(ql),s7e=n(ql,"P",{});var Axt=s(s7e);ywr=r(Axt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Axt.forEach(t),xwr=i(ql),gn=n(ql,"P",{});var Ow=s(gn);$wr=r(Ow,"The model class to instantiate is selected based on the "),l7e=n(Ow,"CODE",{});var Lxt=s(l7e);kwr=r(Lxt,"model_type"),Lxt.forEach(t),Swr=r(Ow,` property of the config object (either
passed as an argument or loaded from `),i7e=n(Ow,"CODE",{});var yxt=s(i7e);Rwr=r(yxt,"pretrained_model_name_or_path"),yxt.forEach(t),Pwr=r(Ow,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=n(Ow,"CODE",{});var xxt=s(d7e);Bwr=r(xxt,"pretrained_model_name_or_path"),xxt.forEach(t),Iwr=r(Ow,":"),Ow.forEach(t),Nwr=i(ql),_e=n(ql,"UL",{});var ve=s(_e);HM=n(ve,"LI",{});var xqe=s(HM);c7e=n(xqe,"STRONG",{});var $xt=s(c7e);qwr=r($xt,"albert"),$xt.forEach(t),jwr=r(xqe," \u2014 "),iY=n(xqe,"A",{href:!0});var kxt=s(iY);Dwr=r(kxt,"TFAlbertForMultipleChoice"),kxt.forEach(t),Gwr=r(xqe," (ALBERT model)"),xqe.forEach(t),Owr=i(ve),UM=n(ve,"LI",{});var $qe=s(UM);f7e=n($qe,"STRONG",{});var Sxt=s(f7e);Vwr=r(Sxt,"bert"),Sxt.forEach(t),Xwr=r($qe," \u2014 "),dY=n($qe,"A",{href:!0});var Rxt=s(dY);zwr=r(Rxt,"TFBertForMultipleChoice"),Rxt.forEach(t),Qwr=r($qe," (BERT model)"),$qe.forEach(t),Wwr=i(ve),JM=n(ve,"LI",{});var kqe=s(JM);m7e=n(kqe,"STRONG",{});var Pxt=s(m7e);Hwr=r(Pxt,"camembert"),Pxt.forEach(t),Uwr=r(kqe," \u2014 "),cY=n(kqe,"A",{href:!0});var Bxt=s(cY);Jwr=r(Bxt,"TFCamembertForMultipleChoice"),Bxt.forEach(t),Ywr=r(kqe," (CamemBERT model)"),kqe.forEach(t),Kwr=i(ve),YM=n(ve,"LI",{});var Sqe=s(YM);g7e=n(Sqe,"STRONG",{});var Ixt=s(g7e);Zwr=r(Ixt,"convbert"),Ixt.forEach(t),eAr=r(Sqe," \u2014 "),fY=n(Sqe,"A",{href:!0});var Nxt=s(fY);oAr=r(Nxt,"TFConvBertForMultipleChoice"),Nxt.forEach(t),rAr=r(Sqe," (ConvBERT model)"),Sqe.forEach(t),tAr=i(ve),KM=n(ve,"LI",{});var Rqe=s(KM);h7e=n(Rqe,"STRONG",{});var qxt=s(h7e);aAr=r(qxt,"distilbert"),qxt.forEach(t),nAr=r(Rqe," \u2014 "),mY=n(Rqe,"A",{href:!0});var jxt=s(mY);sAr=r(jxt,"TFDistilBertForMultipleChoice"),jxt.forEach(t),lAr=r(Rqe," (DistilBERT model)"),Rqe.forEach(t),iAr=i(ve),ZM=n(ve,"LI",{});var Pqe=s(ZM);p7e=n(Pqe,"STRONG",{});var Dxt=s(p7e);dAr=r(Dxt,"electra"),Dxt.forEach(t),cAr=r(Pqe," \u2014 "),gY=n(Pqe,"A",{href:!0});var Gxt=s(gY);fAr=r(Gxt,"TFElectraForMultipleChoice"),Gxt.forEach(t),mAr=r(Pqe," (ELECTRA model)"),Pqe.forEach(t),gAr=i(ve),eE=n(ve,"LI",{});var Bqe=s(eE);_7e=n(Bqe,"STRONG",{});var Oxt=s(_7e);hAr=r(Oxt,"flaubert"),Oxt.forEach(t),pAr=r(Bqe," \u2014 "),hY=n(Bqe,"A",{href:!0});var Vxt=s(hY);_Ar=r(Vxt,"TFFlaubertForMultipleChoice"),Vxt.forEach(t),uAr=r(Bqe," (FlauBERT model)"),Bqe.forEach(t),bAr=i(ve),oE=n(ve,"LI",{});var Iqe=s(oE);u7e=n(Iqe,"STRONG",{});var Xxt=s(u7e);vAr=r(Xxt,"funnel"),Xxt.forEach(t),FAr=r(Iqe," \u2014 "),pY=n(Iqe,"A",{href:!0});var zxt=s(pY);TAr=r(zxt,"TFFunnelForMultipleChoice"),zxt.forEach(t),MAr=r(Iqe," (Funnel Transformer model)"),Iqe.forEach(t),EAr=i(ve),rE=n(ve,"LI",{});var Nqe=s(rE);b7e=n(Nqe,"STRONG",{});var Qxt=s(b7e);CAr=r(Qxt,"longformer"),Qxt.forEach(t),wAr=r(Nqe," \u2014 "),_Y=n(Nqe,"A",{href:!0});var Wxt=s(_Y);AAr=r(Wxt,"TFLongformerForMultipleChoice"),Wxt.forEach(t),LAr=r(Nqe," (Longformer model)"),Nqe.forEach(t),yAr=i(ve),tE=n(ve,"LI",{});var qqe=s(tE);v7e=n(qqe,"STRONG",{});var Hxt=s(v7e);xAr=r(Hxt,"mobilebert"),Hxt.forEach(t),$Ar=r(qqe," \u2014 "),uY=n(qqe,"A",{href:!0});var Uxt=s(uY);kAr=r(Uxt,"TFMobileBertForMultipleChoice"),Uxt.forEach(t),SAr=r(qqe," (MobileBERT model)"),qqe.forEach(t),RAr=i(ve),aE=n(ve,"LI",{});var jqe=s(aE);F7e=n(jqe,"STRONG",{});var Jxt=s(F7e);PAr=r(Jxt,"mpnet"),Jxt.forEach(t),BAr=r(jqe," \u2014 "),bY=n(jqe,"A",{href:!0});var Yxt=s(bY);IAr=r(Yxt,"TFMPNetForMultipleChoice"),Yxt.forEach(t),NAr=r(jqe," (MPNet model)"),jqe.forEach(t),qAr=i(ve),nE=n(ve,"LI",{});var Dqe=s(nE);T7e=n(Dqe,"STRONG",{});var Kxt=s(T7e);jAr=r(Kxt,"rembert"),Kxt.forEach(t),DAr=r(Dqe," \u2014 "),vY=n(Dqe,"A",{href:!0});var Zxt=s(vY);GAr=r(Zxt,"TFRemBertForMultipleChoice"),Zxt.forEach(t),OAr=r(Dqe," (RemBERT model)"),Dqe.forEach(t),VAr=i(ve),sE=n(ve,"LI",{});var Gqe=s(sE);M7e=n(Gqe,"STRONG",{});var e$t=s(M7e);XAr=r(e$t,"roberta"),e$t.forEach(t),zAr=r(Gqe," \u2014 "),FY=n(Gqe,"A",{href:!0});var o$t=s(FY);QAr=r(o$t,"TFRobertaForMultipleChoice"),o$t.forEach(t),WAr=r(Gqe," (RoBERTa model)"),Gqe.forEach(t),HAr=i(ve),lE=n(ve,"LI",{});var Oqe=s(lE);E7e=n(Oqe,"STRONG",{});var r$t=s(E7e);UAr=r(r$t,"roformer"),r$t.forEach(t),JAr=r(Oqe," \u2014 "),TY=n(Oqe,"A",{href:!0});var t$t=s(TY);YAr=r(t$t,"TFRoFormerForMultipleChoice"),t$t.forEach(t),KAr=r(Oqe," (RoFormer model)"),Oqe.forEach(t),ZAr=i(ve),iE=n(ve,"LI",{});var Vqe=s(iE);C7e=n(Vqe,"STRONG",{});var a$t=s(C7e);eLr=r(a$t,"xlm"),a$t.forEach(t),oLr=r(Vqe," \u2014 "),MY=n(Vqe,"A",{href:!0});var n$t=s(MY);rLr=r(n$t,"TFXLMForMultipleChoice"),n$t.forEach(t),tLr=r(Vqe," (XLM model)"),Vqe.forEach(t),aLr=i(ve),dE=n(ve,"LI",{});var Xqe=s(dE);w7e=n(Xqe,"STRONG",{});var s$t=s(w7e);nLr=r(s$t,"xlm-roberta"),s$t.forEach(t),sLr=r(Xqe," \u2014 "),EY=n(Xqe,"A",{href:!0});var l$t=s(EY);lLr=r(l$t,"TFXLMRobertaForMultipleChoice"),l$t.forEach(t),iLr=r(Xqe," (XLM-RoBERTa model)"),Xqe.forEach(t),dLr=i(ve),cE=n(ve,"LI",{});var zqe=s(cE);A7e=n(zqe,"STRONG",{});var i$t=s(A7e);cLr=r(i$t,"xlnet"),i$t.forEach(t),fLr=r(zqe," \u2014 "),CY=n(zqe,"A",{href:!0});var d$t=s(CY);mLr=r(d$t,"TFXLNetForMultipleChoice"),d$t.forEach(t),gLr=r(zqe," (XLNet model)"),zqe.forEach(t),ve.forEach(t),hLr=i(ql),T(fE.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),iVe=i(f),Cc=n(f,"H2",{class:!0});var _ze=s(Cc);mE=n(_ze,"A",{id:!0,class:!0,href:!0});var c$t=s(mE);L7e=n(c$t,"SPAN",{});var f$t=s(L7e);T(ox.$$.fragment,f$t),f$t.forEach(t),c$t.forEach(t),pLr=i(_ze),y7e=n(_ze,"SPAN",{});var m$t=s(y7e);_Lr=r(m$t,"TFAutoModelForNextSentencePrediction"),m$t.forEach(t),_ze.forEach(t),dVe=i(f),ir=n(f,"DIV",{class:!0});var jl=s(ir);T(rx.$$.fragment,jl),uLr=i(jl),wc=n(jl,"P",{});var $re=s(wc);bLr=r($re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=n($re,"A",{href:!0});var g$t=s(wY);vLr=r(g$t,"from_pretrained()"),g$t.forEach(t),FLr=r($re," class method or the "),AY=n($re,"A",{href:!0});var h$t=s(AY);TLr=r(h$t,"from_config()"),h$t.forEach(t),MLr=r($re,` class
method.`),$re.forEach(t),ELr=i(jl),tx=n(jl,"P",{});var uze=s(tx);CLr=r(uze,"This class cannot be instantiated directly using "),x7e=n(uze,"CODE",{});var p$t=s(x7e);wLr=r(p$t,"__init__()"),p$t.forEach(t),ALr=r(uze," (throws an error)."),uze.forEach(t),LLr=i(jl),qt=n(jl,"DIV",{class:!0});var Vw=s(qt);T(ax.$$.fragment,Vw),yLr=i(Vw),$7e=n(Vw,"P",{});var _$t=s($7e);xLr=r(_$t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),_$t.forEach(t),$Lr=i(Vw),Ac=n(Vw,"P",{});var kre=s(Ac);kLr=r(kre,`Note:
Loading a model from its configuration file does `),k7e=n(kre,"STRONG",{});var u$t=s(k7e);SLr=r(u$t,"not"),u$t.forEach(t),RLr=r(kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=n(kre,"A",{href:!0});var b$t=s(LY);PLr=r(b$t,"from_pretrained()"),b$t.forEach(t),BLr=r(kre," to load the model weights."),kre.forEach(t),ILr=i(Vw),T(gE.$$.fragment,Vw),Vw.forEach(t),NLr=i(jl),Ir=n(jl,"DIV",{class:!0});var Dl=s(Ir);T(nx.$$.fragment,Dl),qLr=i(Dl),S7e=n(Dl,"P",{});var v$t=s(S7e);jLr=r(v$t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),v$t.forEach(t),DLr=i(Dl),hn=n(Dl,"P",{});var Xw=s(hn);GLr=r(Xw,"The model class to instantiate is selected based on the "),R7e=n(Xw,"CODE",{});var F$t=s(R7e);OLr=r(F$t,"model_type"),F$t.forEach(t),VLr=r(Xw,` property of the config object (either
passed as an argument or loaded from `),P7e=n(Xw,"CODE",{});var T$t=s(P7e);XLr=r(T$t,"pretrained_model_name_or_path"),T$t.forEach(t),zLr=r(Xw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B7e=n(Xw,"CODE",{});var M$t=s(B7e);QLr=r(M$t,"pretrained_model_name_or_path"),M$t.forEach(t),WLr=r(Xw,":"),Xw.forEach(t),HLr=i(Dl),sx=n(Dl,"UL",{});var bze=s(sx);hE=n(bze,"LI",{});var Qqe=s(hE);I7e=n(Qqe,"STRONG",{});var E$t=s(I7e);ULr=r(E$t,"bert"),E$t.forEach(t),JLr=r(Qqe," \u2014 "),yY=n(Qqe,"A",{href:!0});var C$t=s(yY);YLr=r(C$t,"TFBertForNextSentencePrediction"),C$t.forEach(t),KLr=r(Qqe," (BERT model)"),Qqe.forEach(t),ZLr=i(bze),pE=n(bze,"LI",{});var Wqe=s(pE);N7e=n(Wqe,"STRONG",{});var w$t=s(N7e);eyr=r(w$t,"mobilebert"),w$t.forEach(t),oyr=r(Wqe," \u2014 "),xY=n(Wqe,"A",{href:!0});var A$t=s(xY);ryr=r(A$t,"TFMobileBertForNextSentencePrediction"),A$t.forEach(t),tyr=r(Wqe," (MobileBERT model)"),Wqe.forEach(t),bze.forEach(t),ayr=i(Dl),T(_E.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),cVe=i(f),Lc=n(f,"H2",{class:!0});var vze=s(Lc);uE=n(vze,"A",{id:!0,class:!0,href:!0});var L$t=s(uE);q7e=n(L$t,"SPAN",{});var y$t=s(q7e);T(lx.$$.fragment,y$t),y$t.forEach(t),L$t.forEach(t),nyr=i(vze),j7e=n(vze,"SPAN",{});var x$t=s(j7e);syr=r(x$t,"TFAutoModelForTableQuestionAnswering"),x$t.forEach(t),vze.forEach(t),fVe=i(f),dr=n(f,"DIV",{class:!0});var Gl=s(dr);T(ix.$$.fragment,Gl),lyr=i(Gl),yc=n(Gl,"P",{});var Sre=s(yc);iyr=r(Sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=n(Sre,"A",{href:!0});var $$t=s($Y);dyr=r($$t,"from_pretrained()"),$$t.forEach(t),cyr=r(Sre," class method or the "),kY=n(Sre,"A",{href:!0});var k$t=s(kY);fyr=r(k$t,"from_config()"),k$t.forEach(t),myr=r(Sre,` class
method.`),Sre.forEach(t),gyr=i(Gl),dx=n(Gl,"P",{});var Fze=s(dx);hyr=r(Fze,"This class cannot be instantiated directly using "),D7e=n(Fze,"CODE",{});var S$t=s(D7e);pyr=r(S$t,"__init__()"),S$t.forEach(t),_yr=r(Fze," (throws an error)."),Fze.forEach(t),uyr=i(Gl),jt=n(Gl,"DIV",{class:!0});var zw=s(jt);T(cx.$$.fragment,zw),byr=i(zw),G7e=n(zw,"P",{});var R$t=s(G7e);vyr=r(R$t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),R$t.forEach(t),Fyr=i(zw),xc=n(zw,"P",{});var Rre=s(xc);Tyr=r(Rre,`Note:
Loading a model from its configuration file does `),O7e=n(Rre,"STRONG",{});var P$t=s(O7e);Myr=r(P$t,"not"),P$t.forEach(t),Eyr=r(Rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=n(Rre,"A",{href:!0});var B$t=s(SY);Cyr=r(B$t,"from_pretrained()"),B$t.forEach(t),wyr=r(Rre," to load the model weights."),Rre.forEach(t),Ayr=i(zw),T(bE.$$.fragment,zw),zw.forEach(t),Lyr=i(Gl),Nr=n(Gl,"DIV",{class:!0});var Ol=s(Nr);T(fx.$$.fragment,Ol),yyr=i(Ol),V7e=n(Ol,"P",{});var I$t=s(V7e);xyr=r(I$t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),I$t.forEach(t),$yr=i(Ol),pn=n(Ol,"P",{});var Qw=s(pn);kyr=r(Qw,"The model class to instantiate is selected based on the "),X7e=n(Qw,"CODE",{});var N$t=s(X7e);Syr=r(N$t,"model_type"),N$t.forEach(t),Ryr=r(Qw,` property of the config object (either
passed as an argument or loaded from `),z7e=n(Qw,"CODE",{});var q$t=s(z7e);Pyr=r(q$t,"pretrained_model_name_or_path"),q$t.forEach(t),Byr=r(Qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q7e=n(Qw,"CODE",{});var j$t=s(Q7e);Iyr=r(j$t,"pretrained_model_name_or_path"),j$t.forEach(t),Nyr=r(Qw,":"),Qw.forEach(t),qyr=i(Ol),W7e=n(Ol,"UL",{});var D$t=s(W7e);vE=n(D$t,"LI",{});var Hqe=s(vE);H7e=n(Hqe,"STRONG",{});var G$t=s(H7e);jyr=r(G$t,"tapas"),G$t.forEach(t),Dyr=r(Hqe," \u2014 "),RY=n(Hqe,"A",{href:!0});var O$t=s(RY);Gyr=r(O$t,"TFTapasForQuestionAnswering"),O$t.forEach(t),Oyr=r(Hqe," (TAPAS model)"),Hqe.forEach(t),D$t.forEach(t),Vyr=i(Ol),T(FE.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),mVe=i(f),$c=n(f,"H2",{class:!0});var Tze=s($c);TE=n(Tze,"A",{id:!0,class:!0,href:!0});var V$t=s(TE);U7e=n(V$t,"SPAN",{});var X$t=s(U7e);T(mx.$$.fragment,X$t),X$t.forEach(t),V$t.forEach(t),Xyr=i(Tze),J7e=n(Tze,"SPAN",{});var z$t=s(J7e);zyr=r(z$t,"TFAutoModelForTokenClassification"),z$t.forEach(t),Tze.forEach(t),gVe=i(f),cr=n(f,"DIV",{class:!0});var Vl=s(cr);T(gx.$$.fragment,Vl),Qyr=i(Vl),kc=n(Vl,"P",{});var Pre=s(kc);Wyr=r(Pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=n(Pre,"A",{href:!0});var Q$t=s(PY);Hyr=r(Q$t,"from_pretrained()"),Q$t.forEach(t),Uyr=r(Pre," class method or the "),BY=n(Pre,"A",{href:!0});var W$t=s(BY);Jyr=r(W$t,"from_config()"),W$t.forEach(t),Yyr=r(Pre,` class
method.`),Pre.forEach(t),Kyr=i(Vl),hx=n(Vl,"P",{});var Mze=s(hx);Zyr=r(Mze,"This class cannot be instantiated directly using "),Y7e=n(Mze,"CODE",{});var H$t=s(Y7e);e9r=r(H$t,"__init__()"),H$t.forEach(t),o9r=r(Mze," (throws an error)."),Mze.forEach(t),r9r=i(Vl),Dt=n(Vl,"DIV",{class:!0});var Ww=s(Dt);T(px.$$.fragment,Ww),t9r=i(Ww),K7e=n(Ww,"P",{});var U$t=s(K7e);a9r=r(U$t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),U$t.forEach(t),n9r=i(Ww),Sc=n(Ww,"P",{});var Bre=s(Sc);s9r=r(Bre,`Note:
Loading a model from its configuration file does `),Z7e=n(Bre,"STRONG",{});var J$t=s(Z7e);l9r=r(J$t,"not"),J$t.forEach(t),i9r=r(Bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(Bre,"A",{href:!0});var Y$t=s(IY);d9r=r(Y$t,"from_pretrained()"),Y$t.forEach(t),c9r=r(Bre," to load the model weights."),Bre.forEach(t),f9r=i(Ww),T(ME.$$.fragment,Ww),Ww.forEach(t),m9r=i(Vl),qr=n(Vl,"DIV",{class:!0});var Xl=s(qr);T(_x.$$.fragment,Xl),g9r=i(Xl),e8e=n(Xl,"P",{});var K$t=s(e8e);h9r=r(K$t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),K$t.forEach(t),p9r=i(Xl),_n=n(Xl,"P",{});var Hw=s(_n);_9r=r(Hw,"The model class to instantiate is selected based on the "),o8e=n(Hw,"CODE",{});var Z$t=s(o8e);u9r=r(Z$t,"model_type"),Z$t.forEach(t),b9r=r(Hw,` property of the config object (either
passed as an argument or loaded from `),r8e=n(Hw,"CODE",{});var ekt=s(r8e);v9r=r(ekt,"pretrained_model_name_or_path"),ekt.forEach(t),F9r=r(Hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t8e=n(Hw,"CODE",{});var okt=s(t8e);T9r=r(okt,"pretrained_model_name_or_path"),okt.forEach(t),M9r=r(Hw,":"),Hw.forEach(t),E9r=i(Xl),de=n(Xl,"UL",{});var me=s(de);EE=n(me,"LI",{});var Uqe=s(EE);a8e=n(Uqe,"STRONG",{});var rkt=s(a8e);C9r=r(rkt,"albert"),rkt.forEach(t),w9r=r(Uqe," \u2014 "),NY=n(Uqe,"A",{href:!0});var tkt=s(NY);A9r=r(tkt,"TFAlbertForTokenClassification"),tkt.forEach(t),L9r=r(Uqe," (ALBERT model)"),Uqe.forEach(t),y9r=i(me),CE=n(me,"LI",{});var Jqe=s(CE);n8e=n(Jqe,"STRONG",{});var akt=s(n8e);x9r=r(akt,"bert"),akt.forEach(t),$9r=r(Jqe," \u2014 "),qY=n(Jqe,"A",{href:!0});var nkt=s(qY);k9r=r(nkt,"TFBertForTokenClassification"),nkt.forEach(t),S9r=r(Jqe," (BERT model)"),Jqe.forEach(t),R9r=i(me),wE=n(me,"LI",{});var Yqe=s(wE);s8e=n(Yqe,"STRONG",{});var skt=s(s8e);P9r=r(skt,"camembert"),skt.forEach(t),B9r=r(Yqe," \u2014 "),jY=n(Yqe,"A",{href:!0});var lkt=s(jY);I9r=r(lkt,"TFCamembertForTokenClassification"),lkt.forEach(t),N9r=r(Yqe," (CamemBERT model)"),Yqe.forEach(t),q9r=i(me),AE=n(me,"LI",{});var Kqe=s(AE);l8e=n(Kqe,"STRONG",{});var ikt=s(l8e);j9r=r(ikt,"convbert"),ikt.forEach(t),D9r=r(Kqe," \u2014 "),DY=n(Kqe,"A",{href:!0});var dkt=s(DY);G9r=r(dkt,"TFConvBertForTokenClassification"),dkt.forEach(t),O9r=r(Kqe," (ConvBERT model)"),Kqe.forEach(t),V9r=i(me),LE=n(me,"LI",{});var Zqe=s(LE);i8e=n(Zqe,"STRONG",{});var ckt=s(i8e);X9r=r(ckt,"deberta"),ckt.forEach(t),z9r=r(Zqe," \u2014 "),GY=n(Zqe,"A",{href:!0});var fkt=s(GY);Q9r=r(fkt,"TFDebertaForTokenClassification"),fkt.forEach(t),W9r=r(Zqe," (DeBERTa model)"),Zqe.forEach(t),H9r=i(me),yE=n(me,"LI",{});var eje=s(yE);d8e=n(eje,"STRONG",{});var mkt=s(d8e);U9r=r(mkt,"deberta-v2"),mkt.forEach(t),J9r=r(eje," \u2014 "),OY=n(eje,"A",{href:!0});var gkt=s(OY);Y9r=r(gkt,"TFDebertaV2ForTokenClassification"),gkt.forEach(t),K9r=r(eje," (DeBERTa-v2 model)"),eje.forEach(t),Z9r=i(me),xE=n(me,"LI",{});var oje=s(xE);c8e=n(oje,"STRONG",{});var hkt=s(c8e);exr=r(hkt,"distilbert"),hkt.forEach(t),oxr=r(oje," \u2014 "),VY=n(oje,"A",{href:!0});var pkt=s(VY);rxr=r(pkt,"TFDistilBertForTokenClassification"),pkt.forEach(t),txr=r(oje," (DistilBERT model)"),oje.forEach(t),axr=i(me),$E=n(me,"LI",{});var rje=s($E);f8e=n(rje,"STRONG",{});var _kt=s(f8e);nxr=r(_kt,"electra"),_kt.forEach(t),sxr=r(rje," \u2014 "),XY=n(rje,"A",{href:!0});var ukt=s(XY);lxr=r(ukt,"TFElectraForTokenClassification"),ukt.forEach(t),ixr=r(rje," (ELECTRA model)"),rje.forEach(t),dxr=i(me),kE=n(me,"LI",{});var tje=s(kE);m8e=n(tje,"STRONG",{});var bkt=s(m8e);cxr=r(bkt,"flaubert"),bkt.forEach(t),fxr=r(tje," \u2014 "),zY=n(tje,"A",{href:!0});var vkt=s(zY);mxr=r(vkt,"TFFlaubertForTokenClassification"),vkt.forEach(t),gxr=r(tje," (FlauBERT model)"),tje.forEach(t),hxr=i(me),SE=n(me,"LI",{});var aje=s(SE);g8e=n(aje,"STRONG",{});var Fkt=s(g8e);pxr=r(Fkt,"funnel"),Fkt.forEach(t),_xr=r(aje," \u2014 "),QY=n(aje,"A",{href:!0});var Tkt=s(QY);uxr=r(Tkt,"TFFunnelForTokenClassification"),Tkt.forEach(t),bxr=r(aje," (Funnel Transformer model)"),aje.forEach(t),vxr=i(me),RE=n(me,"LI",{});var nje=s(RE);h8e=n(nje,"STRONG",{});var Mkt=s(h8e);Fxr=r(Mkt,"layoutlm"),Mkt.forEach(t),Txr=r(nje," \u2014 "),WY=n(nje,"A",{href:!0});var Ekt=s(WY);Mxr=r(Ekt,"TFLayoutLMForTokenClassification"),Ekt.forEach(t),Exr=r(nje," (LayoutLM model)"),nje.forEach(t),Cxr=i(me),PE=n(me,"LI",{});var sje=s(PE);p8e=n(sje,"STRONG",{});var Ckt=s(p8e);wxr=r(Ckt,"longformer"),Ckt.forEach(t),Axr=r(sje," \u2014 "),HY=n(sje,"A",{href:!0});var wkt=s(HY);Lxr=r(wkt,"TFLongformerForTokenClassification"),wkt.forEach(t),yxr=r(sje," (Longformer model)"),sje.forEach(t),xxr=i(me),BE=n(me,"LI",{});var lje=s(BE);_8e=n(lje,"STRONG",{});var Akt=s(_8e);$xr=r(Akt,"mobilebert"),Akt.forEach(t),kxr=r(lje," \u2014 "),UY=n(lje,"A",{href:!0});var Lkt=s(UY);Sxr=r(Lkt,"TFMobileBertForTokenClassification"),Lkt.forEach(t),Rxr=r(lje," (MobileBERT model)"),lje.forEach(t),Pxr=i(me),IE=n(me,"LI",{});var ije=s(IE);u8e=n(ije,"STRONG",{});var ykt=s(u8e);Bxr=r(ykt,"mpnet"),ykt.forEach(t),Ixr=r(ije," \u2014 "),JY=n(ije,"A",{href:!0});var xkt=s(JY);Nxr=r(xkt,"TFMPNetForTokenClassification"),xkt.forEach(t),qxr=r(ije," (MPNet model)"),ije.forEach(t),jxr=i(me),NE=n(me,"LI",{});var dje=s(NE);b8e=n(dje,"STRONG",{});var $kt=s(b8e);Dxr=r($kt,"rembert"),$kt.forEach(t),Gxr=r(dje," \u2014 "),YY=n(dje,"A",{href:!0});var kkt=s(YY);Oxr=r(kkt,"TFRemBertForTokenClassification"),kkt.forEach(t),Vxr=r(dje," (RemBERT model)"),dje.forEach(t),Xxr=i(me),qE=n(me,"LI",{});var cje=s(qE);v8e=n(cje,"STRONG",{});var Skt=s(v8e);zxr=r(Skt,"roberta"),Skt.forEach(t),Qxr=r(cje," \u2014 "),KY=n(cje,"A",{href:!0});var Rkt=s(KY);Wxr=r(Rkt,"TFRobertaForTokenClassification"),Rkt.forEach(t),Hxr=r(cje," (RoBERTa model)"),cje.forEach(t),Uxr=i(me),jE=n(me,"LI",{});var fje=s(jE);F8e=n(fje,"STRONG",{});var Pkt=s(F8e);Jxr=r(Pkt,"roformer"),Pkt.forEach(t),Yxr=r(fje," \u2014 "),ZY=n(fje,"A",{href:!0});var Bkt=s(ZY);Kxr=r(Bkt,"TFRoFormerForTokenClassification"),Bkt.forEach(t),Zxr=r(fje," (RoFormer model)"),fje.forEach(t),e$r=i(me),DE=n(me,"LI",{});var mje=s(DE);T8e=n(mje,"STRONG",{});var Ikt=s(T8e);o$r=r(Ikt,"xlm"),Ikt.forEach(t),r$r=r(mje," \u2014 "),eK=n(mje,"A",{href:!0});var Nkt=s(eK);t$r=r(Nkt,"TFXLMForTokenClassification"),Nkt.forEach(t),a$r=r(mje," (XLM model)"),mje.forEach(t),n$r=i(me),GE=n(me,"LI",{});var gje=s(GE);M8e=n(gje,"STRONG",{});var qkt=s(M8e);s$r=r(qkt,"xlm-roberta"),qkt.forEach(t),l$r=r(gje," \u2014 "),oK=n(gje,"A",{href:!0});var jkt=s(oK);i$r=r(jkt,"TFXLMRobertaForTokenClassification"),jkt.forEach(t),d$r=r(gje," (XLM-RoBERTa model)"),gje.forEach(t),c$r=i(me),OE=n(me,"LI",{});var hje=s(OE);E8e=n(hje,"STRONG",{});var Dkt=s(E8e);f$r=r(Dkt,"xlnet"),Dkt.forEach(t),m$r=r(hje," \u2014 "),rK=n(hje,"A",{href:!0});var Gkt=s(rK);g$r=r(Gkt,"TFXLNetForTokenClassification"),Gkt.forEach(t),h$r=r(hje," (XLNet model)"),hje.forEach(t),me.forEach(t),p$r=i(Xl),T(VE.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),hVe=i(f),Rc=n(f,"H2",{class:!0});var Eze=s(Rc);XE=n(Eze,"A",{id:!0,class:!0,href:!0});var Okt=s(XE);C8e=n(Okt,"SPAN",{});var Vkt=s(C8e);T(ux.$$.fragment,Vkt),Vkt.forEach(t),Okt.forEach(t),_$r=i(Eze),w8e=n(Eze,"SPAN",{});var Xkt=s(w8e);u$r=r(Xkt,"TFAutoModelForQuestionAnswering"),Xkt.forEach(t),Eze.forEach(t),pVe=i(f),fr=n(f,"DIV",{class:!0});var zl=s(fr);T(bx.$$.fragment,zl),b$r=i(zl),Pc=n(zl,"P",{});var Ire=s(Pc);v$r=r(Ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=n(Ire,"A",{href:!0});var zkt=s(tK);F$r=r(zkt,"from_pretrained()"),zkt.forEach(t),T$r=r(Ire," class method or the "),aK=n(Ire,"A",{href:!0});var Qkt=s(aK);M$r=r(Qkt,"from_config()"),Qkt.forEach(t),E$r=r(Ire,` class
method.`),Ire.forEach(t),C$r=i(zl),vx=n(zl,"P",{});var Cze=s(vx);w$r=r(Cze,"This class cannot be instantiated directly using "),A8e=n(Cze,"CODE",{});var Wkt=s(A8e);A$r=r(Wkt,"__init__()"),Wkt.forEach(t),L$r=r(Cze," (throws an error)."),Cze.forEach(t),y$r=i(zl),Gt=n(zl,"DIV",{class:!0});var Uw=s(Gt);T(Fx.$$.fragment,Uw),x$r=i(Uw),L8e=n(Uw,"P",{});var Hkt=s(L8e);$$r=r(Hkt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Hkt.forEach(t),k$r=i(Uw),Bc=n(Uw,"P",{});var Nre=s(Bc);S$r=r(Nre,`Note:
Loading a model from its configuration file does `),y8e=n(Nre,"STRONG",{});var Ukt=s(y8e);R$r=r(Ukt,"not"),Ukt.forEach(t),P$r=r(Nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(Nre,"A",{href:!0});var Jkt=s(nK);B$r=r(Jkt,"from_pretrained()"),Jkt.forEach(t),I$r=r(Nre," to load the model weights."),Nre.forEach(t),N$r=i(Uw),T(zE.$$.fragment,Uw),Uw.forEach(t),q$r=i(zl),jr=n(zl,"DIV",{class:!0});var Ql=s(jr);T(Tx.$$.fragment,Ql),j$r=i(Ql),x8e=n(Ql,"P",{});var Ykt=s(x8e);D$r=r(Ykt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ykt.forEach(t),G$r=i(Ql),un=n(Ql,"P",{});var Jw=s(un);O$r=r(Jw,"The model class to instantiate is selected based on the "),$8e=n(Jw,"CODE",{});var Kkt=s($8e);V$r=r(Kkt,"model_type"),Kkt.forEach(t),X$r=r(Jw,` property of the config object (either
passed as an argument or loaded from `),k8e=n(Jw,"CODE",{});var Zkt=s(k8e);z$r=r(Zkt,"pretrained_model_name_or_path"),Zkt.forEach(t),Q$r=r(Jw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S8e=n(Jw,"CODE",{});var eSt=s(S8e);W$r=r(eSt,"pretrained_model_name_or_path"),eSt.forEach(t),H$r=r(Jw,":"),Jw.forEach(t),U$r=i(Ql),ce=n(Ql,"UL",{});var ge=s(ce);QE=n(ge,"LI",{});var pje=s(QE);R8e=n(pje,"STRONG",{});var oSt=s(R8e);J$r=r(oSt,"albert"),oSt.forEach(t),Y$r=r(pje," \u2014 "),sK=n(pje,"A",{href:!0});var rSt=s(sK);K$r=r(rSt,"TFAlbertForQuestionAnswering"),rSt.forEach(t),Z$r=r(pje," (ALBERT model)"),pje.forEach(t),ekr=i(ge),WE=n(ge,"LI",{});var _je=s(WE);P8e=n(_je,"STRONG",{});var tSt=s(P8e);okr=r(tSt,"bert"),tSt.forEach(t),rkr=r(_je," \u2014 "),lK=n(_je,"A",{href:!0});var aSt=s(lK);tkr=r(aSt,"TFBertForQuestionAnswering"),aSt.forEach(t),akr=r(_je," (BERT model)"),_je.forEach(t),nkr=i(ge),HE=n(ge,"LI",{});var uje=s(HE);B8e=n(uje,"STRONG",{});var nSt=s(B8e);skr=r(nSt,"camembert"),nSt.forEach(t),lkr=r(uje," \u2014 "),iK=n(uje,"A",{href:!0});var sSt=s(iK);ikr=r(sSt,"TFCamembertForQuestionAnswering"),sSt.forEach(t),dkr=r(uje," (CamemBERT model)"),uje.forEach(t),ckr=i(ge),UE=n(ge,"LI",{});var bje=s(UE);I8e=n(bje,"STRONG",{});var lSt=s(I8e);fkr=r(lSt,"convbert"),lSt.forEach(t),mkr=r(bje," \u2014 "),dK=n(bje,"A",{href:!0});var iSt=s(dK);gkr=r(iSt,"TFConvBertForQuestionAnswering"),iSt.forEach(t),hkr=r(bje," (ConvBERT model)"),bje.forEach(t),pkr=i(ge),JE=n(ge,"LI",{});var vje=s(JE);N8e=n(vje,"STRONG",{});var dSt=s(N8e);_kr=r(dSt,"deberta"),dSt.forEach(t),ukr=r(vje," \u2014 "),cK=n(vje,"A",{href:!0});var cSt=s(cK);bkr=r(cSt,"TFDebertaForQuestionAnswering"),cSt.forEach(t),vkr=r(vje," (DeBERTa model)"),vje.forEach(t),Fkr=i(ge),YE=n(ge,"LI",{});var Fje=s(YE);q8e=n(Fje,"STRONG",{});var fSt=s(q8e);Tkr=r(fSt,"deberta-v2"),fSt.forEach(t),Mkr=r(Fje," \u2014 "),fK=n(Fje,"A",{href:!0});var mSt=s(fK);Ekr=r(mSt,"TFDebertaV2ForQuestionAnswering"),mSt.forEach(t),Ckr=r(Fje," (DeBERTa-v2 model)"),Fje.forEach(t),wkr=i(ge),KE=n(ge,"LI",{});var Tje=s(KE);j8e=n(Tje,"STRONG",{});var gSt=s(j8e);Akr=r(gSt,"distilbert"),gSt.forEach(t),Lkr=r(Tje," \u2014 "),mK=n(Tje,"A",{href:!0});var hSt=s(mK);ykr=r(hSt,"TFDistilBertForQuestionAnswering"),hSt.forEach(t),xkr=r(Tje," (DistilBERT model)"),Tje.forEach(t),$kr=i(ge),ZE=n(ge,"LI",{});var Mje=s(ZE);D8e=n(Mje,"STRONG",{});var pSt=s(D8e);kkr=r(pSt,"electra"),pSt.forEach(t),Skr=r(Mje," \u2014 "),gK=n(Mje,"A",{href:!0});var _St=s(gK);Rkr=r(_St,"TFElectraForQuestionAnswering"),_St.forEach(t),Pkr=r(Mje," (ELECTRA model)"),Mje.forEach(t),Bkr=i(ge),eC=n(ge,"LI",{});var Eje=s(eC);G8e=n(Eje,"STRONG",{});var uSt=s(G8e);Ikr=r(uSt,"flaubert"),uSt.forEach(t),Nkr=r(Eje," \u2014 "),hK=n(Eje,"A",{href:!0});var bSt=s(hK);qkr=r(bSt,"TFFlaubertForQuestionAnsweringSimple"),bSt.forEach(t),jkr=r(Eje," (FlauBERT model)"),Eje.forEach(t),Dkr=i(ge),oC=n(ge,"LI",{});var Cje=s(oC);O8e=n(Cje,"STRONG",{});var vSt=s(O8e);Gkr=r(vSt,"funnel"),vSt.forEach(t),Okr=r(Cje," \u2014 "),pK=n(Cje,"A",{href:!0});var FSt=s(pK);Vkr=r(FSt,"TFFunnelForQuestionAnswering"),FSt.forEach(t),Xkr=r(Cje," (Funnel Transformer model)"),Cje.forEach(t),zkr=i(ge),rC=n(ge,"LI",{});var wje=s(rC);V8e=n(wje,"STRONG",{});var TSt=s(V8e);Qkr=r(TSt,"gptj"),TSt.forEach(t),Wkr=r(wje," \u2014 "),_K=n(wje,"A",{href:!0});var MSt=s(_K);Hkr=r(MSt,"TFGPTJForQuestionAnswering"),MSt.forEach(t),Ukr=r(wje," (GPT-J model)"),wje.forEach(t),Jkr=i(ge),tC=n(ge,"LI",{});var Aje=s(tC);X8e=n(Aje,"STRONG",{});var ESt=s(X8e);Ykr=r(ESt,"longformer"),ESt.forEach(t),Kkr=r(Aje," \u2014 "),uK=n(Aje,"A",{href:!0});var CSt=s(uK);Zkr=r(CSt,"TFLongformerForQuestionAnswering"),CSt.forEach(t),eSr=r(Aje," (Longformer model)"),Aje.forEach(t),oSr=i(ge),aC=n(ge,"LI",{});var Lje=s(aC);z8e=n(Lje,"STRONG",{});var wSt=s(z8e);rSr=r(wSt,"mobilebert"),wSt.forEach(t),tSr=r(Lje," \u2014 "),bK=n(Lje,"A",{href:!0});var ASt=s(bK);aSr=r(ASt,"TFMobileBertForQuestionAnswering"),ASt.forEach(t),nSr=r(Lje," (MobileBERT model)"),Lje.forEach(t),sSr=i(ge),nC=n(ge,"LI",{});var yje=s(nC);Q8e=n(yje,"STRONG",{});var LSt=s(Q8e);lSr=r(LSt,"mpnet"),LSt.forEach(t),iSr=r(yje," \u2014 "),vK=n(yje,"A",{href:!0});var ySt=s(vK);dSr=r(ySt,"TFMPNetForQuestionAnswering"),ySt.forEach(t),cSr=r(yje," (MPNet model)"),yje.forEach(t),fSr=i(ge),sC=n(ge,"LI",{});var xje=s(sC);W8e=n(xje,"STRONG",{});var xSt=s(W8e);mSr=r(xSt,"rembert"),xSt.forEach(t),gSr=r(xje," \u2014 "),FK=n(xje,"A",{href:!0});var $St=s(FK);hSr=r($St,"TFRemBertForQuestionAnswering"),$St.forEach(t),pSr=r(xje," (RemBERT model)"),xje.forEach(t),_Sr=i(ge),lC=n(ge,"LI",{});var $je=s(lC);H8e=n($je,"STRONG",{});var kSt=s(H8e);uSr=r(kSt,"roberta"),kSt.forEach(t),bSr=r($je," \u2014 "),TK=n($je,"A",{href:!0});var SSt=s(TK);vSr=r(SSt,"TFRobertaForQuestionAnswering"),SSt.forEach(t),FSr=r($je," (RoBERTa model)"),$je.forEach(t),TSr=i(ge),iC=n(ge,"LI",{});var kje=s(iC);U8e=n(kje,"STRONG",{});var RSt=s(U8e);MSr=r(RSt,"roformer"),RSt.forEach(t),ESr=r(kje," \u2014 "),MK=n(kje,"A",{href:!0});var PSt=s(MK);CSr=r(PSt,"TFRoFormerForQuestionAnswering"),PSt.forEach(t),wSr=r(kje," (RoFormer model)"),kje.forEach(t),ASr=i(ge),dC=n(ge,"LI",{});var Sje=s(dC);J8e=n(Sje,"STRONG",{});var BSt=s(J8e);LSr=r(BSt,"xlm"),BSt.forEach(t),ySr=r(Sje," \u2014 "),EK=n(Sje,"A",{href:!0});var ISt=s(EK);xSr=r(ISt,"TFXLMForQuestionAnsweringSimple"),ISt.forEach(t),$Sr=r(Sje," (XLM model)"),Sje.forEach(t),kSr=i(ge),cC=n(ge,"LI",{});var Rje=s(cC);Y8e=n(Rje,"STRONG",{});var NSt=s(Y8e);SSr=r(NSt,"xlm-roberta"),NSt.forEach(t),RSr=r(Rje," \u2014 "),CK=n(Rje,"A",{href:!0});var qSt=s(CK);PSr=r(qSt,"TFXLMRobertaForQuestionAnswering"),qSt.forEach(t),BSr=r(Rje," (XLM-RoBERTa model)"),Rje.forEach(t),ISr=i(ge),fC=n(ge,"LI",{});var Pje=s(fC);K8e=n(Pje,"STRONG",{});var jSt=s(K8e);NSr=r(jSt,"xlnet"),jSt.forEach(t),qSr=r(Pje," \u2014 "),wK=n(Pje,"A",{href:!0});var DSt=s(wK);jSr=r(DSt,"TFXLNetForQuestionAnsweringSimple"),DSt.forEach(t),DSr=r(Pje," (XLNet model)"),Pje.forEach(t),ge.forEach(t),GSr=i(Ql),T(mC.$$.fragment,Ql),Ql.forEach(t),zl.forEach(t),_Ve=i(f),Ic=n(f,"H2",{class:!0});var wze=s(Ic);gC=n(wze,"A",{id:!0,class:!0,href:!0});var GSt=s(gC);Z8e=n(GSt,"SPAN",{});var OSt=s(Z8e);T(Mx.$$.fragment,OSt),OSt.forEach(t),GSt.forEach(t),OSr=i(wze),eMe=n(wze,"SPAN",{});var VSt=s(eMe);VSr=r(VSt,"TFAutoModelForVision2Seq"),VSt.forEach(t),wze.forEach(t),uVe=i(f),mr=n(f,"DIV",{class:!0});var Wl=s(mr);T(Ex.$$.fragment,Wl),XSr=i(Wl),Nc=n(Wl,"P",{});var qre=s(Nc);zSr=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=n(qre,"A",{href:!0});var XSt=s(AK);QSr=r(XSt,"from_pretrained()"),XSt.forEach(t),WSr=r(qre," class method or the "),LK=n(qre,"A",{href:!0});var zSt=s(LK);HSr=r(zSt,"from_config()"),zSt.forEach(t),USr=r(qre,` class
method.`),qre.forEach(t),JSr=i(Wl),Cx=n(Wl,"P",{});var Aze=s(Cx);YSr=r(Aze,"This class cannot be instantiated directly using "),oMe=n(Aze,"CODE",{});var QSt=s(oMe);KSr=r(QSt,"__init__()"),QSt.forEach(t),ZSr=r(Aze," (throws an error)."),Aze.forEach(t),eRr=i(Wl),Ot=n(Wl,"DIV",{class:!0});var Yw=s(Ot);T(wx.$$.fragment,Yw),oRr=i(Yw),rMe=n(Yw,"P",{});var WSt=s(rMe);rRr=r(WSt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),WSt.forEach(t),tRr=i(Yw),qc=n(Yw,"P",{});var jre=s(qc);aRr=r(jre,`Note:
Loading a model from its configuration file does `),tMe=n(jre,"STRONG",{});var HSt=s(tMe);nRr=r(HSt,"not"),HSt.forEach(t),sRr=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=n(jre,"A",{href:!0});var USt=s(yK);lRr=r(USt,"from_pretrained()"),USt.forEach(t),iRr=r(jre," to load the model weights."),jre.forEach(t),dRr=i(Yw),T(hC.$$.fragment,Yw),Yw.forEach(t),cRr=i(Wl),Dr=n(Wl,"DIV",{class:!0});var Hl=s(Dr);T(Ax.$$.fragment,Hl),fRr=i(Hl),aMe=n(Hl,"P",{});var JSt=s(aMe);mRr=r(JSt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),JSt.forEach(t),gRr=i(Hl),bn=n(Hl,"P",{});var Kw=s(bn);hRr=r(Kw,"The model class to instantiate is selected based on the "),nMe=n(Kw,"CODE",{});var YSt=s(nMe);pRr=r(YSt,"model_type"),YSt.forEach(t),_Rr=r(Kw,` property of the config object (either
passed as an argument or loaded from `),sMe=n(Kw,"CODE",{});var KSt=s(sMe);uRr=r(KSt,"pretrained_model_name_or_path"),KSt.forEach(t),bRr=r(Kw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lMe=n(Kw,"CODE",{});var ZSt=s(lMe);vRr=r(ZSt,"pretrained_model_name_or_path"),ZSt.forEach(t),FRr=r(Kw,":"),Kw.forEach(t),TRr=i(Hl),iMe=n(Hl,"UL",{});var eRt=s(iMe);pC=n(eRt,"LI",{});var Bje=s(pC);dMe=n(Bje,"STRONG",{});var oRt=s(dMe);MRr=r(oRt,"vision-encoder-decoder"),oRt.forEach(t),ERr=r(Bje," \u2014 "),xK=n(Bje,"A",{href:!0});var rRt=s(xK);CRr=r(rRt,"TFVisionEncoderDecoderModel"),rRt.forEach(t),wRr=r(Bje," (Vision Encoder decoder model)"),Bje.forEach(t),eRt.forEach(t),ARr=i(Hl),T(_C.$$.fragment,Hl),Hl.forEach(t),Wl.forEach(t),bVe=i(f),jc=n(f,"H2",{class:!0});var Lze=s(jc);uC=n(Lze,"A",{id:!0,class:!0,href:!0});var tRt=s(uC);cMe=n(tRt,"SPAN",{});var aRt=s(cMe);T(Lx.$$.fragment,aRt),aRt.forEach(t),tRt.forEach(t),LRr=i(Lze),fMe=n(Lze,"SPAN",{});var nRt=s(fMe);yRr=r(nRt,"TFAutoModelForSpeechSeq2Seq"),nRt.forEach(t),Lze.forEach(t),vVe=i(f),gr=n(f,"DIV",{class:!0});var Ul=s(gr);T(yx.$$.fragment,Ul),xRr=i(Ul),Dc=n(Ul,"P",{});var Dre=s(Dc);$Rr=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=n(Dre,"A",{href:!0});var sRt=s($K);kRr=r(sRt,"from_pretrained()"),sRt.forEach(t),SRr=r(Dre," class method or the "),kK=n(Dre,"A",{href:!0});var lRt=s(kK);RRr=r(lRt,"from_config()"),lRt.forEach(t),PRr=r(Dre,` class
method.`),Dre.forEach(t),BRr=i(Ul),xx=n(Ul,"P",{});var yze=s(xx);IRr=r(yze,"This class cannot be instantiated directly using "),mMe=n(yze,"CODE",{});var iRt=s(mMe);NRr=r(iRt,"__init__()"),iRt.forEach(t),qRr=r(yze," (throws an error)."),yze.forEach(t),jRr=i(Ul),Vt=n(Ul,"DIV",{class:!0});var Zw=s(Vt);T($x.$$.fragment,Zw),DRr=i(Zw),gMe=n(Zw,"P",{});var dRt=s(gMe);GRr=r(dRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dRt.forEach(t),ORr=i(Zw),Gc=n(Zw,"P",{});var Gre=s(Gc);VRr=r(Gre,`Note:
Loading a model from its configuration file does `),hMe=n(Gre,"STRONG",{});var cRt=s(hMe);XRr=r(cRt,"not"),cRt.forEach(t),zRr=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(Gre,"A",{href:!0});var fRt=s(SK);QRr=r(fRt,"from_pretrained()"),fRt.forEach(t),WRr=r(Gre," to load the model weights."),Gre.forEach(t),HRr=i(Zw),T(bC.$$.fragment,Zw),Zw.forEach(t),URr=i(Ul),Gr=n(Ul,"DIV",{class:!0});var Jl=s(Gr);T(kx.$$.fragment,Jl),JRr=i(Jl),pMe=n(Jl,"P",{});var mRt=s(pMe);YRr=r(mRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),mRt.forEach(t),KRr=i(Jl),vn=n(Jl,"P",{});var eA=s(vn);ZRr=r(eA,"The model class to instantiate is selected based on the "),_Me=n(eA,"CODE",{});var gRt=s(_Me);ePr=r(gRt,"model_type"),gRt.forEach(t),oPr=r(eA,` property of the config object (either
passed as an argument or loaded from `),uMe=n(eA,"CODE",{});var hRt=s(uMe);rPr=r(hRt,"pretrained_model_name_or_path"),hRt.forEach(t),tPr=r(eA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bMe=n(eA,"CODE",{});var pRt=s(bMe);aPr=r(pRt,"pretrained_model_name_or_path"),pRt.forEach(t),nPr=r(eA,":"),eA.forEach(t),sPr=i(Jl),vMe=n(Jl,"UL",{});var _Rt=s(vMe);vC=n(_Rt,"LI",{});var Ije=s(vC);FMe=n(Ije,"STRONG",{});var uRt=s(FMe);lPr=r(uRt,"speech_to_text"),uRt.forEach(t),iPr=r(Ije," \u2014 "),RK=n(Ije,"A",{href:!0});var bRt=s(RK);dPr=r(bRt,"TFSpeech2TextForConditionalGeneration"),bRt.forEach(t),cPr=r(Ije," (Speech2Text model)"),Ije.forEach(t),_Rt.forEach(t),fPr=i(Jl),T(FC.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),FVe=i(f),Oc=n(f,"H2",{class:!0});var xze=s(Oc);TC=n(xze,"A",{id:!0,class:!0,href:!0});var vRt=s(TC);TMe=n(vRt,"SPAN",{});var FRt=s(TMe);T(Sx.$$.fragment,FRt),FRt.forEach(t),vRt.forEach(t),mPr=i(xze),MMe=n(xze,"SPAN",{});var TRt=s(MMe);gPr=r(TRt,"FlaxAutoModel"),TRt.forEach(t),xze.forEach(t),TVe=i(f),hr=n(f,"DIV",{class:!0});var Yl=s(hr);T(Rx.$$.fragment,Yl),hPr=i(Yl),Vc=n(Yl,"P",{});var Ore=s(Vc);pPr=r(Ore,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=n(Ore,"A",{href:!0});var MRt=s(PK);_Pr=r(MRt,"from_pretrained()"),MRt.forEach(t),uPr=r(Ore," class method or the "),BK=n(Ore,"A",{href:!0});var ERt=s(BK);bPr=r(ERt,"from_config()"),ERt.forEach(t),vPr=r(Ore,` class
method.`),Ore.forEach(t),FPr=i(Yl),Px=n(Yl,"P",{});var $ze=s(Px);TPr=r($ze,"This class cannot be instantiated directly using "),EMe=n($ze,"CODE",{});var CRt=s(EMe);MPr=r(CRt,"__init__()"),CRt.forEach(t),EPr=r($ze," (throws an error)."),$ze.forEach(t),CPr=i(Yl),Xt=n(Yl,"DIV",{class:!0});var oA=s(Xt);T(Bx.$$.fragment,oA),wPr=i(oA),CMe=n(oA,"P",{});var wRt=s(CMe);APr=r(wRt,"Instantiates one of the base model classes of the library from a configuration."),wRt.forEach(t),LPr=i(oA),Xc=n(oA,"P",{});var Vre=s(Xc);yPr=r(Vre,`Note:
Loading a model from its configuration file does `),wMe=n(Vre,"STRONG",{});var ARt=s(wMe);xPr=r(ARt,"not"),ARt.forEach(t),$Pr=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(Vre,"A",{href:!0});var LRt=s(IK);kPr=r(LRt,"from_pretrained()"),LRt.forEach(t),SPr=r(Vre," to load the model weights."),Vre.forEach(t),RPr=i(oA),T(MC.$$.fragment,oA),oA.forEach(t),PPr=i(Yl),Or=n(Yl,"DIV",{class:!0});var Kl=s(Or);T(Ix.$$.fragment,Kl),BPr=i(Kl),AMe=n(Kl,"P",{});var yRt=s(AMe);IPr=r(yRt,"Instantiate one of the base model classes of the library from a pretrained model."),yRt.forEach(t),NPr=i(Kl),Fn=n(Kl,"P",{});var rA=s(Fn);qPr=r(rA,"The model class to instantiate is selected based on the "),LMe=n(rA,"CODE",{});var xRt=s(LMe);jPr=r(xRt,"model_type"),xRt.forEach(t),DPr=r(rA,` property of the config object (either
passed as an argument or loaded from `),yMe=n(rA,"CODE",{});var $Rt=s(yMe);GPr=r($Rt,"pretrained_model_name_or_path"),$Rt.forEach(t),OPr=r(rA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=n(rA,"CODE",{});var kRt=s(xMe);VPr=r(kRt,"pretrained_model_name_or_path"),kRt.forEach(t),XPr=r(rA,":"),rA.forEach(t),zPr=i(Kl),oe=n(Kl,"UL",{});var ae=s(oe);EC=n(ae,"LI",{});var Nje=s(EC);$Me=n(Nje,"STRONG",{});var SRt=s($Me);QPr=r(SRt,"albert"),SRt.forEach(t),WPr=r(Nje," \u2014 "),NK=n(Nje,"A",{href:!0});var RRt=s(NK);HPr=r(RRt,"FlaxAlbertModel"),RRt.forEach(t),UPr=r(Nje," (ALBERT model)"),Nje.forEach(t),JPr=i(ae),CC=n(ae,"LI",{});var qje=s(CC);kMe=n(qje,"STRONG",{});var PRt=s(kMe);YPr=r(PRt,"bart"),PRt.forEach(t),KPr=r(qje," \u2014 "),qK=n(qje,"A",{href:!0});var BRt=s(qK);ZPr=r(BRt,"FlaxBartModel"),BRt.forEach(t),eBr=r(qje," (BART model)"),qje.forEach(t),oBr=i(ae),wC=n(ae,"LI",{});var jje=s(wC);SMe=n(jje,"STRONG",{});var IRt=s(SMe);rBr=r(IRt,"beit"),IRt.forEach(t),tBr=r(jje," \u2014 "),jK=n(jje,"A",{href:!0});var NRt=s(jK);aBr=r(NRt,"FlaxBeitModel"),NRt.forEach(t),nBr=r(jje," (BEiT model)"),jje.forEach(t),sBr=i(ae),AC=n(ae,"LI",{});var Dje=s(AC);RMe=n(Dje,"STRONG",{});var qRt=s(RMe);lBr=r(qRt,"bert"),qRt.forEach(t),iBr=r(Dje," \u2014 "),DK=n(Dje,"A",{href:!0});var jRt=s(DK);dBr=r(jRt,"FlaxBertModel"),jRt.forEach(t),cBr=r(Dje," (BERT model)"),Dje.forEach(t),fBr=i(ae),LC=n(ae,"LI",{});var Gje=s(LC);PMe=n(Gje,"STRONG",{});var DRt=s(PMe);mBr=r(DRt,"big_bird"),DRt.forEach(t),gBr=r(Gje," \u2014 "),GK=n(Gje,"A",{href:!0});var GRt=s(GK);hBr=r(GRt,"FlaxBigBirdModel"),GRt.forEach(t),pBr=r(Gje," (BigBird model)"),Gje.forEach(t),_Br=i(ae),yC=n(ae,"LI",{});var Oje=s(yC);BMe=n(Oje,"STRONG",{});var ORt=s(BMe);uBr=r(ORt,"blenderbot"),ORt.forEach(t),bBr=r(Oje," \u2014 "),OK=n(Oje,"A",{href:!0});var VRt=s(OK);vBr=r(VRt,"FlaxBlenderbotModel"),VRt.forEach(t),FBr=r(Oje," (Blenderbot model)"),Oje.forEach(t),TBr=i(ae),xC=n(ae,"LI",{});var Vje=s(xC);IMe=n(Vje,"STRONG",{});var XRt=s(IMe);MBr=r(XRt,"blenderbot-small"),XRt.forEach(t),EBr=r(Vje," \u2014 "),VK=n(Vje,"A",{href:!0});var zRt=s(VK);CBr=r(zRt,"FlaxBlenderbotSmallModel"),zRt.forEach(t),wBr=r(Vje," (BlenderbotSmall model)"),Vje.forEach(t),ABr=i(ae),$C=n(ae,"LI",{});var Xje=s($C);NMe=n(Xje,"STRONG",{});var QRt=s(NMe);LBr=r(QRt,"clip"),QRt.forEach(t),yBr=r(Xje," \u2014 "),XK=n(Xje,"A",{href:!0});var WRt=s(XK);xBr=r(WRt,"FlaxCLIPModel"),WRt.forEach(t),$Br=r(Xje," (CLIP model)"),Xje.forEach(t),kBr=i(ae),kC=n(ae,"LI",{});var zje=s(kC);qMe=n(zje,"STRONG",{});var HRt=s(qMe);SBr=r(HRt,"distilbert"),HRt.forEach(t),RBr=r(zje," \u2014 "),zK=n(zje,"A",{href:!0});var URt=s(zK);PBr=r(URt,"FlaxDistilBertModel"),URt.forEach(t),BBr=r(zje," (DistilBERT model)"),zje.forEach(t),IBr=i(ae),SC=n(ae,"LI",{});var Qje=s(SC);jMe=n(Qje,"STRONG",{});var JRt=s(jMe);NBr=r(JRt,"electra"),JRt.forEach(t),qBr=r(Qje," \u2014 "),QK=n(Qje,"A",{href:!0});var YRt=s(QK);jBr=r(YRt,"FlaxElectraModel"),YRt.forEach(t),DBr=r(Qje," (ELECTRA model)"),Qje.forEach(t),GBr=i(ae),RC=n(ae,"LI",{});var Wje=s(RC);DMe=n(Wje,"STRONG",{});var KRt=s(DMe);OBr=r(KRt,"gpt2"),KRt.forEach(t),VBr=r(Wje," \u2014 "),WK=n(Wje,"A",{href:!0});var ZRt=s(WK);XBr=r(ZRt,"FlaxGPT2Model"),ZRt.forEach(t),zBr=r(Wje," (OpenAI GPT-2 model)"),Wje.forEach(t),QBr=i(ae),PC=n(ae,"LI",{});var Hje=s(PC);GMe=n(Hje,"STRONG",{});var ePt=s(GMe);WBr=r(ePt,"gpt_neo"),ePt.forEach(t),HBr=r(Hje," \u2014 "),HK=n(Hje,"A",{href:!0});var oPt=s(HK);UBr=r(oPt,"FlaxGPTNeoModel"),oPt.forEach(t),JBr=r(Hje," (GPT Neo model)"),Hje.forEach(t),YBr=i(ae),BC=n(ae,"LI",{});var Uje=s(BC);OMe=n(Uje,"STRONG",{});var rPt=s(OMe);KBr=r(rPt,"gptj"),rPt.forEach(t),ZBr=r(Uje," \u2014 "),UK=n(Uje,"A",{href:!0});var tPt=s(UK);eIr=r(tPt,"FlaxGPTJModel"),tPt.forEach(t),oIr=r(Uje," (GPT-J model)"),Uje.forEach(t),rIr=i(ae),IC=n(ae,"LI",{});var Jje=s(IC);VMe=n(Jje,"STRONG",{});var aPt=s(VMe);tIr=r(aPt,"longt5"),aPt.forEach(t),aIr=r(Jje," \u2014 "),JK=n(Jje,"A",{href:!0});var nPt=s(JK);nIr=r(nPt,"FlaxLongT5Model"),nPt.forEach(t),sIr=r(Jje," (LongT5 model)"),Jje.forEach(t),lIr=i(ae),NC=n(ae,"LI",{});var Yje=s(NC);XMe=n(Yje,"STRONG",{});var sPt=s(XMe);iIr=r(sPt,"marian"),sPt.forEach(t),dIr=r(Yje," \u2014 "),YK=n(Yje,"A",{href:!0});var lPt=s(YK);cIr=r(lPt,"FlaxMarianModel"),lPt.forEach(t),fIr=r(Yje," (Marian model)"),Yje.forEach(t),mIr=i(ae),qC=n(ae,"LI",{});var Kje=s(qC);zMe=n(Kje,"STRONG",{});var iPt=s(zMe);gIr=r(iPt,"mbart"),iPt.forEach(t),hIr=r(Kje," \u2014 "),KK=n(Kje,"A",{href:!0});var dPt=s(KK);pIr=r(dPt,"FlaxMBartModel"),dPt.forEach(t),_Ir=r(Kje," (mBART model)"),Kje.forEach(t),uIr=i(ae),jC=n(ae,"LI",{});var Zje=s(jC);QMe=n(Zje,"STRONG",{});var cPt=s(QMe);bIr=r(cPt,"mt5"),cPt.forEach(t),vIr=r(Zje," \u2014 "),ZK=n(Zje,"A",{href:!0});var fPt=s(ZK);FIr=r(fPt,"FlaxMT5Model"),fPt.forEach(t),TIr=r(Zje," (MT5 model)"),Zje.forEach(t),MIr=i(ae),DC=n(ae,"LI",{});var eDe=s(DC);WMe=n(eDe,"STRONG",{});var mPt=s(WMe);EIr=r(mPt,"opt"),mPt.forEach(t),CIr=r(eDe," \u2014 "),eZ=n(eDe,"A",{href:!0});var gPt=s(eZ);wIr=r(gPt,"FlaxOPTModel"),gPt.forEach(t),AIr=r(eDe," (OPT model)"),eDe.forEach(t),LIr=i(ae),GC=n(ae,"LI",{});var oDe=s(GC);HMe=n(oDe,"STRONG",{});var hPt=s(HMe);yIr=r(hPt,"pegasus"),hPt.forEach(t),xIr=r(oDe," \u2014 "),oZ=n(oDe,"A",{href:!0});var pPt=s(oZ);$Ir=r(pPt,"FlaxPegasusModel"),pPt.forEach(t),kIr=r(oDe," (Pegasus model)"),oDe.forEach(t),SIr=i(ae),OC=n(ae,"LI",{});var rDe=s(OC);UMe=n(rDe,"STRONG",{});var _Pt=s(UMe);RIr=r(_Pt,"roberta"),_Pt.forEach(t),PIr=r(rDe," \u2014 "),rZ=n(rDe,"A",{href:!0});var uPt=s(rZ);BIr=r(uPt,"FlaxRobertaModel"),uPt.forEach(t),IIr=r(rDe," (RoBERTa model)"),rDe.forEach(t),NIr=i(ae),VC=n(ae,"LI",{});var tDe=s(VC);JMe=n(tDe,"STRONG",{});var bPt=s(JMe);qIr=r(bPt,"roformer"),bPt.forEach(t),jIr=r(tDe," \u2014 "),tZ=n(tDe,"A",{href:!0});var vPt=s(tZ);DIr=r(vPt,"FlaxRoFormerModel"),vPt.forEach(t),GIr=r(tDe," (RoFormer model)"),tDe.forEach(t),OIr=i(ae),XC=n(ae,"LI",{});var aDe=s(XC);YMe=n(aDe,"STRONG",{});var FPt=s(YMe);VIr=r(FPt,"t5"),FPt.forEach(t),XIr=r(aDe," \u2014 "),aZ=n(aDe,"A",{href:!0});var TPt=s(aZ);zIr=r(TPt,"FlaxT5Model"),TPt.forEach(t),QIr=r(aDe," (T5 model)"),aDe.forEach(t),WIr=i(ae),zC=n(ae,"LI",{});var nDe=s(zC);KMe=n(nDe,"STRONG",{});var MPt=s(KMe);HIr=r(MPt,"vision-text-dual-encoder"),MPt.forEach(t),UIr=r(nDe," \u2014 "),nZ=n(nDe,"A",{href:!0});var EPt=s(nZ);JIr=r(EPt,"FlaxVisionTextDualEncoderModel"),EPt.forEach(t),YIr=r(nDe," (VisionTextDualEncoder model)"),nDe.forEach(t),KIr=i(ae),QC=n(ae,"LI",{});var sDe=s(QC);ZMe=n(sDe,"STRONG",{});var CPt=s(ZMe);ZIr=r(CPt,"vit"),CPt.forEach(t),eNr=r(sDe," \u2014 "),sZ=n(sDe,"A",{href:!0});var wPt=s(sZ);oNr=r(wPt,"FlaxViTModel"),wPt.forEach(t),rNr=r(sDe," (ViT model)"),sDe.forEach(t),tNr=i(ae),WC=n(ae,"LI",{});var lDe=s(WC);eEe=n(lDe,"STRONG",{});var APt=s(eEe);aNr=r(APt,"wav2vec2"),APt.forEach(t),nNr=r(lDe," \u2014 "),lZ=n(lDe,"A",{href:!0});var LPt=s(lZ);sNr=r(LPt,"FlaxWav2Vec2Model"),LPt.forEach(t),lNr=r(lDe," (Wav2Vec2 model)"),lDe.forEach(t),iNr=i(ae),HC=n(ae,"LI",{});var iDe=s(HC);oEe=n(iDe,"STRONG",{});var yPt=s(oEe);dNr=r(yPt,"xglm"),yPt.forEach(t),cNr=r(iDe," \u2014 "),iZ=n(iDe,"A",{href:!0});var xPt=s(iZ);fNr=r(xPt,"FlaxXGLMModel"),xPt.forEach(t),mNr=r(iDe," (XGLM model)"),iDe.forEach(t),gNr=i(ae),UC=n(ae,"LI",{});var dDe=s(UC);rEe=n(dDe,"STRONG",{});var $Pt=s(rEe);hNr=r($Pt,"xlm-roberta"),$Pt.forEach(t),pNr=r(dDe," \u2014 "),dZ=n(dDe,"A",{href:!0});var kPt=s(dZ);_Nr=r(kPt,"FlaxXLMRobertaModel"),kPt.forEach(t),uNr=r(dDe," (XLM-RoBERTa model)"),dDe.forEach(t),ae.forEach(t),bNr=i(Kl),T(JC.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),MVe=i(f),zc=n(f,"H2",{class:!0});var kze=s(zc);YC=n(kze,"A",{id:!0,class:!0,href:!0});var SPt=s(YC);tEe=n(SPt,"SPAN",{});var RPt=s(tEe);T(Nx.$$.fragment,RPt),RPt.forEach(t),SPt.forEach(t),vNr=i(kze),aEe=n(kze,"SPAN",{});var PPt=s(aEe);FNr=r(PPt,"FlaxAutoModelForCausalLM"),PPt.forEach(t),kze.forEach(t),EVe=i(f),pr=n(f,"DIV",{class:!0});var Zl=s(pr);T(qx.$$.fragment,Zl),TNr=i(Zl),Qc=n(Zl,"P",{});var Xre=s(Qc);MNr=r(Xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=n(Xre,"A",{href:!0});var BPt=s(cZ);ENr=r(BPt,"from_pretrained()"),BPt.forEach(t),CNr=r(Xre," class method or the "),fZ=n(Xre,"A",{href:!0});var IPt=s(fZ);wNr=r(IPt,"from_config()"),IPt.forEach(t),ANr=r(Xre,` class
method.`),Xre.forEach(t),LNr=i(Zl),jx=n(Zl,"P",{});var Sze=s(jx);yNr=r(Sze,"This class cannot be instantiated directly using "),nEe=n(Sze,"CODE",{});var NPt=s(nEe);xNr=r(NPt,"__init__()"),NPt.forEach(t),$Nr=r(Sze," (throws an error)."),Sze.forEach(t),kNr=i(Zl),zt=n(Zl,"DIV",{class:!0});var tA=s(zt);T(Dx.$$.fragment,tA),SNr=i(tA),sEe=n(tA,"P",{});var qPt=s(sEe);RNr=r(qPt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qPt.forEach(t),PNr=i(tA),Wc=n(tA,"P",{});var zre=s(Wc);BNr=r(zre,`Note:
Loading a model from its configuration file does `),lEe=n(zre,"STRONG",{});var jPt=s(lEe);INr=r(jPt,"not"),jPt.forEach(t),NNr=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=n(zre,"A",{href:!0});var DPt=s(mZ);qNr=r(DPt,"from_pretrained()"),DPt.forEach(t),jNr=r(zre," to load the model weights."),zre.forEach(t),DNr=i(tA),T(KC.$$.fragment,tA),tA.forEach(t),GNr=i(Zl),Vr=n(Zl,"DIV",{class:!0});var ei=s(Vr);T(Gx.$$.fragment,ei),ONr=i(ei),iEe=n(ei,"P",{});var GPt=s(iEe);VNr=r(GPt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GPt.forEach(t),XNr=i(ei),Tn=n(ei,"P",{});var aA=s(Tn);zNr=r(aA,"The model class to instantiate is selected based on the "),dEe=n(aA,"CODE",{});var OPt=s(dEe);QNr=r(OPt,"model_type"),OPt.forEach(t),WNr=r(aA,` property of the config object (either
passed as an argument or loaded from `),cEe=n(aA,"CODE",{});var VPt=s(cEe);HNr=r(VPt,"pretrained_model_name_or_path"),VPt.forEach(t),UNr=r(aA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=n(aA,"CODE",{});var XPt=s(fEe);JNr=r(XPt,"pretrained_model_name_or_path"),XPt.forEach(t),YNr=r(aA,":"),aA.forEach(t),KNr=i(ei),xe=n(ei,"UL",{});var Ne=s(xe);ZC=n(Ne,"LI",{});var cDe=s(ZC);mEe=n(cDe,"STRONG",{});var zPt=s(mEe);ZNr=r(zPt,"bart"),zPt.forEach(t),eqr=r(cDe," \u2014 "),gZ=n(cDe,"A",{href:!0});var QPt=s(gZ);oqr=r(QPt,"FlaxBartForCausalLM"),QPt.forEach(t),rqr=r(cDe," (BART model)"),cDe.forEach(t),tqr=i(Ne),e5=n(Ne,"LI",{});var fDe=s(e5);gEe=n(fDe,"STRONG",{});var WPt=s(gEe);aqr=r(WPt,"bert"),WPt.forEach(t),nqr=r(fDe," \u2014 "),hZ=n(fDe,"A",{href:!0});var HPt=s(hZ);sqr=r(HPt,"FlaxBertForCausalLM"),HPt.forEach(t),lqr=r(fDe," (BERT model)"),fDe.forEach(t),iqr=i(Ne),o5=n(Ne,"LI",{});var mDe=s(o5);hEe=n(mDe,"STRONG",{});var UPt=s(hEe);dqr=r(UPt,"big_bird"),UPt.forEach(t),cqr=r(mDe," \u2014 "),pZ=n(mDe,"A",{href:!0});var JPt=s(pZ);fqr=r(JPt,"FlaxBigBirdForCausalLM"),JPt.forEach(t),mqr=r(mDe," (BigBird model)"),mDe.forEach(t),gqr=i(Ne),r5=n(Ne,"LI",{});var gDe=s(r5);pEe=n(gDe,"STRONG",{});var YPt=s(pEe);hqr=r(YPt,"electra"),YPt.forEach(t),pqr=r(gDe," \u2014 "),_Z=n(gDe,"A",{href:!0});var KPt=s(_Z);_qr=r(KPt,"FlaxElectraForCausalLM"),KPt.forEach(t),uqr=r(gDe," (ELECTRA model)"),gDe.forEach(t),bqr=i(Ne),t5=n(Ne,"LI",{});var hDe=s(t5);_Ee=n(hDe,"STRONG",{});var ZPt=s(_Ee);vqr=r(ZPt,"gpt2"),ZPt.forEach(t),Fqr=r(hDe," \u2014 "),uZ=n(hDe,"A",{href:!0});var eBt=s(uZ);Tqr=r(eBt,"FlaxGPT2LMHeadModel"),eBt.forEach(t),Mqr=r(hDe," (OpenAI GPT-2 model)"),hDe.forEach(t),Eqr=i(Ne),a5=n(Ne,"LI",{});var pDe=s(a5);uEe=n(pDe,"STRONG",{});var oBt=s(uEe);Cqr=r(oBt,"gpt_neo"),oBt.forEach(t),wqr=r(pDe," \u2014 "),bZ=n(pDe,"A",{href:!0});var rBt=s(bZ);Aqr=r(rBt,"FlaxGPTNeoForCausalLM"),rBt.forEach(t),Lqr=r(pDe," (GPT Neo model)"),pDe.forEach(t),yqr=i(Ne),n5=n(Ne,"LI",{});var _De=s(n5);bEe=n(_De,"STRONG",{});var tBt=s(bEe);xqr=r(tBt,"gptj"),tBt.forEach(t),$qr=r(_De," \u2014 "),vZ=n(_De,"A",{href:!0});var aBt=s(vZ);kqr=r(aBt,"FlaxGPTJForCausalLM"),aBt.forEach(t),Sqr=r(_De," (GPT-J model)"),_De.forEach(t),Rqr=i(Ne),s5=n(Ne,"LI",{});var uDe=s(s5);vEe=n(uDe,"STRONG",{});var nBt=s(vEe);Pqr=r(nBt,"opt"),nBt.forEach(t),Bqr=r(uDe," \u2014 "),FZ=n(uDe,"A",{href:!0});var sBt=s(FZ);Iqr=r(sBt,"FlaxOPTForCausalLM"),sBt.forEach(t),Nqr=r(uDe," (OPT model)"),uDe.forEach(t),qqr=i(Ne),l5=n(Ne,"LI",{});var bDe=s(l5);FEe=n(bDe,"STRONG",{});var lBt=s(FEe);jqr=r(lBt,"roberta"),lBt.forEach(t),Dqr=r(bDe," \u2014 "),TZ=n(bDe,"A",{href:!0});var iBt=s(TZ);Gqr=r(iBt,"FlaxRobertaForCausalLM"),iBt.forEach(t),Oqr=r(bDe," (RoBERTa model)"),bDe.forEach(t),Vqr=i(Ne),i5=n(Ne,"LI",{});var vDe=s(i5);TEe=n(vDe,"STRONG",{});var dBt=s(TEe);Xqr=r(dBt,"xglm"),dBt.forEach(t),zqr=r(vDe," \u2014 "),MZ=n(vDe,"A",{href:!0});var cBt=s(MZ);Qqr=r(cBt,"FlaxXGLMForCausalLM"),cBt.forEach(t),Wqr=r(vDe," (XGLM model)"),vDe.forEach(t),Ne.forEach(t),Hqr=i(ei),T(d5.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),CVe=i(f),Hc=n(f,"H2",{class:!0});var Rze=s(Hc);c5=n(Rze,"A",{id:!0,class:!0,href:!0});var fBt=s(c5);MEe=n(fBt,"SPAN",{});var mBt=s(MEe);T(Ox.$$.fragment,mBt),mBt.forEach(t),fBt.forEach(t),Uqr=i(Rze),EEe=n(Rze,"SPAN",{});var gBt=s(EEe);Jqr=r(gBt,"FlaxAutoModelForPreTraining"),gBt.forEach(t),Rze.forEach(t),wVe=i(f),_r=n(f,"DIV",{class:!0});var oi=s(_r);T(Vx.$$.fragment,oi),Yqr=i(oi),Uc=n(oi,"P",{});var Qre=s(Uc);Kqr=r(Qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=n(Qre,"A",{href:!0});var hBt=s(EZ);Zqr=r(hBt,"from_pretrained()"),hBt.forEach(t),ejr=r(Qre," class method or the "),CZ=n(Qre,"A",{href:!0});var pBt=s(CZ);ojr=r(pBt,"from_config()"),pBt.forEach(t),rjr=r(Qre,` class
method.`),Qre.forEach(t),tjr=i(oi),Xx=n(oi,"P",{});var Pze=s(Xx);ajr=r(Pze,"This class cannot be instantiated directly using "),CEe=n(Pze,"CODE",{});var _Bt=s(CEe);njr=r(_Bt,"__init__()"),_Bt.forEach(t),sjr=r(Pze," (throws an error)."),Pze.forEach(t),ljr=i(oi),Qt=n(oi,"DIV",{class:!0});var nA=s(Qt);T(zx.$$.fragment,nA),ijr=i(nA),wEe=n(nA,"P",{});var uBt=s(wEe);djr=r(uBt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),uBt.forEach(t),cjr=i(nA),Jc=n(nA,"P",{});var Wre=s(Jc);fjr=r(Wre,`Note:
Loading a model from its configuration file does `),AEe=n(Wre,"STRONG",{});var bBt=s(AEe);mjr=r(bBt,"not"),bBt.forEach(t),gjr=r(Wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=n(Wre,"A",{href:!0});var vBt=s(wZ);hjr=r(vBt,"from_pretrained()"),vBt.forEach(t),pjr=r(Wre," to load the model weights."),Wre.forEach(t),_jr=i(nA),T(f5.$$.fragment,nA),nA.forEach(t),ujr=i(oi),Xr=n(oi,"DIV",{class:!0});var ri=s(Xr);T(Qx.$$.fragment,ri),bjr=i(ri),LEe=n(ri,"P",{});var FBt=s(LEe);vjr=r(FBt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),FBt.forEach(t),Fjr=i(ri),Mn=n(ri,"P",{});var sA=s(Mn);Tjr=r(sA,"The model class to instantiate is selected based on the "),yEe=n(sA,"CODE",{});var TBt=s(yEe);Mjr=r(TBt,"model_type"),TBt.forEach(t),Ejr=r(sA,` property of the config object (either
passed as an argument or loaded from `),xEe=n(sA,"CODE",{});var MBt=s(xEe);Cjr=r(MBt,"pretrained_model_name_or_path"),MBt.forEach(t),wjr=r(sA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ee=n(sA,"CODE",{});var EBt=s($Ee);Ajr=r(EBt,"pretrained_model_name_or_path"),EBt.forEach(t),Ljr=r(sA,":"),sA.forEach(t),yjr=i(ri),Ee=n(ri,"UL",{});var we=s(Ee);m5=n(we,"LI",{});var FDe=s(m5);kEe=n(FDe,"STRONG",{});var CBt=s(kEe);xjr=r(CBt,"albert"),CBt.forEach(t),$jr=r(FDe," \u2014 "),AZ=n(FDe,"A",{href:!0});var wBt=s(AZ);kjr=r(wBt,"FlaxAlbertForPreTraining"),wBt.forEach(t),Sjr=r(FDe," (ALBERT model)"),FDe.forEach(t),Rjr=i(we),g5=n(we,"LI",{});var TDe=s(g5);SEe=n(TDe,"STRONG",{});var ABt=s(SEe);Pjr=r(ABt,"bart"),ABt.forEach(t),Bjr=r(TDe," \u2014 "),LZ=n(TDe,"A",{href:!0});var LBt=s(LZ);Ijr=r(LBt,"FlaxBartForConditionalGeneration"),LBt.forEach(t),Njr=r(TDe," (BART model)"),TDe.forEach(t),qjr=i(we),h5=n(we,"LI",{});var MDe=s(h5);REe=n(MDe,"STRONG",{});var yBt=s(REe);jjr=r(yBt,"bert"),yBt.forEach(t),Djr=r(MDe," \u2014 "),yZ=n(MDe,"A",{href:!0});var xBt=s(yZ);Gjr=r(xBt,"FlaxBertForPreTraining"),xBt.forEach(t),Ojr=r(MDe," (BERT model)"),MDe.forEach(t),Vjr=i(we),p5=n(we,"LI",{});var EDe=s(p5);PEe=n(EDe,"STRONG",{});var $Bt=s(PEe);Xjr=r($Bt,"big_bird"),$Bt.forEach(t),zjr=r(EDe," \u2014 "),xZ=n(EDe,"A",{href:!0});var kBt=s(xZ);Qjr=r(kBt,"FlaxBigBirdForPreTraining"),kBt.forEach(t),Wjr=r(EDe," (BigBird model)"),EDe.forEach(t),Hjr=i(we),_5=n(we,"LI",{});var CDe=s(_5);BEe=n(CDe,"STRONG",{});var SBt=s(BEe);Ujr=r(SBt,"electra"),SBt.forEach(t),Jjr=r(CDe," \u2014 "),$Z=n(CDe,"A",{href:!0});var RBt=s($Z);Yjr=r(RBt,"FlaxElectraForPreTraining"),RBt.forEach(t),Kjr=r(CDe," (ELECTRA model)"),CDe.forEach(t),Zjr=i(we),u5=n(we,"LI",{});var wDe=s(u5);IEe=n(wDe,"STRONG",{});var PBt=s(IEe);eDr=r(PBt,"longt5"),PBt.forEach(t),oDr=r(wDe," \u2014 "),kZ=n(wDe,"A",{href:!0});var BBt=s(kZ);rDr=r(BBt,"FlaxLongT5ForConditionalGeneration"),BBt.forEach(t),tDr=r(wDe," (LongT5 model)"),wDe.forEach(t),aDr=i(we),b5=n(we,"LI",{});var ADe=s(b5);NEe=n(ADe,"STRONG",{});var IBt=s(NEe);nDr=r(IBt,"mbart"),IBt.forEach(t),sDr=r(ADe," \u2014 "),SZ=n(ADe,"A",{href:!0});var NBt=s(SZ);lDr=r(NBt,"FlaxMBartForConditionalGeneration"),NBt.forEach(t),iDr=r(ADe," (mBART model)"),ADe.forEach(t),dDr=i(we),v5=n(we,"LI",{});var LDe=s(v5);qEe=n(LDe,"STRONG",{});var qBt=s(qEe);cDr=r(qBt,"mt5"),qBt.forEach(t),fDr=r(LDe," \u2014 "),RZ=n(LDe,"A",{href:!0});var jBt=s(RZ);mDr=r(jBt,"FlaxMT5ForConditionalGeneration"),jBt.forEach(t),gDr=r(LDe," (MT5 model)"),LDe.forEach(t),hDr=i(we),F5=n(we,"LI",{});var yDe=s(F5);jEe=n(yDe,"STRONG",{});var DBt=s(jEe);pDr=r(DBt,"roberta"),DBt.forEach(t),_Dr=r(yDe," \u2014 "),PZ=n(yDe,"A",{href:!0});var GBt=s(PZ);uDr=r(GBt,"FlaxRobertaForMaskedLM"),GBt.forEach(t),bDr=r(yDe," (RoBERTa model)"),yDe.forEach(t),vDr=i(we),T5=n(we,"LI",{});var xDe=s(T5);DEe=n(xDe,"STRONG",{});var OBt=s(DEe);FDr=r(OBt,"roformer"),OBt.forEach(t),TDr=r(xDe," \u2014 "),BZ=n(xDe,"A",{href:!0});var VBt=s(BZ);MDr=r(VBt,"FlaxRoFormerForMaskedLM"),VBt.forEach(t),EDr=r(xDe," (RoFormer model)"),xDe.forEach(t),CDr=i(we),M5=n(we,"LI",{});var $De=s(M5);GEe=n($De,"STRONG",{});var XBt=s(GEe);wDr=r(XBt,"t5"),XBt.forEach(t),ADr=r($De," \u2014 "),IZ=n($De,"A",{href:!0});var zBt=s(IZ);LDr=r(zBt,"FlaxT5ForConditionalGeneration"),zBt.forEach(t),yDr=r($De," (T5 model)"),$De.forEach(t),xDr=i(we),E5=n(we,"LI",{});var kDe=s(E5);OEe=n(kDe,"STRONG",{});var QBt=s(OEe);$Dr=r(QBt,"wav2vec2"),QBt.forEach(t),kDr=r(kDe," \u2014 "),NZ=n(kDe,"A",{href:!0});var WBt=s(NZ);SDr=r(WBt,"FlaxWav2Vec2ForPreTraining"),WBt.forEach(t),RDr=r(kDe," (Wav2Vec2 model)"),kDe.forEach(t),PDr=i(we),C5=n(we,"LI",{});var SDe=s(C5);VEe=n(SDe,"STRONG",{});var HBt=s(VEe);BDr=r(HBt,"xlm-roberta"),HBt.forEach(t),IDr=r(SDe," \u2014 "),qZ=n(SDe,"A",{href:!0});var UBt=s(qZ);NDr=r(UBt,"FlaxXLMRobertaForMaskedLM"),UBt.forEach(t),qDr=r(SDe," (XLM-RoBERTa model)"),SDe.forEach(t),we.forEach(t),jDr=i(ri),T(w5.$$.fragment,ri),ri.forEach(t),oi.forEach(t),AVe=i(f),Yc=n(f,"H2",{class:!0});var Bze=s(Yc);A5=n(Bze,"A",{id:!0,class:!0,href:!0});var JBt=s(A5);XEe=n(JBt,"SPAN",{});var YBt=s(XEe);T(Wx.$$.fragment,YBt),YBt.forEach(t),JBt.forEach(t),DDr=i(Bze),zEe=n(Bze,"SPAN",{});var KBt=s(zEe);GDr=r(KBt,"FlaxAutoModelForMaskedLM"),KBt.forEach(t),Bze.forEach(t),LVe=i(f),ur=n(f,"DIV",{class:!0});var ti=s(ur);T(Hx.$$.fragment,ti),ODr=i(ti),Kc=n(ti,"P",{});var Hre=s(Kc);VDr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=n(Hre,"A",{href:!0});var ZBt=s(jZ);XDr=r(ZBt,"from_pretrained()"),ZBt.forEach(t),zDr=r(Hre," class method or the "),DZ=n(Hre,"A",{href:!0});var eIt=s(DZ);QDr=r(eIt,"from_config()"),eIt.forEach(t),WDr=r(Hre,` class
method.`),Hre.forEach(t),HDr=i(ti),Ux=n(ti,"P",{});var Ize=s(Ux);UDr=r(Ize,"This class cannot be instantiated directly using "),QEe=n(Ize,"CODE",{});var oIt=s(QEe);JDr=r(oIt,"__init__()"),oIt.forEach(t),YDr=r(Ize," (throws an error)."),Ize.forEach(t),KDr=i(ti),Wt=n(ti,"DIV",{class:!0});var lA=s(Wt);T(Jx.$$.fragment,lA),ZDr=i(lA),WEe=n(lA,"P",{});var rIt=s(WEe);eGr=r(rIt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rIt.forEach(t),oGr=i(lA),Zc=n(lA,"P",{});var Ure=s(Zc);rGr=r(Ure,`Note:
Loading a model from its configuration file does `),HEe=n(Ure,"STRONG",{});var tIt=s(HEe);tGr=r(tIt,"not"),tIt.forEach(t),aGr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=n(Ure,"A",{href:!0});var aIt=s(GZ);nGr=r(aIt,"from_pretrained()"),aIt.forEach(t),sGr=r(Ure," to load the model weights."),Ure.forEach(t),lGr=i(lA),T(L5.$$.fragment,lA),lA.forEach(t),iGr=i(ti),zr=n(ti,"DIV",{class:!0});var ai=s(zr);T(Yx.$$.fragment,ai),dGr=i(ai),UEe=n(ai,"P",{});var nIt=s(UEe);cGr=r(nIt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),nIt.forEach(t),fGr=i(ai),En=n(ai,"P",{});var iA=s(En);mGr=r(iA,"The model class to instantiate is selected based on the "),JEe=n(iA,"CODE",{});var sIt=s(JEe);gGr=r(sIt,"model_type"),sIt.forEach(t),hGr=r(iA,` property of the config object (either
passed as an argument or loaded from `),YEe=n(iA,"CODE",{});var lIt=s(YEe);pGr=r(lIt,"pretrained_model_name_or_path"),lIt.forEach(t),_Gr=r(iA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KEe=n(iA,"CODE",{});var iIt=s(KEe);uGr=r(iIt,"pretrained_model_name_or_path"),iIt.forEach(t),bGr=r(iA,":"),iA.forEach(t),vGr=i(ai),$e=n(ai,"UL",{});var qe=s($e);y5=n(qe,"LI",{});var RDe=s(y5);ZEe=n(RDe,"STRONG",{});var dIt=s(ZEe);FGr=r(dIt,"albert"),dIt.forEach(t),TGr=r(RDe," \u2014 "),OZ=n(RDe,"A",{href:!0});var cIt=s(OZ);MGr=r(cIt,"FlaxAlbertForMaskedLM"),cIt.forEach(t),EGr=r(RDe," (ALBERT model)"),RDe.forEach(t),CGr=i(qe),x5=n(qe,"LI",{});var PDe=s(x5);eCe=n(PDe,"STRONG",{});var fIt=s(eCe);wGr=r(fIt,"bart"),fIt.forEach(t),AGr=r(PDe," \u2014 "),VZ=n(PDe,"A",{href:!0});var mIt=s(VZ);LGr=r(mIt,"FlaxBartForConditionalGeneration"),mIt.forEach(t),yGr=r(PDe," (BART model)"),PDe.forEach(t),xGr=i(qe),$5=n(qe,"LI",{});var BDe=s($5);oCe=n(BDe,"STRONG",{});var gIt=s(oCe);$Gr=r(gIt,"bert"),gIt.forEach(t),kGr=r(BDe," \u2014 "),XZ=n(BDe,"A",{href:!0});var hIt=s(XZ);SGr=r(hIt,"FlaxBertForMaskedLM"),hIt.forEach(t),RGr=r(BDe," (BERT model)"),BDe.forEach(t),PGr=i(qe),k5=n(qe,"LI",{});var IDe=s(k5);rCe=n(IDe,"STRONG",{});var pIt=s(rCe);BGr=r(pIt,"big_bird"),pIt.forEach(t),IGr=r(IDe," \u2014 "),zZ=n(IDe,"A",{href:!0});var _It=s(zZ);NGr=r(_It,"FlaxBigBirdForMaskedLM"),_It.forEach(t),qGr=r(IDe," (BigBird model)"),IDe.forEach(t),jGr=i(qe),S5=n(qe,"LI",{});var NDe=s(S5);tCe=n(NDe,"STRONG",{});var uIt=s(tCe);DGr=r(uIt,"distilbert"),uIt.forEach(t),GGr=r(NDe," \u2014 "),QZ=n(NDe,"A",{href:!0});var bIt=s(QZ);OGr=r(bIt,"FlaxDistilBertForMaskedLM"),bIt.forEach(t),VGr=r(NDe," (DistilBERT model)"),NDe.forEach(t),XGr=i(qe),R5=n(qe,"LI",{});var qDe=s(R5);aCe=n(qDe,"STRONG",{});var vIt=s(aCe);zGr=r(vIt,"electra"),vIt.forEach(t),QGr=r(qDe," \u2014 "),WZ=n(qDe,"A",{href:!0});var FIt=s(WZ);WGr=r(FIt,"FlaxElectraForMaskedLM"),FIt.forEach(t),HGr=r(qDe," (ELECTRA model)"),qDe.forEach(t),UGr=i(qe),P5=n(qe,"LI",{});var jDe=s(P5);nCe=n(jDe,"STRONG",{});var TIt=s(nCe);JGr=r(TIt,"mbart"),TIt.forEach(t),YGr=r(jDe," \u2014 "),HZ=n(jDe,"A",{href:!0});var MIt=s(HZ);KGr=r(MIt,"FlaxMBartForConditionalGeneration"),MIt.forEach(t),ZGr=r(jDe," (mBART model)"),jDe.forEach(t),eOr=i(qe),B5=n(qe,"LI",{});var DDe=s(B5);sCe=n(DDe,"STRONG",{});var EIt=s(sCe);oOr=r(EIt,"roberta"),EIt.forEach(t),rOr=r(DDe," \u2014 "),UZ=n(DDe,"A",{href:!0});var CIt=s(UZ);tOr=r(CIt,"FlaxRobertaForMaskedLM"),CIt.forEach(t),aOr=r(DDe," (RoBERTa model)"),DDe.forEach(t),nOr=i(qe),I5=n(qe,"LI",{});var GDe=s(I5);lCe=n(GDe,"STRONG",{});var wIt=s(lCe);sOr=r(wIt,"roformer"),wIt.forEach(t),lOr=r(GDe," \u2014 "),JZ=n(GDe,"A",{href:!0});var AIt=s(JZ);iOr=r(AIt,"FlaxRoFormerForMaskedLM"),AIt.forEach(t),dOr=r(GDe," (RoFormer model)"),GDe.forEach(t),cOr=i(qe),N5=n(qe,"LI",{});var ODe=s(N5);iCe=n(ODe,"STRONG",{});var LIt=s(iCe);fOr=r(LIt,"xlm-roberta"),LIt.forEach(t),mOr=r(ODe," \u2014 "),YZ=n(ODe,"A",{href:!0});var yIt=s(YZ);gOr=r(yIt,"FlaxXLMRobertaForMaskedLM"),yIt.forEach(t),hOr=r(ODe," (XLM-RoBERTa model)"),ODe.forEach(t),qe.forEach(t),pOr=i(ai),T(q5.$$.fragment,ai),ai.forEach(t),ti.forEach(t),yVe=i(f),ef=n(f,"H2",{class:!0});var Nze=s(ef);j5=n(Nze,"A",{id:!0,class:!0,href:!0});var xIt=s(j5);dCe=n(xIt,"SPAN",{});var $It=s(dCe);T(Kx.$$.fragment,$It),$It.forEach(t),xIt.forEach(t),_Or=i(Nze),cCe=n(Nze,"SPAN",{});var kIt=s(cCe);uOr=r(kIt,"FlaxAutoModelForSeq2SeqLM"),kIt.forEach(t),Nze.forEach(t),xVe=i(f),br=n(f,"DIV",{class:!0});var ni=s(br);T(Zx.$$.fragment,ni),bOr=i(ni),of=n(ni,"P",{});var Jre=s(of);vOr=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=n(Jre,"A",{href:!0});var SIt=s(KZ);FOr=r(SIt,"from_pretrained()"),SIt.forEach(t),TOr=r(Jre," class method or the "),ZZ=n(Jre,"A",{href:!0});var RIt=s(ZZ);MOr=r(RIt,"from_config()"),RIt.forEach(t),EOr=r(Jre,` class
method.`),Jre.forEach(t),COr=i(ni),e$=n(ni,"P",{});var qze=s(e$);wOr=r(qze,"This class cannot be instantiated directly using "),fCe=n(qze,"CODE",{});var PIt=s(fCe);AOr=r(PIt,"__init__()"),PIt.forEach(t),LOr=r(qze," (throws an error)."),qze.forEach(t),yOr=i(ni),Ht=n(ni,"DIV",{class:!0});var dA=s(Ht);T(o$.$$.fragment,dA),xOr=i(dA),mCe=n(dA,"P",{});var BIt=s(mCe);$Or=r(BIt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),BIt.forEach(t),kOr=i(dA),rf=n(dA,"P",{});var Yre=s(rf);SOr=r(Yre,`Note:
Loading a model from its configuration file does `),gCe=n(Yre,"STRONG",{});var IIt=s(gCe);ROr=r(IIt,"not"),IIt.forEach(t),POr=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=n(Yre,"A",{href:!0});var NIt=s(eee);BOr=r(NIt,"from_pretrained()"),NIt.forEach(t),IOr=r(Yre," to load the model weights."),Yre.forEach(t),NOr=i(dA),T(D5.$$.fragment,dA),dA.forEach(t),qOr=i(ni),Qr=n(ni,"DIV",{class:!0});var si=s(Qr);T(r$.$$.fragment,si),jOr=i(si),hCe=n(si,"P",{});var qIt=s(hCe);DOr=r(qIt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qIt.forEach(t),GOr=i(si),Cn=n(si,"P",{});var cA=s(Cn);OOr=r(cA,"The model class to instantiate is selected based on the "),pCe=n(cA,"CODE",{});var jIt=s(pCe);VOr=r(jIt,"model_type"),jIt.forEach(t),XOr=r(cA,` property of the config object (either
passed as an argument or loaded from `),_Ce=n(cA,"CODE",{});var DIt=s(_Ce);zOr=r(DIt,"pretrained_model_name_or_path"),DIt.forEach(t),QOr=r(cA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=n(cA,"CODE",{});var GIt=s(uCe);WOr=r(GIt,"pretrained_model_name_or_path"),GIt.forEach(t),HOr=r(cA,":"),cA.forEach(t),UOr=i(si),ke=n(si,"UL",{});var je=s(ke);G5=n(je,"LI",{});var VDe=s(G5);bCe=n(VDe,"STRONG",{});var OIt=s(bCe);JOr=r(OIt,"bart"),OIt.forEach(t),YOr=r(VDe," \u2014 "),oee=n(VDe,"A",{href:!0});var VIt=s(oee);KOr=r(VIt,"FlaxBartForConditionalGeneration"),VIt.forEach(t),ZOr=r(VDe," (BART model)"),VDe.forEach(t),eVr=i(je),O5=n(je,"LI",{});var XDe=s(O5);vCe=n(XDe,"STRONG",{});var XIt=s(vCe);oVr=r(XIt,"blenderbot"),XIt.forEach(t),rVr=r(XDe," \u2014 "),ree=n(XDe,"A",{href:!0});var zIt=s(ree);tVr=r(zIt,"FlaxBlenderbotForConditionalGeneration"),zIt.forEach(t),aVr=r(XDe," (Blenderbot model)"),XDe.forEach(t),nVr=i(je),V5=n(je,"LI",{});var zDe=s(V5);FCe=n(zDe,"STRONG",{});var QIt=s(FCe);sVr=r(QIt,"blenderbot-small"),QIt.forEach(t),lVr=r(zDe," \u2014 "),tee=n(zDe,"A",{href:!0});var WIt=s(tee);iVr=r(WIt,"FlaxBlenderbotSmallForConditionalGeneration"),WIt.forEach(t),dVr=r(zDe," (BlenderbotSmall model)"),zDe.forEach(t),cVr=i(je),X5=n(je,"LI",{});var QDe=s(X5);TCe=n(QDe,"STRONG",{});var HIt=s(TCe);fVr=r(HIt,"encoder-decoder"),HIt.forEach(t),mVr=r(QDe," \u2014 "),aee=n(QDe,"A",{href:!0});var UIt=s(aee);gVr=r(UIt,"FlaxEncoderDecoderModel"),UIt.forEach(t),hVr=r(QDe," (Encoder decoder model)"),QDe.forEach(t),pVr=i(je),z5=n(je,"LI",{});var WDe=s(z5);MCe=n(WDe,"STRONG",{});var JIt=s(MCe);_Vr=r(JIt,"longt5"),JIt.forEach(t),uVr=r(WDe," \u2014 "),nee=n(WDe,"A",{href:!0});var YIt=s(nee);bVr=r(YIt,"FlaxLongT5ForConditionalGeneration"),YIt.forEach(t),vVr=r(WDe," (LongT5 model)"),WDe.forEach(t),FVr=i(je),Q5=n(je,"LI",{});var HDe=s(Q5);ECe=n(HDe,"STRONG",{});var KIt=s(ECe);TVr=r(KIt,"marian"),KIt.forEach(t),MVr=r(HDe," \u2014 "),see=n(HDe,"A",{href:!0});var ZIt=s(see);EVr=r(ZIt,"FlaxMarianMTModel"),ZIt.forEach(t),CVr=r(HDe," (Marian model)"),HDe.forEach(t),wVr=i(je),W5=n(je,"LI",{});var UDe=s(W5);CCe=n(UDe,"STRONG",{});var eNt=s(CCe);AVr=r(eNt,"mbart"),eNt.forEach(t),LVr=r(UDe," \u2014 "),lee=n(UDe,"A",{href:!0});var oNt=s(lee);yVr=r(oNt,"FlaxMBartForConditionalGeneration"),oNt.forEach(t),xVr=r(UDe," (mBART model)"),UDe.forEach(t),$Vr=i(je),H5=n(je,"LI",{});var JDe=s(H5);wCe=n(JDe,"STRONG",{});var rNt=s(wCe);kVr=r(rNt,"mt5"),rNt.forEach(t),SVr=r(JDe," \u2014 "),iee=n(JDe,"A",{href:!0});var tNt=s(iee);RVr=r(tNt,"FlaxMT5ForConditionalGeneration"),tNt.forEach(t),PVr=r(JDe," (MT5 model)"),JDe.forEach(t),BVr=i(je),U5=n(je,"LI",{});var YDe=s(U5);ACe=n(YDe,"STRONG",{});var aNt=s(ACe);IVr=r(aNt,"pegasus"),aNt.forEach(t),NVr=r(YDe," \u2014 "),dee=n(YDe,"A",{href:!0});var nNt=s(dee);qVr=r(nNt,"FlaxPegasusForConditionalGeneration"),nNt.forEach(t),jVr=r(YDe," (Pegasus model)"),YDe.forEach(t),DVr=i(je),J5=n(je,"LI",{});var KDe=s(J5);LCe=n(KDe,"STRONG",{});var sNt=s(LCe);GVr=r(sNt,"t5"),sNt.forEach(t),OVr=r(KDe," \u2014 "),cee=n(KDe,"A",{href:!0});var lNt=s(cee);VVr=r(lNt,"FlaxT5ForConditionalGeneration"),lNt.forEach(t),XVr=r(KDe," (T5 model)"),KDe.forEach(t),je.forEach(t),zVr=i(si),T(Y5.$$.fragment,si),si.forEach(t),ni.forEach(t),$Ve=i(f),tf=n(f,"H2",{class:!0});var jze=s(tf);K5=n(jze,"A",{id:!0,class:!0,href:!0});var iNt=s(K5);yCe=n(iNt,"SPAN",{});var dNt=s(yCe);T(t$.$$.fragment,dNt),dNt.forEach(t),iNt.forEach(t),QVr=i(jze),xCe=n(jze,"SPAN",{});var cNt=s(xCe);WVr=r(cNt,"FlaxAutoModelForSequenceClassification"),cNt.forEach(t),jze.forEach(t),kVe=i(f),vr=n(f,"DIV",{class:!0});var li=s(vr);T(a$.$$.fragment,li),HVr=i(li),af=n(li,"P",{});var Kre=s(af);UVr=r(Kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fee=n(Kre,"A",{href:!0});var fNt=s(fee);JVr=r(fNt,"from_pretrained()"),fNt.forEach(t),YVr=r(Kre," class method or the "),mee=n(Kre,"A",{href:!0});var mNt=s(mee);KVr=r(mNt,"from_config()"),mNt.forEach(t),ZVr=r(Kre,` class
method.`),Kre.forEach(t),eXr=i(li),n$=n(li,"P",{});var Dze=s(n$);oXr=r(Dze,"This class cannot be instantiated directly using "),$Ce=n(Dze,"CODE",{});var gNt=s($Ce);rXr=r(gNt,"__init__()"),gNt.forEach(t),tXr=r(Dze," (throws an error)."),Dze.forEach(t),aXr=i(li),Ut=n(li,"DIV",{class:!0});var fA=s(Ut);T(s$.$$.fragment,fA),nXr=i(fA),kCe=n(fA,"P",{});var hNt=s(kCe);sXr=r(hNt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hNt.forEach(t),lXr=i(fA),nf=n(fA,"P",{});var Zre=s(nf);iXr=r(Zre,`Note:
Loading a model from its configuration file does `),SCe=n(Zre,"STRONG",{});var pNt=s(SCe);dXr=r(pNt,"not"),pNt.forEach(t),cXr=r(Zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=n(Zre,"A",{href:!0});var _Nt=s(gee);fXr=r(_Nt,"from_pretrained()"),_Nt.forEach(t),mXr=r(Zre," to load the model weights."),Zre.forEach(t),gXr=i(fA),T(Z5.$$.fragment,fA),fA.forEach(t),hXr=i(li),Wr=n(li,"DIV",{class:!0});var ii=s(Wr);T(l$.$$.fragment,ii),pXr=i(ii),RCe=n(ii,"P",{});var uNt=s(RCe);_Xr=r(uNt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uNt.forEach(t),uXr=i(ii),wn=n(ii,"P",{});var mA=s(wn);bXr=r(mA,"The model class to instantiate is selected based on the "),PCe=n(mA,"CODE",{});var bNt=s(PCe);vXr=r(bNt,"model_type"),bNt.forEach(t),FXr=r(mA,` property of the config object (either
passed as an argument or loaded from `),BCe=n(mA,"CODE",{});var vNt=s(BCe);TXr=r(vNt,"pretrained_model_name_or_path"),vNt.forEach(t),MXr=r(mA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ICe=n(mA,"CODE",{});var FNt=s(ICe);EXr=r(FNt,"pretrained_model_name_or_path"),FNt.forEach(t),CXr=r(mA,":"),mA.forEach(t),wXr=i(ii),Se=n(ii,"UL",{});var De=s(Se);e3=n(De,"LI",{});var ZDe=s(e3);NCe=n(ZDe,"STRONG",{});var TNt=s(NCe);AXr=r(TNt,"albert"),TNt.forEach(t),LXr=r(ZDe," \u2014 "),hee=n(ZDe,"A",{href:!0});var MNt=s(hee);yXr=r(MNt,"FlaxAlbertForSequenceClassification"),MNt.forEach(t),xXr=r(ZDe," (ALBERT model)"),ZDe.forEach(t),$Xr=i(De),o3=n(De,"LI",{});var eGe=s(o3);qCe=n(eGe,"STRONG",{});var ENt=s(qCe);kXr=r(ENt,"bart"),ENt.forEach(t),SXr=r(eGe," \u2014 "),pee=n(eGe,"A",{href:!0});var CNt=s(pee);RXr=r(CNt,"FlaxBartForSequenceClassification"),CNt.forEach(t),PXr=r(eGe," (BART model)"),eGe.forEach(t),BXr=i(De),r3=n(De,"LI",{});var oGe=s(r3);jCe=n(oGe,"STRONG",{});var wNt=s(jCe);IXr=r(wNt,"bert"),wNt.forEach(t),NXr=r(oGe," \u2014 "),_ee=n(oGe,"A",{href:!0});var ANt=s(_ee);qXr=r(ANt,"FlaxBertForSequenceClassification"),ANt.forEach(t),jXr=r(oGe," (BERT model)"),oGe.forEach(t),DXr=i(De),t3=n(De,"LI",{});var rGe=s(t3);DCe=n(rGe,"STRONG",{});var LNt=s(DCe);GXr=r(LNt,"big_bird"),LNt.forEach(t),OXr=r(rGe," \u2014 "),uee=n(rGe,"A",{href:!0});var yNt=s(uee);VXr=r(yNt,"FlaxBigBirdForSequenceClassification"),yNt.forEach(t),XXr=r(rGe," (BigBird model)"),rGe.forEach(t),zXr=i(De),a3=n(De,"LI",{});var tGe=s(a3);GCe=n(tGe,"STRONG",{});var xNt=s(GCe);QXr=r(xNt,"distilbert"),xNt.forEach(t),WXr=r(tGe," \u2014 "),bee=n(tGe,"A",{href:!0});var $Nt=s(bee);HXr=r($Nt,"FlaxDistilBertForSequenceClassification"),$Nt.forEach(t),UXr=r(tGe," (DistilBERT model)"),tGe.forEach(t),JXr=i(De),n3=n(De,"LI",{});var aGe=s(n3);OCe=n(aGe,"STRONG",{});var kNt=s(OCe);YXr=r(kNt,"electra"),kNt.forEach(t),KXr=r(aGe," \u2014 "),vee=n(aGe,"A",{href:!0});var SNt=s(vee);ZXr=r(SNt,"FlaxElectraForSequenceClassification"),SNt.forEach(t),ezr=r(aGe," (ELECTRA model)"),aGe.forEach(t),ozr=i(De),s3=n(De,"LI",{});var nGe=s(s3);VCe=n(nGe,"STRONG",{});var RNt=s(VCe);rzr=r(RNt,"mbart"),RNt.forEach(t),tzr=r(nGe," \u2014 "),Fee=n(nGe,"A",{href:!0});var PNt=s(Fee);azr=r(PNt,"FlaxMBartForSequenceClassification"),PNt.forEach(t),nzr=r(nGe," (mBART model)"),nGe.forEach(t),szr=i(De),l3=n(De,"LI",{});var sGe=s(l3);XCe=n(sGe,"STRONG",{});var BNt=s(XCe);lzr=r(BNt,"roberta"),BNt.forEach(t),izr=r(sGe," \u2014 "),Tee=n(sGe,"A",{href:!0});var INt=s(Tee);dzr=r(INt,"FlaxRobertaForSequenceClassification"),INt.forEach(t),czr=r(sGe," (RoBERTa model)"),sGe.forEach(t),fzr=i(De),i3=n(De,"LI",{});var lGe=s(i3);zCe=n(lGe,"STRONG",{});var NNt=s(zCe);mzr=r(NNt,"roformer"),NNt.forEach(t),gzr=r(lGe," \u2014 "),Mee=n(lGe,"A",{href:!0});var qNt=s(Mee);hzr=r(qNt,"FlaxRoFormerForSequenceClassification"),qNt.forEach(t),pzr=r(lGe," (RoFormer model)"),lGe.forEach(t),_zr=i(De),d3=n(De,"LI",{});var iGe=s(d3);QCe=n(iGe,"STRONG",{});var jNt=s(QCe);uzr=r(jNt,"xlm-roberta"),jNt.forEach(t),bzr=r(iGe," \u2014 "),Eee=n(iGe,"A",{href:!0});var DNt=s(Eee);vzr=r(DNt,"FlaxXLMRobertaForSequenceClassification"),DNt.forEach(t),Fzr=r(iGe," (XLM-RoBERTa model)"),iGe.forEach(t),De.forEach(t),Tzr=i(ii),T(c3.$$.fragment,ii),ii.forEach(t),li.forEach(t),SVe=i(f),sf=n(f,"H2",{class:!0});var Gze=s(sf);f3=n(Gze,"A",{id:!0,class:!0,href:!0});var GNt=s(f3);WCe=n(GNt,"SPAN",{});var ONt=s(WCe);T(i$.$$.fragment,ONt),ONt.forEach(t),GNt.forEach(t),Mzr=i(Gze),HCe=n(Gze,"SPAN",{});var VNt=s(HCe);Ezr=r(VNt,"FlaxAutoModelForQuestionAnswering"),VNt.forEach(t),Gze.forEach(t),RVe=i(f),Fr=n(f,"DIV",{class:!0});var di=s(Fr);T(d$.$$.fragment,di),Czr=i(di),lf=n(di,"P",{});var ete=s(lf);wzr=r(ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=n(ete,"A",{href:!0});var XNt=s(Cee);Azr=r(XNt,"from_pretrained()"),XNt.forEach(t),Lzr=r(ete," class method or the "),wee=n(ete,"A",{href:!0});var zNt=s(wee);yzr=r(zNt,"from_config()"),zNt.forEach(t),xzr=r(ete,` class
method.`),ete.forEach(t),$zr=i(di),c$=n(di,"P",{});var Oze=s(c$);kzr=r(Oze,"This class cannot be instantiated directly using "),UCe=n(Oze,"CODE",{});var QNt=s(UCe);Szr=r(QNt,"__init__()"),QNt.forEach(t),Rzr=r(Oze," (throws an error)."),Oze.forEach(t),Pzr=i(di),Jt=n(di,"DIV",{class:!0});var gA=s(Jt);T(f$.$$.fragment,gA),Bzr=i(gA),JCe=n(gA,"P",{});var WNt=s(JCe);Izr=r(WNt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),WNt.forEach(t),Nzr=i(gA),df=n(gA,"P",{});var ote=s(df);qzr=r(ote,`Note:
Loading a model from its configuration file does `),YCe=n(ote,"STRONG",{});var HNt=s(YCe);jzr=r(HNt,"not"),HNt.forEach(t),Dzr=r(ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=n(ote,"A",{href:!0});var UNt=s(Aee);Gzr=r(UNt,"from_pretrained()"),UNt.forEach(t),Ozr=r(ote," to load the model weights."),ote.forEach(t),Vzr=i(gA),T(m3.$$.fragment,gA),gA.forEach(t),Xzr=i(di),Hr=n(di,"DIV",{class:!0});var ci=s(Hr);T(m$.$$.fragment,ci),zzr=i(ci),KCe=n(ci,"P",{});var JNt=s(KCe);Qzr=r(JNt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),JNt.forEach(t),Wzr=i(ci),An=n(ci,"P",{});var hA=s(An);Hzr=r(hA,"The model class to instantiate is selected based on the "),ZCe=n(hA,"CODE",{});var YNt=s(ZCe);Uzr=r(YNt,"model_type"),YNt.forEach(t),Jzr=r(hA,` property of the config object (either
passed as an argument or loaded from `),e5e=n(hA,"CODE",{});var KNt=s(e5e);Yzr=r(KNt,"pretrained_model_name_or_path"),KNt.forEach(t),Kzr=r(hA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o5e=n(hA,"CODE",{});var ZNt=s(o5e);Zzr=r(ZNt,"pretrained_model_name_or_path"),ZNt.forEach(t),eQr=r(hA,":"),hA.forEach(t),oQr=i(ci),Re=n(ci,"UL",{});var Ge=s(Re);g3=n(Ge,"LI",{});var dGe=s(g3);r5e=n(dGe,"STRONG",{});var eqt=s(r5e);rQr=r(eqt,"albert"),eqt.forEach(t),tQr=r(dGe," \u2014 "),Lee=n(dGe,"A",{href:!0});var oqt=s(Lee);aQr=r(oqt,"FlaxAlbertForQuestionAnswering"),oqt.forEach(t),nQr=r(dGe," (ALBERT model)"),dGe.forEach(t),sQr=i(Ge),h3=n(Ge,"LI",{});var cGe=s(h3);t5e=n(cGe,"STRONG",{});var rqt=s(t5e);lQr=r(rqt,"bart"),rqt.forEach(t),iQr=r(cGe," \u2014 "),yee=n(cGe,"A",{href:!0});var tqt=s(yee);dQr=r(tqt,"FlaxBartForQuestionAnswering"),tqt.forEach(t),cQr=r(cGe," (BART model)"),cGe.forEach(t),fQr=i(Ge),p3=n(Ge,"LI",{});var fGe=s(p3);a5e=n(fGe,"STRONG",{});var aqt=s(a5e);mQr=r(aqt,"bert"),aqt.forEach(t),gQr=r(fGe," \u2014 "),xee=n(fGe,"A",{href:!0});var nqt=s(xee);hQr=r(nqt,"FlaxBertForQuestionAnswering"),nqt.forEach(t),pQr=r(fGe," (BERT model)"),fGe.forEach(t),_Qr=i(Ge),_3=n(Ge,"LI",{});var mGe=s(_3);n5e=n(mGe,"STRONG",{});var sqt=s(n5e);uQr=r(sqt,"big_bird"),sqt.forEach(t),bQr=r(mGe," \u2014 "),$ee=n(mGe,"A",{href:!0});var lqt=s($ee);vQr=r(lqt,"FlaxBigBirdForQuestionAnswering"),lqt.forEach(t),FQr=r(mGe," (BigBird model)"),mGe.forEach(t),TQr=i(Ge),u3=n(Ge,"LI",{});var gGe=s(u3);s5e=n(gGe,"STRONG",{});var iqt=s(s5e);MQr=r(iqt,"distilbert"),iqt.forEach(t),EQr=r(gGe," \u2014 "),kee=n(gGe,"A",{href:!0});var dqt=s(kee);CQr=r(dqt,"FlaxDistilBertForQuestionAnswering"),dqt.forEach(t),wQr=r(gGe," (DistilBERT model)"),gGe.forEach(t),AQr=i(Ge),b3=n(Ge,"LI",{});var hGe=s(b3);l5e=n(hGe,"STRONG",{});var cqt=s(l5e);LQr=r(cqt,"electra"),cqt.forEach(t),yQr=r(hGe," \u2014 "),See=n(hGe,"A",{href:!0});var fqt=s(See);xQr=r(fqt,"FlaxElectraForQuestionAnswering"),fqt.forEach(t),$Qr=r(hGe," (ELECTRA model)"),hGe.forEach(t),kQr=i(Ge),v3=n(Ge,"LI",{});var pGe=s(v3);i5e=n(pGe,"STRONG",{});var mqt=s(i5e);SQr=r(mqt,"mbart"),mqt.forEach(t),RQr=r(pGe," \u2014 "),Ree=n(pGe,"A",{href:!0});var gqt=s(Ree);PQr=r(gqt,"FlaxMBartForQuestionAnswering"),gqt.forEach(t),BQr=r(pGe," (mBART model)"),pGe.forEach(t),IQr=i(Ge),F3=n(Ge,"LI",{});var _Ge=s(F3);d5e=n(_Ge,"STRONG",{});var hqt=s(d5e);NQr=r(hqt,"roberta"),hqt.forEach(t),qQr=r(_Ge," \u2014 "),Pee=n(_Ge,"A",{href:!0});var pqt=s(Pee);jQr=r(pqt,"FlaxRobertaForQuestionAnswering"),pqt.forEach(t),DQr=r(_Ge," (RoBERTa model)"),_Ge.forEach(t),GQr=i(Ge),T3=n(Ge,"LI",{});var uGe=s(T3);c5e=n(uGe,"STRONG",{});var _qt=s(c5e);OQr=r(_qt,"roformer"),_qt.forEach(t),VQr=r(uGe," \u2014 "),Bee=n(uGe,"A",{href:!0});var uqt=s(Bee);XQr=r(uqt,"FlaxRoFormerForQuestionAnswering"),uqt.forEach(t),zQr=r(uGe," (RoFormer model)"),uGe.forEach(t),QQr=i(Ge),M3=n(Ge,"LI",{});var bGe=s(M3);f5e=n(bGe,"STRONG",{});var bqt=s(f5e);WQr=r(bqt,"xlm-roberta"),bqt.forEach(t),HQr=r(bGe," \u2014 "),Iee=n(bGe,"A",{href:!0});var vqt=s(Iee);UQr=r(vqt,"FlaxXLMRobertaForQuestionAnswering"),vqt.forEach(t),JQr=r(bGe," (XLM-RoBERTa model)"),bGe.forEach(t),Ge.forEach(t),YQr=i(ci),T(E3.$$.fragment,ci),ci.forEach(t),di.forEach(t),PVe=i(f),cf=n(f,"H2",{class:!0});var Vze=s(cf);C3=n(Vze,"A",{id:!0,class:!0,href:!0});var Fqt=s(C3);m5e=n(Fqt,"SPAN",{});var Tqt=s(m5e);T(g$.$$.fragment,Tqt),Tqt.forEach(t),Fqt.forEach(t),KQr=i(Vze),g5e=n(Vze,"SPAN",{});var Mqt=s(g5e);ZQr=r(Mqt,"FlaxAutoModelForTokenClassification"),Mqt.forEach(t),Vze.forEach(t),BVe=i(f),Tr=n(f,"DIV",{class:!0});var fi=s(Tr);T(h$.$$.fragment,fi),eWr=i(fi),ff=n(fi,"P",{});var rte=s(ff);oWr=r(rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=n(rte,"A",{href:!0});var Eqt=s(Nee);rWr=r(Eqt,"from_pretrained()"),Eqt.forEach(t),tWr=r(rte," class method or the "),qee=n(rte,"A",{href:!0});var Cqt=s(qee);aWr=r(Cqt,"from_config()"),Cqt.forEach(t),nWr=r(rte,` class
method.`),rte.forEach(t),sWr=i(fi),p$=n(fi,"P",{});var Xze=s(p$);lWr=r(Xze,"This class cannot be instantiated directly using "),h5e=n(Xze,"CODE",{});var wqt=s(h5e);iWr=r(wqt,"__init__()"),wqt.forEach(t),dWr=r(Xze," (throws an error)."),Xze.forEach(t),cWr=i(fi),Yt=n(fi,"DIV",{class:!0});var pA=s(Yt);T(_$.$$.fragment,pA),fWr=i(pA),p5e=n(pA,"P",{});var Aqt=s(p5e);mWr=r(Aqt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Aqt.forEach(t),gWr=i(pA),mf=n(pA,"P",{});var tte=s(mf);hWr=r(tte,`Note:
Loading a model from its configuration file does `),_5e=n(tte,"STRONG",{});var Lqt=s(_5e);pWr=r(Lqt,"not"),Lqt.forEach(t),_Wr=r(tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=n(tte,"A",{href:!0});var yqt=s(jee);uWr=r(yqt,"from_pretrained()"),yqt.forEach(t),bWr=r(tte," to load the model weights."),tte.forEach(t),vWr=i(pA),T(w3.$$.fragment,pA),pA.forEach(t),FWr=i(fi),Ur=n(fi,"DIV",{class:!0});var mi=s(Ur);T(u$.$$.fragment,mi),TWr=i(mi),u5e=n(mi,"P",{});var xqt=s(u5e);MWr=r(xqt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xqt.forEach(t),EWr=i(mi),Ln=n(mi,"P",{});var _A=s(Ln);CWr=r(_A,"The model class to instantiate is selected based on the "),b5e=n(_A,"CODE",{});var $qt=s(b5e);wWr=r($qt,"model_type"),$qt.forEach(t),AWr=r(_A,` property of the config object (either
passed as an argument or loaded from `),v5e=n(_A,"CODE",{});var kqt=s(v5e);LWr=r(kqt,"pretrained_model_name_or_path"),kqt.forEach(t),yWr=r(_A,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F5e=n(_A,"CODE",{});var Sqt=s(F5e);xWr=r(Sqt,"pretrained_model_name_or_path"),Sqt.forEach(t),$Wr=r(_A,":"),_A.forEach(t),kWr=i(mi),Ve=n(mi,"UL",{});var To=s(Ve);A3=n(To,"LI",{});var vGe=s(A3);T5e=n(vGe,"STRONG",{});var Rqt=s(T5e);SWr=r(Rqt,"albert"),Rqt.forEach(t),RWr=r(vGe," \u2014 "),Dee=n(vGe,"A",{href:!0});var Pqt=s(Dee);PWr=r(Pqt,"FlaxAlbertForTokenClassification"),Pqt.forEach(t),BWr=r(vGe," (ALBERT model)"),vGe.forEach(t),IWr=i(To),L3=n(To,"LI",{});var FGe=s(L3);M5e=n(FGe,"STRONG",{});var Bqt=s(M5e);NWr=r(Bqt,"bert"),Bqt.forEach(t),qWr=r(FGe," \u2014 "),Gee=n(FGe,"A",{href:!0});var Iqt=s(Gee);jWr=r(Iqt,"FlaxBertForTokenClassification"),Iqt.forEach(t),DWr=r(FGe," (BERT model)"),FGe.forEach(t),GWr=i(To),y3=n(To,"LI",{});var TGe=s(y3);E5e=n(TGe,"STRONG",{});var Nqt=s(E5e);OWr=r(Nqt,"big_bird"),Nqt.forEach(t),VWr=r(TGe," \u2014 "),Oee=n(TGe,"A",{href:!0});var qqt=s(Oee);XWr=r(qqt,"FlaxBigBirdForTokenClassification"),qqt.forEach(t),zWr=r(TGe," (BigBird model)"),TGe.forEach(t),QWr=i(To),x3=n(To,"LI",{});var MGe=s(x3);C5e=n(MGe,"STRONG",{});var jqt=s(C5e);WWr=r(jqt,"distilbert"),jqt.forEach(t),HWr=r(MGe," \u2014 "),Vee=n(MGe,"A",{href:!0});var Dqt=s(Vee);UWr=r(Dqt,"FlaxDistilBertForTokenClassification"),Dqt.forEach(t),JWr=r(MGe," (DistilBERT model)"),MGe.forEach(t),YWr=i(To),$3=n(To,"LI",{});var EGe=s($3);w5e=n(EGe,"STRONG",{});var Gqt=s(w5e);KWr=r(Gqt,"electra"),Gqt.forEach(t),ZWr=r(EGe," \u2014 "),Xee=n(EGe,"A",{href:!0});var Oqt=s(Xee);eHr=r(Oqt,"FlaxElectraForTokenClassification"),Oqt.forEach(t),oHr=r(EGe," (ELECTRA model)"),EGe.forEach(t),rHr=i(To),k3=n(To,"LI",{});var CGe=s(k3);A5e=n(CGe,"STRONG",{});var Vqt=s(A5e);tHr=r(Vqt,"roberta"),Vqt.forEach(t),aHr=r(CGe," \u2014 "),zee=n(CGe,"A",{href:!0});var Xqt=s(zee);nHr=r(Xqt,"FlaxRobertaForTokenClassification"),Xqt.forEach(t),sHr=r(CGe," (RoBERTa model)"),CGe.forEach(t),lHr=i(To),S3=n(To,"LI",{});var wGe=s(S3);L5e=n(wGe,"STRONG",{});var zqt=s(L5e);iHr=r(zqt,"roformer"),zqt.forEach(t),dHr=r(wGe," \u2014 "),Qee=n(wGe,"A",{href:!0});var Qqt=s(Qee);cHr=r(Qqt,"FlaxRoFormerForTokenClassification"),Qqt.forEach(t),fHr=r(wGe," (RoFormer model)"),wGe.forEach(t),mHr=i(To),R3=n(To,"LI",{});var AGe=s(R3);y5e=n(AGe,"STRONG",{});var Wqt=s(y5e);gHr=r(Wqt,"xlm-roberta"),Wqt.forEach(t),hHr=r(AGe," \u2014 "),Wee=n(AGe,"A",{href:!0});var Hqt=s(Wee);pHr=r(Hqt,"FlaxXLMRobertaForTokenClassification"),Hqt.forEach(t),_Hr=r(AGe," (XLM-RoBERTa model)"),AGe.forEach(t),To.forEach(t),uHr=i(mi),T(P3.$$.fragment,mi),mi.forEach(t),fi.forEach(t),IVe=i(f),gf=n(f,"H2",{class:!0});var zze=s(gf);B3=n(zze,"A",{id:!0,class:!0,href:!0});var Uqt=s(B3);x5e=n(Uqt,"SPAN",{});var Jqt=s(x5e);T(b$.$$.fragment,Jqt),Jqt.forEach(t),Uqt.forEach(t),bHr=i(zze),$5e=n(zze,"SPAN",{});var Yqt=s($5e);vHr=r(Yqt,"FlaxAutoModelForMultipleChoice"),Yqt.forEach(t),zze.forEach(t),NVe=i(f),Mr=n(f,"DIV",{class:!0});var gi=s(Mr);T(v$.$$.fragment,gi),FHr=i(gi),hf=n(gi,"P",{});var ate=s(hf);THr=r(ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=n(ate,"A",{href:!0});var Kqt=s(Hee);MHr=r(Kqt,"from_pretrained()"),Kqt.forEach(t),EHr=r(ate," class method or the "),Uee=n(ate,"A",{href:!0});var Zqt=s(Uee);CHr=r(Zqt,"from_config()"),Zqt.forEach(t),wHr=r(ate,` class
method.`),ate.forEach(t),AHr=i(gi),F$=n(gi,"P",{});var Qze=s(F$);LHr=r(Qze,"This class cannot be instantiated directly using "),k5e=n(Qze,"CODE",{});var ejt=s(k5e);yHr=r(ejt,"__init__()"),ejt.forEach(t),xHr=r(Qze," (throws an error)."),Qze.forEach(t),$Hr=i(gi),Kt=n(gi,"DIV",{class:!0});var uA=s(Kt);T(T$.$$.fragment,uA),kHr=i(uA),S5e=n(uA,"P",{});var ojt=s(S5e);SHr=r(ojt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),ojt.forEach(t),RHr=i(uA),pf=n(uA,"P",{});var nte=s(pf);PHr=r(nte,`Note:
Loading a model from its configuration file does `),R5e=n(nte,"STRONG",{});var rjt=s(R5e);BHr=r(rjt,"not"),rjt.forEach(t),IHr=r(nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=n(nte,"A",{href:!0});var tjt=s(Jee);NHr=r(tjt,"from_pretrained()"),tjt.forEach(t),qHr=r(nte," to load the model weights."),nte.forEach(t),jHr=i(uA),T(I3.$$.fragment,uA),uA.forEach(t),DHr=i(gi),Jr=n(gi,"DIV",{class:!0});var hi=s(Jr);T(M$.$$.fragment,hi),GHr=i(hi),P5e=n(hi,"P",{});var ajt=s(P5e);OHr=r(ajt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ajt.forEach(t),VHr=i(hi),yn=n(hi,"P",{});var bA=s(yn);XHr=r(bA,"The model class to instantiate is selected based on the "),B5e=n(bA,"CODE",{});var njt=s(B5e);zHr=r(njt,"model_type"),njt.forEach(t),QHr=r(bA,` property of the config object (either
passed as an argument or loaded from `),I5e=n(bA,"CODE",{});var sjt=s(I5e);WHr=r(sjt,"pretrained_model_name_or_path"),sjt.forEach(t),HHr=r(bA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N5e=n(bA,"CODE",{});var ljt=s(N5e);UHr=r(ljt,"pretrained_model_name_or_path"),ljt.forEach(t),JHr=r(bA,":"),bA.forEach(t),YHr=i(hi),Xe=n(hi,"UL",{});var Mo=s(Xe);N3=n(Mo,"LI",{});var LGe=s(N3);q5e=n(LGe,"STRONG",{});var ijt=s(q5e);KHr=r(ijt,"albert"),ijt.forEach(t),ZHr=r(LGe," \u2014 "),Yee=n(LGe,"A",{href:!0});var djt=s(Yee);eUr=r(djt,"FlaxAlbertForMultipleChoice"),djt.forEach(t),oUr=r(LGe," (ALBERT model)"),LGe.forEach(t),rUr=i(Mo),q3=n(Mo,"LI",{});var yGe=s(q3);j5e=n(yGe,"STRONG",{});var cjt=s(j5e);tUr=r(cjt,"bert"),cjt.forEach(t),aUr=r(yGe," \u2014 "),Kee=n(yGe,"A",{href:!0});var fjt=s(Kee);nUr=r(fjt,"FlaxBertForMultipleChoice"),fjt.forEach(t),sUr=r(yGe," (BERT model)"),yGe.forEach(t),lUr=i(Mo),j3=n(Mo,"LI",{});var xGe=s(j3);D5e=n(xGe,"STRONG",{});var mjt=s(D5e);iUr=r(mjt,"big_bird"),mjt.forEach(t),dUr=r(xGe," \u2014 "),Zee=n(xGe,"A",{href:!0});var gjt=s(Zee);cUr=r(gjt,"FlaxBigBirdForMultipleChoice"),gjt.forEach(t),fUr=r(xGe," (BigBird model)"),xGe.forEach(t),mUr=i(Mo),D3=n(Mo,"LI",{});var $Ge=s(D3);G5e=n($Ge,"STRONG",{});var hjt=s(G5e);gUr=r(hjt,"distilbert"),hjt.forEach(t),hUr=r($Ge," \u2014 "),eoe=n($Ge,"A",{href:!0});var pjt=s(eoe);pUr=r(pjt,"FlaxDistilBertForMultipleChoice"),pjt.forEach(t),_Ur=r($Ge," (DistilBERT model)"),$Ge.forEach(t),uUr=i(Mo),G3=n(Mo,"LI",{});var kGe=s(G3);O5e=n(kGe,"STRONG",{});var _jt=s(O5e);bUr=r(_jt,"electra"),_jt.forEach(t),vUr=r(kGe," \u2014 "),ooe=n(kGe,"A",{href:!0});var ujt=s(ooe);FUr=r(ujt,"FlaxElectraForMultipleChoice"),ujt.forEach(t),TUr=r(kGe," (ELECTRA model)"),kGe.forEach(t),MUr=i(Mo),O3=n(Mo,"LI",{});var SGe=s(O3);V5e=n(SGe,"STRONG",{});var bjt=s(V5e);EUr=r(bjt,"roberta"),bjt.forEach(t),CUr=r(SGe," \u2014 "),roe=n(SGe,"A",{href:!0});var vjt=s(roe);wUr=r(vjt,"FlaxRobertaForMultipleChoice"),vjt.forEach(t),AUr=r(SGe," (RoBERTa model)"),SGe.forEach(t),LUr=i(Mo),V3=n(Mo,"LI",{});var RGe=s(V3);X5e=n(RGe,"STRONG",{});var Fjt=s(X5e);yUr=r(Fjt,"roformer"),Fjt.forEach(t),xUr=r(RGe," \u2014 "),toe=n(RGe,"A",{href:!0});var Tjt=s(toe);$Ur=r(Tjt,"FlaxRoFormerForMultipleChoice"),Tjt.forEach(t),kUr=r(RGe," (RoFormer model)"),RGe.forEach(t),SUr=i(Mo),X3=n(Mo,"LI",{});var PGe=s(X3);z5e=n(PGe,"STRONG",{});var Mjt=s(z5e);RUr=r(Mjt,"xlm-roberta"),Mjt.forEach(t),PUr=r(PGe," \u2014 "),aoe=n(PGe,"A",{href:!0});var Ejt=s(aoe);BUr=r(Ejt,"FlaxXLMRobertaForMultipleChoice"),Ejt.forEach(t),IUr=r(PGe," (XLM-RoBERTa model)"),PGe.forEach(t),Mo.forEach(t),NUr=i(hi),T(z3.$$.fragment,hi),hi.forEach(t),gi.forEach(t),qVe=i(f),_f=n(f,"H2",{class:!0});var Wze=s(_f);Q3=n(Wze,"A",{id:!0,class:!0,href:!0});var Cjt=s(Q3);Q5e=n(Cjt,"SPAN",{});var wjt=s(Q5e);T(E$.$$.fragment,wjt),wjt.forEach(t),Cjt.forEach(t),qUr=i(Wze),W5e=n(Wze,"SPAN",{});var Ajt=s(W5e);jUr=r(Ajt,"FlaxAutoModelForNextSentencePrediction"),Ajt.forEach(t),Wze.forEach(t),jVe=i(f),Er=n(f,"DIV",{class:!0});var pi=s(Er);T(C$.$$.fragment,pi),DUr=i(pi),uf=n(pi,"P",{});var ste=s(uf);GUr=r(ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=n(ste,"A",{href:!0});var Ljt=s(noe);OUr=r(Ljt,"from_pretrained()"),Ljt.forEach(t),VUr=r(ste," class method or the "),soe=n(ste,"A",{href:!0});var yjt=s(soe);XUr=r(yjt,"from_config()"),yjt.forEach(t),zUr=r(ste,` class
method.`),ste.forEach(t),QUr=i(pi),w$=n(pi,"P",{});var Hze=s(w$);WUr=r(Hze,"This class cannot be instantiated directly using "),H5e=n(Hze,"CODE",{});var xjt=s(H5e);HUr=r(xjt,"__init__()"),xjt.forEach(t),UUr=r(Hze," (throws an error)."),Hze.forEach(t),JUr=i(pi),Zt=n(pi,"DIV",{class:!0});var vA=s(Zt);T(A$.$$.fragment,vA),YUr=i(vA),U5e=n(vA,"P",{});var $jt=s(U5e);KUr=r($jt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$jt.forEach(t),ZUr=i(vA),bf=n(vA,"P",{});var lte=s(bf);eJr=r(lte,`Note:
Loading a model from its configuration file does `),J5e=n(lte,"STRONG",{});var kjt=s(J5e);oJr=r(kjt,"not"),kjt.forEach(t),rJr=r(lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=n(lte,"A",{href:!0});var Sjt=s(loe);tJr=r(Sjt,"from_pretrained()"),Sjt.forEach(t),aJr=r(lte," to load the model weights."),lte.forEach(t),nJr=i(vA),T(W3.$$.fragment,vA),vA.forEach(t),sJr=i(pi),Yr=n(pi,"DIV",{class:!0});var _i=s(Yr);T(L$.$$.fragment,_i),lJr=i(_i),Y5e=n(_i,"P",{});var Rjt=s(Y5e);iJr=r(Rjt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Rjt.forEach(t),dJr=i(_i),xn=n(_i,"P",{});var FA=s(xn);cJr=r(FA,"The model class to instantiate is selected based on the "),K5e=n(FA,"CODE",{});var Pjt=s(K5e);fJr=r(Pjt,"model_type"),Pjt.forEach(t),mJr=r(FA,` property of the config object (either
passed as an argument or loaded from `),Z5e=n(FA,"CODE",{});var Bjt=s(Z5e);gJr=r(Bjt,"pretrained_model_name_or_path"),Bjt.forEach(t),hJr=r(FA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e3e=n(FA,"CODE",{});var Ijt=s(e3e);pJr=r(Ijt,"pretrained_model_name_or_path"),Ijt.forEach(t),_Jr=r(FA,":"),FA.forEach(t),uJr=i(_i),o3e=n(_i,"UL",{});var Njt=s(o3e);H3=n(Njt,"LI",{});var BGe=s(H3);r3e=n(BGe,"STRONG",{});var qjt=s(r3e);bJr=r(qjt,"bert"),qjt.forEach(t),vJr=r(BGe," \u2014 "),ioe=n(BGe,"A",{href:!0});var jjt=s(ioe);FJr=r(jjt,"FlaxBertForNextSentencePrediction"),jjt.forEach(t),TJr=r(BGe," (BERT model)"),BGe.forEach(t),Njt.forEach(t),MJr=i(_i),T(U3.$$.fragment,_i),_i.forEach(t),pi.forEach(t),DVe=i(f),vf=n(f,"H2",{class:!0});var Uze=s(vf);J3=n(Uze,"A",{id:!0,class:!0,href:!0});var Djt=s(J3);t3e=n(Djt,"SPAN",{});var Gjt=s(t3e);T(y$.$$.fragment,Gjt),Gjt.forEach(t),Djt.forEach(t),EJr=i(Uze),a3e=n(Uze,"SPAN",{});var Ojt=s(a3e);CJr=r(Ojt,"FlaxAutoModelForImageClassification"),Ojt.forEach(t),Uze.forEach(t),GVe=i(f),Cr=n(f,"DIV",{class:!0});var ui=s(Cr);T(x$.$$.fragment,ui),wJr=i(ui),Ff=n(ui,"P",{});var ite=s(Ff);AJr=r(ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=n(ite,"A",{href:!0});var Vjt=s(doe);LJr=r(Vjt,"from_pretrained()"),Vjt.forEach(t),yJr=r(ite," class method or the "),coe=n(ite,"A",{href:!0});var Xjt=s(coe);xJr=r(Xjt,"from_config()"),Xjt.forEach(t),$Jr=r(ite,` class
method.`),ite.forEach(t),kJr=i(ui),$$=n(ui,"P",{});var Jze=s($$);SJr=r(Jze,"This class cannot be instantiated directly using "),n3e=n(Jze,"CODE",{});var zjt=s(n3e);RJr=r(zjt,"__init__()"),zjt.forEach(t),PJr=r(Jze," (throws an error)."),Jze.forEach(t),BJr=i(ui),ea=n(ui,"DIV",{class:!0});var TA=s(ea);T(k$.$$.fragment,TA),IJr=i(TA),s3e=n(TA,"P",{});var Qjt=s(s3e);NJr=r(Qjt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Qjt.forEach(t),qJr=i(TA),Tf=n(TA,"P",{});var dte=s(Tf);jJr=r(dte,`Note:
Loading a model from its configuration file does `),l3e=n(dte,"STRONG",{});var Wjt=s(l3e);DJr=r(Wjt,"not"),Wjt.forEach(t),GJr=r(dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=n(dte,"A",{href:!0});var Hjt=s(foe);OJr=r(Hjt,"from_pretrained()"),Hjt.forEach(t),VJr=r(dte," to load the model weights."),dte.forEach(t),XJr=i(TA),T(Y3.$$.fragment,TA),TA.forEach(t),zJr=i(ui),Kr=n(ui,"DIV",{class:!0});var bi=s(Kr);T(S$.$$.fragment,bi),QJr=i(bi),i3e=n(bi,"P",{});var Ujt=s(i3e);WJr=r(Ujt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ujt.forEach(t),HJr=i(bi),$n=n(bi,"P",{});var MA=s($n);UJr=r(MA,"The model class to instantiate is selected based on the "),d3e=n(MA,"CODE",{});var Jjt=s(d3e);JJr=r(Jjt,"model_type"),Jjt.forEach(t),YJr=r(MA,` property of the config object (either
passed as an argument or loaded from `),c3e=n(MA,"CODE",{});var Yjt=s(c3e);KJr=r(Yjt,"pretrained_model_name_or_path"),Yjt.forEach(t),ZJr=r(MA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f3e=n(MA,"CODE",{});var Kjt=s(f3e);eYr=r(Kjt,"pretrained_model_name_or_path"),Kjt.forEach(t),oYr=r(MA,":"),MA.forEach(t),rYr=i(bi),R$=n(bi,"UL",{});var Yze=s(R$);K3=n(Yze,"LI",{});var IGe=s(K3);m3e=n(IGe,"STRONG",{});var Zjt=s(m3e);tYr=r(Zjt,"beit"),Zjt.forEach(t),aYr=r(IGe," \u2014 "),moe=n(IGe,"A",{href:!0});var eDt=s(moe);nYr=r(eDt,"FlaxBeitForImageClassification"),eDt.forEach(t),sYr=r(IGe," (BEiT model)"),IGe.forEach(t),lYr=i(Yze),Z3=n(Yze,"LI",{});var NGe=s(Z3);g3e=n(NGe,"STRONG",{});var oDt=s(g3e);iYr=r(oDt,"vit"),oDt.forEach(t),dYr=r(NGe," \u2014 "),goe=n(NGe,"A",{href:!0});var rDt=s(goe);cYr=r(rDt,"FlaxViTForImageClassification"),rDt.forEach(t),fYr=r(NGe," (ViT model)"),NGe.forEach(t),Yze.forEach(t),mYr=i(bi),T(e0.$$.fragment,bi),bi.forEach(t),ui.forEach(t),OVe=i(f),Mf=n(f,"H2",{class:!0});var Kze=s(Mf);o0=n(Kze,"A",{id:!0,class:!0,href:!0});var tDt=s(o0);h3e=n(tDt,"SPAN",{});var aDt=s(h3e);T(P$.$$.fragment,aDt),aDt.forEach(t),tDt.forEach(t),gYr=i(Kze),p3e=n(Kze,"SPAN",{});var nDt=s(p3e);hYr=r(nDt,"FlaxAutoModelForVision2Seq"),nDt.forEach(t),Kze.forEach(t),VVe=i(f),wr=n(f,"DIV",{class:!0});var vi=s(wr);T(B$.$$.fragment,vi),pYr=i(vi),Ef=n(vi,"P",{});var cte=s(Ef);_Yr=r(cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=n(cte,"A",{href:!0});var sDt=s(hoe);uYr=r(sDt,"from_pretrained()"),sDt.forEach(t),bYr=r(cte," class method or the "),poe=n(cte,"A",{href:!0});var lDt=s(poe);vYr=r(lDt,"from_config()"),lDt.forEach(t),FYr=r(cte,` class
method.`),cte.forEach(t),TYr=i(vi),I$=n(vi,"P",{});var Zze=s(I$);MYr=r(Zze,"This class cannot be instantiated directly using "),_3e=n(Zze,"CODE",{});var iDt=s(_3e);EYr=r(iDt,"__init__()"),iDt.forEach(t),CYr=r(Zze," (throws an error)."),Zze.forEach(t),wYr=i(vi),oa=n(vi,"DIV",{class:!0});var EA=s(oa);T(N$.$$.fragment,EA),AYr=i(EA),u3e=n(EA,"P",{});var dDt=s(u3e);LYr=r(dDt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dDt.forEach(t),yYr=i(EA),Cf=n(EA,"P",{});var fte=s(Cf);xYr=r(fte,`Note:
Loading a model from its configuration file does `),b3e=n(fte,"STRONG",{});var cDt=s(b3e);$Yr=r(cDt,"not"),cDt.forEach(t),kYr=r(fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=n(fte,"A",{href:!0});var fDt=s(_oe);SYr=r(fDt,"from_pretrained()"),fDt.forEach(t),RYr=r(fte," to load the model weights."),fte.forEach(t),PYr=i(EA),T(r0.$$.fragment,EA),EA.forEach(t),BYr=i(vi),Zr=n(vi,"DIV",{class:!0});var Fi=s(Zr);T(q$.$$.fragment,Fi),IYr=i(Fi),v3e=n(Fi,"P",{});var mDt=s(v3e);NYr=r(mDt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),mDt.forEach(t),qYr=i(Fi),kn=n(Fi,"P",{});var CA=s(kn);jYr=r(CA,"The model class to instantiate is selected based on the "),F3e=n(CA,"CODE",{});var gDt=s(F3e);DYr=r(gDt,"model_type"),gDt.forEach(t),GYr=r(CA,` property of the config object (either
passed as an argument or loaded from `),T3e=n(CA,"CODE",{});var hDt=s(T3e);OYr=r(hDt,"pretrained_model_name_or_path"),hDt.forEach(t),VYr=r(CA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M3e=n(CA,"CODE",{});var pDt=s(M3e);XYr=r(pDt,"pretrained_model_name_or_path"),pDt.forEach(t),zYr=r(CA,":"),CA.forEach(t),QYr=i(Fi),E3e=n(Fi,"UL",{});var _Dt=s(E3e);t0=n(_Dt,"LI",{});var qGe=s(t0);C3e=n(qGe,"STRONG",{});var uDt=s(C3e);WYr=r(uDt,"vision-encoder-decoder"),uDt.forEach(t),HYr=r(qGe," \u2014 "),uoe=n(qGe,"A",{href:!0});var bDt=s(uoe);UYr=r(bDt,"FlaxVisionEncoderDecoderModel"),bDt.forEach(t),JYr=r(qGe," (Vision Encoder decoder model)"),qGe.forEach(t),_Dt.forEach(t),YYr=i(Fi),T(a0.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(COt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Rn,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.AutoConfig"),c(Bn,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.AutoModel"),c(In,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.AutoTokenizer"),c(Li,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertModel"),c(Sf,"id","extending-the-auto-classes"),c(Sf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Sf,"href","#extending-the-auto-classes"),c(yi,"class","relative group"),c(Pf,"id","transformers.AutoConfig"),c(Pf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pf,"href","#transformers.AutoConfig"),c(xi,"class","relative group"),c(iS,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(dS,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertConfig"),c(cS,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartConfig"),c(fS,"href","/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitConfig"),c(mS,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertConfig"),c(gS,"href","/docs/transformers/pr_17864/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(hS,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdConfig"),c(pS,"href","/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(_S,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(uS,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(bS,"href","/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomConfig"),c(vS,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertConfig"),c(FS,"href","/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineConfig"),c(TS,"href","/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPConfig"),c(MS,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertConfig"),c(ES,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextConfig"),c(CS,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLConfig"),c(wS,"href","/docs/transformers/pr_17864/en/model_doc/cvt#transformers.CvtConfig"),c(AS,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(LS,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(yS,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(xS,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaConfig"),c($S,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(kS,"href","/docs/transformers/pr_17864/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(SS,"href","/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTConfig"),c(RS,"href","/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrConfig"),c(PS,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertConfig"),c(BS,"href","/docs/transformers/pr_17864/en/model_doc/dpr#transformers.DPRConfig"),c(IS,"href","/docs/transformers/pr_17864/en/model_doc/dpt#transformers.DPTConfig"),c(NS,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraConfig"),c(qS,"href","/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(jS,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertConfig"),c(DS,"href","/docs/transformers/pr_17864/en/model_doc/flava#transformers.FlavaConfig"),c(GS,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetConfig"),c(OS,"href","/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTConfig"),c(VS,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelConfig"),c(XS,"href","/docs/transformers/pr_17864/en/model_doc/glpn#transformers.GLPNConfig"),c(zS,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Config"),c(QS,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(WS,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(HS,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJConfig"),c(US,"href","/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertConfig"),c(JS,"href","/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertConfig"),c(YS,"href","/docs/transformers/pr_17864/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(KS,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(ZS,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(eR,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(oR,"href","/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDConfig"),c(rR,"href","/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitConfig"),c(tR,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerConfig"),c(aR,"href","/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5Config"),c(nR,"href","/docs/transformers/pr_17864/en/model_doc/luke#transformers.LukeConfig"),c(sR,"href","/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertConfig"),c(lR,"href","/docs/transformers/pr_17864/en/model_doc/m2m_100#transformers.M2M100Config"),c(iR,"href","/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianConfig"),c(dR,"href","/docs/transformers/pr_17864/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(cR,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartConfig"),c(fR,"href","/docs/transformers/pr_17864/en/model_doc/mctct#transformers.MCTCTConfig"),c(mR,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(gR,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(hR,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetConfig"),c(pR,"href","/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Config"),c(_R,"href","/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaConfig"),c(uR,"href","/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(bR,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(vR,"href","/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTConfig"),c(FR,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusConfig"),c(TR,"href","/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverConfig"),c(MR,"href","/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartConfig"),c(ER,"href","/docs/transformers/pr_17864/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(CR,"href","/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(wR,"href","/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(AR,"href","/docs/transformers/pr_17864/en/model_doc/rag#transformers.RagConfig"),c(LR,"href","/docs/transformers/pr_17864/en/model_doc/realm#transformers.RealmConfig"),c(yR,"href","/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerConfig"),c(xR,"href","/docs/transformers/pr_17864/en/model_doc/regnet#transformers.RegNetConfig"),c($R,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertConfig"),c(kR,"href","/docs/transformers/pr_17864/en/model_doc/resnet#transformers.ResNetConfig"),c(SR,"href","/docs/transformers/pr_17864/en/model_doc/retribert#transformers.RetriBertConfig"),c(RR,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaConfig"),c(PR,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerConfig"),c(BR,"href","/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerConfig"),c(IR,"href","/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWConfig"),c(NR,"href","/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDConfig"),c(qR,"href","/docs/transformers/pr_17864/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(jR,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(DR,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(GR,"href","/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterConfig"),c(OR,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(VR,"href","/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinConfig"),c(XR,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Config"),c(zR,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasConfig"),c(QR,"href","/docs/transformers/pr_17864/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(WR,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(HR,"href","/docs/transformers/pr_17864/en/model_doc/trocr#transformers.TrOCRConfig"),c(UR,"href","/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(JR,"href","/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(YR,"href","/docs/transformers/pr_17864/en/model_doc/van#transformers.VanConfig"),c(KR,"href","/docs/transformers/pr_17864/en/model_doc/vilt#transformers.ViltConfig"),c(ZR,"href","/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(eP,"href","/docs/transformers/pr_17864/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(oP,"href","/docs/transformers/pr_17864/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(rP,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTConfig"),c(tP,"href","/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(aP,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(nP,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(sP,"href","/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMConfig"),c(lP,"href","/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMConfig"),c(iP,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMConfig"),c(dP,"href","/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(cP,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(fP,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(mP,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetConfig"),c(gP,"href","/docs/transformers/pr_17864/en/model_doc/yolos#transformers.YolosConfig"),c(hP,"href","/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoConfig"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Og,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vg,"id","transformers.AutoTokenizer"),c(Vg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vg,"href","#transformers.AutoTokenizer"),c(ki,"class","relative group"),c(pP,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(_P,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertTokenizer"),c(uP,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(bP,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartTokenizer"),c(vP,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartTokenizerFast"),c(FP,"href","/docs/transformers/pr_17864/en/model_doc/barthez#transformers.BarthezTokenizer"),c(TP,"href","/docs/transformers/pr_17864/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(MP,"href","/docs/transformers/pr_17864/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(EP,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizer"),c(CP,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizerFast"),c(wP,"href","/docs/transformers/pr_17864/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(AP,"href","/docs/transformers/pr_17864/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(LP,"href","/docs/transformers/pr_17864/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(yP,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(xP,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c($P,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(kP,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(SP,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(RP,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(PP,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(BP,"href","/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(IP,"href","/docs/transformers/pr_17864/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(NP,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertTokenizer"),c(qP,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(jP,"href","/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineTokenizer"),c(DP,"href","/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPTokenizer"),c(GP,"href","/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(OP,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(VP,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(XP,"href","/docs/transformers/pr_17864/en/model_doc/cpm#transformers.CpmTokenizer"),c(zP,"href","/docs/transformers/pr_17864/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(QP,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(WP,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaTokenizer"),c(HP,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(UP,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaTokenizer"),c(JP,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(YP,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(KP,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(ZP,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(eB,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(oB,"href","/docs/transformers/pr_17864/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(rB,"href","/docs/transformers/pr_17864/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(tB,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraTokenizer"),c(aB,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(nB,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(sB,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetTokenizer"),c(lB,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(iB,"href","/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(dB,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelTokenizer"),c(cB,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(fB,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(mB,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(gB,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(hB,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(pB,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(_B,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(uB,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(bB,"href","/docs/transformers/pr_17864/en/model_doc/herbert#transformers.HerbertTokenizer"),c(vB,"href","/docs/transformers/pr_17864/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(FB,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(TB,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaTokenizer"),c(MB,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(EB,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(CB,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(wB,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(AB,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(LB,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(yB,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(xB,"href","/docs/transformers/pr_17864/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c($B,"href","/docs/transformers/pr_17864/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(kB,"href","/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDTokenizer"),c(SB,"href","/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDTokenizerFast"),c(RB,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerTokenizer"),c(PB,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(BB,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Tokenizer"),c(IB,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5TokenizerFast"),c(NB,"href","/docs/transformers/pr_17864/en/model_doc/luke#transformers.LukeTokenizer"),c(qB,"href","/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(jB,"href","/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(DB,"href","/docs/transformers/pr_17864/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(GB,"href","/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianTokenizer"),c(OB,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartTokenizer"),c(VB,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(XB,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(zB,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(QB,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizer"),c(WB,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizerFast"),c(HB,"href","/docs/transformers/pr_17864/en/model_doc/mluke#transformers.MLukeTokenizer"),c(UB,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(JB,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(YB,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(KB,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(ZB,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Tokenizer"),c(eI,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5TokenizerFast"),c(oI,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizer"),c(rI,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizerFast"),c(tI,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertTokenizer"),c(aI,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(nI,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(sI,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(lI,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(iI,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(dI,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(cI,"href","/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(fI,"href","/docs/transformers/pr_17864/en/model_doc/phobert#transformers.PhobertTokenizer"),c(mI,"href","/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartTokenizer"),c(gI,"href","/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(hI,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizer"),c(pI,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizerFast"),c(_I,"href","/docs/transformers/pr_17864/en/model_doc/rag#transformers.RagTokenizer"),c(uI,"href","/docs/transformers/pr_17864/en/model_doc/realm#transformers.RealmTokenizer"),c(bI,"href","/docs/transformers/pr_17864/en/model_doc/realm#transformers.RealmTokenizerFast"),c(vI,"href","/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerTokenizer"),c(FI,"href","/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(TI,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertTokenizer"),c(MI,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(EI,"href","/docs/transformers/pr_17864/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(CI,"href","/docs/transformers/pr_17864/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(wI,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaTokenizer"),c(AI,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(LI,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(yI,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(xI,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c($I,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(kI,"href","/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterTokenizer"),c(SI,"href","/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(RI,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(PI,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(BI,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Tokenizer"),c(II,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5TokenizerFast"),c(NI,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasTokenizer"),c(qI,"href","/docs/transformers/pr_17864/en/model_doc/tapex#transformers.TapexTokenizer"),c(jI,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(DI,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizer"),c(GI,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizerFast"),c(OI,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizer"),c(VI,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertTokenizerFast"),c(XI,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(zI,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(QI,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(WI,"href","/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMTokenizer"),c(HI,"href","/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(UI,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMTokenizer"),c(JI,"href","/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(YI,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(KI,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(ZI,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaTokenizer"),c(eN,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(oN,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(rN,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(tN,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertTokenizer"),c(aN,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ch,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wh,"id","transformers.AutoFeatureExtractor"),c(wh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wh,"href","#transformers.AutoFeatureExtractor"),c(Si,"class","relative group"),c(nN,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(sN,"href","/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(lN,"href","/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(iN,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(dN,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(cN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(fN,"href","/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(mN,"href","/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(gN,"href","/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(hN,"href","/docs/transformers/pr_17864/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(pN,"href","/docs/transformers/pr_17864/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(_N,"href","/docs/transformers/pr_17864/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(uN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(bN,"href","/docs/transformers/pr_17864/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(vN,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(FN,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(TN,"href","/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(MN,"href","/docs/transformers/pr_17864/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(EN,"href","/docs/transformers/pr_17864/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(CN,"href","/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(wN,"href","/docs/transformers/pr_17864/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(AN,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(LN,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yN,"href","/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(xN,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c($N,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kN,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(SN,"href","/docs/transformers/pr_17864/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(RN,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PN,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(NN,"href","/docs/transformers/pr_17864/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lp,"id","transformers.AutoProcessor"),c(lp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lp,"href","#transformers.AutoProcessor"),c(Ri,"class","relative group"),c(qN,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(jN,"href","/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPProcessor"),c(DN,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(GN,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(ON,"href","/docs/transformers/pr_17864/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(VN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(XN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(zN,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(QN,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(WN,"href","/docs/transformers/pr_17864/en/model_doc/trocr#transformers.TrOCRProcessor"),c(HN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(JN,"href","/docs/transformers/pr_17864/en/model_doc/vilt#transformers.ViltProcessor"),c(YN,"href","/docs/transformers/pr_17864/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(KN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZN,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eq,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yp,"id","transformers.AutoModel"),c(yp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yp,"href","#transformers.AutoModel"),c(Bi,"class","relative group"),c(oq,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rq,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tq,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aq,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertModel"),c(nq,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartModel"),c(sq,"href","/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitModel"),c(lq,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertModel"),c(iq,"href","/docs/transformers/pr_17864/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(dq,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdModel"),c(cq,"href","/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(fq,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(mq,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(gq,"href","/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomModel"),c(hq,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertModel"),c(pq,"href","/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineModel"),c(_q,"href","/docs/transformers/pr_17864/en/model_doc/clip#transformers.CLIPModel"),c(uq,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertModel"),c(bq,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextModel"),c(vq,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLModel"),c(Fq,"href","/docs/transformers/pr_17864/en/model_doc/cvt#transformers.CvtModel"),c(Tq,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(Mq,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(Eq,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(Cq,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaModel"),c(wq,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(Aq,"href","/docs/transformers/pr_17864/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(Lq,"href","/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTModel"),c(yq,"href","/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrModel"),c(xq,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertModel"),c($q,"href","/docs/transformers/pr_17864/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(kq,"href","/docs/transformers/pr_17864/en/model_doc/dpt#transformers.DPTModel"),c(Sq,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraModel"),c(Rq,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertModel"),c(Pq,"href","/docs/transformers/pr_17864/en/model_doc/flava#transformers.FlavaModel"),c(Bq,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetModel"),c(Iq,"href","/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTModel"),c(Nq,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelModel"),c(qq,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelBaseModel"),c(jq,"href","/docs/transformers/pr_17864/en/model_doc/glpn#transformers.GLPNModel"),c(Dq,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2Model"),c(Gq,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Oq,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Vq,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJModel"),c(Xq,"href","/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertModel"),c(zq,"href","/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertModel"),c(Qq,"href","/docs/transformers/pr_17864/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(Wq,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Hq,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Uq,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Jq,"href","/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDModel"),c(Yq,"href","/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitModel"),c(Kq,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerModel"),c(Zq,"href","/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5Model"),c(ej,"href","/docs/transformers/pr_17864/en/model_doc/luke#transformers.LukeModel"),c(oj,"href","/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertModel"),c(rj,"href","/docs/transformers/pr_17864/en/model_doc/m2m_100#transformers.M2M100Model"),c(tj,"href","/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianModel"),c(aj,"href","/docs/transformers/pr_17864/en/model_doc/maskformer#transformers.MaskFormerModel"),c(nj,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartModel"),c(sj,"href","/docs/transformers/pr_17864/en/model_doc/mctct#transformers.MCTCTModel"),c(lj,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(ij,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertModel"),c(dj,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetModel"),c(cj,"href","/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5Model"),c(fj,"href","/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaModel"),c(mj,"href","/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerModel"),c(gj,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(hj,"href","/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTModel"),c(pj,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusModel"),c(_j,"href","/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverModel"),c(uj,"href","/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartModel"),c(bj,"href","/docs/transformers/pr_17864/en/model_doc/poolformer#transformers.PoolFormerModel"),c(vj,"href","/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Fj,"href","/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Tj,"href","/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerModel"),c(Mj,"href","/docs/transformers/pr_17864/en/model_doc/regnet#transformers.RegNetModel"),c(Ej,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertModel"),c(Cj,"href","/docs/transformers/pr_17864/en/model_doc/resnet#transformers.ResNetModel"),c(wj,"href","/docs/transformers/pr_17864/en/model_doc/retribert#transformers.RetriBertModel"),c(Aj,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaModel"),c(Lj,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerModel"),c(yj,"href","/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerModel"),c(xj,"href","/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWModel"),c($j,"href","/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDModel"),c(kj,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Sj,"href","/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterModel"),c(Rj,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(Pj,"href","/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinModel"),c(Bj,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5Model"),c(Ij,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasModel"),c(Nj,"href","/docs/transformers/pr_17864/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(qj,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(jj,"href","/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Dj,"href","/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Gj,"href","/docs/transformers/pr_17864/en/model_doc/van#transformers.VanModel"),c(Oj,"href","/docs/transformers/pr_17864/en/model_doc/vilt#transformers.ViltModel"),c(Vj,"href","/docs/transformers/pr_17864/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Xj,"href","/docs/transformers/pr_17864/en/model_doc/visual_bert#transformers.VisualBertModel"),c(zj,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTModel"),c(Qj,"href","/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Wj,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Hj,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Uj,"href","/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMModel"),c(Jj,"href","/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMModel"),c(Yj,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMModel"),c(Kj,"href","/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Zj,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(eD,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(oD,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetModel"),c(rD,"href","/docs/transformers/pr_17864/en/model_doc/yolos#transformers.YolosModel"),c(tD,"href","/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($u,"id","transformers.AutoModelForPreTraining"),c($u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($u,"href","#transformers.AutoModelForPreTraining"),c(qi,"class","relative group"),c(aD,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nD,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sD,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lD,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForPreTraining"),c(iD,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(dD,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForPreTraining"),c(cD,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(fD,"href","/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomForCausalLM"),c(mD,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(gD,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(hD,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(pD,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(_D,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(uD,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(bD,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForPreTraining"),c(vD,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(FD,"href","/docs/transformers/pr_17864/en/model_doc/flava#transformers.FlavaForPreTraining"),c(TD,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForPreTraining"),c(MD,"href","/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(ED,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(CD,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(wD,"href","/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(AD,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(LD,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(yD,"href","/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(xD,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c($D,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(kD,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(SD,"href","/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(RD,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(PD,"href","/docs/transformers/pr_17864/en/model_doc/retribert#transformers.RetriBertModel"),c(BD,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(ID,"href","/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(ND,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(qD,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(jD,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(DD,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(GD,"href","/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(OD,"href","/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(VD,"href","/docs/transformers/pr_17864/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(XD,"href","/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(zD,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(QD,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(WD,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(HD,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(UD,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(JD,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C1,"id","transformers.AutoModelForCausalLM"),c(C1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C1,"href","#transformers.AutoModelForCausalLM"),c(Gi,"class","relative group"),c(YD,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KD,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZD,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eG,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForCausalLM"),c(oG,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertLMHeadModel"),c(rG,"href","/docs/transformers/pr_17864/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(tG,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(aG,"href","/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(nG,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(sG,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(lG,"href","/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomForCausalLM"),c(iG,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(dG,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(cG,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(fG,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForCausalLM"),c(mG,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(gG,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(hG,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(pG,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(_G,"href","/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianForCausalLM"),c(uG,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForCausalLM"),c(bG,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(vG,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(FG,"href","/docs/transformers/pr_17864/en/model_doc/opt#transformers.OPTForCausalLM"),c(TG,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(MG,"href","/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(EG,"href","/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(CG,"href","/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(wG,"href","/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(AG,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(LG,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(yG,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(xG,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c($G,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(kG,"href","/docs/transformers/pr_17864/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(SG,"href","/docs/transformers/pr_17864/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(RG,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(PG,"href","/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(BG,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(IG,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(NG,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m2,"id","transformers.AutoModelForMaskedLM"),c(m2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m2,"href","#transformers.AutoModelForMaskedLM"),c(Xi,"class","relative group"),c(qG,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jG,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DG,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GG,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(OG,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(VG,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForMaskedLM"),c(XG,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(zG,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(QG,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(WG,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(HG,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(UG,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(JG,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(YG,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(KG,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(ZG,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(eO,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(oO,"href","/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(rO,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(tO,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(aO,"href","/docs/transformers/pr_17864/en/model_doc/luke#transformers.LukeForMaskedLM"),c(nO,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(sO,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(lO,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(iO,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(dO,"href","/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(cO,"href","/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(fO,"href","/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(mO,"href","/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(gO,"href","/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(hO,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(pO,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(_O,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(uO,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(bO,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(vO,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(FO,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(TO,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(MO,"href","/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z2,"id","transformers.AutoModelForSeq2SeqLM"),c(Z2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z2,"href","#transformers.AutoModelForSeq2SeqLM"),c(Wi,"class","relative group"),c(EO,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CO,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wO,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AO,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(LO,"href","/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(yO,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(xO,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c($O,"href","/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(kO,"href","/docs/transformers/pr_17864/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(SO,"href","/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(RO,"href","/docs/transformers/pr_17864/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(PO,"href","/docs/transformers/pr_17864/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(BO,"href","/docs/transformers/pr_17864/en/model_doc/marian#transformers.MarianMTModel"),c(IO,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(NO,"href","/docs/transformers/pr_17864/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(qO,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(jO,"href","/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(DO,"href","/docs/transformers/pr_17864/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(GO,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(OO,"href","/docs/transformers/pr_17864/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fb,"id","transformers.AutoModelForSequenceClassification"),c(Fb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fb,"href","#transformers.AutoModelForSequenceClassification"),c(Ji,"class","relative group"),c(VO,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XO,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zO,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QO,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(WO,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForSequenceClassification"),c(HO,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForSequenceClassification"),c(UO,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(JO,"href","/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(YO,"href","/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(KO,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(ZO,"href","/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(eV,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(oV,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(rV,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(tV,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(aV,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(nV,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(sV,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(lV,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(iV,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(dV,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(cV,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(fV,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(mV,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(gV,"href","/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(hV,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(pV,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(_V,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(uV,"href","/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDForSequenceClassification"),c(bV,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(vV,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(FV,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(TV,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(MV,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(EV,"href","/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(CV,"href","/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(wV,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(AV,"href","/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(LV,"href","/docs/transformers/pr_17864/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(yV,"href","/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(xV,"href","/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c($V,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(kV,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(SV,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(RV,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(PV,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(BV,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(IV,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(NV,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(qV,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(jV,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(DV,"href","/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v4,"id","transformers.AutoModelForMultipleChoice"),c(v4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v4,"href","#transformers.AutoModelForMultipleChoice"),c(Zi,"class","relative group"),c(GV,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OV,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VV,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XV,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(zV,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForMultipleChoice"),c(QV,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(WV,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(HV,"href","/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(UV,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(JV,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(YV,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(KV,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(ZV,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(eX,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(oX,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(rX,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(tX,"href","/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(aX,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(nX,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(sX,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(lX,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(iX,"href","/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(dX,"href","/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(cX,"href","/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(fX,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(mX,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(gX,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(hX,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(pX,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(_X,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(uX,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(bX,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(vX,"href","/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z4,"id","transformers.AutoModelForNextSentencePrediction"),c(Z4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z4,"href","#transformers.AutoModelForNextSentencePrediction"),c(rd,"class","relative group"),c(FX,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TX,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MX,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EX,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(CX,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(wX,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(AX,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(LX,"href","/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(yX,"href","/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dv,"id","transformers.AutoModelForTokenClassification"),c(dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dv,"href","#transformers.AutoModelForTokenClassification"),c(nd,"class","relative group"),c(xX,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($X,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kX,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SX,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(RX,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForTokenClassification"),c(PX,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(BX,"href","/docs/transformers/pr_17864/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(IX,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(NX,"href","/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineForTokenClassification"),c(qX,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(jX,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(DX,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(GX,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(OX,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(VX,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(XX,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(zX,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(QX,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(WX,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(HX,"href","/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(UX,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(JX,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(YX,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(KX,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(ZX,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(ez,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(oz,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(rz,"href","/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(tz,"href","/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(az,"href","/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(nz,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(sz,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(lz,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(iz,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(dz,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(cz,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(fz,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(mz,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(gz,"href","/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uv,"id","transformers.AutoModelForQuestionAnswering"),c(Uv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uv,"href","#transformers.AutoModelForQuestionAnswering"),c(id,"class","relative group"),c(hz,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pz,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_z,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uz,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(bz,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(vz,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(Fz,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(Tz,"href","/docs/transformers/pr_17864/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(Mz,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(Ez,"href","/docs/transformers/pr_17864/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(Cz,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(wz,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(Az,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(Lz,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(yz,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(xz,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c($z,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(kz,"href","/docs/transformers/pr_17864/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(Sz,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(Rz,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(Pz,"href","/docs/transformers/pr_17864/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(Bz,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(Iz,"href","/docs/transformers/pr_17864/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(Nz,"href","/docs/transformers/pr_17864/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(qz,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(jz,"href","/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(Dz,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(Gz,"href","/docs/transformers/pr_17864/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(Oz,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(Vz,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(Xz,"href","/docs/transformers/pr_17864/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(zz,"href","/docs/transformers/pr_17864/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(Qz,"href","/docs/transformers/pr_17864/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(Wz,"href","/docs/transformers/pr_17864/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(Hz,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(Uz,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(Jz,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(Yz,"href","/docs/transformers/pr_17864/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(Kz,"href","/docs/transformers/pr_17864/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(Zz,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(eQ,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(oQ,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(rQ,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(tQ,"href","/docs/transformers/pr_17864/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DF,"id","transformers.AutoModelForTableQuestionAnswering"),c(DF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DF,"href","#transformers.AutoModelForTableQuestionAnswering"),c(fd,"class","relative group"),c(aQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lQ,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zF,"id","transformers.AutoModelForImageClassification"),c(zF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zF,"href","#transformers.AutoModelForImageClassification"),c(hd,"class","relative group"),c(iQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fQ,"href","/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitForImageClassification"),c(mQ,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(gQ,"href","/docs/transformers/pr_17864/en/model_doc/cvt#transformers.CvtForImageClassification"),c(hQ,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(pQ,"href","/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTForImageClassification"),c(_Q,"href","/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(uQ,"href","/docs/transformers/pr_17864/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(bQ,"href","/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitForImageClassification"),c(vQ,"href","/docs/transformers/pr_17864/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(FQ,"href","/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(TQ,"href","/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(MQ,"href","/docs/transformers/pr_17864/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(EQ,"href","/docs/transformers/pr_17864/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(CQ,"href","/docs/transformers/pr_17864/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(wQ,"href","/docs/transformers/pr_17864/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(AQ,"href","/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(LQ,"href","/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinForImageClassification"),c(yQ,"href","/docs/transformers/pr_17864/en/model_doc/van#transformers.VanForImageClassification"),c(xQ,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l6,"id","transformers.AutoModelForVision2Seq"),c(l6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l6,"href","#transformers.AutoModelForVision2Seq"),c(ud,"class","relative group"),c($Q,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RQ,"href","/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m6,"id","transformers.AutoModelForVisualQuestionAnswering"),c(m6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m6,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Fd,"class","relative group"),c(PQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NQ,"href","/docs/transformers/pr_17864/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u6,"id","transformers.AutoModelForAudioClassification"),c(u6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u6,"href","#transformers.AutoModelForAudioClassification"),c(Ed,"class","relative group"),c(qQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GQ,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(OQ,"href","/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(VQ,"href","/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(XQ,"href","/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(zQ,"href","/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(QQ,"href","/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(WQ,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(HQ,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(UQ,"href","/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($6,"id","transformers.AutoModelForAudioFrameClassification"),c($6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($6,"href","#transformers.AutoModelForAudioFrameClassification"),c(Ad,"class","relative group"),c(JQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KQ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZQ,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(eW,"href","/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(oW,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(rW,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(tW,"href","/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j6,"id","transformers.AutoModelForCTC"),c(j6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j6,"href","#transformers.AutoModelForCTC"),c(xd,"class","relative group"),c(aW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lW,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(iW,"href","/docs/transformers/pr_17864/en/model_doc/hubert#transformers.HubertForCTC"),c(dW,"href","/docs/transformers/pr_17864/en/model_doc/mctct#transformers.MCTCTForCTC"),c(cW,"href","/docs/transformers/pr_17864/en/model_doc/sew#transformers.SEWForCTC"),c(fW,"href","/docs/transformers/pr_17864/en/model_doc/sew-d#transformers.SEWDForCTC"),c(mW,"href","/docs/transformers/pr_17864/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(gW,"href","/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(hW,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(pW,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(_W,"href","/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z6,"id","transformers.AutoModelForSpeechSeq2Seq"),c(Z6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z6,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Sd,"class","relative group"),c(uW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FW,"href","/docs/transformers/pr_17864/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(TW,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nT,"id","transformers.AutoModelForAudioXVector"),c(nT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nT,"href","#transformers.AutoModelForAudioXVector"),c(Bd,"class","relative group"),c(MW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wW,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(AW,"href","/docs/transformers/pr_17864/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(LW,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(yW,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(xW,"href","/docs/transformers/pr_17864/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hT,"id","transformers.AutoModelForMaskedImageModeling"),c(hT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hT,"href","#transformers.AutoModelForMaskedImageModeling"),c(qd,"class","relative group"),c($W,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RW,"href","/docs/transformers/pr_17864/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(PW,"href","/docs/transformers/pr_17864/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(BW,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TT,"id","transformers.AutoModelForObjectDetection"),c(TT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TT,"href","#transformers.AutoModelForObjectDetection"),c(Od,"class","relative group"),c(IW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jW,"href","/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrForObjectDetection"),c(DW,"href","/docs/transformers/pr_17864/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LT,"id","transformers.AutoModelForImageSegmentation"),c(LT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LT,"href","#transformers.AutoModelForImageSegmentation"),c(zd,"class","relative group"),c(GW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XW,"href","/docs/transformers/pr_17864/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ST,"id","transformers.AutoModelForSemanticSegmentation"),c(ST,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ST,"href","#transformers.AutoModelForSemanticSegmentation"),c(Hd,"class","relative group"),c(zW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HW,"href","/docs/transformers/pr_17864/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(UW,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(JW,"href","/docs/transformers/pr_17864/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(YW,"href","/docs/transformers/pr_17864/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DT,"id","transformers.AutoModelForInstanceSegmentation"),c(DT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DT,"href","#transformers.AutoModelForInstanceSegmentation"),c(Yd,"class","relative group"),c(KW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZW,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eH,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oH,"href","/docs/transformers/pr_17864/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zT,"id","transformers.TFAutoModel"),c(zT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zT,"href","#transformers.TFAutoModel"),c(ec,"class","relative group"),c(rH,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tH,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aH,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nH,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertModel"),c(sH,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.TFBartModel"),c(lH,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertModel"),c(iH,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(dH,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(cH,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertModel"),c(fH,"href","/docs/transformers/pr_17864/en/model_doc/clip#transformers.TFCLIPModel"),c(mH,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertModel"),c(gH,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.TFConvNextModel"),c(hH,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.TFCTRLModel"),c(pH,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(_H,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaModel"),c(uH,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(bH,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(vH,"href","/docs/transformers/pr_17864/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(FH,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraModel"),c(TH,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(MH,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelModel"),c(EH,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(CH,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.TFGPT2Model"),c(wH,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.TFGPTJModel"),c(AH,"href","/docs/transformers/pr_17864/en/model_doc/hubert#transformers.TFHubertModel"),c(LH,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(yH,"href","/docs/transformers/pr_17864/en/model_doc/led#transformers.TFLEDModel"),c(xH,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerModel"),c($H,"href","/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.TFLxmertModel"),c(kH,"href","/docs/transformers/pr_17864/en/model_doc/marian#transformers.TFMarianModel"),c(SH,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.TFMBartModel"),c(RH,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(PH,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetModel"),c(BH,"href","/docs/transformers/pr_17864/en/model_doc/mt5#transformers.TFMT5Model"),c(IH,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(NH,"href","/docs/transformers/pr_17864/en/model_doc/opt#transformers.TFOPTModel"),c(qH,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.TFPegasusModel"),c(jH,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertModel"),c(DH,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaModel"),c(GH,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerModel"),c(OH,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(VH,"href","/docs/transformers/pr_17864/en/model_doc/swin#transformers.TFSwinModel"),c(XH,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.TFT5Model"),c(zH,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasModel"),c(QH,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(WH,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.TFViTModel"),c(HH,"href","/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(UH,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(JH,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMModel"),c(YH,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(KH,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D7,"id","transformers.TFAutoModelForPreTraining"),c(D7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D7,"href","#transformers.TFAutoModelForPreTraining"),c(tc,"class","relative group"),c(ZH,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rU,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(tU,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(aU,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForPreTraining"),c(nU,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(sU,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(lU,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(iU,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(dU,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(cU,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(fU,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(mU,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(gU,"href","/docs/transformers/pr_17864/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(hU,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(pU,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(_U,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(uU,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(bU,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(vU,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(FU,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(TU,"href","/docs/transformers/pr_17864/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(MU,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(EU,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(CU,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m8,"id","transformers.TFAutoModelForCausalLM"),c(m8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m8,"href","#transformers.TFAutoModelForCausalLM"),c(sc,"class","relative group"),c(wU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yU,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(xU,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c($U,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(kU,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(SU,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(RU,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(PU,"href","/docs/transformers/pr_17864/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(BU,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(IU,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(NU,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(qU,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(jU,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(DU,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y8,"id","transformers.TFAutoModelForImageClassification"),c(y8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y8,"href","#transformers.TFAutoModelForImageClassification"),c(dc,"class","relative group"),c(GU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XU,"href","/docs/transformers/pr_17864/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(zU,"href","/docs/transformers/pr_17864/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(QU,"href","/docs/transformers/pr_17864/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(WU,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.TFViTForImageClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B8,"id","transformers.TFAutoModelForMaskedLM"),c(B8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B8,"href","#transformers.TFAutoModelForMaskedLM"),c(mc,"class","relative group"),c(HU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JU,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YU,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(KU,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(ZU,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(eJ,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(oJ,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(rJ,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(tJ,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(aJ,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(nJ,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(sJ,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(lJ,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(iJ,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(dJ,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(cJ,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(fJ,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(mJ,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(gJ,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(hJ,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(pJ,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(_J,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aM,"id","transformers.TFAutoModelForSeq2SeqLM"),c(aM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aM,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(pc,"class","relative group"),c(uJ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bJ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vJ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FJ,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(TJ,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(MJ,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(EJ,"href","/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(CJ,"href","/docs/transformers/pr_17864/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(wJ,"href","/docs/transformers/pr_17864/en/model_doc/marian#transformers.TFMarianMTModel"),c(AJ,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(LJ,"href","/docs/transformers/pr_17864/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(yJ,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(xJ,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uM,"id","transformers.TFAutoModelForSequenceClassification"),c(uM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uM,"href","#transformers.TFAutoModelForSequenceClassification"),c(bc,"class","relative group"),c($J,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kJ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SJ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RJ,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(PJ,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(BJ,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(IJ,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(NJ,"href","/docs/transformers/pr_17864/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(qJ,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(jJ,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(DJ,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(GJ,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(OJ,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(VJ,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(XJ,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(zJ,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(QJ,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(WJ,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(HJ,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(UJ,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(JJ,"href","/docs/transformers/pr_17864/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(YJ,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(KJ,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(ZJ,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(eY,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(oY,"href","/docs/transformers/pr_17864/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(rY,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(tY,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(aY,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QM,"id","transformers.TFAutoModelForMultipleChoice"),c(QM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QM,"href","#transformers.TFAutoModelForMultipleChoice"),c(Tc,"class","relative group"),c(nY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iY,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(dY,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(cY,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(fY,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(mY,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(gY,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(hY,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(pY,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(_Y,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(uY,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(bY,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(vY,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(FY,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(TY,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(MY,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(EY,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(CY,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mE,"id","transformers.TFAutoModelForNextSentencePrediction"),c(mE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mE,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Cc,"class","relative group"),c(wY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yY,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(xY,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uE,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(uE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uE,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Lc,"class","relative group"),c($Y,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RY,"href","/docs/transformers/pr_17864/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TE,"id","transformers.TFAutoModelForTokenClassification"),c(TE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TE,"href","#transformers.TFAutoModelForTokenClassification"),c($c,"class","relative group"),c(PY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(qY,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(jY,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(DY,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(GY,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(OY,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(VY,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(XY,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(zY,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(QY,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(WY,"href","/docs/transformers/pr_17864/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(HY,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(UY,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(JY,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(YY,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(KY,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(ZY,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(eK,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(oK,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(rK,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XE,"id","transformers.TFAutoModelForQuestionAnswering"),c(XE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XE,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Rc,"class","relative group"),c(tK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(lK,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(iK,"href","/docs/transformers/pr_17864/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(dK,"href","/docs/transformers/pr_17864/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(cK,"href","/docs/transformers/pr_17864/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(fK,"href","/docs/transformers/pr_17864/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(mK,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(gK,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(hK,"href","/docs/transformers/pr_17864/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(pK,"href","/docs/transformers/pr_17864/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(_K,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(uK,"href","/docs/transformers/pr_17864/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(bK,"href","/docs/transformers/pr_17864/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(vK,"href","/docs/transformers/pr_17864/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(FK,"href","/docs/transformers/pr_17864/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(TK,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(MK,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(EK,"href","/docs/transformers/pr_17864/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(CK,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(wK,"href","/docs/transformers/pr_17864/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gC,"id","transformers.TFAutoModelForVision2Seq"),c(gC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gC,"href","#transformers.TFAutoModelForVision2Seq"),c(Ic,"class","relative group"),c(AK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xK,"href","/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uC,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(uC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uC,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(jc,"class","relative group"),c($K,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/pr_17864/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TC,"id","transformers.FlaxAutoModel"),c(TC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TC,"href","#transformers.FlaxAutoModel"),c(Oc,"class","relative group"),c(PK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertModel"),c(qK,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartModel"),c(jK,"href","/docs/transformers/pr_17864/en/model_doc/beit#transformers.FlaxBeitModel"),c(DK,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertModel"),c(GK,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(OK,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(VK,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(XK,"href","/docs/transformers/pr_17864/en/model_doc/clip#transformers.FlaxCLIPModel"),c(zK,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(QK,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraModel"),c(WK,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(HK,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(UK,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(JK,"href","/docs/transformers/pr_17864/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(YK,"href","/docs/transformers/pr_17864/en/model_doc/marian#transformers.FlaxMarianModel"),c(KK,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartModel"),c(ZK,"href","/docs/transformers/pr_17864/en/model_doc/mt5#transformers.FlaxMT5Model"),c(eZ,"href","/docs/transformers/pr_17864/en/model_doc/opt#transformers.FlaxOPTModel"),c(oZ,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(rZ,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(tZ,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(aZ,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.FlaxT5Model"),c(nZ,"href","/docs/transformers/pr_17864/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(sZ,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.FlaxViTModel"),c(lZ,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(iZ,"href","/docs/transformers/pr_17864/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(dZ,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YC,"id","transformers.FlaxAutoModelForCausalLM"),c(YC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YC,"href","#transformers.FlaxAutoModelForCausalLM"),c(zc,"class","relative group"),c(cZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gZ,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(hZ,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(pZ,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(_Z,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(uZ,"href","/docs/transformers/pr_17864/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(bZ,"href","/docs/transformers/pr_17864/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(vZ,"href","/docs/transformers/pr_17864/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(FZ,"href","/docs/transformers/pr_17864/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(TZ,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(MZ,"href","/docs/transformers/pr_17864/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c5,"id","transformers.FlaxAutoModelForPreTraining"),c(c5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c5,"href","#transformers.FlaxAutoModelForPreTraining"),c(Hc,"class","relative group"),c(EZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AZ,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(LZ,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(yZ,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(xZ,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c($Z,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(kZ,"href","/docs/transformers/pr_17864/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(SZ,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(RZ,"href","/docs/transformers/pr_17864/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(PZ,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(BZ,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(IZ,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(NZ,"href","/docs/transformers/pr_17864/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(qZ,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A5,"id","transformers.FlaxAutoModelForMaskedLM"),c(A5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A5,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Yc,"class","relative group"),c(jZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OZ,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(VZ,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(XZ,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(zZ,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(QZ,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(WZ,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(HZ,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(UZ,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(JZ,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(YZ,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j5,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(j5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j5,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(ef,"class","relative group"),c(KZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZZ,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oee,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(ree,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(tee,"href","/docs/transformers/pr_17864/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(aee,"href","/docs/transformers/pr_17864/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(nee,"href","/docs/transformers/pr_17864/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(see,"href","/docs/transformers/pr_17864/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(lee,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(iee,"href","/docs/transformers/pr_17864/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(dee,"href","/docs/transformers/pr_17864/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(cee,"href","/docs/transformers/pr_17864/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K5,"id","transformers.FlaxAutoModelForSequenceClassification"),c(K5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K5,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(tf,"class","relative group"),c(fee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hee,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(pee,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(_ee,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(uee,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(bee,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(vee,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Fee,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Tee,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Mee,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Eee,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f3,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(f3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f3,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(sf,"class","relative group"),c(Cee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lee,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(yee,"href","/docs/transformers/pr_17864/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(xee,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c($ee,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(kee,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(See,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Ree,"href","/docs/transformers/pr_17864/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Pee,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Bee,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Iee,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C3,"id","transformers.FlaxAutoModelForTokenClassification"),c(C3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C3,"href","#transformers.FlaxAutoModelForTokenClassification"),c(cf,"class","relative group"),c(Nee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dee,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Gee,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Oee,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Vee,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Xee,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(zee,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Qee,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Wee,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B3,"id","transformers.FlaxAutoModelForMultipleChoice"),c(B3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B3,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(gf,"class","relative group"),c(Hee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jee,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yee,"href","/docs/transformers/pr_17864/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Kee,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Zee,"href","/docs/transformers/pr_17864/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(eoe,"href","/docs/transformers/pr_17864/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(ooe,"href","/docs/transformers/pr_17864/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(roe,"href","/docs/transformers/pr_17864/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(toe,"href","/docs/transformers/pr_17864/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(aoe,"href","/docs/transformers/pr_17864/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q3,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Q3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q3,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(_f,"class","relative group"),c(noe,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(soe,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(loe,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ioe,"href","/docs/transformers/pr_17864/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J3,"id","transformers.FlaxAutoModelForImageClassification"),c(J3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J3,"href","#transformers.FlaxAutoModelForImageClassification"),c(vf,"class","relative group"),c(doe,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(foe,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(moe,"href","/docs/transformers/pr_17864/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(goe,"href","/docs/transformers/pr_17864/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o0,"id","transformers.FlaxAutoModelForVision2Seq"),c(o0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o0,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Mf,"class","relative group"),c(hoe,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(poe,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_oe,"href","/docs/transformers/pr_17864/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uoe,"href","/docs/transformers/pr_17864/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Eo),e(Eo,Ti),b(f,yf,u),b(f,at,u),e(at,Mi),e(at,Ei),e(Ei,wA),e(at,xf),b(f,Oe,u),b(f,Qe,u),e(Qe,Ci),e(Qe,Rn),e(Rn,AA),e(Qe,Pn),e(Qe,Bn),e(Bn,LA),e(Qe,wi),e(Qe,In),e(In,yA),e(Qe,Ai),b(f,$f,u),M(xa,f,u),b(f,We,u),b(f,Ae,u),e(Ae,rS),e(Ae,Li),e(Li,tS),e(Ae,aS),b(f,Co,u),b(f,$a,u),e($a,nS),e($a,kf),e(kf,sS),e($a,eQe),b(f,jGe,u),b(f,yi,u),e(yi,Sf),e(Sf,mte),M(xA,mte,null),e(yi,oQe),e(yi,gte),e(gte,rQe),b(f,DGe,u),b(f,Nn,u),e(Nn,tQe),e(Nn,hte),e(hte,aQe),e(Nn,nQe),e(Nn,pte),e(pte,sQe),e(Nn,lQe),b(f,GGe,u),M($A,f,u),b(f,OGe,u),b(f,lS,u),e(lS,iQe),b(f,VGe,u),M(Rf,f,u),b(f,XGe,u),b(f,xi,u),e(xi,Pf),e(Pf,_te),M(kA,_te,null),e(xi,dQe),e(xi,ute),e(ute,cQe),b(f,zGe,u),b(f,wo,u),M(SA,wo,null),e(wo,fQe),e(wo,RA),e(RA,mQe),e(RA,iS),e(iS,gQe),e(RA,hQe),e(wo,pQe),e(wo,PA),e(PA,_Qe),e(PA,bte),e(bte,uQe),e(PA,bQe),e(wo,vQe),e(wo,Ar),M(BA,Ar,null),e(Ar,FQe),e(Ar,vte),e(vte,TQe),e(Ar,MQe),e(Ar,$i),e($i,EQe),e($i,Fte),e(Fte,CQe),e($i,wQe),e($i,Tte),e(Tte,AQe),e($i,LQe),e(Ar,yQe),e(Ar,A),e(A,Bf),e(Bf,Mte),e(Mte,xQe),e(Bf,$Qe),e(Bf,dS),e(dS,kQe),e(Bf,SQe),e(A,RQe),e(A,If),e(If,Ete),e(Ete,PQe),e(If,BQe),e(If,cS),e(cS,IQe),e(If,NQe),e(A,qQe),e(A,Nf),e(Nf,Cte),e(Cte,jQe),e(Nf,DQe),e(Nf,fS),e(fS,GQe),e(Nf,OQe),e(A,VQe),e(A,qf),e(qf,wte),e(wte,XQe),e(qf,zQe),e(qf,mS),e(mS,QQe),e(qf,WQe),e(A,HQe),e(A,jf),e(jf,Ate),e(Ate,UQe),e(jf,JQe),e(jf,gS),e(gS,YQe),e(jf,KQe),e(A,ZQe),e(A,Df),e(Df,Lte),e(Lte,eWe),e(Df,oWe),e(Df,hS),e(hS,rWe),e(Df,tWe),e(A,aWe),e(A,Gf),e(Gf,yte),e(yte,nWe),e(Gf,sWe),e(Gf,pS),e(pS,lWe),e(Gf,iWe),e(A,dWe),e(A,Of),e(Of,xte),e(xte,cWe),e(Of,fWe),e(Of,_S),e(_S,mWe),e(Of,gWe),e(A,hWe),e(A,Vf),e(Vf,$te),e($te,pWe),e(Vf,_We),e(Vf,uS),e(uS,uWe),e(Vf,bWe),e(A,vWe),e(A,Xf),e(Xf,kte),e(kte,FWe),e(Xf,TWe),e(Xf,bS),e(bS,MWe),e(Xf,EWe),e(A,CWe),e(A,zf),e(zf,Ste),e(Ste,wWe),e(zf,AWe),e(zf,vS),e(vS,LWe),e(zf,yWe),e(A,xWe),e(A,Qf),e(Qf,Rte),e(Rte,$We),e(Qf,kWe),e(Qf,FS),e(FS,SWe),e(Qf,RWe),e(A,PWe),e(A,Wf),e(Wf,Pte),e(Pte,BWe),e(Wf,IWe),e(Wf,TS),e(TS,NWe),e(Wf,qWe),e(A,jWe),e(A,Hf),e(Hf,Bte),e(Bte,DWe),e(Hf,GWe),e(Hf,MS),e(MS,OWe),e(Hf,VWe),e(A,XWe),e(A,Uf),e(Uf,Ite),e(Ite,zWe),e(Uf,QWe),e(Uf,ES),e(ES,WWe),e(Uf,HWe),e(A,UWe),e(A,Jf),e(Jf,Nte),e(Nte,JWe),e(Jf,YWe),e(Jf,CS),e(CS,KWe),e(Jf,ZWe),e(A,eHe),e(A,Yf),e(Yf,qte),e(qte,oHe),e(Yf,rHe),e(Yf,wS),e(wS,tHe),e(Yf,aHe),e(A,nHe),e(A,Kf),e(Kf,jte),e(jte,sHe),e(Kf,lHe),e(Kf,AS),e(AS,iHe),e(Kf,dHe),e(A,cHe),e(A,Zf),e(Zf,Dte),e(Dte,fHe),e(Zf,mHe),e(Zf,LS),e(LS,gHe),e(Zf,hHe),e(A,pHe),e(A,em),e(em,Gte),e(Gte,_He),e(em,uHe),e(em,yS),e(yS,bHe),e(em,vHe),e(A,FHe),e(A,om),e(om,Ote),e(Ote,THe),e(om,MHe),e(om,xS),e(xS,EHe),e(om,CHe),e(A,wHe),e(A,rm),e(rm,Vte),e(Vte,AHe),e(rm,LHe),e(rm,$S),e($S,yHe),e(rm,xHe),e(A,$He),e(A,tm),e(tm,Xte),e(Xte,kHe),e(tm,SHe),e(tm,kS),e(kS,RHe),e(tm,PHe),e(A,BHe),e(A,am),e(am,zte),e(zte,IHe),e(am,NHe),e(am,SS),e(SS,qHe),e(am,jHe),e(A,DHe),e(A,nm),e(nm,Qte),e(Qte,GHe),e(nm,OHe),e(nm,RS),e(RS,VHe),e(nm,XHe),e(A,zHe),e(A,sm),e(sm,Wte),e(Wte,QHe),e(sm,WHe),e(sm,PS),e(PS,HHe),e(sm,UHe),e(A,JHe),e(A,lm),e(lm,Hte),e(Hte,YHe),e(lm,KHe),e(lm,BS),e(BS,ZHe),e(lm,eUe),e(A,oUe),e(A,im),e(im,Ute),e(Ute,rUe),e(im,tUe),e(im,IS),e(IS,aUe),e(im,nUe),e(A,sUe),e(A,dm),e(dm,Jte),e(Jte,lUe),e(dm,iUe),e(dm,NS),e(NS,dUe),e(dm,cUe),e(A,fUe),e(A,cm),e(cm,Yte),e(Yte,mUe),e(cm,gUe),e(cm,qS),e(qS,hUe),e(cm,pUe),e(A,_Ue),e(A,fm),e(fm,Kte),e(Kte,uUe),e(fm,bUe),e(fm,jS),e(jS,vUe),e(fm,FUe),e(A,TUe),e(A,mm),e(mm,Zte),e(Zte,MUe),e(mm,EUe),e(mm,DS),e(DS,CUe),e(mm,wUe),e(A,AUe),e(A,gm),e(gm,eae),e(eae,LUe),e(gm,yUe),e(gm,GS),e(GS,xUe),e(gm,$Ue),e(A,kUe),e(A,hm),e(hm,oae),e(oae,SUe),e(hm,RUe),e(hm,OS),e(OS,PUe),e(hm,BUe),e(A,IUe),e(A,pm),e(pm,rae),e(rae,NUe),e(pm,qUe),e(pm,VS),e(VS,jUe),e(pm,DUe),e(A,GUe),e(A,_m),e(_m,tae),e(tae,OUe),e(_m,VUe),e(_m,XS),e(XS,XUe),e(_m,zUe),e(A,QUe),e(A,um),e(um,aae),e(aae,WUe),e(um,HUe),e(um,zS),e(zS,UUe),e(um,JUe),e(A,YUe),e(A,bm),e(bm,nae),e(nae,KUe),e(bm,ZUe),e(bm,QS),e(QS,eJe),e(bm,oJe),e(A,rJe),e(A,vm),e(vm,sae),e(sae,tJe),e(vm,aJe),e(vm,WS),e(WS,nJe),e(vm,sJe),e(A,lJe),e(A,Fm),e(Fm,lae),e(lae,iJe),e(Fm,dJe),e(Fm,HS),e(HS,cJe),e(Fm,fJe),e(A,mJe),e(A,Tm),e(Tm,iae),e(iae,gJe),e(Tm,hJe),e(Tm,US),e(US,pJe),e(Tm,_Je),e(A,uJe),e(A,Mm),e(Mm,dae),e(dae,bJe),e(Mm,vJe),e(Mm,JS),e(JS,FJe),e(Mm,TJe),e(A,MJe),e(A,Em),e(Em,cae),e(cae,EJe),e(Em,CJe),e(Em,YS),e(YS,wJe),e(Em,AJe),e(A,LJe),e(A,Cm),e(Cm,fae),e(fae,yJe),e(Cm,xJe),e(Cm,KS),e(KS,$Je),e(Cm,kJe),e(A,SJe),e(A,wm),e(wm,mae),e(mae,RJe),e(wm,PJe),e(wm,ZS),e(ZS,BJe),e(wm,IJe),e(A,NJe),e(A,Am),e(Am,gae),e(gae,qJe),e(Am,jJe),e(Am,eR),e(eR,DJe),e(Am,GJe),e(A,OJe),e(A,Lm),e(Lm,hae),e(hae,VJe),e(Lm,XJe),e(Lm,oR),e(oR,zJe),e(Lm,QJe),e(A,WJe),e(A,ym),e(ym,pae),e(pae,HJe),e(ym,UJe),e(ym,rR),e(rR,JJe),e(ym,YJe),e(A,KJe),e(A,xm),e(xm,_ae),e(_ae,ZJe),e(xm,eYe),e(xm,tR),e(tR,oYe),e(xm,rYe),e(A,tYe),e(A,$m),e($m,uae),e(uae,aYe),e($m,nYe),e($m,aR),e(aR,sYe),e($m,lYe),e(A,iYe),e(A,km),e(km,bae),e(bae,dYe),e(km,cYe),e(km,nR),e(nR,fYe),e(km,mYe),e(A,gYe),e(A,Sm),e(Sm,vae),e(vae,hYe),e(Sm,pYe),e(Sm,sR),e(sR,_Ye),e(Sm,uYe),e(A,bYe),e(A,Rm),e(Rm,Fae),e(Fae,vYe),e(Rm,FYe),e(Rm,lR),e(lR,TYe),e(Rm,MYe),e(A,EYe),e(A,Pm),e(Pm,Tae),e(Tae,CYe),e(Pm,wYe),e(Pm,iR),e(iR,AYe),e(Pm,LYe),e(A,yYe),e(A,Bm),e(Bm,Mae),e(Mae,xYe),e(Bm,$Ye),e(Bm,dR),e(dR,kYe),e(Bm,SYe),e(A,RYe),e(A,Im),e(Im,Eae),e(Eae,PYe),e(Im,BYe),e(Im,cR),e(cR,IYe),e(Im,NYe),e(A,qYe),e(A,Nm),e(Nm,Cae),e(Cae,jYe),e(Nm,DYe),e(Nm,fR),e(fR,GYe),e(Nm,OYe),e(A,VYe),e(A,qm),e(qm,wae),e(wae,XYe),e(qm,zYe),e(qm,mR),e(mR,QYe),e(qm,WYe),e(A,HYe),e(A,jm),e(jm,Aae),e(Aae,UYe),e(jm,JYe),e(jm,gR),e(gR,YYe),e(jm,KYe),e(A,ZYe),e(A,Dm),e(Dm,Lae),e(Lae,eKe),e(Dm,oKe),e(Dm,hR),e(hR,rKe),e(Dm,tKe),e(A,aKe),e(A,Gm),e(Gm,yae),e(yae,nKe),e(Gm,sKe),e(Gm,pR),e(pR,lKe),e(Gm,iKe),e(A,dKe),e(A,Om),e(Om,xae),e(xae,cKe),e(Om,fKe),e(Om,_R),e(_R,mKe),e(Om,gKe),e(A,hKe),e(A,Vm),e(Vm,$ae),e($ae,pKe),e(Vm,_Ke),e(Vm,uR),e(uR,uKe),e(Vm,bKe),e(A,vKe),e(A,Xm),e(Xm,kae),e(kae,FKe),e(Xm,TKe),e(Xm,bR),e(bR,MKe),e(Xm,EKe),e(A,CKe),e(A,zm),e(zm,Sae),e(Sae,wKe),e(zm,AKe),e(zm,vR),e(vR,LKe),e(zm,yKe),e(A,xKe),e(A,Qm),e(Qm,Rae),e(Rae,$Ke),e(Qm,kKe),e(Qm,FR),e(FR,SKe),e(Qm,RKe),e(A,PKe),e(A,Wm),e(Wm,Pae),e(Pae,BKe),e(Wm,IKe),e(Wm,TR),e(TR,NKe),e(Wm,qKe),e(A,jKe),e(A,Hm),e(Hm,Bae),e(Bae,DKe),e(Hm,GKe),e(Hm,MR),e(MR,OKe),e(Hm,VKe),e(A,XKe),e(A,Um),e(Um,Iae),e(Iae,zKe),e(Um,QKe),e(Um,ER),e(ER,WKe),e(Um,HKe),e(A,UKe),e(A,Jm),e(Jm,Nae),e(Nae,JKe),e(Jm,YKe),e(Jm,CR),e(CR,KKe),e(Jm,ZKe),e(A,eZe),e(A,Ym),e(Ym,qae),e(qae,oZe),e(Ym,rZe),e(Ym,wR),e(wR,tZe),e(Ym,aZe),e(A,nZe),e(A,Km),e(Km,jae),e(jae,sZe),e(Km,lZe),e(Km,AR),e(AR,iZe),e(Km,dZe),e(A,cZe),e(A,Zm),e(Zm,Dae),e(Dae,fZe),e(Zm,mZe),e(Zm,LR),e(LR,gZe),e(Zm,hZe),e(A,pZe),e(A,eg),e(eg,Gae),e(Gae,_Ze),e(eg,uZe),e(eg,yR),e(yR,bZe),e(eg,vZe),e(A,FZe),e(A,og),e(og,Oae),e(Oae,TZe),e(og,MZe),e(og,xR),e(xR,EZe),e(og,CZe),e(A,wZe),e(A,rg),e(rg,Vae),e(Vae,AZe),e(rg,LZe),e(rg,$R),e($R,yZe),e(rg,xZe),e(A,$Ze),e(A,tg),e(tg,Xae),e(Xae,kZe),e(tg,SZe),e(tg,kR),e(kR,RZe),e(tg,PZe),e(A,BZe),e(A,ag),e(ag,zae),e(zae,IZe),e(ag,NZe),e(ag,SR),e(SR,qZe),e(ag,jZe),e(A,DZe),e(A,ng),e(ng,Qae),e(Qae,GZe),e(ng,OZe),e(ng,RR),e(RR,VZe),e(ng,XZe),e(A,zZe),e(A,sg),e(sg,Wae),e(Wae,QZe),e(sg,WZe),e(sg,PR),e(PR,HZe),e(sg,UZe),e(A,JZe),e(A,lg),e(lg,Hae),e(Hae,YZe),e(lg,KZe),e(lg,BR),e(BR,ZZe),e(lg,eeo),e(A,oeo),e(A,ig),e(ig,Uae),e(Uae,reo),e(ig,teo),e(ig,IR),e(IR,aeo),e(ig,neo),e(A,seo),e(A,dg),e(dg,Jae),e(Jae,leo),e(dg,ieo),e(dg,NR),e(NR,deo),e(dg,ceo),e(A,feo),e(A,cg),e(cg,Yae),e(Yae,meo),e(cg,geo),e(cg,qR),e(qR,heo),e(cg,peo),e(A,_eo),e(A,fg),e(fg,Kae),e(Kae,ueo),e(fg,beo),e(fg,jR),e(jR,veo),e(fg,Feo),e(A,Teo),e(A,mg),e(mg,Zae),e(Zae,Meo),e(mg,Eeo),e(mg,DR),e(DR,Ceo),e(mg,weo),e(A,Aeo),e(A,gg),e(gg,ene),e(ene,Leo),e(gg,yeo),e(gg,GR),e(GR,xeo),e(gg,$eo),e(A,keo),e(A,hg),e(hg,one),e(one,Seo),e(hg,Reo),e(hg,OR),e(OR,Peo),e(hg,Beo),e(A,Ieo),e(A,pg),e(pg,rne),e(rne,Neo),e(pg,qeo),e(pg,VR),e(VR,jeo),e(pg,Deo),e(A,Geo),e(A,_g),e(_g,tne),e(tne,Oeo),e(_g,Veo),e(_g,XR),e(XR,Xeo),e(_g,zeo),e(A,Qeo),e(A,ug),e(ug,ane),e(ane,Weo),e(ug,Heo),e(ug,zR),e(zR,Ueo),e(ug,Jeo),e(A,Yeo),e(A,bg),e(bg,nne),e(nne,Keo),e(bg,Zeo),e(bg,QR),e(QR,eoo),e(bg,ooo),e(A,roo),e(A,vg),e(vg,sne),e(sne,too),e(vg,aoo),e(vg,WR),e(WR,noo),e(vg,soo),e(A,loo),e(A,Fg),e(Fg,lne),e(lne,ioo),e(Fg,doo),e(Fg,HR),e(HR,coo),e(Fg,foo),e(A,moo),e(A,Tg),e(Tg,ine),e(ine,goo),e(Tg,hoo),e(Tg,UR),e(UR,poo),e(Tg,_oo),e(A,uoo),e(A,Mg),e(Mg,dne),e(dne,boo),e(Mg,voo),e(Mg,JR),e(JR,Foo),e(Mg,Too),e(A,Moo),e(A,Eg),e(Eg,cne),e(cne,Eoo),e(Eg,Coo),e(Eg,YR),e(YR,woo),e(Eg,Aoo),e(A,Loo),e(A,Cg),e(Cg,fne),e(fne,yoo),e(Cg,xoo),e(Cg,KR),e(KR,$oo),e(Cg,koo),e(A,Soo),e(A,wg),e(wg,mne),e(mne,Roo),e(wg,Poo),e(wg,ZR),e(ZR,Boo),e(wg,Ioo),e(A,Noo),e(A,Ag),e(Ag,gne),e(gne,qoo),e(Ag,joo),e(Ag,eP),e(eP,Doo),e(Ag,Goo),e(A,Ooo),e(A,Lg),e(Lg,hne),e(hne,Voo),e(Lg,Xoo),e(Lg,oP),e(oP,zoo),e(Lg,Qoo),e(A,Woo),e(A,yg),e(yg,pne),e(pne,Hoo),e(yg,Uoo),e(yg,rP),e(rP,Joo),e(yg,Yoo),e(A,Koo),e(A,xg),e(xg,_ne),e(_ne,Zoo),e(xg,ero),e(xg,tP),e(tP,oro),e(xg,rro),e(A,tro),e(A,$g),e($g,une),e(une,aro),e($g,nro),e($g,aP),e(aP,sro),e($g,lro),e(A,iro),e(A,kg),e(kg,bne),e(bne,dro),e(kg,cro),e(kg,nP),e(nP,fro),e(kg,mro),e(A,gro),e(A,Sg),e(Sg,vne),e(vne,hro),e(Sg,pro),e(Sg,sP),e(sP,_ro),e(Sg,uro),e(A,bro),e(A,Rg),e(Rg,Fne),e(Fne,vro),e(Rg,Fro),e(Rg,lP),e(lP,Tro),e(Rg,Mro),e(A,Ero),e(A,Pg),e(Pg,Tne),e(Tne,Cro),e(Pg,wro),e(Pg,iP),e(iP,Aro),e(Pg,Lro),e(A,yro),e(A,Bg),e(Bg,Mne),e(Mne,xro),e(Bg,$ro),e(Bg,dP),e(dP,kro),e(Bg,Sro),e(A,Rro),e(A,Ig),e(Ig,Ene),e(Ene,Pro),e(Ig,Bro),e(Ig,cP),e(cP,Iro),e(Ig,Nro),e(A,qro),e(A,Ng),e(Ng,Cne),e(Cne,jro),e(Ng,Dro),e(Ng,fP),e(fP,Gro),e(Ng,Oro),e(A,Vro),e(A,qg),e(qg,wne),e(wne,Xro),e(qg,zro),e(qg,mP),e(mP,Qro),e(qg,Wro),e(A,Hro),e(A,jg),e(jg,Ane),e(Ane,Uro),e(jg,Jro),e(jg,gP),e(gP,Yro),e(jg,Kro),e(A,Zro),e(A,Dg),e(Dg,Lne),e(Lne,eto),e(Dg,oto),e(Dg,hP),e(hP,rto),e(Dg,tto),e(Ar,ato),M(Gg,Ar,null),e(wo,nto),e(wo,Og),M(IA,Og,null),e(Og,sto),e(Og,yne),e(yne,lto),b(f,QGe,u),b(f,ki,u),e(ki,Vg),e(Vg,xne),M(NA,xne,null),e(ki,ito),e(ki,$ne),e($ne,dto),b(f,WGe,u),b(f,Ao,u),M(qA,Ao,null),e(Ao,cto),e(Ao,jA),e(jA,fto),e(jA,pP),e(pP,mto),e(jA,gto),e(Ao,hto),e(Ao,DA),e(DA,pto),e(DA,kne),e(kne,_to),e(DA,uto),e(Ao,bto),e(Ao,Lr),M(GA,Lr,null),e(Lr,vto),e(Lr,Sne),e(Sne,Fto),e(Lr,Tto),e(Lr,ka),e(ka,Mto),e(ka,Rne),e(Rne,Eto),e(ka,Cto),e(ka,Pne),e(Pne,wto),e(ka,Ato),e(ka,Bne),e(Bne,Lto),e(ka,yto),e(Lr,xto),e(Lr,k),e(k,qn),e(qn,Ine),e(Ine,$to),e(qn,kto),e(qn,_P),e(_P,Sto),e(qn,Rto),e(qn,uP),e(uP,Pto),e(qn,Bto),e(k,Ito),e(k,jn),e(jn,Nne),e(Nne,Nto),e(jn,qto),e(jn,bP),e(bP,jto),e(jn,Dto),e(jn,vP),e(vP,Gto),e(jn,Oto),e(k,Vto),e(k,Dn),e(Dn,qne),e(qne,Xto),e(Dn,zto),e(Dn,FP),e(FP,Qto),e(Dn,Wto),e(Dn,TP),e(TP,Hto),e(Dn,Uto),e(k,Jto),e(k,Xg),e(Xg,jne),e(jne,Yto),e(Xg,Kto),e(Xg,MP),e(MP,Zto),e(Xg,eao),e(k,oao),e(k,Gn),e(Gn,Dne),e(Dne,rao),e(Gn,tao),e(Gn,EP),e(EP,aao),e(Gn,nao),e(Gn,CP),e(CP,sao),e(Gn,lao),e(k,iao),e(k,zg),e(zg,Gne),e(Gne,dao),e(zg,cao),e(zg,wP),e(wP,fao),e(zg,mao),e(k,gao),e(k,Qg),e(Qg,One),e(One,hao),e(Qg,pao),e(Qg,AP),e(AP,_ao),e(Qg,uao),e(k,bao),e(k,Wg),e(Wg,Vne),e(Vne,vao),e(Wg,Fao),e(Wg,LP),e(LP,Tao),e(Wg,Mao),e(k,Eao),e(k,On),e(On,Xne),e(Xne,Cao),e(On,wao),e(On,yP),e(yP,Aao),e(On,Lao),e(On,xP),e(xP,yao),e(On,xao),e(k,$ao),e(k,Vn),e(Vn,zne),e(zne,kao),e(Vn,Sao),e(Vn,$P),e($P,Rao),e(Vn,Pao),e(Vn,kP),e(kP,Bao),e(Vn,Iao),e(k,Nao),e(k,Xn),e(Xn,Qne),e(Qne,qao),e(Xn,jao),e(Xn,SP),e(SP,Dao),e(Xn,Gao),e(Xn,RP),e(RP,Oao),e(Xn,Vao),e(k,Xao),e(k,Hg),e(Hg,Wne),e(Wne,zao),e(Hg,Qao),e(Hg,PP),e(PP,Wao),e(Hg,Hao),e(k,Uao),e(k,Ug),e(Ug,Hne),e(Hne,Jao),e(Ug,Yao),e(Ug,BP),e(BP,Kao),e(Ug,Zao),e(k,eno),e(k,Jg),e(Jg,Une),e(Une,ono),e(Jg,rno),e(Jg,IP),e(IP,tno),e(Jg,ano),e(k,nno),e(k,zn),e(zn,Jne),e(Jne,sno),e(zn,lno),e(zn,NP),e(NP,ino),e(zn,dno),e(zn,qP),e(qP,cno),e(zn,fno),e(k,mno),e(k,Yg),e(Yg,Yne),e(Yne,gno),e(Yg,hno),e(Yg,jP),e(jP,pno),e(Yg,_no),e(k,uno),e(k,Qn),e(Qn,Kne),e(Kne,bno),e(Qn,vno),e(Qn,DP),e(DP,Fno),e(Qn,Tno),e(Qn,GP),e(GP,Mno),e(Qn,Eno),e(k,Cno),e(k,Wn),e(Wn,Zne),e(Zne,wno),e(Wn,Ano),e(Wn,OP),e(OP,Lno),e(Wn,yno),e(Wn,VP),e(VP,xno),e(Wn,$no),e(k,kno),e(k,Hn),e(Hn,ese),e(ese,Sno),e(Hn,Rno),e(Hn,XP),e(XP,Pno),e(Hn,Bno),e(Hn,zP),e(zP,Ino),e(Hn,Nno),e(k,qno),e(k,Kg),e(Kg,ose),e(ose,jno),e(Kg,Dno),e(Kg,QP),e(QP,Gno),e(Kg,Ono),e(k,Vno),e(k,Un),e(Un,rse),e(rse,Xno),e(Un,zno),e(Un,WP),e(WP,Qno),e(Un,Wno),e(Un,HP),e(HP,Hno),e(Un,Uno),e(k,Jno),e(k,Jn),e(Jn,tse),e(tse,Yno),e(Jn,Kno),e(Jn,UP),e(UP,Zno),e(Jn,eso),e(Jn,JP),e(JP,oso),e(Jn,rso),e(k,tso),e(k,Yn),e(Yn,ase),e(ase,aso),e(Yn,nso),e(Yn,YP),e(YP,sso),e(Yn,lso),e(Yn,KP),e(KP,iso),e(Yn,dso),e(k,cso),e(k,Kn),e(Kn,nse),e(nse,fso),e(Kn,mso),e(Kn,ZP),e(ZP,gso),e(Kn,hso),e(Kn,eB),e(eB,pso),e(Kn,_so),e(k,uso),e(k,Zn),e(Zn,sse),e(sse,bso),e(Zn,vso),e(Zn,oB),e(oB,Fso),e(Zn,Tso),e(Zn,rB),e(rB,Mso),e(Zn,Eso),e(k,Cso),e(k,es),e(es,lse),e(lse,wso),e(es,Aso),e(es,tB),e(tB,Lso),e(es,yso),e(es,aB),e(aB,xso),e(es,$so),e(k,kso),e(k,Zg),e(Zg,ise),e(ise,Sso),e(Zg,Rso),e(Zg,nB),e(nB,Pso),e(Zg,Bso),e(k,Iso),e(k,os),e(os,dse),e(dse,Nso),e(os,qso),e(os,sB),e(sB,jso),e(os,Dso),e(os,lB),e(lB,Gso),e(os,Oso),e(k,Vso),e(k,eh),e(eh,cse),e(cse,Xso),e(eh,zso),e(eh,iB),e(iB,Qso),e(eh,Wso),e(k,Hso),e(k,rs),e(rs,fse),e(fse,Uso),e(rs,Jso),e(rs,dB),e(dB,Yso),e(rs,Kso),e(rs,cB),e(cB,Zso),e(rs,elo),e(k,olo),e(k,ts),e(ts,mse),e(mse,rlo),e(ts,tlo),e(ts,fB),e(fB,alo),e(ts,nlo),e(ts,mB),e(mB,slo),e(ts,llo),e(k,ilo),e(k,as),e(as,gse),e(gse,dlo),e(as,clo),e(as,gB),e(gB,flo),e(as,mlo),e(as,hB),e(hB,glo),e(as,hlo),e(k,plo),e(k,oh),e(oh,hse),e(hse,_lo),e(oh,ulo),e(oh,pB),e(pB,blo),e(oh,vlo),e(k,Flo),e(k,ns),e(ns,pse),e(pse,Tlo),e(ns,Mlo),e(ns,_B),e(_B,Elo),e(ns,Clo),e(ns,uB),e(uB,wlo),e(ns,Alo),e(k,Llo),e(k,ss),e(ss,_se),e(_se,ylo),e(ss,xlo),e(ss,bB),e(bB,$lo),e(ss,klo),e(ss,vB),e(vB,Slo),e(ss,Rlo),e(k,Plo),e(k,rh),e(rh,use),e(use,Blo),e(rh,Ilo),e(rh,FB),e(FB,Nlo),e(rh,qlo),e(k,jlo),e(k,ls),e(ls,bse),e(bse,Dlo),e(ls,Glo),e(ls,TB),e(TB,Olo),e(ls,Vlo),e(ls,MB),e(MB,Xlo),e(ls,zlo),e(k,Qlo),e(k,is),e(is,vse),e(vse,Wlo),e(is,Hlo),e(is,EB),e(EB,Ulo),e(is,Jlo),e(is,CB),e(CB,Ylo),e(is,Klo),e(k,Zlo),e(k,ds),e(ds,Fse),e(Fse,eio),e(ds,oio),e(ds,wB),e(wB,rio),e(ds,tio),e(ds,AB),e(AB,aio),e(ds,nio),e(k,sio),e(k,cs),e(cs,Tse),e(Tse,lio),e(cs,iio),e(cs,LB),e(LB,dio),e(cs,cio),e(cs,yB),e(yB,fio),e(cs,mio),e(k,gio),e(k,fs),e(fs,Mse),e(Mse,hio),e(fs,pio),e(fs,xB),e(xB,_io),e(fs,uio),e(fs,$B),e($B,bio),e(fs,vio),e(k,Fio),e(k,ms),e(ms,Ese),e(Ese,Tio),e(ms,Mio),e(ms,kB),e(kB,Eio),e(ms,Cio),e(ms,SB),e(SB,wio),e(ms,Aio),e(k,Lio),e(k,gs),e(gs,Cse),e(Cse,yio),e(gs,xio),e(gs,RB),e(RB,$io),e(gs,kio),e(gs,PB),e(PB,Sio),e(gs,Rio),e(k,Pio),e(k,hs),e(hs,wse),e(wse,Bio),e(hs,Iio),e(hs,BB),e(BB,Nio),e(hs,qio),e(hs,IB),e(IB,jio),e(hs,Dio),e(k,Gio),e(k,th),e(th,Ase),e(Ase,Oio),e(th,Vio),e(th,NB),e(NB,Xio),e(th,zio),e(k,Qio),e(k,ps),e(ps,Lse),e(Lse,Wio),e(ps,Hio),e(ps,qB),e(qB,Uio),e(ps,Jio),e(ps,jB),e(jB,Yio),e(ps,Kio),e(k,Zio),e(k,ah),e(ah,yse),e(yse,edo),e(ah,odo),e(ah,DB),e(DB,rdo),e(ah,tdo),e(k,ado),e(k,nh),e(nh,xse),e(xse,ndo),e(nh,sdo),e(nh,GB),e(GB,ldo),e(nh,ido),e(k,ddo),e(k,_s),e(_s,$se),e($se,cdo),e(_s,fdo),e(_s,OB),e(OB,mdo),e(_s,gdo),e(_s,VB),e(VB,hdo),e(_s,pdo),e(k,_do),e(k,us),e(us,kse),e(kse,udo),e(us,bdo),e(us,XB),e(XB,vdo),e(us,Fdo),e(us,zB),e(zB,Tdo),e(us,Mdo),e(k,Edo),e(k,bs),e(bs,Sse),e(Sse,Cdo),e(bs,wdo),e(bs,QB),e(QB,Ado),e(bs,Ldo),e(bs,WB),e(WB,ydo),e(bs,xdo),e(k,$do),e(k,sh),e(sh,Rse),e(Rse,kdo),e(sh,Sdo),e(sh,HB),e(HB,Rdo),e(sh,Pdo),e(k,Bdo),e(k,vs),e(vs,Pse),e(Pse,Ido),e(vs,Ndo),e(vs,UB),e(UB,qdo),e(vs,jdo),e(vs,JB),e(JB,Ddo),e(vs,Gdo),e(k,Odo),e(k,Fs),e(Fs,Bse),e(Bse,Vdo),e(Fs,Xdo),e(Fs,YB),e(YB,zdo),e(Fs,Qdo),e(Fs,KB),e(KB,Wdo),e(Fs,Hdo),e(k,Udo),e(k,Ts),e(Ts,Ise),e(Ise,Jdo),e(Ts,Ydo),e(Ts,ZB),e(ZB,Kdo),e(Ts,Zdo),e(Ts,eI),e(eI,eco),e(Ts,oco),e(k,rco),e(k,Ms),e(Ms,Nse),e(Nse,tco),e(Ms,aco),e(Ms,oI),e(oI,nco),e(Ms,sco),e(Ms,rI),e(rI,lco),e(Ms,ico),e(k,dco),e(k,Es),e(Es,qse),e(qse,cco),e(Es,fco),e(Es,tI),e(tI,mco),e(Es,gco),e(Es,aI),e(aI,hco),e(Es,pco),e(k,_co),e(k,Cs),e(Cs,jse),e(jse,uco),e(Cs,bco),e(Cs,nI),e(nI,vco),e(Cs,Fco),e(Cs,sI),e(sI,Tco),e(Cs,Mco),e(k,Eco),e(k,lh),e(lh,Dse),e(Dse,Cco),e(lh,wco),e(lh,lI),e(lI,Aco),e(lh,Lco),e(k,yco),e(k,ws),e(ws,Gse),e(Gse,xco),e(ws,$co),e(ws,iI),e(iI,kco),e(ws,Sco),e(ws,dI),e(dI,Rco),e(ws,Pco),e(k,Bco),e(k,ih),e(ih,Ose),e(Ose,Ico),e(ih,Nco),e(ih,cI),e(cI,qco),e(ih,jco),e(k,Dco),e(k,dh),e(dh,Vse),e(Vse,Gco),e(dh,Oco),e(dh,fI),e(fI,Vco),e(dh,Xco),e(k,zco),e(k,ch),e(ch,Xse),e(Xse,Qco),e(ch,Wco),e(ch,mI),e(mI,Hco),e(ch,Uco),e(k,Jco),e(k,fh),e(fh,zse),e(zse,Yco),e(fh,Kco),e(fh,gI),e(gI,Zco),e(fh,efo),e(k,ofo),e(k,As),e(As,Qse),e(Qse,rfo),e(As,tfo),e(As,hI),e(hI,afo),e(As,nfo),e(As,pI),e(pI,sfo),e(As,lfo),e(k,ifo),e(k,mh),e(mh,Wse),e(Wse,dfo),e(mh,cfo),e(mh,_I),e(_I,ffo),e(mh,mfo),e(k,gfo),e(k,Ls),e(Ls,Hse),e(Hse,hfo),e(Ls,pfo),e(Ls,uI),e(uI,_fo),e(Ls,ufo),e(Ls,bI),e(bI,bfo),e(Ls,vfo),e(k,Ffo),e(k,ys),e(ys,Use),e(Use,Tfo),e(ys,Mfo),e(ys,vI),e(vI,Efo),e(ys,Cfo),e(ys,FI),e(FI,wfo),e(ys,Afo),e(k,Lfo),e(k,xs),e(xs,Jse),e(Jse,yfo),e(xs,xfo),e(xs,TI),e(TI,$fo),e(xs,kfo),e(xs,MI),e(MI,Sfo),e(xs,Rfo),e(k,Pfo),e(k,$s),e($s,Yse),e(Yse,Bfo),e($s,Ifo),e($s,EI),e(EI,Nfo),e($s,qfo),e($s,CI),e(CI,jfo),e($s,Dfo),e(k,Gfo),e(k,ks),e(ks,Kse),e(Kse,Ofo),e(ks,Vfo),e(ks,wI),e(wI,Xfo),e(ks,zfo),e(ks,AI),e(AI,Qfo),e(ks,Wfo),e(k,Hfo),e(k,Ss),e(Ss,Zse),e(Zse,Ufo),e(Ss,Jfo),e(Ss,LI),e(LI,Yfo),e(Ss,Kfo),e(Ss,yI),e(yI,Zfo),e(Ss,emo),e(k,omo),e(k,gh),e(gh,ele),e(ele,rmo),e(gh,tmo),e(gh,xI),e(xI,amo),e(gh,nmo),e(k,smo),e(k,hh),e(hh,ole),e(ole,lmo),e(hh,imo),e(hh,$I),e($I,dmo),e(hh,cmo),e(k,fmo),e(k,Rs),e(Rs,rle),e(rle,mmo),e(Rs,gmo),e(Rs,kI),e(kI,hmo),e(Rs,pmo),e(Rs,SI),e(SI,_mo),e(Rs,umo),e(k,bmo),e(k,Ps),e(Ps,tle),e(tle,vmo),e(Ps,Fmo),e(Ps,RI),e(RI,Tmo),e(Ps,Mmo),e(Ps,PI),e(PI,Emo),e(Ps,Cmo),e(k,wmo),e(k,Bs),e(Bs,ale),e(ale,Amo),e(Bs,Lmo),e(Bs,BI),e(BI,ymo),e(Bs,xmo),e(Bs,II),e(II,$mo),e(Bs,kmo),e(k,Smo),e(k,ph),e(ph,nle),e(nle,Rmo),e(ph,Pmo),e(ph,NI),e(NI,Bmo),e(ph,Imo),e(k,Nmo),e(k,_h),e(_h,sle),e(sle,qmo),e(_h,jmo),e(_h,qI),e(qI,Dmo),e(_h,Gmo),e(k,Omo),e(k,uh),e(uh,lle),e(lle,Vmo),e(uh,Xmo),e(uh,jI),e(jI,zmo),e(uh,Qmo),e(k,Wmo),e(k,Is),e(Is,ile),e(ile,Hmo),e(Is,Umo),e(Is,DI),e(DI,Jmo),e(Is,Ymo),e(Is,GI),e(GI,Kmo),e(Is,Zmo),e(k,ego),e(k,Ns),e(Ns,dle),e(dle,ogo),e(Ns,rgo),e(Ns,OI),e(OI,tgo),e(Ns,ago),e(Ns,VI),e(VI,ngo),e(Ns,sgo),e(k,lgo),e(k,bh),e(bh,cle),e(cle,igo),e(bh,dgo),e(bh,XI),e(XI,cgo),e(bh,fgo),e(k,mgo),e(k,vh),e(vh,fle),e(fle,ggo),e(vh,hgo),e(vh,zI),e(zI,pgo),e(vh,_go),e(k,ugo),e(k,Fh),e(Fh,mle),e(mle,bgo),e(Fh,vgo),e(Fh,QI),e(QI,Fgo),e(Fh,Tgo),e(k,Mgo),e(k,qs),e(qs,gle),e(gle,Ego),e(qs,Cgo),e(qs,WI),e(WI,wgo),e(qs,Ago),e(qs,HI),e(HI,Lgo),e(qs,ygo),e(k,xgo),e(k,Th),e(Th,hle),e(hle,$go),e(Th,kgo),e(Th,UI),e(UI,Sgo),e(Th,Rgo),e(k,Pgo),e(k,Mh),e(Mh,ple),e(ple,Bgo),e(Mh,Igo),e(Mh,JI),e(JI,Ngo),e(Mh,qgo),e(k,jgo),e(k,js),e(js,_le),e(_le,Dgo),e(js,Ggo),e(js,YI),e(YI,Ogo),e(js,Vgo),e(js,KI),e(KI,Xgo),e(js,zgo),e(k,Qgo),e(k,Ds),e(Ds,ule),e(ule,Wgo),e(Ds,Hgo),e(Ds,ZI),e(ZI,Ugo),e(Ds,Jgo),e(Ds,eN),e(eN,Ygo),e(Ds,Kgo),e(k,Zgo),e(k,Gs),e(Gs,ble),e(ble,eho),e(Gs,oho),e(Gs,oN),e(oN,rho),e(Gs,tho),e(Gs,rN),e(rN,aho),e(Gs,nho),e(k,sho),e(k,Os),e(Os,vle),e(vle,lho),e(Os,iho),e(Os,tN),e(tN,dho),e(Os,cho),e(Os,aN),e(aN,fho),e(Os,mho),e(Lr,gho),M(Eh,Lr,null),e(Ao,hho),e(Ao,Ch),M(OA,Ch,null),e(Ch,pho),e(Ch,Fle),e(Fle,_ho),b(f,HGe,u),b(f,Si,u),e(Si,wh),e(wh,Tle),M(VA,Tle,null),e(Si,uho),e(Si,Mle),e(Mle,bho),b(f,UGe,u),b(f,Lo,u),M(XA,Lo,null),e(Lo,vho),e(Lo,zA),e(zA,Fho),e(zA,nN),e(nN,Tho),e(zA,Mho),e(Lo,Eho),e(Lo,QA),e(QA,Cho),e(QA,Ele),e(Ele,who),e(QA,Aho),e(Lo,Lho),e(Lo,He),M(WA,He,null),e(He,yho),e(He,Cle),e(Cle,xho),e(He,$ho),e(He,Sa),e(Sa,kho),e(Sa,wle),e(wle,Sho),e(Sa,Rho),e(Sa,Ale),e(Ale,Pho),e(Sa,Bho),e(Sa,Lle),e(Lle,Iho),e(Sa,Nho),e(He,qho),e(He,Y),e(Y,Ah),e(Ah,yle),e(yle,jho),e(Ah,Dho),e(Ah,sN),e(sN,Gho),e(Ah,Oho),e(Y,Vho),e(Y,Lh),e(Lh,xle),e(xle,Xho),e(Lh,zho),e(Lh,lN),e(lN,Qho),e(Lh,Who),e(Y,Hho),e(Y,yh),e(yh,$le),e($le,Uho),e(yh,Jho),e(yh,iN),e(iN,Yho),e(yh,Kho),e(Y,Zho),e(Y,xh),e(xh,kle),e(kle,epo),e(xh,opo),e(xh,dN),e(dN,rpo),e(xh,tpo),e(Y,apo),e(Y,$h),e($h,Sle),e(Sle,npo),e($h,spo),e($h,cN),e(cN,lpo),e($h,ipo),e(Y,dpo),e(Y,kh),e(kh,Rle),e(Rle,cpo),e(kh,fpo),e(kh,fN),e(fN,mpo),e(kh,gpo),e(Y,hpo),e(Y,Sh),e(Sh,Ple),e(Ple,ppo),e(Sh,_po),e(Sh,mN),e(mN,upo),e(Sh,bpo),e(Y,vpo),e(Y,Rh),e(Rh,Ble),e(Ble,Fpo),e(Rh,Tpo),e(Rh,gN),e(gN,Mpo),e(Rh,Epo),e(Y,Cpo),e(Y,Ph),e(Ph,Ile),e(Ile,wpo),e(Ph,Apo),e(Ph,hN),e(hN,Lpo),e(Ph,ypo),e(Y,xpo),e(Y,Bh),e(Bh,Nle),e(Nle,$po),e(Bh,kpo),e(Bh,pN),e(pN,Spo),e(Bh,Rpo),e(Y,Ppo),e(Y,Ih),e(Ih,qle),e(qle,Bpo),e(Ih,Ipo),e(Ih,_N),e(_N,Npo),e(Ih,qpo),e(Y,jpo),e(Y,Nh),e(Nh,jle),e(jle,Dpo),e(Nh,Gpo),e(Nh,uN),e(uN,Opo),e(Nh,Vpo),e(Y,Xpo),e(Y,qh),e(qh,Dle),e(Dle,zpo),e(qh,Qpo),e(qh,bN),e(bN,Wpo),e(qh,Hpo),e(Y,Upo),e(Y,jh),e(jh,Gle),e(Gle,Jpo),e(jh,Ypo),e(jh,vN),e(vN,Kpo),e(jh,Zpo),e(Y,e_o),e(Y,Dh),e(Dh,Ole),e(Ole,o_o),e(Dh,r_o),e(Dh,FN),e(FN,t_o),e(Dh,a_o),e(Y,n_o),e(Y,Gh),e(Gh,Vle),e(Vle,s_o),e(Gh,l_o),e(Gh,TN),e(TN,i_o),e(Gh,d_o),e(Y,c_o),e(Y,Oh),e(Oh,Xle),e(Xle,f_o),e(Oh,m_o),e(Oh,MN),e(MN,g_o),e(Oh,h_o),e(Y,p_o),e(Y,Vh),e(Vh,zle),e(zle,__o),e(Vh,u_o),e(Vh,EN),e(EN,b_o),e(Vh,v_o),e(Y,F_o),e(Y,Xh),e(Xh,Qle),e(Qle,T_o),e(Xh,M_o),e(Xh,CN),e(CN,E_o),e(Xh,C_o),e(Y,w_o),e(Y,zh),e(zh,Wle),e(Wle,A_o),e(zh,L_o),e(zh,wN),e(wN,y_o),e(zh,x_o),e(Y,$_o),e(Y,Qh),e(Qh,Hle),e(Hle,k_o),e(Qh,S_o),e(Qh,AN),e(AN,R_o),e(Qh,P_o),e(Y,B_o),e(Y,Wh),e(Wh,Ule),e(Ule,I_o),e(Wh,N_o),e(Wh,LN),e(LN,q_o),e(Wh,j_o),e(Y,D_o),e(Y,Hh),e(Hh,Jle),e(Jle,G_o),e(Hh,O_o),e(Hh,yN),e(yN,V_o),e(Hh,X_o),e(Y,z_o),e(Y,Uh),e(Uh,Yle),e(Yle,Q_o),e(Uh,W_o),e(Uh,xN),e(xN,H_o),e(Uh,U_o),e(Y,J_o),e(Y,Jh),e(Jh,Kle),e(Kle,Y_o),e(Jh,K_o),e(Jh,$N),e($N,Z_o),e(Jh,euo),e(Y,ouo),e(Y,Yh),e(Yh,Zle),e(Zle,ruo),e(Yh,tuo),e(Yh,kN),e(kN,auo),e(Yh,nuo),e(Y,suo),e(Y,Kh),e(Kh,eie),e(eie,luo),e(Kh,iuo),e(Kh,SN),e(SN,duo),e(Kh,cuo),e(Y,fuo),e(Y,Zh),e(Zh,oie),e(oie,muo),e(Zh,guo),e(Zh,RN),e(RN,huo),e(Zh,puo),e(Y,_uo),e(Y,ep),e(ep,rie),e(rie,uuo),e(ep,buo),e(ep,PN),e(PN,vuo),e(ep,Fuo),e(Y,Tuo),e(Y,op),e(op,tie),e(tie,Muo),e(op,Euo),e(op,BN),e(BN,Cuo),e(op,wuo),e(Y,Auo),e(Y,rp),e(rp,aie),e(aie,Luo),e(rp,yuo),e(rp,IN),e(IN,xuo),e(rp,$uo),e(Y,kuo),e(Y,tp),e(tp,nie),e(nie,Suo),e(tp,Ruo),e(tp,NN),e(NN,Puo),e(tp,Buo),e(He,Iuo),M(ap,He,null),e(He,Nuo),M(np,He,null),e(Lo,quo),e(Lo,sp),M(HA,sp,null),e(sp,juo),e(sp,sie),e(sie,Duo),b(f,JGe,u),b(f,Ri,u),e(Ri,lp),e(lp,lie),M(UA,lie,null),e(Ri,Guo),e(Ri,iie),e(iie,Ouo),b(f,YGe,u),b(f,yo,u),M(JA,yo,null),e(yo,Vuo),e(yo,YA),e(YA,Xuo),e(YA,qN),e(qN,zuo),e(YA,Quo),e(yo,Wuo),e(yo,KA),e(KA,Huo),e(KA,die),e(die,Uuo),e(KA,Juo),e(yo,Yuo),e(yo,Ue),M(ZA,Ue,null),e(Ue,Kuo),e(Ue,cie),e(cie,Zuo),e(Ue,e1o),e(Ue,Pi),e(Pi,o1o),e(Pi,fie),e(fie,r1o),e(Pi,t1o),e(Pi,mie),e(mie,a1o),e(Pi,n1o),e(Ue,s1o),e(Ue,he),e(he,ip),e(ip,gie),e(gie,l1o),e(ip,i1o),e(ip,jN),e(jN,d1o),e(ip,c1o),e(he,f1o),e(he,dp),e(dp,hie),e(hie,m1o),e(dp,g1o),e(dp,pie),e(pie,h1o),e(dp,p1o),e(he,_1o),e(he,cp),e(cp,_ie),e(_ie,u1o),e(cp,b1o),e(cp,DN),e(DN,v1o),e(cp,F1o),e(he,T1o),e(he,fp),e(fp,uie),e(uie,M1o),e(fp,E1o),e(fp,GN),e(GN,C1o),e(fp,w1o),e(he,A1o),e(he,mp),e(mp,bie),e(bie,L1o),e(mp,y1o),e(mp,ON),e(ON,x1o),e(mp,$1o),e(he,k1o),e(he,gp),e(gp,vie),e(vie,S1o),e(gp,R1o),e(gp,VN),e(VN,P1o),e(gp,B1o),e(he,I1o),e(he,hp),e(hp,Fie),e(Fie,N1o),e(hp,q1o),e(hp,XN),e(XN,j1o),e(hp,D1o),e(he,G1o),e(he,pp),e(pp,Tie),e(Tie,O1o),e(pp,V1o),e(pp,zN),e(zN,X1o),e(pp,z1o),e(he,Q1o),e(he,_p),e(_p,Mie),e(Mie,W1o),e(_p,H1o),e(_p,QN),e(QN,U1o),e(_p,J1o),e(he,Y1o),e(he,up),e(up,Eie),e(Eie,K1o),e(up,Z1o),e(up,WN),e(WN,e2o),e(up,o2o),e(he,r2o),e(he,bp),e(bp,Cie),e(Cie,t2o),e(bp,a2o),e(bp,HN),e(HN,n2o),e(bp,s2o),e(he,l2o),e(he,vp),e(vp,wie),e(wie,i2o),e(vp,d2o),e(vp,UN),e(UN,c2o),e(vp,f2o),e(he,m2o),e(he,Fp),e(Fp,Aie),e(Aie,g2o),e(Fp,h2o),e(Fp,JN),e(JN,p2o),e(Fp,_2o),e(he,u2o),e(he,Tp),e(Tp,Lie),e(Lie,b2o),e(Tp,v2o),e(Tp,YN),e(YN,F2o),e(Tp,T2o),e(he,M2o),e(he,Mp),e(Mp,yie),e(yie,E2o),e(Mp,C2o),e(Mp,KN),e(KN,w2o),e(Mp,A2o),e(he,L2o),e(he,Ep),e(Ep,xie),e(xie,y2o),e(Ep,x2o),e(Ep,ZN),e(ZN,$2o),e(Ep,k2o),e(he,S2o),e(he,Cp),e(Cp,$ie),e($ie,R2o),e(Cp,P2o),e(Cp,eq),e(eq,B2o),e(Cp,I2o),e(Ue,N2o),M(wp,Ue,null),e(Ue,q2o),M(Ap,Ue,null),e(yo,j2o),e(yo,Lp),M(eL,Lp,null),e(Lp,D2o),e(Lp,kie),e(kie,G2o),b(f,KGe,u),b(f,Bi,u),e(Bi,yp),e(yp,Sie),M(oL,Sie,null),e(Bi,O2o),e(Bi,Rie),e(Rie,V2o),b(f,ZGe,u),b(f,xo,u),M(rL,xo,null),e(xo,X2o),e(xo,Ii),e(Ii,z2o),e(Ii,oq),e(oq,Q2o),e(Ii,W2o),e(Ii,rq),e(rq,H2o),e(Ii,U2o),e(xo,J2o),e(xo,tL),e(tL,Y2o),e(tL,Pie),e(Pie,K2o),e(tL,Z2o),e(xo,ebo),e(xo,nt),M(aL,nt,null),e(nt,obo),e(nt,Bie),e(Bie,rbo),e(nt,tbo),e(nt,Ni),e(Ni,abo),e(Ni,Iie),e(Iie,nbo),e(Ni,sbo),e(Ni,tq),e(tq,lbo),e(Ni,ibo),e(nt,dbo),M(xp,nt,null),e(xo,cbo),e(xo,Je),M(nL,Je,null),e(Je,fbo),e(Je,Nie),e(Nie,mbo),e(Je,gbo),e(Je,Ra),e(Ra,hbo),e(Ra,qie),e(qie,pbo),e(Ra,_bo),e(Ra,jie),e(jie,ubo),e(Ra,bbo),e(Ra,Die),e(Die,vbo),e(Ra,Fbo),e(Je,Tbo),e(Je,y),e(y,$p),e($p,Gie),e(Gie,Mbo),e($p,Ebo),e($p,aq),e(aq,Cbo),e($p,wbo),e(y,Abo),e(y,kp),e(kp,Oie),e(Oie,Lbo),e(kp,ybo),e(kp,nq),e(nq,xbo),e(kp,$bo),e(y,kbo),e(y,Sp),e(Sp,Vie),e(Vie,Sbo),e(Sp,Rbo),e(Sp,sq),e(sq,Pbo),e(Sp,Bbo),e(y,Ibo),e(y,Rp),e(Rp,Xie),e(Xie,Nbo),e(Rp,qbo),e(Rp,lq),e(lq,jbo),e(Rp,Dbo),e(y,Gbo),e(y,Pp),e(Pp,zie),e(zie,Obo),e(Pp,Vbo),e(Pp,iq),e(iq,Xbo),e(Pp,zbo),e(y,Qbo),e(y,Bp),e(Bp,Qie),e(Qie,Wbo),e(Bp,Hbo),e(Bp,dq),e(dq,Ubo),e(Bp,Jbo),e(y,Ybo),e(y,Ip),e(Ip,Wie),e(Wie,Kbo),e(Ip,Zbo),e(Ip,cq),e(cq,e4o),e(Ip,o4o),e(y,r4o),e(y,Np),e(Np,Hie),e(Hie,t4o),e(Np,a4o),e(Np,fq),e(fq,n4o),e(Np,s4o),e(y,l4o),e(y,qp),e(qp,Uie),e(Uie,i4o),e(qp,d4o),e(qp,mq),e(mq,c4o),e(qp,f4o),e(y,m4o),e(y,jp),e(jp,Jie),e(Jie,g4o),e(jp,h4o),e(jp,gq),e(gq,p4o),e(jp,_4o),e(y,u4o),e(y,Dp),e(Dp,Yie),e(Yie,b4o),e(Dp,v4o),e(Dp,hq),e(hq,F4o),e(Dp,T4o),e(y,M4o),e(y,Gp),e(Gp,Kie),e(Kie,E4o),e(Gp,C4o),e(Gp,pq),e(pq,w4o),e(Gp,A4o),e(y,L4o),e(y,Op),e(Op,Zie),e(Zie,y4o),e(Op,x4o),e(Op,_q),e(_q,$4o),e(Op,k4o),e(y,S4o),e(y,Vp),e(Vp,ede),e(ede,R4o),e(Vp,P4o),e(Vp,uq),e(uq,B4o),e(Vp,I4o),e(y,N4o),e(y,Xp),e(Xp,ode),e(ode,q4o),e(Xp,j4o),e(Xp,bq),e(bq,D4o),e(Xp,G4o),e(y,O4o),e(y,zp),e(zp,rde),e(rde,V4o),e(zp,X4o),e(zp,vq),e(vq,z4o),e(zp,Q4o),e(y,W4o),e(y,Qp),e(Qp,tde),e(tde,H4o),e(Qp,U4o),e(Qp,Fq),e(Fq,J4o),e(Qp,Y4o),e(y,K4o),e(y,Wp),e(Wp,ade),e(ade,Z4o),e(Wp,evo),e(Wp,Tq),e(Tq,ovo),e(Wp,rvo),e(y,tvo),e(y,Hp),e(Hp,nde),e(nde,avo),e(Hp,nvo),e(Hp,Mq),e(Mq,svo),e(Hp,lvo),e(y,ivo),e(y,Up),e(Up,sde),e(sde,dvo),e(Up,cvo),e(Up,Eq),e(Eq,fvo),e(Up,mvo),e(y,gvo),e(y,Jp),e(Jp,lde),e(lde,hvo),e(Jp,pvo),e(Jp,Cq),e(Cq,_vo),e(Jp,uvo),e(y,bvo),e(y,Yp),e(Yp,ide),e(ide,vvo),e(Yp,Fvo),e(Yp,wq),e(wq,Tvo),e(Yp,Mvo),e(y,Evo),e(y,Kp),e(Kp,dde),e(dde,Cvo),e(Kp,wvo),e(Kp,Aq),e(Aq,Avo),e(Kp,Lvo),e(y,yvo),e(y,Zp),e(Zp,cde),e(cde,xvo),e(Zp,$vo),e(Zp,Lq),e(Lq,kvo),e(Zp,Svo),e(y,Rvo),e(y,e_),e(e_,fde),e(fde,Pvo),e(e_,Bvo),e(e_,yq),e(yq,Ivo),e(e_,Nvo),e(y,qvo),e(y,o_),e(o_,mde),e(mde,jvo),e(o_,Dvo),e(o_,xq),e(xq,Gvo),e(o_,Ovo),e(y,Vvo),e(y,r_),e(r_,gde),e(gde,Xvo),e(r_,zvo),e(r_,$q),e($q,Qvo),e(r_,Wvo),e(y,Hvo),e(y,t_),e(t_,hde),e(hde,Uvo),e(t_,Jvo),e(t_,kq),e(kq,Yvo),e(t_,Kvo),e(y,Zvo),e(y,a_),e(a_,pde),e(pde,eFo),e(a_,oFo),e(a_,Sq),e(Sq,rFo),e(a_,tFo),e(y,aFo),e(y,n_),e(n_,_de),e(_de,nFo),e(n_,sFo),e(n_,Rq),e(Rq,lFo),e(n_,iFo),e(y,dFo),e(y,s_),e(s_,ude),e(ude,cFo),e(s_,fFo),e(s_,Pq),e(Pq,mFo),e(s_,gFo),e(y,hFo),e(y,l_),e(l_,bde),e(bde,pFo),e(l_,_Fo),e(l_,Bq),e(Bq,uFo),e(l_,bFo),e(y,vFo),e(y,i_),e(i_,vde),e(vde,FFo),e(i_,TFo),e(i_,Iq),e(Iq,MFo),e(i_,EFo),e(y,CFo),e(y,Vs),e(Vs,Fde),e(Fde,wFo),e(Vs,AFo),e(Vs,Nq),e(Nq,LFo),e(Vs,yFo),e(Vs,qq),e(qq,xFo),e(Vs,$Fo),e(y,kFo),e(y,d_),e(d_,Tde),e(Tde,SFo),e(d_,RFo),e(d_,jq),e(jq,PFo),e(d_,BFo),e(y,IFo),e(y,c_),e(c_,Mde),e(Mde,NFo),e(c_,qFo),e(c_,Dq),e(Dq,jFo),e(c_,DFo),e(y,GFo),e(y,f_),e(f_,Ede),e(Ede,OFo),e(f_,VFo),e(f_,Gq),e(Gq,XFo),e(f_,zFo),e(y,QFo),e(y,m_),e(m_,Cde),e(Cde,WFo),e(m_,HFo),e(m_,Oq),e(Oq,UFo),e(m_,JFo),e(y,YFo),e(y,g_),e(g_,wde),e(wde,KFo),e(g_,ZFo),e(g_,Vq),e(Vq,e6o),e(g_,o6o),e(y,r6o),e(y,h_),e(h_,Ade),e(Ade,t6o),e(h_,a6o),e(h_,Xq),e(Xq,n6o),e(h_,s6o),e(y,l6o),e(y,p_),e(p_,Lde),e(Lde,i6o),e(p_,d6o),e(p_,zq),e(zq,c6o),e(p_,f6o),e(y,m6o),e(y,__),e(__,yde),e(yde,g6o),e(__,h6o),e(__,Qq),e(Qq,p6o),e(__,_6o),e(y,u6o),e(y,u_),e(u_,xde),e(xde,b6o),e(u_,v6o),e(u_,Wq),e(Wq,F6o),e(u_,T6o),e(y,M6o),e(y,b_),e(b_,$de),e($de,E6o),e(b_,C6o),e(b_,Hq),e(Hq,w6o),e(b_,A6o),e(y,L6o),e(y,v_),e(v_,kde),e(kde,y6o),e(v_,x6o),e(v_,Uq),e(Uq,$6o),e(v_,k6o),e(y,S6o),e(y,F_),e(F_,Sde),e(Sde,R6o),e(F_,P6o),e(F_,Jq),e(Jq,B6o),e(F_,I6o),e(y,N6o),e(y,T_),e(T_,Rde),e(Rde,q6o),e(T_,j6o),e(T_,Yq),e(Yq,D6o),e(T_,G6o),e(y,O6o),e(y,M_),e(M_,Pde),e(Pde,V6o),e(M_,X6o),e(M_,Kq),e(Kq,z6o),e(M_,Q6o),e(y,W6o),e(y,E_),e(E_,Bde),e(Bde,H6o),e(E_,U6o),e(E_,Zq),e(Zq,J6o),e(E_,Y6o),e(y,K6o),e(y,C_),e(C_,Ide),e(Ide,Z6o),e(C_,eTo),e(C_,ej),e(ej,oTo),e(C_,rTo),e(y,tTo),e(y,w_),e(w_,Nde),e(Nde,aTo),e(w_,nTo),e(w_,oj),e(oj,sTo),e(w_,lTo),e(y,iTo),e(y,A_),e(A_,qde),e(qde,dTo),e(A_,cTo),e(A_,rj),e(rj,fTo),e(A_,mTo),e(y,gTo),e(y,L_),e(L_,jde),e(jde,hTo),e(L_,pTo),e(L_,tj),e(tj,_To),e(L_,uTo),e(y,bTo),e(y,y_),e(y_,Dde),e(Dde,vTo),e(y_,FTo),e(y_,aj),e(aj,TTo),e(y_,MTo),e(y,ETo),e(y,x_),e(x_,Gde),e(Gde,CTo),e(x_,wTo),e(x_,nj),e(nj,ATo),e(x_,LTo),e(y,yTo),e(y,$_),e($_,Ode),e(Ode,xTo),e($_,$To),e($_,sj),e(sj,kTo),e($_,STo),e(y,RTo),e(y,k_),e(k_,Vde),e(Vde,PTo),e(k_,BTo),e(k_,lj),e(lj,ITo),e(k_,NTo),e(y,qTo),e(y,S_),e(S_,Xde),e(Xde,jTo),e(S_,DTo),e(S_,ij),e(ij,GTo),e(S_,OTo),e(y,VTo),e(y,R_),e(R_,zde),e(zde,XTo),e(R_,zTo),e(R_,dj),e(dj,QTo),e(R_,WTo),e(y,HTo),e(y,P_),e(P_,Qde),e(Qde,UTo),e(P_,JTo),e(P_,cj),e(cj,YTo),e(P_,KTo),e(y,ZTo),e(y,B_),e(B_,Wde),e(Wde,e7o),e(B_,o7o),e(B_,fj),e(fj,r7o),e(B_,t7o),e(y,a7o),e(y,I_),e(I_,Hde),e(Hde,n7o),e(I_,s7o),e(I_,mj),e(mj,l7o),e(I_,i7o),e(y,d7o),e(y,N_),e(N_,Ude),e(Ude,c7o),e(N_,f7o),e(N_,gj),e(gj,m7o),e(N_,g7o),e(y,h7o),e(y,q_),e(q_,Jde),e(Jde,p7o),e(q_,_7o),e(q_,hj),e(hj,u7o),e(q_,b7o),e(y,v7o),e(y,j_),e(j_,Yde),e(Yde,F7o),e(j_,T7o),e(j_,pj),e(pj,M7o),e(j_,E7o),e(y,C7o),e(y,D_),e(D_,Kde),e(Kde,w7o),e(D_,A7o),e(D_,_j),e(_j,L7o),e(D_,y7o),e(y,x7o),e(y,G_),e(G_,Zde),e(Zde,$7o),e(G_,k7o),e(G_,uj),e(uj,S7o),e(G_,R7o),e(y,P7o),e(y,O_),e(O_,ece),e(ece,B7o),e(O_,I7o),e(O_,bj),e(bj,N7o),e(O_,q7o),e(y,j7o),e(y,V_),e(V_,oce),e(oce,D7o),e(V_,G7o),e(V_,vj),e(vj,O7o),e(V_,V7o),e(y,X7o),e(y,X_),e(X_,rce),e(rce,z7o),e(X_,Q7o),e(X_,Fj),e(Fj,W7o),e(X_,H7o),e(y,U7o),e(y,z_),e(z_,tce),e(tce,J7o),e(z_,Y7o),e(z_,Tj),e(Tj,K7o),e(z_,Z7o),e(y,e8o),e(y,Q_),e(Q_,ace),e(ace,o8o),e(Q_,r8o),e(Q_,Mj),e(Mj,t8o),e(Q_,a8o),e(y,n8o),e(y,W_),e(W_,nce),e(nce,s8o),e(W_,l8o),e(W_,Ej),e(Ej,i8o),e(W_,d8o),e(y,c8o),e(y,H_),e(H_,sce),e(sce,f8o),e(H_,m8o),e(H_,Cj),e(Cj,g8o),e(H_,h8o),e(y,p8o),e(y,U_),e(U_,lce),e(lce,_8o),e(U_,u8o),e(U_,wj),e(wj,b8o),e(U_,v8o),e(y,F8o),e(y,J_),e(J_,ice),e(ice,T8o),e(J_,M8o),e(J_,Aj),e(Aj,E8o),e(J_,C8o),e(y,w8o),e(y,Y_),e(Y_,dce),e(dce,A8o),e(Y_,L8o),e(Y_,Lj),e(Lj,y8o),e(Y_,x8o),e(y,$8o),e(y,K_),e(K_,cce),e(cce,k8o),e(K_,S8o),e(K_,yj),e(yj,R8o),e(K_,P8o),e(y,B8o),e(y,Z_),e(Z_,fce),e(fce,I8o),e(Z_,N8o),e(Z_,xj),e(xj,q8o),e(Z_,j8o),e(y,D8o),e(y,eu),e(eu,mce),e(mce,G8o),e(eu,O8o),e(eu,$j),e($j,V8o),e(eu,X8o),e(y,z8o),e(y,ou),e(ou,gce),e(gce,Q8o),e(ou,W8o),e(ou,kj),e(kj,H8o),e(ou,U8o),e(y,J8o),e(y,ru),e(ru,hce),e(hce,Y8o),e(ru,K8o),e(ru,Sj),e(Sj,Z8o),e(ru,eMo),e(y,oMo),e(y,tu),e(tu,pce),e(pce,rMo),e(tu,tMo),e(tu,Rj),e(Rj,aMo),e(tu,nMo),e(y,sMo),e(y,au),e(au,_ce),e(_ce,lMo),e(au,iMo),e(au,Pj),e(Pj,dMo),e(au,cMo),e(y,fMo),e(y,nu),e(nu,uce),e(uce,mMo),e(nu,gMo),e(nu,Bj),e(Bj,hMo),e(nu,pMo),e(y,_Mo),e(y,su),e(su,bce),e(bce,uMo),e(su,bMo),e(su,Ij),e(Ij,vMo),e(su,FMo),e(y,TMo),e(y,lu),e(lu,vce),e(vce,MMo),e(lu,EMo),e(lu,Nj),e(Nj,CMo),e(lu,wMo),e(y,AMo),e(y,iu),e(iu,Fce),e(Fce,LMo),e(iu,yMo),e(iu,qj),e(qj,xMo),e(iu,$Mo),e(y,kMo),e(y,du),e(du,Tce),e(Tce,SMo),e(du,RMo),e(du,jj),e(jj,PMo),e(du,BMo),e(y,IMo),e(y,cu),e(cu,Mce),e(Mce,NMo),e(cu,qMo),e(cu,Dj),e(Dj,jMo),e(cu,DMo),e(y,GMo),e(y,fu),e(fu,Ece),e(Ece,OMo),e(fu,VMo),e(fu,Gj),e(Gj,XMo),e(fu,zMo),e(y,QMo),e(y,mu),e(mu,Cce),e(Cce,WMo),e(mu,HMo),e(mu,Oj),e(Oj,UMo),e(mu,JMo),e(y,YMo),e(y,gu),e(gu,wce),e(wce,KMo),e(gu,ZMo),e(gu,Vj),e(Vj,eEo),e(gu,oEo),e(y,rEo),e(y,hu),e(hu,Ace),e(Ace,tEo),e(hu,aEo),e(hu,Xj),e(Xj,nEo),e(hu,sEo),e(y,lEo),e(y,pu),e(pu,Lce),e(Lce,iEo),e(pu,dEo),e(pu,zj),e(zj,cEo),e(pu,fEo),e(y,mEo),e(y,_u),e(_u,yce),e(yce,gEo),e(_u,hEo),e(_u,Qj),e(Qj,pEo),e(_u,_Eo),e(y,uEo),e(y,uu),e(uu,xce),e(xce,bEo),e(uu,vEo),e(uu,Wj),e(Wj,FEo),e(uu,TEo),e(y,MEo),e(y,bu),e(bu,$ce),e($ce,EEo),e(bu,CEo),e(bu,Hj),e(Hj,wEo),e(bu,AEo),e(y,LEo),e(y,vu),e(vu,kce),e(kce,yEo),e(vu,xEo),e(vu,Uj),e(Uj,$Eo),e(vu,kEo),e(y,SEo),e(y,Fu),e(Fu,Sce),e(Sce,REo),e(Fu,PEo),e(Fu,Jj),e(Jj,BEo),e(Fu,IEo),e(y,NEo),e(y,Tu),e(Tu,Rce),e(Rce,qEo),e(Tu,jEo),e(Tu,Yj),e(Yj,DEo),e(Tu,GEo),e(y,OEo),e(y,Mu),e(Mu,Pce),e(Pce,VEo),e(Mu,XEo),e(Mu,Kj),e(Kj,zEo),e(Mu,QEo),e(y,WEo),e(y,Eu),e(Eu,Bce),e(Bce,HEo),e(Eu,UEo),e(Eu,Zj),e(Zj,JEo),e(Eu,YEo),e(y,KEo),e(y,Cu),e(Cu,Ice),e(Ice,ZEo),e(Cu,eCo),e(Cu,eD),e(eD,oCo),e(Cu,rCo),e(y,tCo),e(y,wu),e(wu,Nce),e(Nce,aCo),e(wu,nCo),e(wu,oD),e(oD,sCo),e(wu,lCo),e(y,iCo),e(y,Au),e(Au,qce),e(qce,dCo),e(Au,cCo),e(Au,rD),e(rD,fCo),e(Au,mCo),e(y,gCo),e(y,Lu),e(Lu,jce),e(jce,hCo),e(Lu,pCo),e(Lu,tD),e(tD,_Co),e(Lu,uCo),e(Je,bCo),e(Je,yu),e(yu,vCo),e(yu,Dce),e(Dce,FCo),e(yu,TCo),e(yu,Gce),e(Gce,MCo),e(Je,ECo),M(xu,Je,null),b(f,eOe,u),b(f,qi,u),e(qi,$u),e($u,Oce),M(sL,Oce,null),e(qi,CCo),e(qi,Vce),e(Vce,wCo),b(f,oOe,u),b(f,$o,u),M(lL,$o,null),e($o,ACo),e($o,ji),e(ji,LCo),e(ji,aD),e(aD,yCo),e(ji,xCo),e(ji,nD),e(nD,$Co),e(ji,kCo),e($o,SCo),e($o,iL),e(iL,RCo),e(iL,Xce),e(Xce,PCo),e(iL,BCo),e($o,ICo),e($o,st),M(dL,st,null),e(st,NCo),e(st,zce),e(zce,qCo),e(st,jCo),e(st,Di),e(Di,DCo),e(Di,Qce),e(Qce,GCo),e(Di,OCo),e(Di,sD),e(sD,VCo),e(Di,XCo),e(st,zCo),M(ku,st,null),e($o,QCo),e($o,Ye),M(cL,Ye,null),e(Ye,WCo),e(Ye,Wce),e(Wce,HCo),e(Ye,UCo),e(Ye,Pa),e(Pa,JCo),e(Pa,Hce),e(Hce,YCo),e(Pa,KCo),e(Pa,Uce),e(Uce,ZCo),e(Pa,e5o),e(Pa,Jce),e(Jce,o5o),e(Pa,r5o),e(Ye,t5o),e(Ye,G),e(G,Su),e(Su,Yce),e(Yce,a5o),e(Su,n5o),e(Su,lD),e(lD,s5o),e(Su,l5o),e(G,i5o),e(G,Ru),e(Ru,Kce),e(Kce,d5o),e(Ru,c5o),e(Ru,iD),e(iD,f5o),e(Ru,m5o),e(G,g5o),e(G,Pu),e(Pu,Zce),e(Zce,h5o),e(Pu,p5o),e(Pu,dD),e(dD,_5o),e(Pu,u5o),e(G,b5o),e(G,Bu),e(Bu,efe),e(efe,v5o),e(Bu,F5o),e(Bu,cD),e(cD,T5o),e(Bu,M5o),e(G,E5o),e(G,Iu),e(Iu,ofe),e(ofe,C5o),e(Iu,w5o),e(Iu,fD),e(fD,A5o),e(Iu,L5o),e(G,y5o),e(G,Nu),e(Nu,rfe),e(rfe,x5o),e(Nu,$5o),e(Nu,mD),e(mD,k5o),e(Nu,S5o),e(G,R5o),e(G,qu),e(qu,tfe),e(tfe,P5o),e(qu,B5o),e(qu,gD),e(gD,I5o),e(qu,N5o),e(G,q5o),e(G,ju),e(ju,afe),e(afe,j5o),e(ju,D5o),e(ju,hD),e(hD,G5o),e(ju,O5o),e(G,V5o),e(G,Du),e(Du,nfe),e(nfe,X5o),e(Du,z5o),e(Du,pD),e(pD,Q5o),e(Du,W5o),e(G,H5o),e(G,Gu),e(Gu,sfe),e(sfe,U5o),e(Gu,J5o),e(Gu,_D),e(_D,Y5o),e(Gu,K5o),e(G,Z5o),e(G,Ou),e(Ou,lfe),e(lfe,e3o),e(Ou,o3o),e(Ou,uD),e(uD,r3o),e(Ou,t3o),e(G,a3o),e(G,Vu),e(Vu,ife),e(ife,n3o),e(Vu,s3o),e(Vu,bD),e(bD,l3o),e(Vu,i3o),e(G,d3o),e(G,Xu),e(Xu,dfe),e(dfe,c3o),e(Xu,f3o),e(Xu,vD),e(vD,m3o),e(Xu,g3o),e(G,h3o),e(G,zu),e(zu,cfe),e(cfe,p3o),e(zu,_3o),e(zu,FD),e(FD,u3o),e(zu,b3o),e(G,v3o),e(G,Qu),e(Qu,ffe),e(ffe,F3o),e(Qu,T3o),e(Qu,TD),e(TD,M3o),e(Qu,E3o),e(G,C3o),e(G,Wu),e(Wu,mfe),e(mfe,w3o),e(Wu,A3o),e(Wu,MD),e(MD,L3o),e(Wu,y3o),e(G,x3o),e(G,Hu),e(Hu,gfe),e(gfe,$3o),e(Hu,k3o),e(Hu,ED),e(ED,S3o),e(Hu,R3o),e(G,P3o),e(G,Uu),e(Uu,hfe),e(hfe,B3o),e(Uu,I3o),e(Uu,CD),e(CD,N3o),e(Uu,q3o),e(G,j3o),e(G,Ju),e(Ju,pfe),e(pfe,D3o),e(Ju,G3o),e(Ju,wD),e(wD,O3o),e(Ju,V3o),e(G,X3o),e(G,Yu),e(Yu,_fe),e(_fe,z3o),e(Yu,Q3o),e(Yu,AD),e(AD,W3o),e(Yu,H3o),e(G,U3o),e(G,Ku),e(Ku,ufe),e(ufe,J3o),e(Ku,Y3o),e(Ku,LD),e(LD,K3o),e(Ku,Z3o),e(G,e0o),e(G,Zu),e(Zu,bfe),e(bfe,o0o),e(Zu,r0o),e(Zu,yD),e(yD,t0o),e(Zu,a0o),e(G,n0o),e(G,e1),e(e1,vfe),e(vfe,s0o),e(e1,l0o),e(e1,xD),e(xD,i0o),e(e1,d0o),e(G,c0o),e(G,o1),e(o1,Ffe),e(Ffe,f0o),e(o1,m0o),e(o1,$D),e($D,g0o),e(o1,h0o),e(G,p0o),e(G,r1),e(r1,Tfe),e(Tfe,_0o),e(r1,u0o),e(r1,kD),e(kD,b0o),e(r1,v0o),e(G,F0o),e(G,t1),e(t1,Mfe),e(Mfe,T0o),e(t1,M0o),e(t1,SD),e(SD,E0o),e(t1,C0o),e(G,w0o),e(G,a1),e(a1,Efe),e(Efe,A0o),e(a1,L0o),e(a1,RD),e(RD,y0o),e(a1,x0o),e(G,$0o),e(G,n1),e(n1,Cfe),e(Cfe,k0o),e(n1,S0o),e(n1,PD),e(PD,R0o),e(n1,P0o),e(G,B0o),e(G,s1),e(s1,wfe),e(wfe,I0o),e(s1,N0o),e(s1,BD),e(BD,q0o),e(s1,j0o),e(G,D0o),e(G,l1),e(l1,Afe),e(Afe,G0o),e(l1,O0o),e(l1,ID),e(ID,V0o),e(l1,X0o),e(G,z0o),e(G,i1),e(i1,Lfe),e(Lfe,Q0o),e(i1,W0o),e(i1,ND),e(ND,H0o),e(i1,U0o),e(G,J0o),e(G,d1),e(d1,yfe),e(yfe,Y0o),e(d1,K0o),e(d1,qD),e(qD,Z0o),e(d1,ewo),e(G,owo),e(G,c1),e(c1,xfe),e(xfe,rwo),e(c1,two),e(c1,jD),e(jD,awo),e(c1,nwo),e(G,swo),e(G,f1),e(f1,$fe),e($fe,lwo),e(f1,iwo),e(f1,DD),e(DD,dwo),e(f1,cwo),e(G,fwo),e(G,m1),e(m1,kfe),e(kfe,mwo),e(m1,gwo),e(m1,GD),e(GD,hwo),e(m1,pwo),e(G,_wo),e(G,g1),e(g1,Sfe),e(Sfe,uwo),e(g1,bwo),e(g1,OD),e(OD,vwo),e(g1,Fwo),e(G,Two),e(G,h1),e(h1,Rfe),e(Rfe,Mwo),e(h1,Ewo),e(h1,VD),e(VD,Cwo),e(h1,wwo),e(G,Awo),e(G,p1),e(p1,Pfe),e(Pfe,Lwo),e(p1,ywo),e(p1,XD),e(XD,xwo),e(p1,$wo),e(G,kwo),e(G,_1),e(_1,Bfe),e(Bfe,Swo),e(_1,Rwo),e(_1,zD),e(zD,Pwo),e(_1,Bwo),e(G,Iwo),e(G,u1),e(u1,Ife),e(Ife,Nwo),e(u1,qwo),e(u1,QD),e(QD,jwo),e(u1,Dwo),e(G,Gwo),e(G,b1),e(b1,Nfe),e(Nfe,Owo),e(b1,Vwo),e(b1,WD),e(WD,Xwo),e(b1,zwo),e(G,Qwo),e(G,v1),e(v1,qfe),e(qfe,Wwo),e(v1,Hwo),e(v1,HD),e(HD,Uwo),e(v1,Jwo),e(G,Ywo),e(G,F1),e(F1,jfe),e(jfe,Kwo),e(F1,Zwo),e(F1,UD),e(UD,eAo),e(F1,oAo),e(G,rAo),e(G,T1),e(T1,Dfe),e(Dfe,tAo),e(T1,aAo),e(T1,JD),e(JD,nAo),e(T1,sAo),e(Ye,lAo),e(Ye,M1),e(M1,iAo),e(M1,Gfe),e(Gfe,dAo),e(M1,cAo),e(M1,Ofe),e(Ofe,fAo),e(Ye,mAo),M(E1,Ye,null),b(f,rOe,u),b(f,Gi,u),e(Gi,C1),e(C1,Vfe),M(fL,Vfe,null),e(Gi,gAo),e(Gi,Xfe),e(Xfe,hAo),b(f,tOe,u),b(f,ko,u),M(mL,ko,null),e(ko,pAo),e(ko,Oi),e(Oi,_Ao),e(Oi,YD),e(YD,uAo),e(Oi,bAo),e(Oi,KD),e(KD,vAo),e(Oi,FAo),e(ko,TAo),e(ko,gL),e(gL,MAo),e(gL,zfe),e(zfe,EAo),e(gL,CAo),e(ko,wAo),e(ko,lt),M(hL,lt,null),e(lt,AAo),e(lt,Qfe),e(Qfe,LAo),e(lt,yAo),e(lt,Vi),e(Vi,xAo),e(Vi,Wfe),e(Wfe,$Ao),e(Vi,kAo),e(Vi,ZD),e(ZD,SAo),e(Vi,RAo),e(lt,PAo),M(w1,lt,null),e(ko,BAo),e(ko,Ke),M(pL,Ke,null),e(Ke,IAo),e(Ke,Hfe),e(Hfe,NAo),e(Ke,qAo),e(Ke,Ba),e(Ba,jAo),e(Ba,Ufe),e(Ufe,DAo),e(Ba,GAo),e(Ba,Jfe),e(Jfe,OAo),e(Ba,VAo),e(Ba,Yfe),e(Yfe,XAo),e(Ba,zAo),e(Ke,QAo),e(Ke,z),e(z,A1),e(A1,Kfe),e(Kfe,WAo),e(A1,HAo),e(A1,eG),e(eG,UAo),e(A1,JAo),e(z,YAo),e(z,L1),e(L1,Zfe),e(Zfe,KAo),e(L1,ZAo),e(L1,oG),e(oG,eLo),e(L1,oLo),e(z,rLo),e(z,y1),e(y1,eme),e(eme,tLo),e(y1,aLo),e(y1,rG),e(rG,nLo),e(y1,sLo),e(z,lLo),e(z,x1),e(x1,ome),e(ome,iLo),e(x1,dLo),e(x1,tG),e(tG,cLo),e(x1,fLo),e(z,mLo),e(z,$1),e($1,rme),e(rme,gLo),e($1,hLo),e($1,aG),e(aG,pLo),e($1,_Lo),e(z,uLo),e(z,k1),e(k1,tme),e(tme,bLo),e(k1,vLo),e(k1,nG),e(nG,FLo),e(k1,TLo),e(z,MLo),e(z,S1),e(S1,ame),e(ame,ELo),e(S1,CLo),e(S1,sG),e(sG,wLo),e(S1,ALo),e(z,LLo),e(z,R1),e(R1,nme),e(nme,yLo),e(R1,xLo),e(R1,lG),e(lG,$Lo),e(R1,kLo),e(z,SLo),e(z,P1),e(P1,sme),e(sme,RLo),e(P1,PLo),e(P1,iG),e(iG,BLo),e(P1,ILo),e(z,NLo),e(z,B1),e(B1,lme),e(lme,qLo),e(B1,jLo),e(B1,dG),e(dG,DLo),e(B1,GLo),e(z,OLo),e(z,I1),e(I1,ime),e(ime,VLo),e(I1,XLo),e(I1,cG),e(cG,zLo),e(I1,QLo),e(z,WLo),e(z,N1),e(N1,dme),e(dme,HLo),e(N1,ULo),e(N1,fG),e(fG,JLo),e(N1,YLo),e(z,KLo),e(z,q1),e(q1,cme),e(cme,ZLo),e(q1,eyo),e(q1,mG),e(mG,oyo),e(q1,ryo),e(z,tyo),e(z,j1),e(j1,fme),e(fme,ayo),e(j1,nyo),e(j1,gG),e(gG,syo),e(j1,lyo),e(z,iyo),e(z,D1),e(D1,mme),e(mme,dyo),e(D1,cyo),e(D1,hG),e(hG,fyo),e(D1,myo),e(z,gyo),e(z,G1),e(G1,gme),e(gme,hyo),e(G1,pyo),e(G1,pG),e(pG,_yo),e(G1,uyo),e(z,byo),e(z,O1),e(O1,hme),e(hme,vyo),e(O1,Fyo),e(O1,_G),e(_G,Tyo),e(O1,Myo),e(z,Eyo),e(z,V1),e(V1,pme),e(pme,Cyo),e(V1,wyo),e(V1,uG),e(uG,Ayo),e(V1,Lyo),e(z,yyo),e(z,X1),e(X1,_me),e(_me,xyo),e(X1,$yo),e(X1,bG),e(bG,kyo),e(X1,Syo),e(z,Ryo),e(z,z1),e(z1,ume),e(ume,Pyo),e(z1,Byo),e(z1,vG),e(vG,Iyo),e(z1,Nyo),e(z,qyo),e(z,Q1),e(Q1,bme),e(bme,jyo),e(Q1,Dyo),e(Q1,FG),e(FG,Gyo),e(Q1,Oyo),e(z,Vyo),e(z,W1),e(W1,vme),e(vme,Xyo),e(W1,zyo),e(W1,TG),e(TG,Qyo),e(W1,Wyo),e(z,Hyo),e(z,H1),e(H1,Fme),e(Fme,Uyo),e(H1,Jyo),e(H1,MG),e(MG,Yyo),e(H1,Kyo),e(z,Zyo),e(z,U1),e(U1,Tme),e(Tme,e9o),e(U1,o9o),e(U1,EG),e(EG,r9o),e(U1,t9o),e(z,a9o),e(z,J1),e(J1,Mme),e(Mme,n9o),e(J1,s9o),e(J1,CG),e(CG,l9o),e(J1,i9o),e(z,d9o),e(z,Y1),e(Y1,Eme),e(Eme,c9o),e(Y1,f9o),e(Y1,wG),e(wG,m9o),e(Y1,g9o),e(z,h9o),e(z,K1),e(K1,Cme),e(Cme,p9o),e(K1,_9o),e(K1,AG),e(AG,u9o),e(K1,b9o),e(z,v9o),e(z,Z1),e(Z1,wme),e(wme,F9o),e(Z1,T9o),e(Z1,LG),e(LG,M9o),e(Z1,E9o),e(z,C9o),e(z,e2),e(e2,Ame),e(Ame,w9o),e(e2,A9o),e(e2,yG),e(yG,L9o),e(e2,y9o),e(z,x9o),e(z,o2),e(o2,Lme),e(Lme,$9o),e(o2,k9o),e(o2,xG),e(xG,S9o),e(o2,R9o),e(z,P9o),e(z,r2),e(r2,yme),e(yme,B9o),e(r2,I9o),e(r2,$G),e($G,N9o),e(r2,q9o),e(z,j9o),e(z,t2),e(t2,xme),e(xme,D9o),e(t2,G9o),e(t2,kG),e(kG,O9o),e(t2,V9o),e(z,X9o),e(z,a2),e(a2,$me),e($me,z9o),e(a2,Q9o),e(a2,SG),e(SG,W9o),e(a2,H9o),e(z,U9o),e(z,n2),e(n2,kme),e(kme,J9o),e(n2,Y9o),e(n2,RG),e(RG,K9o),e(n2,Z9o),e(z,exo),e(z,s2),e(s2,Sme),e(Sme,oxo),e(s2,rxo),e(s2,PG),e(PG,txo),e(s2,axo),e(z,nxo),e(z,l2),e(l2,Rme),e(Rme,sxo),e(l2,lxo),e(l2,BG),e(BG,ixo),e(l2,dxo),e(z,cxo),e(z,i2),e(i2,Pme),e(Pme,fxo),e(i2,mxo),e(i2,IG),e(IG,gxo),e(i2,hxo),e(z,pxo),e(z,d2),e(d2,Bme),e(Bme,_xo),e(d2,uxo),e(d2,NG),e(NG,bxo),e(d2,vxo),e(Ke,Fxo),e(Ke,c2),e(c2,Txo),e(c2,Ime),e(Ime,Mxo),e(c2,Exo),e(c2,Nme),e(Nme,Cxo),e(Ke,wxo),M(f2,Ke,null),b(f,aOe,u),b(f,Xi,u),e(Xi,m2),e(m2,qme),M(_L,qme,null),e(Xi,Axo),e(Xi,jme),e(jme,Lxo),b(f,nOe,u),b(f,So,u),M(uL,So,null),e(So,yxo),e(So,zi),e(zi,xxo),e(zi,qG),e(qG,$xo),e(zi,kxo),e(zi,jG),e(jG,Sxo),e(zi,Rxo),e(So,Pxo),e(So,bL),e(bL,Bxo),e(bL,Dme),e(Dme,Ixo),e(bL,Nxo),e(So,qxo),e(So,it),M(vL,it,null),e(it,jxo),e(it,Gme),e(Gme,Dxo),e(it,Gxo),e(it,Qi),e(Qi,Oxo),e(Qi,Ome),e(Ome,Vxo),e(Qi,Xxo),e(Qi,DG),e(DG,zxo),e(Qi,Qxo),e(it,Wxo),M(g2,it,null),e(So,Hxo),e(So,Ze),M(FL,Ze,null),e(Ze,Uxo),e(Ze,Vme),e(Vme,Jxo),e(Ze,Yxo),e(Ze,Ia),e(Ia,Kxo),e(Ia,Xme),e(Xme,Zxo),e(Ia,e$o),e(Ia,zme),e(zme,o$o),e(Ia,r$o),e(Ia,Qme),e(Qme,t$o),e(Ia,a$o),e(Ze,n$o),e(Ze,Q),e(Q,h2),e(h2,Wme),e(Wme,s$o),e(h2,l$o),e(h2,GG),e(GG,i$o),e(h2,d$o),e(Q,c$o),e(Q,p2),e(p2,Hme),e(Hme,f$o),e(p2,m$o),e(p2,OG),e(OG,g$o),e(p2,h$o),e(Q,p$o),e(Q,_2),e(_2,Ume),e(Ume,_$o),e(_2,u$o),e(_2,VG),e(VG,b$o),e(_2,v$o),e(Q,F$o),e(Q,u2),e(u2,Jme),e(Jme,T$o),e(u2,M$o),e(u2,XG),e(XG,E$o),e(u2,C$o),e(Q,w$o),e(Q,b2),e(b2,Yme),e(Yme,A$o),e(b2,L$o),e(b2,zG),e(zG,y$o),e(b2,x$o),e(Q,$$o),e(Q,v2),e(v2,Kme),e(Kme,k$o),e(v2,S$o),e(v2,QG),e(QG,R$o),e(v2,P$o),e(Q,B$o),e(Q,F2),e(F2,Zme),e(Zme,I$o),e(F2,N$o),e(F2,WG),e(WG,q$o),e(F2,j$o),e(Q,D$o),e(Q,T2),e(T2,ege),e(ege,G$o),e(T2,O$o),e(T2,HG),e(HG,V$o),e(T2,X$o),e(Q,z$o),e(Q,M2),e(M2,oge),e(oge,Q$o),e(M2,W$o),e(M2,UG),e(UG,H$o),e(M2,U$o),e(Q,J$o),e(Q,E2),e(E2,rge),e(rge,Y$o),e(E2,K$o),e(E2,JG),e(JG,Z$o),e(E2,eko),e(Q,oko),e(Q,C2),e(C2,tge),e(tge,rko),e(C2,tko),e(C2,YG),e(YG,ako),e(C2,nko),e(Q,sko),e(Q,w2),e(w2,age),e(age,lko),e(w2,iko),e(w2,KG),e(KG,dko),e(w2,cko),e(Q,fko),e(Q,A2),e(A2,nge),e(nge,mko),e(A2,gko),e(A2,ZG),e(ZG,hko),e(A2,pko),e(Q,_ko),e(Q,L2),e(L2,sge),e(sge,uko),e(L2,bko),e(L2,eO),e(eO,vko),e(L2,Fko),e(Q,Tko),e(Q,y2),e(y2,lge),e(lge,Mko),e(y2,Eko),e(y2,oO),e(oO,Cko),e(y2,wko),e(Q,Ako),e(Q,x2),e(x2,ige),e(ige,Lko),e(x2,yko),e(x2,rO),e(rO,xko),e(x2,$ko),e(Q,kko),e(Q,$2),e($2,dge),e(dge,Sko),e($2,Rko),e($2,tO),e(tO,Pko),e($2,Bko),e(Q,Iko),e(Q,k2),e(k2,cge),e(cge,Nko),e(k2,qko),e(k2,aO),e(aO,jko),e(k2,Dko),e(Q,Gko),e(Q,S2),e(S2,fge),e(fge,Oko),e(S2,Vko),e(S2,nO),e(nO,Xko),e(S2,zko),e(Q,Qko),e(Q,R2),e(R2,mge),e(mge,Wko),e(R2,Hko),e(R2,sO),e(sO,Uko),e(R2,Jko),e(Q,Yko),e(Q,P2),e(P2,gge),e(gge,Kko),e(P2,Zko),e(P2,lO),e(lO,eSo),e(P2,oSo),e(Q,rSo),e(Q,B2),e(B2,hge),e(hge,tSo),e(B2,aSo),e(B2,iO),e(iO,nSo),e(B2,sSo),e(Q,lSo),e(Q,I2),e(I2,pge),e(pge,iSo),e(I2,dSo),e(I2,dO),e(dO,cSo),e(I2,fSo),e(Q,mSo),e(Q,N2),e(N2,_ge),e(_ge,gSo),e(N2,hSo),e(N2,cO),e(cO,pSo),e(N2,_So),e(Q,uSo),e(Q,q2),e(q2,uge),e(uge,bSo),e(q2,vSo),e(q2,fO),e(fO,FSo),e(q2,TSo),e(Q,MSo),e(Q,j2),e(j2,bge),e(bge,ESo),e(j2,CSo),e(j2,mO),e(mO,wSo),e(j2,ASo),e(Q,LSo),e(Q,D2),e(D2,vge),e(vge,ySo),e(D2,xSo),e(D2,gO),e(gO,$So),e(D2,kSo),e(Q,SSo),e(Q,G2),e(G2,Fge),e(Fge,RSo),e(G2,PSo),e(G2,hO),e(hO,BSo),e(G2,ISo),e(Q,NSo),e(Q,O2),e(O2,Tge),e(Tge,qSo),e(O2,jSo),e(O2,pO),e(pO,DSo),e(O2,GSo),e(Q,OSo),e(Q,V2),e(V2,Mge),e(Mge,VSo),e(V2,XSo),e(V2,_O),e(_O,zSo),e(V2,QSo),e(Q,WSo),e(Q,X2),e(X2,Ege),e(Ege,HSo),e(X2,USo),e(X2,uO),e(uO,JSo),e(X2,YSo),e(Q,KSo),e(Q,z2),e(z2,Cge),e(Cge,ZSo),e(z2,eRo),e(z2,bO),e(bO,oRo),e(z2,rRo),e(Q,tRo),e(Q,Q2),e(Q2,wge),e(wge,aRo),e(Q2,nRo),e(Q2,Age),e(Age,sRo),e(Q2,lRo),e(Q,iRo),e(Q,W2),e(W2,Lge),e(Lge,dRo),e(W2,cRo),e(W2,vO),e(vO,fRo),e(W2,mRo),e(Q,gRo),e(Q,H2),e(H2,yge),e(yge,hRo),e(H2,pRo),e(H2,FO),e(FO,_Ro),e(H2,uRo),e(Q,bRo),e(Q,U2),e(U2,xge),e(xge,vRo),e(U2,FRo),e(U2,TO),e(TO,TRo),e(U2,MRo),e(Q,ERo),e(Q,J2),e(J2,$ge),e($ge,CRo),e(J2,wRo),e(J2,MO),e(MO,ARo),e(J2,LRo),e(Ze,yRo),e(Ze,Y2),e(Y2,xRo),e(Y2,kge),e(kge,$Ro),e(Y2,kRo),e(Y2,Sge),e(Sge,SRo),e(Ze,RRo),M(K2,Ze,null),b(f,sOe,u),b(f,Wi,u),e(Wi,Z2),e(Z2,Rge),M(TL,Rge,null),e(Wi,PRo),e(Wi,Pge),e(Pge,BRo),b(f,lOe,u),b(f,Ro,u),M(ML,Ro,null),e(Ro,IRo),e(Ro,Hi),e(Hi,NRo),e(Hi,EO),e(EO,qRo),e(Hi,jRo),e(Hi,CO),e(CO,DRo),e(Hi,GRo),e(Ro,ORo),e(Ro,EL),e(EL,VRo),e(EL,Bge),e(Bge,XRo),e(EL,zRo),e(Ro,QRo),e(Ro,dt),M(CL,dt,null),e(dt,WRo),e(dt,Ige),e(Ige,HRo),e(dt,URo),e(dt,Ui),e(Ui,JRo),e(Ui,Nge),e(Nge,YRo),e(Ui,KRo),e(Ui,wO),e(wO,ZRo),e(Ui,ePo),e(dt,oPo),M(eb,dt,null),e(Ro,rPo),e(Ro,eo),M(wL,eo,null),e(eo,tPo),e(eo,qge),e(qge,aPo),e(eo,nPo),e(eo,Na),e(Na,sPo),e(Na,jge),e(jge,lPo),e(Na,iPo),e(Na,Dge),e(Dge,dPo),e(Na,cPo),e(Na,Gge),e(Gge,fPo),e(Na,mPo),e(eo,gPo),e(eo,pe),e(pe,ob),e(ob,Oge),e(Oge,hPo),e(ob,pPo),e(ob,AO),e(AO,_Po),e(ob,uPo),e(pe,bPo),e(pe,rb),e(rb,Vge),e(Vge,vPo),e(rb,FPo),e(rb,LO),e(LO,TPo),e(rb,MPo),e(pe,EPo),e(pe,tb),e(tb,Xge),e(Xge,CPo),e(tb,wPo),e(tb,yO),e(yO,APo),e(tb,LPo),e(pe,yPo),e(pe,ab),e(ab,zge),e(zge,xPo),e(ab,$Po),e(ab,xO),e(xO,kPo),e(ab,SPo),e(pe,RPo),e(pe,nb),e(nb,Qge),e(Qge,PPo),e(nb,BPo),e(nb,$O),e($O,IPo),e(nb,NPo),e(pe,qPo),e(pe,sb),e(sb,Wge),e(Wge,jPo),e(sb,DPo),e(sb,kO),e(kO,GPo),e(sb,OPo),e(pe,VPo),e(pe,lb),e(lb,Hge),e(Hge,XPo),e(lb,zPo),e(lb,SO),e(SO,QPo),e(lb,WPo),e(pe,HPo),e(pe,ib),e(ib,Uge),e(Uge,UPo),e(ib,JPo),e(ib,RO),e(RO,YPo),e(ib,KPo),e(pe,ZPo),e(pe,db),e(db,Jge),e(Jge,eBo),e(db,oBo),e(db,PO),e(PO,rBo),e(db,tBo),e(pe,aBo),e(pe,cb),e(cb,Yge),e(Yge,nBo),e(cb,sBo),e(cb,BO),e(BO,lBo),e(cb,iBo),e(pe,dBo),e(pe,fb),e(fb,Kge),e(Kge,cBo),e(fb,fBo),e(fb,IO),e(IO,mBo),e(fb,gBo),e(pe,hBo),e(pe,mb),e(mb,Zge),e(Zge,pBo),e(mb,_Bo),e(mb,NO),e(NO,uBo),e(mb,bBo),e(pe,vBo),e(pe,gb),e(gb,ehe),e(ehe,FBo),e(gb,TBo),e(gb,qO),e(qO,MBo),e(gb,EBo),e(pe,CBo),e(pe,hb),e(hb,ohe),e(ohe,wBo),e(hb,ABo),e(hb,jO),e(jO,LBo),e(hb,yBo),e(pe,xBo),e(pe,pb),e(pb,rhe),e(rhe,$Bo),e(pb,kBo),e(pb,DO),e(DO,SBo),e(pb,RBo),e(pe,PBo),e(pe,_b),e(_b,the),e(the,BBo),e(_b,IBo),e(_b,GO),e(GO,NBo),e(_b,qBo),e(pe,jBo),e(pe,ub),e(ub,ahe),e(ahe,DBo),e(ub,GBo),e(ub,OO),e(OO,OBo),e(ub,VBo),e(eo,XBo),e(eo,bb),e(bb,zBo),e(bb,nhe),e(nhe,QBo),e(bb,WBo),e(bb,she),e(she,HBo),e(eo,UBo),M(vb,eo,null),b(f,iOe,u),b(f,Ji,u),e(Ji,Fb),e(Fb,lhe),M(AL,lhe,null),e(Ji,JBo),e(Ji,ihe),e(ihe,YBo),b(f,dOe,u),b(f,Po,u),M(LL,Po,null),e(Po,KBo),e(Po,Yi),e(Yi,ZBo),e(Yi,VO),e(VO,eIo),e(Yi,oIo),e(Yi,XO),e(XO,rIo),e(Yi,tIo),e(Po,aIo),e(Po,yL),e(yL,nIo),e(yL,dhe),e(dhe,sIo),e(yL,lIo),e(Po,iIo),e(Po,ct),M(xL,ct,null),e(ct,dIo),e(ct,che),e(che,cIo),e(ct,fIo),e(ct,Ki),e(Ki,mIo),e(Ki,fhe),e(fhe,gIo),e(Ki,hIo),e(Ki,zO),e(zO,pIo),e(Ki,_Io),e(ct,uIo),M(Tb,ct,null),e(Po,bIo),e(Po,oo),M($L,oo,null),e(oo,vIo),e(oo,mhe),e(mhe,FIo),e(oo,TIo),e(oo,qa),e(qa,MIo),e(qa,ghe),e(ghe,EIo),e(qa,CIo),e(qa,hhe),e(hhe,wIo),e(qa,AIo),e(qa,phe),e(phe,LIo),e(qa,yIo),e(oo,xIo),e(oo,N),e(N,Mb),e(Mb,_he),e(_he,$Io),e(Mb,kIo),e(Mb,QO),e(QO,SIo),e(Mb,RIo),e(N,PIo),e(N,Eb),e(Eb,uhe),e(uhe,BIo),e(Eb,IIo),e(Eb,WO),e(WO,NIo),e(Eb,qIo),e(N,jIo),e(N,Cb),e(Cb,bhe),e(bhe,DIo),e(Cb,GIo),e(Cb,HO),e(HO,OIo),e(Cb,VIo),e(N,XIo),e(N,wb),e(wb,vhe),e(vhe,zIo),e(wb,QIo),e(wb,UO),e(UO,WIo),e(wb,HIo),e(N,UIo),e(N,Ab),e(Ab,Fhe),e(Fhe,JIo),e(Ab,YIo),e(Ab,JO),e(JO,KIo),e(Ab,ZIo),e(N,eNo),e(N,Lb),e(Lb,The),e(The,oNo),e(Lb,rNo),e(Lb,YO),e(YO,tNo),e(Lb,aNo),e(N,nNo),e(N,yb),e(yb,Mhe),e(Mhe,sNo),e(yb,lNo),e(yb,KO),e(KO,iNo),e(yb,dNo),e(N,cNo),e(N,xb),e(xb,Ehe),e(Ehe,fNo),e(xb,mNo),e(xb,ZO),e(ZO,gNo),e(xb,hNo),e(N,pNo),e(N,$b),e($b,Che),e(Che,_No),e($b,uNo),e($b,eV),e(eV,bNo),e($b,vNo),e(N,FNo),e(N,kb),e(kb,whe),e(whe,TNo),e(kb,MNo),e(kb,oV),e(oV,ENo),e(kb,CNo),e(N,wNo),e(N,Sb),e(Sb,Ahe),e(Ahe,ANo),e(Sb,LNo),e(Sb,rV),e(rV,yNo),e(Sb,xNo),e(N,$No),e(N,Rb),e(Rb,Lhe),e(Lhe,kNo),e(Rb,SNo),e(Rb,tV),e(tV,RNo),e(Rb,PNo),e(N,BNo),e(N,Pb),e(Pb,yhe),e(yhe,INo),e(Pb,NNo),e(Pb,aV),e(aV,qNo),e(Pb,jNo),e(N,DNo),e(N,Bb),e(Bb,xhe),e(xhe,GNo),e(Bb,ONo),e(Bb,nV),e(nV,VNo),e(Bb,XNo),e(N,zNo),e(N,Ib),e(Ib,$he),e($he,QNo),e(Ib,WNo),e(Ib,sV),e(sV,HNo),e(Ib,UNo),e(N,JNo),e(N,Nb),e(Nb,khe),e(khe,YNo),e(Nb,KNo),e(Nb,lV),e(lV,ZNo),e(Nb,eqo),e(N,oqo),e(N,qb),e(qb,She),e(She,rqo),e(qb,tqo),e(qb,iV),e(iV,aqo),e(qb,nqo),e(N,sqo),e(N,jb),e(jb,Rhe),e(Rhe,lqo),e(jb,iqo),e(jb,dV),e(dV,dqo),e(jb,cqo),e(N,fqo),e(N,Db),e(Db,Phe),e(Phe,mqo),e(Db,gqo),e(Db,cV),e(cV,hqo),e(Db,pqo),e(N,_qo),e(N,Gb),e(Gb,Bhe),e(Bhe,uqo),e(Gb,bqo),e(Gb,fV),e(fV,vqo),e(Gb,Fqo),e(N,Tqo),e(N,Ob),e(Ob,Ihe),e(Ihe,Mqo),e(Ob,Eqo),e(Ob,mV),e(mV,Cqo),e(Ob,wqo),e(N,Aqo),e(N,Vb),e(Vb,Nhe),e(Nhe,Lqo),e(Vb,yqo),e(Vb,gV),e(gV,xqo),e(Vb,$qo),e(N,kqo),e(N,Xb),e(Xb,qhe),e(qhe,Sqo),e(Xb,Rqo),e(Xb,hV),e(hV,Pqo),e(Xb,Bqo),e(N,Iqo),e(N,zb),e(zb,jhe),e(jhe,Nqo),e(zb,qqo),e(zb,pV),e(pV,jqo),e(zb,Dqo),e(N,Gqo),e(N,Qb),e(Qb,Dhe),e(Dhe,Oqo),e(Qb,Vqo),e(Qb,_V),e(_V,Xqo),e(Qb,zqo),e(N,Qqo),e(N,Wb),e(Wb,Ghe),e(Ghe,Wqo),e(Wb,Hqo),e(Wb,uV),e(uV,Uqo),e(Wb,Jqo),e(N,Yqo),e(N,Hb),e(Hb,Ohe),e(Ohe,Kqo),e(Hb,Zqo),e(Hb,bV),e(bV,ejo),e(Hb,ojo),e(N,rjo),e(N,Ub),e(Ub,Vhe),e(Vhe,tjo),e(Ub,ajo),e(Ub,vV),e(vV,njo),e(Ub,sjo),e(N,ljo),e(N,Jb),e(Jb,Xhe),e(Xhe,ijo),e(Jb,djo),e(Jb,FV),e(FV,cjo),e(Jb,fjo),e(N,mjo),e(N,Yb),e(Yb,zhe),e(zhe,gjo),e(Yb,hjo),e(Yb,TV),e(TV,pjo),e(Yb,_jo),e(N,ujo),e(N,Kb),e(Kb,Qhe),e(Qhe,bjo),e(Kb,vjo),e(Kb,MV),e(MV,Fjo),e(Kb,Tjo),e(N,Mjo),e(N,Zb),e(Zb,Whe),e(Whe,Ejo),e(Zb,Cjo),e(Zb,EV),e(EV,wjo),e(Zb,Ajo),e(N,Ljo),e(N,e4),e(e4,Hhe),e(Hhe,yjo),e(e4,xjo),e(e4,CV),e(CV,$jo),e(e4,kjo),e(N,Sjo),e(N,o4),e(o4,Uhe),e(Uhe,Rjo),e(o4,Pjo),e(o4,wV),e(wV,Bjo),e(o4,Ijo),e(N,Njo),e(N,r4),e(r4,Jhe),e(Jhe,qjo),e(r4,jjo),e(r4,AV),e(AV,Djo),e(r4,Gjo),e(N,Ojo),e(N,t4),e(t4,Yhe),e(Yhe,Vjo),e(t4,Xjo),e(t4,LV),e(LV,zjo),e(t4,Qjo),e(N,Wjo),e(N,a4),e(a4,Khe),e(Khe,Hjo),e(a4,Ujo),e(a4,yV),e(yV,Jjo),e(a4,Yjo),e(N,Kjo),e(N,n4),e(n4,Zhe),e(Zhe,Zjo),e(n4,eDo),e(n4,xV),e(xV,oDo),e(n4,rDo),e(N,tDo),e(N,s4),e(s4,epe),e(epe,aDo),e(s4,nDo),e(s4,$V),e($V,sDo),e(s4,lDo),e(N,iDo),e(N,l4),e(l4,ope),e(ope,dDo),e(l4,cDo),e(l4,kV),e(kV,fDo),e(l4,mDo),e(N,gDo),e(N,i4),e(i4,rpe),e(rpe,hDo),e(i4,pDo),e(i4,SV),e(SV,_Do),e(i4,uDo),e(N,bDo),e(N,d4),e(d4,tpe),e(tpe,vDo),e(d4,FDo),e(d4,RV),e(RV,TDo),e(d4,MDo),e(N,EDo),e(N,c4),e(c4,ape),e(ape,CDo),e(c4,wDo),e(c4,PV),e(PV,ADo),e(c4,LDo),e(N,yDo),e(N,f4),e(f4,npe),e(npe,xDo),e(f4,$Do),e(f4,BV),e(BV,kDo),e(f4,SDo),e(N,RDo),e(N,m4),e(m4,spe),e(spe,PDo),e(m4,BDo),e(m4,IV),e(IV,IDo),e(m4,NDo),e(N,qDo),e(N,g4),e(g4,lpe),e(lpe,jDo),e(g4,DDo),e(g4,NV),e(NV,GDo),e(g4,ODo),e(N,VDo),e(N,h4),e(h4,ipe),e(ipe,XDo),e(h4,zDo),e(h4,qV),e(qV,QDo),e(h4,WDo),e(N,HDo),e(N,p4),e(p4,dpe),e(dpe,UDo),e(p4,JDo),e(p4,jV),e(jV,YDo),e(p4,KDo),e(N,ZDo),e(N,_4),e(_4,cpe),e(cpe,eGo),e(_4,oGo),e(_4,DV),e(DV,rGo),e(_4,tGo),e(oo,aGo),e(oo,u4),e(u4,nGo),e(u4,fpe),e(fpe,sGo),e(u4,lGo),e(u4,mpe),e(mpe,iGo),e(oo,dGo),M(b4,oo,null),b(f,cOe,u),b(f,Zi,u),e(Zi,v4),e(v4,gpe),M(kL,gpe,null),e(Zi,cGo),e(Zi,hpe),e(hpe,fGo),b(f,fOe,u),b(f,Bo,u),M(SL,Bo,null),e(Bo,mGo),e(Bo,ed),e(ed,gGo),e(ed,GV),e(GV,hGo),e(ed,pGo),e(ed,OV),e(OV,_Go),e(ed,uGo),e(Bo,bGo),e(Bo,RL),e(RL,vGo),e(RL,ppe),e(ppe,FGo),e(RL,TGo),e(Bo,MGo),e(Bo,ft),M(PL,ft,null),e(ft,EGo),e(ft,_pe),e(_pe,CGo),e(ft,wGo),e(ft,od),e(od,AGo),e(od,upe),e(upe,LGo),e(od,yGo),e(od,VV),e(VV,xGo),e(od,$Go),e(ft,kGo),M(F4,ft,null),e(Bo,SGo),e(Bo,ro),M(BL,ro,null),e(ro,RGo),e(ro,bpe),e(bpe,PGo),e(ro,BGo),e(ro,ja),e(ja,IGo),e(ja,vpe),e(vpe,NGo),e(ja,qGo),e(ja,Fpe),e(Fpe,jGo),e(ja,DGo),e(ja,Tpe),e(Tpe,GGo),e(ja,OGo),e(ro,VGo),e(ro,Z),e(Z,T4),e(T4,Mpe),e(Mpe,XGo),e(T4,zGo),e(T4,XV),e(XV,QGo),e(T4,WGo),e(Z,HGo),e(Z,M4),e(M4,Epe),e(Epe,UGo),e(M4,JGo),e(M4,zV),e(zV,YGo),e(M4,KGo),e(Z,ZGo),e(Z,E4),e(E4,Cpe),e(Cpe,eOo),e(E4,oOo),e(E4,QV),e(QV,rOo),e(E4,tOo),e(Z,aOo),e(Z,C4),e(C4,wpe),e(wpe,nOo),e(C4,sOo),e(C4,WV),e(WV,lOo),e(C4,iOo),e(Z,dOo),e(Z,w4),e(w4,Ape),e(Ape,cOo),e(w4,fOo),e(w4,HV),e(HV,mOo),e(w4,gOo),e(Z,hOo),e(Z,A4),e(A4,Lpe),e(Lpe,pOo),e(A4,_Oo),e(A4,UV),e(UV,uOo),e(A4,bOo),e(Z,vOo),e(Z,L4),e(L4,ype),e(ype,FOo),e(L4,TOo),e(L4,JV),e(JV,MOo),e(L4,EOo),e(Z,COo),e(Z,y4),e(y4,xpe),e(xpe,wOo),e(y4,AOo),e(y4,YV),e(YV,LOo),e(y4,yOo),e(Z,xOo),e(Z,x4),e(x4,$pe),e($pe,$Oo),e(x4,kOo),e(x4,KV),e(KV,SOo),e(x4,ROo),e(Z,POo),e(Z,$4),e($4,kpe),e(kpe,BOo),e($4,IOo),e($4,ZV),e(ZV,NOo),e($4,qOo),e(Z,jOo),e(Z,k4),e(k4,Spe),e(Spe,DOo),e(k4,GOo),e(k4,eX),e(eX,OOo),e(k4,VOo),e(Z,XOo),e(Z,S4),e(S4,Rpe),e(Rpe,zOo),e(S4,QOo),e(S4,oX),e(oX,WOo),e(S4,HOo),e(Z,UOo),e(Z,R4),e(R4,Ppe),e(Ppe,JOo),e(R4,YOo),e(R4,rX),e(rX,KOo),e(R4,ZOo),e(Z,eVo),e(Z,P4),e(P4,Bpe),e(Bpe,oVo),e(P4,rVo),e(P4,tX),e(tX,tVo),e(P4,aVo),e(Z,nVo),e(Z,B4),e(B4,Ipe),e(Ipe,sVo),e(B4,lVo),e(B4,aX),e(aX,iVo),e(B4,dVo),e(Z,cVo),e(Z,I4),e(I4,Npe),e(Npe,fVo),e(I4,mVo),e(I4,nX),e(nX,gVo),e(I4,hVo),e(Z,pVo),e(Z,N4),e(N4,qpe),e(qpe,_Vo),e(N4,uVo),e(N4,sX),e(sX,bVo),e(N4,vVo),e(Z,FVo),e(Z,q4),e(q4,jpe),e(jpe,TVo),e(q4,MVo),e(q4,lX),e(lX,EVo),e(q4,CVo),e(Z,wVo),e(Z,j4),e(j4,Dpe),e(Dpe,AVo),e(j4,LVo),e(j4,iX),e(iX,yVo),e(j4,xVo),e(Z,$Vo),e(Z,D4),e(D4,Gpe),e(Gpe,kVo),e(D4,SVo),e(D4,dX),e(dX,RVo),e(D4,PVo),e(Z,BVo),e(Z,G4),e(G4,Ope),e(Ope,IVo),e(G4,NVo),e(G4,cX),e(cX,qVo),e(G4,jVo),e(Z,DVo),e(Z,O4),e(O4,Vpe),e(Vpe,GVo),e(O4,OVo),e(O4,fX),e(fX,VVo),e(O4,XVo),e(Z,zVo),e(Z,V4),e(V4,Xpe),e(Xpe,QVo),e(V4,WVo),e(V4,mX),e(mX,HVo),e(V4,UVo),e(Z,JVo),e(Z,X4),e(X4,zpe),e(zpe,YVo),e(X4,KVo),e(X4,gX),e(gX,ZVo),e(X4,eXo),e(Z,oXo),e(Z,z4),e(z4,Qpe),e(Qpe,rXo),e(z4,tXo),e(z4,hX),e(hX,aXo),e(z4,nXo),e(Z,sXo),e(Z,Q4),e(Q4,Wpe),e(Wpe,lXo),e(Q4,iXo),e(Q4,pX),e(pX,dXo),e(Q4,cXo),e(Z,fXo),e(Z,W4),e(W4,Hpe),e(Hpe,mXo),e(W4,gXo),e(W4,_X),e(_X,hXo),e(W4,pXo),e(Z,_Xo),e(Z,H4),e(H4,Upe),e(Upe,uXo),e(H4,bXo),e(H4,uX),e(uX,vXo),e(H4,FXo),e(Z,TXo),e(Z,U4),e(U4,Jpe),e(Jpe,MXo),e(U4,EXo),e(U4,bX),e(bX,CXo),e(U4,wXo),e(Z,AXo),e(Z,J4),e(J4,Ype),e(Ype,LXo),e(J4,yXo),e(J4,vX),e(vX,xXo),e(J4,$Xo),e(ro,kXo),e(ro,Y4),e(Y4,SXo),e(Y4,Kpe),e(Kpe,RXo),e(Y4,PXo),e(Y4,Zpe),e(Zpe,BXo),e(ro,IXo),M(K4,ro,null),b(f,mOe,u),b(f,rd,u),e(rd,Z4),e(Z4,e_e),M(IL,e_e,null),e(rd,NXo),e(rd,o_e),e(o_e,qXo),b(f,gOe,u),b(f,Io,u),M(NL,Io,null),e(Io,jXo),e(Io,td),e(td,DXo),e(td,FX),e(FX,GXo),e(td,OXo),e(td,TX),e(TX,VXo),e(td,XXo),e(Io,zXo),e(Io,qL),e(qL,QXo),e(qL,r_e),e(r_e,WXo),e(qL,HXo),e(Io,UXo),e(Io,mt),M(jL,mt,null),e(mt,JXo),e(mt,t_e),e(t_e,YXo),e(mt,KXo),e(mt,ad),e(ad,ZXo),e(ad,a_e),e(a_e,ezo),e(ad,ozo),e(ad,MX),e(MX,rzo),e(ad,tzo),e(mt,azo),M(ev,mt,null),e(Io,nzo),e(Io,to),M(DL,to,null),e(to,szo),e(to,n_e),e(n_e,lzo),e(to,izo),e(to,Da),e(Da,dzo),e(Da,s_e),e(s_e,czo),e(Da,fzo),e(Da,l_e),e(l_e,mzo),e(Da,gzo),e(Da,i_e),e(i_e,hzo),e(Da,pzo),e(to,_zo),e(to,No),e(No,ov),e(ov,d_e),e(d_e,uzo),e(ov,bzo),e(ov,EX),e(EX,vzo),e(ov,Fzo),e(No,Tzo),e(No,rv),e(rv,c_e),e(c_e,Mzo),e(rv,Ezo),e(rv,CX),e(CX,Czo),e(rv,wzo),e(No,Azo),e(No,tv),e(tv,f_e),e(f_e,Lzo),e(tv,yzo),e(tv,wX),e(wX,xzo),e(tv,$zo),e(No,kzo),e(No,av),e(av,m_e),e(m_e,Szo),e(av,Rzo),e(av,AX),e(AX,Pzo),e(av,Bzo),e(No,Izo),e(No,nv),e(nv,g_e),e(g_e,Nzo),e(nv,qzo),e(nv,LX),e(LX,jzo),e(nv,Dzo),e(No,Gzo),e(No,sv),e(sv,h_e),e(h_e,Ozo),e(sv,Vzo),e(sv,yX),e(yX,Xzo),e(sv,zzo),e(to,Qzo),e(to,lv),e(lv,Wzo),e(lv,p_e),e(p_e,Hzo),e(lv,Uzo),e(lv,__e),e(__e,Jzo),e(to,Yzo),M(iv,to,null),b(f,hOe,u),b(f,nd,u),e(nd,dv),e(dv,u_e),M(GL,u_e,null),e(nd,Kzo),e(nd,b_e),e(b_e,Zzo),b(f,pOe,u),b(f,qo,u),M(OL,qo,null),e(qo,eQo),e(qo,sd),e(sd,oQo),e(sd,xX),e(xX,rQo),e(sd,tQo),e(sd,$X),e($X,aQo),e(sd,nQo),e(qo,sQo),e(qo,VL),e(VL,lQo),e(VL,v_e),e(v_e,iQo),e(VL,dQo),e(qo,cQo),e(qo,gt),M(XL,gt,null),e(gt,fQo),e(gt,F_e),e(F_e,mQo),e(gt,gQo),e(gt,ld),e(ld,hQo),e(ld,T_e),e(T_e,pQo),e(ld,_Qo),e(ld,kX),e(kX,uQo),e(ld,bQo),e(gt,vQo),M(cv,gt,null),e(qo,FQo),e(qo,ao),M(zL,ao,null),e(ao,TQo),e(ao,M_e),e(M_e,MQo),e(ao,EQo),e(ao,Ga),e(Ga,CQo),e(Ga,E_e),e(E_e,wQo),e(Ga,AQo),e(Ga,C_e),e(C_e,LQo),e(Ga,yQo),e(Ga,w_e),e(w_e,xQo),e(Ga,$Qo),e(ao,kQo),e(ao,H),e(H,fv),e(fv,A_e),e(A_e,SQo),e(fv,RQo),e(fv,SX),e(SX,PQo),e(fv,BQo),e(H,IQo),e(H,mv),e(mv,L_e),e(L_e,NQo),e(mv,qQo),e(mv,RX),e(RX,jQo),e(mv,DQo),e(H,GQo),e(H,gv),e(gv,y_e),e(y_e,OQo),e(gv,VQo),e(gv,PX),e(PX,XQo),e(gv,zQo),e(H,QQo),e(H,hv),e(hv,x_e),e(x_e,WQo),e(hv,HQo),e(hv,BX),e(BX,UQo),e(hv,JQo),e(H,YQo),e(H,pv),e(pv,$_e),e($_e,KQo),e(pv,ZQo),e(pv,IX),e(IX,eWo),e(pv,oWo),e(H,rWo),e(H,_v),e(_v,k_e),e(k_e,tWo),e(_v,aWo),e(_v,NX),e(NX,nWo),e(_v,sWo),e(H,lWo),e(H,uv),e(uv,S_e),e(S_e,iWo),e(uv,dWo),e(uv,qX),e(qX,cWo),e(uv,fWo),e(H,mWo),e(H,bv),e(bv,R_e),e(R_e,gWo),e(bv,hWo),e(bv,jX),e(jX,pWo),e(bv,_Wo),e(H,uWo),e(H,vv),e(vv,P_e),e(P_e,bWo),e(vv,vWo),e(vv,DX),e(DX,FWo),e(vv,TWo),e(H,MWo),e(H,Fv),e(Fv,B_e),e(B_e,EWo),e(Fv,CWo),e(Fv,GX),e(GX,wWo),e(Fv,AWo),e(H,LWo),e(H,Tv),e(Tv,I_e),e(I_e,yWo),e(Tv,xWo),e(Tv,OX),e(OX,$Wo),e(Tv,kWo),e(H,SWo),e(H,Mv),e(Mv,N_e),e(N_e,RWo),e(Mv,PWo),e(Mv,VX),e(VX,BWo),e(Mv,IWo),e(H,NWo),e(H,Ev),e(Ev,q_e),e(q_e,qWo),e(Ev,jWo),e(Ev,XX),e(XX,DWo),e(Ev,GWo),e(H,OWo),e(H,Cv),e(Cv,j_e),e(j_e,VWo),e(Cv,XWo),e(Cv,zX),e(zX,zWo),e(Cv,QWo),e(H,WWo),e(H,wv),e(wv,D_e),e(D_e,HWo),e(wv,UWo),e(wv,QX),e(QX,JWo),e(wv,YWo),e(H,KWo),e(H,Av),e(Av,G_e),e(G_e,ZWo),e(Av,eHo),e(Av,WX),e(WX,oHo),e(Av,rHo),e(H,tHo),e(H,Lv),e(Lv,O_e),e(O_e,aHo),e(Lv,nHo),e(Lv,HX),e(HX,sHo),e(Lv,lHo),e(H,iHo),e(H,yv),e(yv,V_e),e(V_e,dHo),e(yv,cHo),e(yv,UX),e(UX,fHo),e(yv,mHo),e(H,gHo),e(H,xv),e(xv,X_e),e(X_e,hHo),e(xv,pHo),e(xv,JX),e(JX,_Ho),e(xv,uHo),e(H,bHo),e(H,$v),e($v,z_e),e(z_e,vHo),e($v,FHo),e($v,YX),e(YX,THo),e($v,MHo),e(H,EHo),e(H,kv),e(kv,Q_e),e(Q_e,CHo),e(kv,wHo),e(kv,KX),e(KX,AHo),e(kv,LHo),e(H,yHo),e(H,Sv),e(Sv,W_e),e(W_e,xHo),e(Sv,$Ho),e(Sv,ZX),e(ZX,kHo),e(Sv,SHo),e(H,RHo),e(H,Rv),e(Rv,H_e),e(H_e,PHo),e(Rv,BHo),e(Rv,ez),e(ez,IHo),e(Rv,NHo),e(H,qHo),e(H,Pv),e(Pv,U_e),e(U_e,jHo),e(Pv,DHo),e(Pv,oz),e(oz,GHo),e(Pv,OHo),e(H,VHo),e(H,Bv),e(Bv,J_e),e(J_e,XHo),e(Bv,zHo),e(Bv,rz),e(rz,QHo),e(Bv,WHo),e(H,HHo),e(H,Iv),e(Iv,Y_e),e(Y_e,UHo),e(Iv,JHo),e(Iv,tz),e(tz,YHo),e(Iv,KHo),e(H,ZHo),e(H,Nv),e(Nv,K_e),e(K_e,eUo),e(Nv,oUo),e(Nv,az),e(az,rUo),e(Nv,tUo),e(H,aUo),e(H,qv),e(qv,Z_e),e(Z_e,nUo),e(qv,sUo),e(qv,nz),e(nz,lUo),e(qv,iUo),e(H,dUo),e(H,jv),e(jv,eue),e(eue,cUo),e(jv,fUo),e(jv,sz),e(sz,mUo),e(jv,gUo),e(H,hUo),e(H,Dv),e(Dv,oue),e(oue,pUo),e(Dv,_Uo),e(Dv,lz),e(lz,uUo),e(Dv,bUo),e(H,vUo),e(H,Gv),e(Gv,rue),e(rue,FUo),e(Gv,TUo),e(Gv,iz),e(iz,MUo),e(Gv,EUo),e(H,CUo),e(H,Ov),e(Ov,tue),e(tue,wUo),e(Ov,AUo),e(Ov,dz),e(dz,LUo),e(Ov,yUo),e(H,xUo),e(H,Vv),e(Vv,aue),e(aue,$Uo),e(Vv,kUo),e(Vv,cz),e(cz,SUo),e(Vv,RUo),e(H,PUo),e(H,Xv),e(Xv,nue),e(nue,BUo),e(Xv,IUo),e(Xv,fz),e(fz,NUo),e(Xv,qUo),e(H,jUo),e(H,zv),e(zv,sue),e(sue,DUo),e(zv,GUo),e(zv,mz),e(mz,OUo),e(zv,VUo),e(H,XUo),e(H,Qv),e(Qv,lue),e(lue,zUo),e(Qv,QUo),e(Qv,gz),e(gz,WUo),e(Qv,HUo),e(ao,UUo),e(ao,Wv),e(Wv,JUo),e(Wv,iue),e(iue,YUo),e(Wv,KUo),e(Wv,due),e(due,ZUo),e(ao,eJo),M(Hv,ao,null),b(f,_Oe,u),b(f,id,u),e(id,Uv),e(Uv,cue),M(QL,cue,null),e(id,oJo),e(id,fue),e(fue,rJo),b(f,uOe,u),b(f,jo,u),M(WL,jo,null),e(jo,tJo),e(jo,dd),e(dd,aJo),e(dd,hz),e(hz,nJo),e(dd,sJo),e(dd,pz),e(pz,lJo),e(dd,iJo),e(jo,dJo),e(jo,HL),e(HL,cJo),e(HL,mue),e(mue,fJo),e(HL,mJo),e(jo,gJo),e(jo,ht),M(UL,ht,null),e(ht,hJo),e(ht,gue),e(gue,pJo),e(ht,_Jo),e(ht,cd),e(cd,uJo),e(cd,hue),e(hue,bJo),e(cd,vJo),e(cd,_z),e(_z,FJo),e(cd,TJo),e(ht,MJo),M(Jv,ht,null),e(jo,EJo),e(jo,no),M(JL,no,null),e(no,CJo),e(no,pue),e(pue,wJo),e(no,AJo),e(no,Oa),e(Oa,LJo),e(Oa,_ue),e(_ue,yJo),e(Oa,xJo),e(Oa,uue),e(uue,$Jo),e(Oa,kJo),e(Oa,bue),e(bue,SJo),e(Oa,RJo),e(no,PJo),e(no,V),e(V,Yv),e(Yv,vue),e(vue,BJo),e(Yv,IJo),e(Yv,uz),e(uz,NJo),e(Yv,qJo),e(V,jJo),e(V,Kv),e(Kv,Fue),e(Fue,DJo),e(Kv,GJo),e(Kv,bz),e(bz,OJo),e(Kv,VJo),e(V,XJo),e(V,Zv),e(Zv,Tue),e(Tue,zJo),e(Zv,QJo),e(Zv,vz),e(vz,WJo),e(Zv,HJo),e(V,UJo),e(V,eF),e(eF,Mue),e(Mue,JJo),e(eF,YJo),e(eF,Fz),e(Fz,KJo),e(eF,ZJo),e(V,eYo),e(V,oF),e(oF,Eue),e(Eue,oYo),e(oF,rYo),e(oF,Tz),e(Tz,tYo),e(oF,aYo),e(V,nYo),e(V,rF),e(rF,Cue),e(Cue,sYo),e(rF,lYo),e(rF,Mz),e(Mz,iYo),e(rF,dYo),e(V,cYo),e(V,tF),e(tF,wue),e(wue,fYo),e(tF,mYo),e(tF,Ez),e(Ez,gYo),e(tF,hYo),e(V,pYo),e(V,aF),e(aF,Aue),e(Aue,_Yo),e(aF,uYo),e(aF,Cz),e(Cz,bYo),e(aF,vYo),e(V,FYo),e(V,nF),e(nF,Lue),e(Lue,TYo),e(nF,MYo),e(nF,wz),e(wz,EYo),e(nF,CYo),e(V,wYo),e(V,sF),e(sF,yue),e(yue,AYo),e(sF,LYo),e(sF,Az),e(Az,yYo),e(sF,xYo),e(V,$Yo),e(V,lF),e(lF,xue),e(xue,kYo),e(lF,SYo),e(lF,Lz),e(Lz,RYo),e(lF,PYo),e(V,BYo),e(V,iF),e(iF,$ue),e($ue,IYo),e(iF,NYo),e(iF,yz),e(yz,qYo),e(iF,jYo),e(V,DYo),e(V,dF),e(dF,kue),e(kue,GYo),e(dF,OYo),e(dF,xz),e(xz,VYo),e(dF,XYo),e(V,zYo),e(V,cF),e(cF,Sue),e(Sue,QYo),e(cF,WYo),e(cF,$z),e($z,HYo),e(cF,UYo),e(V,JYo),e(V,fF),e(fF,Rue),e(Rue,YYo),e(fF,KYo),e(fF,kz),e(kz,ZYo),e(fF,eKo),e(V,oKo),e(V,mF),e(mF,Pue),e(Pue,rKo),e(mF,tKo),e(mF,Sz),e(Sz,aKo),e(mF,nKo),e(V,sKo),e(V,gF),e(gF,Bue),e(Bue,lKo),e(gF,iKo),e(gF,Rz),e(Rz,dKo),e(gF,cKo),e(V,fKo),e(V,hF),e(hF,Iue),e(Iue,mKo),e(hF,gKo),e(hF,Pz),e(Pz,hKo),e(hF,pKo),e(V,_Ko),e(V,pF),e(pF,Nue),e(Nue,uKo),e(pF,bKo),e(pF,Bz),e(Bz,vKo),e(pF,FKo),e(V,TKo),e(V,_F),e(_F,que),e(que,MKo),e(_F,EKo),e(_F,Iz),e(Iz,CKo),e(_F,wKo),e(V,AKo),e(V,uF),e(uF,jue),e(jue,LKo),e(uF,yKo),e(uF,Nz),e(Nz,xKo),e(uF,$Ko),e(V,kKo),e(V,bF),e(bF,Due),e(Due,SKo),e(bF,RKo),e(bF,qz),e(qz,PKo),e(bF,BKo),e(V,IKo),e(V,vF),e(vF,Gue),e(Gue,NKo),e(vF,qKo),e(vF,jz),e(jz,jKo),e(vF,DKo),e(V,GKo),e(V,FF),e(FF,Oue),e(Oue,OKo),e(FF,VKo),e(FF,Dz),e(Dz,XKo),e(FF,zKo),e(V,QKo),e(V,TF),e(TF,Vue),e(Vue,WKo),e(TF,HKo),e(TF,Gz),e(Gz,UKo),e(TF,JKo),e(V,YKo),e(V,MF),e(MF,Xue),e(Xue,KKo),e(MF,ZKo),e(MF,Oz),e(Oz,eZo),e(MF,oZo),e(V,rZo),e(V,EF),e(EF,zue),e(zue,tZo),e(EF,aZo),e(EF,Vz),e(Vz,nZo),e(EF,sZo),e(V,lZo),e(V,CF),e(CF,Que),e(Que,iZo),e(CF,dZo),e(CF,Xz),e(Xz,cZo),e(CF,fZo),e(V,mZo),e(V,wF),e(wF,Wue),e(Wue,gZo),e(wF,hZo),e(wF,zz),e(zz,pZo),e(wF,_Zo),e(V,uZo),e(V,AF),e(AF,Hue),e(Hue,bZo),e(AF,vZo),e(AF,Qz),e(Qz,FZo),e(AF,TZo),e(V,MZo),e(V,LF),e(LF,Uue),e(Uue,EZo),e(LF,CZo),e(LF,Wz),e(Wz,wZo),e(LF,AZo),e(V,LZo),e(V,yF),e(yF,Jue),e(Jue,yZo),e(yF,xZo),e(yF,Hz),e(Hz,$Zo),e(yF,kZo),e(V,SZo),e(V,xF),e(xF,Yue),e(Yue,RZo),e(xF,PZo),e(xF,Uz),e(Uz,BZo),e(xF,IZo),e(V,NZo),e(V,$F),e($F,Kue),e(Kue,qZo),e($F,jZo),e($F,Jz),e(Jz,DZo),e($F,GZo),e(V,OZo),e(V,kF),e(kF,Zue),e(Zue,VZo),e(kF,XZo),e(kF,Yz),e(Yz,zZo),e(kF,QZo),e(V,WZo),e(V,SF),e(SF,e1e),e(e1e,HZo),e(SF,UZo),e(SF,Kz),e(Kz,JZo),e(SF,YZo),e(V,KZo),e(V,RF),e(RF,o1e),e(o1e,ZZo),e(RF,eer),e(RF,Zz),e(Zz,oer),e(RF,rer),e(V,ter),e(V,PF),e(PF,r1e),e(r1e,aer),e(PF,ner),e(PF,eQ),e(eQ,ser),e(PF,ler),e(V,ier),e(V,BF),e(BF,t1e),e(t1e,der),e(BF,cer),e(BF,oQ),e(oQ,fer),e(BF,mer),e(V,ger),e(V,IF),e(IF,a1e),e(a1e,her),e(IF,per),e(IF,rQ),e(rQ,_er),e(IF,uer),e(V,ber),e(V,NF),e(NF,n1e),e(n1e,ver),e(NF,Fer),e(NF,tQ),e(tQ,Ter),e(NF,Mer),e(no,Eer),e(no,qF),e(qF,Cer),e(qF,s1e),e(s1e,wer),e(qF,Aer),e(qF,l1e),e(l1e,Ler),e(no,yer),M(jF,no,null),b(f,bOe,u),b(f,fd,u),e(fd,DF),e(DF,i1e),M(YL,i1e,null),e(fd,xer),e(fd,d1e),e(d1e,$er),b(f,vOe,u),b(f,Do,u),M(KL,Do,null),e(Do,ker),e(Do,md),e(md,Ser),e(md,aQ),e(aQ,Rer),e(md,Per),e(md,nQ),e(nQ,Ber),e(md,Ier),e(Do,Ner),e(Do,ZL),e(ZL,qer),e(ZL,c1e),e(c1e,jer),e(ZL,Der),e(Do,Ger),e(Do,pt),M(ey,pt,null),e(pt,Oer),e(pt,f1e),e(f1e,Ver),e(pt,Xer),e(pt,gd),e(gd,zer),e(gd,m1e),e(m1e,Qer),e(gd,Wer),e(gd,sQ),e(sQ,Her),e(gd,Uer),e(pt,Jer),M(GF,pt,null),e(Do,Yer),e(Do,so),M(oy,so,null),e(so,Ker),e(so,g1e),e(g1e,Zer),e(so,eor),e(so,Va),e(Va,oor),e(Va,h1e),e(h1e,ror),e(Va,tor),e(Va,p1e),e(p1e,aor),e(Va,nor),e(Va,_1e),e(_1e,sor),e(Va,lor),e(so,ior),e(so,u1e),e(u1e,OF),e(OF,b1e),e(b1e,dor),e(OF,cor),e(OF,lQ),e(lQ,mor),e(OF,gor),e(so,hor),e(so,VF),e(VF,por),e(VF,v1e),e(v1e,_or),e(VF,uor),e(VF,F1e),e(F1e,bor),e(so,vor),M(XF,so,null),b(f,FOe,u),b(f,hd,u),e(hd,zF),e(zF,T1e),M(ry,T1e,null),e(hd,For),e(hd,M1e),e(M1e,Tor),b(f,TOe,u),b(f,Go,u),M(ty,Go,null),e(Go,Mor),e(Go,pd),e(pd,Eor),e(pd,iQ),e(iQ,Cor),e(pd,wor),e(pd,dQ),e(dQ,Aor),e(pd,Lor),e(Go,yor),e(Go,ay),e(ay,xor),e(ay,E1e),e(E1e,$or),e(ay,kor),e(Go,Sor),e(Go,_t),M(ny,_t,null),e(_t,Ror),e(_t,C1e),e(C1e,Por),e(_t,Bor),e(_t,_d),e(_d,Ior),e(_d,w1e),e(w1e,Nor),e(_d,qor),e(_d,cQ),e(cQ,jor),e(_d,Dor),e(_t,Gor),M(QF,_t,null),e(Go,Oor),e(Go,lo),M(sy,lo,null),e(lo,Vor),e(lo,A1e),e(A1e,Xor),e(lo,zor),e(lo,Xa),e(Xa,Qor),e(Xa,L1e),e(L1e,Wor),e(Xa,Hor),e(Xa,y1e),e(y1e,Uor),e(Xa,Jor),e(Xa,x1e),e(x1e,Yor),e(Xa,Kor),e(lo,Zor),e(lo,Fe),e(Fe,WF),e(WF,$1e),e($1e,err),e(WF,orr),e(WF,fQ),e(fQ,rrr),e(WF,trr),e(Fe,arr),e(Fe,HF),e(HF,k1e),e(k1e,nrr),e(HF,srr),e(HF,mQ),e(mQ,lrr),e(HF,irr),e(Fe,drr),e(Fe,UF),e(UF,S1e),e(S1e,crr),e(UF,frr),e(UF,gQ),e(gQ,mrr),e(UF,grr),e(Fe,hrr),e(Fe,JF),e(JF,R1e),e(R1e,prr),e(JF,_rr),e(JF,hQ),e(hQ,urr),e(JF,brr),e(Fe,vrr),e(Fe,Xs),e(Xs,P1e),e(P1e,Frr),e(Xs,Trr),e(Xs,pQ),e(pQ,Mrr),e(Xs,Err),e(Xs,_Q),e(_Q,Crr),e(Xs,wrr),e(Fe,Arr),e(Fe,YF),e(YF,B1e),e(B1e,Lrr),e(YF,yrr),e(YF,uQ),e(uQ,xrr),e(YF,$rr),e(Fe,krr),e(Fe,zs),e(zs,I1e),e(I1e,Srr),e(zs,Rrr),e(zs,bQ),e(bQ,Prr),e(zs,Brr),e(zs,vQ),e(vQ,Irr),e(zs,Nrr),e(Fe,qrr),e(Fe,ut),e(ut,N1e),e(N1e,jrr),e(ut,Drr),e(ut,FQ),e(FQ,Grr),e(ut,Orr),e(ut,TQ),e(TQ,Vrr),e(ut,Xrr),e(ut,MQ),e(MQ,zrr),e(ut,Qrr),e(Fe,Wrr),e(Fe,KF),e(KF,q1e),e(q1e,Hrr),e(KF,Urr),e(KF,EQ),e(EQ,Jrr),e(KF,Yrr),e(Fe,Krr),e(Fe,ZF),e(ZF,j1e),e(j1e,Zrr),e(ZF,etr),e(ZF,CQ),e(CQ,otr),e(ZF,rtr),e(Fe,ttr),e(Fe,e6),e(e6,D1e),e(D1e,atr),e(e6,ntr),e(e6,wQ),e(wQ,str),e(e6,ltr),e(Fe,itr),e(Fe,o6),e(o6,G1e),e(G1e,dtr),e(o6,ctr),e(o6,AQ),e(AQ,ftr),e(o6,mtr),e(Fe,gtr),e(Fe,r6),e(r6,O1e),e(O1e,htr),e(r6,ptr),e(r6,LQ),e(LQ,_tr),e(r6,utr),e(Fe,btr),e(Fe,t6),e(t6,V1e),e(V1e,vtr),e(t6,Ftr),e(t6,yQ),e(yQ,Ttr),e(t6,Mtr),e(Fe,Etr),e(Fe,a6),e(a6,X1e),e(X1e,Ctr),e(a6,wtr),e(a6,xQ),e(xQ,Atr),e(a6,Ltr),e(lo,ytr),e(lo,n6),e(n6,xtr),e(n6,z1e),e(z1e,$tr),e(n6,ktr),e(n6,Q1e),e(Q1e,Str),e(lo,Rtr),M(s6,lo,null),b(f,MOe,u),b(f,ud,u),e(ud,l6),e(l6,W1e),M(ly,W1e,null),e(ud,Ptr),e(ud,H1e),e(H1e,Btr),b(f,EOe,u),b(f,Oo,u),M(iy,Oo,null),e(Oo,Itr),e(Oo,bd),e(bd,Ntr),e(bd,$Q),e($Q,qtr),e(bd,jtr),e(bd,kQ),e(kQ,Dtr),e(bd,Gtr),e(Oo,Otr),e(Oo,dy),e(dy,Vtr),e(dy,U1e),e(U1e,Xtr),e(dy,ztr),e(Oo,Qtr),e(Oo,bt),M(cy,bt,null),e(bt,Wtr),e(bt,J1e),e(J1e,Htr),e(bt,Utr),e(bt,vd),e(vd,Jtr),e(vd,Y1e),e(Y1e,Ytr),e(vd,Ktr),e(vd,SQ),e(SQ,Ztr),e(vd,ear),e(bt,oar),M(i6,bt,null),e(Oo,rar),e(Oo,io),M(fy,io,null),e(io,tar),e(io,K1e),e(K1e,aar),e(io,nar),e(io,za),e(za,sar),e(za,Z1e),e(Z1e,lar),e(za,iar),e(za,e2e),e(e2e,dar),e(za,car),e(za,o2e),e(o2e,far),e(za,mar),e(io,gar),e(io,r2e),e(r2e,d6),e(d6,t2e),e(t2e,har),e(d6,par),e(d6,RQ),e(RQ,_ar),e(d6,uar),e(io,bar),e(io,c6),e(c6,Far),e(c6,a2e),e(a2e,Tar),e(c6,Mar),e(c6,n2e),e(n2e,Ear),e(io,Car),M(f6,io,null),b(f,COe,u),b(f,Fd,u),e(Fd,m6),e(m6,s2e),M(my,s2e,null),e(Fd,war),e(Fd,l2e),e(l2e,Aar),b(f,wOe,u),b(f,Vo,u),M(gy,Vo,null),e(Vo,Lar),e(Vo,Td),e(Td,yar),e(Td,PQ),e(PQ,xar),e(Td,$ar),e(Td,BQ),e(BQ,kar),e(Td,Sar),e(Vo,Rar),e(Vo,hy),e(hy,Par),e(hy,i2e),e(i2e,Bar),e(hy,Iar),e(Vo,Nar),e(Vo,vt),M(py,vt,null),e(vt,qar),e(vt,d2e),e(d2e,jar),e(vt,Dar),e(vt,Md),e(Md,Gar),e(Md,c2e),e(c2e,Oar),e(Md,Var),e(Md,IQ),e(IQ,Xar),e(Md,zar),e(vt,Qar),M(g6,vt,null),e(Vo,War),e(Vo,co),M(_y,co,null),e(co,Har),e(co,f2e),e(f2e,Uar),e(co,Jar),e(co,Qa),e(Qa,Yar),e(Qa,m2e),e(m2e,Kar),e(Qa,Zar),e(Qa,g2e),e(g2e,enr),e(Qa,onr),e(Qa,h2e),e(h2e,rnr),e(Qa,tnr),e(co,anr),e(co,p2e),e(p2e,h6),e(h6,_2e),e(_2e,nnr),e(h6,snr),e(h6,NQ),e(NQ,lnr),e(h6,inr),e(co,dnr),e(co,p6),e(p6,cnr),e(p6,u2e),e(u2e,fnr),e(p6,mnr),e(p6,b2e),e(b2e,gnr),e(co,hnr),M(_6,co,null),b(f,AOe,u),b(f,Ed,u),e(Ed,u6),e(u6,v2e),M(uy,v2e,null),e(Ed,pnr),e(Ed,F2e),e(F2e,_nr),b(f,LOe,u),b(f,Xo,u),M(by,Xo,null),e(Xo,unr),e(Xo,Cd),e(Cd,bnr),e(Cd,qQ),e(qQ,vnr),e(Cd,Fnr),e(Cd,jQ),e(jQ,Tnr),e(Cd,Mnr),e(Xo,Enr),e(Xo,vy),e(vy,Cnr),e(vy,T2e),e(T2e,wnr),e(vy,Anr),e(Xo,Lnr),e(Xo,Ft),M(Fy,Ft,null),e(Ft,ynr),e(Ft,M2e),e(M2e,xnr),e(Ft,$nr),e(Ft,wd),e(wd,knr),e(wd,E2e),e(E2e,Snr),e(wd,Rnr),e(wd,DQ),e(DQ,Pnr),e(wd,Bnr),e(Ft,Inr),M(b6,Ft,null),e(Xo,Nnr),e(Xo,fo),M(Ty,fo,null),e(fo,qnr),e(fo,C2e),e(C2e,jnr),e(fo,Dnr),e(fo,Wa),e(Wa,Gnr),e(Wa,w2e),e(w2e,Onr),e(Wa,Vnr),e(Wa,A2e),e(A2e,Xnr),e(Wa,znr),e(Wa,L2e),e(L2e,Qnr),e(Wa,Wnr),e(fo,Hnr),e(fo,Pe),e(Pe,v6),e(v6,y2e),e(y2e,Unr),e(v6,Jnr),e(v6,GQ),e(GQ,Ynr),e(v6,Knr),e(Pe,Znr),e(Pe,F6),e(F6,x2e),e(x2e,esr),e(F6,osr),e(F6,OQ),e(OQ,rsr),e(F6,tsr),e(Pe,asr),e(Pe,T6),e(T6,$2e),e($2e,nsr),e(T6,ssr),e(T6,VQ),e(VQ,lsr),e(T6,isr),e(Pe,dsr),e(Pe,M6),e(M6,k2e),e(k2e,csr),e(M6,fsr),e(M6,XQ),e(XQ,msr),e(M6,gsr),e(Pe,hsr),e(Pe,E6),e(E6,S2e),e(S2e,psr),e(E6,_sr),e(E6,zQ),e(zQ,usr),e(E6,bsr),e(Pe,vsr),e(Pe,C6),e(C6,R2e),e(R2e,Fsr),e(C6,Tsr),e(C6,QQ),e(QQ,Msr),e(C6,Esr),e(Pe,Csr),e(Pe,w6),e(w6,P2e),e(P2e,wsr),e(w6,Asr),e(w6,WQ),e(WQ,Lsr),e(w6,ysr),e(Pe,xsr),e(Pe,A6),e(A6,B2e),e(B2e,$sr),e(A6,ksr),e(A6,HQ),e(HQ,Ssr),e(A6,Rsr),e(Pe,Psr),e(Pe,L6),e(L6,I2e),e(I2e,Bsr),e(L6,Isr),e(L6,UQ),e(UQ,Nsr),e(L6,qsr),e(fo,jsr),e(fo,y6),e(y6,Dsr),e(y6,N2e),e(N2e,Gsr),e(y6,Osr),e(y6,q2e),e(q2e,Vsr),e(fo,Xsr),M(x6,fo,null),b(f,yOe,u),b(f,Ad,u),e(Ad,$6),e($6,j2e),M(My,j2e,null),e(Ad,zsr),e(Ad,D2e),e(D2e,Qsr),b(f,xOe,u),b(f,zo,u),M(Ey,zo,null),e(zo,Wsr),e(zo,Ld),e(Ld,Hsr),e(Ld,JQ),e(JQ,Usr),e(Ld,Jsr),e(Ld,YQ),e(YQ,Ysr),e(Ld,Ksr),e(zo,Zsr),e(zo,Cy),e(Cy,elr),e(Cy,G2e),e(G2e,olr),e(Cy,rlr),e(zo,tlr),e(zo,Tt),M(wy,Tt,null),e(Tt,alr),e(Tt,O2e),e(O2e,nlr),e(Tt,slr),e(Tt,yd),e(yd,llr),e(yd,V2e),e(V2e,ilr),e(yd,dlr),e(yd,KQ),e(KQ,clr),e(yd,flr),e(Tt,mlr),M(k6,Tt,null),e(zo,glr),e(zo,mo),M(Ay,mo,null),e(mo,hlr),e(mo,X2e),e(X2e,plr),e(mo,_lr),e(mo,Ha),e(Ha,ulr),e(Ha,z2e),e(z2e,blr),e(Ha,vlr),e(Ha,Q2e),e(Q2e,Flr),e(Ha,Tlr),e(Ha,W2e),e(W2e,Mlr),e(Ha,Elr),e(mo,Clr),e(mo,et),e(et,S6),e(S6,H2e),e(H2e,wlr),e(S6,Alr),e(S6,ZQ),e(ZQ,Llr),e(S6,ylr),e(et,xlr),e(et,R6),e(R6,U2e),e(U2e,$lr),e(R6,klr),e(R6,eW),e(eW,Slr),e(R6,Rlr),e(et,Plr),e(et,P6),e(P6,J2e),e(J2e,Blr),e(P6,Ilr),e(P6,oW),e(oW,Nlr),e(P6,qlr),e(et,jlr),e(et,B6),e(B6,Y2e),e(Y2e,Dlr),e(B6,Glr),e(B6,rW),e(rW,Olr),e(B6,Vlr),e(et,Xlr),e(et,I6),e(I6,K2e),e(K2e,zlr),e(I6,Qlr),e(I6,tW),e(tW,Wlr),e(I6,Hlr),e(mo,Ulr),e(mo,N6),e(N6,Jlr),e(N6,Z2e),e(Z2e,Ylr),e(N6,Klr),e(N6,ebe),e(ebe,Zlr),e(mo,eir),M(q6,mo,null),b(f,$Oe,u),b(f,xd,u),e(xd,j6),e(j6,obe),M(Ly,obe,null),e(xd,oir),e(xd,rbe),e(rbe,rir),b(f,kOe,u),b(f,Qo,u),M(yy,Qo,null),e(Qo,tir),e(Qo,$d),e($d,air),e($d,aW),e(aW,nir),e($d,sir),e($d,nW),e(nW,lir),e($d,iir),e(Qo,dir),e(Qo,xy),e(xy,cir),e(xy,tbe),e(tbe,fir),e(xy,mir),e(Qo,gir),e(Qo,Mt),M($y,Mt,null),e(Mt,hir),e(Mt,abe),e(abe,pir),e(Mt,_ir),e(Mt,kd),e(kd,uir),e(kd,nbe),e(nbe,bir),e(kd,vir),e(kd,sW),e(sW,Fir),e(kd,Tir),e(Mt,Mir),M(D6,Mt,null),e(Qo,Eir),e(Qo,go),M(ky,go,null),e(go,Cir),e(go,sbe),e(sbe,wir),e(go,Air),e(go,Ua),e(Ua,Lir),e(Ua,lbe),e(lbe,yir),e(Ua,xir),e(Ua,ibe),e(ibe,$ir),e(Ua,kir),e(Ua,dbe),e(dbe,Sir),e(Ua,Rir),e(go,Pir),e(go,Le),e(Le,G6),e(G6,cbe),e(cbe,Bir),e(G6,Iir),e(G6,lW),e(lW,Nir),e(G6,qir),e(Le,jir),e(Le,O6),e(O6,fbe),e(fbe,Dir),e(O6,Gir),e(O6,iW),e(iW,Oir),e(O6,Vir),e(Le,Xir),e(Le,V6),e(V6,mbe),e(mbe,zir),e(V6,Qir),e(V6,dW),e(dW,Wir),e(V6,Hir),e(Le,Uir),e(Le,X6),e(X6,gbe),e(gbe,Jir),e(X6,Yir),e(X6,cW),e(cW,Kir),e(X6,Zir),e(Le,edr),e(Le,z6),e(z6,hbe),e(hbe,odr),e(z6,rdr),e(z6,fW),e(fW,tdr),e(z6,adr),e(Le,ndr),e(Le,Q6),e(Q6,pbe),e(pbe,sdr),e(Q6,ldr),e(Q6,mW),e(mW,idr),e(Q6,ddr),e(Le,cdr),e(Le,W6),e(W6,_be),e(_be,fdr),e(W6,mdr),e(W6,gW),e(gW,gdr),e(W6,hdr),e(Le,pdr),e(Le,H6),e(H6,ube),e(ube,_dr),e(H6,udr),e(H6,hW),e(hW,bdr),e(H6,vdr),e(Le,Fdr),e(Le,U6),e(U6,bbe),e(bbe,Tdr),e(U6,Mdr),e(U6,pW),e(pW,Edr),e(U6,Cdr),e(Le,wdr),e(Le,J6),e(J6,vbe),e(vbe,Adr),e(J6,Ldr),e(J6,_W),e(_W,ydr),e(J6,xdr),e(go,$dr),e(go,Y6),e(Y6,kdr),e(Y6,Fbe),e(Fbe,Sdr),e(Y6,Rdr),e(Y6,Tbe),e(Tbe,Pdr),e(go,Bdr),M(K6,go,null),b(f,SOe,u),b(f,Sd,u),e(Sd,Z6),e(Z6,Mbe),M(Sy,Mbe,null),e(Sd,Idr),e(Sd,Ebe),e(Ebe,Ndr),b(f,ROe,u),b(f,Wo,u),M(Ry,Wo,null),e(Wo,qdr),e(Wo,Rd),e(Rd,jdr),e(Rd,uW),e(uW,Ddr),e(Rd,Gdr),e(Rd,bW),e(bW,Odr),e(Rd,Vdr),e(Wo,Xdr),e(Wo,Py),e(Py,zdr),e(Py,Cbe),e(Cbe,Qdr),e(Py,Wdr),e(Wo,Hdr),e(Wo,Et),M(By,Et,null),e(Et,Udr),e(Et,wbe),e(wbe,Jdr),e(Et,Ydr),e(Et,Pd),e(Pd,Kdr),e(Pd,Abe),e(Abe,Zdr),e(Pd,ecr),e(Pd,vW),e(vW,ocr),e(Pd,rcr),e(Et,tcr),M(eT,Et,null),e(Wo,acr),e(Wo,ho),M(Iy,ho,null),e(ho,ncr),e(ho,Lbe),e(Lbe,scr),e(ho,lcr),e(ho,Ja),e(Ja,icr),e(Ja,ybe),e(ybe,dcr),e(Ja,ccr),e(Ja,xbe),e(xbe,fcr),e(Ja,mcr),e(Ja,$be),e($be,gcr),e(Ja,hcr),e(ho,pcr),e(ho,Ny),e(Ny,oT),e(oT,kbe),e(kbe,_cr),e(oT,ucr),e(oT,FW),e(FW,bcr),e(oT,vcr),e(Ny,Fcr),e(Ny,rT),e(rT,Sbe),e(Sbe,Tcr),e(rT,Mcr),e(rT,TW),e(TW,Ecr),e(rT,Ccr),e(ho,wcr),e(ho,tT),e(tT,Acr),e(tT,Rbe),e(Rbe,Lcr),e(tT,ycr),e(tT,Pbe),e(Pbe,xcr),e(ho,$cr),M(aT,ho,null),b(f,POe,u),b(f,Bd,u),e(Bd,nT),e(nT,Bbe),M(qy,Bbe,null),e(Bd,kcr),e(Bd,Ibe),e(Ibe,Scr),b(f,BOe,u),b(f,Ho,u),M(jy,Ho,null),e(Ho,Rcr),e(Ho,Id),e(Id,Pcr),e(Id,MW),e(MW,Bcr),e(Id,Icr),e(Id,EW),e(EW,Ncr),e(Id,qcr),e(Ho,jcr),e(Ho,Dy),e(Dy,Dcr),e(Dy,Nbe),e(Nbe,Gcr),e(Dy,Ocr),e(Ho,Vcr),e(Ho,Ct),M(Gy,Ct,null),e(Ct,Xcr),e(Ct,qbe),e(qbe,zcr),e(Ct,Qcr),e(Ct,Nd),e(Nd,Wcr),e(Nd,jbe),e(jbe,Hcr),e(Nd,Ucr),e(Nd,CW),e(CW,Jcr),e(Nd,Ycr),e(Ct,Kcr),M(sT,Ct,null),e(Ho,Zcr),e(Ho,po),M(Oy,po,null),e(po,efr),e(po,Dbe),e(Dbe,ofr),e(po,rfr),e(po,Ya),e(Ya,tfr),e(Ya,Gbe),e(Gbe,afr),e(Ya,nfr),e(Ya,Obe),e(Obe,sfr),e(Ya,lfr),e(Ya,Vbe),e(Vbe,ifr),e(Ya,dfr),e(po,cfr),e(po,ot),e(ot,lT),e(lT,Xbe),e(Xbe,ffr),e(lT,mfr),e(lT,wW),e(wW,gfr),e(lT,hfr),e(ot,pfr),e(ot,iT),e(iT,zbe),e(zbe,_fr),e(iT,ufr),e(iT,AW),e(AW,bfr),e(iT,vfr),e(ot,Ffr),e(ot,dT),e(dT,Qbe),e(Qbe,Tfr),e(dT,Mfr),e(dT,LW),e(LW,Efr),e(dT,Cfr),e(ot,wfr),e(ot,cT),e(cT,Wbe),e(Wbe,Afr),e(cT,Lfr),e(cT,yW),e(yW,yfr),e(cT,xfr),e(ot,$fr),e(ot,fT),e(fT,Hbe),e(Hbe,kfr),e(fT,Sfr),e(fT,xW),e(xW,Rfr),e(fT,Pfr),e(po,Bfr),e(po,mT),e(mT,Ifr),e(mT,Ube),e(Ube,Nfr),e(mT,qfr),e(mT,Jbe),e(Jbe,jfr),e(po,Dfr),M(gT,po,null),b(f,IOe,u),b(f,qd,u),e(qd,hT),e(hT,Ybe),M(Vy,Ybe,null),e(qd,Gfr),e(qd,Kbe),e(Kbe,Ofr),b(f,NOe,u),b(f,Uo,u),M(Xy,Uo,null),e(Uo,Vfr),e(Uo,jd),e(jd,Xfr),e(jd,$W),e($W,zfr),e(jd,Qfr),e(jd,kW),e(kW,Wfr),e(jd,Hfr),e(Uo,Ufr),e(Uo,zy),e(zy,Jfr),e(zy,Zbe),e(Zbe,Yfr),e(zy,Kfr),e(Uo,Zfr),e(Uo,wt),M(Qy,wt,null),e(wt,emr),e(wt,e4e),e(e4e,omr),e(wt,rmr),e(wt,Dd),e(Dd,tmr),e(Dd,o4e),e(o4e,amr),e(Dd,nmr),e(Dd,SW),e(SW,smr),e(Dd,lmr),e(wt,imr),M(pT,wt,null),e(Uo,dmr),e(Uo,_o),M(Wy,_o,null),e(_o,cmr),e(_o,r4e),e(r4e,fmr),e(_o,mmr),e(_o,Ka),e(Ka,gmr),e(Ka,t4e),e(t4e,hmr),e(Ka,pmr),e(Ka,a4e),e(a4e,_mr),e(Ka,umr),e(Ka,n4e),e(n4e,bmr),e(Ka,vmr),e(_o,Fmr),e(_o,Gd),e(Gd,_T),e(_T,s4e),e(s4e,Tmr),e(_T,Mmr),e(_T,RW),e(RW,Emr),e(_T,Cmr),e(Gd,wmr),e(Gd,uT),e(uT,l4e),e(l4e,Amr),e(uT,Lmr),e(uT,PW),e(PW,ymr),e(uT,xmr),e(Gd,$mr),e(Gd,bT),e(bT,i4e),e(i4e,kmr),e(bT,Smr),e(bT,BW),e(BW,Rmr),e(bT,Pmr),e(_o,Bmr),e(_o,vT),e(vT,Imr),e(vT,d4e),e(d4e,Nmr),e(vT,qmr),e(vT,c4e),e(c4e,jmr),e(_o,Dmr),M(FT,_o,null),b(f,qOe,u),b(f,Od,u),e(Od,TT),e(TT,f4e),M(Hy,f4e,null),e(Od,Gmr),e(Od,m4e),e(m4e,Omr),b(f,jOe,u),b(f,Jo,u),M(Uy,Jo,null),e(Jo,Vmr),e(Jo,Vd),e(Vd,Xmr),e(Vd,IW),e(IW,zmr),e(Vd,Qmr),e(Vd,NW),e(NW,Wmr),e(Vd,Hmr),e(Jo,Umr),e(Jo,Jy),e(Jy,Jmr),e(Jy,g4e),e(g4e,Ymr),e(Jy,Kmr),e(Jo,Zmr),e(Jo,At),M(Yy,At,null),e(At,egr),e(At,h4e),e(h4e,ogr),e(At,rgr),e(At,Xd),e(Xd,tgr),e(Xd,p4e),e(p4e,agr),e(Xd,ngr),e(Xd,qW),e(qW,sgr),e(Xd,lgr),e(At,igr),M(MT,At,null),e(Jo,dgr),e(Jo,uo),M(Ky,uo,null),e(uo,cgr),e(uo,_4e),e(_4e,fgr),e(uo,mgr),e(uo,Za),e(Za,ggr),e(Za,u4e),e(u4e,hgr),e(Za,pgr),e(Za,b4e),e(b4e,_gr),e(Za,ugr),e(Za,v4e),e(v4e,bgr),e(Za,vgr),e(uo,Fgr),e(uo,Zy),e(Zy,ET),e(ET,F4e),e(F4e,Tgr),e(ET,Mgr),e(ET,jW),e(jW,Egr),e(ET,Cgr),e(Zy,wgr),e(Zy,CT),e(CT,T4e),e(T4e,Agr),e(CT,Lgr),e(CT,DW),e(DW,ygr),e(CT,xgr),e(uo,$gr),e(uo,wT),e(wT,kgr),e(wT,M4e),e(M4e,Sgr),e(wT,Rgr),e(wT,E4e),e(E4e,Pgr),e(uo,Bgr),M(AT,uo,null),b(f,DOe,u),b(f,zd,u),e(zd,LT),e(LT,C4e),M(e9,C4e,null),e(zd,Igr),e(zd,w4e),e(w4e,Ngr),b(f,GOe,u),b(f,Yo,u),M(o9,Yo,null),e(Yo,qgr),e(Yo,Qd),e(Qd,jgr),e(Qd,GW),e(GW,Dgr),e(Qd,Ggr),e(Qd,OW),e(OW,Ogr),e(Qd,Vgr),e(Yo,Xgr),e(Yo,r9),e(r9,zgr),e(r9,A4e),e(A4e,Qgr),e(r9,Wgr),e(Yo,Hgr),e(Yo,Lt),M(t9,Lt,null),e(Lt,Ugr),e(Lt,L4e),e(L4e,Jgr),e(Lt,Ygr),e(Lt,Wd),e(Wd,Kgr),e(Wd,y4e),e(y4e,Zgr),e(Wd,ehr),e(Wd,VW),e(VW,ohr),e(Wd,rhr),e(Lt,thr),M(yT,Lt,null),e(Yo,ahr),e(Yo,bo),M(a9,bo,null),e(bo,nhr),e(bo,x4e),e(x4e,shr),e(bo,lhr),e(bo,en),e(en,ihr),e(en,$4e),e($4e,dhr),e(en,chr),e(en,k4e),e(k4e,fhr),e(en,mhr),e(en,S4e),e(S4e,ghr),e(en,hhr),e(bo,phr),e(bo,R4e),e(R4e,xT),e(xT,P4e),e(P4e,_hr),e(xT,uhr),e(xT,XW),e(XW,bhr),e(xT,vhr),e(bo,Fhr),e(bo,$T),e($T,Thr),e($T,B4e),e(B4e,Mhr),e($T,Ehr),e($T,I4e),e(I4e,Chr),e(bo,whr),M(kT,bo,null),b(f,OOe,u),b(f,Hd,u),e(Hd,ST),e(ST,N4e),M(n9,N4e,null),e(Hd,Ahr),e(Hd,q4e),e(q4e,Lhr),b(f,VOe,u),b(f,Ko,u),M(s9,Ko,null),e(Ko,yhr),e(Ko,Ud),e(Ud,xhr),e(Ud,zW),e(zW,$hr),e(Ud,khr),e(Ud,QW),e(QW,Shr),e(Ud,Rhr),e(Ko,Phr),e(Ko,l9),e(l9,Bhr),e(l9,j4e),e(j4e,Ihr),e(l9,Nhr),e(Ko,qhr),e(Ko,yt),M(i9,yt,null),e(yt,jhr),e(yt,D4e),e(D4e,Dhr),e(yt,Ghr),e(yt,Jd),e(Jd,Ohr),e(Jd,G4e),e(G4e,Vhr),e(Jd,Xhr),e(Jd,WW),e(WW,zhr),e(Jd,Qhr),e(yt,Whr),M(RT,yt,null),e(Ko,Hhr),e(Ko,vo),M(d9,vo,null),e(vo,Uhr),e(vo,O4e),e(O4e,Jhr),e(vo,Yhr),e(vo,on),e(on,Khr),e(on,V4e),e(V4e,Zhr),e(on,epr),e(on,X4e),e(X4e,opr),e(on,rpr),e(on,z4e),e(z4e,tpr),e(on,apr),e(vo,npr),e(vo,rn),e(rn,PT),e(PT,Q4e),e(Q4e,spr),e(PT,lpr),e(PT,HW),e(HW,ipr),e(PT,dpr),e(rn,cpr),e(rn,BT),e(BT,W4e),e(W4e,fpr),e(BT,mpr),e(BT,UW),e(UW,gpr),e(BT,hpr),e(rn,ppr),e(rn,IT),e(IT,H4e),e(H4e,_pr),e(IT,upr),e(IT,JW),e(JW,bpr),e(IT,vpr),e(rn,Fpr),e(rn,NT),e(NT,U4e),e(U4e,Tpr),e(NT,Mpr),e(NT,YW),e(YW,Epr),e(NT,Cpr),e(vo,wpr),e(vo,qT),e(qT,Apr),e(qT,J4e),e(J4e,Lpr),e(qT,ypr),e(qT,Y4e),e(Y4e,xpr),e(vo,$pr),M(jT,vo,null),b(f,XOe,u),b(f,Yd,u),e(Yd,DT),e(DT,K4e),M(c9,K4e,null),e(Yd,kpr),e(Yd,Z4e),e(Z4e,Spr),b(f,zOe,u),b(f,Zo,u),M(f9,Zo,null),e(Zo,Rpr),e(Zo,Kd),e(Kd,Ppr),e(Kd,KW),e(KW,Bpr),e(Kd,Ipr),e(Kd,ZW),e(ZW,Npr),e(Kd,qpr),e(Zo,jpr),e(Zo,m9),e(m9,Dpr),e(m9,eve),e(eve,Gpr),e(m9,Opr),e(Zo,Vpr),e(Zo,xt),M(g9,xt,null),e(xt,Xpr),e(xt,ove),e(ove,zpr),e(xt,Qpr),e(xt,Zd),e(Zd,Wpr),e(Zd,rve),e(rve,Hpr),e(Zd,Upr),e(Zd,eH),e(eH,Jpr),e(Zd,Ypr),e(xt,Kpr),M(GT,xt,null),e(Zo,Zpr),e(Zo,Fo),M(h9,Fo,null),e(Fo,e_r),e(Fo,tve),e(tve,o_r),e(Fo,r_r),e(Fo,tn),e(tn,t_r),e(tn,ave),e(ave,a_r),e(tn,n_r),e(tn,nve),e(nve,s_r),e(tn,l_r),e(tn,sve),e(sve,i_r),e(tn,d_r),e(Fo,c_r),e(Fo,lve),e(lve,OT),e(OT,ive),e(ive,f_r),e(OT,m_r),e(OT,oH),e(oH,g_r),e(OT,h_r),e(Fo,p_r),e(Fo,VT),e(VT,__r),e(VT,dve),e(dve,u_r),e(VT,b_r),e(VT,cve),e(cve,v_r),e(Fo,F_r),M(XT,Fo,null),b(f,QOe,u),b(f,ec,u),e(ec,zT),e(zT,fve),M(p9,fve,null),e(ec,T_r),e(ec,mve),e(mve,M_r),b(f,WOe,u),b(f,er,u),M(_9,er,null),e(er,E_r),e(er,oc),e(oc,C_r),e(oc,rH),e(rH,w_r),e(oc,A_r),e(oc,tH),e(tH,L_r),e(oc,y_r),e(er,x_r),e(er,u9),e(u9,$_r),e(u9,gve),e(gve,k_r),e(u9,S_r),e(er,R_r),e(er,$t),M(b9,$t,null),e($t,P_r),e($t,hve),e(hve,B_r),e($t,I_r),e($t,rc),e(rc,N_r),e(rc,pve),e(pve,q_r),e(rc,j_r),e(rc,aH),e(aH,D_r),e(rc,G_r),e($t,O_r),M(QT,$t,null),e(er,V_r),e(er,yr),M(v9,yr,null),e(yr,X_r),e(yr,_ve),e(_ve,z_r),e(yr,Q_r),e(yr,an),e(an,W_r),e(an,uve),e(uve,H_r),e(an,U_r),e(an,bve),e(bve,J_r),e(an,Y_r),e(an,vve),e(vve,K_r),e(an,Z_r),e(yr,eur),e(yr,j),e(j,WT),e(WT,Fve),e(Fve,our),e(WT,rur),e(WT,nH),e(nH,tur),e(WT,aur),e(j,nur),e(j,HT),e(HT,Tve),e(Tve,sur),e(HT,lur),e(HT,sH),e(sH,iur),e(HT,dur),e(j,cur),e(j,UT),e(UT,Mve),e(Mve,fur),e(UT,mur),e(UT,lH),e(lH,gur),e(UT,hur),e(j,pur),e(j,JT),e(JT,Eve),e(Eve,_ur),e(JT,uur),e(JT,iH),e(iH,bur),e(JT,vur),e(j,Fur),e(j,YT),e(YT,Cve),e(Cve,Tur),e(YT,Mur),e(YT,dH),e(dH,Eur),e(YT,Cur),e(j,wur),e(j,KT),e(KT,wve),e(wve,Aur),e(KT,Lur),e(KT,cH),e(cH,yur),e(KT,xur),e(j,$ur),e(j,ZT),e(ZT,Ave),e(Ave,kur),e(ZT,Sur),e(ZT,fH),e(fH,Rur),e(ZT,Pur),e(j,Bur),e(j,e7),e(e7,Lve),e(Lve,Iur),e(e7,Nur),e(e7,mH),e(mH,qur),e(e7,jur),e(j,Dur),e(j,o7),e(o7,yve),e(yve,Gur),e(o7,Our),e(o7,gH),e(gH,Vur),e(o7,Xur),e(j,zur),e(j,r7),e(r7,xve),e(xve,Qur),e(r7,Wur),e(r7,hH),e(hH,Hur),e(r7,Uur),e(j,Jur),e(j,t7),e(t7,$ve),e($ve,Yur),e(t7,Kur),e(t7,pH),e(pH,Zur),e(t7,e1r),e(j,o1r),e(j,a7),e(a7,kve),e(kve,r1r),e(a7,t1r),e(a7,_H),e(_H,a1r),e(a7,n1r),e(j,s1r),e(j,n7),e(n7,Sve),e(Sve,l1r),e(n7,i1r),e(n7,uH),e(uH,d1r),e(n7,c1r),e(j,f1r),e(j,s7),e(s7,Rve),e(Rve,m1r),e(s7,g1r),e(s7,bH),e(bH,h1r),e(s7,p1r),e(j,_1r),e(j,l7),e(l7,Pve),e(Pve,u1r),e(l7,b1r),e(l7,vH),e(vH,v1r),e(l7,F1r),e(j,T1r),e(j,i7),e(i7,Bve),e(Bve,M1r),e(i7,E1r),e(i7,FH),e(FH,C1r),e(i7,w1r),e(j,A1r),e(j,d7),e(d7,Ive),e(Ive,L1r),e(d7,y1r),e(d7,TH),e(TH,x1r),e(d7,$1r),e(j,k1r),e(j,Qs),e(Qs,Nve),e(Nve,S1r),e(Qs,R1r),e(Qs,MH),e(MH,P1r),e(Qs,B1r),e(Qs,EH),e(EH,I1r),e(Qs,N1r),e(j,q1r),e(j,c7),e(c7,qve),e(qve,j1r),e(c7,D1r),e(c7,CH),e(CH,G1r),e(c7,O1r),e(j,V1r),e(j,f7),e(f7,jve),e(jve,X1r),e(f7,z1r),e(f7,wH),e(wH,Q1r),e(f7,W1r),e(j,H1r),e(j,m7),e(m7,Dve),e(Dve,U1r),e(m7,J1r),e(m7,AH),e(AH,Y1r),e(m7,K1r),e(j,Z1r),e(j,g7),e(g7,Gve),e(Gve,e2r),e(g7,o2r),e(g7,LH),e(LH,r2r),e(g7,t2r),e(j,a2r),e(j,h7),e(h7,Ove),e(Ove,n2r),e(h7,s2r),e(h7,yH),e(yH,l2r),e(h7,i2r),e(j,d2r),e(j,p7),e(p7,Vve),e(Vve,c2r),e(p7,f2r),e(p7,xH),e(xH,m2r),e(p7,g2r),e(j,h2r),e(j,_7),e(_7,Xve),e(Xve,p2r),e(_7,_2r),e(_7,$H),e($H,u2r),e(_7,b2r),e(j,v2r),e(j,u7),e(u7,zve),e(zve,F2r),e(u7,T2r),e(u7,kH),e(kH,M2r),e(u7,E2r),e(j,C2r),e(j,b7),e(b7,Qve),e(Qve,w2r),e(b7,A2r),e(b7,SH),e(SH,L2r),e(b7,y2r),e(j,x2r),e(j,v7),e(v7,Wve),e(Wve,$2r),e(v7,k2r),e(v7,RH),e(RH,S2r),e(v7,R2r),e(j,P2r),e(j,F7),e(F7,Hve),e(Hve,B2r),e(F7,I2r),e(F7,PH),e(PH,N2r),e(F7,q2r),e(j,j2r),e(j,T7),e(T7,Uve),e(Uve,D2r),e(T7,G2r),e(T7,BH),e(BH,O2r),e(T7,V2r),e(j,X2r),e(j,M7),e(M7,Jve),e(Jve,z2r),e(M7,Q2r),e(M7,IH),e(IH,W2r),e(M7,H2r),e(j,U2r),e(j,E7),e(E7,Yve),e(Yve,J2r),e(E7,Y2r),e(E7,NH),e(NH,K2r),e(E7,Z2r),e(j,ebr),e(j,C7),e(C7,Kve),e(Kve,obr),e(C7,rbr),e(C7,qH),e(qH,tbr),e(C7,abr),e(j,nbr),e(j,w7),e(w7,Zve),e(Zve,sbr),e(w7,lbr),e(w7,jH),e(jH,ibr),e(w7,dbr),e(j,cbr),e(j,A7),e(A7,eFe),e(eFe,fbr),e(A7,mbr),e(A7,DH),e(DH,gbr),e(A7,hbr),e(j,pbr),e(j,L7),e(L7,oFe),e(oFe,_br),e(L7,ubr),e(L7,GH),e(GH,bbr),e(L7,vbr),e(j,Fbr),e(j,y7),e(y7,rFe),e(rFe,Tbr),e(y7,Mbr),e(y7,OH),e(OH,Ebr),e(y7,Cbr),e(j,wbr),e(j,x7),e(x7,tFe),e(tFe,Abr),e(x7,Lbr),e(x7,VH),e(VH,ybr),e(x7,xbr),e(j,$br),e(j,$7),e($7,aFe),e(aFe,kbr),e($7,Sbr),e($7,XH),e(XH,Rbr),e($7,Pbr),e(j,Bbr),e(j,k7),e(k7,nFe),e(nFe,Ibr),e(k7,Nbr),e(k7,zH),e(zH,qbr),e(k7,jbr),e(j,Dbr),e(j,S7),e(S7,sFe),e(sFe,Gbr),e(S7,Obr),e(S7,QH),e(QH,Vbr),e(S7,Xbr),e(j,zbr),e(j,R7),e(R7,lFe),e(lFe,Qbr),e(R7,Wbr),e(R7,WH),e(WH,Hbr),e(R7,Ubr),e(j,Jbr),e(j,P7),e(P7,iFe),e(iFe,Ybr),e(P7,Kbr),e(P7,HH),e(HH,Zbr),e(P7,e4r),e(j,o4r),e(j,B7),e(B7,dFe),e(dFe,r4r),e(B7,t4r),e(B7,UH),e(UH,a4r),e(B7,n4r),e(j,s4r),e(j,I7),e(I7,cFe),e(cFe,l4r),e(I7,i4r),e(I7,JH),e(JH,d4r),e(I7,c4r),e(j,f4r),e(j,N7),e(N7,fFe),e(fFe,m4r),e(N7,g4r),e(N7,YH),e(YH,h4r),e(N7,p4r),e(j,_4r),e(j,q7),e(q7,mFe),e(mFe,u4r),e(q7,b4r),e(q7,KH),e(KH,v4r),e(q7,F4r),e(yr,T4r),M(j7,yr,null),b(f,HOe,u),b(f,tc,u),e(tc,D7),e(D7,gFe),M(F9,gFe,null),e(tc,M4r),e(tc,hFe),e(hFe,E4r),b(f,UOe,u),b(f,or,u),M(T9,or,null),e(or,C4r),e(or,ac),e(ac,w4r),e(ac,ZH),e(ZH,A4r),e(ac,L4r),e(ac,eU),e(eU,y4r),e(ac,x4r),e(or,$4r),e(or,M9),e(M9,k4r),e(M9,pFe),e(pFe,S4r),e(M9,R4r),e(or,P4r),e(or,kt),M(E9,kt,null),e(kt,B4r),e(kt,_Fe),e(_Fe,I4r),e(kt,N4r),e(kt,nc),e(nc,q4r),e(nc,uFe),e(uFe,j4r),e(nc,D4r),e(nc,oU),e(oU,G4r),e(nc,O4r),e(kt,V4r),M(G7,kt,null),e(or,X4r),e(or,xr),M(C9,xr,null),e(xr,z4r),e(xr,bFe),e(bFe,Q4r),e(xr,W4r),e(xr,nn),e(nn,H4r),e(nn,vFe),e(vFe,U4r),e(nn,J4r),e(nn,FFe),e(FFe,Y4r),e(nn,K4r),e(nn,TFe),e(TFe,Z4r),e(nn,evr),e(xr,ovr),e(xr,se),e(se,O7),e(O7,MFe),e(MFe,rvr),e(O7,tvr),e(O7,rU),e(rU,avr),e(O7,nvr),e(se,svr),e(se,V7),e(V7,EFe),e(EFe,lvr),e(V7,ivr),e(V7,tU),e(tU,dvr),e(V7,cvr),e(se,fvr),e(se,X7),e(X7,CFe),e(CFe,mvr),e(X7,gvr),e(X7,aU),e(aU,hvr),e(X7,pvr),e(se,_vr),e(se,z7),e(z7,wFe),e(wFe,uvr),e(z7,bvr),e(z7,nU),e(nU,vvr),e(z7,Fvr),e(se,Tvr),e(se,Q7),e(Q7,AFe),e(AFe,Mvr),e(Q7,Evr),e(Q7,sU),e(sU,Cvr),e(Q7,wvr),e(se,Avr),e(se,W7),e(W7,LFe),e(LFe,Lvr),e(W7,yvr),e(W7,lU),e(lU,xvr),e(W7,$vr),e(se,kvr),e(se,H7),e(H7,yFe),e(yFe,Svr),e(H7,Rvr),e(H7,iU),e(iU,Pvr),e(H7,Bvr),e(se,Ivr),e(se,U7),e(U7,xFe),e(xFe,Nvr),e(U7,qvr),e(U7,dU),e(dU,jvr),e(U7,Dvr),e(se,Gvr),e(se,J7),e(J7,$Fe),e($Fe,Ovr),e(J7,Vvr),e(J7,cU),e(cU,Xvr),e(J7,zvr),e(se,Qvr),e(se,Y7),e(Y7,kFe),e(kFe,Wvr),e(Y7,Hvr),e(Y7,fU),e(fU,Uvr),e(Y7,Jvr),e(se,Yvr),e(se,K7),e(K7,SFe),e(SFe,Kvr),e(K7,Zvr),e(K7,mU),e(mU,eFr),e(K7,oFr),e(se,rFr),e(se,Z7),e(Z7,RFe),e(RFe,tFr),e(Z7,aFr),e(Z7,gU),e(gU,nFr),e(Z7,sFr),e(se,lFr),e(se,e8),e(e8,PFe),e(PFe,iFr),e(e8,dFr),e(e8,hU),e(hU,cFr),e(e8,fFr),e(se,mFr),e(se,o8),e(o8,BFe),e(BFe,gFr),e(o8,hFr),e(o8,pU),e(pU,pFr),e(o8,_Fr),e(se,uFr),e(se,r8),e(r8,IFe),e(IFe,bFr),e(r8,vFr),e(r8,_U),e(_U,FFr),e(r8,TFr),e(se,MFr),e(se,t8),e(t8,NFe),e(NFe,EFr),e(t8,CFr),e(t8,uU),e(uU,wFr),e(t8,AFr),e(se,LFr),e(se,a8),e(a8,qFe),e(qFe,yFr),e(a8,xFr),e(a8,bU),e(bU,$Fr),e(a8,kFr),e(se,SFr),e(se,n8),e(n8,jFe),e(jFe,RFr),e(n8,PFr),e(n8,vU),e(vU,BFr),e(n8,IFr),e(se,NFr),e(se,s8),e(s8,DFe),e(DFe,qFr),e(s8,jFr),e(s8,FU),e(FU,DFr),e(s8,GFr),e(se,OFr),e(se,l8),e(l8,GFe),e(GFe,VFr),e(l8,XFr),e(l8,TU),e(TU,zFr),e(l8,QFr),e(se,WFr),e(se,i8),e(i8,OFe),e(OFe,HFr),e(i8,UFr),e(i8,MU),e(MU,JFr),e(i8,YFr),e(se,KFr),e(se,d8),e(d8,VFe),e(VFe,ZFr),e(d8,e6r),e(d8,EU),e(EU,o6r),e(d8,r6r),e(se,t6r),e(se,c8),e(c8,XFe),e(XFe,a6r),e(c8,n6r),e(c8,CU),e(CU,s6r),e(c8,l6r),e(xr,i6r),M(f8,xr,null),b(f,JOe,u),b(f,sc,u),e(sc,m8),e(m8,zFe),M(w9,zFe,null),e(sc,d6r),e(sc,QFe),e(QFe,c6r),b(f,YOe,u),b(f,rr,u),M(A9,rr,null),e(rr,f6r),e(rr,lc),e(lc,m6r),e(lc,wU),e(wU,g6r),e(lc,h6r),e(lc,AU),e(AU,p6r),e(lc,_6r),e(rr,u6r),e(rr,L9),e(L9,b6r),e(L9,WFe),e(WFe,v6r),e(L9,F6r),e(rr,T6r),e(rr,St),M(y9,St,null),e(St,M6r),e(St,HFe),e(HFe,E6r),e(St,C6r),e(St,ic),e(ic,w6r),e(ic,UFe),e(UFe,A6r),e(ic,L6r),e(ic,LU),e(LU,y6r),e(ic,x6r),e(St,$6r),M(g8,St,null),e(rr,k6r),e(rr,$r),M(x9,$r,null),e($r,S6r),e($r,JFe),e(JFe,R6r),e($r,P6r),e($r,sn),e(sn,B6r),e(sn,YFe),e(YFe,I6r),e(sn,N6r),e(sn,KFe),e(KFe,q6r),e(sn,j6r),e(sn,ZFe),e(ZFe,D6r),e(sn,G6r),e($r,O6r),e($r,Me),e(Me,h8),e(h8,e6e),e(e6e,V6r),e(h8,X6r),e(h8,yU),e(yU,z6r),e(h8,Q6r),e(Me,W6r),e(Me,p8),e(p8,o6e),e(o6e,H6r),e(p8,U6r),e(p8,xU),e(xU,J6r),e(p8,Y6r),e(Me,K6r),e(Me,_8),e(_8,r6e),e(r6e,Z6r),e(_8,eTr),e(_8,$U),e($U,oTr),e(_8,rTr),e(Me,tTr),e(Me,u8),e(u8,t6e),e(t6e,aTr),e(u8,nTr),e(u8,kU),e(kU,sTr),e(u8,lTr),e(Me,iTr),e(Me,b8),e(b8,a6e),e(a6e,dTr),e(b8,cTr),e(b8,SU),e(SU,fTr),e(b8,mTr),e(Me,gTr),e(Me,v8),e(v8,n6e),e(n6e,hTr),e(v8,pTr),e(v8,RU),e(RU,_Tr),e(v8,uTr),e(Me,bTr),e(Me,F8),e(F8,s6e),e(s6e,vTr),e(F8,FTr),e(F8,PU),e(PU,TTr),e(F8,MTr),e(Me,ETr),e(Me,T8),e(T8,l6e),e(l6e,CTr),e(T8,wTr),e(T8,BU),e(BU,ATr),e(T8,LTr),e(Me,yTr),e(Me,M8),e(M8,i6e),e(i6e,xTr),e(M8,$Tr),e(M8,IU),e(IU,kTr),e(M8,STr),e(Me,RTr),e(Me,E8),e(E8,d6e),e(d6e,PTr),e(E8,BTr),e(E8,NU),e(NU,ITr),e(E8,NTr),e(Me,qTr),e(Me,C8),e(C8,c6e),e(c6e,jTr),e(C8,DTr),e(C8,qU),e(qU,GTr),e(C8,OTr),e(Me,VTr),e(Me,w8),e(w8,f6e),e(f6e,XTr),e(w8,zTr),e(w8,jU),e(jU,QTr),e(w8,WTr),e(Me,HTr),e(Me,A8),e(A8,m6e),e(m6e,UTr),e(A8,JTr),e(A8,DU),e(DU,YTr),e(A8,KTr),e($r,ZTr),M(L8,$r,null),b(f,KOe,u),b(f,dc,u),e(dc,y8),e(y8,g6e),M($9,g6e,null),e(dc,e7r),e(dc,h6e),e(h6e,o7r),b(f,ZOe,u),b(f,tr,u),M(k9,tr,null),e(tr,r7r),e(tr,cc),e(cc,t7r),e(cc,GU),e(GU,a7r),e(cc,n7r),e(cc,OU),e(OU,s7r),e(cc,l7r),e(tr,i7r),e(tr,S9),e(S9,d7r),e(S9,p6e),e(p6e,c7r),e(S9,f7r),e(tr,m7r),e(tr,Rt),M(R9,Rt,null),e(Rt,g7r),e(Rt,_6e),e(_6e,h7r),e(Rt,p7r),e(Rt,fc),e(fc,_7r),e(fc,u6e),e(u6e,u7r),e(fc,b7r),e(fc,VU),e(VU,v7r),e(fc,F7r),e(Rt,T7r),M(x8,Rt,null),e(tr,M7r),e(tr,kr),M(P9,kr,null),e(kr,E7r),e(kr,b6e),e(b6e,C7r),e(kr,w7r),e(kr,ln),e(ln,A7r),e(ln,v6e),e(v6e,L7r),e(ln,y7r),e(ln,F6e),e(F6e,x7r),e(ln,$7r),e(ln,T6e),e(T6e,k7r),e(ln,S7r),e(kr,R7r),e(kr,dn),e(dn,$8),e($8,M6e),e(M6e,P7r),e($8,B7r),e($8,XU),e(XU,I7r),e($8,N7r),e(dn,q7r),e(dn,k8),e(k8,E6e),e(E6e,j7r),e(k8,D7r),e(k8,zU),e(zU,G7r),e(k8,O7r),e(dn,V7r),e(dn,S8),e(S8,C6e),e(C6e,X7r),e(S8,z7r),e(S8,QU),e(QU,Q7r),e(S8,W7r),e(dn,H7r),e(dn,R8),e(R8,w6e),e(w6e,U7r),e(R8,J7r),e(R8,WU),e(WU,Y7r),e(R8,K7r),e(kr,Z7r),M(P8,kr,null),b(f,eVe,u),b(f,mc,u),e(mc,B8),e(B8,A6e),M(B9,A6e,null),e(mc,e8r),e(mc,L6e),e(L6e,o8r),b(f,oVe,u),b(f,ar,u),M(I9,ar,null),e(ar,r8r),e(ar,gc),e(gc,t8r),e(gc,HU),e(HU,a8r),e(gc,n8r),e(gc,UU),e(UU,s8r),e(gc,l8r),e(ar,i8r),e(ar,N9),e(N9,d8r),e(N9,y6e),e(y6e,c8r),e(N9,f8r),e(ar,m8r),e(ar,Pt),M(q9,Pt,null),e(Pt,g8r),e(Pt,x6e),e(x6e,h8r),e(Pt,p8r),e(Pt,hc),e(hc,_8r),e(hc,$6e),e($6e,u8r),e(hc,b8r),e(hc,JU),e(JU,v8r),e(hc,F8r),e(Pt,T8r),M(I8,Pt,null),e(ar,M8r),e(ar,Sr),M(j9,Sr,null),e(Sr,E8r),e(Sr,k6e),e(k6e,C8r),e(Sr,w8r),e(Sr,cn),e(cn,A8r),e(cn,S6e),e(S6e,L8r),e(cn,y8r),e(cn,R6e),e(R6e,x8r),e(cn,$8r),e(cn,P6e),e(P6e,k8r),e(cn,S8r),e(Sr,R8r),e(Sr,ie),e(ie,N8),e(N8,B6e),e(B6e,P8r),e(N8,B8r),e(N8,YU),e(YU,I8r),e(N8,N8r),e(ie,q8r),e(ie,q8),e(q8,I6e),e(I6e,j8r),e(q8,D8r),e(q8,KU),e(KU,G8r),e(q8,O8r),e(ie,V8r),e(ie,j8),e(j8,N6e),e(N6e,X8r),e(j8,z8r),e(j8,ZU),e(ZU,Q8r),e(j8,W8r),e(ie,H8r),e(ie,D8),e(D8,q6e),e(q6e,U8r),e(D8,J8r),e(D8,eJ),e(eJ,Y8r),e(D8,K8r),e(ie,Z8r),e(ie,G8),e(G8,j6e),e(j6e,eMr),e(G8,oMr),e(G8,oJ),e(oJ,rMr),e(G8,tMr),e(ie,aMr),e(ie,O8),e(O8,D6e),e(D6e,nMr),e(O8,sMr),e(O8,rJ),e(rJ,lMr),e(O8,iMr),e(ie,dMr),e(ie,V8),e(V8,G6e),e(G6e,cMr),e(V8,fMr),e(V8,tJ),e(tJ,mMr),e(V8,gMr),e(ie,hMr),e(ie,X8),e(X8,O6e),e(O6e,pMr),e(X8,_Mr),e(X8,aJ),e(aJ,uMr),e(X8,bMr),e(ie,vMr),e(ie,z8),e(z8,V6e),e(V6e,FMr),e(z8,TMr),e(z8,nJ),e(nJ,MMr),e(z8,EMr),e(ie,CMr),e(ie,Q8),e(Q8,X6e),e(X6e,wMr),e(Q8,AMr),e(Q8,sJ),e(sJ,LMr),e(Q8,yMr),e(ie,xMr),e(ie,W8),e(W8,z6e),e(z6e,$Mr),e(W8,kMr),e(W8,lJ),e(lJ,SMr),e(W8,RMr),e(ie,PMr),e(ie,H8),e(H8,Q6e),e(Q6e,BMr),e(H8,IMr),e(H8,iJ),e(iJ,NMr),e(H8,qMr),e(ie,jMr),e(ie,U8),e(U8,W6e),e(W6e,DMr),e(U8,GMr),e(U8,dJ),e(dJ,OMr),e(U8,VMr),e(ie,XMr),e(ie,J8),e(J8,H6e),e(H6e,zMr),e(J8,QMr),e(J8,cJ),e(cJ,WMr),e(J8,HMr),e(ie,UMr),e(ie,Y8),e(Y8,U6e),e(U6e,JMr),e(Y8,YMr),e(Y8,fJ),e(fJ,KMr),e(Y8,ZMr),e(ie,eEr),e(ie,K8),e(K8,J6e),e(J6e,oEr),e(K8,rEr),e(K8,mJ),e(mJ,tEr),e(K8,aEr),e(ie,nEr),e(ie,Z8),e(Z8,Y6e),e(Y6e,sEr),e(Z8,lEr),e(Z8,gJ),e(gJ,iEr),e(Z8,dEr),e(ie,cEr),e(ie,eM),e(eM,K6e),e(K6e,fEr),e(eM,mEr),e(eM,hJ),e(hJ,gEr),e(eM,hEr),e(ie,pEr),e(ie,oM),e(oM,Z6e),e(Z6e,_Er),e(oM,uEr),e(oM,pJ),e(pJ,bEr),e(oM,vEr),e(ie,FEr),e(ie,rM),e(rM,eTe),e(eTe,TEr),e(rM,MEr),e(rM,_J),e(_J,EEr),e(rM,CEr),e(Sr,wEr),M(tM,Sr,null),b(f,rVe,u),b(f,pc,u),e(pc,aM),e(aM,oTe),M(D9,oTe,null),e(pc,AEr),e(pc,rTe),e(rTe,LEr),b(f,tVe,u),b(f,nr,u),M(G9,nr,null),e(nr,yEr),e(nr,_c),e(_c,xEr),e(_c,uJ),e(uJ,$Er),e(_c,kEr),e(_c,bJ),e(bJ,SEr),e(_c,REr),e(nr,PEr),e(nr,O9),e(O9,BEr),e(O9,tTe),e(tTe,IEr),e(O9,NEr),e(nr,qEr),e(nr,Bt),M(V9,Bt,null),e(Bt,jEr),e(Bt,aTe),e(aTe,DEr),e(Bt,GEr),e(Bt,uc),e(uc,OEr),e(uc,nTe),e(nTe,VEr),e(uc,XEr),e(uc,vJ),e(vJ,zEr),e(uc,QEr),e(Bt,WEr),M(nM,Bt,null),e(nr,HEr),e(nr,Rr),M(X9,Rr,null),e(Rr,UEr),e(Rr,sTe),e(sTe,JEr),e(Rr,YEr),e(Rr,fn),e(fn,KEr),e(fn,lTe),e(lTe,ZEr),e(fn,eCr),e(fn,iTe),e(iTe,oCr),e(fn,rCr),e(fn,dTe),e(dTe,tCr),e(fn,aCr),e(Rr,nCr),e(Rr,ye),e(ye,sM),e(sM,cTe),e(cTe,sCr),e(sM,lCr),e(sM,FJ),e(FJ,iCr),e(sM,dCr),e(ye,cCr),e(ye,lM),e(lM,fTe),e(fTe,fCr),e(lM,mCr),e(lM,TJ),e(TJ,gCr),e(lM,hCr),e(ye,pCr),e(ye,iM),e(iM,mTe),e(mTe,_Cr),e(iM,uCr),e(iM,MJ),e(MJ,bCr),e(iM,vCr),e(ye,FCr),e(ye,dM),e(dM,gTe),e(gTe,TCr),e(dM,MCr),e(dM,EJ),e(EJ,ECr),e(dM,CCr),e(ye,wCr),e(ye,cM),e(cM,hTe),e(hTe,ACr),e(cM,LCr),e(cM,CJ),e(CJ,yCr),e(cM,xCr),e(ye,$Cr),e(ye,fM),e(fM,pTe),e(pTe,kCr),e(fM,SCr),e(fM,wJ),e(wJ,RCr),e(fM,PCr),e(ye,BCr),e(ye,mM),e(mM,_Te),e(_Te,ICr),e(mM,NCr),e(mM,AJ),e(AJ,qCr),e(mM,jCr),e(ye,DCr),e(ye,gM),e(gM,uTe),e(uTe,GCr),e(gM,OCr),e(gM,LJ),e(LJ,VCr),e(gM,XCr),e(ye,zCr),e(ye,hM),e(hM,bTe),e(bTe,QCr),e(hM,WCr),e(hM,yJ),e(yJ,HCr),e(hM,UCr),e(ye,JCr),e(ye,pM),e(pM,vTe),e(vTe,YCr),e(pM,KCr),e(pM,xJ),e(xJ,ZCr),e(pM,e5r),e(Rr,o5r),M(_M,Rr,null),b(f,aVe,u),b(f,bc,u),e(bc,uM),e(uM,FTe),M(z9,FTe,null),e(bc,r5r),e(bc,TTe),e(TTe,t5r),b(f,nVe,u),b(f,sr,u),M(Q9,sr,null),e(sr,a5r),e(sr,vc),e(vc,n5r),e(vc,$J),e($J,s5r),e(vc,l5r),e(vc,kJ),e(kJ,i5r),e(vc,d5r),e(sr,c5r),e(sr,W9),e(W9,f5r),e(W9,MTe),e(MTe,m5r),e(W9,g5r),e(sr,h5r),e(sr,It),M(H9,It,null),e(It,p5r),e(It,ETe),e(ETe,_5r),e(It,u5r),e(It,Fc),e(Fc,b5r),e(Fc,CTe),e(CTe,v5r),e(Fc,F5r),e(Fc,SJ),e(SJ,T5r),e(Fc,M5r),e(It,E5r),M(bM,It,null),e(sr,C5r),e(sr,Pr),M(U9,Pr,null),e(Pr,w5r),e(Pr,wTe),e(wTe,A5r),e(Pr,L5r),e(Pr,mn),e(mn,y5r),e(mn,ATe),e(ATe,x5r),e(mn,$5r),e(mn,LTe),e(LTe,k5r),e(mn,S5r),e(mn,yTe),e(yTe,R5r),e(mn,P5r),e(Pr,B5r),e(Pr,te),e(te,vM),e(vM,xTe),e(xTe,I5r),e(vM,N5r),e(vM,RJ),e(RJ,q5r),e(vM,j5r),e(te,D5r),e(te,FM),e(FM,$Te),e($Te,G5r),e(FM,O5r),e(FM,PJ),e(PJ,V5r),e(FM,X5r),e(te,z5r),e(te,TM),e(TM,kTe),e(kTe,Q5r),e(TM,W5r),e(TM,BJ),e(BJ,H5r),e(TM,U5r),e(te,J5r),e(te,MM),e(MM,STe),e(STe,Y5r),e(MM,K5r),e(MM,IJ),e(IJ,Z5r),e(MM,e3r),e(te,o3r),e(te,EM),e(EM,RTe),e(RTe,r3r),e(EM,t3r),e(EM,NJ),e(NJ,a3r),e(EM,n3r),e(te,s3r),e(te,CM),e(CM,PTe),e(PTe,l3r),e(CM,i3r),e(CM,qJ),e(qJ,d3r),e(CM,c3r),e(te,f3r),e(te,wM),e(wM,BTe),e(BTe,m3r),e(wM,g3r),e(wM,jJ),e(jJ,h3r),e(wM,p3r),e(te,_3r),e(te,AM),e(AM,ITe),e(ITe,u3r),e(AM,b3r),e(AM,DJ),e(DJ,v3r),e(AM,F3r),e(te,T3r),e(te,LM),e(LM,NTe),e(NTe,M3r),e(LM,E3r),e(LM,GJ),e(GJ,C3r),e(LM,w3r),e(te,A3r),e(te,yM),e(yM,qTe),e(qTe,L3r),e(yM,y3r),e(yM,OJ),e(OJ,x3r),e(yM,$3r),e(te,k3r),e(te,xM),e(xM,jTe),e(jTe,S3r),e(xM,R3r),e(xM,VJ),e(VJ,P3r),e(xM,B3r),e(te,I3r),e(te,$M),e($M,DTe),e(DTe,N3r),e($M,q3r),e($M,XJ),e(XJ,j3r),e($M,D3r),e(te,G3r),e(te,kM),e(kM,GTe),e(GTe,O3r),e(kM,V3r),e(kM,zJ),e(zJ,X3r),e(kM,z3r),e(te,Q3r),e(te,SM),e(SM,OTe),e(OTe,W3r),e(SM,H3r),e(SM,QJ),e(QJ,U3r),e(SM,J3r),e(te,Y3r),e(te,RM),e(RM,VTe),e(VTe,K3r),e(RM,Z3r),e(RM,WJ),e(WJ,e0r),e(RM,o0r),e(te,r0r),e(te,PM),e(PM,XTe),e(XTe,t0r),e(PM,a0r),e(PM,HJ),e(HJ,n0r),e(PM,s0r),e(te,l0r),e(te,BM),e(BM,zTe),e(zTe,i0r),e(BM,d0r),e(BM,UJ),e(UJ,c0r),e(BM,f0r),e(te,m0r),e(te,IM),e(IM,QTe),e(QTe,g0r),e(IM,h0r),e(IM,JJ),e(JJ,p0r),e(IM,_0r),e(te,u0r),e(te,NM),e(NM,WTe),e(WTe,b0r),e(NM,v0r),e(NM,YJ),e(YJ,F0r),e(NM,T0r),e(te,M0r),e(te,qM),e(qM,HTe),e(HTe,E0r),e(qM,C0r),e(qM,KJ),e(KJ,w0r),e(qM,A0r),e(te,L0r),e(te,jM),e(jM,UTe),e(UTe,y0r),e(jM,x0r),e(jM,ZJ),e(ZJ,$0r),e(jM,k0r),e(te,S0r),e(te,DM),e(DM,JTe),e(JTe,R0r),e(DM,P0r),e(DM,eY),e(eY,B0r),e(DM,I0r),e(te,N0r),e(te,GM),e(GM,YTe),e(YTe,q0r),e(GM,j0r),e(GM,oY),e(oY,D0r),e(GM,G0r),e(te,O0r),e(te,OM),e(OM,KTe),e(KTe,V0r),e(OM,X0r),e(OM,rY),e(rY,z0r),e(OM,Q0r),e(te,W0r),e(te,VM),e(VM,ZTe),e(ZTe,H0r),e(VM,U0r),e(VM,tY),e(tY,J0r),e(VM,Y0r),e(te,K0r),e(te,XM),e(XM,e7e),e(e7e,Z0r),e(XM,ewr),e(XM,aY),e(aY,owr),e(XM,rwr),e(Pr,twr),M(zM,Pr,null),b(f,sVe,u),b(f,Tc,u),e(Tc,QM),e(QM,o7e),M(J9,o7e,null),e(Tc,awr),e(Tc,r7e),e(r7e,nwr),b(f,lVe,u),b(f,lr,u),M(Y9,lr,null),e(lr,swr),e(lr,Mc),e(Mc,lwr),e(Mc,nY),e(nY,iwr),e(Mc,dwr),e(Mc,sY),e(sY,cwr),e(Mc,fwr),e(lr,mwr),e(lr,K9),e(K9,gwr),e(K9,t7e),e(t7e,hwr),e(K9,pwr),e(lr,_wr),e(lr,Nt),M(Z9,Nt,null),e(Nt,uwr),e(Nt,a7e),e(a7e,bwr),e(Nt,vwr),e(Nt,Ec),e(Ec,Fwr),e(Ec,n7e),e(n7e,Twr),e(Ec,Mwr),e(Ec,lY),e(lY,Ewr),e(Ec,Cwr),e(Nt,wwr),M(WM,Nt,null),e(lr,Awr),e(lr,Br),M(ex,Br,null),e(Br,Lwr),e(Br,s7e),e(s7e,ywr),e(Br,xwr),e(Br,gn),e(gn,$wr),e(gn,l7e),e(l7e,kwr),e(gn,Swr),e(gn,i7e),e(i7e,Rwr),e(gn,Pwr),e(gn,d7e),e(d7e,Bwr),e(gn,Iwr),e(Br,Nwr),e(Br,_e),e(_e,HM),e(HM,c7e),e(c7e,qwr),e(HM,jwr),e(HM,iY),e(iY,Dwr),e(HM,Gwr),e(_e,Owr),e(_e,UM),e(UM,f7e),e(f7e,Vwr),e(UM,Xwr),e(UM,dY),e(dY,zwr),e(UM,Qwr),e(_e,Wwr),e(_e,JM),e(JM,m7e),e(m7e,Hwr),e(JM,Uwr),e(JM,cY),e(cY,Jwr),e(JM,Ywr),e(_e,Kwr),e(_e,YM),e(YM,g7e),e(g7e,Zwr),e(YM,eAr),e(YM,fY),e(fY,oAr),e(YM,rAr),e(_e,tAr),e(_e,KM),e(KM,h7e),e(h7e,aAr),e(KM,nAr),e(KM,mY),e(mY,sAr),e(KM,lAr),e(_e,iAr),e(_e,ZM),e(ZM,p7e),e(p7e,dAr),e(ZM,cAr),e(ZM,gY),e(gY,fAr),e(ZM,mAr),e(_e,gAr),e(_e,eE),e(eE,_7e),e(_7e,hAr),e(eE,pAr),e(eE,hY),e(hY,_Ar),e(eE,uAr),e(_e,bAr),e(_e,oE),e(oE,u7e),e(u7e,vAr),e(oE,FAr),e(oE,pY),e(pY,TAr),e(oE,MAr),e(_e,EAr),e(_e,rE),e(rE,b7e),e(b7e,CAr),e(rE,wAr),e(rE,_Y),e(_Y,AAr),e(rE,LAr),e(_e,yAr),e(_e,tE),e(tE,v7e),e(v7e,xAr),e(tE,$Ar),e(tE,uY),e(uY,kAr),e(tE,SAr),e(_e,RAr),e(_e,aE),e(aE,F7e),e(F7e,PAr),e(aE,BAr),e(aE,bY),e(bY,IAr),e(aE,NAr),e(_e,qAr),e(_e,nE),e(nE,T7e),e(T7e,jAr),e(nE,DAr),e(nE,vY),e(vY,GAr),e(nE,OAr),e(_e,VAr),e(_e,sE),e(sE,M7e),e(M7e,XAr),e(sE,zAr),e(sE,FY),e(FY,QAr),e(sE,WAr),e(_e,HAr),e(_e,lE),e(lE,E7e),e(E7e,UAr),e(lE,JAr),e(lE,TY),e(TY,YAr),e(lE,KAr),e(_e,ZAr),e(_e,iE),e(iE,C7e),e(C7e,eLr),e(iE,oLr),e(iE,MY),e(MY,rLr),e(iE,tLr),e(_e,aLr),e(_e,dE),e(dE,w7e),e(w7e,nLr),e(dE,sLr),e(dE,EY),e(EY,lLr),e(dE,iLr),e(_e,dLr),e(_e,cE),e(cE,A7e),e(A7e,cLr),e(cE,fLr),e(cE,CY),e(CY,mLr),e(cE,gLr),e(Br,hLr),M(fE,Br,null),b(f,iVe,u),b(f,Cc,u),e(Cc,mE),e(mE,L7e),M(ox,L7e,null),e(Cc,pLr),e(Cc,y7e),e(y7e,_Lr),b(f,dVe,u),b(f,ir,u),M(rx,ir,null),e(ir,uLr),e(ir,wc),e(wc,bLr),e(wc,wY),e(wY,vLr),e(wc,FLr),e(wc,AY),e(AY,TLr),e(wc,MLr),e(ir,ELr),e(ir,tx),e(tx,CLr),e(tx,x7e),e(x7e,wLr),e(tx,ALr),e(ir,LLr),e(ir,qt),M(ax,qt,null),e(qt,yLr),e(qt,$7e),e($7e,xLr),e(qt,$Lr),e(qt,Ac),e(Ac,kLr),e(Ac,k7e),e(k7e,SLr),e(Ac,RLr),e(Ac,LY),e(LY,PLr),e(Ac,BLr),e(qt,ILr),M(gE,qt,null),e(ir,NLr),e(ir,Ir),M(nx,Ir,null),e(Ir,qLr),e(Ir,S7e),e(S7e,jLr),e(Ir,DLr),e(Ir,hn),e(hn,GLr),e(hn,R7e),e(R7e,OLr),e(hn,VLr),e(hn,P7e),e(P7e,XLr),e(hn,zLr),e(hn,B7e),e(B7e,QLr),e(hn,WLr),e(Ir,HLr),e(Ir,sx),e(sx,hE),e(hE,I7e),e(I7e,ULr),e(hE,JLr),e(hE,yY),e(yY,YLr),e(hE,KLr),e(sx,ZLr),e(sx,pE),e(pE,N7e),e(N7e,eyr),e(pE,oyr),e(pE,xY),e(xY,ryr),e(pE,tyr),e(Ir,ayr),M(_E,Ir,null),b(f,cVe,u),b(f,Lc,u),e(Lc,uE),e(uE,q7e),M(lx,q7e,null),e(Lc,nyr),e(Lc,j7e),e(j7e,syr),b(f,fVe,u),b(f,dr,u),M(ix,dr,null),e(dr,lyr),e(dr,yc),e(yc,iyr),e(yc,$Y),e($Y,dyr),e(yc,cyr),e(yc,kY),e(kY,fyr),e(yc,myr),e(dr,gyr),e(dr,dx),e(dx,hyr),e(dx,D7e),e(D7e,pyr),e(dx,_yr),e(dr,uyr),e(dr,jt),M(cx,jt,null),e(jt,byr),e(jt,G7e),e(G7e,vyr),e(jt,Fyr),e(jt,xc),e(xc,Tyr),e(xc,O7e),e(O7e,Myr),e(xc,Eyr),e(xc,SY),e(SY,Cyr),e(xc,wyr),e(jt,Ayr),M(bE,jt,null),e(dr,Lyr),e(dr,Nr),M(fx,Nr,null),e(Nr,yyr),e(Nr,V7e),e(V7e,xyr),e(Nr,$yr),e(Nr,pn),e(pn,kyr),e(pn,X7e),e(X7e,Syr),e(pn,Ryr),e(pn,z7e),e(z7e,Pyr),e(pn,Byr),e(pn,Q7e),e(Q7e,Iyr),e(pn,Nyr),e(Nr,qyr),e(Nr,W7e),e(W7e,vE),e(vE,H7e),e(H7e,jyr),e(vE,Dyr),e(vE,RY),e(RY,Gyr),e(vE,Oyr),e(Nr,Vyr),M(FE,Nr,null),b(f,mVe,u),b(f,$c,u),e($c,TE),e(TE,U7e),M(mx,U7e,null),e($c,Xyr),e($c,J7e),e(J7e,zyr),b(f,gVe,u),b(f,cr,u),M(gx,cr,null),e(cr,Qyr),e(cr,kc),e(kc,Wyr),e(kc,PY),e(PY,Hyr),e(kc,Uyr),e(kc,BY),e(BY,Jyr),e(kc,Yyr),e(cr,Kyr),e(cr,hx),e(hx,Zyr),e(hx,Y7e),e(Y7e,e9r),e(hx,o9r),e(cr,r9r),e(cr,Dt),M(px,Dt,null),e(Dt,t9r),e(Dt,K7e),e(K7e,a9r),e(Dt,n9r),e(Dt,Sc),e(Sc,s9r),e(Sc,Z7e),e(Z7e,l9r),e(Sc,i9r),e(Sc,IY),e(IY,d9r),e(Sc,c9r),e(Dt,f9r),M(ME,Dt,null),e(cr,m9r),e(cr,qr),M(_x,qr,null),e(qr,g9r),e(qr,e8e),e(e8e,h9r),e(qr,p9r),e(qr,_n),e(_n,_9r),e(_n,o8e),e(o8e,u9r),e(_n,b9r),e(_n,r8e),e(r8e,v9r),e(_n,F9r),e(_n,t8e),e(t8e,T9r),e(_n,M9r),e(qr,E9r),e(qr,de),e(de,EE),e(EE,a8e),e(a8e,C9r),e(EE,w9r),e(EE,NY),e(NY,A9r),e(EE,L9r),e(de,y9r),e(de,CE),e(CE,n8e),e(n8e,x9r),e(CE,$9r),e(CE,qY),e(qY,k9r),e(CE,S9r),e(de,R9r),e(de,wE),e(wE,s8e),e(s8e,P9r),e(wE,B9r),e(wE,jY),e(jY,I9r),e(wE,N9r),e(de,q9r),e(de,AE),e(AE,l8e),e(l8e,j9r),e(AE,D9r),e(AE,DY),e(DY,G9r),e(AE,O9r),e(de,V9r),e(de,LE),e(LE,i8e),e(i8e,X9r),e(LE,z9r),e(LE,GY),e(GY,Q9r),e(LE,W9r),e(de,H9r),e(de,yE),e(yE,d8e),e(d8e,U9r),e(yE,J9r),e(yE,OY),e(OY,Y9r),e(yE,K9r),e(de,Z9r),e(de,xE),e(xE,c8e),e(c8e,exr),e(xE,oxr),e(xE,VY),e(VY,rxr),e(xE,txr),e(de,axr),e(de,$E),e($E,f8e),e(f8e,nxr),e($E,sxr),e($E,XY),e(XY,lxr),e($E,ixr),e(de,dxr),e(de,kE),e(kE,m8e),e(m8e,cxr),e(kE,fxr),e(kE,zY),e(zY,mxr),e(kE,gxr),e(de,hxr),e(de,SE),e(SE,g8e),e(g8e,pxr),e(SE,_xr),e(SE,QY),e(QY,uxr),e(SE,bxr),e(de,vxr),e(de,RE),e(RE,h8e),e(h8e,Fxr),e(RE,Txr),e(RE,WY),e(WY,Mxr),e(RE,Exr),e(de,Cxr),e(de,PE),e(PE,p8e),e(p8e,wxr),e(PE,Axr),e(PE,HY),e(HY,Lxr),e(PE,yxr),e(de,xxr),e(de,BE),e(BE,_8e),e(_8e,$xr),e(BE,kxr),e(BE,UY),e(UY,Sxr),e(BE,Rxr),e(de,Pxr),e(de,IE),e(IE,u8e),e(u8e,Bxr),e(IE,Ixr),e(IE,JY),e(JY,Nxr),e(IE,qxr),e(de,jxr),e(de,NE),e(NE,b8e),e(b8e,Dxr),e(NE,Gxr),e(NE,YY),e(YY,Oxr),e(NE,Vxr),e(de,Xxr),e(de,qE),e(qE,v8e),e(v8e,zxr),e(qE,Qxr),e(qE,KY),e(KY,Wxr),e(qE,Hxr),e(de,Uxr),e(de,jE),e(jE,F8e),e(F8e,Jxr),e(jE,Yxr),e(jE,ZY),e(ZY,Kxr),e(jE,Zxr),e(de,e$r),e(de,DE),e(DE,T8e),e(T8e,o$r),e(DE,r$r),e(DE,eK),e(eK,t$r),e(DE,a$r),e(de,n$r),e(de,GE),e(GE,M8e),e(M8e,s$r),e(GE,l$r),e(GE,oK),e(oK,i$r),e(GE,d$r),e(de,c$r),e(de,OE),e(OE,E8e),e(E8e,f$r),e(OE,m$r),e(OE,rK),e(rK,g$r),e(OE,h$r),e(qr,p$r),M(VE,qr,null),b(f,hVe,u),b(f,Rc,u),e(Rc,XE),e(XE,C8e),M(ux,C8e,null),e(Rc,_$r),e(Rc,w8e),e(w8e,u$r),b(f,pVe,u),b(f,fr,u),M(bx,fr,null),e(fr,b$r),e(fr,Pc),e(Pc,v$r),e(Pc,tK),e(tK,F$r),e(Pc,T$r),e(Pc,aK),e(aK,M$r),e(Pc,E$r),e(fr,C$r),e(fr,vx),e(vx,w$r),e(vx,A8e),e(A8e,A$r),e(vx,L$r),e(fr,y$r),e(fr,Gt),M(Fx,Gt,null),e(Gt,x$r),e(Gt,L8e),e(L8e,$$r),e(Gt,k$r),e(Gt,Bc),e(Bc,S$r),e(Bc,y8e),e(y8e,R$r),e(Bc,P$r),e(Bc,nK),e(nK,B$r),e(Bc,I$r),e(Gt,N$r),M(zE,Gt,null),e(fr,q$r),e(fr,jr),M(Tx,jr,null),e(jr,j$r),e(jr,x8e),e(x8e,D$r),e(jr,G$r),e(jr,un),e(un,O$r),e(un,$8e),e($8e,V$r),e(un,X$r),e(un,k8e),e(k8e,z$r),e(un,Q$r),e(un,S8e),e(S8e,W$r),e(un,H$r),e(jr,U$r),e(jr,ce),e(ce,QE),e(QE,R8e),e(R8e,J$r),e(QE,Y$r),e(QE,sK),e(sK,K$r),e(QE,Z$r),e(ce,ekr),e(ce,WE),e(WE,P8e),e(P8e,okr),e(WE,rkr),e(WE,lK),e(lK,tkr),e(WE,akr),e(ce,nkr),e(ce,HE),e(HE,B8e),e(B8e,skr),e(HE,lkr),e(HE,iK),e(iK,ikr),e(HE,dkr),e(ce,ckr),e(ce,UE),e(UE,I8e),e(I8e,fkr),e(UE,mkr),e(UE,dK),e(dK,gkr),e(UE,hkr),e(ce,pkr),e(ce,JE),e(JE,N8e),e(N8e,_kr),e(JE,ukr),e(JE,cK),e(cK,bkr),e(JE,vkr),e(ce,Fkr),e(ce,YE),e(YE,q8e),e(q8e,Tkr),e(YE,Mkr),e(YE,fK),e(fK,Ekr),e(YE,Ckr),e(ce,wkr),e(ce,KE),e(KE,j8e),e(j8e,Akr),e(KE,Lkr),e(KE,mK),e(mK,ykr),e(KE,xkr),e(ce,$kr),e(ce,ZE),e(ZE,D8e),e(D8e,kkr),e(ZE,Skr),e(ZE,gK),e(gK,Rkr),e(ZE,Pkr),e(ce,Bkr),e(ce,eC),e(eC,G8e),e(G8e,Ikr),e(eC,Nkr),e(eC,hK),e(hK,qkr),e(eC,jkr),e(ce,Dkr),e(ce,oC),e(oC,O8e),e(O8e,Gkr),e(oC,Okr),e(oC,pK),e(pK,Vkr),e(oC,Xkr),e(ce,zkr),e(ce,rC),e(rC,V8e),e(V8e,Qkr),e(rC,Wkr),e(rC,_K),e(_K,Hkr),e(rC,Ukr),e(ce,Jkr),e(ce,tC),e(tC,X8e),e(X8e,Ykr),e(tC,Kkr),e(tC,uK),e(uK,Zkr),e(tC,eSr),e(ce,oSr),e(ce,aC),e(aC,z8e),e(z8e,rSr),e(aC,tSr),e(aC,bK),e(bK,aSr),e(aC,nSr),e(ce,sSr),e(ce,nC),e(nC,Q8e),e(Q8e,lSr),e(nC,iSr),e(nC,vK),e(vK,dSr),e(nC,cSr),e(ce,fSr),e(ce,sC),e(sC,W8e),e(W8e,mSr),e(sC,gSr),e(sC,FK),e(FK,hSr),e(sC,pSr),e(ce,_Sr),e(ce,lC),e(lC,H8e),e(H8e,uSr),e(lC,bSr),e(lC,TK),e(TK,vSr),e(lC,FSr),e(ce,TSr),e(ce,iC),e(iC,U8e),e(U8e,MSr),e(iC,ESr),e(iC,MK),e(MK,CSr),e(iC,wSr),e(ce,ASr),e(ce,dC),e(dC,J8e),e(J8e,LSr),e(dC,ySr),e(dC,EK),e(EK,xSr),e(dC,$Sr),e(ce,kSr),e(ce,cC),e(cC,Y8e),e(Y8e,SSr),e(cC,RSr),e(cC,CK),e(CK,PSr),e(cC,BSr),e(ce,ISr),e(ce,fC),e(fC,K8e),e(K8e,NSr),e(fC,qSr),e(fC,wK),e(wK,jSr),e(fC,DSr),e(jr,GSr),M(mC,jr,null),b(f,_Ve,u),b(f,Ic,u),e(Ic,gC),e(gC,Z8e),M(Mx,Z8e,null),e(Ic,OSr),e(Ic,eMe),e(eMe,VSr),b(f,uVe,u),b(f,mr,u),M(Ex,mr,null),e(mr,XSr),e(mr,Nc),e(Nc,zSr),e(Nc,AK),e(AK,QSr),e(Nc,WSr),e(Nc,LK),e(LK,HSr),e(Nc,USr),e(mr,JSr),e(mr,Cx),e(Cx,YSr),e(Cx,oMe),e(oMe,KSr),e(Cx,ZSr),e(mr,eRr),e(mr,Ot),M(wx,Ot,null),e(Ot,oRr),e(Ot,rMe),e(rMe,rRr),e(Ot,tRr),e(Ot,qc),e(qc,aRr),e(qc,tMe),e(tMe,nRr),e(qc,sRr),e(qc,yK),e(yK,lRr),e(qc,iRr),e(Ot,dRr),M(hC,Ot,null),e(mr,cRr),e(mr,Dr),M(Ax,Dr,null),e(Dr,fRr),e(Dr,aMe),e(aMe,mRr),e(Dr,gRr),e(Dr,bn),e(bn,hRr),e(bn,nMe),e(nMe,pRr),e(bn,_Rr),e(bn,sMe),e(sMe,uRr),e(bn,bRr),e(bn,lMe),e(lMe,vRr),e(bn,FRr),e(Dr,TRr),e(Dr,iMe),e(iMe,pC),e(pC,dMe),e(dMe,MRr),e(pC,ERr),e(pC,xK),e(xK,CRr),e(pC,wRr),e(Dr,ARr),M(_C,Dr,null),b(f,bVe,u),b(f,jc,u),e(jc,uC),e(uC,cMe),M(Lx,cMe,null),e(jc,LRr),e(jc,fMe),e(fMe,yRr),b(f,vVe,u),b(f,gr,u),M(yx,gr,null),e(gr,xRr),e(gr,Dc),e(Dc,$Rr),e(Dc,$K),e($K,kRr),e(Dc,SRr),e(Dc,kK),e(kK,RRr),e(Dc,PRr),e(gr,BRr),e(gr,xx),e(xx,IRr),e(xx,mMe),e(mMe,NRr),e(xx,qRr),e(gr,jRr),e(gr,Vt),M($x,Vt,null),e(Vt,DRr),e(Vt,gMe),e(gMe,GRr),e(Vt,ORr),e(Vt,Gc),e(Gc,VRr),e(Gc,hMe),e(hMe,XRr),e(Gc,zRr),e(Gc,SK),e(SK,QRr),e(Gc,WRr),e(Vt,HRr),M(bC,Vt,null),e(gr,URr),e(gr,Gr),M(kx,Gr,null),e(Gr,JRr),e(Gr,pMe),e(pMe,YRr),e(Gr,KRr),e(Gr,vn),e(vn,ZRr),e(vn,_Me),e(_Me,ePr),e(vn,oPr),e(vn,uMe),e(uMe,rPr),e(vn,tPr),e(vn,bMe),e(bMe,aPr),e(vn,nPr),e(Gr,sPr),e(Gr,vMe),e(vMe,vC),e(vC,FMe),e(FMe,lPr),e(vC,iPr),e(vC,RK),e(RK,dPr),e(vC,cPr),e(Gr,fPr),M(FC,Gr,null),b(f,FVe,u),b(f,Oc,u),e(Oc,TC),e(TC,TMe),M(Sx,TMe,null),e(Oc,mPr),e(Oc,MMe),e(MMe,gPr),b(f,TVe,u),b(f,hr,u),M(Rx,hr,null),e(hr,hPr),e(hr,Vc),e(Vc,pPr),e(Vc,PK),e(PK,_Pr),e(Vc,uPr),e(Vc,BK),e(BK,bPr),e(Vc,vPr),e(hr,FPr),e(hr,Px),e(Px,TPr),e(Px,EMe),e(EMe,MPr),e(Px,EPr),e(hr,CPr),e(hr,Xt),M(Bx,Xt,null),e(Xt,wPr),e(Xt,CMe),e(CMe,APr),e(Xt,LPr),e(Xt,Xc),e(Xc,yPr),e(Xc,wMe),e(wMe,xPr),e(Xc,$Pr),e(Xc,IK),e(IK,kPr),e(Xc,SPr),e(Xt,RPr),M(MC,Xt,null),e(hr,PPr),e(hr,Or),M(Ix,Or,null),e(Or,BPr),e(Or,AMe),e(AMe,IPr),e(Or,NPr),e(Or,Fn),e(Fn,qPr),e(Fn,LMe),e(LMe,jPr),e(Fn,DPr),e(Fn,yMe),e(yMe,GPr),e(Fn,OPr),e(Fn,xMe),e(xMe,VPr),e(Fn,XPr),e(Or,zPr),e(Or,oe),e(oe,EC),e(EC,$Me),e($Me,QPr),e(EC,WPr),e(EC,NK),e(NK,HPr),e(EC,UPr),e(oe,JPr),e(oe,CC),e(CC,kMe),e(kMe,YPr),e(CC,KPr),e(CC,qK),e(qK,ZPr),e(CC,eBr),e(oe,oBr),e(oe,wC),e(wC,SMe),e(SMe,rBr),e(wC,tBr),e(wC,jK),e(jK,aBr),e(wC,nBr),e(oe,sBr),e(oe,AC),e(AC,RMe),e(RMe,lBr),e(AC,iBr),e(AC,DK),e(DK,dBr),e(AC,cBr),e(oe,fBr),e(oe,LC),e(LC,PMe),e(PMe,mBr),e(LC,gBr),e(LC,GK),e(GK,hBr),e(LC,pBr),e(oe,_Br),e(oe,yC),e(yC,BMe),e(BMe,uBr),e(yC,bBr),e(yC,OK),e(OK,vBr),e(yC,FBr),e(oe,TBr),e(oe,xC),e(xC,IMe),e(IMe,MBr),e(xC,EBr),e(xC,VK),e(VK,CBr),e(xC,wBr),e(oe,ABr),e(oe,$C),e($C,NMe),e(NMe,LBr),e($C,yBr),e($C,XK),e(XK,xBr),e($C,$Br),e(oe,kBr),e(oe,kC),e(kC,qMe),e(qMe,SBr),e(kC,RBr),e(kC,zK),e(zK,PBr),e(kC,BBr),e(oe,IBr),e(oe,SC),e(SC,jMe),e(jMe,NBr),e(SC,qBr),e(SC,QK),e(QK,jBr),e(SC,DBr),e(oe,GBr),e(oe,RC),e(RC,DMe),e(DMe,OBr),e(RC,VBr),e(RC,WK),e(WK,XBr),e(RC,zBr),e(oe,QBr),e(oe,PC),e(PC,GMe),e(GMe,WBr),e(PC,HBr),e(PC,HK),e(HK,UBr),e(PC,JBr),e(oe,YBr),e(oe,BC),e(BC,OMe),e(OMe,KBr),e(BC,ZBr),e(BC,UK),e(UK,eIr),e(BC,oIr),e(oe,rIr),e(oe,IC),e(IC,VMe),e(VMe,tIr),e(IC,aIr),e(IC,JK),e(JK,nIr),e(IC,sIr),e(oe,lIr),e(oe,NC),e(NC,XMe),e(XMe,iIr),e(NC,dIr),e(NC,YK),e(YK,cIr),e(NC,fIr),e(oe,mIr),e(oe,qC),e(qC,zMe),e(zMe,gIr),e(qC,hIr),e(qC,KK),e(KK,pIr),e(qC,_Ir),e(oe,uIr),e(oe,jC),e(jC,QMe),e(QMe,bIr),e(jC,vIr),e(jC,ZK),e(ZK,FIr),e(jC,TIr),e(oe,MIr),e(oe,DC),e(DC,WMe),e(WMe,EIr),e(DC,CIr),e(DC,eZ),e(eZ,wIr),e(DC,AIr),e(oe,LIr),e(oe,GC),e(GC,HMe),e(HMe,yIr),e(GC,xIr),e(GC,oZ),e(oZ,$Ir),e(GC,kIr),e(oe,SIr),e(oe,OC),e(OC,UMe),e(UMe,RIr),e(OC,PIr),e(OC,rZ),e(rZ,BIr),e(OC,IIr),e(oe,NIr),e(oe,VC),e(VC,JMe),e(JMe,qIr),e(VC,jIr),e(VC,tZ),e(tZ,DIr),e(VC,GIr),e(oe,OIr),e(oe,XC),e(XC,YMe),e(YMe,VIr),e(XC,XIr),e(XC,aZ),e(aZ,zIr),e(XC,QIr),e(oe,WIr),e(oe,zC),e(zC,KMe),e(KMe,HIr),e(zC,UIr),e(zC,nZ),e(nZ,JIr),e(zC,YIr),e(oe,KIr),e(oe,QC),e(QC,ZMe),e(ZMe,ZIr),e(QC,eNr),e(QC,sZ),e(sZ,oNr),e(QC,rNr),e(oe,tNr),e(oe,WC),e(WC,eEe),e(eEe,aNr),e(WC,nNr),e(WC,lZ),e(lZ,sNr),e(WC,lNr),e(oe,iNr),e(oe,HC),e(HC,oEe),e(oEe,dNr),e(HC,cNr),e(HC,iZ),e(iZ,fNr),e(HC,mNr),e(oe,gNr),e(oe,UC),e(UC,rEe),e(rEe,hNr),e(UC,pNr),e(UC,dZ),e(dZ,_Nr),e(UC,uNr),e(Or,bNr),M(JC,Or,null),b(f,MVe,u),b(f,zc,u),e(zc,YC),e(YC,tEe),M(Nx,tEe,null),e(zc,vNr),e(zc,aEe),e(aEe,FNr),b(f,EVe,u),b(f,pr,u),M(qx,pr,null),e(pr,TNr),e(pr,Qc),e(Qc,MNr),e(Qc,cZ),e(cZ,ENr),e(Qc,CNr),e(Qc,fZ),e(fZ,wNr),e(Qc,ANr),e(pr,LNr),e(pr,jx),e(jx,yNr),e(jx,nEe),e(nEe,xNr),e(jx,$Nr),e(pr,kNr),e(pr,zt),M(Dx,zt,null),e(zt,SNr),e(zt,sEe),e(sEe,RNr),e(zt,PNr),e(zt,Wc),e(Wc,BNr),e(Wc,lEe),e(lEe,INr),e(Wc,NNr),e(Wc,mZ),e(mZ,qNr),e(Wc,jNr),e(zt,DNr),M(KC,zt,null),e(pr,GNr),e(pr,Vr),M(Gx,Vr,null),e(Vr,ONr),e(Vr,iEe),e(iEe,VNr),e(Vr,XNr),e(Vr,Tn),e(Tn,zNr),e(Tn,dEe),e(dEe,QNr),e(Tn,WNr),e(Tn,cEe),e(cEe,HNr),e(Tn,UNr),e(Tn,fEe),e(fEe,JNr),e(Tn,YNr),e(Vr,KNr),e(Vr,xe),e(xe,ZC),e(ZC,mEe),e(mEe,ZNr),e(ZC,eqr),e(ZC,gZ),e(gZ,oqr),e(ZC,rqr),e(xe,tqr),e(xe,e5),e(e5,gEe),e(gEe,aqr),e(e5,nqr),e(e5,hZ),e(hZ,sqr),e(e5,lqr),e(xe,iqr),e(xe,o5),e(o5,hEe),e(hEe,dqr),e(o5,cqr),e(o5,pZ),e(pZ,fqr),e(o5,mqr),e(xe,gqr),e(xe,r5),e(r5,pEe),e(pEe,hqr),e(r5,pqr),e(r5,_Z),e(_Z,_qr),e(r5,uqr),e(xe,bqr),e(xe,t5),e(t5,_Ee),e(_Ee,vqr),e(t5,Fqr),e(t5,uZ),e(uZ,Tqr),e(t5,Mqr),e(xe,Eqr),e(xe,a5),e(a5,uEe),e(uEe,Cqr),e(a5,wqr),e(a5,bZ),e(bZ,Aqr),e(a5,Lqr),e(xe,yqr),e(xe,n5),e(n5,bEe),e(bEe,xqr),e(n5,$qr),e(n5,vZ),e(vZ,kqr),e(n5,Sqr),e(xe,Rqr),e(xe,s5),e(s5,vEe),e(vEe,Pqr),e(s5,Bqr),e(s5,FZ),e(FZ,Iqr),e(s5,Nqr),e(xe,qqr),e(xe,l5),e(l5,FEe),e(FEe,jqr),e(l5,Dqr),e(l5,TZ),e(TZ,Gqr),e(l5,Oqr),e(xe,Vqr),e(xe,i5),e(i5,TEe),e(TEe,Xqr),e(i5,zqr),e(i5,MZ),e(MZ,Qqr),e(i5,Wqr),e(Vr,Hqr),M(d5,Vr,null),b(f,CVe,u),b(f,Hc,u),e(Hc,c5),e(c5,MEe),M(Ox,MEe,null),e(Hc,Uqr),e(Hc,EEe),e(EEe,Jqr),b(f,wVe,u),b(f,_r,u),M(Vx,_r,null),e(_r,Yqr),e(_r,Uc),e(Uc,Kqr),e(Uc,EZ),e(EZ,Zqr),e(Uc,ejr),e(Uc,CZ),e(CZ,ojr),e(Uc,rjr),e(_r,tjr),e(_r,Xx),e(Xx,ajr),e(Xx,CEe),e(CEe,njr),e(Xx,sjr),e(_r,ljr),e(_r,Qt),M(zx,Qt,null),e(Qt,ijr),e(Qt,wEe),e(wEe,djr),e(Qt,cjr),e(Qt,Jc),e(Jc,fjr),e(Jc,AEe),e(AEe,mjr),e(Jc,gjr),e(Jc,wZ),e(wZ,hjr),e(Jc,pjr),e(Qt,_jr),M(f5,Qt,null),e(_r,ujr),e(_r,Xr),M(Qx,Xr,null),e(Xr,bjr),e(Xr,LEe),e(LEe,vjr),e(Xr,Fjr),e(Xr,Mn),e(Mn,Tjr),e(Mn,yEe),e(yEe,Mjr),e(Mn,Ejr),e(Mn,xEe),e(xEe,Cjr),e(Mn,wjr),e(Mn,$Ee),e($Ee,Ajr),e(Mn,Ljr),e(Xr,yjr),e(Xr,Ee),e(Ee,m5),e(m5,kEe),e(kEe,xjr),e(m5,$jr),e(m5,AZ),e(AZ,kjr),e(m5,Sjr),e(Ee,Rjr),e(Ee,g5),e(g5,SEe),e(SEe,Pjr),e(g5,Bjr),e(g5,LZ),e(LZ,Ijr),e(g5,Njr),e(Ee,qjr),e(Ee,h5),e(h5,REe),e(REe,jjr),e(h5,Djr),e(h5,yZ),e(yZ,Gjr),e(h5,Ojr),e(Ee,Vjr),e(Ee,p5),e(p5,PEe),e(PEe,Xjr),e(p5,zjr),e(p5,xZ),e(xZ,Qjr),e(p5,Wjr),e(Ee,Hjr),e(Ee,_5),e(_5,BEe),e(BEe,Ujr),e(_5,Jjr),e(_5,$Z),e($Z,Yjr),e(_5,Kjr),e(Ee,Zjr),e(Ee,u5),e(u5,IEe),e(IEe,eDr),e(u5,oDr),e(u5,kZ),e(kZ,rDr),e(u5,tDr),e(Ee,aDr),e(Ee,b5),e(b5,NEe),e(NEe,nDr),e(b5,sDr),e(b5,SZ),e(SZ,lDr),e(b5,iDr),e(Ee,dDr),e(Ee,v5),e(v5,qEe),e(qEe,cDr),e(v5,fDr),e(v5,RZ),e(RZ,mDr),e(v5,gDr),e(Ee,hDr),e(Ee,F5),e(F5,jEe),e(jEe,pDr),e(F5,_Dr),e(F5,PZ),e(PZ,uDr),e(F5,bDr),e(Ee,vDr),e(Ee,T5),e(T5,DEe),e(DEe,FDr),e(T5,TDr),e(T5,BZ),e(BZ,MDr),e(T5,EDr),e(Ee,CDr),e(Ee,M5),e(M5,GEe),e(GEe,wDr),e(M5,ADr),e(M5,IZ),e(IZ,LDr),e(M5,yDr),e(Ee,xDr),e(Ee,E5),e(E5,OEe),e(OEe,$Dr),e(E5,kDr),e(E5,NZ),e(NZ,SDr),e(E5,RDr),e(Ee,PDr),e(Ee,C5),e(C5,VEe),e(VEe,BDr),e(C5,IDr),e(C5,qZ),e(qZ,NDr),e(C5,qDr),e(Xr,jDr),M(w5,Xr,null),b(f,AVe,u),b(f,Yc,u),e(Yc,A5),e(A5,XEe),M(Wx,XEe,null),e(Yc,DDr),e(Yc,zEe),e(zEe,GDr),b(f,LVe,u),b(f,ur,u),M(Hx,ur,null),e(ur,ODr),e(ur,Kc),e(Kc,VDr),e(Kc,jZ),e(jZ,XDr),e(Kc,zDr),e(Kc,DZ),e(DZ,QDr),e(Kc,WDr),e(ur,HDr),e(ur,Ux),e(Ux,UDr),e(Ux,QEe),e(QEe,JDr),e(Ux,YDr),e(ur,KDr),e(ur,Wt),M(Jx,Wt,null),e(Wt,ZDr),e(Wt,WEe),e(WEe,eGr),e(Wt,oGr),e(Wt,Zc),e(Zc,rGr),e(Zc,HEe),e(HEe,tGr),e(Zc,aGr),e(Zc,GZ),e(GZ,nGr),e(Zc,sGr),e(Wt,lGr),M(L5,Wt,null),e(ur,iGr),e(ur,zr),M(Yx,zr,null),e(zr,dGr),e(zr,UEe),e(UEe,cGr),e(zr,fGr),e(zr,En),e(En,mGr),e(En,JEe),e(JEe,gGr),e(En,hGr),e(En,YEe),e(YEe,pGr),e(En,_Gr),e(En,KEe),e(KEe,uGr),e(En,bGr),e(zr,vGr),e(zr,$e),e($e,y5),e(y5,ZEe),e(ZEe,FGr),e(y5,TGr),e(y5,OZ),e(OZ,MGr),e(y5,EGr),e($e,CGr),e($e,x5),e(x5,eCe),e(eCe,wGr),e(x5,AGr),e(x5,VZ),e(VZ,LGr),e(x5,yGr),e($e,xGr),e($e,$5),e($5,oCe),e(oCe,$Gr),e($5,kGr),e($5,XZ),e(XZ,SGr),e($5,RGr),e($e,PGr),e($e,k5),e(k5,rCe),e(rCe,BGr),e(k5,IGr),e(k5,zZ),e(zZ,NGr),e(k5,qGr),e($e,jGr),e($e,S5),e(S5,tCe),e(tCe,DGr),e(S5,GGr),e(S5,QZ),e(QZ,OGr),e(S5,VGr),e($e,XGr),e($e,R5),e(R5,aCe),e(aCe,zGr),e(R5,QGr),e(R5,WZ),e(WZ,WGr),e(R5,HGr),e($e,UGr),e($e,P5),e(P5,nCe),e(nCe,JGr),e(P5,YGr),e(P5,HZ),e(HZ,KGr),e(P5,ZGr),e($e,eOr),e($e,B5),e(B5,sCe),e(sCe,oOr),e(B5,rOr),e(B5,UZ),e(UZ,tOr),e(B5,aOr),e($e,nOr),e($e,I5),e(I5,lCe),e(lCe,sOr),e(I5,lOr),e(I5,JZ),e(JZ,iOr),e(I5,dOr),e($e,cOr),e($e,N5),e(N5,iCe),e(iCe,fOr),e(N5,mOr),e(N5,YZ),e(YZ,gOr),e(N5,hOr),e(zr,pOr),M(q5,zr,null),b(f,yVe,u),b(f,ef,u),e(ef,j5),e(j5,dCe),M(Kx,dCe,null),e(ef,_Or),e(ef,cCe),e(cCe,uOr),b(f,xVe,u),b(f,br,u),M(Zx,br,null),e(br,bOr),e(br,of),e(of,vOr),e(of,KZ),e(KZ,FOr),e(of,TOr),e(of,ZZ),e(ZZ,MOr),e(of,EOr),e(br,COr),e(br,e$),e(e$,wOr),e(e$,fCe),e(fCe,AOr),e(e$,LOr),e(br,yOr),e(br,Ht),M(o$,Ht,null),e(Ht,xOr),e(Ht,mCe),e(mCe,$Or),e(Ht,kOr),e(Ht,rf),e(rf,SOr),e(rf,gCe),e(gCe,ROr),e(rf,POr),e(rf,eee),e(eee,BOr),e(rf,IOr),e(Ht,NOr),M(D5,Ht,null),e(br,qOr),e(br,Qr),M(r$,Qr,null),e(Qr,jOr),e(Qr,hCe),e(hCe,DOr),e(Qr,GOr),e(Qr,Cn),e(Cn,OOr),e(Cn,pCe),e(pCe,VOr),e(Cn,XOr),e(Cn,_Ce),e(_Ce,zOr),e(Cn,QOr),e(Cn,uCe),e(uCe,WOr),e(Cn,HOr),e(Qr,UOr),e(Qr,ke),e(ke,G5),e(G5,bCe),e(bCe,JOr),e(G5,YOr),e(G5,oee),e(oee,KOr),e(G5,ZOr),e(ke,eVr),e(ke,O5),e(O5,vCe),e(vCe,oVr),e(O5,rVr),e(O5,ree),e(ree,tVr),e(O5,aVr),e(ke,nVr),e(ke,V5),e(V5,FCe),e(FCe,sVr),e(V5,lVr),e(V5,tee),e(tee,iVr),e(V5,dVr),e(ke,cVr),e(ke,X5),e(X5,TCe),e(TCe,fVr),e(X5,mVr),e(X5,aee),e(aee,gVr),e(X5,hVr),e(ke,pVr),e(ke,z5),e(z5,MCe),e(MCe,_Vr),e(z5,uVr),e(z5,nee),e(nee,bVr),e(z5,vVr),e(ke,FVr),e(ke,Q5),e(Q5,ECe),e(ECe,TVr),e(Q5,MVr),e(Q5,see),e(see,EVr),e(Q5,CVr),e(ke,wVr),e(ke,W5),e(W5,CCe),e(CCe,AVr),e(W5,LVr),e(W5,lee),e(lee,yVr),e(W5,xVr),e(ke,$Vr),e(ke,H5),e(H5,wCe),e(wCe,kVr),e(H5,SVr),e(H5,iee),e(iee,RVr),e(H5,PVr),e(ke,BVr),e(ke,U5),e(U5,ACe),e(ACe,IVr),e(U5,NVr),e(U5,dee),e(dee,qVr),e(U5,jVr),e(ke,DVr),e(ke,J5),e(J5,LCe),e(LCe,GVr),e(J5,OVr),e(J5,cee),e(cee,VVr),e(J5,XVr),e(Qr,zVr),M(Y5,Qr,null),b(f,$Ve,u),b(f,tf,u),e(tf,K5),e(K5,yCe),M(t$,yCe,null),e(tf,QVr),e(tf,xCe),e(xCe,WVr),b(f,kVe,u),b(f,vr,u),M(a$,vr,null),e(vr,HVr),e(vr,af),e(af,UVr),e(af,fee),e(fee,JVr),e(af,YVr),e(af,mee),e(mee,KVr),e(af,ZVr),e(vr,eXr),e(vr,n$),e(n$,oXr),e(n$,$Ce),e($Ce,rXr),e(n$,tXr),e(vr,aXr),e(vr,Ut),M(s$,Ut,null),e(Ut,nXr),e(Ut,kCe),e(kCe,sXr),e(Ut,lXr),e(Ut,nf),e(nf,iXr),e(nf,SCe),e(SCe,dXr),e(nf,cXr),e(nf,gee),e(gee,fXr),e(nf,mXr),e(Ut,gXr),M(Z5,Ut,null),e(vr,hXr),e(vr,Wr),M(l$,Wr,null),e(Wr,pXr),e(Wr,RCe),e(RCe,_Xr),e(Wr,uXr),e(Wr,wn),e(wn,bXr),e(wn,PCe),e(PCe,vXr),e(wn,FXr),e(wn,BCe),e(BCe,TXr),e(wn,MXr),e(wn,ICe),e(ICe,EXr),e(wn,CXr),e(Wr,wXr),e(Wr,Se),e(Se,e3),e(e3,NCe),e(NCe,AXr),e(e3,LXr),e(e3,hee),e(hee,yXr),e(e3,xXr),e(Se,$Xr),e(Se,o3),e(o3,qCe),e(qCe,kXr),e(o3,SXr),e(o3,pee),e(pee,RXr),e(o3,PXr),e(Se,BXr),e(Se,r3),e(r3,jCe),e(jCe,IXr),e(r3,NXr),e(r3,_ee),e(_ee,qXr),e(r3,jXr),e(Se,DXr),e(Se,t3),e(t3,DCe),e(DCe,GXr),e(t3,OXr),e(t3,uee),e(uee,VXr),e(t3,XXr),e(Se,zXr),e(Se,a3),e(a3,GCe),e(GCe,QXr),e(a3,WXr),e(a3,bee),e(bee,HXr),e(a3,UXr),e(Se,JXr),e(Se,n3),e(n3,OCe),e(OCe,YXr),e(n3,KXr),e(n3,vee),e(vee,ZXr),e(n3,ezr),e(Se,ozr),e(Se,s3),e(s3,VCe),e(VCe,rzr),e(s3,tzr),e(s3,Fee),e(Fee,azr),e(s3,nzr),e(Se,szr),e(Se,l3),e(l3,XCe),e(XCe,lzr),e(l3,izr),e(l3,Tee),e(Tee,dzr),e(l3,czr),e(Se,fzr),e(Se,i3),e(i3,zCe),e(zCe,mzr),e(i3,gzr),e(i3,Mee),e(Mee,hzr),e(i3,pzr),e(Se,_zr),e(Se,d3),e(d3,QCe),e(QCe,uzr),e(d3,bzr),e(d3,Eee),e(Eee,vzr),e(d3,Fzr),e(Wr,Tzr),M(c3,Wr,null),b(f,SVe,u),b(f,sf,u),e(sf,f3),e(f3,WCe),M(i$,WCe,null),e(sf,Mzr),e(sf,HCe),e(HCe,Ezr),b(f,RVe,u),b(f,Fr,u),M(d$,Fr,null),e(Fr,Czr),e(Fr,lf),e(lf,wzr),e(lf,Cee),e(Cee,Azr),e(lf,Lzr),e(lf,wee),e(wee,yzr),e(lf,xzr),e(Fr,$zr),e(Fr,c$),e(c$,kzr),e(c$,UCe),e(UCe,Szr),e(c$,Rzr),e(Fr,Pzr),e(Fr,Jt),M(f$,Jt,null),e(Jt,Bzr),e(Jt,JCe),e(JCe,Izr),e(Jt,Nzr),e(Jt,df),e(df,qzr),e(df,YCe),e(YCe,jzr),e(df,Dzr),e(df,Aee),e(Aee,Gzr),e(df,Ozr),e(Jt,Vzr),M(m3,Jt,null),e(Fr,Xzr),e(Fr,Hr),M(m$,Hr,null),e(Hr,zzr),e(Hr,KCe),e(KCe,Qzr),e(Hr,Wzr),e(Hr,An),e(An,Hzr),e(An,ZCe),e(ZCe,Uzr),e(An,Jzr),e(An,e5e),e(e5e,Yzr),e(An,Kzr),e(An,o5e),e(o5e,Zzr),e(An,eQr),e(Hr,oQr),e(Hr,Re),e(Re,g3),e(g3,r5e),e(r5e,rQr),e(g3,tQr),e(g3,Lee),e(Lee,aQr),e(g3,nQr),e(Re,sQr),e(Re,h3),e(h3,t5e),e(t5e,lQr),e(h3,iQr),e(h3,yee),e(yee,dQr),e(h3,cQr),e(Re,fQr),e(Re,p3),e(p3,a5e),e(a5e,mQr),e(p3,gQr),e(p3,xee),e(xee,hQr),e(p3,pQr),e(Re,_Qr),e(Re,_3),e(_3,n5e),e(n5e,uQr),e(_3,bQr),e(_3,$ee),e($ee,vQr),e(_3,FQr),e(Re,TQr),e(Re,u3),e(u3,s5e),e(s5e,MQr),e(u3,EQr),e(u3,kee),e(kee,CQr),e(u3,wQr),e(Re,AQr),e(Re,b3),e(b3,l5e),e(l5e,LQr),e(b3,yQr),e(b3,See),e(See,xQr),e(b3,$Qr),e(Re,kQr),e(Re,v3),e(v3,i5e),e(i5e,SQr),e(v3,RQr),e(v3,Ree),e(Ree,PQr),e(v3,BQr),e(Re,IQr),e(Re,F3),e(F3,d5e),e(d5e,NQr),e(F3,qQr),e(F3,Pee),e(Pee,jQr),e(F3,DQr),e(Re,GQr),e(Re,T3),e(T3,c5e),e(c5e,OQr),e(T3,VQr),e(T3,Bee),e(Bee,XQr),e(T3,zQr),e(Re,QQr),e(Re,M3),e(M3,f5e),e(f5e,WQr),e(M3,HQr),e(M3,Iee),e(Iee,UQr),e(M3,JQr),e(Hr,YQr),M(E3,Hr,null),b(f,PVe,u),b(f,cf,u),e(cf,C3),e(C3,m5e),M(g$,m5e,null),e(cf,KQr),e(cf,g5e),e(g5e,ZQr),b(f,BVe,u),b(f,Tr,u),M(h$,Tr,null),e(Tr,eWr),e(Tr,ff),e(ff,oWr),e(ff,Nee),e(Nee,rWr),e(ff,tWr),e(ff,qee),e(qee,aWr),e(ff,nWr),e(Tr,sWr),e(Tr,p$),e(p$,lWr),e(p$,h5e),e(h5e,iWr),e(p$,dWr),e(Tr,cWr),e(Tr,Yt),M(_$,Yt,null),e(Yt,fWr),e(Yt,p5e),e(p5e,mWr),e(Yt,gWr),e(Yt,mf),e(mf,hWr),e(mf,_5e),e(_5e,pWr),e(mf,_Wr),e(mf,jee),e(jee,uWr),e(mf,bWr),e(Yt,vWr),M(w3,Yt,null),e(Tr,FWr),e(Tr,Ur),M(u$,Ur,null),e(Ur,TWr),e(Ur,u5e),e(u5e,MWr),e(Ur,EWr),e(Ur,Ln),e(Ln,CWr),e(Ln,b5e),e(b5e,wWr),e(Ln,AWr),e(Ln,v5e),e(v5e,LWr),e(Ln,yWr),e(Ln,F5e),e(F5e,xWr),e(Ln,$Wr),e(Ur,kWr),e(Ur,Ve),e(Ve,A3),e(A3,T5e),e(T5e,SWr),e(A3,RWr),e(A3,Dee),e(Dee,PWr),e(A3,BWr),e(Ve,IWr),e(Ve,L3),e(L3,M5e),e(M5e,NWr),e(L3,qWr),e(L3,Gee),e(Gee,jWr),e(L3,DWr),e(Ve,GWr),e(Ve,y3),e(y3,E5e),e(E5e,OWr),e(y3,VWr),e(y3,Oee),e(Oee,XWr),e(y3,zWr),e(Ve,QWr),e(Ve,x3),e(x3,C5e),e(C5e,WWr),e(x3,HWr),e(x3,Vee),e(Vee,UWr),e(x3,JWr),e(Ve,YWr),e(Ve,$3),e($3,w5e),e(w5e,KWr),e($3,ZWr),e($3,Xee),e(Xee,eHr),e($3,oHr),e(Ve,rHr),e(Ve,k3),e(k3,A5e),e(A5e,tHr),e(k3,aHr),e(k3,zee),e(zee,nHr),e(k3,sHr),e(Ve,lHr),e(Ve,S3),e(S3,L5e),e(L5e,iHr),e(S3,dHr),e(S3,Qee),e(Qee,cHr),e(S3,fHr),e(Ve,mHr),e(Ve,R3),e(R3,y5e),e(y5e,gHr),e(R3,hHr),e(R3,Wee),e(Wee,pHr),e(R3,_Hr),e(Ur,uHr),M(P3,Ur,null),b(f,IVe,u),b(f,gf,u),e(gf,B3),e(B3,x5e),M(b$,x5e,null),e(gf,bHr),e(gf,$5e),e($5e,vHr),b(f,NVe,u),b(f,Mr,u),M(v$,Mr,null),e(Mr,FHr),e(Mr,hf),e(hf,THr),e(hf,Hee),e(Hee,MHr),e(hf,EHr),e(hf,Uee),e(Uee,CHr),e(hf,wHr),e(Mr,AHr),e(Mr,F$),e(F$,LHr),e(F$,k5e),e(k5e,yHr),e(F$,xHr),e(Mr,$Hr),e(Mr,Kt),M(T$,Kt,null),e(Kt,kHr),e(Kt,S5e),e(S5e,SHr),e(Kt,RHr),e(Kt,pf),e(pf,PHr),e(pf,R5e),e(R5e,BHr),e(pf,IHr),e(pf,Jee),e(Jee,NHr),e(pf,qHr),e(Kt,jHr),M(I3,Kt,null),e(Mr,DHr),e(Mr,Jr),M(M$,Jr,null),e(Jr,GHr),e(Jr,P5e),e(P5e,OHr),e(Jr,VHr),e(Jr,yn),e(yn,XHr),e(yn,B5e),e(B5e,zHr),e(yn,QHr),e(yn,I5e),e(I5e,WHr),e(yn,HHr),e(yn,N5e),e(N5e,UHr),e(yn,JHr),e(Jr,YHr),e(Jr,Xe),e(Xe,N3),e(N3,q5e),e(q5e,KHr),e(N3,ZHr),e(N3,Yee),e(Yee,eUr),e(N3,oUr),e(Xe,rUr),e(Xe,q3),e(q3,j5e),e(j5e,tUr),e(q3,aUr),e(q3,Kee),e(Kee,nUr),e(q3,sUr),e(Xe,lUr),e(Xe,j3),e(j3,D5e),e(D5e,iUr),e(j3,dUr),e(j3,Zee),e(Zee,cUr),e(j3,fUr),e(Xe,mUr),e(Xe,D3),e(D3,G5e),e(G5e,gUr),e(D3,hUr),e(D3,eoe),e(eoe,pUr),e(D3,_Ur),e(Xe,uUr),e(Xe,G3),e(G3,O5e),e(O5e,bUr),e(G3,vUr),e(G3,ooe),e(ooe,FUr),e(G3,TUr),e(Xe,MUr),e(Xe,O3),e(O3,V5e),e(V5e,EUr),e(O3,CUr),e(O3,roe),e(roe,wUr),e(O3,AUr),e(Xe,LUr),e(Xe,V3),e(V3,X5e),e(X5e,yUr),e(V3,xUr),e(V3,toe),e(toe,$Ur),e(V3,kUr),e(Xe,SUr),e(Xe,X3),e(X3,z5e),e(z5e,RUr),e(X3,PUr),e(X3,aoe),e(aoe,BUr),e(X3,IUr),e(Jr,NUr),M(z3,Jr,null),b(f,qVe,u),b(f,_f,u),e(_f,Q3),e(Q3,Q5e),M(E$,Q5e,null),e(_f,qUr),e(_f,W5e),e(W5e,jUr),b(f,jVe,u),b(f,Er,u),M(C$,Er,null),e(Er,DUr),e(Er,uf),e(uf,GUr),e(uf,noe),e(noe,OUr),e(uf,VUr),e(uf,soe),e(soe,XUr),e(uf,zUr),e(Er,QUr),e(Er,w$),e(w$,WUr),e(w$,H5e),e(H5e,HUr),e(w$,UUr),e(Er,JUr),e(Er,Zt),M(A$,Zt,null),e(Zt,YUr),e(Zt,U5e),e(U5e,KUr),e(Zt,ZUr),e(Zt,bf),e(bf,eJr),e(bf,J5e),e(J5e,oJr),e(bf,rJr),e(bf,loe),e(loe,tJr),e(bf,aJr),e(Zt,nJr),M(W3,Zt,null),e(Er,sJr),e(Er,Yr),M(L$,Yr,null),e(Yr,lJr),e(Yr,Y5e),e(Y5e,iJr),e(Yr,dJr),e(Yr,xn),e(xn,cJr),e(xn,K5e),e(K5e,fJr),e(xn,mJr),e(xn,Z5e),e(Z5e,gJr),e(xn,hJr),e(xn,e3e),e(e3e,pJr),e(xn,_Jr),e(Yr,uJr),e(Yr,o3e),e(o3e,H3),e(H3,r3e),e(r3e,bJr),e(H3,vJr),e(H3,ioe),e(ioe,FJr),e(H3,TJr),e(Yr,MJr),M(U3,Yr,null),b(f,DVe,u),b(f,vf,u),e(vf,J3),e(J3,t3e),M(y$,t3e,null),e(vf,EJr),e(vf,a3e),e(a3e,CJr),b(f,GVe,u),b(f,Cr,u),M(x$,Cr,null),e(Cr,wJr),e(Cr,Ff),e(Ff,AJr),e(Ff,doe),e(doe,LJr),e(Ff,yJr),e(Ff,coe),e(coe,xJr),e(Ff,$Jr),e(Cr,kJr),e(Cr,$$),e($$,SJr),e($$,n3e),e(n3e,RJr),e($$,PJr),e(Cr,BJr),e(Cr,ea),M(k$,ea,null),e(ea,IJr),e(ea,s3e),e(s3e,NJr),e(ea,qJr),e(ea,Tf),e(Tf,jJr),e(Tf,l3e),e(l3e,DJr),e(Tf,GJr),e(Tf,foe),e(foe,OJr),e(Tf,VJr),e(ea,XJr),M(Y3,ea,null),e(Cr,zJr),e(Cr,Kr),M(S$,Kr,null),e(Kr,QJr),e(Kr,i3e),e(i3e,WJr),e(Kr,HJr),e(Kr,$n),e($n,UJr),e($n,d3e),e(d3e,JJr),e($n,YJr),e($n,c3e),e(c3e,KJr),e($n,ZJr),e($n,f3e),e(f3e,eYr),e($n,oYr),e(Kr,rYr),e(Kr,R$),e(R$,K3),e(K3,m3e),e(m3e,tYr),e(K3,aYr),e(K3,moe),e(moe,nYr),e(K3,sYr),e(R$,lYr),e(R$,Z3),e(Z3,g3e),e(g3e,iYr),e(Z3,dYr),e(Z3,goe),e(goe,cYr),e(Z3,fYr),e(Kr,mYr),M(e0,Kr,null),b(f,OVe,u),b(f,Mf,u),e(Mf,o0),e(o0,h3e),M(P$,h3e,null),e(Mf,gYr),e(Mf,p3e),e(p3e,hYr),b(f,VVe,u),b(f,wr,u),M(B$,wr,null),e(wr,pYr),e(wr,Ef),e(Ef,_Yr),e(Ef,hoe),e(hoe,uYr),e(Ef,bYr),e(Ef,poe),e(poe,vYr),e(Ef,FYr),e(wr,TYr),e(wr,I$),e(I$,MYr),e(I$,_3e),e(_3e,EYr),e(I$,CYr),e(wr,wYr),e(wr,oa),M(N$,oa,null),e(oa,AYr),e(oa,u3e),e(u3e,LYr),e(oa,yYr),e(oa,Cf),e(Cf,xYr),e(Cf,b3e),e(b3e,$Yr),e(Cf,kYr),e(Cf,_oe),e(_oe,SYr),e(Cf,RYr),e(oa,PYr),M(r0,oa,null),e(wr,BYr),e(wr,Zr),M(q$,Zr,null),e(Zr,IYr),e(Zr,v3e),e(v3e,NYr),e(Zr,qYr),e(Zr,kn),e(kn,jYr),e(kn,F3e),e(F3e,DYr),e(kn,GYr),e(kn,T3e),e(T3e,OYr),e(kn,VYr),e(kn,M3e),e(M3e,XYr),e(kn,zYr),e(Zr,QYr),e(Zr,E3e),e(E3e,t0),e(t0,C3e),e(C3e,WYr),e(t0,HYr),e(t0,uoe),e(uoe,UYr),e(t0,JYr),e(Zr,YYr),M(a0,Zr,null),XVe=!0},p(f,[u]){const j$={};u&2&&(j$.$$scope={dirty:u,ctx:f}),Rf.$set(j$);const w3e={};u&2&&(w3e.$$scope={dirty:u,ctx:f}),Gg.$set(w3e);const A3e={};u&2&&(A3e.$$scope={dirty:u,ctx:f}),Eh.$set(A3e);const L3e={};u&2&&(L3e.$$scope={dirty:u,ctx:f}),ap.$set(L3e);const D$={};u&2&&(D$.$$scope={dirty:u,ctx:f}),np.$set(D$);const y3e={};u&2&&(y3e.$$scope={dirty:u,ctx:f}),wp.$set(y3e);const Sn={};u&2&&(Sn.$$scope={dirty:u,ctx:f}),Ap.$set(Sn);const x3e={};u&2&&(x3e.$$scope={dirty:u,ctx:f}),xp.$set(x3e);const $3e={};u&2&&($3e.$$scope={dirty:u,ctx:f}),xu.$set($3e);const k3e={};u&2&&(k3e.$$scope={dirty:u,ctx:f}),ku.$set(k3e);const G$={};u&2&&(G$.$$scope={dirty:u,ctx:f}),E1.$set(G$);const S3e={};u&2&&(S3e.$$scope={dirty:u,ctx:f}),w1.$set(S3e);const O$={};u&2&&(O$.$$scope={dirty:u,ctx:f}),f2.$set(O$);const R3e={};u&2&&(R3e.$$scope={dirty:u,ctx:f}),g2.$set(R3e);const V$={};u&2&&(V$.$$scope={dirty:u,ctx:f}),K2.$set(V$);const P3e={};u&2&&(P3e.$$scope={dirty:u,ctx:f}),eb.$set(P3e);const B3e={};u&2&&(B3e.$$scope={dirty:u,ctx:f}),vb.$set(B3e);const I3e={};u&2&&(I3e.$$scope={dirty:u,ctx:f}),Tb.$set(I3e);const wf={};u&2&&(wf.$$scope={dirty:u,ctx:f}),b4.$set(wf);const N3e={};u&2&&(N3e.$$scope={dirty:u,ctx:f}),F4.$set(N3e);const q3e={};u&2&&(q3e.$$scope={dirty:u,ctx:f}),K4.$set(q3e);const j3e={};u&2&&(j3e.$$scope={dirty:u,ctx:f}),ev.$set(j3e);const X$={};u&2&&(X$.$$scope={dirty:u,ctx:f}),iv.$set(X$);const D3e={};u&2&&(D3e.$$scope={dirty:u,ctx:f}),cv.$set(D3e);const G3e={};u&2&&(G3e.$$scope={dirty:u,ctx:f}),Hv.$set(G3e);const O3e={};u&2&&(O3e.$$scope={dirty:u,ctx:f}),Jv.$set(O3e);const rt={};u&2&&(rt.$$scope={dirty:u,ctx:f}),jF.$set(rt);const z$={};u&2&&(z$.$$scope={dirty:u,ctx:f}),GF.$set(z$);const V3e={};u&2&&(V3e.$$scope={dirty:u,ctx:f}),XF.$set(V3e);const Q$={};u&2&&(Q$.$$scope={dirty:u,ctx:f}),QF.$set(Q$);const X3e={};u&2&&(X3e.$$scope={dirty:u,ctx:f}),s6.$set(X3e);const tt={};u&2&&(tt.$$scope={dirty:u,ctx:f}),i6.$set(tt);const z3e={};u&2&&(z3e.$$scope={dirty:u,ctx:f}),f6.$set(z3e);const Af={};u&2&&(Af.$$scope={dirty:u,ctx:f}),g6.$set(Af);const Q3e={};u&2&&(Q3e.$$scope={dirty:u,ctx:f}),_6.$set(Q3e);const W3e={};u&2&&(W3e.$$scope={dirty:u,ctx:f}),b6.$set(W3e);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),x6.$set(L);const n0={};u&2&&(n0.$$scope={dirty:u,ctx:f}),k6.$set(n0);const H3e={};u&2&&(H3e.$$scope={dirty:u,ctx:f}),q6.$set(H3e);const U3e={};u&2&&(U3e.$$scope={dirty:u,ctx:f}),D6.$set(U3e);const s0={};u&2&&(s0.$$scope={dirty:u,ctx:f}),K6.$set(s0);const J3e={};u&2&&(J3e.$$scope={dirty:u,ctx:f}),eT.$set(J3e);const Y3e={};u&2&&(Y3e.$$scope={dirty:u,ctx:f}),aT.$set(Y3e);const l0={};u&2&&(l0.$$scope={dirty:u,ctx:f}),sT.$set(l0);const K3e={};u&2&&(K3e.$$scope={dirty:u,ctx:f}),gT.$set(K3e);const Z3e={};u&2&&(Z3e.$$scope={dirty:u,ctx:f}),pT.$set(Z3e);const i0={};u&2&&(i0.$$scope={dirty:u,ctx:f}),FT.$set(i0);const e0e={};u&2&&(e0e.$$scope={dirty:u,ctx:f}),MT.$set(e0e);const o0e={};u&2&&(o0e.$$scope={dirty:u,ctx:f}),AT.$set(o0e);const d0={};u&2&&(d0.$$scope={dirty:u,ctx:f}),yT.$set(d0);const r0e={};u&2&&(r0e.$$scope={dirty:u,ctx:f}),kT.$set(r0e);const t0e={};u&2&&(t0e.$$scope={dirty:u,ctx:f}),RT.$set(t0e);const c0={};u&2&&(c0.$$scope={dirty:u,ctx:f}),jT.$set(c0);const a0e={};u&2&&(a0e.$$scope={dirty:u,ctx:f}),GT.$set(a0e);const n0e={};u&2&&(n0e.$$scope={dirty:u,ctx:f}),XT.$set(n0e);const f0={};u&2&&(f0.$$scope={dirty:u,ctx:f}),QT.$set(f0);const s0e={};u&2&&(s0e.$$scope={dirty:u,ctx:f}),j7.$set(s0e);const l0e={};u&2&&(l0e.$$scope={dirty:u,ctx:f}),G7.$set(l0e);const m0={};u&2&&(m0.$$scope={dirty:u,ctx:f}),f8.$set(m0);const i0e={};u&2&&(i0e.$$scope={dirty:u,ctx:f}),g8.$set(i0e);const d0e={};u&2&&(d0e.$$scope={dirty:u,ctx:f}),L8.$set(d0e);const g0={};u&2&&(g0.$$scope={dirty:u,ctx:f}),x8.$set(g0);const c0e={};u&2&&(c0e.$$scope={dirty:u,ctx:f}),P8.$set(c0e);const f0e={};u&2&&(f0e.$$scope={dirty:u,ctx:f}),I8.$set(f0e);const h0={};u&2&&(h0.$$scope={dirty:u,ctx:f}),tM.$set(h0);const m0e={};u&2&&(m0e.$$scope={dirty:u,ctx:f}),nM.$set(m0e);const g0e={};u&2&&(g0e.$$scope={dirty:u,ctx:f}),_M.$set(g0e);const p0={};u&2&&(p0.$$scope={dirty:u,ctx:f}),bM.$set(p0);const h0e={};u&2&&(h0e.$$scope={dirty:u,ctx:f}),zM.$set(h0e);const p0e={};u&2&&(p0e.$$scope={dirty:u,ctx:f}),WM.$set(p0e);const _0={};u&2&&(_0.$$scope={dirty:u,ctx:f}),fE.$set(_0);const _0e={};u&2&&(_0e.$$scope={dirty:u,ctx:f}),gE.$set(_0e);const u0e={};u&2&&(u0e.$$scope={dirty:u,ctx:f}),_E.$set(u0e);const u0={};u&2&&(u0.$$scope={dirty:u,ctx:f}),bE.$set(u0);const b0e={};u&2&&(b0e.$$scope={dirty:u,ctx:f}),FE.$set(b0e);const v0e={};u&2&&(v0e.$$scope={dirty:u,ctx:f}),ME.$set(v0e);const b0={};u&2&&(b0.$$scope={dirty:u,ctx:f}),VE.$set(b0);const F0e={};u&2&&(F0e.$$scope={dirty:u,ctx:f}),zE.$set(F0e);const T0e={};u&2&&(T0e.$$scope={dirty:u,ctx:f}),mC.$set(T0e);const v0={};u&2&&(v0.$$scope={dirty:u,ctx:f}),hC.$set(v0);const M0e={};u&2&&(M0e.$$scope={dirty:u,ctx:f}),_C.$set(M0e);const E0e={};u&2&&(E0e.$$scope={dirty:u,ctx:f}),bC.$set(E0e);const F0={};u&2&&(F0.$$scope={dirty:u,ctx:f}),FC.$set(F0);const C0e={};u&2&&(C0e.$$scope={dirty:u,ctx:f}),MC.$set(C0e);const w0e={};u&2&&(w0e.$$scope={dirty:u,ctx:f}),JC.$set(w0e);const T0={};u&2&&(T0.$$scope={dirty:u,ctx:f}),KC.$set(T0);const A0e={};u&2&&(A0e.$$scope={dirty:u,ctx:f}),d5.$set(A0e);const L0e={};u&2&&(L0e.$$scope={dirty:u,ctx:f}),f5.$set(L0e);const M0={};u&2&&(M0.$$scope={dirty:u,ctx:f}),w5.$set(M0);const y0e={};u&2&&(y0e.$$scope={dirty:u,ctx:f}),L5.$set(y0e);const x0e={};u&2&&(x0e.$$scope={dirty:u,ctx:f}),q5.$set(x0e);const E0={};u&2&&(E0.$$scope={dirty:u,ctx:f}),D5.$set(E0);const $0e={};u&2&&($0e.$$scope={dirty:u,ctx:f}),Y5.$set($0e);const k0e={};u&2&&(k0e.$$scope={dirty:u,ctx:f}),Z5.$set(k0e);const C0={};u&2&&(C0.$$scope={dirty:u,ctx:f}),c3.$set(C0);const S0e={};u&2&&(S0e.$$scope={dirty:u,ctx:f}),m3.$set(S0e);const R0e={};u&2&&(R0e.$$scope={dirty:u,ctx:f}),E3.$set(R0e);const w0={};u&2&&(w0.$$scope={dirty:u,ctx:f}),w3.$set(w0);const P0e={};u&2&&(P0e.$$scope={dirty:u,ctx:f}),P3.$set(P0e);const B0e={};u&2&&(B0e.$$scope={dirty:u,ctx:f}),I3.$set(B0e);const A0={};u&2&&(A0.$$scope={dirty:u,ctx:f}),z3.$set(A0);const I0e={};u&2&&(I0e.$$scope={dirty:u,ctx:f}),W3.$set(I0e);const N0e={};u&2&&(N0e.$$scope={dirty:u,ctx:f}),U3.$set(N0e);const L0={};u&2&&(L0.$$scope={dirty:u,ctx:f}),Y3.$set(L0);const q0e={};u&2&&(q0e.$$scope={dirty:u,ctx:f}),e0.$set(q0e);const j0e={};u&2&&(j0e.$$scope={dirty:u,ctx:f}),r0.$set(j0e);const y0={};u&2&&(y0.$$scope={dirty:u,ctx:f}),a0.$set(y0)},i(f){XVe||(E(d.$$.fragment,f),E(xa.$$.fragment,f),E(xA.$$.fragment,f),E($A.$$.fragment,f),E(Rf.$$.fragment,f),E(kA.$$.fragment,f),E(SA.$$.fragment,f),E(BA.$$.fragment,f),E(Gg.$$.fragment,f),E(IA.$$.fragment,f),E(NA.$$.fragment,f),E(qA.$$.fragment,f),E(GA.$$.fragment,f),E(Eh.$$.fragment,f),E(OA.$$.fragment,f),E(VA.$$.fragment,f),E(XA.$$.fragment,f),E(WA.$$.fragment,f),E(ap.$$.fragment,f),E(np.$$.fragment,f),E(HA.$$.fragment,f),E(UA.$$.fragment,f),E(JA.$$.fragment,f),E(ZA.$$.fragment,f),E(wp.$$.fragment,f),E(Ap.$$.fragment,f),E(eL.$$.fragment,f),E(oL.$$.fragment,f),E(rL.$$.fragment,f),E(aL.$$.fragment,f),E(xp.$$.fragment,f),E(nL.$$.fragment,f),E(xu.$$.fragment,f),E(sL.$$.fragment,f),E(lL.$$.fragment,f),E(dL.$$.fragment,f),E(ku.$$.fragment,f),E(cL.$$.fragment,f),E(E1.$$.fragment,f),E(fL.$$.fragment,f),E(mL.$$.fragment,f),E(hL.$$.fragment,f),E(w1.$$.fragment,f),E(pL.$$.fragment,f),E(f2.$$.fragment,f),E(_L.$$.fragment,f),E(uL.$$.fragment,f),E(vL.$$.fragment,f),E(g2.$$.fragment,f),E(FL.$$.fragment,f),E(K2.$$.fragment,f),E(TL.$$.fragment,f),E(ML.$$.fragment,f),E(CL.$$.fragment,f),E(eb.$$.fragment,f),E(wL.$$.fragment,f),E(vb.$$.fragment,f),E(AL.$$.fragment,f),E(LL.$$.fragment,f),E(xL.$$.fragment,f),E(Tb.$$.fragment,f),E($L.$$.fragment,f),E(b4.$$.fragment,f),E(kL.$$.fragment,f),E(SL.$$.fragment,f),E(PL.$$.fragment,f),E(F4.$$.fragment,f),E(BL.$$.fragment,f),E(K4.$$.fragment,f),E(IL.$$.fragment,f),E(NL.$$.fragment,f),E(jL.$$.fragment,f),E(ev.$$.fragment,f),E(DL.$$.fragment,f),E(iv.$$.fragment,f),E(GL.$$.fragment,f),E(OL.$$.fragment,f),E(XL.$$.fragment,f),E(cv.$$.fragment,f),E(zL.$$.fragment,f),E(Hv.$$.fragment,f),E(QL.$$.fragment,f),E(WL.$$.fragment,f),E(UL.$$.fragment,f),E(Jv.$$.fragment,f),E(JL.$$.fragment,f),E(jF.$$.fragment,f),E(YL.$$.fragment,f),E(KL.$$.fragment,f),E(ey.$$.fragment,f),E(GF.$$.fragment,f),E(oy.$$.fragment,f),E(XF.$$.fragment,f),E(ry.$$.fragment,f),E(ty.$$.fragment,f),E(ny.$$.fragment,f),E(QF.$$.fragment,f),E(sy.$$.fragment,f),E(s6.$$.fragment,f),E(ly.$$.fragment,f),E(iy.$$.fragment,f),E(cy.$$.fragment,f),E(i6.$$.fragment,f),E(fy.$$.fragment,f),E(f6.$$.fragment,f),E(my.$$.fragment,f),E(gy.$$.fragment,f),E(py.$$.fragment,f),E(g6.$$.fragment,f),E(_y.$$.fragment,f),E(_6.$$.fragment,f),E(uy.$$.fragment,f),E(by.$$.fragment,f),E(Fy.$$.fragment,f),E(b6.$$.fragment,f),E(Ty.$$.fragment,f),E(x6.$$.fragment,f),E(My.$$.fragment,f),E(Ey.$$.fragment,f),E(wy.$$.fragment,f),E(k6.$$.fragment,f),E(Ay.$$.fragment,f),E(q6.$$.fragment,f),E(Ly.$$.fragment,f),E(yy.$$.fragment,f),E($y.$$.fragment,f),E(D6.$$.fragment,f),E(ky.$$.fragment,f),E(K6.$$.fragment,f),E(Sy.$$.fragment,f),E(Ry.$$.fragment,f),E(By.$$.fragment,f),E(eT.$$.fragment,f),E(Iy.$$.fragment,f),E(aT.$$.fragment,f),E(qy.$$.fragment,f),E(jy.$$.fragment,f),E(Gy.$$.fragment,f),E(sT.$$.fragment,f),E(Oy.$$.fragment,f),E(gT.$$.fragment,f),E(Vy.$$.fragment,f),E(Xy.$$.fragment,f),E(Qy.$$.fragment,f),E(pT.$$.fragment,f),E(Wy.$$.fragment,f),E(FT.$$.fragment,f),E(Hy.$$.fragment,f),E(Uy.$$.fragment,f),E(Yy.$$.fragment,f),E(MT.$$.fragment,f),E(Ky.$$.fragment,f),E(AT.$$.fragment,f),E(e9.$$.fragment,f),E(o9.$$.fragment,f),E(t9.$$.fragment,f),E(yT.$$.fragment,f),E(a9.$$.fragment,f),E(kT.$$.fragment,f),E(n9.$$.fragment,f),E(s9.$$.fragment,f),E(i9.$$.fragment,f),E(RT.$$.fragment,f),E(d9.$$.fragment,f),E(jT.$$.fragment,f),E(c9.$$.fragment,f),E(f9.$$.fragment,f),E(g9.$$.fragment,f),E(GT.$$.fragment,f),E(h9.$$.fragment,f),E(XT.$$.fragment,f),E(p9.$$.fragment,f),E(_9.$$.fragment,f),E(b9.$$.fragment,f),E(QT.$$.fragment,f),E(v9.$$.fragment,f),E(j7.$$.fragment,f),E(F9.$$.fragment,f),E(T9.$$.fragment,f),E(E9.$$.fragment,f),E(G7.$$.fragment,f),E(C9.$$.fragment,f),E(f8.$$.fragment,f),E(w9.$$.fragment,f),E(A9.$$.fragment,f),E(y9.$$.fragment,f),E(g8.$$.fragment,f),E(x9.$$.fragment,f),E(L8.$$.fragment,f),E($9.$$.fragment,f),E(k9.$$.fragment,f),E(R9.$$.fragment,f),E(x8.$$.fragment,f),E(P9.$$.fragment,f),E(P8.$$.fragment,f),E(B9.$$.fragment,f),E(I9.$$.fragment,f),E(q9.$$.fragment,f),E(I8.$$.fragment,f),E(j9.$$.fragment,f),E(tM.$$.fragment,f),E(D9.$$.fragment,f),E(G9.$$.fragment,f),E(V9.$$.fragment,f),E(nM.$$.fragment,f),E(X9.$$.fragment,f),E(_M.$$.fragment,f),E(z9.$$.fragment,f),E(Q9.$$.fragment,f),E(H9.$$.fragment,f),E(bM.$$.fragment,f),E(U9.$$.fragment,f),E(zM.$$.fragment,f),E(J9.$$.fragment,f),E(Y9.$$.fragment,f),E(Z9.$$.fragment,f),E(WM.$$.fragment,f),E(ex.$$.fragment,f),E(fE.$$.fragment,f),E(ox.$$.fragment,f),E(rx.$$.fragment,f),E(ax.$$.fragment,f),E(gE.$$.fragment,f),E(nx.$$.fragment,f),E(_E.$$.fragment,f),E(lx.$$.fragment,f),E(ix.$$.fragment,f),E(cx.$$.fragment,f),E(bE.$$.fragment,f),E(fx.$$.fragment,f),E(FE.$$.fragment,f),E(mx.$$.fragment,f),E(gx.$$.fragment,f),E(px.$$.fragment,f),E(ME.$$.fragment,f),E(_x.$$.fragment,f),E(VE.$$.fragment,f),E(ux.$$.fragment,f),E(bx.$$.fragment,f),E(Fx.$$.fragment,f),E(zE.$$.fragment,f),E(Tx.$$.fragment,f),E(mC.$$.fragment,f),E(Mx.$$.fragment,f),E(Ex.$$.fragment,f),E(wx.$$.fragment,f),E(hC.$$.fragment,f),E(Ax.$$.fragment,f),E(_C.$$.fragment,f),E(Lx.$$.fragment,f),E(yx.$$.fragment,f),E($x.$$.fragment,f),E(bC.$$.fragment,f),E(kx.$$.fragment,f),E(FC.$$.fragment,f),E(Sx.$$.fragment,f),E(Rx.$$.fragment,f),E(Bx.$$.fragment,f),E(MC.$$.fragment,f),E(Ix.$$.fragment,f),E(JC.$$.fragment,f),E(Nx.$$.fragment,f),E(qx.$$.fragment,f),E(Dx.$$.fragment,f),E(KC.$$.fragment,f),E(Gx.$$.fragment,f),E(d5.$$.fragment,f),E(Ox.$$.fragment,f),E(Vx.$$.fragment,f),E(zx.$$.fragment,f),E(f5.$$.fragment,f),E(Qx.$$.fragment,f),E(w5.$$.fragment,f),E(Wx.$$.fragment,f),E(Hx.$$.fragment,f),E(Jx.$$.fragment,f),E(L5.$$.fragment,f),E(Yx.$$.fragment,f),E(q5.$$.fragment,f),E(Kx.$$.fragment,f),E(Zx.$$.fragment,f),E(o$.$$.fragment,f),E(D5.$$.fragment,f),E(r$.$$.fragment,f),E(Y5.$$.fragment,f),E(t$.$$.fragment,f),E(a$.$$.fragment,f),E(s$.$$.fragment,f),E(Z5.$$.fragment,f),E(l$.$$.fragment,f),E(c3.$$.fragment,f),E(i$.$$.fragment,f),E(d$.$$.fragment,f),E(f$.$$.fragment,f),E(m3.$$.fragment,f),E(m$.$$.fragment,f),E(E3.$$.fragment,f),E(g$.$$.fragment,f),E(h$.$$.fragment,f),E(_$.$$.fragment,f),E(w3.$$.fragment,f),E(u$.$$.fragment,f),E(P3.$$.fragment,f),E(b$.$$.fragment,f),E(v$.$$.fragment,f),E(T$.$$.fragment,f),E(I3.$$.fragment,f),E(M$.$$.fragment,f),E(z3.$$.fragment,f),E(E$.$$.fragment,f),E(C$.$$.fragment,f),E(A$.$$.fragment,f),E(W3.$$.fragment,f),E(L$.$$.fragment,f),E(U3.$$.fragment,f),E(y$.$$.fragment,f),E(x$.$$.fragment,f),E(k$.$$.fragment,f),E(Y3.$$.fragment,f),E(S$.$$.fragment,f),E(e0.$$.fragment,f),E(P$.$$.fragment,f),E(B$.$$.fragment,f),E(N$.$$.fragment,f),E(r0.$$.fragment,f),E(q$.$$.fragment,f),E(a0.$$.fragment,f),XVe=!0)},o(f){C(d.$$.fragment,f),C(xa.$$.fragment,f),C(xA.$$.fragment,f),C($A.$$.fragment,f),C(Rf.$$.fragment,f),C(kA.$$.fragment,f),C(SA.$$.fragment,f),C(BA.$$.fragment,f),C(Gg.$$.fragment,f),C(IA.$$.fragment,f),C(NA.$$.fragment,f),C(qA.$$.fragment,f),C(GA.$$.fragment,f),C(Eh.$$.fragment,f),C(OA.$$.fragment,f),C(VA.$$.fragment,f),C(XA.$$.fragment,f),C(WA.$$.fragment,f),C(ap.$$.fragment,f),C(np.$$.fragment,f),C(HA.$$.fragment,f),C(UA.$$.fragment,f),C(JA.$$.fragment,f),C(ZA.$$.fragment,f),C(wp.$$.fragment,f),C(Ap.$$.fragment,f),C(eL.$$.fragment,f),C(oL.$$.fragment,f),C(rL.$$.fragment,f),C(aL.$$.fragment,f),C(xp.$$.fragment,f),C(nL.$$.fragment,f),C(xu.$$.fragment,f),C(sL.$$.fragment,f),C(lL.$$.fragment,f),C(dL.$$.fragment,f),C(ku.$$.fragment,f),C(cL.$$.fragment,f),C(E1.$$.fragment,f),C(fL.$$.fragment,f),C(mL.$$.fragment,f),C(hL.$$.fragment,f),C(w1.$$.fragment,f),C(pL.$$.fragment,f),C(f2.$$.fragment,f),C(_L.$$.fragment,f),C(uL.$$.fragment,f),C(vL.$$.fragment,f),C(g2.$$.fragment,f),C(FL.$$.fragment,f),C(K2.$$.fragment,f),C(TL.$$.fragment,f),C(ML.$$.fragment,f),C(CL.$$.fragment,f),C(eb.$$.fragment,f),C(wL.$$.fragment,f),C(vb.$$.fragment,f),C(AL.$$.fragment,f),C(LL.$$.fragment,f),C(xL.$$.fragment,f),C(Tb.$$.fragment,f),C($L.$$.fragment,f),C(b4.$$.fragment,f),C(kL.$$.fragment,f),C(SL.$$.fragment,f),C(PL.$$.fragment,f),C(F4.$$.fragment,f),C(BL.$$.fragment,f),C(K4.$$.fragment,f),C(IL.$$.fragment,f),C(NL.$$.fragment,f),C(jL.$$.fragment,f),C(ev.$$.fragment,f),C(DL.$$.fragment,f),C(iv.$$.fragment,f),C(GL.$$.fragment,f),C(OL.$$.fragment,f),C(XL.$$.fragment,f),C(cv.$$.fragment,f),C(zL.$$.fragment,f),C(Hv.$$.fragment,f),C(QL.$$.fragment,f),C(WL.$$.fragment,f),C(UL.$$.fragment,f),C(Jv.$$.fragment,f),C(JL.$$.fragment,f),C(jF.$$.fragment,f),C(YL.$$.fragment,f),C(KL.$$.fragment,f),C(ey.$$.fragment,f),C(GF.$$.fragment,f),C(oy.$$.fragment,f),C(XF.$$.fragment,f),C(ry.$$.fragment,f),C(ty.$$.fragment,f),C(ny.$$.fragment,f),C(QF.$$.fragment,f),C(sy.$$.fragment,f),C(s6.$$.fragment,f),C(ly.$$.fragment,f),C(iy.$$.fragment,f),C(cy.$$.fragment,f),C(i6.$$.fragment,f),C(fy.$$.fragment,f),C(f6.$$.fragment,f),C(my.$$.fragment,f),C(gy.$$.fragment,f),C(py.$$.fragment,f),C(g6.$$.fragment,f),C(_y.$$.fragment,f),C(_6.$$.fragment,f),C(uy.$$.fragment,f),C(by.$$.fragment,f),C(Fy.$$.fragment,f),C(b6.$$.fragment,f),C(Ty.$$.fragment,f),C(x6.$$.fragment,f),C(My.$$.fragment,f),C(Ey.$$.fragment,f),C(wy.$$.fragment,f),C(k6.$$.fragment,f),C(Ay.$$.fragment,f),C(q6.$$.fragment,f),C(Ly.$$.fragment,f),C(yy.$$.fragment,f),C($y.$$.fragment,f),C(D6.$$.fragment,f),C(ky.$$.fragment,f),C(K6.$$.fragment,f),C(Sy.$$.fragment,f),C(Ry.$$.fragment,f),C(By.$$.fragment,f),C(eT.$$.fragment,f),C(Iy.$$.fragment,f),C(aT.$$.fragment,f),C(qy.$$.fragment,f),C(jy.$$.fragment,f),C(Gy.$$.fragment,f),C(sT.$$.fragment,f),C(Oy.$$.fragment,f),C(gT.$$.fragment,f),C(Vy.$$.fragment,f),C(Xy.$$.fragment,f),C(Qy.$$.fragment,f),C(pT.$$.fragment,f),C(Wy.$$.fragment,f),C(FT.$$.fragment,f),C(Hy.$$.fragment,f),C(Uy.$$.fragment,f),C(Yy.$$.fragment,f),C(MT.$$.fragment,f),C(Ky.$$.fragment,f),C(AT.$$.fragment,f),C(e9.$$.fragment,f),C(o9.$$.fragment,f),C(t9.$$.fragment,f),C(yT.$$.fragment,f),C(a9.$$.fragment,f),C(kT.$$.fragment,f),C(n9.$$.fragment,f),C(s9.$$.fragment,f),C(i9.$$.fragment,f),C(RT.$$.fragment,f),C(d9.$$.fragment,f),C(jT.$$.fragment,f),C(c9.$$.fragment,f),C(f9.$$.fragment,f),C(g9.$$.fragment,f),C(GT.$$.fragment,f),C(h9.$$.fragment,f),C(XT.$$.fragment,f),C(p9.$$.fragment,f),C(_9.$$.fragment,f),C(b9.$$.fragment,f),C(QT.$$.fragment,f),C(v9.$$.fragment,f),C(j7.$$.fragment,f),C(F9.$$.fragment,f),C(T9.$$.fragment,f),C(E9.$$.fragment,f),C(G7.$$.fragment,f),C(C9.$$.fragment,f),C(f8.$$.fragment,f),C(w9.$$.fragment,f),C(A9.$$.fragment,f),C(y9.$$.fragment,f),C(g8.$$.fragment,f),C(x9.$$.fragment,f),C(L8.$$.fragment,f),C($9.$$.fragment,f),C(k9.$$.fragment,f),C(R9.$$.fragment,f),C(x8.$$.fragment,f),C(P9.$$.fragment,f),C(P8.$$.fragment,f),C(B9.$$.fragment,f),C(I9.$$.fragment,f),C(q9.$$.fragment,f),C(I8.$$.fragment,f),C(j9.$$.fragment,f),C(tM.$$.fragment,f),C(D9.$$.fragment,f),C(G9.$$.fragment,f),C(V9.$$.fragment,f),C(nM.$$.fragment,f),C(X9.$$.fragment,f),C(_M.$$.fragment,f),C(z9.$$.fragment,f),C(Q9.$$.fragment,f),C(H9.$$.fragment,f),C(bM.$$.fragment,f),C(U9.$$.fragment,f),C(zM.$$.fragment,f),C(J9.$$.fragment,f),C(Y9.$$.fragment,f),C(Z9.$$.fragment,f),C(WM.$$.fragment,f),C(ex.$$.fragment,f),C(fE.$$.fragment,f),C(ox.$$.fragment,f),C(rx.$$.fragment,f),C(ax.$$.fragment,f),C(gE.$$.fragment,f),C(nx.$$.fragment,f),C(_E.$$.fragment,f),C(lx.$$.fragment,f),C(ix.$$.fragment,f),C(cx.$$.fragment,f),C(bE.$$.fragment,f),C(fx.$$.fragment,f),C(FE.$$.fragment,f),C(mx.$$.fragment,f),C(gx.$$.fragment,f),C(px.$$.fragment,f),C(ME.$$.fragment,f),C(_x.$$.fragment,f),C(VE.$$.fragment,f),C(ux.$$.fragment,f),C(bx.$$.fragment,f),C(Fx.$$.fragment,f),C(zE.$$.fragment,f),C(Tx.$$.fragment,f),C(mC.$$.fragment,f),C(Mx.$$.fragment,f),C(Ex.$$.fragment,f),C(wx.$$.fragment,f),C(hC.$$.fragment,f),C(Ax.$$.fragment,f),C(_C.$$.fragment,f),C(Lx.$$.fragment,f),C(yx.$$.fragment,f),C($x.$$.fragment,f),C(bC.$$.fragment,f),C(kx.$$.fragment,f),C(FC.$$.fragment,f),C(Sx.$$.fragment,f),C(Rx.$$.fragment,f),C(Bx.$$.fragment,f),C(MC.$$.fragment,f),C(Ix.$$.fragment,f),C(JC.$$.fragment,f),C(Nx.$$.fragment,f),C(qx.$$.fragment,f),C(Dx.$$.fragment,f),C(KC.$$.fragment,f),C(Gx.$$.fragment,f),C(d5.$$.fragment,f),C(Ox.$$.fragment,f),C(Vx.$$.fragment,f),C(zx.$$.fragment,f),C(f5.$$.fragment,f),C(Qx.$$.fragment,f),C(w5.$$.fragment,f),C(Wx.$$.fragment,f),C(Hx.$$.fragment,f),C(Jx.$$.fragment,f),C(L5.$$.fragment,f),C(Yx.$$.fragment,f),C(q5.$$.fragment,f),C(Kx.$$.fragment,f),C(Zx.$$.fragment,f),C(o$.$$.fragment,f),C(D5.$$.fragment,f),C(r$.$$.fragment,f),C(Y5.$$.fragment,f),C(t$.$$.fragment,f),C(a$.$$.fragment,f),C(s$.$$.fragment,f),C(Z5.$$.fragment,f),C(l$.$$.fragment,f),C(c3.$$.fragment,f),C(i$.$$.fragment,f),C(d$.$$.fragment,f),C(f$.$$.fragment,f),C(m3.$$.fragment,f),C(m$.$$.fragment,f),C(E3.$$.fragment,f),C(g$.$$.fragment,f),C(h$.$$.fragment,f),C(_$.$$.fragment,f),C(w3.$$.fragment,f),C(u$.$$.fragment,f),C(P3.$$.fragment,f),C(b$.$$.fragment,f),C(v$.$$.fragment,f),C(T$.$$.fragment,f),C(I3.$$.fragment,f),C(M$.$$.fragment,f),C(z3.$$.fragment,f),C(E$.$$.fragment,f),C(C$.$$.fragment,f),C(A$.$$.fragment,f),C(W3.$$.fragment,f),C(L$.$$.fragment,f),C(U3.$$.fragment,f),C(y$.$$.fragment,f),C(x$.$$.fragment,f),C(k$.$$.fragment,f),C(Y3.$$.fragment,f),C(S$.$$.fragment,f),C(e0.$$.fragment,f),C(P$.$$.fragment,f),C(B$.$$.fragment,f),C(N$.$$.fragment,f),C(r0.$$.fragment,f),C(q$.$$.fragment,f),C(a0.$$.fragment,f),XVe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(yf),f&&t(at),f&&t(Oe),f&&t(Qe),f&&t($f),w(xa,f),f&&t(We),f&&t(Ae),f&&t(Co),f&&t($a),f&&t(jGe),f&&t(yi),w(xA),f&&t(DGe),f&&t(Nn),f&&t(GGe),w($A,f),f&&t(OGe),f&&t(lS),f&&t(VGe),w(Rf,f),f&&t(XGe),f&&t(xi),w(kA),f&&t(zGe),f&&t(wo),w(SA),w(BA),w(Gg),w(IA),f&&t(QGe),f&&t(ki),w(NA),f&&t(WGe),f&&t(Ao),w(qA),w(GA),w(Eh),w(OA),f&&t(HGe),f&&t(Si),w(VA),f&&t(UGe),f&&t(Lo),w(XA),w(WA),w(ap),w(np),w(HA),f&&t(JGe),f&&t(Ri),w(UA),f&&t(YGe),f&&t(yo),w(JA),w(ZA),w(wp),w(Ap),w(eL),f&&t(KGe),f&&t(Bi),w(oL),f&&t(ZGe),f&&t(xo),w(rL),w(aL),w(xp),w(nL),w(xu),f&&t(eOe),f&&t(qi),w(sL),f&&t(oOe),f&&t($o),w(lL),w(dL),w(ku),w(cL),w(E1),f&&t(rOe),f&&t(Gi),w(fL),f&&t(tOe),f&&t(ko),w(mL),w(hL),w(w1),w(pL),w(f2),f&&t(aOe),f&&t(Xi),w(_L),f&&t(nOe),f&&t(So),w(uL),w(vL),w(g2),w(FL),w(K2),f&&t(sOe),f&&t(Wi),w(TL),f&&t(lOe),f&&t(Ro),w(ML),w(CL),w(eb),w(wL),w(vb),f&&t(iOe),f&&t(Ji),w(AL),f&&t(dOe),f&&t(Po),w(LL),w(xL),w(Tb),w($L),w(b4),f&&t(cOe),f&&t(Zi),w(kL),f&&t(fOe),f&&t(Bo),w(SL),w(PL),w(F4),w(BL),w(K4),f&&t(mOe),f&&t(rd),w(IL),f&&t(gOe),f&&t(Io),w(NL),w(jL),w(ev),w(DL),w(iv),f&&t(hOe),f&&t(nd),w(GL),f&&t(pOe),f&&t(qo),w(OL),w(XL),w(cv),w(zL),w(Hv),f&&t(_Oe),f&&t(id),w(QL),f&&t(uOe),f&&t(jo),w(WL),w(UL),w(Jv),w(JL),w(jF),f&&t(bOe),f&&t(fd),w(YL),f&&t(vOe),f&&t(Do),w(KL),w(ey),w(GF),w(oy),w(XF),f&&t(FOe),f&&t(hd),w(ry),f&&t(TOe),f&&t(Go),w(ty),w(ny),w(QF),w(sy),w(s6),f&&t(MOe),f&&t(ud),w(ly),f&&t(EOe),f&&t(Oo),w(iy),w(cy),w(i6),w(fy),w(f6),f&&t(COe),f&&t(Fd),w(my),f&&t(wOe),f&&t(Vo),w(gy),w(py),w(g6),w(_y),w(_6),f&&t(AOe),f&&t(Ed),w(uy),f&&t(LOe),f&&t(Xo),w(by),w(Fy),w(b6),w(Ty),w(x6),f&&t(yOe),f&&t(Ad),w(My),f&&t(xOe),f&&t(zo),w(Ey),w(wy),w(k6),w(Ay),w(q6),f&&t($Oe),f&&t(xd),w(Ly),f&&t(kOe),f&&t(Qo),w(yy),w($y),w(D6),w(ky),w(K6),f&&t(SOe),f&&t(Sd),w(Sy),f&&t(ROe),f&&t(Wo),w(Ry),w(By),w(eT),w(Iy),w(aT),f&&t(POe),f&&t(Bd),w(qy),f&&t(BOe),f&&t(Ho),w(jy),w(Gy),w(sT),w(Oy),w(gT),f&&t(IOe),f&&t(qd),w(Vy),f&&t(NOe),f&&t(Uo),w(Xy),w(Qy),w(pT),w(Wy),w(FT),f&&t(qOe),f&&t(Od),w(Hy),f&&t(jOe),f&&t(Jo),w(Uy),w(Yy),w(MT),w(Ky),w(AT),f&&t(DOe),f&&t(zd),w(e9),f&&t(GOe),f&&t(Yo),w(o9),w(t9),w(yT),w(a9),w(kT),f&&t(OOe),f&&t(Hd),w(n9),f&&t(VOe),f&&t(Ko),w(s9),w(i9),w(RT),w(d9),w(jT),f&&t(XOe),f&&t(Yd),w(c9),f&&t(zOe),f&&t(Zo),w(f9),w(g9),w(GT),w(h9),w(XT),f&&t(QOe),f&&t(ec),w(p9),f&&t(WOe),f&&t(er),w(_9),w(b9),w(QT),w(v9),w(j7),f&&t(HOe),f&&t(tc),w(F9),f&&t(UOe),f&&t(or),w(T9),w(E9),w(G7),w(C9),w(f8),f&&t(JOe),f&&t(sc),w(w9),f&&t(YOe),f&&t(rr),w(A9),w(y9),w(g8),w(x9),w(L8),f&&t(KOe),f&&t(dc),w($9),f&&t(ZOe),f&&t(tr),w(k9),w(R9),w(x8),w(P9),w(P8),f&&t(eVe),f&&t(mc),w(B9),f&&t(oVe),f&&t(ar),w(I9),w(q9),w(I8),w(j9),w(tM),f&&t(rVe),f&&t(pc),w(D9),f&&t(tVe),f&&t(nr),w(G9),w(V9),w(nM),w(X9),w(_M),f&&t(aVe),f&&t(bc),w(z9),f&&t(nVe),f&&t(sr),w(Q9),w(H9),w(bM),w(U9),w(zM),f&&t(sVe),f&&t(Tc),w(J9),f&&t(lVe),f&&t(lr),w(Y9),w(Z9),w(WM),w(ex),w(fE),f&&t(iVe),f&&t(Cc),w(ox),f&&t(dVe),f&&t(ir),w(rx),w(ax),w(gE),w(nx),w(_E),f&&t(cVe),f&&t(Lc),w(lx),f&&t(fVe),f&&t(dr),w(ix),w(cx),w(bE),w(fx),w(FE),f&&t(mVe),f&&t($c),w(mx),f&&t(gVe),f&&t(cr),w(gx),w(px),w(ME),w(_x),w(VE),f&&t(hVe),f&&t(Rc),w(ux),f&&t(pVe),f&&t(fr),w(bx),w(Fx),w(zE),w(Tx),w(mC),f&&t(_Ve),f&&t(Ic),w(Mx),f&&t(uVe),f&&t(mr),w(Ex),w(wx),w(hC),w(Ax),w(_C),f&&t(bVe),f&&t(jc),w(Lx),f&&t(vVe),f&&t(gr),w(yx),w($x),w(bC),w(kx),w(FC),f&&t(FVe),f&&t(Oc),w(Sx),f&&t(TVe),f&&t(hr),w(Rx),w(Bx),w(MC),w(Ix),w(JC),f&&t(MVe),f&&t(zc),w(Nx),f&&t(EVe),f&&t(pr),w(qx),w(Dx),w(KC),w(Gx),w(d5),f&&t(CVe),f&&t(Hc),w(Ox),f&&t(wVe),f&&t(_r),w(Vx),w(zx),w(f5),w(Qx),w(w5),f&&t(AVe),f&&t(Yc),w(Wx),f&&t(LVe),f&&t(ur),w(Hx),w(Jx),w(L5),w(Yx),w(q5),f&&t(yVe),f&&t(ef),w(Kx),f&&t(xVe),f&&t(br),w(Zx),w(o$),w(D5),w(r$),w(Y5),f&&t($Ve),f&&t(tf),w(t$),f&&t(kVe),f&&t(vr),w(a$),w(s$),w(Z5),w(l$),w(c3),f&&t(SVe),f&&t(sf),w(i$),f&&t(RVe),f&&t(Fr),w(d$),w(f$),w(m3),w(m$),w(E3),f&&t(PVe),f&&t(cf),w(g$),f&&t(BVe),f&&t(Tr),w(h$),w(_$),w(w3),w(u$),w(P3),f&&t(IVe),f&&t(gf),w(b$),f&&t(NVe),f&&t(Mr),w(v$),w(T$),w(I3),w(M$),w(z3),f&&t(qVe),f&&t(_f),w(E$),f&&t(jVe),f&&t(Er),w(C$),w(A$),w(W3),w(L$),w(U3),f&&t(DVe),f&&t(vf),w(y$),f&&t(GVe),f&&t(Cr),w(x$),w(k$),w(Y3),w(S$),w(e0),f&&t(OVe),f&&t(Mf),w(P$),f&&t(VVe),f&&t(wr),w(B$),w(N$),w(r0),w(q$),w(a0)}}}const COt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function wOt(x){return EDt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class SOt extends vDt{constructor(g){super();FDt(this,g,wOt,EOt,TDt,{})}}export{SOt as default,COt as metadata};
