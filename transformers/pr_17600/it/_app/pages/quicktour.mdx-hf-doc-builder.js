import{S as Wt,i as Xt,s as ea,O as R,t as r,P as U,a as p,h as n,d as l,b as h,g as d,G as o,L as he,e as c,w as M,k as _,c as u,x as D,m as v,y as S,Q as cn,q as E,o as j,B as y,n as Ca,p as qa,U as ec,v as Xp,V as us,$ as tc,Z as ac,F as Oo,H as xo,I as Lo,J as No,M as oc}from"../chunks/vendor-hf-doc-builder.js";import{T as Aa,C as Y}from"../chunks/CodeBlock-hf-doc-builder.js";import{A as Qe,b as lc,I as sc,a as ic,D as rc,Y as Qp}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";import{I as vt}from"../chunks/IconCopyLink-hf-doc-builder.js";function nc($){let e,i,a,s,f,g,k,w,b,C,A,F,I,H,T,x,z,q,G,Q,L,K,Z,J,V,se,oe,le,ce,re,ue,ie,X,ne,fe,O,N,te,P,B,pe;return{c(){e=R("svg"),i=R("style"),a=r(`.J {
			stroke: #dce0df;
		}
		.K {
			stroke-linejoin: round;
		}
	`),s=R("g"),f=R("path"),g=R("path"),k=R("path"),w=R("path"),b=R("path"),C=R("path"),A=R("path"),F=R("path"),I=R("g"),H=R("path"),T=R("path"),x=R("path"),z=R("g"),q=R("path"),G=R("path"),Q=R("path"),L=R("g"),K=R("path"),Z=R("path"),J=R("g"),V=R("path"),se=R("path"),oe=R("path"),le=R("path"),ce=R("path"),re=R("path"),ue=R("path"),ie=R("path"),X=R("g"),ne=R("path"),fe=R("path"),O=R("path"),N=R("path"),te=R("g"),P=R("path"),B=R("path"),pe=R("path"),this.h()},l($e){e=U($e,"svg",{class:!0,xmlns:!0,"xmlns:xlink":!0,"aria-hidden":!0,focusable:!0,role:!0,width:!0,height:!0,preserveAspectRatio:!0,viewBox:!0});var W=p(e);i=U(W,"style",{});var be=p(i);a=n(be,`.J {
			stroke: #dce0df;
		}
		.K {
			stroke-linejoin: round;
		}
	`),be.forEach(l),s=U(W,"g",{fill:!0,class:!0});var ae=p(s);f=U(ae,"path",{d:!0}),p(f).forEach(l),g=U(ae,"path",{d:!0}),p(g).forEach(l),k=U(ae,"path",{d:!0}),p(k).forEach(l),w=U(ae,"path",{d:!0}),p(w).forEach(l),b=U(ae,"path",{d:!0}),p(b).forEach(l),C=U(ae,"path",{d:!0}),p(C).forEach(l),A=U(ae,"path",{d:!0}),p(A).forEach(l),F=U(ae,"path",{d:!0}),p(F).forEach(l),ae.forEach(l),I=U(W,"g",{fill:!0,class:!0});var Ee=p(I);H=U(Ee,"path",{d:!0}),p(H).forEach(l),T=U(Ee,"path",{d:!0}),p(T).forEach(l),x=U(Ee,"path",{d:!0}),p(x).forEach(l),Ee.forEach(l),z=U(W,"g",{fill:!0,class:!0});var ve=p(z);q=U(ve,"path",{d:!0}),p(q).forEach(l),G=U(ve,"path",{d:!0}),p(G).forEach(l),ve.forEach(l),Q=U(W,"path",{d:!0,fill:!0,class:!0}),p(Q).forEach(l),L=U(W,"g",{fill:!0,class:!0});var Ae=p(L);K=U(Ae,"path",{d:!0}),p(K).forEach(l),Z=U(Ae,"path",{d:!0}),p(Z).forEach(l),Ae.forEach(l),J=U(W,"g",{fill:!0,class:!0});var ge=p(J);V=U(ge,"path",{d:!0}),p(V).forEach(l),se=U(ge,"path",{d:!0}),p(se).forEach(l),oe=U(ge,"path",{d:!0}),p(oe).forEach(l),le=U(ge,"path",{d:!0}),p(le).forEach(l),ce=U(ge,"path",{d:!0}),p(ce).forEach(l),re=U(ge,"path",{d:!0}),p(re).forEach(l),ue=U(ge,"path",{d:!0}),p(ue).forEach(l),ge.forEach(l),ie=U(W,"path",{d:!0,fill:!0,class:!0}),p(ie).forEach(l),X=U(W,"g",{fill:!0,class:!0});var ee=p(X);ne=U(ee,"path",{d:!0}),p(ne).forEach(l),fe=U(ee,"path",{d:!0}),p(fe).forEach(l),O=U(ee,"path",{d:!0}),p(O).forEach(l),N=U(ee,"path",{d:!0}),p(N).forEach(l),ee.forEach(l),te=U(W,"g",{fill:!0,class:!0});var Ce=p(te);P=U(Ce,"path",{d:!0}),p(P).forEach(l),B=U(Ce,"path",{d:!0}),p(B).forEach(l),pe=U(Ce,"path",{d:!0}),p(pe).forEach(l),Ce.forEach(l),W.forEach(l),this.h()},h(){h(f,"d","M50.5 130.4l-25 43.31h50l25-43.31h-50z"),h(g,"d","M.5 217.01l25-43.3h50l-25 43.3H.5z"),h(k,"d","M125.5 173.71h-50l-25 43.3h50l25-43.3z"),h(w,"d","M175.5 173.71h-50l-25 43.3h50l25-43.3z"),h(b,"d","M150.5 130.4l-25 43.31h50l25-43.31h-50z"),h(C,"d","M175.5 87.1l-25 43.3h50l25-43.3h-50z"),h(A,"d","M200.5 43.8l-25 43.3h50l25-43.3h-50z"),h(F,"d","M225.5.5l-25 43.3h50l25-43.3h-50z"),h(s,"fill","#5e97f6"),h(s,"class","J K"),h(H,"d","M.5 217.01l25 43.3h50l-25-43.3H.5z"),h(T,"d","M125.5 260.31h-50l-25-43.3h50l25 43.3z"),h(x,"d","M175.5 260.31h-50l-25-43.3h50l25 43.3z"),h(I,"fill","#2a56c6"),h(I,"class","J K"),h(q,"d","M200.5 217.01l-25-43.3-25 43.3 25 43.3 25-43.3zm50-86.61l-25-43.3-25 43.3h50z"),h(G,"d","M250.5 43.8l-25 43.3 25 43.3 25-43.3-25-43.3z"),h(z,"fill","#00796b"),h(z,"class","J K"),h(Q,"d","M125.5 173.71l-25-43.31-25 43.31h50z"),h(Q,"fill","#3367d6"),h(Q,"class","J K"),h(K,"d","M250.5 130.4h-50l-25 43.31h50l25-43.31z"),h(Z,"d","M300.5 130.4h-50l-25 43.31h50l25-43.31z"),h(L,"fill","#26a69a"),h(L,"class","J K"),h(V,"d","M350.5 43.8L325.5.5l-25 43.3 25 43.3 25-43.3z"),h(se,"d","M375.5 87.1l-25-43.3-25 43.3 25 43.3 25-43.3z"),h(oe,"d","M400.5 130.4l-25-43.3-25 43.3 25 43.31 25-43.31z"),h(le,"d","M425.5 173.71l-25-43.31-25 43.31 25 43.3 25-43.3z"),h(ce,"d","M450.5 217.01l-25-43.3-25 43.3 25 43.3 25-43.3zM425.5.5l-25 43.3 25 43.3 25-43.3-25-43.3z"),h(re,"d","M375.5 87.1l25-43.3 25 43.3-25 43.3-25-43.3zm-25 43.3l-25 43.31 25 43.3 25-43.3-25-43.31z"),h(ue,"d","M325.5 260.31l-25-43.3 25-43.3 25 43.3-25 43.3z"),h(J,"fill","#9c27b0"),h(J,"class","J K"),h(ie,"d","M275.5 260.31l-25-43.3h50l25 43.3h-50z"),h(ie,"fill","#6a1b9a"),h(ie,"class","J K"),h(ne,"d","M225.5 173.71h-50l25 43.3h50l-25-43.3z"),h(fe,"d","M275.5 173.71h-50l25 43.3 25-43.3zm0-86.61l25 43.3h50l-25-43.3h-50z"),h(O,"d","M300.5 43.8h-50l25 43.3h50l-25-43.3zm125 216.51l-25-43.3h-50l25 43.3h50z"),h(N,"d","M375.5 173.71l-25 43.3h50l-25-43.3z"),h(X,"fill","#00695c"),h(X,"class","J K"),h(P,"d","M325.5.5h-50l-25 43.3h50l25-43.3zm0 173.21h-50l-25 43.3h50l25-43.3z"),h(B,"d","M350.5 130.4h-50l-25 43.31h50l25-43.31zM425.5.5h-50l-25 43.3h50l25-43.3z"),h(pe,"d","M375.5 87.1l-25-43.3h50l-25 43.3z"),h(te,"fill","#ea80fc"),h(te,"class","J K"),h(e,"class",$[0]),h(e,"xmlns","http://www.w3.org/2000/svg"),h(e,"xmlns:xlink","http://www.w3.org/1999/xlink"),h(e,"aria-hidden","true"),h(e,"focusable","false"),h(e,"role","img"),h(e,"width","1.73em"),h(e,"height","1em"),h(e,"preserveAspectRatio","xMidYMid meet"),h(e,"viewBox","0 0 451 260.81")},m($e,W){d($e,e,W),o(e,i),o(i,a),o(e,s),o(s,f),o(s,g),o(s,k),o(s,w),o(s,b),o(s,C),o(s,A),o(s,F),o(e,I),o(I,H),o(I,T),o(I,x),o(e,z),o(z,q),o(z,G),o(e,Q),o(e,L),o(L,K),o(L,Z),o(e,J),o(J,V),o(J,se),o(J,oe),o(J,le),o(J,ce),o(J,re),o(J,ue),o(e,ie),o(e,X),o(X,ne),o(X,fe),o(X,O),o(X,N),o(e,te),o(te,P),o(te,B),o(te,pe)},p($e,[W]){W&1&&h(e,"class",$e[0])},i:he,o:he,d($e){$e&&l(e)}}}function pc($,e,i){let{classNames:a=""}=e;return $.$$set=s=>{"classNames"in s&&i(0,a=s.classNames)},[a]}class cc extends Wt{constructor(e){super();Xt(this,e,pc,nc,ea,{classNames:0})}}function uc($){let e,i;return{c(){e=R("svg"),i=R("path"),this.h()},l(a){e=U(a,"svg",{class:!0,width:!0,height:!0,viewBox:!0,fill:!0,xmlns:!0});var s=p(e);i=U(s,"path",{d:!0,fill:!0}),p(i).forEach(l),s.forEach(l),this.h()},h(){h(i,"d","M0 4.50001C0.390979 2.37042 2.25728 0.756592 4.5 0.756592C6.74272 0.756592 8.60861 2.37042 9 4.50001C8.60902 6.62959 6.74272 8.24342 4.5 8.24342C2.25728 8.24342 0.391395 6.62959 0 4.50001ZM4.5 6.57968C5.05156 6.57968 5.58054 6.36057 5.97055 5.97056C6.36057 5.58054 6.57967 5.05157 6.57967 4.50001C6.57967 3.94844 6.36057 3.41947 5.97055 3.02945C5.58054 2.63944 5.05156 2.42033 4.5 2.42033C3.94844 2.42033 3.41946 2.63944 3.02945 3.02945C2.63943 3.41947 2.42033 3.94844 2.42033 4.50001C2.42033 5.05157 2.63943 5.58054 3.02945 5.97056C3.41946 6.36057 3.94844 6.57968 4.5 6.57968ZM4.5 5.74781C4.16906 5.74781 3.85168 5.61635 3.61767 5.38234C3.38366 5.14833 3.2522 4.83094 3.2522 4.50001C3.2522 4.16907 3.38366 3.85168 3.61767 3.61767C3.85168 3.38367 4.16906 3.2522 4.5 3.2522C4.83094 3.2522 5.14832 3.38367 5.38233 3.61767C5.61634 3.85168 5.7478 4.16907 5.7478 4.50001C5.7478 4.83094 5.61634 5.14833 5.38233 5.38234C5.14832 5.61635 4.83094 5.74781 4.5 5.74781Z"),h(i,"fill","currentColor"),h(e,"class",$[0]),h(e,"width",$[1]),h(e,"height",$[1]),h(e,"viewBox","0 0 9 9"),h(e,"fill","currentColor"),h(e,"xmlns","http://www.w3.org/2000/svg")},m(a,s){d(a,e,s),o(e,i)},p(a,[s]){s&1&&h(e,"class",a[0]),s&2&&h(e,"width",a[1]),s&2&&h(e,"height",a[1])},i:he,o:he,d(a){a&&l(e)}}}function fc($,e,i){let{classNames:a=""}=e,{size:s="1em"}=e;return $.$$set=f=>{"classNames"in f&&i(0,a=f.classNames),"size"in f&&i(1,s=f.size)},[a,s]}class mc extends Wt{constructor(e){super();Xt(this,e,fc,uc,ea,{classNames:0,size:1})}}function dc($){let e,i;return{c(){e=R("svg"),i=R("path"),this.h()},l(a){e=U(a,"svg",{class:!0,width:!0,height:!0,viewBox:!0,fill:!0,xmlns:!0});var s=p(e);i=U(s,"path",{d:!0,fill:!0}),p(i).forEach(l),s.forEach(l),this.h()},h(){h(i,"d","M1.39125 1.9725L0.0883333 0.669997L0.677917 0.0804138L8.9275 8.33041L8.33792 8.91958L6.95875 7.54041C6.22592 8.00523 5.37572 8.25138 4.50792 8.25C2.26125 8.25 0.392083 6.63333 0 4.5C0.179179 3.52946 0.667345 2.64287 1.39167 1.9725H1.39125ZM5.65667 6.23833L5.04667 5.62833C4.81335 5.73996 4.55116 5.77647 4.29622 5.73282C4.04129 5.68918 3.80617 5.56752 3.62328 5.38463C3.44039 5.20175 3.31874 4.96663 3.27509 4.71169C3.23144 4.45676 3.26795 4.19456 3.37958 3.96125L2.76958 3.35125C2.50447 3.75187 2.38595 4.2318 2.4341 4.70978C2.48225 5.18777 2.6941 5.63442 3.0338 5.97411C3.37349 6.31381 3.82015 6.52567 4.29813 6.57382C4.77611 6.62197 5.25605 6.50345 5.65667 6.23833ZM2.83042 1.06666C3.35 0.862497 3.91625 0.749997 4.50792 0.749997C6.75458 0.749997 8.62375 2.36666 9.01583 4.5C8.88816 5.19404 8.60119 5.84899 8.1775 6.41333L6.56917 4.805C6.61694 4.48317 6.58868 4.15463 6.48664 3.84569C6.3846 3.53675 6.21162 3.256 5.98156 3.02594C5.7515 2.79588 5.47075 2.6229 5.16181 2.52086C4.85287 2.41882 4.52433 2.39056 4.2025 2.43833L2.83042 1.06708V1.06666Z"),h(i,"fill","currentColor"),h(e,"class",$[0]),h(e,"width",$[1]),h(e,"height",$[1]),h(e,"viewBox","0 0 10 9"),h(e,"fill","currentColor"),h(e,"xmlns","http://www.w3.org/2000/svg")},m(a,s){d(a,e,s),o(e,i)},p(a,[s]){s&1&&h(e,"class",a[0]),s&2&&h(e,"width",a[1]),s&2&&h(e,"height",a[1])},i:he,o:he,d(a){a&&l(e)}}}function hc($,e,i){let{classNames:a=""}=e,{size:s="1em"}=e;return $.$$set=f=>{"classNames"in f&&i(0,a=f.classNames),"size"in f&&i(1,s=f.size)},[a,s]}class $c extends Wt{constructor(e){super();Xt(this,e,hc,dc,ea,{classNames:0,size:1})}}const{window:gc}=tc;function Kp($){let e,i,a,s,f,g,k,w,b,C;return i=new $c({props:{size:"0.9em"}}),{c(){e=c("div"),M(i.$$.fragment),a=_(),s=c("span"),f=r("Hide "),g=r($[3]),k=r(" content"),this.h()},l(A){e=u(A,"DIV",{class:!0});var F=p(e);D(i.$$.fragment,F),a=v(F),s=u(F,"SPAN",{});var I=p(s);f=n(I,"Hide "),g=n(I,$[3]),k=n(I," content"),I.forEach(l),F.forEach(l),this.h()},h(){h(e,"class","cursor-pointer flex items-center justify-center space-x-1 text-sm px-2 bg-white dark:bg-gray-950 hover:underline leading-none")},m(A,F){d(A,e,F),S(i,e,null),o(e,a),o(e,s),o(s,f),o(s,g),o(s,k),w=!0,b||(C=cn(e,"click",$[5]),b=!0)},p:he,i(A){w||(E(i.$$.fragment,A),w=!0)},o(A){j(i.$$.fragment,A),w=!1},d(A){A&&l(e),y(i),b=!1,C()}}}function _c($){let e,i;const a=$[10].default,s=Oo(a,$,$[9],null);return{c(){e=c("div"),s&&s.c(),this.h()},l(f){e=u(f,"DIV",{class:!0});var g=p(e);s&&s.l(g),g.forEach(l),this.h()},h(){h(e,"class","framework-content")},m(f,g){d(f,e,g),s&&s.m(e,null),i=!0},p(f,g){s&&s.p&&(!i||g&512)&&xo(s,a,f,f[9],i?No(a,f[9],g,null):Lo(f[9]),null)},i(f){i||(E(s,f),i=!0)},o(f){j(s,f),i=!1},d(f){f&&l(e),s&&s.d(f)}}}function vc($){let e,i,a,s,f,g,k,w,b,C;return i=new mc({props:{size:"0.9em"}}),{c(){e=c("div"),M(i.$$.fragment),a=_(),s=c("span"),f=r("Show "),g=r($[3]),k=r(" content"),this.h()},l(A){e=u(A,"DIV",{class:!0});var F=p(e);D(i.$$.fragment,F),a=v(F),s=u(F,"SPAN",{});var I=p(s);f=n(I,"Show "),g=n(I,$[3]),k=n(I," content"),I.forEach(l),F.forEach(l),this.h()},h(){h(e,"class","cursor-pointer mt-[-12.5px] flex items-center justify-center space-x-1 py-4 text-sm hover:underline leading-none")},m(A,F){d(A,e,F),S(i,e,null),o(e,a),o(e,s),o(s,f),o(s,g),o(s,k),w=!0,b||(C=cn(e,"click",$[5]),b=!0)},p:he,i(A){w||(E(i.$$.fragment,A),w=!0)},o(A){j(i.$$.fragment,A),w=!1},d(A){A&&l(e),y(i),b=!1,C()}}}function zc($){let e,i,a,s,f,g,k,w,b,C,A,F,I,H;var T=$[2];function x(L){return{}}T&&(s=new T(x()));let z=!$[1]&&Kp($);const q=[vc,_c],G=[];function Q(L,K){return L[1]?0:1}return C=Q($),A=G[C]=q[C]($),{c(){e=c("div"),i=c("div"),a=c("div"),s&&M(s.$$.fragment),f=_(),g=c("span"),k=r($[3]),w=_(),z&&z.c(),b=_(),A.c(),this.h()},l(L){e=u(L,"DIV",{class:!0});var K=p(e);i=u(K,"DIV",{class:!0});var Z=p(i);a=u(Z,"DIV",{class:!0});var J=p(a);s&&D(s.$$.fragment,J),f=v(J),g=u(J,"SPAN",{});var V=p(g);k=n(V,$[3]),V.forEach(l),J.forEach(l),w=v(Z),z&&z.l(Z),Z.forEach(l),b=v(K),A.l(K),K.forEach(l),this.h()},h(){h(a,"class","flex px-1 items-center space-x-1 bg-white dark:bg-gray-950"),h(i,"class","flex h-[22px] mt-[-12.5px] justify-between leading-none"),h(e,"class","border border-gray-200 rounded-xl px-4 relative")},m(L,K){d(L,e,K),o(e,i),o(i,a),s&&S(s,a,null),o(a,f),o(a,g),o(g,k),o(i,w),z&&z.m(i,null),o(e,b),G[C].m(e,null),$[11](e),F=!0,I||(H=cn(gc,"hashchange",$[6]),I=!0)},p(L,[K]){if(T!==(T=L[2])){if(s){Ca();const J=s;j(J.$$.fragment,1,0,()=>{y(J,1)}),qa()}T?(s=new T(x()),M(s.$$.fragment),E(s.$$.fragment,1),S(s,a,f)):s=null}L[1]?z&&(Ca(),j(z,1,1,()=>{z=null}),qa()):z?(z.p(L,K),K&2&&E(z,1)):(z=Kp(L),z.c(),E(z,1),z.m(i,null));let Z=C;C=Q(L),C===Z?G[C].p(L,K):(Ca(),j(G[Z],1,1,()=>{G[Z]=null}),qa(),A=G[C],A?A.p(L,K):(A=G[C]=q[C](L),A.c()),E(A,1),A.m(e,null))},i(L){F||(s&&E(s.$$.fragment,L),E(z),E(A),F=!0)},o(L){s&&j(s.$$.fragment,L),j(z),j(A),F=!1},d(L){L&&l(e),s&&y(s),z&&z.d(),G[C].d(),$[11](null),I=!1,H()}}}function kc($,e,i){let a,s,{$$slots:f={},$$scope:g}=e,{framework:k}=e,w,b=new Set;const C={pytorch:{Icon:sc,label:"Pytorch"},tensorflow:{Icon:ic,label:"TensorFlow"},jax:{Icon:cc,label:"JAX"}},{Icon:A,label:F}=C[k],I=`hf_doc_framework_${k}_is_hidden`,H=lc(k);ec($,H,q=>i(8,s=q));function T(){us(H,s=s!==Qe.CLOSED?Qe.CLOSED:Qe.OPEN,s),localStorage.setItem(I,s)}function x(){const q=window.location.hash.slice(1);b.has(q)&&(us(H,s=Qe.HASHASHLINK,s),localStorage.setItem(I,s))}Xp(()=>{const q=window.location.hash.slice(1),G="header-link",Q=w.querySelectorAll(`.${G}`);b=new Set([...Q].map(K=>K.id));const L=localStorage.getItem(I);b.has(q)?us(H,s=Qe.HASHASHLINK,s):L===Qe.CLOSED&&s!==Qe.HASHASHLINK&&us(H,s=Qe.CLOSED,s)});function z(q){ac[q?"unshift":"push"](()=>{w=q,i(0,w)})}return $.$$set=q=>{"framework"in q&&i(7,k=q.framework),"$$scope"in q&&i(9,g=q.$$scope)},$.$$.update=()=>{$.$$.dirty&256&&i(1,a=s===Qe.CLOSED)},[w,a,A,F,H,T,x,k,s,g,f,z]}class un extends Wt{constructor(e){super();Xt(this,e,kc,zc,ea,{framework:7})}}const wc=$=>({}),Jp=$=>({}),bc=$=>({}),Bp=$=>({}),Ec=$=>({}),Vp=$=>({});function Zp($){let e,i;return e=new un({props:{framework:"pytorch",$$slots:{default:[jc]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&16&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function jc($){let e;const i=$[3].pytorch,a=Oo(i,$,$[4],Vp);return{c(){a&&a.c()},l(s){a&&a.l(s)},m(s,f){a&&a.m(s,f),e=!0},p(s,f){a&&a.p&&(!e||f&16)&&xo(a,i,s,s[4],e?No(i,s[4],f,Ec):Lo(s[4]),Vp)},i(s){e||(E(a,s),e=!0)},o(s){j(a,s),e=!1},d(s){a&&a.d(s)}}}function Yp($){let e,i;return e=new un({props:{framework:"tensorflow",$$slots:{default:[Ac]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&16&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Ac($){let e;const i=$[3].tensorflow,a=Oo(i,$,$[4],Bp);return{c(){a&&a.c()},l(s){a&&a.l(s)},m(s,f){a&&a.m(s,f),e=!0},p(s,f){a&&a.p&&(!e||f&16)&&xo(a,i,s,s[4],e?No(i,s[4],f,bc):Lo(s[4]),Bp)},i(s){e||(E(a,s),e=!0)},o(s){j(a,s),e=!1},d(s){a&&a.d(s)}}}function Wp($){let e,i;return e=new un({props:{framework:"jax",$$slots:{default:[Cc]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&16&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Cc($){let e;const i=$[3].jax,a=Oo(i,$,$[4],Jp);return{c(){a&&a.c()},l(s){a&&a.l(s)},m(s,f){a&&a.m(s,f),e=!0},p(s,f){a&&a.p&&(!e||f&16)&&xo(a,i,s,s[4],e?No(i,s[4],f,wc):Lo(s[4]),Jp)},i(s){e||(E(a,s),e=!0)},o(s){j(a,s),e=!1},d(s){a&&a.d(s)}}}function qc($){let e,i,a,s,f=$[0]&&Zp($),g=$[1]&&Yp($),k=$[2]&&Wp($);return{c(){e=c("div"),f&&f.c(),i=_(),g&&g.c(),a=_(),k&&k.c(),this.h()},l(w){e=u(w,"DIV",{class:!0});var b=p(e);f&&f.l(b),i=v(b),g&&g.l(b),a=v(b),k&&k.l(b),b.forEach(l),this.h()},h(){h(e,"class","space-y-10 py-6 2xl:py-8 2xl:-mx-4")},m(w,b){d(w,e,b),f&&f.m(e,null),o(e,i),g&&g.m(e,null),o(e,a),k&&k.m(e,null),s=!0},p(w,[b]){w[0]?f?(f.p(w,b),b&1&&E(f,1)):(f=Zp(w),f.c(),E(f,1),f.m(e,i)):f&&(Ca(),j(f,1,1,()=>{f=null}),qa()),w[1]?g?(g.p(w,b),b&2&&E(g,1)):(g=Yp(w),g.c(),E(g,1),g.m(e,a)):g&&(Ca(),j(g,1,1,()=>{g=null}),qa()),w[2]?k?(k.p(w,b),b&4&&E(k,1)):(k=Wp(w),k.c(),E(k,1),k.m(e,null)):k&&(Ca(),j(k,1,1,()=>{k=null}),qa())},i(w){s||(E(f),E(g),E(k),s=!0)},o(w){j(f),j(g),j(k),s=!1},d(w){w&&l(e),f&&f.d(),g&&g.d(),k&&k.d()}}}function Tc($,e,i){let{$$slots:a={},$$scope:s}=e,{pytorch:f=!1}=e,{tensorflow:g=!1}=e,{jax:k=!1}=e;return $.$$set=w=>{"pytorch"in w&&i(0,f=w.pytorch),"tensorflow"in w&&i(1,g=w.tensorflow),"jax"in w&&i(2,k=w.jax),"$$scope"in w&&i(4,s=w.$$scope)},[f,g,k,a,s]}class ja extends Wt{constructor(e){super();Xt(this,e,Tc,qc,ea,{pytorch:0,tensorflow:1,jax:2})}}function Mc($){let e;const i=$[1].default,a=Oo(i,$,$[0],null);return{c(){a&&a.c()},l(s){a&&a.l(s)},m(s,f){a&&a.m(s,f),e=!0},p(s,[f]){a&&a.p&&(!e||f&1)&&xo(a,i,s,s[0],e?No(i,s[0],f,null):Lo(s[0]),null)},i(s){e||(E(a,s),e=!0)},o(s){j(a,s),e=!1},d(s){a&&a.d(s)}}}function Sc($,e,i){let{$$slots:a={},$$scope:s}=e;return $.$$set=f=>{"$$scope"in f&&i(0,s=f.$$scope)},[s,a]}class je extends Wt{constructor(e){super();Xt(this,e,Sc,Mc,ea,{})}}function yc($){let e,i;return{c(){e=c("p"),i=r(`Tutti gli esempi di codice presenti in questa documentazione hanno un pulsante in alto a sinistra che permette di selezionare tra PyTorch e TensorFlow. Se
questo non \xE8 presente, ci si aspetta che il codice funzioni per entrambi i backend senza alcun cambiamento.`)},l(a){e=u(a,"P",{});var s=p(e);i=n(s,`Tutti gli esempi di codice presenti in questa documentazione hanno un pulsante in alto a sinistra che permette di selezionare tra PyTorch e TensorFlow. Se
questo non \xE8 presente, ci si aspetta che il codice funzioni per entrambi i backend senza alcun cambiamento.`),s.forEach(l)},m(a,s){d(a,e,s),o(e,i)},d(a){a&&l(e)}}}function Pc($){let e,i,a,s,f,g,k,w;return{c(){e=c("p"),i=r("Per maggiori dettagli legati alla "),a=c("code"),s=r("pipeline()"),f=r(" e ai compiti ad essa associati, fai riferimento alla documentazione "),g=c("a"),k=r("qui"),w=r("."),this.h()},l(b){e=u(b,"P",{});var C=p(e);i=n(C,"Per maggiori dettagli legati alla "),a=u(C,"CODE",{});var A=p(a);s=n(A,"pipeline()"),A.forEach(l),f=n(C," e ai compiti ad essa associati, fai riferimento alla documentazione "),g=u(C,"A",{href:!0});var F=p(g);k=n(F,"qui"),F.forEach(l),w=n(C,"."),C.forEach(l),this.h()},h(){h(g,"href","./main_classes/pipelines")},m(b,C){d(b,e,C),o(e,i),o(e,a),o(a,s),o(e,f),o(e,g),o(g,k),o(e,w)},d(b){b&&l(e)}}}function Dc($){let e,i;return e=new Y({props:{code:"pip install torch",highlighted:"pip install torch"}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p:he,i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Fc($){let e,i;return e=new je({props:{$$slots:{default:[Dc]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Ic($){let e,i;return e=new Y({props:{code:"pip install tensorflow",highlighted:"pip install tensorflow"}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p:he,i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Oc($){let e,i;return e=new je({props:{$$slots:{default:[Ic]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function xc($){let e,i,a,s,f,g,k,w,b,C,A,F,I,H;return I=new Y({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){e=c("p"),i=r("Usa "),a=c("code"),s=r("AutoModelForSequenceClassification"),f=r(" e "),g=c("code"),k=r("AutoTokenizer"),w=r(" per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),b=c("code"),C=r("AutoClass"),A=r(" in seguito):"),F=_(),M(I.$$.fragment)},l(T){e=u(T,"P",{});var x=p(e);i=n(x,"Usa "),a=u(x,"CODE",{});var z=p(a);s=n(z,"AutoModelForSequenceClassification"),z.forEach(l),f=n(x," e "),g=u(x,"CODE",{});var q=p(g);k=n(q,"AutoTokenizer"),q.forEach(l),w=n(x," per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),b=u(x,"CODE",{});var G=p(b);C=n(G,"AutoClass"),G.forEach(l),A=n(x," in seguito):"),x.forEach(l),F=v(T),D(I.$$.fragment,T)},m(T,x){d(T,e,x),o(e,i),o(e,a),o(a,s),o(e,f),o(e,g),o(g,k),o(e,w),o(e,b),o(b,C),o(e,A),d(T,F,x),S(I,T,x),H=!0},p:he,i(T){H||(E(I.$$.fragment,T),H=!0)},o(T){j(I.$$.fragment,T),H=!1},d(T){T&&l(e),T&&l(F),y(I,T)}}}function Lc($){let e,i;return e=new je({props:{$$slots:{default:[xc]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Nc($){let e,i,a,s,f,g,k,w,b,C,A,F,I,H;return I=new Y({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){e=c("p"),i=r("Usa "),a=c("code"),s=r("TFAutoModelForSequenceClassification"),f=r(" e "),g=c("code"),k=r("AutoTokenizer"),w=r(" per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),b=c("code"),C=r("TFAutoClass"),A=r(" in seguito):"),F=_(),M(I.$$.fragment)},l(T){e=u(T,"P",{});var x=p(e);i=n(x,"Usa "),a=u(x,"CODE",{});var z=p(a);s=n(z,"TFAutoModelForSequenceClassification"),z.forEach(l),f=n(x," e "),g=u(x,"CODE",{});var q=p(g);k=n(q,"AutoTokenizer"),q.forEach(l),w=n(x," per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),b=u(x,"CODE",{});var G=p(b);C=n(G,"TFAutoClass"),G.forEach(l),A=n(x," in seguito):"),x.forEach(l),F=v(T),D(I.$$.fragment,T)},m(T,x){d(T,e,x),o(e,i),o(e,a),o(a,s),o(e,f),o(e,g),o(g,k),o(e,w),o(e,b),o(b,C),o(e,A),d(T,F,x),S(I,T,x),H=!0},p:he,i(T){H||(E(I.$$.fragment,T),H=!0)},o(T){j(I.$$.fragment,T),H=!1},d(T){T&&l(e),T&&l(F),y(I,T)}}}function Hc($){let e,i;return e=new je({props:{$$slots:{default:[Nc]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Rc($){let e,i;return e=new Y({props:{code:`pt_batch = tokenizer(
    ["Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.", "Speriamo te non la odierai."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p:he,i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Uc($){let e,i;return e=new je({props:{$$slots:{default:[Rc]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Gc($){let e,i;return e=new Y({props:{code:`tf_batch = tokenizer(
    ["Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.", "Speriamo te non la odierai."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="tf",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p:he,i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Qc($){let e,i;return e=new je({props:{$$slots:{default:[Gc]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Kc($){let e,i,a,s,f,g,k,w;return{c(){e=c("p"),i=r("Guarda il "),a=c("a"),s=r("task summary"),f=r(" per sapere quale classe di "),g=c("code"),k=r("AutoModel"),w=r(" utilizzare per quale compito."),this.h()},l(b){e=u(b,"P",{});var C=p(e);i=n(C,"Guarda il "),a=u(C,"A",{href:!0});var A=p(a);s=n(A,"task summary"),A.forEach(l),f=n(C," per sapere quale classe di "),g=u(C,"CODE",{});var F=p(g);k=n(F,"AutoModel"),F.forEach(l),w=n(C," utilizzare per quale compito."),C.forEach(l),this.h()},h(){h(a,"href","./task_summary")},m(b,C){d(b,e,C),o(e,i),o(e,a),o(a,s),o(e,f),o(e,g),o(g,k),o(e,w)},d(b){b&&l(e)}}}function Jc($){let e,i,a,s,f,g,k,w,b,C,A,F,I,H,T,x,z,q,G,Q,L,K,Z,J,V,se,oe,le,ce,re,ue,ie,X,ne,fe,O,N,te;return x=new Y({props:{code:`from transformers import AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`}}),q=new Aa({props:{$$slots:{default:[Kc]},$$scope:{ctx:$}}}),se=new Y({props:{code:"pt_outputs = pt_model(**pt_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)'}}),N=new Y({props:{code:`from torch import nn

pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0041</span>, <span class="hljs-number">0.0037</span>, <span class="hljs-number">0.0203</span>, <span class="hljs-number">0.2005</span>, <span class="hljs-number">0.7713</span>],
        [<span class="hljs-number">0.3766</span>, <span class="hljs-number">0.3292</span>, <span class="hljs-number">0.1832</span>, <span class="hljs-number">0.0558</span>, <span class="hljs-number">0.0552</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`}}),{c(){e=c("p"),i=r("\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),a=c("code"),s=r("AutoModel"),f=r(" come caricheresti un "),g=c("code"),k=r("AutoTokenizer"),w=r(". L\u2019unica differenza \xE8 selezionare l\u2019"),b=c("code"),C=r("AutoModel"),A=r(" corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=c("code"),I=r("AutoModelForSequenceClassification"),H=r(":"),T=_(),M(x.$$.fragment),z=_(),M(q.$$.fragment),G=_(),Q=c("p"),L=r("Ora puoi passare il tuo lotto di input pre-processati direttamente al modello. Devi solo spacchettare il dizionario aggiungendo "),K=c("code"),Z=r("**"),J=r(":"),V=_(),M(se.$$.fragment),oe=_(),le=c("p"),ce=r("Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),re=c("code"),ue=r("logits"),ie=r(". Applica la funzione softmax a "),X=c("code"),ne=r("logits"),fe=r(" per ottenere le probabilit\xE0:"),O=_(),M(N.$$.fragment)},l(P){e=u(P,"P",{});var B=p(e);i=n(B,"\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),a=u(B,"CODE",{});var pe=p(a);s=n(pe,"AutoModel"),pe.forEach(l),f=n(B," come caricheresti un "),g=u(B,"CODE",{});var $e=p(g);k=n($e,"AutoTokenizer"),$e.forEach(l),w=n(B,". L\u2019unica differenza \xE8 selezionare l\u2019"),b=u(B,"CODE",{});var W=p(b);C=n(W,"AutoModel"),W.forEach(l),A=n(B," corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=u(B,"CODE",{});var be=p(F);I=n(be,"AutoModelForSequenceClassification"),be.forEach(l),H=n(B,":"),B.forEach(l),T=v(P),D(x.$$.fragment,P),z=v(P),D(q.$$.fragment,P),G=v(P),Q=u(P,"P",{});var ae=p(Q);L=n(ae,"Ora puoi passare il tuo lotto di input pre-processati direttamente al modello. Devi solo spacchettare il dizionario aggiungendo "),K=u(ae,"CODE",{});var Ee=p(K);Z=n(Ee,"**"),Ee.forEach(l),J=n(ae,":"),ae.forEach(l),V=v(P),D(se.$$.fragment,P),oe=v(P),le=u(P,"P",{});var ve=p(le);ce=n(ve,"Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),re=u(ve,"CODE",{});var Ae=p(re);ue=n(Ae,"logits"),Ae.forEach(l),ie=n(ve,". Applica la funzione softmax a "),X=u(ve,"CODE",{});var ge=p(X);ne=n(ge,"logits"),ge.forEach(l),fe=n(ve," per ottenere le probabilit\xE0:"),ve.forEach(l),O=v(P),D(N.$$.fragment,P)},m(P,B){d(P,e,B),o(e,i),o(e,a),o(a,s),o(e,f),o(e,g),o(g,k),o(e,w),o(e,b),o(b,C),o(e,A),o(e,F),o(F,I),o(e,H),d(P,T,B),S(x,P,B),d(P,z,B),S(q,P,B),d(P,G,B),d(P,Q,B),o(Q,L),o(Q,K),o(K,Z),o(Q,J),d(P,V,B),S(se,P,B),d(P,oe,B),d(P,le,B),o(le,ce),o(le,re),o(re,ue),o(le,ie),o(le,X),o(X,ne),o(le,fe),d(P,O,B),S(N,P,B),te=!0},p(P,B){const pe={};B&2&&(pe.$$scope={dirty:B,ctx:P}),q.$set(pe)},i(P){te||(E(x.$$.fragment,P),E(q.$$.fragment,P),E(se.$$.fragment,P),E(N.$$.fragment,P),te=!0)},o(P){j(x.$$.fragment,P),j(q.$$.fragment,P),j(se.$$.fragment,P),j(N.$$.fragment,P),te=!1},d(P){P&&l(e),P&&l(T),y(x,P),P&&l(z),y(q,P),P&&l(G),P&&l(Q),P&&l(V),y(se,P),P&&l(oe),P&&l(le),P&&l(O),y(N,P)}}}function Bc($){let e,i;return e=new je({props:{$$slots:{default:[Jc]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Vc($){let e,i,a,s,f,g,k,w;return{c(){e=c("p"),i=r("Guarda il "),a=c("a"),s=r("task summary"),f=r(" per sapere quale classe di "),g=c("code"),k=r("AutoModel"),w=r(" utilizzare per quale compito."),this.h()},l(b){e=u(b,"P",{});var C=p(e);i=n(C,"Guarda il "),a=u(C,"A",{href:!0});var A=p(a);s=n(A,"task summary"),A.forEach(l),f=n(C," per sapere quale classe di "),g=u(C,"CODE",{});var F=p(g);k=n(F,"AutoModel"),F.forEach(l),w=n(C," utilizzare per quale compito."),C.forEach(l),this.h()},h(){h(a,"href","./task_summary")},m(b,C){d(b,e,C),o(e,i),o(e,a),o(a,s),o(e,f),o(e,g),o(g,k),o(e,w)},d(b){b&&l(e)}}}function Zc($){let e,i,a,s,f,g,k,w,b,C,A,F,I,H,T,x,z,q,G,Q,L,K,Z,J,V,se,oe,le,ce,re,ue,ie,X,ne,fe;return x=new Y({props:{code:`from transformers import TFAutoModelForSequenceClassification

nome_del_modello = "nlptown/bert-base-multilingual-uncased-sentiment"
tf_model = TFAutoModelForSequenceClassification.from_pretrained(nome_del_modello)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>nome_del_modello = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(nome_del_modello)`}}),q=new Aa({props:{$$slots:{default:[Vc]},$$scope:{ctx:$}}}),Z=new Y({props:{code:"tf_outputs = tf_model(tf_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)'}}),ne=new Y({props:{code:`import tensorflow as tf

tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
tf_predictions`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`}}),{c(){e=c("p"),i=r("\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),a=c("code"),s=r("TFAutoModel"),f=r(" come caricheresti un "),g=c("code"),k=r("AutoTokenizer"),w=r(". L\u2019unica differenza \xE8 selezionare il "),b=c("code"),C=r("TFAutoModel"),A=r(" corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=c("code"),I=r("TFAutoModelForSequenceClassification"),H=r(":"),T=_(),M(x.$$.fragment),z=_(),M(q.$$.fragment),G=_(),Q=c("p"),L=r("Ora puoi passare il tuo lotto di input pre-processati direttamente al modello passando le chiavi del dizionario al tensore:"),K=_(),M(Z.$$.fragment),J=_(),V=c("p"),se=r("Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),oe=c("code"),le=r("logits"),ce=r(". Applica la funzione softmax a "),re=c("code"),ue=r("logits"),ie=r(" per ottenere le probabilit\xE0:"),X=_(),M(ne.$$.fragment)},l(O){e=u(O,"P",{});var N=p(e);i=n(N,"\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),a=u(N,"CODE",{});var te=p(a);s=n(te,"TFAutoModel"),te.forEach(l),f=n(N," come caricheresti un "),g=u(N,"CODE",{});var P=p(g);k=n(P,"AutoTokenizer"),P.forEach(l),w=n(N,". L\u2019unica differenza \xE8 selezionare il "),b=u(N,"CODE",{});var B=p(b);C=n(B,"TFAutoModel"),B.forEach(l),A=n(N," corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=u(N,"CODE",{});var pe=p(F);I=n(pe,"TFAutoModelForSequenceClassification"),pe.forEach(l),H=n(N,":"),N.forEach(l),T=v(O),D(x.$$.fragment,O),z=v(O),D(q.$$.fragment,O),G=v(O),Q=u(O,"P",{});var $e=p(Q);L=n($e,"Ora puoi passare il tuo lotto di input pre-processati direttamente al modello passando le chiavi del dizionario al tensore:"),$e.forEach(l),K=v(O),D(Z.$$.fragment,O),J=v(O),V=u(O,"P",{});var W=p(V);se=n(W,"Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),oe=u(W,"CODE",{});var be=p(oe);le=n(be,"logits"),be.forEach(l),ce=n(W,". Applica la funzione softmax a "),re=u(W,"CODE",{});var ae=p(re);ue=n(ae,"logits"),ae.forEach(l),ie=n(W," per ottenere le probabilit\xE0:"),W.forEach(l),X=v(O),D(ne.$$.fragment,O)},m(O,N){d(O,e,N),o(e,i),o(e,a),o(a,s),o(e,f),o(e,g),o(g,k),o(e,w),o(e,b),o(b,C),o(e,A),o(e,F),o(F,I),o(e,H),d(O,T,N),S(x,O,N),d(O,z,N),S(q,O,N),d(O,G,N),d(O,Q,N),o(Q,L),d(O,K,N),S(Z,O,N),d(O,J,N),d(O,V,N),o(V,se),o(V,oe),o(oe,le),o(V,ce),o(V,re),o(re,ue),o(V,ie),d(O,X,N),S(ne,O,N),fe=!0},p(O,N){const te={};N&2&&(te.$$scope={dirty:N,ctx:O}),q.$set(te)},i(O){fe||(E(x.$$.fragment,O),E(q.$$.fragment,O),E(Z.$$.fragment,O),E(ne.$$.fragment,O),fe=!0)},o(O){j(x.$$.fragment,O),j(q.$$.fragment,O),j(Z.$$.fragment,O),j(ne.$$.fragment,O),fe=!1},d(O){O&&l(e),O&&l(T),y(x,O),O&&l(z),y(q,O),O&&l(G),O&&l(Q),O&&l(K),y(Z,O),O&&l(J),O&&l(V),O&&l(X),y(ne,O)}}}function Yc($){let e,i;return e=new je({props:{$$slots:{default:[Zc]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function Wc($){let e,i,a,s,f;return{c(){e=c("p"),i=r("Tutti i modelli di \u{1F917} Transformers (PyTorch e TensorFlow) restituiscono i tensori "),a=c("em"),s=r("prima"),f=r(` della funzione finale
di attivazione (come la softmax) perch\xE9 la funzione di attivazione finale viene spesso unita a quella di perdita.`)},l(g){e=u(g,"P",{});var k=p(e);i=n(k,"Tutti i modelli di \u{1F917} Transformers (PyTorch e TensorFlow) restituiscono i tensori "),a=u(k,"EM",{});var w=p(a);s=n(w,"prima"),w.forEach(l),f=n(k,` della funzione finale
di attivazione (come la softmax) perch\xE9 la funzione di attivazione finale viene spesso unita a quella di perdita.`),k.forEach(l)},m(g,k){d(g,e,k),o(e,i),o(e,a),o(a,s),o(e,f)},d(g){g&&l(e)}}}function Xc($){let e,i,a,s,f;return{c(){e=c("p"),i=r(`Gli output del modello di \u{1F917} Transformers sono delle dataclasses speciali in modo che i loro attributi vengano auto-completati all\u2019interno di un IDE.
Gli output del modello si comportano anche come una tupla o un dizionario (ad esempio, puoi indicizzare con un intero, una slice o una stringa) nel qual caso gli attributi che sono `),a=c("code"),s=r("None"),f=r(" vengono ignorati.")},l(g){e=u(g,"P",{});var k=p(e);i=n(k,`Gli output del modello di \u{1F917} Transformers sono delle dataclasses speciali in modo che i loro attributi vengano auto-completati all\u2019interno di un IDE.
Gli output del modello si comportano anche come una tupla o un dizionario (ad esempio, puoi indicizzare con un intero, una slice o una stringa) nel qual caso gli attributi che sono `),a=u(k,"CODE",{});var w=p(a);s=n(w,"None"),w.forEach(l),f=n(k," vengono ignorati."),k.forEach(l)},m(g,k){d(g,e,k),o(e,i),o(e,a),o(a,s),o(e,f)},d(g){g&&l(e)}}}function eu($){let e,i,a,s,f,g,k,w,b,C,A,F,I,H,T,x;return k=new Y({props:{code:`pt_save_directory = "./pt_save_pretrained"
tokenizer.save_pretrained(pt_save_directory)
pt_model.save_pretrained(pt_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`}}),T=new Y({props:{code:'pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)'}}),{c(){e=c("p"),i=r("Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),a=c("code"),s=r("PreTrainedModel.save_pretrained()"),f=r(":"),g=_(),M(k.$$.fragment),w=_(),b=c("p"),C=r("Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),A=c("code"),F=r("PreTrainedModel.from_pretrained()"),I=r(":"),H=_(),M(T.$$.fragment)},l(z){e=u(z,"P",{});var q=p(e);i=n(q,"Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),a=u(q,"CODE",{});var G=p(a);s=n(G,"PreTrainedModel.save_pretrained()"),G.forEach(l),f=n(q,":"),q.forEach(l),g=v(z),D(k.$$.fragment,z),w=v(z),b=u(z,"P",{});var Q=p(b);C=n(Q,"Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),A=u(Q,"CODE",{});var L=p(A);F=n(L,"PreTrainedModel.from_pretrained()"),L.forEach(l),I=n(Q,":"),Q.forEach(l),H=v(z),D(T.$$.fragment,z)},m(z,q){d(z,e,q),o(e,i),o(e,a),o(a,s),o(e,f),d(z,g,q),S(k,z,q),d(z,w,q),d(z,b,q),o(b,C),o(b,A),o(A,F),o(b,I),d(z,H,q),S(T,z,q),x=!0},p:he,i(z){x||(E(k.$$.fragment,z),E(T.$$.fragment,z),x=!0)},o(z){j(k.$$.fragment,z),j(T.$$.fragment,z),x=!1},d(z){z&&l(e),z&&l(g),y(k,z),z&&l(w),z&&l(b),z&&l(H),y(T,z)}}}function tu($){let e,i;return e=new je({props:{$$slots:{default:[eu]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function au($){let e,i,a,s,f,g,k,w,b,C,A,F,I,H,T,x;return k=new Y({props:{code:`tf_save_directory = "./tf_save_pretrained"
tokenizer.save_pretrained(tf_save_directory)
tf_model.save_pretrained(tf_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`}}),T=new Y({props:{code:'tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)'}}),{c(){e=c("p"),i=r("Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),a=c("code"),s=r("TFPreTrainedModel.save_pretrained()"),f=r(":"),g=_(),M(k.$$.fragment),w=_(),b=c("p"),C=r("Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),A=c("code"),F=r("TFPreTrainedModel.from_pretrained()"),I=r(":"),H=_(),M(T.$$.fragment)},l(z){e=u(z,"P",{});var q=p(e);i=n(q,"Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),a=u(q,"CODE",{});var G=p(a);s=n(G,"TFPreTrainedModel.save_pretrained()"),G.forEach(l),f=n(q,":"),q.forEach(l),g=v(z),D(k.$$.fragment,z),w=v(z),b=u(z,"P",{});var Q=p(b);C=n(Q,"Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),A=u(Q,"CODE",{});var L=p(A);F=n(L,"TFPreTrainedModel.from_pretrained()"),L.forEach(l),I=n(Q,":"),Q.forEach(l),H=v(z),D(T.$$.fragment,z)},m(z,q){d(z,e,q),o(e,i),o(e,a),o(a,s),o(e,f),d(z,g,q),S(k,z,q),d(z,w,q),d(z,b,q),o(b,C),o(b,A),o(A,F),o(b,I),d(z,H,q),S(T,z,q),x=!0},p:he,i(z){x||(E(k.$$.fragment,z),E(T.$$.fragment,z),x=!0)},o(z){j(k.$$.fragment,z),j(T.$$.fragment,z),x=!1},d(z){z&&l(e),z&&l(g),y(k,z),z&&l(w),z&&l(b),z&&l(H),y(T,z)}}}function ou($){let e,i;return e=new je({props:{$$slots:{default:[au]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function lu($){let e,i;return e=new Y({props:{code:`from transformers import AutoModel

tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p:he,i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function su($){let e,i;return e=new je({props:{$$slots:{default:[lu]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function iu($){let e,i;return e=new Y({props:{code:`from transformers import TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p:he,i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function ru($){let e,i;return e=new je({props:{$$slots:{default:[iu]},$$scope:{ctx:$}}}),{c(){M(e.$$.fragment)},l(a){D(e.$$.fragment,a)},m(a,s){S(e,a,s),i=!0},p(a,s){const f={};s&2&&(f.$$scope={dirty:s,ctx:a}),e.$set(f)},i(a){i||(E(e.$$.fragment,a),i=!0)},o(a){j(e.$$.fragment,a),i=!1},d(a){y(e,a)}}}function nu($){let e,i,a,s,f,g,k,w,b,C,A,F,I,H,T,x,z,q,G,Q,L,K,Z,J,V,se,oe,le,ce,re,ue,ie,X,ne,fe,O,N,te,P,B,pe,$e,W,be,ae,Ee,ve,Ae,ge,ee,Ce,fs,ms,Ta,ds,hs,Ma,$s,gs,Sa,_s,vs,ya,zs,ks,Pa,ws,bs,Da,Es,js,Fa,As,Ho,zt,Ia,Cs,qs,Ro,qe,Oa,Ts,Ms,xa,Ss,ys,La,Ps,Uo,kt,Na,Ds,Fs,Go,Ke,Ha,Is,Os,Ra,xs,Qo,Je,Ko,xe,Be,Ua,wt,Ls,Ga,Ns,Jo,Ve,Hs,Qa,Rs,Us,Bo,ta,Gs,Vo,Ze,Zo,Ye,Qs,Ka,Ks,Js,Yo,bt,Wo,Te,Bs,Et,Vs,Zs,Ja,Ys,Ws,Xo,jt,el,We,Xs,Ba,ei,ti,tl,At,al,Me,ai,Va,oi,li,Ct,si,ii,ol,qt,ll,Xe,ri,Za,ni,pi,sl,Tt,il,Se,ci,Mt,ui,fi,St,mi,di,rl,yt,nl,et,hi,Ya,$i,gi,pl,Pt,cl,aa,_i,ul,Dt,fl,tt,vi,oa,zi,ki,ml,Le,at,Wa,Ft,wi,Xa,bi,dl,ze,Ei,eo,ji,Ai,It,Ci,qi,to,Ti,Mi,Ot,Si,yi,hl,xt,$l,ot,gl,ye,Pi,ao,Di,Fi,oo,Ii,Oi,_l,Lt,vl,Pe,xi,la,Li,Ni,sa,Hi,Ri,zl,Ne,lt,lo,Nt,Ui,so,Gi,kl,Ht,wl,me,Qi,io,Ki,Ji,ro,Bi,Vi,no,Zi,Yi,ia,Wi,Xi,po,er,tr,co,ar,or,bl,De,lr,uo,sr,ir,fo,rr,nr,El,He,st,mo,Rt,pr,ho,cr,jl,Fe,ur,$o,fr,mr,ra,dr,hr,Al,it,$r,go,gr,_r,Cl,Ut,ql,rt,vr,_o,zr,kr,Tl,na,wr,Ml,Gt,Sl,pa,br,yl,nt,ca,ua,Er,jr,Ar,fa,ma,Cr,qr,Pl,pt,Tr,vo,Mr,Sr,Dl,ct,Fl,ut,yr,da,Pr,Dr,Il,Re,ft,zo,Qt,Fr,ko,Ir,Ol,mt,xl,dt,Ll,de,Or,Kt,wo,xr,Lr,Jt,bo,Nr,Hr,Eo,Rr,Ur,jo,Gr,Qr,Bt,Kr,Jr,ha,Br,Vr,Nl,ht,Hl,Ue,$t,Ao,Vt,Zr,Co,Yr,Rl,gt,Ul,Ie,Wr,qo,Xr,en,To,tn,an,Gl,_t,Ql;return g=new vt({}),A=new rc({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/quicktour.ipynb"}]}}),K=new Aa({props:{$$slots:{default:[yc]},$$scope:{ctx:$}}}),oe=new vt({}),N=new Qp({props:{id:"tiZFewofSLM"}}),Je=new Aa({props:{$$slots:{default:[Pc]},$$scope:{ctx:$}}}),wt=new vt({}),Ze=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Oc],pytorch:[Fc]},$$scope:{ctx:$}}}),bt=new Y({props:{code:`from transformers import pipeline

classificatore = pipeline("sentiment-analysis", model="MilaNLProc/feel-it-italian-sentiment")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classificatore = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=<span class="hljs-string">&quot;MilaNLProc/feel-it-italian-sentiment&quot;</span>)`}}),jt=new Y({props:{code:'classificatore("Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.")',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classificatore(<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;positive&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9997</span>}]`}}),At=new Y({props:{code:`risultati = classificatore(
    ["Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.", "Speriamo te non la odierai."]
)
for risultato in risultati:
    print(f"etichetta: {risultato['label']}, con punteggio: {round(risultato['score'], 4)}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>risultati = classificatore(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>]
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> risultato <span class="hljs-keyword">in</span> risultati:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;etichetta: <span class="hljs-subst">{risultato[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, con punteggio: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(risultato[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
etichetta: positive, con punteggio: <span class="hljs-number">0.9998</span>
etichetta: negative, con punteggio: <span class="hljs-number">0.9998</span>`}}),qt=new Y({props:{code:"pip install datasets ",highlighted:"pip install datasets "}}),Tt=new Y({props:{code:`import torch
from transformers import pipeline

riconoscitore_vocale = pipeline(
    "automatic-speech-recognition", model="radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>riconoscitore_vocale = pipeline(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram&quot;</span>
<span class="hljs-meta">... </span>)`}}),yt=new Y({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="it-IT", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;it-IT&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),Pt=new Y({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=riconoscitore_vocale.feature_extractor.sampling_rate))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=riconoscitore_vocale.feature_extractor.sampling_rate))'}}),Dt=new Y({props:{code:`risultato = riconoscitore_vocale(dataset[:4]["audio"])
print([d["text"] for d in risultato])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>risultato = riconoscitore_vocale(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> risultato])
[<span class="hljs-string">&#x27;dovrei caricare dei soldi sul mio conto corrente&#x27;</span>, <span class="hljs-string">&#x27;buongiorno e senza vorrei depositare denaro sul mio conto corrente come devo fare per cortesia&#x27;</span>, <span class="hljs-string">&#x27;s\xEC salve vorrei depositare del denaro sul mio conto&#x27;</span>, <span class="hljs-string">&#x27;e buon pomeriggio vorrei depositare dei soldi sul mio conto bancario volleo sapere come posso fare se e posso farlo online ed un altro conto o andandoo tramite bancomut&#x27;</span>]`}}),Ft=new vt({}),xt=new Y({props:{code:'model_name = "nlptown/bert-base-multilingual-uncased-sentiment"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>'}}),ot=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Hc],pytorch:[Lc]},$$scope:{ctx:$}}}),Lt=new Y({props:{code:`classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier("Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`}}),Nt=new vt({}),Ht=new Qp({props:{id:"AhChOFRegn4"}}),Rt=new vt({}),Ut=new Y({props:{code:`from transformers import AutoTokenizer

nome_del_modello = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(nome_del_modello)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>nome_del_modello = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(nome_del_modello)`}}),Gt=new Y({props:{code:`encoding = tokenizer("Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.")
print(encoding)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">56821</span>, <span class="hljs-number">10132</span>, <span class="hljs-number">14407</span>, <span class="hljs-number">13019</span>, <span class="hljs-number">13007</span>, <span class="hljs-number">10120</span>, <span class="hljs-number">47201</span>, <span class="hljs-number">10330</span>, <span class="hljs-number">10106</span>, <span class="hljs-number">91686</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
<span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),ct=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Qc],pytorch:[Uc]},$$scope:{ctx:$}}}),Qt=new vt({}),mt=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Yc],pytorch:[Bc]},$$scope:{ctx:$}}}),dt=new Aa({props:{$$slots:{default:[Wc]},$$scope:{ctx:$}}}),ht=new Aa({props:{$$slots:{default:[Xc]},$$scope:{ctx:$}}}),Vt=new vt({}),gt=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ou],pytorch:[tu]},$$scope:{ctx:$}}}),_t=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ru],pytorch:[su]},$$scope:{ctx:$}}}),{c(){e=c("meta"),i=_(),a=c("h1"),s=c("a"),f=c("span"),M(g.$$.fragment),k=_(),w=c("span"),b=r("Quick tour"),C=_(),M(A.$$.fragment),F=_(),I=c("p"),H=r("Entra in azione con \u{1F917} Transformers! Inizia utilizzando "),T=c("code"),x=r("pipeline()"),z=r(" per un\u2019inferenza veloce, carica un modello pre-allenato e un tokenizer con una "),q=c("a"),G=r("AutoClass"),Q=r(" per risolvere i tuoi compiti legati a testo, immagini o audio."),L=_(),M(K.$$.fragment),Z=_(),J=c("h2"),V=c("a"),se=c("span"),M(oe.$$.fragment),le=_(),ce=c("span"),re=r("Pipeline"),ue=_(),ie=c("p"),X=c("code"),ne=r("pipeline()"),fe=r(" \xE8 il modo pi\xF9 semplice per utilizzare un modello pre-allenato per un dato compito."),O=_(),M(N.$$.fragment),te=_(),P=c("p"),B=r("La "),pe=c("code"),$e=r("pipeline()"),W=r(" supporta molti compiti comuni:"),be=_(),ae=c("p"),Ee=c("strong"),ve=r("Testo"),Ae=r(":"),ge=_(),ee=c("ul"),Ce=c("li"),fs=r("Analisi del Sentimento (Sentiment Analysis, in inglese): classifica la polarit\xE0 di un testo dato."),ms=_(),Ta=c("li"),ds=r("Generazione del Testo (Text Generation, in inglese): genera del testo a partire da un dato input."),hs=_(),Ma=c("li"),$s=r("Riconoscimento di Entit\xE0 (Name Entity Recognition o NER, in inglese): etichetta ogni parola con l\u2019entit\xE0 che questa rappresenta (persona, data, luogo, ecc.)."),gs=_(),Sa=c("li"),_s=r("Rispondere a Domande (Question answering, in inglese): estrae la risposta da un contesto, dato del contesto e una domanda."),vs=_(),ya=c("li"),zs=r("Riempimento di Maschere (Fill-mask, in inglese): riempie gli spazi mancanti in un testo che ha parole mascherate."),ks=_(),Pa=c("li"),ws=r("Riassumere (Summarization, in inglese): genera una sintesi di una lunga sequenza di testo o di un documento."),bs=_(),Da=c("li"),Es=r("Traduzione (Translation, in inglese): traduce un testo in un\u2019altra lingua."),js=_(),Fa=c("li"),As=r("Estrazione di Caratteristiche (Feature Extraction, in inglese): crea un tensore che rappresenta un testo."),Ho=_(),zt=c("p"),Ia=c("strong"),Cs=r("Immagini"),qs=r(":"),Ro=_(),qe=c("ul"),Oa=c("li"),Ts=r("Classificazione di Immagini (Image Classification, in inglese): classifica un\u2019immagine."),Ms=_(),xa=c("li"),Ss=r("Segmentazione di Immagini (Image Segmentation, in inglese): classifica ogni pixel di un\u2019immagine."),ys=_(),La=c("li"),Ps=r("Rilevazione di Oggetti (Object Detection, in inglese): rileva oggetti all\u2019interno di un\u2019immagine."),Uo=_(),kt=c("p"),Na=c("strong"),Ds=r("Audio"),Fs=r(":"),Go=_(),Ke=c("ul"),Ha=c("li"),Is=r("Classificazione di Audio (Audio Classification, in inglese): assegna un\u2019etichetta ad un segmento di audio dato."),Os=_(),Ra=c("li"),xs=r("Riconoscimento Vocale Automatico (Automatic Speech Recognition o ASR, in inglese): trascrive il contenuto di un audio dato in un testo."),Qo=_(),M(Je.$$.fragment),Ko=_(),xe=c("h3"),Be=c("a"),Ua=c("span"),M(wt.$$.fragment),Ls=_(),Ga=c("span"),Ns=r("Utilizzo della Pipeline"),Jo=_(),Ve=c("p"),Hs=r("Nel seguente esempio, utilizzerai la "),Qa=c("code"),Rs=r("pipeline()"),Us=r(" per l\u2019analisi del sentimento."),Bo=_(),ta=c("p"),Gs=r("Installa le seguenti dipendenze se non lo hai gi\xE0 fatto:"),Vo=_(),M(Ze.$$.fragment),Zo=_(),Ye=c("p"),Qs=r("Importa "),Ka=c("code"),Ks=r("pipeline()"),Js=r(" e specifica il compito che vuoi completare:"),Yo=_(),M(bt.$$.fragment),Wo=_(),Te=c("p"),Bs=r("La pipeline scarica e salva il "),Et=c("a"),Vs=r("modello pre-allenato"),Zs=r(" e il tokenizer per l\u2019analisi del sentimento. Se non avessimo scelto un modello, la pipeline ne avrebbe scelto uno di default. Ora puoi utilizzare il "),Ja=c("code"),Ys=r("classifier"),Ws=r(" sul tuo testo obiettivo:"),Xo=_(),M(jt.$$.fragment),el=_(),We=c("p"),Xs=r("Per pi\xF9 di una frase, passa una lista di frasi alla "),Ba=c("code"),ei=r("pipeline()"),ti=r(" la quale restituir\xE0 una lista di dizionari:"),tl=_(),M(At.$$.fragment),al=_(),Me=c("p"),ai=r("La "),Va=c("code"),oi=r("pipeline()"),li=r(" pu\xF2 anche iterare su un dataset intero. Inizia installando la libreria "),Ct=c("a"),si=r("\u{1F917} Datasets"),ii=r(":"),ol=_(),M(qt.$$.fragment),ll=_(),Xe=c("p"),ri=r("Crea una "),Za=c("code"),ni=r("pipeline()"),pi=r(" con il compito che vuoi risolvere e con il modello che vuoi utilizzare."),sl=_(),M(Tt.$$.fragment),il=_(),Se=c("p"),ci=r("Poi, carica un dataset (vedi \u{1F917} Datasets "),Mt=c("a"),ui=r("Quick Start"),fi=r(" per maggiori dettagli) sul quale vuoi iterare. Per esempio, carichiamo il dataset "),St=c("a"),mi=r("MInDS-14"),di=r(":"),rl=_(),M(yt.$$.fragment),nl=_(),et=c("p"),hi=r("Dobbiamo assicurarci che la frequenza di campionamento del set di dati corrisponda alla frequenza di campionamento con cui \xE8 stato addestrato "),Ya=c("code"),$i=r("radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram"),gi=r("."),pl=_(),M(Pt.$$.fragment),cl=_(),aa=c("p"),_i=r(`I file audio vengono caricati automaticamente e ri-campionati quando chiamiamo la colonna \u201Caudio\u201D.
Estraiamo i vettori delle forme d\u2019onda grezze delle prime 4 osservazioni e passiamoli come lista alla pipeline:`),ul=_(),M(Dt.$$.fragment),fl=_(),tt=c("p"),vi=r("Per un dataset pi\xF9 grande dove gli input sono di dimensione maggiore (come nel parlato/audio o nella visione), dovrai passare un generatore al posto di una lista che carica tutti gli input in memoria. Guarda la "),oa=c("a"),zi=r("documentazione della pipeline"),ki=r(" per maggiori informazioni."),ml=_(),Le=c("h3"),at=c("a"),Wa=c("span"),M(Ft.$$.fragment),wi=_(),Xa=c("span"),bi=r("Utilizzare un altro modello e tokenizer nella pipeline"),dl=_(),ze=c("p"),Ei=r("La "),eo=c("code"),ji=r("pipeline()"),Ai=r(" pu\xF2 ospitare qualsiasi modello del "),It=c("a"),Ci=r("Model Hub"),qi=r(", rendendo semplice l\u2019adattamento della "),to=c("code"),Ti=r("pipeline()"),Mi=r(" per altri casi d\u2019uso. Per esempio, se si vuole un modello capace di trattare testo in francese, usa i tag presenti nel Model Hub in modo da filtrare per ottenere un modello appropriato. Il miglior risultato filtrato restituisce un modello multi-lingua "),Ot=c("a"),Si=r("BERT model"),yi=r(" fine-tuned per l\u2019analisi del sentimento. Ottimo, utilizziamo questo modello!"),hl=_(),M(xt.$$.fragment),$l=_(),M(ot.$$.fragment),gl=_(),ye=c("p"),Pi=r("Poi puoi specificare il modello e il tokenizer nella "),ao=c("code"),Di=r("pipeline()"),Fi=r(", e applicare il "),oo=c("code"),Ii=r("classifier"),Oi=r(" sul tuo testo obiettivo:"),_l=_(),M(Lt.$$.fragment),vl=_(),Pe=c("p"),xi=r("Se non riesci a trovare un modello per il tuo caso d\u2019uso, dovrai fare fine-tuning di un modello pre-allenato sui tuoi dati. Dai un\u2019occhiata al nostro tutorial "),la=c("a"),Li=r("fine-tuning tutorial"),Ni=r(" per imparare come. Infine, dopo che hai completato il fine-tuning del tuo modello pre-allenato, considera per favore di condividerlo (vedi il tutorial "),sa=c("a"),Hi=r("qui"),Ri=r(") con la comunit\xE0 sul Model Hub per democratizzare l\u2019NLP! \u{1F917}"),zl=_(),Ne=c("h2"),lt=c("a"),lo=c("span"),M(Nt.$$.fragment),Ui=_(),so=c("span"),Gi=r("AutoClass"),kl=_(),M(Ht.$$.fragment),wl=_(),me=c("p"),Qi=r("Al suo interno, le classi "),io=c("code"),Ki=r("AutoModelForSequenceClassification"),Ji=r(" e "),ro=c("code"),Bi=r("AutoTokenizer"),Vi=r(" lavorano assieme per dare potere alla "),no=c("code"),Zi=r("pipeline()"),Yi=r(". Una "),ia=c("a"),Wi=r("AutoClass"),Xi=r(" \xE8 una scorciatoia che automaticamente recupera l\u2019architettura di un modello pre-allenato a partire dal suo nome o path. Hai solo bisogno di selezionare la "),po=c("code"),er=r("AutoClass"),tr=r(" appropriata per il tuo compito e il suo tokenizer associato con "),co=c("code"),ar=r("AutoTokenizer"),or=r("."),bl=_(),De=c("p"),lr=r("Ritorniamo al nostro esempio e vediamo come puoi utilizzare la "),uo=c("code"),sr=r("AutoClass"),ir=r(" per replicare i risultati della "),fo=c("code"),rr=r("pipeline()"),nr=r("."),El=_(),He=c("h3"),st=c("a"),mo=c("span"),M(Rt.$$.fragment),pr=_(),ho=c("span"),cr=r("AutoTokenizer"),jl=_(),Fe=c("p"),ur=r("Un tokenizer \xE8 responsabile dell\u2019elaborazione del testo in modo da trasformarlo in un formato comprensibile dal modello. Per prima cosa, il tokenizer divider\xE0 il testo in parole chiamate "),$o=c("em"),fr=r("token"),mr=r(". Ci sono diverse regole che governano il processo di tokenizzazione, tra cui come dividere una parola e a quale livello (impara di pi\xF9 sulla tokenizzazione "),ra=c("a"),dr=r("qui"),hr=r("). La cosa pi\xF9 importante da ricordare comunque \xE8 che hai bisogno di inizializzare il tokenizer con lo stesso nome del modello in modo da assicurarti che stai utilizzando le stesse regole di tokenizzazione con cui il modello \xE8 stato pre-allenato."),Al=_(),it=c("p"),$r=r("Carica un tokenizer con "),go=c("code"),gr=r("AutoTokenizer"),_r=r(":"),Cl=_(),M(Ut.$$.fragment),ql=_(),rt=c("p"),vr=r("Dopodich\xE9, il tokenizer converte i token in numeri in modo da costruire un tensore come input del modello. Questo \xE8 conosciuto come il "),_o=c("em"),zr=r("vocabolario"),kr=r(" del modello."),Tl=_(),na=c("p"),wr=r("Passa il tuo testo al tokenizer:"),Ml=_(),M(Gt.$$.fragment),Sl=_(),pa=c("p"),br=r("Il tokenizer restituir\xE0 un dizionario contenente:"),yl=_(),nt=c("ul"),ca=c("li"),ua=c("a"),Er=r("input_ids"),jr=r(": rappresentazioni numeriche dei tuoi token."),Ar=_(),fa=c("li"),ma=c("a"),Cr=r("attention_mask"),qr=r(": indica quali token devono essere presi in considerazione."),Pl=_(),pt=c("p"),Tr=r("Come con la "),vo=c("code"),Mr=r("pipeline()"),Sr=r(", il tokenizer accetter\xE0 una lista di input. In pi\xF9, il tokenizer pu\xF2 anche completare (pad, in inglese) e troncare il testo in modo da restituire un lotto (batch, in inglese) di lunghezza uniforme:"),Dl=_(),M(ct.$$.fragment),Fl=_(),ut=c("p"),yr=r("Leggi il tutorial sul "),da=c("a"),Pr=r("preproccesing"),Dr=r(" per maggiori dettagli sulla tokenizzazione."),Il=_(),Re=c("h3"),ft=c("a"),zo=c("span"),M(Qt.$$.fragment),Fr=_(),ko=c("span"),Ir=r("AutoModel"),Ol=_(),M(mt.$$.fragment),xl=_(),M(dt.$$.fragment),Ll=_(),de=c("p"),Or=r("I modelli sono "),Kt=c("a"),wo=c("code"),xr=r("torch.nn.Module"),Lr=r(" o "),Jt=c("a"),bo=c("code"),Nr=r("tf.keras.Model"),Hr=r(" standard cos\xEC puoi utilizzarli all\u2019interno del tuo training loop usuale. Tuttavia, per rendere le cose pi\xF9 semplici, \u{1F917} Transformers fornisce una classe "),Eo=c("code"),Rr=r("Trainer"),Ur=r(" per PyTorch che aggiunge delle funzionalit\xE0 per l\u2019allenamento distribuito, precisione mista, e altro ancora. Per TensorFlow, puoi utilizzare il metodo "),jo=c("code"),Gr=r("fit"),Qr=r(" di "),Bt=c("a"),Kr=r("Keras"),Jr=r(". Fai riferimento al "),ha=c("a"),Br=r("tutorial per il training"),Vr=r(" per maggiori dettagli."),Nl=_(),M(ht.$$.fragment),Hl=_(),Ue=c("h3"),$t=c("a"),Ao=c("span"),M(Vt.$$.fragment),Zr=_(),Co=c("span"),Yr=r("Salva un modello"),Rl=_(),M(gt.$$.fragment),Ul=_(),Ie=c("p"),Wr=r("Una caratteristica particolarmente interessante di \u{1F917} Transformers \xE8 la sua abilit\xE0 di salvare un modello e ri-caricarlo sia come modello di PyTorch che di TensorFlow. I parametri "),qo=c("code"),Xr=r("from_pt"),en=r(" o "),To=c("code"),tn=r("from_tf"),an=r(" possono convertire un modello da un framework all\u2019altro:"),Gl=_(),M(_t.$$.fragment),this.h()},l(t){const m=oc('[data-svelte="svelte-1phssyn"]',document.head);e=u(m,"META",{name:!0,content:!0}),m.forEach(l),i=v(t),a=u(t,"H1",{class:!0});var Zt=p(a);s=u(Zt,"A",{id:!0,class:!0,href:!0});var Mo=p(s);f=u(Mo,"SPAN",{});var So=p(f);D(g.$$.fragment,So),So.forEach(l),Mo.forEach(l),k=v(Zt),w=u(Zt,"SPAN",{});var yo=p(w);b=n(yo,"Quick tour"),yo.forEach(l),Zt.forEach(l),C=v(t),D(A.$$.fragment,t),F=v(t),I=u(t,"P",{});var Ge=p(I);H=n(Ge,"Entra in azione con \u{1F917} Transformers! Inizia utilizzando "),T=u(Ge,"CODE",{});var Po=p(T);x=n(Po,"pipeline()"),Po.forEach(l),z=n(Ge," per un\u2019inferenza veloce, carica un modello pre-allenato e un tokenizer con una "),q=u(Ge,"A",{href:!0});var Do=p(q);G=n(Do,"AutoClass"),Do.forEach(l),Q=n(Ge," per risolvere i tuoi compiti legati a testo, immagini o audio."),Ge.forEach(l),L=v(t),D(K.$$.fragment,t),Z=v(t),J=u(t,"H2",{class:!0});var Yt=p(J);V=u(Yt,"A",{id:!0,class:!0,href:!0});var Fo=p(V);se=u(Fo,"SPAN",{});var Io=p(se);D(oe.$$.fragment,Io),Io.forEach(l),Fo.forEach(l),le=v(Yt),ce=u(Yt,"SPAN",{});var fn=p(ce);re=n(fn,"Pipeline"),fn.forEach(l),Yt.forEach(l),ue=v(t),ie=u(t,"P",{});var on=p(ie);X=u(on,"CODE",{});var mn=p(X);ne=n(mn,"pipeline()"),mn.forEach(l),fe=n(on," \xE8 il modo pi\xF9 semplice per utilizzare un modello pre-allenato per un dato compito."),on.forEach(l),O=v(t),D(N.$$.fragment,t),te=v(t),P=u(t,"P",{});var Kl=p(P);B=n(Kl,"La "),pe=u(Kl,"CODE",{});var dn=p(pe);$e=n(dn,"pipeline()"),dn.forEach(l),W=n(Kl," supporta molti compiti comuni:"),Kl.forEach(l),be=v(t),ae=u(t,"P",{});var ln=p(ae);Ee=u(ln,"STRONG",{});var hn=p(Ee);ve=n(hn,"Testo"),hn.forEach(l),Ae=n(ln,":"),ln.forEach(l),ge=v(t),ee=u(t,"UL",{});var _e=p(ee);Ce=u(_e,"LI",{});var $n=p(Ce);fs=n($n,"Analisi del Sentimento (Sentiment Analysis, in inglese): classifica la polarit\xE0 di un testo dato."),$n.forEach(l),ms=v(_e),Ta=u(_e,"LI",{});var gn=p(Ta);ds=n(gn,"Generazione del Testo (Text Generation, in inglese): genera del testo a partire da un dato input."),gn.forEach(l),hs=v(_e),Ma=u(_e,"LI",{});var _n=p(Ma);$s=n(_n,"Riconoscimento di Entit\xE0 (Name Entity Recognition o NER, in inglese): etichetta ogni parola con l\u2019entit\xE0 che questa rappresenta (persona, data, luogo, ecc.)."),_n.forEach(l),gs=v(_e),Sa=u(_e,"LI",{});var vn=p(Sa);_s=n(vn,"Rispondere a Domande (Question answering, in inglese): estrae la risposta da un contesto, dato del contesto e una domanda."),vn.forEach(l),vs=v(_e),ya=u(_e,"LI",{});var zn=p(ya);zs=n(zn,"Riempimento di Maschere (Fill-mask, in inglese): riempie gli spazi mancanti in un testo che ha parole mascherate."),zn.forEach(l),ks=v(_e),Pa=u(_e,"LI",{});var kn=p(Pa);ws=n(kn,"Riassumere (Summarization, in inglese): genera una sintesi di una lunga sequenza di testo o di un documento."),kn.forEach(l),bs=v(_e),Da=u(_e,"LI",{});var wn=p(Da);Es=n(wn,"Traduzione (Translation, in inglese): traduce un testo in un\u2019altra lingua."),wn.forEach(l),js=v(_e),Fa=u(_e,"LI",{});var bn=p(Fa);As=n(bn,"Estrazione di Caratteristiche (Feature Extraction, in inglese): crea un tensore che rappresenta un testo."),bn.forEach(l),_e.forEach(l),Ho=v(t),zt=u(t,"P",{});var sn=p(zt);Ia=u(sn,"STRONG",{});var En=p(Ia);Cs=n(En,"Immagini"),En.forEach(l),qs=n(sn,":"),sn.forEach(l),Ro=v(t),qe=u(t,"UL",{});var $a=p(qe);Oa=u($a,"LI",{});var jn=p(Oa);Ts=n(jn,"Classificazione di Immagini (Image Classification, in inglese): classifica un\u2019immagine."),jn.forEach(l),Ms=v($a),xa=u($a,"LI",{});var An=p(xa);Ss=n(An,"Segmentazione di Immagini (Image Segmentation, in inglese): classifica ogni pixel di un\u2019immagine."),An.forEach(l),ys=v($a),La=u($a,"LI",{});var Cn=p(La);Ps=n(Cn,"Rilevazione di Oggetti (Object Detection, in inglese): rileva oggetti all\u2019interno di un\u2019immagine."),Cn.forEach(l),$a.forEach(l),Uo=v(t),kt=u(t,"P",{});var rn=p(kt);Na=u(rn,"STRONG",{});var qn=p(Na);Ds=n(qn,"Audio"),qn.forEach(l),Fs=n(rn,":"),rn.forEach(l),Go=v(t),Ke=u(t,"UL",{});var Jl=p(Ke);Ha=u(Jl,"LI",{});var Tn=p(Ha);Is=n(Tn,"Classificazione di Audio (Audio Classification, in inglese): assegna un\u2019etichetta ad un segmento di audio dato."),Tn.forEach(l),Os=v(Jl),Ra=u(Jl,"LI",{});var Mn=p(Ra);xs=n(Mn,"Riconoscimento Vocale Automatico (Automatic Speech Recognition o ASR, in inglese): trascrive il contenuto di un audio dato in un testo."),Mn.forEach(l),Jl.forEach(l),Qo=v(t),D(Je.$$.fragment,t),Ko=v(t),xe=u(t,"H3",{class:!0});var Bl=p(xe);Be=u(Bl,"A",{id:!0,class:!0,href:!0});var Sn=p(Be);Ua=u(Sn,"SPAN",{});var yn=p(Ua);D(wt.$$.fragment,yn),yn.forEach(l),Sn.forEach(l),Ls=v(Bl),Ga=u(Bl,"SPAN",{});var Pn=p(Ga);Ns=n(Pn,"Utilizzo della Pipeline"),Pn.forEach(l),Bl.forEach(l),Jo=v(t),Ve=u(t,"P",{});var Vl=p(Ve);Hs=n(Vl,"Nel seguente esempio, utilizzerai la "),Qa=u(Vl,"CODE",{});var Dn=p(Qa);Rs=n(Dn,"pipeline()"),Dn.forEach(l),Us=n(Vl," per l\u2019analisi del sentimento."),Vl.forEach(l),Bo=v(t),ta=u(t,"P",{});var Fn=p(ta);Gs=n(Fn,"Installa le seguenti dipendenze se non lo hai gi\xE0 fatto:"),Fn.forEach(l),Vo=v(t),D(Ze.$$.fragment,t),Zo=v(t),Ye=u(t,"P",{});var Zl=p(Ye);Qs=n(Zl,"Importa "),Ka=u(Zl,"CODE",{});var In=p(Ka);Ks=n(In,"pipeline()"),In.forEach(l),Js=n(Zl," e specifica il compito che vuoi completare:"),Zl.forEach(l),Yo=v(t),D(bt.$$.fragment,t),Wo=v(t),Te=u(t,"P",{});var ga=p(Te);Bs=n(ga,"La pipeline scarica e salva il "),Et=u(ga,"A",{href:!0,rel:!0});var On=p(Et);Vs=n(On,"modello pre-allenato"),On.forEach(l),Zs=n(ga," e il tokenizer per l\u2019analisi del sentimento. Se non avessimo scelto un modello, la pipeline ne avrebbe scelto uno di default. Ora puoi utilizzare il "),Ja=u(ga,"CODE",{});var xn=p(Ja);Ys=n(xn,"classifier"),xn.forEach(l),Ws=n(ga," sul tuo testo obiettivo:"),ga.forEach(l),Xo=v(t),D(jt.$$.fragment,t),el=v(t),We=u(t,"P",{});var Yl=p(We);Xs=n(Yl,"Per pi\xF9 di una frase, passa una lista di frasi alla "),Ba=u(Yl,"CODE",{});var Ln=p(Ba);ei=n(Ln,"pipeline()"),Ln.forEach(l),ti=n(Yl," la quale restituir\xE0 una lista di dizionari:"),Yl.forEach(l),tl=v(t),D(At.$$.fragment,t),al=v(t),Me=u(t,"P",{});var _a=p(Me);ai=n(_a,"La "),Va=u(_a,"CODE",{});var Nn=p(Va);oi=n(Nn,"pipeline()"),Nn.forEach(l),li=n(_a," pu\xF2 anche iterare su un dataset intero. Inizia installando la libreria "),Ct=u(_a,"A",{href:!0,rel:!0});var Hn=p(Ct);si=n(Hn,"\u{1F917} Datasets"),Hn.forEach(l),ii=n(_a,":"),_a.forEach(l),ol=v(t),D(qt.$$.fragment,t),ll=v(t),Xe=u(t,"P",{});var Wl=p(Xe);ri=n(Wl,"Crea una "),Za=u(Wl,"CODE",{});var Rn=p(Za);ni=n(Rn,"pipeline()"),Rn.forEach(l),pi=n(Wl," con il compito che vuoi risolvere e con il modello che vuoi utilizzare."),Wl.forEach(l),sl=v(t),D(Tt.$$.fragment,t),il=v(t),Se=u(t,"P",{});var va=p(Se);ci=n(va,"Poi, carica un dataset (vedi \u{1F917} Datasets "),Mt=u(va,"A",{href:!0,rel:!0});var Un=p(Mt);ui=n(Un,"Quick Start"),Un.forEach(l),fi=n(va," per maggiori dettagli) sul quale vuoi iterare. Per esempio, carichiamo il dataset "),St=u(va,"A",{href:!0,rel:!0});var Gn=p(St);mi=n(Gn,"MInDS-14"),Gn.forEach(l),di=n(va,":"),va.forEach(l),rl=v(t),D(yt.$$.fragment,t),nl=v(t),et=u(t,"P",{});var Xl=p(et);hi=n(Xl,"Dobbiamo assicurarci che la frequenza di campionamento del set di dati corrisponda alla frequenza di campionamento con cui \xE8 stato addestrato "),Ya=u(Xl,"CODE",{});var Qn=p(Ya);$i=n(Qn,"radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram"),Qn.forEach(l),gi=n(Xl,"."),Xl.forEach(l),pl=v(t),D(Pt.$$.fragment,t),cl=v(t),aa=u(t,"P",{});var Kn=p(aa);_i=n(Kn,`I file audio vengono caricati automaticamente e ri-campionati quando chiamiamo la colonna \u201Caudio\u201D.
Estraiamo i vettori delle forme d\u2019onda grezze delle prime 4 osservazioni e passiamoli come lista alla pipeline:`),Kn.forEach(l),ul=v(t),D(Dt.$$.fragment,t),fl=v(t),tt=u(t,"P",{});var es=p(tt);vi=n(es,"Per un dataset pi\xF9 grande dove gli input sono di dimensione maggiore (come nel parlato/audio o nella visione), dovrai passare un generatore al posto di una lista che carica tutti gli input in memoria. Guarda la "),oa=u(es,"A",{href:!0});var Jn=p(oa);zi=n(Jn,"documentazione della pipeline"),Jn.forEach(l),ki=n(es," per maggiori informazioni."),es.forEach(l),ml=v(t),Le=u(t,"H3",{class:!0});var ts=p(Le);at=u(ts,"A",{id:!0,class:!0,href:!0});var Bn=p(at);Wa=u(Bn,"SPAN",{});var Vn=p(Wa);D(Ft.$$.fragment,Vn),Vn.forEach(l),Bn.forEach(l),wi=v(ts),Xa=u(ts,"SPAN",{});var Zn=p(Xa);bi=n(Zn,"Utilizzare un altro modello e tokenizer nella pipeline"),Zn.forEach(l),ts.forEach(l),dl=v(t),ze=u(t,"P",{});var Oe=p(ze);Ei=n(Oe,"La "),eo=u(Oe,"CODE",{});var Yn=p(eo);ji=n(Yn,"pipeline()"),Yn.forEach(l),Ai=n(Oe," pu\xF2 ospitare qualsiasi modello del "),It=u(Oe,"A",{href:!0,rel:!0});var Wn=p(It);Ci=n(Wn,"Model Hub"),Wn.forEach(l),qi=n(Oe,", rendendo semplice l\u2019adattamento della "),to=u(Oe,"CODE",{});var Xn=p(to);Ti=n(Xn,"pipeline()"),Xn.forEach(l),Mi=n(Oe," per altri casi d\u2019uso. Per esempio, se si vuole un modello capace di trattare testo in francese, usa i tag presenti nel Model Hub in modo da filtrare per ottenere un modello appropriato. Il miglior risultato filtrato restituisce un modello multi-lingua "),Ot=u(Oe,"A",{href:!0,rel:!0});var ep=p(Ot);Si=n(ep,"BERT model"),ep.forEach(l),yi=n(Oe," fine-tuned per l\u2019analisi del sentimento. Ottimo, utilizziamo questo modello!"),Oe.forEach(l),hl=v(t),D(xt.$$.fragment,t),$l=v(t),D(ot.$$.fragment,t),gl=v(t),ye=u(t,"P",{});var za=p(ye);Pi=n(za,"Poi puoi specificare il modello e il tokenizer nella "),ao=u(za,"CODE",{});var tp=p(ao);Di=n(tp,"pipeline()"),tp.forEach(l),Fi=n(za,", e applicare il "),oo=u(za,"CODE",{});var ap=p(oo);Ii=n(ap,"classifier"),ap.forEach(l),Oi=n(za," sul tuo testo obiettivo:"),za.forEach(l),_l=v(t),D(Lt.$$.fragment,t),vl=v(t),Pe=u(t,"P",{});var ka=p(Pe);xi=n(ka,"Se non riesci a trovare un modello per il tuo caso d\u2019uso, dovrai fare fine-tuning di un modello pre-allenato sui tuoi dati. Dai un\u2019occhiata al nostro tutorial "),la=u(ka,"A",{href:!0});var op=p(la);Li=n(op,"fine-tuning tutorial"),op.forEach(l),Ni=n(ka," per imparare come. Infine, dopo che hai completato il fine-tuning del tuo modello pre-allenato, considera per favore di condividerlo (vedi il tutorial "),sa=u(ka,"A",{href:!0});var lp=p(sa);Hi=n(lp,"qui"),lp.forEach(l),Ri=n(ka,") con la comunit\xE0 sul Model Hub per democratizzare l\u2019NLP! \u{1F917}"),ka.forEach(l),zl=v(t),Ne=u(t,"H2",{class:!0});var as=p(Ne);lt=u(as,"A",{id:!0,class:!0,href:!0});var sp=p(lt);lo=u(sp,"SPAN",{});var ip=p(lo);D(Nt.$$.fragment,ip),ip.forEach(l),sp.forEach(l),Ui=v(as),so=u(as,"SPAN",{});var rp=p(so);Gi=n(rp,"AutoClass"),rp.forEach(l),as.forEach(l),kl=v(t),D(Ht.$$.fragment,t),wl=v(t),me=u(t,"P",{});var ke=p(me);Qi=n(ke,"Al suo interno, le classi "),io=u(ke,"CODE",{});var np=p(io);Ki=n(np,"AutoModelForSequenceClassification"),np.forEach(l),Ji=n(ke," e "),ro=u(ke,"CODE",{});var pp=p(ro);Bi=n(pp,"AutoTokenizer"),pp.forEach(l),Vi=n(ke," lavorano assieme per dare potere alla "),no=u(ke,"CODE",{});var cp=p(no);Zi=n(cp,"pipeline()"),cp.forEach(l),Yi=n(ke,". Una "),ia=u(ke,"A",{href:!0});var up=p(ia);Wi=n(up,"AutoClass"),up.forEach(l),Xi=n(ke," \xE8 una scorciatoia che automaticamente recupera l\u2019architettura di un modello pre-allenato a partire dal suo nome o path. Hai solo bisogno di selezionare la "),po=u(ke,"CODE",{});var fp=p(po);er=n(fp,"AutoClass"),fp.forEach(l),tr=n(ke," appropriata per il tuo compito e il suo tokenizer associato con "),co=u(ke,"CODE",{});var mp=p(co);ar=n(mp,"AutoTokenizer"),mp.forEach(l),or=n(ke,"."),ke.forEach(l),bl=v(t),De=u(t,"P",{});var wa=p(De);lr=n(wa,"Ritorniamo al nostro esempio e vediamo come puoi utilizzare la "),uo=u(wa,"CODE",{});var dp=p(uo);sr=n(dp,"AutoClass"),dp.forEach(l),ir=n(wa," per replicare i risultati della "),fo=u(wa,"CODE",{});var hp=p(fo);rr=n(hp,"pipeline()"),hp.forEach(l),nr=n(wa,"."),wa.forEach(l),El=v(t),He=u(t,"H3",{class:!0});var os=p(He);st=u(os,"A",{id:!0,class:!0,href:!0});var $p=p(st);mo=u($p,"SPAN",{});var gp=p(mo);D(Rt.$$.fragment,gp),gp.forEach(l),$p.forEach(l),pr=v(os),ho=u(os,"SPAN",{});var _p=p(ho);cr=n(_p,"AutoTokenizer"),_p.forEach(l),os.forEach(l),jl=v(t),Fe=u(t,"P",{});var ba=p(Fe);ur=n(ba,"Un tokenizer \xE8 responsabile dell\u2019elaborazione del testo in modo da trasformarlo in un formato comprensibile dal modello. Per prima cosa, il tokenizer divider\xE0 il testo in parole chiamate "),$o=u(ba,"EM",{});var vp=p($o);fr=n(vp,"token"),vp.forEach(l),mr=n(ba,". Ci sono diverse regole che governano il processo di tokenizzazione, tra cui come dividere una parola e a quale livello (impara di pi\xF9 sulla tokenizzazione "),ra=u(ba,"A",{href:!0});var zp=p(ra);dr=n(zp,"qui"),zp.forEach(l),hr=n(ba,"). La cosa pi\xF9 importante da ricordare comunque \xE8 che hai bisogno di inizializzare il tokenizer con lo stesso nome del modello in modo da assicurarti che stai utilizzando le stesse regole di tokenizzazione con cui il modello \xE8 stato pre-allenato."),ba.forEach(l),Al=v(t),it=u(t,"P",{});var ls=p(it);$r=n(ls,"Carica un tokenizer con "),go=u(ls,"CODE",{});var kp=p(go);gr=n(kp,"AutoTokenizer"),kp.forEach(l),_r=n(ls,":"),ls.forEach(l),Cl=v(t),D(Ut.$$.fragment,t),ql=v(t),rt=u(t,"P",{});var ss=p(rt);vr=n(ss,"Dopodich\xE9, il tokenizer converte i token in numeri in modo da costruire un tensore come input del modello. Questo \xE8 conosciuto come il "),_o=u(ss,"EM",{});var wp=p(_o);zr=n(wp,"vocabolario"),wp.forEach(l),kr=n(ss," del modello."),ss.forEach(l),Tl=v(t),na=u(t,"P",{});var bp=p(na);wr=n(bp,"Passa il tuo testo al tokenizer:"),bp.forEach(l),Ml=v(t),D(Gt.$$.fragment,t),Sl=v(t),pa=u(t,"P",{});var Ep=p(pa);br=n(Ep,"Il tokenizer restituir\xE0 un dizionario contenente:"),Ep.forEach(l),yl=v(t),nt=u(t,"UL",{});var is=p(nt);ca=u(is,"LI",{});var nn=p(ca);ua=u(nn,"A",{href:!0});var jp=p(ua);Er=n(jp,"input_ids"),jp.forEach(l),jr=n(nn,": rappresentazioni numeriche dei tuoi token."),nn.forEach(l),Ar=v(is),fa=u(is,"LI",{});var pn=p(fa);ma=u(pn,"A",{href:!0});var Ap=p(ma);Cr=n(Ap,"attention_mask"),Ap.forEach(l),qr=n(pn,": indica quali token devono essere presi in considerazione."),pn.forEach(l),is.forEach(l),Pl=v(t),pt=u(t,"P",{});var rs=p(pt);Tr=n(rs,"Come con la "),vo=u(rs,"CODE",{});var Cp=p(vo);Mr=n(Cp,"pipeline()"),Cp.forEach(l),Sr=n(rs,", il tokenizer accetter\xE0 una lista di input. In pi\xF9, il tokenizer pu\xF2 anche completare (pad, in inglese) e troncare il testo in modo da restituire un lotto (batch, in inglese) di lunghezza uniforme:"),rs.forEach(l),Dl=v(t),D(ct.$$.fragment,t),Fl=v(t),ut=u(t,"P",{});var ns=p(ut);yr=n(ns,"Leggi il tutorial sul "),da=u(ns,"A",{href:!0});var qp=p(da);Pr=n(qp,"preproccesing"),qp.forEach(l),Dr=n(ns," per maggiori dettagli sulla tokenizzazione."),ns.forEach(l),Il=v(t),Re=u(t,"H3",{class:!0});var ps=p(Re);ft=u(ps,"A",{id:!0,class:!0,href:!0});var Tp=p(ft);zo=u(Tp,"SPAN",{});var Mp=p(zo);D(Qt.$$.fragment,Mp),Mp.forEach(l),Tp.forEach(l),Fr=v(ps),ko=u(ps,"SPAN",{});var Sp=p(ko);Ir=n(Sp,"AutoModel"),Sp.forEach(l),ps.forEach(l),Ol=v(t),D(mt.$$.fragment,t),xl=v(t),D(dt.$$.fragment,t),Ll=v(t),de=u(t,"P",{});var we=p(de);Or=n(we,"I modelli sono "),Kt=u(we,"A",{href:!0,rel:!0});var yp=p(Kt);wo=u(yp,"CODE",{});var Pp=p(wo);xr=n(Pp,"torch.nn.Module"),Pp.forEach(l),yp.forEach(l),Lr=n(we," o "),Jt=u(we,"A",{href:!0,rel:!0});var Dp=p(Jt);bo=u(Dp,"CODE",{});var Fp=p(bo);Nr=n(Fp,"tf.keras.Model"),Fp.forEach(l),Dp.forEach(l),Hr=n(we," standard cos\xEC puoi utilizzarli all\u2019interno del tuo training loop usuale. Tuttavia, per rendere le cose pi\xF9 semplici, \u{1F917} Transformers fornisce una classe "),Eo=u(we,"CODE",{});var Ip=p(Eo);Rr=n(Ip,"Trainer"),Ip.forEach(l),Ur=n(we," per PyTorch che aggiunge delle funzionalit\xE0 per l\u2019allenamento distribuito, precisione mista, e altro ancora. Per TensorFlow, puoi utilizzare il metodo "),jo=u(we,"CODE",{});var Op=p(jo);Gr=n(Op,"fit"),Op.forEach(l),Qr=n(we," di "),Bt=u(we,"A",{href:!0,rel:!0});var xp=p(Bt);Kr=n(xp,"Keras"),xp.forEach(l),Jr=n(we,". Fai riferimento al "),ha=u(we,"A",{href:!0});var Lp=p(ha);Br=n(Lp,"tutorial per il training"),Lp.forEach(l),Vr=n(we," per maggiori dettagli."),we.forEach(l),Nl=v(t),D(ht.$$.fragment,t),Hl=v(t),Ue=u(t,"H3",{class:!0});var cs=p(Ue);$t=u(cs,"A",{id:!0,class:!0,href:!0});var Np=p($t);Ao=u(Np,"SPAN",{});var Hp=p(Ao);D(Vt.$$.fragment,Hp),Hp.forEach(l),Np.forEach(l),Zr=v(cs),Co=u(cs,"SPAN",{});var Rp=p(Co);Yr=n(Rp,"Salva un modello"),Rp.forEach(l),cs.forEach(l),Rl=v(t),D(gt.$$.fragment,t),Ul=v(t),Ie=u(t,"P",{});var Ea=p(Ie);Wr=n(Ea,"Una caratteristica particolarmente interessante di \u{1F917} Transformers \xE8 la sua abilit\xE0 di salvare un modello e ri-caricarlo sia come modello di PyTorch che di TensorFlow. I parametri "),qo=u(Ea,"CODE",{});var Up=p(qo);Xr=n(Up,"from_pt"),Up.forEach(l),en=n(Ea," o "),To=u(Ea,"CODE",{});var Gp=p(To);tn=n(Gp,"from_tf"),Gp.forEach(l),an=n(Ea," possono convertire un modello da un framework all\u2019altro:"),Ea.forEach(l),Gl=v(t),D(_t.$$.fragment,t),this.h()},h(){h(e,"name","hf:doc:metadata"),h(e,"content",JSON.stringify(pu)),h(s,"id","quick-tour"),h(s,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(s,"href","#quick-tour"),h(a,"class","relative group"),h(q,"href","./model_doc/auto"),h(V,"id","pipeline"),h(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(V,"href","#pipeline"),h(J,"class","relative group"),h(Be,"id","utilizzo-della-pipeline"),h(Be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Be,"href","#utilizzo-della-pipeline"),h(xe,"class","relative group"),h(Et,"href","https://huggingface.co/MilaNLProc/feel-it-italian-sentiment"),h(Et,"rel","nofollow"),h(Ct,"href","https://huggingface.co/docs/datasets/"),h(Ct,"rel","nofollow"),h(Mt,"href","https://huggingface.co/docs/datasets/quickstart.html"),h(Mt,"rel","nofollow"),h(St,"href","https://huggingface.co/datasets/PolyAI/minds14"),h(St,"rel","nofollow"),h(oa,"href","./main_classes/pipelines"),h(at,"id","utilizzare-un-altro-modello-e-tokenizer-nella-pipeline"),h(at,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(at,"href","#utilizzare-un-altro-modello-e-tokenizer-nella-pipeline"),h(Le,"class","relative group"),h(It,"href","https://huggingface.co/models"),h(It,"rel","nofollow"),h(Ot,"href","https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"),h(Ot,"rel","nofollow"),h(la,"href","./training"),h(sa,"href","./model_sharing"),h(lt,"id","autoclass"),h(lt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(lt,"href","#autoclass"),h(Ne,"class","relative group"),h(ia,"href","./model_doc/auto"),h(st,"id","autotokenizer"),h(st,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(st,"href","#autotokenizer"),h(He,"class","relative group"),h(ra,"href","./tokenizer_summary"),h(ua,"href","./glossary#input-ids"),h(ma,"href",".glossary#attention-mask"),h(da,"href","./preprocessing"),h(ft,"id","automodel"),h(ft,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ft,"href","#automodel"),h(Re,"class","relative group"),h(Kt,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(Kt,"rel","nofollow"),h(Jt,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(Jt,"rel","nofollow"),h(Bt,"href","https://keras.io/"),h(Bt,"rel","nofollow"),h(ha,"href","./training"),h($t,"id","salva-un-modello"),h($t,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h($t,"href","#salva-un-modello"),h(Ue,"class","relative group")},m(t,m){o(document.head,e),d(t,i,m),d(t,a,m),o(a,s),o(s,f),S(g,f,null),o(a,k),o(a,w),o(w,b),d(t,C,m),S(A,t,m),d(t,F,m),d(t,I,m),o(I,H),o(I,T),o(T,x),o(I,z),o(I,q),o(q,G),o(I,Q),d(t,L,m),S(K,t,m),d(t,Z,m),d(t,J,m),o(J,V),o(V,se),S(oe,se,null),o(J,le),o(J,ce),o(ce,re),d(t,ue,m),d(t,ie,m),o(ie,X),o(X,ne),o(ie,fe),d(t,O,m),S(N,t,m),d(t,te,m),d(t,P,m),o(P,B),o(P,pe),o(pe,$e),o(P,W),d(t,be,m),d(t,ae,m),o(ae,Ee),o(Ee,ve),o(ae,Ae),d(t,ge,m),d(t,ee,m),o(ee,Ce),o(Ce,fs),o(ee,ms),o(ee,Ta),o(Ta,ds),o(ee,hs),o(ee,Ma),o(Ma,$s),o(ee,gs),o(ee,Sa),o(Sa,_s),o(ee,vs),o(ee,ya),o(ya,zs),o(ee,ks),o(ee,Pa),o(Pa,ws),o(ee,bs),o(ee,Da),o(Da,Es),o(ee,js),o(ee,Fa),o(Fa,As),d(t,Ho,m),d(t,zt,m),o(zt,Ia),o(Ia,Cs),o(zt,qs),d(t,Ro,m),d(t,qe,m),o(qe,Oa),o(Oa,Ts),o(qe,Ms),o(qe,xa),o(xa,Ss),o(qe,ys),o(qe,La),o(La,Ps),d(t,Uo,m),d(t,kt,m),o(kt,Na),o(Na,Ds),o(kt,Fs),d(t,Go,m),d(t,Ke,m),o(Ke,Ha),o(Ha,Is),o(Ke,Os),o(Ke,Ra),o(Ra,xs),d(t,Qo,m),S(Je,t,m),d(t,Ko,m),d(t,xe,m),o(xe,Be),o(Be,Ua),S(wt,Ua,null),o(xe,Ls),o(xe,Ga),o(Ga,Ns),d(t,Jo,m),d(t,Ve,m),o(Ve,Hs),o(Ve,Qa),o(Qa,Rs),o(Ve,Us),d(t,Bo,m),d(t,ta,m),o(ta,Gs),d(t,Vo,m),S(Ze,t,m),d(t,Zo,m),d(t,Ye,m),o(Ye,Qs),o(Ye,Ka),o(Ka,Ks),o(Ye,Js),d(t,Yo,m),S(bt,t,m),d(t,Wo,m),d(t,Te,m),o(Te,Bs),o(Te,Et),o(Et,Vs),o(Te,Zs),o(Te,Ja),o(Ja,Ys),o(Te,Ws),d(t,Xo,m),S(jt,t,m),d(t,el,m),d(t,We,m),o(We,Xs),o(We,Ba),o(Ba,ei),o(We,ti),d(t,tl,m),S(At,t,m),d(t,al,m),d(t,Me,m),o(Me,ai),o(Me,Va),o(Va,oi),o(Me,li),o(Me,Ct),o(Ct,si),o(Me,ii),d(t,ol,m),S(qt,t,m),d(t,ll,m),d(t,Xe,m),o(Xe,ri),o(Xe,Za),o(Za,ni),o(Xe,pi),d(t,sl,m),S(Tt,t,m),d(t,il,m),d(t,Se,m),o(Se,ci),o(Se,Mt),o(Mt,ui),o(Se,fi),o(Se,St),o(St,mi),o(Se,di),d(t,rl,m),S(yt,t,m),d(t,nl,m),d(t,et,m),o(et,hi),o(et,Ya),o(Ya,$i),o(et,gi),d(t,pl,m),S(Pt,t,m),d(t,cl,m),d(t,aa,m),o(aa,_i),d(t,ul,m),S(Dt,t,m),d(t,fl,m),d(t,tt,m),o(tt,vi),o(tt,oa),o(oa,zi),o(tt,ki),d(t,ml,m),d(t,Le,m),o(Le,at),o(at,Wa),S(Ft,Wa,null),o(Le,wi),o(Le,Xa),o(Xa,bi),d(t,dl,m),d(t,ze,m),o(ze,Ei),o(ze,eo),o(eo,ji),o(ze,Ai),o(ze,It),o(It,Ci),o(ze,qi),o(ze,to),o(to,Ti),o(ze,Mi),o(ze,Ot),o(Ot,Si),o(ze,yi),d(t,hl,m),S(xt,t,m),d(t,$l,m),S(ot,t,m),d(t,gl,m),d(t,ye,m),o(ye,Pi),o(ye,ao),o(ao,Di),o(ye,Fi),o(ye,oo),o(oo,Ii),o(ye,Oi),d(t,_l,m),S(Lt,t,m),d(t,vl,m),d(t,Pe,m),o(Pe,xi),o(Pe,la),o(la,Li),o(Pe,Ni),o(Pe,sa),o(sa,Hi),o(Pe,Ri),d(t,zl,m),d(t,Ne,m),o(Ne,lt),o(lt,lo),S(Nt,lo,null),o(Ne,Ui),o(Ne,so),o(so,Gi),d(t,kl,m),S(Ht,t,m),d(t,wl,m),d(t,me,m),o(me,Qi),o(me,io),o(io,Ki),o(me,Ji),o(me,ro),o(ro,Bi),o(me,Vi),o(me,no),o(no,Zi),o(me,Yi),o(me,ia),o(ia,Wi),o(me,Xi),o(me,po),o(po,er),o(me,tr),o(me,co),o(co,ar),o(me,or),d(t,bl,m),d(t,De,m),o(De,lr),o(De,uo),o(uo,sr),o(De,ir),o(De,fo),o(fo,rr),o(De,nr),d(t,El,m),d(t,He,m),o(He,st),o(st,mo),S(Rt,mo,null),o(He,pr),o(He,ho),o(ho,cr),d(t,jl,m),d(t,Fe,m),o(Fe,ur),o(Fe,$o),o($o,fr),o(Fe,mr),o(Fe,ra),o(ra,dr),o(Fe,hr),d(t,Al,m),d(t,it,m),o(it,$r),o(it,go),o(go,gr),o(it,_r),d(t,Cl,m),S(Ut,t,m),d(t,ql,m),d(t,rt,m),o(rt,vr),o(rt,_o),o(_o,zr),o(rt,kr),d(t,Tl,m),d(t,na,m),o(na,wr),d(t,Ml,m),S(Gt,t,m),d(t,Sl,m),d(t,pa,m),o(pa,br),d(t,yl,m),d(t,nt,m),o(nt,ca),o(ca,ua),o(ua,Er),o(ca,jr),o(nt,Ar),o(nt,fa),o(fa,ma),o(ma,Cr),o(fa,qr),d(t,Pl,m),d(t,pt,m),o(pt,Tr),o(pt,vo),o(vo,Mr),o(pt,Sr),d(t,Dl,m),S(ct,t,m),d(t,Fl,m),d(t,ut,m),o(ut,yr),o(ut,da),o(da,Pr),o(ut,Dr),d(t,Il,m),d(t,Re,m),o(Re,ft),o(ft,zo),S(Qt,zo,null),o(Re,Fr),o(Re,ko),o(ko,Ir),d(t,Ol,m),S(mt,t,m),d(t,xl,m),S(dt,t,m),d(t,Ll,m),d(t,de,m),o(de,Or),o(de,Kt),o(Kt,wo),o(wo,xr),o(de,Lr),o(de,Jt),o(Jt,bo),o(bo,Nr),o(de,Hr),o(de,Eo),o(Eo,Rr),o(de,Ur),o(de,jo),o(jo,Gr),o(de,Qr),o(de,Bt),o(Bt,Kr),o(de,Jr),o(de,ha),o(ha,Br),o(de,Vr),d(t,Nl,m),S(ht,t,m),d(t,Hl,m),d(t,Ue,m),o(Ue,$t),o($t,Ao),S(Vt,Ao,null),o(Ue,Zr),o(Ue,Co),o(Co,Yr),d(t,Rl,m),S(gt,t,m),d(t,Ul,m),d(t,Ie,m),o(Ie,Wr),o(Ie,qo),o(qo,Xr),o(Ie,en),o(Ie,To),o(To,tn),o(Ie,an),d(t,Gl,m),S(_t,t,m),Ql=!0},p(t,[m]){const Zt={};m&2&&(Zt.$$scope={dirty:m,ctx:t}),K.$set(Zt);const Mo={};m&2&&(Mo.$$scope={dirty:m,ctx:t}),Je.$set(Mo);const So={};m&2&&(So.$$scope={dirty:m,ctx:t}),Ze.$set(So);const yo={};m&2&&(yo.$$scope={dirty:m,ctx:t}),ot.$set(yo);const Ge={};m&2&&(Ge.$$scope={dirty:m,ctx:t}),ct.$set(Ge);const Po={};m&2&&(Po.$$scope={dirty:m,ctx:t}),mt.$set(Po);const Do={};m&2&&(Do.$$scope={dirty:m,ctx:t}),dt.$set(Do);const Yt={};m&2&&(Yt.$$scope={dirty:m,ctx:t}),ht.$set(Yt);const Fo={};m&2&&(Fo.$$scope={dirty:m,ctx:t}),gt.$set(Fo);const Io={};m&2&&(Io.$$scope={dirty:m,ctx:t}),_t.$set(Io)},i(t){Ql||(E(g.$$.fragment,t),E(A.$$.fragment,t),E(K.$$.fragment,t),E(oe.$$.fragment,t),E(N.$$.fragment,t),E(Je.$$.fragment,t),E(wt.$$.fragment,t),E(Ze.$$.fragment,t),E(bt.$$.fragment,t),E(jt.$$.fragment,t),E(At.$$.fragment,t),E(qt.$$.fragment,t),E(Tt.$$.fragment,t),E(yt.$$.fragment,t),E(Pt.$$.fragment,t),E(Dt.$$.fragment,t),E(Ft.$$.fragment,t),E(xt.$$.fragment,t),E(ot.$$.fragment,t),E(Lt.$$.fragment,t),E(Nt.$$.fragment,t),E(Ht.$$.fragment,t),E(Rt.$$.fragment,t),E(Ut.$$.fragment,t),E(Gt.$$.fragment,t),E(ct.$$.fragment,t),E(Qt.$$.fragment,t),E(mt.$$.fragment,t),E(dt.$$.fragment,t),E(ht.$$.fragment,t),E(Vt.$$.fragment,t),E(gt.$$.fragment,t),E(_t.$$.fragment,t),Ql=!0)},o(t){j(g.$$.fragment,t),j(A.$$.fragment,t),j(K.$$.fragment,t),j(oe.$$.fragment,t),j(N.$$.fragment,t),j(Je.$$.fragment,t),j(wt.$$.fragment,t),j(Ze.$$.fragment,t),j(bt.$$.fragment,t),j(jt.$$.fragment,t),j(At.$$.fragment,t),j(qt.$$.fragment,t),j(Tt.$$.fragment,t),j(yt.$$.fragment,t),j(Pt.$$.fragment,t),j(Dt.$$.fragment,t),j(Ft.$$.fragment,t),j(xt.$$.fragment,t),j(ot.$$.fragment,t),j(Lt.$$.fragment,t),j(Nt.$$.fragment,t),j(Ht.$$.fragment,t),j(Rt.$$.fragment,t),j(Ut.$$.fragment,t),j(Gt.$$.fragment,t),j(ct.$$.fragment,t),j(Qt.$$.fragment,t),j(mt.$$.fragment,t),j(dt.$$.fragment,t),j(ht.$$.fragment,t),j(Vt.$$.fragment,t),j(gt.$$.fragment,t),j(_t.$$.fragment,t),Ql=!1},d(t){l(e),t&&l(i),t&&l(a),y(g),t&&l(C),y(A,t),t&&l(F),t&&l(I),t&&l(L),y(K,t),t&&l(Z),t&&l(J),y(oe),t&&l(ue),t&&l(ie),t&&l(O),y(N,t),t&&l(te),t&&l(P),t&&l(be),t&&l(ae),t&&l(ge),t&&l(ee),t&&l(Ho),t&&l(zt),t&&l(Ro),t&&l(qe),t&&l(Uo),t&&l(kt),t&&l(Go),t&&l(Ke),t&&l(Qo),y(Je,t),t&&l(Ko),t&&l(xe),y(wt),t&&l(Jo),t&&l(Ve),t&&l(Bo),t&&l(ta),t&&l(Vo),y(Ze,t),t&&l(Zo),t&&l(Ye),t&&l(Yo),y(bt,t),t&&l(Wo),t&&l(Te),t&&l(Xo),y(jt,t),t&&l(el),t&&l(We),t&&l(tl),y(At,t),t&&l(al),t&&l(Me),t&&l(ol),y(qt,t),t&&l(ll),t&&l(Xe),t&&l(sl),y(Tt,t),t&&l(il),t&&l(Se),t&&l(rl),y(yt,t),t&&l(nl),t&&l(et),t&&l(pl),y(Pt,t),t&&l(cl),t&&l(aa),t&&l(ul),y(Dt,t),t&&l(fl),t&&l(tt),t&&l(ml),t&&l(Le),y(Ft),t&&l(dl),t&&l(ze),t&&l(hl),y(xt,t),t&&l($l),y(ot,t),t&&l(gl),t&&l(ye),t&&l(_l),y(Lt,t),t&&l(vl),t&&l(Pe),t&&l(zl),t&&l(Ne),y(Nt),t&&l(kl),y(Ht,t),t&&l(wl),t&&l(me),t&&l(bl),t&&l(De),t&&l(El),t&&l(He),y(Rt),t&&l(jl),t&&l(Fe),t&&l(Al),t&&l(it),t&&l(Cl),y(Ut,t),t&&l(ql),t&&l(rt),t&&l(Tl),t&&l(na),t&&l(Ml),y(Gt,t),t&&l(Sl),t&&l(pa),t&&l(yl),t&&l(nt),t&&l(Pl),t&&l(pt),t&&l(Dl),y(ct,t),t&&l(Fl),t&&l(ut),t&&l(Il),t&&l(Re),y(Qt),t&&l(Ol),y(mt,t),t&&l(xl),y(dt,t),t&&l(Ll),t&&l(de),t&&l(Nl),y(ht,t),t&&l(Hl),t&&l(Ue),y(Vt),t&&l(Rl),y(gt,t),t&&l(Ul),t&&l(Ie),t&&l(Gl),y(_t,t)}}}const pu={local:"quick-tour",sections:[{local:"pipeline",sections:[{local:"utilizzo-della-pipeline",title:"Utilizzo della Pipeline"},{local:"utilizzare-un-altro-modello-e-tokenizer-nella-pipeline",title:"Utilizzare un altro modello e tokenizer nella pipeline"}],title:"Pipeline"},{local:"autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"automodel",title:"AutoModel"},{local:"salva-un-modello",title:"Salva un modello"}],title:"AutoClass"}],title:"Quick tour"};function cu($){return Xp(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class hu extends Wt{constructor(e){super();Xt(this,e,cu,nu,ea,{})}}export{hu as default,pu as metadata};
