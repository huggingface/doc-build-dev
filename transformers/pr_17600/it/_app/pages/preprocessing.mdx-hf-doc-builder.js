import{S as fb,i as gb,s as _b,e as l,k as c,w as b,t as r,M as vb,c as t,d as a,m as u,a as p,x as d,h as o,b as m,N as bb,G as e,g as i,y as j,q as f,o as g,B as _,v as $b,L as db}from"../chunks/vendor-hf-doc-builder.js";import{T as kb,C as $}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as Eb,Y as zb,F as wb,M as jb}from"../chunks/Markdown-hf-doc-builder.js";import{I as w}from"../chunks/IconCopyLink-hf-doc-builder.js";function qb(P){let v,k,h,E,z;return{c(){v=l("p"),k=r("Se stai pensando si utilizzare un modello preaddestrato, \xE8 importante utilizzare il tokenizer preaddestrato associato. Questo assicura che il testo sia separato allo stesso modo che nel corpus usato per l\u2019addestramento, e venga usata la stessa mappatura tokens-to-index (solitamente indicato come il "),h=l("em"),E=r("vocabolario"),z=r(") come nel preaddestramento.")},l(q){v=t(q,"P",{});var C=p(v);k=o(C,"Se stai pensando si utilizzare un modello preaddestrato, \xE8 importante utilizzare il tokenizer preaddestrato associato. Questo assicura che il testo sia separato allo stesso modo che nel corpus usato per l\u2019addestramento, e venga usata la stessa mappatura tokens-to-index (solitamente indicato come il "),h=t(C,"EM",{});var is=p(h);E=o(is,"vocabolario"),is.forEach(a),z=o(C,") come nel preaddestramento."),C.forEach(a)},m(q,C){i(q,v,C),e(v,k),e(v,h),e(h,E),e(v,z)},d(q){q&&a(v)}}}function xb(P){let v,k;return v=new $({props:{code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors="pt")
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: tensor([[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                      [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
                      [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]), 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                           [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                           [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]), 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                           [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                           [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])}`}}),{c(){b(v.$$.fragment)},l(h){d(v.$$.fragment,h)},m(h,E){j(v,h,E),k=!0},p:db,i(h){k||(f(v.$$.fragment,h),k=!0)},o(h){g(v.$$.fragment,h),k=!1},d(h){_(v,h)}}}function yb(P){let v,k;return v=new jb({props:{$$slots:{default:[xb]},$$scope:{ctx:P}}}),{c(){b(v.$$.fragment)},l(h){d(v.$$.fragment,h)},m(h,E){j(v,h,E),k=!0},p(h,E){const z={};E&2&&(z.$$scope={dirty:E,ctx:h}),v.$set(z)},i(h){k||(f(v.$$.fragment,h),k=!0)},o(h){g(v.$$.fragment,h),k=!1},d(h){_(v,h)}}}function Pb(P){let v,k;return v=new $({props:{code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors="tf")
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">9</span>), dtype=int32, numpy=
array([[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
       [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
       [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],
      dtype=int32)&gt;, 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">9</span>), dtype=int32, numpy=
array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
       [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
       [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], dtype=int32)&gt;, 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">9</span>), dtype=int32, numpy=
array([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], dtype=int32)&gt;}`}}),{c(){b(v.$$.fragment)},l(h){d(v.$$.fragment,h)},m(h,E){j(v,h,E),k=!0},p:db,i(h){k||(f(v.$$.fragment,h),k=!0)},o(h){g(v.$$.fragment,h),k=!1},d(h){_(v,h)}}}function Ab(P){let v,k;return v=new jb({props:{$$slots:{default:[Pb]},$$scope:{ctx:P}}}),{c(){b(v.$$.fragment)},l(h){d(v.$$.fragment,h)},m(h,E){j(v,h,E),k=!0},p(h,E){const z={};E&2&&(z.$$scope={dirty:E,ctx:h}),v.$set(z)},i(h){k||(f(v.$$.fragment,h),k=!0)},o(h){g(v.$$.fragment,h),k=!1},d(h){_(v,h)}}}function Cb(P){let v,k,h,E,z,q,C,is,$r,Ul,Qs,Rl,oe,kr,Fl,D,on,Er,zr,cn,wr,qr,un,xr,Hl,W,cs,mn,Bs,yr,hn,Pr,Ml,Js,Ql,I,Ar,ie,Cr,Dr,bn,Ir,Sr,Bl,us,Jl,S,Tr,dn,Or,Nr,jn,Lr,Ur,Wl,V,ms,fn,Ws,Rr,gn,Fr,Vl,hs,Hr,_n,Mr,Qr,Gl,Vs,Yl,ce,Br,Kl,Gs,Xl,ue,Jr,Zl,T,me,he,Wr,Vr,Gr,be,de,Yr,Kr,Xr,je,fe,Zr,so,st,bs,ao,vn,eo,no,at,Ys,et,O,lo,$n,to,po,kn,ro,oo,nt,ge,io,lt,Ks,tt,G,ds,En,Xs,co,zn,uo,pt,js,mo,wn,ho,bo,rt,N,jo,qn,fo,go,xn,_o,vo,ot,Zs,it,fs,$o,yn,ko,Eo,ct,Y,gs,Pn,sa,zo,An,wo,ut,_e,qo,mt,L,xo,Cn,yo,Po,Dn,Ao,Co,ht,aa,bt,K,_s,In,ea,Do,Sn,Io,dt,ve,So,jt,x,To,Tn,Oo,No,On,Lo,Uo,Nn,Ro,Fo,ft,vs,gt,X,$s,Ln,na,Ho,Un,Mo,_t,ks,Qo,$e,Bo,Jo,vt,la,$t,U,Wo,ta,Vo,Go,pa,Yo,Ko,kt,ra,Et,R,Xo,Rn,Zo,si,Fn,ai,ei,zt,oa,wt,ke,ni,qt,F,Ee,Hn,li,ti,pi,ze,Mn,ri,oi,ii,we,Qn,ci,ui,xt,Z,Es,Bn,ia,mi,Jn,hi,yt,zs,bi,ca,di,ji,Pt,ws,fi,ua,gi,_i,At,ma,Ct,qe,ha,vi,ba,Wn,$i,ki,Dt,da,It,ja,Vn,Ei,St,fa,Tt,qs,zi,Gn,wi,qi,Ot,ss,xs,Yn,ga,xi,Kn,yi,Nt,y,Pi,Xn,Ai,Ci,Zn,Di,Ii,sl,Si,Ti,Lt,ys,Oi,al,Ni,Li,Ut,_a,Rt,H,Ui,el,Ri,Fi,nl,Hi,Mi,Ft,va,Ht,as,Ps,ll,$a,Qi,tl,Bi,Mt,xe,Ji,Qt,ka,Bt,ye,Wi,Jt,Ea,Wt,Pe,Vi,Vt,za,Gt,Ae,Gi,Yt,wa,Kt,Ce,Yi,Xt,es,As,pl,qa,Ki,rl,Xi,Zt,De,Zi,sp,M,sc,xa,ac,ec,ol,nc,lc,ap,ya,ep,Cs,tc,Pa,il,pc,rc,np,Aa,lp,Ie,Se,yu,tp,ns,Ds,cl,Ca,oc,ul,ic,pp,Is,cc,ml,uc,mc,rp,Da,op,ls,Ss,hl,Ia,hc,bl,bc,ip,Ts,dc,Sa,dl,jc,fc,cp,Te,A,gc,Ta,jl,_c,vc,Oa,fl,$c,kc,Na,gl,Ec,zc,up,La,mp,Ua,ts,wc,Oe,_l,qc,xc,vl,yc,Pc,hp,Ra,bp,Fa,Ha,Ac,Ma,$l,Cc,Dc,dp,Qa,jp,Ba,Ja,Ic,kl,Sc,Tc,fp,Wa,gp,Ne,Oc,_p,Va,vp,Le,Ue,Pu,$p,ps,Os,El,Ga,Nc,zl,Lc,kp,Re,Uc,Ep,Ns,wl,Rc,Fc,ql,Hc,zp,Ls,Mc,Ya,Qc,Bc,wp,Ka,qp,Q,Jc,xl,Wc,Vc,yl,Gc,Yc,xp,Xa,yp,B,Kc,Pl,Xc,Zc,Al,su,au,Pp,Za,Ap,Us,eu,Fe,nu,lu,Cp,se,Dp,rs,Rs,Cl,ae,tu,Dl,pu,Ip,He,ru,Sp,ee,Tp,Me,os,ou,Il,iu,cu,Sl,uu,mu,Op,ne,Np,le,te,hu,Tl,bu,du,Lp,pe,Up,J,ju,Ol,fu,gu,Nl,_u,vu,Rp,Qe,$u,Fp;return q=new w({}),Qs=new Eb({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/preprocessing.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/preprocessing.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/preprocessing.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/preprocessing.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/preprocessing.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/preprocessing.ipynb"}]}}),Bs=new w({}),Js=new zb({props:{id:"Yffk5aydLzg"}}),us=new kb({props:{$$slots:{default:[qb]},$$scope:{ctx:P}}}),Ws=new w({}),Vs=new $({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`}}),Gs=new $({props:{code:`encoded_input = tokenizer("Do not meddle in the affairs of wizards, for they are subtle and quick to anger.")
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(<span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">2079</span>, <span class="hljs-number">2025</span>, <span class="hljs-number">19960</span>, <span class="hljs-number">10362</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">3821</span>, <span class="hljs-number">1997</span>, <span class="hljs-number">16657</span>, <span class="hljs-number">1010</span>, <span class="hljs-number">2005</span>, <span class="hljs-number">2027</span>, <span class="hljs-number">2024</span>, <span class="hljs-number">11259</span>, <span class="hljs-number">1998</span>, <span class="hljs-number">4248</span>, <span class="hljs-number">2000</span>, <span class="hljs-number">4963</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),Ys=new $({props:{code:'tokenizer.decode(encoded_input["input_ids"])',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(encoded_input[<span class="hljs-string">&quot;input_ids&quot;</span>])
<span class="hljs-string">&#x27;[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]&#x27;</span>`}}),Ks=new $({props:{code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_inputs = tokenizer(batch_sentences)
print(encoded_inputs)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_inputs = tokenizer(batch_sentences)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_inputs)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>]], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]]}`}}),Xs=new w({}),Zs=new $({props:{code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_input = tokenizer(batch_sentences, padding=True)
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]}`}}),sa=new w({}),aa=new $({props:{code:`batch_sentences = [
    "But what about second breakfast?",
    "Don't think he knows about second breakfast, Pip.",
    "What about elevensies?",
]
encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)
print(encoded_input)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>], 
               [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], 
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]}`}}),ea=new w({}),vs=new wb({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Ab],pytorch:[yb]},$$scope:{ctx:P}}}),na=new w({}),la=new $({props:{code:"pip install datasets",highlighted:"pip install datasets"}}),ra=new $({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),oa=new $({props:{code:'dataset[0]["audio"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.00024414</span>, -<span class="hljs-number">0.00024414</span>, ..., -<span class="hljs-number">0.00024414</span>,
         <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        ], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">8000</span>}`}}),ia=new w({}),ma=new $({props:{code:`dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")
dataset[0]["audio"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.00024414</span>, -<span class="hljs-number">0.00024414</span>, ..., -<span class="hljs-number">0.00024414</span>,
         <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        ], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">8000</span>}`}}),da=new $({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=16_000))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16_000</span>))'}}),fa=new $({props:{code:'dataset[0]["audio"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">2.3443763e-05</span>,  <span class="hljs-number">2.1729663e-04</span>,  <span class="hljs-number">2.2145823e-04</span>, ...,
         <span class="hljs-number">3.8356509e-05</span>, -<span class="hljs-number">7.3497440e-06</span>, -<span class="hljs-number">2.1754686e-05</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>}`}}),ga=new w({}),_a=new $({props:{code:`from transformers import AutoFeatureExtractor

feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>)`}}),va=new $({props:{code:`audio_input = [dataset[0]["audio"]["array"]]
feature_extractor(audio_input, sampling_rate=16000)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>audio_input = [dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor(audio_input, sampling_rate=<span class="hljs-number">16000</span>)
{<span class="hljs-string">&#x27;input_values&#x27;</span>: [array([ <span class="hljs-number">3.8106556e-04</span>,  <span class="hljs-number">2.7506407e-03</span>,  <span class="hljs-number">2.8015103e-03</span>, ...,
        <span class="hljs-number">5.6335266e-04</span>,  <span class="hljs-number">4.6588284e-06</span>, -<span class="hljs-number">1.7142107e-04</span>], dtype=float32)]}`}}),$a=new w({}),ka=new $({props:{code:`dataset[0]["audio"]["array"].shape

dataset[1]["audio"]["array"].shape`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>].shape
(<span class="hljs-number">173398</span>,)

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">1</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>].shape
(<span class="hljs-number">106496</span>,)`}}),Ea=new $({props:{code:`def preprocess_function(examples):
    audio_arrays = [x["array"] for x in examples["audio"]]
    inputs = feature_extractor(
        audio_arrays,
        sampling_rate=16000,
        padding=True,
        max_length=100000,
        truncation=True,
    )
    return inputs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    audio_arrays = [x[<span class="hljs-string">&quot;array&quot;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;audio&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = feature_extractor(
<span class="hljs-meta">... </span>        audio_arrays,
<span class="hljs-meta">... </span>        sampling_rate=<span class="hljs-number">16000</span>,
<span class="hljs-meta">... </span>        padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>        max_length=<span class="hljs-number">100000</span>,
<span class="hljs-meta">... </span>        truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    )
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs`}}),za=new $({props:{code:"processed_dataset = preprocess_function(dataset[:5])",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>processed_dataset = preprocess_function(dataset[:<span class="hljs-number">5</span>])'}}),wa=new $({props:{code:`processed_dataset["input_values"][0].shape

processed_dataset["input_values"][1].shape`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>processed_dataset[<span class="hljs-string">&quot;input_values&quot;</span>][<span class="hljs-number">0</span>].shape
(<span class="hljs-number">100000</span>,)

<span class="hljs-meta">&gt;&gt;&gt; </span>processed_dataset[<span class="hljs-string">&quot;input_values&quot;</span>][<span class="hljs-number">1</span>].shape
(<span class="hljs-number">100000</span>,)`}}),qa=new w({}),ya=new $({props:{code:`from datasets import load_dataset

dataset = load_dataset("food101", split="train[:100]")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[:100]&quot;</span>)`}}),Aa=new $({props:{code:'dataset[0]["image"]',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]'}}),Ca=new w({}),Da=new $({props:{code:`from transformers import AutoFeatureExtractor

feature_extractor = AutoFeatureExtractor.from_pretrained("google/vit-base-patch16-224")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224&quot;</span>)`}}),Ia=new w({}),La=new $({props:{code:`from torchvision.transforms import Compose, Normalize, RandomResizedCrop, ColorJitter, ToTensor

normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)
_transforms = Compose(
    [RandomResizedCrop(feature_extractor.size), ColorJitter(brightness=0.5, hue=0.5), ToTensor(), normalize]
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose, Normalize, RandomResizedCrop, ColorJitter, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)
<span class="hljs-meta">&gt;&gt;&gt; </span>_transforms = Compose(
<span class="hljs-meta">... </span>    [RandomResizedCrop(feature_extractor.size), ColorJitter(brightness=<span class="hljs-number">0.5</span>, hue=<span class="hljs-number">0.5</span>), ToTensor(), normalize]
<span class="hljs-meta">... </span>)`}}),Ra=new $({props:{code:`def transforms(examples):
    examples["pixel_values"] = [_transforms(image.convert("RGB")) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [_transforms(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),Qa=new $({props:{code:"dataset.set_transform(transforms)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)'}}),Wa=new $({props:{code:'dataset[0]["image"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at <span class="hljs-number">0x7F1A7B0630D0</span>&gt;,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">6</span>,
 <span class="hljs-string">&#x27;pixel_values&#x27;</span>: tensor([[[ <span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0745</span>,  <span class="hljs-number">0.1216</span>,  ..., -<span class="hljs-number">0.9922</span>, -<span class="hljs-number">0.9922</span>, -<span class="hljs-number">0.9922</span>],
          [-<span class="hljs-number">0.0196</span>,  <span class="hljs-number">0.0667</span>,  <span class="hljs-number">0.1294</span>,  ..., -<span class="hljs-number">0.9765</span>, -<span class="hljs-number">0.9843</span>, -<span class="hljs-number">0.9922</span>],
          [ <span class="hljs-number">0.0196</span>,  <span class="hljs-number">0.0824</span>,  <span class="hljs-number">0.1137</span>,  ..., -<span class="hljs-number">0.9765</span>, -<span class="hljs-number">0.9686</span>, -<span class="hljs-number">0.8667</span>],
          ...,
          [ <span class="hljs-number">0.0275</span>,  <span class="hljs-number">0.0745</span>,  <span class="hljs-number">0.0510</span>,  ..., -<span class="hljs-number">0.1137</span>, -<span class="hljs-number">0.1216</span>, -<span class="hljs-number">0.0824</span>],
          [ <span class="hljs-number">0.0667</span>,  <span class="hljs-number">0.0824</span>,  <span class="hljs-number">0.0667</span>,  ..., -<span class="hljs-number">0.0588</span>, -<span class="hljs-number">0.0745</span>, -<span class="hljs-number">0.0980</span>],
          [ <span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0431</span>,  ..., -<span class="hljs-number">0.0039</span>, -<span class="hljs-number">0.0039</span>, -<span class="hljs-number">0.0588</span>]],
 
         [[ <span class="hljs-number">0.2078</span>,  <span class="hljs-number">0.2471</span>,  <span class="hljs-number">0.2863</span>,  ..., -<span class="hljs-number">0.9451</span>, -<span class="hljs-number">0.9373</span>, -<span class="hljs-number">0.9451</span>],
          [ <span class="hljs-number">0.1608</span>,  <span class="hljs-number">0.2471</span>,  <span class="hljs-number">0.3098</span>,  ..., -<span class="hljs-number">0.9373</span>, -<span class="hljs-number">0.9451</span>, -<span class="hljs-number">0.9373</span>],
          [ <span class="hljs-number">0.2078</span>,  <span class="hljs-number">0.2706</span>,  <span class="hljs-number">0.3020</span>,  ..., -<span class="hljs-number">0.9608</span>, -<span class="hljs-number">0.9373</span>, -<span class="hljs-number">0.8275</span>],
          ...,
          [-<span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0118</span>, -<span class="hljs-number">0.0039</span>,  ..., -<span class="hljs-number">0.2392</span>, -<span class="hljs-number">0.2471</span>, -<span class="hljs-number">0.2078</span>],
          [ <span class="hljs-number">0.0196</span>,  <span class="hljs-number">0.0353</span>,  <span class="hljs-number">0.0196</span>,  ..., -<span class="hljs-number">0.1843</span>, -<span class="hljs-number">0.2000</span>, -<span class="hljs-number">0.2235</span>],
          [-<span class="hljs-number">0.0118</span>, -<span class="hljs-number">0.0039</span>, -<span class="hljs-number">0.0039</span>,  ..., -<span class="hljs-number">0.0980</span>, -<span class="hljs-number">0.0980</span>, -<span class="hljs-number">0.1529</span>]],
 
         [[ <span class="hljs-number">0.3961</span>,  <span class="hljs-number">0.4431</span>,  <span class="hljs-number">0.4980</span>,  ..., -<span class="hljs-number">0.9216</span>, -<span class="hljs-number">0.9137</span>, -<span class="hljs-number">0.9216</span>],
          [ <span class="hljs-number">0.3569</span>,  <span class="hljs-number">0.4510</span>,  <span class="hljs-number">0.5216</span>,  ..., -<span class="hljs-number">0.9059</span>, -<span class="hljs-number">0.9137</span>, -<span class="hljs-number">0.9137</span>],
          [ <span class="hljs-number">0.4118</span>,  <span class="hljs-number">0.4745</span>,  <span class="hljs-number">0.5216</span>,  ..., -<span class="hljs-number">0.9137</span>, -<span class="hljs-number">0.8902</span>, -<span class="hljs-number">0.7804</span>],
          ...,
          [-<span class="hljs-number">0.2314</span>, -<span class="hljs-number">0.1922</span>, -<span class="hljs-number">0.2078</span>,  ..., -<span class="hljs-number">0.4196</span>, -<span class="hljs-number">0.4275</span>, -<span class="hljs-number">0.3882</span>],
          [-<span class="hljs-number">0.1843</span>, -<span class="hljs-number">0.1686</span>, -<span class="hljs-number">0.2000</span>,  ..., -<span class="hljs-number">0.3647</span>, -<span class="hljs-number">0.3804</span>, -<span class="hljs-number">0.4039</span>],
          [-<span class="hljs-number">0.1922</span>, -<span class="hljs-number">0.1922</span>, -<span class="hljs-number">0.1922</span>,  ..., -<span class="hljs-number">0.2941</span>, -<span class="hljs-number">0.2863</span>, -<span class="hljs-number">0.3412</span>]]])}`}}),Va=new $({props:{code:`import numpy as np
import matplotlib.pyplot as plt

img = dataset[0]["pixel_values"]
plt.imshow(img.permute(1, 2, 0))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-meta">&gt;&gt;&gt; </span>img = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))`}}),Ga=new w({}),Ka=new $({props:{code:`from datasets import load_dataset

lj_speech = load_dataset("lj_speech", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = load_dataset(<span class="hljs-string">&quot;lj_speech&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),Xa=new $({props:{code:'lj_speech = lj_speech.map(remove_columns=["file", "id", "normalized_text"])',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = lj_speech.<span class="hljs-built_in">map</span>(remove_columns=[<span class="hljs-string">&quot;file&quot;</span>, <span class="hljs-string">&quot;id&quot;</span>, <span class="hljs-string">&quot;normalized_text&quot;</span>])'}}),Za=new $({props:{code:`lj_speech[0]["audio"]

lj_speech[0]["text"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([-<span class="hljs-number">7.3242188e-04</span>, -<span class="hljs-number">7.6293945e-04</span>, -<span class="hljs-number">6.4086914e-04</span>, ...,
         <span class="hljs-number">7.3242188e-04</span>,  <span class="hljs-number">2.1362305e-04</span>,  <span class="hljs-number">6.1035156e-05</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">22050</span>}

<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;text&quot;</span>]
<span class="hljs-string">&#x27;Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition&#x27;</span>`}}),se=new $({props:{code:'lj_speech = lj_speech.cast_column("audio", Audio(sampling_rate=16_000))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = lj_speech.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16_000</span>))'}}),ae=new w({}),ee=new $({props:{code:`from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`}}),ne=new $({props:{code:`def prepare_dataset(example):
    audio = example["audio"]

    example["input_values"] = processor(audio["array"], sampling_rate=16000)

    with processor.as_target_processor():
        example["labels"] = processor(example["text"]).input_ids
    return example`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataset</span>(<span class="hljs-params">example</span>):
<span class="hljs-meta">... </span>    audio = example[<span class="hljs-string">&quot;audio&quot;</span>]

<span class="hljs-meta">... </span>    example[<span class="hljs-string">&quot;input_values&quot;</span>] = processor(audio[<span class="hljs-string">&quot;array&quot;</span>], sampling_rate=<span class="hljs-number">16000</span>)

<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> processor.as_target_processor():
<span class="hljs-meta">... </span>        example[<span class="hljs-string">&quot;labels&quot;</span>] = processor(example[<span class="hljs-string">&quot;text&quot;</span>]).input_ids
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> example`}}),pe=new $({props:{code:"prepare_dataset(lj_speech[0])",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>prepare_dataset(lj_speech[<span class="hljs-number">0</span>])'}}),{c(){v=l("meta"),k=c(),h=l("h1"),E=l("a"),z=l("span"),b(q.$$.fragment),C=c(),is=l("span"),$r=r("Preprocess"),Ul=c(),b(Qs.$$.fragment),Rl=c(),oe=l("p"),kr=r("Prima di poter usare i dati in un modello, bisogna processarli in un formato accettabile per quest\u2019ultimo. Un modello non comprende il testo piano, le immagini o l\u2019audio. Bisogna convertire questi input in numeri e assemblarli all\u2019interno di tensori. In questa esercitazione, tu potrai:"),Fl=c(),D=l("ul"),on=l("li"),Er=r("Preprocessare dati testuali con un tokenizer."),zr=c(),cn=l("li"),wr=r("Preprocessare immagini o dati audio con un estrattore di caratteristiche."),qr=c(),un=l("li"),xr=r("Preprocessare dati per attivit\xE0 multimodali mediante un processore."),Hl=c(),W=l("h2"),cs=l("a"),mn=l("span"),b(Bs.$$.fragment),yr=c(),hn=l("span"),Pr=r("NLP"),Ml=c(),b(Js.$$.fragment),Ql=c(),I=l("p"),Ar=r("Lo strumento principale per processare dati testuali \xE8 un "),ie=l("a"),Cr=r("tokenizer"),Dr=r(". Un tokenizer inizia separando il testo in "),bn=l("em"),Ir=r("tokens"),Sr=r(" secondo una serie di regole. I tokens sono convertiti in numeri, questi vengono utilizzati per costruire i tensori di input del modello. Anche altri input addizionali se richiesti dal modello vengono aggiunti dal tokenizer."),Bl=c(),b(us.$$.fragment),Jl=c(),S=l("p"),Tr=r("Iniziamo subito caricando un tokenizer preaddestrato con la classe "),dn=l("code"),Or=r("AutoTokenizer"),Nr=r(". Questo scarica il "),jn=l("em"),Lr=r("vocabolario"),Ur=r(" usato quando il modello \xE8 stato preaddestrato."),Wl=c(),V=l("h3"),ms=l("a"),fn=l("span"),b(Ws.$$.fragment),Rr=c(),gn=l("span"),Fr=r("Tokenize"),Vl=c(),hs=l("p"),Hr=r("Carica un tokenizer preaddestrato con "),_n=l("code"),Mr=r("AutoTokenizer.from_pretrained()"),Qr=r(":"),Gl=c(),b(Vs.$$.fragment),Yl=c(),ce=l("p"),Br=r("Poi inserisci le tue frasi nel tokenizer:"),Kl=c(),b(Gs.$$.fragment),Xl=c(),ue=l("p"),Jr=r("Il tokenizer restituisce un dizionario contenente tre oggetti importanti:"),Zl=c(),T=l("ul"),me=l("li"),he=l("a"),Wr=r("input_ids"),Vr=r(" sono gli indici che corrispondono ad ogni token nella frase."),Gr=c(),be=l("li"),de=l("a"),Yr=r("attention_mask"),Kr=r(" indicata se un token deve essere elaborato o no."),Xr=c(),je=l("li"),fe=l("a"),Zr=r("token_type_ids"),so=r(" identifica a quale sequenza appartiene un token se \xE8 presente pi\xF9 di una sequenza."),st=c(),bs=l("p"),ao=r("Si possono decodificare gli "),vn=l("code"),eo=r("input_ids"),no=r(" per farsi restituire l\u2019input originale:"),at=c(),b(Ys.$$.fragment),et=c(),O=l("p"),lo=r("Come si pu\xF2 vedere, il tokenizer aggiunge due token speciali - "),$n=l("code"),to=r("CLS"),po=r(" and "),kn=l("code"),ro=r("SEP"),oo=r(" (classifier and separator) - alla frase. Non tutti i modelli hanno bisogno dei token speciali, ma se servono, il tokenizer li aggiunger\xE0 automaticamente."),nt=c(),ge=l("p"),io=r("Se ci sono pi\xF9 frasi che vuoi processare, passale come una lista al tokenizer:"),lt=c(),b(Ks.$$.fragment),tt=c(),G=l("h3"),ds=l("a"),En=l("span"),b(Xs.$$.fragment),co=c(),zn=l("span"),uo=r("Pad"),pt=c(),js=l("p"),mo=r("Questo \xE8 un argomento importante. Quando processi un insieme di frasi potrebbero non avere tutte la stessa lunghezza. Questo \xE8 un problema perch\xE8 i tensori, in input del modello, devono avere dimensioni uniformi. Il padding \xE8 una strategia per assicurarsi che i tensori siano rettangolari aggiungendo uno speciale "),wn=l("em"),ho=r("padding token"),bo=r(" alle frasi pi\xF9 corte."),rt=c(),N=l("p"),jo=r("Imposta il parametro "),qn=l("code"),fo=r("padding"),go=r(" a "),xn=l("code"),_o=r("True"),vo=r(" per imbottire le frasi pi\xF9 corte nel gruppo in modo che combacino con la massima lunghezza presente:"),ot=c(),b(Zs.$$.fragment),it=c(),fs=l("p"),$o=r("Nota che il tokenizer aggiunge alle sequenze degli "),yn=l("code"),ko=r("0"),Eo=r(" perch\xE8 sono troppo corte!"),ct=c(),Y=l("h3"),gs=l("a"),Pn=l("span"),b(sa.$$.fragment),zo=c(),An=l("span"),wo=r("Truncation"),ut=c(),_e=l("p"),qo=r("L\u2019altra faccia della medaglia \xE8 che avolte le sequenze possono essere troppo lunghe per essere gestite dal modello. In questo caso, avrai bisogno di troncare la sequenza per avere una lunghezza minore."),mt=c(),L=l("p"),xo=r("Imposta il parametro "),Cn=l("code"),yo=r("truncation"),Po=r(" a "),Dn=l("code"),Ao=r("True"),Co=r(" per troncare una sequenza alla massima lunghezza accettata dal modello:"),ht=c(),b(aa.$$.fragment),bt=c(),K=l("h3"),_s=l("a"),In=l("span"),b(ea.$$.fragment),Do=c(),Sn=l("span"),Io=r("Costruire i tensori"),dt=c(),ve=l("p"),So=r("Infine, vuoi che il tokenizer restituisca i tensori prodotti dal modello."),jt=c(),x=l("p"),To=r("Imposta il parametro "),Tn=l("code"),Oo=r("return_tensors"),No=r(" su "),On=l("code"),Lo=r("pt"),Uo=r(" per PyTorch, o "),Nn=l("code"),Ro=r("tf"),Fo=r(" per TensorFlow:"),ft=c(),b(vs.$$.fragment),gt=c(),X=l("h2"),$s=l("a"),Ln=l("span"),b(na.$$.fragment),Ho=c(),Un=l("span"),Mo=r("Audio"),_t=c(),ks=l("p"),Qo=r("Gli input audio sono processati in modo differente rispetto al testo, ma l\u2019obiettivo rimane lo stesso: creare sequenze numeriche che il modello pu\xF2 capire. Un "),$e=l("a"),Bo=r("estrattore di caratteristiche"),Jo=r(" \xE8 progettato con lo scopo preciso di estrarre caratteristiche da immagini o dati audio grezzi e convertirli in tensori. Prima di iniziare, installa \u{1F917} Datasets per caricare un dataset audio e sperimentare:"),vt=c(),b(la.$$.fragment),$t=c(),U=l("p"),Wo=r("Carica il dataset "),ta=l("a"),Vo=r("MInDS-14"),Go=r(" (vedi il \u{1F917} "),pa=l("a"),Yo=r("Datasets tutorial"),Ko=r(" per avere maggiori dettagli su come caricare un dataset):"),kt=c(),b(ra.$$.fragment),Et=c(),R=l("p"),Xo=r("Accedi al primo elemento della colonna "),Rn=l("code"),Zo=r("audio"),si=r(" per dare uno sguardo all\u2019input. Richiamando la colonna "),Fn=l("code"),ai=r("audio"),ei=r(" sar\xE0 caricato automaticamente e ricampionato il file audio:"),zt=c(),b(oa.$$.fragment),wt=c(),ke=l("p"),ni=r("Questo restituisce tre oggetti:"),qt=c(),F=l("ul"),Ee=l("li"),Hn=l("code"),li=r("array"),ti=r(" \xE8 il segnale vocale caricato - e potenzialmente ricampionato - come vettore 1D."),pi=c(),ze=l("li"),Mn=l("code"),ri=r("path"),oi=r(" il percorso del file audio."),ii=c(),we=l("li"),Qn=l("code"),ci=r("sampling_rate"),ui=r(" si riferisce al numero di campioni del segnale vocale misurati al secondo."),xt=c(),Z=l("h3"),Es=l("a"),Bn=l("span"),b(ia.$$.fragment),mi=c(),Jn=l("span"),hi=r("Ricampionamento"),yt=c(),zs=l("p"),bi=r("Per questo tutorial, puoi usare il modello "),ca=l("a"),di=r("Wav2Vec2"),ji=r(". Come puoi vedere dalla model card, il modello Wav2Vec2 \xE8 preaddestrato su un campionamento vocale a 16kHz. E\u2019 importante che la frequenza di campionamento dei tuoi dati audio combaci con la frequenza di campionamento del dataset usato per preaddestrare il modello. Se la frequenza di campionamento dei tuoi dati non \xE8 uguale dovrai ricampionare i tuoi dati audio."),Pt=c(),ws=l("p"),fi=r("Per esempio, il dataset "),ua=l("a"),gi=r("MInDS-14"),_i=r(" ha una frequenza di campionamento di 8000kHz. Utilizzando il modello Wav2Vec2 msu questo dataset, alzala a 16kHz:"),At=c(),b(ma.$$.fragment),Ct=c(),qe=l("ol"),ha=l("li"),vi=r("Usa il metodo in \u{1F917} Datasets\u2019 "),ba=l("a"),Wn=l("code"),$i=r("cast_column"),ki=r(" per alzare della frequenza di campionamento a 16kHz:"),Dt=c(),b(da.$$.fragment),It=c(),ja=l("ol"),Vn=l("li"),Ei=r("Carica il file audio:"),St=c(),b(fa.$$.fragment),Tt=c(),qs=l("p"),zi=r("Come puoi notare, la "),Gn=l("code"),wi=r("sampling_rate"),qi=r(" adesso \xE8 16kHz!"),Ot=c(),ss=l("h3"),xs=l("a"),Yn=l("span"),b(ga.$$.fragment),xi=c(),Kn=l("span"),yi=r("Feature extractor"),Nt=c(),y=l("p"),Pi=r("Il prossimo passo \xE8 caricare un estrattore di caratteristiche per normalizzare e fare padding sull\u2019input. Quando applichiamo il padding sui dati testuali, uno "),Xn=l("code"),Ai=r("0"),Ci=r(" \xE8 aggiunto alle sequenze pi\xF9 brevi. La stessa idea si applica ai dati audio, l\u2019estrattore di caratteristiche per gli audio aggiunger\xE0 uno "),Zn=l("code"),Di=r("0"),Ii=r(" - interpretato come silenzaio - agli "),sl=l("code"),Si=r("array"),Ti=r("."),Lt=c(),ys=l("p"),Oi=r("Carica l\u2019estrattore delle caratteristiche con "),al=l("code"),Ni=r("AutoFeatureExtractor.from_pretrained()"),Li=r(":"),Ut=c(),b(_a.$$.fragment),Rt=c(),H=l("p"),Ui=r("Inserisci l\u2019 "),el=l("code"),Ri=r("array"),Fi=r(" audio nell\u2019estrattore delle caratteristiche. Noi raccomandiamo sempre di aggiungere il parametro "),nl=l("code"),Hi=r("sampling_rate"),Mi=r(" nell\u2019estrattore delle caratteristiche per correggere meglio qualche errore, dovuto ai silenzi, che potrebbe verificarsi."),Ft=c(),b(va.$$.fragment),Ht=c(),as=l("h3"),Ps=l("a"),ll=l("span"),b($a.$$.fragment),Qi=c(),tl=l("span"),Bi=r("Pad and truncate"),Mt=c(),xe=l("p"),Ji=r("Come per il tokenizer, puoi applicare le operazioni padding o truncation per manipolare sequenze di variabili a lotti. Dai uno sguaro alla lunghezza delle sequenze di questi due campioni audio:"),Qt=c(),b(ka.$$.fragment),Bt=c(),ye=l("p"),Wi=r("Come puoi vedere, il primo campione ga una sequenza pi\xF9 lunga del secondo. LCrea una funzione che preprocesser\xE0 il dataset. Specifica una lunghezza massima del campione, e l\u2019estrattore di features si occuper\xE0 di riempire o troncare la sequenza per coincidervi:"),Jt=c(),b(Ea.$$.fragment),Wt=c(),Pe=l("p"),Vi=r("Applica la funzione ai primi esempi nel dataset:"),Vt=c(),b(za.$$.fragment),Gt=c(),Ae=l("p"),Gi=r("Adesso guarda la lunghezza dei campioni elaborati:"),Yt=c(),b(wa.$$.fragment),Kt=c(),Ce=l("p"),Yi=r("La lunghezza dei campioni adesso coincide con la massima lunghezza impostata nelle funzione."),Xt=c(),es=l("h2"),As=l("a"),pl=l("span"),b(qa.$$.fragment),Ki=c(),rl=l("span"),Xi=r("Vision"),Zt=c(),De=l("p"),Zi=r("Un estrattore di caratteristiche si pu\xF2 usare anche per processare immagini e per compiti di visione. Ancora una volta, l\u2019obiettivo \xE8 convertire l\u2019immagine grezza in un lotto di tensori come input."),sp=c(),M=l("p"),sc=r("Carica il dataset "),xa=l("a"),ac=r("food101"),ec=r(" per questa esercitazione. Usa il parametro "),ol=l("code"),nc=r("split"),lc=r(" di \u{1F917} Datasets  per caricare solo un piccolo campione dal dataset di addestramento poich\xE8 il set di dati \xE8 molto grande:"),ap=c(),b(ya.$$.fragment),ep=c(),Cs=l("p"),tc=r("Secondo passo, dai uno sguardo alle immagini usando la caratteristica "),Pa=l("a"),il=l("code"),pc=r("Image"),rc=r(" di \u{1F917} Datasets:"),np=c(),b(Aa.$$.fragment),lp=c(),Ie=l("p"),Se=l("img"),tp=c(),ns=l("h3"),Ds=l("a"),cl=l("span"),b(Ca.$$.fragment),oc=c(),ul=l("span"),ic=r("Feature extractor"),pp=c(),Is=l("p"),cc=r("Carica l\u2019estrattore di caratteristiche "),ml=l("code"),uc=r("AutoFeatureExtractor.from_pretrained()"),mc=r(":"),rp=c(),b(Da.$$.fragment),op=c(),ls=l("h3"),Ss=l("a"),hl=l("span"),b(Ia.$$.fragment),hc=c(),bl=l("span"),bc=r("Data augmentation"),ip=c(),Ts=l("p"),dc=r("Per le attivit\xE0 di visione, \xE8 usuale aggiungere alcuni tipi di data augmentation alle immagini come parte del preprocessing. Puoi aggiungere augmentations con qualsiasi libreria che preferisci, ma in questa esercitazione, userai il modulo "),Sa=l("a"),dl=l("code"),jc=r("transforms"),fc=r(" di torchvision."),cp=c(),Te=l("ol"),A=l("li"),gc=r("Normalizza l\u2019immagine e usa "),Ta=l("a"),jl=l("code"),_c=r("Compose"),vc=r(" per concatenare alcune trasformazioni - "),Oa=l("a"),fl=l("code"),$c=r("RandomResizedCrop"),kc=r(" e "),Na=l("a"),gl=l("code"),Ec=r("ColorJitter"),zc=r(" - insieme:"),up=c(),b(La.$$.fragment),mp=c(),Ua=l("ol"),ts=l("li"),wc=r("Il modello accetta "),Oe=l("a"),_l=l("code"),qc=r("pixel_values"),xc=r(" come input. Questo valore \xE8 generato dall\u2019estrattore di caratteristiche. Crea una funzione che genera "),vl=l("code"),yc=r("pixel_values"),Pc=r(" dai transforms:"),hp=c(),b(Ra.$$.fragment),bp=c(),Fa=l("ol"),Ha=l("li"),Ac=r("Poi utilizza \u{1F917} Datasets "),Ma=l("a"),$l=l("code"),Cc=r("set_transform"),Dc=r("per applicare al volo la trasformzazione:"),dp=c(),b(Qa.$$.fragment),jp=c(),Ba=l("ol"),Ja=l("li"),Ic=r("Adesso quando accedi all\u2019immagine, puoi notare che l\u2019estrattore di caratteristiche ha aggiunto "),kl=l("code"),Sc=r("pixel_values"),Tc=r(" allo schema di input:"),fp=c(),b(Wa.$$.fragment),gp=c(),Ne=l("p"),Oc=r("Di seguito come si vede l\u2019immagine dopo la fase di preprocessing. Come ci si aspetterebbe dalle trasformazioni applicate, l\u2019immagine \xE8 stata ritagliata in modo casuale e le propriet\xE0 del colore sono diverse."),_p=c(),b(Va.$$.fragment),vp=c(),Le=l("p"),Ue=l("img"),$p=c(),ps=l("h2"),Os=l("a"),El=l("span"),b(Ga.$$.fragment),Nc=c(),zl=l("span"),Lc=r("Multimodal"),kp=c(),Re=l("p"),Uc=r("Per attivit\xE0 multimodali userai una combinazione di tutto quello che hai imparato poco fa e applicherai le tue competenze alla comprensione automatica del parlato (Automatic Speech Recognition -  ASR). Questo significa che avrai bisogno di:"),Ep=c(),Ns=l("ul"),wl=l("li"),Rc=r("Un estrattore delle caratteristiche per processare i dati audio."),Fc=c(),ql=l("li"),Hc=r("Il Tokenizer per processarfe i testi."),zp=c(),Ls=l("p"),Mc=r("Ritorna sul datasere "),Ya=l("a"),Qc=r("LJ Speech"),Bc=r(":"),wp=c(),b(Ka.$$.fragment),qp=c(),Q=l("p"),Jc=r("Visto che sei interessato solo alle colonne "),xl=l("code"),Wc=r("audio"),Vc=r(" e "),yl=l("code"),Gc=r("text"),Yc=r(", elimina tutte le altre:"),xp=c(),b(Xa.$$.fragment),yp=c(),B=l("p"),Kc=r("Adesso guarda le colonne "),Pl=l("code"),Xc=r("audio"),Zc=r(" e "),Al=l("code"),su=r("text"),au=r(":"),Pp=c(),b(Za.$$.fragment),Ap=c(),Us=l("p"),eu=r("Ricorda dalla sezione precedente sull\u2019elaborazione dei dati audio, tu dovresti sempre "),Fe=l("a"),nu=r("ricampionare"),lu=r(" la frequenza di campionamento dei tuoi dati audio per farla coincidere con quella del dataset usato dal modello preaddestrato:"),Cp=c(),b(se.$$.fragment),Dp=c(),rs=l("h3"),Rs=l("a"),Cl=l("span"),b(ae.$$.fragment),tu=c(),Dl=l("span"),pu=r("Processor"),Ip=c(),He=l("p"),ru=r("Un processor combina un estrattore di caratteristiche e un tokenizer. Carica un processor con [`AutoProcessor.from_pretrained]:"),Sp=c(),b(ee.$$.fragment),Tp=c(),Me=l("ol"),os=l("li"),ou=r("Crea una funzione che processi i dati audio in "),Il=l("code"),iu=r("input_values"),cu=r(", e tokenizza il in to "),Sl=l("code"),uu=r("labels"),mu=r(". Questi sono i tuoi input per il modello:"),Op=c(),b(ne.$$.fragment),Np=c(),le=l("ol"),te=l("li"),hu=r("Applica la funzione "),Tl=l("code"),bu=r("prepare_dataset"),du=r(" ad un campione:"),Lp=c(),b(pe.$$.fragment),Up=c(),J=l("p"),ju=r("Nota che il processor ha aggiunto "),Ol=l("code"),fu=r("input_values"),gu=r(" e "),Nl=l("code"),_u=r("labels"),vu=r(". La frequenza di campionamento \xE8 stata corretta riducendola a 16kHz."),Rp=c(),Qe=l("p"),$u=r("Fantastico, ora dovreste essere in grado di preelaborare i dati per qualsiasi modalit\xE0 e persino di combinare modalit\xE0 diverse! Nella prossima esercitazione, impareremo a mettere a punto un modello sui dati appena pre-elaborati."),this.h()},l(s){const n=vb('[data-svelte="svelte-1phssyn"]',document.head);v=t(n,"META",{name:!0,content:!0}),n.forEach(a),k=u(s),h=t(s,"H1",{class:!0});var re=p(h);E=t(re,"A",{id:!0,class:!0,href:!0});var Ll=p(E);z=t(Ll,"SPAN",{});var Au=p(z);d(q.$$.fragment,Au),Au.forEach(a),Ll.forEach(a),C=u(re),is=t(re,"SPAN",{});var Cu=p(is);$r=o(Cu,"Preprocess"),Cu.forEach(a),re.forEach(a),Ul=u(s),d(Qs.$$.fragment,s),Rl=u(s),oe=t(s,"P",{});var Du=p(oe);kr=o(Du,"Prima di poter usare i dati in un modello, bisogna processarli in un formato accettabile per quest\u2019ultimo. Un modello non comprende il testo piano, le immagini o l\u2019audio. Bisogna convertire questi input in numeri e assemblarli all\u2019interno di tensori. In questa esercitazione, tu potrai:"),Du.forEach(a),Fl=u(s),D=t(s,"UL",{});var Be=p(D);on=t(Be,"LI",{});var Iu=p(on);Er=o(Iu,"Preprocessare dati testuali con un tokenizer."),Iu.forEach(a),zr=u(Be),cn=t(Be,"LI",{});var Su=p(cn);wr=o(Su,"Preprocessare immagini o dati audio con un estrattore di caratteristiche."),Su.forEach(a),qr=u(Be),un=t(Be,"LI",{});var Tu=p(un);xr=o(Tu,"Preprocessare dati per attivit\xE0 multimodali mediante un processore."),Tu.forEach(a),Be.forEach(a),Hl=u(s),W=t(s,"H2",{class:!0});var Hp=p(W);cs=t(Hp,"A",{id:!0,class:!0,href:!0});var Ou=p(cs);mn=t(Ou,"SPAN",{});var Nu=p(mn);d(Bs.$$.fragment,Nu),Nu.forEach(a),Ou.forEach(a),yr=u(Hp),hn=t(Hp,"SPAN",{});var Lu=p(hn);Pr=o(Lu,"NLP"),Lu.forEach(a),Hp.forEach(a),Ml=u(s),d(Js.$$.fragment,s),Ql=u(s),I=t(s,"P",{});var Je=p(I);Ar=o(Je,"Lo strumento principale per processare dati testuali \xE8 un "),ie=t(Je,"A",{href:!0});var Uu=p(ie);Cr=o(Uu,"tokenizer"),Uu.forEach(a),Dr=o(Je,". Un tokenizer inizia separando il testo in "),bn=t(Je,"EM",{});var Ru=p(bn);Ir=o(Ru,"tokens"),Ru.forEach(a),Sr=o(Je," secondo una serie di regole. I tokens sono convertiti in numeri, questi vengono utilizzati per costruire i tensori di input del modello. Anche altri input addizionali se richiesti dal modello vengono aggiunti dal tokenizer."),Je.forEach(a),Bl=u(s),d(us.$$.fragment,s),Jl=u(s),S=t(s,"P",{});var We=p(S);Tr=o(We,"Iniziamo subito caricando un tokenizer preaddestrato con la classe "),dn=t(We,"CODE",{});var Fu=p(dn);Or=o(Fu,"AutoTokenizer"),Fu.forEach(a),Nr=o(We,". Questo scarica il "),jn=t(We,"EM",{});var Hu=p(jn);Lr=o(Hu,"vocabolario"),Hu.forEach(a),Ur=o(We," usato quando il modello \xE8 stato preaddestrato."),We.forEach(a),Wl=u(s),V=t(s,"H3",{class:!0});var Mp=p(V);ms=t(Mp,"A",{id:!0,class:!0,href:!0});var Mu=p(ms);fn=t(Mu,"SPAN",{});var Qu=p(fn);d(Ws.$$.fragment,Qu),Qu.forEach(a),Mu.forEach(a),Rr=u(Mp),gn=t(Mp,"SPAN",{});var Bu=p(gn);Fr=o(Bu,"Tokenize"),Bu.forEach(a),Mp.forEach(a),Vl=u(s),hs=t(s,"P",{});var Qp=p(hs);Hr=o(Qp,"Carica un tokenizer preaddestrato con "),_n=t(Qp,"CODE",{});var Ju=p(_n);Mr=o(Ju,"AutoTokenizer.from_pretrained()"),Ju.forEach(a),Qr=o(Qp,":"),Qp.forEach(a),Gl=u(s),d(Vs.$$.fragment,s),Yl=u(s),ce=t(s,"P",{});var Wu=p(ce);Br=o(Wu,"Poi inserisci le tue frasi nel tokenizer:"),Wu.forEach(a),Kl=u(s),d(Gs.$$.fragment,s),Xl=u(s),ue=t(s,"P",{});var Vu=p(ue);Jr=o(Vu,"Il tokenizer restituisce un dizionario contenente tre oggetti importanti:"),Vu.forEach(a),Zl=u(s),T=t(s,"UL",{});var Ve=p(T);me=t(Ve,"LI",{});var ku=p(me);he=t(ku,"A",{href:!0});var Gu=p(he);Wr=o(Gu,"input_ids"),Gu.forEach(a),Vr=o(ku," sono gli indici che corrispondono ad ogni token nella frase."),ku.forEach(a),Gr=u(Ve),be=t(Ve,"LI",{});var Eu=p(be);de=t(Eu,"A",{href:!0});var Yu=p(de);Yr=o(Yu,"attention_mask"),Yu.forEach(a),Kr=o(Eu," indicata se un token deve essere elaborato o no."),Eu.forEach(a),Xr=u(Ve),je=t(Ve,"LI",{});var zu=p(je);fe=t(zu,"A",{href:!0});var Ku=p(fe);Zr=o(Ku,"token_type_ids"),Ku.forEach(a),so=o(zu," identifica a quale sequenza appartiene un token se \xE8 presente pi\xF9 di una sequenza."),zu.forEach(a),Ve.forEach(a),st=u(s),bs=t(s,"P",{});var Bp=p(bs);ao=o(Bp,"Si possono decodificare gli "),vn=t(Bp,"CODE",{});var Xu=p(vn);eo=o(Xu,"input_ids"),Xu.forEach(a),no=o(Bp," per farsi restituire l\u2019input originale:"),Bp.forEach(a),at=u(s),d(Ys.$$.fragment,s),et=u(s),O=t(s,"P",{});var Ge=p(O);lo=o(Ge,"Come si pu\xF2 vedere, il tokenizer aggiunge due token speciali - "),$n=t(Ge,"CODE",{});var Zu=p($n);to=o(Zu,"CLS"),Zu.forEach(a),po=o(Ge," and "),kn=t(Ge,"CODE",{});var sm=p(kn);ro=o(sm,"SEP"),sm.forEach(a),oo=o(Ge," (classifier and separator) - alla frase. Non tutti i modelli hanno bisogno dei token speciali, ma se servono, il tokenizer li aggiunger\xE0 automaticamente."),Ge.forEach(a),nt=u(s),ge=t(s,"P",{});var am=p(ge);io=o(am,"Se ci sono pi\xF9 frasi che vuoi processare, passale come una lista al tokenizer:"),am.forEach(a),lt=u(s),d(Ks.$$.fragment,s),tt=u(s),G=t(s,"H3",{class:!0});var Jp=p(G);ds=t(Jp,"A",{id:!0,class:!0,href:!0});var em=p(ds);En=t(em,"SPAN",{});var nm=p(En);d(Xs.$$.fragment,nm),nm.forEach(a),em.forEach(a),co=u(Jp),zn=t(Jp,"SPAN",{});var lm=p(zn);uo=o(lm,"Pad"),lm.forEach(a),Jp.forEach(a),pt=u(s),js=t(s,"P",{});var Wp=p(js);mo=o(Wp,"Questo \xE8 un argomento importante. Quando processi un insieme di frasi potrebbero non avere tutte la stessa lunghezza. Questo \xE8 un problema perch\xE8 i tensori, in input del modello, devono avere dimensioni uniformi. Il padding \xE8 una strategia per assicurarsi che i tensori siano rettangolari aggiungendo uno speciale "),wn=t(Wp,"EM",{});var tm=p(wn);ho=o(tm,"padding token"),tm.forEach(a),bo=o(Wp," alle frasi pi\xF9 corte."),Wp.forEach(a),rt=u(s),N=t(s,"P",{});var Ye=p(N);jo=o(Ye,"Imposta il parametro "),qn=t(Ye,"CODE",{});var pm=p(qn);fo=o(pm,"padding"),pm.forEach(a),go=o(Ye," a "),xn=t(Ye,"CODE",{});var rm=p(xn);_o=o(rm,"True"),rm.forEach(a),vo=o(Ye," per imbottire le frasi pi\xF9 corte nel gruppo in modo che combacino con la massima lunghezza presente:"),Ye.forEach(a),ot=u(s),d(Zs.$$.fragment,s),it=u(s),fs=t(s,"P",{});var Vp=p(fs);$o=o(Vp,"Nota che il tokenizer aggiunge alle sequenze degli "),yn=t(Vp,"CODE",{});var om=p(yn);ko=o(om,"0"),om.forEach(a),Eo=o(Vp," perch\xE8 sono troppo corte!"),Vp.forEach(a),ct=u(s),Y=t(s,"H3",{class:!0});var Gp=p(Y);gs=t(Gp,"A",{id:!0,class:!0,href:!0});var im=p(gs);Pn=t(im,"SPAN",{});var cm=p(Pn);d(sa.$$.fragment,cm),cm.forEach(a),im.forEach(a),zo=u(Gp),An=t(Gp,"SPAN",{});var um=p(An);wo=o(um,"Truncation"),um.forEach(a),Gp.forEach(a),ut=u(s),_e=t(s,"P",{});var mm=p(_e);qo=o(mm,"L\u2019altra faccia della medaglia \xE8 che avolte le sequenze possono essere troppo lunghe per essere gestite dal modello. In questo caso, avrai bisogno di troncare la sequenza per avere una lunghezza minore."),mm.forEach(a),mt=u(s),L=t(s,"P",{});var Ke=p(L);xo=o(Ke,"Imposta il parametro "),Cn=t(Ke,"CODE",{});var hm=p(Cn);yo=o(hm,"truncation"),hm.forEach(a),Po=o(Ke," a "),Dn=t(Ke,"CODE",{});var bm=p(Dn);Ao=o(bm,"True"),bm.forEach(a),Co=o(Ke," per troncare una sequenza alla massima lunghezza accettata dal modello:"),Ke.forEach(a),ht=u(s),d(aa.$$.fragment,s),bt=u(s),K=t(s,"H3",{class:!0});var Yp=p(K);_s=t(Yp,"A",{id:!0,class:!0,href:!0});var dm=p(_s);In=t(dm,"SPAN",{});var jm=p(In);d(ea.$$.fragment,jm),jm.forEach(a),dm.forEach(a),Do=u(Yp),Sn=t(Yp,"SPAN",{});var fm=p(Sn);Io=o(fm,"Costruire i tensori"),fm.forEach(a),Yp.forEach(a),dt=u(s),ve=t(s,"P",{});var gm=p(ve);So=o(gm,"Infine, vuoi che il tokenizer restituisca i tensori prodotti dal modello."),gm.forEach(a),jt=u(s),x=t(s,"P",{});var Fs=p(x);To=o(Fs,"Imposta il parametro "),Tn=t(Fs,"CODE",{});var _m=p(Tn);Oo=o(_m,"return_tensors"),_m.forEach(a),No=o(Fs," su "),On=t(Fs,"CODE",{});var vm=p(On);Lo=o(vm,"pt"),vm.forEach(a),Uo=o(Fs," per PyTorch, o "),Nn=t(Fs,"CODE",{});var $m=p(Nn);Ro=o($m,"tf"),$m.forEach(a),Fo=o(Fs," per TensorFlow:"),Fs.forEach(a),ft=u(s),d(vs.$$.fragment,s),gt=u(s),X=t(s,"H2",{class:!0});var Kp=p(X);$s=t(Kp,"A",{id:!0,class:!0,href:!0});var km=p($s);Ln=t(km,"SPAN",{});var Em=p(Ln);d(na.$$.fragment,Em),Em.forEach(a),km.forEach(a),Ho=u(Kp),Un=t(Kp,"SPAN",{});var zm=p(Un);Mo=o(zm,"Audio"),zm.forEach(a),Kp.forEach(a),_t=u(s),ks=t(s,"P",{});var Xp=p(ks);Qo=o(Xp,"Gli input audio sono processati in modo differente rispetto al testo, ma l\u2019obiettivo rimane lo stesso: creare sequenze numeriche che il modello pu\xF2 capire. Un "),$e=t(Xp,"A",{href:!0});var wm=p($e);Bo=o(wm,"estrattore di caratteristiche"),wm.forEach(a),Jo=o(Xp," \xE8 progettato con lo scopo preciso di estrarre caratteristiche da immagini o dati audio grezzi e convertirli in tensori. Prima di iniziare, installa \u{1F917} Datasets per caricare un dataset audio e sperimentare:"),Xp.forEach(a),vt=u(s),d(la.$$.fragment,s),$t=u(s),U=t(s,"P",{});var Xe=p(U);Wo=o(Xe,"Carica il dataset "),ta=t(Xe,"A",{href:!0,rel:!0});var qm=p(ta);Vo=o(qm,"MInDS-14"),qm.forEach(a),Go=o(Xe," (vedi il \u{1F917} "),pa=t(Xe,"A",{href:!0,rel:!0});var xm=p(pa);Yo=o(xm,"Datasets tutorial"),xm.forEach(a),Ko=o(Xe," per avere maggiori dettagli su come caricare un dataset):"),Xe.forEach(a),kt=u(s),d(ra.$$.fragment,s),Et=u(s),R=t(s,"P",{});var Ze=p(R);Xo=o(Ze,"Accedi al primo elemento della colonna "),Rn=t(Ze,"CODE",{});var ym=p(Rn);Zo=o(ym,"audio"),ym.forEach(a),si=o(Ze," per dare uno sguardo all\u2019input. Richiamando la colonna "),Fn=t(Ze,"CODE",{});var Pm=p(Fn);ai=o(Pm,"audio"),Pm.forEach(a),ei=o(Ze," sar\xE0 caricato automaticamente e ricampionato il file audio:"),Ze.forEach(a),zt=u(s),d(oa.$$.fragment,s),wt=u(s),ke=t(s,"P",{});var Am=p(ke);ni=o(Am,"Questo restituisce tre oggetti:"),Am.forEach(a),qt=u(s),F=t(s,"UL",{});var sn=p(F);Ee=t(sn,"LI",{});var wu=p(Ee);Hn=t(wu,"CODE",{});var Cm=p(Hn);li=o(Cm,"array"),Cm.forEach(a),ti=o(wu," \xE8 il segnale vocale caricato - e potenzialmente ricampionato - come vettore 1D."),wu.forEach(a),pi=u(sn),ze=t(sn,"LI",{});var qu=p(ze);Mn=t(qu,"CODE",{});var Dm=p(Mn);ri=o(Dm,"path"),Dm.forEach(a),oi=o(qu," il percorso del file audio."),qu.forEach(a),ii=u(sn),we=t(sn,"LI",{});var xu=p(we);Qn=t(xu,"CODE",{});var Im=p(Qn);ci=o(Im,"sampling_rate"),Im.forEach(a),ui=o(xu," si riferisce al numero di campioni del segnale vocale misurati al secondo."),xu.forEach(a),sn.forEach(a),xt=u(s),Z=t(s,"H3",{class:!0});var Zp=p(Z);Es=t(Zp,"A",{id:!0,class:!0,href:!0});var Sm=p(Es);Bn=t(Sm,"SPAN",{});var Tm=p(Bn);d(ia.$$.fragment,Tm),Tm.forEach(a),Sm.forEach(a),mi=u(Zp),Jn=t(Zp,"SPAN",{});var Om=p(Jn);hi=o(Om,"Ricampionamento"),Om.forEach(a),Zp.forEach(a),yt=u(s),zs=t(s,"P",{});var sr=p(zs);bi=o(sr,"Per questo tutorial, puoi usare il modello "),ca=t(sr,"A",{href:!0,rel:!0});var Nm=p(ca);di=o(Nm,"Wav2Vec2"),Nm.forEach(a),ji=o(sr,". Come puoi vedere dalla model card, il modello Wav2Vec2 \xE8 preaddestrato su un campionamento vocale a 16kHz. E\u2019 importante che la frequenza di campionamento dei tuoi dati audio combaci con la frequenza di campionamento del dataset usato per preaddestrare il modello. Se la frequenza di campionamento dei tuoi dati non \xE8 uguale dovrai ricampionare i tuoi dati audio."),sr.forEach(a),Pt=u(s),ws=t(s,"P",{});var ar=p(ws);fi=o(ar,"Per esempio, il dataset "),ua=t(ar,"A",{href:!0,rel:!0});var Lm=p(ua);gi=o(Lm,"MInDS-14"),Lm.forEach(a),_i=o(ar," ha una frequenza di campionamento di 8000kHz. Utilizzando il modello Wav2Vec2 msu questo dataset, alzala a 16kHz:"),ar.forEach(a),At=u(s),d(ma.$$.fragment,s),Ct=u(s),qe=t(s,"OL",{});var Um=p(qe);ha=t(Um,"LI",{});var er=p(ha);vi=o(er,"Usa il metodo in \u{1F917} Datasets\u2019 "),ba=t(er,"A",{href:!0,rel:!0});var Rm=p(ba);Wn=t(Rm,"CODE",{});var Fm=p(Wn);$i=o(Fm,"cast_column"),Fm.forEach(a),Rm.forEach(a),ki=o(er," per alzare della frequenza di campionamento a 16kHz:"),er.forEach(a),Um.forEach(a),Dt=u(s),d(da.$$.fragment,s),It=u(s),ja=t(s,"OL",{start:!0});var Hm=p(ja);Vn=t(Hm,"LI",{});var Mm=p(Vn);Ei=o(Mm,"Carica il file audio:"),Mm.forEach(a),Hm.forEach(a),St=u(s),d(fa.$$.fragment,s),Tt=u(s),qs=t(s,"P",{});var nr=p(qs);zi=o(nr,"Come puoi notare, la "),Gn=t(nr,"CODE",{});var Qm=p(Gn);wi=o(Qm,"sampling_rate"),Qm.forEach(a),qi=o(nr," adesso \xE8 16kHz!"),nr.forEach(a),Ot=u(s),ss=t(s,"H3",{class:!0});var lr=p(ss);xs=t(lr,"A",{id:!0,class:!0,href:!0});var Bm=p(xs);Yn=t(Bm,"SPAN",{});var Jm=p(Yn);d(ga.$$.fragment,Jm),Jm.forEach(a),Bm.forEach(a),xi=u(lr),Kn=t(lr,"SPAN",{});var Wm=p(Kn);yi=o(Wm,"Feature extractor"),Wm.forEach(a),lr.forEach(a),Nt=u(s),y=t(s,"P",{});var Hs=p(y);Pi=o(Hs,"Il prossimo passo \xE8 caricare un estrattore di caratteristiche per normalizzare e fare padding sull\u2019input. Quando applichiamo il padding sui dati testuali, uno "),Xn=t(Hs,"CODE",{});var Vm=p(Xn);Ai=o(Vm,"0"),Vm.forEach(a),Ci=o(Hs," \xE8 aggiunto alle sequenze pi\xF9 brevi. La stessa idea si applica ai dati audio, l\u2019estrattore di caratteristiche per gli audio aggiunger\xE0 uno "),Zn=t(Hs,"CODE",{});var Gm=p(Zn);Di=o(Gm,"0"),Gm.forEach(a),Ii=o(Hs," - interpretato come silenzaio - agli "),sl=t(Hs,"CODE",{});var Ym=p(sl);Si=o(Ym,"array"),Ym.forEach(a),Ti=o(Hs,"."),Hs.forEach(a),Lt=u(s),ys=t(s,"P",{});var tr=p(ys);Oi=o(tr,"Carica l\u2019estrattore delle caratteristiche con "),al=t(tr,"CODE",{});var Km=p(al);Ni=o(Km,"AutoFeatureExtractor.from_pretrained()"),Km.forEach(a),Li=o(tr,":"),tr.forEach(a),Ut=u(s),d(_a.$$.fragment,s),Rt=u(s),H=t(s,"P",{});var an=p(H);Ui=o(an,"Inserisci l\u2019 "),el=t(an,"CODE",{});var Xm=p(el);Ri=o(Xm,"array"),Xm.forEach(a),Fi=o(an," audio nell\u2019estrattore delle caratteristiche. Noi raccomandiamo sempre di aggiungere il parametro "),nl=t(an,"CODE",{});var Zm=p(nl);Hi=o(Zm,"sampling_rate"),Zm.forEach(a),Mi=o(an," nell\u2019estrattore delle caratteristiche per correggere meglio qualche errore, dovuto ai silenzi, che potrebbe verificarsi."),an.forEach(a),Ft=u(s),d(va.$$.fragment,s),Ht=u(s),as=t(s,"H3",{class:!0});var pr=p(as);Ps=t(pr,"A",{id:!0,class:!0,href:!0});var sh=p(Ps);ll=t(sh,"SPAN",{});var ah=p(ll);d($a.$$.fragment,ah),ah.forEach(a),sh.forEach(a),Qi=u(pr),tl=t(pr,"SPAN",{});var eh=p(tl);Bi=o(eh,"Pad and truncate"),eh.forEach(a),pr.forEach(a),Mt=u(s),xe=t(s,"P",{});var nh=p(xe);Ji=o(nh,"Come per il tokenizer, puoi applicare le operazioni padding o truncation per manipolare sequenze di variabili a lotti. Dai uno sguaro alla lunghezza delle sequenze di questi due campioni audio:"),nh.forEach(a),Qt=u(s),d(ka.$$.fragment,s),Bt=u(s),ye=t(s,"P",{});var lh=p(ye);Wi=o(lh,"Come puoi vedere, il primo campione ga una sequenza pi\xF9 lunga del secondo. LCrea una funzione che preprocesser\xE0 il dataset. Specifica una lunghezza massima del campione, e l\u2019estrattore di features si occuper\xE0 di riempire o troncare la sequenza per coincidervi:"),lh.forEach(a),Jt=u(s),d(Ea.$$.fragment,s),Wt=u(s),Pe=t(s,"P",{});var th=p(Pe);Vi=o(th,"Applica la funzione ai primi esempi nel dataset:"),th.forEach(a),Vt=u(s),d(za.$$.fragment,s),Gt=u(s),Ae=t(s,"P",{});var ph=p(Ae);Gi=o(ph,"Adesso guarda la lunghezza dei campioni elaborati:"),ph.forEach(a),Yt=u(s),d(wa.$$.fragment,s),Kt=u(s),Ce=t(s,"P",{});var rh=p(Ce);Yi=o(rh,"La lunghezza dei campioni adesso coincide con la massima lunghezza impostata nelle funzione."),rh.forEach(a),Xt=u(s),es=t(s,"H2",{class:!0});var rr=p(es);As=t(rr,"A",{id:!0,class:!0,href:!0});var oh=p(As);pl=t(oh,"SPAN",{});var ih=p(pl);d(qa.$$.fragment,ih),ih.forEach(a),oh.forEach(a),Ki=u(rr),rl=t(rr,"SPAN",{});var ch=p(rl);Xi=o(ch,"Vision"),ch.forEach(a),rr.forEach(a),Zt=u(s),De=t(s,"P",{});var uh=p(De);Zi=o(uh,"Un estrattore di caratteristiche si pu\xF2 usare anche per processare immagini e per compiti di visione. Ancora una volta, l\u2019obiettivo \xE8 convertire l\u2019immagine grezza in un lotto di tensori come input."),uh.forEach(a),sp=u(s),M=t(s,"P",{});var en=p(M);sc=o(en,"Carica il dataset "),xa=t(en,"A",{href:!0,rel:!0});var mh=p(xa);ac=o(mh,"food101"),mh.forEach(a),ec=o(en," per questa esercitazione. Usa il parametro "),ol=t(en,"CODE",{});var hh=p(ol);nc=o(hh,"split"),hh.forEach(a),lc=o(en," di \u{1F917} Datasets  per caricare solo un piccolo campione dal dataset di addestramento poich\xE8 il set di dati \xE8 molto grande:"),en.forEach(a),ap=u(s),d(ya.$$.fragment,s),ep=u(s),Cs=t(s,"P",{});var or=p(Cs);tc=o(or,"Secondo passo, dai uno sguardo alle immagini usando la caratteristica "),Pa=t(or,"A",{href:!0,rel:!0});var bh=p(Pa);il=t(bh,"CODE",{});var dh=p(il);pc=o(dh,"Image"),dh.forEach(a),bh.forEach(a),rc=o(or," di \u{1F917} Datasets:"),or.forEach(a),np=u(s),d(Aa.$$.fragment,s),lp=u(s),Ie=t(s,"P",{});var jh=p(Ie);Se=t(jh,"IMG",{src:!0,alt:!0}),jh.forEach(a),tp=u(s),ns=t(s,"H3",{class:!0});var ir=p(ns);Ds=t(ir,"A",{id:!0,class:!0,href:!0});var fh=p(Ds);cl=t(fh,"SPAN",{});var gh=p(cl);d(Ca.$$.fragment,gh),gh.forEach(a),fh.forEach(a),oc=u(ir),ul=t(ir,"SPAN",{});var _h=p(ul);ic=o(_h,"Feature extractor"),_h.forEach(a),ir.forEach(a),pp=u(s),Is=t(s,"P",{});var cr=p(Is);cc=o(cr,"Carica l\u2019estrattore di caratteristiche "),ml=t(cr,"CODE",{});var vh=p(ml);uc=o(vh,"AutoFeatureExtractor.from_pretrained()"),vh.forEach(a),mc=o(cr,":"),cr.forEach(a),rp=u(s),d(Da.$$.fragment,s),op=u(s),ls=t(s,"H3",{class:!0});var ur=p(ls);Ss=t(ur,"A",{id:!0,class:!0,href:!0});var $h=p(Ss);hl=t($h,"SPAN",{});var kh=p(hl);d(Ia.$$.fragment,kh),kh.forEach(a),$h.forEach(a),hc=u(ur),bl=t(ur,"SPAN",{});var Eh=p(bl);bc=o(Eh,"Data augmentation"),Eh.forEach(a),ur.forEach(a),ip=u(s),Ts=t(s,"P",{});var mr=p(Ts);dc=o(mr,"Per le attivit\xE0 di visione, \xE8 usuale aggiungere alcuni tipi di data augmentation alle immagini come parte del preprocessing. Puoi aggiungere augmentations con qualsiasi libreria che preferisci, ma in questa esercitazione, userai il modulo "),Sa=t(mr,"A",{href:!0,rel:!0});var zh=p(Sa);dl=t(zh,"CODE",{});var wh=p(dl);jc=o(wh,"transforms"),wh.forEach(a),zh.forEach(a),fc=o(mr," di torchvision."),mr.forEach(a),cp=u(s),Te=t(s,"OL",{});var qh=p(Te);A=t(qh,"LI",{});var Ms=p(A);gc=o(Ms,"Normalizza l\u2019immagine e usa "),Ta=t(Ms,"A",{href:!0,rel:!0});var xh=p(Ta);jl=t(xh,"CODE",{});var yh=p(jl);_c=o(yh,"Compose"),yh.forEach(a),xh.forEach(a),vc=o(Ms," per concatenare alcune trasformazioni - "),Oa=t(Ms,"A",{href:!0,rel:!0});var Ph=p(Oa);fl=t(Ph,"CODE",{});var Ah=p(fl);$c=o(Ah,"RandomResizedCrop"),Ah.forEach(a),Ph.forEach(a),kc=o(Ms," e "),Na=t(Ms,"A",{href:!0,rel:!0});var Ch=p(Na);gl=t(Ch,"CODE",{});var Dh=p(gl);Ec=o(Dh,"ColorJitter"),Dh.forEach(a),Ch.forEach(a),zc=o(Ms," - insieme:"),Ms.forEach(a),qh.forEach(a),up=u(s),d(La.$$.fragment,s),mp=u(s),Ua=t(s,"OL",{start:!0});var Ih=p(Ua);ts=t(Ih,"LI",{});var nn=p(ts);wc=o(nn,"Il modello accetta "),Oe=t(nn,"A",{href:!0});var Sh=p(Oe);_l=t(Sh,"CODE",{});var Th=p(_l);qc=o(Th,"pixel_values"),Th.forEach(a),Sh.forEach(a),xc=o(nn," come input. Questo valore \xE8 generato dall\u2019estrattore di caratteristiche. Crea una funzione che genera "),vl=t(nn,"CODE",{});var Oh=p(vl);yc=o(Oh,"pixel_values"),Oh.forEach(a),Pc=o(nn," dai transforms:"),nn.forEach(a),Ih.forEach(a),hp=u(s),d(Ra.$$.fragment,s),bp=u(s),Fa=t(s,"OL",{start:!0});var Nh=p(Fa);Ha=t(Nh,"LI",{});var hr=p(Ha);Ac=o(hr,"Poi utilizza \u{1F917} Datasets "),Ma=t(hr,"A",{href:!0,rel:!0});var Lh=p(Ma);$l=t(Lh,"CODE",{});var Uh=p($l);Cc=o(Uh,"set_transform"),Uh.forEach(a),Lh.forEach(a),Dc=o(hr,"per applicare al volo la trasformzazione:"),hr.forEach(a),Nh.forEach(a),dp=u(s),d(Qa.$$.fragment,s),jp=u(s),Ba=t(s,"OL",{start:!0});var Rh=p(Ba);Ja=t(Rh,"LI",{});var br=p(Ja);Ic=o(br,"Adesso quando accedi all\u2019immagine, puoi notare che l\u2019estrattore di caratteristiche ha aggiunto "),kl=t(br,"CODE",{});var Fh=p(kl);Sc=o(Fh,"pixel_values"),Fh.forEach(a),Tc=o(br," allo schema di input:"),br.forEach(a),Rh.forEach(a),fp=u(s),d(Wa.$$.fragment,s),gp=u(s),Ne=t(s,"P",{});var Hh=p(Ne);Oc=o(Hh,"Di seguito come si vede l\u2019immagine dopo la fase di preprocessing. Come ci si aspetterebbe dalle trasformazioni applicate, l\u2019immagine \xE8 stata ritagliata in modo casuale e le propriet\xE0 del colore sono diverse."),Hh.forEach(a),_p=u(s),d(Va.$$.fragment,s),vp=u(s),Le=t(s,"P",{});var Mh=p(Le);Ue=t(Mh,"IMG",{src:!0,alt:!0}),Mh.forEach(a),$p=u(s),ps=t(s,"H2",{class:!0});var dr=p(ps);Os=t(dr,"A",{id:!0,class:!0,href:!0});var Qh=p(Os);El=t(Qh,"SPAN",{});var Bh=p(El);d(Ga.$$.fragment,Bh),Bh.forEach(a),Qh.forEach(a),Nc=u(dr),zl=t(dr,"SPAN",{});var Jh=p(zl);Lc=o(Jh,"Multimodal"),Jh.forEach(a),dr.forEach(a),kp=u(s),Re=t(s,"P",{});var Wh=p(Re);Uc=o(Wh,"Per attivit\xE0 multimodali userai una combinazione di tutto quello che hai imparato poco fa e applicherai le tue competenze alla comprensione automatica del parlato (Automatic Speech Recognition -  ASR). Questo significa che avrai bisogno di:"),Wh.forEach(a),Ep=u(s),Ns=t(s,"UL",{});var jr=p(Ns);wl=t(jr,"LI",{});var Vh=p(wl);Rc=o(Vh,"Un estrattore delle caratteristiche per processare i dati audio."),Vh.forEach(a),Fc=u(jr),ql=t(jr,"LI",{});var Gh=p(ql);Hc=o(Gh,"Il Tokenizer per processarfe i testi."),Gh.forEach(a),jr.forEach(a),zp=u(s),Ls=t(s,"P",{});var fr=p(Ls);Mc=o(fr,"Ritorna sul datasere "),Ya=t(fr,"A",{href:!0,rel:!0});var Yh=p(Ya);Qc=o(Yh,"LJ Speech"),Yh.forEach(a),Bc=o(fr,":"),fr.forEach(a),wp=u(s),d(Ka.$$.fragment,s),qp=u(s),Q=t(s,"P",{});var ln=p(Q);Jc=o(ln,"Visto che sei interessato solo alle colonne "),xl=t(ln,"CODE",{});var Kh=p(xl);Wc=o(Kh,"audio"),Kh.forEach(a),Vc=o(ln," e "),yl=t(ln,"CODE",{});var Xh=p(yl);Gc=o(Xh,"text"),Xh.forEach(a),Yc=o(ln,", elimina tutte le altre:"),ln.forEach(a),xp=u(s),d(Xa.$$.fragment,s),yp=u(s),B=t(s,"P",{});var tn=p(B);Kc=o(tn,"Adesso guarda le colonne "),Pl=t(tn,"CODE",{});var Zh=p(Pl);Xc=o(Zh,"audio"),Zh.forEach(a),Zc=o(tn," e "),Al=t(tn,"CODE",{});var sb=p(Al);su=o(sb,"text"),sb.forEach(a),au=o(tn,":"),tn.forEach(a),Pp=u(s),d(Za.$$.fragment,s),Ap=u(s),Us=t(s,"P",{});var gr=p(Us);eu=o(gr,"Ricorda dalla sezione precedente sull\u2019elaborazione dei dati audio, tu dovresti sempre "),Fe=t(gr,"A",{href:!0});var ab=p(Fe);nu=o(ab,"ricampionare"),ab.forEach(a),lu=o(gr," la frequenza di campionamento dei tuoi dati audio per farla coincidere con quella del dataset usato dal modello preaddestrato:"),gr.forEach(a),Cp=u(s),d(se.$$.fragment,s),Dp=u(s),rs=t(s,"H3",{class:!0});var _r=p(rs);Rs=t(_r,"A",{id:!0,class:!0,href:!0});var eb=p(Rs);Cl=t(eb,"SPAN",{});var nb=p(Cl);d(ae.$$.fragment,nb),nb.forEach(a),eb.forEach(a),tu=u(_r),Dl=t(_r,"SPAN",{});var lb=p(Dl);pu=o(lb,"Processor"),lb.forEach(a),_r.forEach(a),Ip=u(s),He=t(s,"P",{});var tb=p(He);ru=o(tb,"Un processor combina un estrattore di caratteristiche e un tokenizer. Carica un processor con [`AutoProcessor.from_pretrained]:"),tb.forEach(a),Sp=u(s),d(ee.$$.fragment,s),Tp=u(s),Me=t(s,"OL",{});var pb=p(Me);os=t(pb,"LI",{});var pn=p(os);ou=o(pn,"Crea una funzione che processi i dati audio in "),Il=t(pn,"CODE",{});var rb=p(Il);iu=o(rb,"input_values"),rb.forEach(a),cu=o(pn,", e tokenizza il in to "),Sl=t(pn,"CODE",{});var ob=p(Sl);uu=o(ob,"labels"),ob.forEach(a),mu=o(pn,". Questi sono i tuoi input per il modello:"),pn.forEach(a),pb.forEach(a),Op=u(s),d(ne.$$.fragment,s),Np=u(s),le=t(s,"OL",{start:!0});var ib=p(le);te=t(ib,"LI",{});var vr=p(te);hu=o(vr,"Applica la funzione "),Tl=t(vr,"CODE",{});var cb=p(Tl);bu=o(cb,"prepare_dataset"),cb.forEach(a),du=o(vr," ad un campione:"),vr.forEach(a),ib.forEach(a),Lp=u(s),d(pe.$$.fragment,s),Up=u(s),J=t(s,"P",{});var rn=p(J);ju=o(rn,"Nota che il processor ha aggiunto "),Ol=t(rn,"CODE",{});var ub=p(Ol);fu=o(ub,"input_values"),ub.forEach(a),gu=o(rn," e "),Nl=t(rn,"CODE",{});var mb=p(Nl);_u=o(mb,"labels"),mb.forEach(a),vu=o(rn,". La frequenza di campionamento \xE8 stata corretta riducendola a 16kHz."),rn.forEach(a),Rp=u(s),Qe=t(s,"P",{});var hb=p(Qe);$u=o(hb,"Fantastico, ora dovreste essere in grado di preelaborare i dati per qualsiasi modalit\xE0 e persino di combinare modalit\xE0 diverse! Nella prossima esercitazione, impareremo a mettere a punto un modello sui dati appena pre-elaborati."),hb.forEach(a),this.h()},h(){m(v,"name","hf:doc:metadata"),m(v,"content",JSON.stringify(Db)),m(E,"id","preprocess"),m(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E,"href","#preprocess"),m(h,"class","relative group"),m(cs,"id","nlp"),m(cs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cs,"href","#nlp"),m(W,"class","relative group"),m(ie,"href","main_classes/tokenizer"),m(ms,"id","tokenize"),m(ms,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ms,"href","#tokenize"),m(V,"class","relative group"),m(he,"href","glossary#input-ids"),m(de,"href","glossary#attention-mask"),m(fe,"href","glossary#token-type-ids"),m(ds,"id","pad"),m(ds,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ds,"href","#pad"),m(G,"class","relative group"),m(gs,"id","truncation"),m(gs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(gs,"href","#truncation"),m(Y,"class","relative group"),m(_s,"id","costruire-i-tensori"),m(_s,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_s,"href","#costruire-i-tensori"),m(K,"class","relative group"),m($s,"id","audio"),m($s,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($s,"href","#audio"),m(X,"class","relative group"),m($e,"href","main_classes/feature_extractor"),m(ta,"href","https://huggingface.co/datasets/PolyAI/minds14"),m(ta,"rel","nofollow"),m(pa,"href","https://huggingface.co/docs/datasets/load_hub.html"),m(pa,"rel","nofollow"),m(Es,"id","ricampionamento"),m(Es,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Es,"href","#ricampionamento"),m(Z,"class","relative group"),m(ca,"href","https://huggingface.co/facebook/wav2vec2-base"),m(ca,"rel","nofollow"),m(ua,"href","https://huggingface.co/datasets/PolyAI/minds14"),m(ua,"rel","nofollow"),m(ba,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.cast_column"),m(ba,"rel","nofollow"),m(ja,"start","2"),m(xs,"id","feature-extractor"),m(xs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(xs,"href","#feature-extractor"),m(ss,"class","relative group"),m(Ps,"id","pad-and-truncate"),m(Ps,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ps,"href","#pad-and-truncate"),m(as,"class","relative group"),m(As,"id","vision"),m(As,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(As,"href","#vision"),m(es,"class","relative group"),m(xa,"href","https://huggingface.co/datasets/food101"),m(xa,"rel","nofollow"),m(Pa,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=image#datasets.Image"),m(Pa,"rel","nofollow"),bb(Se.src,yu="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vision-preprocess-tutorial.png")||m(Se,"src",yu),m(Se,"alt","vision-preprocess-tutorial.png"),m(Ds,"id","feature-extractor"),m(Ds,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ds,"href","#feature-extractor"),m(ns,"class","relative group"),m(Ss,"id","data-augmentation"),m(Ss,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ss,"href","#data-augmentation"),m(ls,"class","relative group"),m(Sa,"href","https://pytorch.org/vision/stable/transforms.html"),m(Sa,"rel","nofollow"),m(Ta,"href","https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html"),m(Ta,"rel","nofollow"),m(Oa,"href","https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html"),m(Oa,"rel","nofollow"),m(Na,"href","https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html"),m(Na,"rel","nofollow"),m(Oe,"href","model_doc/visionencoderdecoder#transformers.VisionEncoderDecoderModel.forward.pixel_values"),m(Ua,"start","2"),m(Ma,"href","https://huggingface.co/docs/datasets/process.html#format-transform"),m(Ma,"rel","nofollow"),m(Fa,"start","3"),m(Ba,"start","4"),bb(Ue.src,Pu="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/preprocessed_image.png")||m(Ue,"src",Pu),m(Ue,"alt","preprocessed_image"),m(Os,"id","multimodal"),m(Os,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Os,"href","#multimodal"),m(ps,"class","relative group"),m(Ya,"href","https://huggingface.co/datasets/lj_speech"),m(Ya,"rel","nofollow"),m(Fe,"href","preprocessing#audio"),m(Rs,"id","processor"),m(Rs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Rs,"href","#processor"),m(rs,"class","relative group"),m(le,"start","2")},m(s,n){e(document.head,v),i(s,k,n),i(s,h,n),e(h,E),e(E,z),j(q,z,null),e(h,C),e(h,is),e(is,$r),i(s,Ul,n),j(Qs,s,n),i(s,Rl,n),i(s,oe,n),e(oe,kr),i(s,Fl,n),i(s,D,n),e(D,on),e(on,Er),e(D,zr),e(D,cn),e(cn,wr),e(D,qr),e(D,un),e(un,xr),i(s,Hl,n),i(s,W,n),e(W,cs),e(cs,mn),j(Bs,mn,null),e(W,yr),e(W,hn),e(hn,Pr),i(s,Ml,n),j(Js,s,n),i(s,Ql,n),i(s,I,n),e(I,Ar),e(I,ie),e(ie,Cr),e(I,Dr),e(I,bn),e(bn,Ir),e(I,Sr),i(s,Bl,n),j(us,s,n),i(s,Jl,n),i(s,S,n),e(S,Tr),e(S,dn),e(dn,Or),e(S,Nr),e(S,jn),e(jn,Lr),e(S,Ur),i(s,Wl,n),i(s,V,n),e(V,ms),e(ms,fn),j(Ws,fn,null),e(V,Rr),e(V,gn),e(gn,Fr),i(s,Vl,n),i(s,hs,n),e(hs,Hr),e(hs,_n),e(_n,Mr),e(hs,Qr),i(s,Gl,n),j(Vs,s,n),i(s,Yl,n),i(s,ce,n),e(ce,Br),i(s,Kl,n),j(Gs,s,n),i(s,Xl,n),i(s,ue,n),e(ue,Jr),i(s,Zl,n),i(s,T,n),e(T,me),e(me,he),e(he,Wr),e(me,Vr),e(T,Gr),e(T,be),e(be,de),e(de,Yr),e(be,Kr),e(T,Xr),e(T,je),e(je,fe),e(fe,Zr),e(je,so),i(s,st,n),i(s,bs,n),e(bs,ao),e(bs,vn),e(vn,eo),e(bs,no),i(s,at,n),j(Ys,s,n),i(s,et,n),i(s,O,n),e(O,lo),e(O,$n),e($n,to),e(O,po),e(O,kn),e(kn,ro),e(O,oo),i(s,nt,n),i(s,ge,n),e(ge,io),i(s,lt,n),j(Ks,s,n),i(s,tt,n),i(s,G,n),e(G,ds),e(ds,En),j(Xs,En,null),e(G,co),e(G,zn),e(zn,uo),i(s,pt,n),i(s,js,n),e(js,mo),e(js,wn),e(wn,ho),e(js,bo),i(s,rt,n),i(s,N,n),e(N,jo),e(N,qn),e(qn,fo),e(N,go),e(N,xn),e(xn,_o),e(N,vo),i(s,ot,n),j(Zs,s,n),i(s,it,n),i(s,fs,n),e(fs,$o),e(fs,yn),e(yn,ko),e(fs,Eo),i(s,ct,n),i(s,Y,n),e(Y,gs),e(gs,Pn),j(sa,Pn,null),e(Y,zo),e(Y,An),e(An,wo),i(s,ut,n),i(s,_e,n),e(_e,qo),i(s,mt,n),i(s,L,n),e(L,xo),e(L,Cn),e(Cn,yo),e(L,Po),e(L,Dn),e(Dn,Ao),e(L,Co),i(s,ht,n),j(aa,s,n),i(s,bt,n),i(s,K,n),e(K,_s),e(_s,In),j(ea,In,null),e(K,Do),e(K,Sn),e(Sn,Io),i(s,dt,n),i(s,ve,n),e(ve,So),i(s,jt,n),i(s,x,n),e(x,To),e(x,Tn),e(Tn,Oo),e(x,No),e(x,On),e(On,Lo),e(x,Uo),e(x,Nn),e(Nn,Ro),e(x,Fo),i(s,ft,n),j(vs,s,n),i(s,gt,n),i(s,X,n),e(X,$s),e($s,Ln),j(na,Ln,null),e(X,Ho),e(X,Un),e(Un,Mo),i(s,_t,n),i(s,ks,n),e(ks,Qo),e(ks,$e),e($e,Bo),e(ks,Jo),i(s,vt,n),j(la,s,n),i(s,$t,n),i(s,U,n),e(U,Wo),e(U,ta),e(ta,Vo),e(U,Go),e(U,pa),e(pa,Yo),e(U,Ko),i(s,kt,n),j(ra,s,n),i(s,Et,n),i(s,R,n),e(R,Xo),e(R,Rn),e(Rn,Zo),e(R,si),e(R,Fn),e(Fn,ai),e(R,ei),i(s,zt,n),j(oa,s,n),i(s,wt,n),i(s,ke,n),e(ke,ni),i(s,qt,n),i(s,F,n),e(F,Ee),e(Ee,Hn),e(Hn,li),e(Ee,ti),e(F,pi),e(F,ze),e(ze,Mn),e(Mn,ri),e(ze,oi),e(F,ii),e(F,we),e(we,Qn),e(Qn,ci),e(we,ui),i(s,xt,n),i(s,Z,n),e(Z,Es),e(Es,Bn),j(ia,Bn,null),e(Z,mi),e(Z,Jn),e(Jn,hi),i(s,yt,n),i(s,zs,n),e(zs,bi),e(zs,ca),e(ca,di),e(zs,ji),i(s,Pt,n),i(s,ws,n),e(ws,fi),e(ws,ua),e(ua,gi),e(ws,_i),i(s,At,n),j(ma,s,n),i(s,Ct,n),i(s,qe,n),e(qe,ha),e(ha,vi),e(ha,ba),e(ba,Wn),e(Wn,$i),e(ha,ki),i(s,Dt,n),j(da,s,n),i(s,It,n),i(s,ja,n),e(ja,Vn),e(Vn,Ei),i(s,St,n),j(fa,s,n),i(s,Tt,n),i(s,qs,n),e(qs,zi),e(qs,Gn),e(Gn,wi),e(qs,qi),i(s,Ot,n),i(s,ss,n),e(ss,xs),e(xs,Yn),j(ga,Yn,null),e(ss,xi),e(ss,Kn),e(Kn,yi),i(s,Nt,n),i(s,y,n),e(y,Pi),e(y,Xn),e(Xn,Ai),e(y,Ci),e(y,Zn),e(Zn,Di),e(y,Ii),e(y,sl),e(sl,Si),e(y,Ti),i(s,Lt,n),i(s,ys,n),e(ys,Oi),e(ys,al),e(al,Ni),e(ys,Li),i(s,Ut,n),j(_a,s,n),i(s,Rt,n),i(s,H,n),e(H,Ui),e(H,el),e(el,Ri),e(H,Fi),e(H,nl),e(nl,Hi),e(H,Mi),i(s,Ft,n),j(va,s,n),i(s,Ht,n),i(s,as,n),e(as,Ps),e(Ps,ll),j($a,ll,null),e(as,Qi),e(as,tl),e(tl,Bi),i(s,Mt,n),i(s,xe,n),e(xe,Ji),i(s,Qt,n),j(ka,s,n),i(s,Bt,n),i(s,ye,n),e(ye,Wi),i(s,Jt,n),j(Ea,s,n),i(s,Wt,n),i(s,Pe,n),e(Pe,Vi),i(s,Vt,n),j(za,s,n),i(s,Gt,n),i(s,Ae,n),e(Ae,Gi),i(s,Yt,n),j(wa,s,n),i(s,Kt,n),i(s,Ce,n),e(Ce,Yi),i(s,Xt,n),i(s,es,n),e(es,As),e(As,pl),j(qa,pl,null),e(es,Ki),e(es,rl),e(rl,Xi),i(s,Zt,n),i(s,De,n),e(De,Zi),i(s,sp,n),i(s,M,n),e(M,sc),e(M,xa),e(xa,ac),e(M,ec),e(M,ol),e(ol,nc),e(M,lc),i(s,ap,n),j(ya,s,n),i(s,ep,n),i(s,Cs,n),e(Cs,tc),e(Cs,Pa),e(Pa,il),e(il,pc),e(Cs,rc),i(s,np,n),j(Aa,s,n),i(s,lp,n),i(s,Ie,n),e(Ie,Se),i(s,tp,n),i(s,ns,n),e(ns,Ds),e(Ds,cl),j(Ca,cl,null),e(ns,oc),e(ns,ul),e(ul,ic),i(s,pp,n),i(s,Is,n),e(Is,cc),e(Is,ml),e(ml,uc),e(Is,mc),i(s,rp,n),j(Da,s,n),i(s,op,n),i(s,ls,n),e(ls,Ss),e(Ss,hl),j(Ia,hl,null),e(ls,hc),e(ls,bl),e(bl,bc),i(s,ip,n),i(s,Ts,n),e(Ts,dc),e(Ts,Sa),e(Sa,dl),e(dl,jc),e(Ts,fc),i(s,cp,n),i(s,Te,n),e(Te,A),e(A,gc),e(A,Ta),e(Ta,jl),e(jl,_c),e(A,vc),e(A,Oa),e(Oa,fl),e(fl,$c),e(A,kc),e(A,Na),e(Na,gl),e(gl,Ec),e(A,zc),i(s,up,n),j(La,s,n),i(s,mp,n),i(s,Ua,n),e(Ua,ts),e(ts,wc),e(ts,Oe),e(Oe,_l),e(_l,qc),e(ts,xc),e(ts,vl),e(vl,yc),e(ts,Pc),i(s,hp,n),j(Ra,s,n),i(s,bp,n),i(s,Fa,n),e(Fa,Ha),e(Ha,Ac),e(Ha,Ma),e(Ma,$l),e($l,Cc),e(Ha,Dc),i(s,dp,n),j(Qa,s,n),i(s,jp,n),i(s,Ba,n),e(Ba,Ja),e(Ja,Ic),e(Ja,kl),e(kl,Sc),e(Ja,Tc),i(s,fp,n),j(Wa,s,n),i(s,gp,n),i(s,Ne,n),e(Ne,Oc),i(s,_p,n),j(Va,s,n),i(s,vp,n),i(s,Le,n),e(Le,Ue),i(s,$p,n),i(s,ps,n),e(ps,Os),e(Os,El),j(Ga,El,null),e(ps,Nc),e(ps,zl),e(zl,Lc),i(s,kp,n),i(s,Re,n),e(Re,Uc),i(s,Ep,n),i(s,Ns,n),e(Ns,wl),e(wl,Rc),e(Ns,Fc),e(Ns,ql),e(ql,Hc),i(s,zp,n),i(s,Ls,n),e(Ls,Mc),e(Ls,Ya),e(Ya,Qc),e(Ls,Bc),i(s,wp,n),j(Ka,s,n),i(s,qp,n),i(s,Q,n),e(Q,Jc),e(Q,xl),e(xl,Wc),e(Q,Vc),e(Q,yl),e(yl,Gc),e(Q,Yc),i(s,xp,n),j(Xa,s,n),i(s,yp,n),i(s,B,n),e(B,Kc),e(B,Pl),e(Pl,Xc),e(B,Zc),e(B,Al),e(Al,su),e(B,au),i(s,Pp,n),j(Za,s,n),i(s,Ap,n),i(s,Us,n),e(Us,eu),e(Us,Fe),e(Fe,nu),e(Us,lu),i(s,Cp,n),j(se,s,n),i(s,Dp,n),i(s,rs,n),e(rs,Rs),e(Rs,Cl),j(ae,Cl,null),e(rs,tu),e(rs,Dl),e(Dl,pu),i(s,Ip,n),i(s,He,n),e(He,ru),i(s,Sp,n),j(ee,s,n),i(s,Tp,n),i(s,Me,n),e(Me,os),e(os,ou),e(os,Il),e(Il,iu),e(os,cu),e(os,Sl),e(Sl,uu),e(os,mu),i(s,Op,n),j(ne,s,n),i(s,Np,n),i(s,le,n),e(le,te),e(te,hu),e(te,Tl),e(Tl,bu),e(te,du),i(s,Lp,n),j(pe,s,n),i(s,Up,n),i(s,J,n),e(J,ju),e(J,Ol),e(Ol,fu),e(J,gu),e(J,Nl),e(Nl,_u),e(J,vu),i(s,Rp,n),i(s,Qe,n),e(Qe,$u),Fp=!0},p(s,[n]){const re={};n&2&&(re.$$scope={dirty:n,ctx:s}),us.$set(re);const Ll={};n&2&&(Ll.$$scope={dirty:n,ctx:s}),vs.$set(Ll)},i(s){Fp||(f(q.$$.fragment,s),f(Qs.$$.fragment,s),f(Bs.$$.fragment,s),f(Js.$$.fragment,s),f(us.$$.fragment,s),f(Ws.$$.fragment,s),f(Vs.$$.fragment,s),f(Gs.$$.fragment,s),f(Ys.$$.fragment,s),f(Ks.$$.fragment,s),f(Xs.$$.fragment,s),f(Zs.$$.fragment,s),f(sa.$$.fragment,s),f(aa.$$.fragment,s),f(ea.$$.fragment,s),f(vs.$$.fragment,s),f(na.$$.fragment,s),f(la.$$.fragment,s),f(ra.$$.fragment,s),f(oa.$$.fragment,s),f(ia.$$.fragment,s),f(ma.$$.fragment,s),f(da.$$.fragment,s),f(fa.$$.fragment,s),f(ga.$$.fragment,s),f(_a.$$.fragment,s),f(va.$$.fragment,s),f($a.$$.fragment,s),f(ka.$$.fragment,s),f(Ea.$$.fragment,s),f(za.$$.fragment,s),f(wa.$$.fragment,s),f(qa.$$.fragment,s),f(ya.$$.fragment,s),f(Aa.$$.fragment,s),f(Ca.$$.fragment,s),f(Da.$$.fragment,s),f(Ia.$$.fragment,s),f(La.$$.fragment,s),f(Ra.$$.fragment,s),f(Qa.$$.fragment,s),f(Wa.$$.fragment,s),f(Va.$$.fragment,s),f(Ga.$$.fragment,s),f(Ka.$$.fragment,s),f(Xa.$$.fragment,s),f(Za.$$.fragment,s),f(se.$$.fragment,s),f(ae.$$.fragment,s),f(ee.$$.fragment,s),f(ne.$$.fragment,s),f(pe.$$.fragment,s),Fp=!0)},o(s){g(q.$$.fragment,s),g(Qs.$$.fragment,s),g(Bs.$$.fragment,s),g(Js.$$.fragment,s),g(us.$$.fragment,s),g(Ws.$$.fragment,s),g(Vs.$$.fragment,s),g(Gs.$$.fragment,s),g(Ys.$$.fragment,s),g(Ks.$$.fragment,s),g(Xs.$$.fragment,s),g(Zs.$$.fragment,s),g(sa.$$.fragment,s),g(aa.$$.fragment,s),g(ea.$$.fragment,s),g(vs.$$.fragment,s),g(na.$$.fragment,s),g(la.$$.fragment,s),g(ra.$$.fragment,s),g(oa.$$.fragment,s),g(ia.$$.fragment,s),g(ma.$$.fragment,s),g(da.$$.fragment,s),g(fa.$$.fragment,s),g(ga.$$.fragment,s),g(_a.$$.fragment,s),g(va.$$.fragment,s),g($a.$$.fragment,s),g(ka.$$.fragment,s),g(Ea.$$.fragment,s),g(za.$$.fragment,s),g(wa.$$.fragment,s),g(qa.$$.fragment,s),g(ya.$$.fragment,s),g(Aa.$$.fragment,s),g(Ca.$$.fragment,s),g(Da.$$.fragment,s),g(Ia.$$.fragment,s),g(La.$$.fragment,s),g(Ra.$$.fragment,s),g(Qa.$$.fragment,s),g(Wa.$$.fragment,s),g(Va.$$.fragment,s),g(Ga.$$.fragment,s),g(Ka.$$.fragment,s),g(Xa.$$.fragment,s),g(Za.$$.fragment,s),g(se.$$.fragment,s),g(ae.$$.fragment,s),g(ee.$$.fragment,s),g(ne.$$.fragment,s),g(pe.$$.fragment,s),Fp=!1},d(s){a(v),s&&a(k),s&&a(h),_(q),s&&a(Ul),_(Qs,s),s&&a(Rl),s&&a(oe),s&&a(Fl),s&&a(D),s&&a(Hl),s&&a(W),_(Bs),s&&a(Ml),_(Js,s),s&&a(Ql),s&&a(I),s&&a(Bl),_(us,s),s&&a(Jl),s&&a(S),s&&a(Wl),s&&a(V),_(Ws),s&&a(Vl),s&&a(hs),s&&a(Gl),_(Vs,s),s&&a(Yl),s&&a(ce),s&&a(Kl),_(Gs,s),s&&a(Xl),s&&a(ue),s&&a(Zl),s&&a(T),s&&a(st),s&&a(bs),s&&a(at),_(Ys,s),s&&a(et),s&&a(O),s&&a(nt),s&&a(ge),s&&a(lt),_(Ks,s),s&&a(tt),s&&a(G),_(Xs),s&&a(pt),s&&a(js),s&&a(rt),s&&a(N),s&&a(ot),_(Zs,s),s&&a(it),s&&a(fs),s&&a(ct),s&&a(Y),_(sa),s&&a(ut),s&&a(_e),s&&a(mt),s&&a(L),s&&a(ht),_(aa,s),s&&a(bt),s&&a(K),_(ea),s&&a(dt),s&&a(ve),s&&a(jt),s&&a(x),s&&a(ft),_(vs,s),s&&a(gt),s&&a(X),_(na),s&&a(_t),s&&a(ks),s&&a(vt),_(la,s),s&&a($t),s&&a(U),s&&a(kt),_(ra,s),s&&a(Et),s&&a(R),s&&a(zt),_(oa,s),s&&a(wt),s&&a(ke),s&&a(qt),s&&a(F),s&&a(xt),s&&a(Z),_(ia),s&&a(yt),s&&a(zs),s&&a(Pt),s&&a(ws),s&&a(At),_(ma,s),s&&a(Ct),s&&a(qe),s&&a(Dt),_(da,s),s&&a(It),s&&a(ja),s&&a(St),_(fa,s),s&&a(Tt),s&&a(qs),s&&a(Ot),s&&a(ss),_(ga),s&&a(Nt),s&&a(y),s&&a(Lt),s&&a(ys),s&&a(Ut),_(_a,s),s&&a(Rt),s&&a(H),s&&a(Ft),_(va,s),s&&a(Ht),s&&a(as),_($a),s&&a(Mt),s&&a(xe),s&&a(Qt),_(ka,s),s&&a(Bt),s&&a(ye),s&&a(Jt),_(Ea,s),s&&a(Wt),s&&a(Pe),s&&a(Vt),_(za,s),s&&a(Gt),s&&a(Ae),s&&a(Yt),_(wa,s),s&&a(Kt),s&&a(Ce),s&&a(Xt),s&&a(es),_(qa),s&&a(Zt),s&&a(De),s&&a(sp),s&&a(M),s&&a(ap),_(ya,s),s&&a(ep),s&&a(Cs),s&&a(np),_(Aa,s),s&&a(lp),s&&a(Ie),s&&a(tp),s&&a(ns),_(Ca),s&&a(pp),s&&a(Is),s&&a(rp),_(Da,s),s&&a(op),s&&a(ls),_(Ia),s&&a(ip),s&&a(Ts),s&&a(cp),s&&a(Te),s&&a(up),_(La,s),s&&a(mp),s&&a(Ua),s&&a(hp),_(Ra,s),s&&a(bp),s&&a(Fa),s&&a(dp),_(Qa,s),s&&a(jp),s&&a(Ba),s&&a(fp),_(Wa,s),s&&a(gp),s&&a(Ne),s&&a(_p),_(Va,s),s&&a(vp),s&&a(Le),s&&a($p),s&&a(ps),_(Ga),s&&a(kp),s&&a(Re),s&&a(Ep),s&&a(Ns),s&&a(zp),s&&a(Ls),s&&a(wp),_(Ka,s),s&&a(qp),s&&a(Q),s&&a(xp),_(Xa,s),s&&a(yp),s&&a(B),s&&a(Pp),_(Za,s),s&&a(Ap),s&&a(Us),s&&a(Cp),_(se,s),s&&a(Dp),s&&a(rs),_(ae),s&&a(Ip),s&&a(He),s&&a(Sp),_(ee,s),s&&a(Tp),s&&a(Me),s&&a(Op),_(ne,s),s&&a(Np),s&&a(le),s&&a(Lp),_(pe,s),s&&a(Up),s&&a(J),s&&a(Rp),s&&a(Qe)}}}const Db={local:"preprocess",sections:[{local:"nlp",sections:[{local:"tokenize",title:"Tokenize"},{local:"pad",title:"Pad"},{local:"truncation",title:"Truncation"},{local:"costruire-i-tensori",title:"Costruire i tensori"}],title:"NLP"},{local:"audio",sections:[{local:"ricampionamento",title:"Ricampionamento"},{local:"feature-extractor",title:"Feature extractor"},{local:"pad-and-truncate",title:"Pad and truncate"}],title:"Audio"},{local:"vision",sections:[{local:"feature-extractor",title:"Feature extractor"},{local:"data-augmentation",title:"Data augmentation"}],title:"Vision"},{local:"multimodal",sections:[{local:"processor",title:"Processor"}],title:"Multimodal"}],title:"Preprocess"};function Ib(P){return $b(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Lb extends fb{constructor(v){super();gb(this,v,Ib,Cb,_b,{})}}export{Lb as default,Db as metadata};
