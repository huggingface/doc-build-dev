import{S as tjt,i as ajt,s as njt,e as a,k as l,w as F,t as o,M as sjt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as ljt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as UJr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function ijt(x){let g,v,p,m,u,d,h,Eo,Fi,Lf,at,Ti,Mi,vL,yf,Oe,We,Ei,Sn,FL,Rn,Pn,TL,Ci,Bn,ML,wi,xf,ya;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),u=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Fi=a("code"),Lf=o("model_type"),at=o(" attribute is set to the same key you use when registering the config (here "),Ti=a("code"),Mi=o('"new-model"'),vL=o(")."),yf=l(),Oe=a("p"),We=o("Likewise, if your "),Ei=a("code"),Sn=o("NewModel"),FL=o(" is a subclass of "),Rn=a("a"),Pn=o("PreTrainedModel"),TL=o(`, make sure its
`),Ci=a("code"),Bn=o("config_class"),ML=o(` attribute is set to the same class you use when registering the model (here
`),wi=a("code"),xf=o("NewModelConfig"),ya=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var Uk=s(p);m=r(Uk,"NewModelConfig"),Uk.forEach(t),u=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Ai=s(d);h=r(Ai,"PretrainedConfig"),Ai.forEach(t),Eo=r(Ae,`, make sure its
`),Fi=n(Ae,"CODE",{});var Jk=s(Fi);Lf=r(Jk,"model_type"),Jk.forEach(t),at=r(Ae," attribute is set to the same key you use when registering the config (here "),Ti=n(Ae,"CODE",{});var Yk=s(Ti);Mi=r(Yk,'"new-model"'),Yk.forEach(t),vL=r(Ae,")."),Ae.forEach(t),yf=i(Qe),Oe=n(Qe,"P",{});var Co=s(Oe);We=r(Co,"Likewise, if your "),Ei=n(Co,"CODE",{});var xa=s(Ei);Sn=r(xa,"NewModel"),xa.forEach(t),FL=r(Co," is a subclass of "),Rn=n(Co,"A",{href:!0});var Kk=s(Rn);Pn=r(Kk,"PreTrainedModel"),Kk.forEach(t),TL=r(Co,`, make sure its
`),Ci=n(Co,"CODE",{});var $f=s(Ci);Bn=r($f,"config_class"),$f.forEach(t),ML=r(Co,` attribute is set to the same class you use when registering the model (here
`),wi=n(Co,"CODE",{});var Zk=s(wi);xf=r(Zk,"NewModelConfig"),Zk.forEach(t),ya=r(Co,")."),Co.forEach(t),this.h()},h(){c(Rn,"href","/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,u),e(g,d),e(d,h),e(g,Eo),e(g,Fi),e(Fi,Lf),e(g,at),e(g,Ti),e(Ti,Mi),e(g,vL),b(Qe,yf,Ae),b(Qe,Oe,Ae),e(Oe,We),e(Oe,Ei),e(Ei,Sn),e(Oe,FL),e(Oe,Rn),e(Rn,Pn),e(Oe,TL),e(Oe,Ci),e(Ci,Bn),e(Oe,ML),e(Oe,wi),e(wi,xf),e(Oe,ya)},d(Qe){Qe&&t(g),Qe&&t(yf),Qe&&t(Oe)}}}function djt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fjt(x){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function mjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gjt(x){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function hjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ujt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _jt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Tjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ejt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Cjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ajt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ljt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $jt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Sjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ijt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Njt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Djt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ojt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ujt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Dt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ADt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Dt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ODt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lGt(x){let g,v,p,m,u,d,h,Eo,Fi,Lf,at,Ti,Mi,vL,yf,Oe,We,Ei,Sn,FL,Rn,Pn,TL,Ci,Bn,ML,wi,xf,ya,Qe,Ae,Uk,Ai,Jk,Yk,Co,xa,Kk,$f,Zk,xze,hGe,Li,kf,Kre,EL,$ze,Zre,kze,pGe,In,Sze,ete,Rze,Pze,ote,Bze,Ize,uGe,CL,_Ge,eS,Nze,bGe,Sf,vGe,yi,Rf,rte,wL,qze,tte,jze,FGe,wo,AL,Dze,LL,Gze,oS,Oze,Vze,Xze,yL,zze,ate,Wze,Qze,Hze,wr,xL,Uze,nte,Jze,Yze,xi,Kze,ste,Zze,eWe,lte,oWe,rWe,tWe,A,Pf,ite,aWe,nWe,rS,sWe,lWe,iWe,Bf,dte,dWe,cWe,tS,fWe,mWe,gWe,If,cte,hWe,pWe,aS,uWe,_We,bWe,Nf,fte,vWe,FWe,nS,TWe,MWe,EWe,qf,mte,CWe,wWe,sS,AWe,LWe,yWe,jf,gte,xWe,$We,lS,kWe,SWe,RWe,Df,hte,PWe,BWe,iS,IWe,NWe,qWe,Gf,pte,jWe,DWe,dS,GWe,OWe,VWe,Of,ute,XWe,zWe,cS,WWe,QWe,HWe,Vf,_te,UWe,JWe,fS,YWe,KWe,ZWe,Xf,bte,eQe,oQe,mS,rQe,tQe,aQe,zf,vte,nQe,sQe,gS,lQe,iQe,dQe,Wf,Fte,cQe,fQe,hS,mQe,gQe,hQe,Qf,Tte,pQe,uQe,pS,_Qe,bQe,vQe,Hf,Mte,FQe,TQe,uS,MQe,EQe,CQe,Uf,Ete,wQe,AQe,_S,LQe,yQe,xQe,Jf,Cte,$Qe,kQe,bS,SQe,RQe,PQe,Yf,wte,BQe,IQe,vS,NQe,qQe,jQe,Kf,Ate,DQe,GQe,FS,OQe,VQe,XQe,Zf,Lte,zQe,WQe,TS,QQe,HQe,UQe,em,yte,JQe,YQe,MS,KQe,ZQe,eHe,om,xte,oHe,rHe,ES,tHe,aHe,nHe,rm,$te,sHe,lHe,CS,iHe,dHe,cHe,tm,kte,fHe,mHe,wS,gHe,hHe,pHe,am,Ste,uHe,_He,AS,bHe,vHe,FHe,nm,Rte,THe,MHe,LS,EHe,CHe,wHe,sm,Pte,AHe,LHe,yS,yHe,xHe,$He,lm,Bte,kHe,SHe,xS,RHe,PHe,BHe,im,Ite,IHe,NHe,$S,qHe,jHe,DHe,dm,Nte,GHe,OHe,kS,VHe,XHe,zHe,cm,qte,WHe,QHe,SS,HHe,UHe,JHe,fm,jte,YHe,KHe,RS,ZHe,eUe,oUe,mm,Dte,rUe,tUe,PS,aUe,nUe,sUe,gm,Gte,lUe,iUe,BS,dUe,cUe,fUe,hm,Ote,mUe,gUe,IS,hUe,pUe,uUe,pm,Vte,_Ue,bUe,NS,vUe,FUe,TUe,um,Xte,MUe,EUe,qS,CUe,wUe,AUe,_m,zte,LUe,yUe,jS,xUe,$Ue,kUe,bm,Wte,SUe,RUe,DS,PUe,BUe,IUe,vm,Qte,NUe,qUe,GS,jUe,DUe,GUe,Fm,Hte,OUe,VUe,OS,XUe,zUe,WUe,Tm,Ute,QUe,HUe,VS,UUe,JUe,YUe,Mm,Jte,KUe,ZUe,XS,eJe,oJe,rJe,Em,Yte,tJe,aJe,zS,nJe,sJe,lJe,Cm,Kte,iJe,dJe,WS,cJe,fJe,mJe,wm,Zte,gJe,hJe,QS,pJe,uJe,_Je,Am,eae,bJe,vJe,HS,FJe,TJe,MJe,Lm,oae,EJe,CJe,US,wJe,AJe,LJe,ym,rae,yJe,xJe,JS,$Je,kJe,SJe,xm,tae,RJe,PJe,YS,BJe,IJe,NJe,$m,aae,qJe,jJe,KS,DJe,GJe,OJe,km,nae,VJe,XJe,ZS,zJe,WJe,QJe,Sm,sae,HJe,UJe,eR,JJe,YJe,KJe,Rm,lae,ZJe,eYe,oR,oYe,rYe,tYe,Pm,iae,aYe,nYe,rR,sYe,lYe,iYe,Bm,dae,dYe,cYe,tR,fYe,mYe,gYe,Im,cae,hYe,pYe,aR,uYe,_Ye,bYe,Nm,fae,vYe,FYe,nR,TYe,MYe,EYe,qm,mae,CYe,wYe,sR,AYe,LYe,yYe,jm,gae,xYe,$Ye,lR,kYe,SYe,RYe,Dm,hae,PYe,BYe,iR,IYe,NYe,qYe,Gm,pae,jYe,DYe,dR,GYe,OYe,VYe,Om,uae,XYe,zYe,cR,WYe,QYe,HYe,Vm,_ae,UYe,JYe,fR,YYe,KYe,ZYe,Xm,bae,eKe,oKe,mR,rKe,tKe,aKe,zm,vae,nKe,sKe,gR,lKe,iKe,dKe,Wm,Fae,cKe,fKe,hR,mKe,gKe,hKe,Qm,Tae,pKe,uKe,pR,_Ke,bKe,vKe,Hm,Mae,FKe,TKe,uR,MKe,EKe,CKe,Um,Eae,wKe,AKe,_R,LKe,yKe,xKe,Jm,Cae,$Ke,kKe,bR,SKe,RKe,PKe,Ym,wae,BKe,IKe,vR,NKe,qKe,jKe,Km,Aae,DKe,GKe,FR,OKe,VKe,XKe,Zm,Lae,zKe,WKe,TR,QKe,HKe,UKe,eg,yae,JKe,YKe,MR,KKe,ZKe,eZe,og,xae,oZe,rZe,ER,tZe,aZe,nZe,rg,$ae,sZe,lZe,CR,iZe,dZe,cZe,tg,kae,fZe,mZe,wR,gZe,hZe,pZe,ag,Sae,uZe,_Ze,AR,bZe,vZe,FZe,ng,Rae,TZe,MZe,LR,EZe,CZe,wZe,sg,Pae,AZe,LZe,yR,yZe,xZe,$Ze,lg,Bae,kZe,SZe,xR,RZe,PZe,BZe,ig,Iae,IZe,NZe,$R,qZe,jZe,DZe,dg,Nae,GZe,OZe,kR,VZe,XZe,zZe,cg,qae,WZe,QZe,SR,HZe,UZe,JZe,fg,jae,YZe,KZe,RR,ZZe,eeo,oeo,mg,Dae,reo,teo,PR,aeo,neo,seo,gg,Gae,leo,ieo,BR,deo,ceo,feo,hg,Oae,meo,geo,IR,heo,peo,ueo,pg,Vae,_eo,beo,NR,veo,Feo,Teo,ug,Xae,Meo,Eeo,qR,Ceo,weo,Aeo,_g,zae,Leo,yeo,jR,xeo,$eo,keo,bg,Wae,Seo,Reo,DR,Peo,Beo,Ieo,vg,Qae,Neo,qeo,GR,jeo,Deo,Geo,Fg,Hae,Oeo,Veo,OR,Xeo,zeo,Weo,Tg,Uae,Qeo,Heo,VR,Ueo,Jeo,Yeo,Mg,Jae,Keo,Zeo,XR,eoo,ooo,roo,Eg,Yae,too,aoo,zR,noo,soo,loo,Cg,Kae,ioo,doo,WR,coo,foo,moo,wg,Zae,goo,hoo,QR,poo,uoo,_oo,Ag,ene,boo,voo,HR,Foo,Too,Moo,Lg,one,Eoo,Coo,UR,woo,Aoo,Loo,yg,rne,yoo,xoo,JR,$oo,koo,Soo,xg,tne,Roo,Poo,YR,Boo,Ioo,Noo,$g,ane,qoo,joo,KR,Doo,Goo,Ooo,kg,nne,Voo,Xoo,ZR,zoo,Woo,Qoo,Sg,sne,Hoo,Uoo,eP,Joo,Yoo,Koo,Rg,lne,Zoo,ero,oP,oro,rro,tro,Pg,ine,aro,nro,rP,sro,lro,iro,Bg,dne,dro,cro,tP,fro,mro,gro,Ig,cne,hro,pro,aP,uro,_ro,bro,Ng,fne,vro,Fro,nP,Tro,Mro,Ero,qg,mne,Cro,wro,sP,Aro,Lro,yro,jg,gne,xro,$ro,lP,kro,Sro,Rro,Dg,Pro,Gg,$L,Bro,hne,Iro,TGe,$i,Og,pne,kL,Nro,une,qro,MGe,Ao,SL,jro,RL,Dro,iP,Gro,Oro,Vro,PL,Xro,_ne,zro,Wro,Qro,Ar,BL,Hro,bne,Uro,Jro,$a,Yro,vne,Kro,Zro,Fne,eto,oto,Tne,rto,tto,ato,k,Nn,Mne,nto,sto,dP,lto,ito,cP,dto,cto,fto,qn,Ene,mto,gto,fP,hto,pto,mP,uto,_to,bto,jn,Cne,vto,Fto,gP,Tto,Mto,hP,Eto,Cto,wto,Vg,wne,Ato,Lto,pP,yto,xto,$to,Dn,Ane,kto,Sto,uP,Rto,Pto,_P,Bto,Ito,Nto,Xg,Lne,qto,jto,bP,Dto,Gto,Oto,zg,yne,Vto,Xto,vP,zto,Wto,Qto,Wg,xne,Hto,Uto,FP,Jto,Yto,Kto,Gn,$ne,Zto,eao,TP,oao,rao,MP,tao,aao,nao,On,kne,sao,lao,EP,iao,dao,CP,cao,fao,mao,Vn,Sne,gao,hao,wP,pao,uao,AP,_ao,bao,vao,Qg,Rne,Fao,Tao,LP,Mao,Eao,Cao,Hg,Pne,wao,Aao,yP,Lao,yao,xao,Ug,Bne,$ao,kao,xP,Sao,Rao,Pao,Xn,Ine,Bao,Iao,$P,Nao,qao,kP,jao,Dao,Gao,Jg,Nne,Oao,Vao,SP,Xao,zao,Wao,zn,qne,Qao,Hao,RP,Uao,Jao,PP,Yao,Kao,Zao,Wn,jne,eno,ono,BP,rno,tno,IP,ano,nno,sno,Qn,Dne,lno,ino,NP,dno,cno,qP,fno,mno,gno,Yg,Gne,hno,pno,jP,uno,_no,bno,Hn,One,vno,Fno,DP,Tno,Mno,GP,Eno,Cno,wno,Un,Vne,Ano,Lno,OP,yno,xno,VP,$no,kno,Sno,Jn,Xne,Rno,Pno,XP,Bno,Ino,zP,Nno,qno,jno,Yn,zne,Dno,Gno,WP,Ono,Vno,QP,Xno,zno,Wno,Kn,Wne,Qno,Hno,HP,Uno,Jno,UP,Yno,Kno,Zno,Zn,Qne,eso,oso,JP,rso,tso,YP,aso,nso,sso,Kg,Hne,lso,iso,KP,dso,cso,fso,es,Une,mso,gso,ZP,hso,pso,eB,uso,_so,bso,Zg,Jne,vso,Fso,oB,Tso,Mso,Eso,os,Yne,Cso,wso,rB,Aso,Lso,tB,yso,xso,$so,rs,Kne,kso,Sso,aB,Rso,Pso,nB,Bso,Iso,Nso,ts,Zne,qso,jso,sB,Dso,Gso,lB,Oso,Vso,Xso,eh,ese,zso,Wso,iB,Qso,Hso,Uso,as,ose,Jso,Yso,dB,Kso,Zso,cB,elo,olo,rlo,ns,rse,tlo,alo,fB,nlo,slo,mB,llo,ilo,dlo,oh,tse,clo,flo,gB,mlo,glo,hlo,ss,ase,plo,ulo,hB,_lo,blo,pB,vlo,Flo,Tlo,ls,nse,Mlo,Elo,uB,Clo,wlo,_B,Alo,Llo,ylo,is,sse,xlo,$lo,bB,klo,Slo,vB,Rlo,Plo,Blo,ds,lse,Ilo,Nlo,FB,qlo,jlo,TB,Dlo,Glo,Olo,cs,ise,Vlo,Xlo,MB,zlo,Wlo,EB,Qlo,Hlo,Ulo,fs,dse,Jlo,Ylo,CB,Klo,Zlo,wB,eio,oio,rio,ms,cse,tio,aio,AB,nio,sio,LB,lio,iio,dio,gs,fse,cio,fio,yB,mio,gio,xB,hio,pio,uio,rh,mse,_io,bio,$B,vio,Fio,Tio,hs,gse,Mio,Eio,kB,Cio,wio,SB,Aio,Lio,yio,th,hse,xio,$io,RB,kio,Sio,Rio,ah,pse,Pio,Bio,PB,Iio,Nio,qio,ps,use,jio,Dio,BB,Gio,Oio,IB,Vio,Xio,zio,us,_se,Wio,Qio,NB,Hio,Uio,qB,Jio,Yio,Kio,_s,bse,Zio,edo,jB,odo,rdo,DB,tdo,ado,ndo,nh,vse,sdo,ldo,GB,ido,ddo,cdo,bs,Fse,fdo,mdo,OB,gdo,hdo,VB,pdo,udo,_do,vs,Tse,bdo,vdo,XB,Fdo,Tdo,zB,Mdo,Edo,Cdo,Fs,Mse,wdo,Ado,WB,Ldo,ydo,QB,xdo,$do,kdo,Ts,Ese,Sdo,Rdo,HB,Pdo,Bdo,UB,Ido,Ndo,qdo,Ms,Cse,jdo,Ddo,JB,Gdo,Odo,YB,Vdo,Xdo,zdo,sh,wse,Wdo,Qdo,KB,Hdo,Udo,Jdo,Es,Ase,Ydo,Kdo,ZB,Zdo,eco,eI,oco,rco,tco,lh,Lse,aco,nco,oI,sco,lco,ico,ih,yse,dco,cco,rI,fco,mco,gco,dh,xse,hco,pco,tI,uco,_co,bco,ch,$se,vco,Fco,aI,Tco,Mco,Eco,Cs,kse,Cco,wco,nI,Aco,Lco,sI,yco,xco,$co,fh,Sse,kco,Sco,lI,Rco,Pco,Bco,ws,Rse,Ico,Nco,iI,qco,jco,dI,Dco,Gco,Oco,As,Pse,Vco,Xco,cI,zco,Wco,fI,Qco,Hco,Uco,Ls,Bse,Jco,Yco,mI,Kco,Zco,gI,efo,ofo,rfo,ys,Ise,tfo,afo,hI,nfo,sfo,pI,lfo,ifo,dfo,xs,Nse,cfo,ffo,uI,mfo,gfo,_I,hfo,pfo,ufo,$s,qse,_fo,bfo,bI,vfo,Ffo,vI,Tfo,Mfo,Efo,mh,jse,Cfo,wfo,FI,Afo,Lfo,yfo,gh,Dse,xfo,$fo,TI,kfo,Sfo,Rfo,ks,Gse,Pfo,Bfo,MI,Ifo,Nfo,EI,qfo,jfo,Dfo,Ss,Ose,Gfo,Ofo,CI,Vfo,Xfo,wI,zfo,Wfo,Qfo,Rs,Vse,Hfo,Ufo,AI,Jfo,Yfo,LI,Kfo,Zfo,emo,hh,Xse,omo,rmo,yI,tmo,amo,nmo,ph,zse,smo,lmo,xI,imo,dmo,cmo,uh,Wse,fmo,mmo,$I,gmo,hmo,pmo,Ps,Qse,umo,_mo,kI,bmo,vmo,SI,Fmo,Tmo,Mmo,Bs,Hse,Emo,Cmo,RI,wmo,Amo,PI,Lmo,ymo,xmo,_h,Use,$mo,kmo,BI,Smo,Rmo,Pmo,bh,Jse,Bmo,Imo,II,Nmo,qmo,jmo,vh,Yse,Dmo,Gmo,NI,Omo,Vmo,Xmo,Is,Kse,zmo,Wmo,qI,Qmo,Hmo,jI,Umo,Jmo,Ymo,Fh,Zse,Kmo,Zmo,DI,ego,ogo,rgo,Th,ele,tgo,ago,GI,ngo,sgo,lgo,Ns,ole,igo,dgo,OI,cgo,fgo,VI,mgo,ggo,hgo,qs,rle,pgo,ugo,XI,_go,bgo,zI,vgo,Fgo,Tgo,js,tle,Mgo,Ego,WI,Cgo,wgo,QI,Ago,Lgo,ygo,Ds,ale,xgo,$go,HI,kgo,Sgo,UI,Rgo,Pgo,Bgo,Mh,Igo,Eh,IL,Ngo,nle,qgo,EGe,ki,Ch,sle,NL,jgo,lle,Dgo,CGe,Lo,qL,Ggo,jL,Ogo,JI,Vgo,Xgo,zgo,DL,Wgo,ile,Qgo,Hgo,Ugo,He,GL,Jgo,dle,Ygo,Kgo,ka,Zgo,cle,eho,oho,fle,rho,tho,mle,aho,nho,sho,Y,wh,gle,lho,iho,YI,dho,cho,fho,Ah,hle,mho,gho,KI,hho,pho,uho,Lh,ple,_ho,bho,ZI,vho,Fho,Tho,yh,ule,Mho,Eho,eN,Cho,who,Aho,xh,_le,Lho,yho,oN,xho,$ho,kho,$h,ble,Sho,Rho,rN,Pho,Bho,Iho,kh,vle,Nho,qho,tN,jho,Dho,Gho,Sh,Fle,Oho,Vho,aN,Xho,zho,Who,Rh,Tle,Qho,Hho,nN,Uho,Jho,Yho,Ph,Mle,Kho,Zho,sN,epo,opo,rpo,Bh,Ele,tpo,apo,lN,npo,spo,lpo,Ih,Cle,ipo,dpo,iN,cpo,fpo,mpo,Nh,wle,gpo,hpo,dN,ppo,upo,_po,qh,Ale,bpo,vpo,cN,Fpo,Tpo,Mpo,jh,Lle,Epo,Cpo,fN,wpo,Apo,Lpo,Dh,yle,ypo,xpo,mN,$po,kpo,Spo,Gh,xle,Rpo,Ppo,gN,Bpo,Ipo,Npo,Oh,$le,qpo,jpo,hN,Dpo,Gpo,Opo,Vh,kle,Vpo,Xpo,pN,zpo,Wpo,Qpo,Xh,Sle,Hpo,Upo,uN,Jpo,Ypo,Kpo,zh,Rle,Zpo,euo,_N,ouo,ruo,tuo,Wh,Ple,auo,nuo,bN,suo,luo,iuo,Qh,Ble,duo,cuo,vN,fuo,muo,guo,Hh,Ile,huo,puo,FN,uuo,_uo,buo,Uh,Nle,vuo,Fuo,TN,Tuo,Muo,Euo,Jh,qle,Cuo,wuo,MN,Auo,Luo,yuo,Yh,jle,xuo,$uo,EN,kuo,Suo,Ruo,Kh,Dle,Puo,Buo,CN,Iuo,Nuo,quo,Zh,Gle,juo,Duo,wN,Guo,Ouo,Vuo,ep,Ole,Xuo,zuo,AN,Wuo,Quo,Huo,op,Vle,Uuo,Juo,LN,Yuo,Kuo,Zuo,rp,Xle,e_o,o_o,yN,r_o,t_o,a_o,tp,zle,n_o,s_o,xN,l_o,i_o,d_o,ap,c_o,np,f_o,sp,OL,m_o,Wle,g_o,wGe,Si,lp,Qle,VL,h_o,Hle,p_o,AGe,yo,XL,u_o,zL,__o,$N,b_o,v_o,F_o,WL,T_o,Ule,M_o,E_o,C_o,Ue,QL,w_o,Jle,A_o,L_o,Ri,y_o,Yle,x_o,$_o,Kle,k_o,S_o,R_o,he,ip,Zle,P_o,B_o,kN,I_o,N_o,q_o,dp,eie,j_o,D_o,oie,G_o,O_o,V_o,cp,rie,X_o,z_o,SN,W_o,Q_o,H_o,fp,tie,U_o,J_o,RN,Y_o,K_o,Z_o,mp,aie,e7o,o7o,PN,r7o,t7o,a7o,gp,nie,n7o,s7o,BN,l7o,i7o,d7o,hp,sie,c7o,f7o,IN,m7o,g7o,h7o,pp,lie,p7o,u7o,NN,_7o,b7o,v7o,up,iie,F7o,T7o,qN,M7o,E7o,C7o,_p,die,w7o,A7o,jN,L7o,y7o,x7o,bp,cie,$7o,k7o,DN,S7o,R7o,P7o,vp,fie,B7o,I7o,GN,N7o,q7o,j7o,Fp,mie,D7o,G7o,ON,O7o,V7o,X7o,Tp,gie,z7o,W7o,VN,Q7o,H7o,U7o,Mp,hie,J7o,Y7o,XN,K7o,Z7o,e2o,Ep,pie,o2o,r2o,zN,t2o,a2o,n2o,Cp,uie,s2o,l2o,WN,i2o,d2o,c2o,wp,f2o,Ap,m2o,Lp,HL,g2o,_ie,h2o,LGe,Pi,yp,bie,UL,p2o,vie,u2o,yGe,xo,JL,_2o,Bi,b2o,QN,v2o,F2o,HN,T2o,M2o,E2o,YL,C2o,Fie,w2o,A2o,L2o,nt,KL,y2o,Tie,x2o,$2o,Ii,k2o,Mie,S2o,R2o,UN,P2o,B2o,I2o,xp,N2o,Je,ZL,q2o,Eie,j2o,D2o,Sa,G2o,Cie,O2o,V2o,wie,X2o,z2o,Aie,W2o,Q2o,H2o,y,$p,Lie,U2o,J2o,JN,Y2o,K2o,Z2o,kp,yie,e1o,o1o,YN,r1o,t1o,a1o,Sp,xie,n1o,s1o,KN,l1o,i1o,d1o,Rp,$ie,c1o,f1o,ZN,m1o,g1o,h1o,Pp,kie,p1o,u1o,eq,_1o,b1o,v1o,Bp,Sie,F1o,T1o,oq,M1o,E1o,C1o,Ip,Rie,w1o,A1o,rq,L1o,y1o,x1o,Np,Pie,$1o,k1o,tq,S1o,R1o,P1o,qp,Bie,B1o,I1o,aq,N1o,q1o,j1o,jp,Iie,D1o,G1o,nq,O1o,V1o,X1o,Dp,Nie,z1o,W1o,sq,Q1o,H1o,U1o,Gp,qie,J1o,Y1o,lq,K1o,Z1o,ebo,Op,jie,obo,rbo,iq,tbo,abo,nbo,Vp,Die,sbo,lbo,dq,ibo,dbo,cbo,Xp,Gie,fbo,mbo,cq,gbo,hbo,pbo,zp,Oie,ubo,_bo,fq,bbo,vbo,Fbo,Wp,Vie,Tbo,Mbo,mq,Ebo,Cbo,wbo,Qp,Xie,Abo,Lbo,gq,ybo,xbo,$bo,Hp,zie,kbo,Sbo,hq,Rbo,Pbo,Bbo,Up,Wie,Ibo,Nbo,pq,qbo,jbo,Dbo,Jp,Qie,Gbo,Obo,uq,Vbo,Xbo,zbo,Yp,Hie,Wbo,Qbo,_q,Hbo,Ubo,Jbo,Kp,Uie,Ybo,Kbo,bq,Zbo,evo,ovo,Zp,Jie,rvo,tvo,vq,avo,nvo,svo,eu,Yie,lvo,ivo,Fq,dvo,cvo,fvo,ou,Kie,mvo,gvo,Tq,hvo,pvo,uvo,ru,Zie,_vo,bvo,Mq,vvo,Fvo,Tvo,tu,ede,Mvo,Evo,Eq,Cvo,wvo,Avo,au,ode,Lvo,yvo,Cq,xvo,$vo,kvo,nu,rde,Svo,Rvo,wq,Pvo,Bvo,Ivo,su,tde,Nvo,qvo,Aq,jvo,Dvo,Gvo,lu,ade,Ovo,Vvo,Lq,Xvo,zvo,Wvo,iu,nde,Qvo,Hvo,yq,Uvo,Jvo,Yvo,Gs,sde,Kvo,Zvo,xq,eFo,oFo,$q,rFo,tFo,aFo,du,lde,nFo,sFo,kq,lFo,iFo,dFo,cu,ide,cFo,fFo,Sq,mFo,gFo,hFo,fu,dde,pFo,uFo,Rq,_Fo,bFo,vFo,mu,cde,FFo,TFo,Pq,MFo,EFo,CFo,gu,fde,wFo,AFo,Bq,LFo,yFo,xFo,hu,mde,$Fo,kFo,Iq,SFo,RFo,PFo,pu,gde,BFo,IFo,Nq,NFo,qFo,jFo,uu,hde,DFo,GFo,qq,OFo,VFo,XFo,_u,pde,zFo,WFo,jq,QFo,HFo,UFo,bu,ude,JFo,YFo,Dq,KFo,ZFo,eTo,vu,_de,oTo,rTo,Gq,tTo,aTo,nTo,Fu,bde,sTo,lTo,Oq,iTo,dTo,cTo,Tu,vde,fTo,mTo,Vq,gTo,hTo,pTo,Mu,Fde,uTo,_To,Xq,bTo,vTo,FTo,Eu,Tde,TTo,MTo,zq,ETo,CTo,wTo,Cu,Mde,ATo,LTo,Wq,yTo,xTo,$To,wu,Ede,kTo,STo,Qq,RTo,PTo,BTo,Au,Cde,ITo,NTo,Hq,qTo,jTo,DTo,Lu,wde,GTo,OTo,Uq,VTo,XTo,zTo,yu,Ade,WTo,QTo,Jq,HTo,UTo,JTo,xu,Lde,YTo,KTo,Yq,ZTo,eMo,oMo,$u,yde,rMo,tMo,Kq,aMo,nMo,sMo,ku,xde,lMo,iMo,Zq,dMo,cMo,fMo,Su,$de,mMo,gMo,ej,hMo,pMo,uMo,Ru,kde,_Mo,bMo,oj,vMo,FMo,TMo,Pu,Sde,MMo,EMo,rj,CMo,wMo,AMo,Bu,Rde,LMo,yMo,tj,xMo,$Mo,kMo,Iu,Pde,SMo,RMo,aj,PMo,BMo,IMo,Nu,Bde,NMo,qMo,nj,jMo,DMo,GMo,qu,Ide,OMo,VMo,sj,XMo,zMo,WMo,ju,Nde,QMo,HMo,lj,UMo,JMo,YMo,Du,qde,KMo,ZMo,ij,eEo,oEo,rEo,Gu,jde,tEo,aEo,dj,nEo,sEo,lEo,Ou,Dde,iEo,dEo,cj,cEo,fEo,mEo,Vu,Gde,gEo,hEo,fj,pEo,uEo,_Eo,Xu,Ode,bEo,vEo,mj,FEo,TEo,MEo,zu,Vde,EEo,CEo,gj,wEo,AEo,LEo,Wu,Xde,yEo,xEo,hj,$Eo,kEo,SEo,Qu,zde,REo,PEo,pj,BEo,IEo,NEo,Hu,Wde,qEo,jEo,uj,DEo,GEo,OEo,Uu,Qde,VEo,XEo,_j,zEo,WEo,QEo,Ju,Hde,HEo,UEo,bj,JEo,YEo,KEo,Yu,Ude,ZEo,e4o,vj,o4o,r4o,t4o,Ku,Jde,a4o,n4o,Fj,s4o,l4o,i4o,Zu,Yde,d4o,c4o,Tj,f4o,m4o,g4o,e_,Kde,h4o,p4o,Mj,u4o,_4o,b4o,o_,Zde,v4o,F4o,Ej,T4o,M4o,E4o,r_,ece,C4o,w4o,Cj,A4o,L4o,y4o,t_,oce,x4o,$4o,wj,k4o,S4o,R4o,a_,rce,P4o,B4o,Aj,I4o,N4o,q4o,n_,tce,j4o,D4o,Lj,G4o,O4o,V4o,s_,ace,X4o,z4o,yj,W4o,Q4o,H4o,l_,nce,U4o,J4o,xj,Y4o,K4o,Z4o,i_,sce,eCo,oCo,$j,rCo,tCo,aCo,d_,lce,nCo,sCo,kj,lCo,iCo,dCo,c_,ice,cCo,fCo,Sj,mCo,gCo,hCo,f_,dce,pCo,uCo,Rj,_Co,bCo,vCo,m_,cce,FCo,TCo,Pj,MCo,ECo,CCo,g_,fce,wCo,ACo,Bj,LCo,yCo,xCo,h_,mce,$Co,kCo,Ij,SCo,RCo,PCo,p_,gce,BCo,ICo,Nj,NCo,qCo,jCo,u_,hce,DCo,GCo,qj,OCo,VCo,XCo,__,pce,zCo,WCo,jj,QCo,HCo,UCo,b_,uce,JCo,YCo,Dj,KCo,ZCo,e5o,v_,_ce,o5o,r5o,Gj,t5o,a5o,n5o,F_,bce,s5o,l5o,Oj,i5o,d5o,c5o,T_,vce,f5o,m5o,Vj,g5o,h5o,p5o,M_,Fce,u5o,_5o,Xj,b5o,v5o,F5o,E_,Tce,T5o,M5o,zj,E5o,C5o,w5o,C_,Mce,A5o,L5o,Wj,y5o,x5o,$5o,w_,Ece,k5o,S5o,Qj,R5o,P5o,B5o,A_,Cce,I5o,N5o,Hj,q5o,j5o,D5o,L_,wce,G5o,O5o,Uj,V5o,X5o,z5o,y_,W5o,Ace,Q5o,H5o,Lce,U5o,J5o,x_,xGe,Ni,$_,yce,ey,Y5o,xce,K5o,$Ge,$o,oy,Z5o,qi,e3o,Jj,o3o,r3o,Yj,t3o,a3o,n3o,ry,s3o,$ce,l3o,i3o,d3o,st,ty,c3o,kce,f3o,m3o,ji,g3o,Sce,h3o,p3o,Kj,u3o,_3o,b3o,k_,v3o,Ye,ay,F3o,Rce,T3o,M3o,Ra,E3o,Pce,C3o,w3o,Bce,A3o,L3o,Ice,y3o,x3o,$3o,G,S_,Nce,k3o,S3o,Zj,R3o,P3o,B3o,R_,qce,I3o,N3o,eD,q3o,j3o,D3o,P_,jce,G3o,O3o,oD,V3o,X3o,z3o,B_,Dce,W3o,Q3o,rD,H3o,U3o,J3o,I_,Gce,Y3o,K3o,tD,Z3o,e0o,o0o,N_,Oce,r0o,t0o,aD,a0o,n0o,s0o,q_,Vce,l0o,i0o,nD,d0o,c0o,f0o,j_,Xce,m0o,g0o,sD,h0o,p0o,u0o,D_,zce,_0o,b0o,lD,v0o,F0o,T0o,G_,Wce,M0o,E0o,iD,C0o,w0o,A0o,O_,Qce,L0o,y0o,dD,x0o,$0o,k0o,V_,Hce,S0o,R0o,cD,P0o,B0o,I0o,X_,Uce,N0o,q0o,fD,j0o,D0o,G0o,z_,Jce,O0o,V0o,mD,X0o,z0o,W0o,W_,Yce,Q0o,H0o,gD,U0o,J0o,Y0o,Q_,Kce,K0o,Z0o,hD,ewo,owo,rwo,H_,Zce,two,awo,pD,nwo,swo,lwo,U_,efe,iwo,dwo,uD,cwo,fwo,mwo,J_,ofe,gwo,hwo,_D,pwo,uwo,_wo,Y_,rfe,bwo,vwo,bD,Fwo,Two,Mwo,K_,tfe,Ewo,Cwo,vD,wwo,Awo,Lwo,Z_,afe,ywo,xwo,FD,$wo,kwo,Swo,e7,nfe,Rwo,Pwo,TD,Bwo,Iwo,Nwo,o7,sfe,qwo,jwo,MD,Dwo,Gwo,Owo,r7,lfe,Vwo,Xwo,ED,zwo,Wwo,Qwo,t7,ife,Hwo,Uwo,CD,Jwo,Ywo,Kwo,a7,dfe,Zwo,eAo,wD,oAo,rAo,tAo,n7,cfe,aAo,nAo,AD,sAo,lAo,iAo,s7,ffe,dAo,cAo,LD,fAo,mAo,gAo,l7,mfe,hAo,pAo,yD,uAo,_Ao,bAo,i7,gfe,vAo,FAo,xD,TAo,MAo,EAo,d7,hfe,CAo,wAo,$D,AAo,LAo,yAo,c7,pfe,xAo,$Ao,kD,kAo,SAo,RAo,f7,ufe,PAo,BAo,SD,IAo,NAo,qAo,m7,_fe,jAo,DAo,RD,GAo,OAo,VAo,g7,bfe,XAo,zAo,PD,WAo,QAo,HAo,h7,vfe,UAo,JAo,BD,YAo,KAo,ZAo,p7,Ffe,e6o,o6o,ID,r6o,t6o,a6o,u7,Tfe,n6o,s6o,ND,l6o,i6o,d6o,_7,Mfe,c6o,f6o,qD,m6o,g6o,h6o,b7,Efe,p6o,u6o,jD,_6o,b6o,v6o,v7,Cfe,F6o,T6o,DD,M6o,E6o,C6o,F7,wfe,w6o,A6o,GD,L6o,y6o,x6o,T7,$6o,Afe,k6o,S6o,Lfe,R6o,P6o,M7,kGe,Di,E7,yfe,ny,B6o,xfe,I6o,SGe,ko,sy,N6o,Gi,q6o,OD,j6o,D6o,VD,G6o,O6o,V6o,ly,X6o,$fe,z6o,W6o,Q6o,lt,iy,H6o,kfe,U6o,J6o,Oi,Y6o,Sfe,K6o,Z6o,XD,eLo,oLo,rLo,C7,tLo,Ke,dy,aLo,Rfe,nLo,sLo,Pa,lLo,Pfe,iLo,dLo,Bfe,cLo,fLo,Ife,mLo,gLo,hLo,z,w7,Nfe,pLo,uLo,zD,_Lo,bLo,vLo,A7,qfe,FLo,TLo,WD,MLo,ELo,CLo,L7,jfe,wLo,ALo,QD,LLo,yLo,xLo,y7,Dfe,$Lo,kLo,HD,SLo,RLo,PLo,x7,Gfe,BLo,ILo,UD,NLo,qLo,jLo,$7,Ofe,DLo,GLo,JD,OLo,VLo,XLo,k7,Vfe,zLo,WLo,YD,QLo,HLo,ULo,S7,Xfe,JLo,YLo,KD,KLo,ZLo,eyo,R7,zfe,oyo,ryo,ZD,tyo,ayo,nyo,P7,Wfe,syo,lyo,eG,iyo,dyo,cyo,B7,Qfe,fyo,myo,oG,gyo,hyo,pyo,I7,Hfe,uyo,_yo,rG,byo,vyo,Fyo,N7,Ufe,Tyo,Myo,tG,Eyo,Cyo,wyo,q7,Jfe,Ayo,Lyo,aG,yyo,xyo,$yo,j7,Yfe,kyo,Syo,nG,Ryo,Pyo,Byo,D7,Kfe,Iyo,Nyo,sG,qyo,jyo,Dyo,G7,Zfe,Gyo,Oyo,lG,Vyo,Xyo,zyo,O7,eme,Wyo,Qyo,iG,Hyo,Uyo,Jyo,V7,ome,Yyo,Kyo,dG,Zyo,e8o,o8o,X7,rme,r8o,t8o,cG,a8o,n8o,s8o,z7,tme,l8o,i8o,fG,d8o,c8o,f8o,W7,ame,m8o,g8o,mG,h8o,p8o,u8o,Q7,nme,_8o,b8o,gG,v8o,F8o,T8o,H7,sme,M8o,E8o,hG,C8o,w8o,A8o,U7,lme,L8o,y8o,pG,x8o,$8o,k8o,J7,ime,S8o,R8o,uG,P8o,B8o,I8o,Y7,dme,N8o,q8o,_G,j8o,D8o,G8o,K7,cme,O8o,V8o,bG,X8o,z8o,W8o,Z7,fme,Q8o,H8o,vG,U8o,J8o,Y8o,e2,mme,K8o,Z8o,FG,e9o,o9o,r9o,o2,gme,t9o,a9o,TG,n9o,s9o,l9o,r2,hme,i9o,d9o,MG,c9o,f9o,m9o,t2,pme,g9o,h9o,EG,p9o,u9o,_9o,a2,ume,b9o,v9o,CG,F9o,T9o,M9o,n2,_me,E9o,C9o,wG,w9o,A9o,L9o,s2,bme,y9o,x9o,AG,$9o,k9o,S9o,l2,vme,R9o,P9o,LG,B9o,I9o,N9o,i2,Fme,q9o,j9o,yG,D9o,G9o,O9o,d2,V9o,Tme,X9o,z9o,Mme,W9o,Q9o,c2,RGe,Vi,f2,Eme,cy,H9o,Cme,U9o,PGe,So,fy,J9o,Xi,Y9o,xG,K9o,Z9o,$G,exo,oxo,rxo,my,txo,wme,axo,nxo,sxo,it,gy,lxo,Ame,ixo,dxo,zi,cxo,Lme,fxo,mxo,kG,gxo,hxo,pxo,m2,uxo,Ze,hy,_xo,yme,bxo,vxo,Ba,Fxo,xme,Txo,Mxo,$me,Exo,Cxo,kme,wxo,Axo,Lxo,Q,g2,Sme,yxo,xxo,SG,$xo,kxo,Sxo,h2,Rme,Rxo,Pxo,RG,Bxo,Ixo,Nxo,p2,Pme,qxo,jxo,PG,Dxo,Gxo,Oxo,u2,Bme,Vxo,Xxo,BG,zxo,Wxo,Qxo,_2,Ime,Hxo,Uxo,IG,Jxo,Yxo,Kxo,b2,Nme,Zxo,e$o,NG,o$o,r$o,t$o,v2,qme,a$o,n$o,qG,s$o,l$o,i$o,F2,jme,d$o,c$o,jG,f$o,m$o,g$o,T2,Dme,h$o,p$o,DG,u$o,_$o,b$o,M2,Gme,v$o,F$o,GG,T$o,M$o,E$o,E2,Ome,C$o,w$o,OG,A$o,L$o,y$o,C2,Vme,x$o,$$o,VG,k$o,S$o,R$o,w2,Xme,P$o,B$o,XG,I$o,N$o,q$o,A2,zme,j$o,D$o,zG,G$o,O$o,V$o,L2,Wme,X$o,z$o,WG,W$o,Q$o,H$o,y2,Qme,U$o,J$o,QG,Y$o,K$o,Z$o,x2,Hme,eko,oko,HG,rko,tko,ako,$2,Ume,nko,sko,UG,lko,iko,dko,k2,Jme,cko,fko,JG,mko,gko,hko,S2,Yme,pko,uko,YG,_ko,bko,vko,R2,Kme,Fko,Tko,KG,Mko,Eko,Cko,P2,Zme,wko,Ako,ZG,Lko,yko,xko,B2,ege,$ko,kko,eO,Sko,Rko,Pko,I2,oge,Bko,Iko,oO,Nko,qko,jko,N2,rge,Dko,Gko,rO,Oko,Vko,Xko,q2,tge,zko,Wko,tO,Qko,Hko,Uko,j2,age,Jko,Yko,aO,Kko,Zko,eSo,D2,nge,oSo,rSo,nO,tSo,aSo,nSo,G2,sge,sSo,lSo,sO,iSo,dSo,cSo,O2,lge,fSo,mSo,lO,gSo,hSo,pSo,V2,ige,uSo,_So,iO,bSo,vSo,FSo,X2,dge,TSo,MSo,cge,ESo,CSo,wSo,z2,fge,ASo,LSo,dO,ySo,xSo,$So,W2,mge,kSo,SSo,cO,RSo,PSo,BSo,Q2,gge,ISo,NSo,fO,qSo,jSo,DSo,H2,hge,GSo,OSo,mO,VSo,XSo,zSo,U2,WSo,pge,QSo,HSo,uge,USo,JSo,J2,BGe,Wi,Y2,_ge,py,YSo,bge,KSo,IGe,Ro,uy,ZSo,Qi,eRo,gO,oRo,rRo,hO,tRo,aRo,nRo,_y,sRo,vge,lRo,iRo,dRo,dt,by,cRo,Fge,fRo,mRo,Hi,gRo,Tge,hRo,pRo,pO,uRo,_Ro,bRo,K2,vRo,eo,vy,FRo,Mge,TRo,MRo,Ia,ERo,Ege,CRo,wRo,Cge,ARo,LRo,wge,yRo,xRo,$Ro,pe,Z2,Age,kRo,SRo,uO,RRo,PRo,BRo,e1,Lge,IRo,NRo,_O,qRo,jRo,DRo,o1,yge,GRo,ORo,bO,VRo,XRo,zRo,r1,xge,WRo,QRo,vO,HRo,URo,JRo,t1,$ge,YRo,KRo,FO,ZRo,ePo,oPo,a1,kge,rPo,tPo,TO,aPo,nPo,sPo,n1,Sge,lPo,iPo,MO,dPo,cPo,fPo,s1,Rge,mPo,gPo,EO,hPo,pPo,uPo,l1,Pge,_Po,bPo,CO,vPo,FPo,TPo,i1,Bge,MPo,EPo,wO,CPo,wPo,APo,d1,Ige,LPo,yPo,AO,xPo,$Po,kPo,c1,Nge,SPo,RPo,LO,PPo,BPo,IPo,f1,qge,NPo,qPo,yO,jPo,DPo,GPo,m1,jge,OPo,VPo,xO,XPo,zPo,WPo,g1,Dge,QPo,HPo,$O,UPo,JPo,YPo,h1,Gge,KPo,ZPo,kO,eBo,oBo,rBo,p1,Oge,tBo,aBo,SO,nBo,sBo,lBo,u1,iBo,Vge,dBo,cBo,Xge,fBo,mBo,_1,NGe,Ui,b1,zge,Fy,gBo,Wge,hBo,qGe,Po,Ty,pBo,Ji,uBo,RO,_Bo,bBo,PO,vBo,FBo,TBo,My,MBo,Qge,EBo,CBo,wBo,ct,Ey,ABo,Hge,LBo,yBo,Yi,xBo,Uge,$Bo,kBo,BO,SBo,RBo,PBo,v1,BBo,oo,Cy,IBo,Jge,NBo,qBo,Na,jBo,Yge,DBo,GBo,Kge,OBo,VBo,Zge,XBo,zBo,WBo,N,F1,ehe,QBo,HBo,IO,UBo,JBo,YBo,T1,ohe,KBo,ZBo,NO,eIo,oIo,rIo,M1,rhe,tIo,aIo,qO,nIo,sIo,lIo,E1,the,iIo,dIo,jO,cIo,fIo,mIo,C1,ahe,gIo,hIo,DO,pIo,uIo,_Io,w1,nhe,bIo,vIo,GO,FIo,TIo,MIo,A1,she,EIo,CIo,OO,wIo,AIo,LIo,L1,lhe,yIo,xIo,VO,$Io,kIo,SIo,y1,ihe,RIo,PIo,XO,BIo,IIo,NIo,x1,dhe,qIo,jIo,zO,DIo,GIo,OIo,$1,che,VIo,XIo,WO,zIo,WIo,QIo,k1,fhe,HIo,UIo,QO,JIo,YIo,KIo,S1,mhe,ZIo,eNo,HO,oNo,rNo,tNo,R1,ghe,aNo,nNo,UO,sNo,lNo,iNo,P1,hhe,dNo,cNo,JO,fNo,mNo,gNo,B1,phe,hNo,pNo,YO,uNo,_No,bNo,I1,uhe,vNo,FNo,KO,TNo,MNo,ENo,N1,_he,CNo,wNo,ZO,ANo,LNo,yNo,q1,bhe,xNo,$No,eV,kNo,SNo,RNo,j1,vhe,PNo,BNo,oV,INo,NNo,qNo,D1,Fhe,jNo,DNo,rV,GNo,ONo,VNo,G1,The,XNo,zNo,tV,WNo,QNo,HNo,O1,Mhe,UNo,JNo,aV,YNo,KNo,ZNo,V1,Ehe,eqo,oqo,nV,rqo,tqo,aqo,X1,Che,nqo,sqo,sV,lqo,iqo,dqo,z1,whe,cqo,fqo,lV,mqo,gqo,hqo,W1,Ahe,pqo,uqo,iV,_qo,bqo,vqo,Q1,Lhe,Fqo,Tqo,dV,Mqo,Eqo,Cqo,H1,yhe,wqo,Aqo,cV,Lqo,yqo,xqo,U1,xhe,$qo,kqo,fV,Sqo,Rqo,Pqo,J1,$he,Bqo,Iqo,mV,Nqo,qqo,jqo,Y1,khe,Dqo,Gqo,gV,Oqo,Vqo,Xqo,K1,She,zqo,Wqo,hV,Qqo,Hqo,Uqo,Z1,Rhe,Jqo,Yqo,pV,Kqo,Zqo,ejo,eb,Phe,ojo,rjo,uV,tjo,ajo,njo,ob,Bhe,sjo,ljo,_V,ijo,djo,cjo,rb,Ihe,fjo,mjo,bV,gjo,hjo,pjo,tb,Nhe,ujo,_jo,vV,bjo,vjo,Fjo,ab,qhe,Tjo,Mjo,FV,Ejo,Cjo,wjo,nb,jhe,Ajo,Ljo,TV,yjo,xjo,$jo,sb,Dhe,kjo,Sjo,MV,Rjo,Pjo,Bjo,lb,Ghe,Ijo,Njo,EV,qjo,jjo,Djo,ib,Ohe,Gjo,Ojo,CV,Vjo,Xjo,zjo,db,Vhe,Wjo,Qjo,wV,Hjo,Ujo,Jjo,cb,Xhe,Yjo,Kjo,AV,Zjo,eDo,oDo,fb,zhe,rDo,tDo,LV,aDo,nDo,sDo,mb,Whe,lDo,iDo,yV,dDo,cDo,fDo,gb,Qhe,mDo,gDo,xV,hDo,pDo,uDo,hb,_Do,Hhe,bDo,vDo,Uhe,FDo,TDo,pb,jGe,Ki,ub,Jhe,wy,MDo,Yhe,EDo,DGe,Bo,Ay,CDo,Zi,wDo,$V,ADo,LDo,kV,yDo,xDo,$Do,Ly,kDo,Khe,SDo,RDo,PDo,ft,yy,BDo,Zhe,IDo,NDo,ed,qDo,epe,jDo,DDo,SV,GDo,ODo,VDo,_b,XDo,ro,xy,zDo,ope,WDo,QDo,qa,HDo,rpe,UDo,JDo,tpe,YDo,KDo,ape,ZDo,eGo,oGo,Z,bb,npe,rGo,tGo,RV,aGo,nGo,sGo,vb,spe,lGo,iGo,PV,dGo,cGo,fGo,Fb,lpe,mGo,gGo,BV,hGo,pGo,uGo,Tb,ipe,_Go,bGo,IV,vGo,FGo,TGo,Mb,dpe,MGo,EGo,NV,CGo,wGo,AGo,Eb,cpe,LGo,yGo,qV,xGo,$Go,kGo,Cb,fpe,SGo,RGo,jV,PGo,BGo,IGo,wb,mpe,NGo,qGo,DV,jGo,DGo,GGo,Ab,gpe,OGo,VGo,GV,XGo,zGo,WGo,Lb,hpe,QGo,HGo,OV,UGo,JGo,YGo,yb,ppe,KGo,ZGo,VV,eOo,oOo,rOo,xb,upe,tOo,aOo,XV,nOo,sOo,lOo,$b,_pe,iOo,dOo,zV,cOo,fOo,mOo,kb,bpe,gOo,hOo,WV,pOo,uOo,_Oo,Sb,vpe,bOo,vOo,QV,FOo,TOo,MOo,Rb,Fpe,EOo,COo,HV,wOo,AOo,LOo,Pb,Tpe,yOo,xOo,UV,$Oo,kOo,SOo,Bb,Mpe,ROo,POo,JV,BOo,IOo,NOo,Ib,Epe,qOo,jOo,YV,DOo,GOo,OOo,Nb,Cpe,VOo,XOo,KV,zOo,WOo,QOo,qb,wpe,HOo,UOo,ZV,JOo,YOo,KOo,jb,Ape,ZOo,eVo,eX,oVo,rVo,tVo,Db,Lpe,aVo,nVo,oX,sVo,lVo,iVo,Gb,ype,dVo,cVo,rX,fVo,mVo,gVo,Ob,xpe,hVo,pVo,tX,uVo,_Vo,bVo,Vb,$pe,vVo,FVo,aX,TVo,MVo,EVo,Xb,kpe,CVo,wVo,nX,AVo,LVo,yVo,zb,Spe,xVo,$Vo,sX,kVo,SVo,RVo,Wb,Rpe,PVo,BVo,lX,IVo,NVo,qVo,Qb,jVo,Ppe,DVo,GVo,Bpe,OVo,VVo,Hb,GGe,od,Ub,Ipe,$y,XVo,Npe,zVo,OGe,Io,ky,WVo,rd,QVo,iX,HVo,UVo,dX,JVo,YVo,KVo,Sy,ZVo,qpe,eXo,oXo,rXo,mt,Ry,tXo,jpe,aXo,nXo,td,sXo,Dpe,lXo,iXo,cX,dXo,cXo,fXo,Jb,mXo,to,Py,gXo,Gpe,hXo,pXo,ja,uXo,Ope,_Xo,bXo,Vpe,vXo,FXo,Xpe,TXo,MXo,EXo,Zr,Yb,zpe,CXo,wXo,fX,AXo,LXo,yXo,Kb,Wpe,xXo,$Xo,mX,kXo,SXo,RXo,Zb,Qpe,PXo,BXo,gX,IXo,NXo,qXo,ev,Hpe,jXo,DXo,hX,GXo,OXo,VXo,ov,Upe,XXo,zXo,pX,WXo,QXo,HXo,rv,UXo,Jpe,JXo,YXo,Ype,KXo,ZXo,tv,VGe,ad,av,Kpe,By,ezo,Zpe,ozo,XGe,No,Iy,rzo,nd,tzo,uX,azo,nzo,_X,szo,lzo,izo,Ny,dzo,eue,czo,fzo,mzo,gt,qy,gzo,oue,hzo,pzo,sd,uzo,rue,_zo,bzo,bX,vzo,Fzo,Tzo,nv,Mzo,ao,jy,Ezo,tue,Czo,wzo,Da,Azo,aue,Lzo,yzo,nue,xzo,$zo,sue,kzo,Szo,Rzo,H,sv,lue,Pzo,Bzo,vX,Izo,Nzo,qzo,lv,iue,jzo,Dzo,FX,Gzo,Ozo,Vzo,iv,due,Xzo,zzo,TX,Wzo,Qzo,Hzo,dv,cue,Uzo,Jzo,MX,Yzo,Kzo,Zzo,cv,fue,eWo,oWo,EX,rWo,tWo,aWo,fv,mue,nWo,sWo,CX,lWo,iWo,dWo,mv,gue,cWo,fWo,wX,mWo,gWo,hWo,gv,hue,pWo,uWo,AX,_Wo,bWo,vWo,hv,pue,FWo,TWo,LX,MWo,EWo,CWo,pv,uue,wWo,AWo,yX,LWo,yWo,xWo,uv,_ue,$Wo,kWo,xX,SWo,RWo,PWo,_v,bue,BWo,IWo,$X,NWo,qWo,jWo,bv,vue,DWo,GWo,kX,OWo,VWo,XWo,vv,Fue,zWo,WWo,SX,QWo,HWo,UWo,Fv,Tue,JWo,YWo,RX,KWo,ZWo,eQo,Tv,Mue,oQo,rQo,PX,tQo,aQo,nQo,Mv,Eue,sQo,lQo,BX,iQo,dQo,cQo,Ev,Cue,fQo,mQo,IX,gQo,hQo,pQo,Cv,wue,uQo,_Qo,NX,bQo,vQo,FQo,wv,Aue,TQo,MQo,qX,EQo,CQo,wQo,Av,Lue,AQo,LQo,jX,yQo,xQo,$Qo,Lv,yue,kQo,SQo,DX,RQo,PQo,BQo,yv,xue,IQo,NQo,GX,qQo,jQo,DQo,xv,$ue,GQo,OQo,OX,VQo,XQo,zQo,$v,kue,WQo,QQo,VX,HQo,UQo,JQo,kv,Sue,YQo,KQo,XX,ZQo,eHo,oHo,Sv,Rue,rHo,tHo,zX,aHo,nHo,sHo,Rv,Pue,lHo,iHo,WX,dHo,cHo,fHo,Pv,Bue,mHo,gHo,QX,hHo,pHo,uHo,Bv,Iue,_Ho,bHo,HX,vHo,FHo,THo,Iv,Nue,MHo,EHo,UX,CHo,wHo,AHo,Nv,que,LHo,yHo,JX,xHo,$Ho,kHo,qv,jue,SHo,RHo,YX,PHo,BHo,IHo,jv,Due,NHo,qHo,KX,jHo,DHo,GHo,Dv,Gue,OHo,VHo,ZX,XHo,zHo,WHo,Gv,QHo,Oue,HHo,UHo,Vue,JHo,YHo,Ov,zGe,ld,Vv,Xue,Dy,KHo,zue,ZHo,WGe,qo,Gy,eUo,id,oUo,ez,rUo,tUo,oz,aUo,nUo,sUo,Oy,lUo,Wue,iUo,dUo,cUo,ht,Vy,fUo,Que,mUo,gUo,dd,hUo,Hue,pUo,uUo,rz,_Uo,bUo,vUo,Xv,FUo,no,Xy,TUo,Uue,MUo,EUo,Ga,CUo,Jue,wUo,AUo,Yue,LUo,yUo,Kue,xUo,$Uo,kUo,V,zv,Zue,SUo,RUo,tz,PUo,BUo,IUo,Wv,e_e,NUo,qUo,az,jUo,DUo,GUo,Qv,o_e,OUo,VUo,nz,XUo,zUo,WUo,Hv,r_e,QUo,HUo,sz,UUo,JUo,YUo,Uv,t_e,KUo,ZUo,lz,eJo,oJo,rJo,Jv,a_e,tJo,aJo,iz,nJo,sJo,lJo,Yv,n_e,iJo,dJo,dz,cJo,fJo,mJo,Kv,s_e,gJo,hJo,cz,pJo,uJo,_Jo,Zv,l_e,bJo,vJo,fz,FJo,TJo,MJo,eF,i_e,EJo,CJo,mz,wJo,AJo,LJo,oF,d_e,yJo,xJo,gz,$Jo,kJo,SJo,rF,c_e,RJo,PJo,hz,BJo,IJo,NJo,tF,f_e,qJo,jJo,pz,DJo,GJo,OJo,aF,m_e,VJo,XJo,uz,zJo,WJo,QJo,nF,g_e,HJo,UJo,_z,JJo,YJo,KJo,sF,h_e,ZJo,eYo,bz,oYo,rYo,tYo,lF,p_e,aYo,nYo,vz,sYo,lYo,iYo,iF,u_e,dYo,cYo,Fz,fYo,mYo,gYo,dF,__e,hYo,pYo,Tz,uYo,_Yo,bYo,cF,b_e,vYo,FYo,Mz,TYo,MYo,EYo,fF,v_e,CYo,wYo,Ez,AYo,LYo,yYo,mF,F_e,xYo,$Yo,Cz,kYo,SYo,RYo,gF,T_e,PYo,BYo,wz,IYo,NYo,qYo,hF,M_e,jYo,DYo,Az,GYo,OYo,VYo,pF,E_e,XYo,zYo,Lz,WYo,QYo,HYo,uF,C_e,UYo,JYo,yz,YYo,KYo,ZYo,_F,w_e,eKo,oKo,xz,rKo,tKo,aKo,bF,A_e,nKo,sKo,$z,lKo,iKo,dKo,vF,L_e,cKo,fKo,kz,mKo,gKo,hKo,FF,y_e,pKo,uKo,Sz,_Ko,bKo,vKo,TF,x_e,FKo,TKo,Rz,MKo,EKo,CKo,MF,$_e,wKo,AKo,Pz,LKo,yKo,xKo,EF,k_e,$Ko,kKo,Bz,SKo,RKo,PKo,CF,S_e,BKo,IKo,Iz,NKo,qKo,jKo,wF,R_e,DKo,GKo,Nz,OKo,VKo,XKo,AF,P_e,zKo,WKo,qz,QKo,HKo,UKo,LF,B_e,JKo,YKo,jz,KKo,ZKo,eZo,yF,I_e,oZo,rZo,Dz,tZo,aZo,nZo,xF,N_e,sZo,lZo,Gz,iZo,dZo,cZo,$F,q_e,fZo,mZo,Oz,gZo,hZo,pZo,kF,uZo,j_e,_Zo,bZo,D_e,vZo,FZo,SF,QGe,cd,RF,G_e,zy,TZo,O_e,MZo,HGe,jo,Wy,EZo,fd,CZo,Vz,wZo,AZo,Xz,LZo,yZo,xZo,Qy,$Zo,V_e,kZo,SZo,RZo,pt,Hy,PZo,X_e,BZo,IZo,md,NZo,z_e,qZo,jZo,zz,DZo,GZo,OZo,PF,VZo,so,Uy,XZo,W_e,zZo,WZo,Oa,QZo,Q_e,HZo,UZo,H_e,JZo,YZo,U_e,KZo,ZZo,eer,J_e,BF,Y_e,oer,rer,Wz,ter,aer,ner,IF,ser,K_e,ler,ier,Z_e,der,cer,NF,UGe,gd,qF,e7e,Jy,fer,o7e,mer,JGe,Do,Yy,ger,hd,her,Qz,per,uer,Hz,_er,ber,ver,Ky,Fer,r7e,Ter,Mer,Eer,ut,Zy,Cer,t7e,wer,Aer,pd,Ler,a7e,yer,xer,Uz,$er,ker,Ser,jF,Rer,lo,e8,Per,n7e,Ber,Ier,Va,Ner,s7e,qer,jer,l7e,Der,Ger,i7e,Oer,Ver,Xer,_e,DF,d7e,zer,Wer,Jz,Qer,Her,Uer,GF,c7e,Jer,Yer,Yz,Ker,Zer,eor,OF,f7e,oor,ror,Kz,tor,aor,nor,VF,m7e,sor,lor,Zz,ior,dor,cor,Os,g7e,mor,gor,eW,hor,por,oW,uor,_or,bor,XF,h7e,vor,For,rW,Tor,Mor,Eor,Vs,p7e,Cor,wor,tW,Aor,Lor,aW,yor,xor,$or,zF,u7e,kor,Sor,nW,Ror,Por,Bor,_t,_7e,Ior,Nor,sW,qor,jor,lW,Dor,Gor,iW,Oor,Vor,Xor,WF,b7e,zor,Wor,dW,Qor,Hor,Uor,QF,v7e,Jor,Yor,cW,Kor,Zor,err,HF,F7e,orr,rrr,fW,trr,arr,nrr,UF,T7e,srr,lrr,mW,irr,drr,crr,JF,M7e,frr,mrr,gW,grr,hrr,prr,YF,E7e,urr,_rr,hW,brr,vrr,Frr,KF,C7e,Trr,Mrr,pW,Err,Crr,wrr,ZF,Arr,w7e,Lrr,yrr,A7e,xrr,$rr,eT,YGe,ud,oT,L7e,o8,krr,y7e,Srr,KGe,Go,r8,Rrr,_d,Prr,uW,Brr,Irr,_W,Nrr,qrr,jrr,t8,Drr,x7e,Grr,Orr,Vrr,bt,a8,Xrr,$7e,zrr,Wrr,bd,Qrr,k7e,Hrr,Urr,bW,Jrr,Yrr,Krr,rT,Zrr,io,n8,etr,S7e,otr,rtr,Xa,ttr,R7e,atr,ntr,P7e,str,ltr,B7e,itr,dtr,ctr,I7e,tT,N7e,ftr,mtr,vW,gtr,htr,ptr,aT,utr,q7e,_tr,btr,j7e,vtr,Ftr,nT,ZGe,vd,sT,D7e,s8,Ttr,G7e,Mtr,eOe,Oo,l8,Etr,Fd,Ctr,FW,wtr,Atr,TW,Ltr,ytr,xtr,i8,$tr,O7e,ktr,Str,Rtr,vt,d8,Ptr,V7e,Btr,Itr,Td,Ntr,X7e,qtr,jtr,MW,Dtr,Gtr,Otr,lT,Vtr,co,c8,Xtr,z7e,ztr,Wtr,za,Qtr,W7e,Htr,Utr,Q7e,Jtr,Ytr,H7e,Ktr,Ztr,ear,U7e,iT,J7e,oar,rar,EW,tar,aar,nar,dT,sar,Y7e,lar,iar,K7e,dar,car,cT,oOe,Md,fT,Z7e,f8,far,e2e,mar,rOe,Vo,m8,gar,Ed,har,CW,par,uar,wW,_ar,bar,Far,g8,Tar,o2e,Mar,Ear,Car,Ft,h8,war,r2e,Aar,Lar,Cd,yar,t2e,xar,$ar,AW,kar,Sar,Rar,mT,Par,fo,p8,Bar,a2e,Iar,Nar,Wa,qar,n2e,jar,Dar,s2e,Gar,Oar,l2e,Var,Xar,zar,Pe,gT,i2e,War,Qar,LW,Har,Uar,Jar,hT,d2e,Yar,Kar,yW,Zar,enr,onr,pT,c2e,rnr,tnr,xW,anr,nnr,snr,uT,f2e,lnr,inr,$W,dnr,cnr,fnr,_T,m2e,mnr,gnr,kW,hnr,pnr,unr,bT,g2e,_nr,bnr,SW,vnr,Fnr,Tnr,vT,h2e,Mnr,Enr,RW,Cnr,wnr,Anr,FT,p2e,Lnr,ynr,PW,xnr,$nr,knr,TT,u2e,Snr,Rnr,BW,Pnr,Bnr,Inr,MT,Nnr,_2e,qnr,jnr,b2e,Dnr,Gnr,ET,tOe,wd,CT,v2e,u8,Onr,F2e,Vnr,aOe,Xo,_8,Xnr,Ad,znr,IW,Wnr,Qnr,NW,Hnr,Unr,Jnr,b8,Ynr,T2e,Knr,Znr,esr,Tt,v8,osr,M2e,rsr,tsr,Ld,asr,E2e,nsr,ssr,qW,lsr,isr,dsr,wT,csr,mo,F8,fsr,C2e,msr,gsr,Qa,hsr,w2e,psr,usr,A2e,_sr,bsr,L2e,vsr,Fsr,Tsr,et,AT,y2e,Msr,Esr,jW,Csr,wsr,Asr,LT,x2e,Lsr,ysr,DW,xsr,$sr,ksr,yT,$2e,Ssr,Rsr,GW,Psr,Bsr,Isr,xT,k2e,Nsr,qsr,OW,jsr,Dsr,Gsr,$T,S2e,Osr,Vsr,VW,Xsr,zsr,Wsr,kT,Qsr,R2e,Hsr,Usr,P2e,Jsr,Ysr,ST,nOe,yd,RT,B2e,T8,Ksr,I2e,Zsr,sOe,zo,M8,elr,xd,olr,XW,rlr,tlr,zW,alr,nlr,slr,E8,llr,N2e,ilr,dlr,clr,Mt,C8,flr,q2e,mlr,glr,$d,hlr,j2e,plr,ulr,WW,_lr,blr,vlr,PT,Flr,go,w8,Tlr,D2e,Mlr,Elr,Ha,Clr,G2e,wlr,Alr,O2e,Llr,ylr,V2e,xlr,$lr,klr,Le,BT,X2e,Slr,Rlr,QW,Plr,Blr,Ilr,IT,z2e,Nlr,qlr,HW,jlr,Dlr,Glr,NT,W2e,Olr,Vlr,UW,Xlr,zlr,Wlr,qT,Q2e,Qlr,Hlr,JW,Ulr,Jlr,Ylr,jT,H2e,Klr,Zlr,YW,eir,oir,rir,DT,U2e,tir,air,KW,nir,sir,lir,GT,J2e,iir,dir,ZW,cir,fir,mir,OT,Y2e,gir,hir,eQ,pir,uir,_ir,VT,K2e,bir,vir,oQ,Fir,Tir,Mir,XT,Z2e,Eir,Cir,rQ,wir,Air,Lir,zT,yir,e1e,xir,$ir,o1e,kir,Sir,WT,lOe,kd,QT,r1e,A8,Rir,t1e,Pir,iOe,Wo,L8,Bir,Sd,Iir,tQ,Nir,qir,aQ,jir,Dir,Gir,y8,Oir,a1e,Vir,Xir,zir,Et,x8,Wir,n1e,Qir,Hir,Rd,Uir,s1e,Jir,Yir,nQ,Kir,Zir,edr,HT,odr,ho,$8,rdr,l1e,tdr,adr,Ua,ndr,i1e,sdr,ldr,d1e,idr,ddr,c1e,cdr,fdr,mdr,k8,UT,f1e,gdr,hdr,sQ,pdr,udr,_dr,JT,m1e,bdr,vdr,lQ,Fdr,Tdr,Mdr,YT,Edr,g1e,Cdr,wdr,h1e,Adr,Ldr,KT,dOe,Pd,ZT,p1e,S8,ydr,u1e,xdr,cOe,Qo,R8,$dr,Bd,kdr,iQ,Sdr,Rdr,dQ,Pdr,Bdr,Idr,P8,Ndr,_1e,qdr,jdr,Ddr,Ct,B8,Gdr,b1e,Odr,Vdr,Id,Xdr,v1e,zdr,Wdr,cQ,Qdr,Hdr,Udr,eM,Jdr,po,I8,Ydr,F1e,Kdr,Zdr,Ja,ecr,T1e,ocr,rcr,M1e,tcr,acr,E1e,ncr,scr,lcr,ot,oM,C1e,icr,dcr,fQ,ccr,fcr,mcr,rM,w1e,gcr,hcr,mQ,pcr,ucr,_cr,tM,A1e,bcr,vcr,gQ,Fcr,Tcr,Mcr,aM,L1e,Ecr,Ccr,hQ,wcr,Acr,Lcr,nM,y1e,ycr,xcr,pQ,$cr,kcr,Scr,sM,Rcr,x1e,Pcr,Bcr,$1e,Icr,Ncr,lM,fOe,Nd,iM,k1e,N8,qcr,S1e,jcr,mOe,Ho,q8,Dcr,qd,Gcr,uQ,Ocr,Vcr,_Q,Xcr,zcr,Wcr,j8,Qcr,R1e,Hcr,Ucr,Jcr,wt,D8,Ycr,P1e,Kcr,Zcr,jd,efr,B1e,ofr,rfr,bQ,tfr,afr,nfr,dM,sfr,uo,G8,lfr,I1e,ifr,dfr,Ya,cfr,N1e,ffr,mfr,q1e,gfr,hfr,j1e,pfr,ufr,_fr,Dd,cM,D1e,bfr,vfr,vQ,Ffr,Tfr,Mfr,fM,G1e,Efr,Cfr,FQ,wfr,Afr,Lfr,mM,O1e,yfr,xfr,TQ,$fr,kfr,Sfr,gM,Rfr,V1e,Pfr,Bfr,X1e,Ifr,Nfr,hM,gOe,Gd,pM,z1e,O8,qfr,W1e,jfr,hOe,Uo,V8,Dfr,Od,Gfr,MQ,Ofr,Vfr,EQ,Xfr,zfr,Wfr,X8,Qfr,Q1e,Hfr,Ufr,Jfr,At,z8,Yfr,H1e,Kfr,Zfr,Vd,emr,U1e,omr,rmr,CQ,tmr,amr,nmr,uM,smr,_o,W8,lmr,J1e,imr,dmr,Ka,cmr,Y1e,fmr,mmr,K1e,gmr,hmr,Z1e,pmr,umr,_mr,Q8,_M,ebe,bmr,vmr,wQ,Fmr,Tmr,Mmr,bM,obe,Emr,Cmr,AQ,wmr,Amr,Lmr,vM,ymr,rbe,xmr,$mr,tbe,kmr,Smr,FM,pOe,Xd,TM,abe,H8,Rmr,nbe,Pmr,uOe,Jo,U8,Bmr,zd,Imr,LQ,Nmr,qmr,yQ,jmr,Dmr,Gmr,J8,Omr,sbe,Vmr,Xmr,zmr,Lt,Y8,Wmr,lbe,Qmr,Hmr,Wd,Umr,ibe,Jmr,Ymr,xQ,Kmr,Zmr,egr,MM,ogr,bo,K8,rgr,dbe,tgr,agr,Za,ngr,cbe,sgr,lgr,fbe,igr,dgr,mbe,cgr,fgr,mgr,gbe,EM,hbe,ggr,hgr,$Q,pgr,ugr,_gr,CM,bgr,pbe,vgr,Fgr,ube,Tgr,Mgr,wM,_Oe,Qd,AM,_be,Z8,Egr,bbe,Cgr,bOe,Yo,e9,wgr,Hd,Agr,kQ,Lgr,ygr,SQ,xgr,$gr,kgr,o9,Sgr,vbe,Rgr,Pgr,Bgr,yt,r9,Igr,Fbe,Ngr,qgr,Ud,jgr,Tbe,Dgr,Ggr,RQ,Ogr,Vgr,Xgr,LM,zgr,vo,t9,Wgr,Mbe,Qgr,Hgr,en,Ugr,Ebe,Jgr,Ygr,Cbe,Kgr,Zgr,wbe,ehr,ohr,rhr,on,yM,Abe,thr,ahr,PQ,nhr,shr,lhr,xM,Lbe,ihr,dhr,BQ,chr,fhr,mhr,$M,ybe,ghr,hhr,IQ,phr,uhr,_hr,kM,xbe,bhr,vhr,NQ,Fhr,Thr,Mhr,SM,Ehr,$be,Chr,whr,kbe,Ahr,Lhr,RM,vOe,Jd,PM,Sbe,a9,yhr,Rbe,xhr,FOe,Ko,n9,$hr,Yd,khr,qQ,Shr,Rhr,jQ,Phr,Bhr,Ihr,s9,Nhr,Pbe,qhr,jhr,Dhr,xt,l9,Ghr,Bbe,Ohr,Vhr,Kd,Xhr,Ibe,zhr,Whr,DQ,Qhr,Hhr,Uhr,BM,Jhr,Fo,i9,Yhr,Nbe,Khr,Zhr,rn,epr,qbe,opr,rpr,jbe,tpr,apr,Dbe,npr,spr,lpr,Gbe,IM,Obe,ipr,dpr,GQ,cpr,fpr,mpr,NM,gpr,Vbe,hpr,ppr,Xbe,upr,_pr,qM,TOe,Zd,jM,zbe,d9,bpr,Wbe,vpr,MOe,Zo,c9,Fpr,ec,Tpr,OQ,Mpr,Epr,VQ,Cpr,wpr,Apr,f9,Lpr,Qbe,ypr,xpr,$pr,$t,m9,kpr,Hbe,Spr,Rpr,oc,Ppr,Ube,Bpr,Ipr,XQ,Npr,qpr,jpr,DM,Dpr,Lr,g9,Gpr,Jbe,Opr,Vpr,tn,Xpr,Ybe,zpr,Wpr,Kbe,Qpr,Hpr,Zbe,Upr,Jpr,Ypr,q,GM,eve,Kpr,Zpr,zQ,eur,our,rur,OM,ove,tur,aur,WQ,nur,sur,lur,VM,rve,iur,dur,QQ,cur,fur,mur,XM,tve,gur,hur,HQ,pur,uur,_ur,zM,ave,bur,vur,UQ,Fur,Tur,Mur,WM,nve,Eur,Cur,JQ,wur,Aur,Lur,QM,sve,yur,xur,YQ,$ur,kur,Sur,HM,lve,Rur,Pur,KQ,Bur,Iur,Nur,UM,ive,qur,jur,ZQ,Dur,Gur,Our,JM,dve,Vur,Xur,eH,zur,Wur,Qur,YM,cve,Hur,Uur,oH,Jur,Yur,Kur,KM,fve,Zur,e_r,rH,o_r,r_r,t_r,ZM,mve,a_r,n_r,tH,s_r,l_r,i_r,eE,gve,d_r,c_r,aH,f_r,m_r,g_r,oE,hve,h_r,p_r,nH,u_r,__r,b_r,rE,pve,v_r,F_r,sH,T_r,M_r,E_r,tE,uve,C_r,w_r,lH,A_r,L_r,y_r,Xs,_ve,x_r,$_r,iH,k_r,S_r,dH,R_r,P_r,B_r,aE,bve,I_r,N_r,cH,q_r,j_r,D_r,nE,vve,G_r,O_r,fH,V_r,X_r,z_r,sE,Fve,W_r,Q_r,mH,H_r,U_r,J_r,lE,Tve,Y_r,K_r,gH,Z_r,e7r,o7r,iE,Mve,r7r,t7r,hH,a7r,n7r,s7r,dE,Eve,l7r,i7r,pH,d7r,c7r,f7r,cE,Cve,m7r,g7r,uH,h7r,p7r,u7r,fE,wve,_7r,b7r,_H,v7r,F7r,T7r,mE,Ave,M7r,E7r,bH,C7r,w7r,A7r,gE,Lve,L7r,y7r,vH,x7r,$7r,k7r,hE,yve,S7r,R7r,FH,P7r,B7r,I7r,pE,xve,N7r,q7r,TH,j7r,D7r,G7r,uE,$ve,O7r,V7r,MH,X7r,z7r,W7r,_E,kve,Q7r,H7r,EH,U7r,J7r,Y7r,bE,Sve,K7r,Z7r,CH,e2r,o2r,r2r,vE,Rve,t2r,a2r,wH,n2r,s2r,l2r,FE,Pve,i2r,d2r,AH,c2r,f2r,m2r,TE,Bve,g2r,h2r,LH,p2r,u2r,_2r,ME,Ive,b2r,v2r,yH,F2r,T2r,M2r,EE,Nve,E2r,C2r,xH,w2r,A2r,L2r,CE,qve,y2r,x2r,$H,$2r,k2r,S2r,wE,jve,R2r,P2r,kH,B2r,I2r,N2r,AE,Dve,q2r,j2r,SH,D2r,G2r,O2r,LE,Gve,V2r,X2r,RH,z2r,W2r,Q2r,yE,Ove,H2r,U2r,PH,J2r,Y2r,K2r,xE,Vve,Z2r,e1r,BH,o1r,r1r,t1r,$E,Xve,a1r,n1r,IH,s1r,l1r,i1r,kE,zve,d1r,c1r,NH,f1r,m1r,g1r,SE,Wve,h1r,p1r,qH,u1r,_1r,b1r,RE,EOe,rc,PE,Qve,h9,v1r,Hve,F1r,COe,er,p9,T1r,tc,M1r,jH,E1r,C1r,DH,w1r,A1r,L1r,u9,y1r,Uve,x1r,$1r,k1r,kt,_9,S1r,Jve,R1r,P1r,ac,B1r,Yve,I1r,N1r,GH,q1r,j1r,D1r,BE,G1r,yr,b9,O1r,Kve,V1r,X1r,an,z1r,Zve,W1r,Q1r,eFe,H1r,U1r,oFe,J1r,Y1r,K1r,se,IE,rFe,Z1r,ebr,OH,obr,rbr,tbr,NE,tFe,abr,nbr,VH,sbr,lbr,ibr,qE,aFe,dbr,cbr,XH,fbr,mbr,gbr,jE,nFe,hbr,pbr,zH,ubr,_br,bbr,DE,sFe,vbr,Fbr,WH,Tbr,Mbr,Ebr,GE,lFe,Cbr,wbr,QH,Abr,Lbr,ybr,OE,iFe,xbr,$br,HH,kbr,Sbr,Rbr,VE,dFe,Pbr,Bbr,UH,Ibr,Nbr,qbr,XE,cFe,jbr,Dbr,JH,Gbr,Obr,Vbr,zE,fFe,Xbr,zbr,YH,Wbr,Qbr,Hbr,WE,mFe,Ubr,Jbr,KH,Ybr,Kbr,Zbr,QE,gFe,evr,ovr,ZH,rvr,tvr,avr,HE,hFe,nvr,svr,eU,lvr,ivr,dvr,UE,pFe,cvr,fvr,oU,mvr,gvr,hvr,JE,uFe,pvr,uvr,rU,_vr,bvr,vvr,YE,_Fe,Fvr,Tvr,tU,Mvr,Evr,Cvr,KE,bFe,wvr,Avr,aU,Lvr,yvr,xvr,ZE,vFe,$vr,kvr,nU,Svr,Rvr,Pvr,e4,FFe,Bvr,Ivr,sU,Nvr,qvr,jvr,o4,TFe,Dvr,Gvr,lU,Ovr,Vvr,Xvr,r4,MFe,zvr,Wvr,iU,Qvr,Hvr,Uvr,t4,EFe,Jvr,Yvr,dU,Kvr,Zvr,eFr,a4,CFe,oFr,rFr,cU,tFr,aFr,nFr,n4,wOe,nc,s4,wFe,v9,sFr,AFe,lFr,AOe,or,F9,iFr,sc,dFr,fU,cFr,fFr,mU,mFr,gFr,hFr,T9,pFr,LFe,uFr,_Fr,bFr,St,M9,vFr,yFe,FFr,TFr,lc,MFr,xFe,EFr,CFr,gU,wFr,AFr,LFr,l4,yFr,xr,E9,xFr,$Fe,$Fr,kFr,nn,SFr,kFe,RFr,PFr,SFe,BFr,IFr,RFe,NFr,qFr,jFr,Me,i4,PFe,DFr,GFr,hU,OFr,VFr,XFr,d4,BFe,zFr,WFr,pU,QFr,HFr,UFr,c4,IFe,JFr,YFr,uU,KFr,ZFr,eTr,f4,NFe,oTr,rTr,_U,tTr,aTr,nTr,m4,qFe,sTr,lTr,bU,iTr,dTr,cTr,g4,jFe,fTr,mTr,vU,gTr,hTr,pTr,h4,DFe,uTr,_Tr,FU,bTr,vTr,FTr,p4,GFe,TTr,MTr,TU,ETr,CTr,wTr,u4,OFe,ATr,LTr,MU,yTr,xTr,$Tr,_4,VFe,kTr,STr,EU,RTr,PTr,BTr,b4,XFe,ITr,NTr,CU,qTr,jTr,DTr,v4,zFe,GTr,OTr,wU,VTr,XTr,zTr,F4,WFe,WTr,QTr,AU,HTr,UTr,JTr,T4,LOe,ic,M4,QFe,C9,YTr,HFe,KTr,yOe,rr,w9,ZTr,dc,eMr,LU,oMr,rMr,yU,tMr,aMr,nMr,A9,sMr,UFe,lMr,iMr,dMr,Rt,L9,cMr,JFe,fMr,mMr,cc,gMr,YFe,hMr,pMr,xU,uMr,_Mr,bMr,E4,vMr,$r,y9,FMr,KFe,TMr,MMr,sn,EMr,ZFe,CMr,wMr,eTe,AMr,LMr,oTe,yMr,xMr,$Mr,ln,C4,rTe,kMr,SMr,$U,RMr,PMr,BMr,w4,tTe,IMr,NMr,kU,qMr,jMr,DMr,A4,aTe,GMr,OMr,SU,VMr,XMr,zMr,L4,nTe,WMr,QMr,RU,HMr,UMr,JMr,y4,xOe,fc,x4,sTe,x9,YMr,lTe,KMr,$Oe,tr,$9,ZMr,mc,eEr,PU,oEr,rEr,BU,tEr,aEr,nEr,k9,sEr,iTe,lEr,iEr,dEr,Pt,S9,cEr,dTe,fEr,mEr,gc,gEr,cTe,hEr,pEr,IU,uEr,_Er,bEr,$4,vEr,kr,R9,FEr,fTe,TEr,MEr,dn,EEr,mTe,CEr,wEr,gTe,AEr,LEr,hTe,yEr,xEr,$Er,ie,k4,pTe,kEr,SEr,NU,REr,PEr,BEr,S4,uTe,IEr,NEr,qU,qEr,jEr,DEr,R4,_Te,GEr,OEr,jU,VEr,XEr,zEr,P4,bTe,WEr,QEr,DU,HEr,UEr,JEr,B4,vTe,YEr,KEr,GU,ZEr,e4r,o4r,I4,FTe,r4r,t4r,OU,a4r,n4r,s4r,N4,TTe,l4r,i4r,VU,d4r,c4r,f4r,q4,MTe,m4r,g4r,XU,h4r,p4r,u4r,j4,ETe,_4r,b4r,zU,v4r,F4r,T4r,D4,CTe,M4r,E4r,WU,C4r,w4r,A4r,G4,wTe,L4r,y4r,QU,x4r,$4r,k4r,O4,ATe,S4r,R4r,HU,P4r,B4r,I4r,V4,LTe,N4r,q4r,UU,j4r,D4r,G4r,X4,yTe,O4r,V4r,JU,X4r,z4r,W4r,z4,xTe,Q4r,H4r,YU,U4r,J4r,Y4r,W4,$Te,K4r,Z4r,KU,eCr,oCr,rCr,Q4,kTe,tCr,aCr,ZU,nCr,sCr,lCr,H4,STe,iCr,dCr,eJ,cCr,fCr,mCr,U4,RTe,gCr,hCr,oJ,pCr,uCr,_Cr,J4,PTe,bCr,vCr,rJ,FCr,TCr,MCr,Y4,kOe,hc,K4,BTe,P9,ECr,ITe,CCr,SOe,ar,B9,wCr,pc,ACr,tJ,LCr,yCr,aJ,xCr,$Cr,kCr,I9,SCr,NTe,RCr,PCr,BCr,Bt,N9,ICr,qTe,NCr,qCr,uc,jCr,jTe,DCr,GCr,nJ,OCr,VCr,XCr,Z4,zCr,Sr,q9,WCr,DTe,QCr,HCr,cn,UCr,GTe,JCr,YCr,OTe,KCr,ZCr,VTe,e5r,o5r,r5r,ye,eC,XTe,t5r,a5r,sJ,n5r,s5r,l5r,oC,zTe,i5r,d5r,lJ,c5r,f5r,m5r,rC,WTe,g5r,h5r,iJ,p5r,u5r,_5r,tC,QTe,b5r,v5r,dJ,F5r,T5r,M5r,aC,HTe,E5r,C5r,cJ,w5r,A5r,L5r,nC,UTe,y5r,x5r,fJ,$5r,k5r,S5r,sC,JTe,R5r,P5r,mJ,B5r,I5r,N5r,lC,YTe,q5r,j5r,gJ,D5r,G5r,O5r,iC,KTe,V5r,X5r,hJ,z5r,W5r,Q5r,dC,ZTe,H5r,U5r,pJ,J5r,Y5r,K5r,cC,ROe,_c,fC,eMe,j9,Z5r,oMe,e3r,POe,nr,D9,o3r,bc,r3r,uJ,t3r,a3r,_J,n3r,s3r,l3r,G9,i3r,rMe,d3r,c3r,f3r,It,O9,m3r,tMe,g3r,h3r,vc,p3r,aMe,u3r,_3r,bJ,b3r,v3r,F3r,mC,T3r,Rr,V9,M3r,nMe,E3r,C3r,fn,w3r,sMe,A3r,L3r,lMe,y3r,x3r,iMe,$3r,k3r,S3r,te,gC,dMe,R3r,P3r,vJ,B3r,I3r,N3r,hC,cMe,q3r,j3r,FJ,D3r,G3r,O3r,pC,fMe,V3r,X3r,TJ,z3r,W3r,Q3r,uC,mMe,H3r,U3r,MJ,J3r,Y3r,K3r,_C,gMe,Z3r,e0r,EJ,o0r,r0r,t0r,bC,hMe,a0r,n0r,CJ,s0r,l0r,i0r,vC,pMe,d0r,c0r,wJ,f0r,m0r,g0r,FC,uMe,h0r,p0r,AJ,u0r,_0r,b0r,TC,_Me,v0r,F0r,LJ,T0r,M0r,E0r,MC,bMe,C0r,w0r,yJ,A0r,L0r,y0r,EC,vMe,x0r,$0r,xJ,k0r,S0r,R0r,CC,FMe,P0r,B0r,$J,I0r,N0r,q0r,wC,TMe,j0r,D0r,kJ,G0r,O0r,V0r,AC,MMe,X0r,z0r,SJ,W0r,Q0r,H0r,LC,EMe,U0r,J0r,RJ,Y0r,K0r,Z0r,yC,CMe,ewr,owr,PJ,rwr,twr,awr,xC,wMe,nwr,swr,BJ,lwr,iwr,dwr,$C,AMe,cwr,fwr,IJ,mwr,gwr,hwr,kC,LMe,pwr,uwr,NJ,_wr,bwr,vwr,SC,yMe,Fwr,Twr,qJ,Mwr,Ewr,Cwr,RC,xMe,wwr,Awr,jJ,Lwr,ywr,xwr,PC,$Me,$wr,kwr,DJ,Swr,Rwr,Pwr,BC,kMe,Bwr,Iwr,GJ,Nwr,qwr,jwr,IC,SMe,Dwr,Gwr,OJ,Owr,Vwr,Xwr,NC,RMe,zwr,Wwr,VJ,Qwr,Hwr,Uwr,qC,PMe,Jwr,Ywr,XJ,Kwr,Zwr,eAr,jC,BOe,Fc,DC,BMe,X9,oAr,IMe,rAr,IOe,sr,z9,tAr,Tc,aAr,zJ,nAr,sAr,WJ,lAr,iAr,dAr,W9,cAr,NMe,fAr,mAr,gAr,Nt,Q9,hAr,qMe,pAr,uAr,Mc,_Ar,jMe,bAr,vAr,QJ,FAr,TAr,MAr,GC,EAr,Pr,H9,CAr,DMe,wAr,AAr,mn,LAr,GMe,yAr,xAr,OMe,$Ar,kAr,VMe,SAr,RAr,PAr,ue,OC,XMe,BAr,IAr,HJ,NAr,qAr,jAr,VC,zMe,DAr,GAr,UJ,OAr,VAr,XAr,XC,WMe,zAr,WAr,JJ,QAr,HAr,UAr,zC,QMe,JAr,YAr,YJ,KAr,ZAr,e6r,WC,HMe,o6r,r6r,KJ,t6r,a6r,n6r,QC,UMe,s6r,l6r,ZJ,i6r,d6r,c6r,HC,JMe,f6r,m6r,eY,g6r,h6r,p6r,UC,YMe,u6r,_6r,oY,b6r,v6r,F6r,JC,KMe,T6r,M6r,rY,E6r,C6r,w6r,YC,ZMe,A6r,L6r,tY,y6r,x6r,$6r,KC,eEe,k6r,S6r,aY,R6r,P6r,B6r,ZC,oEe,I6r,N6r,nY,q6r,j6r,D6r,e5,rEe,G6r,O6r,sY,V6r,X6r,z6r,o5,tEe,W6r,Q6r,lY,H6r,U6r,J6r,r5,aEe,Y6r,K6r,iY,Z6r,eLr,oLr,t5,nEe,rLr,tLr,dY,aLr,nLr,sLr,a5,sEe,lLr,iLr,cY,dLr,cLr,fLr,n5,NOe,Ec,s5,lEe,U9,mLr,iEe,gLr,qOe,lr,J9,hLr,Cc,pLr,fY,uLr,_Lr,mY,bLr,vLr,FLr,Y9,TLr,dEe,MLr,ELr,CLr,qt,K9,wLr,cEe,ALr,LLr,wc,yLr,fEe,xLr,$Lr,gY,kLr,SLr,RLr,l5,PLr,Br,Z9,BLr,mEe,ILr,NLr,gn,qLr,gEe,jLr,DLr,hEe,GLr,OLr,pEe,VLr,XLr,zLr,ex,i5,uEe,WLr,QLr,hY,HLr,ULr,JLr,d5,_Ee,YLr,KLr,pY,ZLr,eyr,oyr,c5,jOe,Ac,f5,bEe,ox,ryr,vEe,tyr,DOe,ir,rx,ayr,Lc,nyr,uY,syr,lyr,_Y,iyr,dyr,cyr,tx,fyr,FEe,myr,gyr,hyr,jt,ax,pyr,TEe,uyr,_yr,yc,byr,MEe,vyr,Fyr,bY,Tyr,Myr,Eyr,m5,Cyr,Ir,nx,wyr,EEe,Ayr,Lyr,hn,yyr,CEe,xyr,$yr,wEe,kyr,Syr,AEe,Ryr,Pyr,Byr,LEe,g5,yEe,Iyr,Nyr,vY,qyr,jyr,Dyr,h5,GOe,xc,p5,xEe,sx,Gyr,$Ee,Oyr,OOe,dr,lx,Vyr,$c,Xyr,FY,zyr,Wyr,TY,Qyr,Hyr,Uyr,ix,Jyr,kEe,Yyr,Kyr,Zyr,Dt,dx,e8r,SEe,o8r,r8r,kc,t8r,REe,a8r,n8r,MY,s8r,l8r,i8r,u5,d8r,Nr,cx,c8r,PEe,f8r,m8r,pn,g8r,BEe,h8r,p8r,IEe,u8r,_8r,NEe,b8r,v8r,F8r,de,_5,qEe,T8r,M8r,EY,E8r,C8r,w8r,b5,jEe,A8r,L8r,CY,y8r,x8r,$8r,v5,DEe,k8r,S8r,wY,R8r,P8r,B8r,F5,GEe,I8r,N8r,AY,q8r,j8r,D8r,T5,OEe,G8r,O8r,LY,V8r,X8r,z8r,M5,VEe,W8r,Q8r,yY,H8r,U8r,J8r,E5,XEe,Y8r,K8r,xY,Z8r,e9r,o9r,C5,zEe,r9r,t9r,$Y,a9r,n9r,s9r,w5,WEe,l9r,i9r,kY,d9r,c9r,f9r,A5,QEe,m9r,g9r,SY,h9r,p9r,u9r,L5,HEe,_9r,b9r,RY,v9r,F9r,T9r,y5,UEe,M9r,E9r,PY,C9r,w9r,A9r,x5,JEe,L9r,y9r,BY,x9r,$9r,k9r,$5,YEe,S9r,R9r,IY,P9r,B9r,I9r,k5,KEe,N9r,q9r,NY,j9r,D9r,G9r,S5,ZEe,O9r,V9r,qY,X9r,z9r,W9r,R5,e4e,Q9r,H9r,jY,U9r,J9r,Y9r,P5,o4e,K9r,Z9r,DY,exr,oxr,rxr,B5,r4e,txr,axr,GY,nxr,sxr,lxr,I5,t4e,ixr,dxr,OY,cxr,fxr,mxr,N5,VOe,Sc,q5,a4e,fx,gxr,n4e,hxr,XOe,cr,mx,pxr,Rc,uxr,VY,_xr,bxr,XY,vxr,Fxr,Txr,gx,Mxr,s4e,Exr,Cxr,wxr,Gt,hx,Axr,l4e,Lxr,yxr,Pc,xxr,i4e,$xr,kxr,zY,Sxr,Rxr,Pxr,j5,Bxr,qr,px,Ixr,d4e,Nxr,qxr,un,jxr,c4e,Dxr,Gxr,f4e,Oxr,Vxr,m4e,Xxr,zxr,Wxr,ce,D5,g4e,Qxr,Hxr,WY,Uxr,Jxr,Yxr,G5,h4e,Kxr,Zxr,QY,e$r,o$r,r$r,O5,p4e,t$r,a$r,HY,n$r,s$r,l$r,V5,u4e,i$r,d$r,UY,c$r,f$r,m$r,X5,_4e,g$r,h$r,JY,p$r,u$r,_$r,z5,b4e,b$r,v$r,YY,F$r,T$r,M$r,W5,v4e,E$r,C$r,KY,w$r,A$r,L$r,Q5,F4e,y$r,x$r,ZY,$$r,k$r,S$r,H5,T4e,R$r,P$r,eK,B$r,I$r,N$r,U5,M4e,q$r,j$r,oK,D$r,G$r,O$r,J5,E4e,V$r,X$r,rK,z$r,W$r,Q$r,Y5,C4e,H$r,U$r,tK,J$r,Y$r,K$r,K5,w4e,Z$r,ekr,aK,okr,rkr,tkr,Z5,A4e,akr,nkr,nK,skr,lkr,ikr,e3,L4e,dkr,ckr,sK,fkr,mkr,gkr,o3,y4e,hkr,pkr,lK,ukr,_kr,bkr,r3,x4e,vkr,Fkr,iK,Tkr,Mkr,Ekr,t3,$4e,Ckr,wkr,dK,Akr,Lkr,ykr,a3,k4e,xkr,$kr,cK,kkr,Skr,Rkr,n3,S4e,Pkr,Bkr,fK,Ikr,Nkr,qkr,s3,zOe,Bc,l3,R4e,ux,jkr,P4e,Dkr,WOe,fr,_x,Gkr,Ic,Okr,mK,Vkr,Xkr,gK,zkr,Wkr,Qkr,bx,Hkr,B4e,Ukr,Jkr,Ykr,Ot,vx,Kkr,I4e,Zkr,eSr,Nc,oSr,N4e,rSr,tSr,hK,aSr,nSr,sSr,i3,lSr,jr,Fx,iSr,q4e,dSr,cSr,_n,fSr,j4e,mSr,gSr,D4e,hSr,pSr,G4e,uSr,_Sr,bSr,O4e,d3,V4e,vSr,FSr,pK,TSr,MSr,ESr,c3,QOe,qc,f3,X4e,Tx,CSr,z4e,wSr,HOe,mr,Mx,ASr,jc,LSr,uK,ySr,xSr,_K,$Sr,kSr,SSr,Ex,RSr,W4e,PSr,BSr,ISr,Vt,Cx,NSr,Q4e,qSr,jSr,Dc,DSr,H4e,GSr,OSr,bK,VSr,XSr,zSr,m3,WSr,Dr,wx,QSr,U4e,HSr,USr,bn,JSr,J4e,YSr,KSr,Y4e,ZSr,eRr,K4e,oRr,rRr,tRr,Z4e,g3,eCe,aRr,nRr,vK,sRr,lRr,iRr,h3,UOe,Gc,p3,oCe,Ax,dRr,rCe,cRr,JOe,gr,Lx,fRr,Oc,mRr,FK,gRr,hRr,TK,pRr,uRr,_Rr,yx,bRr,tCe,vRr,FRr,TRr,Xt,xx,MRr,aCe,ERr,CRr,Vc,wRr,nCe,ARr,LRr,MK,yRr,xRr,$Rr,u3,kRr,Gr,$x,SRr,sCe,RRr,PRr,vn,BRr,lCe,IRr,NRr,iCe,qRr,jRr,dCe,DRr,GRr,ORr,oe,_3,cCe,VRr,XRr,EK,zRr,WRr,QRr,b3,fCe,HRr,URr,CK,JRr,YRr,KRr,v3,mCe,ZRr,ePr,wK,oPr,rPr,tPr,F3,gCe,aPr,nPr,AK,sPr,lPr,iPr,T3,hCe,dPr,cPr,LK,fPr,mPr,gPr,M3,pCe,hPr,pPr,yK,uPr,_Pr,bPr,E3,uCe,vPr,FPr,xK,TPr,MPr,EPr,C3,_Ce,CPr,wPr,$K,APr,LPr,yPr,w3,bCe,xPr,$Pr,kK,kPr,SPr,RPr,A3,vCe,PPr,BPr,SK,IPr,NPr,qPr,L3,FCe,jPr,DPr,RK,GPr,OPr,VPr,y3,TCe,XPr,zPr,PK,WPr,QPr,HPr,x3,MCe,UPr,JPr,BK,YPr,KPr,ZPr,$3,ECe,eBr,oBr,IK,rBr,tBr,aBr,k3,CCe,nBr,sBr,NK,lBr,iBr,dBr,S3,wCe,cBr,fBr,qK,mBr,gBr,hBr,R3,ACe,pBr,uBr,jK,_Br,bBr,vBr,P3,LCe,FBr,TBr,DK,MBr,EBr,CBr,B3,yCe,wBr,ABr,GK,LBr,yBr,xBr,I3,xCe,$Br,kBr,OK,SBr,RBr,PBr,N3,$Ce,BBr,IBr,VK,NBr,qBr,jBr,q3,kCe,DBr,GBr,XK,OBr,VBr,XBr,j3,SCe,zBr,WBr,zK,QBr,HBr,UBr,D3,RCe,JBr,YBr,WK,KBr,ZBr,eIr,G3,PCe,oIr,rIr,QK,tIr,aIr,nIr,O3,BCe,sIr,lIr,HK,iIr,dIr,cIr,V3,ICe,fIr,mIr,UK,gIr,hIr,pIr,X3,YOe,Xc,z3,NCe,kx,uIr,qCe,_Ir,KOe,hr,Sx,bIr,zc,vIr,JK,FIr,TIr,YK,MIr,EIr,CIr,Rx,wIr,jCe,AIr,LIr,yIr,zt,Px,xIr,DCe,$Ir,kIr,Wc,SIr,GCe,RIr,PIr,KK,BIr,IIr,NIr,W3,qIr,Or,Bx,jIr,OCe,DIr,GIr,Fn,OIr,VCe,VIr,XIr,XCe,zIr,WIr,zCe,QIr,HIr,UIr,xe,Q3,WCe,JIr,YIr,ZK,KIr,ZIr,eNr,H3,QCe,oNr,rNr,eZ,tNr,aNr,nNr,U3,HCe,sNr,lNr,oZ,iNr,dNr,cNr,J3,UCe,fNr,mNr,rZ,gNr,hNr,pNr,Y3,JCe,uNr,_Nr,tZ,bNr,vNr,FNr,K3,YCe,TNr,MNr,aZ,ENr,CNr,wNr,Z3,KCe,ANr,LNr,nZ,yNr,xNr,$Nr,e0,ZCe,kNr,SNr,sZ,RNr,PNr,BNr,o0,e5e,INr,NNr,lZ,qNr,jNr,DNr,r0,o5e,GNr,ONr,iZ,VNr,XNr,zNr,t0,ZOe,Qc,a0,r5e,Ix,WNr,t5e,QNr,eVe,pr,Nx,HNr,Hc,UNr,dZ,JNr,YNr,cZ,KNr,ZNr,eqr,qx,oqr,a5e,rqr,tqr,aqr,Wt,jx,nqr,n5e,sqr,lqr,Uc,iqr,s5e,dqr,cqr,fZ,fqr,mqr,gqr,n0,hqr,Vr,Dx,pqr,l5e,uqr,_qr,Tn,bqr,i5e,vqr,Fqr,d5e,Tqr,Mqr,c5e,Eqr,Cqr,wqr,Ee,s0,f5e,Aqr,Lqr,mZ,yqr,xqr,$qr,l0,m5e,kqr,Sqr,gZ,Rqr,Pqr,Bqr,i0,g5e,Iqr,Nqr,hZ,qqr,jqr,Dqr,d0,h5e,Gqr,Oqr,pZ,Vqr,Xqr,zqr,c0,p5e,Wqr,Qqr,uZ,Hqr,Uqr,Jqr,f0,u5e,Yqr,Kqr,_Z,Zqr,ejr,ojr,m0,_5e,rjr,tjr,bZ,ajr,njr,sjr,g0,b5e,ljr,ijr,vZ,djr,cjr,fjr,h0,v5e,mjr,gjr,FZ,hjr,pjr,ujr,p0,F5e,_jr,bjr,TZ,vjr,Fjr,Tjr,u0,T5e,Mjr,Ejr,MZ,Cjr,wjr,Ajr,_0,M5e,Ljr,yjr,EZ,xjr,$jr,kjr,b0,E5e,Sjr,Rjr,CZ,Pjr,Bjr,Ijr,v0,oVe,Jc,F0,C5e,Gx,Njr,w5e,qjr,rVe,ur,Ox,jjr,Yc,Djr,wZ,Gjr,Ojr,AZ,Vjr,Xjr,zjr,Vx,Wjr,A5e,Qjr,Hjr,Ujr,Qt,Xx,Jjr,L5e,Yjr,Kjr,Kc,Zjr,y5e,eDr,oDr,LZ,rDr,tDr,aDr,T0,nDr,Xr,zx,sDr,x5e,lDr,iDr,Mn,dDr,$5e,cDr,fDr,k5e,mDr,gDr,S5e,hDr,pDr,uDr,$e,M0,R5e,_Dr,bDr,yZ,vDr,FDr,TDr,E0,P5e,MDr,EDr,xZ,CDr,wDr,ADr,C0,B5e,LDr,yDr,$Z,xDr,$Dr,kDr,w0,I5e,SDr,RDr,kZ,PDr,BDr,IDr,A0,N5e,NDr,qDr,SZ,jDr,DDr,GDr,L0,q5e,ODr,VDr,RZ,XDr,zDr,WDr,y0,j5e,QDr,HDr,PZ,UDr,JDr,YDr,x0,D5e,KDr,ZDr,BZ,eGr,oGr,rGr,$0,G5e,tGr,aGr,IZ,nGr,sGr,lGr,k0,O5e,iGr,dGr,NZ,cGr,fGr,mGr,S0,tVe,Zc,R0,V5e,Wx,gGr,X5e,hGr,aVe,_r,Qx,pGr,ef,uGr,qZ,_Gr,bGr,jZ,vGr,FGr,TGr,Hx,MGr,z5e,EGr,CGr,wGr,Ht,Ux,AGr,W5e,LGr,yGr,of,xGr,Q5e,$Gr,kGr,DZ,SGr,RGr,PGr,P0,BGr,zr,Jx,IGr,H5e,NGr,qGr,En,jGr,U5e,DGr,GGr,J5e,OGr,VGr,Y5e,XGr,zGr,WGr,ke,B0,K5e,QGr,HGr,GZ,UGr,JGr,YGr,I0,Z5e,KGr,ZGr,OZ,eOr,oOr,rOr,N0,e3e,tOr,aOr,VZ,nOr,sOr,lOr,q0,o3e,iOr,dOr,XZ,cOr,fOr,mOr,j0,r3e,gOr,hOr,zZ,pOr,uOr,_Or,D0,t3e,bOr,vOr,WZ,FOr,TOr,MOr,G0,a3e,EOr,COr,QZ,wOr,AOr,LOr,O0,n3e,yOr,xOr,HZ,$Or,kOr,SOr,V0,s3e,ROr,POr,UZ,BOr,IOr,NOr,X0,l3e,qOr,jOr,JZ,DOr,GOr,OOr,z0,nVe,rf,W0,i3e,Yx,VOr,d3e,XOr,sVe,br,Kx,zOr,tf,WOr,YZ,QOr,HOr,KZ,UOr,JOr,YOr,Zx,KOr,c3e,ZOr,eVr,oVr,Ut,e$,rVr,f3e,tVr,aVr,af,nVr,m3e,sVr,lVr,ZZ,iVr,dVr,cVr,Q0,fVr,Wr,o$,mVr,g3e,gVr,hVr,Cn,pVr,h3e,uVr,_Vr,p3e,bVr,vVr,u3e,FVr,TVr,MVr,Se,H0,_3e,EVr,CVr,eee,wVr,AVr,LVr,U0,b3e,yVr,xVr,oee,$Vr,kVr,SVr,J0,v3e,RVr,PVr,ree,BVr,IVr,NVr,Y0,F3e,qVr,jVr,tee,DVr,GVr,OVr,K0,T3e,VVr,XVr,aee,zVr,WVr,QVr,Z0,M3e,HVr,UVr,nee,JVr,YVr,KVr,ew,E3e,ZVr,eXr,see,oXr,rXr,tXr,ow,C3e,aXr,nXr,lee,sXr,lXr,iXr,rw,w3e,dXr,cXr,iee,fXr,mXr,gXr,tw,A3e,hXr,pXr,dee,uXr,_Xr,bXr,aw,lVe,nf,nw,L3e,r$,vXr,y3e,FXr,iVe,vr,t$,TXr,sf,MXr,cee,EXr,CXr,fee,wXr,AXr,LXr,a$,yXr,x3e,xXr,$Xr,kXr,Jt,n$,SXr,$3e,RXr,PXr,lf,BXr,k3e,IXr,NXr,mee,qXr,jXr,DXr,sw,GXr,Qr,s$,OXr,S3e,VXr,XXr,wn,zXr,R3e,WXr,QXr,P3e,HXr,UXr,B3e,JXr,YXr,KXr,Re,lw,I3e,ZXr,ezr,gee,ozr,rzr,tzr,iw,N3e,azr,nzr,hee,szr,lzr,izr,dw,q3e,dzr,czr,pee,fzr,mzr,gzr,cw,j3e,hzr,pzr,uee,uzr,_zr,bzr,fw,D3e,vzr,Fzr,_ee,Tzr,Mzr,Ezr,mw,G3e,Czr,wzr,bee,Azr,Lzr,yzr,gw,O3e,xzr,$zr,vee,kzr,Szr,Rzr,hw,V3e,Pzr,Bzr,Fee,Izr,Nzr,qzr,pw,X3e,jzr,Dzr,Tee,Gzr,Ozr,Vzr,uw,z3e,Xzr,zzr,Mee,Wzr,Qzr,Hzr,_w,dVe,df,bw,W3e,l$,Uzr,Q3e,Jzr,cVe,Fr,i$,Yzr,cf,Kzr,Eee,Zzr,eWr,Cee,oWr,rWr,tWr,d$,aWr,H3e,nWr,sWr,lWr,Yt,c$,iWr,U3e,dWr,cWr,ff,fWr,J3e,mWr,gWr,wee,hWr,pWr,uWr,vw,_Wr,Hr,f$,bWr,Y3e,vWr,FWr,An,TWr,K3e,MWr,EWr,Z3e,CWr,wWr,e0e,AWr,LWr,yWr,Ve,Fw,o0e,xWr,$Wr,Aee,kWr,SWr,RWr,Tw,r0e,PWr,BWr,Lee,IWr,NWr,qWr,Mw,t0e,jWr,DWr,yee,GWr,OWr,VWr,Ew,a0e,XWr,zWr,xee,WWr,QWr,HWr,Cw,n0e,UWr,JWr,$ee,YWr,KWr,ZWr,ww,s0e,eQr,oQr,kee,rQr,tQr,aQr,Aw,l0e,nQr,sQr,See,lQr,iQr,dQr,Lw,i0e,cQr,fQr,Ree,mQr,gQr,hQr,yw,fVe,mf,xw,d0e,m$,pQr,c0e,uQr,mVe,Tr,g$,_Qr,gf,bQr,Pee,vQr,FQr,Bee,TQr,MQr,EQr,h$,CQr,f0e,wQr,AQr,LQr,Kt,p$,yQr,m0e,xQr,$Qr,hf,kQr,g0e,SQr,RQr,Iee,PQr,BQr,IQr,$w,NQr,Ur,u$,qQr,h0e,jQr,DQr,Ln,GQr,p0e,OQr,VQr,u0e,XQr,zQr,_0e,WQr,QQr,HQr,Xe,kw,b0e,UQr,JQr,Nee,YQr,KQr,ZQr,Sw,v0e,eHr,oHr,qee,rHr,tHr,aHr,Rw,F0e,nHr,sHr,jee,lHr,iHr,dHr,Pw,T0e,cHr,fHr,Dee,mHr,gHr,hHr,Bw,M0e,pHr,uHr,Gee,_Hr,bHr,vHr,Iw,E0e,FHr,THr,Oee,MHr,EHr,CHr,Nw,C0e,wHr,AHr,Vee,LHr,yHr,xHr,qw,w0e,$Hr,kHr,Xee,SHr,RHr,PHr,jw,gVe,pf,Dw,A0e,_$,BHr,L0e,IHr,hVe,Mr,b$,NHr,uf,qHr,zee,jHr,DHr,Wee,GHr,OHr,VHr,v$,XHr,y0e,zHr,WHr,QHr,Zt,F$,HHr,x0e,UHr,JHr,_f,YHr,$0e,KHr,ZHr,Qee,eUr,oUr,rUr,Gw,tUr,Jr,T$,aUr,k0e,nUr,sUr,yn,lUr,S0e,iUr,dUr,R0e,cUr,fUr,P0e,mUr,gUr,hUr,B0e,Ow,I0e,pUr,uUr,Hee,_Ur,bUr,vUr,Vw,pVe,bf,Xw,N0e,M$,FUr,q0e,TUr,uVe,Er,E$,MUr,vf,EUr,Uee,CUr,wUr,Jee,AUr,LUr,yUr,C$,xUr,j0e,$Ur,kUr,SUr,ea,w$,RUr,D0e,PUr,BUr,Ff,IUr,G0e,NUr,qUr,Yee,jUr,DUr,GUr,zw,OUr,Yr,A$,VUr,O0e,XUr,zUr,xn,WUr,V0e,QUr,HUr,X0e,UUr,JUr,z0e,YUr,KUr,ZUr,L$,Ww,W0e,eJr,oJr,Kee,rJr,tJr,aJr,Qw,Q0e,nJr,sJr,Zee,lJr,iJr,dJr,Hw,_Ve,Tf,Uw,H0e,y$,cJr,U0e,fJr,bVe,Cr,x$,mJr,Mf,gJr,eoe,hJr,pJr,ooe,uJr,_Jr,bJr,$$,vJr,J0e,FJr,TJr,MJr,oa,k$,EJr,Y0e,CJr,wJr,Ef,AJr,K0e,LJr,yJr,roe,xJr,$Jr,kJr,Jw,SJr,Kr,S$,RJr,Z0e,PJr,BJr,$n,IJr,ewe,NJr,qJr,owe,jJr,DJr,rwe,GJr,OJr,VJr,twe,Yw,awe,XJr,zJr,toe,WJr,QJr,HJr,Kw,vVe;return d=new re({}),ya=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),EL=new re({}),CL=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Sf=new UJr({props:{warning:!0,$$slots:{default:[ijt]},$$scope:{ctx:x}}}),wL=new re({}),AL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/configuration_auto.py#L597"}}),xL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/configuration_auto.py#L620"}}),Dg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[djt]},$$scope:{ctx:x}}}),$L=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/configuration_auto.py#L743"}}),kL=new re({}),SL=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/tokenization_auto.py#L399"}}),BL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17772/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/tokenization_auto.py#L413"}}),Mh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[cjt]},$$scope:{ctx:x}}}),IL=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/tokenization_auto.py#L612"}}),NL=new re({}),qL=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/feature_extraction_auto.py#L194"}}),GL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17772/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/feature_extraction_auto.py#L208"}}),ap=new UJr({props:{$$slots:{default:[fjt]},$$scope:{ctx:x}}}),np=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[mjt]},$$scope:{ctx:x}}}),OL=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/feature_extraction_auto.py#L335"}}),VL=new re({}),XL=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/processing_auto.py#L88"}}),QL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/processing_auto.py#L102"}}),wp=new UJr({props:{$$slots:{default:[gjt]},$$scope:{ctx:x}}}),Ap=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[hjt]},$$scope:{ctx:x}}}),HL=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/processing_auto.py#L255"}}),UL=new re({}),JL=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L760"}}),KL=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/omnivore#transformers.OmnivoreConfig">OmnivoreConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/omnivore#transformers.OmnivoreModel">OmnivoreModel</a> (Omnivore model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),xp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[pjt]},$$scope:{ctx:x}}}),ZL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),x_=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[ujt]},$$scope:{ctx:x}}}),ey=new re({}),oy=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L767"}}),ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),k_=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[_jt]},$$scope:{ctx:x}}}),ay=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),M7=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[bjt]},$$scope:{ctx:x}}}),ny=new re({}),sy=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L782"}}),iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),C7=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[vjt]},$$scope:{ctx:x}}}),dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),c2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Fjt]},$$scope:{ctx:x}}}),cy=new re({}),fy=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L789"}}),gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),m2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[Tjt]},$$scope:{ctx:x}}}),hy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),J2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Mjt]},$$scope:{ctx:x}}}),py=new re({}),uy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L796"}}),by=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),K2=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Ejt]},$$scope:{ctx:x}}}),vy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),_1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Cjt]},$$scope:{ctx:x}}}),Fy=new re({}),Ty=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L805"}}),Ey=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),v1=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[wjt]},$$scope:{ctx:x}}}),Cy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),pb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Ajt]},$$scope:{ctx:x}}}),wy=new re({}),Ay=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L850"}}),yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),_b=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Ljt]},$$scope:{ctx:x}}}),xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),Hb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[yjt]},$$scope:{ctx:x}}}),$y=new re({}),ky=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L857"}}),Ry=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),Jb=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[xjt]},$$scope:{ctx:x}}}),Py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),tv=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[$jt]},$$scope:{ctx:x}}}),By=new re({}),Iy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L843"}}),qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),nv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[kjt]},$$scope:{ctx:x}}}),jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),Ov=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Sjt]},$$scope:{ctx:x}}}),Dy=new re({}),Gy=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L814"}}),Vy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),Xv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Rjt]},$$scope:{ctx:x}}}),Xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),SF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Pjt]},$$scope:{ctx:x}}}),zy=new re({}),Wy=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L821"}}),Hy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),PF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Bjt]},$$scope:{ctx:x}}}),Uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),NF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Ijt]},$$scope:{ctx:x}}}),Jy=new re({}),Yy=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L866"}}),Zy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/omnivore#transformers.OmnivoreConfig">OmnivoreConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/omnivore#transformers.OmnivoreForVisionClassification">OmnivoreForVisionClassification</a> (Omnivore model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),jF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[Njt]},$$scope:{ctx:x}}}),e8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),eT=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[qjt]},$$scope:{ctx:x}}}),o8=new re({}),r8=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L905"}}),a8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),rT=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[jjt]},$$scope:{ctx:x}}}),n8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),nT=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Djt]},$$scope:{ctx:x}}}),s8=new re({}),l8=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L832"}}),d8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),lT=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Gjt]},$$scope:{ctx:x}}}),c8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),cT=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[Ojt]},$$scope:{ctx:x}}}),f8=new re({}),m8=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L912"}}),h8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),mT=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Vjt]},$$scope:{ctx:x}}}),p8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),ET=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Xjt]},$$scope:{ctx:x}}}),u8=new re({}),_8=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L935"}}),v8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),wT=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[zjt]},$$scope:{ctx:x}}}),F8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),ST=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[Wjt]},$$scope:{ctx:x}}}),T8=new re({}),M8=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L919"}}),C8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),PT=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Qjt]},$$scope:{ctx:x}}}),w8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),WT=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[Hjt]},$$scope:{ctx:x}}}),A8=new re({}),L8=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L926"}}),x8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),HT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Ujt]},$$scope:{ctx:x}}}),$8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),KT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Jjt]},$$scope:{ctx:x}}}),S8=new re({}),R8=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L944"}}),B8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),eM=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Yjt]},$$scope:{ctx:x}}}),I8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),lM=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Kjt]},$$scope:{ctx:x}}}),N8=new re({}),q8=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L951"}}),D8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),dM=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Zjt]},$$scope:{ctx:x}}}),G8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),hM=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[eDt]},$$scope:{ctx:x}}}),O8=new re({}),V8=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L898"}}),z8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),uM=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[oDt]},$$scope:{ctx:x}}}),W8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),FM=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[rDt]},$$scope:{ctx:x}}}),H8=new re({}),U8=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L873"}}),Y8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),MM=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[tDt]},$$scope:{ctx:x}}}),K8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),wM=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[aDt]},$$scope:{ctx:x}}}),Z8=new re({}),e9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L880"}}),r9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),LM=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[nDt]},$$scope:{ctx:x}}}),t9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),RM=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[sDt]},$$scope:{ctx:x}}}),a9=new re({}),n9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_auto.py#L889"}}),l9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),BM=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[lDt]},$$scope:{ctx:x}}}),i9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),qM=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[iDt]},$$scope:{ctx:x}}}),d9=new re({}),c9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L406"}}),m9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),DM=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[dDt]},$$scope:{ctx:x}}}),g9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),RE=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[cDt]},$$scope:{ctx:x}}}),h9=new re({}),p9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L413"}}),_9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),BE=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[fDt]},$$scope:{ctx:x}}}),b9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),n4=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[mDt]},$$scope:{ctx:x}}}),v9=new re({}),F9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),M9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),l4=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[gDt]},$$scope:{ctx:x}}}),E9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),T4=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[hDt]},$$scope:{ctx:x}}}),C9=new re({}),w9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),L9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),E4=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[pDt]},$$scope:{ctx:x}}}),y9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),y4=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[uDt]},$$scope:{ctx:x}}}),x9=new re({}),$9=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),S9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),$4=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[_Dt]},$$scope:{ctx:x}}}),R9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),Y4=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[bDt]},$$scope:{ctx:x}}}),P9=new re({}),B9=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),N9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),Z4=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[vDt]},$$scope:{ctx:x}}}),q9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),cC=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[FDt]},$$scope:{ctx:x}}}),j9=new re({}),D9=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),O9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),mC=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[TDt]},$$scope:{ctx:x}}}),V9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[MDt]},$$scope:{ctx:x}}}),X9=new re({}),z9=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),Q9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[EDt]},$$scope:{ctx:x}}}),H9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),n5=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[CDt]},$$scope:{ctx:x}}}),U9=new re({}),J9=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),K9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),l5=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[wDt]},$$scope:{ctx:x}}}),Z9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),c5=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[ADt]},$$scope:{ctx:x}}}),ox=new re({}),rx=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),ax=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),m5=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[LDt]},$$scope:{ctx:x}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),h5=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[yDt]},$$scope:{ctx:x}}}),sx=new re({}),lx=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),dx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),u5=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[xDt]},$$scope:{ctx:x}}}),cx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),N5=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[$Dt]},$$scope:{ctx:x}}}),fx=new re({}),mx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L494"}}),hx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),j5=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[kDt]},$$scope:{ctx:x}}}),px=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),s3=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[SDt]},$$scope:{ctx:x}}}),ux=new re({}),_x=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),vx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),i3=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[RDt]},$$scope:{ctx:x}}}),Fx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),c3=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[PDt]},$$scope:{ctx:x}}}),Tx=new re({}),Mx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_tf_auto.py#L537"}}),Cx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),m3=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[BDt]},$$scope:{ctx:x}}}),wx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),h3=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[IDt]},$$scope:{ctx:x}}}),Ax=new re({}),Lx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),xx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),u3=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[NDt]},$$scope:{ctx:x}}}),$x=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),X3=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[qDt]},$$scope:{ctx:x}}}),kx=new re({}),Sx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Px=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),W3=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[jDt]},$$scope:{ctx:x}}}),Bx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),t0=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[DDt]},$$scope:{ctx:x}}}),Ix=new re({}),Nx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),jx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),n0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[GDt]},$$scope:{ctx:x}}}),Dx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),v0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[ODt]},$$scope:{ctx:x}}}),Gx=new re({}),Ox=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),Xx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),T0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[VDt]},$$scope:{ctx:x}}}),zx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),S0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[XDt]},$$scope:{ctx:x}}}),Wx=new re({}),Qx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),Ux=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),P0=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[zDt]},$$scope:{ctx:x}}}),Jx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),z0=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[WDt]},$$scope:{ctx:x}}}),Yx=new re({}),Kx=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),e$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),Q0=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[QDt]},$$scope:{ctx:x}}}),o$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),aw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[HDt]},$$scope:{ctx:x}}}),r$=new re({}),t$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),n$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),sw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[UDt]},$$scope:{ctx:x}}}),s$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),_w=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[JDt]},$$scope:{ctx:x}}}),l$=new re({}),i$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),c$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),vw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[YDt]},$$scope:{ctx:x}}}),f$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),yw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[KDt]},$$scope:{ctx:x}}}),m$=new re({}),g$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),p$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),$w=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[ZDt]},$$scope:{ctx:x}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),jw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[eGt]},$$scope:{ctx:x}}}),_$=new re({}),b$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),F$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),Gw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[oGt]},$$scope:{ctx:x}}}),T$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),Vw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[rGt]},$$scope:{ctx:x}}}),M$=new re({}),E$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),w$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),zw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[tGt]},$$scope:{ctx:x}}}),A$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),Hw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[aGt]},$$scope:{ctx:x}}}),y$=new re({}),x$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),k$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L389"}}),Jw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[nGt]},$$scope:{ctx:x}}}),S$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17772/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17772/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17772/src/transformers/models/auto/auto_factory.py#L417"}}),Kw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[sGt]},$$scope:{ctx:x}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),u=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Fi=o("Auto Classes"),Lf=l(),at=a("p"),Ti=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Mi=a("code"),vL=o("from_pretrained()"),yf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),We=a("p"),Ei=o("Instantiating one of "),Sn=a("a"),FL=o("AutoConfig"),Rn=o(", "),Pn=a("a"),TL=o("AutoModel"),Ci=o(`, and
`),Bn=a("a"),ML=o("AutoTokenizer"),wi=o(" will directly create a class of the relevant architecture. For instance"),xf=l(),F(ya.$$.fragment),Qe=l(),Ae=a("p"),Uk=o("will create a model that is an instance of "),Ai=a("a"),Jk=o("BertModel"),Yk=o("."),Co=l(),xa=a("p"),Kk=o("There is one class of "),$f=a("code"),Zk=o("AutoModel"),xze=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),hGe=l(),Li=a("h2"),kf=a("a"),Kre=a("span"),F(EL.$$.fragment),$ze=l(),Zre=a("span"),kze=o("Extending the Auto Classes"),pGe=l(),In=a("p"),Sze=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ete=a("code"),Rze=o("NewModel"),Pze=o(", make sure you have a "),ote=a("code"),Bze=o("NewModelConfig"),Ize=o(` then you can add those to the auto
classes like this:`),uGe=l(),F(CL.$$.fragment),_Ge=l(),eS=a("p"),Nze=o("You will then be able to use the auto classes like you would usually do!"),bGe=l(),F(Sf.$$.fragment),vGe=l(),yi=a("h2"),Rf=a("a"),rte=a("span"),F(wL.$$.fragment),qze=l(),tte=a("span"),jze=o("AutoConfig"),FGe=l(),wo=a("div"),F(AL.$$.fragment),Dze=l(),LL=a("p"),Gze=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),oS=a("a"),Oze=o("from_pretrained()"),Vze=o(" class method."),Xze=l(),yL=a("p"),zze=o("This class cannot be instantiated directly using "),ate=a("code"),Wze=o("__init__()"),Qze=o(" (throws an error)."),Hze=l(),wr=a("div"),F(xL.$$.fragment),Uze=l(),nte=a("p"),Jze=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Yze=l(),xi=a("p"),Kze=o("The configuration class to instantiate is selected based on the "),ste=a("code"),Zze=o("model_type"),eWe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),lte=a("code"),oWe=o("pretrained_model_name_or_path"),rWe=o(":"),tWe=l(),A=a("ul"),Pf=a("li"),ite=a("strong"),aWe=o("albert"),nWe=o(" \u2014 "),rS=a("a"),sWe=o("AlbertConfig"),lWe=o(" (ALBERT model)"),iWe=l(),Bf=a("li"),dte=a("strong"),dWe=o("bart"),cWe=o(" \u2014 "),tS=a("a"),fWe=o("BartConfig"),mWe=o(" (BART model)"),gWe=l(),If=a("li"),cte=a("strong"),hWe=o("beit"),pWe=o(" \u2014 "),aS=a("a"),uWe=o("BeitConfig"),_We=o(" (BEiT model)"),bWe=l(),Nf=a("li"),fte=a("strong"),vWe=o("bert"),FWe=o(" \u2014 "),nS=a("a"),TWe=o("BertConfig"),MWe=o(" (BERT model)"),EWe=l(),qf=a("li"),mte=a("strong"),CWe=o("bert-generation"),wWe=o(" \u2014 "),sS=a("a"),AWe=o("BertGenerationConfig"),LWe=o(" (Bert Generation model)"),yWe=l(),jf=a("li"),gte=a("strong"),xWe=o("big_bird"),$We=o(" \u2014 "),lS=a("a"),kWe=o("BigBirdConfig"),SWe=o(" (BigBird model)"),RWe=l(),Df=a("li"),hte=a("strong"),PWe=o("bigbird_pegasus"),BWe=o(" \u2014 "),iS=a("a"),IWe=o("BigBirdPegasusConfig"),NWe=o(" (BigBird-Pegasus model)"),qWe=l(),Gf=a("li"),pte=a("strong"),jWe=o("blenderbot"),DWe=o(" \u2014 "),dS=a("a"),GWe=o("BlenderbotConfig"),OWe=o(" (Blenderbot model)"),VWe=l(),Of=a("li"),ute=a("strong"),XWe=o("blenderbot-small"),zWe=o(" \u2014 "),cS=a("a"),WWe=o("BlenderbotSmallConfig"),QWe=o(" (BlenderbotSmall model)"),HWe=l(),Vf=a("li"),_te=a("strong"),UWe=o("bloom"),JWe=o(" \u2014 "),fS=a("a"),YWe=o("BloomConfig"),KWe=o(" (BLOOM model)"),ZWe=l(),Xf=a("li"),bte=a("strong"),eQe=o("camembert"),oQe=o(" \u2014 "),mS=a("a"),rQe=o("CamembertConfig"),tQe=o(" (CamemBERT model)"),aQe=l(),zf=a("li"),vte=a("strong"),nQe=o("canine"),sQe=o(" \u2014 "),gS=a("a"),lQe=o("CanineConfig"),iQe=o(" (CANINE model)"),dQe=l(),Wf=a("li"),Fte=a("strong"),cQe=o("clip"),fQe=o(" \u2014 "),hS=a("a"),mQe=o("CLIPConfig"),gQe=o(" (CLIP model)"),hQe=l(),Qf=a("li"),Tte=a("strong"),pQe=o("convbert"),uQe=o(" \u2014 "),pS=a("a"),_Qe=o("ConvBertConfig"),bQe=o(" (ConvBERT model)"),vQe=l(),Hf=a("li"),Mte=a("strong"),FQe=o("convnext"),TQe=o(" \u2014 "),uS=a("a"),MQe=o("ConvNextConfig"),EQe=o(" (ConvNeXT model)"),CQe=l(),Uf=a("li"),Ete=a("strong"),wQe=o("ctrl"),AQe=o(" \u2014 "),_S=a("a"),LQe=o("CTRLConfig"),yQe=o(" (CTRL model)"),xQe=l(),Jf=a("li"),Cte=a("strong"),$Qe=o("cvt"),kQe=o(" \u2014 "),bS=a("a"),SQe=o("CvtConfig"),RQe=o(" (CvT model)"),PQe=l(),Yf=a("li"),wte=a("strong"),BQe=o("data2vec-audio"),IQe=o(" \u2014 "),vS=a("a"),NQe=o("Data2VecAudioConfig"),qQe=o(" (Data2VecAudio model)"),jQe=l(),Kf=a("li"),Ate=a("strong"),DQe=o("data2vec-text"),GQe=o(" \u2014 "),FS=a("a"),OQe=o("Data2VecTextConfig"),VQe=o(" (Data2VecText model)"),XQe=l(),Zf=a("li"),Lte=a("strong"),zQe=o("data2vec-vision"),WQe=o(" \u2014 "),TS=a("a"),QQe=o("Data2VecVisionConfig"),HQe=o(" (Data2VecVision model)"),UQe=l(),em=a("li"),yte=a("strong"),JQe=o("deberta"),YQe=o(" \u2014 "),MS=a("a"),KQe=o("DebertaConfig"),ZQe=o(" (DeBERTa model)"),eHe=l(),om=a("li"),xte=a("strong"),oHe=o("deberta-v2"),rHe=o(" \u2014 "),ES=a("a"),tHe=o("DebertaV2Config"),aHe=o(" (DeBERTa-v2 model)"),nHe=l(),rm=a("li"),$te=a("strong"),sHe=o("decision_transformer"),lHe=o(" \u2014 "),CS=a("a"),iHe=o("DecisionTransformerConfig"),dHe=o(" (Decision Transformer model)"),cHe=l(),tm=a("li"),kte=a("strong"),fHe=o("deit"),mHe=o(" \u2014 "),wS=a("a"),gHe=o("DeiTConfig"),hHe=o(" (DeiT model)"),pHe=l(),am=a("li"),Ste=a("strong"),uHe=o("detr"),_He=o(" \u2014 "),AS=a("a"),bHe=o("DetrConfig"),vHe=o(" (DETR model)"),FHe=l(),nm=a("li"),Rte=a("strong"),THe=o("distilbert"),MHe=o(" \u2014 "),LS=a("a"),EHe=o("DistilBertConfig"),CHe=o(" (DistilBERT model)"),wHe=l(),sm=a("li"),Pte=a("strong"),AHe=o("dpr"),LHe=o(" \u2014 "),yS=a("a"),yHe=o("DPRConfig"),xHe=o(" (DPR model)"),$He=l(),lm=a("li"),Bte=a("strong"),kHe=o("dpt"),SHe=o(" \u2014 "),xS=a("a"),RHe=o("DPTConfig"),PHe=o(" (DPT model)"),BHe=l(),im=a("li"),Ite=a("strong"),IHe=o("electra"),NHe=o(" \u2014 "),$S=a("a"),qHe=o("ElectraConfig"),jHe=o(" (ELECTRA model)"),DHe=l(),dm=a("li"),Nte=a("strong"),GHe=o("encoder-decoder"),OHe=o(" \u2014 "),kS=a("a"),VHe=o("EncoderDecoderConfig"),XHe=o(" (Encoder decoder model)"),zHe=l(),cm=a("li"),qte=a("strong"),WHe=o("flaubert"),QHe=o(" \u2014 "),SS=a("a"),HHe=o("FlaubertConfig"),UHe=o(" (FlauBERT model)"),JHe=l(),fm=a("li"),jte=a("strong"),YHe=o("flava"),KHe=o(" \u2014 "),RS=a("a"),ZHe=o("FlavaConfig"),eUe=o(" (FLAVA model)"),oUe=l(),mm=a("li"),Dte=a("strong"),rUe=o("fnet"),tUe=o(" \u2014 "),PS=a("a"),aUe=o("FNetConfig"),nUe=o(" (FNet model)"),sUe=l(),gm=a("li"),Gte=a("strong"),lUe=o("fsmt"),iUe=o(" \u2014 "),BS=a("a"),dUe=o("FSMTConfig"),cUe=o(" (FairSeq Machine-Translation model)"),fUe=l(),hm=a("li"),Ote=a("strong"),mUe=o("funnel"),gUe=o(" \u2014 "),IS=a("a"),hUe=o("FunnelConfig"),pUe=o(" (Funnel Transformer model)"),uUe=l(),pm=a("li"),Vte=a("strong"),_Ue=o("glpn"),bUe=o(" \u2014 "),NS=a("a"),vUe=o("GLPNConfig"),FUe=o(" (GLPN model)"),TUe=l(),um=a("li"),Xte=a("strong"),MUe=o("gpt2"),EUe=o(" \u2014 "),qS=a("a"),CUe=o("GPT2Config"),wUe=o(" (OpenAI GPT-2 model)"),AUe=l(),_m=a("li"),zte=a("strong"),LUe=o("gpt_neo"),yUe=o(" \u2014 "),jS=a("a"),xUe=o("GPTNeoConfig"),$Ue=o(" (GPT Neo model)"),kUe=l(),bm=a("li"),Wte=a("strong"),SUe=o("gpt_neox"),RUe=o(" \u2014 "),DS=a("a"),PUe=o("GPTNeoXConfig"),BUe=o(" (GPT NeoX model)"),IUe=l(),vm=a("li"),Qte=a("strong"),NUe=o("gptj"),qUe=o(" \u2014 "),GS=a("a"),jUe=o("GPTJConfig"),DUe=o(" (GPT-J model)"),GUe=l(),Fm=a("li"),Hte=a("strong"),OUe=o("hubert"),VUe=o(" \u2014 "),OS=a("a"),XUe=o("HubertConfig"),zUe=o(" (Hubert model)"),WUe=l(),Tm=a("li"),Ute=a("strong"),QUe=o("ibert"),HUe=o(" \u2014 "),VS=a("a"),UUe=o("IBertConfig"),JUe=o(" (I-BERT model)"),YUe=l(),Mm=a("li"),Jte=a("strong"),KUe=o("imagegpt"),ZUe=o(" \u2014 "),XS=a("a"),eJe=o("ImageGPTConfig"),oJe=o(" (ImageGPT model)"),rJe=l(),Em=a("li"),Yte=a("strong"),tJe=o("layoutlm"),aJe=o(" \u2014 "),zS=a("a"),nJe=o("LayoutLMConfig"),sJe=o(" (LayoutLM model)"),lJe=l(),Cm=a("li"),Kte=a("strong"),iJe=o("layoutlmv2"),dJe=o(" \u2014 "),WS=a("a"),cJe=o("LayoutLMv2Config"),fJe=o(" (LayoutLMv2 model)"),mJe=l(),wm=a("li"),Zte=a("strong"),gJe=o("layoutlmv3"),hJe=o(" \u2014 "),QS=a("a"),pJe=o("LayoutLMv3Config"),uJe=o(" (LayoutLMv3 model)"),_Je=l(),Am=a("li"),eae=a("strong"),bJe=o("led"),vJe=o(" \u2014 "),HS=a("a"),FJe=o("LEDConfig"),TJe=o(" (LED model)"),MJe=l(),Lm=a("li"),oae=a("strong"),EJe=o("levit"),CJe=o(" \u2014 "),US=a("a"),wJe=o("LevitConfig"),AJe=o(" (LeViT model)"),LJe=l(),ym=a("li"),rae=a("strong"),yJe=o("longformer"),xJe=o(" \u2014 "),JS=a("a"),$Je=o("LongformerConfig"),kJe=o(" (Longformer model)"),SJe=l(),xm=a("li"),tae=a("strong"),RJe=o("longt5"),PJe=o(" \u2014 "),YS=a("a"),BJe=o("LongT5Config"),IJe=o(" (LongT5 model)"),NJe=l(),$m=a("li"),aae=a("strong"),qJe=o("luke"),jJe=o(" \u2014 "),KS=a("a"),DJe=o("LukeConfig"),GJe=o(" (LUKE model)"),OJe=l(),km=a("li"),nae=a("strong"),VJe=o("lxmert"),XJe=o(" \u2014 "),ZS=a("a"),zJe=o("LxmertConfig"),WJe=o(" (LXMERT model)"),QJe=l(),Sm=a("li"),sae=a("strong"),HJe=o("m2m_100"),UJe=o(" \u2014 "),eR=a("a"),JJe=o("M2M100Config"),YJe=o(" (M2M100 model)"),KJe=l(),Rm=a("li"),lae=a("strong"),ZJe=o("marian"),eYe=o(" \u2014 "),oR=a("a"),oYe=o("MarianConfig"),rYe=o(" (Marian model)"),tYe=l(),Pm=a("li"),iae=a("strong"),aYe=o("maskformer"),nYe=o(" \u2014 "),rR=a("a"),sYe=o("MaskFormerConfig"),lYe=o(" (MaskFormer model)"),iYe=l(),Bm=a("li"),dae=a("strong"),dYe=o("mbart"),cYe=o(" \u2014 "),tR=a("a"),fYe=o("MBartConfig"),mYe=o(" (mBART model)"),gYe=l(),Im=a("li"),cae=a("strong"),hYe=o("mctct"),pYe=o(" \u2014 "),aR=a("a"),uYe=o("MCTCTConfig"),_Ye=o(" (M-CTC-T model)"),bYe=l(),Nm=a("li"),fae=a("strong"),vYe=o("megatron-bert"),FYe=o(" \u2014 "),nR=a("a"),TYe=o("MegatronBertConfig"),MYe=o(" (Megatron-BERT model)"),EYe=l(),qm=a("li"),mae=a("strong"),CYe=o("mobilebert"),wYe=o(" \u2014 "),sR=a("a"),AYe=o("MobileBertConfig"),LYe=o(" (MobileBERT model)"),yYe=l(),jm=a("li"),gae=a("strong"),xYe=o("mpnet"),$Ye=o(" \u2014 "),lR=a("a"),kYe=o("MPNetConfig"),SYe=o(" (MPNet model)"),RYe=l(),Dm=a("li"),hae=a("strong"),PYe=o("mt5"),BYe=o(" \u2014 "),iR=a("a"),IYe=o("MT5Config"),NYe=o(" (MT5 model)"),qYe=l(),Gm=a("li"),pae=a("strong"),jYe=o("nystromformer"),DYe=o(" \u2014 "),dR=a("a"),GYe=o("NystromformerConfig"),OYe=o(" (Nystr\xF6mformer model)"),VYe=l(),Om=a("li"),uae=a("strong"),XYe=o("omnivore"),zYe=o(" \u2014 "),cR=a("a"),WYe=o("OmnivoreConfig"),QYe=o(" (Omnivore model)"),HYe=l(),Vm=a("li"),_ae=a("strong"),UYe=o("openai-gpt"),JYe=o(" \u2014 "),fR=a("a"),YYe=o("OpenAIGPTConfig"),KYe=o(" (OpenAI GPT model)"),ZYe=l(),Xm=a("li"),bae=a("strong"),eKe=o("opt"),oKe=o(" \u2014 "),mR=a("a"),rKe=o("OPTConfig"),tKe=o(" (OPT model)"),aKe=l(),zm=a("li"),vae=a("strong"),nKe=o("pegasus"),sKe=o(" \u2014 "),gR=a("a"),lKe=o("PegasusConfig"),iKe=o(" (Pegasus model)"),dKe=l(),Wm=a("li"),Fae=a("strong"),cKe=o("perceiver"),fKe=o(" \u2014 "),hR=a("a"),mKe=o("PerceiverConfig"),gKe=o(" (Perceiver model)"),hKe=l(),Qm=a("li"),Tae=a("strong"),pKe=o("plbart"),uKe=o(" \u2014 "),pR=a("a"),_Ke=o("PLBartConfig"),bKe=o(" (PLBart model)"),vKe=l(),Hm=a("li"),Mae=a("strong"),FKe=o("poolformer"),TKe=o(" \u2014 "),uR=a("a"),MKe=o("PoolFormerConfig"),EKe=o(" (PoolFormer model)"),CKe=l(),Um=a("li"),Eae=a("strong"),wKe=o("prophetnet"),AKe=o(" \u2014 "),_R=a("a"),LKe=o("ProphetNetConfig"),yKe=o(" (ProphetNet model)"),xKe=l(),Jm=a("li"),Cae=a("strong"),$Ke=o("qdqbert"),kKe=o(" \u2014 "),bR=a("a"),SKe=o("QDQBertConfig"),RKe=o(" (QDQBert model)"),PKe=l(),Ym=a("li"),wae=a("strong"),BKe=o("rag"),IKe=o(" \u2014 "),vR=a("a"),NKe=o("RagConfig"),qKe=o(" (RAG model)"),jKe=l(),Km=a("li"),Aae=a("strong"),DKe=o("realm"),GKe=o(" \u2014 "),FR=a("a"),OKe=o("RealmConfig"),VKe=o(" (REALM model)"),XKe=l(),Zm=a("li"),Lae=a("strong"),zKe=o("reformer"),WKe=o(" \u2014 "),TR=a("a"),QKe=o("ReformerConfig"),HKe=o(" (Reformer model)"),UKe=l(),eg=a("li"),yae=a("strong"),JKe=o("regnet"),YKe=o(" \u2014 "),MR=a("a"),KKe=o("RegNetConfig"),ZKe=o(" (RegNet model)"),eZe=l(),og=a("li"),xae=a("strong"),oZe=o("rembert"),rZe=o(" \u2014 "),ER=a("a"),tZe=o("RemBertConfig"),aZe=o(" (RemBERT model)"),nZe=l(),rg=a("li"),$ae=a("strong"),sZe=o("resnet"),lZe=o(" \u2014 "),CR=a("a"),iZe=o("ResNetConfig"),dZe=o(" (ResNet model)"),cZe=l(),tg=a("li"),kae=a("strong"),fZe=o("retribert"),mZe=o(" \u2014 "),wR=a("a"),gZe=o("RetriBertConfig"),hZe=o(" (RetriBERT model)"),pZe=l(),ag=a("li"),Sae=a("strong"),uZe=o("roberta"),_Ze=o(" \u2014 "),AR=a("a"),bZe=o("RobertaConfig"),vZe=o(" (RoBERTa model)"),FZe=l(),ng=a("li"),Rae=a("strong"),TZe=o("roformer"),MZe=o(" \u2014 "),LR=a("a"),EZe=o("RoFormerConfig"),CZe=o(" (RoFormer model)"),wZe=l(),sg=a("li"),Pae=a("strong"),AZe=o("segformer"),LZe=o(" \u2014 "),yR=a("a"),yZe=o("SegformerConfig"),xZe=o(" (SegFormer model)"),$Ze=l(),lg=a("li"),Bae=a("strong"),kZe=o("sew"),SZe=o(" \u2014 "),xR=a("a"),RZe=o("SEWConfig"),PZe=o(" (SEW model)"),BZe=l(),ig=a("li"),Iae=a("strong"),IZe=o("sew-d"),NZe=o(" \u2014 "),$R=a("a"),qZe=o("SEWDConfig"),jZe=o(" (SEW-D model)"),DZe=l(),dg=a("li"),Nae=a("strong"),GZe=o("speech-encoder-decoder"),OZe=o(" \u2014 "),kR=a("a"),VZe=o("SpeechEncoderDecoderConfig"),XZe=o(" (Speech Encoder decoder model)"),zZe=l(),cg=a("li"),qae=a("strong"),WZe=o("speech_to_text"),QZe=o(" \u2014 "),SR=a("a"),HZe=o("Speech2TextConfig"),UZe=o(" (Speech2Text model)"),JZe=l(),fg=a("li"),jae=a("strong"),YZe=o("speech_to_text_2"),KZe=o(" \u2014 "),RR=a("a"),ZZe=o("Speech2Text2Config"),eeo=o(" (Speech2Text2 model)"),oeo=l(),mg=a("li"),Dae=a("strong"),reo=o("splinter"),teo=o(" \u2014 "),PR=a("a"),aeo=o("SplinterConfig"),neo=o(" (Splinter model)"),seo=l(),gg=a("li"),Gae=a("strong"),leo=o("squeezebert"),ieo=o(" \u2014 "),BR=a("a"),deo=o("SqueezeBertConfig"),ceo=o(" (SqueezeBERT model)"),feo=l(),hg=a("li"),Oae=a("strong"),meo=o("swin"),geo=o(" \u2014 "),IR=a("a"),heo=o("SwinConfig"),peo=o(" (Swin Transformer model)"),ueo=l(),pg=a("li"),Vae=a("strong"),_eo=o("t5"),beo=o(" \u2014 "),NR=a("a"),veo=o("T5Config"),Feo=o(" (T5 model)"),Teo=l(),ug=a("li"),Xae=a("strong"),Meo=o("tapas"),Eeo=o(" \u2014 "),qR=a("a"),Ceo=o("TapasConfig"),weo=o(" (TAPAS model)"),Aeo=l(),_g=a("li"),zae=a("strong"),Leo=o("trajectory_transformer"),yeo=o(" \u2014 "),jR=a("a"),xeo=o("TrajectoryTransformerConfig"),$eo=o(" (Trajectory Transformer model)"),keo=l(),bg=a("li"),Wae=a("strong"),Seo=o("transfo-xl"),Reo=o(" \u2014 "),DR=a("a"),Peo=o("TransfoXLConfig"),Beo=o(" (Transformer-XL model)"),Ieo=l(),vg=a("li"),Qae=a("strong"),Neo=o("trocr"),qeo=o(" \u2014 "),GR=a("a"),jeo=o("TrOCRConfig"),Deo=o(" (TrOCR model)"),Geo=l(),Fg=a("li"),Hae=a("strong"),Oeo=o("unispeech"),Veo=o(" \u2014 "),OR=a("a"),Xeo=o("UniSpeechConfig"),zeo=o(" (UniSpeech model)"),Weo=l(),Tg=a("li"),Uae=a("strong"),Qeo=o("unispeech-sat"),Heo=o(" \u2014 "),VR=a("a"),Ueo=o("UniSpeechSatConfig"),Jeo=o(" (UniSpeechSat model)"),Yeo=l(),Mg=a("li"),Jae=a("strong"),Keo=o("van"),Zeo=o(" \u2014 "),XR=a("a"),eoo=o("VanConfig"),ooo=o(" (VAN model)"),roo=l(),Eg=a("li"),Yae=a("strong"),too=o("vilt"),aoo=o(" \u2014 "),zR=a("a"),noo=o("ViltConfig"),soo=o(" (ViLT model)"),loo=l(),Cg=a("li"),Kae=a("strong"),ioo=o("vision-encoder-decoder"),doo=o(" \u2014 "),WR=a("a"),coo=o("VisionEncoderDecoderConfig"),foo=o(" (Vision Encoder decoder model)"),moo=l(),wg=a("li"),Zae=a("strong"),goo=o("vision-text-dual-encoder"),hoo=o(" \u2014 "),QR=a("a"),poo=o("VisionTextDualEncoderConfig"),uoo=o(" (VisionTextDualEncoder model)"),_oo=l(),Ag=a("li"),ene=a("strong"),boo=o("visual_bert"),voo=o(" \u2014 "),HR=a("a"),Foo=o("VisualBertConfig"),Too=o(" (VisualBERT model)"),Moo=l(),Lg=a("li"),one=a("strong"),Eoo=o("vit"),Coo=o(" \u2014 "),UR=a("a"),woo=o("ViTConfig"),Aoo=o(" (ViT model)"),Loo=l(),yg=a("li"),rne=a("strong"),yoo=o("vit_mae"),xoo=o(" \u2014 "),JR=a("a"),$oo=o("ViTMAEConfig"),koo=o(" (ViTMAE model)"),Soo=l(),xg=a("li"),tne=a("strong"),Roo=o("wav2vec2"),Poo=o(" \u2014 "),YR=a("a"),Boo=o("Wav2Vec2Config"),Ioo=o(" (Wav2Vec2 model)"),Noo=l(),$g=a("li"),ane=a("strong"),qoo=o("wav2vec2-conformer"),joo=o(" \u2014 "),KR=a("a"),Doo=o("Wav2Vec2ConformerConfig"),Goo=o(" (Wav2Vec2-Conformer model)"),Ooo=l(),kg=a("li"),nne=a("strong"),Voo=o("wavlm"),Xoo=o(" \u2014 "),ZR=a("a"),zoo=o("WavLMConfig"),Woo=o(" (WavLM model)"),Qoo=l(),Sg=a("li"),sne=a("strong"),Hoo=o("xglm"),Uoo=o(" \u2014 "),eP=a("a"),Joo=o("XGLMConfig"),Yoo=o(" (XGLM model)"),Koo=l(),Rg=a("li"),lne=a("strong"),Zoo=o("xlm"),ero=o(" \u2014 "),oP=a("a"),oro=o("XLMConfig"),rro=o(" (XLM model)"),tro=l(),Pg=a("li"),ine=a("strong"),aro=o("xlm-prophetnet"),nro=o(" \u2014 "),rP=a("a"),sro=o("XLMProphetNetConfig"),lro=o(" (XLM-ProphetNet model)"),iro=l(),Bg=a("li"),dne=a("strong"),dro=o("xlm-roberta"),cro=o(" \u2014 "),tP=a("a"),fro=o("XLMRobertaConfig"),mro=o(" (XLM-RoBERTa model)"),gro=l(),Ig=a("li"),cne=a("strong"),hro=o("xlm-roberta-xl"),pro=o(" \u2014 "),aP=a("a"),uro=o("XLMRobertaXLConfig"),_ro=o(" (XLM-RoBERTa-XL model)"),bro=l(),Ng=a("li"),fne=a("strong"),vro=o("xlnet"),Fro=o(" \u2014 "),nP=a("a"),Tro=o("XLNetConfig"),Mro=o(" (XLNet model)"),Ero=l(),qg=a("li"),mne=a("strong"),Cro=o("yolos"),wro=o(" \u2014 "),sP=a("a"),Aro=o("YolosConfig"),Lro=o(" (YOLOS model)"),yro=l(),jg=a("li"),gne=a("strong"),xro=o("yoso"),$ro=o(" \u2014 "),lP=a("a"),kro=o("YosoConfig"),Sro=o(" (YOSO model)"),Rro=l(),F(Dg.$$.fragment),Pro=l(),Gg=a("div"),F($L.$$.fragment),Bro=l(),hne=a("p"),Iro=o("Register a new configuration for this class."),TGe=l(),$i=a("h2"),Og=a("a"),pne=a("span"),F(kL.$$.fragment),Nro=l(),une=a("span"),qro=o("AutoTokenizer"),MGe=l(),Ao=a("div"),F(SL.$$.fragment),jro=l(),RL=a("p"),Dro=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),iP=a("a"),Gro=o("AutoTokenizer.from_pretrained()"),Oro=o(" class method."),Vro=l(),PL=a("p"),Xro=o("This class cannot be instantiated directly using "),_ne=a("code"),zro=o("__init__()"),Wro=o(" (throws an error)."),Qro=l(),Ar=a("div"),F(BL.$$.fragment),Hro=l(),bne=a("p"),Uro=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Jro=l(),$a=a("p"),Yro=o("The tokenizer class to instantiate is selected based on the "),vne=a("code"),Kro=o("model_type"),Zro=o(` property of the config object (either
passed as an argument or loaded from `),Fne=a("code"),eto=o("pretrained_model_name_or_path"),oto=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tne=a("code"),rto=o("pretrained_model_name_or_path"),tto=o(":"),ato=l(),k=a("ul"),Nn=a("li"),Mne=a("strong"),nto=o("albert"),sto=o(" \u2014 "),dP=a("a"),lto=o("AlbertTokenizer"),ito=o(" or "),cP=a("a"),dto=o("AlbertTokenizerFast"),cto=o(" (ALBERT model)"),fto=l(),qn=a("li"),Ene=a("strong"),mto=o("bart"),gto=o(" \u2014 "),fP=a("a"),hto=o("BartTokenizer"),pto=o(" or "),mP=a("a"),uto=o("BartTokenizerFast"),_to=o(" (BART model)"),bto=l(),jn=a("li"),Cne=a("strong"),vto=o("barthez"),Fto=o(" \u2014 "),gP=a("a"),Tto=o("BarthezTokenizer"),Mto=o(" or "),hP=a("a"),Eto=o("BarthezTokenizerFast"),Cto=o(" (BARThez model)"),wto=l(),Vg=a("li"),wne=a("strong"),Ato=o("bartpho"),Lto=o(" \u2014 "),pP=a("a"),yto=o("BartphoTokenizer"),xto=o(" (BARTpho model)"),$to=l(),Dn=a("li"),Ane=a("strong"),kto=o("bert"),Sto=o(" \u2014 "),uP=a("a"),Rto=o("BertTokenizer"),Pto=o(" or "),_P=a("a"),Bto=o("BertTokenizerFast"),Ito=o(" (BERT model)"),Nto=l(),Xg=a("li"),Lne=a("strong"),qto=o("bert-generation"),jto=o(" \u2014 "),bP=a("a"),Dto=o("BertGenerationTokenizer"),Gto=o(" (Bert Generation model)"),Oto=l(),zg=a("li"),yne=a("strong"),Vto=o("bert-japanese"),Xto=o(" \u2014 "),vP=a("a"),zto=o("BertJapaneseTokenizer"),Wto=o(" (BertJapanese model)"),Qto=l(),Wg=a("li"),xne=a("strong"),Hto=o("bertweet"),Uto=o(" \u2014 "),FP=a("a"),Jto=o("BertweetTokenizer"),Yto=o(" (BERTweet model)"),Kto=l(),Gn=a("li"),$ne=a("strong"),Zto=o("big_bird"),eao=o(" \u2014 "),TP=a("a"),oao=o("BigBirdTokenizer"),rao=o(" or "),MP=a("a"),tao=o("BigBirdTokenizerFast"),aao=o(" (BigBird model)"),nao=l(),On=a("li"),kne=a("strong"),sao=o("bigbird_pegasus"),lao=o(" \u2014 "),EP=a("a"),iao=o("PegasusTokenizer"),dao=o(" or "),CP=a("a"),cao=o("PegasusTokenizerFast"),fao=o(" (BigBird-Pegasus model)"),mao=l(),Vn=a("li"),Sne=a("strong"),gao=o("blenderbot"),hao=o(" \u2014 "),wP=a("a"),pao=o("BlenderbotTokenizer"),uao=o(" or "),AP=a("a"),_ao=o("BlenderbotTokenizerFast"),bao=o(" (Blenderbot model)"),vao=l(),Qg=a("li"),Rne=a("strong"),Fao=o("blenderbot-small"),Tao=o(" \u2014 "),LP=a("a"),Mao=o("BlenderbotSmallTokenizer"),Eao=o(" (BlenderbotSmall model)"),Cao=l(),Hg=a("li"),Pne=a("strong"),wao=o("bloom"),Aao=o(" \u2014 "),yP=a("a"),Lao=o("BloomTokenizerFast"),yao=o(" (BLOOM model)"),xao=l(),Ug=a("li"),Bne=a("strong"),$ao=o("byt5"),kao=o(" \u2014 "),xP=a("a"),Sao=o("ByT5Tokenizer"),Rao=o(" (ByT5 model)"),Pao=l(),Xn=a("li"),Ine=a("strong"),Bao=o("camembert"),Iao=o(" \u2014 "),$P=a("a"),Nao=o("CamembertTokenizer"),qao=o(" or "),kP=a("a"),jao=o("CamembertTokenizerFast"),Dao=o(" (CamemBERT model)"),Gao=l(),Jg=a("li"),Nne=a("strong"),Oao=o("canine"),Vao=o(" \u2014 "),SP=a("a"),Xao=o("CanineTokenizer"),zao=o(" (CANINE model)"),Wao=l(),zn=a("li"),qne=a("strong"),Qao=o("clip"),Hao=o(" \u2014 "),RP=a("a"),Uao=o("CLIPTokenizer"),Jao=o(" or "),PP=a("a"),Yao=o("CLIPTokenizerFast"),Kao=o(" (CLIP model)"),Zao=l(),Wn=a("li"),jne=a("strong"),eno=o("convbert"),ono=o(" \u2014 "),BP=a("a"),rno=o("ConvBertTokenizer"),tno=o(" or "),IP=a("a"),ano=o("ConvBertTokenizerFast"),nno=o(" (ConvBERT model)"),sno=l(),Qn=a("li"),Dne=a("strong"),lno=o("cpm"),ino=o(" \u2014 "),NP=a("a"),dno=o("CpmTokenizer"),cno=o(" or "),qP=a("a"),fno=o("CpmTokenizerFast"),mno=o(" (CPM model)"),gno=l(),Yg=a("li"),Gne=a("strong"),hno=o("ctrl"),pno=o(" \u2014 "),jP=a("a"),uno=o("CTRLTokenizer"),_no=o(" (CTRL model)"),bno=l(),Hn=a("li"),One=a("strong"),vno=o("data2vec-text"),Fno=o(" \u2014 "),DP=a("a"),Tno=o("RobertaTokenizer"),Mno=o(" or "),GP=a("a"),Eno=o("RobertaTokenizerFast"),Cno=o(" (Data2VecText model)"),wno=l(),Un=a("li"),Vne=a("strong"),Ano=o("deberta"),Lno=o(" \u2014 "),OP=a("a"),yno=o("DebertaTokenizer"),xno=o(" or "),VP=a("a"),$no=o("DebertaTokenizerFast"),kno=o(" (DeBERTa model)"),Sno=l(),Jn=a("li"),Xne=a("strong"),Rno=o("deberta-v2"),Pno=o(" \u2014 "),XP=a("a"),Bno=o("DebertaV2Tokenizer"),Ino=o(" or "),zP=a("a"),Nno=o("DebertaV2TokenizerFast"),qno=o(" (DeBERTa-v2 model)"),jno=l(),Yn=a("li"),zne=a("strong"),Dno=o("distilbert"),Gno=o(" \u2014 "),WP=a("a"),Ono=o("DistilBertTokenizer"),Vno=o(" or "),QP=a("a"),Xno=o("DistilBertTokenizerFast"),zno=o(" (DistilBERT model)"),Wno=l(),Kn=a("li"),Wne=a("strong"),Qno=o("dpr"),Hno=o(" \u2014 "),HP=a("a"),Uno=o("DPRQuestionEncoderTokenizer"),Jno=o(" or "),UP=a("a"),Yno=o("DPRQuestionEncoderTokenizerFast"),Kno=o(" (DPR model)"),Zno=l(),Zn=a("li"),Qne=a("strong"),eso=o("electra"),oso=o(" \u2014 "),JP=a("a"),rso=o("ElectraTokenizer"),tso=o(" or "),YP=a("a"),aso=o("ElectraTokenizerFast"),nso=o(" (ELECTRA model)"),sso=l(),Kg=a("li"),Hne=a("strong"),lso=o("flaubert"),iso=o(" \u2014 "),KP=a("a"),dso=o("FlaubertTokenizer"),cso=o(" (FlauBERT model)"),fso=l(),es=a("li"),Une=a("strong"),mso=o("fnet"),gso=o(" \u2014 "),ZP=a("a"),hso=o("FNetTokenizer"),pso=o(" or "),eB=a("a"),uso=o("FNetTokenizerFast"),_so=o(" (FNet model)"),bso=l(),Zg=a("li"),Jne=a("strong"),vso=o("fsmt"),Fso=o(" \u2014 "),oB=a("a"),Tso=o("FSMTTokenizer"),Mso=o(" (FairSeq Machine-Translation model)"),Eso=l(),os=a("li"),Yne=a("strong"),Cso=o("funnel"),wso=o(" \u2014 "),rB=a("a"),Aso=o("FunnelTokenizer"),Lso=o(" or "),tB=a("a"),yso=o("FunnelTokenizerFast"),xso=o(" (Funnel Transformer model)"),$so=l(),rs=a("li"),Kne=a("strong"),kso=o("gpt2"),Sso=o(" \u2014 "),aB=a("a"),Rso=o("GPT2Tokenizer"),Pso=o(" or "),nB=a("a"),Bso=o("GPT2TokenizerFast"),Iso=o(" (OpenAI GPT-2 model)"),Nso=l(),ts=a("li"),Zne=a("strong"),qso=o("gpt_neo"),jso=o(" \u2014 "),sB=a("a"),Dso=o("GPT2Tokenizer"),Gso=o(" or "),lB=a("a"),Oso=o("GPT2TokenizerFast"),Vso=o(" (GPT Neo model)"),Xso=l(),eh=a("li"),ese=a("strong"),zso=o("gpt_neox"),Wso=o(" \u2014 "),iB=a("a"),Qso=o("GPTNeoXTokenizerFast"),Hso=o(" (GPT NeoX model)"),Uso=l(),as=a("li"),ose=a("strong"),Jso=o("gptj"),Yso=o(" \u2014 "),dB=a("a"),Kso=o("GPT2Tokenizer"),Zso=o(" or "),cB=a("a"),elo=o("GPT2TokenizerFast"),olo=o(" (GPT-J model)"),rlo=l(),ns=a("li"),rse=a("strong"),tlo=o("herbert"),alo=o(" \u2014 "),fB=a("a"),nlo=o("HerbertTokenizer"),slo=o(" or "),mB=a("a"),llo=o("HerbertTokenizerFast"),ilo=o(" (HerBERT model)"),dlo=l(),oh=a("li"),tse=a("strong"),clo=o("hubert"),flo=o(" \u2014 "),gB=a("a"),mlo=o("Wav2Vec2CTCTokenizer"),glo=o(" (Hubert model)"),hlo=l(),ss=a("li"),ase=a("strong"),plo=o("ibert"),ulo=o(" \u2014 "),hB=a("a"),_lo=o("RobertaTokenizer"),blo=o(" or "),pB=a("a"),vlo=o("RobertaTokenizerFast"),Flo=o(" (I-BERT model)"),Tlo=l(),ls=a("li"),nse=a("strong"),Mlo=o("layoutlm"),Elo=o(" \u2014 "),uB=a("a"),Clo=o("LayoutLMTokenizer"),wlo=o(" or "),_B=a("a"),Alo=o("LayoutLMTokenizerFast"),Llo=o(" (LayoutLM model)"),ylo=l(),is=a("li"),sse=a("strong"),xlo=o("layoutlmv2"),$lo=o(" \u2014 "),bB=a("a"),klo=o("LayoutLMv2Tokenizer"),Slo=o(" or "),vB=a("a"),Rlo=o("LayoutLMv2TokenizerFast"),Plo=o(" (LayoutLMv2 model)"),Blo=l(),ds=a("li"),lse=a("strong"),Ilo=o("layoutlmv3"),Nlo=o(" \u2014 "),FB=a("a"),qlo=o("LayoutLMv3Tokenizer"),jlo=o(" or "),TB=a("a"),Dlo=o("LayoutLMv3TokenizerFast"),Glo=o(" (LayoutLMv3 model)"),Olo=l(),cs=a("li"),ise=a("strong"),Vlo=o("layoutxlm"),Xlo=o(" \u2014 "),MB=a("a"),zlo=o("LayoutXLMTokenizer"),Wlo=o(" or "),EB=a("a"),Qlo=o("LayoutXLMTokenizerFast"),Hlo=o(" (LayoutXLM model)"),Ulo=l(),fs=a("li"),dse=a("strong"),Jlo=o("led"),Ylo=o(" \u2014 "),CB=a("a"),Klo=o("LEDTokenizer"),Zlo=o(" or "),wB=a("a"),eio=o("LEDTokenizerFast"),oio=o(" (LED model)"),rio=l(),ms=a("li"),cse=a("strong"),tio=o("longformer"),aio=o(" \u2014 "),AB=a("a"),nio=o("LongformerTokenizer"),sio=o(" or "),LB=a("a"),lio=o("LongformerTokenizerFast"),iio=o(" (Longformer model)"),dio=l(),gs=a("li"),fse=a("strong"),cio=o("longt5"),fio=o(" \u2014 "),yB=a("a"),mio=o("T5Tokenizer"),gio=o(" or "),xB=a("a"),hio=o("T5TokenizerFast"),pio=o(" (LongT5 model)"),uio=l(),rh=a("li"),mse=a("strong"),_io=o("luke"),bio=o(" \u2014 "),$B=a("a"),vio=o("LukeTokenizer"),Fio=o(" (LUKE model)"),Tio=l(),hs=a("li"),gse=a("strong"),Mio=o("lxmert"),Eio=o(" \u2014 "),kB=a("a"),Cio=o("LxmertTokenizer"),wio=o(" or "),SB=a("a"),Aio=o("LxmertTokenizerFast"),Lio=o(" (LXMERT model)"),yio=l(),th=a("li"),hse=a("strong"),xio=o("m2m_100"),$io=o(" \u2014 "),RB=a("a"),kio=o("M2M100Tokenizer"),Sio=o(" (M2M100 model)"),Rio=l(),ah=a("li"),pse=a("strong"),Pio=o("marian"),Bio=o(" \u2014 "),PB=a("a"),Iio=o("MarianTokenizer"),Nio=o(" (Marian model)"),qio=l(),ps=a("li"),use=a("strong"),jio=o("mbart"),Dio=o(" \u2014 "),BB=a("a"),Gio=o("MBartTokenizer"),Oio=o(" or "),IB=a("a"),Vio=o("MBartTokenizerFast"),Xio=o(" (mBART model)"),zio=l(),us=a("li"),_se=a("strong"),Wio=o("mbart50"),Qio=o(" \u2014 "),NB=a("a"),Hio=o("MBart50Tokenizer"),Uio=o(" or "),qB=a("a"),Jio=o("MBart50TokenizerFast"),Yio=o(" (mBART-50 model)"),Kio=l(),_s=a("li"),bse=a("strong"),Zio=o("megatron-bert"),edo=o(" \u2014 "),jB=a("a"),odo=o("BertTokenizer"),rdo=o(" or "),DB=a("a"),tdo=o("BertTokenizerFast"),ado=o(" (Megatron-BERT model)"),ndo=l(),nh=a("li"),vse=a("strong"),sdo=o("mluke"),ldo=o(" \u2014 "),GB=a("a"),ido=o("MLukeTokenizer"),ddo=o(" (mLUKE model)"),cdo=l(),bs=a("li"),Fse=a("strong"),fdo=o("mobilebert"),mdo=o(" \u2014 "),OB=a("a"),gdo=o("MobileBertTokenizer"),hdo=o(" or "),VB=a("a"),pdo=o("MobileBertTokenizerFast"),udo=o(" (MobileBERT model)"),_do=l(),vs=a("li"),Tse=a("strong"),bdo=o("mpnet"),vdo=o(" \u2014 "),XB=a("a"),Fdo=o("MPNetTokenizer"),Tdo=o(" or "),zB=a("a"),Mdo=o("MPNetTokenizerFast"),Edo=o(" (MPNet model)"),Cdo=l(),Fs=a("li"),Mse=a("strong"),wdo=o("mt5"),Ado=o(" \u2014 "),WB=a("a"),Ldo=o("MT5Tokenizer"),ydo=o(" or "),QB=a("a"),xdo=o("MT5TokenizerFast"),$do=o(" (MT5 model)"),kdo=l(),Ts=a("li"),Ese=a("strong"),Sdo=o("nystromformer"),Rdo=o(" \u2014 "),HB=a("a"),Pdo=o("AlbertTokenizer"),Bdo=o(" or "),UB=a("a"),Ido=o("AlbertTokenizerFast"),Ndo=o(" (Nystr\xF6mformer model)"),qdo=l(),Ms=a("li"),Cse=a("strong"),jdo=o("openai-gpt"),Ddo=o(" \u2014 "),JB=a("a"),Gdo=o("OpenAIGPTTokenizer"),Odo=o(" or "),YB=a("a"),Vdo=o("OpenAIGPTTokenizerFast"),Xdo=o(" (OpenAI GPT model)"),zdo=l(),sh=a("li"),wse=a("strong"),Wdo=o("opt"),Qdo=o(" \u2014 "),KB=a("a"),Hdo=o("GPT2Tokenizer"),Udo=o(" (OPT model)"),Jdo=l(),Es=a("li"),Ase=a("strong"),Ydo=o("pegasus"),Kdo=o(" \u2014 "),ZB=a("a"),Zdo=o("PegasusTokenizer"),eco=o(" or "),eI=a("a"),oco=o("PegasusTokenizerFast"),rco=o(" (Pegasus model)"),tco=l(),lh=a("li"),Lse=a("strong"),aco=o("perceiver"),nco=o(" \u2014 "),oI=a("a"),sco=o("PerceiverTokenizer"),lco=o(" (Perceiver model)"),ico=l(),ih=a("li"),yse=a("strong"),dco=o("phobert"),cco=o(" \u2014 "),rI=a("a"),fco=o("PhobertTokenizer"),mco=o(" (PhoBERT model)"),gco=l(),dh=a("li"),xse=a("strong"),hco=o("plbart"),pco=o(" \u2014 "),tI=a("a"),uco=o("PLBartTokenizer"),_co=o(" (PLBart model)"),bco=l(),ch=a("li"),$se=a("strong"),vco=o("prophetnet"),Fco=o(" \u2014 "),aI=a("a"),Tco=o("ProphetNetTokenizer"),Mco=o(" (ProphetNet model)"),Eco=l(),Cs=a("li"),kse=a("strong"),Cco=o("qdqbert"),wco=o(" \u2014 "),nI=a("a"),Aco=o("BertTokenizer"),Lco=o(" or "),sI=a("a"),yco=o("BertTokenizerFast"),xco=o(" (QDQBert model)"),$co=l(),fh=a("li"),Sse=a("strong"),kco=o("rag"),Sco=o(" \u2014 "),lI=a("a"),Rco=o("RagTokenizer"),Pco=o(" (RAG model)"),Bco=l(),ws=a("li"),Rse=a("strong"),Ico=o("realm"),Nco=o(" \u2014 "),iI=a("a"),qco=o("RealmTokenizer"),jco=o(" or "),dI=a("a"),Dco=o("RealmTokenizerFast"),Gco=o(" (REALM model)"),Oco=l(),As=a("li"),Pse=a("strong"),Vco=o("reformer"),Xco=o(" \u2014 "),cI=a("a"),zco=o("ReformerTokenizer"),Wco=o(" or "),fI=a("a"),Qco=o("ReformerTokenizerFast"),Hco=o(" (Reformer model)"),Uco=l(),Ls=a("li"),Bse=a("strong"),Jco=o("rembert"),Yco=o(" \u2014 "),mI=a("a"),Kco=o("RemBertTokenizer"),Zco=o(" or "),gI=a("a"),efo=o("RemBertTokenizerFast"),ofo=o(" (RemBERT model)"),rfo=l(),ys=a("li"),Ise=a("strong"),tfo=o("retribert"),afo=o(" \u2014 "),hI=a("a"),nfo=o("RetriBertTokenizer"),sfo=o(" or "),pI=a("a"),lfo=o("RetriBertTokenizerFast"),ifo=o(" (RetriBERT model)"),dfo=l(),xs=a("li"),Nse=a("strong"),cfo=o("roberta"),ffo=o(" \u2014 "),uI=a("a"),mfo=o("RobertaTokenizer"),gfo=o(" or "),_I=a("a"),hfo=o("RobertaTokenizerFast"),pfo=o(" (RoBERTa model)"),ufo=l(),$s=a("li"),qse=a("strong"),_fo=o("roformer"),bfo=o(" \u2014 "),bI=a("a"),vfo=o("RoFormerTokenizer"),Ffo=o(" or "),vI=a("a"),Tfo=o("RoFormerTokenizerFast"),Mfo=o(" (RoFormer model)"),Efo=l(),mh=a("li"),jse=a("strong"),Cfo=o("speech_to_text"),wfo=o(" \u2014 "),FI=a("a"),Afo=o("Speech2TextTokenizer"),Lfo=o(" (Speech2Text model)"),yfo=l(),gh=a("li"),Dse=a("strong"),xfo=o("speech_to_text_2"),$fo=o(" \u2014 "),TI=a("a"),kfo=o("Speech2Text2Tokenizer"),Sfo=o(" (Speech2Text2 model)"),Rfo=l(),ks=a("li"),Gse=a("strong"),Pfo=o("splinter"),Bfo=o(" \u2014 "),MI=a("a"),Ifo=o("SplinterTokenizer"),Nfo=o(" or "),EI=a("a"),qfo=o("SplinterTokenizerFast"),jfo=o(" (Splinter model)"),Dfo=l(),Ss=a("li"),Ose=a("strong"),Gfo=o("squeezebert"),Ofo=o(" \u2014 "),CI=a("a"),Vfo=o("SqueezeBertTokenizer"),Xfo=o(" or "),wI=a("a"),zfo=o("SqueezeBertTokenizerFast"),Wfo=o(" (SqueezeBERT model)"),Qfo=l(),Rs=a("li"),Vse=a("strong"),Hfo=o("t5"),Ufo=o(" \u2014 "),AI=a("a"),Jfo=o("T5Tokenizer"),Yfo=o(" or "),LI=a("a"),Kfo=o("T5TokenizerFast"),Zfo=o(" (T5 model)"),emo=l(),hh=a("li"),Xse=a("strong"),omo=o("tapas"),rmo=o(" \u2014 "),yI=a("a"),tmo=o("TapasTokenizer"),amo=o(" (TAPAS model)"),nmo=l(),ph=a("li"),zse=a("strong"),smo=o("tapex"),lmo=o(" \u2014 "),xI=a("a"),imo=o("TapexTokenizer"),dmo=o(" (TAPEX model)"),cmo=l(),uh=a("li"),Wse=a("strong"),fmo=o("transfo-xl"),mmo=o(" \u2014 "),$I=a("a"),gmo=o("TransfoXLTokenizer"),hmo=o(" (Transformer-XL model)"),pmo=l(),Ps=a("li"),Qse=a("strong"),umo=o("vilt"),_mo=o(" \u2014 "),kI=a("a"),bmo=o("BertTokenizer"),vmo=o(" or "),SI=a("a"),Fmo=o("BertTokenizerFast"),Tmo=o(" (ViLT model)"),Mmo=l(),Bs=a("li"),Hse=a("strong"),Emo=o("visual_bert"),Cmo=o(" \u2014 "),RI=a("a"),wmo=o("BertTokenizer"),Amo=o(" or "),PI=a("a"),Lmo=o("BertTokenizerFast"),ymo=o(" (VisualBERT model)"),xmo=l(),_h=a("li"),Use=a("strong"),$mo=o("wav2vec2"),kmo=o(" \u2014 "),BI=a("a"),Smo=o("Wav2Vec2CTCTokenizer"),Rmo=o(" (Wav2Vec2 model)"),Pmo=l(),bh=a("li"),Jse=a("strong"),Bmo=o("wav2vec2-conformer"),Imo=o(" \u2014 "),II=a("a"),Nmo=o("Wav2Vec2CTCTokenizer"),qmo=o(" (Wav2Vec2-Conformer model)"),jmo=l(),vh=a("li"),Yse=a("strong"),Dmo=o("wav2vec2_phoneme"),Gmo=o(" \u2014 "),NI=a("a"),Omo=o("Wav2Vec2PhonemeCTCTokenizer"),Vmo=o(" (Wav2Vec2Phoneme model)"),Xmo=l(),Is=a("li"),Kse=a("strong"),zmo=o("xglm"),Wmo=o(" \u2014 "),qI=a("a"),Qmo=o("XGLMTokenizer"),Hmo=o(" or "),jI=a("a"),Umo=o("XGLMTokenizerFast"),Jmo=o(" (XGLM model)"),Ymo=l(),Fh=a("li"),Zse=a("strong"),Kmo=o("xlm"),Zmo=o(" \u2014 "),DI=a("a"),ego=o("XLMTokenizer"),ogo=o(" (XLM model)"),rgo=l(),Th=a("li"),ele=a("strong"),tgo=o("xlm-prophetnet"),ago=o(" \u2014 "),GI=a("a"),ngo=o("XLMProphetNetTokenizer"),sgo=o(" (XLM-ProphetNet model)"),lgo=l(),Ns=a("li"),ole=a("strong"),igo=o("xlm-roberta"),dgo=o(" \u2014 "),OI=a("a"),cgo=o("XLMRobertaTokenizer"),fgo=o(" or "),VI=a("a"),mgo=o("XLMRobertaTokenizerFast"),ggo=o(" (XLM-RoBERTa model)"),hgo=l(),qs=a("li"),rle=a("strong"),pgo=o("xlm-roberta-xl"),ugo=o(" \u2014 "),XI=a("a"),_go=o("RobertaTokenizer"),bgo=o(" or "),zI=a("a"),vgo=o("RobertaTokenizerFast"),Fgo=o(" (XLM-RoBERTa-XL model)"),Tgo=l(),js=a("li"),tle=a("strong"),Mgo=o("xlnet"),Ego=o(" \u2014 "),WI=a("a"),Cgo=o("XLNetTokenizer"),wgo=o(" or "),QI=a("a"),Ago=o("XLNetTokenizerFast"),Lgo=o(" (XLNet model)"),ygo=l(),Ds=a("li"),ale=a("strong"),xgo=o("yoso"),$go=o(" \u2014 "),HI=a("a"),kgo=o("AlbertTokenizer"),Sgo=o(" or "),UI=a("a"),Rgo=o("AlbertTokenizerFast"),Pgo=o(" (YOSO model)"),Bgo=l(),F(Mh.$$.fragment),Igo=l(),Eh=a("div"),F(IL.$$.fragment),Ngo=l(),nle=a("p"),qgo=o("Register a new tokenizer in this mapping."),EGe=l(),ki=a("h2"),Ch=a("a"),sle=a("span"),F(NL.$$.fragment),jgo=l(),lle=a("span"),Dgo=o("AutoFeatureExtractor"),CGe=l(),Lo=a("div"),F(qL.$$.fragment),Ggo=l(),jL=a("p"),Ogo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),JI=a("a"),Vgo=o("AutoFeatureExtractor.from_pretrained()"),Xgo=o(" class method."),zgo=l(),DL=a("p"),Wgo=o("This class cannot be instantiated directly using "),ile=a("code"),Qgo=o("__init__()"),Hgo=o(" (throws an error)."),Ugo=l(),He=a("div"),F(GL.$$.fragment),Jgo=l(),dle=a("p"),Ygo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Kgo=l(),ka=a("p"),Zgo=o("The feature extractor class to instantiate is selected based on the "),cle=a("code"),eho=o("model_type"),oho=o(` property of the config object
(either passed as an argument or loaded from `),fle=a("code"),rho=o("pretrained_model_name_or_path"),tho=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),mle=a("code"),aho=o("pretrained_model_name_or_path"),nho=o(":"),sho=l(),Y=a("ul"),wh=a("li"),gle=a("strong"),lho=o("beit"),iho=o(" \u2014 "),YI=a("a"),dho=o("BeitFeatureExtractor"),cho=o(" (BEiT model)"),fho=l(),Ah=a("li"),hle=a("strong"),mho=o("clip"),gho=o(" \u2014 "),KI=a("a"),hho=o("CLIPFeatureExtractor"),pho=o(" (CLIP model)"),uho=l(),Lh=a("li"),ple=a("strong"),_ho=o("convnext"),bho=o(" \u2014 "),ZI=a("a"),vho=o("ConvNextFeatureExtractor"),Fho=o(" (ConvNeXT model)"),Tho=l(),yh=a("li"),ule=a("strong"),Mho=o("cvt"),Eho=o(" \u2014 "),eN=a("a"),Cho=o("ConvNextFeatureExtractor"),who=o(" (CvT model)"),Aho=l(),xh=a("li"),_le=a("strong"),Lho=o("data2vec-audio"),yho=o(" \u2014 "),oN=a("a"),xho=o("Wav2Vec2FeatureExtractor"),$ho=o(" (Data2VecAudio model)"),kho=l(),$h=a("li"),ble=a("strong"),Sho=o("data2vec-vision"),Rho=o(" \u2014 "),rN=a("a"),Pho=o("BeitFeatureExtractor"),Bho=o(" (Data2VecVision model)"),Iho=l(),kh=a("li"),vle=a("strong"),Nho=o("deit"),qho=o(" \u2014 "),tN=a("a"),jho=o("DeiTFeatureExtractor"),Dho=o(" (DeiT model)"),Gho=l(),Sh=a("li"),Fle=a("strong"),Oho=o("detr"),Vho=o(" \u2014 "),aN=a("a"),Xho=o("DetrFeatureExtractor"),zho=o(" (DETR model)"),Who=l(),Rh=a("li"),Tle=a("strong"),Qho=o("dpt"),Hho=o(" \u2014 "),nN=a("a"),Uho=o("DPTFeatureExtractor"),Jho=o(" (DPT model)"),Yho=l(),Ph=a("li"),Mle=a("strong"),Kho=o("flava"),Zho=o(" \u2014 "),sN=a("a"),epo=o("FlavaFeatureExtractor"),opo=o(" (FLAVA model)"),rpo=l(),Bh=a("li"),Ele=a("strong"),tpo=o("glpn"),apo=o(" \u2014 "),lN=a("a"),npo=o("GLPNFeatureExtractor"),spo=o(" (GLPN model)"),lpo=l(),Ih=a("li"),Cle=a("strong"),ipo=o("hubert"),dpo=o(" \u2014 "),iN=a("a"),cpo=o("Wav2Vec2FeatureExtractor"),fpo=o(" (Hubert model)"),mpo=l(),Nh=a("li"),wle=a("strong"),gpo=o("imagegpt"),hpo=o(" \u2014 "),dN=a("a"),ppo=o("ImageGPTFeatureExtractor"),upo=o(" (ImageGPT model)"),_po=l(),qh=a("li"),Ale=a("strong"),bpo=o("layoutlmv2"),vpo=o(" \u2014 "),cN=a("a"),Fpo=o("LayoutLMv2FeatureExtractor"),Tpo=o(" (LayoutLMv2 model)"),Mpo=l(),jh=a("li"),Lle=a("strong"),Epo=o("layoutlmv3"),Cpo=o(" \u2014 "),fN=a("a"),wpo=o("LayoutLMv3FeatureExtractor"),Apo=o(" (LayoutLMv3 model)"),Lpo=l(),Dh=a("li"),yle=a("strong"),ypo=o("levit"),xpo=o(" \u2014 "),mN=a("a"),$po=o("LevitFeatureExtractor"),kpo=o(" (LeViT model)"),Spo=l(),Gh=a("li"),xle=a("strong"),Rpo=o("maskformer"),Ppo=o(" \u2014 "),gN=a("a"),Bpo=o("MaskFormerFeatureExtractor"),Ipo=o(" (MaskFormer model)"),Npo=l(),Oh=a("li"),$le=a("strong"),qpo=o("mctct"),jpo=o(" \u2014 "),hN=a("a"),Dpo=o("MCTCTFeatureExtractor"),Gpo=o(" (M-CTC-T model)"),Opo=l(),Vh=a("li"),kle=a("strong"),Vpo=o("omnivore"),Xpo=o(" \u2014 "),pN=a("a"),zpo=o("OmnivoreFeatureExtractor"),Wpo=o(" (Omnivore model)"),Qpo=l(),Xh=a("li"),Sle=a("strong"),Hpo=o("perceiver"),Upo=o(" \u2014 "),uN=a("a"),Jpo=o("PerceiverFeatureExtractor"),Ypo=o(" (Perceiver model)"),Kpo=l(),zh=a("li"),Rle=a("strong"),Zpo=o("poolformer"),euo=o(" \u2014 "),_N=a("a"),ouo=o("PoolFormerFeatureExtractor"),ruo=o(" (PoolFormer model)"),tuo=l(),Wh=a("li"),Ple=a("strong"),auo=o("regnet"),nuo=o(" \u2014 "),bN=a("a"),suo=o("ConvNextFeatureExtractor"),luo=o(" (RegNet model)"),iuo=l(),Qh=a("li"),Ble=a("strong"),duo=o("resnet"),cuo=o(" \u2014 "),vN=a("a"),fuo=o("ConvNextFeatureExtractor"),muo=o(" (ResNet model)"),guo=l(),Hh=a("li"),Ile=a("strong"),huo=o("segformer"),puo=o(" \u2014 "),FN=a("a"),uuo=o("SegformerFeatureExtractor"),_uo=o(" (SegFormer model)"),buo=l(),Uh=a("li"),Nle=a("strong"),vuo=o("speech_to_text"),Fuo=o(" \u2014 "),TN=a("a"),Tuo=o("Speech2TextFeatureExtractor"),Muo=o(" (Speech2Text model)"),Euo=l(),Jh=a("li"),qle=a("strong"),Cuo=o("swin"),wuo=o(" \u2014 "),MN=a("a"),Auo=o("ViTFeatureExtractor"),Luo=o(" (Swin Transformer model)"),yuo=l(),Yh=a("li"),jle=a("strong"),xuo=o("van"),$uo=o(" \u2014 "),EN=a("a"),kuo=o("ConvNextFeatureExtractor"),Suo=o(" (VAN model)"),Ruo=l(),Kh=a("li"),Dle=a("strong"),Puo=o("vilt"),Buo=o(" \u2014 "),CN=a("a"),Iuo=o("ViltFeatureExtractor"),Nuo=o(" (ViLT model)"),quo=l(),Zh=a("li"),Gle=a("strong"),juo=o("vit"),Duo=o(" \u2014 "),wN=a("a"),Guo=o("ViTFeatureExtractor"),Ouo=o(" (ViT model)"),Vuo=l(),ep=a("li"),Ole=a("strong"),Xuo=o("vit_mae"),zuo=o(" \u2014 "),AN=a("a"),Wuo=o("ViTFeatureExtractor"),Quo=o(" (ViTMAE model)"),Huo=l(),op=a("li"),Vle=a("strong"),Uuo=o("wav2vec2"),Juo=o(" \u2014 "),LN=a("a"),Yuo=o("Wav2Vec2FeatureExtractor"),Kuo=o(" (Wav2Vec2 model)"),Zuo=l(),rp=a("li"),Xle=a("strong"),e_o=o("wav2vec2-conformer"),o_o=o(" \u2014 "),yN=a("a"),r_o=o("Wav2Vec2FeatureExtractor"),t_o=o(" (Wav2Vec2-Conformer model)"),a_o=l(),tp=a("li"),zle=a("strong"),n_o=o("yolos"),s_o=o(" \u2014 "),xN=a("a"),l_o=o("YolosFeatureExtractor"),i_o=o(" (YOLOS model)"),d_o=l(),F(ap.$$.fragment),c_o=l(),F(np.$$.fragment),f_o=l(),sp=a("div"),F(OL.$$.fragment),m_o=l(),Wle=a("p"),g_o=o("Register a new feature extractor for this class."),wGe=l(),Si=a("h2"),lp=a("a"),Qle=a("span"),F(VL.$$.fragment),h_o=l(),Hle=a("span"),p_o=o("AutoProcessor"),AGe=l(),yo=a("div"),F(XL.$$.fragment),u_o=l(),zL=a("p"),__o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),$N=a("a"),b_o=o("AutoProcessor.from_pretrained()"),v_o=o(" class method."),F_o=l(),WL=a("p"),T_o=o("This class cannot be instantiated directly using "),Ule=a("code"),M_o=o("__init__()"),E_o=o(" (throws an error)."),C_o=l(),Ue=a("div"),F(QL.$$.fragment),w_o=l(),Jle=a("p"),A_o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),L_o=l(),Ri=a("p"),y_o=o("The processor class to instantiate is selected based on the "),Yle=a("code"),x_o=o("model_type"),$_o=o(` property of the config object (either
passed as an argument or loaded from `),Kle=a("code"),k_o=o("pretrained_model_name_or_path"),S_o=o(" if possible):"),R_o=l(),he=a("ul"),ip=a("li"),Zle=a("strong"),P_o=o("clip"),B_o=o(" \u2014 "),kN=a("a"),I_o=o("CLIPProcessor"),N_o=o(" (CLIP model)"),q_o=l(),dp=a("li"),eie=a("strong"),j_o=o("flava"),D_o=o(" \u2014 "),oie=a("code"),G_o=o("FLAVAProcessor"),O_o=o(" (FLAVA model)"),V_o=l(),cp=a("li"),rie=a("strong"),X_o=o("layoutlmv2"),z_o=o(" \u2014 "),SN=a("a"),W_o=o("LayoutLMv2Processor"),Q_o=o(" (LayoutLMv2 model)"),H_o=l(),fp=a("li"),tie=a("strong"),U_o=o("layoutlmv3"),J_o=o(" \u2014 "),RN=a("a"),Y_o=o("LayoutLMv3Processor"),K_o=o(" (LayoutLMv3 model)"),Z_o=l(),mp=a("li"),aie=a("strong"),e7o=o("layoutxlm"),o7o=o(" \u2014 "),PN=a("a"),r7o=o("LayoutXLMProcessor"),t7o=o(" (LayoutXLM model)"),a7o=l(),gp=a("li"),nie=a("strong"),n7o=o("sew"),s7o=o(" \u2014 "),BN=a("a"),l7o=o("Wav2Vec2Processor"),i7o=o(" (SEW model)"),d7o=l(),hp=a("li"),sie=a("strong"),c7o=o("sew-d"),f7o=o(" \u2014 "),IN=a("a"),m7o=o("Wav2Vec2Processor"),g7o=o(" (SEW-D model)"),h7o=l(),pp=a("li"),lie=a("strong"),p7o=o("speech_to_text"),u7o=o(" \u2014 "),NN=a("a"),_7o=o("Speech2TextProcessor"),b7o=o(" (Speech2Text model)"),v7o=l(),up=a("li"),iie=a("strong"),F7o=o("speech_to_text_2"),T7o=o(" \u2014 "),qN=a("a"),M7o=o("Speech2Text2Processor"),E7o=o(" (Speech2Text2 model)"),C7o=l(),_p=a("li"),die=a("strong"),w7o=o("trocr"),A7o=o(" \u2014 "),jN=a("a"),L7o=o("TrOCRProcessor"),y7o=o(" (TrOCR model)"),x7o=l(),bp=a("li"),cie=a("strong"),$7o=o("unispeech"),k7o=o(" \u2014 "),DN=a("a"),S7o=o("Wav2Vec2Processor"),R7o=o(" (UniSpeech model)"),P7o=l(),vp=a("li"),fie=a("strong"),B7o=o("unispeech-sat"),I7o=o(" \u2014 "),GN=a("a"),N7o=o("Wav2Vec2Processor"),q7o=o(" (UniSpeechSat model)"),j7o=l(),Fp=a("li"),mie=a("strong"),D7o=o("vilt"),G7o=o(" \u2014 "),ON=a("a"),O7o=o("ViltProcessor"),V7o=o(" (ViLT model)"),X7o=l(),Tp=a("li"),gie=a("strong"),z7o=o("vision-text-dual-encoder"),W7o=o(" \u2014 "),VN=a("a"),Q7o=o("VisionTextDualEncoderProcessor"),H7o=o(" (VisionTextDualEncoder model)"),U7o=l(),Mp=a("li"),hie=a("strong"),J7o=o("wav2vec2"),Y7o=o(" \u2014 "),XN=a("a"),K7o=o("Wav2Vec2Processor"),Z7o=o(" (Wav2Vec2 model)"),e2o=l(),Ep=a("li"),pie=a("strong"),o2o=o("wav2vec2-conformer"),r2o=o(" \u2014 "),zN=a("a"),t2o=o("Wav2Vec2Processor"),a2o=o(" (Wav2Vec2-Conformer model)"),n2o=l(),Cp=a("li"),uie=a("strong"),s2o=o("wavlm"),l2o=o(" \u2014 "),WN=a("a"),i2o=o("Wav2Vec2Processor"),d2o=o(" (WavLM model)"),c2o=l(),F(wp.$$.fragment),f2o=l(),F(Ap.$$.fragment),m2o=l(),Lp=a("div"),F(HL.$$.fragment),g2o=l(),_ie=a("p"),h2o=o("Register a new processor for this class."),LGe=l(),Pi=a("h2"),yp=a("a"),bie=a("span"),F(UL.$$.fragment),p2o=l(),vie=a("span"),u2o=o("AutoModel"),yGe=l(),xo=a("div"),F(JL.$$.fragment),_2o=l(),Bi=a("p"),b2o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),QN=a("a"),v2o=o("from_pretrained()"),F2o=o(" class method or the "),HN=a("a"),T2o=o("from_config()"),M2o=o(` class
method.`),E2o=l(),YL=a("p"),C2o=o("This class cannot be instantiated directly using "),Fie=a("code"),w2o=o("__init__()"),A2o=o(" (throws an error)."),L2o=l(),nt=a("div"),F(KL.$$.fragment),y2o=l(),Tie=a("p"),x2o=o("Instantiates one of the base model classes of the library from a configuration."),$2o=l(),Ii=a("p"),k2o=o(`Note:
Loading a model from its configuration file does `),Mie=a("strong"),S2o=o("not"),R2o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UN=a("a"),P2o=o("from_pretrained()"),B2o=o(" to load the model weights."),I2o=l(),F(xp.$$.fragment),N2o=l(),Je=a("div"),F(ZL.$$.fragment),q2o=l(),Eie=a("p"),j2o=o("Instantiate one of the base model classes of the library from a pretrained model."),D2o=l(),Sa=a("p"),G2o=o("The model class to instantiate is selected based on the "),Cie=a("code"),O2o=o("model_type"),V2o=o(` property of the config object (either
passed as an argument or loaded from `),wie=a("code"),X2o=o("pretrained_model_name_or_path"),z2o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Aie=a("code"),W2o=o("pretrained_model_name_or_path"),Q2o=o(":"),H2o=l(),y=a("ul"),$p=a("li"),Lie=a("strong"),U2o=o("albert"),J2o=o(" \u2014 "),JN=a("a"),Y2o=o("AlbertModel"),K2o=o(" (ALBERT model)"),Z2o=l(),kp=a("li"),yie=a("strong"),e1o=o("bart"),o1o=o(" \u2014 "),YN=a("a"),r1o=o("BartModel"),t1o=o(" (BART model)"),a1o=l(),Sp=a("li"),xie=a("strong"),n1o=o("beit"),s1o=o(" \u2014 "),KN=a("a"),l1o=o("BeitModel"),i1o=o(" (BEiT model)"),d1o=l(),Rp=a("li"),$ie=a("strong"),c1o=o("bert"),f1o=o(" \u2014 "),ZN=a("a"),m1o=o("BertModel"),g1o=o(" (BERT model)"),h1o=l(),Pp=a("li"),kie=a("strong"),p1o=o("bert-generation"),u1o=o(" \u2014 "),eq=a("a"),_1o=o("BertGenerationEncoder"),b1o=o(" (Bert Generation model)"),v1o=l(),Bp=a("li"),Sie=a("strong"),F1o=o("big_bird"),T1o=o(" \u2014 "),oq=a("a"),M1o=o("BigBirdModel"),E1o=o(" (BigBird model)"),C1o=l(),Ip=a("li"),Rie=a("strong"),w1o=o("bigbird_pegasus"),A1o=o(" \u2014 "),rq=a("a"),L1o=o("BigBirdPegasusModel"),y1o=o(" (BigBird-Pegasus model)"),x1o=l(),Np=a("li"),Pie=a("strong"),$1o=o("blenderbot"),k1o=o(" \u2014 "),tq=a("a"),S1o=o("BlenderbotModel"),R1o=o(" (Blenderbot model)"),P1o=l(),qp=a("li"),Bie=a("strong"),B1o=o("blenderbot-small"),I1o=o(" \u2014 "),aq=a("a"),N1o=o("BlenderbotSmallModel"),q1o=o(" (BlenderbotSmall model)"),j1o=l(),jp=a("li"),Iie=a("strong"),D1o=o("bloom"),G1o=o(" \u2014 "),nq=a("a"),O1o=o("BloomModel"),V1o=o(" (BLOOM model)"),X1o=l(),Dp=a("li"),Nie=a("strong"),z1o=o("camembert"),W1o=o(" \u2014 "),sq=a("a"),Q1o=o("CamembertModel"),H1o=o(" (CamemBERT model)"),U1o=l(),Gp=a("li"),qie=a("strong"),J1o=o("canine"),Y1o=o(" \u2014 "),lq=a("a"),K1o=o("CanineModel"),Z1o=o(" (CANINE model)"),ebo=l(),Op=a("li"),jie=a("strong"),obo=o("clip"),rbo=o(" \u2014 "),iq=a("a"),tbo=o("CLIPModel"),abo=o(" (CLIP model)"),nbo=l(),Vp=a("li"),Die=a("strong"),sbo=o("convbert"),lbo=o(" \u2014 "),dq=a("a"),ibo=o("ConvBertModel"),dbo=o(" (ConvBERT model)"),cbo=l(),Xp=a("li"),Gie=a("strong"),fbo=o("convnext"),mbo=o(" \u2014 "),cq=a("a"),gbo=o("ConvNextModel"),hbo=o(" (ConvNeXT model)"),pbo=l(),zp=a("li"),Oie=a("strong"),ubo=o("ctrl"),_bo=o(" \u2014 "),fq=a("a"),bbo=o("CTRLModel"),vbo=o(" (CTRL model)"),Fbo=l(),Wp=a("li"),Vie=a("strong"),Tbo=o("cvt"),Mbo=o(" \u2014 "),mq=a("a"),Ebo=o("CvtModel"),Cbo=o(" (CvT model)"),wbo=l(),Qp=a("li"),Xie=a("strong"),Abo=o("data2vec-audio"),Lbo=o(" \u2014 "),gq=a("a"),ybo=o("Data2VecAudioModel"),xbo=o(" (Data2VecAudio model)"),$bo=l(),Hp=a("li"),zie=a("strong"),kbo=o("data2vec-text"),Sbo=o(" \u2014 "),hq=a("a"),Rbo=o("Data2VecTextModel"),Pbo=o(" (Data2VecText model)"),Bbo=l(),Up=a("li"),Wie=a("strong"),Ibo=o("data2vec-vision"),Nbo=o(" \u2014 "),pq=a("a"),qbo=o("Data2VecVisionModel"),jbo=o(" (Data2VecVision model)"),Dbo=l(),Jp=a("li"),Qie=a("strong"),Gbo=o("deberta"),Obo=o(" \u2014 "),uq=a("a"),Vbo=o("DebertaModel"),Xbo=o(" (DeBERTa model)"),zbo=l(),Yp=a("li"),Hie=a("strong"),Wbo=o("deberta-v2"),Qbo=o(" \u2014 "),_q=a("a"),Hbo=o("DebertaV2Model"),Ubo=o(" (DeBERTa-v2 model)"),Jbo=l(),Kp=a("li"),Uie=a("strong"),Ybo=o("decision_transformer"),Kbo=o(" \u2014 "),bq=a("a"),Zbo=o("DecisionTransformerModel"),evo=o(" (Decision Transformer model)"),ovo=l(),Zp=a("li"),Jie=a("strong"),rvo=o("deit"),tvo=o(" \u2014 "),vq=a("a"),avo=o("DeiTModel"),nvo=o(" (DeiT model)"),svo=l(),eu=a("li"),Yie=a("strong"),lvo=o("detr"),ivo=o(" \u2014 "),Fq=a("a"),dvo=o("DetrModel"),cvo=o(" (DETR model)"),fvo=l(),ou=a("li"),Kie=a("strong"),mvo=o("distilbert"),gvo=o(" \u2014 "),Tq=a("a"),hvo=o("DistilBertModel"),pvo=o(" (DistilBERT model)"),uvo=l(),ru=a("li"),Zie=a("strong"),_vo=o("dpr"),bvo=o(" \u2014 "),Mq=a("a"),vvo=o("DPRQuestionEncoder"),Fvo=o(" (DPR model)"),Tvo=l(),tu=a("li"),ede=a("strong"),Mvo=o("dpt"),Evo=o(" \u2014 "),Eq=a("a"),Cvo=o("DPTModel"),wvo=o(" (DPT model)"),Avo=l(),au=a("li"),ode=a("strong"),Lvo=o("electra"),yvo=o(" \u2014 "),Cq=a("a"),xvo=o("ElectraModel"),$vo=o(" (ELECTRA model)"),kvo=l(),nu=a("li"),rde=a("strong"),Svo=o("flaubert"),Rvo=o(" \u2014 "),wq=a("a"),Pvo=o("FlaubertModel"),Bvo=o(" (FlauBERT model)"),Ivo=l(),su=a("li"),tde=a("strong"),Nvo=o("flava"),qvo=o(" \u2014 "),Aq=a("a"),jvo=o("FlavaModel"),Dvo=o(" (FLAVA model)"),Gvo=l(),lu=a("li"),ade=a("strong"),Ovo=o("fnet"),Vvo=o(" \u2014 "),Lq=a("a"),Xvo=o("FNetModel"),zvo=o(" (FNet model)"),Wvo=l(),iu=a("li"),nde=a("strong"),Qvo=o("fsmt"),Hvo=o(" \u2014 "),yq=a("a"),Uvo=o("FSMTModel"),Jvo=o(" (FairSeq Machine-Translation model)"),Yvo=l(),Gs=a("li"),sde=a("strong"),Kvo=o("funnel"),Zvo=o(" \u2014 "),xq=a("a"),eFo=o("FunnelModel"),oFo=o(" or "),$q=a("a"),rFo=o("FunnelBaseModel"),tFo=o(" (Funnel Transformer model)"),aFo=l(),du=a("li"),lde=a("strong"),nFo=o("glpn"),sFo=o(" \u2014 "),kq=a("a"),lFo=o("GLPNModel"),iFo=o(" (GLPN model)"),dFo=l(),cu=a("li"),ide=a("strong"),cFo=o("gpt2"),fFo=o(" \u2014 "),Sq=a("a"),mFo=o("GPT2Model"),gFo=o(" (OpenAI GPT-2 model)"),hFo=l(),fu=a("li"),dde=a("strong"),pFo=o("gpt_neo"),uFo=o(" \u2014 "),Rq=a("a"),_Fo=o("GPTNeoModel"),bFo=o(" (GPT Neo model)"),vFo=l(),mu=a("li"),cde=a("strong"),FFo=o("gpt_neox"),TFo=o(" \u2014 "),Pq=a("a"),MFo=o("GPTNeoXModel"),EFo=o(" (GPT NeoX model)"),CFo=l(),gu=a("li"),fde=a("strong"),wFo=o("gptj"),AFo=o(" \u2014 "),Bq=a("a"),LFo=o("GPTJModel"),yFo=o(" (GPT-J model)"),xFo=l(),hu=a("li"),mde=a("strong"),$Fo=o("hubert"),kFo=o(" \u2014 "),Iq=a("a"),SFo=o("HubertModel"),RFo=o(" (Hubert model)"),PFo=l(),pu=a("li"),gde=a("strong"),BFo=o("ibert"),IFo=o(" \u2014 "),Nq=a("a"),NFo=o("IBertModel"),qFo=o(" (I-BERT model)"),jFo=l(),uu=a("li"),hde=a("strong"),DFo=o("imagegpt"),GFo=o(" \u2014 "),qq=a("a"),OFo=o("ImageGPTModel"),VFo=o(" (ImageGPT model)"),XFo=l(),_u=a("li"),pde=a("strong"),zFo=o("layoutlm"),WFo=o(" \u2014 "),jq=a("a"),QFo=o("LayoutLMModel"),HFo=o(" (LayoutLM model)"),UFo=l(),bu=a("li"),ude=a("strong"),JFo=o("layoutlmv2"),YFo=o(" \u2014 "),Dq=a("a"),KFo=o("LayoutLMv2Model"),ZFo=o(" (LayoutLMv2 model)"),eTo=l(),vu=a("li"),_de=a("strong"),oTo=o("layoutlmv3"),rTo=o(" \u2014 "),Gq=a("a"),tTo=o("LayoutLMv3Model"),aTo=o(" (LayoutLMv3 model)"),nTo=l(),Fu=a("li"),bde=a("strong"),sTo=o("led"),lTo=o(" \u2014 "),Oq=a("a"),iTo=o("LEDModel"),dTo=o(" (LED model)"),cTo=l(),Tu=a("li"),vde=a("strong"),fTo=o("levit"),mTo=o(" \u2014 "),Vq=a("a"),gTo=o("LevitModel"),hTo=o(" (LeViT model)"),pTo=l(),Mu=a("li"),Fde=a("strong"),uTo=o("longformer"),_To=o(" \u2014 "),Xq=a("a"),bTo=o("LongformerModel"),vTo=o(" (Longformer model)"),FTo=l(),Eu=a("li"),Tde=a("strong"),TTo=o("longt5"),MTo=o(" \u2014 "),zq=a("a"),ETo=o("LongT5Model"),CTo=o(" (LongT5 model)"),wTo=l(),Cu=a("li"),Mde=a("strong"),ATo=o("luke"),LTo=o(" \u2014 "),Wq=a("a"),yTo=o("LukeModel"),xTo=o(" (LUKE model)"),$To=l(),wu=a("li"),Ede=a("strong"),kTo=o("lxmert"),STo=o(" \u2014 "),Qq=a("a"),RTo=o("LxmertModel"),PTo=o(" (LXMERT model)"),BTo=l(),Au=a("li"),Cde=a("strong"),ITo=o("m2m_100"),NTo=o(" \u2014 "),Hq=a("a"),qTo=o("M2M100Model"),jTo=o(" (M2M100 model)"),DTo=l(),Lu=a("li"),wde=a("strong"),GTo=o("marian"),OTo=o(" \u2014 "),Uq=a("a"),VTo=o("MarianModel"),XTo=o(" (Marian model)"),zTo=l(),yu=a("li"),Ade=a("strong"),WTo=o("maskformer"),QTo=o(" \u2014 "),Jq=a("a"),HTo=o("MaskFormerModel"),UTo=o(" (MaskFormer model)"),JTo=l(),xu=a("li"),Lde=a("strong"),YTo=o("mbart"),KTo=o(" \u2014 "),Yq=a("a"),ZTo=o("MBartModel"),eMo=o(" (mBART model)"),oMo=l(),$u=a("li"),yde=a("strong"),rMo=o("mctct"),tMo=o(" \u2014 "),Kq=a("a"),aMo=o("MCTCTModel"),nMo=o(" (M-CTC-T model)"),sMo=l(),ku=a("li"),xde=a("strong"),lMo=o("megatron-bert"),iMo=o(" \u2014 "),Zq=a("a"),dMo=o("MegatronBertModel"),cMo=o(" (Megatron-BERT model)"),fMo=l(),Su=a("li"),$de=a("strong"),mMo=o("mobilebert"),gMo=o(" \u2014 "),ej=a("a"),hMo=o("MobileBertModel"),pMo=o(" (MobileBERT model)"),uMo=l(),Ru=a("li"),kde=a("strong"),_Mo=o("mpnet"),bMo=o(" \u2014 "),oj=a("a"),vMo=o("MPNetModel"),FMo=o(" (MPNet model)"),TMo=l(),Pu=a("li"),Sde=a("strong"),MMo=o("mt5"),EMo=o(" \u2014 "),rj=a("a"),CMo=o("MT5Model"),wMo=o(" (MT5 model)"),AMo=l(),Bu=a("li"),Rde=a("strong"),LMo=o("nystromformer"),yMo=o(" \u2014 "),tj=a("a"),xMo=o("NystromformerModel"),$Mo=o(" (Nystr\xF6mformer model)"),kMo=l(),Iu=a("li"),Pde=a("strong"),SMo=o("omnivore"),RMo=o(" \u2014 "),aj=a("a"),PMo=o("OmnivoreModel"),BMo=o(" (Omnivore model)"),IMo=l(),Nu=a("li"),Bde=a("strong"),NMo=o("openai-gpt"),qMo=o(" \u2014 "),nj=a("a"),jMo=o("OpenAIGPTModel"),DMo=o(" (OpenAI GPT model)"),GMo=l(),qu=a("li"),Ide=a("strong"),OMo=o("opt"),VMo=o(" \u2014 "),sj=a("a"),XMo=o("OPTModel"),zMo=o(" (OPT model)"),WMo=l(),ju=a("li"),Nde=a("strong"),QMo=o("pegasus"),HMo=o(" \u2014 "),lj=a("a"),UMo=o("PegasusModel"),JMo=o(" (Pegasus model)"),YMo=l(),Du=a("li"),qde=a("strong"),KMo=o("perceiver"),ZMo=o(" \u2014 "),ij=a("a"),eEo=o("PerceiverModel"),oEo=o(" (Perceiver model)"),rEo=l(),Gu=a("li"),jde=a("strong"),tEo=o("plbart"),aEo=o(" \u2014 "),dj=a("a"),nEo=o("PLBartModel"),sEo=o(" (PLBart model)"),lEo=l(),Ou=a("li"),Dde=a("strong"),iEo=o("poolformer"),dEo=o(" \u2014 "),cj=a("a"),cEo=o("PoolFormerModel"),fEo=o(" (PoolFormer model)"),mEo=l(),Vu=a("li"),Gde=a("strong"),gEo=o("prophetnet"),hEo=o(" \u2014 "),fj=a("a"),pEo=o("ProphetNetModel"),uEo=o(" (ProphetNet model)"),_Eo=l(),Xu=a("li"),Ode=a("strong"),bEo=o("qdqbert"),vEo=o(" \u2014 "),mj=a("a"),FEo=o("QDQBertModel"),TEo=o(" (QDQBert model)"),MEo=l(),zu=a("li"),Vde=a("strong"),EEo=o("reformer"),CEo=o(" \u2014 "),gj=a("a"),wEo=o("ReformerModel"),AEo=o(" (Reformer model)"),LEo=l(),Wu=a("li"),Xde=a("strong"),yEo=o("regnet"),xEo=o(" \u2014 "),hj=a("a"),$Eo=o("RegNetModel"),kEo=o(" (RegNet model)"),SEo=l(),Qu=a("li"),zde=a("strong"),REo=o("rembert"),PEo=o(" \u2014 "),pj=a("a"),BEo=o("RemBertModel"),IEo=o(" (RemBERT model)"),NEo=l(),Hu=a("li"),Wde=a("strong"),qEo=o("resnet"),jEo=o(" \u2014 "),uj=a("a"),DEo=o("ResNetModel"),GEo=o(" (ResNet model)"),OEo=l(),Uu=a("li"),Qde=a("strong"),VEo=o("retribert"),XEo=o(" \u2014 "),_j=a("a"),zEo=o("RetriBertModel"),WEo=o(" (RetriBERT model)"),QEo=l(),Ju=a("li"),Hde=a("strong"),HEo=o("roberta"),UEo=o(" \u2014 "),bj=a("a"),JEo=o("RobertaModel"),YEo=o(" (RoBERTa model)"),KEo=l(),Yu=a("li"),Ude=a("strong"),ZEo=o("roformer"),e4o=o(" \u2014 "),vj=a("a"),o4o=o("RoFormerModel"),r4o=o(" (RoFormer model)"),t4o=l(),Ku=a("li"),Jde=a("strong"),a4o=o("segformer"),n4o=o(" \u2014 "),Fj=a("a"),s4o=o("SegformerModel"),l4o=o(" (SegFormer model)"),i4o=l(),Zu=a("li"),Yde=a("strong"),d4o=o("sew"),c4o=o(" \u2014 "),Tj=a("a"),f4o=o("SEWModel"),m4o=o(" (SEW model)"),g4o=l(),e_=a("li"),Kde=a("strong"),h4o=o("sew-d"),p4o=o(" \u2014 "),Mj=a("a"),u4o=o("SEWDModel"),_4o=o(" (SEW-D model)"),b4o=l(),o_=a("li"),Zde=a("strong"),v4o=o("speech_to_text"),F4o=o(" \u2014 "),Ej=a("a"),T4o=o("Speech2TextModel"),M4o=o(" (Speech2Text model)"),E4o=l(),r_=a("li"),ece=a("strong"),C4o=o("splinter"),w4o=o(" \u2014 "),Cj=a("a"),A4o=o("SplinterModel"),L4o=o(" (Splinter model)"),y4o=l(),t_=a("li"),oce=a("strong"),x4o=o("squeezebert"),$4o=o(" \u2014 "),wj=a("a"),k4o=o("SqueezeBertModel"),S4o=o(" (SqueezeBERT model)"),R4o=l(),a_=a("li"),rce=a("strong"),P4o=o("swin"),B4o=o(" \u2014 "),Aj=a("a"),I4o=o("SwinModel"),N4o=o(" (Swin Transformer model)"),q4o=l(),n_=a("li"),tce=a("strong"),j4o=o("t5"),D4o=o(" \u2014 "),Lj=a("a"),G4o=o("T5Model"),O4o=o(" (T5 model)"),V4o=l(),s_=a("li"),ace=a("strong"),X4o=o("tapas"),z4o=o(" \u2014 "),yj=a("a"),W4o=o("TapasModel"),Q4o=o(" (TAPAS model)"),H4o=l(),l_=a("li"),nce=a("strong"),U4o=o("trajectory_transformer"),J4o=o(" \u2014 "),xj=a("a"),Y4o=o("TrajectoryTransformerModel"),K4o=o(" (Trajectory Transformer model)"),Z4o=l(),i_=a("li"),sce=a("strong"),eCo=o("transfo-xl"),oCo=o(" \u2014 "),$j=a("a"),rCo=o("TransfoXLModel"),tCo=o(" (Transformer-XL model)"),aCo=l(),d_=a("li"),lce=a("strong"),nCo=o("unispeech"),sCo=o(" \u2014 "),kj=a("a"),lCo=o("UniSpeechModel"),iCo=o(" (UniSpeech model)"),dCo=l(),c_=a("li"),ice=a("strong"),cCo=o("unispeech-sat"),fCo=o(" \u2014 "),Sj=a("a"),mCo=o("UniSpeechSatModel"),gCo=o(" (UniSpeechSat model)"),hCo=l(),f_=a("li"),dce=a("strong"),pCo=o("van"),uCo=o(" \u2014 "),Rj=a("a"),_Co=o("VanModel"),bCo=o(" (VAN model)"),vCo=l(),m_=a("li"),cce=a("strong"),FCo=o("vilt"),TCo=o(" \u2014 "),Pj=a("a"),MCo=o("ViltModel"),ECo=o(" (ViLT model)"),CCo=l(),g_=a("li"),fce=a("strong"),wCo=o("vision-text-dual-encoder"),ACo=o(" \u2014 "),Bj=a("a"),LCo=o("VisionTextDualEncoderModel"),yCo=o(" (VisionTextDualEncoder model)"),xCo=l(),h_=a("li"),mce=a("strong"),$Co=o("visual_bert"),kCo=o(" \u2014 "),Ij=a("a"),SCo=o("VisualBertModel"),RCo=o(" (VisualBERT model)"),PCo=l(),p_=a("li"),gce=a("strong"),BCo=o("vit"),ICo=o(" \u2014 "),Nj=a("a"),NCo=o("ViTModel"),qCo=o(" (ViT model)"),jCo=l(),u_=a("li"),hce=a("strong"),DCo=o("vit_mae"),GCo=o(" \u2014 "),qj=a("a"),OCo=o("ViTMAEModel"),VCo=o(" (ViTMAE model)"),XCo=l(),__=a("li"),pce=a("strong"),zCo=o("wav2vec2"),WCo=o(" \u2014 "),jj=a("a"),QCo=o("Wav2Vec2Model"),HCo=o(" (Wav2Vec2 model)"),UCo=l(),b_=a("li"),uce=a("strong"),JCo=o("wav2vec2-conformer"),YCo=o(" \u2014 "),Dj=a("a"),KCo=o("Wav2Vec2ConformerModel"),ZCo=o(" (Wav2Vec2-Conformer model)"),e5o=l(),v_=a("li"),_ce=a("strong"),o5o=o("wavlm"),r5o=o(" \u2014 "),Gj=a("a"),t5o=o("WavLMModel"),a5o=o(" (WavLM model)"),n5o=l(),F_=a("li"),bce=a("strong"),s5o=o("xglm"),l5o=o(" \u2014 "),Oj=a("a"),i5o=o("XGLMModel"),d5o=o(" (XGLM model)"),c5o=l(),T_=a("li"),vce=a("strong"),f5o=o("xlm"),m5o=o(" \u2014 "),Vj=a("a"),g5o=o("XLMModel"),h5o=o(" (XLM model)"),p5o=l(),M_=a("li"),Fce=a("strong"),u5o=o("xlm-prophetnet"),_5o=o(" \u2014 "),Xj=a("a"),b5o=o("XLMProphetNetModel"),v5o=o(" (XLM-ProphetNet model)"),F5o=l(),E_=a("li"),Tce=a("strong"),T5o=o("xlm-roberta"),M5o=o(" \u2014 "),zj=a("a"),E5o=o("XLMRobertaModel"),C5o=o(" (XLM-RoBERTa model)"),w5o=l(),C_=a("li"),Mce=a("strong"),A5o=o("xlm-roberta-xl"),L5o=o(" \u2014 "),Wj=a("a"),y5o=o("XLMRobertaXLModel"),x5o=o(" (XLM-RoBERTa-XL model)"),$5o=l(),w_=a("li"),Ece=a("strong"),k5o=o("xlnet"),S5o=o(" \u2014 "),Qj=a("a"),R5o=o("XLNetModel"),P5o=o(" (XLNet model)"),B5o=l(),A_=a("li"),Cce=a("strong"),I5o=o("yolos"),N5o=o(" \u2014 "),Hj=a("a"),q5o=o("YolosModel"),j5o=o(" (YOLOS model)"),D5o=l(),L_=a("li"),wce=a("strong"),G5o=o("yoso"),O5o=o(" \u2014 "),Uj=a("a"),V5o=o("YosoModel"),X5o=o(" (YOSO model)"),z5o=l(),y_=a("p"),W5o=o("The model is set in evaluation mode by default using "),Ace=a("code"),Q5o=o("model.eval()"),H5o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lce=a("code"),U5o=o("model.train()"),J5o=l(),F(x_.$$.fragment),xGe=l(),Ni=a("h2"),$_=a("a"),yce=a("span"),F(ey.$$.fragment),Y5o=l(),xce=a("span"),K5o=o("AutoModelForPreTraining"),$Ge=l(),$o=a("div"),F(oy.$$.fragment),Z5o=l(),qi=a("p"),e3o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Jj=a("a"),o3o=o("from_pretrained()"),r3o=o(" class method or the "),Yj=a("a"),t3o=o("from_config()"),a3o=o(` class
method.`),n3o=l(),ry=a("p"),s3o=o("This class cannot be instantiated directly using "),$ce=a("code"),l3o=o("__init__()"),i3o=o(" (throws an error)."),d3o=l(),st=a("div"),F(ty.$$.fragment),c3o=l(),kce=a("p"),f3o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),m3o=l(),ji=a("p"),g3o=o(`Note:
Loading a model from its configuration file does `),Sce=a("strong"),h3o=o("not"),p3o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kj=a("a"),u3o=o("from_pretrained()"),_3o=o(" to load the model weights."),b3o=l(),F(k_.$$.fragment),v3o=l(),Ye=a("div"),F(ay.$$.fragment),F3o=l(),Rce=a("p"),T3o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),M3o=l(),Ra=a("p"),E3o=o("The model class to instantiate is selected based on the "),Pce=a("code"),C3o=o("model_type"),w3o=o(` property of the config object (either
passed as an argument or loaded from `),Bce=a("code"),A3o=o("pretrained_model_name_or_path"),L3o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ice=a("code"),y3o=o("pretrained_model_name_or_path"),x3o=o(":"),$3o=l(),G=a("ul"),S_=a("li"),Nce=a("strong"),k3o=o("albert"),S3o=o(" \u2014 "),Zj=a("a"),R3o=o("AlbertForPreTraining"),P3o=o(" (ALBERT model)"),B3o=l(),R_=a("li"),qce=a("strong"),I3o=o("bart"),N3o=o(" \u2014 "),eD=a("a"),q3o=o("BartForConditionalGeneration"),j3o=o(" (BART model)"),D3o=l(),P_=a("li"),jce=a("strong"),G3o=o("bert"),O3o=o(" \u2014 "),oD=a("a"),V3o=o("BertForPreTraining"),X3o=o(" (BERT model)"),z3o=l(),B_=a("li"),Dce=a("strong"),W3o=o("big_bird"),Q3o=o(" \u2014 "),rD=a("a"),H3o=o("BigBirdForPreTraining"),U3o=o(" (BigBird model)"),J3o=l(),I_=a("li"),Gce=a("strong"),Y3o=o("bloom"),K3o=o(" \u2014 "),tD=a("a"),Z3o=o("BloomForCausalLM"),e0o=o(" (BLOOM model)"),o0o=l(),N_=a("li"),Oce=a("strong"),r0o=o("camembert"),t0o=o(" \u2014 "),aD=a("a"),a0o=o("CamembertForMaskedLM"),n0o=o(" (CamemBERT model)"),s0o=l(),q_=a("li"),Vce=a("strong"),l0o=o("ctrl"),i0o=o(" \u2014 "),nD=a("a"),d0o=o("CTRLLMHeadModel"),c0o=o(" (CTRL model)"),f0o=l(),j_=a("li"),Xce=a("strong"),m0o=o("data2vec-text"),g0o=o(" \u2014 "),sD=a("a"),h0o=o("Data2VecTextForMaskedLM"),p0o=o(" (Data2VecText model)"),u0o=l(),D_=a("li"),zce=a("strong"),_0o=o("deberta"),b0o=o(" \u2014 "),lD=a("a"),v0o=o("DebertaForMaskedLM"),F0o=o(" (DeBERTa model)"),T0o=l(),G_=a("li"),Wce=a("strong"),M0o=o("deberta-v2"),E0o=o(" \u2014 "),iD=a("a"),C0o=o("DebertaV2ForMaskedLM"),w0o=o(" (DeBERTa-v2 model)"),A0o=l(),O_=a("li"),Qce=a("strong"),L0o=o("distilbert"),y0o=o(" \u2014 "),dD=a("a"),x0o=o("DistilBertForMaskedLM"),$0o=o(" (DistilBERT model)"),k0o=l(),V_=a("li"),Hce=a("strong"),S0o=o("electra"),R0o=o(" \u2014 "),cD=a("a"),P0o=o("ElectraForPreTraining"),B0o=o(" (ELECTRA model)"),I0o=l(),X_=a("li"),Uce=a("strong"),N0o=o("flaubert"),q0o=o(" \u2014 "),fD=a("a"),j0o=o("FlaubertWithLMHeadModel"),D0o=o(" (FlauBERT model)"),G0o=l(),z_=a("li"),Jce=a("strong"),O0o=o("flava"),V0o=o(" \u2014 "),mD=a("a"),X0o=o("FlavaForPreTraining"),z0o=o(" (FLAVA model)"),W0o=l(),W_=a("li"),Yce=a("strong"),Q0o=o("fnet"),H0o=o(" \u2014 "),gD=a("a"),U0o=o("FNetForPreTraining"),J0o=o(" (FNet model)"),Y0o=l(),Q_=a("li"),Kce=a("strong"),K0o=o("fsmt"),Z0o=o(" \u2014 "),hD=a("a"),ewo=o("FSMTForConditionalGeneration"),owo=o(" (FairSeq Machine-Translation model)"),rwo=l(),H_=a("li"),Zce=a("strong"),two=o("funnel"),awo=o(" \u2014 "),pD=a("a"),nwo=o("FunnelForPreTraining"),swo=o(" (Funnel Transformer model)"),lwo=l(),U_=a("li"),efe=a("strong"),iwo=o("gpt2"),dwo=o(" \u2014 "),uD=a("a"),cwo=o("GPT2LMHeadModel"),fwo=o(" (OpenAI GPT-2 model)"),mwo=l(),J_=a("li"),ofe=a("strong"),gwo=o("ibert"),hwo=o(" \u2014 "),_D=a("a"),pwo=o("IBertForMaskedLM"),uwo=o(" (I-BERT model)"),_wo=l(),Y_=a("li"),rfe=a("strong"),bwo=o("layoutlm"),vwo=o(" \u2014 "),bD=a("a"),Fwo=o("LayoutLMForMaskedLM"),Two=o(" (LayoutLM model)"),Mwo=l(),K_=a("li"),tfe=a("strong"),Ewo=o("longformer"),Cwo=o(" \u2014 "),vD=a("a"),wwo=o("LongformerForMaskedLM"),Awo=o(" (Longformer model)"),Lwo=l(),Z_=a("li"),afe=a("strong"),ywo=o("lxmert"),xwo=o(" \u2014 "),FD=a("a"),$wo=o("LxmertForPreTraining"),kwo=o(" (LXMERT model)"),Swo=l(),e7=a("li"),nfe=a("strong"),Rwo=o("megatron-bert"),Pwo=o(" \u2014 "),TD=a("a"),Bwo=o("MegatronBertForPreTraining"),Iwo=o(" (Megatron-BERT model)"),Nwo=l(),o7=a("li"),sfe=a("strong"),qwo=o("mobilebert"),jwo=o(" \u2014 "),MD=a("a"),Dwo=o("MobileBertForPreTraining"),Gwo=o(" (MobileBERT model)"),Owo=l(),r7=a("li"),lfe=a("strong"),Vwo=o("mpnet"),Xwo=o(" \u2014 "),ED=a("a"),zwo=o("MPNetForMaskedLM"),Wwo=o(" (MPNet model)"),Qwo=l(),t7=a("li"),ife=a("strong"),Hwo=o("openai-gpt"),Uwo=o(" \u2014 "),CD=a("a"),Jwo=o("OpenAIGPTLMHeadModel"),Ywo=o(" (OpenAI GPT model)"),Kwo=l(),a7=a("li"),dfe=a("strong"),Zwo=o("retribert"),eAo=o(" \u2014 "),wD=a("a"),oAo=o("RetriBertModel"),rAo=o(" (RetriBERT model)"),tAo=l(),n7=a("li"),cfe=a("strong"),aAo=o("roberta"),nAo=o(" \u2014 "),AD=a("a"),sAo=o("RobertaForMaskedLM"),lAo=o(" (RoBERTa model)"),iAo=l(),s7=a("li"),ffe=a("strong"),dAo=o("splinter"),cAo=o(" \u2014 "),LD=a("a"),fAo=o("SplinterForPreTraining"),mAo=o(" (Splinter model)"),gAo=l(),l7=a("li"),mfe=a("strong"),hAo=o("squeezebert"),pAo=o(" \u2014 "),yD=a("a"),uAo=o("SqueezeBertForMaskedLM"),_Ao=o(" (SqueezeBERT model)"),bAo=l(),i7=a("li"),gfe=a("strong"),vAo=o("t5"),FAo=o(" \u2014 "),xD=a("a"),TAo=o("T5ForConditionalGeneration"),MAo=o(" (T5 model)"),EAo=l(),d7=a("li"),hfe=a("strong"),CAo=o("tapas"),wAo=o(" \u2014 "),$D=a("a"),AAo=o("TapasForMaskedLM"),LAo=o(" (TAPAS model)"),yAo=l(),c7=a("li"),pfe=a("strong"),xAo=o("transfo-xl"),$Ao=o(" \u2014 "),kD=a("a"),kAo=o("TransfoXLLMHeadModel"),SAo=o(" (Transformer-XL model)"),RAo=l(),f7=a("li"),ufe=a("strong"),PAo=o("unispeech"),BAo=o(" \u2014 "),SD=a("a"),IAo=o("UniSpeechForPreTraining"),NAo=o(" (UniSpeech model)"),qAo=l(),m7=a("li"),_fe=a("strong"),jAo=o("unispeech-sat"),DAo=o(" \u2014 "),RD=a("a"),GAo=o("UniSpeechSatForPreTraining"),OAo=o(" (UniSpeechSat model)"),VAo=l(),g7=a("li"),bfe=a("strong"),XAo=o("visual_bert"),zAo=o(" \u2014 "),PD=a("a"),WAo=o("VisualBertForPreTraining"),QAo=o(" (VisualBERT model)"),HAo=l(),h7=a("li"),vfe=a("strong"),UAo=o("vit_mae"),JAo=o(" \u2014 "),BD=a("a"),YAo=o("ViTMAEForPreTraining"),KAo=o(" (ViTMAE model)"),ZAo=l(),p7=a("li"),Ffe=a("strong"),e6o=o("wav2vec2"),o6o=o(" \u2014 "),ID=a("a"),r6o=o("Wav2Vec2ForPreTraining"),t6o=o(" (Wav2Vec2 model)"),a6o=l(),u7=a("li"),Tfe=a("strong"),n6o=o("wav2vec2-conformer"),s6o=o(" \u2014 "),ND=a("a"),l6o=o("Wav2Vec2ConformerForPreTraining"),i6o=o(" (Wav2Vec2-Conformer model)"),d6o=l(),_7=a("li"),Mfe=a("strong"),c6o=o("xlm"),f6o=o(" \u2014 "),qD=a("a"),m6o=o("XLMWithLMHeadModel"),g6o=o(" (XLM model)"),h6o=l(),b7=a("li"),Efe=a("strong"),p6o=o("xlm-roberta"),u6o=o(" \u2014 "),jD=a("a"),_6o=o("XLMRobertaForMaskedLM"),b6o=o(" (XLM-RoBERTa model)"),v6o=l(),v7=a("li"),Cfe=a("strong"),F6o=o("xlm-roberta-xl"),T6o=o(" \u2014 "),DD=a("a"),M6o=o("XLMRobertaXLForMaskedLM"),E6o=o(" (XLM-RoBERTa-XL model)"),C6o=l(),F7=a("li"),wfe=a("strong"),w6o=o("xlnet"),A6o=o(" \u2014 "),GD=a("a"),L6o=o("XLNetLMHeadModel"),y6o=o(" (XLNet model)"),x6o=l(),T7=a("p"),$6o=o("The model is set in evaluation mode by default using "),Afe=a("code"),k6o=o("model.eval()"),S6o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lfe=a("code"),R6o=o("model.train()"),P6o=l(),F(M7.$$.fragment),kGe=l(),Di=a("h2"),E7=a("a"),yfe=a("span"),F(ny.$$.fragment),B6o=l(),xfe=a("span"),I6o=o("AutoModelForCausalLM"),SGe=l(),ko=a("div"),F(sy.$$.fragment),N6o=l(),Gi=a("p"),q6o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),OD=a("a"),j6o=o("from_pretrained()"),D6o=o(" class method or the "),VD=a("a"),G6o=o("from_config()"),O6o=o(` class
method.`),V6o=l(),ly=a("p"),X6o=o("This class cannot be instantiated directly using "),$fe=a("code"),z6o=o("__init__()"),W6o=o(" (throws an error)."),Q6o=l(),lt=a("div"),F(iy.$$.fragment),H6o=l(),kfe=a("p"),U6o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),J6o=l(),Oi=a("p"),Y6o=o(`Note:
Loading a model from its configuration file does `),Sfe=a("strong"),K6o=o("not"),Z6o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XD=a("a"),eLo=o("from_pretrained()"),oLo=o(" to load the model weights."),rLo=l(),F(C7.$$.fragment),tLo=l(),Ke=a("div"),F(dy.$$.fragment),aLo=l(),Rfe=a("p"),nLo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),sLo=l(),Pa=a("p"),lLo=o("The model class to instantiate is selected based on the "),Pfe=a("code"),iLo=o("model_type"),dLo=o(` property of the config object (either
passed as an argument or loaded from `),Bfe=a("code"),cLo=o("pretrained_model_name_or_path"),fLo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ife=a("code"),mLo=o("pretrained_model_name_or_path"),gLo=o(":"),hLo=l(),z=a("ul"),w7=a("li"),Nfe=a("strong"),pLo=o("bart"),uLo=o(" \u2014 "),zD=a("a"),_Lo=o("BartForCausalLM"),bLo=o(" (BART model)"),vLo=l(),A7=a("li"),qfe=a("strong"),FLo=o("bert"),TLo=o(" \u2014 "),WD=a("a"),MLo=o("BertLMHeadModel"),ELo=o(" (BERT model)"),CLo=l(),L7=a("li"),jfe=a("strong"),wLo=o("bert-generation"),ALo=o(" \u2014 "),QD=a("a"),LLo=o("BertGenerationDecoder"),yLo=o(" (Bert Generation model)"),xLo=l(),y7=a("li"),Dfe=a("strong"),$Lo=o("big_bird"),kLo=o(" \u2014 "),HD=a("a"),SLo=o("BigBirdForCausalLM"),RLo=o(" (BigBird model)"),PLo=l(),x7=a("li"),Gfe=a("strong"),BLo=o("bigbird_pegasus"),ILo=o(" \u2014 "),UD=a("a"),NLo=o("BigBirdPegasusForCausalLM"),qLo=o(" (BigBird-Pegasus model)"),jLo=l(),$7=a("li"),Ofe=a("strong"),DLo=o("blenderbot"),GLo=o(" \u2014 "),JD=a("a"),OLo=o("BlenderbotForCausalLM"),VLo=o(" (Blenderbot model)"),XLo=l(),k7=a("li"),Vfe=a("strong"),zLo=o("blenderbot-small"),WLo=o(" \u2014 "),YD=a("a"),QLo=o("BlenderbotSmallForCausalLM"),HLo=o(" (BlenderbotSmall model)"),ULo=l(),S7=a("li"),Xfe=a("strong"),JLo=o("bloom"),YLo=o(" \u2014 "),KD=a("a"),KLo=o("BloomForCausalLM"),ZLo=o(" (BLOOM model)"),eyo=l(),R7=a("li"),zfe=a("strong"),oyo=o("camembert"),ryo=o(" \u2014 "),ZD=a("a"),tyo=o("CamembertForCausalLM"),ayo=o(" (CamemBERT model)"),nyo=l(),P7=a("li"),Wfe=a("strong"),syo=o("ctrl"),lyo=o(" \u2014 "),eG=a("a"),iyo=o("CTRLLMHeadModel"),dyo=o(" (CTRL model)"),cyo=l(),B7=a("li"),Qfe=a("strong"),fyo=o("data2vec-text"),myo=o(" \u2014 "),oG=a("a"),gyo=o("Data2VecTextForCausalLM"),hyo=o(" (Data2VecText model)"),pyo=l(),I7=a("li"),Hfe=a("strong"),uyo=o("electra"),_yo=o(" \u2014 "),rG=a("a"),byo=o("ElectraForCausalLM"),vyo=o(" (ELECTRA model)"),Fyo=l(),N7=a("li"),Ufe=a("strong"),Tyo=o("gpt2"),Myo=o(" \u2014 "),tG=a("a"),Eyo=o("GPT2LMHeadModel"),Cyo=o(" (OpenAI GPT-2 model)"),wyo=l(),q7=a("li"),Jfe=a("strong"),Ayo=o("gpt_neo"),Lyo=o(" \u2014 "),aG=a("a"),yyo=o("GPTNeoForCausalLM"),xyo=o(" (GPT Neo model)"),$yo=l(),j7=a("li"),Yfe=a("strong"),kyo=o("gpt_neox"),Syo=o(" \u2014 "),nG=a("a"),Ryo=o("GPTNeoXForCausalLM"),Pyo=o(" (GPT NeoX model)"),Byo=l(),D7=a("li"),Kfe=a("strong"),Iyo=o("gptj"),Nyo=o(" \u2014 "),sG=a("a"),qyo=o("GPTJForCausalLM"),jyo=o(" (GPT-J model)"),Dyo=l(),G7=a("li"),Zfe=a("strong"),Gyo=o("marian"),Oyo=o(" \u2014 "),lG=a("a"),Vyo=o("MarianForCausalLM"),Xyo=o(" (Marian model)"),zyo=l(),O7=a("li"),eme=a("strong"),Wyo=o("mbart"),Qyo=o(" \u2014 "),iG=a("a"),Hyo=o("MBartForCausalLM"),Uyo=o(" (mBART model)"),Jyo=l(),V7=a("li"),ome=a("strong"),Yyo=o("megatron-bert"),Kyo=o(" \u2014 "),dG=a("a"),Zyo=o("MegatronBertForCausalLM"),e8o=o(" (Megatron-BERT model)"),o8o=l(),X7=a("li"),rme=a("strong"),r8o=o("openai-gpt"),t8o=o(" \u2014 "),cG=a("a"),a8o=o("OpenAIGPTLMHeadModel"),n8o=o(" (OpenAI GPT model)"),s8o=l(),z7=a("li"),tme=a("strong"),l8o=o("opt"),i8o=o(" \u2014 "),fG=a("a"),d8o=o("OPTForCausalLM"),c8o=o(" (OPT model)"),f8o=l(),W7=a("li"),ame=a("strong"),m8o=o("pegasus"),g8o=o(" \u2014 "),mG=a("a"),h8o=o("PegasusForCausalLM"),p8o=o(" (Pegasus model)"),u8o=l(),Q7=a("li"),nme=a("strong"),_8o=o("plbart"),b8o=o(" \u2014 "),gG=a("a"),v8o=o("PLBartForCausalLM"),F8o=o(" (PLBart model)"),T8o=l(),H7=a("li"),sme=a("strong"),M8o=o("prophetnet"),E8o=o(" \u2014 "),hG=a("a"),C8o=o("ProphetNetForCausalLM"),w8o=o(" (ProphetNet model)"),A8o=l(),U7=a("li"),lme=a("strong"),L8o=o("qdqbert"),y8o=o(" \u2014 "),pG=a("a"),x8o=o("QDQBertLMHeadModel"),$8o=o(" (QDQBert model)"),k8o=l(),J7=a("li"),ime=a("strong"),S8o=o("reformer"),R8o=o(" \u2014 "),uG=a("a"),P8o=o("ReformerModelWithLMHead"),B8o=o(" (Reformer model)"),I8o=l(),Y7=a("li"),dme=a("strong"),N8o=o("rembert"),q8o=o(" \u2014 "),_G=a("a"),j8o=o("RemBertForCausalLM"),D8o=o(" (RemBERT model)"),G8o=l(),K7=a("li"),cme=a("strong"),O8o=o("roberta"),V8o=o(" \u2014 "),bG=a("a"),X8o=o("RobertaForCausalLM"),z8o=o(" (RoBERTa model)"),W8o=l(),Z7=a("li"),fme=a("strong"),Q8o=o("roformer"),H8o=o(" \u2014 "),vG=a("a"),U8o=o("RoFormerForCausalLM"),J8o=o(" (RoFormer model)"),Y8o=l(),e2=a("li"),mme=a("strong"),K8o=o("speech_to_text_2"),Z8o=o(" \u2014 "),FG=a("a"),e9o=o("Speech2Text2ForCausalLM"),o9o=o(" (Speech2Text2 model)"),r9o=l(),o2=a("li"),gme=a("strong"),t9o=o("transfo-xl"),a9o=o(" \u2014 "),TG=a("a"),n9o=o("TransfoXLLMHeadModel"),s9o=o(" (Transformer-XL model)"),l9o=l(),r2=a("li"),hme=a("strong"),i9o=o("trocr"),d9o=o(" \u2014 "),MG=a("a"),c9o=o("TrOCRForCausalLM"),f9o=o(" (TrOCR model)"),m9o=l(),t2=a("li"),pme=a("strong"),g9o=o("xglm"),h9o=o(" \u2014 "),EG=a("a"),p9o=o("XGLMForCausalLM"),u9o=o(" (XGLM model)"),_9o=l(),a2=a("li"),ume=a("strong"),b9o=o("xlm"),v9o=o(" \u2014 "),CG=a("a"),F9o=o("XLMWithLMHeadModel"),T9o=o(" (XLM model)"),M9o=l(),n2=a("li"),_me=a("strong"),E9o=o("xlm-prophetnet"),C9o=o(" \u2014 "),wG=a("a"),w9o=o("XLMProphetNetForCausalLM"),A9o=o(" (XLM-ProphetNet model)"),L9o=l(),s2=a("li"),bme=a("strong"),y9o=o("xlm-roberta"),x9o=o(" \u2014 "),AG=a("a"),$9o=o("XLMRobertaForCausalLM"),k9o=o(" (XLM-RoBERTa model)"),S9o=l(),l2=a("li"),vme=a("strong"),R9o=o("xlm-roberta-xl"),P9o=o(" \u2014 "),LG=a("a"),B9o=o("XLMRobertaXLForCausalLM"),I9o=o(" (XLM-RoBERTa-XL model)"),N9o=l(),i2=a("li"),Fme=a("strong"),q9o=o("xlnet"),j9o=o(" \u2014 "),yG=a("a"),D9o=o("XLNetLMHeadModel"),G9o=o(" (XLNet model)"),O9o=l(),d2=a("p"),V9o=o("The model is set in evaluation mode by default using "),Tme=a("code"),X9o=o("model.eval()"),z9o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mme=a("code"),W9o=o("model.train()"),Q9o=l(),F(c2.$$.fragment),RGe=l(),Vi=a("h2"),f2=a("a"),Eme=a("span"),F(cy.$$.fragment),H9o=l(),Cme=a("span"),U9o=o("AutoModelForMaskedLM"),PGe=l(),So=a("div"),F(fy.$$.fragment),J9o=l(),Xi=a("p"),Y9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),xG=a("a"),K9o=o("from_pretrained()"),Z9o=o(" class method or the "),$G=a("a"),exo=o("from_config()"),oxo=o(` class
method.`),rxo=l(),my=a("p"),txo=o("This class cannot be instantiated directly using "),wme=a("code"),axo=o("__init__()"),nxo=o(" (throws an error)."),sxo=l(),it=a("div"),F(gy.$$.fragment),lxo=l(),Ame=a("p"),ixo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),dxo=l(),zi=a("p"),cxo=o(`Note:
Loading a model from its configuration file does `),Lme=a("strong"),fxo=o("not"),mxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kG=a("a"),gxo=o("from_pretrained()"),hxo=o(" to load the model weights."),pxo=l(),F(m2.$$.fragment),uxo=l(),Ze=a("div"),F(hy.$$.fragment),_xo=l(),yme=a("p"),bxo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),vxo=l(),Ba=a("p"),Fxo=o("The model class to instantiate is selected based on the "),xme=a("code"),Txo=o("model_type"),Mxo=o(` property of the config object (either
passed as an argument or loaded from `),$me=a("code"),Exo=o("pretrained_model_name_or_path"),Cxo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kme=a("code"),wxo=o("pretrained_model_name_or_path"),Axo=o(":"),Lxo=l(),Q=a("ul"),g2=a("li"),Sme=a("strong"),yxo=o("albert"),xxo=o(" \u2014 "),SG=a("a"),$xo=o("AlbertForMaskedLM"),kxo=o(" (ALBERT model)"),Sxo=l(),h2=a("li"),Rme=a("strong"),Rxo=o("bart"),Pxo=o(" \u2014 "),RG=a("a"),Bxo=o("BartForConditionalGeneration"),Ixo=o(" (BART model)"),Nxo=l(),p2=a("li"),Pme=a("strong"),qxo=o("bert"),jxo=o(" \u2014 "),PG=a("a"),Dxo=o("BertForMaskedLM"),Gxo=o(" (BERT model)"),Oxo=l(),u2=a("li"),Bme=a("strong"),Vxo=o("big_bird"),Xxo=o(" \u2014 "),BG=a("a"),zxo=o("BigBirdForMaskedLM"),Wxo=o(" (BigBird model)"),Qxo=l(),_2=a("li"),Ime=a("strong"),Hxo=o("camembert"),Uxo=o(" \u2014 "),IG=a("a"),Jxo=o("CamembertForMaskedLM"),Yxo=o(" (CamemBERT model)"),Kxo=l(),b2=a("li"),Nme=a("strong"),Zxo=o("convbert"),e$o=o(" \u2014 "),NG=a("a"),o$o=o("ConvBertForMaskedLM"),r$o=o(" (ConvBERT model)"),t$o=l(),v2=a("li"),qme=a("strong"),a$o=o("data2vec-text"),n$o=o(" \u2014 "),qG=a("a"),s$o=o("Data2VecTextForMaskedLM"),l$o=o(" (Data2VecText model)"),i$o=l(),F2=a("li"),jme=a("strong"),d$o=o("deberta"),c$o=o(" \u2014 "),jG=a("a"),f$o=o("DebertaForMaskedLM"),m$o=o(" (DeBERTa model)"),g$o=l(),T2=a("li"),Dme=a("strong"),h$o=o("deberta-v2"),p$o=o(" \u2014 "),DG=a("a"),u$o=o("DebertaV2ForMaskedLM"),_$o=o(" (DeBERTa-v2 model)"),b$o=l(),M2=a("li"),Gme=a("strong"),v$o=o("distilbert"),F$o=o(" \u2014 "),GG=a("a"),T$o=o("DistilBertForMaskedLM"),M$o=o(" (DistilBERT model)"),E$o=l(),E2=a("li"),Ome=a("strong"),C$o=o("electra"),w$o=o(" \u2014 "),OG=a("a"),A$o=o("ElectraForMaskedLM"),L$o=o(" (ELECTRA model)"),y$o=l(),C2=a("li"),Vme=a("strong"),x$o=o("flaubert"),$$o=o(" \u2014 "),VG=a("a"),k$o=o("FlaubertWithLMHeadModel"),S$o=o(" (FlauBERT model)"),R$o=l(),w2=a("li"),Xme=a("strong"),P$o=o("fnet"),B$o=o(" \u2014 "),XG=a("a"),I$o=o("FNetForMaskedLM"),N$o=o(" (FNet model)"),q$o=l(),A2=a("li"),zme=a("strong"),j$o=o("funnel"),D$o=o(" \u2014 "),zG=a("a"),G$o=o("FunnelForMaskedLM"),O$o=o(" (Funnel Transformer model)"),V$o=l(),L2=a("li"),Wme=a("strong"),X$o=o("ibert"),z$o=o(" \u2014 "),WG=a("a"),W$o=o("IBertForMaskedLM"),Q$o=o(" (I-BERT model)"),H$o=l(),y2=a("li"),Qme=a("strong"),U$o=o("layoutlm"),J$o=o(" \u2014 "),QG=a("a"),Y$o=o("LayoutLMForMaskedLM"),K$o=o(" (LayoutLM model)"),Z$o=l(),x2=a("li"),Hme=a("strong"),eko=o("longformer"),oko=o(" \u2014 "),HG=a("a"),rko=o("LongformerForMaskedLM"),tko=o(" (Longformer model)"),ako=l(),$2=a("li"),Ume=a("strong"),nko=o("luke"),sko=o(" \u2014 "),UG=a("a"),lko=o("LukeForMaskedLM"),iko=o(" (LUKE model)"),dko=l(),k2=a("li"),Jme=a("strong"),cko=o("mbart"),fko=o(" \u2014 "),JG=a("a"),mko=o("MBartForConditionalGeneration"),gko=o(" (mBART model)"),hko=l(),S2=a("li"),Yme=a("strong"),pko=o("megatron-bert"),uko=o(" \u2014 "),YG=a("a"),_ko=o("MegatronBertForMaskedLM"),bko=o(" (Megatron-BERT model)"),vko=l(),R2=a("li"),Kme=a("strong"),Fko=o("mobilebert"),Tko=o(" \u2014 "),KG=a("a"),Mko=o("MobileBertForMaskedLM"),Eko=o(" (MobileBERT model)"),Cko=l(),P2=a("li"),Zme=a("strong"),wko=o("mpnet"),Ako=o(" \u2014 "),ZG=a("a"),Lko=o("MPNetForMaskedLM"),yko=o(" (MPNet model)"),xko=l(),B2=a("li"),ege=a("strong"),$ko=o("nystromformer"),kko=o(" \u2014 "),eO=a("a"),Sko=o("NystromformerForMaskedLM"),Rko=o(" (Nystr\xF6mformer model)"),Pko=l(),I2=a("li"),oge=a("strong"),Bko=o("perceiver"),Iko=o(" \u2014 "),oO=a("a"),Nko=o("PerceiverForMaskedLM"),qko=o(" (Perceiver model)"),jko=l(),N2=a("li"),rge=a("strong"),Dko=o("qdqbert"),Gko=o(" \u2014 "),rO=a("a"),Oko=o("QDQBertForMaskedLM"),Vko=o(" (QDQBert model)"),Xko=l(),q2=a("li"),tge=a("strong"),zko=o("reformer"),Wko=o(" \u2014 "),tO=a("a"),Qko=o("ReformerForMaskedLM"),Hko=o(" (Reformer model)"),Uko=l(),j2=a("li"),age=a("strong"),Jko=o("rembert"),Yko=o(" \u2014 "),aO=a("a"),Kko=o("RemBertForMaskedLM"),Zko=o(" (RemBERT model)"),eSo=l(),D2=a("li"),nge=a("strong"),oSo=o("roberta"),rSo=o(" \u2014 "),nO=a("a"),tSo=o("RobertaForMaskedLM"),aSo=o(" (RoBERTa model)"),nSo=l(),G2=a("li"),sge=a("strong"),sSo=o("roformer"),lSo=o(" \u2014 "),sO=a("a"),iSo=o("RoFormerForMaskedLM"),dSo=o(" (RoFormer model)"),cSo=l(),O2=a("li"),lge=a("strong"),fSo=o("squeezebert"),mSo=o(" \u2014 "),lO=a("a"),gSo=o("SqueezeBertForMaskedLM"),hSo=o(" (SqueezeBERT model)"),pSo=l(),V2=a("li"),ige=a("strong"),uSo=o("tapas"),_So=o(" \u2014 "),iO=a("a"),bSo=o("TapasForMaskedLM"),vSo=o(" (TAPAS model)"),FSo=l(),X2=a("li"),dge=a("strong"),TSo=o("wav2vec2"),MSo=o(" \u2014 "),cge=a("code"),ESo=o("Wav2Vec2ForMaskedLM"),CSo=o(" (Wav2Vec2 model)"),wSo=l(),z2=a("li"),fge=a("strong"),ASo=o("xlm"),LSo=o(" \u2014 "),dO=a("a"),ySo=o("XLMWithLMHeadModel"),xSo=o(" (XLM model)"),$So=l(),W2=a("li"),mge=a("strong"),kSo=o("xlm-roberta"),SSo=o(" \u2014 "),cO=a("a"),RSo=o("XLMRobertaForMaskedLM"),PSo=o(" (XLM-RoBERTa model)"),BSo=l(),Q2=a("li"),gge=a("strong"),ISo=o("xlm-roberta-xl"),NSo=o(" \u2014 "),fO=a("a"),qSo=o("XLMRobertaXLForMaskedLM"),jSo=o(" (XLM-RoBERTa-XL model)"),DSo=l(),H2=a("li"),hge=a("strong"),GSo=o("yoso"),OSo=o(" \u2014 "),mO=a("a"),VSo=o("YosoForMaskedLM"),XSo=o(" (YOSO model)"),zSo=l(),U2=a("p"),WSo=o("The model is set in evaluation mode by default using "),pge=a("code"),QSo=o("model.eval()"),HSo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),uge=a("code"),USo=o("model.train()"),JSo=l(),F(J2.$$.fragment),BGe=l(),Wi=a("h2"),Y2=a("a"),_ge=a("span"),F(py.$$.fragment),YSo=l(),bge=a("span"),KSo=o("AutoModelForSeq2SeqLM"),IGe=l(),Ro=a("div"),F(uy.$$.fragment),ZSo=l(),Qi=a("p"),eRo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),gO=a("a"),oRo=o("from_pretrained()"),rRo=o(" class method or the "),hO=a("a"),tRo=o("from_config()"),aRo=o(` class
method.`),nRo=l(),_y=a("p"),sRo=o("This class cannot be instantiated directly using "),vge=a("code"),lRo=o("__init__()"),iRo=o(" (throws an error)."),dRo=l(),dt=a("div"),F(by.$$.fragment),cRo=l(),Fge=a("p"),fRo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),mRo=l(),Hi=a("p"),gRo=o(`Note:
Loading a model from its configuration file does `),Tge=a("strong"),hRo=o("not"),pRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pO=a("a"),uRo=o("from_pretrained()"),_Ro=o(" to load the model weights."),bRo=l(),F(K2.$$.fragment),vRo=l(),eo=a("div"),F(vy.$$.fragment),FRo=l(),Mge=a("p"),TRo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),MRo=l(),Ia=a("p"),ERo=o("The model class to instantiate is selected based on the "),Ege=a("code"),CRo=o("model_type"),wRo=o(` property of the config object (either
passed as an argument or loaded from `),Cge=a("code"),ARo=o("pretrained_model_name_or_path"),LRo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wge=a("code"),yRo=o("pretrained_model_name_or_path"),xRo=o(":"),$Ro=l(),pe=a("ul"),Z2=a("li"),Age=a("strong"),kRo=o("bart"),SRo=o(" \u2014 "),uO=a("a"),RRo=o("BartForConditionalGeneration"),PRo=o(" (BART model)"),BRo=l(),e1=a("li"),Lge=a("strong"),IRo=o("bigbird_pegasus"),NRo=o(" \u2014 "),_O=a("a"),qRo=o("BigBirdPegasusForConditionalGeneration"),jRo=o(" (BigBird-Pegasus model)"),DRo=l(),o1=a("li"),yge=a("strong"),GRo=o("blenderbot"),ORo=o(" \u2014 "),bO=a("a"),VRo=o("BlenderbotForConditionalGeneration"),XRo=o(" (Blenderbot model)"),zRo=l(),r1=a("li"),xge=a("strong"),WRo=o("blenderbot-small"),QRo=o(" \u2014 "),vO=a("a"),HRo=o("BlenderbotSmallForConditionalGeneration"),URo=o(" (BlenderbotSmall model)"),JRo=l(),t1=a("li"),$ge=a("strong"),YRo=o("encoder-decoder"),KRo=o(" \u2014 "),FO=a("a"),ZRo=o("EncoderDecoderModel"),ePo=o(" (Encoder decoder model)"),oPo=l(),a1=a("li"),kge=a("strong"),rPo=o("fsmt"),tPo=o(" \u2014 "),TO=a("a"),aPo=o("FSMTForConditionalGeneration"),nPo=o(" (FairSeq Machine-Translation model)"),sPo=l(),n1=a("li"),Sge=a("strong"),lPo=o("led"),iPo=o(" \u2014 "),MO=a("a"),dPo=o("LEDForConditionalGeneration"),cPo=o(" (LED model)"),fPo=l(),s1=a("li"),Rge=a("strong"),mPo=o("longt5"),gPo=o(" \u2014 "),EO=a("a"),hPo=o("LongT5ForConditionalGeneration"),pPo=o(" (LongT5 model)"),uPo=l(),l1=a("li"),Pge=a("strong"),_Po=o("m2m_100"),bPo=o(" \u2014 "),CO=a("a"),vPo=o("M2M100ForConditionalGeneration"),FPo=o(" (M2M100 model)"),TPo=l(),i1=a("li"),Bge=a("strong"),MPo=o("marian"),EPo=o(" \u2014 "),wO=a("a"),CPo=o("MarianMTModel"),wPo=o(" (Marian model)"),APo=l(),d1=a("li"),Ige=a("strong"),LPo=o("mbart"),yPo=o(" \u2014 "),AO=a("a"),xPo=o("MBartForConditionalGeneration"),$Po=o(" (mBART model)"),kPo=l(),c1=a("li"),Nge=a("strong"),SPo=o("mt5"),RPo=o(" \u2014 "),LO=a("a"),PPo=o("MT5ForConditionalGeneration"),BPo=o(" (MT5 model)"),IPo=l(),f1=a("li"),qge=a("strong"),NPo=o("pegasus"),qPo=o(" \u2014 "),yO=a("a"),jPo=o("PegasusForConditionalGeneration"),DPo=o(" (Pegasus model)"),GPo=l(),m1=a("li"),jge=a("strong"),OPo=o("plbart"),VPo=o(" \u2014 "),xO=a("a"),XPo=o("PLBartForConditionalGeneration"),zPo=o(" (PLBart model)"),WPo=l(),g1=a("li"),Dge=a("strong"),QPo=o("prophetnet"),HPo=o(" \u2014 "),$O=a("a"),UPo=o("ProphetNetForConditionalGeneration"),JPo=o(" (ProphetNet model)"),YPo=l(),h1=a("li"),Gge=a("strong"),KPo=o("t5"),ZPo=o(" \u2014 "),kO=a("a"),eBo=o("T5ForConditionalGeneration"),oBo=o(" (T5 model)"),rBo=l(),p1=a("li"),Oge=a("strong"),tBo=o("xlm-prophetnet"),aBo=o(" \u2014 "),SO=a("a"),nBo=o("XLMProphetNetForConditionalGeneration"),sBo=o(" (XLM-ProphetNet model)"),lBo=l(),u1=a("p"),iBo=o("The model is set in evaluation mode by default using "),Vge=a("code"),dBo=o("model.eval()"),cBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xge=a("code"),fBo=o("model.train()"),mBo=l(),F(_1.$$.fragment),NGe=l(),Ui=a("h2"),b1=a("a"),zge=a("span"),F(Fy.$$.fragment),gBo=l(),Wge=a("span"),hBo=o("AutoModelForSequenceClassification"),qGe=l(),Po=a("div"),F(Ty.$$.fragment),pBo=l(),Ji=a("p"),uBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),RO=a("a"),_Bo=o("from_pretrained()"),bBo=o(" class method or the "),PO=a("a"),vBo=o("from_config()"),FBo=o(` class
method.`),TBo=l(),My=a("p"),MBo=o("This class cannot be instantiated directly using "),Qge=a("code"),EBo=o("__init__()"),CBo=o(" (throws an error)."),wBo=l(),ct=a("div"),F(Ey.$$.fragment),ABo=l(),Hge=a("p"),LBo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),yBo=l(),Yi=a("p"),xBo=o(`Note:
Loading a model from its configuration file does `),Uge=a("strong"),$Bo=o("not"),kBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BO=a("a"),SBo=o("from_pretrained()"),RBo=o(" to load the model weights."),PBo=l(),F(v1.$$.fragment),BBo=l(),oo=a("div"),F(Cy.$$.fragment),IBo=l(),Jge=a("p"),NBo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qBo=l(),Na=a("p"),jBo=o("The model class to instantiate is selected based on the "),Yge=a("code"),DBo=o("model_type"),GBo=o(` property of the config object (either
passed as an argument or loaded from `),Kge=a("code"),OBo=o("pretrained_model_name_or_path"),VBo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zge=a("code"),XBo=o("pretrained_model_name_or_path"),zBo=o(":"),WBo=l(),N=a("ul"),F1=a("li"),ehe=a("strong"),QBo=o("albert"),HBo=o(" \u2014 "),IO=a("a"),UBo=o("AlbertForSequenceClassification"),JBo=o(" (ALBERT model)"),YBo=l(),T1=a("li"),ohe=a("strong"),KBo=o("bart"),ZBo=o(" \u2014 "),NO=a("a"),eIo=o("BartForSequenceClassification"),oIo=o(" (BART model)"),rIo=l(),M1=a("li"),rhe=a("strong"),tIo=o("bert"),aIo=o(" \u2014 "),qO=a("a"),nIo=o("BertForSequenceClassification"),sIo=o(" (BERT model)"),lIo=l(),E1=a("li"),the=a("strong"),iIo=o("big_bird"),dIo=o(" \u2014 "),jO=a("a"),cIo=o("BigBirdForSequenceClassification"),fIo=o(" (BigBird model)"),mIo=l(),C1=a("li"),ahe=a("strong"),gIo=o("bigbird_pegasus"),hIo=o(" \u2014 "),DO=a("a"),pIo=o("BigBirdPegasusForSequenceClassification"),uIo=o(" (BigBird-Pegasus model)"),_Io=l(),w1=a("li"),nhe=a("strong"),bIo=o("bloom"),vIo=o(" \u2014 "),GO=a("a"),FIo=o("BloomForSequenceClassification"),TIo=o(" (BLOOM model)"),MIo=l(),A1=a("li"),she=a("strong"),EIo=o("camembert"),CIo=o(" \u2014 "),OO=a("a"),wIo=o("CamembertForSequenceClassification"),AIo=o(" (CamemBERT model)"),LIo=l(),L1=a("li"),lhe=a("strong"),yIo=o("canine"),xIo=o(" \u2014 "),VO=a("a"),$Io=o("CanineForSequenceClassification"),kIo=o(" (CANINE model)"),SIo=l(),y1=a("li"),ihe=a("strong"),RIo=o("convbert"),PIo=o(" \u2014 "),XO=a("a"),BIo=o("ConvBertForSequenceClassification"),IIo=o(" (ConvBERT model)"),NIo=l(),x1=a("li"),dhe=a("strong"),qIo=o("ctrl"),jIo=o(" \u2014 "),zO=a("a"),DIo=o("CTRLForSequenceClassification"),GIo=o(" (CTRL model)"),OIo=l(),$1=a("li"),che=a("strong"),VIo=o("data2vec-text"),XIo=o(" \u2014 "),WO=a("a"),zIo=o("Data2VecTextForSequenceClassification"),WIo=o(" (Data2VecText model)"),QIo=l(),k1=a("li"),fhe=a("strong"),HIo=o("deberta"),UIo=o(" \u2014 "),QO=a("a"),JIo=o("DebertaForSequenceClassification"),YIo=o(" (DeBERTa model)"),KIo=l(),S1=a("li"),mhe=a("strong"),ZIo=o("deberta-v2"),eNo=o(" \u2014 "),HO=a("a"),oNo=o("DebertaV2ForSequenceClassification"),rNo=o(" (DeBERTa-v2 model)"),tNo=l(),R1=a("li"),ghe=a("strong"),aNo=o("distilbert"),nNo=o(" \u2014 "),UO=a("a"),sNo=o("DistilBertForSequenceClassification"),lNo=o(" (DistilBERT model)"),iNo=l(),P1=a("li"),hhe=a("strong"),dNo=o("electra"),cNo=o(" \u2014 "),JO=a("a"),fNo=o("ElectraForSequenceClassification"),mNo=o(" (ELECTRA model)"),gNo=l(),B1=a("li"),phe=a("strong"),hNo=o("flaubert"),pNo=o(" \u2014 "),YO=a("a"),uNo=o("FlaubertForSequenceClassification"),_No=o(" (FlauBERT model)"),bNo=l(),I1=a("li"),uhe=a("strong"),vNo=o("fnet"),FNo=o(" \u2014 "),KO=a("a"),TNo=o("FNetForSequenceClassification"),MNo=o(" (FNet model)"),ENo=l(),N1=a("li"),_he=a("strong"),CNo=o("funnel"),wNo=o(" \u2014 "),ZO=a("a"),ANo=o("FunnelForSequenceClassification"),LNo=o(" (Funnel Transformer model)"),yNo=l(),q1=a("li"),bhe=a("strong"),xNo=o("gpt2"),$No=o(" \u2014 "),eV=a("a"),kNo=o("GPT2ForSequenceClassification"),SNo=o(" (OpenAI GPT-2 model)"),RNo=l(),j1=a("li"),vhe=a("strong"),PNo=o("gpt_neo"),BNo=o(" \u2014 "),oV=a("a"),INo=o("GPTNeoForSequenceClassification"),NNo=o(" (GPT Neo model)"),qNo=l(),D1=a("li"),Fhe=a("strong"),jNo=o("gptj"),DNo=o(" \u2014 "),rV=a("a"),GNo=o("GPTJForSequenceClassification"),ONo=o(" (GPT-J model)"),VNo=l(),G1=a("li"),The=a("strong"),XNo=o("ibert"),zNo=o(" \u2014 "),tV=a("a"),WNo=o("IBertForSequenceClassification"),QNo=o(" (I-BERT model)"),HNo=l(),O1=a("li"),Mhe=a("strong"),UNo=o("layoutlm"),JNo=o(" \u2014 "),aV=a("a"),YNo=o("LayoutLMForSequenceClassification"),KNo=o(" (LayoutLM model)"),ZNo=l(),V1=a("li"),Ehe=a("strong"),eqo=o("layoutlmv2"),oqo=o(" \u2014 "),nV=a("a"),rqo=o("LayoutLMv2ForSequenceClassification"),tqo=o(" (LayoutLMv2 model)"),aqo=l(),X1=a("li"),Che=a("strong"),nqo=o("layoutlmv3"),sqo=o(" \u2014 "),sV=a("a"),lqo=o("LayoutLMv3ForSequenceClassification"),iqo=o(" (LayoutLMv3 model)"),dqo=l(),z1=a("li"),whe=a("strong"),cqo=o("led"),fqo=o(" \u2014 "),lV=a("a"),mqo=o("LEDForSequenceClassification"),gqo=o(" (LED model)"),hqo=l(),W1=a("li"),Ahe=a("strong"),pqo=o("longformer"),uqo=o(" \u2014 "),iV=a("a"),_qo=o("LongformerForSequenceClassification"),bqo=o(" (Longformer model)"),vqo=l(),Q1=a("li"),Lhe=a("strong"),Fqo=o("mbart"),Tqo=o(" \u2014 "),dV=a("a"),Mqo=o("MBartForSequenceClassification"),Eqo=o(" (mBART model)"),Cqo=l(),H1=a("li"),yhe=a("strong"),wqo=o("megatron-bert"),Aqo=o(" \u2014 "),cV=a("a"),Lqo=o("MegatronBertForSequenceClassification"),yqo=o(" (Megatron-BERT model)"),xqo=l(),U1=a("li"),xhe=a("strong"),$qo=o("mobilebert"),kqo=o(" \u2014 "),fV=a("a"),Sqo=o("MobileBertForSequenceClassification"),Rqo=o(" (MobileBERT model)"),Pqo=l(),J1=a("li"),$he=a("strong"),Bqo=o("mpnet"),Iqo=o(" \u2014 "),mV=a("a"),Nqo=o("MPNetForSequenceClassification"),qqo=o(" (MPNet model)"),jqo=l(),Y1=a("li"),khe=a("strong"),Dqo=o("nystromformer"),Gqo=o(" \u2014 "),gV=a("a"),Oqo=o("NystromformerForSequenceClassification"),Vqo=o(" (Nystr\xF6mformer model)"),Xqo=l(),K1=a("li"),She=a("strong"),zqo=o("openai-gpt"),Wqo=o(" \u2014 "),hV=a("a"),Qqo=o("OpenAIGPTForSequenceClassification"),Hqo=o(" (OpenAI GPT model)"),Uqo=l(),Z1=a("li"),Rhe=a("strong"),Jqo=o("perceiver"),Yqo=o(" \u2014 "),pV=a("a"),Kqo=o("PerceiverForSequenceClassification"),Zqo=o(" (Perceiver model)"),ejo=l(),eb=a("li"),Phe=a("strong"),ojo=o("plbart"),rjo=o(" \u2014 "),uV=a("a"),tjo=o("PLBartForSequenceClassification"),ajo=o(" (PLBart model)"),njo=l(),ob=a("li"),Bhe=a("strong"),sjo=o("qdqbert"),ljo=o(" \u2014 "),_V=a("a"),ijo=o("QDQBertForSequenceClassification"),djo=o(" (QDQBert model)"),cjo=l(),rb=a("li"),Ihe=a("strong"),fjo=o("reformer"),mjo=o(" \u2014 "),bV=a("a"),gjo=o("ReformerForSequenceClassification"),hjo=o(" (Reformer model)"),pjo=l(),tb=a("li"),Nhe=a("strong"),ujo=o("rembert"),_jo=o(" \u2014 "),vV=a("a"),bjo=o("RemBertForSequenceClassification"),vjo=o(" (RemBERT model)"),Fjo=l(),ab=a("li"),qhe=a("strong"),Tjo=o("roberta"),Mjo=o(" \u2014 "),FV=a("a"),Ejo=o("RobertaForSequenceClassification"),Cjo=o(" (RoBERTa model)"),wjo=l(),nb=a("li"),jhe=a("strong"),Ajo=o("roformer"),Ljo=o(" \u2014 "),TV=a("a"),yjo=o("RoFormerForSequenceClassification"),xjo=o(" (RoFormer model)"),$jo=l(),sb=a("li"),Dhe=a("strong"),kjo=o("squeezebert"),Sjo=o(" \u2014 "),MV=a("a"),Rjo=o("SqueezeBertForSequenceClassification"),Pjo=o(" (SqueezeBERT model)"),Bjo=l(),lb=a("li"),Ghe=a("strong"),Ijo=o("tapas"),Njo=o(" \u2014 "),EV=a("a"),qjo=o("TapasForSequenceClassification"),jjo=o(" (TAPAS model)"),Djo=l(),ib=a("li"),Ohe=a("strong"),Gjo=o("transfo-xl"),Ojo=o(" \u2014 "),CV=a("a"),Vjo=o("TransfoXLForSequenceClassification"),Xjo=o(" (Transformer-XL model)"),zjo=l(),db=a("li"),Vhe=a("strong"),Wjo=o("xlm"),Qjo=o(" \u2014 "),wV=a("a"),Hjo=o("XLMForSequenceClassification"),Ujo=o(" (XLM model)"),Jjo=l(),cb=a("li"),Xhe=a("strong"),Yjo=o("xlm-roberta"),Kjo=o(" \u2014 "),AV=a("a"),Zjo=o("XLMRobertaForSequenceClassification"),eDo=o(" (XLM-RoBERTa model)"),oDo=l(),fb=a("li"),zhe=a("strong"),rDo=o("xlm-roberta-xl"),tDo=o(" \u2014 "),LV=a("a"),aDo=o("XLMRobertaXLForSequenceClassification"),nDo=o(" (XLM-RoBERTa-XL model)"),sDo=l(),mb=a("li"),Whe=a("strong"),lDo=o("xlnet"),iDo=o(" \u2014 "),yV=a("a"),dDo=o("XLNetForSequenceClassification"),cDo=o(" (XLNet model)"),fDo=l(),gb=a("li"),Qhe=a("strong"),mDo=o("yoso"),gDo=o(" \u2014 "),xV=a("a"),hDo=o("YosoForSequenceClassification"),pDo=o(" (YOSO model)"),uDo=l(),hb=a("p"),_Do=o("The model is set in evaluation mode by default using "),Hhe=a("code"),bDo=o("model.eval()"),vDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uhe=a("code"),FDo=o("model.train()"),TDo=l(),F(pb.$$.fragment),jGe=l(),Ki=a("h2"),ub=a("a"),Jhe=a("span"),F(wy.$$.fragment),MDo=l(),Yhe=a("span"),EDo=o("AutoModelForMultipleChoice"),DGe=l(),Bo=a("div"),F(Ay.$$.fragment),CDo=l(),Zi=a("p"),wDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),$V=a("a"),ADo=o("from_pretrained()"),LDo=o(" class method or the "),kV=a("a"),yDo=o("from_config()"),xDo=o(` class
method.`),$Do=l(),Ly=a("p"),kDo=o("This class cannot be instantiated directly using "),Khe=a("code"),SDo=o("__init__()"),RDo=o(" (throws an error)."),PDo=l(),ft=a("div"),F(yy.$$.fragment),BDo=l(),Zhe=a("p"),IDo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),NDo=l(),ed=a("p"),qDo=o(`Note:
Loading a model from its configuration file does `),epe=a("strong"),jDo=o("not"),DDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SV=a("a"),GDo=o("from_pretrained()"),ODo=o(" to load the model weights."),VDo=l(),F(_b.$$.fragment),XDo=l(),ro=a("div"),F(xy.$$.fragment),zDo=l(),ope=a("p"),WDo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),QDo=l(),qa=a("p"),HDo=o("The model class to instantiate is selected based on the "),rpe=a("code"),UDo=o("model_type"),JDo=o(` property of the config object (either
passed as an argument or loaded from `),tpe=a("code"),YDo=o("pretrained_model_name_or_path"),KDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ape=a("code"),ZDo=o("pretrained_model_name_or_path"),eGo=o(":"),oGo=l(),Z=a("ul"),bb=a("li"),npe=a("strong"),rGo=o("albert"),tGo=o(" \u2014 "),RV=a("a"),aGo=o("AlbertForMultipleChoice"),nGo=o(" (ALBERT model)"),sGo=l(),vb=a("li"),spe=a("strong"),lGo=o("bert"),iGo=o(" \u2014 "),PV=a("a"),dGo=o("BertForMultipleChoice"),cGo=o(" (BERT model)"),fGo=l(),Fb=a("li"),lpe=a("strong"),mGo=o("big_bird"),gGo=o(" \u2014 "),BV=a("a"),hGo=o("BigBirdForMultipleChoice"),pGo=o(" (BigBird model)"),uGo=l(),Tb=a("li"),ipe=a("strong"),_Go=o("camembert"),bGo=o(" \u2014 "),IV=a("a"),vGo=o("CamembertForMultipleChoice"),FGo=o(" (CamemBERT model)"),TGo=l(),Mb=a("li"),dpe=a("strong"),MGo=o("canine"),EGo=o(" \u2014 "),NV=a("a"),CGo=o("CanineForMultipleChoice"),wGo=o(" (CANINE model)"),AGo=l(),Eb=a("li"),cpe=a("strong"),LGo=o("convbert"),yGo=o(" \u2014 "),qV=a("a"),xGo=o("ConvBertForMultipleChoice"),$Go=o(" (ConvBERT model)"),kGo=l(),Cb=a("li"),fpe=a("strong"),SGo=o("data2vec-text"),RGo=o(" \u2014 "),jV=a("a"),PGo=o("Data2VecTextForMultipleChoice"),BGo=o(" (Data2VecText model)"),IGo=l(),wb=a("li"),mpe=a("strong"),NGo=o("deberta-v2"),qGo=o(" \u2014 "),DV=a("a"),jGo=o("DebertaV2ForMultipleChoice"),DGo=o(" (DeBERTa-v2 model)"),GGo=l(),Ab=a("li"),gpe=a("strong"),OGo=o("distilbert"),VGo=o(" \u2014 "),GV=a("a"),XGo=o("DistilBertForMultipleChoice"),zGo=o(" (DistilBERT model)"),WGo=l(),Lb=a("li"),hpe=a("strong"),QGo=o("electra"),HGo=o(" \u2014 "),OV=a("a"),UGo=o("ElectraForMultipleChoice"),JGo=o(" (ELECTRA model)"),YGo=l(),yb=a("li"),ppe=a("strong"),KGo=o("flaubert"),ZGo=o(" \u2014 "),VV=a("a"),eOo=o("FlaubertForMultipleChoice"),oOo=o(" (FlauBERT model)"),rOo=l(),xb=a("li"),upe=a("strong"),tOo=o("fnet"),aOo=o(" \u2014 "),XV=a("a"),nOo=o("FNetForMultipleChoice"),sOo=o(" (FNet model)"),lOo=l(),$b=a("li"),_pe=a("strong"),iOo=o("funnel"),dOo=o(" \u2014 "),zV=a("a"),cOo=o("FunnelForMultipleChoice"),fOo=o(" (Funnel Transformer model)"),mOo=l(),kb=a("li"),bpe=a("strong"),gOo=o("ibert"),hOo=o(" \u2014 "),WV=a("a"),pOo=o("IBertForMultipleChoice"),uOo=o(" (I-BERT model)"),_Oo=l(),Sb=a("li"),vpe=a("strong"),bOo=o("longformer"),vOo=o(" \u2014 "),QV=a("a"),FOo=o("LongformerForMultipleChoice"),TOo=o(" (Longformer model)"),MOo=l(),Rb=a("li"),Fpe=a("strong"),EOo=o("megatron-bert"),COo=o(" \u2014 "),HV=a("a"),wOo=o("MegatronBertForMultipleChoice"),AOo=o(" (Megatron-BERT model)"),LOo=l(),Pb=a("li"),Tpe=a("strong"),yOo=o("mobilebert"),xOo=o(" \u2014 "),UV=a("a"),$Oo=o("MobileBertForMultipleChoice"),kOo=o(" (MobileBERT model)"),SOo=l(),Bb=a("li"),Mpe=a("strong"),ROo=o("mpnet"),POo=o(" \u2014 "),JV=a("a"),BOo=o("MPNetForMultipleChoice"),IOo=o(" (MPNet model)"),NOo=l(),Ib=a("li"),Epe=a("strong"),qOo=o("nystromformer"),jOo=o(" \u2014 "),YV=a("a"),DOo=o("NystromformerForMultipleChoice"),GOo=o(" (Nystr\xF6mformer model)"),OOo=l(),Nb=a("li"),Cpe=a("strong"),VOo=o("qdqbert"),XOo=o(" \u2014 "),KV=a("a"),zOo=o("QDQBertForMultipleChoice"),WOo=o(" (QDQBert model)"),QOo=l(),qb=a("li"),wpe=a("strong"),HOo=o("rembert"),UOo=o(" \u2014 "),ZV=a("a"),JOo=o("RemBertForMultipleChoice"),YOo=o(" (RemBERT model)"),KOo=l(),jb=a("li"),Ape=a("strong"),ZOo=o("roberta"),eVo=o(" \u2014 "),eX=a("a"),oVo=o("RobertaForMultipleChoice"),rVo=o(" (RoBERTa model)"),tVo=l(),Db=a("li"),Lpe=a("strong"),aVo=o("roformer"),nVo=o(" \u2014 "),oX=a("a"),sVo=o("RoFormerForMultipleChoice"),lVo=o(" (RoFormer model)"),iVo=l(),Gb=a("li"),ype=a("strong"),dVo=o("squeezebert"),cVo=o(" \u2014 "),rX=a("a"),fVo=o("SqueezeBertForMultipleChoice"),mVo=o(" (SqueezeBERT model)"),gVo=l(),Ob=a("li"),xpe=a("strong"),hVo=o("xlm"),pVo=o(" \u2014 "),tX=a("a"),uVo=o("XLMForMultipleChoice"),_Vo=o(" (XLM model)"),bVo=l(),Vb=a("li"),$pe=a("strong"),vVo=o("xlm-roberta"),FVo=o(" \u2014 "),aX=a("a"),TVo=o("XLMRobertaForMultipleChoice"),MVo=o(" (XLM-RoBERTa model)"),EVo=l(),Xb=a("li"),kpe=a("strong"),CVo=o("xlm-roberta-xl"),wVo=o(" \u2014 "),nX=a("a"),AVo=o("XLMRobertaXLForMultipleChoice"),LVo=o(" (XLM-RoBERTa-XL model)"),yVo=l(),zb=a("li"),Spe=a("strong"),xVo=o("xlnet"),$Vo=o(" \u2014 "),sX=a("a"),kVo=o("XLNetForMultipleChoice"),SVo=o(" (XLNet model)"),RVo=l(),Wb=a("li"),Rpe=a("strong"),PVo=o("yoso"),BVo=o(" \u2014 "),lX=a("a"),IVo=o("YosoForMultipleChoice"),NVo=o(" (YOSO model)"),qVo=l(),Qb=a("p"),jVo=o("The model is set in evaluation mode by default using "),Ppe=a("code"),DVo=o("model.eval()"),GVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bpe=a("code"),OVo=o("model.train()"),VVo=l(),F(Hb.$$.fragment),GGe=l(),od=a("h2"),Ub=a("a"),Ipe=a("span"),F($y.$$.fragment),XVo=l(),Npe=a("span"),zVo=o("AutoModelForNextSentencePrediction"),OGe=l(),Io=a("div"),F(ky.$$.fragment),WVo=l(),rd=a("p"),QVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),iX=a("a"),HVo=o("from_pretrained()"),UVo=o(" class method or the "),dX=a("a"),JVo=o("from_config()"),YVo=o(` class
method.`),KVo=l(),Sy=a("p"),ZVo=o("This class cannot be instantiated directly using "),qpe=a("code"),eXo=o("__init__()"),oXo=o(" (throws an error)."),rXo=l(),mt=a("div"),F(Ry.$$.fragment),tXo=l(),jpe=a("p"),aXo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),nXo=l(),td=a("p"),sXo=o(`Note:
Loading a model from its configuration file does `),Dpe=a("strong"),lXo=o("not"),iXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cX=a("a"),dXo=o("from_pretrained()"),cXo=o(" to load the model weights."),fXo=l(),F(Jb.$$.fragment),mXo=l(),to=a("div"),F(Py.$$.fragment),gXo=l(),Gpe=a("p"),hXo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),pXo=l(),ja=a("p"),uXo=o("The model class to instantiate is selected based on the "),Ope=a("code"),_Xo=o("model_type"),bXo=o(` property of the config object (either
passed as an argument or loaded from `),Vpe=a("code"),vXo=o("pretrained_model_name_or_path"),FXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xpe=a("code"),TXo=o("pretrained_model_name_or_path"),MXo=o(":"),EXo=l(),Zr=a("ul"),Yb=a("li"),zpe=a("strong"),CXo=o("bert"),wXo=o(" \u2014 "),fX=a("a"),AXo=o("BertForNextSentencePrediction"),LXo=o(" (BERT model)"),yXo=l(),Kb=a("li"),Wpe=a("strong"),xXo=o("fnet"),$Xo=o(" \u2014 "),mX=a("a"),kXo=o("FNetForNextSentencePrediction"),SXo=o(" (FNet model)"),RXo=l(),Zb=a("li"),Qpe=a("strong"),PXo=o("megatron-bert"),BXo=o(" \u2014 "),gX=a("a"),IXo=o("MegatronBertForNextSentencePrediction"),NXo=o(" (Megatron-BERT model)"),qXo=l(),ev=a("li"),Hpe=a("strong"),jXo=o("mobilebert"),DXo=o(" \u2014 "),hX=a("a"),GXo=o("MobileBertForNextSentencePrediction"),OXo=o(" (MobileBERT model)"),VXo=l(),ov=a("li"),Upe=a("strong"),XXo=o("qdqbert"),zXo=o(" \u2014 "),pX=a("a"),WXo=o("QDQBertForNextSentencePrediction"),QXo=o(" (QDQBert model)"),HXo=l(),rv=a("p"),UXo=o("The model is set in evaluation mode by default using "),Jpe=a("code"),JXo=o("model.eval()"),YXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=a("code"),KXo=o("model.train()"),ZXo=l(),F(tv.$$.fragment),VGe=l(),ad=a("h2"),av=a("a"),Kpe=a("span"),F(By.$$.fragment),ezo=l(),Zpe=a("span"),ozo=o("AutoModelForTokenClassification"),XGe=l(),No=a("div"),F(Iy.$$.fragment),rzo=l(),nd=a("p"),tzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),uX=a("a"),azo=o("from_pretrained()"),nzo=o(" class method or the "),_X=a("a"),szo=o("from_config()"),lzo=o(` class
method.`),izo=l(),Ny=a("p"),dzo=o("This class cannot be instantiated directly using "),eue=a("code"),czo=o("__init__()"),fzo=o(" (throws an error)."),mzo=l(),gt=a("div"),F(qy.$$.fragment),gzo=l(),oue=a("p"),hzo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),pzo=l(),sd=a("p"),uzo=o(`Note:
Loading a model from its configuration file does `),rue=a("strong"),_zo=o("not"),bzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bX=a("a"),vzo=o("from_pretrained()"),Fzo=o(" to load the model weights."),Tzo=l(),F(nv.$$.fragment),Mzo=l(),ao=a("div"),F(jy.$$.fragment),Ezo=l(),tue=a("p"),Czo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),wzo=l(),Da=a("p"),Azo=o("The model class to instantiate is selected based on the "),aue=a("code"),Lzo=o("model_type"),yzo=o(` property of the config object (either
passed as an argument or loaded from `),nue=a("code"),xzo=o("pretrained_model_name_or_path"),$zo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sue=a("code"),kzo=o("pretrained_model_name_or_path"),Szo=o(":"),Rzo=l(),H=a("ul"),sv=a("li"),lue=a("strong"),Pzo=o("albert"),Bzo=o(" \u2014 "),vX=a("a"),Izo=o("AlbertForTokenClassification"),Nzo=o(" (ALBERT model)"),qzo=l(),lv=a("li"),iue=a("strong"),jzo=o("bert"),Dzo=o(" \u2014 "),FX=a("a"),Gzo=o("BertForTokenClassification"),Ozo=o(" (BERT model)"),Vzo=l(),iv=a("li"),due=a("strong"),Xzo=o("big_bird"),zzo=o(" \u2014 "),TX=a("a"),Wzo=o("BigBirdForTokenClassification"),Qzo=o(" (BigBird model)"),Hzo=l(),dv=a("li"),cue=a("strong"),Uzo=o("bloom"),Jzo=o(" \u2014 "),MX=a("a"),Yzo=o("BloomForTokenClassification"),Kzo=o(" (BLOOM model)"),Zzo=l(),cv=a("li"),fue=a("strong"),eWo=o("camembert"),oWo=o(" \u2014 "),EX=a("a"),rWo=o("CamembertForTokenClassification"),tWo=o(" (CamemBERT model)"),aWo=l(),fv=a("li"),mue=a("strong"),nWo=o("canine"),sWo=o(" \u2014 "),CX=a("a"),lWo=o("CanineForTokenClassification"),iWo=o(" (CANINE model)"),dWo=l(),mv=a("li"),gue=a("strong"),cWo=o("convbert"),fWo=o(" \u2014 "),wX=a("a"),mWo=o("ConvBertForTokenClassification"),gWo=o(" (ConvBERT model)"),hWo=l(),gv=a("li"),hue=a("strong"),pWo=o("data2vec-text"),uWo=o(" \u2014 "),AX=a("a"),_Wo=o("Data2VecTextForTokenClassification"),bWo=o(" (Data2VecText model)"),vWo=l(),hv=a("li"),pue=a("strong"),FWo=o("deberta"),TWo=o(" \u2014 "),LX=a("a"),MWo=o("DebertaForTokenClassification"),EWo=o(" (DeBERTa model)"),CWo=l(),pv=a("li"),uue=a("strong"),wWo=o("deberta-v2"),AWo=o(" \u2014 "),yX=a("a"),LWo=o("DebertaV2ForTokenClassification"),yWo=o(" (DeBERTa-v2 model)"),xWo=l(),uv=a("li"),_ue=a("strong"),$Wo=o("distilbert"),kWo=o(" \u2014 "),xX=a("a"),SWo=o("DistilBertForTokenClassification"),RWo=o(" (DistilBERT model)"),PWo=l(),_v=a("li"),bue=a("strong"),BWo=o("electra"),IWo=o(" \u2014 "),$X=a("a"),NWo=o("ElectraForTokenClassification"),qWo=o(" (ELECTRA model)"),jWo=l(),bv=a("li"),vue=a("strong"),DWo=o("flaubert"),GWo=o(" \u2014 "),kX=a("a"),OWo=o("FlaubertForTokenClassification"),VWo=o(" (FlauBERT model)"),XWo=l(),vv=a("li"),Fue=a("strong"),zWo=o("fnet"),WWo=o(" \u2014 "),SX=a("a"),QWo=o("FNetForTokenClassification"),HWo=o(" (FNet model)"),UWo=l(),Fv=a("li"),Tue=a("strong"),JWo=o("funnel"),YWo=o(" \u2014 "),RX=a("a"),KWo=o("FunnelForTokenClassification"),ZWo=o(" (Funnel Transformer model)"),eQo=l(),Tv=a("li"),Mue=a("strong"),oQo=o("gpt2"),rQo=o(" \u2014 "),PX=a("a"),tQo=o("GPT2ForTokenClassification"),aQo=o(" (OpenAI GPT-2 model)"),nQo=l(),Mv=a("li"),Eue=a("strong"),sQo=o("ibert"),lQo=o(" \u2014 "),BX=a("a"),iQo=o("IBertForTokenClassification"),dQo=o(" (I-BERT model)"),cQo=l(),Ev=a("li"),Cue=a("strong"),fQo=o("layoutlm"),mQo=o(" \u2014 "),IX=a("a"),gQo=o("LayoutLMForTokenClassification"),hQo=o(" (LayoutLM model)"),pQo=l(),Cv=a("li"),wue=a("strong"),uQo=o("layoutlmv2"),_Qo=o(" \u2014 "),NX=a("a"),bQo=o("LayoutLMv2ForTokenClassification"),vQo=o(" (LayoutLMv2 model)"),FQo=l(),wv=a("li"),Aue=a("strong"),TQo=o("layoutlmv3"),MQo=o(" \u2014 "),qX=a("a"),EQo=o("LayoutLMv3ForTokenClassification"),CQo=o(" (LayoutLMv3 model)"),wQo=l(),Av=a("li"),Lue=a("strong"),AQo=o("longformer"),LQo=o(" \u2014 "),jX=a("a"),yQo=o("LongformerForTokenClassification"),xQo=o(" (Longformer model)"),$Qo=l(),Lv=a("li"),yue=a("strong"),kQo=o("megatron-bert"),SQo=o(" \u2014 "),DX=a("a"),RQo=o("MegatronBertForTokenClassification"),PQo=o(" (Megatron-BERT model)"),BQo=l(),yv=a("li"),xue=a("strong"),IQo=o("mobilebert"),NQo=o(" \u2014 "),GX=a("a"),qQo=o("MobileBertForTokenClassification"),jQo=o(" (MobileBERT model)"),DQo=l(),xv=a("li"),$ue=a("strong"),GQo=o("mpnet"),OQo=o(" \u2014 "),OX=a("a"),VQo=o("MPNetForTokenClassification"),XQo=o(" (MPNet model)"),zQo=l(),$v=a("li"),kue=a("strong"),WQo=o("nystromformer"),QQo=o(" \u2014 "),VX=a("a"),HQo=o("NystromformerForTokenClassification"),UQo=o(" (Nystr\xF6mformer model)"),JQo=l(),kv=a("li"),Sue=a("strong"),YQo=o("qdqbert"),KQo=o(" \u2014 "),XX=a("a"),ZQo=o("QDQBertForTokenClassification"),eHo=o(" (QDQBert model)"),oHo=l(),Sv=a("li"),Rue=a("strong"),rHo=o("rembert"),tHo=o(" \u2014 "),zX=a("a"),aHo=o("RemBertForTokenClassification"),nHo=o(" (RemBERT model)"),sHo=l(),Rv=a("li"),Pue=a("strong"),lHo=o("roberta"),iHo=o(" \u2014 "),WX=a("a"),dHo=o("RobertaForTokenClassification"),cHo=o(" (RoBERTa model)"),fHo=l(),Pv=a("li"),Bue=a("strong"),mHo=o("roformer"),gHo=o(" \u2014 "),QX=a("a"),hHo=o("RoFormerForTokenClassification"),pHo=o(" (RoFormer model)"),uHo=l(),Bv=a("li"),Iue=a("strong"),_Ho=o("squeezebert"),bHo=o(" \u2014 "),HX=a("a"),vHo=o("SqueezeBertForTokenClassification"),FHo=o(" (SqueezeBERT model)"),THo=l(),Iv=a("li"),Nue=a("strong"),MHo=o("xlm"),EHo=o(" \u2014 "),UX=a("a"),CHo=o("XLMForTokenClassification"),wHo=o(" (XLM model)"),AHo=l(),Nv=a("li"),que=a("strong"),LHo=o("xlm-roberta"),yHo=o(" \u2014 "),JX=a("a"),xHo=o("XLMRobertaForTokenClassification"),$Ho=o(" (XLM-RoBERTa model)"),kHo=l(),qv=a("li"),jue=a("strong"),SHo=o("xlm-roberta-xl"),RHo=o(" \u2014 "),YX=a("a"),PHo=o("XLMRobertaXLForTokenClassification"),BHo=o(" (XLM-RoBERTa-XL model)"),IHo=l(),jv=a("li"),Due=a("strong"),NHo=o("xlnet"),qHo=o(" \u2014 "),KX=a("a"),jHo=o("XLNetForTokenClassification"),DHo=o(" (XLNet model)"),GHo=l(),Dv=a("li"),Gue=a("strong"),OHo=o("yoso"),VHo=o(" \u2014 "),ZX=a("a"),XHo=o("YosoForTokenClassification"),zHo=o(" (YOSO model)"),WHo=l(),Gv=a("p"),QHo=o("The model is set in evaluation mode by default using "),Oue=a("code"),HHo=o("model.eval()"),UHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vue=a("code"),JHo=o("model.train()"),YHo=l(),F(Ov.$$.fragment),zGe=l(),ld=a("h2"),Vv=a("a"),Xue=a("span"),F(Dy.$$.fragment),KHo=l(),zue=a("span"),ZHo=o("AutoModelForQuestionAnswering"),WGe=l(),qo=a("div"),F(Gy.$$.fragment),eUo=l(),id=a("p"),oUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ez=a("a"),rUo=o("from_pretrained()"),tUo=o(" class method or the "),oz=a("a"),aUo=o("from_config()"),nUo=o(` class
method.`),sUo=l(),Oy=a("p"),lUo=o("This class cannot be instantiated directly using "),Wue=a("code"),iUo=o("__init__()"),dUo=o(" (throws an error)."),cUo=l(),ht=a("div"),F(Vy.$$.fragment),fUo=l(),Que=a("p"),mUo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),gUo=l(),dd=a("p"),hUo=o(`Note:
Loading a model from its configuration file does `),Hue=a("strong"),pUo=o("not"),uUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rz=a("a"),_Uo=o("from_pretrained()"),bUo=o(" to load the model weights."),vUo=l(),F(Xv.$$.fragment),FUo=l(),no=a("div"),F(Xy.$$.fragment),TUo=l(),Uue=a("p"),MUo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),EUo=l(),Ga=a("p"),CUo=o("The model class to instantiate is selected based on the "),Jue=a("code"),wUo=o("model_type"),AUo=o(` property of the config object (either
passed as an argument or loaded from `),Yue=a("code"),LUo=o("pretrained_model_name_or_path"),yUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kue=a("code"),xUo=o("pretrained_model_name_or_path"),$Uo=o(":"),kUo=l(),V=a("ul"),zv=a("li"),Zue=a("strong"),SUo=o("albert"),RUo=o(" \u2014 "),tz=a("a"),PUo=o("AlbertForQuestionAnswering"),BUo=o(" (ALBERT model)"),IUo=l(),Wv=a("li"),e_e=a("strong"),NUo=o("bart"),qUo=o(" \u2014 "),az=a("a"),jUo=o("BartForQuestionAnswering"),DUo=o(" (BART model)"),GUo=l(),Qv=a("li"),o_e=a("strong"),OUo=o("bert"),VUo=o(" \u2014 "),nz=a("a"),XUo=o("BertForQuestionAnswering"),zUo=o(" (BERT model)"),WUo=l(),Hv=a("li"),r_e=a("strong"),QUo=o("big_bird"),HUo=o(" \u2014 "),sz=a("a"),UUo=o("BigBirdForQuestionAnswering"),JUo=o(" (BigBird model)"),YUo=l(),Uv=a("li"),t_e=a("strong"),KUo=o("bigbird_pegasus"),ZUo=o(" \u2014 "),lz=a("a"),eJo=o("BigBirdPegasusForQuestionAnswering"),oJo=o(" (BigBird-Pegasus model)"),rJo=l(),Jv=a("li"),a_e=a("strong"),tJo=o("camembert"),aJo=o(" \u2014 "),iz=a("a"),nJo=o("CamembertForQuestionAnswering"),sJo=o(" (CamemBERT model)"),lJo=l(),Yv=a("li"),n_e=a("strong"),iJo=o("canine"),dJo=o(" \u2014 "),dz=a("a"),cJo=o("CanineForQuestionAnswering"),fJo=o(" (CANINE model)"),mJo=l(),Kv=a("li"),s_e=a("strong"),gJo=o("convbert"),hJo=o(" \u2014 "),cz=a("a"),pJo=o("ConvBertForQuestionAnswering"),uJo=o(" (ConvBERT model)"),_Jo=l(),Zv=a("li"),l_e=a("strong"),bJo=o("data2vec-text"),vJo=o(" \u2014 "),fz=a("a"),FJo=o("Data2VecTextForQuestionAnswering"),TJo=o(" (Data2VecText model)"),MJo=l(),eF=a("li"),i_e=a("strong"),EJo=o("deberta"),CJo=o(" \u2014 "),mz=a("a"),wJo=o("DebertaForQuestionAnswering"),AJo=o(" (DeBERTa model)"),LJo=l(),oF=a("li"),d_e=a("strong"),yJo=o("deberta-v2"),xJo=o(" \u2014 "),gz=a("a"),$Jo=o("DebertaV2ForQuestionAnswering"),kJo=o(" (DeBERTa-v2 model)"),SJo=l(),rF=a("li"),c_e=a("strong"),RJo=o("distilbert"),PJo=o(" \u2014 "),hz=a("a"),BJo=o("DistilBertForQuestionAnswering"),IJo=o(" (DistilBERT model)"),NJo=l(),tF=a("li"),f_e=a("strong"),qJo=o("electra"),jJo=o(" \u2014 "),pz=a("a"),DJo=o("ElectraForQuestionAnswering"),GJo=o(" (ELECTRA model)"),OJo=l(),aF=a("li"),m_e=a("strong"),VJo=o("flaubert"),XJo=o(" \u2014 "),uz=a("a"),zJo=o("FlaubertForQuestionAnsweringSimple"),WJo=o(" (FlauBERT model)"),QJo=l(),nF=a("li"),g_e=a("strong"),HJo=o("fnet"),UJo=o(" \u2014 "),_z=a("a"),JJo=o("FNetForQuestionAnswering"),YJo=o(" (FNet model)"),KJo=l(),sF=a("li"),h_e=a("strong"),ZJo=o("funnel"),eYo=o(" \u2014 "),bz=a("a"),oYo=o("FunnelForQuestionAnswering"),rYo=o(" (Funnel Transformer model)"),tYo=l(),lF=a("li"),p_e=a("strong"),aYo=o("gptj"),nYo=o(" \u2014 "),vz=a("a"),sYo=o("GPTJForQuestionAnswering"),lYo=o(" (GPT-J model)"),iYo=l(),iF=a("li"),u_e=a("strong"),dYo=o("ibert"),cYo=o(" \u2014 "),Fz=a("a"),fYo=o("IBertForQuestionAnswering"),mYo=o(" (I-BERT model)"),gYo=l(),dF=a("li"),__e=a("strong"),hYo=o("layoutlmv2"),pYo=o(" \u2014 "),Tz=a("a"),uYo=o("LayoutLMv2ForQuestionAnswering"),_Yo=o(" (LayoutLMv2 model)"),bYo=l(),cF=a("li"),b_e=a("strong"),vYo=o("layoutlmv3"),FYo=o(" \u2014 "),Mz=a("a"),TYo=o("LayoutLMv3ForQuestionAnswering"),MYo=o(" (LayoutLMv3 model)"),EYo=l(),fF=a("li"),v_e=a("strong"),CYo=o("led"),wYo=o(" \u2014 "),Ez=a("a"),AYo=o("LEDForQuestionAnswering"),LYo=o(" (LED model)"),yYo=l(),mF=a("li"),F_e=a("strong"),xYo=o("longformer"),$Yo=o(" \u2014 "),Cz=a("a"),kYo=o("LongformerForQuestionAnswering"),SYo=o(" (Longformer model)"),RYo=l(),gF=a("li"),T_e=a("strong"),PYo=o("lxmert"),BYo=o(" \u2014 "),wz=a("a"),IYo=o("LxmertForQuestionAnswering"),NYo=o(" (LXMERT model)"),qYo=l(),hF=a("li"),M_e=a("strong"),jYo=o("mbart"),DYo=o(" \u2014 "),Az=a("a"),GYo=o("MBartForQuestionAnswering"),OYo=o(" (mBART model)"),VYo=l(),pF=a("li"),E_e=a("strong"),XYo=o("megatron-bert"),zYo=o(" \u2014 "),Lz=a("a"),WYo=o("MegatronBertForQuestionAnswering"),QYo=o(" (Megatron-BERT model)"),HYo=l(),uF=a("li"),C_e=a("strong"),UYo=o("mobilebert"),JYo=o(" \u2014 "),yz=a("a"),YYo=o("MobileBertForQuestionAnswering"),KYo=o(" (MobileBERT model)"),ZYo=l(),_F=a("li"),w_e=a("strong"),eKo=o("mpnet"),oKo=o(" \u2014 "),xz=a("a"),rKo=o("MPNetForQuestionAnswering"),tKo=o(" (MPNet model)"),aKo=l(),bF=a("li"),A_e=a("strong"),nKo=o("nystromformer"),sKo=o(" \u2014 "),$z=a("a"),lKo=o("NystromformerForQuestionAnswering"),iKo=o(" (Nystr\xF6mformer model)"),dKo=l(),vF=a("li"),L_e=a("strong"),cKo=o("qdqbert"),fKo=o(" \u2014 "),kz=a("a"),mKo=o("QDQBertForQuestionAnswering"),gKo=o(" (QDQBert model)"),hKo=l(),FF=a("li"),y_e=a("strong"),pKo=o("reformer"),uKo=o(" \u2014 "),Sz=a("a"),_Ko=o("ReformerForQuestionAnswering"),bKo=o(" (Reformer model)"),vKo=l(),TF=a("li"),x_e=a("strong"),FKo=o("rembert"),TKo=o(" \u2014 "),Rz=a("a"),MKo=o("RemBertForQuestionAnswering"),EKo=o(" (RemBERT model)"),CKo=l(),MF=a("li"),$_e=a("strong"),wKo=o("roberta"),AKo=o(" \u2014 "),Pz=a("a"),LKo=o("RobertaForQuestionAnswering"),yKo=o(" (RoBERTa model)"),xKo=l(),EF=a("li"),k_e=a("strong"),$Ko=o("roformer"),kKo=o(" \u2014 "),Bz=a("a"),SKo=o("RoFormerForQuestionAnswering"),RKo=o(" (RoFormer model)"),PKo=l(),CF=a("li"),S_e=a("strong"),BKo=o("splinter"),IKo=o(" \u2014 "),Iz=a("a"),NKo=o("SplinterForQuestionAnswering"),qKo=o(" (Splinter model)"),jKo=l(),wF=a("li"),R_e=a("strong"),DKo=o("squeezebert"),GKo=o(" \u2014 "),Nz=a("a"),OKo=o("SqueezeBertForQuestionAnswering"),VKo=o(" (SqueezeBERT model)"),XKo=l(),AF=a("li"),P_e=a("strong"),zKo=o("xlm"),WKo=o(" \u2014 "),qz=a("a"),QKo=o("XLMForQuestionAnsweringSimple"),HKo=o(" (XLM model)"),UKo=l(),LF=a("li"),B_e=a("strong"),JKo=o("xlm-roberta"),YKo=o(" \u2014 "),jz=a("a"),KKo=o("XLMRobertaForQuestionAnswering"),ZKo=o(" (XLM-RoBERTa model)"),eZo=l(),yF=a("li"),I_e=a("strong"),oZo=o("xlm-roberta-xl"),rZo=o(" \u2014 "),Dz=a("a"),tZo=o("XLMRobertaXLForQuestionAnswering"),aZo=o(" (XLM-RoBERTa-XL model)"),nZo=l(),xF=a("li"),N_e=a("strong"),sZo=o("xlnet"),lZo=o(" \u2014 "),Gz=a("a"),iZo=o("XLNetForQuestionAnsweringSimple"),dZo=o(" (XLNet model)"),cZo=l(),$F=a("li"),q_e=a("strong"),fZo=o("yoso"),mZo=o(" \u2014 "),Oz=a("a"),gZo=o("YosoForQuestionAnswering"),hZo=o(" (YOSO model)"),pZo=l(),kF=a("p"),uZo=o("The model is set in evaluation mode by default using "),j_e=a("code"),_Zo=o("model.eval()"),bZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D_e=a("code"),vZo=o("model.train()"),FZo=l(),F(SF.$$.fragment),QGe=l(),cd=a("h2"),RF=a("a"),G_e=a("span"),F(zy.$$.fragment),TZo=l(),O_e=a("span"),MZo=o("AutoModelForTableQuestionAnswering"),HGe=l(),jo=a("div"),F(Wy.$$.fragment),EZo=l(),fd=a("p"),CZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Vz=a("a"),wZo=o("from_pretrained()"),AZo=o(" class method or the "),Xz=a("a"),LZo=o("from_config()"),yZo=o(` class
method.`),xZo=l(),Qy=a("p"),$Zo=o("This class cannot be instantiated directly using "),V_e=a("code"),kZo=o("__init__()"),SZo=o(" (throws an error)."),RZo=l(),pt=a("div"),F(Hy.$$.fragment),PZo=l(),X_e=a("p"),BZo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),IZo=l(),md=a("p"),NZo=o(`Note:
Loading a model from its configuration file does `),z_e=a("strong"),qZo=o("not"),jZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zz=a("a"),DZo=o("from_pretrained()"),GZo=o(" to load the model weights."),OZo=l(),F(PF.$$.fragment),VZo=l(),so=a("div"),F(Uy.$$.fragment),XZo=l(),W_e=a("p"),zZo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),WZo=l(),Oa=a("p"),QZo=o("The model class to instantiate is selected based on the "),Q_e=a("code"),HZo=o("model_type"),UZo=o(` property of the config object (either
passed as an argument or loaded from `),H_e=a("code"),JZo=o("pretrained_model_name_or_path"),YZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U_e=a("code"),KZo=o("pretrained_model_name_or_path"),ZZo=o(":"),eer=l(),J_e=a("ul"),BF=a("li"),Y_e=a("strong"),oer=o("tapas"),rer=o(" \u2014 "),Wz=a("a"),ter=o("TapasForQuestionAnswering"),aer=o(" (TAPAS model)"),ner=l(),IF=a("p"),ser=o("The model is set in evaluation mode by default using "),K_e=a("code"),ler=o("model.eval()"),ier=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z_e=a("code"),der=o("model.train()"),cer=l(),F(NF.$$.fragment),UGe=l(),gd=a("h2"),qF=a("a"),e7e=a("span"),F(Jy.$$.fragment),fer=l(),o7e=a("span"),mer=o("AutoModelForImageClassification"),JGe=l(),Do=a("div"),F(Yy.$$.fragment),ger=l(),hd=a("p"),her=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Qz=a("a"),per=o("from_pretrained()"),uer=o(" class method or the "),Hz=a("a"),_er=o("from_config()"),ber=o(` class
method.`),ver=l(),Ky=a("p"),Fer=o("This class cannot be instantiated directly using "),r7e=a("code"),Ter=o("__init__()"),Mer=o(" (throws an error)."),Eer=l(),ut=a("div"),F(Zy.$$.fragment),Cer=l(),t7e=a("p"),wer=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Aer=l(),pd=a("p"),Ler=o(`Note:
Loading a model from its configuration file does `),a7e=a("strong"),yer=o("not"),xer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uz=a("a"),$er=o("from_pretrained()"),ker=o(" to load the model weights."),Ser=l(),F(jF.$$.fragment),Rer=l(),lo=a("div"),F(e8.$$.fragment),Per=l(),n7e=a("p"),Ber=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ier=l(),Va=a("p"),Ner=o("The model class to instantiate is selected based on the "),s7e=a("code"),qer=o("model_type"),jer=o(` property of the config object (either
passed as an argument or loaded from `),l7e=a("code"),Der=o("pretrained_model_name_or_path"),Ger=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i7e=a("code"),Oer=o("pretrained_model_name_or_path"),Ver=o(":"),Xer=l(),_e=a("ul"),DF=a("li"),d7e=a("strong"),zer=o("beit"),Wer=o(" \u2014 "),Jz=a("a"),Qer=o("BeitForImageClassification"),Her=o(" (BEiT model)"),Uer=l(),GF=a("li"),c7e=a("strong"),Jer=o("convnext"),Yer=o(" \u2014 "),Yz=a("a"),Ker=o("ConvNextForImageClassification"),Zer=o(" (ConvNeXT model)"),eor=l(),OF=a("li"),f7e=a("strong"),oor=o("cvt"),ror=o(" \u2014 "),Kz=a("a"),tor=o("CvtForImageClassification"),aor=o(" (CvT model)"),nor=l(),VF=a("li"),m7e=a("strong"),sor=o("data2vec-vision"),lor=o(" \u2014 "),Zz=a("a"),ior=o("Data2VecVisionForImageClassification"),dor=o(" (Data2VecVision model)"),cor=l(),Os=a("li"),g7e=a("strong"),mor=o("deit"),gor=o(" \u2014 "),eW=a("a"),hor=o("DeiTForImageClassification"),por=o(" or "),oW=a("a"),uor=o("DeiTForImageClassificationWithTeacher"),_or=o(" (DeiT model)"),bor=l(),XF=a("li"),h7e=a("strong"),vor=o("imagegpt"),For=o(" \u2014 "),rW=a("a"),Tor=o("ImageGPTForImageClassification"),Mor=o(" (ImageGPT model)"),Eor=l(),Vs=a("li"),p7e=a("strong"),Cor=o("levit"),wor=o(" \u2014 "),tW=a("a"),Aor=o("LevitForImageClassification"),Lor=o(" or "),aW=a("a"),yor=o("LevitForImageClassificationWithTeacher"),xor=o(" (LeViT model)"),$or=l(),zF=a("li"),u7e=a("strong"),kor=o("omnivore"),Sor=o(" \u2014 "),nW=a("a"),Ror=o("OmnivoreForVisionClassification"),Por=o(" (Omnivore model)"),Bor=l(),_t=a("li"),_7e=a("strong"),Ior=o("perceiver"),Nor=o(" \u2014 "),sW=a("a"),qor=o("PerceiverForImageClassificationLearned"),jor=o(" or "),lW=a("a"),Dor=o("PerceiverForImageClassificationFourier"),Gor=o(" or "),iW=a("a"),Oor=o("PerceiverForImageClassificationConvProcessing"),Vor=o(" (Perceiver model)"),Xor=l(),WF=a("li"),b7e=a("strong"),zor=o("poolformer"),Wor=o(" \u2014 "),dW=a("a"),Qor=o("PoolFormerForImageClassification"),Hor=o(" (PoolFormer model)"),Uor=l(),QF=a("li"),v7e=a("strong"),Jor=o("regnet"),Yor=o(" \u2014 "),cW=a("a"),Kor=o("RegNetForImageClassification"),Zor=o(" (RegNet model)"),err=l(),HF=a("li"),F7e=a("strong"),orr=o("resnet"),rrr=o(" \u2014 "),fW=a("a"),trr=o("ResNetForImageClassification"),arr=o(" (ResNet model)"),nrr=l(),UF=a("li"),T7e=a("strong"),srr=o("segformer"),lrr=o(" \u2014 "),mW=a("a"),irr=o("SegformerForImageClassification"),drr=o(" (SegFormer model)"),crr=l(),JF=a("li"),M7e=a("strong"),frr=o("swin"),mrr=o(" \u2014 "),gW=a("a"),grr=o("SwinForImageClassification"),hrr=o(" (Swin Transformer model)"),prr=l(),YF=a("li"),E7e=a("strong"),urr=o("van"),_rr=o(" \u2014 "),hW=a("a"),brr=o("VanForImageClassification"),vrr=o(" (VAN model)"),Frr=l(),KF=a("li"),C7e=a("strong"),Trr=o("vit"),Mrr=o(" \u2014 "),pW=a("a"),Err=o("ViTForImageClassification"),Crr=o(" (ViT model)"),wrr=l(),ZF=a("p"),Arr=o("The model is set in evaluation mode by default using "),w7e=a("code"),Lrr=o("model.eval()"),yrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A7e=a("code"),xrr=o("model.train()"),$rr=l(),F(eT.$$.fragment),YGe=l(),ud=a("h2"),oT=a("a"),L7e=a("span"),F(o8.$$.fragment),krr=l(),y7e=a("span"),Srr=o("AutoModelForVision2Seq"),KGe=l(),Go=a("div"),F(r8.$$.fragment),Rrr=l(),_d=a("p"),Prr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),uW=a("a"),Brr=o("from_pretrained()"),Irr=o(" class method or the "),_W=a("a"),Nrr=o("from_config()"),qrr=o(` class
method.`),jrr=l(),t8=a("p"),Drr=o("This class cannot be instantiated directly using "),x7e=a("code"),Grr=o("__init__()"),Orr=o(" (throws an error)."),Vrr=l(),bt=a("div"),F(a8.$$.fragment),Xrr=l(),$7e=a("p"),zrr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Wrr=l(),bd=a("p"),Qrr=o(`Note:
Loading a model from its configuration file does `),k7e=a("strong"),Hrr=o("not"),Urr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bW=a("a"),Jrr=o("from_pretrained()"),Yrr=o(" to load the model weights."),Krr=l(),F(rT.$$.fragment),Zrr=l(),io=a("div"),F(n8.$$.fragment),etr=l(),S7e=a("p"),otr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),rtr=l(),Xa=a("p"),ttr=o("The model class to instantiate is selected based on the "),R7e=a("code"),atr=o("model_type"),ntr=o(` property of the config object (either
passed as an argument or loaded from `),P7e=a("code"),str=o("pretrained_model_name_or_path"),ltr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B7e=a("code"),itr=o("pretrained_model_name_or_path"),dtr=o(":"),ctr=l(),I7e=a("ul"),tT=a("li"),N7e=a("strong"),ftr=o("vision-encoder-decoder"),mtr=o(" \u2014 "),vW=a("a"),gtr=o("VisionEncoderDecoderModel"),htr=o(" (Vision Encoder decoder model)"),ptr=l(),aT=a("p"),utr=o("The model is set in evaluation mode by default using "),q7e=a("code"),_tr=o("model.eval()"),btr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j7e=a("code"),vtr=o("model.train()"),Ftr=l(),F(nT.$$.fragment),ZGe=l(),vd=a("h2"),sT=a("a"),D7e=a("span"),F(s8.$$.fragment),Ttr=l(),G7e=a("span"),Mtr=o("AutoModelForVisualQuestionAnswering"),eOe=l(),Oo=a("div"),F(l8.$$.fragment),Etr=l(),Fd=a("p"),Ctr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),FW=a("a"),wtr=o("from_pretrained()"),Atr=o(" class method or the "),TW=a("a"),Ltr=o("from_config()"),ytr=o(` class
method.`),xtr=l(),i8=a("p"),$tr=o("This class cannot be instantiated directly using "),O7e=a("code"),ktr=o("__init__()"),Str=o(" (throws an error)."),Rtr=l(),vt=a("div"),F(d8.$$.fragment),Ptr=l(),V7e=a("p"),Btr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Itr=l(),Td=a("p"),Ntr=o(`Note:
Loading a model from its configuration file does `),X7e=a("strong"),qtr=o("not"),jtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MW=a("a"),Dtr=o("from_pretrained()"),Gtr=o(" to load the model weights."),Otr=l(),F(lT.$$.fragment),Vtr=l(),co=a("div"),F(c8.$$.fragment),Xtr=l(),z7e=a("p"),ztr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Wtr=l(),za=a("p"),Qtr=o("The model class to instantiate is selected based on the "),W7e=a("code"),Htr=o("model_type"),Utr=o(` property of the config object (either
passed as an argument or loaded from `),Q7e=a("code"),Jtr=o("pretrained_model_name_or_path"),Ytr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H7e=a("code"),Ktr=o("pretrained_model_name_or_path"),Ztr=o(":"),ear=l(),U7e=a("ul"),iT=a("li"),J7e=a("strong"),oar=o("vilt"),rar=o(" \u2014 "),EW=a("a"),tar=o("ViltForQuestionAnswering"),aar=o(" (ViLT model)"),nar=l(),dT=a("p"),sar=o("The model is set in evaluation mode by default using "),Y7e=a("code"),lar=o("model.eval()"),iar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K7e=a("code"),dar=o("model.train()"),car=l(),F(cT.$$.fragment),oOe=l(),Md=a("h2"),fT=a("a"),Z7e=a("span"),F(f8.$$.fragment),far=l(),e2e=a("span"),mar=o("AutoModelForAudioClassification"),rOe=l(),Vo=a("div"),F(m8.$$.fragment),gar=l(),Ed=a("p"),har=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),CW=a("a"),par=o("from_pretrained()"),uar=o(" class method or the "),wW=a("a"),_ar=o("from_config()"),bar=o(` class
method.`),Far=l(),g8=a("p"),Tar=o("This class cannot be instantiated directly using "),o2e=a("code"),Mar=o("__init__()"),Ear=o(" (throws an error)."),Car=l(),Ft=a("div"),F(h8.$$.fragment),war=l(),r2e=a("p"),Aar=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Lar=l(),Cd=a("p"),yar=o(`Note:
Loading a model from its configuration file does `),t2e=a("strong"),xar=o("not"),$ar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AW=a("a"),kar=o("from_pretrained()"),Sar=o(" to load the model weights."),Rar=l(),F(mT.$$.fragment),Par=l(),fo=a("div"),F(p8.$$.fragment),Bar=l(),a2e=a("p"),Iar=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Nar=l(),Wa=a("p"),qar=o("The model class to instantiate is selected based on the "),n2e=a("code"),jar=o("model_type"),Dar=o(` property of the config object (either
passed as an argument or loaded from `),s2e=a("code"),Gar=o("pretrained_model_name_or_path"),Oar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l2e=a("code"),Var=o("pretrained_model_name_or_path"),Xar=o(":"),zar=l(),Pe=a("ul"),gT=a("li"),i2e=a("strong"),War=o("data2vec-audio"),Qar=o(" \u2014 "),LW=a("a"),Har=o("Data2VecAudioForSequenceClassification"),Uar=o(" (Data2VecAudio model)"),Jar=l(),hT=a("li"),d2e=a("strong"),Yar=o("hubert"),Kar=o(" \u2014 "),yW=a("a"),Zar=o("HubertForSequenceClassification"),enr=o(" (Hubert model)"),onr=l(),pT=a("li"),c2e=a("strong"),rnr=o("sew"),tnr=o(" \u2014 "),xW=a("a"),anr=o("SEWForSequenceClassification"),nnr=o(" (SEW model)"),snr=l(),uT=a("li"),f2e=a("strong"),lnr=o("sew-d"),inr=o(" \u2014 "),$W=a("a"),dnr=o("SEWDForSequenceClassification"),cnr=o(" (SEW-D model)"),fnr=l(),_T=a("li"),m2e=a("strong"),mnr=o("unispeech"),gnr=o(" \u2014 "),kW=a("a"),hnr=o("UniSpeechForSequenceClassification"),pnr=o(" (UniSpeech model)"),unr=l(),bT=a("li"),g2e=a("strong"),_nr=o("unispeech-sat"),bnr=o(" \u2014 "),SW=a("a"),vnr=o("UniSpeechSatForSequenceClassification"),Fnr=o(" (UniSpeechSat model)"),Tnr=l(),vT=a("li"),h2e=a("strong"),Mnr=o("wav2vec2"),Enr=o(" \u2014 "),RW=a("a"),Cnr=o("Wav2Vec2ForSequenceClassification"),wnr=o(" (Wav2Vec2 model)"),Anr=l(),FT=a("li"),p2e=a("strong"),Lnr=o("wav2vec2-conformer"),ynr=o(" \u2014 "),PW=a("a"),xnr=o("Wav2Vec2ConformerForSequenceClassification"),$nr=o(" (Wav2Vec2-Conformer model)"),knr=l(),TT=a("li"),u2e=a("strong"),Snr=o("wavlm"),Rnr=o(" \u2014 "),BW=a("a"),Pnr=o("WavLMForSequenceClassification"),Bnr=o(" (WavLM model)"),Inr=l(),MT=a("p"),Nnr=o("The model is set in evaluation mode by default using "),_2e=a("code"),qnr=o("model.eval()"),jnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b2e=a("code"),Dnr=o("model.train()"),Gnr=l(),F(ET.$$.fragment),tOe=l(),wd=a("h2"),CT=a("a"),v2e=a("span"),F(u8.$$.fragment),Onr=l(),F2e=a("span"),Vnr=o("AutoModelForAudioFrameClassification"),aOe=l(),Xo=a("div"),F(_8.$$.fragment),Xnr=l(),Ad=a("p"),znr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),IW=a("a"),Wnr=o("from_pretrained()"),Qnr=o(" class method or the "),NW=a("a"),Hnr=o("from_config()"),Unr=o(` class
method.`),Jnr=l(),b8=a("p"),Ynr=o("This class cannot be instantiated directly using "),T2e=a("code"),Knr=o("__init__()"),Znr=o(" (throws an error)."),esr=l(),Tt=a("div"),F(v8.$$.fragment),osr=l(),M2e=a("p"),rsr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),tsr=l(),Ld=a("p"),asr=o(`Note:
Loading a model from its configuration file does `),E2e=a("strong"),nsr=o("not"),ssr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=a("a"),lsr=o("from_pretrained()"),isr=o(" to load the model weights."),dsr=l(),F(wT.$$.fragment),csr=l(),mo=a("div"),F(F8.$$.fragment),fsr=l(),C2e=a("p"),msr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),gsr=l(),Qa=a("p"),hsr=o("The model class to instantiate is selected based on the "),w2e=a("code"),psr=o("model_type"),usr=o(` property of the config object (either
passed as an argument or loaded from `),A2e=a("code"),_sr=o("pretrained_model_name_or_path"),bsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=a("code"),vsr=o("pretrained_model_name_or_path"),Fsr=o(":"),Tsr=l(),et=a("ul"),AT=a("li"),y2e=a("strong"),Msr=o("data2vec-audio"),Esr=o(" \u2014 "),jW=a("a"),Csr=o("Data2VecAudioForAudioFrameClassification"),wsr=o(" (Data2VecAudio model)"),Asr=l(),LT=a("li"),x2e=a("strong"),Lsr=o("unispeech-sat"),ysr=o(" \u2014 "),DW=a("a"),xsr=o("UniSpeechSatForAudioFrameClassification"),$sr=o(" (UniSpeechSat model)"),ksr=l(),yT=a("li"),$2e=a("strong"),Ssr=o("wav2vec2"),Rsr=o(" \u2014 "),GW=a("a"),Psr=o("Wav2Vec2ForAudioFrameClassification"),Bsr=o(" (Wav2Vec2 model)"),Isr=l(),xT=a("li"),k2e=a("strong"),Nsr=o("wav2vec2-conformer"),qsr=o(" \u2014 "),OW=a("a"),jsr=o("Wav2Vec2ConformerForAudioFrameClassification"),Dsr=o(" (Wav2Vec2-Conformer model)"),Gsr=l(),$T=a("li"),S2e=a("strong"),Osr=o("wavlm"),Vsr=o(" \u2014 "),VW=a("a"),Xsr=o("WavLMForAudioFrameClassification"),zsr=o(" (WavLM model)"),Wsr=l(),kT=a("p"),Qsr=o("The model is set in evaluation mode by default using "),R2e=a("code"),Hsr=o("model.eval()"),Usr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P2e=a("code"),Jsr=o("model.train()"),Ysr=l(),F(ST.$$.fragment),nOe=l(),yd=a("h2"),RT=a("a"),B2e=a("span"),F(T8.$$.fragment),Ksr=l(),I2e=a("span"),Zsr=o("AutoModelForCTC"),sOe=l(),zo=a("div"),F(M8.$$.fragment),elr=l(),xd=a("p"),olr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),XW=a("a"),rlr=o("from_pretrained()"),tlr=o(" class method or the "),zW=a("a"),alr=o("from_config()"),nlr=o(` class
method.`),slr=l(),E8=a("p"),llr=o("This class cannot be instantiated directly using "),N2e=a("code"),ilr=o("__init__()"),dlr=o(" (throws an error)."),clr=l(),Mt=a("div"),F(C8.$$.fragment),flr=l(),q2e=a("p"),mlr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),glr=l(),$d=a("p"),hlr=o(`Note:
Loading a model from its configuration file does `),j2e=a("strong"),plr=o("not"),ulr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=a("a"),_lr=o("from_pretrained()"),blr=o(" to load the model weights."),vlr=l(),F(PT.$$.fragment),Flr=l(),go=a("div"),F(w8.$$.fragment),Tlr=l(),D2e=a("p"),Mlr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Elr=l(),Ha=a("p"),Clr=o("The model class to instantiate is selected based on the "),G2e=a("code"),wlr=o("model_type"),Alr=o(` property of the config object (either
passed as an argument or loaded from `),O2e=a("code"),Llr=o("pretrained_model_name_or_path"),ylr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V2e=a("code"),xlr=o("pretrained_model_name_or_path"),$lr=o(":"),klr=l(),Le=a("ul"),BT=a("li"),X2e=a("strong"),Slr=o("data2vec-audio"),Rlr=o(" \u2014 "),QW=a("a"),Plr=o("Data2VecAudioForCTC"),Blr=o(" (Data2VecAudio model)"),Ilr=l(),IT=a("li"),z2e=a("strong"),Nlr=o("hubert"),qlr=o(" \u2014 "),HW=a("a"),jlr=o("HubertForCTC"),Dlr=o(" (Hubert model)"),Glr=l(),NT=a("li"),W2e=a("strong"),Olr=o("mctct"),Vlr=o(" \u2014 "),UW=a("a"),Xlr=o("MCTCTForCTC"),zlr=o(" (M-CTC-T model)"),Wlr=l(),qT=a("li"),Q2e=a("strong"),Qlr=o("sew"),Hlr=o(" \u2014 "),JW=a("a"),Ulr=o("SEWForCTC"),Jlr=o(" (SEW model)"),Ylr=l(),jT=a("li"),H2e=a("strong"),Klr=o("sew-d"),Zlr=o(" \u2014 "),YW=a("a"),eir=o("SEWDForCTC"),oir=o(" (SEW-D model)"),rir=l(),DT=a("li"),U2e=a("strong"),tir=o("unispeech"),air=o(" \u2014 "),KW=a("a"),nir=o("UniSpeechForCTC"),sir=o(" (UniSpeech model)"),lir=l(),GT=a("li"),J2e=a("strong"),iir=o("unispeech-sat"),dir=o(" \u2014 "),ZW=a("a"),cir=o("UniSpeechSatForCTC"),fir=o(" (UniSpeechSat model)"),mir=l(),OT=a("li"),Y2e=a("strong"),gir=o("wav2vec2"),hir=o(" \u2014 "),eQ=a("a"),pir=o("Wav2Vec2ForCTC"),uir=o(" (Wav2Vec2 model)"),_ir=l(),VT=a("li"),K2e=a("strong"),bir=o("wav2vec2-conformer"),vir=o(" \u2014 "),oQ=a("a"),Fir=o("Wav2Vec2ConformerForCTC"),Tir=o(" (Wav2Vec2-Conformer model)"),Mir=l(),XT=a("li"),Z2e=a("strong"),Eir=o("wavlm"),Cir=o(" \u2014 "),rQ=a("a"),wir=o("WavLMForCTC"),Air=o(" (WavLM model)"),Lir=l(),zT=a("p"),yir=o("The model is set in evaluation mode by default using "),e1e=a("code"),xir=o("model.eval()"),$ir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o1e=a("code"),kir=o("model.train()"),Sir=l(),F(WT.$$.fragment),lOe=l(),kd=a("h2"),QT=a("a"),r1e=a("span"),F(A8.$$.fragment),Rir=l(),t1e=a("span"),Pir=o("AutoModelForSpeechSeq2Seq"),iOe=l(),Wo=a("div"),F(L8.$$.fragment),Bir=l(),Sd=a("p"),Iir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),tQ=a("a"),Nir=o("from_pretrained()"),qir=o(" class method or the "),aQ=a("a"),jir=o("from_config()"),Dir=o(` class
method.`),Gir=l(),y8=a("p"),Oir=o("This class cannot be instantiated directly using "),a1e=a("code"),Vir=o("__init__()"),Xir=o(" (throws an error)."),zir=l(),Et=a("div"),F(x8.$$.fragment),Wir=l(),n1e=a("p"),Qir=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Hir=l(),Rd=a("p"),Uir=o(`Note:
Loading a model from its configuration file does `),s1e=a("strong"),Jir=o("not"),Yir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nQ=a("a"),Kir=o("from_pretrained()"),Zir=o(" to load the model weights."),edr=l(),F(HT.$$.fragment),odr=l(),ho=a("div"),F($8.$$.fragment),rdr=l(),l1e=a("p"),tdr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),adr=l(),Ua=a("p"),ndr=o("The model class to instantiate is selected based on the "),i1e=a("code"),sdr=o("model_type"),ldr=o(` property of the config object (either
passed as an argument or loaded from `),d1e=a("code"),idr=o("pretrained_model_name_or_path"),ddr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c1e=a("code"),cdr=o("pretrained_model_name_or_path"),fdr=o(":"),mdr=l(),k8=a("ul"),UT=a("li"),f1e=a("strong"),gdr=o("speech-encoder-decoder"),hdr=o(" \u2014 "),sQ=a("a"),pdr=o("SpeechEncoderDecoderModel"),udr=o(" (Speech Encoder decoder model)"),_dr=l(),JT=a("li"),m1e=a("strong"),bdr=o("speech_to_text"),vdr=o(" \u2014 "),lQ=a("a"),Fdr=o("Speech2TextForConditionalGeneration"),Tdr=o(" (Speech2Text model)"),Mdr=l(),YT=a("p"),Edr=o("The model is set in evaluation mode by default using "),g1e=a("code"),Cdr=o("model.eval()"),wdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h1e=a("code"),Adr=o("model.train()"),Ldr=l(),F(KT.$$.fragment),dOe=l(),Pd=a("h2"),ZT=a("a"),p1e=a("span"),F(S8.$$.fragment),ydr=l(),u1e=a("span"),xdr=o("AutoModelForAudioXVector"),cOe=l(),Qo=a("div"),F(R8.$$.fragment),$dr=l(),Bd=a("p"),kdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),iQ=a("a"),Sdr=o("from_pretrained()"),Rdr=o(" class method or the "),dQ=a("a"),Pdr=o("from_config()"),Bdr=o(` class
method.`),Idr=l(),P8=a("p"),Ndr=o("This class cannot be instantiated directly using "),_1e=a("code"),qdr=o("__init__()"),jdr=o(" (throws an error)."),Ddr=l(),Ct=a("div"),F(B8.$$.fragment),Gdr=l(),b1e=a("p"),Odr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Vdr=l(),Id=a("p"),Xdr=o(`Note:
Loading a model from its configuration file does `),v1e=a("strong"),zdr=o("not"),Wdr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),Qdr=o("from_pretrained()"),Hdr=o(" to load the model weights."),Udr=l(),F(eM.$$.fragment),Jdr=l(),po=a("div"),F(I8.$$.fragment),Ydr=l(),F1e=a("p"),Kdr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Zdr=l(),Ja=a("p"),ecr=o("The model class to instantiate is selected based on the "),T1e=a("code"),ocr=o("model_type"),rcr=o(` property of the config object (either
passed as an argument or loaded from `),M1e=a("code"),tcr=o("pretrained_model_name_or_path"),acr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E1e=a("code"),ncr=o("pretrained_model_name_or_path"),scr=o(":"),lcr=l(),ot=a("ul"),oM=a("li"),C1e=a("strong"),icr=o("data2vec-audio"),dcr=o(" \u2014 "),fQ=a("a"),ccr=o("Data2VecAudioForXVector"),fcr=o(" (Data2VecAudio model)"),mcr=l(),rM=a("li"),w1e=a("strong"),gcr=o("unispeech-sat"),hcr=o(" \u2014 "),mQ=a("a"),pcr=o("UniSpeechSatForXVector"),ucr=o(" (UniSpeechSat model)"),_cr=l(),tM=a("li"),A1e=a("strong"),bcr=o("wav2vec2"),vcr=o(" \u2014 "),gQ=a("a"),Fcr=o("Wav2Vec2ForXVector"),Tcr=o(" (Wav2Vec2 model)"),Mcr=l(),aM=a("li"),L1e=a("strong"),Ecr=o("wav2vec2-conformer"),Ccr=o(" \u2014 "),hQ=a("a"),wcr=o("Wav2Vec2ConformerForXVector"),Acr=o(" (Wav2Vec2-Conformer model)"),Lcr=l(),nM=a("li"),y1e=a("strong"),ycr=o("wavlm"),xcr=o(" \u2014 "),pQ=a("a"),$cr=o("WavLMForXVector"),kcr=o(" (WavLM model)"),Scr=l(),sM=a("p"),Rcr=o("The model is set in evaluation mode by default using "),x1e=a("code"),Pcr=o("model.eval()"),Bcr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$1e=a("code"),Icr=o("model.train()"),Ncr=l(),F(lM.$$.fragment),fOe=l(),Nd=a("h2"),iM=a("a"),k1e=a("span"),F(N8.$$.fragment),qcr=l(),S1e=a("span"),jcr=o("AutoModelForMaskedImageModeling"),mOe=l(),Ho=a("div"),F(q8.$$.fragment),Dcr=l(),qd=a("p"),Gcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),uQ=a("a"),Ocr=o("from_pretrained()"),Vcr=o(" class method or the "),_Q=a("a"),Xcr=o("from_config()"),zcr=o(` class
method.`),Wcr=l(),j8=a("p"),Qcr=o("This class cannot be instantiated directly using "),R1e=a("code"),Hcr=o("__init__()"),Ucr=o(" (throws an error)."),Jcr=l(),wt=a("div"),F(D8.$$.fragment),Ycr=l(),P1e=a("p"),Kcr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Zcr=l(),jd=a("p"),efr=o(`Note:
Loading a model from its configuration file does `),B1e=a("strong"),ofr=o("not"),rfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bQ=a("a"),tfr=o("from_pretrained()"),afr=o(" to load the model weights."),nfr=l(),F(dM.$$.fragment),sfr=l(),uo=a("div"),F(G8.$$.fragment),lfr=l(),I1e=a("p"),ifr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),dfr=l(),Ya=a("p"),cfr=o("The model class to instantiate is selected based on the "),N1e=a("code"),ffr=o("model_type"),mfr=o(` property of the config object (either
passed as an argument or loaded from `),q1e=a("code"),gfr=o("pretrained_model_name_or_path"),hfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j1e=a("code"),pfr=o("pretrained_model_name_or_path"),ufr=o(":"),_fr=l(),Dd=a("ul"),cM=a("li"),D1e=a("strong"),bfr=o("deit"),vfr=o(" \u2014 "),vQ=a("a"),Ffr=o("DeiTForMaskedImageModeling"),Tfr=o(" (DeiT model)"),Mfr=l(),fM=a("li"),G1e=a("strong"),Efr=o("swin"),Cfr=o(" \u2014 "),FQ=a("a"),wfr=o("SwinForMaskedImageModeling"),Afr=o(" (Swin Transformer model)"),Lfr=l(),mM=a("li"),O1e=a("strong"),yfr=o("vit"),xfr=o(" \u2014 "),TQ=a("a"),$fr=o("ViTForMaskedImageModeling"),kfr=o(" (ViT model)"),Sfr=l(),gM=a("p"),Rfr=o("The model is set in evaluation mode by default using "),V1e=a("code"),Pfr=o("model.eval()"),Bfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X1e=a("code"),Ifr=o("model.train()"),Nfr=l(),F(hM.$$.fragment),gOe=l(),Gd=a("h2"),pM=a("a"),z1e=a("span"),F(O8.$$.fragment),qfr=l(),W1e=a("span"),jfr=o("AutoModelForObjectDetection"),hOe=l(),Uo=a("div"),F(V8.$$.fragment),Dfr=l(),Od=a("p"),Gfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),MQ=a("a"),Ofr=o("from_pretrained()"),Vfr=o(" class method or the "),EQ=a("a"),Xfr=o("from_config()"),zfr=o(` class
method.`),Wfr=l(),X8=a("p"),Qfr=o("This class cannot be instantiated directly using "),Q1e=a("code"),Hfr=o("__init__()"),Ufr=o(" (throws an error)."),Jfr=l(),At=a("div"),F(z8.$$.fragment),Yfr=l(),H1e=a("p"),Kfr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Zfr=l(),Vd=a("p"),emr=o(`Note:
Loading a model from its configuration file does `),U1e=a("strong"),omr=o("not"),rmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CQ=a("a"),tmr=o("from_pretrained()"),amr=o(" to load the model weights."),nmr=l(),F(uM.$$.fragment),smr=l(),_o=a("div"),F(W8.$$.fragment),lmr=l(),J1e=a("p"),imr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),dmr=l(),Ka=a("p"),cmr=o("The model class to instantiate is selected based on the "),Y1e=a("code"),fmr=o("model_type"),mmr=o(` property of the config object (either
passed as an argument or loaded from `),K1e=a("code"),gmr=o("pretrained_model_name_or_path"),hmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=a("code"),pmr=o("pretrained_model_name_or_path"),umr=o(":"),_mr=l(),Q8=a("ul"),_M=a("li"),ebe=a("strong"),bmr=o("detr"),vmr=o(" \u2014 "),wQ=a("a"),Fmr=o("DetrForObjectDetection"),Tmr=o(" (DETR model)"),Mmr=l(),bM=a("li"),obe=a("strong"),Emr=o("yolos"),Cmr=o(" \u2014 "),AQ=a("a"),wmr=o("YolosForObjectDetection"),Amr=o(" (YOLOS model)"),Lmr=l(),vM=a("p"),ymr=o("The model is set in evaluation mode by default using "),rbe=a("code"),xmr=o("model.eval()"),$mr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tbe=a("code"),kmr=o("model.train()"),Smr=l(),F(FM.$$.fragment),pOe=l(),Xd=a("h2"),TM=a("a"),abe=a("span"),F(H8.$$.fragment),Rmr=l(),nbe=a("span"),Pmr=o("AutoModelForImageSegmentation"),uOe=l(),Jo=a("div"),F(U8.$$.fragment),Bmr=l(),zd=a("p"),Imr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),LQ=a("a"),Nmr=o("from_pretrained()"),qmr=o(" class method or the "),yQ=a("a"),jmr=o("from_config()"),Dmr=o(` class
method.`),Gmr=l(),J8=a("p"),Omr=o("This class cannot be instantiated directly using "),sbe=a("code"),Vmr=o("__init__()"),Xmr=o(" (throws an error)."),zmr=l(),Lt=a("div"),F(Y8.$$.fragment),Wmr=l(),lbe=a("p"),Qmr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Hmr=l(),Wd=a("p"),Umr=o(`Note:
Loading a model from its configuration file does `),ibe=a("strong"),Jmr=o("not"),Ymr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xQ=a("a"),Kmr=o("from_pretrained()"),Zmr=o(" to load the model weights."),egr=l(),F(MM.$$.fragment),ogr=l(),bo=a("div"),F(K8.$$.fragment),rgr=l(),dbe=a("p"),tgr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),agr=l(),Za=a("p"),ngr=o("The model class to instantiate is selected based on the "),cbe=a("code"),sgr=o("model_type"),lgr=o(` property of the config object (either
passed as an argument or loaded from `),fbe=a("code"),igr=o("pretrained_model_name_or_path"),dgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mbe=a("code"),cgr=o("pretrained_model_name_or_path"),fgr=o(":"),mgr=l(),gbe=a("ul"),EM=a("li"),hbe=a("strong"),ggr=o("detr"),hgr=o(" \u2014 "),$Q=a("a"),pgr=o("DetrForSegmentation"),ugr=o(" (DETR model)"),_gr=l(),CM=a("p"),bgr=o("The model is set in evaluation mode by default using "),pbe=a("code"),vgr=o("model.eval()"),Fgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ube=a("code"),Tgr=o("model.train()"),Mgr=l(),F(wM.$$.fragment),_Oe=l(),Qd=a("h2"),AM=a("a"),_be=a("span"),F(Z8.$$.fragment),Egr=l(),bbe=a("span"),Cgr=o("AutoModelForSemanticSegmentation"),bOe=l(),Yo=a("div"),F(e9.$$.fragment),wgr=l(),Hd=a("p"),Agr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),kQ=a("a"),Lgr=o("from_pretrained()"),ygr=o(" class method or the "),SQ=a("a"),xgr=o("from_config()"),$gr=o(` class
method.`),kgr=l(),o9=a("p"),Sgr=o("This class cannot be instantiated directly using "),vbe=a("code"),Rgr=o("__init__()"),Pgr=o(" (throws an error)."),Bgr=l(),yt=a("div"),F(r9.$$.fragment),Igr=l(),Fbe=a("p"),Ngr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),qgr=l(),Ud=a("p"),jgr=o(`Note:
Loading a model from its configuration file does `),Tbe=a("strong"),Dgr=o("not"),Ggr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RQ=a("a"),Ogr=o("from_pretrained()"),Vgr=o(" to load the model weights."),Xgr=l(),F(LM.$$.fragment),zgr=l(),vo=a("div"),F(t9.$$.fragment),Wgr=l(),Mbe=a("p"),Qgr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Hgr=l(),en=a("p"),Ugr=o("The model class to instantiate is selected based on the "),Ebe=a("code"),Jgr=o("model_type"),Ygr=o(` property of the config object (either
passed as an argument or loaded from `),Cbe=a("code"),Kgr=o("pretrained_model_name_or_path"),Zgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wbe=a("code"),ehr=o("pretrained_model_name_or_path"),ohr=o(":"),rhr=l(),on=a("ul"),yM=a("li"),Abe=a("strong"),thr=o("beit"),ahr=o(" \u2014 "),PQ=a("a"),nhr=o("BeitForSemanticSegmentation"),shr=o(" (BEiT model)"),lhr=l(),xM=a("li"),Lbe=a("strong"),ihr=o("data2vec-vision"),dhr=o(" \u2014 "),BQ=a("a"),chr=o("Data2VecVisionForSemanticSegmentation"),fhr=o(" (Data2VecVision model)"),mhr=l(),$M=a("li"),ybe=a("strong"),ghr=o("dpt"),hhr=o(" \u2014 "),IQ=a("a"),phr=o("DPTForSemanticSegmentation"),uhr=o(" (DPT model)"),_hr=l(),kM=a("li"),xbe=a("strong"),bhr=o("segformer"),vhr=o(" \u2014 "),NQ=a("a"),Fhr=o("SegformerForSemanticSegmentation"),Thr=o(" (SegFormer model)"),Mhr=l(),SM=a("p"),Ehr=o("The model is set in evaluation mode by default using "),$be=a("code"),Chr=o("model.eval()"),whr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kbe=a("code"),Ahr=o("model.train()"),Lhr=l(),F(RM.$$.fragment),vOe=l(),Jd=a("h2"),PM=a("a"),Sbe=a("span"),F(a9.$$.fragment),yhr=l(),Rbe=a("span"),xhr=o("AutoModelForInstanceSegmentation"),FOe=l(),Ko=a("div"),F(n9.$$.fragment),$hr=l(),Yd=a("p"),khr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),qQ=a("a"),Shr=o("from_pretrained()"),Rhr=o(" class method or the "),jQ=a("a"),Phr=o("from_config()"),Bhr=o(` class
method.`),Ihr=l(),s9=a("p"),Nhr=o("This class cannot be instantiated directly using "),Pbe=a("code"),qhr=o("__init__()"),jhr=o(" (throws an error)."),Dhr=l(),xt=a("div"),F(l9.$$.fragment),Ghr=l(),Bbe=a("p"),Ohr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Vhr=l(),Kd=a("p"),Xhr=o(`Note:
Loading a model from its configuration file does `),Ibe=a("strong"),zhr=o("not"),Whr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=a("a"),Qhr=o("from_pretrained()"),Hhr=o(" to load the model weights."),Uhr=l(),F(BM.$$.fragment),Jhr=l(),Fo=a("div"),F(i9.$$.fragment),Yhr=l(),Nbe=a("p"),Khr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Zhr=l(),rn=a("p"),epr=o("The model class to instantiate is selected based on the "),qbe=a("code"),opr=o("model_type"),rpr=o(` property of the config object (either
passed as an argument or loaded from `),jbe=a("code"),tpr=o("pretrained_model_name_or_path"),apr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dbe=a("code"),npr=o("pretrained_model_name_or_path"),spr=o(":"),lpr=l(),Gbe=a("ul"),IM=a("li"),Obe=a("strong"),ipr=o("maskformer"),dpr=o(" \u2014 "),GQ=a("a"),cpr=o("MaskFormerForInstanceSegmentation"),fpr=o(" (MaskFormer model)"),mpr=l(),NM=a("p"),gpr=o("The model is set in evaluation mode by default using "),Vbe=a("code"),hpr=o("model.eval()"),ppr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xbe=a("code"),upr=o("model.train()"),_pr=l(),F(qM.$$.fragment),TOe=l(),Zd=a("h2"),jM=a("a"),zbe=a("span"),F(d9.$$.fragment),bpr=l(),Wbe=a("span"),vpr=o("TFAutoModel"),MOe=l(),Zo=a("div"),F(c9.$$.fragment),Fpr=l(),ec=a("p"),Tpr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),OQ=a("a"),Mpr=o("from_pretrained()"),Epr=o(" class method or the "),VQ=a("a"),Cpr=o("from_config()"),wpr=o(` class
method.`),Apr=l(),f9=a("p"),Lpr=o("This class cannot be instantiated directly using "),Qbe=a("code"),ypr=o("__init__()"),xpr=o(" (throws an error)."),$pr=l(),$t=a("div"),F(m9.$$.fragment),kpr=l(),Hbe=a("p"),Spr=o("Instantiates one of the base model classes of the library from a configuration."),Rpr=l(),oc=a("p"),Ppr=o(`Note:
Loading a model from its configuration file does `),Ube=a("strong"),Bpr=o("not"),Ipr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XQ=a("a"),Npr=o("from_pretrained()"),qpr=o(" to load the model weights."),jpr=l(),F(DM.$$.fragment),Dpr=l(),Lr=a("div"),F(g9.$$.fragment),Gpr=l(),Jbe=a("p"),Opr=o("Instantiate one of the base model classes of the library from a pretrained model."),Vpr=l(),tn=a("p"),Xpr=o("The model class to instantiate is selected based on the "),Ybe=a("code"),zpr=o("model_type"),Wpr=o(` property of the config object (either
passed as an argument or loaded from `),Kbe=a("code"),Qpr=o("pretrained_model_name_or_path"),Hpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zbe=a("code"),Upr=o("pretrained_model_name_or_path"),Jpr=o(":"),Ypr=l(),q=a("ul"),GM=a("li"),eve=a("strong"),Kpr=o("albert"),Zpr=o(" \u2014 "),zQ=a("a"),eur=o("TFAlbertModel"),our=o(" (ALBERT model)"),rur=l(),OM=a("li"),ove=a("strong"),tur=o("bart"),aur=o(" \u2014 "),WQ=a("a"),nur=o("TFBartModel"),sur=o(" (BART model)"),lur=l(),VM=a("li"),rve=a("strong"),iur=o("bert"),dur=o(" \u2014 "),QQ=a("a"),cur=o("TFBertModel"),fur=o(" (BERT model)"),mur=l(),XM=a("li"),tve=a("strong"),gur=o("blenderbot"),hur=o(" \u2014 "),HQ=a("a"),pur=o("TFBlenderbotModel"),uur=o(" (Blenderbot model)"),_ur=l(),zM=a("li"),ave=a("strong"),bur=o("blenderbot-small"),vur=o(" \u2014 "),UQ=a("a"),Fur=o("TFBlenderbotSmallModel"),Tur=o(" (BlenderbotSmall model)"),Mur=l(),WM=a("li"),nve=a("strong"),Eur=o("camembert"),Cur=o(" \u2014 "),JQ=a("a"),wur=o("TFCamembertModel"),Aur=o(" (CamemBERT model)"),Lur=l(),QM=a("li"),sve=a("strong"),yur=o("clip"),xur=o(" \u2014 "),YQ=a("a"),$ur=o("TFCLIPModel"),kur=o(" (CLIP model)"),Sur=l(),HM=a("li"),lve=a("strong"),Rur=o("convbert"),Pur=o(" \u2014 "),KQ=a("a"),Bur=o("TFConvBertModel"),Iur=o(" (ConvBERT model)"),Nur=l(),UM=a("li"),ive=a("strong"),qur=o("convnext"),jur=o(" \u2014 "),ZQ=a("a"),Dur=o("TFConvNextModel"),Gur=o(" (ConvNeXT model)"),Our=l(),JM=a("li"),dve=a("strong"),Vur=o("ctrl"),Xur=o(" \u2014 "),eH=a("a"),zur=o("TFCTRLModel"),Wur=o(" (CTRL model)"),Qur=l(),YM=a("li"),cve=a("strong"),Hur=o("data2vec-vision"),Uur=o(" \u2014 "),oH=a("a"),Jur=o("TFData2VecVisionModel"),Yur=o(" (Data2VecVision model)"),Kur=l(),KM=a("li"),fve=a("strong"),Zur=o("deberta"),e_r=o(" \u2014 "),rH=a("a"),o_r=o("TFDebertaModel"),r_r=o(" (DeBERTa model)"),t_r=l(),ZM=a("li"),mve=a("strong"),a_r=o("deberta-v2"),n_r=o(" \u2014 "),tH=a("a"),s_r=o("TFDebertaV2Model"),l_r=o(" (DeBERTa-v2 model)"),i_r=l(),eE=a("li"),gve=a("strong"),d_r=o("distilbert"),c_r=o(" \u2014 "),aH=a("a"),f_r=o("TFDistilBertModel"),m_r=o(" (DistilBERT model)"),g_r=l(),oE=a("li"),hve=a("strong"),h_r=o("dpr"),p_r=o(" \u2014 "),nH=a("a"),u_r=o("TFDPRQuestionEncoder"),__r=o(" (DPR model)"),b_r=l(),rE=a("li"),pve=a("strong"),v_r=o("electra"),F_r=o(" \u2014 "),sH=a("a"),T_r=o("TFElectraModel"),M_r=o(" (ELECTRA model)"),E_r=l(),tE=a("li"),uve=a("strong"),C_r=o("flaubert"),w_r=o(" \u2014 "),lH=a("a"),A_r=o("TFFlaubertModel"),L_r=o(" (FlauBERT model)"),y_r=l(),Xs=a("li"),_ve=a("strong"),x_r=o("funnel"),$_r=o(" \u2014 "),iH=a("a"),k_r=o("TFFunnelModel"),S_r=o(" or "),dH=a("a"),R_r=o("TFFunnelBaseModel"),P_r=o(" (Funnel Transformer model)"),B_r=l(),aE=a("li"),bve=a("strong"),I_r=o("gpt2"),N_r=o(" \u2014 "),cH=a("a"),q_r=o("TFGPT2Model"),j_r=o(" (OpenAI GPT-2 model)"),D_r=l(),nE=a("li"),vve=a("strong"),G_r=o("gptj"),O_r=o(" \u2014 "),fH=a("a"),V_r=o("TFGPTJModel"),X_r=o(" (GPT-J model)"),z_r=l(),sE=a("li"),Fve=a("strong"),W_r=o("hubert"),Q_r=o(" \u2014 "),mH=a("a"),H_r=o("TFHubertModel"),U_r=o(" (Hubert model)"),J_r=l(),lE=a("li"),Tve=a("strong"),Y_r=o("layoutlm"),K_r=o(" \u2014 "),gH=a("a"),Z_r=o("TFLayoutLMModel"),e7r=o(" (LayoutLM model)"),o7r=l(),iE=a("li"),Mve=a("strong"),r7r=o("led"),t7r=o(" \u2014 "),hH=a("a"),a7r=o("TFLEDModel"),n7r=o(" (LED model)"),s7r=l(),dE=a("li"),Eve=a("strong"),l7r=o("longformer"),i7r=o(" \u2014 "),pH=a("a"),d7r=o("TFLongformerModel"),c7r=o(" (Longformer model)"),f7r=l(),cE=a("li"),Cve=a("strong"),m7r=o("lxmert"),g7r=o(" \u2014 "),uH=a("a"),h7r=o("TFLxmertModel"),p7r=o(" (LXMERT model)"),u7r=l(),fE=a("li"),wve=a("strong"),_7r=o("marian"),b7r=o(" \u2014 "),_H=a("a"),v7r=o("TFMarianModel"),F7r=o(" (Marian model)"),T7r=l(),mE=a("li"),Ave=a("strong"),M7r=o("mbart"),E7r=o(" \u2014 "),bH=a("a"),C7r=o("TFMBartModel"),w7r=o(" (mBART model)"),A7r=l(),gE=a("li"),Lve=a("strong"),L7r=o("mobilebert"),y7r=o(" \u2014 "),vH=a("a"),x7r=o("TFMobileBertModel"),$7r=o(" (MobileBERT model)"),k7r=l(),hE=a("li"),yve=a("strong"),S7r=o("mpnet"),R7r=o(" \u2014 "),FH=a("a"),P7r=o("TFMPNetModel"),B7r=o(" (MPNet model)"),I7r=l(),pE=a("li"),xve=a("strong"),N7r=o("mt5"),q7r=o(" \u2014 "),TH=a("a"),j7r=o("TFMT5Model"),D7r=o(" (MT5 model)"),G7r=l(),uE=a("li"),$ve=a("strong"),O7r=o("openai-gpt"),V7r=o(" \u2014 "),MH=a("a"),X7r=o("TFOpenAIGPTModel"),z7r=o(" (OpenAI GPT model)"),W7r=l(),_E=a("li"),kve=a("strong"),Q7r=o("opt"),H7r=o(" \u2014 "),EH=a("a"),U7r=o("TFOPTModel"),J7r=o(" (OPT model)"),Y7r=l(),bE=a("li"),Sve=a("strong"),K7r=o("pegasus"),Z7r=o(" \u2014 "),CH=a("a"),e2r=o("TFPegasusModel"),o2r=o(" (Pegasus model)"),r2r=l(),vE=a("li"),Rve=a("strong"),t2r=o("rembert"),a2r=o(" \u2014 "),wH=a("a"),n2r=o("TFRemBertModel"),s2r=o(" (RemBERT model)"),l2r=l(),FE=a("li"),Pve=a("strong"),i2r=o("roberta"),d2r=o(" \u2014 "),AH=a("a"),c2r=o("TFRobertaModel"),f2r=o(" (RoBERTa model)"),m2r=l(),TE=a("li"),Bve=a("strong"),g2r=o("roformer"),h2r=o(" \u2014 "),LH=a("a"),p2r=o("TFRoFormerModel"),u2r=o(" (RoFormer model)"),_2r=l(),ME=a("li"),Ive=a("strong"),b2r=o("speech_to_text"),v2r=o(" \u2014 "),yH=a("a"),F2r=o("TFSpeech2TextModel"),T2r=o(" (Speech2Text model)"),M2r=l(),EE=a("li"),Nve=a("strong"),E2r=o("swin"),C2r=o(" \u2014 "),xH=a("a"),w2r=o("TFSwinModel"),A2r=o(" (Swin Transformer model)"),L2r=l(),CE=a("li"),qve=a("strong"),y2r=o("t5"),x2r=o(" \u2014 "),$H=a("a"),$2r=o("TFT5Model"),k2r=o(" (T5 model)"),S2r=l(),wE=a("li"),jve=a("strong"),R2r=o("tapas"),P2r=o(" \u2014 "),kH=a("a"),B2r=o("TFTapasModel"),I2r=o(" (TAPAS model)"),N2r=l(),AE=a("li"),Dve=a("strong"),q2r=o("transfo-xl"),j2r=o(" \u2014 "),SH=a("a"),D2r=o("TFTransfoXLModel"),G2r=o(" (Transformer-XL model)"),O2r=l(),LE=a("li"),Gve=a("strong"),V2r=o("vit"),X2r=o(" \u2014 "),RH=a("a"),z2r=o("TFViTModel"),W2r=o(" (ViT model)"),Q2r=l(),yE=a("li"),Ove=a("strong"),H2r=o("vit_mae"),U2r=o(" \u2014 "),PH=a("a"),J2r=o("TFViTMAEModel"),Y2r=o(" (ViTMAE model)"),K2r=l(),xE=a("li"),Vve=a("strong"),Z2r=o("wav2vec2"),e1r=o(" \u2014 "),BH=a("a"),o1r=o("TFWav2Vec2Model"),r1r=o(" (Wav2Vec2 model)"),t1r=l(),$E=a("li"),Xve=a("strong"),a1r=o("xlm"),n1r=o(" \u2014 "),IH=a("a"),s1r=o("TFXLMModel"),l1r=o(" (XLM model)"),i1r=l(),kE=a("li"),zve=a("strong"),d1r=o("xlm-roberta"),c1r=o(" \u2014 "),NH=a("a"),f1r=o("TFXLMRobertaModel"),m1r=o(" (XLM-RoBERTa model)"),g1r=l(),SE=a("li"),Wve=a("strong"),h1r=o("xlnet"),p1r=o(" \u2014 "),qH=a("a"),u1r=o("TFXLNetModel"),_1r=o(" (XLNet model)"),b1r=l(),F(RE.$$.fragment),EOe=l(),rc=a("h2"),PE=a("a"),Qve=a("span"),F(h9.$$.fragment),v1r=l(),Hve=a("span"),F1r=o("TFAutoModelForPreTraining"),COe=l(),er=a("div"),F(p9.$$.fragment),T1r=l(),tc=a("p"),M1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),jH=a("a"),E1r=o("from_pretrained()"),C1r=o(" class method or the "),DH=a("a"),w1r=o("from_config()"),A1r=o(` class
method.`),L1r=l(),u9=a("p"),y1r=o("This class cannot be instantiated directly using "),Uve=a("code"),x1r=o("__init__()"),$1r=o(" (throws an error)."),k1r=l(),kt=a("div"),F(_9.$$.fragment),S1r=l(),Jve=a("p"),R1r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),P1r=l(),ac=a("p"),B1r=o(`Note:
Loading a model from its configuration file does `),Yve=a("strong"),I1r=o("not"),N1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GH=a("a"),q1r=o("from_pretrained()"),j1r=o(" to load the model weights."),D1r=l(),F(BE.$$.fragment),G1r=l(),yr=a("div"),F(b9.$$.fragment),O1r=l(),Kve=a("p"),V1r=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),X1r=l(),an=a("p"),z1r=o("The model class to instantiate is selected based on the "),Zve=a("code"),W1r=o("model_type"),Q1r=o(` property of the config object (either
passed as an argument or loaded from `),eFe=a("code"),H1r=o("pretrained_model_name_or_path"),U1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oFe=a("code"),J1r=o("pretrained_model_name_or_path"),Y1r=o(":"),K1r=l(),se=a("ul"),IE=a("li"),rFe=a("strong"),Z1r=o("albert"),ebr=o(" \u2014 "),OH=a("a"),obr=o("TFAlbertForPreTraining"),rbr=o(" (ALBERT model)"),tbr=l(),NE=a("li"),tFe=a("strong"),abr=o("bart"),nbr=o(" \u2014 "),VH=a("a"),sbr=o("TFBartForConditionalGeneration"),lbr=o(" (BART model)"),ibr=l(),qE=a("li"),aFe=a("strong"),dbr=o("bert"),cbr=o(" \u2014 "),XH=a("a"),fbr=o("TFBertForPreTraining"),mbr=o(" (BERT model)"),gbr=l(),jE=a("li"),nFe=a("strong"),hbr=o("camembert"),pbr=o(" \u2014 "),zH=a("a"),ubr=o("TFCamembertForMaskedLM"),_br=o(" (CamemBERT model)"),bbr=l(),DE=a("li"),sFe=a("strong"),vbr=o("ctrl"),Fbr=o(" \u2014 "),WH=a("a"),Tbr=o("TFCTRLLMHeadModel"),Mbr=o(" (CTRL model)"),Ebr=l(),GE=a("li"),lFe=a("strong"),Cbr=o("distilbert"),wbr=o(" \u2014 "),QH=a("a"),Abr=o("TFDistilBertForMaskedLM"),Lbr=o(" (DistilBERT model)"),ybr=l(),OE=a("li"),iFe=a("strong"),xbr=o("electra"),$br=o(" \u2014 "),HH=a("a"),kbr=o("TFElectraForPreTraining"),Sbr=o(" (ELECTRA model)"),Rbr=l(),VE=a("li"),dFe=a("strong"),Pbr=o("flaubert"),Bbr=o(" \u2014 "),UH=a("a"),Ibr=o("TFFlaubertWithLMHeadModel"),Nbr=o(" (FlauBERT model)"),qbr=l(),XE=a("li"),cFe=a("strong"),jbr=o("funnel"),Dbr=o(" \u2014 "),JH=a("a"),Gbr=o("TFFunnelForPreTraining"),Obr=o(" (Funnel Transformer model)"),Vbr=l(),zE=a("li"),fFe=a("strong"),Xbr=o("gpt2"),zbr=o(" \u2014 "),YH=a("a"),Wbr=o("TFGPT2LMHeadModel"),Qbr=o(" (OpenAI GPT-2 model)"),Hbr=l(),WE=a("li"),mFe=a("strong"),Ubr=o("layoutlm"),Jbr=o(" \u2014 "),KH=a("a"),Ybr=o("TFLayoutLMForMaskedLM"),Kbr=o(" (LayoutLM model)"),Zbr=l(),QE=a("li"),gFe=a("strong"),evr=o("lxmert"),ovr=o(" \u2014 "),ZH=a("a"),rvr=o("TFLxmertForPreTraining"),tvr=o(" (LXMERT model)"),avr=l(),HE=a("li"),hFe=a("strong"),nvr=o("mobilebert"),svr=o(" \u2014 "),eU=a("a"),lvr=o("TFMobileBertForPreTraining"),ivr=o(" (MobileBERT model)"),dvr=l(),UE=a("li"),pFe=a("strong"),cvr=o("mpnet"),fvr=o(" \u2014 "),oU=a("a"),mvr=o("TFMPNetForMaskedLM"),gvr=o(" (MPNet model)"),hvr=l(),JE=a("li"),uFe=a("strong"),pvr=o("openai-gpt"),uvr=o(" \u2014 "),rU=a("a"),_vr=o("TFOpenAIGPTLMHeadModel"),bvr=o(" (OpenAI GPT model)"),vvr=l(),YE=a("li"),_Fe=a("strong"),Fvr=o("roberta"),Tvr=o(" \u2014 "),tU=a("a"),Mvr=o("TFRobertaForMaskedLM"),Evr=o(" (RoBERTa model)"),Cvr=l(),KE=a("li"),bFe=a("strong"),wvr=o("t5"),Avr=o(" \u2014 "),aU=a("a"),Lvr=o("TFT5ForConditionalGeneration"),yvr=o(" (T5 model)"),xvr=l(),ZE=a("li"),vFe=a("strong"),$vr=o("tapas"),kvr=o(" \u2014 "),nU=a("a"),Svr=o("TFTapasForMaskedLM"),Rvr=o(" (TAPAS model)"),Pvr=l(),e4=a("li"),FFe=a("strong"),Bvr=o("transfo-xl"),Ivr=o(" \u2014 "),sU=a("a"),Nvr=o("TFTransfoXLLMHeadModel"),qvr=o(" (Transformer-XL model)"),jvr=l(),o4=a("li"),TFe=a("strong"),Dvr=o("vit_mae"),Gvr=o(" \u2014 "),lU=a("a"),Ovr=o("TFViTMAEForPreTraining"),Vvr=o(" (ViTMAE model)"),Xvr=l(),r4=a("li"),MFe=a("strong"),zvr=o("xlm"),Wvr=o(" \u2014 "),iU=a("a"),Qvr=o("TFXLMWithLMHeadModel"),Hvr=o(" (XLM model)"),Uvr=l(),t4=a("li"),EFe=a("strong"),Jvr=o("xlm-roberta"),Yvr=o(" \u2014 "),dU=a("a"),Kvr=o("TFXLMRobertaForMaskedLM"),Zvr=o(" (XLM-RoBERTa model)"),eFr=l(),a4=a("li"),CFe=a("strong"),oFr=o("xlnet"),rFr=o(" \u2014 "),cU=a("a"),tFr=o("TFXLNetLMHeadModel"),aFr=o(" (XLNet model)"),nFr=l(),F(n4.$$.fragment),wOe=l(),nc=a("h2"),s4=a("a"),wFe=a("span"),F(v9.$$.fragment),sFr=l(),AFe=a("span"),lFr=o("TFAutoModelForCausalLM"),AOe=l(),or=a("div"),F(F9.$$.fragment),iFr=l(),sc=a("p"),dFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),fU=a("a"),cFr=o("from_pretrained()"),fFr=o(" class method or the "),mU=a("a"),mFr=o("from_config()"),gFr=o(` class
method.`),hFr=l(),T9=a("p"),pFr=o("This class cannot be instantiated directly using "),LFe=a("code"),uFr=o("__init__()"),_Fr=o(" (throws an error)."),bFr=l(),St=a("div"),F(M9.$$.fragment),vFr=l(),yFe=a("p"),FFr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),TFr=l(),lc=a("p"),MFr=o(`Note:
Loading a model from its configuration file does `),xFe=a("strong"),EFr=o("not"),CFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gU=a("a"),wFr=o("from_pretrained()"),AFr=o(" to load the model weights."),LFr=l(),F(l4.$$.fragment),yFr=l(),xr=a("div"),F(E9.$$.fragment),xFr=l(),$Fe=a("p"),$Fr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kFr=l(),nn=a("p"),SFr=o("The model class to instantiate is selected based on the "),kFe=a("code"),RFr=o("model_type"),PFr=o(` property of the config object (either
passed as an argument or loaded from `),SFe=a("code"),BFr=o("pretrained_model_name_or_path"),IFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RFe=a("code"),NFr=o("pretrained_model_name_or_path"),qFr=o(":"),jFr=l(),Me=a("ul"),i4=a("li"),PFe=a("strong"),DFr=o("bert"),GFr=o(" \u2014 "),hU=a("a"),OFr=o("TFBertLMHeadModel"),VFr=o(" (BERT model)"),XFr=l(),d4=a("li"),BFe=a("strong"),zFr=o("camembert"),WFr=o(" \u2014 "),pU=a("a"),QFr=o("TFCamembertForCausalLM"),HFr=o(" (CamemBERT model)"),UFr=l(),c4=a("li"),IFe=a("strong"),JFr=o("ctrl"),YFr=o(" \u2014 "),uU=a("a"),KFr=o("TFCTRLLMHeadModel"),ZFr=o(" (CTRL model)"),eTr=l(),f4=a("li"),NFe=a("strong"),oTr=o("gpt2"),rTr=o(" \u2014 "),_U=a("a"),tTr=o("TFGPT2LMHeadModel"),aTr=o(" (OpenAI GPT-2 model)"),nTr=l(),m4=a("li"),qFe=a("strong"),sTr=o("gptj"),lTr=o(" \u2014 "),bU=a("a"),iTr=o("TFGPTJForCausalLM"),dTr=o(" (GPT-J model)"),cTr=l(),g4=a("li"),jFe=a("strong"),fTr=o("openai-gpt"),mTr=o(" \u2014 "),vU=a("a"),gTr=o("TFOpenAIGPTLMHeadModel"),hTr=o(" (OpenAI GPT model)"),pTr=l(),h4=a("li"),DFe=a("strong"),uTr=o("opt"),_Tr=o(" \u2014 "),FU=a("a"),bTr=o("TFOPTForCausalLM"),vTr=o(" (OPT model)"),FTr=l(),p4=a("li"),GFe=a("strong"),TTr=o("rembert"),MTr=o(" \u2014 "),TU=a("a"),ETr=o("TFRemBertForCausalLM"),CTr=o(" (RemBERT model)"),wTr=l(),u4=a("li"),OFe=a("strong"),ATr=o("roberta"),LTr=o(" \u2014 "),MU=a("a"),yTr=o("TFRobertaForCausalLM"),xTr=o(" (RoBERTa model)"),$Tr=l(),_4=a("li"),VFe=a("strong"),kTr=o("roformer"),STr=o(" \u2014 "),EU=a("a"),RTr=o("TFRoFormerForCausalLM"),PTr=o(" (RoFormer model)"),BTr=l(),b4=a("li"),XFe=a("strong"),ITr=o("transfo-xl"),NTr=o(" \u2014 "),CU=a("a"),qTr=o("TFTransfoXLLMHeadModel"),jTr=o(" (Transformer-XL model)"),DTr=l(),v4=a("li"),zFe=a("strong"),GTr=o("xlm"),OTr=o(" \u2014 "),wU=a("a"),VTr=o("TFXLMWithLMHeadModel"),XTr=o(" (XLM model)"),zTr=l(),F4=a("li"),WFe=a("strong"),WTr=o("xlnet"),QTr=o(" \u2014 "),AU=a("a"),HTr=o("TFXLNetLMHeadModel"),UTr=o(" (XLNet model)"),JTr=l(),F(T4.$$.fragment),LOe=l(),ic=a("h2"),M4=a("a"),QFe=a("span"),F(C9.$$.fragment),YTr=l(),HFe=a("span"),KTr=o("TFAutoModelForImageClassification"),yOe=l(),rr=a("div"),F(w9.$$.fragment),ZTr=l(),dc=a("p"),eMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),LU=a("a"),oMr=o("from_pretrained()"),rMr=o(" class method or the "),yU=a("a"),tMr=o("from_config()"),aMr=o(` class
method.`),nMr=l(),A9=a("p"),sMr=o("This class cannot be instantiated directly using "),UFe=a("code"),lMr=o("__init__()"),iMr=o(" (throws an error)."),dMr=l(),Rt=a("div"),F(L9.$$.fragment),cMr=l(),JFe=a("p"),fMr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),mMr=l(),cc=a("p"),gMr=o(`Note:
Loading a model from its configuration file does `),YFe=a("strong"),hMr=o("not"),pMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=a("a"),uMr=o("from_pretrained()"),_Mr=o(" to load the model weights."),bMr=l(),F(E4.$$.fragment),vMr=l(),$r=a("div"),F(y9.$$.fragment),FMr=l(),KFe=a("p"),TMr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),MMr=l(),sn=a("p"),EMr=o("The model class to instantiate is selected based on the "),ZFe=a("code"),CMr=o("model_type"),wMr=o(` property of the config object (either
passed as an argument or loaded from `),eTe=a("code"),AMr=o("pretrained_model_name_or_path"),LMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oTe=a("code"),yMr=o("pretrained_model_name_or_path"),xMr=o(":"),$Mr=l(),ln=a("ul"),C4=a("li"),rTe=a("strong"),kMr=o("convnext"),SMr=o(" \u2014 "),$U=a("a"),RMr=o("TFConvNextForImageClassification"),PMr=o(" (ConvNeXT model)"),BMr=l(),w4=a("li"),tTe=a("strong"),IMr=o("data2vec-vision"),NMr=o(" \u2014 "),kU=a("a"),qMr=o("TFData2VecVisionForImageClassification"),jMr=o(" (Data2VecVision model)"),DMr=l(),A4=a("li"),aTe=a("strong"),GMr=o("swin"),OMr=o(" \u2014 "),SU=a("a"),VMr=o("TFSwinForImageClassification"),XMr=o(" (Swin Transformer model)"),zMr=l(),L4=a("li"),nTe=a("strong"),WMr=o("vit"),QMr=o(" \u2014 "),RU=a("a"),HMr=o("TFViTForImageClassification"),UMr=o(" (ViT model)"),JMr=l(),F(y4.$$.fragment),xOe=l(),fc=a("h2"),x4=a("a"),sTe=a("span"),F(x9.$$.fragment),YMr=l(),lTe=a("span"),KMr=o("TFAutoModelForMaskedLM"),$Oe=l(),tr=a("div"),F($9.$$.fragment),ZMr=l(),mc=a("p"),eEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PU=a("a"),oEr=o("from_pretrained()"),rEr=o(" class method or the "),BU=a("a"),tEr=o("from_config()"),aEr=o(` class
method.`),nEr=l(),k9=a("p"),sEr=o("This class cannot be instantiated directly using "),iTe=a("code"),lEr=o("__init__()"),iEr=o(" (throws an error)."),dEr=l(),Pt=a("div"),F(S9.$$.fragment),cEr=l(),dTe=a("p"),fEr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),mEr=l(),gc=a("p"),gEr=o(`Note:
Loading a model from its configuration file does `),cTe=a("strong"),hEr=o("not"),pEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IU=a("a"),uEr=o("from_pretrained()"),_Er=o(" to load the model weights."),bEr=l(),F($4.$$.fragment),vEr=l(),kr=a("div"),F(R9.$$.fragment),FEr=l(),fTe=a("p"),TEr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),MEr=l(),dn=a("p"),EEr=o("The model class to instantiate is selected based on the "),mTe=a("code"),CEr=o("model_type"),wEr=o(` property of the config object (either
passed as an argument or loaded from `),gTe=a("code"),AEr=o("pretrained_model_name_or_path"),LEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hTe=a("code"),yEr=o("pretrained_model_name_or_path"),xEr=o(":"),$Er=l(),ie=a("ul"),k4=a("li"),pTe=a("strong"),kEr=o("albert"),SEr=o(" \u2014 "),NU=a("a"),REr=o("TFAlbertForMaskedLM"),PEr=o(" (ALBERT model)"),BEr=l(),S4=a("li"),uTe=a("strong"),IEr=o("bert"),NEr=o(" \u2014 "),qU=a("a"),qEr=o("TFBertForMaskedLM"),jEr=o(" (BERT model)"),DEr=l(),R4=a("li"),_Te=a("strong"),GEr=o("camembert"),OEr=o(" \u2014 "),jU=a("a"),VEr=o("TFCamembertForMaskedLM"),XEr=o(" (CamemBERT model)"),zEr=l(),P4=a("li"),bTe=a("strong"),WEr=o("convbert"),QEr=o(" \u2014 "),DU=a("a"),HEr=o("TFConvBertForMaskedLM"),UEr=o(" (ConvBERT model)"),JEr=l(),B4=a("li"),vTe=a("strong"),YEr=o("deberta"),KEr=o(" \u2014 "),GU=a("a"),ZEr=o("TFDebertaForMaskedLM"),e4r=o(" (DeBERTa model)"),o4r=l(),I4=a("li"),FTe=a("strong"),r4r=o("deberta-v2"),t4r=o(" \u2014 "),OU=a("a"),a4r=o("TFDebertaV2ForMaskedLM"),n4r=o(" (DeBERTa-v2 model)"),s4r=l(),N4=a("li"),TTe=a("strong"),l4r=o("distilbert"),i4r=o(" \u2014 "),VU=a("a"),d4r=o("TFDistilBertForMaskedLM"),c4r=o(" (DistilBERT model)"),f4r=l(),q4=a("li"),MTe=a("strong"),m4r=o("electra"),g4r=o(" \u2014 "),XU=a("a"),h4r=o("TFElectraForMaskedLM"),p4r=o(" (ELECTRA model)"),u4r=l(),j4=a("li"),ETe=a("strong"),_4r=o("flaubert"),b4r=o(" \u2014 "),zU=a("a"),v4r=o("TFFlaubertWithLMHeadModel"),F4r=o(" (FlauBERT model)"),T4r=l(),D4=a("li"),CTe=a("strong"),M4r=o("funnel"),E4r=o(" \u2014 "),WU=a("a"),C4r=o("TFFunnelForMaskedLM"),w4r=o(" (Funnel Transformer model)"),A4r=l(),G4=a("li"),wTe=a("strong"),L4r=o("layoutlm"),y4r=o(" \u2014 "),QU=a("a"),x4r=o("TFLayoutLMForMaskedLM"),$4r=o(" (LayoutLM model)"),k4r=l(),O4=a("li"),ATe=a("strong"),S4r=o("longformer"),R4r=o(" \u2014 "),HU=a("a"),P4r=o("TFLongformerForMaskedLM"),B4r=o(" (Longformer model)"),I4r=l(),V4=a("li"),LTe=a("strong"),N4r=o("mobilebert"),q4r=o(" \u2014 "),UU=a("a"),j4r=o("TFMobileBertForMaskedLM"),D4r=o(" (MobileBERT model)"),G4r=l(),X4=a("li"),yTe=a("strong"),O4r=o("mpnet"),V4r=o(" \u2014 "),JU=a("a"),X4r=o("TFMPNetForMaskedLM"),z4r=o(" (MPNet model)"),W4r=l(),z4=a("li"),xTe=a("strong"),Q4r=o("rembert"),H4r=o(" \u2014 "),YU=a("a"),U4r=o("TFRemBertForMaskedLM"),J4r=o(" (RemBERT model)"),Y4r=l(),W4=a("li"),$Te=a("strong"),K4r=o("roberta"),Z4r=o(" \u2014 "),KU=a("a"),eCr=o("TFRobertaForMaskedLM"),oCr=o(" (RoBERTa model)"),rCr=l(),Q4=a("li"),kTe=a("strong"),tCr=o("roformer"),aCr=o(" \u2014 "),ZU=a("a"),nCr=o("TFRoFormerForMaskedLM"),sCr=o(" (RoFormer model)"),lCr=l(),H4=a("li"),STe=a("strong"),iCr=o("tapas"),dCr=o(" \u2014 "),eJ=a("a"),cCr=o("TFTapasForMaskedLM"),fCr=o(" (TAPAS model)"),mCr=l(),U4=a("li"),RTe=a("strong"),gCr=o("xlm"),hCr=o(" \u2014 "),oJ=a("a"),pCr=o("TFXLMWithLMHeadModel"),uCr=o(" (XLM model)"),_Cr=l(),J4=a("li"),PTe=a("strong"),bCr=o("xlm-roberta"),vCr=o(" \u2014 "),rJ=a("a"),FCr=o("TFXLMRobertaForMaskedLM"),TCr=o(" (XLM-RoBERTa model)"),MCr=l(),F(Y4.$$.fragment),kOe=l(),hc=a("h2"),K4=a("a"),BTe=a("span"),F(P9.$$.fragment),ECr=l(),ITe=a("span"),CCr=o("TFAutoModelForSeq2SeqLM"),SOe=l(),ar=a("div"),F(B9.$$.fragment),wCr=l(),pc=a("p"),ACr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tJ=a("a"),LCr=o("from_pretrained()"),yCr=o(" class method or the "),aJ=a("a"),xCr=o("from_config()"),$Cr=o(` class
method.`),kCr=l(),I9=a("p"),SCr=o("This class cannot be instantiated directly using "),NTe=a("code"),RCr=o("__init__()"),PCr=o(" (throws an error)."),BCr=l(),Bt=a("div"),F(N9.$$.fragment),ICr=l(),qTe=a("p"),NCr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),qCr=l(),uc=a("p"),jCr=o(`Note:
Loading a model from its configuration file does `),jTe=a("strong"),DCr=o("not"),GCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nJ=a("a"),OCr=o("from_pretrained()"),VCr=o(" to load the model weights."),XCr=l(),F(Z4.$$.fragment),zCr=l(),Sr=a("div"),F(q9.$$.fragment),WCr=l(),DTe=a("p"),QCr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),HCr=l(),cn=a("p"),UCr=o("The model class to instantiate is selected based on the "),GTe=a("code"),JCr=o("model_type"),YCr=o(` property of the config object (either
passed as an argument or loaded from `),OTe=a("code"),KCr=o("pretrained_model_name_or_path"),ZCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VTe=a("code"),e5r=o("pretrained_model_name_or_path"),o5r=o(":"),r5r=l(),ye=a("ul"),eC=a("li"),XTe=a("strong"),t5r=o("bart"),a5r=o(" \u2014 "),sJ=a("a"),n5r=o("TFBartForConditionalGeneration"),s5r=o(" (BART model)"),l5r=l(),oC=a("li"),zTe=a("strong"),i5r=o("blenderbot"),d5r=o(" \u2014 "),lJ=a("a"),c5r=o("TFBlenderbotForConditionalGeneration"),f5r=o(" (Blenderbot model)"),m5r=l(),rC=a("li"),WTe=a("strong"),g5r=o("blenderbot-small"),h5r=o(" \u2014 "),iJ=a("a"),p5r=o("TFBlenderbotSmallForConditionalGeneration"),u5r=o(" (BlenderbotSmall model)"),_5r=l(),tC=a("li"),QTe=a("strong"),b5r=o("encoder-decoder"),v5r=o(" \u2014 "),dJ=a("a"),F5r=o("TFEncoderDecoderModel"),T5r=o(" (Encoder decoder model)"),M5r=l(),aC=a("li"),HTe=a("strong"),E5r=o("led"),C5r=o(" \u2014 "),cJ=a("a"),w5r=o("TFLEDForConditionalGeneration"),A5r=o(" (LED model)"),L5r=l(),nC=a("li"),UTe=a("strong"),y5r=o("marian"),x5r=o(" \u2014 "),fJ=a("a"),$5r=o("TFMarianMTModel"),k5r=o(" (Marian model)"),S5r=l(),sC=a("li"),JTe=a("strong"),R5r=o("mbart"),P5r=o(" \u2014 "),mJ=a("a"),B5r=o("TFMBartForConditionalGeneration"),I5r=o(" (mBART model)"),N5r=l(),lC=a("li"),YTe=a("strong"),q5r=o("mt5"),j5r=o(" \u2014 "),gJ=a("a"),D5r=o("TFMT5ForConditionalGeneration"),G5r=o(" (MT5 model)"),O5r=l(),iC=a("li"),KTe=a("strong"),V5r=o("pegasus"),X5r=o(" \u2014 "),hJ=a("a"),z5r=o("TFPegasusForConditionalGeneration"),W5r=o(" (Pegasus model)"),Q5r=l(),dC=a("li"),ZTe=a("strong"),H5r=o("t5"),U5r=o(" \u2014 "),pJ=a("a"),J5r=o("TFT5ForConditionalGeneration"),Y5r=o(" (T5 model)"),K5r=l(),F(cC.$$.fragment),ROe=l(),_c=a("h2"),fC=a("a"),eMe=a("span"),F(j9.$$.fragment),Z5r=l(),oMe=a("span"),e3r=o("TFAutoModelForSequenceClassification"),POe=l(),nr=a("div"),F(D9.$$.fragment),o3r=l(),bc=a("p"),r3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uJ=a("a"),t3r=o("from_pretrained()"),a3r=o(" class method or the "),_J=a("a"),n3r=o("from_config()"),s3r=o(` class
method.`),l3r=l(),G9=a("p"),i3r=o("This class cannot be instantiated directly using "),rMe=a("code"),d3r=o("__init__()"),c3r=o(" (throws an error)."),f3r=l(),It=a("div"),F(O9.$$.fragment),m3r=l(),tMe=a("p"),g3r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),h3r=l(),vc=a("p"),p3r=o(`Note:
Loading a model from its configuration file does `),aMe=a("strong"),u3r=o("not"),_3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bJ=a("a"),b3r=o("from_pretrained()"),v3r=o(" to load the model weights."),F3r=l(),F(mC.$$.fragment),T3r=l(),Rr=a("div"),F(V9.$$.fragment),M3r=l(),nMe=a("p"),E3r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),C3r=l(),fn=a("p"),w3r=o("The model class to instantiate is selected based on the "),sMe=a("code"),A3r=o("model_type"),L3r=o(` property of the config object (either
passed as an argument or loaded from `),lMe=a("code"),y3r=o("pretrained_model_name_or_path"),x3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iMe=a("code"),$3r=o("pretrained_model_name_or_path"),k3r=o(":"),S3r=l(),te=a("ul"),gC=a("li"),dMe=a("strong"),R3r=o("albert"),P3r=o(" \u2014 "),vJ=a("a"),B3r=o("TFAlbertForSequenceClassification"),I3r=o(" (ALBERT model)"),N3r=l(),hC=a("li"),cMe=a("strong"),q3r=o("bert"),j3r=o(" \u2014 "),FJ=a("a"),D3r=o("TFBertForSequenceClassification"),G3r=o(" (BERT model)"),O3r=l(),pC=a("li"),fMe=a("strong"),V3r=o("camembert"),X3r=o(" \u2014 "),TJ=a("a"),z3r=o("TFCamembertForSequenceClassification"),W3r=o(" (CamemBERT model)"),Q3r=l(),uC=a("li"),mMe=a("strong"),H3r=o("convbert"),U3r=o(" \u2014 "),MJ=a("a"),J3r=o("TFConvBertForSequenceClassification"),Y3r=o(" (ConvBERT model)"),K3r=l(),_C=a("li"),gMe=a("strong"),Z3r=o("ctrl"),e0r=o(" \u2014 "),EJ=a("a"),o0r=o("TFCTRLForSequenceClassification"),r0r=o(" (CTRL model)"),t0r=l(),bC=a("li"),hMe=a("strong"),a0r=o("deberta"),n0r=o(" \u2014 "),CJ=a("a"),s0r=o("TFDebertaForSequenceClassification"),l0r=o(" (DeBERTa model)"),i0r=l(),vC=a("li"),pMe=a("strong"),d0r=o("deberta-v2"),c0r=o(" \u2014 "),wJ=a("a"),f0r=o("TFDebertaV2ForSequenceClassification"),m0r=o(" (DeBERTa-v2 model)"),g0r=l(),FC=a("li"),uMe=a("strong"),h0r=o("distilbert"),p0r=o(" \u2014 "),AJ=a("a"),u0r=o("TFDistilBertForSequenceClassification"),_0r=o(" (DistilBERT model)"),b0r=l(),TC=a("li"),_Me=a("strong"),v0r=o("electra"),F0r=o(" \u2014 "),LJ=a("a"),T0r=o("TFElectraForSequenceClassification"),M0r=o(" (ELECTRA model)"),E0r=l(),MC=a("li"),bMe=a("strong"),C0r=o("flaubert"),w0r=o(" \u2014 "),yJ=a("a"),A0r=o("TFFlaubertForSequenceClassification"),L0r=o(" (FlauBERT model)"),y0r=l(),EC=a("li"),vMe=a("strong"),x0r=o("funnel"),$0r=o(" \u2014 "),xJ=a("a"),k0r=o("TFFunnelForSequenceClassification"),S0r=o(" (Funnel Transformer model)"),R0r=l(),CC=a("li"),FMe=a("strong"),P0r=o("gpt2"),B0r=o(" \u2014 "),$J=a("a"),I0r=o("TFGPT2ForSequenceClassification"),N0r=o(" (OpenAI GPT-2 model)"),q0r=l(),wC=a("li"),TMe=a("strong"),j0r=o("gptj"),D0r=o(" \u2014 "),kJ=a("a"),G0r=o("TFGPTJForSequenceClassification"),O0r=o(" (GPT-J model)"),V0r=l(),AC=a("li"),MMe=a("strong"),X0r=o("layoutlm"),z0r=o(" \u2014 "),SJ=a("a"),W0r=o("TFLayoutLMForSequenceClassification"),Q0r=o(" (LayoutLM model)"),H0r=l(),LC=a("li"),EMe=a("strong"),U0r=o("longformer"),J0r=o(" \u2014 "),RJ=a("a"),Y0r=o("TFLongformerForSequenceClassification"),K0r=o(" (Longformer model)"),Z0r=l(),yC=a("li"),CMe=a("strong"),ewr=o("mobilebert"),owr=o(" \u2014 "),PJ=a("a"),rwr=o("TFMobileBertForSequenceClassification"),twr=o(" (MobileBERT model)"),awr=l(),xC=a("li"),wMe=a("strong"),nwr=o("mpnet"),swr=o(" \u2014 "),BJ=a("a"),lwr=o("TFMPNetForSequenceClassification"),iwr=o(" (MPNet model)"),dwr=l(),$C=a("li"),AMe=a("strong"),cwr=o("openai-gpt"),fwr=o(" \u2014 "),IJ=a("a"),mwr=o("TFOpenAIGPTForSequenceClassification"),gwr=o(" (OpenAI GPT model)"),hwr=l(),kC=a("li"),LMe=a("strong"),pwr=o("rembert"),uwr=o(" \u2014 "),NJ=a("a"),_wr=o("TFRemBertForSequenceClassification"),bwr=o(" (RemBERT model)"),vwr=l(),SC=a("li"),yMe=a("strong"),Fwr=o("roberta"),Twr=o(" \u2014 "),qJ=a("a"),Mwr=o("TFRobertaForSequenceClassification"),Ewr=o(" (RoBERTa model)"),Cwr=l(),RC=a("li"),xMe=a("strong"),wwr=o("roformer"),Awr=o(" \u2014 "),jJ=a("a"),Lwr=o("TFRoFormerForSequenceClassification"),ywr=o(" (RoFormer model)"),xwr=l(),PC=a("li"),$Me=a("strong"),$wr=o("tapas"),kwr=o(" \u2014 "),DJ=a("a"),Swr=o("TFTapasForSequenceClassification"),Rwr=o(" (TAPAS model)"),Pwr=l(),BC=a("li"),kMe=a("strong"),Bwr=o("transfo-xl"),Iwr=o(" \u2014 "),GJ=a("a"),Nwr=o("TFTransfoXLForSequenceClassification"),qwr=o(" (Transformer-XL model)"),jwr=l(),IC=a("li"),SMe=a("strong"),Dwr=o("xlm"),Gwr=o(" \u2014 "),OJ=a("a"),Owr=o("TFXLMForSequenceClassification"),Vwr=o(" (XLM model)"),Xwr=l(),NC=a("li"),RMe=a("strong"),zwr=o("xlm-roberta"),Wwr=o(" \u2014 "),VJ=a("a"),Qwr=o("TFXLMRobertaForSequenceClassification"),Hwr=o(" (XLM-RoBERTa model)"),Uwr=l(),qC=a("li"),PMe=a("strong"),Jwr=o("xlnet"),Ywr=o(" \u2014 "),XJ=a("a"),Kwr=o("TFXLNetForSequenceClassification"),Zwr=o(" (XLNet model)"),eAr=l(),F(jC.$$.fragment),BOe=l(),Fc=a("h2"),DC=a("a"),BMe=a("span"),F(X9.$$.fragment),oAr=l(),IMe=a("span"),rAr=o("TFAutoModelForMultipleChoice"),IOe=l(),sr=a("div"),F(z9.$$.fragment),tAr=l(),Tc=a("p"),aAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zJ=a("a"),nAr=o("from_pretrained()"),sAr=o(" class method or the "),WJ=a("a"),lAr=o("from_config()"),iAr=o(` class
method.`),dAr=l(),W9=a("p"),cAr=o("This class cannot be instantiated directly using "),NMe=a("code"),fAr=o("__init__()"),mAr=o(" (throws an error)."),gAr=l(),Nt=a("div"),F(Q9.$$.fragment),hAr=l(),qMe=a("p"),pAr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),uAr=l(),Mc=a("p"),_Ar=o(`Note:
Loading a model from its configuration file does `),jMe=a("strong"),bAr=o("not"),vAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=a("a"),FAr=o("from_pretrained()"),TAr=o(" to load the model weights."),MAr=l(),F(GC.$$.fragment),EAr=l(),Pr=a("div"),F(H9.$$.fragment),CAr=l(),DMe=a("p"),wAr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),AAr=l(),mn=a("p"),LAr=o("The model class to instantiate is selected based on the "),GMe=a("code"),yAr=o("model_type"),xAr=o(` property of the config object (either
passed as an argument or loaded from `),OMe=a("code"),$Ar=o("pretrained_model_name_or_path"),kAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VMe=a("code"),SAr=o("pretrained_model_name_or_path"),RAr=o(":"),PAr=l(),ue=a("ul"),OC=a("li"),XMe=a("strong"),BAr=o("albert"),IAr=o(" \u2014 "),HJ=a("a"),NAr=o("TFAlbertForMultipleChoice"),qAr=o(" (ALBERT model)"),jAr=l(),VC=a("li"),zMe=a("strong"),DAr=o("bert"),GAr=o(" \u2014 "),UJ=a("a"),OAr=o("TFBertForMultipleChoice"),VAr=o(" (BERT model)"),XAr=l(),XC=a("li"),WMe=a("strong"),zAr=o("camembert"),WAr=o(" \u2014 "),JJ=a("a"),QAr=o("TFCamembertForMultipleChoice"),HAr=o(" (CamemBERT model)"),UAr=l(),zC=a("li"),QMe=a("strong"),JAr=o("convbert"),YAr=o(" \u2014 "),YJ=a("a"),KAr=o("TFConvBertForMultipleChoice"),ZAr=o(" (ConvBERT model)"),e6r=l(),WC=a("li"),HMe=a("strong"),o6r=o("distilbert"),r6r=o(" \u2014 "),KJ=a("a"),t6r=o("TFDistilBertForMultipleChoice"),a6r=o(" (DistilBERT model)"),n6r=l(),QC=a("li"),UMe=a("strong"),s6r=o("electra"),l6r=o(" \u2014 "),ZJ=a("a"),i6r=o("TFElectraForMultipleChoice"),d6r=o(" (ELECTRA model)"),c6r=l(),HC=a("li"),JMe=a("strong"),f6r=o("flaubert"),m6r=o(" \u2014 "),eY=a("a"),g6r=o("TFFlaubertForMultipleChoice"),h6r=o(" (FlauBERT model)"),p6r=l(),UC=a("li"),YMe=a("strong"),u6r=o("funnel"),_6r=o(" \u2014 "),oY=a("a"),b6r=o("TFFunnelForMultipleChoice"),v6r=o(" (Funnel Transformer model)"),F6r=l(),JC=a("li"),KMe=a("strong"),T6r=o("longformer"),M6r=o(" \u2014 "),rY=a("a"),E6r=o("TFLongformerForMultipleChoice"),C6r=o(" (Longformer model)"),w6r=l(),YC=a("li"),ZMe=a("strong"),A6r=o("mobilebert"),L6r=o(" \u2014 "),tY=a("a"),y6r=o("TFMobileBertForMultipleChoice"),x6r=o(" (MobileBERT model)"),$6r=l(),KC=a("li"),eEe=a("strong"),k6r=o("mpnet"),S6r=o(" \u2014 "),aY=a("a"),R6r=o("TFMPNetForMultipleChoice"),P6r=o(" (MPNet model)"),B6r=l(),ZC=a("li"),oEe=a("strong"),I6r=o("rembert"),N6r=o(" \u2014 "),nY=a("a"),q6r=o("TFRemBertForMultipleChoice"),j6r=o(" (RemBERT model)"),D6r=l(),e5=a("li"),rEe=a("strong"),G6r=o("roberta"),O6r=o(" \u2014 "),sY=a("a"),V6r=o("TFRobertaForMultipleChoice"),X6r=o(" (RoBERTa model)"),z6r=l(),o5=a("li"),tEe=a("strong"),W6r=o("roformer"),Q6r=o(" \u2014 "),lY=a("a"),H6r=o("TFRoFormerForMultipleChoice"),U6r=o(" (RoFormer model)"),J6r=l(),r5=a("li"),aEe=a("strong"),Y6r=o("xlm"),K6r=o(" \u2014 "),iY=a("a"),Z6r=o("TFXLMForMultipleChoice"),eLr=o(" (XLM model)"),oLr=l(),t5=a("li"),nEe=a("strong"),rLr=o("xlm-roberta"),tLr=o(" \u2014 "),dY=a("a"),aLr=o("TFXLMRobertaForMultipleChoice"),nLr=o(" (XLM-RoBERTa model)"),sLr=l(),a5=a("li"),sEe=a("strong"),lLr=o("xlnet"),iLr=o(" \u2014 "),cY=a("a"),dLr=o("TFXLNetForMultipleChoice"),cLr=o(" (XLNet model)"),fLr=l(),F(n5.$$.fragment),NOe=l(),Ec=a("h2"),s5=a("a"),lEe=a("span"),F(U9.$$.fragment),mLr=l(),iEe=a("span"),gLr=o("TFAutoModelForNextSentencePrediction"),qOe=l(),lr=a("div"),F(J9.$$.fragment),hLr=l(),Cc=a("p"),pLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fY=a("a"),uLr=o("from_pretrained()"),_Lr=o(" class method or the "),mY=a("a"),bLr=o("from_config()"),vLr=o(` class
method.`),FLr=l(),Y9=a("p"),TLr=o("This class cannot be instantiated directly using "),dEe=a("code"),MLr=o("__init__()"),ELr=o(" (throws an error)."),CLr=l(),qt=a("div"),F(K9.$$.fragment),wLr=l(),cEe=a("p"),ALr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),LLr=l(),wc=a("p"),yLr=o(`Note:
Loading a model from its configuration file does `),fEe=a("strong"),xLr=o("not"),$Lr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gY=a("a"),kLr=o("from_pretrained()"),SLr=o(" to load the model weights."),RLr=l(),F(l5.$$.fragment),PLr=l(),Br=a("div"),F(Z9.$$.fragment),BLr=l(),mEe=a("p"),ILr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),NLr=l(),gn=a("p"),qLr=o("The model class to instantiate is selected based on the "),gEe=a("code"),jLr=o("model_type"),DLr=o(` property of the config object (either
passed as an argument or loaded from `),hEe=a("code"),GLr=o("pretrained_model_name_or_path"),OLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pEe=a("code"),VLr=o("pretrained_model_name_or_path"),XLr=o(":"),zLr=l(),ex=a("ul"),i5=a("li"),uEe=a("strong"),WLr=o("bert"),QLr=o(" \u2014 "),hY=a("a"),HLr=o("TFBertForNextSentencePrediction"),ULr=o(" (BERT model)"),JLr=l(),d5=a("li"),_Ee=a("strong"),YLr=o("mobilebert"),KLr=o(" \u2014 "),pY=a("a"),ZLr=o("TFMobileBertForNextSentencePrediction"),eyr=o(" (MobileBERT model)"),oyr=l(),F(c5.$$.fragment),jOe=l(),Ac=a("h2"),f5=a("a"),bEe=a("span"),F(ox.$$.fragment),ryr=l(),vEe=a("span"),tyr=o("TFAutoModelForTableQuestionAnswering"),DOe=l(),ir=a("div"),F(rx.$$.fragment),ayr=l(),Lc=a("p"),nyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),uY=a("a"),syr=o("from_pretrained()"),lyr=o(" class method or the "),_Y=a("a"),iyr=o("from_config()"),dyr=o(` class
method.`),cyr=l(),tx=a("p"),fyr=o("This class cannot be instantiated directly using "),FEe=a("code"),myr=o("__init__()"),gyr=o(" (throws an error)."),hyr=l(),jt=a("div"),F(ax.$$.fragment),pyr=l(),TEe=a("p"),uyr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),_yr=l(),yc=a("p"),byr=o(`Note:
Loading a model from its configuration file does `),MEe=a("strong"),vyr=o("not"),Fyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bY=a("a"),Tyr=o("from_pretrained()"),Myr=o(" to load the model weights."),Eyr=l(),F(m5.$$.fragment),Cyr=l(),Ir=a("div"),F(nx.$$.fragment),wyr=l(),EEe=a("p"),Ayr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Lyr=l(),hn=a("p"),yyr=o("The model class to instantiate is selected based on the "),CEe=a("code"),xyr=o("model_type"),$yr=o(` property of the config object (either
passed as an argument or loaded from `),wEe=a("code"),kyr=o("pretrained_model_name_or_path"),Syr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AEe=a("code"),Ryr=o("pretrained_model_name_or_path"),Pyr=o(":"),Byr=l(),LEe=a("ul"),g5=a("li"),yEe=a("strong"),Iyr=o("tapas"),Nyr=o(" \u2014 "),vY=a("a"),qyr=o("TFTapasForQuestionAnswering"),jyr=o(" (TAPAS model)"),Dyr=l(),F(h5.$$.fragment),GOe=l(),xc=a("h2"),p5=a("a"),xEe=a("span"),F(sx.$$.fragment),Gyr=l(),$Ee=a("span"),Oyr=o("TFAutoModelForTokenClassification"),OOe=l(),dr=a("div"),F(lx.$$.fragment),Vyr=l(),$c=a("p"),Xyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),FY=a("a"),zyr=o("from_pretrained()"),Wyr=o(" class method or the "),TY=a("a"),Qyr=o("from_config()"),Hyr=o(` class
method.`),Uyr=l(),ix=a("p"),Jyr=o("This class cannot be instantiated directly using "),kEe=a("code"),Yyr=o("__init__()"),Kyr=o(" (throws an error)."),Zyr=l(),Dt=a("div"),F(dx.$$.fragment),e8r=l(),SEe=a("p"),o8r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),r8r=l(),kc=a("p"),t8r=o(`Note:
Loading a model from its configuration file does `),REe=a("strong"),a8r=o("not"),n8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MY=a("a"),s8r=o("from_pretrained()"),l8r=o(" to load the model weights."),i8r=l(),F(u5.$$.fragment),d8r=l(),Nr=a("div"),F(cx.$$.fragment),c8r=l(),PEe=a("p"),f8r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),m8r=l(),pn=a("p"),g8r=o("The model class to instantiate is selected based on the "),BEe=a("code"),h8r=o("model_type"),p8r=o(` property of the config object (either
passed as an argument or loaded from `),IEe=a("code"),u8r=o("pretrained_model_name_or_path"),_8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NEe=a("code"),b8r=o("pretrained_model_name_or_path"),v8r=o(":"),F8r=l(),de=a("ul"),_5=a("li"),qEe=a("strong"),T8r=o("albert"),M8r=o(" \u2014 "),EY=a("a"),E8r=o("TFAlbertForTokenClassification"),C8r=o(" (ALBERT model)"),w8r=l(),b5=a("li"),jEe=a("strong"),A8r=o("bert"),L8r=o(" \u2014 "),CY=a("a"),y8r=o("TFBertForTokenClassification"),x8r=o(" (BERT model)"),$8r=l(),v5=a("li"),DEe=a("strong"),k8r=o("camembert"),S8r=o(" \u2014 "),wY=a("a"),R8r=o("TFCamembertForTokenClassification"),P8r=o(" (CamemBERT model)"),B8r=l(),F5=a("li"),GEe=a("strong"),I8r=o("convbert"),N8r=o(" \u2014 "),AY=a("a"),q8r=o("TFConvBertForTokenClassification"),j8r=o(" (ConvBERT model)"),D8r=l(),T5=a("li"),OEe=a("strong"),G8r=o("deberta"),O8r=o(" \u2014 "),LY=a("a"),V8r=o("TFDebertaForTokenClassification"),X8r=o(" (DeBERTa model)"),z8r=l(),M5=a("li"),VEe=a("strong"),W8r=o("deberta-v2"),Q8r=o(" \u2014 "),yY=a("a"),H8r=o("TFDebertaV2ForTokenClassification"),U8r=o(" (DeBERTa-v2 model)"),J8r=l(),E5=a("li"),XEe=a("strong"),Y8r=o("distilbert"),K8r=o(" \u2014 "),xY=a("a"),Z8r=o("TFDistilBertForTokenClassification"),e9r=o(" (DistilBERT model)"),o9r=l(),C5=a("li"),zEe=a("strong"),r9r=o("electra"),t9r=o(" \u2014 "),$Y=a("a"),a9r=o("TFElectraForTokenClassification"),n9r=o(" (ELECTRA model)"),s9r=l(),w5=a("li"),WEe=a("strong"),l9r=o("flaubert"),i9r=o(" \u2014 "),kY=a("a"),d9r=o("TFFlaubertForTokenClassification"),c9r=o(" (FlauBERT model)"),f9r=l(),A5=a("li"),QEe=a("strong"),m9r=o("funnel"),g9r=o(" \u2014 "),SY=a("a"),h9r=o("TFFunnelForTokenClassification"),p9r=o(" (Funnel Transformer model)"),u9r=l(),L5=a("li"),HEe=a("strong"),_9r=o("layoutlm"),b9r=o(" \u2014 "),RY=a("a"),v9r=o("TFLayoutLMForTokenClassification"),F9r=o(" (LayoutLM model)"),T9r=l(),y5=a("li"),UEe=a("strong"),M9r=o("longformer"),E9r=o(" \u2014 "),PY=a("a"),C9r=o("TFLongformerForTokenClassification"),w9r=o(" (Longformer model)"),A9r=l(),x5=a("li"),JEe=a("strong"),L9r=o("mobilebert"),y9r=o(" \u2014 "),BY=a("a"),x9r=o("TFMobileBertForTokenClassification"),$9r=o(" (MobileBERT model)"),k9r=l(),$5=a("li"),YEe=a("strong"),S9r=o("mpnet"),R9r=o(" \u2014 "),IY=a("a"),P9r=o("TFMPNetForTokenClassification"),B9r=o(" (MPNet model)"),I9r=l(),k5=a("li"),KEe=a("strong"),N9r=o("rembert"),q9r=o(" \u2014 "),NY=a("a"),j9r=o("TFRemBertForTokenClassification"),D9r=o(" (RemBERT model)"),G9r=l(),S5=a("li"),ZEe=a("strong"),O9r=o("roberta"),V9r=o(" \u2014 "),qY=a("a"),X9r=o("TFRobertaForTokenClassification"),z9r=o(" (RoBERTa model)"),W9r=l(),R5=a("li"),e4e=a("strong"),Q9r=o("roformer"),H9r=o(" \u2014 "),jY=a("a"),U9r=o("TFRoFormerForTokenClassification"),J9r=o(" (RoFormer model)"),Y9r=l(),P5=a("li"),o4e=a("strong"),K9r=o("xlm"),Z9r=o(" \u2014 "),DY=a("a"),exr=o("TFXLMForTokenClassification"),oxr=o(" (XLM model)"),rxr=l(),B5=a("li"),r4e=a("strong"),txr=o("xlm-roberta"),axr=o(" \u2014 "),GY=a("a"),nxr=o("TFXLMRobertaForTokenClassification"),sxr=o(" (XLM-RoBERTa model)"),lxr=l(),I5=a("li"),t4e=a("strong"),ixr=o("xlnet"),dxr=o(" \u2014 "),OY=a("a"),cxr=o("TFXLNetForTokenClassification"),fxr=o(" (XLNet model)"),mxr=l(),F(N5.$$.fragment),VOe=l(),Sc=a("h2"),q5=a("a"),a4e=a("span"),F(fx.$$.fragment),gxr=l(),n4e=a("span"),hxr=o("TFAutoModelForQuestionAnswering"),XOe=l(),cr=a("div"),F(mx.$$.fragment),pxr=l(),Rc=a("p"),uxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),VY=a("a"),_xr=o("from_pretrained()"),bxr=o(" class method or the "),XY=a("a"),vxr=o("from_config()"),Fxr=o(` class
method.`),Txr=l(),gx=a("p"),Mxr=o("This class cannot be instantiated directly using "),s4e=a("code"),Exr=o("__init__()"),Cxr=o(" (throws an error)."),wxr=l(),Gt=a("div"),F(hx.$$.fragment),Axr=l(),l4e=a("p"),Lxr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),yxr=l(),Pc=a("p"),xxr=o(`Note:
Loading a model from its configuration file does `),i4e=a("strong"),$xr=o("not"),kxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zY=a("a"),Sxr=o("from_pretrained()"),Rxr=o(" to load the model weights."),Pxr=l(),F(j5.$$.fragment),Bxr=l(),qr=a("div"),F(px.$$.fragment),Ixr=l(),d4e=a("p"),Nxr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),qxr=l(),un=a("p"),jxr=o("The model class to instantiate is selected based on the "),c4e=a("code"),Dxr=o("model_type"),Gxr=o(` property of the config object (either
passed as an argument or loaded from `),f4e=a("code"),Oxr=o("pretrained_model_name_or_path"),Vxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m4e=a("code"),Xxr=o("pretrained_model_name_or_path"),zxr=o(":"),Wxr=l(),ce=a("ul"),D5=a("li"),g4e=a("strong"),Qxr=o("albert"),Hxr=o(" \u2014 "),WY=a("a"),Uxr=o("TFAlbertForQuestionAnswering"),Jxr=o(" (ALBERT model)"),Yxr=l(),G5=a("li"),h4e=a("strong"),Kxr=o("bert"),Zxr=o(" \u2014 "),QY=a("a"),e$r=o("TFBertForQuestionAnswering"),o$r=o(" (BERT model)"),r$r=l(),O5=a("li"),p4e=a("strong"),t$r=o("camembert"),a$r=o(" \u2014 "),HY=a("a"),n$r=o("TFCamembertForQuestionAnswering"),s$r=o(" (CamemBERT model)"),l$r=l(),V5=a("li"),u4e=a("strong"),i$r=o("convbert"),d$r=o(" \u2014 "),UY=a("a"),c$r=o("TFConvBertForQuestionAnswering"),f$r=o(" (ConvBERT model)"),m$r=l(),X5=a("li"),_4e=a("strong"),g$r=o("deberta"),h$r=o(" \u2014 "),JY=a("a"),p$r=o("TFDebertaForQuestionAnswering"),u$r=o(" (DeBERTa model)"),_$r=l(),z5=a("li"),b4e=a("strong"),b$r=o("deberta-v2"),v$r=o(" \u2014 "),YY=a("a"),F$r=o("TFDebertaV2ForQuestionAnswering"),T$r=o(" (DeBERTa-v2 model)"),M$r=l(),W5=a("li"),v4e=a("strong"),E$r=o("distilbert"),C$r=o(" \u2014 "),KY=a("a"),w$r=o("TFDistilBertForQuestionAnswering"),A$r=o(" (DistilBERT model)"),L$r=l(),Q5=a("li"),F4e=a("strong"),y$r=o("electra"),x$r=o(" \u2014 "),ZY=a("a"),$$r=o("TFElectraForQuestionAnswering"),k$r=o(" (ELECTRA model)"),S$r=l(),H5=a("li"),T4e=a("strong"),R$r=o("flaubert"),P$r=o(" \u2014 "),eK=a("a"),B$r=o("TFFlaubertForQuestionAnsweringSimple"),I$r=o(" (FlauBERT model)"),N$r=l(),U5=a("li"),M4e=a("strong"),q$r=o("funnel"),j$r=o(" \u2014 "),oK=a("a"),D$r=o("TFFunnelForQuestionAnswering"),G$r=o(" (Funnel Transformer model)"),O$r=l(),J5=a("li"),E4e=a("strong"),V$r=o("gptj"),X$r=o(" \u2014 "),rK=a("a"),z$r=o("TFGPTJForQuestionAnswering"),W$r=o(" (GPT-J model)"),Q$r=l(),Y5=a("li"),C4e=a("strong"),H$r=o("longformer"),U$r=o(" \u2014 "),tK=a("a"),J$r=o("TFLongformerForQuestionAnswering"),Y$r=o(" (Longformer model)"),K$r=l(),K5=a("li"),w4e=a("strong"),Z$r=o("mobilebert"),ekr=o(" \u2014 "),aK=a("a"),okr=o("TFMobileBertForQuestionAnswering"),rkr=o(" (MobileBERT model)"),tkr=l(),Z5=a("li"),A4e=a("strong"),akr=o("mpnet"),nkr=o(" \u2014 "),nK=a("a"),skr=o("TFMPNetForQuestionAnswering"),lkr=o(" (MPNet model)"),ikr=l(),e3=a("li"),L4e=a("strong"),dkr=o("rembert"),ckr=o(" \u2014 "),sK=a("a"),fkr=o("TFRemBertForQuestionAnswering"),mkr=o(" (RemBERT model)"),gkr=l(),o3=a("li"),y4e=a("strong"),hkr=o("roberta"),pkr=o(" \u2014 "),lK=a("a"),ukr=o("TFRobertaForQuestionAnswering"),_kr=o(" (RoBERTa model)"),bkr=l(),r3=a("li"),x4e=a("strong"),vkr=o("roformer"),Fkr=o(" \u2014 "),iK=a("a"),Tkr=o("TFRoFormerForQuestionAnswering"),Mkr=o(" (RoFormer model)"),Ekr=l(),t3=a("li"),$4e=a("strong"),Ckr=o("xlm"),wkr=o(" \u2014 "),dK=a("a"),Akr=o("TFXLMForQuestionAnsweringSimple"),Lkr=o(" (XLM model)"),ykr=l(),a3=a("li"),k4e=a("strong"),xkr=o("xlm-roberta"),$kr=o(" \u2014 "),cK=a("a"),kkr=o("TFXLMRobertaForQuestionAnswering"),Skr=o(" (XLM-RoBERTa model)"),Rkr=l(),n3=a("li"),S4e=a("strong"),Pkr=o("xlnet"),Bkr=o(" \u2014 "),fK=a("a"),Ikr=o("TFXLNetForQuestionAnsweringSimple"),Nkr=o(" (XLNet model)"),qkr=l(),F(s3.$$.fragment),zOe=l(),Bc=a("h2"),l3=a("a"),R4e=a("span"),F(ux.$$.fragment),jkr=l(),P4e=a("span"),Dkr=o("TFAutoModelForVision2Seq"),WOe=l(),fr=a("div"),F(_x.$$.fragment),Gkr=l(),Ic=a("p"),Okr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),mK=a("a"),Vkr=o("from_pretrained()"),Xkr=o(" class method or the "),gK=a("a"),zkr=o("from_config()"),Wkr=o(` class
method.`),Qkr=l(),bx=a("p"),Hkr=o("This class cannot be instantiated directly using "),B4e=a("code"),Ukr=o("__init__()"),Jkr=o(" (throws an error)."),Ykr=l(),Ot=a("div"),F(vx.$$.fragment),Kkr=l(),I4e=a("p"),Zkr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),eSr=l(),Nc=a("p"),oSr=o(`Note:
Loading a model from its configuration file does `),N4e=a("strong"),rSr=o("not"),tSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hK=a("a"),aSr=o("from_pretrained()"),nSr=o(" to load the model weights."),sSr=l(),F(i3.$$.fragment),lSr=l(),jr=a("div"),F(Fx.$$.fragment),iSr=l(),q4e=a("p"),dSr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),cSr=l(),_n=a("p"),fSr=o("The model class to instantiate is selected based on the "),j4e=a("code"),mSr=o("model_type"),gSr=o(` property of the config object (either
passed as an argument or loaded from `),D4e=a("code"),hSr=o("pretrained_model_name_or_path"),pSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G4e=a("code"),uSr=o("pretrained_model_name_or_path"),_Sr=o(":"),bSr=l(),O4e=a("ul"),d3=a("li"),V4e=a("strong"),vSr=o("vision-encoder-decoder"),FSr=o(" \u2014 "),pK=a("a"),TSr=o("TFVisionEncoderDecoderModel"),MSr=o(" (Vision Encoder decoder model)"),ESr=l(),F(c3.$$.fragment),QOe=l(),qc=a("h2"),f3=a("a"),X4e=a("span"),F(Tx.$$.fragment),CSr=l(),z4e=a("span"),wSr=o("TFAutoModelForSpeechSeq2Seq"),HOe=l(),mr=a("div"),F(Mx.$$.fragment),ASr=l(),jc=a("p"),LSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uK=a("a"),ySr=o("from_pretrained()"),xSr=o(" class method or the "),_K=a("a"),$Sr=o("from_config()"),kSr=o(` class
method.`),SSr=l(),Ex=a("p"),RSr=o("This class cannot be instantiated directly using "),W4e=a("code"),PSr=o("__init__()"),BSr=o(" (throws an error)."),ISr=l(),Vt=a("div"),F(Cx.$$.fragment),NSr=l(),Q4e=a("p"),qSr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),jSr=l(),Dc=a("p"),DSr=o(`Note:
Loading a model from its configuration file does `),H4e=a("strong"),GSr=o("not"),OSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=a("a"),VSr=o("from_pretrained()"),XSr=o(" to load the model weights."),zSr=l(),F(m3.$$.fragment),WSr=l(),Dr=a("div"),F(wx.$$.fragment),QSr=l(),U4e=a("p"),HSr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),USr=l(),bn=a("p"),JSr=o("The model class to instantiate is selected based on the "),J4e=a("code"),YSr=o("model_type"),KSr=o(` property of the config object (either
passed as an argument or loaded from `),Y4e=a("code"),ZSr=o("pretrained_model_name_or_path"),eRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=a("code"),oRr=o("pretrained_model_name_or_path"),rRr=o(":"),tRr=l(),Z4e=a("ul"),g3=a("li"),eCe=a("strong"),aRr=o("speech_to_text"),nRr=o(" \u2014 "),vK=a("a"),sRr=o("TFSpeech2TextForConditionalGeneration"),lRr=o(" (Speech2Text model)"),iRr=l(),F(h3.$$.fragment),UOe=l(),Gc=a("h2"),p3=a("a"),oCe=a("span"),F(Ax.$$.fragment),dRr=l(),rCe=a("span"),cRr=o("FlaxAutoModel"),JOe=l(),gr=a("div"),F(Lx.$$.fragment),fRr=l(),Oc=a("p"),mRr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),FK=a("a"),gRr=o("from_pretrained()"),hRr=o(" class method or the "),TK=a("a"),pRr=o("from_config()"),uRr=o(` class
method.`),_Rr=l(),yx=a("p"),bRr=o("This class cannot be instantiated directly using "),tCe=a("code"),vRr=o("__init__()"),FRr=o(" (throws an error)."),TRr=l(),Xt=a("div"),F(xx.$$.fragment),MRr=l(),aCe=a("p"),ERr=o("Instantiates one of the base model classes of the library from a configuration."),CRr=l(),Vc=a("p"),wRr=o(`Note:
Loading a model from its configuration file does `),nCe=a("strong"),ARr=o("not"),LRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MK=a("a"),yRr=o("from_pretrained()"),xRr=o(" to load the model weights."),$Rr=l(),F(u3.$$.fragment),kRr=l(),Gr=a("div"),F($x.$$.fragment),SRr=l(),sCe=a("p"),RRr=o("Instantiate one of the base model classes of the library from a pretrained model."),PRr=l(),vn=a("p"),BRr=o("The model class to instantiate is selected based on the "),lCe=a("code"),IRr=o("model_type"),NRr=o(` property of the config object (either
passed as an argument or loaded from `),iCe=a("code"),qRr=o("pretrained_model_name_or_path"),jRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dCe=a("code"),DRr=o("pretrained_model_name_or_path"),GRr=o(":"),ORr=l(),oe=a("ul"),_3=a("li"),cCe=a("strong"),VRr=o("albert"),XRr=o(" \u2014 "),EK=a("a"),zRr=o("FlaxAlbertModel"),WRr=o(" (ALBERT model)"),QRr=l(),b3=a("li"),fCe=a("strong"),HRr=o("bart"),URr=o(" \u2014 "),CK=a("a"),JRr=o("FlaxBartModel"),YRr=o(" (BART model)"),KRr=l(),v3=a("li"),mCe=a("strong"),ZRr=o("beit"),ePr=o(" \u2014 "),wK=a("a"),oPr=o("FlaxBeitModel"),rPr=o(" (BEiT model)"),tPr=l(),F3=a("li"),gCe=a("strong"),aPr=o("bert"),nPr=o(" \u2014 "),AK=a("a"),sPr=o("FlaxBertModel"),lPr=o(" (BERT model)"),iPr=l(),T3=a("li"),hCe=a("strong"),dPr=o("big_bird"),cPr=o(" \u2014 "),LK=a("a"),fPr=o("FlaxBigBirdModel"),mPr=o(" (BigBird model)"),gPr=l(),M3=a("li"),pCe=a("strong"),hPr=o("blenderbot"),pPr=o(" \u2014 "),yK=a("a"),uPr=o("FlaxBlenderbotModel"),_Pr=o(" (Blenderbot model)"),bPr=l(),E3=a("li"),uCe=a("strong"),vPr=o("blenderbot-small"),FPr=o(" \u2014 "),xK=a("a"),TPr=o("FlaxBlenderbotSmallModel"),MPr=o(" (BlenderbotSmall model)"),EPr=l(),C3=a("li"),_Ce=a("strong"),CPr=o("clip"),wPr=o(" \u2014 "),$K=a("a"),APr=o("FlaxCLIPModel"),LPr=o(" (CLIP model)"),yPr=l(),w3=a("li"),bCe=a("strong"),xPr=o("distilbert"),$Pr=o(" \u2014 "),kK=a("a"),kPr=o("FlaxDistilBertModel"),SPr=o(" (DistilBERT model)"),RPr=l(),A3=a("li"),vCe=a("strong"),PPr=o("electra"),BPr=o(" \u2014 "),SK=a("a"),IPr=o("FlaxElectraModel"),NPr=o(" (ELECTRA model)"),qPr=l(),L3=a("li"),FCe=a("strong"),jPr=o("gpt2"),DPr=o(" \u2014 "),RK=a("a"),GPr=o("FlaxGPT2Model"),OPr=o(" (OpenAI GPT-2 model)"),VPr=l(),y3=a("li"),TCe=a("strong"),XPr=o("gpt_neo"),zPr=o(" \u2014 "),PK=a("a"),WPr=o("FlaxGPTNeoModel"),QPr=o(" (GPT Neo model)"),HPr=l(),x3=a("li"),MCe=a("strong"),UPr=o("gptj"),JPr=o(" \u2014 "),BK=a("a"),YPr=o("FlaxGPTJModel"),KPr=o(" (GPT-J model)"),ZPr=l(),$3=a("li"),ECe=a("strong"),eBr=o("longt5"),oBr=o(" \u2014 "),IK=a("a"),rBr=o("FlaxLongT5Model"),tBr=o(" (LongT5 model)"),aBr=l(),k3=a("li"),CCe=a("strong"),nBr=o("marian"),sBr=o(" \u2014 "),NK=a("a"),lBr=o("FlaxMarianModel"),iBr=o(" (Marian model)"),dBr=l(),S3=a("li"),wCe=a("strong"),cBr=o("mbart"),fBr=o(" \u2014 "),qK=a("a"),mBr=o("FlaxMBartModel"),gBr=o(" (mBART model)"),hBr=l(),R3=a("li"),ACe=a("strong"),pBr=o("mt5"),uBr=o(" \u2014 "),jK=a("a"),_Br=o("FlaxMT5Model"),bBr=o(" (MT5 model)"),vBr=l(),P3=a("li"),LCe=a("strong"),FBr=o("opt"),TBr=o(" \u2014 "),DK=a("a"),MBr=o("FlaxOPTModel"),EBr=o(" (OPT model)"),CBr=l(),B3=a("li"),yCe=a("strong"),wBr=o("pegasus"),ABr=o(" \u2014 "),GK=a("a"),LBr=o("FlaxPegasusModel"),yBr=o(" (Pegasus model)"),xBr=l(),I3=a("li"),xCe=a("strong"),$Br=o("roberta"),kBr=o(" \u2014 "),OK=a("a"),SBr=o("FlaxRobertaModel"),RBr=o(" (RoBERTa model)"),PBr=l(),N3=a("li"),$Ce=a("strong"),BBr=o("roformer"),IBr=o(" \u2014 "),VK=a("a"),NBr=o("FlaxRoFormerModel"),qBr=o(" (RoFormer model)"),jBr=l(),q3=a("li"),kCe=a("strong"),DBr=o("t5"),GBr=o(" \u2014 "),XK=a("a"),OBr=o("FlaxT5Model"),VBr=o(" (T5 model)"),XBr=l(),j3=a("li"),SCe=a("strong"),zBr=o("vision-text-dual-encoder"),WBr=o(" \u2014 "),zK=a("a"),QBr=o("FlaxVisionTextDualEncoderModel"),HBr=o(" (VisionTextDualEncoder model)"),UBr=l(),D3=a("li"),RCe=a("strong"),JBr=o("vit"),YBr=o(" \u2014 "),WK=a("a"),KBr=o("FlaxViTModel"),ZBr=o(" (ViT model)"),eIr=l(),G3=a("li"),PCe=a("strong"),oIr=o("wav2vec2"),rIr=o(" \u2014 "),QK=a("a"),tIr=o("FlaxWav2Vec2Model"),aIr=o(" (Wav2Vec2 model)"),nIr=l(),O3=a("li"),BCe=a("strong"),sIr=o("xglm"),lIr=o(" \u2014 "),HK=a("a"),iIr=o("FlaxXGLMModel"),dIr=o(" (XGLM model)"),cIr=l(),V3=a("li"),ICe=a("strong"),fIr=o("xlm-roberta"),mIr=o(" \u2014 "),UK=a("a"),gIr=o("FlaxXLMRobertaModel"),hIr=o(" (XLM-RoBERTa model)"),pIr=l(),F(X3.$$.fragment),YOe=l(),Xc=a("h2"),z3=a("a"),NCe=a("span"),F(kx.$$.fragment),uIr=l(),qCe=a("span"),_Ir=o("FlaxAutoModelForCausalLM"),KOe=l(),hr=a("div"),F(Sx.$$.fragment),bIr=l(),zc=a("p"),vIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),JK=a("a"),FIr=o("from_pretrained()"),TIr=o(" class method or the "),YK=a("a"),MIr=o("from_config()"),EIr=o(` class
method.`),CIr=l(),Rx=a("p"),wIr=o("This class cannot be instantiated directly using "),jCe=a("code"),AIr=o("__init__()"),LIr=o(" (throws an error)."),yIr=l(),zt=a("div"),F(Px.$$.fragment),xIr=l(),DCe=a("p"),$Ir=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),kIr=l(),Wc=a("p"),SIr=o(`Note:
Loading a model from its configuration file does `),GCe=a("strong"),RIr=o("not"),PIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KK=a("a"),BIr=o("from_pretrained()"),IIr=o(" to load the model weights."),NIr=l(),F(W3.$$.fragment),qIr=l(),Or=a("div"),F(Bx.$$.fragment),jIr=l(),OCe=a("p"),DIr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GIr=l(),Fn=a("p"),OIr=o("The model class to instantiate is selected based on the "),VCe=a("code"),VIr=o("model_type"),XIr=o(` property of the config object (either
passed as an argument or loaded from `),XCe=a("code"),zIr=o("pretrained_model_name_or_path"),WIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zCe=a("code"),QIr=o("pretrained_model_name_or_path"),HIr=o(":"),UIr=l(),xe=a("ul"),Q3=a("li"),WCe=a("strong"),JIr=o("bart"),YIr=o(" \u2014 "),ZK=a("a"),KIr=o("FlaxBartForCausalLM"),ZIr=o(" (BART model)"),eNr=l(),H3=a("li"),QCe=a("strong"),oNr=o("bert"),rNr=o(" \u2014 "),eZ=a("a"),tNr=o("FlaxBertForCausalLM"),aNr=o(" (BERT model)"),nNr=l(),U3=a("li"),HCe=a("strong"),sNr=o("big_bird"),lNr=o(" \u2014 "),oZ=a("a"),iNr=o("FlaxBigBirdForCausalLM"),dNr=o(" (BigBird model)"),cNr=l(),J3=a("li"),UCe=a("strong"),fNr=o("electra"),mNr=o(" \u2014 "),rZ=a("a"),gNr=o("FlaxElectraForCausalLM"),hNr=o(" (ELECTRA model)"),pNr=l(),Y3=a("li"),JCe=a("strong"),uNr=o("gpt2"),_Nr=o(" \u2014 "),tZ=a("a"),bNr=o("FlaxGPT2LMHeadModel"),vNr=o(" (OpenAI GPT-2 model)"),FNr=l(),K3=a("li"),YCe=a("strong"),TNr=o("gpt_neo"),MNr=o(" \u2014 "),aZ=a("a"),ENr=o("FlaxGPTNeoForCausalLM"),CNr=o(" (GPT Neo model)"),wNr=l(),Z3=a("li"),KCe=a("strong"),ANr=o("gptj"),LNr=o(" \u2014 "),nZ=a("a"),yNr=o("FlaxGPTJForCausalLM"),xNr=o(" (GPT-J model)"),$Nr=l(),e0=a("li"),ZCe=a("strong"),kNr=o("opt"),SNr=o(" \u2014 "),sZ=a("a"),RNr=o("FlaxOPTForCausalLM"),PNr=o(" (OPT model)"),BNr=l(),o0=a("li"),e5e=a("strong"),INr=o("roberta"),NNr=o(" \u2014 "),lZ=a("a"),qNr=o("FlaxRobertaForCausalLM"),jNr=o(" (RoBERTa model)"),DNr=l(),r0=a("li"),o5e=a("strong"),GNr=o("xglm"),ONr=o(" \u2014 "),iZ=a("a"),VNr=o("FlaxXGLMForCausalLM"),XNr=o(" (XGLM model)"),zNr=l(),F(t0.$$.fragment),ZOe=l(),Qc=a("h2"),a0=a("a"),r5e=a("span"),F(Ix.$$.fragment),WNr=l(),t5e=a("span"),QNr=o("FlaxAutoModelForPreTraining"),eVe=l(),pr=a("div"),F(Nx.$$.fragment),HNr=l(),Hc=a("p"),UNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),dZ=a("a"),JNr=o("from_pretrained()"),YNr=o(" class method or the "),cZ=a("a"),KNr=o("from_config()"),ZNr=o(` class
method.`),eqr=l(),qx=a("p"),oqr=o("This class cannot be instantiated directly using "),a5e=a("code"),rqr=o("__init__()"),tqr=o(" (throws an error)."),aqr=l(),Wt=a("div"),F(jx.$$.fragment),nqr=l(),n5e=a("p"),sqr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),lqr=l(),Uc=a("p"),iqr=o(`Note:
Loading a model from its configuration file does `),s5e=a("strong"),dqr=o("not"),cqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fZ=a("a"),fqr=o("from_pretrained()"),mqr=o(" to load the model weights."),gqr=l(),F(n0.$$.fragment),hqr=l(),Vr=a("div"),F(Dx.$$.fragment),pqr=l(),l5e=a("p"),uqr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),_qr=l(),Tn=a("p"),bqr=o("The model class to instantiate is selected based on the "),i5e=a("code"),vqr=o("model_type"),Fqr=o(` property of the config object (either
passed as an argument or loaded from `),d5e=a("code"),Tqr=o("pretrained_model_name_or_path"),Mqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c5e=a("code"),Eqr=o("pretrained_model_name_or_path"),Cqr=o(":"),wqr=l(),Ee=a("ul"),s0=a("li"),f5e=a("strong"),Aqr=o("albert"),Lqr=o(" \u2014 "),mZ=a("a"),yqr=o("FlaxAlbertForPreTraining"),xqr=o(" (ALBERT model)"),$qr=l(),l0=a("li"),m5e=a("strong"),kqr=o("bart"),Sqr=o(" \u2014 "),gZ=a("a"),Rqr=o("FlaxBartForConditionalGeneration"),Pqr=o(" (BART model)"),Bqr=l(),i0=a("li"),g5e=a("strong"),Iqr=o("bert"),Nqr=o(" \u2014 "),hZ=a("a"),qqr=o("FlaxBertForPreTraining"),jqr=o(" (BERT model)"),Dqr=l(),d0=a("li"),h5e=a("strong"),Gqr=o("big_bird"),Oqr=o(" \u2014 "),pZ=a("a"),Vqr=o("FlaxBigBirdForPreTraining"),Xqr=o(" (BigBird model)"),zqr=l(),c0=a("li"),p5e=a("strong"),Wqr=o("electra"),Qqr=o(" \u2014 "),uZ=a("a"),Hqr=o("FlaxElectraForPreTraining"),Uqr=o(" (ELECTRA model)"),Jqr=l(),f0=a("li"),u5e=a("strong"),Yqr=o("longt5"),Kqr=o(" \u2014 "),_Z=a("a"),Zqr=o("FlaxLongT5ForConditionalGeneration"),ejr=o(" (LongT5 model)"),ojr=l(),m0=a("li"),_5e=a("strong"),rjr=o("mbart"),tjr=o(" \u2014 "),bZ=a("a"),ajr=o("FlaxMBartForConditionalGeneration"),njr=o(" (mBART model)"),sjr=l(),g0=a("li"),b5e=a("strong"),ljr=o("mt5"),ijr=o(" \u2014 "),vZ=a("a"),djr=o("FlaxMT5ForConditionalGeneration"),cjr=o(" (MT5 model)"),fjr=l(),h0=a("li"),v5e=a("strong"),mjr=o("roberta"),gjr=o(" \u2014 "),FZ=a("a"),hjr=o("FlaxRobertaForMaskedLM"),pjr=o(" (RoBERTa model)"),ujr=l(),p0=a("li"),F5e=a("strong"),_jr=o("roformer"),bjr=o(" \u2014 "),TZ=a("a"),vjr=o("FlaxRoFormerForMaskedLM"),Fjr=o(" (RoFormer model)"),Tjr=l(),u0=a("li"),T5e=a("strong"),Mjr=o("t5"),Ejr=o(" \u2014 "),MZ=a("a"),Cjr=o("FlaxT5ForConditionalGeneration"),wjr=o(" (T5 model)"),Ajr=l(),_0=a("li"),M5e=a("strong"),Ljr=o("wav2vec2"),yjr=o(" \u2014 "),EZ=a("a"),xjr=o("FlaxWav2Vec2ForPreTraining"),$jr=o(" (Wav2Vec2 model)"),kjr=l(),b0=a("li"),E5e=a("strong"),Sjr=o("xlm-roberta"),Rjr=o(" \u2014 "),CZ=a("a"),Pjr=o("FlaxXLMRobertaForMaskedLM"),Bjr=o(" (XLM-RoBERTa model)"),Ijr=l(),F(v0.$$.fragment),oVe=l(),Jc=a("h2"),F0=a("a"),C5e=a("span"),F(Gx.$$.fragment),Njr=l(),w5e=a("span"),qjr=o("FlaxAutoModelForMaskedLM"),rVe=l(),ur=a("div"),F(Ox.$$.fragment),jjr=l(),Yc=a("p"),Djr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),wZ=a("a"),Gjr=o("from_pretrained()"),Ojr=o(" class method or the "),AZ=a("a"),Vjr=o("from_config()"),Xjr=o(` class
method.`),zjr=l(),Vx=a("p"),Wjr=o("This class cannot be instantiated directly using "),A5e=a("code"),Qjr=o("__init__()"),Hjr=o(" (throws an error)."),Ujr=l(),Qt=a("div"),F(Xx.$$.fragment),Jjr=l(),L5e=a("p"),Yjr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Kjr=l(),Kc=a("p"),Zjr=o(`Note:
Loading a model from its configuration file does `),y5e=a("strong"),eDr=o("not"),oDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LZ=a("a"),rDr=o("from_pretrained()"),tDr=o(" to load the model weights."),aDr=l(),F(T0.$$.fragment),nDr=l(),Xr=a("div"),F(zx.$$.fragment),sDr=l(),x5e=a("p"),lDr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),iDr=l(),Mn=a("p"),dDr=o("The model class to instantiate is selected based on the "),$5e=a("code"),cDr=o("model_type"),fDr=o(` property of the config object (either
passed as an argument or loaded from `),k5e=a("code"),mDr=o("pretrained_model_name_or_path"),gDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S5e=a("code"),hDr=o("pretrained_model_name_or_path"),pDr=o(":"),uDr=l(),$e=a("ul"),M0=a("li"),R5e=a("strong"),_Dr=o("albert"),bDr=o(" \u2014 "),yZ=a("a"),vDr=o("FlaxAlbertForMaskedLM"),FDr=o(" (ALBERT model)"),TDr=l(),E0=a("li"),P5e=a("strong"),MDr=o("bart"),EDr=o(" \u2014 "),xZ=a("a"),CDr=o("FlaxBartForConditionalGeneration"),wDr=o(" (BART model)"),ADr=l(),C0=a("li"),B5e=a("strong"),LDr=o("bert"),yDr=o(" \u2014 "),$Z=a("a"),xDr=o("FlaxBertForMaskedLM"),$Dr=o(" (BERT model)"),kDr=l(),w0=a("li"),I5e=a("strong"),SDr=o("big_bird"),RDr=o(" \u2014 "),kZ=a("a"),PDr=o("FlaxBigBirdForMaskedLM"),BDr=o(" (BigBird model)"),IDr=l(),A0=a("li"),N5e=a("strong"),NDr=o("distilbert"),qDr=o(" \u2014 "),SZ=a("a"),jDr=o("FlaxDistilBertForMaskedLM"),DDr=o(" (DistilBERT model)"),GDr=l(),L0=a("li"),q5e=a("strong"),ODr=o("electra"),VDr=o(" \u2014 "),RZ=a("a"),XDr=o("FlaxElectraForMaskedLM"),zDr=o(" (ELECTRA model)"),WDr=l(),y0=a("li"),j5e=a("strong"),QDr=o("mbart"),HDr=o(" \u2014 "),PZ=a("a"),UDr=o("FlaxMBartForConditionalGeneration"),JDr=o(" (mBART model)"),YDr=l(),x0=a("li"),D5e=a("strong"),KDr=o("roberta"),ZDr=o(" \u2014 "),BZ=a("a"),eGr=o("FlaxRobertaForMaskedLM"),oGr=o(" (RoBERTa model)"),rGr=l(),$0=a("li"),G5e=a("strong"),tGr=o("roformer"),aGr=o(" \u2014 "),IZ=a("a"),nGr=o("FlaxRoFormerForMaskedLM"),sGr=o(" (RoFormer model)"),lGr=l(),k0=a("li"),O5e=a("strong"),iGr=o("xlm-roberta"),dGr=o(" \u2014 "),NZ=a("a"),cGr=o("FlaxXLMRobertaForMaskedLM"),fGr=o(" (XLM-RoBERTa model)"),mGr=l(),F(S0.$$.fragment),tVe=l(),Zc=a("h2"),R0=a("a"),V5e=a("span"),F(Wx.$$.fragment),gGr=l(),X5e=a("span"),hGr=o("FlaxAutoModelForSeq2SeqLM"),aVe=l(),_r=a("div"),F(Qx.$$.fragment),pGr=l(),ef=a("p"),uGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qZ=a("a"),_Gr=o("from_pretrained()"),bGr=o(" class method or the "),jZ=a("a"),vGr=o("from_config()"),FGr=o(` class
method.`),TGr=l(),Hx=a("p"),MGr=o("This class cannot be instantiated directly using "),z5e=a("code"),EGr=o("__init__()"),CGr=o(" (throws an error)."),wGr=l(),Ht=a("div"),F(Ux.$$.fragment),AGr=l(),W5e=a("p"),LGr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yGr=l(),of=a("p"),xGr=o(`Note:
Loading a model from its configuration file does `),Q5e=a("strong"),$Gr=o("not"),kGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DZ=a("a"),SGr=o("from_pretrained()"),RGr=o(" to load the model weights."),PGr=l(),F(P0.$$.fragment),BGr=l(),zr=a("div"),F(Jx.$$.fragment),IGr=l(),H5e=a("p"),NGr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qGr=l(),En=a("p"),jGr=o("The model class to instantiate is selected based on the "),U5e=a("code"),DGr=o("model_type"),GGr=o(` property of the config object (either
passed as an argument or loaded from `),J5e=a("code"),OGr=o("pretrained_model_name_or_path"),VGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y5e=a("code"),XGr=o("pretrained_model_name_or_path"),zGr=o(":"),WGr=l(),ke=a("ul"),B0=a("li"),K5e=a("strong"),QGr=o("bart"),HGr=o(" \u2014 "),GZ=a("a"),UGr=o("FlaxBartForConditionalGeneration"),JGr=o(" (BART model)"),YGr=l(),I0=a("li"),Z5e=a("strong"),KGr=o("blenderbot"),ZGr=o(" \u2014 "),OZ=a("a"),eOr=o("FlaxBlenderbotForConditionalGeneration"),oOr=o(" (Blenderbot model)"),rOr=l(),N0=a("li"),e3e=a("strong"),tOr=o("blenderbot-small"),aOr=o(" \u2014 "),VZ=a("a"),nOr=o("FlaxBlenderbotSmallForConditionalGeneration"),sOr=o(" (BlenderbotSmall model)"),lOr=l(),q0=a("li"),o3e=a("strong"),iOr=o("encoder-decoder"),dOr=o(" \u2014 "),XZ=a("a"),cOr=o("FlaxEncoderDecoderModel"),fOr=o(" (Encoder decoder model)"),mOr=l(),j0=a("li"),r3e=a("strong"),gOr=o("longt5"),hOr=o(" \u2014 "),zZ=a("a"),pOr=o("FlaxLongT5ForConditionalGeneration"),uOr=o(" (LongT5 model)"),_Or=l(),D0=a("li"),t3e=a("strong"),bOr=o("marian"),vOr=o(" \u2014 "),WZ=a("a"),FOr=o("FlaxMarianMTModel"),TOr=o(" (Marian model)"),MOr=l(),G0=a("li"),a3e=a("strong"),EOr=o("mbart"),COr=o(" \u2014 "),QZ=a("a"),wOr=o("FlaxMBartForConditionalGeneration"),AOr=o(" (mBART model)"),LOr=l(),O0=a("li"),n3e=a("strong"),yOr=o("mt5"),xOr=o(" \u2014 "),HZ=a("a"),$Or=o("FlaxMT5ForConditionalGeneration"),kOr=o(" (MT5 model)"),SOr=l(),V0=a("li"),s3e=a("strong"),ROr=o("pegasus"),POr=o(" \u2014 "),UZ=a("a"),BOr=o("FlaxPegasusForConditionalGeneration"),IOr=o(" (Pegasus model)"),NOr=l(),X0=a("li"),l3e=a("strong"),qOr=o("t5"),jOr=o(" \u2014 "),JZ=a("a"),DOr=o("FlaxT5ForConditionalGeneration"),GOr=o(" (T5 model)"),OOr=l(),F(z0.$$.fragment),nVe=l(),rf=a("h2"),W0=a("a"),i3e=a("span"),F(Yx.$$.fragment),VOr=l(),d3e=a("span"),XOr=o("FlaxAutoModelForSequenceClassification"),sVe=l(),br=a("div"),F(Kx.$$.fragment),zOr=l(),tf=a("p"),WOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),YZ=a("a"),QOr=o("from_pretrained()"),HOr=o(" class method or the "),KZ=a("a"),UOr=o("from_config()"),JOr=o(` class
method.`),YOr=l(),Zx=a("p"),KOr=o("This class cannot be instantiated directly using "),c3e=a("code"),ZOr=o("__init__()"),eVr=o(" (throws an error)."),oVr=l(),Ut=a("div"),F(e$.$$.fragment),rVr=l(),f3e=a("p"),tVr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),aVr=l(),af=a("p"),nVr=o(`Note:
Loading a model from its configuration file does `),m3e=a("strong"),sVr=o("not"),lVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZZ=a("a"),iVr=o("from_pretrained()"),dVr=o(" to load the model weights."),cVr=l(),F(Q0.$$.fragment),fVr=l(),Wr=a("div"),F(o$.$$.fragment),mVr=l(),g3e=a("p"),gVr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),hVr=l(),Cn=a("p"),pVr=o("The model class to instantiate is selected based on the "),h3e=a("code"),uVr=o("model_type"),_Vr=o(` property of the config object (either
passed as an argument or loaded from `),p3e=a("code"),bVr=o("pretrained_model_name_or_path"),vVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u3e=a("code"),FVr=o("pretrained_model_name_or_path"),TVr=o(":"),MVr=l(),Se=a("ul"),H0=a("li"),_3e=a("strong"),EVr=o("albert"),CVr=o(" \u2014 "),eee=a("a"),wVr=o("FlaxAlbertForSequenceClassification"),AVr=o(" (ALBERT model)"),LVr=l(),U0=a("li"),b3e=a("strong"),yVr=o("bart"),xVr=o(" \u2014 "),oee=a("a"),$Vr=o("FlaxBartForSequenceClassification"),kVr=o(" (BART model)"),SVr=l(),J0=a("li"),v3e=a("strong"),RVr=o("bert"),PVr=o(" \u2014 "),ree=a("a"),BVr=o("FlaxBertForSequenceClassification"),IVr=o(" (BERT model)"),NVr=l(),Y0=a("li"),F3e=a("strong"),qVr=o("big_bird"),jVr=o(" \u2014 "),tee=a("a"),DVr=o("FlaxBigBirdForSequenceClassification"),GVr=o(" (BigBird model)"),OVr=l(),K0=a("li"),T3e=a("strong"),VVr=o("distilbert"),XVr=o(" \u2014 "),aee=a("a"),zVr=o("FlaxDistilBertForSequenceClassification"),WVr=o(" (DistilBERT model)"),QVr=l(),Z0=a("li"),M3e=a("strong"),HVr=o("electra"),UVr=o(" \u2014 "),nee=a("a"),JVr=o("FlaxElectraForSequenceClassification"),YVr=o(" (ELECTRA model)"),KVr=l(),ew=a("li"),E3e=a("strong"),ZVr=o("mbart"),eXr=o(" \u2014 "),see=a("a"),oXr=o("FlaxMBartForSequenceClassification"),rXr=o(" (mBART model)"),tXr=l(),ow=a("li"),C3e=a("strong"),aXr=o("roberta"),nXr=o(" \u2014 "),lee=a("a"),sXr=o("FlaxRobertaForSequenceClassification"),lXr=o(" (RoBERTa model)"),iXr=l(),rw=a("li"),w3e=a("strong"),dXr=o("roformer"),cXr=o(" \u2014 "),iee=a("a"),fXr=o("FlaxRoFormerForSequenceClassification"),mXr=o(" (RoFormer model)"),gXr=l(),tw=a("li"),A3e=a("strong"),hXr=o("xlm-roberta"),pXr=o(" \u2014 "),dee=a("a"),uXr=o("FlaxXLMRobertaForSequenceClassification"),_Xr=o(" (XLM-RoBERTa model)"),bXr=l(),F(aw.$$.fragment),lVe=l(),nf=a("h2"),nw=a("a"),L3e=a("span"),F(r$.$$.fragment),vXr=l(),y3e=a("span"),FXr=o("FlaxAutoModelForQuestionAnswering"),iVe=l(),vr=a("div"),F(t$.$$.fragment),TXr=l(),sf=a("p"),MXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cee=a("a"),EXr=o("from_pretrained()"),CXr=o(" class method or the "),fee=a("a"),wXr=o("from_config()"),AXr=o(` class
method.`),LXr=l(),a$=a("p"),yXr=o("This class cannot be instantiated directly using "),x3e=a("code"),xXr=o("__init__()"),$Xr=o(" (throws an error)."),kXr=l(),Jt=a("div"),F(n$.$$.fragment),SXr=l(),$3e=a("p"),RXr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),PXr=l(),lf=a("p"),BXr=o(`Note:
Loading a model from its configuration file does `),k3e=a("strong"),IXr=o("not"),NXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mee=a("a"),qXr=o("from_pretrained()"),jXr=o(" to load the model weights."),DXr=l(),F(sw.$$.fragment),GXr=l(),Qr=a("div"),F(s$.$$.fragment),OXr=l(),S3e=a("p"),VXr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),XXr=l(),wn=a("p"),zXr=o("The model class to instantiate is selected based on the "),R3e=a("code"),WXr=o("model_type"),QXr=o(` property of the config object (either
passed as an argument or loaded from `),P3e=a("code"),HXr=o("pretrained_model_name_or_path"),UXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B3e=a("code"),JXr=o("pretrained_model_name_or_path"),YXr=o(":"),KXr=l(),Re=a("ul"),lw=a("li"),I3e=a("strong"),ZXr=o("albert"),ezr=o(" \u2014 "),gee=a("a"),ozr=o("FlaxAlbertForQuestionAnswering"),rzr=o(" (ALBERT model)"),tzr=l(),iw=a("li"),N3e=a("strong"),azr=o("bart"),nzr=o(" \u2014 "),hee=a("a"),szr=o("FlaxBartForQuestionAnswering"),lzr=o(" (BART model)"),izr=l(),dw=a("li"),q3e=a("strong"),dzr=o("bert"),czr=o(" \u2014 "),pee=a("a"),fzr=o("FlaxBertForQuestionAnswering"),mzr=o(" (BERT model)"),gzr=l(),cw=a("li"),j3e=a("strong"),hzr=o("big_bird"),pzr=o(" \u2014 "),uee=a("a"),uzr=o("FlaxBigBirdForQuestionAnswering"),_zr=o(" (BigBird model)"),bzr=l(),fw=a("li"),D3e=a("strong"),vzr=o("distilbert"),Fzr=o(" \u2014 "),_ee=a("a"),Tzr=o("FlaxDistilBertForQuestionAnswering"),Mzr=o(" (DistilBERT model)"),Ezr=l(),mw=a("li"),G3e=a("strong"),Czr=o("electra"),wzr=o(" \u2014 "),bee=a("a"),Azr=o("FlaxElectraForQuestionAnswering"),Lzr=o(" (ELECTRA model)"),yzr=l(),gw=a("li"),O3e=a("strong"),xzr=o("mbart"),$zr=o(" \u2014 "),vee=a("a"),kzr=o("FlaxMBartForQuestionAnswering"),Szr=o(" (mBART model)"),Rzr=l(),hw=a("li"),V3e=a("strong"),Pzr=o("roberta"),Bzr=o(" \u2014 "),Fee=a("a"),Izr=o("FlaxRobertaForQuestionAnswering"),Nzr=o(" (RoBERTa model)"),qzr=l(),pw=a("li"),X3e=a("strong"),jzr=o("roformer"),Dzr=o(" \u2014 "),Tee=a("a"),Gzr=o("FlaxRoFormerForQuestionAnswering"),Ozr=o(" (RoFormer model)"),Vzr=l(),uw=a("li"),z3e=a("strong"),Xzr=o("xlm-roberta"),zzr=o(" \u2014 "),Mee=a("a"),Wzr=o("FlaxXLMRobertaForQuestionAnswering"),Qzr=o(" (XLM-RoBERTa model)"),Hzr=l(),F(_w.$$.fragment),dVe=l(),df=a("h2"),bw=a("a"),W3e=a("span"),F(l$.$$.fragment),Uzr=l(),Q3e=a("span"),Jzr=o("FlaxAutoModelForTokenClassification"),cVe=l(),Fr=a("div"),F(i$.$$.fragment),Yzr=l(),cf=a("p"),Kzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Eee=a("a"),Zzr=o("from_pretrained()"),eWr=o(" class method or the "),Cee=a("a"),oWr=o("from_config()"),rWr=o(` class
method.`),tWr=l(),d$=a("p"),aWr=o("This class cannot be instantiated directly using "),H3e=a("code"),nWr=o("__init__()"),sWr=o(" (throws an error)."),lWr=l(),Yt=a("div"),F(c$.$$.fragment),iWr=l(),U3e=a("p"),dWr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),cWr=l(),ff=a("p"),fWr=o(`Note:
Loading a model from its configuration file does `),J3e=a("strong"),mWr=o("not"),gWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wee=a("a"),hWr=o("from_pretrained()"),pWr=o(" to load the model weights."),uWr=l(),F(vw.$$.fragment),_Wr=l(),Hr=a("div"),F(f$.$$.fragment),bWr=l(),Y3e=a("p"),vWr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),FWr=l(),An=a("p"),TWr=o("The model class to instantiate is selected based on the "),K3e=a("code"),MWr=o("model_type"),EWr=o(` property of the config object (either
passed as an argument or loaded from `),Z3e=a("code"),CWr=o("pretrained_model_name_or_path"),wWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e0e=a("code"),AWr=o("pretrained_model_name_or_path"),LWr=o(":"),yWr=l(),Ve=a("ul"),Fw=a("li"),o0e=a("strong"),xWr=o("albert"),$Wr=o(" \u2014 "),Aee=a("a"),kWr=o("FlaxAlbertForTokenClassification"),SWr=o(" (ALBERT model)"),RWr=l(),Tw=a("li"),r0e=a("strong"),PWr=o("bert"),BWr=o(" \u2014 "),Lee=a("a"),IWr=o("FlaxBertForTokenClassification"),NWr=o(" (BERT model)"),qWr=l(),Mw=a("li"),t0e=a("strong"),jWr=o("big_bird"),DWr=o(" \u2014 "),yee=a("a"),GWr=o("FlaxBigBirdForTokenClassification"),OWr=o(" (BigBird model)"),VWr=l(),Ew=a("li"),a0e=a("strong"),XWr=o("distilbert"),zWr=o(" \u2014 "),xee=a("a"),WWr=o("FlaxDistilBertForTokenClassification"),QWr=o(" (DistilBERT model)"),HWr=l(),Cw=a("li"),n0e=a("strong"),UWr=o("electra"),JWr=o(" \u2014 "),$ee=a("a"),YWr=o("FlaxElectraForTokenClassification"),KWr=o(" (ELECTRA model)"),ZWr=l(),ww=a("li"),s0e=a("strong"),eQr=o("roberta"),oQr=o(" \u2014 "),kee=a("a"),rQr=o("FlaxRobertaForTokenClassification"),tQr=o(" (RoBERTa model)"),aQr=l(),Aw=a("li"),l0e=a("strong"),nQr=o("roformer"),sQr=o(" \u2014 "),See=a("a"),lQr=o("FlaxRoFormerForTokenClassification"),iQr=o(" (RoFormer model)"),dQr=l(),Lw=a("li"),i0e=a("strong"),cQr=o("xlm-roberta"),fQr=o(" \u2014 "),Ree=a("a"),mQr=o("FlaxXLMRobertaForTokenClassification"),gQr=o(" (XLM-RoBERTa model)"),hQr=l(),F(yw.$$.fragment),fVe=l(),mf=a("h2"),xw=a("a"),d0e=a("span"),F(m$.$$.fragment),pQr=l(),c0e=a("span"),uQr=o("FlaxAutoModelForMultipleChoice"),mVe=l(),Tr=a("div"),F(g$.$$.fragment),_Qr=l(),gf=a("p"),bQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Pee=a("a"),vQr=o("from_pretrained()"),FQr=o(" class method or the "),Bee=a("a"),TQr=o("from_config()"),MQr=o(` class
method.`),EQr=l(),h$=a("p"),CQr=o("This class cannot be instantiated directly using "),f0e=a("code"),wQr=o("__init__()"),AQr=o(" (throws an error)."),LQr=l(),Kt=a("div"),F(p$.$$.fragment),yQr=l(),m0e=a("p"),xQr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),$Qr=l(),hf=a("p"),kQr=o(`Note:
Loading a model from its configuration file does `),g0e=a("strong"),SQr=o("not"),RQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Iee=a("a"),PQr=o("from_pretrained()"),BQr=o(" to load the model weights."),IQr=l(),F($w.$$.fragment),NQr=l(),Ur=a("div"),F(u$.$$.fragment),qQr=l(),h0e=a("p"),jQr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),DQr=l(),Ln=a("p"),GQr=o("The model class to instantiate is selected based on the "),p0e=a("code"),OQr=o("model_type"),VQr=o(` property of the config object (either
passed as an argument or loaded from `),u0e=a("code"),XQr=o("pretrained_model_name_or_path"),zQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_0e=a("code"),WQr=o("pretrained_model_name_or_path"),QQr=o(":"),HQr=l(),Xe=a("ul"),kw=a("li"),b0e=a("strong"),UQr=o("albert"),JQr=o(" \u2014 "),Nee=a("a"),YQr=o("FlaxAlbertForMultipleChoice"),KQr=o(" (ALBERT model)"),ZQr=l(),Sw=a("li"),v0e=a("strong"),eHr=o("bert"),oHr=o(" \u2014 "),qee=a("a"),rHr=o("FlaxBertForMultipleChoice"),tHr=o(" (BERT model)"),aHr=l(),Rw=a("li"),F0e=a("strong"),nHr=o("big_bird"),sHr=o(" \u2014 "),jee=a("a"),lHr=o("FlaxBigBirdForMultipleChoice"),iHr=o(" (BigBird model)"),dHr=l(),Pw=a("li"),T0e=a("strong"),cHr=o("distilbert"),fHr=o(" \u2014 "),Dee=a("a"),mHr=o("FlaxDistilBertForMultipleChoice"),gHr=o(" (DistilBERT model)"),hHr=l(),Bw=a("li"),M0e=a("strong"),pHr=o("electra"),uHr=o(" \u2014 "),Gee=a("a"),_Hr=o("FlaxElectraForMultipleChoice"),bHr=o(" (ELECTRA model)"),vHr=l(),Iw=a("li"),E0e=a("strong"),FHr=o("roberta"),THr=o(" \u2014 "),Oee=a("a"),MHr=o("FlaxRobertaForMultipleChoice"),EHr=o(" (RoBERTa model)"),CHr=l(),Nw=a("li"),C0e=a("strong"),wHr=o("roformer"),AHr=o(" \u2014 "),Vee=a("a"),LHr=o("FlaxRoFormerForMultipleChoice"),yHr=o(" (RoFormer model)"),xHr=l(),qw=a("li"),w0e=a("strong"),$Hr=o("xlm-roberta"),kHr=o(" \u2014 "),Xee=a("a"),SHr=o("FlaxXLMRobertaForMultipleChoice"),RHr=o(" (XLM-RoBERTa model)"),PHr=l(),F(jw.$$.fragment),gVe=l(),pf=a("h2"),Dw=a("a"),A0e=a("span"),F(_$.$$.fragment),BHr=l(),L0e=a("span"),IHr=o("FlaxAutoModelForNextSentencePrediction"),hVe=l(),Mr=a("div"),F(b$.$$.fragment),NHr=l(),uf=a("p"),qHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),zee=a("a"),jHr=o("from_pretrained()"),DHr=o(" class method or the "),Wee=a("a"),GHr=o("from_config()"),OHr=o(` class
method.`),VHr=l(),v$=a("p"),XHr=o("This class cannot be instantiated directly using "),y0e=a("code"),zHr=o("__init__()"),WHr=o(" (throws an error)."),QHr=l(),Zt=a("div"),F(F$.$$.fragment),HHr=l(),x0e=a("p"),UHr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),JHr=l(),_f=a("p"),YHr=o(`Note:
Loading a model from its configuration file does `),$0e=a("strong"),KHr=o("not"),ZHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qee=a("a"),eUr=o("from_pretrained()"),oUr=o(" to load the model weights."),rUr=l(),F(Gw.$$.fragment),tUr=l(),Jr=a("div"),F(T$.$$.fragment),aUr=l(),k0e=a("p"),nUr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),sUr=l(),yn=a("p"),lUr=o("The model class to instantiate is selected based on the "),S0e=a("code"),iUr=o("model_type"),dUr=o(` property of the config object (either
passed as an argument or loaded from `),R0e=a("code"),cUr=o("pretrained_model_name_or_path"),fUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P0e=a("code"),mUr=o("pretrained_model_name_or_path"),gUr=o(":"),hUr=l(),B0e=a("ul"),Ow=a("li"),I0e=a("strong"),pUr=o("bert"),uUr=o(" \u2014 "),Hee=a("a"),_Ur=o("FlaxBertForNextSentencePrediction"),bUr=o(" (BERT model)"),vUr=l(),F(Vw.$$.fragment),pVe=l(),bf=a("h2"),Xw=a("a"),N0e=a("span"),F(M$.$$.fragment),FUr=l(),q0e=a("span"),TUr=o("FlaxAutoModelForImageClassification"),uVe=l(),Er=a("div"),F(E$.$$.fragment),MUr=l(),vf=a("p"),EUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Uee=a("a"),CUr=o("from_pretrained()"),wUr=o(" class method or the "),Jee=a("a"),AUr=o("from_config()"),LUr=o(` class
method.`),yUr=l(),C$=a("p"),xUr=o("This class cannot be instantiated directly using "),j0e=a("code"),$Ur=o("__init__()"),kUr=o(" (throws an error)."),SUr=l(),ea=a("div"),F(w$.$$.fragment),RUr=l(),D0e=a("p"),PUr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),BUr=l(),Ff=a("p"),IUr=o(`Note:
Loading a model from its configuration file does `),G0e=a("strong"),NUr=o("not"),qUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=a("a"),jUr=o("from_pretrained()"),DUr=o(" to load the model weights."),GUr=l(),F(zw.$$.fragment),OUr=l(),Yr=a("div"),F(A$.$$.fragment),VUr=l(),O0e=a("p"),XUr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),zUr=l(),xn=a("p"),WUr=o("The model class to instantiate is selected based on the "),V0e=a("code"),QUr=o("model_type"),HUr=o(` property of the config object (either
passed as an argument or loaded from `),X0e=a("code"),UUr=o("pretrained_model_name_or_path"),JUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z0e=a("code"),YUr=o("pretrained_model_name_or_path"),KUr=o(":"),ZUr=l(),L$=a("ul"),Ww=a("li"),W0e=a("strong"),eJr=o("beit"),oJr=o(" \u2014 "),Kee=a("a"),rJr=o("FlaxBeitForImageClassification"),tJr=o(" (BEiT model)"),aJr=l(),Qw=a("li"),Q0e=a("strong"),nJr=o("vit"),sJr=o(" \u2014 "),Zee=a("a"),lJr=o("FlaxViTForImageClassification"),iJr=o(" (ViT model)"),dJr=l(),F(Hw.$$.fragment),_Ve=l(),Tf=a("h2"),Uw=a("a"),H0e=a("span"),F(y$.$$.fragment),cJr=l(),U0e=a("span"),fJr=o("FlaxAutoModelForVision2Seq"),bVe=l(),Cr=a("div"),F(x$.$$.fragment),mJr=l(),Mf=a("p"),gJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eoe=a("a"),hJr=o("from_pretrained()"),pJr=o(" class method or the "),ooe=a("a"),uJr=o("from_config()"),_Jr=o(` class
method.`),bJr=l(),$$=a("p"),vJr=o("This class cannot be instantiated directly using "),J0e=a("code"),FJr=o("__init__()"),TJr=o(" (throws an error)."),MJr=l(),oa=a("div"),F(k$.$$.fragment),EJr=l(),Y0e=a("p"),CJr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),wJr=l(),Ef=a("p"),AJr=o(`Note:
Loading a model from its configuration file does `),K0e=a("strong"),LJr=o("not"),yJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),roe=a("a"),xJr=o("from_pretrained()"),$Jr=o(" to load the model weights."),kJr=l(),F(Jw.$$.fragment),SJr=l(),Kr=a("div"),F(S$.$$.fragment),RJr=l(),Z0e=a("p"),PJr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),BJr=l(),$n=a("p"),IJr=o("The model class to instantiate is selected based on the "),ewe=a("code"),NJr=o("model_type"),qJr=o(` property of the config object (either
passed as an argument or loaded from `),owe=a("code"),jJr=o("pretrained_model_name_or_path"),DJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rwe=a("code"),GJr=o("pretrained_model_name_or_path"),OJr=o(":"),VJr=l(),twe=a("ul"),Yw=a("li"),awe=a("strong"),XJr=o("vision-encoder-decoder"),zJr=o(" \u2014 "),toe=a("a"),WJr=o("FlaxVisionEncoderDecoderModel"),QJr=o(" (Vision Encoder decoder model)"),HJr=l(),F(Kw.$$.fragment),this.h()},l(f){const _=sjt('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var R$=s(p);m=n(R$,"A",{id:!0,class:!0,href:!0});var nwe=s(m);u=n(nwe,"SPAN",{});var swe=s(u);T(d.$$.fragment,swe),swe.forEach(t),nwe.forEach(t),h=i(R$),Eo=n(R$,"SPAN",{});var lwe=s(Eo);Fi=r(lwe,"Auto Classes"),lwe.forEach(t),R$.forEach(t),Lf=i(f),at=n(f,"P",{});var P$=s(at);Ti=r(P$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Mi=n(P$,"CODE",{});var iwe=s(Mi);vL=r(iwe,"from_pretrained()"),iwe.forEach(t),yf=r(P$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),P$.forEach(t),Oe=i(f),We=n(f,"P",{});var kn=s(We);Ei=r(kn,"Instantiating one of "),Sn=n(kn,"A",{href:!0});var dwe=s(Sn);FL=r(dwe,"AutoConfig"),dwe.forEach(t),Rn=r(kn,", "),Pn=n(kn,"A",{href:!0});var cwe=s(Pn);TL=r(cwe,"AutoModel"),cwe.forEach(t),Ci=r(kn,`, and
`),Bn=n(kn,"A",{href:!0});var fwe=s(Bn);ML=r(fwe,"AutoTokenizer"),fwe.forEach(t),wi=r(kn," will directly create a class of the relevant architecture. For instance"),kn.forEach(t),xf=i(f),T(ya.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var B$=s(Ae);Uk=r(B$,"will create a model that is an instance of "),Ai=n(B$,"A",{href:!0});var mwe=s(Ai);Jk=r(mwe,"BertModel"),mwe.forEach(t),Yk=r(B$,"."),B$.forEach(t),Co=i(f),xa=n(f,"P",{});var I$=s(xa);Kk=r(I$,"There is one class of "),$f=n(I$,"CODE",{});var gwe=s($f);Zk=r(gwe,"AutoModel"),gwe.forEach(t),xze=r(I$," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),I$.forEach(t),hGe=i(f),Li=n(f,"H2",{class:!0});var N$=s(Li);kf=n(N$,"A",{id:!0,class:!0,href:!0});var hwe=s(kf);Kre=n(hwe,"SPAN",{});var pwe=s(Kre);T(EL.$$.fragment,pwe),pwe.forEach(t),hwe.forEach(t),$ze=i(N$),Zre=n(N$,"SPAN",{});var uwe=s(Zre);kze=r(uwe,"Extending the Auto Classes"),uwe.forEach(t),N$.forEach(t),pGe=i(f),In=n(f,"P",{});var Cf=s(In);Sze=r(Cf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ete=n(Cf,"CODE",{});var _we=s(ete);Rze=r(_we,"NewModel"),_we.forEach(t),Pze=r(Cf,", make sure you have a "),ote=n(Cf,"CODE",{});var bwe=s(ote);Bze=r(bwe,"NewModelConfig"),bwe.forEach(t),Ize=r(Cf,` then you can add those to the auto
classes like this:`),Cf.forEach(t),uGe=i(f),T(CL.$$.fragment,f),_Ge=i(f),eS=n(f,"P",{});var vwe=s(eS);Nze=r(vwe,"You will then be able to use the auto classes like you would usually do!"),vwe.forEach(t),bGe=i(f),T(Sf.$$.fragment,f),vGe=i(f),yi=n(f,"H2",{class:!0});var q$=s(yi);Rf=n(q$,"A",{id:!0,class:!0,href:!0});var Fwe=s(Rf);rte=n(Fwe,"SPAN",{});var Twe=s(rte);T(wL.$$.fragment,Twe),Twe.forEach(t),Fwe.forEach(t),qze=i(q$),tte=n(q$,"SPAN",{});var Mwe=s(tte);jze=r(Mwe,"AutoConfig"),Mwe.forEach(t),q$.forEach(t),FGe=i(f),wo=n(f,"DIV",{class:!0});var rt=s(wo);T(AL.$$.fragment,rt),Dze=i(rt),LL=n(rt,"P",{});var j$=s(LL);Gze=r(j$,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),oS=n(j$,"A",{href:!0});var Ewe=s(oS);Oze=r(Ewe,"from_pretrained()"),Ewe.forEach(t),Vze=r(j$," class method."),j$.forEach(t),Xze=i(rt),yL=n(rt,"P",{});var D$=s(yL);zze=r(D$,"This class cannot be instantiated directly using "),ate=n(D$,"CODE",{});var Cwe=s(ate);Wze=r(Cwe,"__init__()"),Cwe.forEach(t),Qze=r(D$," (throws an error)."),D$.forEach(t),Hze=i(rt),wr=n(rt,"DIV",{class:!0});var tt=s(wr);T(xL.$$.fragment,tt),Uze=i(tt),nte=n(tt,"P",{});var wwe=s(nte);Jze=r(wwe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),wwe.forEach(t),Yze=i(tt),xi=n(tt,"P",{});var wf=s(xi);Kze=r(wf,"The configuration class to instantiate is selected based on the "),ste=n(wf,"CODE",{});var Awe=s(ste);Zze=r(Awe,"model_type"),Awe.forEach(t),eWe=r(wf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),lte=n(wf,"CODE",{});var Lwe=s(lte);oWe=r(Lwe,"pretrained_model_name_or_path"),Lwe.forEach(t),rWe=r(wf,":"),wf.forEach(t),tWe=i(tt),A=n(tt,"UL",{});var L=s(A);Pf=n(L,"LI",{});var Zw=s(Pf);ite=n(Zw,"STRONG",{});var ywe=s(ite);aWe=r(ywe,"albert"),ywe.forEach(t),nWe=r(Zw," \u2014 "),rS=n(Zw,"A",{href:!0});var xwe=s(rS);sWe=r(xwe,"AlbertConfig"),xwe.forEach(t),lWe=r(Zw," (ALBERT model)"),Zw.forEach(t),iWe=i(L),Bf=n(L,"LI",{});var eA=s(Bf);dte=n(eA,"STRONG",{});var $we=s(dte);dWe=r($we,"bart"),$we.forEach(t),cWe=r(eA," \u2014 "),tS=n(eA,"A",{href:!0});var kwe=s(tS);fWe=r(kwe,"BartConfig"),kwe.forEach(t),mWe=r(eA," (BART model)"),eA.forEach(t),gWe=i(L),If=n(L,"LI",{});var oA=s(If);cte=n(oA,"STRONG",{});var Swe=s(cte);hWe=r(Swe,"beit"),Swe.forEach(t),pWe=r(oA," \u2014 "),aS=n(oA,"A",{href:!0});var Rwe=s(aS);uWe=r(Rwe,"BeitConfig"),Rwe.forEach(t),_We=r(oA," (BEiT model)"),oA.forEach(t),bWe=i(L),Nf=n(L,"LI",{});var rA=s(Nf);fte=n(rA,"STRONG",{});var Pwe=s(fte);vWe=r(Pwe,"bert"),Pwe.forEach(t),FWe=r(rA," \u2014 "),nS=n(rA,"A",{href:!0});var Bwe=s(nS);TWe=r(Bwe,"BertConfig"),Bwe.forEach(t),MWe=r(rA," (BERT model)"),rA.forEach(t),EWe=i(L),qf=n(L,"LI",{});var tA=s(qf);mte=n(tA,"STRONG",{});var Iwe=s(mte);CWe=r(Iwe,"bert-generation"),Iwe.forEach(t),wWe=r(tA," \u2014 "),sS=n(tA,"A",{href:!0});var Nwe=s(sS);AWe=r(Nwe,"BertGenerationConfig"),Nwe.forEach(t),LWe=r(tA," (Bert Generation model)"),tA.forEach(t),yWe=i(L),jf=n(L,"LI",{});var aA=s(jf);gte=n(aA,"STRONG",{});var qwe=s(gte);xWe=r(qwe,"big_bird"),qwe.forEach(t),$We=r(aA," \u2014 "),lS=n(aA,"A",{href:!0});var jwe=s(lS);kWe=r(jwe,"BigBirdConfig"),jwe.forEach(t),SWe=r(aA," (BigBird model)"),aA.forEach(t),RWe=i(L),Df=n(L,"LI",{});var nA=s(Df);hte=n(nA,"STRONG",{});var Dwe=s(hte);PWe=r(Dwe,"bigbird_pegasus"),Dwe.forEach(t),BWe=r(nA," \u2014 "),iS=n(nA,"A",{href:!0});var Gwe=s(iS);IWe=r(Gwe,"BigBirdPegasusConfig"),Gwe.forEach(t),NWe=r(nA," (BigBird-Pegasus model)"),nA.forEach(t),qWe=i(L),Gf=n(L,"LI",{});var sA=s(Gf);pte=n(sA,"STRONG",{});var Owe=s(pte);jWe=r(Owe,"blenderbot"),Owe.forEach(t),DWe=r(sA," \u2014 "),dS=n(sA,"A",{href:!0});var Vwe=s(dS);GWe=r(Vwe,"BlenderbotConfig"),Vwe.forEach(t),OWe=r(sA," (Blenderbot model)"),sA.forEach(t),VWe=i(L),Of=n(L,"LI",{});var lA=s(Of);ute=n(lA,"STRONG",{});var Xwe=s(ute);XWe=r(Xwe,"blenderbot-small"),Xwe.forEach(t),zWe=r(lA," \u2014 "),cS=n(lA,"A",{href:!0});var zwe=s(cS);WWe=r(zwe,"BlenderbotSmallConfig"),zwe.forEach(t),QWe=r(lA," (BlenderbotSmall model)"),lA.forEach(t),HWe=i(L),Vf=n(L,"LI",{});var iA=s(Vf);_te=n(iA,"STRONG",{});var Wwe=s(_te);UWe=r(Wwe,"bloom"),Wwe.forEach(t),JWe=r(iA," \u2014 "),fS=n(iA,"A",{href:!0});var Qwe=s(fS);YWe=r(Qwe,"BloomConfig"),Qwe.forEach(t),KWe=r(iA," (BLOOM model)"),iA.forEach(t),ZWe=i(L),Xf=n(L,"LI",{});var dA=s(Xf);bte=n(dA,"STRONG",{});var Hwe=s(bte);eQe=r(Hwe,"camembert"),Hwe.forEach(t),oQe=r(dA," \u2014 "),mS=n(dA,"A",{href:!0});var Uwe=s(mS);rQe=r(Uwe,"CamembertConfig"),Uwe.forEach(t),tQe=r(dA," (CamemBERT model)"),dA.forEach(t),aQe=i(L),zf=n(L,"LI",{});var cA=s(zf);vte=n(cA,"STRONG",{});var Jwe=s(vte);nQe=r(Jwe,"canine"),Jwe.forEach(t),sQe=r(cA," \u2014 "),gS=n(cA,"A",{href:!0});var Ywe=s(gS);lQe=r(Ywe,"CanineConfig"),Ywe.forEach(t),iQe=r(cA," (CANINE model)"),cA.forEach(t),dQe=i(L),Wf=n(L,"LI",{});var fA=s(Wf);Fte=n(fA,"STRONG",{});var Kwe=s(Fte);cQe=r(Kwe,"clip"),Kwe.forEach(t),fQe=r(fA," \u2014 "),hS=n(fA,"A",{href:!0});var Zwe=s(hS);mQe=r(Zwe,"CLIPConfig"),Zwe.forEach(t),gQe=r(fA," (CLIP model)"),fA.forEach(t),hQe=i(L),Qf=n(L,"LI",{});var mA=s(Qf);Tte=n(mA,"STRONG",{});var eAe=s(Tte);pQe=r(eAe,"convbert"),eAe.forEach(t),uQe=r(mA," \u2014 "),pS=n(mA,"A",{href:!0});var oAe=s(pS);_Qe=r(oAe,"ConvBertConfig"),oAe.forEach(t),bQe=r(mA," (ConvBERT model)"),mA.forEach(t),vQe=i(L),Hf=n(L,"LI",{});var gA=s(Hf);Mte=n(gA,"STRONG",{});var rAe=s(Mte);FQe=r(rAe,"convnext"),rAe.forEach(t),TQe=r(gA," \u2014 "),uS=n(gA,"A",{href:!0});var tAe=s(uS);MQe=r(tAe,"ConvNextConfig"),tAe.forEach(t),EQe=r(gA," (ConvNeXT model)"),gA.forEach(t),CQe=i(L),Uf=n(L,"LI",{});var hA=s(Uf);Ete=n(hA,"STRONG",{});var aAe=s(Ete);wQe=r(aAe,"ctrl"),aAe.forEach(t),AQe=r(hA," \u2014 "),_S=n(hA,"A",{href:!0});var nAe=s(_S);LQe=r(nAe,"CTRLConfig"),nAe.forEach(t),yQe=r(hA," (CTRL model)"),hA.forEach(t),xQe=i(L),Jf=n(L,"LI",{});var pA=s(Jf);Cte=n(pA,"STRONG",{});var sAe=s(Cte);$Qe=r(sAe,"cvt"),sAe.forEach(t),kQe=r(pA," \u2014 "),bS=n(pA,"A",{href:!0});var lAe=s(bS);SQe=r(lAe,"CvtConfig"),lAe.forEach(t),RQe=r(pA," (CvT model)"),pA.forEach(t),PQe=i(L),Yf=n(L,"LI",{});var uA=s(Yf);wte=n(uA,"STRONG",{});var iAe=s(wte);BQe=r(iAe,"data2vec-audio"),iAe.forEach(t),IQe=r(uA," \u2014 "),vS=n(uA,"A",{href:!0});var dAe=s(vS);NQe=r(dAe,"Data2VecAudioConfig"),dAe.forEach(t),qQe=r(uA," (Data2VecAudio model)"),uA.forEach(t),jQe=i(L),Kf=n(L,"LI",{});var _A=s(Kf);Ate=n(_A,"STRONG",{});var cAe=s(Ate);DQe=r(cAe,"data2vec-text"),cAe.forEach(t),GQe=r(_A," \u2014 "),FS=n(_A,"A",{href:!0});var fAe=s(FS);OQe=r(fAe,"Data2VecTextConfig"),fAe.forEach(t),VQe=r(_A," (Data2VecText model)"),_A.forEach(t),XQe=i(L),Zf=n(L,"LI",{});var bA=s(Zf);Lte=n(bA,"STRONG",{});var mAe=s(Lte);zQe=r(mAe,"data2vec-vision"),mAe.forEach(t),WQe=r(bA," \u2014 "),TS=n(bA,"A",{href:!0});var gAe=s(TS);QQe=r(gAe,"Data2VecVisionConfig"),gAe.forEach(t),HQe=r(bA," (Data2VecVision model)"),bA.forEach(t),UQe=i(L),em=n(L,"LI",{});var vA=s(em);yte=n(vA,"STRONG",{});var hAe=s(yte);JQe=r(hAe,"deberta"),hAe.forEach(t),YQe=r(vA," \u2014 "),MS=n(vA,"A",{href:!0});var pAe=s(MS);KQe=r(pAe,"DebertaConfig"),pAe.forEach(t),ZQe=r(vA," (DeBERTa model)"),vA.forEach(t),eHe=i(L),om=n(L,"LI",{});var FA=s(om);xte=n(FA,"STRONG",{});var uAe=s(xte);oHe=r(uAe,"deberta-v2"),uAe.forEach(t),rHe=r(FA," \u2014 "),ES=n(FA,"A",{href:!0});var _Ae=s(ES);tHe=r(_Ae,"DebertaV2Config"),_Ae.forEach(t),aHe=r(FA," (DeBERTa-v2 model)"),FA.forEach(t),nHe=i(L),rm=n(L,"LI",{});var TA=s(rm);$te=n(TA,"STRONG",{});var bAe=s($te);sHe=r(bAe,"decision_transformer"),bAe.forEach(t),lHe=r(TA," \u2014 "),CS=n(TA,"A",{href:!0});var vAe=s(CS);iHe=r(vAe,"DecisionTransformerConfig"),vAe.forEach(t),dHe=r(TA," (Decision Transformer model)"),TA.forEach(t),cHe=i(L),tm=n(L,"LI",{});var MA=s(tm);kte=n(MA,"STRONG",{});var JJr=s(kte);fHe=r(JJr,"deit"),JJr.forEach(t),mHe=r(MA," \u2014 "),wS=n(MA,"A",{href:!0});var YJr=s(wS);gHe=r(YJr,"DeiTConfig"),YJr.forEach(t),hHe=r(MA," (DeiT model)"),MA.forEach(t),pHe=i(L),am=n(L,"LI",{});var FAe=s(am);Ste=n(FAe,"STRONG",{});var KJr=s(Ste);uHe=r(KJr,"detr"),KJr.forEach(t),_He=r(FAe," \u2014 "),AS=n(FAe,"A",{href:!0});var ZJr=s(AS);bHe=r(ZJr,"DetrConfig"),ZJr.forEach(t),vHe=r(FAe," (DETR model)"),FAe.forEach(t),FHe=i(L),nm=n(L,"LI",{});var TAe=s(nm);Rte=n(TAe,"STRONG",{});var eYr=s(Rte);THe=r(eYr,"distilbert"),eYr.forEach(t),MHe=r(TAe," \u2014 "),LS=n(TAe,"A",{href:!0});var oYr=s(LS);EHe=r(oYr,"DistilBertConfig"),oYr.forEach(t),CHe=r(TAe," (DistilBERT model)"),TAe.forEach(t),wHe=i(L),sm=n(L,"LI",{});var MAe=s(sm);Pte=n(MAe,"STRONG",{});var rYr=s(Pte);AHe=r(rYr,"dpr"),rYr.forEach(t),LHe=r(MAe," \u2014 "),yS=n(MAe,"A",{href:!0});var tYr=s(yS);yHe=r(tYr,"DPRConfig"),tYr.forEach(t),xHe=r(MAe," (DPR model)"),MAe.forEach(t),$He=i(L),lm=n(L,"LI",{});var EAe=s(lm);Bte=n(EAe,"STRONG",{});var aYr=s(Bte);kHe=r(aYr,"dpt"),aYr.forEach(t),SHe=r(EAe," \u2014 "),xS=n(EAe,"A",{href:!0});var nYr=s(xS);RHe=r(nYr,"DPTConfig"),nYr.forEach(t),PHe=r(EAe," (DPT model)"),EAe.forEach(t),BHe=i(L),im=n(L,"LI",{});var CAe=s(im);Ite=n(CAe,"STRONG",{});var sYr=s(Ite);IHe=r(sYr,"electra"),sYr.forEach(t),NHe=r(CAe," \u2014 "),$S=n(CAe,"A",{href:!0});var lYr=s($S);qHe=r(lYr,"ElectraConfig"),lYr.forEach(t),jHe=r(CAe," (ELECTRA model)"),CAe.forEach(t),DHe=i(L),dm=n(L,"LI",{});var wAe=s(dm);Nte=n(wAe,"STRONG",{});var iYr=s(Nte);GHe=r(iYr,"encoder-decoder"),iYr.forEach(t),OHe=r(wAe," \u2014 "),kS=n(wAe,"A",{href:!0});var dYr=s(kS);VHe=r(dYr,"EncoderDecoderConfig"),dYr.forEach(t),XHe=r(wAe," (Encoder decoder model)"),wAe.forEach(t),zHe=i(L),cm=n(L,"LI",{});var AAe=s(cm);qte=n(AAe,"STRONG",{});var cYr=s(qte);WHe=r(cYr,"flaubert"),cYr.forEach(t),QHe=r(AAe," \u2014 "),SS=n(AAe,"A",{href:!0});var fYr=s(SS);HHe=r(fYr,"FlaubertConfig"),fYr.forEach(t),UHe=r(AAe," (FlauBERT model)"),AAe.forEach(t),JHe=i(L),fm=n(L,"LI",{});var LAe=s(fm);jte=n(LAe,"STRONG",{});var mYr=s(jte);YHe=r(mYr,"flava"),mYr.forEach(t),KHe=r(LAe," \u2014 "),RS=n(LAe,"A",{href:!0});var gYr=s(RS);ZHe=r(gYr,"FlavaConfig"),gYr.forEach(t),eUe=r(LAe," (FLAVA model)"),LAe.forEach(t),oUe=i(L),mm=n(L,"LI",{});var yAe=s(mm);Dte=n(yAe,"STRONG",{});var hYr=s(Dte);rUe=r(hYr,"fnet"),hYr.forEach(t),tUe=r(yAe," \u2014 "),PS=n(yAe,"A",{href:!0});var pYr=s(PS);aUe=r(pYr,"FNetConfig"),pYr.forEach(t),nUe=r(yAe," (FNet model)"),yAe.forEach(t),sUe=i(L),gm=n(L,"LI",{});var xAe=s(gm);Gte=n(xAe,"STRONG",{});var uYr=s(Gte);lUe=r(uYr,"fsmt"),uYr.forEach(t),iUe=r(xAe," \u2014 "),BS=n(xAe,"A",{href:!0});var _Yr=s(BS);dUe=r(_Yr,"FSMTConfig"),_Yr.forEach(t),cUe=r(xAe," (FairSeq Machine-Translation model)"),xAe.forEach(t),fUe=i(L),hm=n(L,"LI",{});var $Ae=s(hm);Ote=n($Ae,"STRONG",{});var bYr=s(Ote);mUe=r(bYr,"funnel"),bYr.forEach(t),gUe=r($Ae," \u2014 "),IS=n($Ae,"A",{href:!0});var vYr=s(IS);hUe=r(vYr,"FunnelConfig"),vYr.forEach(t),pUe=r($Ae," (Funnel Transformer model)"),$Ae.forEach(t),uUe=i(L),pm=n(L,"LI",{});var kAe=s(pm);Vte=n(kAe,"STRONG",{});var FYr=s(Vte);_Ue=r(FYr,"glpn"),FYr.forEach(t),bUe=r(kAe," \u2014 "),NS=n(kAe,"A",{href:!0});var TYr=s(NS);vUe=r(TYr,"GLPNConfig"),TYr.forEach(t),FUe=r(kAe," (GLPN model)"),kAe.forEach(t),TUe=i(L),um=n(L,"LI",{});var SAe=s(um);Xte=n(SAe,"STRONG",{});var MYr=s(Xte);MUe=r(MYr,"gpt2"),MYr.forEach(t),EUe=r(SAe," \u2014 "),qS=n(SAe,"A",{href:!0});var EYr=s(qS);CUe=r(EYr,"GPT2Config"),EYr.forEach(t),wUe=r(SAe," (OpenAI GPT-2 model)"),SAe.forEach(t),AUe=i(L),_m=n(L,"LI",{});var RAe=s(_m);zte=n(RAe,"STRONG",{});var CYr=s(zte);LUe=r(CYr,"gpt_neo"),CYr.forEach(t),yUe=r(RAe," \u2014 "),jS=n(RAe,"A",{href:!0});var wYr=s(jS);xUe=r(wYr,"GPTNeoConfig"),wYr.forEach(t),$Ue=r(RAe," (GPT Neo model)"),RAe.forEach(t),kUe=i(L),bm=n(L,"LI",{});var PAe=s(bm);Wte=n(PAe,"STRONG",{});var AYr=s(Wte);SUe=r(AYr,"gpt_neox"),AYr.forEach(t),RUe=r(PAe," \u2014 "),DS=n(PAe,"A",{href:!0});var LYr=s(DS);PUe=r(LYr,"GPTNeoXConfig"),LYr.forEach(t),BUe=r(PAe," (GPT NeoX model)"),PAe.forEach(t),IUe=i(L),vm=n(L,"LI",{});var BAe=s(vm);Qte=n(BAe,"STRONG",{});var yYr=s(Qte);NUe=r(yYr,"gptj"),yYr.forEach(t),qUe=r(BAe," \u2014 "),GS=n(BAe,"A",{href:!0});var xYr=s(GS);jUe=r(xYr,"GPTJConfig"),xYr.forEach(t),DUe=r(BAe," (GPT-J model)"),BAe.forEach(t),GUe=i(L),Fm=n(L,"LI",{});var IAe=s(Fm);Hte=n(IAe,"STRONG",{});var $Yr=s(Hte);OUe=r($Yr,"hubert"),$Yr.forEach(t),VUe=r(IAe," \u2014 "),OS=n(IAe,"A",{href:!0});var kYr=s(OS);XUe=r(kYr,"HubertConfig"),kYr.forEach(t),zUe=r(IAe," (Hubert model)"),IAe.forEach(t),WUe=i(L),Tm=n(L,"LI",{});var NAe=s(Tm);Ute=n(NAe,"STRONG",{});var SYr=s(Ute);QUe=r(SYr,"ibert"),SYr.forEach(t),HUe=r(NAe," \u2014 "),VS=n(NAe,"A",{href:!0});var RYr=s(VS);UUe=r(RYr,"IBertConfig"),RYr.forEach(t),JUe=r(NAe," (I-BERT model)"),NAe.forEach(t),YUe=i(L),Mm=n(L,"LI",{});var qAe=s(Mm);Jte=n(qAe,"STRONG",{});var PYr=s(Jte);KUe=r(PYr,"imagegpt"),PYr.forEach(t),ZUe=r(qAe," \u2014 "),XS=n(qAe,"A",{href:!0});var BYr=s(XS);eJe=r(BYr,"ImageGPTConfig"),BYr.forEach(t),oJe=r(qAe," (ImageGPT model)"),qAe.forEach(t),rJe=i(L),Em=n(L,"LI",{});var jAe=s(Em);Yte=n(jAe,"STRONG",{});var IYr=s(Yte);tJe=r(IYr,"layoutlm"),IYr.forEach(t),aJe=r(jAe," \u2014 "),zS=n(jAe,"A",{href:!0});var NYr=s(zS);nJe=r(NYr,"LayoutLMConfig"),NYr.forEach(t),sJe=r(jAe," (LayoutLM model)"),jAe.forEach(t),lJe=i(L),Cm=n(L,"LI",{});var DAe=s(Cm);Kte=n(DAe,"STRONG",{});var qYr=s(Kte);iJe=r(qYr,"layoutlmv2"),qYr.forEach(t),dJe=r(DAe," \u2014 "),WS=n(DAe,"A",{href:!0});var jYr=s(WS);cJe=r(jYr,"LayoutLMv2Config"),jYr.forEach(t),fJe=r(DAe," (LayoutLMv2 model)"),DAe.forEach(t),mJe=i(L),wm=n(L,"LI",{});var GAe=s(wm);Zte=n(GAe,"STRONG",{});var DYr=s(Zte);gJe=r(DYr,"layoutlmv3"),DYr.forEach(t),hJe=r(GAe," \u2014 "),QS=n(GAe,"A",{href:!0});var GYr=s(QS);pJe=r(GYr,"LayoutLMv3Config"),GYr.forEach(t),uJe=r(GAe," (LayoutLMv3 model)"),GAe.forEach(t),_Je=i(L),Am=n(L,"LI",{});var OAe=s(Am);eae=n(OAe,"STRONG",{});var OYr=s(eae);bJe=r(OYr,"led"),OYr.forEach(t),vJe=r(OAe," \u2014 "),HS=n(OAe,"A",{href:!0});var VYr=s(HS);FJe=r(VYr,"LEDConfig"),VYr.forEach(t),TJe=r(OAe," (LED model)"),OAe.forEach(t),MJe=i(L),Lm=n(L,"LI",{});var VAe=s(Lm);oae=n(VAe,"STRONG",{});var XYr=s(oae);EJe=r(XYr,"levit"),XYr.forEach(t),CJe=r(VAe," \u2014 "),US=n(VAe,"A",{href:!0});var zYr=s(US);wJe=r(zYr,"LevitConfig"),zYr.forEach(t),AJe=r(VAe," (LeViT model)"),VAe.forEach(t),LJe=i(L),ym=n(L,"LI",{});var XAe=s(ym);rae=n(XAe,"STRONG",{});var WYr=s(rae);yJe=r(WYr,"longformer"),WYr.forEach(t),xJe=r(XAe," \u2014 "),JS=n(XAe,"A",{href:!0});var QYr=s(JS);$Je=r(QYr,"LongformerConfig"),QYr.forEach(t),kJe=r(XAe," (Longformer model)"),XAe.forEach(t),SJe=i(L),xm=n(L,"LI",{});var zAe=s(xm);tae=n(zAe,"STRONG",{});var HYr=s(tae);RJe=r(HYr,"longt5"),HYr.forEach(t),PJe=r(zAe," \u2014 "),YS=n(zAe,"A",{href:!0});var UYr=s(YS);BJe=r(UYr,"LongT5Config"),UYr.forEach(t),IJe=r(zAe," (LongT5 model)"),zAe.forEach(t),NJe=i(L),$m=n(L,"LI",{});var WAe=s($m);aae=n(WAe,"STRONG",{});var JYr=s(aae);qJe=r(JYr,"luke"),JYr.forEach(t),jJe=r(WAe," \u2014 "),KS=n(WAe,"A",{href:!0});var YYr=s(KS);DJe=r(YYr,"LukeConfig"),YYr.forEach(t),GJe=r(WAe," (LUKE model)"),WAe.forEach(t),OJe=i(L),km=n(L,"LI",{});var QAe=s(km);nae=n(QAe,"STRONG",{});var KYr=s(nae);VJe=r(KYr,"lxmert"),KYr.forEach(t),XJe=r(QAe," \u2014 "),ZS=n(QAe,"A",{href:!0});var ZYr=s(ZS);zJe=r(ZYr,"LxmertConfig"),ZYr.forEach(t),WJe=r(QAe," (LXMERT model)"),QAe.forEach(t),QJe=i(L),Sm=n(L,"LI",{});var HAe=s(Sm);sae=n(HAe,"STRONG",{});var eKr=s(sae);HJe=r(eKr,"m2m_100"),eKr.forEach(t),UJe=r(HAe," \u2014 "),eR=n(HAe,"A",{href:!0});var oKr=s(eR);JJe=r(oKr,"M2M100Config"),oKr.forEach(t),YJe=r(HAe," (M2M100 model)"),HAe.forEach(t),KJe=i(L),Rm=n(L,"LI",{});var UAe=s(Rm);lae=n(UAe,"STRONG",{});var rKr=s(lae);ZJe=r(rKr,"marian"),rKr.forEach(t),eYe=r(UAe," \u2014 "),oR=n(UAe,"A",{href:!0});var tKr=s(oR);oYe=r(tKr,"MarianConfig"),tKr.forEach(t),rYe=r(UAe," (Marian model)"),UAe.forEach(t),tYe=i(L),Pm=n(L,"LI",{});var JAe=s(Pm);iae=n(JAe,"STRONG",{});var aKr=s(iae);aYe=r(aKr,"maskformer"),aKr.forEach(t),nYe=r(JAe," \u2014 "),rR=n(JAe,"A",{href:!0});var nKr=s(rR);sYe=r(nKr,"MaskFormerConfig"),nKr.forEach(t),lYe=r(JAe," (MaskFormer model)"),JAe.forEach(t),iYe=i(L),Bm=n(L,"LI",{});var YAe=s(Bm);dae=n(YAe,"STRONG",{});var sKr=s(dae);dYe=r(sKr,"mbart"),sKr.forEach(t),cYe=r(YAe," \u2014 "),tR=n(YAe,"A",{href:!0});var lKr=s(tR);fYe=r(lKr,"MBartConfig"),lKr.forEach(t),mYe=r(YAe," (mBART model)"),YAe.forEach(t),gYe=i(L),Im=n(L,"LI",{});var KAe=s(Im);cae=n(KAe,"STRONG",{});var iKr=s(cae);hYe=r(iKr,"mctct"),iKr.forEach(t),pYe=r(KAe," \u2014 "),aR=n(KAe,"A",{href:!0});var dKr=s(aR);uYe=r(dKr,"MCTCTConfig"),dKr.forEach(t),_Ye=r(KAe," (M-CTC-T model)"),KAe.forEach(t),bYe=i(L),Nm=n(L,"LI",{});var ZAe=s(Nm);fae=n(ZAe,"STRONG",{});var cKr=s(fae);vYe=r(cKr,"megatron-bert"),cKr.forEach(t),FYe=r(ZAe," \u2014 "),nR=n(ZAe,"A",{href:!0});var fKr=s(nR);TYe=r(fKr,"MegatronBertConfig"),fKr.forEach(t),MYe=r(ZAe," (Megatron-BERT model)"),ZAe.forEach(t),EYe=i(L),qm=n(L,"LI",{});var e6e=s(qm);mae=n(e6e,"STRONG",{});var mKr=s(mae);CYe=r(mKr,"mobilebert"),mKr.forEach(t),wYe=r(e6e," \u2014 "),sR=n(e6e,"A",{href:!0});var gKr=s(sR);AYe=r(gKr,"MobileBertConfig"),gKr.forEach(t),LYe=r(e6e," (MobileBERT model)"),e6e.forEach(t),yYe=i(L),jm=n(L,"LI",{});var o6e=s(jm);gae=n(o6e,"STRONG",{});var hKr=s(gae);xYe=r(hKr,"mpnet"),hKr.forEach(t),$Ye=r(o6e," \u2014 "),lR=n(o6e,"A",{href:!0});var pKr=s(lR);kYe=r(pKr,"MPNetConfig"),pKr.forEach(t),SYe=r(o6e," (MPNet model)"),o6e.forEach(t),RYe=i(L),Dm=n(L,"LI",{});var r6e=s(Dm);hae=n(r6e,"STRONG",{});var uKr=s(hae);PYe=r(uKr,"mt5"),uKr.forEach(t),BYe=r(r6e," \u2014 "),iR=n(r6e,"A",{href:!0});var _Kr=s(iR);IYe=r(_Kr,"MT5Config"),_Kr.forEach(t),NYe=r(r6e," (MT5 model)"),r6e.forEach(t),qYe=i(L),Gm=n(L,"LI",{});var t6e=s(Gm);pae=n(t6e,"STRONG",{});var bKr=s(pae);jYe=r(bKr,"nystromformer"),bKr.forEach(t),DYe=r(t6e," \u2014 "),dR=n(t6e,"A",{href:!0});var vKr=s(dR);GYe=r(vKr,"NystromformerConfig"),vKr.forEach(t),OYe=r(t6e," (Nystr\xF6mformer model)"),t6e.forEach(t),VYe=i(L),Om=n(L,"LI",{});var a6e=s(Om);uae=n(a6e,"STRONG",{});var FKr=s(uae);XYe=r(FKr,"omnivore"),FKr.forEach(t),zYe=r(a6e," \u2014 "),cR=n(a6e,"A",{href:!0});var TKr=s(cR);WYe=r(TKr,"OmnivoreConfig"),TKr.forEach(t),QYe=r(a6e," (Omnivore model)"),a6e.forEach(t),HYe=i(L),Vm=n(L,"LI",{});var n6e=s(Vm);_ae=n(n6e,"STRONG",{});var MKr=s(_ae);UYe=r(MKr,"openai-gpt"),MKr.forEach(t),JYe=r(n6e," \u2014 "),fR=n(n6e,"A",{href:!0});var EKr=s(fR);YYe=r(EKr,"OpenAIGPTConfig"),EKr.forEach(t),KYe=r(n6e," (OpenAI GPT model)"),n6e.forEach(t),ZYe=i(L),Xm=n(L,"LI",{});var s6e=s(Xm);bae=n(s6e,"STRONG",{});var CKr=s(bae);eKe=r(CKr,"opt"),CKr.forEach(t),oKe=r(s6e," \u2014 "),mR=n(s6e,"A",{href:!0});var wKr=s(mR);rKe=r(wKr,"OPTConfig"),wKr.forEach(t),tKe=r(s6e," (OPT model)"),s6e.forEach(t),aKe=i(L),zm=n(L,"LI",{});var l6e=s(zm);vae=n(l6e,"STRONG",{});var AKr=s(vae);nKe=r(AKr,"pegasus"),AKr.forEach(t),sKe=r(l6e," \u2014 "),gR=n(l6e,"A",{href:!0});var LKr=s(gR);lKe=r(LKr,"PegasusConfig"),LKr.forEach(t),iKe=r(l6e," (Pegasus model)"),l6e.forEach(t),dKe=i(L),Wm=n(L,"LI",{});var i6e=s(Wm);Fae=n(i6e,"STRONG",{});var yKr=s(Fae);cKe=r(yKr,"perceiver"),yKr.forEach(t),fKe=r(i6e," \u2014 "),hR=n(i6e,"A",{href:!0});var xKr=s(hR);mKe=r(xKr,"PerceiverConfig"),xKr.forEach(t),gKe=r(i6e," (Perceiver model)"),i6e.forEach(t),hKe=i(L),Qm=n(L,"LI",{});var d6e=s(Qm);Tae=n(d6e,"STRONG",{});var $Kr=s(Tae);pKe=r($Kr,"plbart"),$Kr.forEach(t),uKe=r(d6e," \u2014 "),pR=n(d6e,"A",{href:!0});var kKr=s(pR);_Ke=r(kKr,"PLBartConfig"),kKr.forEach(t),bKe=r(d6e," (PLBart model)"),d6e.forEach(t),vKe=i(L),Hm=n(L,"LI",{});var c6e=s(Hm);Mae=n(c6e,"STRONG",{});var SKr=s(Mae);FKe=r(SKr,"poolformer"),SKr.forEach(t),TKe=r(c6e," \u2014 "),uR=n(c6e,"A",{href:!0});var RKr=s(uR);MKe=r(RKr,"PoolFormerConfig"),RKr.forEach(t),EKe=r(c6e," (PoolFormer model)"),c6e.forEach(t),CKe=i(L),Um=n(L,"LI",{});var f6e=s(Um);Eae=n(f6e,"STRONG",{});var PKr=s(Eae);wKe=r(PKr,"prophetnet"),PKr.forEach(t),AKe=r(f6e," \u2014 "),_R=n(f6e,"A",{href:!0});var BKr=s(_R);LKe=r(BKr,"ProphetNetConfig"),BKr.forEach(t),yKe=r(f6e," (ProphetNet model)"),f6e.forEach(t),xKe=i(L),Jm=n(L,"LI",{});var m6e=s(Jm);Cae=n(m6e,"STRONG",{});var IKr=s(Cae);$Ke=r(IKr,"qdqbert"),IKr.forEach(t),kKe=r(m6e," \u2014 "),bR=n(m6e,"A",{href:!0});var NKr=s(bR);SKe=r(NKr,"QDQBertConfig"),NKr.forEach(t),RKe=r(m6e," (QDQBert model)"),m6e.forEach(t),PKe=i(L),Ym=n(L,"LI",{});var g6e=s(Ym);wae=n(g6e,"STRONG",{});var qKr=s(wae);BKe=r(qKr,"rag"),qKr.forEach(t),IKe=r(g6e," \u2014 "),vR=n(g6e,"A",{href:!0});var jKr=s(vR);NKe=r(jKr,"RagConfig"),jKr.forEach(t),qKe=r(g6e," (RAG model)"),g6e.forEach(t),jKe=i(L),Km=n(L,"LI",{});var h6e=s(Km);Aae=n(h6e,"STRONG",{});var DKr=s(Aae);DKe=r(DKr,"realm"),DKr.forEach(t),GKe=r(h6e," \u2014 "),FR=n(h6e,"A",{href:!0});var GKr=s(FR);OKe=r(GKr,"RealmConfig"),GKr.forEach(t),VKe=r(h6e," (REALM model)"),h6e.forEach(t),XKe=i(L),Zm=n(L,"LI",{});var p6e=s(Zm);Lae=n(p6e,"STRONG",{});var OKr=s(Lae);zKe=r(OKr,"reformer"),OKr.forEach(t),WKe=r(p6e," \u2014 "),TR=n(p6e,"A",{href:!0});var VKr=s(TR);QKe=r(VKr,"ReformerConfig"),VKr.forEach(t),HKe=r(p6e," (Reformer model)"),p6e.forEach(t),UKe=i(L),eg=n(L,"LI",{});var u6e=s(eg);yae=n(u6e,"STRONG",{});var XKr=s(yae);JKe=r(XKr,"regnet"),XKr.forEach(t),YKe=r(u6e," \u2014 "),MR=n(u6e,"A",{href:!0});var zKr=s(MR);KKe=r(zKr,"RegNetConfig"),zKr.forEach(t),ZKe=r(u6e," (RegNet model)"),u6e.forEach(t),eZe=i(L),og=n(L,"LI",{});var _6e=s(og);xae=n(_6e,"STRONG",{});var WKr=s(xae);oZe=r(WKr,"rembert"),WKr.forEach(t),rZe=r(_6e," \u2014 "),ER=n(_6e,"A",{href:!0});var QKr=s(ER);tZe=r(QKr,"RemBertConfig"),QKr.forEach(t),aZe=r(_6e," (RemBERT model)"),_6e.forEach(t),nZe=i(L),rg=n(L,"LI",{});var b6e=s(rg);$ae=n(b6e,"STRONG",{});var HKr=s($ae);sZe=r(HKr,"resnet"),HKr.forEach(t),lZe=r(b6e," \u2014 "),CR=n(b6e,"A",{href:!0});var UKr=s(CR);iZe=r(UKr,"ResNetConfig"),UKr.forEach(t),dZe=r(b6e," (ResNet model)"),b6e.forEach(t),cZe=i(L),tg=n(L,"LI",{});var v6e=s(tg);kae=n(v6e,"STRONG",{});var JKr=s(kae);fZe=r(JKr,"retribert"),JKr.forEach(t),mZe=r(v6e," \u2014 "),wR=n(v6e,"A",{href:!0});var YKr=s(wR);gZe=r(YKr,"RetriBertConfig"),YKr.forEach(t),hZe=r(v6e," (RetriBERT model)"),v6e.forEach(t),pZe=i(L),ag=n(L,"LI",{});var F6e=s(ag);Sae=n(F6e,"STRONG",{});var KKr=s(Sae);uZe=r(KKr,"roberta"),KKr.forEach(t),_Ze=r(F6e," \u2014 "),AR=n(F6e,"A",{href:!0});var ZKr=s(AR);bZe=r(ZKr,"RobertaConfig"),ZKr.forEach(t),vZe=r(F6e," (RoBERTa model)"),F6e.forEach(t),FZe=i(L),ng=n(L,"LI",{});var T6e=s(ng);Rae=n(T6e,"STRONG",{});var eZr=s(Rae);TZe=r(eZr,"roformer"),eZr.forEach(t),MZe=r(T6e," \u2014 "),LR=n(T6e,"A",{href:!0});var oZr=s(LR);EZe=r(oZr,"RoFormerConfig"),oZr.forEach(t),CZe=r(T6e," (RoFormer model)"),T6e.forEach(t),wZe=i(L),sg=n(L,"LI",{});var M6e=s(sg);Pae=n(M6e,"STRONG",{});var rZr=s(Pae);AZe=r(rZr,"segformer"),rZr.forEach(t),LZe=r(M6e," \u2014 "),yR=n(M6e,"A",{href:!0});var tZr=s(yR);yZe=r(tZr,"SegformerConfig"),tZr.forEach(t),xZe=r(M6e," (SegFormer model)"),M6e.forEach(t),$Ze=i(L),lg=n(L,"LI",{});var E6e=s(lg);Bae=n(E6e,"STRONG",{});var aZr=s(Bae);kZe=r(aZr,"sew"),aZr.forEach(t),SZe=r(E6e," \u2014 "),xR=n(E6e,"A",{href:!0});var nZr=s(xR);RZe=r(nZr,"SEWConfig"),nZr.forEach(t),PZe=r(E6e," (SEW model)"),E6e.forEach(t),BZe=i(L),ig=n(L,"LI",{});var C6e=s(ig);Iae=n(C6e,"STRONG",{});var sZr=s(Iae);IZe=r(sZr,"sew-d"),sZr.forEach(t),NZe=r(C6e," \u2014 "),$R=n(C6e,"A",{href:!0});var lZr=s($R);qZe=r(lZr,"SEWDConfig"),lZr.forEach(t),jZe=r(C6e," (SEW-D model)"),C6e.forEach(t),DZe=i(L),dg=n(L,"LI",{});var w6e=s(dg);Nae=n(w6e,"STRONG",{});var iZr=s(Nae);GZe=r(iZr,"speech-encoder-decoder"),iZr.forEach(t),OZe=r(w6e," \u2014 "),kR=n(w6e,"A",{href:!0});var dZr=s(kR);VZe=r(dZr,"SpeechEncoderDecoderConfig"),dZr.forEach(t),XZe=r(w6e," (Speech Encoder decoder model)"),w6e.forEach(t),zZe=i(L),cg=n(L,"LI",{});var A6e=s(cg);qae=n(A6e,"STRONG",{});var cZr=s(qae);WZe=r(cZr,"speech_to_text"),cZr.forEach(t),QZe=r(A6e," \u2014 "),SR=n(A6e,"A",{href:!0});var fZr=s(SR);HZe=r(fZr,"Speech2TextConfig"),fZr.forEach(t),UZe=r(A6e," (Speech2Text model)"),A6e.forEach(t),JZe=i(L),fg=n(L,"LI",{});var L6e=s(fg);jae=n(L6e,"STRONG",{});var mZr=s(jae);YZe=r(mZr,"speech_to_text_2"),mZr.forEach(t),KZe=r(L6e," \u2014 "),RR=n(L6e,"A",{href:!0});var gZr=s(RR);ZZe=r(gZr,"Speech2Text2Config"),gZr.forEach(t),eeo=r(L6e," (Speech2Text2 model)"),L6e.forEach(t),oeo=i(L),mg=n(L,"LI",{});var y6e=s(mg);Dae=n(y6e,"STRONG",{});var hZr=s(Dae);reo=r(hZr,"splinter"),hZr.forEach(t),teo=r(y6e," \u2014 "),PR=n(y6e,"A",{href:!0});var pZr=s(PR);aeo=r(pZr,"SplinterConfig"),pZr.forEach(t),neo=r(y6e," (Splinter model)"),y6e.forEach(t),seo=i(L),gg=n(L,"LI",{});var x6e=s(gg);Gae=n(x6e,"STRONG",{});var uZr=s(Gae);leo=r(uZr,"squeezebert"),uZr.forEach(t),ieo=r(x6e," \u2014 "),BR=n(x6e,"A",{href:!0});var _Zr=s(BR);deo=r(_Zr,"SqueezeBertConfig"),_Zr.forEach(t),ceo=r(x6e," (SqueezeBERT model)"),x6e.forEach(t),feo=i(L),hg=n(L,"LI",{});var $6e=s(hg);Oae=n($6e,"STRONG",{});var bZr=s(Oae);meo=r(bZr,"swin"),bZr.forEach(t),geo=r($6e," \u2014 "),IR=n($6e,"A",{href:!0});var vZr=s(IR);heo=r(vZr,"SwinConfig"),vZr.forEach(t),peo=r($6e," (Swin Transformer model)"),$6e.forEach(t),ueo=i(L),pg=n(L,"LI",{});var k6e=s(pg);Vae=n(k6e,"STRONG",{});var FZr=s(Vae);_eo=r(FZr,"t5"),FZr.forEach(t),beo=r(k6e," \u2014 "),NR=n(k6e,"A",{href:!0});var TZr=s(NR);veo=r(TZr,"T5Config"),TZr.forEach(t),Feo=r(k6e," (T5 model)"),k6e.forEach(t),Teo=i(L),ug=n(L,"LI",{});var S6e=s(ug);Xae=n(S6e,"STRONG",{});var MZr=s(Xae);Meo=r(MZr,"tapas"),MZr.forEach(t),Eeo=r(S6e," \u2014 "),qR=n(S6e,"A",{href:!0});var EZr=s(qR);Ceo=r(EZr,"TapasConfig"),EZr.forEach(t),weo=r(S6e," (TAPAS model)"),S6e.forEach(t),Aeo=i(L),_g=n(L,"LI",{});var R6e=s(_g);zae=n(R6e,"STRONG",{});var CZr=s(zae);Leo=r(CZr,"trajectory_transformer"),CZr.forEach(t),yeo=r(R6e," \u2014 "),jR=n(R6e,"A",{href:!0});var wZr=s(jR);xeo=r(wZr,"TrajectoryTransformerConfig"),wZr.forEach(t),$eo=r(R6e," (Trajectory Transformer model)"),R6e.forEach(t),keo=i(L),bg=n(L,"LI",{});var P6e=s(bg);Wae=n(P6e,"STRONG",{});var AZr=s(Wae);Seo=r(AZr,"transfo-xl"),AZr.forEach(t),Reo=r(P6e," \u2014 "),DR=n(P6e,"A",{href:!0});var LZr=s(DR);Peo=r(LZr,"TransfoXLConfig"),LZr.forEach(t),Beo=r(P6e," (Transformer-XL model)"),P6e.forEach(t),Ieo=i(L),vg=n(L,"LI",{});var B6e=s(vg);Qae=n(B6e,"STRONG",{});var yZr=s(Qae);Neo=r(yZr,"trocr"),yZr.forEach(t),qeo=r(B6e," \u2014 "),GR=n(B6e,"A",{href:!0});var xZr=s(GR);jeo=r(xZr,"TrOCRConfig"),xZr.forEach(t),Deo=r(B6e," (TrOCR model)"),B6e.forEach(t),Geo=i(L),Fg=n(L,"LI",{});var I6e=s(Fg);Hae=n(I6e,"STRONG",{});var $Zr=s(Hae);Oeo=r($Zr,"unispeech"),$Zr.forEach(t),Veo=r(I6e," \u2014 "),OR=n(I6e,"A",{href:!0});var kZr=s(OR);Xeo=r(kZr,"UniSpeechConfig"),kZr.forEach(t),zeo=r(I6e," (UniSpeech model)"),I6e.forEach(t),Weo=i(L),Tg=n(L,"LI",{});var N6e=s(Tg);Uae=n(N6e,"STRONG",{});var SZr=s(Uae);Qeo=r(SZr,"unispeech-sat"),SZr.forEach(t),Heo=r(N6e," \u2014 "),VR=n(N6e,"A",{href:!0});var RZr=s(VR);Ueo=r(RZr,"UniSpeechSatConfig"),RZr.forEach(t),Jeo=r(N6e," (UniSpeechSat model)"),N6e.forEach(t),Yeo=i(L),Mg=n(L,"LI",{});var q6e=s(Mg);Jae=n(q6e,"STRONG",{});var PZr=s(Jae);Keo=r(PZr,"van"),PZr.forEach(t),Zeo=r(q6e," \u2014 "),XR=n(q6e,"A",{href:!0});var BZr=s(XR);eoo=r(BZr,"VanConfig"),BZr.forEach(t),ooo=r(q6e," (VAN model)"),q6e.forEach(t),roo=i(L),Eg=n(L,"LI",{});var j6e=s(Eg);Yae=n(j6e,"STRONG",{});var IZr=s(Yae);too=r(IZr,"vilt"),IZr.forEach(t),aoo=r(j6e," \u2014 "),zR=n(j6e,"A",{href:!0});var NZr=s(zR);noo=r(NZr,"ViltConfig"),NZr.forEach(t),soo=r(j6e," (ViLT model)"),j6e.forEach(t),loo=i(L),Cg=n(L,"LI",{});var D6e=s(Cg);Kae=n(D6e,"STRONG",{});var qZr=s(Kae);ioo=r(qZr,"vision-encoder-decoder"),qZr.forEach(t),doo=r(D6e," \u2014 "),WR=n(D6e,"A",{href:!0});var jZr=s(WR);coo=r(jZr,"VisionEncoderDecoderConfig"),jZr.forEach(t),foo=r(D6e," (Vision Encoder decoder model)"),D6e.forEach(t),moo=i(L),wg=n(L,"LI",{});var G6e=s(wg);Zae=n(G6e,"STRONG",{});var DZr=s(Zae);goo=r(DZr,"vision-text-dual-encoder"),DZr.forEach(t),hoo=r(G6e," \u2014 "),QR=n(G6e,"A",{href:!0});var GZr=s(QR);poo=r(GZr,"VisionTextDualEncoderConfig"),GZr.forEach(t),uoo=r(G6e," (VisionTextDualEncoder model)"),G6e.forEach(t),_oo=i(L),Ag=n(L,"LI",{});var O6e=s(Ag);ene=n(O6e,"STRONG",{});var OZr=s(ene);boo=r(OZr,"visual_bert"),OZr.forEach(t),voo=r(O6e," \u2014 "),HR=n(O6e,"A",{href:!0});var VZr=s(HR);Foo=r(VZr,"VisualBertConfig"),VZr.forEach(t),Too=r(O6e," (VisualBERT model)"),O6e.forEach(t),Moo=i(L),Lg=n(L,"LI",{});var V6e=s(Lg);one=n(V6e,"STRONG",{});var XZr=s(one);Eoo=r(XZr,"vit"),XZr.forEach(t),Coo=r(V6e," \u2014 "),UR=n(V6e,"A",{href:!0});var zZr=s(UR);woo=r(zZr,"ViTConfig"),zZr.forEach(t),Aoo=r(V6e," (ViT model)"),V6e.forEach(t),Loo=i(L),yg=n(L,"LI",{});var X6e=s(yg);rne=n(X6e,"STRONG",{});var WZr=s(rne);yoo=r(WZr,"vit_mae"),WZr.forEach(t),xoo=r(X6e," \u2014 "),JR=n(X6e,"A",{href:!0});var QZr=s(JR);$oo=r(QZr,"ViTMAEConfig"),QZr.forEach(t),koo=r(X6e," (ViTMAE model)"),X6e.forEach(t),Soo=i(L),xg=n(L,"LI",{});var z6e=s(xg);tne=n(z6e,"STRONG",{});var HZr=s(tne);Roo=r(HZr,"wav2vec2"),HZr.forEach(t),Poo=r(z6e," \u2014 "),YR=n(z6e,"A",{href:!0});var UZr=s(YR);Boo=r(UZr,"Wav2Vec2Config"),UZr.forEach(t),Ioo=r(z6e," (Wav2Vec2 model)"),z6e.forEach(t),Noo=i(L),$g=n(L,"LI",{});var W6e=s($g);ane=n(W6e,"STRONG",{});var JZr=s(ane);qoo=r(JZr,"wav2vec2-conformer"),JZr.forEach(t),joo=r(W6e," \u2014 "),KR=n(W6e,"A",{href:!0});var YZr=s(KR);Doo=r(YZr,"Wav2Vec2ConformerConfig"),YZr.forEach(t),Goo=r(W6e," (Wav2Vec2-Conformer model)"),W6e.forEach(t),Ooo=i(L),kg=n(L,"LI",{});var Q6e=s(kg);nne=n(Q6e,"STRONG",{});var KZr=s(nne);Voo=r(KZr,"wavlm"),KZr.forEach(t),Xoo=r(Q6e," \u2014 "),ZR=n(Q6e,"A",{href:!0});var ZZr=s(ZR);zoo=r(ZZr,"WavLMConfig"),ZZr.forEach(t),Woo=r(Q6e," (WavLM model)"),Q6e.forEach(t),Qoo=i(L),Sg=n(L,"LI",{});var H6e=s(Sg);sne=n(H6e,"STRONG",{});var eet=s(sne);Hoo=r(eet,"xglm"),eet.forEach(t),Uoo=r(H6e," \u2014 "),eP=n(H6e,"A",{href:!0});var oet=s(eP);Joo=r(oet,"XGLMConfig"),oet.forEach(t),Yoo=r(H6e," (XGLM model)"),H6e.forEach(t),Koo=i(L),Rg=n(L,"LI",{});var U6e=s(Rg);lne=n(U6e,"STRONG",{});var ret=s(lne);Zoo=r(ret,"xlm"),ret.forEach(t),ero=r(U6e," \u2014 "),oP=n(U6e,"A",{href:!0});var tet=s(oP);oro=r(tet,"XLMConfig"),tet.forEach(t),rro=r(U6e," (XLM model)"),U6e.forEach(t),tro=i(L),Pg=n(L,"LI",{});var J6e=s(Pg);ine=n(J6e,"STRONG",{});var aet=s(ine);aro=r(aet,"xlm-prophetnet"),aet.forEach(t),nro=r(J6e," \u2014 "),rP=n(J6e,"A",{href:!0});var net=s(rP);sro=r(net,"XLMProphetNetConfig"),net.forEach(t),lro=r(J6e," (XLM-ProphetNet model)"),J6e.forEach(t),iro=i(L),Bg=n(L,"LI",{});var Y6e=s(Bg);dne=n(Y6e,"STRONG",{});var set=s(dne);dro=r(set,"xlm-roberta"),set.forEach(t),cro=r(Y6e," \u2014 "),tP=n(Y6e,"A",{href:!0});var iet=s(tP);fro=r(iet,"XLMRobertaConfig"),iet.forEach(t),mro=r(Y6e," (XLM-RoBERTa model)"),Y6e.forEach(t),gro=i(L),Ig=n(L,"LI",{});var K6e=s(Ig);cne=n(K6e,"STRONG",{});var det=s(cne);hro=r(det,"xlm-roberta-xl"),det.forEach(t),pro=r(K6e," \u2014 "),aP=n(K6e,"A",{href:!0});var cet=s(aP);uro=r(cet,"XLMRobertaXLConfig"),cet.forEach(t),_ro=r(K6e," (XLM-RoBERTa-XL model)"),K6e.forEach(t),bro=i(L),Ng=n(L,"LI",{});var Z6e=s(Ng);fne=n(Z6e,"STRONG",{});var fet=s(fne);vro=r(fet,"xlnet"),fet.forEach(t),Fro=r(Z6e," \u2014 "),nP=n(Z6e,"A",{href:!0});var met=s(nP);Tro=r(met,"XLNetConfig"),met.forEach(t),Mro=r(Z6e," (XLNet model)"),Z6e.forEach(t),Ero=i(L),qg=n(L,"LI",{});var eLe=s(qg);mne=n(eLe,"STRONG",{});var get=s(mne);Cro=r(get,"yolos"),get.forEach(t),wro=r(eLe," \u2014 "),sP=n(eLe,"A",{href:!0});var het=s(sP);Aro=r(het,"YolosConfig"),het.forEach(t),Lro=r(eLe," (YOLOS model)"),eLe.forEach(t),yro=i(L),jg=n(L,"LI",{});var oLe=s(jg);gne=n(oLe,"STRONG",{});var pet=s(gne);xro=r(pet,"yoso"),pet.forEach(t),$ro=r(oLe," \u2014 "),lP=n(oLe,"A",{href:!0});var uet=s(lP);kro=r(uet,"YosoConfig"),uet.forEach(t),Sro=r(oLe," (YOSO model)"),oLe.forEach(t),L.forEach(t),Rro=i(tt),T(Dg.$$.fragment,tt),tt.forEach(t),Pro=i(rt),Gg=n(rt,"DIV",{class:!0});var FVe=s(Gg);T($L.$$.fragment,FVe),Bro=i(FVe),hne=n(FVe,"P",{});var _et=s(hne);Iro=r(_et,"Register a new configuration for this class."),_et.forEach(t),FVe.forEach(t),rt.forEach(t),TGe=i(f),$i=n(f,"H2",{class:!0});var TVe=s($i);Og=n(TVe,"A",{id:!0,class:!0,href:!0});var bet=s(Og);pne=n(bet,"SPAN",{});var vet=s(pne);T(kL.$$.fragment,vet),vet.forEach(t),bet.forEach(t),Nro=i(TVe),une=n(TVe,"SPAN",{});var Fet=s(une);qro=r(Fet,"AutoTokenizer"),Fet.forEach(t),TVe.forEach(t),MGe=i(f),Ao=n(f,"DIV",{class:!0});var zs=s(Ao);T(SL.$$.fragment,zs),jro=i(zs),RL=n(zs,"P",{});var MVe=s(RL);Dro=r(MVe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),iP=n(MVe,"A",{href:!0});var Tet=s(iP);Gro=r(Tet,"AutoTokenizer.from_pretrained()"),Tet.forEach(t),Oro=r(MVe," class method."),MVe.forEach(t),Vro=i(zs),PL=n(zs,"P",{});var EVe=s(PL);Xro=r(EVe,"This class cannot be instantiated directly using "),_ne=n(EVe,"CODE",{});var Met=s(_ne);zro=r(Met,"__init__()"),Met.forEach(t),Wro=r(EVe," (throws an error)."),EVe.forEach(t),Qro=i(zs),Ar=n(zs,"DIV",{class:!0});var Ws=s(Ar);T(BL.$$.fragment,Ws),Hro=i(Ws),bne=n(Ws,"P",{});var Eet=s(bne);Uro=r(Eet,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Eet.forEach(t),Jro=i(Ws),$a=n(Ws,"P",{});var EA=s($a);Yro=r(EA,"The tokenizer class to instantiate is selected based on the "),vne=n(EA,"CODE",{});var Cet=s(vne);Kro=r(Cet,"model_type"),Cet.forEach(t),Zro=r(EA,` property of the config object (either
passed as an argument or loaded from `),Fne=n(EA,"CODE",{});var wet=s(Fne);eto=r(wet,"pretrained_model_name_or_path"),wet.forEach(t),oto=r(EA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tne=n(EA,"CODE",{});var Aet=s(Tne);rto=r(Aet,"pretrained_model_name_or_path"),Aet.forEach(t),tto=r(EA,":"),EA.forEach(t),ato=i(Ws),k=n(Ws,"UL",{});var S=s(k);Nn=n(S,"LI",{});var G$=s(Nn);Mne=n(G$,"STRONG",{});var Let=s(Mne);nto=r(Let,"albert"),Let.forEach(t),sto=r(G$," \u2014 "),dP=n(G$,"A",{href:!0});var yet=s(dP);lto=r(yet,"AlbertTokenizer"),yet.forEach(t),ito=r(G$," or "),cP=n(G$,"A",{href:!0});var xet=s(cP);dto=r(xet,"AlbertTokenizerFast"),xet.forEach(t),cto=r(G$," (ALBERT model)"),G$.forEach(t),fto=i(S),qn=n(S,"LI",{});var O$=s(qn);Ene=n(O$,"STRONG",{});var $et=s(Ene);mto=r($et,"bart"),$et.forEach(t),gto=r(O$," \u2014 "),fP=n(O$,"A",{href:!0});var ket=s(fP);hto=r(ket,"BartTokenizer"),ket.forEach(t),pto=r(O$," or "),mP=n(O$,"A",{href:!0});var Set=s(mP);uto=r(Set,"BartTokenizerFast"),Set.forEach(t),_to=r(O$," (BART model)"),O$.forEach(t),bto=i(S),jn=n(S,"LI",{});var V$=s(jn);Cne=n(V$,"STRONG",{});var Ret=s(Cne);vto=r(Ret,"barthez"),Ret.forEach(t),Fto=r(V$," \u2014 "),gP=n(V$,"A",{href:!0});var Pet=s(gP);Tto=r(Pet,"BarthezTokenizer"),Pet.forEach(t),Mto=r(V$," or "),hP=n(V$,"A",{href:!0});var Bet=s(hP);Eto=r(Bet,"BarthezTokenizerFast"),Bet.forEach(t),Cto=r(V$," (BARThez model)"),V$.forEach(t),wto=i(S),Vg=n(S,"LI",{});var rLe=s(Vg);wne=n(rLe,"STRONG",{});var Iet=s(wne);Ato=r(Iet,"bartpho"),Iet.forEach(t),Lto=r(rLe," \u2014 "),pP=n(rLe,"A",{href:!0});var Net=s(pP);yto=r(Net,"BartphoTokenizer"),Net.forEach(t),xto=r(rLe," (BARTpho model)"),rLe.forEach(t),$to=i(S),Dn=n(S,"LI",{});var X$=s(Dn);Ane=n(X$,"STRONG",{});var qet=s(Ane);kto=r(qet,"bert"),qet.forEach(t),Sto=r(X$," \u2014 "),uP=n(X$,"A",{href:!0});var jet=s(uP);Rto=r(jet,"BertTokenizer"),jet.forEach(t),Pto=r(X$," or "),_P=n(X$,"A",{href:!0});var Det=s(_P);Bto=r(Det,"BertTokenizerFast"),Det.forEach(t),Ito=r(X$," (BERT model)"),X$.forEach(t),Nto=i(S),Xg=n(S,"LI",{});var tLe=s(Xg);Lne=n(tLe,"STRONG",{});var Get=s(Lne);qto=r(Get,"bert-generation"),Get.forEach(t),jto=r(tLe," \u2014 "),bP=n(tLe,"A",{href:!0});var Oet=s(bP);Dto=r(Oet,"BertGenerationTokenizer"),Oet.forEach(t),Gto=r(tLe," (Bert Generation model)"),tLe.forEach(t),Oto=i(S),zg=n(S,"LI",{});var aLe=s(zg);yne=n(aLe,"STRONG",{});var Vet=s(yne);Vto=r(Vet,"bert-japanese"),Vet.forEach(t),Xto=r(aLe," \u2014 "),vP=n(aLe,"A",{href:!0});var Xet=s(vP);zto=r(Xet,"BertJapaneseTokenizer"),Xet.forEach(t),Wto=r(aLe," (BertJapanese model)"),aLe.forEach(t),Qto=i(S),Wg=n(S,"LI",{});var nLe=s(Wg);xne=n(nLe,"STRONG",{});var zet=s(xne);Hto=r(zet,"bertweet"),zet.forEach(t),Uto=r(nLe," \u2014 "),FP=n(nLe,"A",{href:!0});var Wet=s(FP);Jto=r(Wet,"BertweetTokenizer"),Wet.forEach(t),Yto=r(nLe," (BERTweet model)"),nLe.forEach(t),Kto=i(S),Gn=n(S,"LI",{});var z$=s(Gn);$ne=n(z$,"STRONG",{});var Qet=s($ne);Zto=r(Qet,"big_bird"),Qet.forEach(t),eao=r(z$," \u2014 "),TP=n(z$,"A",{href:!0});var Het=s(TP);oao=r(Het,"BigBirdTokenizer"),Het.forEach(t),rao=r(z$," or "),MP=n(z$,"A",{href:!0});var Uet=s(MP);tao=r(Uet,"BigBirdTokenizerFast"),Uet.forEach(t),aao=r(z$," (BigBird model)"),z$.forEach(t),nao=i(S),On=n(S,"LI",{});var W$=s(On);kne=n(W$,"STRONG",{});var Jet=s(kne);sao=r(Jet,"bigbird_pegasus"),Jet.forEach(t),lao=r(W$," \u2014 "),EP=n(W$,"A",{href:!0});var Yet=s(EP);iao=r(Yet,"PegasusTokenizer"),Yet.forEach(t),dao=r(W$," or "),CP=n(W$,"A",{href:!0});var Ket=s(CP);cao=r(Ket,"PegasusTokenizerFast"),Ket.forEach(t),fao=r(W$," (BigBird-Pegasus model)"),W$.forEach(t),mao=i(S),Vn=n(S,"LI",{});var Q$=s(Vn);Sne=n(Q$,"STRONG",{});var Zet=s(Sne);gao=r(Zet,"blenderbot"),Zet.forEach(t),hao=r(Q$," \u2014 "),wP=n(Q$,"A",{href:!0});var eot=s(wP);pao=r(eot,"BlenderbotTokenizer"),eot.forEach(t),uao=r(Q$," or "),AP=n(Q$,"A",{href:!0});var oot=s(AP);_ao=r(oot,"BlenderbotTokenizerFast"),oot.forEach(t),bao=r(Q$," (Blenderbot model)"),Q$.forEach(t),vao=i(S),Qg=n(S,"LI",{});var sLe=s(Qg);Rne=n(sLe,"STRONG",{});var rot=s(Rne);Fao=r(rot,"blenderbot-small"),rot.forEach(t),Tao=r(sLe," \u2014 "),LP=n(sLe,"A",{href:!0});var tot=s(LP);Mao=r(tot,"BlenderbotSmallTokenizer"),tot.forEach(t),Eao=r(sLe," (BlenderbotSmall model)"),sLe.forEach(t),Cao=i(S),Hg=n(S,"LI",{});var lLe=s(Hg);Pne=n(lLe,"STRONG",{});var aot=s(Pne);wao=r(aot,"bloom"),aot.forEach(t),Aao=r(lLe," \u2014 "),yP=n(lLe,"A",{href:!0});var not=s(yP);Lao=r(not,"BloomTokenizerFast"),not.forEach(t),yao=r(lLe," (BLOOM model)"),lLe.forEach(t),xao=i(S),Ug=n(S,"LI",{});var iLe=s(Ug);Bne=n(iLe,"STRONG",{});var sot=s(Bne);$ao=r(sot,"byt5"),sot.forEach(t),kao=r(iLe," \u2014 "),xP=n(iLe,"A",{href:!0});var lot=s(xP);Sao=r(lot,"ByT5Tokenizer"),lot.forEach(t),Rao=r(iLe," (ByT5 model)"),iLe.forEach(t),Pao=i(S),Xn=n(S,"LI",{});var H$=s(Xn);Ine=n(H$,"STRONG",{});var iot=s(Ine);Bao=r(iot,"camembert"),iot.forEach(t),Iao=r(H$," \u2014 "),$P=n(H$,"A",{href:!0});var dot=s($P);Nao=r(dot,"CamembertTokenizer"),dot.forEach(t),qao=r(H$," or "),kP=n(H$,"A",{href:!0});var cot=s(kP);jao=r(cot,"CamembertTokenizerFast"),cot.forEach(t),Dao=r(H$," (CamemBERT model)"),H$.forEach(t),Gao=i(S),Jg=n(S,"LI",{});var dLe=s(Jg);Nne=n(dLe,"STRONG",{});var fot=s(Nne);Oao=r(fot,"canine"),fot.forEach(t),Vao=r(dLe," \u2014 "),SP=n(dLe,"A",{href:!0});var mot=s(SP);Xao=r(mot,"CanineTokenizer"),mot.forEach(t),zao=r(dLe," (CANINE model)"),dLe.forEach(t),Wao=i(S),zn=n(S,"LI",{});var U$=s(zn);qne=n(U$,"STRONG",{});var got=s(qne);Qao=r(got,"clip"),got.forEach(t),Hao=r(U$," \u2014 "),RP=n(U$,"A",{href:!0});var hot=s(RP);Uao=r(hot,"CLIPTokenizer"),hot.forEach(t),Jao=r(U$," or "),PP=n(U$,"A",{href:!0});var pot=s(PP);Yao=r(pot,"CLIPTokenizerFast"),pot.forEach(t),Kao=r(U$," (CLIP model)"),U$.forEach(t),Zao=i(S),Wn=n(S,"LI",{});var J$=s(Wn);jne=n(J$,"STRONG",{});var uot=s(jne);eno=r(uot,"convbert"),uot.forEach(t),ono=r(J$," \u2014 "),BP=n(J$,"A",{href:!0});var _ot=s(BP);rno=r(_ot,"ConvBertTokenizer"),_ot.forEach(t),tno=r(J$," or "),IP=n(J$,"A",{href:!0});var bot=s(IP);ano=r(bot,"ConvBertTokenizerFast"),bot.forEach(t),nno=r(J$," (ConvBERT model)"),J$.forEach(t),sno=i(S),Qn=n(S,"LI",{});var Y$=s(Qn);Dne=n(Y$,"STRONG",{});var vot=s(Dne);lno=r(vot,"cpm"),vot.forEach(t),ino=r(Y$," \u2014 "),NP=n(Y$,"A",{href:!0});var Fot=s(NP);dno=r(Fot,"CpmTokenizer"),Fot.forEach(t),cno=r(Y$," or "),qP=n(Y$,"A",{href:!0});var Tot=s(qP);fno=r(Tot,"CpmTokenizerFast"),Tot.forEach(t),mno=r(Y$," (CPM model)"),Y$.forEach(t),gno=i(S),Yg=n(S,"LI",{});var cLe=s(Yg);Gne=n(cLe,"STRONG",{});var Mot=s(Gne);hno=r(Mot,"ctrl"),Mot.forEach(t),pno=r(cLe," \u2014 "),jP=n(cLe,"A",{href:!0});var Eot=s(jP);uno=r(Eot,"CTRLTokenizer"),Eot.forEach(t),_no=r(cLe," (CTRL model)"),cLe.forEach(t),bno=i(S),Hn=n(S,"LI",{});var K$=s(Hn);One=n(K$,"STRONG",{});var Cot=s(One);vno=r(Cot,"data2vec-text"),Cot.forEach(t),Fno=r(K$," \u2014 "),DP=n(K$,"A",{href:!0});var wot=s(DP);Tno=r(wot,"RobertaTokenizer"),wot.forEach(t),Mno=r(K$," or "),GP=n(K$,"A",{href:!0});var Aot=s(GP);Eno=r(Aot,"RobertaTokenizerFast"),Aot.forEach(t),Cno=r(K$," (Data2VecText model)"),K$.forEach(t),wno=i(S),Un=n(S,"LI",{});var Z$=s(Un);Vne=n(Z$,"STRONG",{});var Lot=s(Vne);Ano=r(Lot,"deberta"),Lot.forEach(t),Lno=r(Z$," \u2014 "),OP=n(Z$,"A",{href:!0});var yot=s(OP);yno=r(yot,"DebertaTokenizer"),yot.forEach(t),xno=r(Z$," or "),VP=n(Z$,"A",{href:!0});var xot=s(VP);$no=r(xot,"DebertaTokenizerFast"),xot.forEach(t),kno=r(Z$," (DeBERTa model)"),Z$.forEach(t),Sno=i(S),Jn=n(S,"LI",{});var ek=s(Jn);Xne=n(ek,"STRONG",{});var $ot=s(Xne);Rno=r($ot,"deberta-v2"),$ot.forEach(t),Pno=r(ek," \u2014 "),XP=n(ek,"A",{href:!0});var kot=s(XP);Bno=r(kot,"DebertaV2Tokenizer"),kot.forEach(t),Ino=r(ek," or "),zP=n(ek,"A",{href:!0});var Sot=s(zP);Nno=r(Sot,"DebertaV2TokenizerFast"),Sot.forEach(t),qno=r(ek," (DeBERTa-v2 model)"),ek.forEach(t),jno=i(S),Yn=n(S,"LI",{});var ok=s(Yn);zne=n(ok,"STRONG",{});var Rot=s(zne);Dno=r(Rot,"distilbert"),Rot.forEach(t),Gno=r(ok," \u2014 "),WP=n(ok,"A",{href:!0});var Pot=s(WP);Ono=r(Pot,"DistilBertTokenizer"),Pot.forEach(t),Vno=r(ok," or "),QP=n(ok,"A",{href:!0});var Bot=s(QP);Xno=r(Bot,"DistilBertTokenizerFast"),Bot.forEach(t),zno=r(ok," (DistilBERT model)"),ok.forEach(t),Wno=i(S),Kn=n(S,"LI",{});var rk=s(Kn);Wne=n(rk,"STRONG",{});var Iot=s(Wne);Qno=r(Iot,"dpr"),Iot.forEach(t),Hno=r(rk," \u2014 "),HP=n(rk,"A",{href:!0});var Not=s(HP);Uno=r(Not,"DPRQuestionEncoderTokenizer"),Not.forEach(t),Jno=r(rk," or "),UP=n(rk,"A",{href:!0});var qot=s(UP);Yno=r(qot,"DPRQuestionEncoderTokenizerFast"),qot.forEach(t),Kno=r(rk," (DPR model)"),rk.forEach(t),Zno=i(S),Zn=n(S,"LI",{});var tk=s(Zn);Qne=n(tk,"STRONG",{});var jot=s(Qne);eso=r(jot,"electra"),jot.forEach(t),oso=r(tk," \u2014 "),JP=n(tk,"A",{href:!0});var Dot=s(JP);rso=r(Dot,"ElectraTokenizer"),Dot.forEach(t),tso=r(tk," or "),YP=n(tk,"A",{href:!0});var Got=s(YP);aso=r(Got,"ElectraTokenizerFast"),Got.forEach(t),nso=r(tk," (ELECTRA model)"),tk.forEach(t),sso=i(S),Kg=n(S,"LI",{});var fLe=s(Kg);Hne=n(fLe,"STRONG",{});var Oot=s(Hne);lso=r(Oot,"flaubert"),Oot.forEach(t),iso=r(fLe," \u2014 "),KP=n(fLe,"A",{href:!0});var Vot=s(KP);dso=r(Vot,"FlaubertTokenizer"),Vot.forEach(t),cso=r(fLe," (FlauBERT model)"),fLe.forEach(t),fso=i(S),es=n(S,"LI",{});var ak=s(es);Une=n(ak,"STRONG",{});var Xot=s(Une);mso=r(Xot,"fnet"),Xot.forEach(t),gso=r(ak," \u2014 "),ZP=n(ak,"A",{href:!0});var zot=s(ZP);hso=r(zot,"FNetTokenizer"),zot.forEach(t),pso=r(ak," or "),eB=n(ak,"A",{href:!0});var Wot=s(eB);uso=r(Wot,"FNetTokenizerFast"),Wot.forEach(t),_so=r(ak," (FNet model)"),ak.forEach(t),bso=i(S),Zg=n(S,"LI",{});var mLe=s(Zg);Jne=n(mLe,"STRONG",{});var Qot=s(Jne);vso=r(Qot,"fsmt"),Qot.forEach(t),Fso=r(mLe," \u2014 "),oB=n(mLe,"A",{href:!0});var Hot=s(oB);Tso=r(Hot,"FSMTTokenizer"),Hot.forEach(t),Mso=r(mLe," (FairSeq Machine-Translation model)"),mLe.forEach(t),Eso=i(S),os=n(S,"LI",{});var nk=s(os);Yne=n(nk,"STRONG",{});var Uot=s(Yne);Cso=r(Uot,"funnel"),Uot.forEach(t),wso=r(nk," \u2014 "),rB=n(nk,"A",{href:!0});var Jot=s(rB);Aso=r(Jot,"FunnelTokenizer"),Jot.forEach(t),Lso=r(nk," or "),tB=n(nk,"A",{href:!0});var Yot=s(tB);yso=r(Yot,"FunnelTokenizerFast"),Yot.forEach(t),xso=r(nk," (Funnel Transformer model)"),nk.forEach(t),$so=i(S),rs=n(S,"LI",{});var sk=s(rs);Kne=n(sk,"STRONG",{});var Kot=s(Kne);kso=r(Kot,"gpt2"),Kot.forEach(t),Sso=r(sk," \u2014 "),aB=n(sk,"A",{href:!0});var Zot=s(aB);Rso=r(Zot,"GPT2Tokenizer"),Zot.forEach(t),Pso=r(sk," or "),nB=n(sk,"A",{href:!0});var ert=s(nB);Bso=r(ert,"GPT2TokenizerFast"),ert.forEach(t),Iso=r(sk," (OpenAI GPT-2 model)"),sk.forEach(t),Nso=i(S),ts=n(S,"LI",{});var lk=s(ts);Zne=n(lk,"STRONG",{});var ort=s(Zne);qso=r(ort,"gpt_neo"),ort.forEach(t),jso=r(lk," \u2014 "),sB=n(lk,"A",{href:!0});var rrt=s(sB);Dso=r(rrt,"GPT2Tokenizer"),rrt.forEach(t),Gso=r(lk," or "),lB=n(lk,"A",{href:!0});var trt=s(lB);Oso=r(trt,"GPT2TokenizerFast"),trt.forEach(t),Vso=r(lk," (GPT Neo model)"),lk.forEach(t),Xso=i(S),eh=n(S,"LI",{});var gLe=s(eh);ese=n(gLe,"STRONG",{});var art=s(ese);zso=r(art,"gpt_neox"),art.forEach(t),Wso=r(gLe," \u2014 "),iB=n(gLe,"A",{href:!0});var nrt=s(iB);Qso=r(nrt,"GPTNeoXTokenizerFast"),nrt.forEach(t),Hso=r(gLe," (GPT NeoX model)"),gLe.forEach(t),Uso=i(S),as=n(S,"LI",{});var ik=s(as);ose=n(ik,"STRONG",{});var srt=s(ose);Jso=r(srt,"gptj"),srt.forEach(t),Yso=r(ik," \u2014 "),dB=n(ik,"A",{href:!0});var lrt=s(dB);Kso=r(lrt,"GPT2Tokenizer"),lrt.forEach(t),Zso=r(ik," or "),cB=n(ik,"A",{href:!0});var irt=s(cB);elo=r(irt,"GPT2TokenizerFast"),irt.forEach(t),olo=r(ik," (GPT-J model)"),ik.forEach(t),rlo=i(S),ns=n(S,"LI",{});var dk=s(ns);rse=n(dk,"STRONG",{});var drt=s(rse);tlo=r(drt,"herbert"),drt.forEach(t),alo=r(dk," \u2014 "),fB=n(dk,"A",{href:!0});var crt=s(fB);nlo=r(crt,"HerbertTokenizer"),crt.forEach(t),slo=r(dk," or "),mB=n(dk,"A",{href:!0});var frt=s(mB);llo=r(frt,"HerbertTokenizerFast"),frt.forEach(t),ilo=r(dk," (HerBERT model)"),dk.forEach(t),dlo=i(S),oh=n(S,"LI",{});var hLe=s(oh);tse=n(hLe,"STRONG",{});var mrt=s(tse);clo=r(mrt,"hubert"),mrt.forEach(t),flo=r(hLe," \u2014 "),gB=n(hLe,"A",{href:!0});var grt=s(gB);mlo=r(grt,"Wav2Vec2CTCTokenizer"),grt.forEach(t),glo=r(hLe," (Hubert model)"),hLe.forEach(t),hlo=i(S),ss=n(S,"LI",{});var ck=s(ss);ase=n(ck,"STRONG",{});var hrt=s(ase);plo=r(hrt,"ibert"),hrt.forEach(t),ulo=r(ck," \u2014 "),hB=n(ck,"A",{href:!0});var prt=s(hB);_lo=r(prt,"RobertaTokenizer"),prt.forEach(t),blo=r(ck," or "),pB=n(ck,"A",{href:!0});var urt=s(pB);vlo=r(urt,"RobertaTokenizerFast"),urt.forEach(t),Flo=r(ck," (I-BERT model)"),ck.forEach(t),Tlo=i(S),ls=n(S,"LI",{});var fk=s(ls);nse=n(fk,"STRONG",{});var _rt=s(nse);Mlo=r(_rt,"layoutlm"),_rt.forEach(t),Elo=r(fk," \u2014 "),uB=n(fk,"A",{href:!0});var brt=s(uB);Clo=r(brt,"LayoutLMTokenizer"),brt.forEach(t),wlo=r(fk," or "),_B=n(fk,"A",{href:!0});var vrt=s(_B);Alo=r(vrt,"LayoutLMTokenizerFast"),vrt.forEach(t),Llo=r(fk," (LayoutLM model)"),fk.forEach(t),ylo=i(S),is=n(S,"LI",{});var mk=s(is);sse=n(mk,"STRONG",{});var Frt=s(sse);xlo=r(Frt,"layoutlmv2"),Frt.forEach(t),$lo=r(mk," \u2014 "),bB=n(mk,"A",{href:!0});var Trt=s(bB);klo=r(Trt,"LayoutLMv2Tokenizer"),Trt.forEach(t),Slo=r(mk," or "),vB=n(mk,"A",{href:!0});var Mrt=s(vB);Rlo=r(Mrt,"LayoutLMv2TokenizerFast"),Mrt.forEach(t),Plo=r(mk," (LayoutLMv2 model)"),mk.forEach(t),Blo=i(S),ds=n(S,"LI",{});var gk=s(ds);lse=n(gk,"STRONG",{});var Ert=s(lse);Ilo=r(Ert,"layoutlmv3"),Ert.forEach(t),Nlo=r(gk," \u2014 "),FB=n(gk,"A",{href:!0});var Crt=s(FB);qlo=r(Crt,"LayoutLMv3Tokenizer"),Crt.forEach(t),jlo=r(gk," or "),TB=n(gk,"A",{href:!0});var wrt=s(TB);Dlo=r(wrt,"LayoutLMv3TokenizerFast"),wrt.forEach(t),Glo=r(gk," (LayoutLMv3 model)"),gk.forEach(t),Olo=i(S),cs=n(S,"LI",{});var hk=s(cs);ise=n(hk,"STRONG",{});var Art=s(ise);Vlo=r(Art,"layoutxlm"),Art.forEach(t),Xlo=r(hk," \u2014 "),MB=n(hk,"A",{href:!0});var Lrt=s(MB);zlo=r(Lrt,"LayoutXLMTokenizer"),Lrt.forEach(t),Wlo=r(hk," or "),EB=n(hk,"A",{href:!0});var yrt=s(EB);Qlo=r(yrt,"LayoutXLMTokenizerFast"),yrt.forEach(t),Hlo=r(hk," (LayoutXLM model)"),hk.forEach(t),Ulo=i(S),fs=n(S,"LI",{});var pk=s(fs);dse=n(pk,"STRONG",{});var xrt=s(dse);Jlo=r(xrt,"led"),xrt.forEach(t),Ylo=r(pk," \u2014 "),CB=n(pk,"A",{href:!0});var $rt=s(CB);Klo=r($rt,"LEDTokenizer"),$rt.forEach(t),Zlo=r(pk," or "),wB=n(pk,"A",{href:!0});var krt=s(wB);eio=r(krt,"LEDTokenizerFast"),krt.forEach(t),oio=r(pk," (LED model)"),pk.forEach(t),rio=i(S),ms=n(S,"LI",{});var uk=s(ms);cse=n(uk,"STRONG",{});var Srt=s(cse);tio=r(Srt,"longformer"),Srt.forEach(t),aio=r(uk," \u2014 "),AB=n(uk,"A",{href:!0});var Rrt=s(AB);nio=r(Rrt,"LongformerTokenizer"),Rrt.forEach(t),sio=r(uk," or "),LB=n(uk,"A",{href:!0});var Prt=s(LB);lio=r(Prt,"LongformerTokenizerFast"),Prt.forEach(t),iio=r(uk," (Longformer model)"),uk.forEach(t),dio=i(S),gs=n(S,"LI",{});var _k=s(gs);fse=n(_k,"STRONG",{});var Brt=s(fse);cio=r(Brt,"longt5"),Brt.forEach(t),fio=r(_k," \u2014 "),yB=n(_k,"A",{href:!0});var Irt=s(yB);mio=r(Irt,"T5Tokenizer"),Irt.forEach(t),gio=r(_k," or "),xB=n(_k,"A",{href:!0});var Nrt=s(xB);hio=r(Nrt,"T5TokenizerFast"),Nrt.forEach(t),pio=r(_k," (LongT5 model)"),_k.forEach(t),uio=i(S),rh=n(S,"LI",{});var pLe=s(rh);mse=n(pLe,"STRONG",{});var qrt=s(mse);_io=r(qrt,"luke"),qrt.forEach(t),bio=r(pLe," \u2014 "),$B=n(pLe,"A",{href:!0});var jrt=s($B);vio=r(jrt,"LukeTokenizer"),jrt.forEach(t),Fio=r(pLe," (LUKE model)"),pLe.forEach(t),Tio=i(S),hs=n(S,"LI",{});var bk=s(hs);gse=n(bk,"STRONG",{});var Drt=s(gse);Mio=r(Drt,"lxmert"),Drt.forEach(t),Eio=r(bk," \u2014 "),kB=n(bk,"A",{href:!0});var Grt=s(kB);Cio=r(Grt,"LxmertTokenizer"),Grt.forEach(t),wio=r(bk," or "),SB=n(bk,"A",{href:!0});var Ort=s(SB);Aio=r(Ort,"LxmertTokenizerFast"),Ort.forEach(t),Lio=r(bk," (LXMERT model)"),bk.forEach(t),yio=i(S),th=n(S,"LI",{});var uLe=s(th);hse=n(uLe,"STRONG",{});var Vrt=s(hse);xio=r(Vrt,"m2m_100"),Vrt.forEach(t),$io=r(uLe," \u2014 "),RB=n(uLe,"A",{href:!0});var Xrt=s(RB);kio=r(Xrt,"M2M100Tokenizer"),Xrt.forEach(t),Sio=r(uLe," (M2M100 model)"),uLe.forEach(t),Rio=i(S),ah=n(S,"LI",{});var _Le=s(ah);pse=n(_Le,"STRONG",{});var zrt=s(pse);Pio=r(zrt,"marian"),zrt.forEach(t),Bio=r(_Le," \u2014 "),PB=n(_Le,"A",{href:!0});var Wrt=s(PB);Iio=r(Wrt,"MarianTokenizer"),Wrt.forEach(t),Nio=r(_Le," (Marian model)"),_Le.forEach(t),qio=i(S),ps=n(S,"LI",{});var vk=s(ps);use=n(vk,"STRONG",{});var Qrt=s(use);jio=r(Qrt,"mbart"),Qrt.forEach(t),Dio=r(vk," \u2014 "),BB=n(vk,"A",{href:!0});var Hrt=s(BB);Gio=r(Hrt,"MBartTokenizer"),Hrt.forEach(t),Oio=r(vk," or "),IB=n(vk,"A",{href:!0});var Urt=s(IB);Vio=r(Urt,"MBartTokenizerFast"),Urt.forEach(t),Xio=r(vk," (mBART model)"),vk.forEach(t),zio=i(S),us=n(S,"LI",{});var Fk=s(us);_se=n(Fk,"STRONG",{});var Jrt=s(_se);Wio=r(Jrt,"mbart50"),Jrt.forEach(t),Qio=r(Fk," \u2014 "),NB=n(Fk,"A",{href:!0});var Yrt=s(NB);Hio=r(Yrt,"MBart50Tokenizer"),Yrt.forEach(t),Uio=r(Fk," or "),qB=n(Fk,"A",{href:!0});var Krt=s(qB);Jio=r(Krt,"MBart50TokenizerFast"),Krt.forEach(t),Yio=r(Fk," (mBART-50 model)"),Fk.forEach(t),Kio=i(S),_s=n(S,"LI",{});var Tk=s(_s);bse=n(Tk,"STRONG",{});var Zrt=s(bse);Zio=r(Zrt,"megatron-bert"),Zrt.forEach(t),edo=r(Tk," \u2014 "),jB=n(Tk,"A",{href:!0});var ett=s(jB);odo=r(ett,"BertTokenizer"),ett.forEach(t),rdo=r(Tk," or "),DB=n(Tk,"A",{href:!0});var ott=s(DB);tdo=r(ott,"BertTokenizerFast"),ott.forEach(t),ado=r(Tk," (Megatron-BERT model)"),Tk.forEach(t),ndo=i(S),nh=n(S,"LI",{});var bLe=s(nh);vse=n(bLe,"STRONG",{});var rtt=s(vse);sdo=r(rtt,"mluke"),rtt.forEach(t),ldo=r(bLe," \u2014 "),GB=n(bLe,"A",{href:!0});var ttt=s(GB);ido=r(ttt,"MLukeTokenizer"),ttt.forEach(t),ddo=r(bLe," (mLUKE model)"),bLe.forEach(t),cdo=i(S),bs=n(S,"LI",{});var Mk=s(bs);Fse=n(Mk,"STRONG",{});var att=s(Fse);fdo=r(att,"mobilebert"),att.forEach(t),mdo=r(Mk," \u2014 "),OB=n(Mk,"A",{href:!0});var ntt=s(OB);gdo=r(ntt,"MobileBertTokenizer"),ntt.forEach(t),hdo=r(Mk," or "),VB=n(Mk,"A",{href:!0});var stt=s(VB);pdo=r(stt,"MobileBertTokenizerFast"),stt.forEach(t),udo=r(Mk," (MobileBERT model)"),Mk.forEach(t),_do=i(S),vs=n(S,"LI",{});var Ek=s(vs);Tse=n(Ek,"STRONG",{});var ltt=s(Tse);bdo=r(ltt,"mpnet"),ltt.forEach(t),vdo=r(Ek," \u2014 "),XB=n(Ek,"A",{href:!0});var itt=s(XB);Fdo=r(itt,"MPNetTokenizer"),itt.forEach(t),Tdo=r(Ek," or "),zB=n(Ek,"A",{href:!0});var dtt=s(zB);Mdo=r(dtt,"MPNetTokenizerFast"),dtt.forEach(t),Edo=r(Ek," (MPNet model)"),Ek.forEach(t),Cdo=i(S),Fs=n(S,"LI",{});var Ck=s(Fs);Mse=n(Ck,"STRONG",{});var ctt=s(Mse);wdo=r(ctt,"mt5"),ctt.forEach(t),Ado=r(Ck," \u2014 "),WB=n(Ck,"A",{href:!0});var ftt=s(WB);Ldo=r(ftt,"MT5Tokenizer"),ftt.forEach(t),ydo=r(Ck," or "),QB=n(Ck,"A",{href:!0});var mtt=s(QB);xdo=r(mtt,"MT5TokenizerFast"),mtt.forEach(t),$do=r(Ck," (MT5 model)"),Ck.forEach(t),kdo=i(S),Ts=n(S,"LI",{});var wk=s(Ts);Ese=n(wk,"STRONG",{});var gtt=s(Ese);Sdo=r(gtt,"nystromformer"),gtt.forEach(t),Rdo=r(wk," \u2014 "),HB=n(wk,"A",{href:!0});var htt=s(HB);Pdo=r(htt,"AlbertTokenizer"),htt.forEach(t),Bdo=r(wk," or "),UB=n(wk,"A",{href:!0});var ptt=s(UB);Ido=r(ptt,"AlbertTokenizerFast"),ptt.forEach(t),Ndo=r(wk," (Nystr\xF6mformer model)"),wk.forEach(t),qdo=i(S),Ms=n(S,"LI",{});var Ak=s(Ms);Cse=n(Ak,"STRONG",{});var utt=s(Cse);jdo=r(utt,"openai-gpt"),utt.forEach(t),Ddo=r(Ak," \u2014 "),JB=n(Ak,"A",{href:!0});var _tt=s(JB);Gdo=r(_tt,"OpenAIGPTTokenizer"),_tt.forEach(t),Odo=r(Ak," or "),YB=n(Ak,"A",{href:!0});var btt=s(YB);Vdo=r(btt,"OpenAIGPTTokenizerFast"),btt.forEach(t),Xdo=r(Ak," (OpenAI GPT model)"),Ak.forEach(t),zdo=i(S),sh=n(S,"LI",{});var vLe=s(sh);wse=n(vLe,"STRONG",{});var vtt=s(wse);Wdo=r(vtt,"opt"),vtt.forEach(t),Qdo=r(vLe," \u2014 "),KB=n(vLe,"A",{href:!0});var Ftt=s(KB);Hdo=r(Ftt,"GPT2Tokenizer"),Ftt.forEach(t),Udo=r(vLe," (OPT model)"),vLe.forEach(t),Jdo=i(S),Es=n(S,"LI",{});var Lk=s(Es);Ase=n(Lk,"STRONG",{});var Ttt=s(Ase);Ydo=r(Ttt,"pegasus"),Ttt.forEach(t),Kdo=r(Lk," \u2014 "),ZB=n(Lk,"A",{href:!0});var Mtt=s(ZB);Zdo=r(Mtt,"PegasusTokenizer"),Mtt.forEach(t),eco=r(Lk," or "),eI=n(Lk,"A",{href:!0});var Ett=s(eI);oco=r(Ett,"PegasusTokenizerFast"),Ett.forEach(t),rco=r(Lk," (Pegasus model)"),Lk.forEach(t),tco=i(S),lh=n(S,"LI",{});var FLe=s(lh);Lse=n(FLe,"STRONG",{});var Ctt=s(Lse);aco=r(Ctt,"perceiver"),Ctt.forEach(t),nco=r(FLe," \u2014 "),oI=n(FLe,"A",{href:!0});var wtt=s(oI);sco=r(wtt,"PerceiverTokenizer"),wtt.forEach(t),lco=r(FLe," (Perceiver model)"),FLe.forEach(t),ico=i(S),ih=n(S,"LI",{});var TLe=s(ih);yse=n(TLe,"STRONG",{});var Att=s(yse);dco=r(Att,"phobert"),Att.forEach(t),cco=r(TLe," \u2014 "),rI=n(TLe,"A",{href:!0});var Ltt=s(rI);fco=r(Ltt,"PhobertTokenizer"),Ltt.forEach(t),mco=r(TLe," (PhoBERT model)"),TLe.forEach(t),gco=i(S),dh=n(S,"LI",{});var MLe=s(dh);xse=n(MLe,"STRONG",{});var ytt=s(xse);hco=r(ytt,"plbart"),ytt.forEach(t),pco=r(MLe," \u2014 "),tI=n(MLe,"A",{href:!0});var xtt=s(tI);uco=r(xtt,"PLBartTokenizer"),xtt.forEach(t),_co=r(MLe," (PLBart model)"),MLe.forEach(t),bco=i(S),ch=n(S,"LI",{});var ELe=s(ch);$se=n(ELe,"STRONG",{});var $tt=s($se);vco=r($tt,"prophetnet"),$tt.forEach(t),Fco=r(ELe," \u2014 "),aI=n(ELe,"A",{href:!0});var ktt=s(aI);Tco=r(ktt,"ProphetNetTokenizer"),ktt.forEach(t),Mco=r(ELe," (ProphetNet model)"),ELe.forEach(t),Eco=i(S),Cs=n(S,"LI",{});var yk=s(Cs);kse=n(yk,"STRONG",{});var Stt=s(kse);Cco=r(Stt,"qdqbert"),Stt.forEach(t),wco=r(yk," \u2014 "),nI=n(yk,"A",{href:!0});var Rtt=s(nI);Aco=r(Rtt,"BertTokenizer"),Rtt.forEach(t),Lco=r(yk," or "),sI=n(yk,"A",{href:!0});var Ptt=s(sI);yco=r(Ptt,"BertTokenizerFast"),Ptt.forEach(t),xco=r(yk," (QDQBert model)"),yk.forEach(t),$co=i(S),fh=n(S,"LI",{});var CLe=s(fh);Sse=n(CLe,"STRONG",{});var Btt=s(Sse);kco=r(Btt,"rag"),Btt.forEach(t),Sco=r(CLe," \u2014 "),lI=n(CLe,"A",{href:!0});var Itt=s(lI);Rco=r(Itt,"RagTokenizer"),Itt.forEach(t),Pco=r(CLe," (RAG model)"),CLe.forEach(t),Bco=i(S),ws=n(S,"LI",{});var xk=s(ws);Rse=n(xk,"STRONG",{});var Ntt=s(Rse);Ico=r(Ntt,"realm"),Ntt.forEach(t),Nco=r(xk," \u2014 "),iI=n(xk,"A",{href:!0});var qtt=s(iI);qco=r(qtt,"RealmTokenizer"),qtt.forEach(t),jco=r(xk," or "),dI=n(xk,"A",{href:!0});var jtt=s(dI);Dco=r(jtt,"RealmTokenizerFast"),jtt.forEach(t),Gco=r(xk," (REALM model)"),xk.forEach(t),Oco=i(S),As=n(S,"LI",{});var $k=s(As);Pse=n($k,"STRONG",{});var Dtt=s(Pse);Vco=r(Dtt,"reformer"),Dtt.forEach(t),Xco=r($k," \u2014 "),cI=n($k,"A",{href:!0});var Gtt=s(cI);zco=r(Gtt,"ReformerTokenizer"),Gtt.forEach(t),Wco=r($k," or "),fI=n($k,"A",{href:!0});var Ott=s(fI);Qco=r(Ott,"ReformerTokenizerFast"),Ott.forEach(t),Hco=r($k," (Reformer model)"),$k.forEach(t),Uco=i(S),Ls=n(S,"LI",{});var kk=s(Ls);Bse=n(kk,"STRONG",{});var Vtt=s(Bse);Jco=r(Vtt,"rembert"),Vtt.forEach(t),Yco=r(kk," \u2014 "),mI=n(kk,"A",{href:!0});var Xtt=s(mI);Kco=r(Xtt,"RemBertTokenizer"),Xtt.forEach(t),Zco=r(kk," or "),gI=n(kk,"A",{href:!0});var ztt=s(gI);efo=r(ztt,"RemBertTokenizerFast"),ztt.forEach(t),ofo=r(kk," (RemBERT model)"),kk.forEach(t),rfo=i(S),ys=n(S,"LI",{});var Sk=s(ys);Ise=n(Sk,"STRONG",{});var Wtt=s(Ise);tfo=r(Wtt,"retribert"),Wtt.forEach(t),afo=r(Sk," \u2014 "),hI=n(Sk,"A",{href:!0});var Qtt=s(hI);nfo=r(Qtt,"RetriBertTokenizer"),Qtt.forEach(t),sfo=r(Sk," or "),pI=n(Sk,"A",{href:!0});var Htt=s(pI);lfo=r(Htt,"RetriBertTokenizerFast"),Htt.forEach(t),ifo=r(Sk," (RetriBERT model)"),Sk.forEach(t),dfo=i(S),xs=n(S,"LI",{});var Rk=s(xs);Nse=n(Rk,"STRONG",{});var Utt=s(Nse);cfo=r(Utt,"roberta"),Utt.forEach(t),ffo=r(Rk," \u2014 "),uI=n(Rk,"A",{href:!0});var Jtt=s(uI);mfo=r(Jtt,"RobertaTokenizer"),Jtt.forEach(t),gfo=r(Rk," or "),_I=n(Rk,"A",{href:!0});var Ytt=s(_I);hfo=r(Ytt,"RobertaTokenizerFast"),Ytt.forEach(t),pfo=r(Rk," (RoBERTa model)"),Rk.forEach(t),ufo=i(S),$s=n(S,"LI",{});var Pk=s($s);qse=n(Pk,"STRONG",{});var Ktt=s(qse);_fo=r(Ktt,"roformer"),Ktt.forEach(t),bfo=r(Pk," \u2014 "),bI=n(Pk,"A",{href:!0});var Ztt=s(bI);vfo=r(Ztt,"RoFormerTokenizer"),Ztt.forEach(t),Ffo=r(Pk," or "),vI=n(Pk,"A",{href:!0});var eat=s(vI);Tfo=r(eat,"RoFormerTokenizerFast"),eat.forEach(t),Mfo=r(Pk," (RoFormer model)"),Pk.forEach(t),Efo=i(S),mh=n(S,"LI",{});var wLe=s(mh);jse=n(wLe,"STRONG",{});var oat=s(jse);Cfo=r(oat,"speech_to_text"),oat.forEach(t),wfo=r(wLe," \u2014 "),FI=n(wLe,"A",{href:!0});var rat=s(FI);Afo=r(rat,"Speech2TextTokenizer"),rat.forEach(t),Lfo=r(wLe," (Speech2Text model)"),wLe.forEach(t),yfo=i(S),gh=n(S,"LI",{});var ALe=s(gh);Dse=n(ALe,"STRONG",{});var tat=s(Dse);xfo=r(tat,"speech_to_text_2"),tat.forEach(t),$fo=r(ALe," \u2014 "),TI=n(ALe,"A",{href:!0});var aat=s(TI);kfo=r(aat,"Speech2Text2Tokenizer"),aat.forEach(t),Sfo=r(ALe," (Speech2Text2 model)"),ALe.forEach(t),Rfo=i(S),ks=n(S,"LI",{});var Bk=s(ks);Gse=n(Bk,"STRONG",{});var nat=s(Gse);Pfo=r(nat,"splinter"),nat.forEach(t),Bfo=r(Bk," \u2014 "),MI=n(Bk,"A",{href:!0});var sat=s(MI);Ifo=r(sat,"SplinterTokenizer"),sat.forEach(t),Nfo=r(Bk," or "),EI=n(Bk,"A",{href:!0});var lat=s(EI);qfo=r(lat,"SplinterTokenizerFast"),lat.forEach(t),jfo=r(Bk," (Splinter model)"),Bk.forEach(t),Dfo=i(S),Ss=n(S,"LI",{});var Ik=s(Ss);Ose=n(Ik,"STRONG",{});var iat=s(Ose);Gfo=r(iat,"squeezebert"),iat.forEach(t),Ofo=r(Ik," \u2014 "),CI=n(Ik,"A",{href:!0});var dat=s(CI);Vfo=r(dat,"SqueezeBertTokenizer"),dat.forEach(t),Xfo=r(Ik," or "),wI=n(Ik,"A",{href:!0});var cat=s(wI);zfo=r(cat,"SqueezeBertTokenizerFast"),cat.forEach(t),Wfo=r(Ik," (SqueezeBERT model)"),Ik.forEach(t),Qfo=i(S),Rs=n(S,"LI",{});var Nk=s(Rs);Vse=n(Nk,"STRONG",{});var fat=s(Vse);Hfo=r(fat,"t5"),fat.forEach(t),Ufo=r(Nk," \u2014 "),AI=n(Nk,"A",{href:!0});var mat=s(AI);Jfo=r(mat,"T5Tokenizer"),mat.forEach(t),Yfo=r(Nk," or "),LI=n(Nk,"A",{href:!0});var gat=s(LI);Kfo=r(gat,"T5TokenizerFast"),gat.forEach(t),Zfo=r(Nk," (T5 model)"),Nk.forEach(t),emo=i(S),hh=n(S,"LI",{});var LLe=s(hh);Xse=n(LLe,"STRONG",{});var hat=s(Xse);omo=r(hat,"tapas"),hat.forEach(t),rmo=r(LLe," \u2014 "),yI=n(LLe,"A",{href:!0});var pat=s(yI);tmo=r(pat,"TapasTokenizer"),pat.forEach(t),amo=r(LLe," (TAPAS model)"),LLe.forEach(t),nmo=i(S),ph=n(S,"LI",{});var yLe=s(ph);zse=n(yLe,"STRONG",{});var uat=s(zse);smo=r(uat,"tapex"),uat.forEach(t),lmo=r(yLe," \u2014 "),xI=n(yLe,"A",{href:!0});var _at=s(xI);imo=r(_at,"TapexTokenizer"),_at.forEach(t),dmo=r(yLe," (TAPEX model)"),yLe.forEach(t),cmo=i(S),uh=n(S,"LI",{});var xLe=s(uh);Wse=n(xLe,"STRONG",{});var bat=s(Wse);fmo=r(bat,"transfo-xl"),bat.forEach(t),mmo=r(xLe," \u2014 "),$I=n(xLe,"A",{href:!0});var vat=s($I);gmo=r(vat,"TransfoXLTokenizer"),vat.forEach(t),hmo=r(xLe," (Transformer-XL model)"),xLe.forEach(t),pmo=i(S),Ps=n(S,"LI",{});var qk=s(Ps);Qse=n(qk,"STRONG",{});var Fat=s(Qse);umo=r(Fat,"vilt"),Fat.forEach(t),_mo=r(qk," \u2014 "),kI=n(qk,"A",{href:!0});var Tat=s(kI);bmo=r(Tat,"BertTokenizer"),Tat.forEach(t),vmo=r(qk," or "),SI=n(qk,"A",{href:!0});var Mat=s(SI);Fmo=r(Mat,"BertTokenizerFast"),Mat.forEach(t),Tmo=r(qk," (ViLT model)"),qk.forEach(t),Mmo=i(S),Bs=n(S,"LI",{});var jk=s(Bs);Hse=n(jk,"STRONG",{});var Eat=s(Hse);Emo=r(Eat,"visual_bert"),Eat.forEach(t),Cmo=r(jk," \u2014 "),RI=n(jk,"A",{href:!0});var Cat=s(RI);wmo=r(Cat,"BertTokenizer"),Cat.forEach(t),Amo=r(jk," or "),PI=n(jk,"A",{href:!0});var wat=s(PI);Lmo=r(wat,"BertTokenizerFast"),wat.forEach(t),ymo=r(jk," (VisualBERT model)"),jk.forEach(t),xmo=i(S),_h=n(S,"LI",{});var $Le=s(_h);Use=n($Le,"STRONG",{});var Aat=s(Use);$mo=r(Aat,"wav2vec2"),Aat.forEach(t),kmo=r($Le," \u2014 "),BI=n($Le,"A",{href:!0});var Lat=s(BI);Smo=r(Lat,"Wav2Vec2CTCTokenizer"),Lat.forEach(t),Rmo=r($Le," (Wav2Vec2 model)"),$Le.forEach(t),Pmo=i(S),bh=n(S,"LI",{});var kLe=s(bh);Jse=n(kLe,"STRONG",{});var yat=s(Jse);Bmo=r(yat,"wav2vec2-conformer"),yat.forEach(t),Imo=r(kLe," \u2014 "),II=n(kLe,"A",{href:!0});var xat=s(II);Nmo=r(xat,"Wav2Vec2CTCTokenizer"),xat.forEach(t),qmo=r(kLe," (Wav2Vec2-Conformer model)"),kLe.forEach(t),jmo=i(S),vh=n(S,"LI",{});var SLe=s(vh);Yse=n(SLe,"STRONG",{});var $at=s(Yse);Dmo=r($at,"wav2vec2_phoneme"),$at.forEach(t),Gmo=r(SLe," \u2014 "),NI=n(SLe,"A",{href:!0});var kat=s(NI);Omo=r(kat,"Wav2Vec2PhonemeCTCTokenizer"),kat.forEach(t),Vmo=r(SLe," (Wav2Vec2Phoneme model)"),SLe.forEach(t),Xmo=i(S),Is=n(S,"LI",{});var Dk=s(Is);Kse=n(Dk,"STRONG",{});var Sat=s(Kse);zmo=r(Sat,"xglm"),Sat.forEach(t),Wmo=r(Dk," \u2014 "),qI=n(Dk,"A",{href:!0});var Rat=s(qI);Qmo=r(Rat,"XGLMTokenizer"),Rat.forEach(t),Hmo=r(Dk," or "),jI=n(Dk,"A",{href:!0});var Pat=s(jI);Umo=r(Pat,"XGLMTokenizerFast"),Pat.forEach(t),Jmo=r(Dk," (XGLM model)"),Dk.forEach(t),Ymo=i(S),Fh=n(S,"LI",{});var RLe=s(Fh);Zse=n(RLe,"STRONG",{});var Bat=s(Zse);Kmo=r(Bat,"xlm"),Bat.forEach(t),Zmo=r(RLe," \u2014 "),DI=n(RLe,"A",{href:!0});var Iat=s(DI);ego=r(Iat,"XLMTokenizer"),Iat.forEach(t),ogo=r(RLe," (XLM model)"),RLe.forEach(t),rgo=i(S),Th=n(S,"LI",{});var PLe=s(Th);ele=n(PLe,"STRONG",{});var Nat=s(ele);tgo=r(Nat,"xlm-prophetnet"),Nat.forEach(t),ago=r(PLe," \u2014 "),GI=n(PLe,"A",{href:!0});var qat=s(GI);ngo=r(qat,"XLMProphetNetTokenizer"),qat.forEach(t),sgo=r(PLe," (XLM-ProphetNet model)"),PLe.forEach(t),lgo=i(S),Ns=n(S,"LI",{});var Gk=s(Ns);ole=n(Gk,"STRONG",{});var jat=s(ole);igo=r(jat,"xlm-roberta"),jat.forEach(t),dgo=r(Gk," \u2014 "),OI=n(Gk,"A",{href:!0});var Dat=s(OI);cgo=r(Dat,"XLMRobertaTokenizer"),Dat.forEach(t),fgo=r(Gk," or "),VI=n(Gk,"A",{href:!0});var Gat=s(VI);mgo=r(Gat,"XLMRobertaTokenizerFast"),Gat.forEach(t),ggo=r(Gk," (XLM-RoBERTa model)"),Gk.forEach(t),hgo=i(S),qs=n(S,"LI",{});var Ok=s(qs);rle=n(Ok,"STRONG",{});var Oat=s(rle);pgo=r(Oat,"xlm-roberta-xl"),Oat.forEach(t),ugo=r(Ok," \u2014 "),XI=n(Ok,"A",{href:!0});var Vat=s(XI);_go=r(Vat,"RobertaTokenizer"),Vat.forEach(t),bgo=r(Ok," or "),zI=n(Ok,"A",{href:!0});var Xat=s(zI);vgo=r(Xat,"RobertaTokenizerFast"),Xat.forEach(t),Fgo=r(Ok," (XLM-RoBERTa-XL model)"),Ok.forEach(t),Tgo=i(S),js=n(S,"LI",{});var Vk=s(js);tle=n(Vk,"STRONG",{});var zat=s(tle);Mgo=r(zat,"xlnet"),zat.forEach(t),Ego=r(Vk," \u2014 "),WI=n(Vk,"A",{href:!0});var Wat=s(WI);Cgo=r(Wat,"XLNetTokenizer"),Wat.forEach(t),wgo=r(Vk," or "),QI=n(Vk,"A",{href:!0});var Qat=s(QI);Ago=r(Qat,"XLNetTokenizerFast"),Qat.forEach(t),Lgo=r(Vk," (XLNet model)"),Vk.forEach(t),ygo=i(S),Ds=n(S,"LI",{});var Xk=s(Ds);ale=n(Xk,"STRONG",{});var Hat=s(ale);xgo=r(Hat,"yoso"),Hat.forEach(t),$go=r(Xk," \u2014 "),HI=n(Xk,"A",{href:!0});var Uat=s(HI);kgo=r(Uat,"AlbertTokenizer"),Uat.forEach(t),Sgo=r(Xk," or "),UI=n(Xk,"A",{href:!0});var Jat=s(UI);Rgo=r(Jat,"AlbertTokenizerFast"),Jat.forEach(t),Pgo=r(Xk," (YOSO model)"),Xk.forEach(t),S.forEach(t),Bgo=i(Ws),T(Mh.$$.fragment,Ws),Ws.forEach(t),Igo=i(zs),Eh=n(zs,"DIV",{class:!0});var CVe=s(Eh);T(IL.$$.fragment,CVe),Ngo=i(CVe),nle=n(CVe,"P",{});var Yat=s(nle);qgo=r(Yat,"Register a new tokenizer in this mapping."),Yat.forEach(t),CVe.forEach(t),zs.forEach(t),EGe=i(f),ki=n(f,"H2",{class:!0});var wVe=s(ki);Ch=n(wVe,"A",{id:!0,class:!0,href:!0});var Kat=s(Ch);sle=n(Kat,"SPAN",{});var Zat=s(sle);T(NL.$$.fragment,Zat),Zat.forEach(t),Kat.forEach(t),jgo=i(wVe),lle=n(wVe,"SPAN",{});var ent=s(lle);Dgo=r(ent,"AutoFeatureExtractor"),ent.forEach(t),wVe.forEach(t),CGe=i(f),Lo=n(f,"DIV",{class:!0});var Qs=s(Lo);T(qL.$$.fragment,Qs),Ggo=i(Qs),jL=n(Qs,"P",{});var AVe=s(jL);Ogo=r(AVe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),JI=n(AVe,"A",{href:!0});var ont=s(JI);Vgo=r(ont,"AutoFeatureExtractor.from_pretrained()"),ont.forEach(t),Xgo=r(AVe," class method."),AVe.forEach(t),zgo=i(Qs),DL=n(Qs,"P",{});var LVe=s(DL);Wgo=r(LVe,"This class cannot be instantiated directly using "),ile=n(LVe,"CODE",{});var rnt=s(ile);Qgo=r(rnt,"__init__()"),rnt.forEach(t),Hgo=r(LVe," (throws an error)."),LVe.forEach(t),Ugo=i(Qs),He=n(Qs,"DIV",{class:!0});var ra=s(He);T(GL.$$.fragment,ra),Jgo=i(ra),dle=n(ra,"P",{});var tnt=s(dle);Ygo=r(tnt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),tnt.forEach(t),Kgo=i(ra),ka=n(ra,"P",{});var CA=s(ka);Zgo=r(CA,"The feature extractor class to instantiate is selected based on the "),cle=n(CA,"CODE",{});var ant=s(cle);eho=r(ant,"model_type"),ant.forEach(t),oho=r(CA,` property of the config object
(either passed as an argument or loaded from `),fle=n(CA,"CODE",{});var nnt=s(fle);rho=r(nnt,"pretrained_model_name_or_path"),nnt.forEach(t),tho=r(CA,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),mle=n(CA,"CODE",{});var snt=s(mle);aho=r(snt,"pretrained_model_name_or_path"),snt.forEach(t),nho=r(CA,":"),CA.forEach(t),sho=i(ra),Y=n(ra,"UL",{});var K=s(Y);wh=n(K,"LI",{});var BLe=s(wh);gle=n(BLe,"STRONG",{});var lnt=s(gle);lho=r(lnt,"beit"),lnt.forEach(t),iho=r(BLe," \u2014 "),YI=n(BLe,"A",{href:!0});var int=s(YI);dho=r(int,"BeitFeatureExtractor"),int.forEach(t),cho=r(BLe," (BEiT model)"),BLe.forEach(t),fho=i(K),Ah=n(K,"LI",{});var ILe=s(Ah);hle=n(ILe,"STRONG",{});var dnt=s(hle);mho=r(dnt,"clip"),dnt.forEach(t),gho=r(ILe," \u2014 "),KI=n(ILe,"A",{href:!0});var cnt=s(KI);hho=r(cnt,"CLIPFeatureExtractor"),cnt.forEach(t),pho=r(ILe," (CLIP model)"),ILe.forEach(t),uho=i(K),Lh=n(K,"LI",{});var NLe=s(Lh);ple=n(NLe,"STRONG",{});var fnt=s(ple);_ho=r(fnt,"convnext"),fnt.forEach(t),bho=r(NLe," \u2014 "),ZI=n(NLe,"A",{href:!0});var mnt=s(ZI);vho=r(mnt,"ConvNextFeatureExtractor"),mnt.forEach(t),Fho=r(NLe," (ConvNeXT model)"),NLe.forEach(t),Tho=i(K),yh=n(K,"LI",{});var qLe=s(yh);ule=n(qLe,"STRONG",{});var gnt=s(ule);Mho=r(gnt,"cvt"),gnt.forEach(t),Eho=r(qLe," \u2014 "),eN=n(qLe,"A",{href:!0});var hnt=s(eN);Cho=r(hnt,"ConvNextFeatureExtractor"),hnt.forEach(t),who=r(qLe," (CvT model)"),qLe.forEach(t),Aho=i(K),xh=n(K,"LI",{});var jLe=s(xh);_le=n(jLe,"STRONG",{});var pnt=s(_le);Lho=r(pnt,"data2vec-audio"),pnt.forEach(t),yho=r(jLe," \u2014 "),oN=n(jLe,"A",{href:!0});var unt=s(oN);xho=r(unt,"Wav2Vec2FeatureExtractor"),unt.forEach(t),$ho=r(jLe," (Data2VecAudio model)"),jLe.forEach(t),kho=i(K),$h=n(K,"LI",{});var DLe=s($h);ble=n(DLe,"STRONG",{});var _nt=s(ble);Sho=r(_nt,"data2vec-vision"),_nt.forEach(t),Rho=r(DLe," \u2014 "),rN=n(DLe,"A",{href:!0});var bnt=s(rN);Pho=r(bnt,"BeitFeatureExtractor"),bnt.forEach(t),Bho=r(DLe," (Data2VecVision model)"),DLe.forEach(t),Iho=i(K),kh=n(K,"LI",{});var GLe=s(kh);vle=n(GLe,"STRONG",{});var vnt=s(vle);Nho=r(vnt,"deit"),vnt.forEach(t),qho=r(GLe," \u2014 "),tN=n(GLe,"A",{href:!0});var Fnt=s(tN);jho=r(Fnt,"DeiTFeatureExtractor"),Fnt.forEach(t),Dho=r(GLe," (DeiT model)"),GLe.forEach(t),Gho=i(K),Sh=n(K,"LI",{});var OLe=s(Sh);Fle=n(OLe,"STRONG",{});var Tnt=s(Fle);Oho=r(Tnt,"detr"),Tnt.forEach(t),Vho=r(OLe," \u2014 "),aN=n(OLe,"A",{href:!0});var Mnt=s(aN);Xho=r(Mnt,"DetrFeatureExtractor"),Mnt.forEach(t),zho=r(OLe," (DETR model)"),OLe.forEach(t),Who=i(K),Rh=n(K,"LI",{});var VLe=s(Rh);Tle=n(VLe,"STRONG",{});var Ent=s(Tle);Qho=r(Ent,"dpt"),Ent.forEach(t),Hho=r(VLe," \u2014 "),nN=n(VLe,"A",{href:!0});var Cnt=s(nN);Uho=r(Cnt,"DPTFeatureExtractor"),Cnt.forEach(t),Jho=r(VLe," (DPT model)"),VLe.forEach(t),Yho=i(K),Ph=n(K,"LI",{});var XLe=s(Ph);Mle=n(XLe,"STRONG",{});var wnt=s(Mle);Kho=r(wnt,"flava"),wnt.forEach(t),Zho=r(XLe," \u2014 "),sN=n(XLe,"A",{href:!0});var Ant=s(sN);epo=r(Ant,"FlavaFeatureExtractor"),Ant.forEach(t),opo=r(XLe," (FLAVA model)"),XLe.forEach(t),rpo=i(K),Bh=n(K,"LI",{});var zLe=s(Bh);Ele=n(zLe,"STRONG",{});var Lnt=s(Ele);tpo=r(Lnt,"glpn"),Lnt.forEach(t),apo=r(zLe," \u2014 "),lN=n(zLe,"A",{href:!0});var ynt=s(lN);npo=r(ynt,"GLPNFeatureExtractor"),ynt.forEach(t),spo=r(zLe," (GLPN model)"),zLe.forEach(t),lpo=i(K),Ih=n(K,"LI",{});var WLe=s(Ih);Cle=n(WLe,"STRONG",{});var xnt=s(Cle);ipo=r(xnt,"hubert"),xnt.forEach(t),dpo=r(WLe," \u2014 "),iN=n(WLe,"A",{href:!0});var $nt=s(iN);cpo=r($nt,"Wav2Vec2FeatureExtractor"),$nt.forEach(t),fpo=r(WLe," (Hubert model)"),WLe.forEach(t),mpo=i(K),Nh=n(K,"LI",{});var QLe=s(Nh);wle=n(QLe,"STRONG",{});var knt=s(wle);gpo=r(knt,"imagegpt"),knt.forEach(t),hpo=r(QLe," \u2014 "),dN=n(QLe,"A",{href:!0});var Snt=s(dN);ppo=r(Snt,"ImageGPTFeatureExtractor"),Snt.forEach(t),upo=r(QLe," (ImageGPT model)"),QLe.forEach(t),_po=i(K),qh=n(K,"LI",{});var HLe=s(qh);Ale=n(HLe,"STRONG",{});var Rnt=s(Ale);bpo=r(Rnt,"layoutlmv2"),Rnt.forEach(t),vpo=r(HLe," \u2014 "),cN=n(HLe,"A",{href:!0});var Pnt=s(cN);Fpo=r(Pnt,"LayoutLMv2FeatureExtractor"),Pnt.forEach(t),Tpo=r(HLe," (LayoutLMv2 model)"),HLe.forEach(t),Mpo=i(K),jh=n(K,"LI",{});var ULe=s(jh);Lle=n(ULe,"STRONG",{});var Bnt=s(Lle);Epo=r(Bnt,"layoutlmv3"),Bnt.forEach(t),Cpo=r(ULe," \u2014 "),fN=n(ULe,"A",{href:!0});var Int=s(fN);wpo=r(Int,"LayoutLMv3FeatureExtractor"),Int.forEach(t),Apo=r(ULe," (LayoutLMv3 model)"),ULe.forEach(t),Lpo=i(K),Dh=n(K,"LI",{});var JLe=s(Dh);yle=n(JLe,"STRONG",{});var Nnt=s(yle);ypo=r(Nnt,"levit"),Nnt.forEach(t),xpo=r(JLe," \u2014 "),mN=n(JLe,"A",{href:!0});var qnt=s(mN);$po=r(qnt,"LevitFeatureExtractor"),qnt.forEach(t),kpo=r(JLe," (LeViT model)"),JLe.forEach(t),Spo=i(K),Gh=n(K,"LI",{});var YLe=s(Gh);xle=n(YLe,"STRONG",{});var jnt=s(xle);Rpo=r(jnt,"maskformer"),jnt.forEach(t),Ppo=r(YLe," \u2014 "),gN=n(YLe,"A",{href:!0});var Dnt=s(gN);Bpo=r(Dnt,"MaskFormerFeatureExtractor"),Dnt.forEach(t),Ipo=r(YLe," (MaskFormer model)"),YLe.forEach(t),Npo=i(K),Oh=n(K,"LI",{});var KLe=s(Oh);$le=n(KLe,"STRONG",{});var Gnt=s($le);qpo=r(Gnt,"mctct"),Gnt.forEach(t),jpo=r(KLe," \u2014 "),hN=n(KLe,"A",{href:!0});var Ont=s(hN);Dpo=r(Ont,"MCTCTFeatureExtractor"),Ont.forEach(t),Gpo=r(KLe," (M-CTC-T model)"),KLe.forEach(t),Opo=i(K),Vh=n(K,"LI",{});var ZLe=s(Vh);kle=n(ZLe,"STRONG",{});var Vnt=s(kle);Vpo=r(Vnt,"omnivore"),Vnt.forEach(t),Xpo=r(ZLe," \u2014 "),pN=n(ZLe,"A",{href:!0});var Xnt=s(pN);zpo=r(Xnt,"OmnivoreFeatureExtractor"),Xnt.forEach(t),Wpo=r(ZLe," (Omnivore model)"),ZLe.forEach(t),Qpo=i(K),Xh=n(K,"LI",{});var eye=s(Xh);Sle=n(eye,"STRONG",{});var znt=s(Sle);Hpo=r(znt,"perceiver"),znt.forEach(t),Upo=r(eye," \u2014 "),uN=n(eye,"A",{href:!0});var Wnt=s(uN);Jpo=r(Wnt,"PerceiverFeatureExtractor"),Wnt.forEach(t),Ypo=r(eye," (Perceiver model)"),eye.forEach(t),Kpo=i(K),zh=n(K,"LI",{});var oye=s(zh);Rle=n(oye,"STRONG",{});var Qnt=s(Rle);Zpo=r(Qnt,"poolformer"),Qnt.forEach(t),euo=r(oye," \u2014 "),_N=n(oye,"A",{href:!0});var Hnt=s(_N);ouo=r(Hnt,"PoolFormerFeatureExtractor"),Hnt.forEach(t),ruo=r(oye," (PoolFormer model)"),oye.forEach(t),tuo=i(K),Wh=n(K,"LI",{});var rye=s(Wh);Ple=n(rye,"STRONG",{});var Unt=s(Ple);auo=r(Unt,"regnet"),Unt.forEach(t),nuo=r(rye," \u2014 "),bN=n(rye,"A",{href:!0});var Jnt=s(bN);suo=r(Jnt,"ConvNextFeatureExtractor"),Jnt.forEach(t),luo=r(rye," (RegNet model)"),rye.forEach(t),iuo=i(K),Qh=n(K,"LI",{});var tye=s(Qh);Ble=n(tye,"STRONG",{});var Ynt=s(Ble);duo=r(Ynt,"resnet"),Ynt.forEach(t),cuo=r(tye," \u2014 "),vN=n(tye,"A",{href:!0});var Knt=s(vN);fuo=r(Knt,"ConvNextFeatureExtractor"),Knt.forEach(t),muo=r(tye," (ResNet model)"),tye.forEach(t),guo=i(K),Hh=n(K,"LI",{});var aye=s(Hh);Ile=n(aye,"STRONG",{});var Znt=s(Ile);huo=r(Znt,"segformer"),Znt.forEach(t),puo=r(aye," \u2014 "),FN=n(aye,"A",{href:!0});var est=s(FN);uuo=r(est,"SegformerFeatureExtractor"),est.forEach(t),_uo=r(aye," (SegFormer model)"),aye.forEach(t),buo=i(K),Uh=n(K,"LI",{});var nye=s(Uh);Nle=n(nye,"STRONG",{});var ost=s(Nle);vuo=r(ost,"speech_to_text"),ost.forEach(t),Fuo=r(nye," \u2014 "),TN=n(nye,"A",{href:!0});var rst=s(TN);Tuo=r(rst,"Speech2TextFeatureExtractor"),rst.forEach(t),Muo=r(nye," (Speech2Text model)"),nye.forEach(t),Euo=i(K),Jh=n(K,"LI",{});var sye=s(Jh);qle=n(sye,"STRONG",{});var tst=s(qle);Cuo=r(tst,"swin"),tst.forEach(t),wuo=r(sye," \u2014 "),MN=n(sye,"A",{href:!0});var ast=s(MN);Auo=r(ast,"ViTFeatureExtractor"),ast.forEach(t),Luo=r(sye," (Swin Transformer model)"),sye.forEach(t),yuo=i(K),Yh=n(K,"LI",{});var lye=s(Yh);jle=n(lye,"STRONG",{});var nst=s(jle);xuo=r(nst,"van"),nst.forEach(t),$uo=r(lye," \u2014 "),EN=n(lye,"A",{href:!0});var sst=s(EN);kuo=r(sst,"ConvNextFeatureExtractor"),sst.forEach(t),Suo=r(lye," (VAN model)"),lye.forEach(t),Ruo=i(K),Kh=n(K,"LI",{});var iye=s(Kh);Dle=n(iye,"STRONG",{});var lst=s(Dle);Puo=r(lst,"vilt"),lst.forEach(t),Buo=r(iye," \u2014 "),CN=n(iye,"A",{href:!0});var ist=s(CN);Iuo=r(ist,"ViltFeatureExtractor"),ist.forEach(t),Nuo=r(iye," (ViLT model)"),iye.forEach(t),quo=i(K),Zh=n(K,"LI",{});var dye=s(Zh);Gle=n(dye,"STRONG",{});var dst=s(Gle);juo=r(dst,"vit"),dst.forEach(t),Duo=r(dye," \u2014 "),wN=n(dye,"A",{href:!0});var cst=s(wN);Guo=r(cst,"ViTFeatureExtractor"),cst.forEach(t),Ouo=r(dye," (ViT model)"),dye.forEach(t),Vuo=i(K),ep=n(K,"LI",{});var cye=s(ep);Ole=n(cye,"STRONG",{});var fst=s(Ole);Xuo=r(fst,"vit_mae"),fst.forEach(t),zuo=r(cye," \u2014 "),AN=n(cye,"A",{href:!0});var mst=s(AN);Wuo=r(mst,"ViTFeatureExtractor"),mst.forEach(t),Quo=r(cye," (ViTMAE model)"),cye.forEach(t),Huo=i(K),op=n(K,"LI",{});var fye=s(op);Vle=n(fye,"STRONG",{});var gst=s(Vle);Uuo=r(gst,"wav2vec2"),gst.forEach(t),Juo=r(fye," \u2014 "),LN=n(fye,"A",{href:!0});var hst=s(LN);Yuo=r(hst,"Wav2Vec2FeatureExtractor"),hst.forEach(t),Kuo=r(fye," (Wav2Vec2 model)"),fye.forEach(t),Zuo=i(K),rp=n(K,"LI",{});var mye=s(rp);Xle=n(mye,"STRONG",{});var pst=s(Xle);e_o=r(pst,"wav2vec2-conformer"),pst.forEach(t),o_o=r(mye," \u2014 "),yN=n(mye,"A",{href:!0});var ust=s(yN);r_o=r(ust,"Wav2Vec2FeatureExtractor"),ust.forEach(t),t_o=r(mye," (Wav2Vec2-Conformer model)"),mye.forEach(t),a_o=i(K),tp=n(K,"LI",{});var gye=s(tp);zle=n(gye,"STRONG",{});var _st=s(zle);n_o=r(_st,"yolos"),_st.forEach(t),s_o=r(gye," \u2014 "),xN=n(gye,"A",{href:!0});var bst=s(xN);l_o=r(bst,"YolosFeatureExtractor"),bst.forEach(t),i_o=r(gye," (YOLOS model)"),gye.forEach(t),K.forEach(t),d_o=i(ra),T(ap.$$.fragment,ra),c_o=i(ra),T(np.$$.fragment,ra),ra.forEach(t),f_o=i(Qs),sp=n(Qs,"DIV",{class:!0});var yVe=s(sp);T(OL.$$.fragment,yVe),m_o=i(yVe),Wle=n(yVe,"P",{});var vst=s(Wle);g_o=r(vst,"Register a new feature extractor for this class."),vst.forEach(t),yVe.forEach(t),Qs.forEach(t),wGe=i(f),Si=n(f,"H2",{class:!0});var xVe=s(Si);lp=n(xVe,"A",{id:!0,class:!0,href:!0});var Fst=s(lp);Qle=n(Fst,"SPAN",{});var Tst=s(Qle);T(VL.$$.fragment,Tst),Tst.forEach(t),Fst.forEach(t),h_o=i(xVe),Hle=n(xVe,"SPAN",{});var Mst=s(Hle);p_o=r(Mst,"AutoProcessor"),Mst.forEach(t),xVe.forEach(t),AGe=i(f),yo=n(f,"DIV",{class:!0});var Hs=s(yo);T(XL.$$.fragment,Hs),u_o=i(Hs),zL=n(Hs,"P",{});var $Ve=s(zL);__o=r($Ve,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),$N=n($Ve,"A",{href:!0});var Est=s($N);b_o=r(Est,"AutoProcessor.from_pretrained()"),Est.forEach(t),v_o=r($Ve," class method."),$Ve.forEach(t),F_o=i(Hs),WL=n(Hs,"P",{});var kVe=s(WL);T_o=r(kVe,"This class cannot be instantiated directly using "),Ule=n(kVe,"CODE",{});var Cst=s(Ule);M_o=r(Cst,"__init__()"),Cst.forEach(t),E_o=r(kVe," (throws an error)."),kVe.forEach(t),C_o=i(Hs),Ue=n(Hs,"DIV",{class:!0});var ta=s(Ue);T(QL.$$.fragment,ta),w_o=i(ta),Jle=n(ta,"P",{});var wst=s(Jle);A_o=r(wst,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),wst.forEach(t),L_o=i(ta),Ri=n(ta,"P",{});var aoe=s(Ri);y_o=r(aoe,"The processor class to instantiate is selected based on the "),Yle=n(aoe,"CODE",{});var Ast=s(Yle);x_o=r(Ast,"model_type"),Ast.forEach(t),$_o=r(aoe,` property of the config object (either
passed as an argument or loaded from `),Kle=n(aoe,"CODE",{});var Lst=s(Kle);k_o=r(Lst,"pretrained_model_name_or_path"),Lst.forEach(t),S_o=r(aoe," if possible):"),aoe.forEach(t),R_o=i(ta),he=n(ta,"UL",{});var be=s(he);ip=n(be,"LI",{});var hye=s(ip);Zle=n(hye,"STRONG",{});var yst=s(Zle);P_o=r(yst,"clip"),yst.forEach(t),B_o=r(hye," \u2014 "),kN=n(hye,"A",{href:!0});var xst=s(kN);I_o=r(xst,"CLIPProcessor"),xst.forEach(t),N_o=r(hye," (CLIP model)"),hye.forEach(t),q_o=i(be),dp=n(be,"LI",{});var pye=s(dp);eie=n(pye,"STRONG",{});var $st=s(eie);j_o=r($st,"flava"),$st.forEach(t),D_o=r(pye," \u2014 "),oie=n(pye,"CODE",{});var kst=s(oie);G_o=r(kst,"FLAVAProcessor"),kst.forEach(t),O_o=r(pye," (FLAVA model)"),pye.forEach(t),V_o=i(be),cp=n(be,"LI",{});var uye=s(cp);rie=n(uye,"STRONG",{});var Sst=s(rie);X_o=r(Sst,"layoutlmv2"),Sst.forEach(t),z_o=r(uye," \u2014 "),SN=n(uye,"A",{href:!0});var Rst=s(SN);W_o=r(Rst,"LayoutLMv2Processor"),Rst.forEach(t),Q_o=r(uye," (LayoutLMv2 model)"),uye.forEach(t),H_o=i(be),fp=n(be,"LI",{});var _ye=s(fp);tie=n(_ye,"STRONG",{});var Pst=s(tie);U_o=r(Pst,"layoutlmv3"),Pst.forEach(t),J_o=r(_ye," \u2014 "),RN=n(_ye,"A",{href:!0});var Bst=s(RN);Y_o=r(Bst,"LayoutLMv3Processor"),Bst.forEach(t),K_o=r(_ye," (LayoutLMv3 model)"),_ye.forEach(t),Z_o=i(be),mp=n(be,"LI",{});var bye=s(mp);aie=n(bye,"STRONG",{});var Ist=s(aie);e7o=r(Ist,"layoutxlm"),Ist.forEach(t),o7o=r(bye," \u2014 "),PN=n(bye,"A",{href:!0});var Nst=s(PN);r7o=r(Nst,"LayoutXLMProcessor"),Nst.forEach(t),t7o=r(bye," (LayoutXLM model)"),bye.forEach(t),a7o=i(be),gp=n(be,"LI",{});var vye=s(gp);nie=n(vye,"STRONG",{});var qst=s(nie);n7o=r(qst,"sew"),qst.forEach(t),s7o=r(vye," \u2014 "),BN=n(vye,"A",{href:!0});var jst=s(BN);l7o=r(jst,"Wav2Vec2Processor"),jst.forEach(t),i7o=r(vye," (SEW model)"),vye.forEach(t),d7o=i(be),hp=n(be,"LI",{});var Fye=s(hp);sie=n(Fye,"STRONG",{});var Dst=s(sie);c7o=r(Dst,"sew-d"),Dst.forEach(t),f7o=r(Fye," \u2014 "),IN=n(Fye,"A",{href:!0});var Gst=s(IN);m7o=r(Gst,"Wav2Vec2Processor"),Gst.forEach(t),g7o=r(Fye," (SEW-D model)"),Fye.forEach(t),h7o=i(be),pp=n(be,"LI",{});var Tye=s(pp);lie=n(Tye,"STRONG",{});var Ost=s(lie);p7o=r(Ost,"speech_to_text"),Ost.forEach(t),u7o=r(Tye," \u2014 "),NN=n(Tye,"A",{href:!0});var Vst=s(NN);_7o=r(Vst,"Speech2TextProcessor"),Vst.forEach(t),b7o=r(Tye," (Speech2Text model)"),Tye.forEach(t),v7o=i(be),up=n(be,"LI",{});var Mye=s(up);iie=n(Mye,"STRONG",{});var Xst=s(iie);F7o=r(Xst,"speech_to_text_2"),Xst.forEach(t),T7o=r(Mye," \u2014 "),qN=n(Mye,"A",{href:!0});var zst=s(qN);M7o=r(zst,"Speech2Text2Processor"),zst.forEach(t),E7o=r(Mye," (Speech2Text2 model)"),Mye.forEach(t),C7o=i(be),_p=n(be,"LI",{});var Eye=s(_p);die=n(Eye,"STRONG",{});var Wst=s(die);w7o=r(Wst,"trocr"),Wst.forEach(t),A7o=r(Eye," \u2014 "),jN=n(Eye,"A",{href:!0});var Qst=s(jN);L7o=r(Qst,"TrOCRProcessor"),Qst.forEach(t),y7o=r(Eye," (TrOCR model)"),Eye.forEach(t),x7o=i(be),bp=n(be,"LI",{});var Cye=s(bp);cie=n(Cye,"STRONG",{});var Hst=s(cie);$7o=r(Hst,"unispeech"),Hst.forEach(t),k7o=r(Cye," \u2014 "),DN=n(Cye,"A",{href:!0});var Ust=s(DN);S7o=r(Ust,"Wav2Vec2Processor"),Ust.forEach(t),R7o=r(Cye," (UniSpeech model)"),Cye.forEach(t),P7o=i(be),vp=n(be,"LI",{});var wye=s(vp);fie=n(wye,"STRONG",{});var Jst=s(fie);B7o=r(Jst,"unispeech-sat"),Jst.forEach(t),I7o=r(wye," \u2014 "),GN=n(wye,"A",{href:!0});var Yst=s(GN);N7o=r(Yst,"Wav2Vec2Processor"),Yst.forEach(t),q7o=r(wye," (UniSpeechSat model)"),wye.forEach(t),j7o=i(be),Fp=n(be,"LI",{});var Aye=s(Fp);mie=n(Aye,"STRONG",{});var Kst=s(mie);D7o=r(Kst,"vilt"),Kst.forEach(t),G7o=r(Aye," \u2014 "),ON=n(Aye,"A",{href:!0});var Zst=s(ON);O7o=r(Zst,"ViltProcessor"),Zst.forEach(t),V7o=r(Aye," (ViLT model)"),Aye.forEach(t),X7o=i(be),Tp=n(be,"LI",{});var Lye=s(Tp);gie=n(Lye,"STRONG",{});var elt=s(gie);z7o=r(elt,"vision-text-dual-encoder"),elt.forEach(t),W7o=r(Lye," \u2014 "),VN=n(Lye,"A",{href:!0});var olt=s(VN);Q7o=r(olt,"VisionTextDualEncoderProcessor"),olt.forEach(t),H7o=r(Lye," (VisionTextDualEncoder model)"),Lye.forEach(t),U7o=i(be),Mp=n(be,"LI",{});var yye=s(Mp);hie=n(yye,"STRONG",{});var rlt=s(hie);J7o=r(rlt,"wav2vec2"),rlt.forEach(t),Y7o=r(yye," \u2014 "),XN=n(yye,"A",{href:!0});var tlt=s(XN);K7o=r(tlt,"Wav2Vec2Processor"),tlt.forEach(t),Z7o=r(yye," (Wav2Vec2 model)"),yye.forEach(t),e2o=i(be),Ep=n(be,"LI",{});var xye=s(Ep);pie=n(xye,"STRONG",{});var alt=s(pie);o2o=r(alt,"wav2vec2-conformer"),alt.forEach(t),r2o=r(xye," \u2014 "),zN=n(xye,"A",{href:!0});var nlt=s(zN);t2o=r(nlt,"Wav2Vec2Processor"),nlt.forEach(t),a2o=r(xye," (Wav2Vec2-Conformer model)"),xye.forEach(t),n2o=i(be),Cp=n(be,"LI",{});var $ye=s(Cp);uie=n($ye,"STRONG",{});var slt=s(uie);s2o=r(slt,"wavlm"),slt.forEach(t),l2o=r($ye," \u2014 "),WN=n($ye,"A",{href:!0});var llt=s(WN);i2o=r(llt,"Wav2Vec2Processor"),llt.forEach(t),d2o=r($ye," (WavLM model)"),$ye.forEach(t),be.forEach(t),c2o=i(ta),T(wp.$$.fragment,ta),f2o=i(ta),T(Ap.$$.fragment,ta),ta.forEach(t),m2o=i(Hs),Lp=n(Hs,"DIV",{class:!0});var SVe=s(Lp);T(HL.$$.fragment,SVe),g2o=i(SVe),_ie=n(SVe,"P",{});var ilt=s(_ie);h2o=r(ilt,"Register a new processor for this class."),ilt.forEach(t),SVe.forEach(t),Hs.forEach(t),LGe=i(f),Pi=n(f,"H2",{class:!0});var RVe=s(Pi);yp=n(RVe,"A",{id:!0,class:!0,href:!0});var dlt=s(yp);bie=n(dlt,"SPAN",{});var clt=s(bie);T(UL.$$.fragment,clt),clt.forEach(t),dlt.forEach(t),p2o=i(RVe),vie=n(RVe,"SPAN",{});var flt=s(vie);u2o=r(flt,"AutoModel"),flt.forEach(t),RVe.forEach(t),yGe=i(f),xo=n(f,"DIV",{class:!0});var Us=s(xo);T(JL.$$.fragment,Us),_2o=i(Us),Bi=n(Us,"P",{});var noe=s(Bi);b2o=r(noe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),QN=n(noe,"A",{href:!0});var mlt=s(QN);v2o=r(mlt,"from_pretrained()"),mlt.forEach(t),F2o=r(noe," class method or the "),HN=n(noe,"A",{href:!0});var glt=s(HN);T2o=r(glt,"from_config()"),glt.forEach(t),M2o=r(noe,` class
method.`),noe.forEach(t),E2o=i(Us),YL=n(Us,"P",{});var PVe=s(YL);C2o=r(PVe,"This class cannot be instantiated directly using "),Fie=n(PVe,"CODE",{});var hlt=s(Fie);w2o=r(hlt,"__init__()"),hlt.forEach(t),A2o=r(PVe," (throws an error)."),PVe.forEach(t),L2o=i(Us),nt=n(Us,"DIV",{class:!0});var wA=s(nt);T(KL.$$.fragment,wA),y2o=i(wA),Tie=n(wA,"P",{});var plt=s(Tie);x2o=r(plt,"Instantiates one of the base model classes of the library from a configuration."),plt.forEach(t),$2o=i(wA),Ii=n(wA,"P",{});var soe=s(Ii);k2o=r(soe,`Note:
Loading a model from its configuration file does `),Mie=n(soe,"STRONG",{});var ult=s(Mie);S2o=r(ult,"not"),ult.forEach(t),R2o=r(soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),UN=n(soe,"A",{href:!0});var _lt=s(UN);P2o=r(_lt,"from_pretrained()"),_lt.forEach(t),B2o=r(soe," to load the model weights."),soe.forEach(t),I2o=i(wA),T(xp.$$.fragment,wA),wA.forEach(t),N2o=i(Us),Je=n(Us,"DIV",{class:!0});var aa=s(Je);T(ZL.$$.fragment,aa),q2o=i(aa),Eie=n(aa,"P",{});var blt=s(Eie);j2o=r(blt,"Instantiate one of the base model classes of the library from a pretrained model."),blt.forEach(t),D2o=i(aa),Sa=n(aa,"P",{});var AA=s(Sa);G2o=r(AA,"The model class to instantiate is selected based on the "),Cie=n(AA,"CODE",{});var vlt=s(Cie);O2o=r(vlt,"model_type"),vlt.forEach(t),V2o=r(AA,` property of the config object (either
passed as an argument or loaded from `),wie=n(AA,"CODE",{});var Flt=s(wie);X2o=r(Flt,"pretrained_model_name_or_path"),Flt.forEach(t),z2o=r(AA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Aie=n(AA,"CODE",{});var Tlt=s(Aie);W2o=r(Tlt,"pretrained_model_name_or_path"),Tlt.forEach(t),Q2o=r(AA,":"),AA.forEach(t),H2o=i(aa),y=n(aa,"UL",{});var $=s(y);$p=n($,"LI",{});var kye=s($p);Lie=n(kye,"STRONG",{});var Mlt=s(Lie);U2o=r(Mlt,"albert"),Mlt.forEach(t),J2o=r(kye," \u2014 "),JN=n(kye,"A",{href:!0});var Elt=s(JN);Y2o=r(Elt,"AlbertModel"),Elt.forEach(t),K2o=r(kye," (ALBERT model)"),kye.forEach(t),Z2o=i($),kp=n($,"LI",{});var Sye=s(kp);yie=n(Sye,"STRONG",{});var Clt=s(yie);e1o=r(Clt,"bart"),Clt.forEach(t),o1o=r(Sye," \u2014 "),YN=n(Sye,"A",{href:!0});var wlt=s(YN);r1o=r(wlt,"BartModel"),wlt.forEach(t),t1o=r(Sye," (BART model)"),Sye.forEach(t),a1o=i($),Sp=n($,"LI",{});var Rye=s(Sp);xie=n(Rye,"STRONG",{});var Alt=s(xie);n1o=r(Alt,"beit"),Alt.forEach(t),s1o=r(Rye," \u2014 "),KN=n(Rye,"A",{href:!0});var Llt=s(KN);l1o=r(Llt,"BeitModel"),Llt.forEach(t),i1o=r(Rye," (BEiT model)"),Rye.forEach(t),d1o=i($),Rp=n($,"LI",{});var Pye=s(Rp);$ie=n(Pye,"STRONG",{});var ylt=s($ie);c1o=r(ylt,"bert"),ylt.forEach(t),f1o=r(Pye," \u2014 "),ZN=n(Pye,"A",{href:!0});var xlt=s(ZN);m1o=r(xlt,"BertModel"),xlt.forEach(t),g1o=r(Pye," (BERT model)"),Pye.forEach(t),h1o=i($),Pp=n($,"LI",{});var Bye=s(Pp);kie=n(Bye,"STRONG",{});var $lt=s(kie);p1o=r($lt,"bert-generation"),$lt.forEach(t),u1o=r(Bye," \u2014 "),eq=n(Bye,"A",{href:!0});var klt=s(eq);_1o=r(klt,"BertGenerationEncoder"),klt.forEach(t),b1o=r(Bye," (Bert Generation model)"),Bye.forEach(t),v1o=i($),Bp=n($,"LI",{});var Iye=s(Bp);Sie=n(Iye,"STRONG",{});var Slt=s(Sie);F1o=r(Slt,"big_bird"),Slt.forEach(t),T1o=r(Iye," \u2014 "),oq=n(Iye,"A",{href:!0});var Rlt=s(oq);M1o=r(Rlt,"BigBirdModel"),Rlt.forEach(t),E1o=r(Iye," (BigBird model)"),Iye.forEach(t),C1o=i($),Ip=n($,"LI",{});var Nye=s(Ip);Rie=n(Nye,"STRONG",{});var Plt=s(Rie);w1o=r(Plt,"bigbird_pegasus"),Plt.forEach(t),A1o=r(Nye," \u2014 "),rq=n(Nye,"A",{href:!0});var Blt=s(rq);L1o=r(Blt,"BigBirdPegasusModel"),Blt.forEach(t),y1o=r(Nye," (BigBird-Pegasus model)"),Nye.forEach(t),x1o=i($),Np=n($,"LI",{});var qye=s(Np);Pie=n(qye,"STRONG",{});var Ilt=s(Pie);$1o=r(Ilt,"blenderbot"),Ilt.forEach(t),k1o=r(qye," \u2014 "),tq=n(qye,"A",{href:!0});var Nlt=s(tq);S1o=r(Nlt,"BlenderbotModel"),Nlt.forEach(t),R1o=r(qye," (Blenderbot model)"),qye.forEach(t),P1o=i($),qp=n($,"LI",{});var jye=s(qp);Bie=n(jye,"STRONG",{});var qlt=s(Bie);B1o=r(qlt,"blenderbot-small"),qlt.forEach(t),I1o=r(jye," \u2014 "),aq=n(jye,"A",{href:!0});var jlt=s(aq);N1o=r(jlt,"BlenderbotSmallModel"),jlt.forEach(t),q1o=r(jye," (BlenderbotSmall model)"),jye.forEach(t),j1o=i($),jp=n($,"LI",{});var Dye=s(jp);Iie=n(Dye,"STRONG",{});var Dlt=s(Iie);D1o=r(Dlt,"bloom"),Dlt.forEach(t),G1o=r(Dye," \u2014 "),nq=n(Dye,"A",{href:!0});var Glt=s(nq);O1o=r(Glt,"BloomModel"),Glt.forEach(t),V1o=r(Dye," (BLOOM model)"),Dye.forEach(t),X1o=i($),Dp=n($,"LI",{});var Gye=s(Dp);Nie=n(Gye,"STRONG",{});var Olt=s(Nie);z1o=r(Olt,"camembert"),Olt.forEach(t),W1o=r(Gye," \u2014 "),sq=n(Gye,"A",{href:!0});var Vlt=s(sq);Q1o=r(Vlt,"CamembertModel"),Vlt.forEach(t),H1o=r(Gye," (CamemBERT model)"),Gye.forEach(t),U1o=i($),Gp=n($,"LI",{});var Oye=s(Gp);qie=n(Oye,"STRONG",{});var Xlt=s(qie);J1o=r(Xlt,"canine"),Xlt.forEach(t),Y1o=r(Oye," \u2014 "),lq=n(Oye,"A",{href:!0});var zlt=s(lq);K1o=r(zlt,"CanineModel"),zlt.forEach(t),Z1o=r(Oye," (CANINE model)"),Oye.forEach(t),ebo=i($),Op=n($,"LI",{});var Vye=s(Op);jie=n(Vye,"STRONG",{});var Wlt=s(jie);obo=r(Wlt,"clip"),Wlt.forEach(t),rbo=r(Vye," \u2014 "),iq=n(Vye,"A",{href:!0});var Qlt=s(iq);tbo=r(Qlt,"CLIPModel"),Qlt.forEach(t),abo=r(Vye," (CLIP model)"),Vye.forEach(t),nbo=i($),Vp=n($,"LI",{});var Xye=s(Vp);Die=n(Xye,"STRONG",{});var Hlt=s(Die);sbo=r(Hlt,"convbert"),Hlt.forEach(t),lbo=r(Xye," \u2014 "),dq=n(Xye,"A",{href:!0});var Ult=s(dq);ibo=r(Ult,"ConvBertModel"),Ult.forEach(t),dbo=r(Xye," (ConvBERT model)"),Xye.forEach(t),cbo=i($),Xp=n($,"LI",{});var zye=s(Xp);Gie=n(zye,"STRONG",{});var Jlt=s(Gie);fbo=r(Jlt,"convnext"),Jlt.forEach(t),mbo=r(zye," \u2014 "),cq=n(zye,"A",{href:!0});var Ylt=s(cq);gbo=r(Ylt,"ConvNextModel"),Ylt.forEach(t),hbo=r(zye," (ConvNeXT model)"),zye.forEach(t),pbo=i($),zp=n($,"LI",{});var Wye=s(zp);Oie=n(Wye,"STRONG",{});var Klt=s(Oie);ubo=r(Klt,"ctrl"),Klt.forEach(t),_bo=r(Wye," \u2014 "),fq=n(Wye,"A",{href:!0});var Zlt=s(fq);bbo=r(Zlt,"CTRLModel"),Zlt.forEach(t),vbo=r(Wye," (CTRL model)"),Wye.forEach(t),Fbo=i($),Wp=n($,"LI",{});var Qye=s(Wp);Vie=n(Qye,"STRONG",{});var eit=s(Vie);Tbo=r(eit,"cvt"),eit.forEach(t),Mbo=r(Qye," \u2014 "),mq=n(Qye,"A",{href:!0});var oit=s(mq);Ebo=r(oit,"CvtModel"),oit.forEach(t),Cbo=r(Qye," (CvT model)"),Qye.forEach(t),wbo=i($),Qp=n($,"LI",{});var Hye=s(Qp);Xie=n(Hye,"STRONG",{});var rit=s(Xie);Abo=r(rit,"data2vec-audio"),rit.forEach(t),Lbo=r(Hye," \u2014 "),gq=n(Hye,"A",{href:!0});var tit=s(gq);ybo=r(tit,"Data2VecAudioModel"),tit.forEach(t),xbo=r(Hye," (Data2VecAudio model)"),Hye.forEach(t),$bo=i($),Hp=n($,"LI",{});var Uye=s(Hp);zie=n(Uye,"STRONG",{});var ait=s(zie);kbo=r(ait,"data2vec-text"),ait.forEach(t),Sbo=r(Uye," \u2014 "),hq=n(Uye,"A",{href:!0});var nit=s(hq);Rbo=r(nit,"Data2VecTextModel"),nit.forEach(t),Pbo=r(Uye," (Data2VecText model)"),Uye.forEach(t),Bbo=i($),Up=n($,"LI",{});var Jye=s(Up);Wie=n(Jye,"STRONG",{});var sit=s(Wie);Ibo=r(sit,"data2vec-vision"),sit.forEach(t),Nbo=r(Jye," \u2014 "),pq=n(Jye,"A",{href:!0});var lit=s(pq);qbo=r(lit,"Data2VecVisionModel"),lit.forEach(t),jbo=r(Jye," (Data2VecVision model)"),Jye.forEach(t),Dbo=i($),Jp=n($,"LI",{});var Yye=s(Jp);Qie=n(Yye,"STRONG",{});var iit=s(Qie);Gbo=r(iit,"deberta"),iit.forEach(t),Obo=r(Yye," \u2014 "),uq=n(Yye,"A",{href:!0});var dit=s(uq);Vbo=r(dit,"DebertaModel"),dit.forEach(t),Xbo=r(Yye," (DeBERTa model)"),Yye.forEach(t),zbo=i($),Yp=n($,"LI",{});var Kye=s(Yp);Hie=n(Kye,"STRONG",{});var cit=s(Hie);Wbo=r(cit,"deberta-v2"),cit.forEach(t),Qbo=r(Kye," \u2014 "),_q=n(Kye,"A",{href:!0});var fit=s(_q);Hbo=r(fit,"DebertaV2Model"),fit.forEach(t),Ubo=r(Kye," (DeBERTa-v2 model)"),Kye.forEach(t),Jbo=i($),Kp=n($,"LI",{});var Zye=s(Kp);Uie=n(Zye,"STRONG",{});var mit=s(Uie);Ybo=r(mit,"decision_transformer"),mit.forEach(t),Kbo=r(Zye," \u2014 "),bq=n(Zye,"A",{href:!0});var git=s(bq);Zbo=r(git,"DecisionTransformerModel"),git.forEach(t),evo=r(Zye," (Decision Transformer model)"),Zye.forEach(t),ovo=i($),Zp=n($,"LI",{});var e8e=s(Zp);Jie=n(e8e,"STRONG",{});var hit=s(Jie);rvo=r(hit,"deit"),hit.forEach(t),tvo=r(e8e," \u2014 "),vq=n(e8e,"A",{href:!0});var pit=s(vq);avo=r(pit,"DeiTModel"),pit.forEach(t),nvo=r(e8e," (DeiT model)"),e8e.forEach(t),svo=i($),eu=n($,"LI",{});var o8e=s(eu);Yie=n(o8e,"STRONG",{});var uit=s(Yie);lvo=r(uit,"detr"),uit.forEach(t),ivo=r(o8e," \u2014 "),Fq=n(o8e,"A",{href:!0});var _it=s(Fq);dvo=r(_it,"DetrModel"),_it.forEach(t),cvo=r(o8e," (DETR model)"),o8e.forEach(t),fvo=i($),ou=n($,"LI",{});var r8e=s(ou);Kie=n(r8e,"STRONG",{});var bit=s(Kie);mvo=r(bit,"distilbert"),bit.forEach(t),gvo=r(r8e," \u2014 "),Tq=n(r8e,"A",{href:!0});var vit=s(Tq);hvo=r(vit,"DistilBertModel"),vit.forEach(t),pvo=r(r8e," (DistilBERT model)"),r8e.forEach(t),uvo=i($),ru=n($,"LI",{});var t8e=s(ru);Zie=n(t8e,"STRONG",{});var Fit=s(Zie);_vo=r(Fit,"dpr"),Fit.forEach(t),bvo=r(t8e," \u2014 "),Mq=n(t8e,"A",{href:!0});var Tit=s(Mq);vvo=r(Tit,"DPRQuestionEncoder"),Tit.forEach(t),Fvo=r(t8e," (DPR model)"),t8e.forEach(t),Tvo=i($),tu=n($,"LI",{});var a8e=s(tu);ede=n(a8e,"STRONG",{});var Mit=s(ede);Mvo=r(Mit,"dpt"),Mit.forEach(t),Evo=r(a8e," \u2014 "),Eq=n(a8e,"A",{href:!0});var Eit=s(Eq);Cvo=r(Eit,"DPTModel"),Eit.forEach(t),wvo=r(a8e," (DPT model)"),a8e.forEach(t),Avo=i($),au=n($,"LI",{});var n8e=s(au);ode=n(n8e,"STRONG",{});var Cit=s(ode);Lvo=r(Cit,"electra"),Cit.forEach(t),yvo=r(n8e," \u2014 "),Cq=n(n8e,"A",{href:!0});var wit=s(Cq);xvo=r(wit,"ElectraModel"),wit.forEach(t),$vo=r(n8e," (ELECTRA model)"),n8e.forEach(t),kvo=i($),nu=n($,"LI",{});var s8e=s(nu);rde=n(s8e,"STRONG",{});var Ait=s(rde);Svo=r(Ait,"flaubert"),Ait.forEach(t),Rvo=r(s8e," \u2014 "),wq=n(s8e,"A",{href:!0});var Lit=s(wq);Pvo=r(Lit,"FlaubertModel"),Lit.forEach(t),Bvo=r(s8e," (FlauBERT model)"),s8e.forEach(t),Ivo=i($),su=n($,"LI",{});var l8e=s(su);tde=n(l8e,"STRONG",{});var yit=s(tde);Nvo=r(yit,"flava"),yit.forEach(t),qvo=r(l8e," \u2014 "),Aq=n(l8e,"A",{href:!0});var xit=s(Aq);jvo=r(xit,"FlavaModel"),xit.forEach(t),Dvo=r(l8e," (FLAVA model)"),l8e.forEach(t),Gvo=i($),lu=n($,"LI",{});var i8e=s(lu);ade=n(i8e,"STRONG",{});var $it=s(ade);Ovo=r($it,"fnet"),$it.forEach(t),Vvo=r(i8e," \u2014 "),Lq=n(i8e,"A",{href:!0});var kit=s(Lq);Xvo=r(kit,"FNetModel"),kit.forEach(t),zvo=r(i8e," (FNet model)"),i8e.forEach(t),Wvo=i($),iu=n($,"LI",{});var d8e=s(iu);nde=n(d8e,"STRONG",{});var Sit=s(nde);Qvo=r(Sit,"fsmt"),Sit.forEach(t),Hvo=r(d8e," \u2014 "),yq=n(d8e,"A",{href:!0});var Rit=s(yq);Uvo=r(Rit,"FSMTModel"),Rit.forEach(t),Jvo=r(d8e," (FairSeq Machine-Translation model)"),d8e.forEach(t),Yvo=i($),Gs=n($,"LI",{});var zk=s(Gs);sde=n(zk,"STRONG",{});var Pit=s(sde);Kvo=r(Pit,"funnel"),Pit.forEach(t),Zvo=r(zk," \u2014 "),xq=n(zk,"A",{href:!0});var Bit=s(xq);eFo=r(Bit,"FunnelModel"),Bit.forEach(t),oFo=r(zk," or "),$q=n(zk,"A",{href:!0});var Iit=s($q);rFo=r(Iit,"FunnelBaseModel"),Iit.forEach(t),tFo=r(zk," (Funnel Transformer model)"),zk.forEach(t),aFo=i($),du=n($,"LI",{});var c8e=s(du);lde=n(c8e,"STRONG",{});var Nit=s(lde);nFo=r(Nit,"glpn"),Nit.forEach(t),sFo=r(c8e," \u2014 "),kq=n(c8e,"A",{href:!0});var qit=s(kq);lFo=r(qit,"GLPNModel"),qit.forEach(t),iFo=r(c8e," (GLPN model)"),c8e.forEach(t),dFo=i($),cu=n($,"LI",{});var f8e=s(cu);ide=n(f8e,"STRONG",{});var jit=s(ide);cFo=r(jit,"gpt2"),jit.forEach(t),fFo=r(f8e," \u2014 "),Sq=n(f8e,"A",{href:!0});var Dit=s(Sq);mFo=r(Dit,"GPT2Model"),Dit.forEach(t),gFo=r(f8e," (OpenAI GPT-2 model)"),f8e.forEach(t),hFo=i($),fu=n($,"LI",{});var m8e=s(fu);dde=n(m8e,"STRONG",{});var Git=s(dde);pFo=r(Git,"gpt_neo"),Git.forEach(t),uFo=r(m8e," \u2014 "),Rq=n(m8e,"A",{href:!0});var Oit=s(Rq);_Fo=r(Oit,"GPTNeoModel"),Oit.forEach(t),bFo=r(m8e," (GPT Neo model)"),m8e.forEach(t),vFo=i($),mu=n($,"LI",{});var g8e=s(mu);cde=n(g8e,"STRONG",{});var Vit=s(cde);FFo=r(Vit,"gpt_neox"),Vit.forEach(t),TFo=r(g8e," \u2014 "),Pq=n(g8e,"A",{href:!0});var Xit=s(Pq);MFo=r(Xit,"GPTNeoXModel"),Xit.forEach(t),EFo=r(g8e," (GPT NeoX model)"),g8e.forEach(t),CFo=i($),gu=n($,"LI",{});var h8e=s(gu);fde=n(h8e,"STRONG",{});var zit=s(fde);wFo=r(zit,"gptj"),zit.forEach(t),AFo=r(h8e," \u2014 "),Bq=n(h8e,"A",{href:!0});var Wit=s(Bq);LFo=r(Wit,"GPTJModel"),Wit.forEach(t),yFo=r(h8e," (GPT-J model)"),h8e.forEach(t),xFo=i($),hu=n($,"LI",{});var p8e=s(hu);mde=n(p8e,"STRONG",{});var Qit=s(mde);$Fo=r(Qit,"hubert"),Qit.forEach(t),kFo=r(p8e," \u2014 "),Iq=n(p8e,"A",{href:!0});var Hit=s(Iq);SFo=r(Hit,"HubertModel"),Hit.forEach(t),RFo=r(p8e," (Hubert model)"),p8e.forEach(t),PFo=i($),pu=n($,"LI",{});var u8e=s(pu);gde=n(u8e,"STRONG",{});var Uit=s(gde);BFo=r(Uit,"ibert"),Uit.forEach(t),IFo=r(u8e," \u2014 "),Nq=n(u8e,"A",{href:!0});var Jit=s(Nq);NFo=r(Jit,"IBertModel"),Jit.forEach(t),qFo=r(u8e," (I-BERT model)"),u8e.forEach(t),jFo=i($),uu=n($,"LI",{});var _8e=s(uu);hde=n(_8e,"STRONG",{});var Yit=s(hde);DFo=r(Yit,"imagegpt"),Yit.forEach(t),GFo=r(_8e," \u2014 "),qq=n(_8e,"A",{href:!0});var Kit=s(qq);OFo=r(Kit,"ImageGPTModel"),Kit.forEach(t),VFo=r(_8e," (ImageGPT model)"),_8e.forEach(t),XFo=i($),_u=n($,"LI",{});var b8e=s(_u);pde=n(b8e,"STRONG",{});var Zit=s(pde);zFo=r(Zit,"layoutlm"),Zit.forEach(t),WFo=r(b8e," \u2014 "),jq=n(b8e,"A",{href:!0});var edt=s(jq);QFo=r(edt,"LayoutLMModel"),edt.forEach(t),HFo=r(b8e," (LayoutLM model)"),b8e.forEach(t),UFo=i($),bu=n($,"LI",{});var v8e=s(bu);ude=n(v8e,"STRONG",{});var odt=s(ude);JFo=r(odt,"layoutlmv2"),odt.forEach(t),YFo=r(v8e," \u2014 "),Dq=n(v8e,"A",{href:!0});var rdt=s(Dq);KFo=r(rdt,"LayoutLMv2Model"),rdt.forEach(t),ZFo=r(v8e," (LayoutLMv2 model)"),v8e.forEach(t),eTo=i($),vu=n($,"LI",{});var F8e=s(vu);_de=n(F8e,"STRONG",{});var tdt=s(_de);oTo=r(tdt,"layoutlmv3"),tdt.forEach(t),rTo=r(F8e," \u2014 "),Gq=n(F8e,"A",{href:!0});var adt=s(Gq);tTo=r(adt,"LayoutLMv3Model"),adt.forEach(t),aTo=r(F8e," (LayoutLMv3 model)"),F8e.forEach(t),nTo=i($),Fu=n($,"LI",{});var T8e=s(Fu);bde=n(T8e,"STRONG",{});var ndt=s(bde);sTo=r(ndt,"led"),ndt.forEach(t),lTo=r(T8e," \u2014 "),Oq=n(T8e,"A",{href:!0});var sdt=s(Oq);iTo=r(sdt,"LEDModel"),sdt.forEach(t),dTo=r(T8e," (LED model)"),T8e.forEach(t),cTo=i($),Tu=n($,"LI",{});var M8e=s(Tu);vde=n(M8e,"STRONG",{});var ldt=s(vde);fTo=r(ldt,"levit"),ldt.forEach(t),mTo=r(M8e," \u2014 "),Vq=n(M8e,"A",{href:!0});var idt=s(Vq);gTo=r(idt,"LevitModel"),idt.forEach(t),hTo=r(M8e," (LeViT model)"),M8e.forEach(t),pTo=i($),Mu=n($,"LI",{});var E8e=s(Mu);Fde=n(E8e,"STRONG",{});var ddt=s(Fde);uTo=r(ddt,"longformer"),ddt.forEach(t),_To=r(E8e," \u2014 "),Xq=n(E8e,"A",{href:!0});var cdt=s(Xq);bTo=r(cdt,"LongformerModel"),cdt.forEach(t),vTo=r(E8e," (Longformer model)"),E8e.forEach(t),FTo=i($),Eu=n($,"LI",{});var C8e=s(Eu);Tde=n(C8e,"STRONG",{});var fdt=s(Tde);TTo=r(fdt,"longt5"),fdt.forEach(t),MTo=r(C8e," \u2014 "),zq=n(C8e,"A",{href:!0});var mdt=s(zq);ETo=r(mdt,"LongT5Model"),mdt.forEach(t),CTo=r(C8e," (LongT5 model)"),C8e.forEach(t),wTo=i($),Cu=n($,"LI",{});var w8e=s(Cu);Mde=n(w8e,"STRONG",{});var gdt=s(Mde);ATo=r(gdt,"luke"),gdt.forEach(t),LTo=r(w8e," \u2014 "),Wq=n(w8e,"A",{href:!0});var hdt=s(Wq);yTo=r(hdt,"LukeModel"),hdt.forEach(t),xTo=r(w8e," (LUKE model)"),w8e.forEach(t),$To=i($),wu=n($,"LI",{});var A8e=s(wu);Ede=n(A8e,"STRONG",{});var pdt=s(Ede);kTo=r(pdt,"lxmert"),pdt.forEach(t),STo=r(A8e," \u2014 "),Qq=n(A8e,"A",{href:!0});var udt=s(Qq);RTo=r(udt,"LxmertModel"),udt.forEach(t),PTo=r(A8e," (LXMERT model)"),A8e.forEach(t),BTo=i($),Au=n($,"LI",{});var L8e=s(Au);Cde=n(L8e,"STRONG",{});var _dt=s(Cde);ITo=r(_dt,"m2m_100"),_dt.forEach(t),NTo=r(L8e," \u2014 "),Hq=n(L8e,"A",{href:!0});var bdt=s(Hq);qTo=r(bdt,"M2M100Model"),bdt.forEach(t),jTo=r(L8e," (M2M100 model)"),L8e.forEach(t),DTo=i($),Lu=n($,"LI",{});var y8e=s(Lu);wde=n(y8e,"STRONG",{});var vdt=s(wde);GTo=r(vdt,"marian"),vdt.forEach(t),OTo=r(y8e," \u2014 "),Uq=n(y8e,"A",{href:!0});var Fdt=s(Uq);VTo=r(Fdt,"MarianModel"),Fdt.forEach(t),XTo=r(y8e," (Marian model)"),y8e.forEach(t),zTo=i($),yu=n($,"LI",{});var x8e=s(yu);Ade=n(x8e,"STRONG",{});var Tdt=s(Ade);WTo=r(Tdt,"maskformer"),Tdt.forEach(t),QTo=r(x8e," \u2014 "),Jq=n(x8e,"A",{href:!0});var Mdt=s(Jq);HTo=r(Mdt,"MaskFormerModel"),Mdt.forEach(t),UTo=r(x8e," (MaskFormer model)"),x8e.forEach(t),JTo=i($),xu=n($,"LI",{});var $8e=s(xu);Lde=n($8e,"STRONG",{});var Edt=s(Lde);YTo=r(Edt,"mbart"),Edt.forEach(t),KTo=r($8e," \u2014 "),Yq=n($8e,"A",{href:!0});var Cdt=s(Yq);ZTo=r(Cdt,"MBartModel"),Cdt.forEach(t),eMo=r($8e," (mBART model)"),$8e.forEach(t),oMo=i($),$u=n($,"LI",{});var k8e=s($u);yde=n(k8e,"STRONG",{});var wdt=s(yde);rMo=r(wdt,"mctct"),wdt.forEach(t),tMo=r(k8e," \u2014 "),Kq=n(k8e,"A",{href:!0});var Adt=s(Kq);aMo=r(Adt,"MCTCTModel"),Adt.forEach(t),nMo=r(k8e," (M-CTC-T model)"),k8e.forEach(t),sMo=i($),ku=n($,"LI",{});var S8e=s(ku);xde=n(S8e,"STRONG",{});var Ldt=s(xde);lMo=r(Ldt,"megatron-bert"),Ldt.forEach(t),iMo=r(S8e," \u2014 "),Zq=n(S8e,"A",{href:!0});var ydt=s(Zq);dMo=r(ydt,"MegatronBertModel"),ydt.forEach(t),cMo=r(S8e," (Megatron-BERT model)"),S8e.forEach(t),fMo=i($),Su=n($,"LI",{});var R8e=s(Su);$de=n(R8e,"STRONG",{});var xdt=s($de);mMo=r(xdt,"mobilebert"),xdt.forEach(t),gMo=r(R8e," \u2014 "),ej=n(R8e,"A",{href:!0});var $dt=s(ej);hMo=r($dt,"MobileBertModel"),$dt.forEach(t),pMo=r(R8e," (MobileBERT model)"),R8e.forEach(t),uMo=i($),Ru=n($,"LI",{});var P8e=s(Ru);kde=n(P8e,"STRONG",{});var kdt=s(kde);_Mo=r(kdt,"mpnet"),kdt.forEach(t),bMo=r(P8e," \u2014 "),oj=n(P8e,"A",{href:!0});var Sdt=s(oj);vMo=r(Sdt,"MPNetModel"),Sdt.forEach(t),FMo=r(P8e," (MPNet model)"),P8e.forEach(t),TMo=i($),Pu=n($,"LI",{});var B8e=s(Pu);Sde=n(B8e,"STRONG",{});var Rdt=s(Sde);MMo=r(Rdt,"mt5"),Rdt.forEach(t),EMo=r(B8e," \u2014 "),rj=n(B8e,"A",{href:!0});var Pdt=s(rj);CMo=r(Pdt,"MT5Model"),Pdt.forEach(t),wMo=r(B8e," (MT5 model)"),B8e.forEach(t),AMo=i($),Bu=n($,"LI",{});var I8e=s(Bu);Rde=n(I8e,"STRONG",{});var Bdt=s(Rde);LMo=r(Bdt,"nystromformer"),Bdt.forEach(t),yMo=r(I8e," \u2014 "),tj=n(I8e,"A",{href:!0});var Idt=s(tj);xMo=r(Idt,"NystromformerModel"),Idt.forEach(t),$Mo=r(I8e," (Nystr\xF6mformer model)"),I8e.forEach(t),kMo=i($),Iu=n($,"LI",{});var N8e=s(Iu);Pde=n(N8e,"STRONG",{});var Ndt=s(Pde);SMo=r(Ndt,"omnivore"),Ndt.forEach(t),RMo=r(N8e," \u2014 "),aj=n(N8e,"A",{href:!0});var qdt=s(aj);PMo=r(qdt,"OmnivoreModel"),qdt.forEach(t),BMo=r(N8e," (Omnivore model)"),N8e.forEach(t),IMo=i($),Nu=n($,"LI",{});var q8e=s(Nu);Bde=n(q8e,"STRONG",{});var jdt=s(Bde);NMo=r(jdt,"openai-gpt"),jdt.forEach(t),qMo=r(q8e," \u2014 "),nj=n(q8e,"A",{href:!0});var Ddt=s(nj);jMo=r(Ddt,"OpenAIGPTModel"),Ddt.forEach(t),DMo=r(q8e," (OpenAI GPT model)"),q8e.forEach(t),GMo=i($),qu=n($,"LI",{});var j8e=s(qu);Ide=n(j8e,"STRONG",{});var Gdt=s(Ide);OMo=r(Gdt,"opt"),Gdt.forEach(t),VMo=r(j8e," \u2014 "),sj=n(j8e,"A",{href:!0});var Odt=s(sj);XMo=r(Odt,"OPTModel"),Odt.forEach(t),zMo=r(j8e," (OPT model)"),j8e.forEach(t),WMo=i($),ju=n($,"LI",{});var D8e=s(ju);Nde=n(D8e,"STRONG",{});var Vdt=s(Nde);QMo=r(Vdt,"pegasus"),Vdt.forEach(t),HMo=r(D8e," \u2014 "),lj=n(D8e,"A",{href:!0});var Xdt=s(lj);UMo=r(Xdt,"PegasusModel"),Xdt.forEach(t),JMo=r(D8e," (Pegasus model)"),D8e.forEach(t),YMo=i($),Du=n($,"LI",{});var G8e=s(Du);qde=n(G8e,"STRONG",{});var zdt=s(qde);KMo=r(zdt,"perceiver"),zdt.forEach(t),ZMo=r(G8e," \u2014 "),ij=n(G8e,"A",{href:!0});var Wdt=s(ij);eEo=r(Wdt,"PerceiverModel"),Wdt.forEach(t),oEo=r(G8e," (Perceiver model)"),G8e.forEach(t),rEo=i($),Gu=n($,"LI",{});var O8e=s(Gu);jde=n(O8e,"STRONG",{});var Qdt=s(jde);tEo=r(Qdt,"plbart"),Qdt.forEach(t),aEo=r(O8e," \u2014 "),dj=n(O8e,"A",{href:!0});var Hdt=s(dj);nEo=r(Hdt,"PLBartModel"),Hdt.forEach(t),sEo=r(O8e," (PLBart model)"),O8e.forEach(t),lEo=i($),Ou=n($,"LI",{});var V8e=s(Ou);Dde=n(V8e,"STRONG",{});var Udt=s(Dde);iEo=r(Udt,"poolformer"),Udt.forEach(t),dEo=r(V8e," \u2014 "),cj=n(V8e,"A",{href:!0});var Jdt=s(cj);cEo=r(Jdt,"PoolFormerModel"),Jdt.forEach(t),fEo=r(V8e," (PoolFormer model)"),V8e.forEach(t),mEo=i($),Vu=n($,"LI",{});var X8e=s(Vu);Gde=n(X8e,"STRONG",{});var Ydt=s(Gde);gEo=r(Ydt,"prophetnet"),Ydt.forEach(t),hEo=r(X8e," \u2014 "),fj=n(X8e,"A",{href:!0});var Kdt=s(fj);pEo=r(Kdt,"ProphetNetModel"),Kdt.forEach(t),uEo=r(X8e," (ProphetNet model)"),X8e.forEach(t),_Eo=i($),Xu=n($,"LI",{});var z8e=s(Xu);Ode=n(z8e,"STRONG",{});var Zdt=s(Ode);bEo=r(Zdt,"qdqbert"),Zdt.forEach(t),vEo=r(z8e," \u2014 "),mj=n(z8e,"A",{href:!0});var ect=s(mj);FEo=r(ect,"QDQBertModel"),ect.forEach(t),TEo=r(z8e," (QDQBert model)"),z8e.forEach(t),MEo=i($),zu=n($,"LI",{});var W8e=s(zu);Vde=n(W8e,"STRONG",{});var oct=s(Vde);EEo=r(oct,"reformer"),oct.forEach(t),CEo=r(W8e," \u2014 "),gj=n(W8e,"A",{href:!0});var rct=s(gj);wEo=r(rct,"ReformerModel"),rct.forEach(t),AEo=r(W8e," (Reformer model)"),W8e.forEach(t),LEo=i($),Wu=n($,"LI",{});var Q8e=s(Wu);Xde=n(Q8e,"STRONG",{});var tct=s(Xde);yEo=r(tct,"regnet"),tct.forEach(t),xEo=r(Q8e," \u2014 "),hj=n(Q8e,"A",{href:!0});var act=s(hj);$Eo=r(act,"RegNetModel"),act.forEach(t),kEo=r(Q8e," (RegNet model)"),Q8e.forEach(t),SEo=i($),Qu=n($,"LI",{});var H8e=s(Qu);zde=n(H8e,"STRONG",{});var nct=s(zde);REo=r(nct,"rembert"),nct.forEach(t),PEo=r(H8e," \u2014 "),pj=n(H8e,"A",{href:!0});var sct=s(pj);BEo=r(sct,"RemBertModel"),sct.forEach(t),IEo=r(H8e," (RemBERT model)"),H8e.forEach(t),NEo=i($),Hu=n($,"LI",{});var U8e=s(Hu);Wde=n(U8e,"STRONG",{});var lct=s(Wde);qEo=r(lct,"resnet"),lct.forEach(t),jEo=r(U8e," \u2014 "),uj=n(U8e,"A",{href:!0});var ict=s(uj);DEo=r(ict,"ResNetModel"),ict.forEach(t),GEo=r(U8e," (ResNet model)"),U8e.forEach(t),OEo=i($),Uu=n($,"LI",{});var J8e=s(Uu);Qde=n(J8e,"STRONG",{});var dct=s(Qde);VEo=r(dct,"retribert"),dct.forEach(t),XEo=r(J8e," \u2014 "),_j=n(J8e,"A",{href:!0});var cct=s(_j);zEo=r(cct,"RetriBertModel"),cct.forEach(t),WEo=r(J8e," (RetriBERT model)"),J8e.forEach(t),QEo=i($),Ju=n($,"LI",{});var Y8e=s(Ju);Hde=n(Y8e,"STRONG",{});var fct=s(Hde);HEo=r(fct,"roberta"),fct.forEach(t),UEo=r(Y8e," \u2014 "),bj=n(Y8e,"A",{href:!0});var mct=s(bj);JEo=r(mct,"RobertaModel"),mct.forEach(t),YEo=r(Y8e," (RoBERTa model)"),Y8e.forEach(t),KEo=i($),Yu=n($,"LI",{});var K8e=s(Yu);Ude=n(K8e,"STRONG",{});var gct=s(Ude);ZEo=r(gct,"roformer"),gct.forEach(t),e4o=r(K8e," \u2014 "),vj=n(K8e,"A",{href:!0});var hct=s(vj);o4o=r(hct,"RoFormerModel"),hct.forEach(t),r4o=r(K8e," (RoFormer model)"),K8e.forEach(t),t4o=i($),Ku=n($,"LI",{});var Z8e=s(Ku);Jde=n(Z8e,"STRONG",{});var pct=s(Jde);a4o=r(pct,"segformer"),pct.forEach(t),n4o=r(Z8e," \u2014 "),Fj=n(Z8e,"A",{href:!0});var uct=s(Fj);s4o=r(uct,"SegformerModel"),uct.forEach(t),l4o=r(Z8e," (SegFormer model)"),Z8e.forEach(t),i4o=i($),Zu=n($,"LI",{});var e9e=s(Zu);Yde=n(e9e,"STRONG",{});var _ct=s(Yde);d4o=r(_ct,"sew"),_ct.forEach(t),c4o=r(e9e," \u2014 "),Tj=n(e9e,"A",{href:!0});var bct=s(Tj);f4o=r(bct,"SEWModel"),bct.forEach(t),m4o=r(e9e," (SEW model)"),e9e.forEach(t),g4o=i($),e_=n($,"LI",{});var o9e=s(e_);Kde=n(o9e,"STRONG",{});var vct=s(Kde);h4o=r(vct,"sew-d"),vct.forEach(t),p4o=r(o9e," \u2014 "),Mj=n(o9e,"A",{href:!0});var Fct=s(Mj);u4o=r(Fct,"SEWDModel"),Fct.forEach(t),_4o=r(o9e," (SEW-D model)"),o9e.forEach(t),b4o=i($),o_=n($,"LI",{});var r9e=s(o_);Zde=n(r9e,"STRONG",{});var Tct=s(Zde);v4o=r(Tct,"speech_to_text"),Tct.forEach(t),F4o=r(r9e," \u2014 "),Ej=n(r9e,"A",{href:!0});var Mct=s(Ej);T4o=r(Mct,"Speech2TextModel"),Mct.forEach(t),M4o=r(r9e," (Speech2Text model)"),r9e.forEach(t),E4o=i($),r_=n($,"LI",{});var t9e=s(r_);ece=n(t9e,"STRONG",{});var Ect=s(ece);C4o=r(Ect,"splinter"),Ect.forEach(t),w4o=r(t9e," \u2014 "),Cj=n(t9e,"A",{href:!0});var Cct=s(Cj);A4o=r(Cct,"SplinterModel"),Cct.forEach(t),L4o=r(t9e," (Splinter model)"),t9e.forEach(t),y4o=i($),t_=n($,"LI",{});var a9e=s(t_);oce=n(a9e,"STRONG",{});var wct=s(oce);x4o=r(wct,"squeezebert"),wct.forEach(t),$4o=r(a9e," \u2014 "),wj=n(a9e,"A",{href:!0});var Act=s(wj);k4o=r(Act,"SqueezeBertModel"),Act.forEach(t),S4o=r(a9e," (SqueezeBERT model)"),a9e.forEach(t),R4o=i($),a_=n($,"LI",{});var n9e=s(a_);rce=n(n9e,"STRONG",{});var Lct=s(rce);P4o=r(Lct,"swin"),Lct.forEach(t),B4o=r(n9e," \u2014 "),Aj=n(n9e,"A",{href:!0});var yct=s(Aj);I4o=r(yct,"SwinModel"),yct.forEach(t),N4o=r(n9e," (Swin Transformer model)"),n9e.forEach(t),q4o=i($),n_=n($,"LI",{});var s9e=s(n_);tce=n(s9e,"STRONG",{});var xct=s(tce);j4o=r(xct,"t5"),xct.forEach(t),D4o=r(s9e," \u2014 "),Lj=n(s9e,"A",{href:!0});var $ct=s(Lj);G4o=r($ct,"T5Model"),$ct.forEach(t),O4o=r(s9e," (T5 model)"),s9e.forEach(t),V4o=i($),s_=n($,"LI",{});var l9e=s(s_);ace=n(l9e,"STRONG",{});var kct=s(ace);X4o=r(kct,"tapas"),kct.forEach(t),z4o=r(l9e," \u2014 "),yj=n(l9e,"A",{href:!0});var Sct=s(yj);W4o=r(Sct,"TapasModel"),Sct.forEach(t),Q4o=r(l9e," (TAPAS model)"),l9e.forEach(t),H4o=i($),l_=n($,"LI",{});var i9e=s(l_);nce=n(i9e,"STRONG",{});var Rct=s(nce);U4o=r(Rct,"trajectory_transformer"),Rct.forEach(t),J4o=r(i9e," \u2014 "),xj=n(i9e,"A",{href:!0});var Pct=s(xj);Y4o=r(Pct,"TrajectoryTransformerModel"),Pct.forEach(t),K4o=r(i9e," (Trajectory Transformer model)"),i9e.forEach(t),Z4o=i($),i_=n($,"LI",{});var d9e=s(i_);sce=n(d9e,"STRONG",{});var Bct=s(sce);eCo=r(Bct,"transfo-xl"),Bct.forEach(t),oCo=r(d9e," \u2014 "),$j=n(d9e,"A",{href:!0});var Ict=s($j);rCo=r(Ict,"TransfoXLModel"),Ict.forEach(t),tCo=r(d9e," (Transformer-XL model)"),d9e.forEach(t),aCo=i($),d_=n($,"LI",{});var c9e=s(d_);lce=n(c9e,"STRONG",{});var Nct=s(lce);nCo=r(Nct,"unispeech"),Nct.forEach(t),sCo=r(c9e," \u2014 "),kj=n(c9e,"A",{href:!0});var qct=s(kj);lCo=r(qct,"UniSpeechModel"),qct.forEach(t),iCo=r(c9e," (UniSpeech model)"),c9e.forEach(t),dCo=i($),c_=n($,"LI",{});var f9e=s(c_);ice=n(f9e,"STRONG",{});var jct=s(ice);cCo=r(jct,"unispeech-sat"),jct.forEach(t),fCo=r(f9e," \u2014 "),Sj=n(f9e,"A",{href:!0});var Dct=s(Sj);mCo=r(Dct,"UniSpeechSatModel"),Dct.forEach(t),gCo=r(f9e," (UniSpeechSat model)"),f9e.forEach(t),hCo=i($),f_=n($,"LI",{});var m9e=s(f_);dce=n(m9e,"STRONG",{});var Gct=s(dce);pCo=r(Gct,"van"),Gct.forEach(t),uCo=r(m9e," \u2014 "),Rj=n(m9e,"A",{href:!0});var Oct=s(Rj);_Co=r(Oct,"VanModel"),Oct.forEach(t),bCo=r(m9e," (VAN model)"),m9e.forEach(t),vCo=i($),m_=n($,"LI",{});var g9e=s(m_);cce=n(g9e,"STRONG",{});var Vct=s(cce);FCo=r(Vct,"vilt"),Vct.forEach(t),TCo=r(g9e," \u2014 "),Pj=n(g9e,"A",{href:!0});var Xct=s(Pj);MCo=r(Xct,"ViltModel"),Xct.forEach(t),ECo=r(g9e," (ViLT model)"),g9e.forEach(t),CCo=i($),g_=n($,"LI",{});var h9e=s(g_);fce=n(h9e,"STRONG",{});var zct=s(fce);wCo=r(zct,"vision-text-dual-encoder"),zct.forEach(t),ACo=r(h9e," \u2014 "),Bj=n(h9e,"A",{href:!0});var Wct=s(Bj);LCo=r(Wct,"VisionTextDualEncoderModel"),Wct.forEach(t),yCo=r(h9e," (VisionTextDualEncoder model)"),h9e.forEach(t),xCo=i($),h_=n($,"LI",{});var p9e=s(h_);mce=n(p9e,"STRONG",{});var Qct=s(mce);$Co=r(Qct,"visual_bert"),Qct.forEach(t),kCo=r(p9e," \u2014 "),Ij=n(p9e,"A",{href:!0});var Hct=s(Ij);SCo=r(Hct,"VisualBertModel"),Hct.forEach(t),RCo=r(p9e," (VisualBERT model)"),p9e.forEach(t),PCo=i($),p_=n($,"LI",{});var u9e=s(p_);gce=n(u9e,"STRONG",{});var Uct=s(gce);BCo=r(Uct,"vit"),Uct.forEach(t),ICo=r(u9e," \u2014 "),Nj=n(u9e,"A",{href:!0});var Jct=s(Nj);NCo=r(Jct,"ViTModel"),Jct.forEach(t),qCo=r(u9e," (ViT model)"),u9e.forEach(t),jCo=i($),u_=n($,"LI",{});var _9e=s(u_);hce=n(_9e,"STRONG",{});var Yct=s(hce);DCo=r(Yct,"vit_mae"),Yct.forEach(t),GCo=r(_9e," \u2014 "),qj=n(_9e,"A",{href:!0});var Kct=s(qj);OCo=r(Kct,"ViTMAEModel"),Kct.forEach(t),VCo=r(_9e," (ViTMAE model)"),_9e.forEach(t),XCo=i($),__=n($,"LI",{});var b9e=s(__);pce=n(b9e,"STRONG",{});var Zct=s(pce);zCo=r(Zct,"wav2vec2"),Zct.forEach(t),WCo=r(b9e," \u2014 "),jj=n(b9e,"A",{href:!0});var eft=s(jj);QCo=r(eft,"Wav2Vec2Model"),eft.forEach(t),HCo=r(b9e," (Wav2Vec2 model)"),b9e.forEach(t),UCo=i($),b_=n($,"LI",{});var v9e=s(b_);uce=n(v9e,"STRONG",{});var oft=s(uce);JCo=r(oft,"wav2vec2-conformer"),oft.forEach(t),YCo=r(v9e," \u2014 "),Dj=n(v9e,"A",{href:!0});var rft=s(Dj);KCo=r(rft,"Wav2Vec2ConformerModel"),rft.forEach(t),ZCo=r(v9e," (Wav2Vec2-Conformer model)"),v9e.forEach(t),e5o=i($),v_=n($,"LI",{});var F9e=s(v_);_ce=n(F9e,"STRONG",{});var tft=s(_ce);o5o=r(tft,"wavlm"),tft.forEach(t),r5o=r(F9e," \u2014 "),Gj=n(F9e,"A",{href:!0});var aft=s(Gj);t5o=r(aft,"WavLMModel"),aft.forEach(t),a5o=r(F9e," (WavLM model)"),F9e.forEach(t),n5o=i($),F_=n($,"LI",{});var T9e=s(F_);bce=n(T9e,"STRONG",{});var nft=s(bce);s5o=r(nft,"xglm"),nft.forEach(t),l5o=r(T9e," \u2014 "),Oj=n(T9e,"A",{href:!0});var sft=s(Oj);i5o=r(sft,"XGLMModel"),sft.forEach(t),d5o=r(T9e," (XGLM model)"),T9e.forEach(t),c5o=i($),T_=n($,"LI",{});var M9e=s(T_);vce=n(M9e,"STRONG",{});var lft=s(vce);f5o=r(lft,"xlm"),lft.forEach(t),m5o=r(M9e," \u2014 "),Vj=n(M9e,"A",{href:!0});var ift=s(Vj);g5o=r(ift,"XLMModel"),ift.forEach(t),h5o=r(M9e," (XLM model)"),M9e.forEach(t),p5o=i($),M_=n($,"LI",{});var E9e=s(M_);Fce=n(E9e,"STRONG",{});var dft=s(Fce);u5o=r(dft,"xlm-prophetnet"),dft.forEach(t),_5o=r(E9e," \u2014 "),Xj=n(E9e,"A",{href:!0});var cft=s(Xj);b5o=r(cft,"XLMProphetNetModel"),cft.forEach(t),v5o=r(E9e," (XLM-ProphetNet model)"),E9e.forEach(t),F5o=i($),E_=n($,"LI",{});var C9e=s(E_);Tce=n(C9e,"STRONG",{});var fft=s(Tce);T5o=r(fft,"xlm-roberta"),fft.forEach(t),M5o=r(C9e," \u2014 "),zj=n(C9e,"A",{href:!0});var mft=s(zj);E5o=r(mft,"XLMRobertaModel"),mft.forEach(t),C5o=r(C9e," (XLM-RoBERTa model)"),C9e.forEach(t),w5o=i($),C_=n($,"LI",{});var w9e=s(C_);Mce=n(w9e,"STRONG",{});var gft=s(Mce);A5o=r(gft,"xlm-roberta-xl"),gft.forEach(t),L5o=r(w9e," \u2014 "),Wj=n(w9e,"A",{href:!0});var hft=s(Wj);y5o=r(hft,"XLMRobertaXLModel"),hft.forEach(t),x5o=r(w9e," (XLM-RoBERTa-XL model)"),w9e.forEach(t),$5o=i($),w_=n($,"LI",{});var A9e=s(w_);Ece=n(A9e,"STRONG",{});var pft=s(Ece);k5o=r(pft,"xlnet"),pft.forEach(t),S5o=r(A9e," \u2014 "),Qj=n(A9e,"A",{href:!0});var uft=s(Qj);R5o=r(uft,"XLNetModel"),uft.forEach(t),P5o=r(A9e," (XLNet model)"),A9e.forEach(t),B5o=i($),A_=n($,"LI",{});var L9e=s(A_);Cce=n(L9e,"STRONG",{});var _ft=s(Cce);I5o=r(_ft,"yolos"),_ft.forEach(t),N5o=r(L9e," \u2014 "),Hj=n(L9e,"A",{href:!0});var bft=s(Hj);q5o=r(bft,"YolosModel"),bft.forEach(t),j5o=r(L9e," (YOLOS model)"),L9e.forEach(t),D5o=i($),L_=n($,"LI",{});var y9e=s(L_);wce=n(y9e,"STRONG",{});var vft=s(wce);G5o=r(vft,"yoso"),vft.forEach(t),O5o=r(y9e," \u2014 "),Uj=n(y9e,"A",{href:!0});var Fft=s(Uj);V5o=r(Fft,"YosoModel"),Fft.forEach(t),X5o=r(y9e," (YOSO model)"),y9e.forEach(t),$.forEach(t),z5o=i(aa),y_=n(aa,"P",{});var x9e=s(y_);W5o=r(x9e,"The model is set in evaluation mode by default using "),Ace=n(x9e,"CODE",{});var Tft=s(Ace);Q5o=r(Tft,"model.eval()"),Tft.forEach(t),H5o=r(x9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lce=n(x9e,"CODE",{});var Mft=s(Lce);U5o=r(Mft,"model.train()"),Mft.forEach(t),x9e.forEach(t),J5o=i(aa),T(x_.$$.fragment,aa),aa.forEach(t),Us.forEach(t),xGe=i(f),Ni=n(f,"H2",{class:!0});var BVe=s(Ni);$_=n(BVe,"A",{id:!0,class:!0,href:!0});var Eft=s($_);yce=n(Eft,"SPAN",{});var Cft=s(yce);T(ey.$$.fragment,Cft),Cft.forEach(t),Eft.forEach(t),Y5o=i(BVe),xce=n(BVe,"SPAN",{});var wft=s(xce);K5o=r(wft,"AutoModelForPreTraining"),wft.forEach(t),BVe.forEach(t),$Ge=i(f),$o=n(f,"DIV",{class:!0});var Js=s($o);T(oy.$$.fragment,Js),Z5o=i(Js),qi=n(Js,"P",{});var loe=s(qi);e3o=r(loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Jj=n(loe,"A",{href:!0});var Aft=s(Jj);o3o=r(Aft,"from_pretrained()"),Aft.forEach(t),r3o=r(loe," class method or the "),Yj=n(loe,"A",{href:!0});var Lft=s(Yj);t3o=r(Lft,"from_config()"),Lft.forEach(t),a3o=r(loe,` class
method.`),loe.forEach(t),n3o=i(Js),ry=n(Js,"P",{});var IVe=s(ry);s3o=r(IVe,"This class cannot be instantiated directly using "),$ce=n(IVe,"CODE",{});var yft=s($ce);l3o=r(yft,"__init__()"),yft.forEach(t),i3o=r(IVe," (throws an error)."),IVe.forEach(t),d3o=i(Js),st=n(Js,"DIV",{class:!0});var LA=s(st);T(ty.$$.fragment,LA),c3o=i(LA),kce=n(LA,"P",{});var xft=s(kce);f3o=r(xft,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),xft.forEach(t),m3o=i(LA),ji=n(LA,"P",{});var ioe=s(ji);g3o=r(ioe,`Note:
Loading a model from its configuration file does `),Sce=n(ioe,"STRONG",{});var $ft=s(Sce);h3o=r($ft,"not"),$ft.forEach(t),p3o=r(ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kj=n(ioe,"A",{href:!0});var kft=s(Kj);u3o=r(kft,"from_pretrained()"),kft.forEach(t),_3o=r(ioe," to load the model weights."),ioe.forEach(t),b3o=i(LA),T(k_.$$.fragment,LA),LA.forEach(t),v3o=i(Js),Ye=n(Js,"DIV",{class:!0});var na=s(Ye);T(ay.$$.fragment,na),F3o=i(na),Rce=n(na,"P",{});var Sft=s(Rce);T3o=r(Sft,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Sft.forEach(t),M3o=i(na),Ra=n(na,"P",{});var yA=s(Ra);E3o=r(yA,"The model class to instantiate is selected based on the "),Pce=n(yA,"CODE",{});var Rft=s(Pce);C3o=r(Rft,"model_type"),Rft.forEach(t),w3o=r(yA,` property of the config object (either
passed as an argument or loaded from `),Bce=n(yA,"CODE",{});var Pft=s(Bce);A3o=r(Pft,"pretrained_model_name_or_path"),Pft.forEach(t),L3o=r(yA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ice=n(yA,"CODE",{});var Bft=s(Ice);y3o=r(Bft,"pretrained_model_name_or_path"),Bft.forEach(t),x3o=r(yA,":"),yA.forEach(t),$3o=i(na),G=n(na,"UL",{});var O=s(G);S_=n(O,"LI",{});var $9e=s(S_);Nce=n($9e,"STRONG",{});var Ift=s(Nce);k3o=r(Ift,"albert"),Ift.forEach(t),S3o=r($9e," \u2014 "),Zj=n($9e,"A",{href:!0});var Nft=s(Zj);R3o=r(Nft,"AlbertForPreTraining"),Nft.forEach(t),P3o=r($9e," (ALBERT model)"),$9e.forEach(t),B3o=i(O),R_=n(O,"LI",{});var k9e=s(R_);qce=n(k9e,"STRONG",{});var qft=s(qce);I3o=r(qft,"bart"),qft.forEach(t),N3o=r(k9e," \u2014 "),eD=n(k9e,"A",{href:!0});var jft=s(eD);q3o=r(jft,"BartForConditionalGeneration"),jft.forEach(t),j3o=r(k9e," (BART model)"),k9e.forEach(t),D3o=i(O),P_=n(O,"LI",{});var S9e=s(P_);jce=n(S9e,"STRONG",{});var Dft=s(jce);G3o=r(Dft,"bert"),Dft.forEach(t),O3o=r(S9e," \u2014 "),oD=n(S9e,"A",{href:!0});var Gft=s(oD);V3o=r(Gft,"BertForPreTraining"),Gft.forEach(t),X3o=r(S9e," (BERT model)"),S9e.forEach(t),z3o=i(O),B_=n(O,"LI",{});var R9e=s(B_);Dce=n(R9e,"STRONG",{});var Oft=s(Dce);W3o=r(Oft,"big_bird"),Oft.forEach(t),Q3o=r(R9e," \u2014 "),rD=n(R9e,"A",{href:!0});var Vft=s(rD);H3o=r(Vft,"BigBirdForPreTraining"),Vft.forEach(t),U3o=r(R9e," (BigBird model)"),R9e.forEach(t),J3o=i(O),I_=n(O,"LI",{});var P9e=s(I_);Gce=n(P9e,"STRONG",{});var Xft=s(Gce);Y3o=r(Xft,"bloom"),Xft.forEach(t),K3o=r(P9e," \u2014 "),tD=n(P9e,"A",{href:!0});var zft=s(tD);Z3o=r(zft,"BloomForCausalLM"),zft.forEach(t),e0o=r(P9e," (BLOOM model)"),P9e.forEach(t),o0o=i(O),N_=n(O,"LI",{});var B9e=s(N_);Oce=n(B9e,"STRONG",{});var Wft=s(Oce);r0o=r(Wft,"camembert"),Wft.forEach(t),t0o=r(B9e," \u2014 "),aD=n(B9e,"A",{href:!0});var Qft=s(aD);a0o=r(Qft,"CamembertForMaskedLM"),Qft.forEach(t),n0o=r(B9e," (CamemBERT model)"),B9e.forEach(t),s0o=i(O),q_=n(O,"LI",{});var I9e=s(q_);Vce=n(I9e,"STRONG",{});var Hft=s(Vce);l0o=r(Hft,"ctrl"),Hft.forEach(t),i0o=r(I9e," \u2014 "),nD=n(I9e,"A",{href:!0});var Uft=s(nD);d0o=r(Uft,"CTRLLMHeadModel"),Uft.forEach(t),c0o=r(I9e," (CTRL model)"),I9e.forEach(t),f0o=i(O),j_=n(O,"LI",{});var N9e=s(j_);Xce=n(N9e,"STRONG",{});var Jft=s(Xce);m0o=r(Jft,"data2vec-text"),Jft.forEach(t),g0o=r(N9e," \u2014 "),sD=n(N9e,"A",{href:!0});var Yft=s(sD);h0o=r(Yft,"Data2VecTextForMaskedLM"),Yft.forEach(t),p0o=r(N9e," (Data2VecText model)"),N9e.forEach(t),u0o=i(O),D_=n(O,"LI",{});var q9e=s(D_);zce=n(q9e,"STRONG",{});var Kft=s(zce);_0o=r(Kft,"deberta"),Kft.forEach(t),b0o=r(q9e," \u2014 "),lD=n(q9e,"A",{href:!0});var Zft=s(lD);v0o=r(Zft,"DebertaForMaskedLM"),Zft.forEach(t),F0o=r(q9e," (DeBERTa model)"),q9e.forEach(t),T0o=i(O),G_=n(O,"LI",{});var j9e=s(G_);Wce=n(j9e,"STRONG",{});var emt=s(Wce);M0o=r(emt,"deberta-v2"),emt.forEach(t),E0o=r(j9e," \u2014 "),iD=n(j9e,"A",{href:!0});var omt=s(iD);C0o=r(omt,"DebertaV2ForMaskedLM"),omt.forEach(t),w0o=r(j9e," (DeBERTa-v2 model)"),j9e.forEach(t),A0o=i(O),O_=n(O,"LI",{});var D9e=s(O_);Qce=n(D9e,"STRONG",{});var rmt=s(Qce);L0o=r(rmt,"distilbert"),rmt.forEach(t),y0o=r(D9e," \u2014 "),dD=n(D9e,"A",{href:!0});var tmt=s(dD);x0o=r(tmt,"DistilBertForMaskedLM"),tmt.forEach(t),$0o=r(D9e," (DistilBERT model)"),D9e.forEach(t),k0o=i(O),V_=n(O,"LI",{});var G9e=s(V_);Hce=n(G9e,"STRONG",{});var amt=s(Hce);S0o=r(amt,"electra"),amt.forEach(t),R0o=r(G9e," \u2014 "),cD=n(G9e,"A",{href:!0});var nmt=s(cD);P0o=r(nmt,"ElectraForPreTraining"),nmt.forEach(t),B0o=r(G9e," (ELECTRA model)"),G9e.forEach(t),I0o=i(O),X_=n(O,"LI",{});var O9e=s(X_);Uce=n(O9e,"STRONG",{});var smt=s(Uce);N0o=r(smt,"flaubert"),smt.forEach(t),q0o=r(O9e," \u2014 "),fD=n(O9e,"A",{href:!0});var lmt=s(fD);j0o=r(lmt,"FlaubertWithLMHeadModel"),lmt.forEach(t),D0o=r(O9e," (FlauBERT model)"),O9e.forEach(t),G0o=i(O),z_=n(O,"LI",{});var V9e=s(z_);Jce=n(V9e,"STRONG",{});var imt=s(Jce);O0o=r(imt,"flava"),imt.forEach(t),V0o=r(V9e," \u2014 "),mD=n(V9e,"A",{href:!0});var dmt=s(mD);X0o=r(dmt,"FlavaForPreTraining"),dmt.forEach(t),z0o=r(V9e," (FLAVA model)"),V9e.forEach(t),W0o=i(O),W_=n(O,"LI",{});var X9e=s(W_);Yce=n(X9e,"STRONG",{});var cmt=s(Yce);Q0o=r(cmt,"fnet"),cmt.forEach(t),H0o=r(X9e," \u2014 "),gD=n(X9e,"A",{href:!0});var fmt=s(gD);U0o=r(fmt,"FNetForPreTraining"),fmt.forEach(t),J0o=r(X9e," (FNet model)"),X9e.forEach(t),Y0o=i(O),Q_=n(O,"LI",{});var z9e=s(Q_);Kce=n(z9e,"STRONG",{});var mmt=s(Kce);K0o=r(mmt,"fsmt"),mmt.forEach(t),Z0o=r(z9e," \u2014 "),hD=n(z9e,"A",{href:!0});var gmt=s(hD);ewo=r(gmt,"FSMTForConditionalGeneration"),gmt.forEach(t),owo=r(z9e," (FairSeq Machine-Translation model)"),z9e.forEach(t),rwo=i(O),H_=n(O,"LI",{});var W9e=s(H_);Zce=n(W9e,"STRONG",{});var hmt=s(Zce);two=r(hmt,"funnel"),hmt.forEach(t),awo=r(W9e," \u2014 "),pD=n(W9e,"A",{href:!0});var pmt=s(pD);nwo=r(pmt,"FunnelForPreTraining"),pmt.forEach(t),swo=r(W9e," (Funnel Transformer model)"),W9e.forEach(t),lwo=i(O),U_=n(O,"LI",{});var Q9e=s(U_);efe=n(Q9e,"STRONG",{});var umt=s(efe);iwo=r(umt,"gpt2"),umt.forEach(t),dwo=r(Q9e," \u2014 "),uD=n(Q9e,"A",{href:!0});var _mt=s(uD);cwo=r(_mt,"GPT2LMHeadModel"),_mt.forEach(t),fwo=r(Q9e," (OpenAI GPT-2 model)"),Q9e.forEach(t),mwo=i(O),J_=n(O,"LI",{});var H9e=s(J_);ofe=n(H9e,"STRONG",{});var bmt=s(ofe);gwo=r(bmt,"ibert"),bmt.forEach(t),hwo=r(H9e," \u2014 "),_D=n(H9e,"A",{href:!0});var vmt=s(_D);pwo=r(vmt,"IBertForMaskedLM"),vmt.forEach(t),uwo=r(H9e," (I-BERT model)"),H9e.forEach(t),_wo=i(O),Y_=n(O,"LI",{});var U9e=s(Y_);rfe=n(U9e,"STRONG",{});var Fmt=s(rfe);bwo=r(Fmt,"layoutlm"),Fmt.forEach(t),vwo=r(U9e," \u2014 "),bD=n(U9e,"A",{href:!0});var Tmt=s(bD);Fwo=r(Tmt,"LayoutLMForMaskedLM"),Tmt.forEach(t),Two=r(U9e," (LayoutLM model)"),U9e.forEach(t),Mwo=i(O),K_=n(O,"LI",{});var J9e=s(K_);tfe=n(J9e,"STRONG",{});var Mmt=s(tfe);Ewo=r(Mmt,"longformer"),Mmt.forEach(t),Cwo=r(J9e," \u2014 "),vD=n(J9e,"A",{href:!0});var Emt=s(vD);wwo=r(Emt,"LongformerForMaskedLM"),Emt.forEach(t),Awo=r(J9e," (Longformer model)"),J9e.forEach(t),Lwo=i(O),Z_=n(O,"LI",{});var Y9e=s(Z_);afe=n(Y9e,"STRONG",{});var Cmt=s(afe);ywo=r(Cmt,"lxmert"),Cmt.forEach(t),xwo=r(Y9e," \u2014 "),FD=n(Y9e,"A",{href:!0});var wmt=s(FD);$wo=r(wmt,"LxmertForPreTraining"),wmt.forEach(t),kwo=r(Y9e," (LXMERT model)"),Y9e.forEach(t),Swo=i(O),e7=n(O,"LI",{});var K9e=s(e7);nfe=n(K9e,"STRONG",{});var Amt=s(nfe);Rwo=r(Amt,"megatron-bert"),Amt.forEach(t),Pwo=r(K9e," \u2014 "),TD=n(K9e,"A",{href:!0});var Lmt=s(TD);Bwo=r(Lmt,"MegatronBertForPreTraining"),Lmt.forEach(t),Iwo=r(K9e," (Megatron-BERT model)"),K9e.forEach(t),Nwo=i(O),o7=n(O,"LI",{});var Z9e=s(o7);sfe=n(Z9e,"STRONG",{});var ymt=s(sfe);qwo=r(ymt,"mobilebert"),ymt.forEach(t),jwo=r(Z9e," \u2014 "),MD=n(Z9e,"A",{href:!0});var xmt=s(MD);Dwo=r(xmt,"MobileBertForPreTraining"),xmt.forEach(t),Gwo=r(Z9e," (MobileBERT model)"),Z9e.forEach(t),Owo=i(O),r7=n(O,"LI",{});var exe=s(r7);lfe=n(exe,"STRONG",{});var $mt=s(lfe);Vwo=r($mt,"mpnet"),$mt.forEach(t),Xwo=r(exe," \u2014 "),ED=n(exe,"A",{href:!0});var kmt=s(ED);zwo=r(kmt,"MPNetForMaskedLM"),kmt.forEach(t),Wwo=r(exe," (MPNet model)"),exe.forEach(t),Qwo=i(O),t7=n(O,"LI",{});var oxe=s(t7);ife=n(oxe,"STRONG",{});var Smt=s(ife);Hwo=r(Smt,"openai-gpt"),Smt.forEach(t),Uwo=r(oxe," \u2014 "),CD=n(oxe,"A",{href:!0});var Rmt=s(CD);Jwo=r(Rmt,"OpenAIGPTLMHeadModel"),Rmt.forEach(t),Ywo=r(oxe," (OpenAI GPT model)"),oxe.forEach(t),Kwo=i(O),a7=n(O,"LI",{});var rxe=s(a7);dfe=n(rxe,"STRONG",{});var Pmt=s(dfe);Zwo=r(Pmt,"retribert"),Pmt.forEach(t),eAo=r(rxe," \u2014 "),wD=n(rxe,"A",{href:!0});var Bmt=s(wD);oAo=r(Bmt,"RetriBertModel"),Bmt.forEach(t),rAo=r(rxe," (RetriBERT model)"),rxe.forEach(t),tAo=i(O),n7=n(O,"LI",{});var txe=s(n7);cfe=n(txe,"STRONG",{});var Imt=s(cfe);aAo=r(Imt,"roberta"),Imt.forEach(t),nAo=r(txe," \u2014 "),AD=n(txe,"A",{href:!0});var Nmt=s(AD);sAo=r(Nmt,"RobertaForMaskedLM"),Nmt.forEach(t),lAo=r(txe," (RoBERTa model)"),txe.forEach(t),iAo=i(O),s7=n(O,"LI",{});var axe=s(s7);ffe=n(axe,"STRONG",{});var qmt=s(ffe);dAo=r(qmt,"splinter"),qmt.forEach(t),cAo=r(axe," \u2014 "),LD=n(axe,"A",{href:!0});var jmt=s(LD);fAo=r(jmt,"SplinterForPreTraining"),jmt.forEach(t),mAo=r(axe," (Splinter model)"),axe.forEach(t),gAo=i(O),l7=n(O,"LI",{});var nxe=s(l7);mfe=n(nxe,"STRONG",{});var Dmt=s(mfe);hAo=r(Dmt,"squeezebert"),Dmt.forEach(t),pAo=r(nxe," \u2014 "),yD=n(nxe,"A",{href:!0});var Gmt=s(yD);uAo=r(Gmt,"SqueezeBertForMaskedLM"),Gmt.forEach(t),_Ao=r(nxe," (SqueezeBERT model)"),nxe.forEach(t),bAo=i(O),i7=n(O,"LI",{});var sxe=s(i7);gfe=n(sxe,"STRONG",{});var Omt=s(gfe);vAo=r(Omt,"t5"),Omt.forEach(t),FAo=r(sxe," \u2014 "),xD=n(sxe,"A",{href:!0});var Vmt=s(xD);TAo=r(Vmt,"T5ForConditionalGeneration"),Vmt.forEach(t),MAo=r(sxe," (T5 model)"),sxe.forEach(t),EAo=i(O),d7=n(O,"LI",{});var lxe=s(d7);hfe=n(lxe,"STRONG",{});var Xmt=s(hfe);CAo=r(Xmt,"tapas"),Xmt.forEach(t),wAo=r(lxe," \u2014 "),$D=n(lxe,"A",{href:!0});var zmt=s($D);AAo=r(zmt,"TapasForMaskedLM"),zmt.forEach(t),LAo=r(lxe," (TAPAS model)"),lxe.forEach(t),yAo=i(O),c7=n(O,"LI",{});var ixe=s(c7);pfe=n(ixe,"STRONG",{});var Wmt=s(pfe);xAo=r(Wmt,"transfo-xl"),Wmt.forEach(t),$Ao=r(ixe," \u2014 "),kD=n(ixe,"A",{href:!0});var Qmt=s(kD);kAo=r(Qmt,"TransfoXLLMHeadModel"),Qmt.forEach(t),SAo=r(ixe," (Transformer-XL model)"),ixe.forEach(t),RAo=i(O),f7=n(O,"LI",{});var dxe=s(f7);ufe=n(dxe,"STRONG",{});var Hmt=s(ufe);PAo=r(Hmt,"unispeech"),Hmt.forEach(t),BAo=r(dxe," \u2014 "),SD=n(dxe,"A",{href:!0});var Umt=s(SD);IAo=r(Umt,"UniSpeechForPreTraining"),Umt.forEach(t),NAo=r(dxe," (UniSpeech model)"),dxe.forEach(t),qAo=i(O),m7=n(O,"LI",{});var cxe=s(m7);_fe=n(cxe,"STRONG",{});var Jmt=s(_fe);jAo=r(Jmt,"unispeech-sat"),Jmt.forEach(t),DAo=r(cxe," \u2014 "),RD=n(cxe,"A",{href:!0});var Ymt=s(RD);GAo=r(Ymt,"UniSpeechSatForPreTraining"),Ymt.forEach(t),OAo=r(cxe," (UniSpeechSat model)"),cxe.forEach(t),VAo=i(O),g7=n(O,"LI",{});var fxe=s(g7);bfe=n(fxe,"STRONG",{});var Kmt=s(bfe);XAo=r(Kmt,"visual_bert"),Kmt.forEach(t),zAo=r(fxe," \u2014 "),PD=n(fxe,"A",{href:!0});var Zmt=s(PD);WAo=r(Zmt,"VisualBertForPreTraining"),Zmt.forEach(t),QAo=r(fxe," (VisualBERT model)"),fxe.forEach(t),HAo=i(O),h7=n(O,"LI",{});var mxe=s(h7);vfe=n(mxe,"STRONG",{});var egt=s(vfe);UAo=r(egt,"vit_mae"),egt.forEach(t),JAo=r(mxe," \u2014 "),BD=n(mxe,"A",{href:!0});var ogt=s(BD);YAo=r(ogt,"ViTMAEForPreTraining"),ogt.forEach(t),KAo=r(mxe," (ViTMAE model)"),mxe.forEach(t),ZAo=i(O),p7=n(O,"LI",{});var gxe=s(p7);Ffe=n(gxe,"STRONG",{});var rgt=s(Ffe);e6o=r(rgt,"wav2vec2"),rgt.forEach(t),o6o=r(gxe," \u2014 "),ID=n(gxe,"A",{href:!0});var tgt=s(ID);r6o=r(tgt,"Wav2Vec2ForPreTraining"),tgt.forEach(t),t6o=r(gxe," (Wav2Vec2 model)"),gxe.forEach(t),a6o=i(O),u7=n(O,"LI",{});var hxe=s(u7);Tfe=n(hxe,"STRONG",{});var agt=s(Tfe);n6o=r(agt,"wav2vec2-conformer"),agt.forEach(t),s6o=r(hxe," \u2014 "),ND=n(hxe,"A",{href:!0});var ngt=s(ND);l6o=r(ngt,"Wav2Vec2ConformerForPreTraining"),ngt.forEach(t),i6o=r(hxe," (Wav2Vec2-Conformer model)"),hxe.forEach(t),d6o=i(O),_7=n(O,"LI",{});var pxe=s(_7);Mfe=n(pxe,"STRONG",{});var sgt=s(Mfe);c6o=r(sgt,"xlm"),sgt.forEach(t),f6o=r(pxe," \u2014 "),qD=n(pxe,"A",{href:!0});var lgt=s(qD);m6o=r(lgt,"XLMWithLMHeadModel"),lgt.forEach(t),g6o=r(pxe," (XLM model)"),pxe.forEach(t),h6o=i(O),b7=n(O,"LI",{});var uxe=s(b7);Efe=n(uxe,"STRONG",{});var igt=s(Efe);p6o=r(igt,"xlm-roberta"),igt.forEach(t),u6o=r(uxe," \u2014 "),jD=n(uxe,"A",{href:!0});var dgt=s(jD);_6o=r(dgt,"XLMRobertaForMaskedLM"),dgt.forEach(t),b6o=r(uxe," (XLM-RoBERTa model)"),uxe.forEach(t),v6o=i(O),v7=n(O,"LI",{});var _xe=s(v7);Cfe=n(_xe,"STRONG",{});var cgt=s(Cfe);F6o=r(cgt,"xlm-roberta-xl"),cgt.forEach(t),T6o=r(_xe," \u2014 "),DD=n(_xe,"A",{href:!0});var fgt=s(DD);M6o=r(fgt,"XLMRobertaXLForMaskedLM"),fgt.forEach(t),E6o=r(_xe," (XLM-RoBERTa-XL model)"),_xe.forEach(t),C6o=i(O),F7=n(O,"LI",{});var bxe=s(F7);wfe=n(bxe,"STRONG",{});var mgt=s(wfe);w6o=r(mgt,"xlnet"),mgt.forEach(t),A6o=r(bxe," \u2014 "),GD=n(bxe,"A",{href:!0});var ggt=s(GD);L6o=r(ggt,"XLNetLMHeadModel"),ggt.forEach(t),y6o=r(bxe," (XLNet model)"),bxe.forEach(t),O.forEach(t),x6o=i(na),T7=n(na,"P",{});var vxe=s(T7);$6o=r(vxe,"The model is set in evaluation mode by default using "),Afe=n(vxe,"CODE",{});var hgt=s(Afe);k6o=r(hgt,"model.eval()"),hgt.forEach(t),S6o=r(vxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lfe=n(vxe,"CODE",{});var pgt=s(Lfe);R6o=r(pgt,"model.train()"),pgt.forEach(t),vxe.forEach(t),P6o=i(na),T(M7.$$.fragment,na),na.forEach(t),Js.forEach(t),kGe=i(f),Di=n(f,"H2",{class:!0});var NVe=s(Di);E7=n(NVe,"A",{id:!0,class:!0,href:!0});var ugt=s(E7);yfe=n(ugt,"SPAN",{});var _gt=s(yfe);T(ny.$$.fragment,_gt),_gt.forEach(t),ugt.forEach(t),B6o=i(NVe),xfe=n(NVe,"SPAN",{});var bgt=s(xfe);I6o=r(bgt,"AutoModelForCausalLM"),bgt.forEach(t),NVe.forEach(t),SGe=i(f),ko=n(f,"DIV",{class:!0});var Ys=s(ko);T(sy.$$.fragment,Ys),N6o=i(Ys),Gi=n(Ys,"P",{});var doe=s(Gi);q6o=r(doe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),OD=n(doe,"A",{href:!0});var vgt=s(OD);j6o=r(vgt,"from_pretrained()"),vgt.forEach(t),D6o=r(doe," class method or the "),VD=n(doe,"A",{href:!0});var Fgt=s(VD);G6o=r(Fgt,"from_config()"),Fgt.forEach(t),O6o=r(doe,` class
method.`),doe.forEach(t),V6o=i(Ys),ly=n(Ys,"P",{});var qVe=s(ly);X6o=r(qVe,"This class cannot be instantiated directly using "),$fe=n(qVe,"CODE",{});var Tgt=s($fe);z6o=r(Tgt,"__init__()"),Tgt.forEach(t),W6o=r(qVe," (throws an error)."),qVe.forEach(t),Q6o=i(Ys),lt=n(Ys,"DIV",{class:!0});var xA=s(lt);T(iy.$$.fragment,xA),H6o=i(xA),kfe=n(xA,"P",{});var Mgt=s(kfe);U6o=r(Mgt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Mgt.forEach(t),J6o=i(xA),Oi=n(xA,"P",{});var coe=s(Oi);Y6o=r(coe,`Note:
Loading a model from its configuration file does `),Sfe=n(coe,"STRONG",{});var Egt=s(Sfe);K6o=r(Egt,"not"),Egt.forEach(t),Z6o=r(coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),XD=n(coe,"A",{href:!0});var Cgt=s(XD);eLo=r(Cgt,"from_pretrained()"),Cgt.forEach(t),oLo=r(coe," to load the model weights."),coe.forEach(t),rLo=i(xA),T(C7.$$.fragment,xA),xA.forEach(t),tLo=i(Ys),Ke=n(Ys,"DIV",{class:!0});var sa=s(Ke);T(dy.$$.fragment,sa),aLo=i(sa),Rfe=n(sa,"P",{});var wgt=s(Rfe);nLo=r(wgt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),wgt.forEach(t),sLo=i(sa),Pa=n(sa,"P",{});var $A=s(Pa);lLo=r($A,"The model class to instantiate is selected based on the "),Pfe=n($A,"CODE",{});var Agt=s(Pfe);iLo=r(Agt,"model_type"),Agt.forEach(t),dLo=r($A,` property of the config object (either
passed as an argument or loaded from `),Bfe=n($A,"CODE",{});var Lgt=s(Bfe);cLo=r(Lgt,"pretrained_model_name_or_path"),Lgt.forEach(t),fLo=r($A,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ife=n($A,"CODE",{});var ygt=s(Ife);mLo=r(ygt,"pretrained_model_name_or_path"),ygt.forEach(t),gLo=r($A,":"),$A.forEach(t),hLo=i(sa),z=n(sa,"UL",{});var W=s(z);w7=n(W,"LI",{});var Fxe=s(w7);Nfe=n(Fxe,"STRONG",{});var xgt=s(Nfe);pLo=r(xgt,"bart"),xgt.forEach(t),uLo=r(Fxe," \u2014 "),zD=n(Fxe,"A",{href:!0});var $gt=s(zD);_Lo=r($gt,"BartForCausalLM"),$gt.forEach(t),bLo=r(Fxe," (BART model)"),Fxe.forEach(t),vLo=i(W),A7=n(W,"LI",{});var Txe=s(A7);qfe=n(Txe,"STRONG",{});var kgt=s(qfe);FLo=r(kgt,"bert"),kgt.forEach(t),TLo=r(Txe," \u2014 "),WD=n(Txe,"A",{href:!0});var Sgt=s(WD);MLo=r(Sgt,"BertLMHeadModel"),Sgt.forEach(t),ELo=r(Txe," (BERT model)"),Txe.forEach(t),CLo=i(W),L7=n(W,"LI",{});var Mxe=s(L7);jfe=n(Mxe,"STRONG",{});var Rgt=s(jfe);wLo=r(Rgt,"bert-generation"),Rgt.forEach(t),ALo=r(Mxe," \u2014 "),QD=n(Mxe,"A",{href:!0});var Pgt=s(QD);LLo=r(Pgt,"BertGenerationDecoder"),Pgt.forEach(t),yLo=r(Mxe," (Bert Generation model)"),Mxe.forEach(t),xLo=i(W),y7=n(W,"LI",{});var Exe=s(y7);Dfe=n(Exe,"STRONG",{});var Bgt=s(Dfe);$Lo=r(Bgt,"big_bird"),Bgt.forEach(t),kLo=r(Exe," \u2014 "),HD=n(Exe,"A",{href:!0});var Igt=s(HD);SLo=r(Igt,"BigBirdForCausalLM"),Igt.forEach(t),RLo=r(Exe," (BigBird model)"),Exe.forEach(t),PLo=i(W),x7=n(W,"LI",{});var Cxe=s(x7);Gfe=n(Cxe,"STRONG",{});var Ngt=s(Gfe);BLo=r(Ngt,"bigbird_pegasus"),Ngt.forEach(t),ILo=r(Cxe," \u2014 "),UD=n(Cxe,"A",{href:!0});var qgt=s(UD);NLo=r(qgt,"BigBirdPegasusForCausalLM"),qgt.forEach(t),qLo=r(Cxe," (BigBird-Pegasus model)"),Cxe.forEach(t),jLo=i(W),$7=n(W,"LI",{});var wxe=s($7);Ofe=n(wxe,"STRONG",{});var jgt=s(Ofe);DLo=r(jgt,"blenderbot"),jgt.forEach(t),GLo=r(wxe," \u2014 "),JD=n(wxe,"A",{href:!0});var Dgt=s(JD);OLo=r(Dgt,"BlenderbotForCausalLM"),Dgt.forEach(t),VLo=r(wxe," (Blenderbot model)"),wxe.forEach(t),XLo=i(W),k7=n(W,"LI",{});var Axe=s(k7);Vfe=n(Axe,"STRONG",{});var Ggt=s(Vfe);zLo=r(Ggt,"blenderbot-small"),Ggt.forEach(t),WLo=r(Axe," \u2014 "),YD=n(Axe,"A",{href:!0});var Ogt=s(YD);QLo=r(Ogt,"BlenderbotSmallForCausalLM"),Ogt.forEach(t),HLo=r(Axe," (BlenderbotSmall model)"),Axe.forEach(t),ULo=i(W),S7=n(W,"LI",{});var Lxe=s(S7);Xfe=n(Lxe,"STRONG",{});var Vgt=s(Xfe);JLo=r(Vgt,"bloom"),Vgt.forEach(t),YLo=r(Lxe," \u2014 "),KD=n(Lxe,"A",{href:!0});var Xgt=s(KD);KLo=r(Xgt,"BloomForCausalLM"),Xgt.forEach(t),ZLo=r(Lxe," (BLOOM model)"),Lxe.forEach(t),eyo=i(W),R7=n(W,"LI",{});var yxe=s(R7);zfe=n(yxe,"STRONG",{});var zgt=s(zfe);oyo=r(zgt,"camembert"),zgt.forEach(t),ryo=r(yxe," \u2014 "),ZD=n(yxe,"A",{href:!0});var Wgt=s(ZD);tyo=r(Wgt,"CamembertForCausalLM"),Wgt.forEach(t),ayo=r(yxe," (CamemBERT model)"),yxe.forEach(t),nyo=i(W),P7=n(W,"LI",{});var xxe=s(P7);Wfe=n(xxe,"STRONG",{});var Qgt=s(Wfe);syo=r(Qgt,"ctrl"),Qgt.forEach(t),lyo=r(xxe," \u2014 "),eG=n(xxe,"A",{href:!0});var Hgt=s(eG);iyo=r(Hgt,"CTRLLMHeadModel"),Hgt.forEach(t),dyo=r(xxe," (CTRL model)"),xxe.forEach(t),cyo=i(W),B7=n(W,"LI",{});var $xe=s(B7);Qfe=n($xe,"STRONG",{});var Ugt=s(Qfe);fyo=r(Ugt,"data2vec-text"),Ugt.forEach(t),myo=r($xe," \u2014 "),oG=n($xe,"A",{href:!0});var Jgt=s(oG);gyo=r(Jgt,"Data2VecTextForCausalLM"),Jgt.forEach(t),hyo=r($xe," (Data2VecText model)"),$xe.forEach(t),pyo=i(W),I7=n(W,"LI",{});var kxe=s(I7);Hfe=n(kxe,"STRONG",{});var Ygt=s(Hfe);uyo=r(Ygt,"electra"),Ygt.forEach(t),_yo=r(kxe," \u2014 "),rG=n(kxe,"A",{href:!0});var Kgt=s(rG);byo=r(Kgt,"ElectraForCausalLM"),Kgt.forEach(t),vyo=r(kxe," (ELECTRA model)"),kxe.forEach(t),Fyo=i(W),N7=n(W,"LI",{});var Sxe=s(N7);Ufe=n(Sxe,"STRONG",{});var Zgt=s(Ufe);Tyo=r(Zgt,"gpt2"),Zgt.forEach(t),Myo=r(Sxe," \u2014 "),tG=n(Sxe,"A",{href:!0});var eht=s(tG);Eyo=r(eht,"GPT2LMHeadModel"),eht.forEach(t),Cyo=r(Sxe," (OpenAI GPT-2 model)"),Sxe.forEach(t),wyo=i(W),q7=n(W,"LI",{});var Rxe=s(q7);Jfe=n(Rxe,"STRONG",{});var oht=s(Jfe);Ayo=r(oht,"gpt_neo"),oht.forEach(t),Lyo=r(Rxe," \u2014 "),aG=n(Rxe,"A",{href:!0});var rht=s(aG);yyo=r(rht,"GPTNeoForCausalLM"),rht.forEach(t),xyo=r(Rxe," (GPT Neo model)"),Rxe.forEach(t),$yo=i(W),j7=n(W,"LI",{});var Pxe=s(j7);Yfe=n(Pxe,"STRONG",{});var tht=s(Yfe);kyo=r(tht,"gpt_neox"),tht.forEach(t),Syo=r(Pxe," \u2014 "),nG=n(Pxe,"A",{href:!0});var aht=s(nG);Ryo=r(aht,"GPTNeoXForCausalLM"),aht.forEach(t),Pyo=r(Pxe," (GPT NeoX model)"),Pxe.forEach(t),Byo=i(W),D7=n(W,"LI",{});var Bxe=s(D7);Kfe=n(Bxe,"STRONG",{});var nht=s(Kfe);Iyo=r(nht,"gptj"),nht.forEach(t),Nyo=r(Bxe," \u2014 "),sG=n(Bxe,"A",{href:!0});var sht=s(sG);qyo=r(sht,"GPTJForCausalLM"),sht.forEach(t),jyo=r(Bxe," (GPT-J model)"),Bxe.forEach(t),Dyo=i(W),G7=n(W,"LI",{});var Ixe=s(G7);Zfe=n(Ixe,"STRONG",{});var lht=s(Zfe);Gyo=r(lht,"marian"),lht.forEach(t),Oyo=r(Ixe," \u2014 "),lG=n(Ixe,"A",{href:!0});var iht=s(lG);Vyo=r(iht,"MarianForCausalLM"),iht.forEach(t),Xyo=r(Ixe," (Marian model)"),Ixe.forEach(t),zyo=i(W),O7=n(W,"LI",{});var Nxe=s(O7);eme=n(Nxe,"STRONG",{});var dht=s(eme);Wyo=r(dht,"mbart"),dht.forEach(t),Qyo=r(Nxe," \u2014 "),iG=n(Nxe,"A",{href:!0});var cht=s(iG);Hyo=r(cht,"MBartForCausalLM"),cht.forEach(t),Uyo=r(Nxe," (mBART model)"),Nxe.forEach(t),Jyo=i(W),V7=n(W,"LI",{});var qxe=s(V7);ome=n(qxe,"STRONG",{});var fht=s(ome);Yyo=r(fht,"megatron-bert"),fht.forEach(t),Kyo=r(qxe," \u2014 "),dG=n(qxe,"A",{href:!0});var mht=s(dG);Zyo=r(mht,"MegatronBertForCausalLM"),mht.forEach(t),e8o=r(qxe," (Megatron-BERT model)"),qxe.forEach(t),o8o=i(W),X7=n(W,"LI",{});var jxe=s(X7);rme=n(jxe,"STRONG",{});var ght=s(rme);r8o=r(ght,"openai-gpt"),ght.forEach(t),t8o=r(jxe," \u2014 "),cG=n(jxe,"A",{href:!0});var hht=s(cG);a8o=r(hht,"OpenAIGPTLMHeadModel"),hht.forEach(t),n8o=r(jxe," (OpenAI GPT model)"),jxe.forEach(t),s8o=i(W),z7=n(W,"LI",{});var Dxe=s(z7);tme=n(Dxe,"STRONG",{});var pht=s(tme);l8o=r(pht,"opt"),pht.forEach(t),i8o=r(Dxe," \u2014 "),fG=n(Dxe,"A",{href:!0});var uht=s(fG);d8o=r(uht,"OPTForCausalLM"),uht.forEach(t),c8o=r(Dxe," (OPT model)"),Dxe.forEach(t),f8o=i(W),W7=n(W,"LI",{});var Gxe=s(W7);ame=n(Gxe,"STRONG",{});var _ht=s(ame);m8o=r(_ht,"pegasus"),_ht.forEach(t),g8o=r(Gxe," \u2014 "),mG=n(Gxe,"A",{href:!0});var bht=s(mG);h8o=r(bht,"PegasusForCausalLM"),bht.forEach(t),p8o=r(Gxe," (Pegasus model)"),Gxe.forEach(t),u8o=i(W),Q7=n(W,"LI",{});var Oxe=s(Q7);nme=n(Oxe,"STRONG",{});var vht=s(nme);_8o=r(vht,"plbart"),vht.forEach(t),b8o=r(Oxe," \u2014 "),gG=n(Oxe,"A",{href:!0});var Fht=s(gG);v8o=r(Fht,"PLBartForCausalLM"),Fht.forEach(t),F8o=r(Oxe," (PLBart model)"),Oxe.forEach(t),T8o=i(W),H7=n(W,"LI",{});var Vxe=s(H7);sme=n(Vxe,"STRONG",{});var Tht=s(sme);M8o=r(Tht,"prophetnet"),Tht.forEach(t),E8o=r(Vxe," \u2014 "),hG=n(Vxe,"A",{href:!0});var Mht=s(hG);C8o=r(Mht,"ProphetNetForCausalLM"),Mht.forEach(t),w8o=r(Vxe," (ProphetNet model)"),Vxe.forEach(t),A8o=i(W),U7=n(W,"LI",{});var Xxe=s(U7);lme=n(Xxe,"STRONG",{});var Eht=s(lme);L8o=r(Eht,"qdqbert"),Eht.forEach(t),y8o=r(Xxe," \u2014 "),pG=n(Xxe,"A",{href:!0});var Cht=s(pG);x8o=r(Cht,"QDQBertLMHeadModel"),Cht.forEach(t),$8o=r(Xxe," (QDQBert model)"),Xxe.forEach(t),k8o=i(W),J7=n(W,"LI",{});var zxe=s(J7);ime=n(zxe,"STRONG",{});var wht=s(ime);S8o=r(wht,"reformer"),wht.forEach(t),R8o=r(zxe," \u2014 "),uG=n(zxe,"A",{href:!0});var Aht=s(uG);P8o=r(Aht,"ReformerModelWithLMHead"),Aht.forEach(t),B8o=r(zxe," (Reformer model)"),zxe.forEach(t),I8o=i(W),Y7=n(W,"LI",{});var Wxe=s(Y7);dme=n(Wxe,"STRONG",{});var Lht=s(dme);N8o=r(Lht,"rembert"),Lht.forEach(t),q8o=r(Wxe," \u2014 "),_G=n(Wxe,"A",{href:!0});var yht=s(_G);j8o=r(yht,"RemBertForCausalLM"),yht.forEach(t),D8o=r(Wxe," (RemBERT model)"),Wxe.forEach(t),G8o=i(W),K7=n(W,"LI",{});var Qxe=s(K7);cme=n(Qxe,"STRONG",{});var xht=s(cme);O8o=r(xht,"roberta"),xht.forEach(t),V8o=r(Qxe," \u2014 "),bG=n(Qxe,"A",{href:!0});var $ht=s(bG);X8o=r($ht,"RobertaForCausalLM"),$ht.forEach(t),z8o=r(Qxe," (RoBERTa model)"),Qxe.forEach(t),W8o=i(W),Z7=n(W,"LI",{});var Hxe=s(Z7);fme=n(Hxe,"STRONG",{});var kht=s(fme);Q8o=r(kht,"roformer"),kht.forEach(t),H8o=r(Hxe," \u2014 "),vG=n(Hxe,"A",{href:!0});var Sht=s(vG);U8o=r(Sht,"RoFormerForCausalLM"),Sht.forEach(t),J8o=r(Hxe," (RoFormer model)"),Hxe.forEach(t),Y8o=i(W),e2=n(W,"LI",{});var Uxe=s(e2);mme=n(Uxe,"STRONG",{});var Rht=s(mme);K8o=r(Rht,"speech_to_text_2"),Rht.forEach(t),Z8o=r(Uxe," \u2014 "),FG=n(Uxe,"A",{href:!0});var Pht=s(FG);e9o=r(Pht,"Speech2Text2ForCausalLM"),Pht.forEach(t),o9o=r(Uxe," (Speech2Text2 model)"),Uxe.forEach(t),r9o=i(W),o2=n(W,"LI",{});var Jxe=s(o2);gme=n(Jxe,"STRONG",{});var Bht=s(gme);t9o=r(Bht,"transfo-xl"),Bht.forEach(t),a9o=r(Jxe," \u2014 "),TG=n(Jxe,"A",{href:!0});var Iht=s(TG);n9o=r(Iht,"TransfoXLLMHeadModel"),Iht.forEach(t),s9o=r(Jxe," (Transformer-XL model)"),Jxe.forEach(t),l9o=i(W),r2=n(W,"LI",{});var Yxe=s(r2);hme=n(Yxe,"STRONG",{});var Nht=s(hme);i9o=r(Nht,"trocr"),Nht.forEach(t),d9o=r(Yxe," \u2014 "),MG=n(Yxe,"A",{href:!0});var qht=s(MG);c9o=r(qht,"TrOCRForCausalLM"),qht.forEach(t),f9o=r(Yxe," (TrOCR model)"),Yxe.forEach(t),m9o=i(W),t2=n(W,"LI",{});var Kxe=s(t2);pme=n(Kxe,"STRONG",{});var jht=s(pme);g9o=r(jht,"xglm"),jht.forEach(t),h9o=r(Kxe," \u2014 "),EG=n(Kxe,"A",{href:!0});var Dht=s(EG);p9o=r(Dht,"XGLMForCausalLM"),Dht.forEach(t),u9o=r(Kxe," (XGLM model)"),Kxe.forEach(t),_9o=i(W),a2=n(W,"LI",{});var Zxe=s(a2);ume=n(Zxe,"STRONG",{});var Ght=s(ume);b9o=r(Ght,"xlm"),Ght.forEach(t),v9o=r(Zxe," \u2014 "),CG=n(Zxe,"A",{href:!0});var Oht=s(CG);F9o=r(Oht,"XLMWithLMHeadModel"),Oht.forEach(t),T9o=r(Zxe," (XLM model)"),Zxe.forEach(t),M9o=i(W),n2=n(W,"LI",{});var e$e=s(n2);_me=n(e$e,"STRONG",{});var Vht=s(_me);E9o=r(Vht,"xlm-prophetnet"),Vht.forEach(t),C9o=r(e$e," \u2014 "),wG=n(e$e,"A",{href:!0});var Xht=s(wG);w9o=r(Xht,"XLMProphetNetForCausalLM"),Xht.forEach(t),A9o=r(e$e," (XLM-ProphetNet model)"),e$e.forEach(t),L9o=i(W),s2=n(W,"LI",{});var o$e=s(s2);bme=n(o$e,"STRONG",{});var zht=s(bme);y9o=r(zht,"xlm-roberta"),zht.forEach(t),x9o=r(o$e," \u2014 "),AG=n(o$e,"A",{href:!0});var Wht=s(AG);$9o=r(Wht,"XLMRobertaForCausalLM"),Wht.forEach(t),k9o=r(o$e," (XLM-RoBERTa model)"),o$e.forEach(t),S9o=i(W),l2=n(W,"LI",{});var r$e=s(l2);vme=n(r$e,"STRONG",{});var Qht=s(vme);R9o=r(Qht,"xlm-roberta-xl"),Qht.forEach(t),P9o=r(r$e," \u2014 "),LG=n(r$e,"A",{href:!0});var Hht=s(LG);B9o=r(Hht,"XLMRobertaXLForCausalLM"),Hht.forEach(t),I9o=r(r$e," (XLM-RoBERTa-XL model)"),r$e.forEach(t),N9o=i(W),i2=n(W,"LI",{});var t$e=s(i2);Fme=n(t$e,"STRONG",{});var Uht=s(Fme);q9o=r(Uht,"xlnet"),Uht.forEach(t),j9o=r(t$e," \u2014 "),yG=n(t$e,"A",{href:!0});var Jht=s(yG);D9o=r(Jht,"XLNetLMHeadModel"),Jht.forEach(t),G9o=r(t$e," (XLNet model)"),t$e.forEach(t),W.forEach(t),O9o=i(sa),d2=n(sa,"P",{});var a$e=s(d2);V9o=r(a$e,"The model is set in evaluation mode by default using "),Tme=n(a$e,"CODE",{});var Yht=s(Tme);X9o=r(Yht,"model.eval()"),Yht.forEach(t),z9o=r(a$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mme=n(a$e,"CODE",{});var Kht=s(Mme);W9o=r(Kht,"model.train()"),Kht.forEach(t),a$e.forEach(t),Q9o=i(sa),T(c2.$$.fragment,sa),sa.forEach(t),Ys.forEach(t),RGe=i(f),Vi=n(f,"H2",{class:!0});var jVe=s(Vi);f2=n(jVe,"A",{id:!0,class:!0,href:!0});var Zht=s(f2);Eme=n(Zht,"SPAN",{});var ept=s(Eme);T(cy.$$.fragment,ept),ept.forEach(t),Zht.forEach(t),H9o=i(jVe),Cme=n(jVe,"SPAN",{});var opt=s(Cme);U9o=r(opt,"AutoModelForMaskedLM"),opt.forEach(t),jVe.forEach(t),PGe=i(f),So=n(f,"DIV",{class:!0});var Ks=s(So);T(fy.$$.fragment,Ks),J9o=i(Ks),Xi=n(Ks,"P",{});var foe=s(Xi);Y9o=r(foe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),xG=n(foe,"A",{href:!0});var rpt=s(xG);K9o=r(rpt,"from_pretrained()"),rpt.forEach(t),Z9o=r(foe," class method or the "),$G=n(foe,"A",{href:!0});var tpt=s($G);exo=r(tpt,"from_config()"),tpt.forEach(t),oxo=r(foe,` class
method.`),foe.forEach(t),rxo=i(Ks),my=n(Ks,"P",{});var DVe=s(my);txo=r(DVe,"This class cannot be instantiated directly using "),wme=n(DVe,"CODE",{});var apt=s(wme);axo=r(apt,"__init__()"),apt.forEach(t),nxo=r(DVe," (throws an error)."),DVe.forEach(t),sxo=i(Ks),it=n(Ks,"DIV",{class:!0});var kA=s(it);T(gy.$$.fragment,kA),lxo=i(kA),Ame=n(kA,"P",{});var npt=s(Ame);ixo=r(npt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),npt.forEach(t),dxo=i(kA),zi=n(kA,"P",{});var moe=s(zi);cxo=r(moe,`Note:
Loading a model from its configuration file does `),Lme=n(moe,"STRONG",{});var spt=s(Lme);fxo=r(spt,"not"),spt.forEach(t),mxo=r(moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kG=n(moe,"A",{href:!0});var lpt=s(kG);gxo=r(lpt,"from_pretrained()"),lpt.forEach(t),hxo=r(moe," to load the model weights."),moe.forEach(t),pxo=i(kA),T(m2.$$.fragment,kA),kA.forEach(t),uxo=i(Ks),Ze=n(Ks,"DIV",{class:!0});var la=s(Ze);T(hy.$$.fragment,la),_xo=i(la),yme=n(la,"P",{});var ipt=s(yme);bxo=r(ipt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ipt.forEach(t),vxo=i(la),Ba=n(la,"P",{});var SA=s(Ba);Fxo=r(SA,"The model class to instantiate is selected based on the "),xme=n(SA,"CODE",{});var dpt=s(xme);Txo=r(dpt,"model_type"),dpt.forEach(t),Mxo=r(SA,` property of the config object (either
passed as an argument or loaded from `),$me=n(SA,"CODE",{});var cpt=s($me);Exo=r(cpt,"pretrained_model_name_or_path"),cpt.forEach(t),Cxo=r(SA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kme=n(SA,"CODE",{});var fpt=s(kme);wxo=r(fpt,"pretrained_model_name_or_path"),fpt.forEach(t),Axo=r(SA,":"),SA.forEach(t),Lxo=i(la),Q=n(la,"UL",{});var U=s(Q);g2=n(U,"LI",{});var n$e=s(g2);Sme=n(n$e,"STRONG",{});var mpt=s(Sme);yxo=r(mpt,"albert"),mpt.forEach(t),xxo=r(n$e," \u2014 "),SG=n(n$e,"A",{href:!0});var gpt=s(SG);$xo=r(gpt,"AlbertForMaskedLM"),gpt.forEach(t),kxo=r(n$e," (ALBERT model)"),n$e.forEach(t),Sxo=i(U),h2=n(U,"LI",{});var s$e=s(h2);Rme=n(s$e,"STRONG",{});var hpt=s(Rme);Rxo=r(hpt,"bart"),hpt.forEach(t),Pxo=r(s$e," \u2014 "),RG=n(s$e,"A",{href:!0});var ppt=s(RG);Bxo=r(ppt,"BartForConditionalGeneration"),ppt.forEach(t),Ixo=r(s$e," (BART model)"),s$e.forEach(t),Nxo=i(U),p2=n(U,"LI",{});var l$e=s(p2);Pme=n(l$e,"STRONG",{});var upt=s(Pme);qxo=r(upt,"bert"),upt.forEach(t),jxo=r(l$e," \u2014 "),PG=n(l$e,"A",{href:!0});var _pt=s(PG);Dxo=r(_pt,"BertForMaskedLM"),_pt.forEach(t),Gxo=r(l$e," (BERT model)"),l$e.forEach(t),Oxo=i(U),u2=n(U,"LI",{});var i$e=s(u2);Bme=n(i$e,"STRONG",{});var bpt=s(Bme);Vxo=r(bpt,"big_bird"),bpt.forEach(t),Xxo=r(i$e," \u2014 "),BG=n(i$e,"A",{href:!0});var vpt=s(BG);zxo=r(vpt,"BigBirdForMaskedLM"),vpt.forEach(t),Wxo=r(i$e," (BigBird model)"),i$e.forEach(t),Qxo=i(U),_2=n(U,"LI",{});var d$e=s(_2);Ime=n(d$e,"STRONG",{});var Fpt=s(Ime);Hxo=r(Fpt,"camembert"),Fpt.forEach(t),Uxo=r(d$e," \u2014 "),IG=n(d$e,"A",{href:!0});var Tpt=s(IG);Jxo=r(Tpt,"CamembertForMaskedLM"),Tpt.forEach(t),Yxo=r(d$e," (CamemBERT model)"),d$e.forEach(t),Kxo=i(U),b2=n(U,"LI",{});var c$e=s(b2);Nme=n(c$e,"STRONG",{});var Mpt=s(Nme);Zxo=r(Mpt,"convbert"),Mpt.forEach(t),e$o=r(c$e," \u2014 "),NG=n(c$e,"A",{href:!0});var Ept=s(NG);o$o=r(Ept,"ConvBertForMaskedLM"),Ept.forEach(t),r$o=r(c$e," (ConvBERT model)"),c$e.forEach(t),t$o=i(U),v2=n(U,"LI",{});var f$e=s(v2);qme=n(f$e,"STRONG",{});var Cpt=s(qme);a$o=r(Cpt,"data2vec-text"),Cpt.forEach(t),n$o=r(f$e," \u2014 "),qG=n(f$e,"A",{href:!0});var wpt=s(qG);s$o=r(wpt,"Data2VecTextForMaskedLM"),wpt.forEach(t),l$o=r(f$e," (Data2VecText model)"),f$e.forEach(t),i$o=i(U),F2=n(U,"LI",{});var m$e=s(F2);jme=n(m$e,"STRONG",{});var Apt=s(jme);d$o=r(Apt,"deberta"),Apt.forEach(t),c$o=r(m$e," \u2014 "),jG=n(m$e,"A",{href:!0});var Lpt=s(jG);f$o=r(Lpt,"DebertaForMaskedLM"),Lpt.forEach(t),m$o=r(m$e," (DeBERTa model)"),m$e.forEach(t),g$o=i(U),T2=n(U,"LI",{});var g$e=s(T2);Dme=n(g$e,"STRONG",{});var ypt=s(Dme);h$o=r(ypt,"deberta-v2"),ypt.forEach(t),p$o=r(g$e," \u2014 "),DG=n(g$e,"A",{href:!0});var xpt=s(DG);u$o=r(xpt,"DebertaV2ForMaskedLM"),xpt.forEach(t),_$o=r(g$e," (DeBERTa-v2 model)"),g$e.forEach(t),b$o=i(U),M2=n(U,"LI",{});var h$e=s(M2);Gme=n(h$e,"STRONG",{});var $pt=s(Gme);v$o=r($pt,"distilbert"),$pt.forEach(t),F$o=r(h$e," \u2014 "),GG=n(h$e,"A",{href:!0});var kpt=s(GG);T$o=r(kpt,"DistilBertForMaskedLM"),kpt.forEach(t),M$o=r(h$e," (DistilBERT model)"),h$e.forEach(t),E$o=i(U),E2=n(U,"LI",{});var p$e=s(E2);Ome=n(p$e,"STRONG",{});var Spt=s(Ome);C$o=r(Spt,"electra"),Spt.forEach(t),w$o=r(p$e," \u2014 "),OG=n(p$e,"A",{href:!0});var Rpt=s(OG);A$o=r(Rpt,"ElectraForMaskedLM"),Rpt.forEach(t),L$o=r(p$e," (ELECTRA model)"),p$e.forEach(t),y$o=i(U),C2=n(U,"LI",{});var u$e=s(C2);Vme=n(u$e,"STRONG",{});var Ppt=s(Vme);x$o=r(Ppt,"flaubert"),Ppt.forEach(t),$$o=r(u$e," \u2014 "),VG=n(u$e,"A",{href:!0});var Bpt=s(VG);k$o=r(Bpt,"FlaubertWithLMHeadModel"),Bpt.forEach(t),S$o=r(u$e," (FlauBERT model)"),u$e.forEach(t),R$o=i(U),w2=n(U,"LI",{});var _$e=s(w2);Xme=n(_$e,"STRONG",{});var Ipt=s(Xme);P$o=r(Ipt,"fnet"),Ipt.forEach(t),B$o=r(_$e," \u2014 "),XG=n(_$e,"A",{href:!0});var Npt=s(XG);I$o=r(Npt,"FNetForMaskedLM"),Npt.forEach(t),N$o=r(_$e," (FNet model)"),_$e.forEach(t),q$o=i(U),A2=n(U,"LI",{});var b$e=s(A2);zme=n(b$e,"STRONG",{});var qpt=s(zme);j$o=r(qpt,"funnel"),qpt.forEach(t),D$o=r(b$e," \u2014 "),zG=n(b$e,"A",{href:!0});var jpt=s(zG);G$o=r(jpt,"FunnelForMaskedLM"),jpt.forEach(t),O$o=r(b$e," (Funnel Transformer model)"),b$e.forEach(t),V$o=i(U),L2=n(U,"LI",{});var v$e=s(L2);Wme=n(v$e,"STRONG",{});var Dpt=s(Wme);X$o=r(Dpt,"ibert"),Dpt.forEach(t),z$o=r(v$e," \u2014 "),WG=n(v$e,"A",{href:!0});var Gpt=s(WG);W$o=r(Gpt,"IBertForMaskedLM"),Gpt.forEach(t),Q$o=r(v$e," (I-BERT model)"),v$e.forEach(t),H$o=i(U),y2=n(U,"LI",{});var F$e=s(y2);Qme=n(F$e,"STRONG",{});var Opt=s(Qme);U$o=r(Opt,"layoutlm"),Opt.forEach(t),J$o=r(F$e," \u2014 "),QG=n(F$e,"A",{href:!0});var Vpt=s(QG);Y$o=r(Vpt,"LayoutLMForMaskedLM"),Vpt.forEach(t),K$o=r(F$e," (LayoutLM model)"),F$e.forEach(t),Z$o=i(U),x2=n(U,"LI",{});var T$e=s(x2);Hme=n(T$e,"STRONG",{});var Xpt=s(Hme);eko=r(Xpt,"longformer"),Xpt.forEach(t),oko=r(T$e," \u2014 "),HG=n(T$e,"A",{href:!0});var zpt=s(HG);rko=r(zpt,"LongformerForMaskedLM"),zpt.forEach(t),tko=r(T$e," (Longformer model)"),T$e.forEach(t),ako=i(U),$2=n(U,"LI",{});var M$e=s($2);Ume=n(M$e,"STRONG",{});var Wpt=s(Ume);nko=r(Wpt,"luke"),Wpt.forEach(t),sko=r(M$e," \u2014 "),UG=n(M$e,"A",{href:!0});var Qpt=s(UG);lko=r(Qpt,"LukeForMaskedLM"),Qpt.forEach(t),iko=r(M$e," (LUKE model)"),M$e.forEach(t),dko=i(U),k2=n(U,"LI",{});var E$e=s(k2);Jme=n(E$e,"STRONG",{});var Hpt=s(Jme);cko=r(Hpt,"mbart"),Hpt.forEach(t),fko=r(E$e," \u2014 "),JG=n(E$e,"A",{href:!0});var Upt=s(JG);mko=r(Upt,"MBartForConditionalGeneration"),Upt.forEach(t),gko=r(E$e," (mBART model)"),E$e.forEach(t),hko=i(U),S2=n(U,"LI",{});var C$e=s(S2);Yme=n(C$e,"STRONG",{});var Jpt=s(Yme);pko=r(Jpt,"megatron-bert"),Jpt.forEach(t),uko=r(C$e," \u2014 "),YG=n(C$e,"A",{href:!0});var Ypt=s(YG);_ko=r(Ypt,"MegatronBertForMaskedLM"),Ypt.forEach(t),bko=r(C$e," (Megatron-BERT model)"),C$e.forEach(t),vko=i(U),R2=n(U,"LI",{});var w$e=s(R2);Kme=n(w$e,"STRONG",{});var Kpt=s(Kme);Fko=r(Kpt,"mobilebert"),Kpt.forEach(t),Tko=r(w$e," \u2014 "),KG=n(w$e,"A",{href:!0});var Zpt=s(KG);Mko=r(Zpt,"MobileBertForMaskedLM"),Zpt.forEach(t),Eko=r(w$e," (MobileBERT model)"),w$e.forEach(t),Cko=i(U),P2=n(U,"LI",{});var A$e=s(P2);Zme=n(A$e,"STRONG",{});var eut=s(Zme);wko=r(eut,"mpnet"),eut.forEach(t),Ako=r(A$e," \u2014 "),ZG=n(A$e,"A",{href:!0});var out=s(ZG);Lko=r(out,"MPNetForMaskedLM"),out.forEach(t),yko=r(A$e," (MPNet model)"),A$e.forEach(t),xko=i(U),B2=n(U,"LI",{});var L$e=s(B2);ege=n(L$e,"STRONG",{});var rut=s(ege);$ko=r(rut,"nystromformer"),rut.forEach(t),kko=r(L$e," \u2014 "),eO=n(L$e,"A",{href:!0});var tut=s(eO);Sko=r(tut,"NystromformerForMaskedLM"),tut.forEach(t),Rko=r(L$e," (Nystr\xF6mformer model)"),L$e.forEach(t),Pko=i(U),I2=n(U,"LI",{});var y$e=s(I2);oge=n(y$e,"STRONG",{});var aut=s(oge);Bko=r(aut,"perceiver"),aut.forEach(t),Iko=r(y$e," \u2014 "),oO=n(y$e,"A",{href:!0});var nut=s(oO);Nko=r(nut,"PerceiverForMaskedLM"),nut.forEach(t),qko=r(y$e," (Perceiver model)"),y$e.forEach(t),jko=i(U),N2=n(U,"LI",{});var x$e=s(N2);rge=n(x$e,"STRONG",{});var sut=s(rge);Dko=r(sut,"qdqbert"),sut.forEach(t),Gko=r(x$e," \u2014 "),rO=n(x$e,"A",{href:!0});var lut=s(rO);Oko=r(lut,"QDQBertForMaskedLM"),lut.forEach(t),Vko=r(x$e," (QDQBert model)"),x$e.forEach(t),Xko=i(U),q2=n(U,"LI",{});var $$e=s(q2);tge=n($$e,"STRONG",{});var iut=s(tge);zko=r(iut,"reformer"),iut.forEach(t),Wko=r($$e," \u2014 "),tO=n($$e,"A",{href:!0});var dut=s(tO);Qko=r(dut,"ReformerForMaskedLM"),dut.forEach(t),Hko=r($$e," (Reformer model)"),$$e.forEach(t),Uko=i(U),j2=n(U,"LI",{});var k$e=s(j2);age=n(k$e,"STRONG",{});var cut=s(age);Jko=r(cut,"rembert"),cut.forEach(t),Yko=r(k$e," \u2014 "),aO=n(k$e,"A",{href:!0});var fut=s(aO);Kko=r(fut,"RemBertForMaskedLM"),fut.forEach(t),Zko=r(k$e," (RemBERT model)"),k$e.forEach(t),eSo=i(U),D2=n(U,"LI",{});var S$e=s(D2);nge=n(S$e,"STRONG",{});var mut=s(nge);oSo=r(mut,"roberta"),mut.forEach(t),rSo=r(S$e," \u2014 "),nO=n(S$e,"A",{href:!0});var gut=s(nO);tSo=r(gut,"RobertaForMaskedLM"),gut.forEach(t),aSo=r(S$e," (RoBERTa model)"),S$e.forEach(t),nSo=i(U),G2=n(U,"LI",{});var R$e=s(G2);sge=n(R$e,"STRONG",{});var hut=s(sge);sSo=r(hut,"roformer"),hut.forEach(t),lSo=r(R$e," \u2014 "),sO=n(R$e,"A",{href:!0});var put=s(sO);iSo=r(put,"RoFormerForMaskedLM"),put.forEach(t),dSo=r(R$e," (RoFormer model)"),R$e.forEach(t),cSo=i(U),O2=n(U,"LI",{});var P$e=s(O2);lge=n(P$e,"STRONG",{});var uut=s(lge);fSo=r(uut,"squeezebert"),uut.forEach(t),mSo=r(P$e," \u2014 "),lO=n(P$e,"A",{href:!0});var _ut=s(lO);gSo=r(_ut,"SqueezeBertForMaskedLM"),_ut.forEach(t),hSo=r(P$e," (SqueezeBERT model)"),P$e.forEach(t),pSo=i(U),V2=n(U,"LI",{});var B$e=s(V2);ige=n(B$e,"STRONG",{});var but=s(ige);uSo=r(but,"tapas"),but.forEach(t),_So=r(B$e," \u2014 "),iO=n(B$e,"A",{href:!0});var vut=s(iO);bSo=r(vut,"TapasForMaskedLM"),vut.forEach(t),vSo=r(B$e," (TAPAS model)"),B$e.forEach(t),FSo=i(U),X2=n(U,"LI",{});var I$e=s(X2);dge=n(I$e,"STRONG",{});var Fut=s(dge);TSo=r(Fut,"wav2vec2"),Fut.forEach(t),MSo=r(I$e," \u2014 "),cge=n(I$e,"CODE",{});var Tut=s(cge);ESo=r(Tut,"Wav2Vec2ForMaskedLM"),Tut.forEach(t),CSo=r(I$e," (Wav2Vec2 model)"),I$e.forEach(t),wSo=i(U),z2=n(U,"LI",{});var N$e=s(z2);fge=n(N$e,"STRONG",{});var Mut=s(fge);ASo=r(Mut,"xlm"),Mut.forEach(t),LSo=r(N$e," \u2014 "),dO=n(N$e,"A",{href:!0});var Eut=s(dO);ySo=r(Eut,"XLMWithLMHeadModel"),Eut.forEach(t),xSo=r(N$e," (XLM model)"),N$e.forEach(t),$So=i(U),W2=n(U,"LI",{});var q$e=s(W2);mge=n(q$e,"STRONG",{});var Cut=s(mge);kSo=r(Cut,"xlm-roberta"),Cut.forEach(t),SSo=r(q$e," \u2014 "),cO=n(q$e,"A",{href:!0});var wut=s(cO);RSo=r(wut,"XLMRobertaForMaskedLM"),wut.forEach(t),PSo=r(q$e," (XLM-RoBERTa model)"),q$e.forEach(t),BSo=i(U),Q2=n(U,"LI",{});var j$e=s(Q2);gge=n(j$e,"STRONG",{});var Aut=s(gge);ISo=r(Aut,"xlm-roberta-xl"),Aut.forEach(t),NSo=r(j$e," \u2014 "),fO=n(j$e,"A",{href:!0});var Lut=s(fO);qSo=r(Lut,"XLMRobertaXLForMaskedLM"),Lut.forEach(t),jSo=r(j$e," (XLM-RoBERTa-XL model)"),j$e.forEach(t),DSo=i(U),H2=n(U,"LI",{});var D$e=s(H2);hge=n(D$e,"STRONG",{});var yut=s(hge);GSo=r(yut,"yoso"),yut.forEach(t),OSo=r(D$e," \u2014 "),mO=n(D$e,"A",{href:!0});var xut=s(mO);VSo=r(xut,"YosoForMaskedLM"),xut.forEach(t),XSo=r(D$e," (YOSO model)"),D$e.forEach(t),U.forEach(t),zSo=i(la),U2=n(la,"P",{});var G$e=s(U2);WSo=r(G$e,"The model is set in evaluation mode by default using "),pge=n(G$e,"CODE",{});var $ut=s(pge);QSo=r($ut,"model.eval()"),$ut.forEach(t),HSo=r(G$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),uge=n(G$e,"CODE",{});var kut=s(uge);USo=r(kut,"model.train()"),kut.forEach(t),G$e.forEach(t),JSo=i(la),T(J2.$$.fragment,la),la.forEach(t),Ks.forEach(t),BGe=i(f),Wi=n(f,"H2",{class:!0});var GVe=s(Wi);Y2=n(GVe,"A",{id:!0,class:!0,href:!0});var Sut=s(Y2);_ge=n(Sut,"SPAN",{});var Rut=s(_ge);T(py.$$.fragment,Rut),Rut.forEach(t),Sut.forEach(t),YSo=i(GVe),bge=n(GVe,"SPAN",{});var Put=s(bge);KSo=r(Put,"AutoModelForSeq2SeqLM"),Put.forEach(t),GVe.forEach(t),IGe=i(f),Ro=n(f,"DIV",{class:!0});var Zs=s(Ro);T(uy.$$.fragment,Zs),ZSo=i(Zs),Qi=n(Zs,"P",{});var goe=s(Qi);eRo=r(goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),gO=n(goe,"A",{href:!0});var But=s(gO);oRo=r(But,"from_pretrained()"),But.forEach(t),rRo=r(goe," class method or the "),hO=n(goe,"A",{href:!0});var Iut=s(hO);tRo=r(Iut,"from_config()"),Iut.forEach(t),aRo=r(goe,` class
method.`),goe.forEach(t),nRo=i(Zs),_y=n(Zs,"P",{});var OVe=s(_y);sRo=r(OVe,"This class cannot be instantiated directly using "),vge=n(OVe,"CODE",{});var Nut=s(vge);lRo=r(Nut,"__init__()"),Nut.forEach(t),iRo=r(OVe," (throws an error)."),OVe.forEach(t),dRo=i(Zs),dt=n(Zs,"DIV",{class:!0});var RA=s(dt);T(by.$$.fragment,RA),cRo=i(RA),Fge=n(RA,"P",{});var qut=s(Fge);fRo=r(qut,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),qut.forEach(t),mRo=i(RA),Hi=n(RA,"P",{});var hoe=s(Hi);gRo=r(hoe,`Note:
Loading a model from its configuration file does `),Tge=n(hoe,"STRONG",{});var jut=s(Tge);hRo=r(jut,"not"),jut.forEach(t),pRo=r(hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),pO=n(hoe,"A",{href:!0});var Dut=s(pO);uRo=r(Dut,"from_pretrained()"),Dut.forEach(t),_Ro=r(hoe," to load the model weights."),hoe.forEach(t),bRo=i(RA),T(K2.$$.fragment,RA),RA.forEach(t),vRo=i(Zs),eo=n(Zs,"DIV",{class:!0});var ia=s(eo);T(vy.$$.fragment,ia),FRo=i(ia),Mge=n(ia,"P",{});var Gut=s(Mge);TRo=r(Gut,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Gut.forEach(t),MRo=i(ia),Ia=n(ia,"P",{});var PA=s(Ia);ERo=r(PA,"The model class to instantiate is selected based on the "),Ege=n(PA,"CODE",{});var Out=s(Ege);CRo=r(Out,"model_type"),Out.forEach(t),wRo=r(PA,` property of the config object (either
passed as an argument or loaded from `),Cge=n(PA,"CODE",{});var Vut=s(Cge);ARo=r(Vut,"pretrained_model_name_or_path"),Vut.forEach(t),LRo=r(PA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wge=n(PA,"CODE",{});var Xut=s(wge);yRo=r(Xut,"pretrained_model_name_or_path"),Xut.forEach(t),xRo=r(PA,":"),PA.forEach(t),$Ro=i(ia),pe=n(ia,"UL",{});var ve=s(pe);Z2=n(ve,"LI",{});var O$e=s(Z2);Age=n(O$e,"STRONG",{});var zut=s(Age);kRo=r(zut,"bart"),zut.forEach(t),SRo=r(O$e," \u2014 "),uO=n(O$e,"A",{href:!0});var Wut=s(uO);RRo=r(Wut,"BartForConditionalGeneration"),Wut.forEach(t),PRo=r(O$e," (BART model)"),O$e.forEach(t),BRo=i(ve),e1=n(ve,"LI",{});var V$e=s(e1);Lge=n(V$e,"STRONG",{});var Qut=s(Lge);IRo=r(Qut,"bigbird_pegasus"),Qut.forEach(t),NRo=r(V$e," \u2014 "),_O=n(V$e,"A",{href:!0});var Hut=s(_O);qRo=r(Hut,"BigBirdPegasusForConditionalGeneration"),Hut.forEach(t),jRo=r(V$e," (BigBird-Pegasus model)"),V$e.forEach(t),DRo=i(ve),o1=n(ve,"LI",{});var X$e=s(o1);yge=n(X$e,"STRONG",{});var Uut=s(yge);GRo=r(Uut,"blenderbot"),Uut.forEach(t),ORo=r(X$e," \u2014 "),bO=n(X$e,"A",{href:!0});var Jut=s(bO);VRo=r(Jut,"BlenderbotForConditionalGeneration"),Jut.forEach(t),XRo=r(X$e," (Blenderbot model)"),X$e.forEach(t),zRo=i(ve),r1=n(ve,"LI",{});var z$e=s(r1);xge=n(z$e,"STRONG",{});var Yut=s(xge);WRo=r(Yut,"blenderbot-small"),Yut.forEach(t),QRo=r(z$e," \u2014 "),vO=n(z$e,"A",{href:!0});var Kut=s(vO);HRo=r(Kut,"BlenderbotSmallForConditionalGeneration"),Kut.forEach(t),URo=r(z$e," (BlenderbotSmall model)"),z$e.forEach(t),JRo=i(ve),t1=n(ve,"LI",{});var W$e=s(t1);$ge=n(W$e,"STRONG",{});var Zut=s($ge);YRo=r(Zut,"encoder-decoder"),Zut.forEach(t),KRo=r(W$e," \u2014 "),FO=n(W$e,"A",{href:!0});var e_t=s(FO);ZRo=r(e_t,"EncoderDecoderModel"),e_t.forEach(t),ePo=r(W$e," (Encoder decoder model)"),W$e.forEach(t),oPo=i(ve),a1=n(ve,"LI",{});var Q$e=s(a1);kge=n(Q$e,"STRONG",{});var o_t=s(kge);rPo=r(o_t,"fsmt"),o_t.forEach(t),tPo=r(Q$e," \u2014 "),TO=n(Q$e,"A",{href:!0});var r_t=s(TO);aPo=r(r_t,"FSMTForConditionalGeneration"),r_t.forEach(t),nPo=r(Q$e," (FairSeq Machine-Translation model)"),Q$e.forEach(t),sPo=i(ve),n1=n(ve,"LI",{});var H$e=s(n1);Sge=n(H$e,"STRONG",{});var t_t=s(Sge);lPo=r(t_t,"led"),t_t.forEach(t),iPo=r(H$e," \u2014 "),MO=n(H$e,"A",{href:!0});var a_t=s(MO);dPo=r(a_t,"LEDForConditionalGeneration"),a_t.forEach(t),cPo=r(H$e," (LED model)"),H$e.forEach(t),fPo=i(ve),s1=n(ve,"LI",{});var U$e=s(s1);Rge=n(U$e,"STRONG",{});var n_t=s(Rge);mPo=r(n_t,"longt5"),n_t.forEach(t),gPo=r(U$e," \u2014 "),EO=n(U$e,"A",{href:!0});var s_t=s(EO);hPo=r(s_t,"LongT5ForConditionalGeneration"),s_t.forEach(t),pPo=r(U$e," (LongT5 model)"),U$e.forEach(t),uPo=i(ve),l1=n(ve,"LI",{});var J$e=s(l1);Pge=n(J$e,"STRONG",{});var l_t=s(Pge);_Po=r(l_t,"m2m_100"),l_t.forEach(t),bPo=r(J$e," \u2014 "),CO=n(J$e,"A",{href:!0});var i_t=s(CO);vPo=r(i_t,"M2M100ForConditionalGeneration"),i_t.forEach(t),FPo=r(J$e," (M2M100 model)"),J$e.forEach(t),TPo=i(ve),i1=n(ve,"LI",{});var Y$e=s(i1);Bge=n(Y$e,"STRONG",{});var d_t=s(Bge);MPo=r(d_t,"marian"),d_t.forEach(t),EPo=r(Y$e," \u2014 "),wO=n(Y$e,"A",{href:!0});var c_t=s(wO);CPo=r(c_t,"MarianMTModel"),c_t.forEach(t),wPo=r(Y$e," (Marian model)"),Y$e.forEach(t),APo=i(ve),d1=n(ve,"LI",{});var K$e=s(d1);Ige=n(K$e,"STRONG",{});var f_t=s(Ige);LPo=r(f_t,"mbart"),f_t.forEach(t),yPo=r(K$e," \u2014 "),AO=n(K$e,"A",{href:!0});var m_t=s(AO);xPo=r(m_t,"MBartForConditionalGeneration"),m_t.forEach(t),$Po=r(K$e," (mBART model)"),K$e.forEach(t),kPo=i(ve),c1=n(ve,"LI",{});var Z$e=s(c1);Nge=n(Z$e,"STRONG",{});var g_t=s(Nge);SPo=r(g_t,"mt5"),g_t.forEach(t),RPo=r(Z$e," \u2014 "),LO=n(Z$e,"A",{href:!0});var h_t=s(LO);PPo=r(h_t,"MT5ForConditionalGeneration"),h_t.forEach(t),BPo=r(Z$e," (MT5 model)"),Z$e.forEach(t),IPo=i(ve),f1=n(ve,"LI",{});var eke=s(f1);qge=n(eke,"STRONG",{});var p_t=s(qge);NPo=r(p_t,"pegasus"),p_t.forEach(t),qPo=r(eke," \u2014 "),yO=n(eke,"A",{href:!0});var u_t=s(yO);jPo=r(u_t,"PegasusForConditionalGeneration"),u_t.forEach(t),DPo=r(eke," (Pegasus model)"),eke.forEach(t),GPo=i(ve),m1=n(ve,"LI",{});var oke=s(m1);jge=n(oke,"STRONG",{});var __t=s(jge);OPo=r(__t,"plbart"),__t.forEach(t),VPo=r(oke," \u2014 "),xO=n(oke,"A",{href:!0});var b_t=s(xO);XPo=r(b_t,"PLBartForConditionalGeneration"),b_t.forEach(t),zPo=r(oke," (PLBart model)"),oke.forEach(t),WPo=i(ve),g1=n(ve,"LI",{});var rke=s(g1);Dge=n(rke,"STRONG",{});var v_t=s(Dge);QPo=r(v_t,"prophetnet"),v_t.forEach(t),HPo=r(rke," \u2014 "),$O=n(rke,"A",{href:!0});var F_t=s($O);UPo=r(F_t,"ProphetNetForConditionalGeneration"),F_t.forEach(t),JPo=r(rke," (ProphetNet model)"),rke.forEach(t),YPo=i(ve),h1=n(ve,"LI",{});var tke=s(h1);Gge=n(tke,"STRONG",{});var T_t=s(Gge);KPo=r(T_t,"t5"),T_t.forEach(t),ZPo=r(tke," \u2014 "),kO=n(tke,"A",{href:!0});var M_t=s(kO);eBo=r(M_t,"T5ForConditionalGeneration"),M_t.forEach(t),oBo=r(tke," (T5 model)"),tke.forEach(t),rBo=i(ve),p1=n(ve,"LI",{});var ake=s(p1);Oge=n(ake,"STRONG",{});var E_t=s(Oge);tBo=r(E_t,"xlm-prophetnet"),E_t.forEach(t),aBo=r(ake," \u2014 "),SO=n(ake,"A",{href:!0});var C_t=s(SO);nBo=r(C_t,"XLMProphetNetForConditionalGeneration"),C_t.forEach(t),sBo=r(ake," (XLM-ProphetNet model)"),ake.forEach(t),ve.forEach(t),lBo=i(ia),u1=n(ia,"P",{});var nke=s(u1);iBo=r(nke,"The model is set in evaluation mode by default using "),Vge=n(nke,"CODE",{});var w_t=s(Vge);dBo=r(w_t,"model.eval()"),w_t.forEach(t),cBo=r(nke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xge=n(nke,"CODE",{});var A_t=s(Xge);fBo=r(A_t,"model.train()"),A_t.forEach(t),nke.forEach(t),mBo=i(ia),T(_1.$$.fragment,ia),ia.forEach(t),Zs.forEach(t),NGe=i(f),Ui=n(f,"H2",{class:!0});var VVe=s(Ui);b1=n(VVe,"A",{id:!0,class:!0,href:!0});var L_t=s(b1);zge=n(L_t,"SPAN",{});var y_t=s(zge);T(Fy.$$.fragment,y_t),y_t.forEach(t),L_t.forEach(t),gBo=i(VVe),Wge=n(VVe,"SPAN",{});var x_t=s(Wge);hBo=r(x_t,"AutoModelForSequenceClassification"),x_t.forEach(t),VVe.forEach(t),qGe=i(f),Po=n(f,"DIV",{class:!0});var el=s(Po);T(Ty.$$.fragment,el),pBo=i(el),Ji=n(el,"P",{});var poe=s(Ji);uBo=r(poe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),RO=n(poe,"A",{href:!0});var $_t=s(RO);_Bo=r($_t,"from_pretrained()"),$_t.forEach(t),bBo=r(poe," class method or the "),PO=n(poe,"A",{href:!0});var k_t=s(PO);vBo=r(k_t,"from_config()"),k_t.forEach(t),FBo=r(poe,` class
method.`),poe.forEach(t),TBo=i(el),My=n(el,"P",{});var XVe=s(My);MBo=r(XVe,"This class cannot be instantiated directly using "),Qge=n(XVe,"CODE",{});var S_t=s(Qge);EBo=r(S_t,"__init__()"),S_t.forEach(t),CBo=r(XVe," (throws an error)."),XVe.forEach(t),wBo=i(el),ct=n(el,"DIV",{class:!0});var BA=s(ct);T(Ey.$$.fragment,BA),ABo=i(BA),Hge=n(BA,"P",{});var R_t=s(Hge);LBo=r(R_t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),R_t.forEach(t),yBo=i(BA),Yi=n(BA,"P",{});var uoe=s(Yi);xBo=r(uoe,`Note:
Loading a model from its configuration file does `),Uge=n(uoe,"STRONG",{});var P_t=s(Uge);$Bo=r(P_t,"not"),P_t.forEach(t),kBo=r(uoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),BO=n(uoe,"A",{href:!0});var B_t=s(BO);SBo=r(B_t,"from_pretrained()"),B_t.forEach(t),RBo=r(uoe," to load the model weights."),uoe.forEach(t),PBo=i(BA),T(v1.$$.fragment,BA),BA.forEach(t),BBo=i(el),oo=n(el,"DIV",{class:!0});var da=s(oo);T(Cy.$$.fragment,da),IBo=i(da),Jge=n(da,"P",{});var I_t=s(Jge);NBo=r(I_t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),I_t.forEach(t),qBo=i(da),Na=n(da,"P",{});var IA=s(Na);jBo=r(IA,"The model class to instantiate is selected based on the "),Yge=n(IA,"CODE",{});var N_t=s(Yge);DBo=r(N_t,"model_type"),N_t.forEach(t),GBo=r(IA,` property of the config object (either
passed as an argument or loaded from `),Kge=n(IA,"CODE",{});var q_t=s(Kge);OBo=r(q_t,"pretrained_model_name_or_path"),q_t.forEach(t),VBo=r(IA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zge=n(IA,"CODE",{});var j_t=s(Zge);XBo=r(j_t,"pretrained_model_name_or_path"),j_t.forEach(t),zBo=r(IA,":"),IA.forEach(t),WBo=i(da),N=n(da,"UL",{});var j=s(N);F1=n(j,"LI",{});var ske=s(F1);ehe=n(ske,"STRONG",{});var D_t=s(ehe);QBo=r(D_t,"albert"),D_t.forEach(t),HBo=r(ske," \u2014 "),IO=n(ske,"A",{href:!0});var G_t=s(IO);UBo=r(G_t,"AlbertForSequenceClassification"),G_t.forEach(t),JBo=r(ske," (ALBERT model)"),ske.forEach(t),YBo=i(j),T1=n(j,"LI",{});var lke=s(T1);ohe=n(lke,"STRONG",{});var O_t=s(ohe);KBo=r(O_t,"bart"),O_t.forEach(t),ZBo=r(lke," \u2014 "),NO=n(lke,"A",{href:!0});var V_t=s(NO);eIo=r(V_t,"BartForSequenceClassification"),V_t.forEach(t),oIo=r(lke," (BART model)"),lke.forEach(t),rIo=i(j),M1=n(j,"LI",{});var ike=s(M1);rhe=n(ike,"STRONG",{});var X_t=s(rhe);tIo=r(X_t,"bert"),X_t.forEach(t),aIo=r(ike," \u2014 "),qO=n(ike,"A",{href:!0});var z_t=s(qO);nIo=r(z_t,"BertForSequenceClassification"),z_t.forEach(t),sIo=r(ike," (BERT model)"),ike.forEach(t),lIo=i(j),E1=n(j,"LI",{});var dke=s(E1);the=n(dke,"STRONG",{});var W_t=s(the);iIo=r(W_t,"big_bird"),W_t.forEach(t),dIo=r(dke," \u2014 "),jO=n(dke,"A",{href:!0});var Q_t=s(jO);cIo=r(Q_t,"BigBirdForSequenceClassification"),Q_t.forEach(t),fIo=r(dke," (BigBird model)"),dke.forEach(t),mIo=i(j),C1=n(j,"LI",{});var cke=s(C1);ahe=n(cke,"STRONG",{});var H_t=s(ahe);gIo=r(H_t,"bigbird_pegasus"),H_t.forEach(t),hIo=r(cke," \u2014 "),DO=n(cke,"A",{href:!0});var U_t=s(DO);pIo=r(U_t,"BigBirdPegasusForSequenceClassification"),U_t.forEach(t),uIo=r(cke," (BigBird-Pegasus model)"),cke.forEach(t),_Io=i(j),w1=n(j,"LI",{});var fke=s(w1);nhe=n(fke,"STRONG",{});var J_t=s(nhe);bIo=r(J_t,"bloom"),J_t.forEach(t),vIo=r(fke," \u2014 "),GO=n(fke,"A",{href:!0});var Y_t=s(GO);FIo=r(Y_t,"BloomForSequenceClassification"),Y_t.forEach(t),TIo=r(fke," (BLOOM model)"),fke.forEach(t),MIo=i(j),A1=n(j,"LI",{});var mke=s(A1);she=n(mke,"STRONG",{});var K_t=s(she);EIo=r(K_t,"camembert"),K_t.forEach(t),CIo=r(mke," \u2014 "),OO=n(mke,"A",{href:!0});var Z_t=s(OO);wIo=r(Z_t,"CamembertForSequenceClassification"),Z_t.forEach(t),AIo=r(mke," (CamemBERT model)"),mke.forEach(t),LIo=i(j),L1=n(j,"LI",{});var gke=s(L1);lhe=n(gke,"STRONG",{});var e7t=s(lhe);yIo=r(e7t,"canine"),e7t.forEach(t),xIo=r(gke," \u2014 "),VO=n(gke,"A",{href:!0});var o7t=s(VO);$Io=r(o7t,"CanineForSequenceClassification"),o7t.forEach(t),kIo=r(gke," (CANINE model)"),gke.forEach(t),SIo=i(j),y1=n(j,"LI",{});var hke=s(y1);ihe=n(hke,"STRONG",{});var r7t=s(ihe);RIo=r(r7t,"convbert"),r7t.forEach(t),PIo=r(hke," \u2014 "),XO=n(hke,"A",{href:!0});var t7t=s(XO);BIo=r(t7t,"ConvBertForSequenceClassification"),t7t.forEach(t),IIo=r(hke," (ConvBERT model)"),hke.forEach(t),NIo=i(j),x1=n(j,"LI",{});var pke=s(x1);dhe=n(pke,"STRONG",{});var a7t=s(dhe);qIo=r(a7t,"ctrl"),a7t.forEach(t),jIo=r(pke," \u2014 "),zO=n(pke,"A",{href:!0});var n7t=s(zO);DIo=r(n7t,"CTRLForSequenceClassification"),n7t.forEach(t),GIo=r(pke," (CTRL model)"),pke.forEach(t),OIo=i(j),$1=n(j,"LI",{});var uke=s($1);che=n(uke,"STRONG",{});var s7t=s(che);VIo=r(s7t,"data2vec-text"),s7t.forEach(t),XIo=r(uke," \u2014 "),WO=n(uke,"A",{href:!0});var l7t=s(WO);zIo=r(l7t,"Data2VecTextForSequenceClassification"),l7t.forEach(t),WIo=r(uke," (Data2VecText model)"),uke.forEach(t),QIo=i(j),k1=n(j,"LI",{});var _ke=s(k1);fhe=n(_ke,"STRONG",{});var i7t=s(fhe);HIo=r(i7t,"deberta"),i7t.forEach(t),UIo=r(_ke," \u2014 "),QO=n(_ke,"A",{href:!0});var d7t=s(QO);JIo=r(d7t,"DebertaForSequenceClassification"),d7t.forEach(t),YIo=r(_ke," (DeBERTa model)"),_ke.forEach(t),KIo=i(j),S1=n(j,"LI",{});var bke=s(S1);mhe=n(bke,"STRONG",{});var c7t=s(mhe);ZIo=r(c7t,"deberta-v2"),c7t.forEach(t),eNo=r(bke," \u2014 "),HO=n(bke,"A",{href:!0});var f7t=s(HO);oNo=r(f7t,"DebertaV2ForSequenceClassification"),f7t.forEach(t),rNo=r(bke," (DeBERTa-v2 model)"),bke.forEach(t),tNo=i(j),R1=n(j,"LI",{});var vke=s(R1);ghe=n(vke,"STRONG",{});var m7t=s(ghe);aNo=r(m7t,"distilbert"),m7t.forEach(t),nNo=r(vke," \u2014 "),UO=n(vke,"A",{href:!0});var g7t=s(UO);sNo=r(g7t,"DistilBertForSequenceClassification"),g7t.forEach(t),lNo=r(vke," (DistilBERT model)"),vke.forEach(t),iNo=i(j),P1=n(j,"LI",{});var Fke=s(P1);hhe=n(Fke,"STRONG",{});var h7t=s(hhe);dNo=r(h7t,"electra"),h7t.forEach(t),cNo=r(Fke," \u2014 "),JO=n(Fke,"A",{href:!0});var p7t=s(JO);fNo=r(p7t,"ElectraForSequenceClassification"),p7t.forEach(t),mNo=r(Fke," (ELECTRA model)"),Fke.forEach(t),gNo=i(j),B1=n(j,"LI",{});var Tke=s(B1);phe=n(Tke,"STRONG",{});var u7t=s(phe);hNo=r(u7t,"flaubert"),u7t.forEach(t),pNo=r(Tke," \u2014 "),YO=n(Tke,"A",{href:!0});var _7t=s(YO);uNo=r(_7t,"FlaubertForSequenceClassification"),_7t.forEach(t),_No=r(Tke," (FlauBERT model)"),Tke.forEach(t),bNo=i(j),I1=n(j,"LI",{});var Mke=s(I1);uhe=n(Mke,"STRONG",{});var b7t=s(uhe);vNo=r(b7t,"fnet"),b7t.forEach(t),FNo=r(Mke," \u2014 "),KO=n(Mke,"A",{href:!0});var v7t=s(KO);TNo=r(v7t,"FNetForSequenceClassification"),v7t.forEach(t),MNo=r(Mke," (FNet model)"),Mke.forEach(t),ENo=i(j),N1=n(j,"LI",{});var Eke=s(N1);_he=n(Eke,"STRONG",{});var F7t=s(_he);CNo=r(F7t,"funnel"),F7t.forEach(t),wNo=r(Eke," \u2014 "),ZO=n(Eke,"A",{href:!0});var T7t=s(ZO);ANo=r(T7t,"FunnelForSequenceClassification"),T7t.forEach(t),LNo=r(Eke," (Funnel Transformer model)"),Eke.forEach(t),yNo=i(j),q1=n(j,"LI",{});var Cke=s(q1);bhe=n(Cke,"STRONG",{});var M7t=s(bhe);xNo=r(M7t,"gpt2"),M7t.forEach(t),$No=r(Cke," \u2014 "),eV=n(Cke,"A",{href:!0});var E7t=s(eV);kNo=r(E7t,"GPT2ForSequenceClassification"),E7t.forEach(t),SNo=r(Cke," (OpenAI GPT-2 model)"),Cke.forEach(t),RNo=i(j),j1=n(j,"LI",{});var wke=s(j1);vhe=n(wke,"STRONG",{});var C7t=s(vhe);PNo=r(C7t,"gpt_neo"),C7t.forEach(t),BNo=r(wke," \u2014 "),oV=n(wke,"A",{href:!0});var w7t=s(oV);INo=r(w7t,"GPTNeoForSequenceClassification"),w7t.forEach(t),NNo=r(wke," (GPT Neo model)"),wke.forEach(t),qNo=i(j),D1=n(j,"LI",{});var Ake=s(D1);Fhe=n(Ake,"STRONG",{});var A7t=s(Fhe);jNo=r(A7t,"gptj"),A7t.forEach(t),DNo=r(Ake," \u2014 "),rV=n(Ake,"A",{href:!0});var L7t=s(rV);GNo=r(L7t,"GPTJForSequenceClassification"),L7t.forEach(t),ONo=r(Ake," (GPT-J model)"),Ake.forEach(t),VNo=i(j),G1=n(j,"LI",{});var Lke=s(G1);The=n(Lke,"STRONG",{});var y7t=s(The);XNo=r(y7t,"ibert"),y7t.forEach(t),zNo=r(Lke," \u2014 "),tV=n(Lke,"A",{href:!0});var x7t=s(tV);WNo=r(x7t,"IBertForSequenceClassification"),x7t.forEach(t),QNo=r(Lke," (I-BERT model)"),Lke.forEach(t),HNo=i(j),O1=n(j,"LI",{});var yke=s(O1);Mhe=n(yke,"STRONG",{});var $7t=s(Mhe);UNo=r($7t,"layoutlm"),$7t.forEach(t),JNo=r(yke," \u2014 "),aV=n(yke,"A",{href:!0});var k7t=s(aV);YNo=r(k7t,"LayoutLMForSequenceClassification"),k7t.forEach(t),KNo=r(yke," (LayoutLM model)"),yke.forEach(t),ZNo=i(j),V1=n(j,"LI",{});var xke=s(V1);Ehe=n(xke,"STRONG",{});var S7t=s(Ehe);eqo=r(S7t,"layoutlmv2"),S7t.forEach(t),oqo=r(xke," \u2014 "),nV=n(xke,"A",{href:!0});var R7t=s(nV);rqo=r(R7t,"LayoutLMv2ForSequenceClassification"),R7t.forEach(t),tqo=r(xke," (LayoutLMv2 model)"),xke.forEach(t),aqo=i(j),X1=n(j,"LI",{});var $ke=s(X1);Che=n($ke,"STRONG",{});var P7t=s(Che);nqo=r(P7t,"layoutlmv3"),P7t.forEach(t),sqo=r($ke," \u2014 "),sV=n($ke,"A",{href:!0});var B7t=s(sV);lqo=r(B7t,"LayoutLMv3ForSequenceClassification"),B7t.forEach(t),iqo=r($ke," (LayoutLMv3 model)"),$ke.forEach(t),dqo=i(j),z1=n(j,"LI",{});var kke=s(z1);whe=n(kke,"STRONG",{});var I7t=s(whe);cqo=r(I7t,"led"),I7t.forEach(t),fqo=r(kke," \u2014 "),lV=n(kke,"A",{href:!0});var N7t=s(lV);mqo=r(N7t,"LEDForSequenceClassification"),N7t.forEach(t),gqo=r(kke," (LED model)"),kke.forEach(t),hqo=i(j),W1=n(j,"LI",{});var Ske=s(W1);Ahe=n(Ske,"STRONG",{});var q7t=s(Ahe);pqo=r(q7t,"longformer"),q7t.forEach(t),uqo=r(Ske," \u2014 "),iV=n(Ske,"A",{href:!0});var j7t=s(iV);_qo=r(j7t,"LongformerForSequenceClassification"),j7t.forEach(t),bqo=r(Ske," (Longformer model)"),Ske.forEach(t),vqo=i(j),Q1=n(j,"LI",{});var Rke=s(Q1);Lhe=n(Rke,"STRONG",{});var D7t=s(Lhe);Fqo=r(D7t,"mbart"),D7t.forEach(t),Tqo=r(Rke," \u2014 "),dV=n(Rke,"A",{href:!0});var G7t=s(dV);Mqo=r(G7t,"MBartForSequenceClassification"),G7t.forEach(t),Eqo=r(Rke," (mBART model)"),Rke.forEach(t),Cqo=i(j),H1=n(j,"LI",{});var Pke=s(H1);yhe=n(Pke,"STRONG",{});var O7t=s(yhe);wqo=r(O7t,"megatron-bert"),O7t.forEach(t),Aqo=r(Pke," \u2014 "),cV=n(Pke,"A",{href:!0});var V7t=s(cV);Lqo=r(V7t,"MegatronBertForSequenceClassification"),V7t.forEach(t),yqo=r(Pke," (Megatron-BERT model)"),Pke.forEach(t),xqo=i(j),U1=n(j,"LI",{});var Bke=s(U1);xhe=n(Bke,"STRONG",{});var X7t=s(xhe);$qo=r(X7t,"mobilebert"),X7t.forEach(t),kqo=r(Bke," \u2014 "),fV=n(Bke,"A",{href:!0});var z7t=s(fV);Sqo=r(z7t,"MobileBertForSequenceClassification"),z7t.forEach(t),Rqo=r(Bke," (MobileBERT model)"),Bke.forEach(t),Pqo=i(j),J1=n(j,"LI",{});var Ike=s(J1);$he=n(Ike,"STRONG",{});var W7t=s($he);Bqo=r(W7t,"mpnet"),W7t.forEach(t),Iqo=r(Ike," \u2014 "),mV=n(Ike,"A",{href:!0});var Q7t=s(mV);Nqo=r(Q7t,"MPNetForSequenceClassification"),Q7t.forEach(t),qqo=r(Ike," (MPNet model)"),Ike.forEach(t),jqo=i(j),Y1=n(j,"LI",{});var Nke=s(Y1);khe=n(Nke,"STRONG",{});var H7t=s(khe);Dqo=r(H7t,"nystromformer"),H7t.forEach(t),Gqo=r(Nke," \u2014 "),gV=n(Nke,"A",{href:!0});var U7t=s(gV);Oqo=r(U7t,"NystromformerForSequenceClassification"),U7t.forEach(t),Vqo=r(Nke," (Nystr\xF6mformer model)"),Nke.forEach(t),Xqo=i(j),K1=n(j,"LI",{});var qke=s(K1);She=n(qke,"STRONG",{});var J7t=s(She);zqo=r(J7t,"openai-gpt"),J7t.forEach(t),Wqo=r(qke," \u2014 "),hV=n(qke,"A",{href:!0});var Y7t=s(hV);Qqo=r(Y7t,"OpenAIGPTForSequenceClassification"),Y7t.forEach(t),Hqo=r(qke," (OpenAI GPT model)"),qke.forEach(t),Uqo=i(j),Z1=n(j,"LI",{});var jke=s(Z1);Rhe=n(jke,"STRONG",{});var K7t=s(Rhe);Jqo=r(K7t,"perceiver"),K7t.forEach(t),Yqo=r(jke," \u2014 "),pV=n(jke,"A",{href:!0});var Z7t=s(pV);Kqo=r(Z7t,"PerceiverForSequenceClassification"),Z7t.forEach(t),Zqo=r(jke," (Perceiver model)"),jke.forEach(t),ejo=i(j),eb=n(j,"LI",{});var Dke=s(eb);Phe=n(Dke,"STRONG",{});var e2t=s(Phe);ojo=r(e2t,"plbart"),e2t.forEach(t),rjo=r(Dke," \u2014 "),uV=n(Dke,"A",{href:!0});var o2t=s(uV);tjo=r(o2t,"PLBartForSequenceClassification"),o2t.forEach(t),ajo=r(Dke," (PLBart model)"),Dke.forEach(t),njo=i(j),ob=n(j,"LI",{});var Gke=s(ob);Bhe=n(Gke,"STRONG",{});var r2t=s(Bhe);sjo=r(r2t,"qdqbert"),r2t.forEach(t),ljo=r(Gke," \u2014 "),_V=n(Gke,"A",{href:!0});var t2t=s(_V);ijo=r(t2t,"QDQBertForSequenceClassification"),t2t.forEach(t),djo=r(Gke," (QDQBert model)"),Gke.forEach(t),cjo=i(j),rb=n(j,"LI",{});var Oke=s(rb);Ihe=n(Oke,"STRONG",{});var a2t=s(Ihe);fjo=r(a2t,"reformer"),a2t.forEach(t),mjo=r(Oke," \u2014 "),bV=n(Oke,"A",{href:!0});var n2t=s(bV);gjo=r(n2t,"ReformerForSequenceClassification"),n2t.forEach(t),hjo=r(Oke," (Reformer model)"),Oke.forEach(t),pjo=i(j),tb=n(j,"LI",{});var Vke=s(tb);Nhe=n(Vke,"STRONG",{});var s2t=s(Nhe);ujo=r(s2t,"rembert"),s2t.forEach(t),_jo=r(Vke," \u2014 "),vV=n(Vke,"A",{href:!0});var l2t=s(vV);bjo=r(l2t,"RemBertForSequenceClassification"),l2t.forEach(t),vjo=r(Vke," (RemBERT model)"),Vke.forEach(t),Fjo=i(j),ab=n(j,"LI",{});var Xke=s(ab);qhe=n(Xke,"STRONG",{});var i2t=s(qhe);Tjo=r(i2t,"roberta"),i2t.forEach(t),Mjo=r(Xke," \u2014 "),FV=n(Xke,"A",{href:!0});var d2t=s(FV);Ejo=r(d2t,"RobertaForSequenceClassification"),d2t.forEach(t),Cjo=r(Xke," (RoBERTa model)"),Xke.forEach(t),wjo=i(j),nb=n(j,"LI",{});var zke=s(nb);jhe=n(zke,"STRONG",{});var c2t=s(jhe);Ajo=r(c2t,"roformer"),c2t.forEach(t),Ljo=r(zke," \u2014 "),TV=n(zke,"A",{href:!0});var f2t=s(TV);yjo=r(f2t,"RoFormerForSequenceClassification"),f2t.forEach(t),xjo=r(zke," (RoFormer model)"),zke.forEach(t),$jo=i(j),sb=n(j,"LI",{});var Wke=s(sb);Dhe=n(Wke,"STRONG",{});var m2t=s(Dhe);kjo=r(m2t,"squeezebert"),m2t.forEach(t),Sjo=r(Wke," \u2014 "),MV=n(Wke,"A",{href:!0});var g2t=s(MV);Rjo=r(g2t,"SqueezeBertForSequenceClassification"),g2t.forEach(t),Pjo=r(Wke," (SqueezeBERT model)"),Wke.forEach(t),Bjo=i(j),lb=n(j,"LI",{});var Qke=s(lb);Ghe=n(Qke,"STRONG",{});var h2t=s(Ghe);Ijo=r(h2t,"tapas"),h2t.forEach(t),Njo=r(Qke," \u2014 "),EV=n(Qke,"A",{href:!0});var p2t=s(EV);qjo=r(p2t,"TapasForSequenceClassification"),p2t.forEach(t),jjo=r(Qke," (TAPAS model)"),Qke.forEach(t),Djo=i(j),ib=n(j,"LI",{});var Hke=s(ib);Ohe=n(Hke,"STRONG",{});var u2t=s(Ohe);Gjo=r(u2t,"transfo-xl"),u2t.forEach(t),Ojo=r(Hke," \u2014 "),CV=n(Hke,"A",{href:!0});var _2t=s(CV);Vjo=r(_2t,"TransfoXLForSequenceClassification"),_2t.forEach(t),Xjo=r(Hke," (Transformer-XL model)"),Hke.forEach(t),zjo=i(j),db=n(j,"LI",{});var Uke=s(db);Vhe=n(Uke,"STRONG",{});var b2t=s(Vhe);Wjo=r(b2t,"xlm"),b2t.forEach(t),Qjo=r(Uke," \u2014 "),wV=n(Uke,"A",{href:!0});var v2t=s(wV);Hjo=r(v2t,"XLMForSequenceClassification"),v2t.forEach(t),Ujo=r(Uke," (XLM model)"),Uke.forEach(t),Jjo=i(j),cb=n(j,"LI",{});var Jke=s(cb);Xhe=n(Jke,"STRONG",{});var F2t=s(Xhe);Yjo=r(F2t,"xlm-roberta"),F2t.forEach(t),Kjo=r(Jke," \u2014 "),AV=n(Jke,"A",{href:!0});var T2t=s(AV);Zjo=r(T2t,"XLMRobertaForSequenceClassification"),T2t.forEach(t),eDo=r(Jke," (XLM-RoBERTa model)"),Jke.forEach(t),oDo=i(j),fb=n(j,"LI",{});var Yke=s(fb);zhe=n(Yke,"STRONG",{});var M2t=s(zhe);rDo=r(M2t,"xlm-roberta-xl"),M2t.forEach(t),tDo=r(Yke," \u2014 "),LV=n(Yke,"A",{href:!0});var E2t=s(LV);aDo=r(E2t,"XLMRobertaXLForSequenceClassification"),E2t.forEach(t),nDo=r(Yke," (XLM-RoBERTa-XL model)"),Yke.forEach(t),sDo=i(j),mb=n(j,"LI",{});var Kke=s(mb);Whe=n(Kke,"STRONG",{});var C2t=s(Whe);lDo=r(C2t,"xlnet"),C2t.forEach(t),iDo=r(Kke," \u2014 "),yV=n(Kke,"A",{href:!0});var w2t=s(yV);dDo=r(w2t,"XLNetForSequenceClassification"),w2t.forEach(t),cDo=r(Kke," (XLNet model)"),Kke.forEach(t),fDo=i(j),gb=n(j,"LI",{});var Zke=s(gb);Qhe=n(Zke,"STRONG",{});var A2t=s(Qhe);mDo=r(A2t,"yoso"),A2t.forEach(t),gDo=r(Zke," \u2014 "),xV=n(Zke,"A",{href:!0});var L2t=s(xV);hDo=r(L2t,"YosoForSequenceClassification"),L2t.forEach(t),pDo=r(Zke," (YOSO model)"),Zke.forEach(t),j.forEach(t),uDo=i(da),hb=n(da,"P",{});var eSe=s(hb);_Do=r(eSe,"The model is set in evaluation mode by default using "),Hhe=n(eSe,"CODE",{});var y2t=s(Hhe);bDo=r(y2t,"model.eval()"),y2t.forEach(t),vDo=r(eSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uhe=n(eSe,"CODE",{});var x2t=s(Uhe);FDo=r(x2t,"model.train()"),x2t.forEach(t),eSe.forEach(t),TDo=i(da),T(pb.$$.fragment,da),da.forEach(t),el.forEach(t),jGe=i(f),Ki=n(f,"H2",{class:!0});var zVe=s(Ki);ub=n(zVe,"A",{id:!0,class:!0,href:!0});var $2t=s(ub);Jhe=n($2t,"SPAN",{});var k2t=s(Jhe);T(wy.$$.fragment,k2t),k2t.forEach(t),$2t.forEach(t),MDo=i(zVe),Yhe=n(zVe,"SPAN",{});var S2t=s(Yhe);EDo=r(S2t,"AutoModelForMultipleChoice"),S2t.forEach(t),zVe.forEach(t),DGe=i(f),Bo=n(f,"DIV",{class:!0});var ol=s(Bo);T(Ay.$$.fragment,ol),CDo=i(ol),Zi=n(ol,"P",{});var _oe=s(Zi);wDo=r(_oe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),$V=n(_oe,"A",{href:!0});var R2t=s($V);ADo=r(R2t,"from_pretrained()"),R2t.forEach(t),LDo=r(_oe," class method or the "),kV=n(_oe,"A",{href:!0});var P2t=s(kV);yDo=r(P2t,"from_config()"),P2t.forEach(t),xDo=r(_oe,` class
method.`),_oe.forEach(t),$Do=i(ol),Ly=n(ol,"P",{});var WVe=s(Ly);kDo=r(WVe,"This class cannot be instantiated directly using "),Khe=n(WVe,"CODE",{});var B2t=s(Khe);SDo=r(B2t,"__init__()"),B2t.forEach(t),RDo=r(WVe," (throws an error)."),WVe.forEach(t),PDo=i(ol),ft=n(ol,"DIV",{class:!0});var NA=s(ft);T(yy.$$.fragment,NA),BDo=i(NA),Zhe=n(NA,"P",{});var I2t=s(Zhe);IDo=r(I2t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),I2t.forEach(t),NDo=i(NA),ed=n(NA,"P",{});var boe=s(ed);qDo=r(boe,`Note:
Loading a model from its configuration file does `),epe=n(boe,"STRONG",{});var N2t=s(epe);jDo=r(N2t,"not"),N2t.forEach(t),DDo=r(boe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SV=n(boe,"A",{href:!0});var q2t=s(SV);GDo=r(q2t,"from_pretrained()"),q2t.forEach(t),ODo=r(boe," to load the model weights."),boe.forEach(t),VDo=i(NA),T(_b.$$.fragment,NA),NA.forEach(t),XDo=i(ol),ro=n(ol,"DIV",{class:!0});var ca=s(ro);T(xy.$$.fragment,ca),zDo=i(ca),ope=n(ca,"P",{});var j2t=s(ope);WDo=r(j2t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),j2t.forEach(t),QDo=i(ca),qa=n(ca,"P",{});var qA=s(qa);HDo=r(qA,"The model class to instantiate is selected based on the "),rpe=n(qA,"CODE",{});var D2t=s(rpe);UDo=r(D2t,"model_type"),D2t.forEach(t),JDo=r(qA,` property of the config object (either
passed as an argument or loaded from `),tpe=n(qA,"CODE",{});var G2t=s(tpe);YDo=r(G2t,"pretrained_model_name_or_path"),G2t.forEach(t),KDo=r(qA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ape=n(qA,"CODE",{});var O2t=s(ape);ZDo=r(O2t,"pretrained_model_name_or_path"),O2t.forEach(t),eGo=r(qA,":"),qA.forEach(t),oGo=i(ca),Z=n(ca,"UL",{});var ee=s(Z);bb=n(ee,"LI",{});var oSe=s(bb);npe=n(oSe,"STRONG",{});var V2t=s(npe);rGo=r(V2t,"albert"),V2t.forEach(t),tGo=r(oSe," \u2014 "),RV=n(oSe,"A",{href:!0});var X2t=s(RV);aGo=r(X2t,"AlbertForMultipleChoice"),X2t.forEach(t),nGo=r(oSe," (ALBERT model)"),oSe.forEach(t),sGo=i(ee),vb=n(ee,"LI",{});var rSe=s(vb);spe=n(rSe,"STRONG",{});var z2t=s(spe);lGo=r(z2t,"bert"),z2t.forEach(t),iGo=r(rSe," \u2014 "),PV=n(rSe,"A",{href:!0});var W2t=s(PV);dGo=r(W2t,"BertForMultipleChoice"),W2t.forEach(t),cGo=r(rSe," (BERT model)"),rSe.forEach(t),fGo=i(ee),Fb=n(ee,"LI",{});var tSe=s(Fb);lpe=n(tSe,"STRONG",{});var Q2t=s(lpe);mGo=r(Q2t,"big_bird"),Q2t.forEach(t),gGo=r(tSe," \u2014 "),BV=n(tSe,"A",{href:!0});var H2t=s(BV);hGo=r(H2t,"BigBirdForMultipleChoice"),H2t.forEach(t),pGo=r(tSe," (BigBird model)"),tSe.forEach(t),uGo=i(ee),Tb=n(ee,"LI",{});var aSe=s(Tb);ipe=n(aSe,"STRONG",{});var U2t=s(ipe);_Go=r(U2t,"camembert"),U2t.forEach(t),bGo=r(aSe," \u2014 "),IV=n(aSe,"A",{href:!0});var J2t=s(IV);vGo=r(J2t,"CamembertForMultipleChoice"),J2t.forEach(t),FGo=r(aSe," (CamemBERT model)"),aSe.forEach(t),TGo=i(ee),Mb=n(ee,"LI",{});var nSe=s(Mb);dpe=n(nSe,"STRONG",{});var Y2t=s(dpe);MGo=r(Y2t,"canine"),Y2t.forEach(t),EGo=r(nSe," \u2014 "),NV=n(nSe,"A",{href:!0});var K2t=s(NV);CGo=r(K2t,"CanineForMultipleChoice"),K2t.forEach(t),wGo=r(nSe," (CANINE model)"),nSe.forEach(t),AGo=i(ee),Eb=n(ee,"LI",{});var sSe=s(Eb);cpe=n(sSe,"STRONG",{});var Z2t=s(cpe);LGo=r(Z2t,"convbert"),Z2t.forEach(t),yGo=r(sSe," \u2014 "),qV=n(sSe,"A",{href:!0});var e1t=s(qV);xGo=r(e1t,"ConvBertForMultipleChoice"),e1t.forEach(t),$Go=r(sSe," (ConvBERT model)"),sSe.forEach(t),kGo=i(ee),Cb=n(ee,"LI",{});var lSe=s(Cb);fpe=n(lSe,"STRONG",{});var o1t=s(fpe);SGo=r(o1t,"data2vec-text"),o1t.forEach(t),RGo=r(lSe," \u2014 "),jV=n(lSe,"A",{href:!0});var r1t=s(jV);PGo=r(r1t,"Data2VecTextForMultipleChoice"),r1t.forEach(t),BGo=r(lSe," (Data2VecText model)"),lSe.forEach(t),IGo=i(ee),wb=n(ee,"LI",{});var iSe=s(wb);mpe=n(iSe,"STRONG",{});var t1t=s(mpe);NGo=r(t1t,"deberta-v2"),t1t.forEach(t),qGo=r(iSe," \u2014 "),DV=n(iSe,"A",{href:!0});var a1t=s(DV);jGo=r(a1t,"DebertaV2ForMultipleChoice"),a1t.forEach(t),DGo=r(iSe," (DeBERTa-v2 model)"),iSe.forEach(t),GGo=i(ee),Ab=n(ee,"LI",{});var dSe=s(Ab);gpe=n(dSe,"STRONG",{});var n1t=s(gpe);OGo=r(n1t,"distilbert"),n1t.forEach(t),VGo=r(dSe," \u2014 "),GV=n(dSe,"A",{href:!0});var s1t=s(GV);XGo=r(s1t,"DistilBertForMultipleChoice"),s1t.forEach(t),zGo=r(dSe," (DistilBERT model)"),dSe.forEach(t),WGo=i(ee),Lb=n(ee,"LI",{});var cSe=s(Lb);hpe=n(cSe,"STRONG",{});var l1t=s(hpe);QGo=r(l1t,"electra"),l1t.forEach(t),HGo=r(cSe," \u2014 "),OV=n(cSe,"A",{href:!0});var i1t=s(OV);UGo=r(i1t,"ElectraForMultipleChoice"),i1t.forEach(t),JGo=r(cSe," (ELECTRA model)"),cSe.forEach(t),YGo=i(ee),yb=n(ee,"LI",{});var fSe=s(yb);ppe=n(fSe,"STRONG",{});var d1t=s(ppe);KGo=r(d1t,"flaubert"),d1t.forEach(t),ZGo=r(fSe," \u2014 "),VV=n(fSe,"A",{href:!0});var c1t=s(VV);eOo=r(c1t,"FlaubertForMultipleChoice"),c1t.forEach(t),oOo=r(fSe," (FlauBERT model)"),fSe.forEach(t),rOo=i(ee),xb=n(ee,"LI",{});var mSe=s(xb);upe=n(mSe,"STRONG",{});var f1t=s(upe);tOo=r(f1t,"fnet"),f1t.forEach(t),aOo=r(mSe," \u2014 "),XV=n(mSe,"A",{href:!0});var m1t=s(XV);nOo=r(m1t,"FNetForMultipleChoice"),m1t.forEach(t),sOo=r(mSe," (FNet model)"),mSe.forEach(t),lOo=i(ee),$b=n(ee,"LI",{});var gSe=s($b);_pe=n(gSe,"STRONG",{});var g1t=s(_pe);iOo=r(g1t,"funnel"),g1t.forEach(t),dOo=r(gSe," \u2014 "),zV=n(gSe,"A",{href:!0});var h1t=s(zV);cOo=r(h1t,"FunnelForMultipleChoice"),h1t.forEach(t),fOo=r(gSe," (Funnel Transformer model)"),gSe.forEach(t),mOo=i(ee),kb=n(ee,"LI",{});var hSe=s(kb);bpe=n(hSe,"STRONG",{});var p1t=s(bpe);gOo=r(p1t,"ibert"),p1t.forEach(t),hOo=r(hSe," \u2014 "),WV=n(hSe,"A",{href:!0});var u1t=s(WV);pOo=r(u1t,"IBertForMultipleChoice"),u1t.forEach(t),uOo=r(hSe," (I-BERT model)"),hSe.forEach(t),_Oo=i(ee),Sb=n(ee,"LI",{});var pSe=s(Sb);vpe=n(pSe,"STRONG",{});var _1t=s(vpe);bOo=r(_1t,"longformer"),_1t.forEach(t),vOo=r(pSe," \u2014 "),QV=n(pSe,"A",{href:!0});var b1t=s(QV);FOo=r(b1t,"LongformerForMultipleChoice"),b1t.forEach(t),TOo=r(pSe," (Longformer model)"),pSe.forEach(t),MOo=i(ee),Rb=n(ee,"LI",{});var uSe=s(Rb);Fpe=n(uSe,"STRONG",{});var v1t=s(Fpe);EOo=r(v1t,"megatron-bert"),v1t.forEach(t),COo=r(uSe," \u2014 "),HV=n(uSe,"A",{href:!0});var F1t=s(HV);wOo=r(F1t,"MegatronBertForMultipleChoice"),F1t.forEach(t),AOo=r(uSe," (Megatron-BERT model)"),uSe.forEach(t),LOo=i(ee),Pb=n(ee,"LI",{});var _Se=s(Pb);Tpe=n(_Se,"STRONG",{});var T1t=s(Tpe);yOo=r(T1t,"mobilebert"),T1t.forEach(t),xOo=r(_Se," \u2014 "),UV=n(_Se,"A",{href:!0});var M1t=s(UV);$Oo=r(M1t,"MobileBertForMultipleChoice"),M1t.forEach(t),kOo=r(_Se," (MobileBERT model)"),_Se.forEach(t),SOo=i(ee),Bb=n(ee,"LI",{});var bSe=s(Bb);Mpe=n(bSe,"STRONG",{});var E1t=s(Mpe);ROo=r(E1t,"mpnet"),E1t.forEach(t),POo=r(bSe," \u2014 "),JV=n(bSe,"A",{href:!0});var C1t=s(JV);BOo=r(C1t,"MPNetForMultipleChoice"),C1t.forEach(t),IOo=r(bSe," (MPNet model)"),bSe.forEach(t),NOo=i(ee),Ib=n(ee,"LI",{});var vSe=s(Ib);Epe=n(vSe,"STRONG",{});var w1t=s(Epe);qOo=r(w1t,"nystromformer"),w1t.forEach(t),jOo=r(vSe," \u2014 "),YV=n(vSe,"A",{href:!0});var A1t=s(YV);DOo=r(A1t,"NystromformerForMultipleChoice"),A1t.forEach(t),GOo=r(vSe," (Nystr\xF6mformer model)"),vSe.forEach(t),OOo=i(ee),Nb=n(ee,"LI",{});var FSe=s(Nb);Cpe=n(FSe,"STRONG",{});var L1t=s(Cpe);VOo=r(L1t,"qdqbert"),L1t.forEach(t),XOo=r(FSe," \u2014 "),KV=n(FSe,"A",{href:!0});var y1t=s(KV);zOo=r(y1t,"QDQBertForMultipleChoice"),y1t.forEach(t),WOo=r(FSe," (QDQBert model)"),FSe.forEach(t),QOo=i(ee),qb=n(ee,"LI",{});var TSe=s(qb);wpe=n(TSe,"STRONG",{});var x1t=s(wpe);HOo=r(x1t,"rembert"),x1t.forEach(t),UOo=r(TSe," \u2014 "),ZV=n(TSe,"A",{href:!0});var $1t=s(ZV);JOo=r($1t,"RemBertForMultipleChoice"),$1t.forEach(t),YOo=r(TSe," (RemBERT model)"),TSe.forEach(t),KOo=i(ee),jb=n(ee,"LI",{});var MSe=s(jb);Ape=n(MSe,"STRONG",{});var k1t=s(Ape);ZOo=r(k1t,"roberta"),k1t.forEach(t),eVo=r(MSe," \u2014 "),eX=n(MSe,"A",{href:!0});var S1t=s(eX);oVo=r(S1t,"RobertaForMultipleChoice"),S1t.forEach(t),rVo=r(MSe," (RoBERTa model)"),MSe.forEach(t),tVo=i(ee),Db=n(ee,"LI",{});var ESe=s(Db);Lpe=n(ESe,"STRONG",{});var R1t=s(Lpe);aVo=r(R1t,"roformer"),R1t.forEach(t),nVo=r(ESe," \u2014 "),oX=n(ESe,"A",{href:!0});var P1t=s(oX);sVo=r(P1t,"RoFormerForMultipleChoice"),P1t.forEach(t),lVo=r(ESe," (RoFormer model)"),ESe.forEach(t),iVo=i(ee),Gb=n(ee,"LI",{});var CSe=s(Gb);ype=n(CSe,"STRONG",{});var B1t=s(ype);dVo=r(B1t,"squeezebert"),B1t.forEach(t),cVo=r(CSe," \u2014 "),rX=n(CSe,"A",{href:!0});var I1t=s(rX);fVo=r(I1t,"SqueezeBertForMultipleChoice"),I1t.forEach(t),mVo=r(CSe," (SqueezeBERT model)"),CSe.forEach(t),gVo=i(ee),Ob=n(ee,"LI",{});var wSe=s(Ob);xpe=n(wSe,"STRONG",{});var N1t=s(xpe);hVo=r(N1t,"xlm"),N1t.forEach(t),pVo=r(wSe," \u2014 "),tX=n(wSe,"A",{href:!0});var q1t=s(tX);uVo=r(q1t,"XLMForMultipleChoice"),q1t.forEach(t),_Vo=r(wSe," (XLM model)"),wSe.forEach(t),bVo=i(ee),Vb=n(ee,"LI",{});var ASe=s(Vb);$pe=n(ASe,"STRONG",{});var j1t=s($pe);vVo=r(j1t,"xlm-roberta"),j1t.forEach(t),FVo=r(ASe," \u2014 "),aX=n(ASe,"A",{href:!0});var D1t=s(aX);TVo=r(D1t,"XLMRobertaForMultipleChoice"),D1t.forEach(t),MVo=r(ASe," (XLM-RoBERTa model)"),ASe.forEach(t),EVo=i(ee),Xb=n(ee,"LI",{});var LSe=s(Xb);kpe=n(LSe,"STRONG",{});var G1t=s(kpe);CVo=r(G1t,"xlm-roberta-xl"),G1t.forEach(t),wVo=r(LSe," \u2014 "),nX=n(LSe,"A",{href:!0});var O1t=s(nX);AVo=r(O1t,"XLMRobertaXLForMultipleChoice"),O1t.forEach(t),LVo=r(LSe," (XLM-RoBERTa-XL model)"),LSe.forEach(t),yVo=i(ee),zb=n(ee,"LI",{});var ySe=s(zb);Spe=n(ySe,"STRONG",{});var V1t=s(Spe);xVo=r(V1t,"xlnet"),V1t.forEach(t),$Vo=r(ySe," \u2014 "),sX=n(ySe,"A",{href:!0});var X1t=s(sX);kVo=r(X1t,"XLNetForMultipleChoice"),X1t.forEach(t),SVo=r(ySe," (XLNet model)"),ySe.forEach(t),RVo=i(ee),Wb=n(ee,"LI",{});var xSe=s(Wb);Rpe=n(xSe,"STRONG",{});var z1t=s(Rpe);PVo=r(z1t,"yoso"),z1t.forEach(t),BVo=r(xSe," \u2014 "),lX=n(xSe,"A",{href:!0});var W1t=s(lX);IVo=r(W1t,"YosoForMultipleChoice"),W1t.forEach(t),NVo=r(xSe," (YOSO model)"),xSe.forEach(t),ee.forEach(t),qVo=i(ca),Qb=n(ca,"P",{});var $Se=s(Qb);jVo=r($Se,"The model is set in evaluation mode by default using "),Ppe=n($Se,"CODE",{});var Q1t=s(Ppe);DVo=r(Q1t,"model.eval()"),Q1t.forEach(t),GVo=r($Se,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bpe=n($Se,"CODE",{});var H1t=s(Bpe);OVo=r(H1t,"model.train()"),H1t.forEach(t),$Se.forEach(t),VVo=i(ca),T(Hb.$$.fragment,ca),ca.forEach(t),ol.forEach(t),GGe=i(f),od=n(f,"H2",{class:!0});var QVe=s(od);Ub=n(QVe,"A",{id:!0,class:!0,href:!0});var U1t=s(Ub);Ipe=n(U1t,"SPAN",{});var J1t=s(Ipe);T($y.$$.fragment,J1t),J1t.forEach(t),U1t.forEach(t),XVo=i(QVe),Npe=n(QVe,"SPAN",{});var Y1t=s(Npe);zVo=r(Y1t,"AutoModelForNextSentencePrediction"),Y1t.forEach(t),QVe.forEach(t),OGe=i(f),Io=n(f,"DIV",{class:!0});var rl=s(Io);T(ky.$$.fragment,rl),WVo=i(rl),rd=n(rl,"P",{});var voe=s(rd);QVo=r(voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),iX=n(voe,"A",{href:!0});var K1t=s(iX);HVo=r(K1t,"from_pretrained()"),K1t.forEach(t),UVo=r(voe," class method or the "),dX=n(voe,"A",{href:!0});var Z1t=s(dX);JVo=r(Z1t,"from_config()"),Z1t.forEach(t),YVo=r(voe,` class
method.`),voe.forEach(t),KVo=i(rl),Sy=n(rl,"P",{});var HVe=s(Sy);ZVo=r(HVe,"This class cannot be instantiated directly using "),qpe=n(HVe,"CODE",{});var ebt=s(qpe);eXo=r(ebt,"__init__()"),ebt.forEach(t),oXo=r(HVe," (throws an error)."),HVe.forEach(t),rXo=i(rl),mt=n(rl,"DIV",{class:!0});var jA=s(mt);T(Ry.$$.fragment,jA),tXo=i(jA),jpe=n(jA,"P",{});var obt=s(jpe);aXo=r(obt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),obt.forEach(t),nXo=i(jA),td=n(jA,"P",{});var Foe=s(td);sXo=r(Foe,`Note:
Loading a model from its configuration file does `),Dpe=n(Foe,"STRONG",{});var rbt=s(Dpe);lXo=r(rbt,"not"),rbt.forEach(t),iXo=r(Foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cX=n(Foe,"A",{href:!0});var tbt=s(cX);dXo=r(tbt,"from_pretrained()"),tbt.forEach(t),cXo=r(Foe," to load the model weights."),Foe.forEach(t),fXo=i(jA),T(Jb.$$.fragment,jA),jA.forEach(t),mXo=i(rl),to=n(rl,"DIV",{class:!0});var fa=s(to);T(Py.$$.fragment,fa),gXo=i(fa),Gpe=n(fa,"P",{});var abt=s(Gpe);hXo=r(abt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),abt.forEach(t),pXo=i(fa),ja=n(fa,"P",{});var DA=s(ja);uXo=r(DA,"The model class to instantiate is selected based on the "),Ope=n(DA,"CODE",{});var nbt=s(Ope);_Xo=r(nbt,"model_type"),nbt.forEach(t),bXo=r(DA,` property of the config object (either
passed as an argument or loaded from `),Vpe=n(DA,"CODE",{});var sbt=s(Vpe);vXo=r(sbt,"pretrained_model_name_or_path"),sbt.forEach(t),FXo=r(DA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xpe=n(DA,"CODE",{});var lbt=s(Xpe);TXo=r(lbt,"pretrained_model_name_or_path"),lbt.forEach(t),MXo=r(DA,":"),DA.forEach(t),EXo=i(fa),Zr=n(fa,"UL",{});var tl=s(Zr);Yb=n(tl,"LI",{});var kSe=s(Yb);zpe=n(kSe,"STRONG",{});var ibt=s(zpe);CXo=r(ibt,"bert"),ibt.forEach(t),wXo=r(kSe," \u2014 "),fX=n(kSe,"A",{href:!0});var dbt=s(fX);AXo=r(dbt,"BertForNextSentencePrediction"),dbt.forEach(t),LXo=r(kSe," (BERT model)"),kSe.forEach(t),yXo=i(tl),Kb=n(tl,"LI",{});var SSe=s(Kb);Wpe=n(SSe,"STRONG",{});var cbt=s(Wpe);xXo=r(cbt,"fnet"),cbt.forEach(t),$Xo=r(SSe," \u2014 "),mX=n(SSe,"A",{href:!0});var fbt=s(mX);kXo=r(fbt,"FNetForNextSentencePrediction"),fbt.forEach(t),SXo=r(SSe," (FNet model)"),SSe.forEach(t),RXo=i(tl),Zb=n(tl,"LI",{});var RSe=s(Zb);Qpe=n(RSe,"STRONG",{});var mbt=s(Qpe);PXo=r(mbt,"megatron-bert"),mbt.forEach(t),BXo=r(RSe," \u2014 "),gX=n(RSe,"A",{href:!0});var gbt=s(gX);IXo=r(gbt,"MegatronBertForNextSentencePrediction"),gbt.forEach(t),NXo=r(RSe," (Megatron-BERT model)"),RSe.forEach(t),qXo=i(tl),ev=n(tl,"LI",{});var PSe=s(ev);Hpe=n(PSe,"STRONG",{});var hbt=s(Hpe);jXo=r(hbt,"mobilebert"),hbt.forEach(t),DXo=r(PSe," \u2014 "),hX=n(PSe,"A",{href:!0});var pbt=s(hX);GXo=r(pbt,"MobileBertForNextSentencePrediction"),pbt.forEach(t),OXo=r(PSe," (MobileBERT model)"),PSe.forEach(t),VXo=i(tl),ov=n(tl,"LI",{});var BSe=s(ov);Upe=n(BSe,"STRONG",{});var ubt=s(Upe);XXo=r(ubt,"qdqbert"),ubt.forEach(t),zXo=r(BSe," \u2014 "),pX=n(BSe,"A",{href:!0});var _bt=s(pX);WXo=r(_bt,"QDQBertForNextSentencePrediction"),_bt.forEach(t),QXo=r(BSe," (QDQBert model)"),BSe.forEach(t),tl.forEach(t),HXo=i(fa),rv=n(fa,"P",{});var ISe=s(rv);UXo=r(ISe,"The model is set in evaluation mode by default using "),Jpe=n(ISe,"CODE",{});var bbt=s(Jpe);JXo=r(bbt,"model.eval()"),bbt.forEach(t),YXo=r(ISe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=n(ISe,"CODE",{});var vbt=s(Ype);KXo=r(vbt,"model.train()"),vbt.forEach(t),ISe.forEach(t),ZXo=i(fa),T(tv.$$.fragment,fa),fa.forEach(t),rl.forEach(t),VGe=i(f),ad=n(f,"H2",{class:!0});var UVe=s(ad);av=n(UVe,"A",{id:!0,class:!0,href:!0});var Fbt=s(av);Kpe=n(Fbt,"SPAN",{});var Tbt=s(Kpe);T(By.$$.fragment,Tbt),Tbt.forEach(t),Fbt.forEach(t),ezo=i(UVe),Zpe=n(UVe,"SPAN",{});var Mbt=s(Zpe);ozo=r(Mbt,"AutoModelForTokenClassification"),Mbt.forEach(t),UVe.forEach(t),XGe=i(f),No=n(f,"DIV",{class:!0});var al=s(No);T(Iy.$$.fragment,al),rzo=i(al),nd=n(al,"P",{});var Toe=s(nd);tzo=r(Toe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),uX=n(Toe,"A",{href:!0});var Ebt=s(uX);azo=r(Ebt,"from_pretrained()"),Ebt.forEach(t),nzo=r(Toe," class method or the "),_X=n(Toe,"A",{href:!0});var Cbt=s(_X);szo=r(Cbt,"from_config()"),Cbt.forEach(t),lzo=r(Toe,` class
method.`),Toe.forEach(t),izo=i(al),Ny=n(al,"P",{});var JVe=s(Ny);dzo=r(JVe,"This class cannot be instantiated directly using "),eue=n(JVe,"CODE",{});var wbt=s(eue);czo=r(wbt,"__init__()"),wbt.forEach(t),fzo=r(JVe," (throws an error)."),JVe.forEach(t),mzo=i(al),gt=n(al,"DIV",{class:!0});var GA=s(gt);T(qy.$$.fragment,GA),gzo=i(GA),oue=n(GA,"P",{});var Abt=s(oue);hzo=r(Abt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Abt.forEach(t),pzo=i(GA),sd=n(GA,"P",{});var Moe=s(sd);uzo=r(Moe,`Note:
Loading a model from its configuration file does `),rue=n(Moe,"STRONG",{});var Lbt=s(rue);_zo=r(Lbt,"not"),Lbt.forEach(t),bzo=r(Moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),bX=n(Moe,"A",{href:!0});var ybt=s(bX);vzo=r(ybt,"from_pretrained()"),ybt.forEach(t),Fzo=r(Moe," to load the model weights."),Moe.forEach(t),Tzo=i(GA),T(nv.$$.fragment,GA),GA.forEach(t),Mzo=i(al),ao=n(al,"DIV",{class:!0});var ma=s(ao);T(jy.$$.fragment,ma),Ezo=i(ma),tue=n(ma,"P",{});var xbt=s(tue);Czo=r(xbt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xbt.forEach(t),wzo=i(ma),Da=n(ma,"P",{});var OA=s(Da);Azo=r(OA,"The model class to instantiate is selected based on the "),aue=n(OA,"CODE",{});var $bt=s(aue);Lzo=r($bt,"model_type"),$bt.forEach(t),yzo=r(OA,` property of the config object (either
passed as an argument or loaded from `),nue=n(OA,"CODE",{});var kbt=s(nue);xzo=r(kbt,"pretrained_model_name_or_path"),kbt.forEach(t),$zo=r(OA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sue=n(OA,"CODE",{});var Sbt=s(sue);kzo=r(Sbt,"pretrained_model_name_or_path"),Sbt.forEach(t),Szo=r(OA,":"),OA.forEach(t),Rzo=i(ma),H=n(ma,"UL",{});var J=s(H);sv=n(J,"LI",{});var NSe=s(sv);lue=n(NSe,"STRONG",{});var Rbt=s(lue);Pzo=r(Rbt,"albert"),Rbt.forEach(t),Bzo=r(NSe," \u2014 "),vX=n(NSe,"A",{href:!0});var Pbt=s(vX);Izo=r(Pbt,"AlbertForTokenClassification"),Pbt.forEach(t),Nzo=r(NSe," (ALBERT model)"),NSe.forEach(t),qzo=i(J),lv=n(J,"LI",{});var qSe=s(lv);iue=n(qSe,"STRONG",{});var Bbt=s(iue);jzo=r(Bbt,"bert"),Bbt.forEach(t),Dzo=r(qSe," \u2014 "),FX=n(qSe,"A",{href:!0});var Ibt=s(FX);Gzo=r(Ibt,"BertForTokenClassification"),Ibt.forEach(t),Ozo=r(qSe," (BERT model)"),qSe.forEach(t),Vzo=i(J),iv=n(J,"LI",{});var jSe=s(iv);due=n(jSe,"STRONG",{});var Nbt=s(due);Xzo=r(Nbt,"big_bird"),Nbt.forEach(t),zzo=r(jSe," \u2014 "),TX=n(jSe,"A",{href:!0});var qbt=s(TX);Wzo=r(qbt,"BigBirdForTokenClassification"),qbt.forEach(t),Qzo=r(jSe," (BigBird model)"),jSe.forEach(t),Hzo=i(J),dv=n(J,"LI",{});var DSe=s(dv);cue=n(DSe,"STRONG",{});var jbt=s(cue);Uzo=r(jbt,"bloom"),jbt.forEach(t),Jzo=r(DSe," \u2014 "),MX=n(DSe,"A",{href:!0});var Dbt=s(MX);Yzo=r(Dbt,"BloomForTokenClassification"),Dbt.forEach(t),Kzo=r(DSe," (BLOOM model)"),DSe.forEach(t),Zzo=i(J),cv=n(J,"LI",{});var GSe=s(cv);fue=n(GSe,"STRONG",{});var Gbt=s(fue);eWo=r(Gbt,"camembert"),Gbt.forEach(t),oWo=r(GSe," \u2014 "),EX=n(GSe,"A",{href:!0});var Obt=s(EX);rWo=r(Obt,"CamembertForTokenClassification"),Obt.forEach(t),tWo=r(GSe," (CamemBERT model)"),GSe.forEach(t),aWo=i(J),fv=n(J,"LI",{});var OSe=s(fv);mue=n(OSe,"STRONG",{});var Vbt=s(mue);nWo=r(Vbt,"canine"),Vbt.forEach(t),sWo=r(OSe," \u2014 "),CX=n(OSe,"A",{href:!0});var Xbt=s(CX);lWo=r(Xbt,"CanineForTokenClassification"),Xbt.forEach(t),iWo=r(OSe," (CANINE model)"),OSe.forEach(t),dWo=i(J),mv=n(J,"LI",{});var VSe=s(mv);gue=n(VSe,"STRONG",{});var zbt=s(gue);cWo=r(zbt,"convbert"),zbt.forEach(t),fWo=r(VSe," \u2014 "),wX=n(VSe,"A",{href:!0});var Wbt=s(wX);mWo=r(Wbt,"ConvBertForTokenClassification"),Wbt.forEach(t),gWo=r(VSe," (ConvBERT model)"),VSe.forEach(t),hWo=i(J),gv=n(J,"LI",{});var XSe=s(gv);hue=n(XSe,"STRONG",{});var Qbt=s(hue);pWo=r(Qbt,"data2vec-text"),Qbt.forEach(t),uWo=r(XSe," \u2014 "),AX=n(XSe,"A",{href:!0});var Hbt=s(AX);_Wo=r(Hbt,"Data2VecTextForTokenClassification"),Hbt.forEach(t),bWo=r(XSe," (Data2VecText model)"),XSe.forEach(t),vWo=i(J),hv=n(J,"LI",{});var zSe=s(hv);pue=n(zSe,"STRONG",{});var Ubt=s(pue);FWo=r(Ubt,"deberta"),Ubt.forEach(t),TWo=r(zSe," \u2014 "),LX=n(zSe,"A",{href:!0});var Jbt=s(LX);MWo=r(Jbt,"DebertaForTokenClassification"),Jbt.forEach(t),EWo=r(zSe," (DeBERTa model)"),zSe.forEach(t),CWo=i(J),pv=n(J,"LI",{});var WSe=s(pv);uue=n(WSe,"STRONG",{});var Ybt=s(uue);wWo=r(Ybt,"deberta-v2"),Ybt.forEach(t),AWo=r(WSe," \u2014 "),yX=n(WSe,"A",{href:!0});var Kbt=s(yX);LWo=r(Kbt,"DebertaV2ForTokenClassification"),Kbt.forEach(t),yWo=r(WSe," (DeBERTa-v2 model)"),WSe.forEach(t),xWo=i(J),uv=n(J,"LI",{});var QSe=s(uv);_ue=n(QSe,"STRONG",{});var Zbt=s(_ue);$Wo=r(Zbt,"distilbert"),Zbt.forEach(t),kWo=r(QSe," \u2014 "),xX=n(QSe,"A",{href:!0});var evt=s(xX);SWo=r(evt,"DistilBertForTokenClassification"),evt.forEach(t),RWo=r(QSe," (DistilBERT model)"),QSe.forEach(t),PWo=i(J),_v=n(J,"LI",{});var HSe=s(_v);bue=n(HSe,"STRONG",{});var ovt=s(bue);BWo=r(ovt,"electra"),ovt.forEach(t),IWo=r(HSe," \u2014 "),$X=n(HSe,"A",{href:!0});var rvt=s($X);NWo=r(rvt,"ElectraForTokenClassification"),rvt.forEach(t),qWo=r(HSe," (ELECTRA model)"),HSe.forEach(t),jWo=i(J),bv=n(J,"LI",{});var USe=s(bv);vue=n(USe,"STRONG",{});var tvt=s(vue);DWo=r(tvt,"flaubert"),tvt.forEach(t),GWo=r(USe," \u2014 "),kX=n(USe,"A",{href:!0});var avt=s(kX);OWo=r(avt,"FlaubertForTokenClassification"),avt.forEach(t),VWo=r(USe," (FlauBERT model)"),USe.forEach(t),XWo=i(J),vv=n(J,"LI",{});var JSe=s(vv);Fue=n(JSe,"STRONG",{});var nvt=s(Fue);zWo=r(nvt,"fnet"),nvt.forEach(t),WWo=r(JSe," \u2014 "),SX=n(JSe,"A",{href:!0});var svt=s(SX);QWo=r(svt,"FNetForTokenClassification"),svt.forEach(t),HWo=r(JSe," (FNet model)"),JSe.forEach(t),UWo=i(J),Fv=n(J,"LI",{});var YSe=s(Fv);Tue=n(YSe,"STRONG",{});var lvt=s(Tue);JWo=r(lvt,"funnel"),lvt.forEach(t),YWo=r(YSe," \u2014 "),RX=n(YSe,"A",{href:!0});var ivt=s(RX);KWo=r(ivt,"FunnelForTokenClassification"),ivt.forEach(t),ZWo=r(YSe," (Funnel Transformer model)"),YSe.forEach(t),eQo=i(J),Tv=n(J,"LI",{});var KSe=s(Tv);Mue=n(KSe,"STRONG",{});var dvt=s(Mue);oQo=r(dvt,"gpt2"),dvt.forEach(t),rQo=r(KSe," \u2014 "),PX=n(KSe,"A",{href:!0});var cvt=s(PX);tQo=r(cvt,"GPT2ForTokenClassification"),cvt.forEach(t),aQo=r(KSe," (OpenAI GPT-2 model)"),KSe.forEach(t),nQo=i(J),Mv=n(J,"LI",{});var ZSe=s(Mv);Eue=n(ZSe,"STRONG",{});var fvt=s(Eue);sQo=r(fvt,"ibert"),fvt.forEach(t),lQo=r(ZSe," \u2014 "),BX=n(ZSe,"A",{href:!0});var mvt=s(BX);iQo=r(mvt,"IBertForTokenClassification"),mvt.forEach(t),dQo=r(ZSe," (I-BERT model)"),ZSe.forEach(t),cQo=i(J),Ev=n(J,"LI",{});var eRe=s(Ev);Cue=n(eRe,"STRONG",{});var gvt=s(Cue);fQo=r(gvt,"layoutlm"),gvt.forEach(t),mQo=r(eRe," \u2014 "),IX=n(eRe,"A",{href:!0});var hvt=s(IX);gQo=r(hvt,"LayoutLMForTokenClassification"),hvt.forEach(t),hQo=r(eRe," (LayoutLM model)"),eRe.forEach(t),pQo=i(J),Cv=n(J,"LI",{});var oRe=s(Cv);wue=n(oRe,"STRONG",{});var pvt=s(wue);uQo=r(pvt,"layoutlmv2"),pvt.forEach(t),_Qo=r(oRe," \u2014 "),NX=n(oRe,"A",{href:!0});var uvt=s(NX);bQo=r(uvt,"LayoutLMv2ForTokenClassification"),uvt.forEach(t),vQo=r(oRe," (LayoutLMv2 model)"),oRe.forEach(t),FQo=i(J),wv=n(J,"LI",{});var rRe=s(wv);Aue=n(rRe,"STRONG",{});var _vt=s(Aue);TQo=r(_vt,"layoutlmv3"),_vt.forEach(t),MQo=r(rRe," \u2014 "),qX=n(rRe,"A",{href:!0});var bvt=s(qX);EQo=r(bvt,"LayoutLMv3ForTokenClassification"),bvt.forEach(t),CQo=r(rRe," (LayoutLMv3 model)"),rRe.forEach(t),wQo=i(J),Av=n(J,"LI",{});var tRe=s(Av);Lue=n(tRe,"STRONG",{});var vvt=s(Lue);AQo=r(vvt,"longformer"),vvt.forEach(t),LQo=r(tRe," \u2014 "),jX=n(tRe,"A",{href:!0});var Fvt=s(jX);yQo=r(Fvt,"LongformerForTokenClassification"),Fvt.forEach(t),xQo=r(tRe," (Longformer model)"),tRe.forEach(t),$Qo=i(J),Lv=n(J,"LI",{});var aRe=s(Lv);yue=n(aRe,"STRONG",{});var Tvt=s(yue);kQo=r(Tvt,"megatron-bert"),Tvt.forEach(t),SQo=r(aRe," \u2014 "),DX=n(aRe,"A",{href:!0});var Mvt=s(DX);RQo=r(Mvt,"MegatronBertForTokenClassification"),Mvt.forEach(t),PQo=r(aRe," (Megatron-BERT model)"),aRe.forEach(t),BQo=i(J),yv=n(J,"LI",{});var nRe=s(yv);xue=n(nRe,"STRONG",{});var Evt=s(xue);IQo=r(Evt,"mobilebert"),Evt.forEach(t),NQo=r(nRe," \u2014 "),GX=n(nRe,"A",{href:!0});var Cvt=s(GX);qQo=r(Cvt,"MobileBertForTokenClassification"),Cvt.forEach(t),jQo=r(nRe," (MobileBERT model)"),nRe.forEach(t),DQo=i(J),xv=n(J,"LI",{});var sRe=s(xv);$ue=n(sRe,"STRONG",{});var wvt=s($ue);GQo=r(wvt,"mpnet"),wvt.forEach(t),OQo=r(sRe," \u2014 "),OX=n(sRe,"A",{href:!0});var Avt=s(OX);VQo=r(Avt,"MPNetForTokenClassification"),Avt.forEach(t),XQo=r(sRe," (MPNet model)"),sRe.forEach(t),zQo=i(J),$v=n(J,"LI",{});var lRe=s($v);kue=n(lRe,"STRONG",{});var Lvt=s(kue);WQo=r(Lvt,"nystromformer"),Lvt.forEach(t),QQo=r(lRe," \u2014 "),VX=n(lRe,"A",{href:!0});var yvt=s(VX);HQo=r(yvt,"NystromformerForTokenClassification"),yvt.forEach(t),UQo=r(lRe," (Nystr\xF6mformer model)"),lRe.forEach(t),JQo=i(J),kv=n(J,"LI",{});var iRe=s(kv);Sue=n(iRe,"STRONG",{});var xvt=s(Sue);YQo=r(xvt,"qdqbert"),xvt.forEach(t),KQo=r(iRe," \u2014 "),XX=n(iRe,"A",{href:!0});var $vt=s(XX);ZQo=r($vt,"QDQBertForTokenClassification"),$vt.forEach(t),eHo=r(iRe," (QDQBert model)"),iRe.forEach(t),oHo=i(J),Sv=n(J,"LI",{});var dRe=s(Sv);Rue=n(dRe,"STRONG",{});var kvt=s(Rue);rHo=r(kvt,"rembert"),kvt.forEach(t),tHo=r(dRe," \u2014 "),zX=n(dRe,"A",{href:!0});var Svt=s(zX);aHo=r(Svt,"RemBertForTokenClassification"),Svt.forEach(t),nHo=r(dRe," (RemBERT model)"),dRe.forEach(t),sHo=i(J),Rv=n(J,"LI",{});var cRe=s(Rv);Pue=n(cRe,"STRONG",{});var Rvt=s(Pue);lHo=r(Rvt,"roberta"),Rvt.forEach(t),iHo=r(cRe," \u2014 "),WX=n(cRe,"A",{href:!0});var Pvt=s(WX);dHo=r(Pvt,"RobertaForTokenClassification"),Pvt.forEach(t),cHo=r(cRe," (RoBERTa model)"),cRe.forEach(t),fHo=i(J),Pv=n(J,"LI",{});var fRe=s(Pv);Bue=n(fRe,"STRONG",{});var Bvt=s(Bue);mHo=r(Bvt,"roformer"),Bvt.forEach(t),gHo=r(fRe," \u2014 "),QX=n(fRe,"A",{href:!0});var Ivt=s(QX);hHo=r(Ivt,"RoFormerForTokenClassification"),Ivt.forEach(t),pHo=r(fRe," (RoFormer model)"),fRe.forEach(t),uHo=i(J),Bv=n(J,"LI",{});var mRe=s(Bv);Iue=n(mRe,"STRONG",{});var Nvt=s(Iue);_Ho=r(Nvt,"squeezebert"),Nvt.forEach(t),bHo=r(mRe," \u2014 "),HX=n(mRe,"A",{href:!0});var qvt=s(HX);vHo=r(qvt,"SqueezeBertForTokenClassification"),qvt.forEach(t),FHo=r(mRe," (SqueezeBERT model)"),mRe.forEach(t),THo=i(J),Iv=n(J,"LI",{});var gRe=s(Iv);Nue=n(gRe,"STRONG",{});var jvt=s(Nue);MHo=r(jvt,"xlm"),jvt.forEach(t),EHo=r(gRe," \u2014 "),UX=n(gRe,"A",{href:!0});var Dvt=s(UX);CHo=r(Dvt,"XLMForTokenClassification"),Dvt.forEach(t),wHo=r(gRe," (XLM model)"),gRe.forEach(t),AHo=i(J),Nv=n(J,"LI",{});var hRe=s(Nv);que=n(hRe,"STRONG",{});var Gvt=s(que);LHo=r(Gvt,"xlm-roberta"),Gvt.forEach(t),yHo=r(hRe," \u2014 "),JX=n(hRe,"A",{href:!0});var Ovt=s(JX);xHo=r(Ovt,"XLMRobertaForTokenClassification"),Ovt.forEach(t),$Ho=r(hRe," (XLM-RoBERTa model)"),hRe.forEach(t),kHo=i(J),qv=n(J,"LI",{});var pRe=s(qv);jue=n(pRe,"STRONG",{});var Vvt=s(jue);SHo=r(Vvt,"xlm-roberta-xl"),Vvt.forEach(t),RHo=r(pRe," \u2014 "),YX=n(pRe,"A",{href:!0});var Xvt=s(YX);PHo=r(Xvt,"XLMRobertaXLForTokenClassification"),Xvt.forEach(t),BHo=r(pRe," (XLM-RoBERTa-XL model)"),pRe.forEach(t),IHo=i(J),jv=n(J,"LI",{});var uRe=s(jv);Due=n(uRe,"STRONG",{});var zvt=s(Due);NHo=r(zvt,"xlnet"),zvt.forEach(t),qHo=r(uRe," \u2014 "),KX=n(uRe,"A",{href:!0});var Wvt=s(KX);jHo=r(Wvt,"XLNetForTokenClassification"),Wvt.forEach(t),DHo=r(uRe," (XLNet model)"),uRe.forEach(t),GHo=i(J),Dv=n(J,"LI",{});var _Re=s(Dv);Gue=n(_Re,"STRONG",{});var Qvt=s(Gue);OHo=r(Qvt,"yoso"),Qvt.forEach(t),VHo=r(_Re," \u2014 "),ZX=n(_Re,"A",{href:!0});var Hvt=s(ZX);XHo=r(Hvt,"YosoForTokenClassification"),Hvt.forEach(t),zHo=r(_Re," (YOSO model)"),_Re.forEach(t),J.forEach(t),WHo=i(ma),Gv=n(ma,"P",{});var bRe=s(Gv);QHo=r(bRe,"The model is set in evaluation mode by default using "),Oue=n(bRe,"CODE",{});var Uvt=s(Oue);HHo=r(Uvt,"model.eval()"),Uvt.forEach(t),UHo=r(bRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vue=n(bRe,"CODE",{});var Jvt=s(Vue);JHo=r(Jvt,"model.train()"),Jvt.forEach(t),bRe.forEach(t),YHo=i(ma),T(Ov.$$.fragment,ma),ma.forEach(t),al.forEach(t),zGe=i(f),ld=n(f,"H2",{class:!0});var YVe=s(ld);Vv=n(YVe,"A",{id:!0,class:!0,href:!0});var Yvt=s(Vv);Xue=n(Yvt,"SPAN",{});var Kvt=s(Xue);T(Dy.$$.fragment,Kvt),Kvt.forEach(t),Yvt.forEach(t),KHo=i(YVe),zue=n(YVe,"SPAN",{});var Zvt=s(zue);ZHo=r(Zvt,"AutoModelForQuestionAnswering"),Zvt.forEach(t),YVe.forEach(t),WGe=i(f),qo=n(f,"DIV",{class:!0});var nl=s(qo);T(Gy.$$.fragment,nl),eUo=i(nl),id=n(nl,"P",{});var Eoe=s(id);oUo=r(Eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ez=n(Eoe,"A",{href:!0});var eFt=s(ez);rUo=r(eFt,"from_pretrained()"),eFt.forEach(t),tUo=r(Eoe," class method or the "),oz=n(Eoe,"A",{href:!0});var oFt=s(oz);aUo=r(oFt,"from_config()"),oFt.forEach(t),nUo=r(Eoe,` class
method.`),Eoe.forEach(t),sUo=i(nl),Oy=n(nl,"P",{});var KVe=s(Oy);lUo=r(KVe,"This class cannot be instantiated directly using "),Wue=n(KVe,"CODE",{});var rFt=s(Wue);iUo=r(rFt,"__init__()"),rFt.forEach(t),dUo=r(KVe," (throws an error)."),KVe.forEach(t),cUo=i(nl),ht=n(nl,"DIV",{class:!0});var VA=s(ht);T(Vy.$$.fragment,VA),fUo=i(VA),Que=n(VA,"P",{});var tFt=s(Que);mUo=r(tFt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),tFt.forEach(t),gUo=i(VA),dd=n(VA,"P",{});var Coe=s(dd);hUo=r(Coe,`Note:
Loading a model from its configuration file does `),Hue=n(Coe,"STRONG",{});var aFt=s(Hue);pUo=r(aFt,"not"),aFt.forEach(t),uUo=r(Coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),rz=n(Coe,"A",{href:!0});var nFt=s(rz);_Uo=r(nFt,"from_pretrained()"),nFt.forEach(t),bUo=r(Coe," to load the model weights."),Coe.forEach(t),vUo=i(VA),T(Xv.$$.fragment,VA),VA.forEach(t),FUo=i(nl),no=n(nl,"DIV",{class:!0});var ga=s(no);T(Xy.$$.fragment,ga),TUo=i(ga),Uue=n(ga,"P",{});var sFt=s(Uue);MUo=r(sFt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),sFt.forEach(t),EUo=i(ga),Ga=n(ga,"P",{});var XA=s(Ga);CUo=r(XA,"The model class to instantiate is selected based on the "),Jue=n(XA,"CODE",{});var lFt=s(Jue);wUo=r(lFt,"model_type"),lFt.forEach(t),AUo=r(XA,` property of the config object (either
passed as an argument or loaded from `),Yue=n(XA,"CODE",{});var iFt=s(Yue);LUo=r(iFt,"pretrained_model_name_or_path"),iFt.forEach(t),yUo=r(XA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kue=n(XA,"CODE",{});var dFt=s(Kue);xUo=r(dFt,"pretrained_model_name_or_path"),dFt.forEach(t),$Uo=r(XA,":"),XA.forEach(t),kUo=i(ga),V=n(ga,"UL",{});var X=s(V);zv=n(X,"LI",{});var vRe=s(zv);Zue=n(vRe,"STRONG",{});var cFt=s(Zue);SUo=r(cFt,"albert"),cFt.forEach(t),RUo=r(vRe," \u2014 "),tz=n(vRe,"A",{href:!0});var fFt=s(tz);PUo=r(fFt,"AlbertForQuestionAnswering"),fFt.forEach(t),BUo=r(vRe," (ALBERT model)"),vRe.forEach(t),IUo=i(X),Wv=n(X,"LI",{});var FRe=s(Wv);e_e=n(FRe,"STRONG",{});var mFt=s(e_e);NUo=r(mFt,"bart"),mFt.forEach(t),qUo=r(FRe," \u2014 "),az=n(FRe,"A",{href:!0});var gFt=s(az);jUo=r(gFt,"BartForQuestionAnswering"),gFt.forEach(t),DUo=r(FRe," (BART model)"),FRe.forEach(t),GUo=i(X),Qv=n(X,"LI",{});var TRe=s(Qv);o_e=n(TRe,"STRONG",{});var hFt=s(o_e);OUo=r(hFt,"bert"),hFt.forEach(t),VUo=r(TRe," \u2014 "),nz=n(TRe,"A",{href:!0});var pFt=s(nz);XUo=r(pFt,"BertForQuestionAnswering"),pFt.forEach(t),zUo=r(TRe," (BERT model)"),TRe.forEach(t),WUo=i(X),Hv=n(X,"LI",{});var MRe=s(Hv);r_e=n(MRe,"STRONG",{});var uFt=s(r_e);QUo=r(uFt,"big_bird"),uFt.forEach(t),HUo=r(MRe," \u2014 "),sz=n(MRe,"A",{href:!0});var _Ft=s(sz);UUo=r(_Ft,"BigBirdForQuestionAnswering"),_Ft.forEach(t),JUo=r(MRe," (BigBird model)"),MRe.forEach(t),YUo=i(X),Uv=n(X,"LI",{});var ERe=s(Uv);t_e=n(ERe,"STRONG",{});var bFt=s(t_e);KUo=r(bFt,"bigbird_pegasus"),bFt.forEach(t),ZUo=r(ERe," \u2014 "),lz=n(ERe,"A",{href:!0});var vFt=s(lz);eJo=r(vFt,"BigBirdPegasusForQuestionAnswering"),vFt.forEach(t),oJo=r(ERe," (BigBird-Pegasus model)"),ERe.forEach(t),rJo=i(X),Jv=n(X,"LI",{});var CRe=s(Jv);a_e=n(CRe,"STRONG",{});var FFt=s(a_e);tJo=r(FFt,"camembert"),FFt.forEach(t),aJo=r(CRe," \u2014 "),iz=n(CRe,"A",{href:!0});var TFt=s(iz);nJo=r(TFt,"CamembertForQuestionAnswering"),TFt.forEach(t),sJo=r(CRe," (CamemBERT model)"),CRe.forEach(t),lJo=i(X),Yv=n(X,"LI",{});var wRe=s(Yv);n_e=n(wRe,"STRONG",{});var MFt=s(n_e);iJo=r(MFt,"canine"),MFt.forEach(t),dJo=r(wRe," \u2014 "),dz=n(wRe,"A",{href:!0});var EFt=s(dz);cJo=r(EFt,"CanineForQuestionAnswering"),EFt.forEach(t),fJo=r(wRe," (CANINE model)"),wRe.forEach(t),mJo=i(X),Kv=n(X,"LI",{});var ARe=s(Kv);s_e=n(ARe,"STRONG",{});var CFt=s(s_e);gJo=r(CFt,"convbert"),CFt.forEach(t),hJo=r(ARe," \u2014 "),cz=n(ARe,"A",{href:!0});var wFt=s(cz);pJo=r(wFt,"ConvBertForQuestionAnswering"),wFt.forEach(t),uJo=r(ARe," (ConvBERT model)"),ARe.forEach(t),_Jo=i(X),Zv=n(X,"LI",{});var LRe=s(Zv);l_e=n(LRe,"STRONG",{});var AFt=s(l_e);bJo=r(AFt,"data2vec-text"),AFt.forEach(t),vJo=r(LRe," \u2014 "),fz=n(LRe,"A",{href:!0});var LFt=s(fz);FJo=r(LFt,"Data2VecTextForQuestionAnswering"),LFt.forEach(t),TJo=r(LRe," (Data2VecText model)"),LRe.forEach(t),MJo=i(X),eF=n(X,"LI",{});var yRe=s(eF);i_e=n(yRe,"STRONG",{});var yFt=s(i_e);EJo=r(yFt,"deberta"),yFt.forEach(t),CJo=r(yRe," \u2014 "),mz=n(yRe,"A",{href:!0});var xFt=s(mz);wJo=r(xFt,"DebertaForQuestionAnswering"),xFt.forEach(t),AJo=r(yRe," (DeBERTa model)"),yRe.forEach(t),LJo=i(X),oF=n(X,"LI",{});var xRe=s(oF);d_e=n(xRe,"STRONG",{});var $Ft=s(d_e);yJo=r($Ft,"deberta-v2"),$Ft.forEach(t),xJo=r(xRe," \u2014 "),gz=n(xRe,"A",{href:!0});var kFt=s(gz);$Jo=r(kFt,"DebertaV2ForQuestionAnswering"),kFt.forEach(t),kJo=r(xRe," (DeBERTa-v2 model)"),xRe.forEach(t),SJo=i(X),rF=n(X,"LI",{});var $Re=s(rF);c_e=n($Re,"STRONG",{});var SFt=s(c_e);RJo=r(SFt,"distilbert"),SFt.forEach(t),PJo=r($Re," \u2014 "),hz=n($Re,"A",{href:!0});var RFt=s(hz);BJo=r(RFt,"DistilBertForQuestionAnswering"),RFt.forEach(t),IJo=r($Re," (DistilBERT model)"),$Re.forEach(t),NJo=i(X),tF=n(X,"LI",{});var kRe=s(tF);f_e=n(kRe,"STRONG",{});var PFt=s(f_e);qJo=r(PFt,"electra"),PFt.forEach(t),jJo=r(kRe," \u2014 "),pz=n(kRe,"A",{href:!0});var BFt=s(pz);DJo=r(BFt,"ElectraForQuestionAnswering"),BFt.forEach(t),GJo=r(kRe," (ELECTRA model)"),kRe.forEach(t),OJo=i(X),aF=n(X,"LI",{});var SRe=s(aF);m_e=n(SRe,"STRONG",{});var IFt=s(m_e);VJo=r(IFt,"flaubert"),IFt.forEach(t),XJo=r(SRe," \u2014 "),uz=n(SRe,"A",{href:!0});var NFt=s(uz);zJo=r(NFt,"FlaubertForQuestionAnsweringSimple"),NFt.forEach(t),WJo=r(SRe," (FlauBERT model)"),SRe.forEach(t),QJo=i(X),nF=n(X,"LI",{});var RRe=s(nF);g_e=n(RRe,"STRONG",{});var qFt=s(g_e);HJo=r(qFt,"fnet"),qFt.forEach(t),UJo=r(RRe," \u2014 "),_z=n(RRe,"A",{href:!0});var jFt=s(_z);JJo=r(jFt,"FNetForQuestionAnswering"),jFt.forEach(t),YJo=r(RRe," (FNet model)"),RRe.forEach(t),KJo=i(X),sF=n(X,"LI",{});var PRe=s(sF);h_e=n(PRe,"STRONG",{});var DFt=s(h_e);ZJo=r(DFt,"funnel"),DFt.forEach(t),eYo=r(PRe," \u2014 "),bz=n(PRe,"A",{href:!0});var GFt=s(bz);oYo=r(GFt,"FunnelForQuestionAnswering"),GFt.forEach(t),rYo=r(PRe," (Funnel Transformer model)"),PRe.forEach(t),tYo=i(X),lF=n(X,"LI",{});var BRe=s(lF);p_e=n(BRe,"STRONG",{});var OFt=s(p_e);aYo=r(OFt,"gptj"),OFt.forEach(t),nYo=r(BRe," \u2014 "),vz=n(BRe,"A",{href:!0});var VFt=s(vz);sYo=r(VFt,"GPTJForQuestionAnswering"),VFt.forEach(t),lYo=r(BRe," (GPT-J model)"),BRe.forEach(t),iYo=i(X),iF=n(X,"LI",{});var IRe=s(iF);u_e=n(IRe,"STRONG",{});var XFt=s(u_e);dYo=r(XFt,"ibert"),XFt.forEach(t),cYo=r(IRe," \u2014 "),Fz=n(IRe,"A",{href:!0});var zFt=s(Fz);fYo=r(zFt,"IBertForQuestionAnswering"),zFt.forEach(t),mYo=r(IRe," (I-BERT model)"),IRe.forEach(t),gYo=i(X),dF=n(X,"LI",{});var NRe=s(dF);__e=n(NRe,"STRONG",{});var WFt=s(__e);hYo=r(WFt,"layoutlmv2"),WFt.forEach(t),pYo=r(NRe," \u2014 "),Tz=n(NRe,"A",{href:!0});var QFt=s(Tz);uYo=r(QFt,"LayoutLMv2ForQuestionAnswering"),QFt.forEach(t),_Yo=r(NRe," (LayoutLMv2 model)"),NRe.forEach(t),bYo=i(X),cF=n(X,"LI",{});var qRe=s(cF);b_e=n(qRe,"STRONG",{});var HFt=s(b_e);vYo=r(HFt,"layoutlmv3"),HFt.forEach(t),FYo=r(qRe," \u2014 "),Mz=n(qRe,"A",{href:!0});var UFt=s(Mz);TYo=r(UFt,"LayoutLMv3ForQuestionAnswering"),UFt.forEach(t),MYo=r(qRe," (LayoutLMv3 model)"),qRe.forEach(t),EYo=i(X),fF=n(X,"LI",{});var jRe=s(fF);v_e=n(jRe,"STRONG",{});var JFt=s(v_e);CYo=r(JFt,"led"),JFt.forEach(t),wYo=r(jRe," \u2014 "),Ez=n(jRe,"A",{href:!0});var YFt=s(Ez);AYo=r(YFt,"LEDForQuestionAnswering"),YFt.forEach(t),LYo=r(jRe," (LED model)"),jRe.forEach(t),yYo=i(X),mF=n(X,"LI",{});var DRe=s(mF);F_e=n(DRe,"STRONG",{});var KFt=s(F_e);xYo=r(KFt,"longformer"),KFt.forEach(t),$Yo=r(DRe," \u2014 "),Cz=n(DRe,"A",{href:!0});var ZFt=s(Cz);kYo=r(ZFt,"LongformerForQuestionAnswering"),ZFt.forEach(t),SYo=r(DRe," (Longformer model)"),DRe.forEach(t),RYo=i(X),gF=n(X,"LI",{});var GRe=s(gF);T_e=n(GRe,"STRONG",{});var eTt=s(T_e);PYo=r(eTt,"lxmert"),eTt.forEach(t),BYo=r(GRe," \u2014 "),wz=n(GRe,"A",{href:!0});var oTt=s(wz);IYo=r(oTt,"LxmertForQuestionAnswering"),oTt.forEach(t),NYo=r(GRe," (LXMERT model)"),GRe.forEach(t),qYo=i(X),hF=n(X,"LI",{});var ORe=s(hF);M_e=n(ORe,"STRONG",{});var rTt=s(M_e);jYo=r(rTt,"mbart"),rTt.forEach(t),DYo=r(ORe," \u2014 "),Az=n(ORe,"A",{href:!0});var tTt=s(Az);GYo=r(tTt,"MBartForQuestionAnswering"),tTt.forEach(t),OYo=r(ORe," (mBART model)"),ORe.forEach(t),VYo=i(X),pF=n(X,"LI",{});var VRe=s(pF);E_e=n(VRe,"STRONG",{});var aTt=s(E_e);XYo=r(aTt,"megatron-bert"),aTt.forEach(t),zYo=r(VRe," \u2014 "),Lz=n(VRe,"A",{href:!0});var nTt=s(Lz);WYo=r(nTt,"MegatronBertForQuestionAnswering"),nTt.forEach(t),QYo=r(VRe," (Megatron-BERT model)"),VRe.forEach(t),HYo=i(X),uF=n(X,"LI",{});var XRe=s(uF);C_e=n(XRe,"STRONG",{});var sTt=s(C_e);UYo=r(sTt,"mobilebert"),sTt.forEach(t),JYo=r(XRe," \u2014 "),yz=n(XRe,"A",{href:!0});var lTt=s(yz);YYo=r(lTt,"MobileBertForQuestionAnswering"),lTt.forEach(t),KYo=r(XRe," (MobileBERT model)"),XRe.forEach(t),ZYo=i(X),_F=n(X,"LI",{});var zRe=s(_F);w_e=n(zRe,"STRONG",{});var iTt=s(w_e);eKo=r(iTt,"mpnet"),iTt.forEach(t),oKo=r(zRe," \u2014 "),xz=n(zRe,"A",{href:!0});var dTt=s(xz);rKo=r(dTt,"MPNetForQuestionAnswering"),dTt.forEach(t),tKo=r(zRe," (MPNet model)"),zRe.forEach(t),aKo=i(X),bF=n(X,"LI",{});var WRe=s(bF);A_e=n(WRe,"STRONG",{});var cTt=s(A_e);nKo=r(cTt,"nystromformer"),cTt.forEach(t),sKo=r(WRe," \u2014 "),$z=n(WRe,"A",{href:!0});var fTt=s($z);lKo=r(fTt,"NystromformerForQuestionAnswering"),fTt.forEach(t),iKo=r(WRe," (Nystr\xF6mformer model)"),WRe.forEach(t),dKo=i(X),vF=n(X,"LI",{});var QRe=s(vF);L_e=n(QRe,"STRONG",{});var mTt=s(L_e);cKo=r(mTt,"qdqbert"),mTt.forEach(t),fKo=r(QRe," \u2014 "),kz=n(QRe,"A",{href:!0});var gTt=s(kz);mKo=r(gTt,"QDQBertForQuestionAnswering"),gTt.forEach(t),gKo=r(QRe," (QDQBert model)"),QRe.forEach(t),hKo=i(X),FF=n(X,"LI",{});var HRe=s(FF);y_e=n(HRe,"STRONG",{});var hTt=s(y_e);pKo=r(hTt,"reformer"),hTt.forEach(t),uKo=r(HRe," \u2014 "),Sz=n(HRe,"A",{href:!0});var pTt=s(Sz);_Ko=r(pTt,"ReformerForQuestionAnswering"),pTt.forEach(t),bKo=r(HRe," (Reformer model)"),HRe.forEach(t),vKo=i(X),TF=n(X,"LI",{});var URe=s(TF);x_e=n(URe,"STRONG",{});var uTt=s(x_e);FKo=r(uTt,"rembert"),uTt.forEach(t),TKo=r(URe," \u2014 "),Rz=n(URe,"A",{href:!0});var _Tt=s(Rz);MKo=r(_Tt,"RemBertForQuestionAnswering"),_Tt.forEach(t),EKo=r(URe," (RemBERT model)"),URe.forEach(t),CKo=i(X),MF=n(X,"LI",{});var JRe=s(MF);$_e=n(JRe,"STRONG",{});var bTt=s($_e);wKo=r(bTt,"roberta"),bTt.forEach(t),AKo=r(JRe," \u2014 "),Pz=n(JRe,"A",{href:!0});var vTt=s(Pz);LKo=r(vTt,"RobertaForQuestionAnswering"),vTt.forEach(t),yKo=r(JRe," (RoBERTa model)"),JRe.forEach(t),xKo=i(X),EF=n(X,"LI",{});var YRe=s(EF);k_e=n(YRe,"STRONG",{});var FTt=s(k_e);$Ko=r(FTt,"roformer"),FTt.forEach(t),kKo=r(YRe," \u2014 "),Bz=n(YRe,"A",{href:!0});var TTt=s(Bz);SKo=r(TTt,"RoFormerForQuestionAnswering"),TTt.forEach(t),RKo=r(YRe," (RoFormer model)"),YRe.forEach(t),PKo=i(X),CF=n(X,"LI",{});var KRe=s(CF);S_e=n(KRe,"STRONG",{});var MTt=s(S_e);BKo=r(MTt,"splinter"),MTt.forEach(t),IKo=r(KRe," \u2014 "),Iz=n(KRe,"A",{href:!0});var ETt=s(Iz);NKo=r(ETt,"SplinterForQuestionAnswering"),ETt.forEach(t),qKo=r(KRe," (Splinter model)"),KRe.forEach(t),jKo=i(X),wF=n(X,"LI",{});var ZRe=s(wF);R_e=n(ZRe,"STRONG",{});var CTt=s(R_e);DKo=r(CTt,"squeezebert"),CTt.forEach(t),GKo=r(ZRe," \u2014 "),Nz=n(ZRe,"A",{href:!0});var wTt=s(Nz);OKo=r(wTt,"SqueezeBertForQuestionAnswering"),wTt.forEach(t),VKo=r(ZRe," (SqueezeBERT model)"),ZRe.forEach(t),XKo=i(X),AF=n(X,"LI",{});var ePe=s(AF);P_e=n(ePe,"STRONG",{});var ATt=s(P_e);zKo=r(ATt,"xlm"),ATt.forEach(t),WKo=r(ePe," \u2014 "),qz=n(ePe,"A",{href:!0});var LTt=s(qz);QKo=r(LTt,"XLMForQuestionAnsweringSimple"),LTt.forEach(t),HKo=r(ePe," (XLM model)"),ePe.forEach(t),UKo=i(X),LF=n(X,"LI",{});var oPe=s(LF);B_e=n(oPe,"STRONG",{});var yTt=s(B_e);JKo=r(yTt,"xlm-roberta"),yTt.forEach(t),YKo=r(oPe," \u2014 "),jz=n(oPe,"A",{href:!0});var xTt=s(jz);KKo=r(xTt,"XLMRobertaForQuestionAnswering"),xTt.forEach(t),ZKo=r(oPe," (XLM-RoBERTa model)"),oPe.forEach(t),eZo=i(X),yF=n(X,"LI",{});var rPe=s(yF);I_e=n(rPe,"STRONG",{});var $Tt=s(I_e);oZo=r($Tt,"xlm-roberta-xl"),$Tt.forEach(t),rZo=r(rPe," \u2014 "),Dz=n(rPe,"A",{href:!0});var kTt=s(Dz);tZo=r(kTt,"XLMRobertaXLForQuestionAnswering"),kTt.forEach(t),aZo=r(rPe," (XLM-RoBERTa-XL model)"),rPe.forEach(t),nZo=i(X),xF=n(X,"LI",{});var tPe=s(xF);N_e=n(tPe,"STRONG",{});var STt=s(N_e);sZo=r(STt,"xlnet"),STt.forEach(t),lZo=r(tPe," \u2014 "),Gz=n(tPe,"A",{href:!0});var RTt=s(Gz);iZo=r(RTt,"XLNetForQuestionAnsweringSimple"),RTt.forEach(t),dZo=r(tPe," (XLNet model)"),tPe.forEach(t),cZo=i(X),$F=n(X,"LI",{});var aPe=s($F);q_e=n(aPe,"STRONG",{});var PTt=s(q_e);fZo=r(PTt,"yoso"),PTt.forEach(t),mZo=r(aPe," \u2014 "),Oz=n(aPe,"A",{href:!0});var BTt=s(Oz);gZo=r(BTt,"YosoForQuestionAnswering"),BTt.forEach(t),hZo=r(aPe," (YOSO model)"),aPe.forEach(t),X.forEach(t),pZo=i(ga),kF=n(ga,"P",{});var nPe=s(kF);uZo=r(nPe,"The model is set in evaluation mode by default using "),j_e=n(nPe,"CODE",{});var ITt=s(j_e);_Zo=r(ITt,"model.eval()"),ITt.forEach(t),bZo=r(nPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D_e=n(nPe,"CODE",{});var NTt=s(D_e);vZo=r(NTt,"model.train()"),NTt.forEach(t),nPe.forEach(t),FZo=i(ga),T(SF.$$.fragment,ga),ga.forEach(t),nl.forEach(t),QGe=i(f),cd=n(f,"H2",{class:!0});var ZVe=s(cd);RF=n(ZVe,"A",{id:!0,class:!0,href:!0});var qTt=s(RF);G_e=n(qTt,"SPAN",{});var jTt=s(G_e);T(zy.$$.fragment,jTt),jTt.forEach(t),qTt.forEach(t),TZo=i(ZVe),O_e=n(ZVe,"SPAN",{});var DTt=s(O_e);MZo=r(DTt,"AutoModelForTableQuestionAnswering"),DTt.forEach(t),ZVe.forEach(t),HGe=i(f),jo=n(f,"DIV",{class:!0});var sl=s(jo);T(Wy.$$.fragment,sl),EZo=i(sl),fd=n(sl,"P",{});var woe=s(fd);CZo=r(woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Vz=n(woe,"A",{href:!0});var GTt=s(Vz);wZo=r(GTt,"from_pretrained()"),GTt.forEach(t),AZo=r(woe," class method or the "),Xz=n(woe,"A",{href:!0});var OTt=s(Xz);LZo=r(OTt,"from_config()"),OTt.forEach(t),yZo=r(woe,` class
method.`),woe.forEach(t),xZo=i(sl),Qy=n(sl,"P",{});var eXe=s(Qy);$Zo=r(eXe,"This class cannot be instantiated directly using "),V_e=n(eXe,"CODE",{});var VTt=s(V_e);kZo=r(VTt,"__init__()"),VTt.forEach(t),SZo=r(eXe," (throws an error)."),eXe.forEach(t),RZo=i(sl),pt=n(sl,"DIV",{class:!0});var zA=s(pt);T(Hy.$$.fragment,zA),PZo=i(zA),X_e=n(zA,"P",{});var XTt=s(X_e);BZo=r(XTt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),XTt.forEach(t),IZo=i(zA),md=n(zA,"P",{});var Aoe=s(md);NZo=r(Aoe,`Note:
Loading a model from its configuration file does `),z_e=n(Aoe,"STRONG",{});var zTt=s(z_e);qZo=r(zTt,"not"),zTt.forEach(t),jZo=r(Aoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zz=n(Aoe,"A",{href:!0});var WTt=s(zz);DZo=r(WTt,"from_pretrained()"),WTt.forEach(t),GZo=r(Aoe," to load the model weights."),Aoe.forEach(t),OZo=i(zA),T(PF.$$.fragment,zA),zA.forEach(t),VZo=i(sl),so=n(sl,"DIV",{class:!0});var ha=s(so);T(Uy.$$.fragment,ha),XZo=i(ha),W_e=n(ha,"P",{});var QTt=s(W_e);zZo=r(QTt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),QTt.forEach(t),WZo=i(ha),Oa=n(ha,"P",{});var WA=s(Oa);QZo=r(WA,"The model class to instantiate is selected based on the "),Q_e=n(WA,"CODE",{});var HTt=s(Q_e);HZo=r(HTt,"model_type"),HTt.forEach(t),UZo=r(WA,` property of the config object (either
passed as an argument or loaded from `),H_e=n(WA,"CODE",{});var UTt=s(H_e);JZo=r(UTt,"pretrained_model_name_or_path"),UTt.forEach(t),YZo=r(WA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U_e=n(WA,"CODE",{});var JTt=s(U_e);KZo=r(JTt,"pretrained_model_name_or_path"),JTt.forEach(t),ZZo=r(WA,":"),WA.forEach(t),eer=i(ha),J_e=n(ha,"UL",{});var YTt=s(J_e);BF=n(YTt,"LI",{});var sPe=s(BF);Y_e=n(sPe,"STRONG",{});var KTt=s(Y_e);oer=r(KTt,"tapas"),KTt.forEach(t),rer=r(sPe," \u2014 "),Wz=n(sPe,"A",{href:!0});var ZTt=s(Wz);ter=r(ZTt,"TapasForQuestionAnswering"),ZTt.forEach(t),aer=r(sPe," (TAPAS model)"),sPe.forEach(t),YTt.forEach(t),ner=i(ha),IF=n(ha,"P",{});var lPe=s(IF);ser=r(lPe,"The model is set in evaluation mode by default using "),K_e=n(lPe,"CODE",{});var eMt=s(K_e);ler=r(eMt,"model.eval()"),eMt.forEach(t),ier=r(lPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z_e=n(lPe,"CODE",{});var oMt=s(Z_e);der=r(oMt,"model.train()"),oMt.forEach(t),lPe.forEach(t),cer=i(ha),T(NF.$$.fragment,ha),ha.forEach(t),sl.forEach(t),UGe=i(f),gd=n(f,"H2",{class:!0});var oXe=s(gd);qF=n(oXe,"A",{id:!0,class:!0,href:!0});var rMt=s(qF);e7e=n(rMt,"SPAN",{});var tMt=s(e7e);T(Jy.$$.fragment,tMt),tMt.forEach(t),rMt.forEach(t),fer=i(oXe),o7e=n(oXe,"SPAN",{});var aMt=s(o7e);mer=r(aMt,"AutoModelForImageClassification"),aMt.forEach(t),oXe.forEach(t),JGe=i(f),Do=n(f,"DIV",{class:!0});var ll=s(Do);T(Yy.$$.fragment,ll),ger=i(ll),hd=n(ll,"P",{});var Loe=s(hd);her=r(Loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Qz=n(Loe,"A",{href:!0});var nMt=s(Qz);per=r(nMt,"from_pretrained()"),nMt.forEach(t),uer=r(Loe," class method or the "),Hz=n(Loe,"A",{href:!0});var sMt=s(Hz);_er=r(sMt,"from_config()"),sMt.forEach(t),ber=r(Loe,` class
method.`),Loe.forEach(t),ver=i(ll),Ky=n(ll,"P",{});var rXe=s(Ky);Fer=r(rXe,"This class cannot be instantiated directly using "),r7e=n(rXe,"CODE",{});var lMt=s(r7e);Ter=r(lMt,"__init__()"),lMt.forEach(t),Mer=r(rXe," (throws an error)."),rXe.forEach(t),Eer=i(ll),ut=n(ll,"DIV",{class:!0});var QA=s(ut);T(Zy.$$.fragment,QA),Cer=i(QA),t7e=n(QA,"P",{});var iMt=s(t7e);wer=r(iMt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),iMt.forEach(t),Aer=i(QA),pd=n(QA,"P",{});var yoe=s(pd);Ler=r(yoe,`Note:
Loading a model from its configuration file does `),a7e=n(yoe,"STRONG",{});var dMt=s(a7e);yer=r(dMt,"not"),dMt.forEach(t),xer=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uz=n(yoe,"A",{href:!0});var cMt=s(Uz);$er=r(cMt,"from_pretrained()"),cMt.forEach(t),ker=r(yoe," to load the model weights."),yoe.forEach(t),Ser=i(QA),T(jF.$$.fragment,QA),QA.forEach(t),Rer=i(ll),lo=n(ll,"DIV",{class:!0});var pa=s(lo);T(e8.$$.fragment,pa),Per=i(pa),n7e=n(pa,"P",{});var fMt=s(n7e);Ber=r(fMt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),fMt.forEach(t),Ier=i(pa),Va=n(pa,"P",{});var HA=s(Va);Ner=r(HA,"The model class to instantiate is selected based on the "),s7e=n(HA,"CODE",{});var mMt=s(s7e);qer=r(mMt,"model_type"),mMt.forEach(t),jer=r(HA,` property of the config object (either
passed as an argument or loaded from `),l7e=n(HA,"CODE",{});var gMt=s(l7e);Der=r(gMt,"pretrained_model_name_or_path"),gMt.forEach(t),Ger=r(HA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i7e=n(HA,"CODE",{});var hMt=s(i7e);Oer=r(hMt,"pretrained_model_name_or_path"),hMt.forEach(t),Ver=r(HA,":"),HA.forEach(t),Xer=i(pa),_e=n(pa,"UL",{});var Te=s(_e);DF=n(Te,"LI",{});var iPe=s(DF);d7e=n(iPe,"STRONG",{});var pMt=s(d7e);zer=r(pMt,"beit"),pMt.forEach(t),Wer=r(iPe," \u2014 "),Jz=n(iPe,"A",{href:!0});var uMt=s(Jz);Qer=r(uMt,"BeitForImageClassification"),uMt.forEach(t),Her=r(iPe," (BEiT model)"),iPe.forEach(t),Uer=i(Te),GF=n(Te,"LI",{});var dPe=s(GF);c7e=n(dPe,"STRONG",{});var _Mt=s(c7e);Jer=r(_Mt,"convnext"),_Mt.forEach(t),Yer=r(dPe," \u2014 "),Yz=n(dPe,"A",{href:!0});var bMt=s(Yz);Ker=r(bMt,"ConvNextForImageClassification"),bMt.forEach(t),Zer=r(dPe," (ConvNeXT model)"),dPe.forEach(t),eor=i(Te),OF=n(Te,"LI",{});var cPe=s(OF);f7e=n(cPe,"STRONG",{});var vMt=s(f7e);oor=r(vMt,"cvt"),vMt.forEach(t),ror=r(cPe," \u2014 "),Kz=n(cPe,"A",{href:!0});var FMt=s(Kz);tor=r(FMt,"CvtForImageClassification"),FMt.forEach(t),aor=r(cPe," (CvT model)"),cPe.forEach(t),nor=i(Te),VF=n(Te,"LI",{});var fPe=s(VF);m7e=n(fPe,"STRONG",{});var TMt=s(m7e);sor=r(TMt,"data2vec-vision"),TMt.forEach(t),lor=r(fPe," \u2014 "),Zz=n(fPe,"A",{href:!0});var MMt=s(Zz);ior=r(MMt,"Data2VecVisionForImageClassification"),MMt.forEach(t),dor=r(fPe," (Data2VecVision model)"),fPe.forEach(t),cor=i(Te),Os=n(Te,"LI",{});var Wk=s(Os);g7e=n(Wk,"STRONG",{});var EMt=s(g7e);mor=r(EMt,"deit"),EMt.forEach(t),gor=r(Wk," \u2014 "),eW=n(Wk,"A",{href:!0});var CMt=s(eW);hor=r(CMt,"DeiTForImageClassification"),CMt.forEach(t),por=r(Wk," or "),oW=n(Wk,"A",{href:!0});var wMt=s(oW);uor=r(wMt,"DeiTForImageClassificationWithTeacher"),wMt.forEach(t),_or=r(Wk," (DeiT model)"),Wk.forEach(t),bor=i(Te),XF=n(Te,"LI",{});var mPe=s(XF);h7e=n(mPe,"STRONG",{});var AMt=s(h7e);vor=r(AMt,"imagegpt"),AMt.forEach(t),For=r(mPe," \u2014 "),rW=n(mPe,"A",{href:!0});var LMt=s(rW);Tor=r(LMt,"ImageGPTForImageClassification"),LMt.forEach(t),Mor=r(mPe," (ImageGPT model)"),mPe.forEach(t),Eor=i(Te),Vs=n(Te,"LI",{});var Qk=s(Vs);p7e=n(Qk,"STRONG",{});var yMt=s(p7e);Cor=r(yMt,"levit"),yMt.forEach(t),wor=r(Qk," \u2014 "),tW=n(Qk,"A",{href:!0});var xMt=s(tW);Aor=r(xMt,"LevitForImageClassification"),xMt.forEach(t),Lor=r(Qk," or "),aW=n(Qk,"A",{href:!0});var $Mt=s(aW);yor=r($Mt,"LevitForImageClassificationWithTeacher"),$Mt.forEach(t),xor=r(Qk," (LeViT model)"),Qk.forEach(t),$or=i(Te),zF=n(Te,"LI",{});var gPe=s(zF);u7e=n(gPe,"STRONG",{});var kMt=s(u7e);kor=r(kMt,"omnivore"),kMt.forEach(t),Sor=r(gPe," \u2014 "),nW=n(gPe,"A",{href:!0});var SMt=s(nW);Ror=r(SMt,"OmnivoreForVisionClassification"),SMt.forEach(t),Por=r(gPe," (Omnivore model)"),gPe.forEach(t),Bor=i(Te),_t=n(Te,"LI",{});var Af=s(_t);_7e=n(Af,"STRONG",{});var RMt=s(_7e);Ior=r(RMt,"perceiver"),RMt.forEach(t),Nor=r(Af," \u2014 "),sW=n(Af,"A",{href:!0});var PMt=s(sW);qor=r(PMt,"PerceiverForImageClassificationLearned"),PMt.forEach(t),jor=r(Af," or "),lW=n(Af,"A",{href:!0});var BMt=s(lW);Dor=r(BMt,"PerceiverForImageClassificationFourier"),BMt.forEach(t),Gor=r(Af," or "),iW=n(Af,"A",{href:!0});var IMt=s(iW);Oor=r(IMt,"PerceiverForImageClassificationConvProcessing"),IMt.forEach(t),Vor=r(Af," (Perceiver model)"),Af.forEach(t),Xor=i(Te),WF=n(Te,"LI",{});var hPe=s(WF);b7e=n(hPe,"STRONG",{});var NMt=s(b7e);zor=r(NMt,"poolformer"),NMt.forEach(t),Wor=r(hPe," \u2014 "),dW=n(hPe,"A",{href:!0});var qMt=s(dW);Qor=r(qMt,"PoolFormerForImageClassification"),qMt.forEach(t),Hor=r(hPe," (PoolFormer model)"),hPe.forEach(t),Uor=i(Te),QF=n(Te,"LI",{});var pPe=s(QF);v7e=n(pPe,"STRONG",{});var jMt=s(v7e);Jor=r(jMt,"regnet"),jMt.forEach(t),Yor=r(pPe," \u2014 "),cW=n(pPe,"A",{href:!0});var DMt=s(cW);Kor=r(DMt,"RegNetForImageClassification"),DMt.forEach(t),Zor=r(pPe," (RegNet model)"),pPe.forEach(t),err=i(Te),HF=n(Te,"LI",{});var uPe=s(HF);F7e=n(uPe,"STRONG",{});var GMt=s(F7e);orr=r(GMt,"resnet"),GMt.forEach(t),rrr=r(uPe," \u2014 "),fW=n(uPe,"A",{href:!0});var OMt=s(fW);trr=r(OMt,"ResNetForImageClassification"),OMt.forEach(t),arr=r(uPe," (ResNet model)"),uPe.forEach(t),nrr=i(Te),UF=n(Te,"LI",{});var _Pe=s(UF);T7e=n(_Pe,"STRONG",{});var VMt=s(T7e);srr=r(VMt,"segformer"),VMt.forEach(t),lrr=r(_Pe," \u2014 "),mW=n(_Pe,"A",{href:!0});var XMt=s(mW);irr=r(XMt,"SegformerForImageClassification"),XMt.forEach(t),drr=r(_Pe," (SegFormer model)"),_Pe.forEach(t),crr=i(Te),JF=n(Te,"LI",{});var bPe=s(JF);M7e=n(bPe,"STRONG",{});var zMt=s(M7e);frr=r(zMt,"swin"),zMt.forEach(t),mrr=r(bPe," \u2014 "),gW=n(bPe,"A",{href:!0});var WMt=s(gW);grr=r(WMt,"SwinForImageClassification"),WMt.forEach(t),hrr=r(bPe," (Swin Transformer model)"),bPe.forEach(t),prr=i(Te),YF=n(Te,"LI",{});var vPe=s(YF);E7e=n(vPe,"STRONG",{});var QMt=s(E7e);urr=r(QMt,"van"),QMt.forEach(t),_rr=r(vPe," \u2014 "),hW=n(vPe,"A",{href:!0});var HMt=s(hW);brr=r(HMt,"VanForImageClassification"),HMt.forEach(t),vrr=r(vPe," (VAN model)"),vPe.forEach(t),Frr=i(Te),KF=n(Te,"LI",{});var FPe=s(KF);C7e=n(FPe,"STRONG",{});var UMt=s(C7e);Trr=r(UMt,"vit"),UMt.forEach(t),Mrr=r(FPe," \u2014 "),pW=n(FPe,"A",{href:!0});var JMt=s(pW);Err=r(JMt,"ViTForImageClassification"),JMt.forEach(t),Crr=r(FPe," (ViT model)"),FPe.forEach(t),Te.forEach(t),wrr=i(pa),ZF=n(pa,"P",{});var TPe=s(ZF);Arr=r(TPe,"The model is set in evaluation mode by default using "),w7e=n(TPe,"CODE",{});var YMt=s(w7e);Lrr=r(YMt,"model.eval()"),YMt.forEach(t),yrr=r(TPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A7e=n(TPe,"CODE",{});var KMt=s(A7e);xrr=r(KMt,"model.train()"),KMt.forEach(t),TPe.forEach(t),$rr=i(pa),T(eT.$$.fragment,pa),pa.forEach(t),ll.forEach(t),YGe=i(f),ud=n(f,"H2",{class:!0});var tXe=s(ud);oT=n(tXe,"A",{id:!0,class:!0,href:!0});var ZMt=s(oT);L7e=n(ZMt,"SPAN",{});var eEt=s(L7e);T(o8.$$.fragment,eEt),eEt.forEach(t),ZMt.forEach(t),krr=i(tXe),y7e=n(tXe,"SPAN",{});var oEt=s(y7e);Srr=r(oEt,"AutoModelForVision2Seq"),oEt.forEach(t),tXe.forEach(t),KGe=i(f),Go=n(f,"DIV",{class:!0});var il=s(Go);T(r8.$$.fragment,il),Rrr=i(il),_d=n(il,"P",{});var xoe=s(_d);Prr=r(xoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),uW=n(xoe,"A",{href:!0});var rEt=s(uW);Brr=r(rEt,"from_pretrained()"),rEt.forEach(t),Irr=r(xoe," class method or the "),_W=n(xoe,"A",{href:!0});var tEt=s(_W);Nrr=r(tEt,"from_config()"),tEt.forEach(t),qrr=r(xoe,` class
method.`),xoe.forEach(t),jrr=i(il),t8=n(il,"P",{});var aXe=s(t8);Drr=r(aXe,"This class cannot be instantiated directly using "),x7e=n(aXe,"CODE",{});var aEt=s(x7e);Grr=r(aEt,"__init__()"),aEt.forEach(t),Orr=r(aXe," (throws an error)."),aXe.forEach(t),Vrr=i(il),bt=n(il,"DIV",{class:!0});var UA=s(bt);T(a8.$$.fragment,UA),Xrr=i(UA),$7e=n(UA,"P",{});var nEt=s($7e);zrr=r(nEt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),nEt.forEach(t),Wrr=i(UA),bd=n(UA,"P",{});var $oe=s(bd);Qrr=r($oe,`Note:
Loading a model from its configuration file does `),k7e=n($oe,"STRONG",{});var sEt=s(k7e);Hrr=r(sEt,"not"),sEt.forEach(t),Urr=r($oe,` load the model weights. It only affects the
model\u2019s configuration. Use `),bW=n($oe,"A",{href:!0});var lEt=s(bW);Jrr=r(lEt,"from_pretrained()"),lEt.forEach(t),Yrr=r($oe," to load the model weights."),$oe.forEach(t),Krr=i(UA),T(rT.$$.fragment,UA),UA.forEach(t),Zrr=i(il),io=n(il,"DIV",{class:!0});var ua=s(io);T(n8.$$.fragment,ua),etr=i(ua),S7e=n(ua,"P",{});var iEt=s(S7e);otr=r(iEt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),iEt.forEach(t),rtr=i(ua),Xa=n(ua,"P",{});var JA=s(Xa);ttr=r(JA,"The model class to instantiate is selected based on the "),R7e=n(JA,"CODE",{});var dEt=s(R7e);atr=r(dEt,"model_type"),dEt.forEach(t),ntr=r(JA,` property of the config object (either
passed as an argument or loaded from `),P7e=n(JA,"CODE",{});var cEt=s(P7e);str=r(cEt,"pretrained_model_name_or_path"),cEt.forEach(t),ltr=r(JA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B7e=n(JA,"CODE",{});var fEt=s(B7e);itr=r(fEt,"pretrained_model_name_or_path"),fEt.forEach(t),dtr=r(JA,":"),JA.forEach(t),ctr=i(ua),I7e=n(ua,"UL",{});var mEt=s(I7e);tT=n(mEt,"LI",{});var MPe=s(tT);N7e=n(MPe,"STRONG",{});var gEt=s(N7e);ftr=r(gEt,"vision-encoder-decoder"),gEt.forEach(t),mtr=r(MPe," \u2014 "),vW=n(MPe,"A",{href:!0});var hEt=s(vW);gtr=r(hEt,"VisionEncoderDecoderModel"),hEt.forEach(t),htr=r(MPe," (Vision Encoder decoder model)"),MPe.forEach(t),mEt.forEach(t),ptr=i(ua),aT=n(ua,"P",{});var EPe=s(aT);utr=r(EPe,"The model is set in evaluation mode by default using "),q7e=n(EPe,"CODE",{});var pEt=s(q7e);_tr=r(pEt,"model.eval()"),pEt.forEach(t),btr=r(EPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j7e=n(EPe,"CODE",{});var uEt=s(j7e);vtr=r(uEt,"model.train()"),uEt.forEach(t),EPe.forEach(t),Ftr=i(ua),T(nT.$$.fragment,ua),ua.forEach(t),il.forEach(t),ZGe=i(f),vd=n(f,"H2",{class:!0});var nXe=s(vd);sT=n(nXe,"A",{id:!0,class:!0,href:!0});var _Et=s(sT);D7e=n(_Et,"SPAN",{});var bEt=s(D7e);T(s8.$$.fragment,bEt),bEt.forEach(t),_Et.forEach(t),Ttr=i(nXe),G7e=n(nXe,"SPAN",{});var vEt=s(G7e);Mtr=r(vEt,"AutoModelForVisualQuestionAnswering"),vEt.forEach(t),nXe.forEach(t),eOe=i(f),Oo=n(f,"DIV",{class:!0});var dl=s(Oo);T(l8.$$.fragment,dl),Etr=i(dl),Fd=n(dl,"P",{});var koe=s(Fd);Ctr=r(koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),FW=n(koe,"A",{href:!0});var FEt=s(FW);wtr=r(FEt,"from_pretrained()"),FEt.forEach(t),Atr=r(koe," class method or the "),TW=n(koe,"A",{href:!0});var TEt=s(TW);Ltr=r(TEt,"from_config()"),TEt.forEach(t),ytr=r(koe,` class
method.`),koe.forEach(t),xtr=i(dl),i8=n(dl,"P",{});var sXe=s(i8);$tr=r(sXe,"This class cannot be instantiated directly using "),O7e=n(sXe,"CODE",{});var MEt=s(O7e);ktr=r(MEt,"__init__()"),MEt.forEach(t),Str=r(sXe," (throws an error)."),sXe.forEach(t),Rtr=i(dl),vt=n(dl,"DIV",{class:!0});var YA=s(vt);T(d8.$$.fragment,YA),Ptr=i(YA),V7e=n(YA,"P",{});var EEt=s(V7e);Btr=r(EEt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),EEt.forEach(t),Itr=i(YA),Td=n(YA,"P",{});var Soe=s(Td);Ntr=r(Soe,`Note:
Loading a model from its configuration file does `),X7e=n(Soe,"STRONG",{});var CEt=s(X7e);qtr=r(CEt,"not"),CEt.forEach(t),jtr=r(Soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MW=n(Soe,"A",{href:!0});var wEt=s(MW);Dtr=r(wEt,"from_pretrained()"),wEt.forEach(t),Gtr=r(Soe," to load the model weights."),Soe.forEach(t),Otr=i(YA),T(lT.$$.fragment,YA),YA.forEach(t),Vtr=i(dl),co=n(dl,"DIV",{class:!0});var _a=s(co);T(c8.$$.fragment,_a),Xtr=i(_a),z7e=n(_a,"P",{});var AEt=s(z7e);ztr=r(AEt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),AEt.forEach(t),Wtr=i(_a),za=n(_a,"P",{});var KA=s(za);Qtr=r(KA,"The model class to instantiate is selected based on the "),W7e=n(KA,"CODE",{});var LEt=s(W7e);Htr=r(LEt,"model_type"),LEt.forEach(t),Utr=r(KA,` property of the config object (either
passed as an argument or loaded from `),Q7e=n(KA,"CODE",{});var yEt=s(Q7e);Jtr=r(yEt,"pretrained_model_name_or_path"),yEt.forEach(t),Ytr=r(KA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H7e=n(KA,"CODE",{});var xEt=s(H7e);Ktr=r(xEt,"pretrained_model_name_or_path"),xEt.forEach(t),Ztr=r(KA,":"),KA.forEach(t),ear=i(_a),U7e=n(_a,"UL",{});var $Et=s(U7e);iT=n($Et,"LI",{});var CPe=s(iT);J7e=n(CPe,"STRONG",{});var kEt=s(J7e);oar=r(kEt,"vilt"),kEt.forEach(t),rar=r(CPe," \u2014 "),EW=n(CPe,"A",{href:!0});var SEt=s(EW);tar=r(SEt,"ViltForQuestionAnswering"),SEt.forEach(t),aar=r(CPe," (ViLT model)"),CPe.forEach(t),$Et.forEach(t),nar=i(_a),dT=n(_a,"P",{});var wPe=s(dT);sar=r(wPe,"The model is set in evaluation mode by default using "),Y7e=n(wPe,"CODE",{});var REt=s(Y7e);lar=r(REt,"model.eval()"),REt.forEach(t),iar=r(wPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K7e=n(wPe,"CODE",{});var PEt=s(K7e);dar=r(PEt,"model.train()"),PEt.forEach(t),wPe.forEach(t),car=i(_a),T(cT.$$.fragment,_a),_a.forEach(t),dl.forEach(t),oOe=i(f),Md=n(f,"H2",{class:!0});var lXe=s(Md);fT=n(lXe,"A",{id:!0,class:!0,href:!0});var BEt=s(fT);Z7e=n(BEt,"SPAN",{});var IEt=s(Z7e);T(f8.$$.fragment,IEt),IEt.forEach(t),BEt.forEach(t),far=i(lXe),e2e=n(lXe,"SPAN",{});var NEt=s(e2e);mar=r(NEt,"AutoModelForAudioClassification"),NEt.forEach(t),lXe.forEach(t),rOe=i(f),Vo=n(f,"DIV",{class:!0});var cl=s(Vo);T(m8.$$.fragment,cl),gar=i(cl),Ed=n(cl,"P",{});var Roe=s(Ed);har=r(Roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),CW=n(Roe,"A",{href:!0});var qEt=s(CW);par=r(qEt,"from_pretrained()"),qEt.forEach(t),uar=r(Roe," class method or the "),wW=n(Roe,"A",{href:!0});var jEt=s(wW);_ar=r(jEt,"from_config()"),jEt.forEach(t),bar=r(Roe,` class
method.`),Roe.forEach(t),Far=i(cl),g8=n(cl,"P",{});var iXe=s(g8);Tar=r(iXe,"This class cannot be instantiated directly using "),o2e=n(iXe,"CODE",{});var DEt=s(o2e);Mar=r(DEt,"__init__()"),DEt.forEach(t),Ear=r(iXe," (throws an error)."),iXe.forEach(t),Car=i(cl),Ft=n(cl,"DIV",{class:!0});var ZA=s(Ft);T(h8.$$.fragment,ZA),war=i(ZA),r2e=n(ZA,"P",{});var GEt=s(r2e);Aar=r(GEt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),GEt.forEach(t),Lar=i(ZA),Cd=n(ZA,"P",{});var Poe=s(Cd);yar=r(Poe,`Note:
Loading a model from its configuration file does `),t2e=n(Poe,"STRONG",{});var OEt=s(t2e);xar=r(OEt,"not"),OEt.forEach(t),$ar=r(Poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),AW=n(Poe,"A",{href:!0});var VEt=s(AW);kar=r(VEt,"from_pretrained()"),VEt.forEach(t),Sar=r(Poe," to load the model weights."),Poe.forEach(t),Rar=i(ZA),T(mT.$$.fragment,ZA),ZA.forEach(t),Par=i(cl),fo=n(cl,"DIV",{class:!0});var ba=s(fo);T(p8.$$.fragment,ba),Bar=i(ba),a2e=n(ba,"P",{});var XEt=s(a2e);Iar=r(XEt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),XEt.forEach(t),Nar=i(ba),Wa=n(ba,"P",{});var e6=s(Wa);qar=r(e6,"The model class to instantiate is selected based on the "),n2e=n(e6,"CODE",{});var zEt=s(n2e);jar=r(zEt,"model_type"),zEt.forEach(t),Dar=r(e6,` property of the config object (either
passed as an argument or loaded from `),s2e=n(e6,"CODE",{});var WEt=s(s2e);Gar=r(WEt,"pretrained_model_name_or_path"),WEt.forEach(t),Oar=r(e6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l2e=n(e6,"CODE",{});var QEt=s(l2e);Var=r(QEt,"pretrained_model_name_or_path"),QEt.forEach(t),Xar=r(e6,":"),e6.forEach(t),zar=i(ba),Pe=n(ba,"UL",{});var ze=s(Pe);gT=n(ze,"LI",{});var APe=s(gT);i2e=n(APe,"STRONG",{});var HEt=s(i2e);War=r(HEt,"data2vec-audio"),HEt.forEach(t),Qar=r(APe," \u2014 "),LW=n(APe,"A",{href:!0});var UEt=s(LW);Har=r(UEt,"Data2VecAudioForSequenceClassification"),UEt.forEach(t),Uar=r(APe," (Data2VecAudio model)"),APe.forEach(t),Jar=i(ze),hT=n(ze,"LI",{});var LPe=s(hT);d2e=n(LPe,"STRONG",{});var JEt=s(d2e);Yar=r(JEt,"hubert"),JEt.forEach(t),Kar=r(LPe," \u2014 "),yW=n(LPe,"A",{href:!0});var YEt=s(yW);Zar=r(YEt,"HubertForSequenceClassification"),YEt.forEach(t),enr=r(LPe," (Hubert model)"),LPe.forEach(t),onr=i(ze),pT=n(ze,"LI",{});var yPe=s(pT);c2e=n(yPe,"STRONG",{});var KEt=s(c2e);rnr=r(KEt,"sew"),KEt.forEach(t),tnr=r(yPe," \u2014 "),xW=n(yPe,"A",{href:!0});var ZEt=s(xW);anr=r(ZEt,"SEWForSequenceClassification"),ZEt.forEach(t),nnr=r(yPe," (SEW model)"),yPe.forEach(t),snr=i(ze),uT=n(ze,"LI",{});var xPe=s(uT);f2e=n(xPe,"STRONG",{});var e4t=s(f2e);lnr=r(e4t,"sew-d"),e4t.forEach(t),inr=r(xPe," \u2014 "),$W=n(xPe,"A",{href:!0});var o4t=s($W);dnr=r(o4t,"SEWDForSequenceClassification"),o4t.forEach(t),cnr=r(xPe," (SEW-D model)"),xPe.forEach(t),fnr=i(ze),_T=n(ze,"LI",{});var $Pe=s(_T);m2e=n($Pe,"STRONG",{});var r4t=s(m2e);mnr=r(r4t,"unispeech"),r4t.forEach(t),gnr=r($Pe," \u2014 "),kW=n($Pe,"A",{href:!0});var t4t=s(kW);hnr=r(t4t,"UniSpeechForSequenceClassification"),t4t.forEach(t),pnr=r($Pe," (UniSpeech model)"),$Pe.forEach(t),unr=i(ze),bT=n(ze,"LI",{});var kPe=s(bT);g2e=n(kPe,"STRONG",{});var a4t=s(g2e);_nr=r(a4t,"unispeech-sat"),a4t.forEach(t),bnr=r(kPe," \u2014 "),SW=n(kPe,"A",{href:!0});var n4t=s(SW);vnr=r(n4t,"UniSpeechSatForSequenceClassification"),n4t.forEach(t),Fnr=r(kPe," (UniSpeechSat model)"),kPe.forEach(t),Tnr=i(ze),vT=n(ze,"LI",{});var SPe=s(vT);h2e=n(SPe,"STRONG",{});var s4t=s(h2e);Mnr=r(s4t,"wav2vec2"),s4t.forEach(t),Enr=r(SPe," \u2014 "),RW=n(SPe,"A",{href:!0});var l4t=s(RW);Cnr=r(l4t,"Wav2Vec2ForSequenceClassification"),l4t.forEach(t),wnr=r(SPe," (Wav2Vec2 model)"),SPe.forEach(t),Anr=i(ze),FT=n(ze,"LI",{});var RPe=s(FT);p2e=n(RPe,"STRONG",{});var i4t=s(p2e);Lnr=r(i4t,"wav2vec2-conformer"),i4t.forEach(t),ynr=r(RPe," \u2014 "),PW=n(RPe,"A",{href:!0});var d4t=s(PW);xnr=r(d4t,"Wav2Vec2ConformerForSequenceClassification"),d4t.forEach(t),$nr=r(RPe," (Wav2Vec2-Conformer model)"),RPe.forEach(t),knr=i(ze),TT=n(ze,"LI",{});var PPe=s(TT);u2e=n(PPe,"STRONG",{});var c4t=s(u2e);Snr=r(c4t,"wavlm"),c4t.forEach(t),Rnr=r(PPe," \u2014 "),BW=n(PPe,"A",{href:!0});var f4t=s(BW);Pnr=r(f4t,"WavLMForSequenceClassification"),f4t.forEach(t),Bnr=r(PPe," (WavLM model)"),PPe.forEach(t),ze.forEach(t),Inr=i(ba),MT=n(ba,"P",{});var BPe=s(MT);Nnr=r(BPe,"The model is set in evaluation mode by default using "),_2e=n(BPe,"CODE",{});var m4t=s(_2e);qnr=r(m4t,"model.eval()"),m4t.forEach(t),jnr=r(BPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b2e=n(BPe,"CODE",{});var g4t=s(b2e);Dnr=r(g4t,"model.train()"),g4t.forEach(t),BPe.forEach(t),Gnr=i(ba),T(ET.$$.fragment,ba),ba.forEach(t),cl.forEach(t),tOe=i(f),wd=n(f,"H2",{class:!0});var dXe=s(wd);CT=n(dXe,"A",{id:!0,class:!0,href:!0});var h4t=s(CT);v2e=n(h4t,"SPAN",{});var p4t=s(v2e);T(u8.$$.fragment,p4t),p4t.forEach(t),h4t.forEach(t),Onr=i(dXe),F2e=n(dXe,"SPAN",{});var u4t=s(F2e);Vnr=r(u4t,"AutoModelForAudioFrameClassification"),u4t.forEach(t),dXe.forEach(t),aOe=i(f),Xo=n(f,"DIV",{class:!0});var fl=s(Xo);T(_8.$$.fragment,fl),Xnr=i(fl),Ad=n(fl,"P",{});var Boe=s(Ad);znr=r(Boe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),IW=n(Boe,"A",{href:!0});var _4t=s(IW);Wnr=r(_4t,"from_pretrained()"),_4t.forEach(t),Qnr=r(Boe," class method or the "),NW=n(Boe,"A",{href:!0});var b4t=s(NW);Hnr=r(b4t,"from_config()"),b4t.forEach(t),Unr=r(Boe,` class
method.`),Boe.forEach(t),Jnr=i(fl),b8=n(fl,"P",{});var cXe=s(b8);Ynr=r(cXe,"This class cannot be instantiated directly using "),T2e=n(cXe,"CODE",{});var v4t=s(T2e);Knr=r(v4t,"__init__()"),v4t.forEach(t),Znr=r(cXe," (throws an error)."),cXe.forEach(t),esr=i(fl),Tt=n(fl,"DIV",{class:!0});var o6=s(Tt);T(v8.$$.fragment,o6),osr=i(o6),M2e=n(o6,"P",{});var F4t=s(M2e);rsr=r(F4t,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),F4t.forEach(t),tsr=i(o6),Ld=n(o6,"P",{});var Ioe=s(Ld);asr=r(Ioe,`Note:
Loading a model from its configuration file does `),E2e=n(Ioe,"STRONG",{});var T4t=s(E2e);nsr=r(T4t,"not"),T4t.forEach(t),ssr=r(Ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=n(Ioe,"A",{href:!0});var M4t=s(qW);lsr=r(M4t,"from_pretrained()"),M4t.forEach(t),isr=r(Ioe," to load the model weights."),Ioe.forEach(t),dsr=i(o6),T(wT.$$.fragment,o6),o6.forEach(t),csr=i(fl),mo=n(fl,"DIV",{class:!0});var va=s(mo);T(F8.$$.fragment,va),fsr=i(va),C2e=n(va,"P",{});var E4t=s(C2e);msr=r(E4t,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),E4t.forEach(t),gsr=i(va),Qa=n(va,"P",{});var r6=s(Qa);hsr=r(r6,"The model class to instantiate is selected based on the "),w2e=n(r6,"CODE",{});var C4t=s(w2e);psr=r(C4t,"model_type"),C4t.forEach(t),usr=r(r6,` property of the config object (either
passed as an argument or loaded from `),A2e=n(r6,"CODE",{});var w4t=s(A2e);_sr=r(w4t,"pretrained_model_name_or_path"),w4t.forEach(t),bsr=r(r6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=n(r6,"CODE",{});var A4t=s(L2e);vsr=r(A4t,"pretrained_model_name_or_path"),A4t.forEach(t),Fsr=r(r6,":"),r6.forEach(t),Tsr=i(va),et=n(va,"UL",{});var ml=s(et);AT=n(ml,"LI",{});var IPe=s(AT);y2e=n(IPe,"STRONG",{});var L4t=s(y2e);Msr=r(L4t,"data2vec-audio"),L4t.forEach(t),Esr=r(IPe," \u2014 "),jW=n(IPe,"A",{href:!0});var y4t=s(jW);Csr=r(y4t,"Data2VecAudioForAudioFrameClassification"),y4t.forEach(t),wsr=r(IPe," (Data2VecAudio model)"),IPe.forEach(t),Asr=i(ml),LT=n(ml,"LI",{});var NPe=s(LT);x2e=n(NPe,"STRONG",{});var x4t=s(x2e);Lsr=r(x4t,"unispeech-sat"),x4t.forEach(t),ysr=r(NPe," \u2014 "),DW=n(NPe,"A",{href:!0});var $4t=s(DW);xsr=r($4t,"UniSpeechSatForAudioFrameClassification"),$4t.forEach(t),$sr=r(NPe," (UniSpeechSat model)"),NPe.forEach(t),ksr=i(ml),yT=n(ml,"LI",{});var qPe=s(yT);$2e=n(qPe,"STRONG",{});var k4t=s($2e);Ssr=r(k4t,"wav2vec2"),k4t.forEach(t),Rsr=r(qPe," \u2014 "),GW=n(qPe,"A",{href:!0});var S4t=s(GW);Psr=r(S4t,"Wav2Vec2ForAudioFrameClassification"),S4t.forEach(t),Bsr=r(qPe," (Wav2Vec2 model)"),qPe.forEach(t),Isr=i(ml),xT=n(ml,"LI",{});var jPe=s(xT);k2e=n(jPe,"STRONG",{});var R4t=s(k2e);Nsr=r(R4t,"wav2vec2-conformer"),R4t.forEach(t),qsr=r(jPe," \u2014 "),OW=n(jPe,"A",{href:!0});var P4t=s(OW);jsr=r(P4t,"Wav2Vec2ConformerForAudioFrameClassification"),P4t.forEach(t),Dsr=r(jPe," (Wav2Vec2-Conformer model)"),jPe.forEach(t),Gsr=i(ml),$T=n(ml,"LI",{});var DPe=s($T);S2e=n(DPe,"STRONG",{});var B4t=s(S2e);Osr=r(B4t,"wavlm"),B4t.forEach(t),Vsr=r(DPe," \u2014 "),VW=n(DPe,"A",{href:!0});var I4t=s(VW);Xsr=r(I4t,"WavLMForAudioFrameClassification"),I4t.forEach(t),zsr=r(DPe," (WavLM model)"),DPe.forEach(t),ml.forEach(t),Wsr=i(va),kT=n(va,"P",{});var GPe=s(kT);Qsr=r(GPe,"The model is set in evaluation mode by default using "),R2e=n(GPe,"CODE",{});var N4t=s(R2e);Hsr=r(N4t,"model.eval()"),N4t.forEach(t),Usr=r(GPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P2e=n(GPe,"CODE",{});var q4t=s(P2e);Jsr=r(q4t,"model.train()"),q4t.forEach(t),GPe.forEach(t),Ysr=i(va),T(ST.$$.fragment,va),va.forEach(t),fl.forEach(t),nOe=i(f),yd=n(f,"H2",{class:!0});var fXe=s(yd);RT=n(fXe,"A",{id:!0,class:!0,href:!0});var j4t=s(RT);B2e=n(j4t,"SPAN",{});var D4t=s(B2e);T(T8.$$.fragment,D4t),D4t.forEach(t),j4t.forEach(t),Ksr=i(fXe),I2e=n(fXe,"SPAN",{});var G4t=s(I2e);Zsr=r(G4t,"AutoModelForCTC"),G4t.forEach(t),fXe.forEach(t),sOe=i(f),zo=n(f,"DIV",{class:!0});var gl=s(zo);T(M8.$$.fragment,gl),elr=i(gl),xd=n(gl,"P",{});var Noe=s(xd);olr=r(Noe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),XW=n(Noe,"A",{href:!0});var O4t=s(XW);rlr=r(O4t,"from_pretrained()"),O4t.forEach(t),tlr=r(Noe," class method or the "),zW=n(Noe,"A",{href:!0});var V4t=s(zW);alr=r(V4t,"from_config()"),V4t.forEach(t),nlr=r(Noe,` class
method.`),Noe.forEach(t),slr=i(gl),E8=n(gl,"P",{});var mXe=s(E8);llr=r(mXe,"This class cannot be instantiated directly using "),N2e=n(mXe,"CODE",{});var X4t=s(N2e);ilr=r(X4t,"__init__()"),X4t.forEach(t),dlr=r(mXe," (throws an error)."),mXe.forEach(t),clr=i(gl),Mt=n(gl,"DIV",{class:!0});var t6=s(Mt);T(C8.$$.fragment,t6),flr=i(t6),q2e=n(t6,"P",{});var z4t=s(q2e);mlr=r(z4t,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),z4t.forEach(t),glr=i(t6),$d=n(t6,"P",{});var qoe=s($d);hlr=r(qoe,`Note:
Loading a model from its configuration file does `),j2e=n(qoe,"STRONG",{});var W4t=s(j2e);plr=r(W4t,"not"),W4t.forEach(t),ulr=r(qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=n(qoe,"A",{href:!0});var Q4t=s(WW);_lr=r(Q4t,"from_pretrained()"),Q4t.forEach(t),blr=r(qoe," to load the model weights."),qoe.forEach(t),vlr=i(t6),T(PT.$$.fragment,t6),t6.forEach(t),Flr=i(gl),go=n(gl,"DIV",{class:!0});var Fa=s(go);T(w8.$$.fragment,Fa),Tlr=i(Fa),D2e=n(Fa,"P",{});var H4t=s(D2e);Mlr=r(H4t,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),H4t.forEach(t),Elr=i(Fa),Ha=n(Fa,"P",{});var a6=s(Ha);Clr=r(a6,"The model class to instantiate is selected based on the "),G2e=n(a6,"CODE",{});var U4t=s(G2e);wlr=r(U4t,"model_type"),U4t.forEach(t),Alr=r(a6,` property of the config object (either
passed as an argument or loaded from `),O2e=n(a6,"CODE",{});var J4t=s(O2e);Llr=r(J4t,"pretrained_model_name_or_path"),J4t.forEach(t),ylr=r(a6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V2e=n(a6,"CODE",{});var Y4t=s(V2e);xlr=r(Y4t,"pretrained_model_name_or_path"),Y4t.forEach(t),$lr=r(a6,":"),a6.forEach(t),klr=i(Fa),Le=n(Fa,"UL",{});var Be=s(Le);BT=n(Be,"LI",{});var OPe=s(BT);X2e=n(OPe,"STRONG",{});var K4t=s(X2e);Slr=r(K4t,"data2vec-audio"),K4t.forEach(t),Rlr=r(OPe," \u2014 "),QW=n(OPe,"A",{href:!0});var Z4t=s(QW);Plr=r(Z4t,"Data2VecAudioForCTC"),Z4t.forEach(t),Blr=r(OPe," (Data2VecAudio model)"),OPe.forEach(t),Ilr=i(Be),IT=n(Be,"LI",{});var VPe=s(IT);z2e=n(VPe,"STRONG",{});var eCt=s(z2e);Nlr=r(eCt,"hubert"),eCt.forEach(t),qlr=r(VPe," \u2014 "),HW=n(VPe,"A",{href:!0});var oCt=s(HW);jlr=r(oCt,"HubertForCTC"),oCt.forEach(t),Dlr=r(VPe," (Hubert model)"),VPe.forEach(t),Glr=i(Be),NT=n(Be,"LI",{});var XPe=s(NT);W2e=n(XPe,"STRONG",{});var rCt=s(W2e);Olr=r(rCt,"mctct"),rCt.forEach(t),Vlr=r(XPe," \u2014 "),UW=n(XPe,"A",{href:!0});var tCt=s(UW);Xlr=r(tCt,"MCTCTForCTC"),tCt.forEach(t),zlr=r(XPe," (M-CTC-T model)"),XPe.forEach(t),Wlr=i(Be),qT=n(Be,"LI",{});var zPe=s(qT);Q2e=n(zPe,"STRONG",{});var aCt=s(Q2e);Qlr=r(aCt,"sew"),aCt.forEach(t),Hlr=r(zPe," \u2014 "),JW=n(zPe,"A",{href:!0});var nCt=s(JW);Ulr=r(nCt,"SEWForCTC"),nCt.forEach(t),Jlr=r(zPe," (SEW model)"),zPe.forEach(t),Ylr=i(Be),jT=n(Be,"LI",{});var WPe=s(jT);H2e=n(WPe,"STRONG",{});var sCt=s(H2e);Klr=r(sCt,"sew-d"),sCt.forEach(t),Zlr=r(WPe," \u2014 "),YW=n(WPe,"A",{href:!0});var lCt=s(YW);eir=r(lCt,"SEWDForCTC"),lCt.forEach(t),oir=r(WPe," (SEW-D model)"),WPe.forEach(t),rir=i(Be),DT=n(Be,"LI",{});var QPe=s(DT);U2e=n(QPe,"STRONG",{});var iCt=s(U2e);tir=r(iCt,"unispeech"),iCt.forEach(t),air=r(QPe," \u2014 "),KW=n(QPe,"A",{href:!0});var dCt=s(KW);nir=r(dCt,"UniSpeechForCTC"),dCt.forEach(t),sir=r(QPe," (UniSpeech model)"),QPe.forEach(t),lir=i(Be),GT=n(Be,"LI",{});var HPe=s(GT);J2e=n(HPe,"STRONG",{});var cCt=s(J2e);iir=r(cCt,"unispeech-sat"),cCt.forEach(t),dir=r(HPe," \u2014 "),ZW=n(HPe,"A",{href:!0});var fCt=s(ZW);cir=r(fCt,"UniSpeechSatForCTC"),fCt.forEach(t),fir=r(HPe," (UniSpeechSat model)"),HPe.forEach(t),mir=i(Be),OT=n(Be,"LI",{});var UPe=s(OT);Y2e=n(UPe,"STRONG",{});var mCt=s(Y2e);gir=r(mCt,"wav2vec2"),mCt.forEach(t),hir=r(UPe," \u2014 "),eQ=n(UPe,"A",{href:!0});var gCt=s(eQ);pir=r(gCt,"Wav2Vec2ForCTC"),gCt.forEach(t),uir=r(UPe," (Wav2Vec2 model)"),UPe.forEach(t),_ir=i(Be),VT=n(Be,"LI",{});var JPe=s(VT);K2e=n(JPe,"STRONG",{});var hCt=s(K2e);bir=r(hCt,"wav2vec2-conformer"),hCt.forEach(t),vir=r(JPe," \u2014 "),oQ=n(JPe,"A",{href:!0});var pCt=s(oQ);Fir=r(pCt,"Wav2Vec2ConformerForCTC"),pCt.forEach(t),Tir=r(JPe," (Wav2Vec2-Conformer model)"),JPe.forEach(t),Mir=i(Be),XT=n(Be,"LI",{});var YPe=s(XT);Z2e=n(YPe,"STRONG",{});var uCt=s(Z2e);Eir=r(uCt,"wavlm"),uCt.forEach(t),Cir=r(YPe," \u2014 "),rQ=n(YPe,"A",{href:!0});var _Ct=s(rQ);wir=r(_Ct,"WavLMForCTC"),_Ct.forEach(t),Air=r(YPe," (WavLM model)"),YPe.forEach(t),Be.forEach(t),Lir=i(Fa),zT=n(Fa,"P",{});var KPe=s(zT);yir=r(KPe,"The model is set in evaluation mode by default using "),e1e=n(KPe,"CODE",{});var bCt=s(e1e);xir=r(bCt,"model.eval()"),bCt.forEach(t),$ir=r(KPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o1e=n(KPe,"CODE",{});var vCt=s(o1e);kir=r(vCt,"model.train()"),vCt.forEach(t),KPe.forEach(t),Sir=i(Fa),T(WT.$$.fragment,Fa),Fa.forEach(t),gl.forEach(t),lOe=i(f),kd=n(f,"H2",{class:!0});var gXe=s(kd);QT=n(gXe,"A",{id:!0,class:!0,href:!0});var FCt=s(QT);r1e=n(FCt,"SPAN",{});var TCt=s(r1e);T(A8.$$.fragment,TCt),TCt.forEach(t),FCt.forEach(t),Rir=i(gXe),t1e=n(gXe,"SPAN",{});var MCt=s(t1e);Pir=r(MCt,"AutoModelForSpeechSeq2Seq"),MCt.forEach(t),gXe.forEach(t),iOe=i(f),Wo=n(f,"DIV",{class:!0});var hl=s(Wo);T(L8.$$.fragment,hl),Bir=i(hl),Sd=n(hl,"P",{});var joe=s(Sd);Iir=r(joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),tQ=n(joe,"A",{href:!0});var ECt=s(tQ);Nir=r(ECt,"from_pretrained()"),ECt.forEach(t),qir=r(joe," class method or the "),aQ=n(joe,"A",{href:!0});var CCt=s(aQ);jir=r(CCt,"from_config()"),CCt.forEach(t),Dir=r(joe,` class
method.`),joe.forEach(t),Gir=i(hl),y8=n(hl,"P",{});var hXe=s(y8);Oir=r(hXe,"This class cannot be instantiated directly using "),a1e=n(hXe,"CODE",{});var wCt=s(a1e);Vir=r(wCt,"__init__()"),wCt.forEach(t),Xir=r(hXe," (throws an error)."),hXe.forEach(t),zir=i(hl),Et=n(hl,"DIV",{class:!0});var n6=s(Et);T(x8.$$.fragment,n6),Wir=i(n6),n1e=n(n6,"P",{});var ACt=s(n1e);Qir=r(ACt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ACt.forEach(t),Hir=i(n6),Rd=n(n6,"P",{});var Doe=s(Rd);Uir=r(Doe,`Note:
Loading a model from its configuration file does `),s1e=n(Doe,"STRONG",{});var LCt=s(s1e);Jir=r(LCt,"not"),LCt.forEach(t),Yir=r(Doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),nQ=n(Doe,"A",{href:!0});var yCt=s(nQ);Kir=r(yCt,"from_pretrained()"),yCt.forEach(t),Zir=r(Doe," to load the model weights."),Doe.forEach(t),edr=i(n6),T(HT.$$.fragment,n6),n6.forEach(t),odr=i(hl),ho=n(hl,"DIV",{class:!0});var Ta=s(ho);T($8.$$.fragment,Ta),rdr=i(Ta),l1e=n(Ta,"P",{});var xCt=s(l1e);tdr=r(xCt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),xCt.forEach(t),adr=i(Ta),Ua=n(Ta,"P",{});var s6=s(Ua);ndr=r(s6,"The model class to instantiate is selected based on the "),i1e=n(s6,"CODE",{});var $Ct=s(i1e);sdr=r($Ct,"model_type"),$Ct.forEach(t),ldr=r(s6,` property of the config object (either
passed as an argument or loaded from `),d1e=n(s6,"CODE",{});var kCt=s(d1e);idr=r(kCt,"pretrained_model_name_or_path"),kCt.forEach(t),ddr=r(s6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c1e=n(s6,"CODE",{});var SCt=s(c1e);cdr=r(SCt,"pretrained_model_name_or_path"),SCt.forEach(t),fdr=r(s6,":"),s6.forEach(t),mdr=i(Ta),k8=n(Ta,"UL",{});var pXe=s(k8);UT=n(pXe,"LI",{});var ZPe=s(UT);f1e=n(ZPe,"STRONG",{});var RCt=s(f1e);gdr=r(RCt,"speech-encoder-decoder"),RCt.forEach(t),hdr=r(ZPe," \u2014 "),sQ=n(ZPe,"A",{href:!0});var PCt=s(sQ);pdr=r(PCt,"SpeechEncoderDecoderModel"),PCt.forEach(t),udr=r(ZPe," (Speech Encoder decoder model)"),ZPe.forEach(t),_dr=i(pXe),JT=n(pXe,"LI",{});var eBe=s(JT);m1e=n(eBe,"STRONG",{});var BCt=s(m1e);bdr=r(BCt,"speech_to_text"),BCt.forEach(t),vdr=r(eBe," \u2014 "),lQ=n(eBe,"A",{href:!0});var ICt=s(lQ);Fdr=r(ICt,"Speech2TextForConditionalGeneration"),ICt.forEach(t),Tdr=r(eBe," (Speech2Text model)"),eBe.forEach(t),pXe.forEach(t),Mdr=i(Ta),YT=n(Ta,"P",{});var oBe=s(YT);Edr=r(oBe,"The model is set in evaluation mode by default using "),g1e=n(oBe,"CODE",{});var NCt=s(g1e);Cdr=r(NCt,"model.eval()"),NCt.forEach(t),wdr=r(oBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h1e=n(oBe,"CODE",{});var qCt=s(h1e);Adr=r(qCt,"model.train()"),qCt.forEach(t),oBe.forEach(t),Ldr=i(Ta),T(KT.$$.fragment,Ta),Ta.forEach(t),hl.forEach(t),dOe=i(f),Pd=n(f,"H2",{class:!0});var uXe=s(Pd);ZT=n(uXe,"A",{id:!0,class:!0,href:!0});var jCt=s(ZT);p1e=n(jCt,"SPAN",{});var DCt=s(p1e);T(S8.$$.fragment,DCt),DCt.forEach(t),jCt.forEach(t),ydr=i(uXe),u1e=n(uXe,"SPAN",{});var GCt=s(u1e);xdr=r(GCt,"AutoModelForAudioXVector"),GCt.forEach(t),uXe.forEach(t),cOe=i(f),Qo=n(f,"DIV",{class:!0});var pl=s(Qo);T(R8.$$.fragment,pl),$dr=i(pl),Bd=n(pl,"P",{});var Goe=s(Bd);kdr=r(Goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),iQ=n(Goe,"A",{href:!0});var OCt=s(iQ);Sdr=r(OCt,"from_pretrained()"),OCt.forEach(t),Rdr=r(Goe," class method or the "),dQ=n(Goe,"A",{href:!0});var VCt=s(dQ);Pdr=r(VCt,"from_config()"),VCt.forEach(t),Bdr=r(Goe,` class
method.`),Goe.forEach(t),Idr=i(pl),P8=n(pl,"P",{});var _Xe=s(P8);Ndr=r(_Xe,"This class cannot be instantiated directly using "),_1e=n(_Xe,"CODE",{});var XCt=s(_1e);qdr=r(XCt,"__init__()"),XCt.forEach(t),jdr=r(_Xe," (throws an error)."),_Xe.forEach(t),Ddr=i(pl),Ct=n(pl,"DIV",{class:!0});var l6=s(Ct);T(B8.$$.fragment,l6),Gdr=i(l6),b1e=n(l6,"P",{});var zCt=s(b1e);Odr=r(zCt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),zCt.forEach(t),Vdr=i(l6),Id=n(l6,"P",{});var Ooe=s(Id);Xdr=r(Ooe,`Note:
Loading a model from its configuration file does `),v1e=n(Ooe,"STRONG",{});var WCt=s(v1e);zdr=r(WCt,"not"),WCt.forEach(t),Wdr=r(Ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(Ooe,"A",{href:!0});var QCt=s(cQ);Qdr=r(QCt,"from_pretrained()"),QCt.forEach(t),Hdr=r(Ooe," to load the model weights."),Ooe.forEach(t),Udr=i(l6),T(eM.$$.fragment,l6),l6.forEach(t),Jdr=i(pl),po=n(pl,"DIV",{class:!0});var Ma=s(po);T(I8.$$.fragment,Ma),Ydr=i(Ma),F1e=n(Ma,"P",{});var HCt=s(F1e);Kdr=r(HCt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),HCt.forEach(t),Zdr=i(Ma),Ja=n(Ma,"P",{});var i6=s(Ja);ecr=r(i6,"The model class to instantiate is selected based on the "),T1e=n(i6,"CODE",{});var UCt=s(T1e);ocr=r(UCt,"model_type"),UCt.forEach(t),rcr=r(i6,` property of the config object (either
passed as an argument or loaded from `),M1e=n(i6,"CODE",{});var JCt=s(M1e);tcr=r(JCt,"pretrained_model_name_or_path"),JCt.forEach(t),acr=r(i6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E1e=n(i6,"CODE",{});var YCt=s(E1e);ncr=r(YCt,"pretrained_model_name_or_path"),YCt.forEach(t),scr=r(i6,":"),i6.forEach(t),lcr=i(Ma),ot=n(Ma,"UL",{});var ul=s(ot);oM=n(ul,"LI",{});var rBe=s(oM);C1e=n(rBe,"STRONG",{});var KCt=s(C1e);icr=r(KCt,"data2vec-audio"),KCt.forEach(t),dcr=r(rBe," \u2014 "),fQ=n(rBe,"A",{href:!0});var ZCt=s(fQ);ccr=r(ZCt,"Data2VecAudioForXVector"),ZCt.forEach(t),fcr=r(rBe," (Data2VecAudio model)"),rBe.forEach(t),mcr=i(ul),rM=n(ul,"LI",{});var tBe=s(rM);w1e=n(tBe,"STRONG",{});var e5t=s(w1e);gcr=r(e5t,"unispeech-sat"),e5t.forEach(t),hcr=r(tBe," \u2014 "),mQ=n(tBe,"A",{href:!0});var o5t=s(mQ);pcr=r(o5t,"UniSpeechSatForXVector"),o5t.forEach(t),ucr=r(tBe," (UniSpeechSat model)"),tBe.forEach(t),_cr=i(ul),tM=n(ul,"LI",{});var aBe=s(tM);A1e=n(aBe,"STRONG",{});var r5t=s(A1e);bcr=r(r5t,"wav2vec2"),r5t.forEach(t),vcr=r(aBe," \u2014 "),gQ=n(aBe,"A",{href:!0});var t5t=s(gQ);Fcr=r(t5t,"Wav2Vec2ForXVector"),t5t.forEach(t),Tcr=r(aBe," (Wav2Vec2 model)"),aBe.forEach(t),Mcr=i(ul),aM=n(ul,"LI",{});var nBe=s(aM);L1e=n(nBe,"STRONG",{});var a5t=s(L1e);Ecr=r(a5t,"wav2vec2-conformer"),a5t.forEach(t),Ccr=r(nBe," \u2014 "),hQ=n(nBe,"A",{href:!0});var n5t=s(hQ);wcr=r(n5t,"Wav2Vec2ConformerForXVector"),n5t.forEach(t),Acr=r(nBe," (Wav2Vec2-Conformer model)"),nBe.forEach(t),Lcr=i(ul),nM=n(ul,"LI",{});var sBe=s(nM);y1e=n(sBe,"STRONG",{});var s5t=s(y1e);ycr=r(s5t,"wavlm"),s5t.forEach(t),xcr=r(sBe," \u2014 "),pQ=n(sBe,"A",{href:!0});var l5t=s(pQ);$cr=r(l5t,"WavLMForXVector"),l5t.forEach(t),kcr=r(sBe," (WavLM model)"),sBe.forEach(t),ul.forEach(t),Scr=i(Ma),sM=n(Ma,"P",{});var lBe=s(sM);Rcr=r(lBe,"The model is set in evaluation mode by default using "),x1e=n(lBe,"CODE",{});var i5t=s(x1e);Pcr=r(i5t,"model.eval()"),i5t.forEach(t),Bcr=r(lBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$1e=n(lBe,"CODE",{});var d5t=s($1e);Icr=r(d5t,"model.train()"),d5t.forEach(t),lBe.forEach(t),Ncr=i(Ma),T(lM.$$.fragment,Ma),Ma.forEach(t),pl.forEach(t),fOe=i(f),Nd=n(f,"H2",{class:!0});var bXe=s(Nd);iM=n(bXe,"A",{id:!0,class:!0,href:!0});var c5t=s(iM);k1e=n(c5t,"SPAN",{});var f5t=s(k1e);T(N8.$$.fragment,f5t),f5t.forEach(t),c5t.forEach(t),qcr=i(bXe),S1e=n(bXe,"SPAN",{});var m5t=s(S1e);jcr=r(m5t,"AutoModelForMaskedImageModeling"),m5t.forEach(t),bXe.forEach(t),mOe=i(f),Ho=n(f,"DIV",{class:!0});var _l=s(Ho);T(q8.$$.fragment,_l),Dcr=i(_l),qd=n(_l,"P",{});var Voe=s(qd);Gcr=r(Voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),uQ=n(Voe,"A",{href:!0});var g5t=s(uQ);Ocr=r(g5t,"from_pretrained()"),g5t.forEach(t),Vcr=r(Voe," class method or the "),_Q=n(Voe,"A",{href:!0});var h5t=s(_Q);Xcr=r(h5t,"from_config()"),h5t.forEach(t),zcr=r(Voe,` class
method.`),Voe.forEach(t),Wcr=i(_l),j8=n(_l,"P",{});var vXe=s(j8);Qcr=r(vXe,"This class cannot be instantiated directly using "),R1e=n(vXe,"CODE",{});var p5t=s(R1e);Hcr=r(p5t,"__init__()"),p5t.forEach(t),Ucr=r(vXe," (throws an error)."),vXe.forEach(t),Jcr=i(_l),wt=n(_l,"DIV",{class:!0});var d6=s(wt);T(D8.$$.fragment,d6),Ycr=i(d6),P1e=n(d6,"P",{});var u5t=s(P1e);Kcr=r(u5t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),u5t.forEach(t),Zcr=i(d6),jd=n(d6,"P",{});var Xoe=s(jd);efr=r(Xoe,`Note:
Loading a model from its configuration file does `),B1e=n(Xoe,"STRONG",{});var _5t=s(B1e);ofr=r(_5t,"not"),_5t.forEach(t),rfr=r(Xoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),bQ=n(Xoe,"A",{href:!0});var b5t=s(bQ);tfr=r(b5t,"from_pretrained()"),b5t.forEach(t),afr=r(Xoe," to load the model weights."),Xoe.forEach(t),nfr=i(d6),T(dM.$$.fragment,d6),d6.forEach(t),sfr=i(_l),uo=n(_l,"DIV",{class:!0});var Ea=s(uo);T(G8.$$.fragment,Ea),lfr=i(Ea),I1e=n(Ea,"P",{});var v5t=s(I1e);ifr=r(v5t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),v5t.forEach(t),dfr=i(Ea),Ya=n(Ea,"P",{});var c6=s(Ya);cfr=r(c6,"The model class to instantiate is selected based on the "),N1e=n(c6,"CODE",{});var F5t=s(N1e);ffr=r(F5t,"model_type"),F5t.forEach(t),mfr=r(c6,` property of the config object (either
passed as an argument or loaded from `),q1e=n(c6,"CODE",{});var T5t=s(q1e);gfr=r(T5t,"pretrained_model_name_or_path"),T5t.forEach(t),hfr=r(c6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j1e=n(c6,"CODE",{});var M5t=s(j1e);pfr=r(M5t,"pretrained_model_name_or_path"),M5t.forEach(t),ufr=r(c6,":"),c6.forEach(t),_fr=i(Ea),Dd=n(Ea,"UL",{});var zoe=s(Dd);cM=n(zoe,"LI",{});var iBe=s(cM);D1e=n(iBe,"STRONG",{});var E5t=s(D1e);bfr=r(E5t,"deit"),E5t.forEach(t),vfr=r(iBe," \u2014 "),vQ=n(iBe,"A",{href:!0});var C5t=s(vQ);Ffr=r(C5t,"DeiTForMaskedImageModeling"),C5t.forEach(t),Tfr=r(iBe," (DeiT model)"),iBe.forEach(t),Mfr=i(zoe),fM=n(zoe,"LI",{});var dBe=s(fM);G1e=n(dBe,"STRONG",{});var w5t=s(G1e);Efr=r(w5t,"swin"),w5t.forEach(t),Cfr=r(dBe," \u2014 "),FQ=n(dBe,"A",{href:!0});var A5t=s(FQ);wfr=r(A5t,"SwinForMaskedImageModeling"),A5t.forEach(t),Afr=r(dBe," (Swin Transformer model)"),dBe.forEach(t),Lfr=i(zoe),mM=n(zoe,"LI",{});var cBe=s(mM);O1e=n(cBe,"STRONG",{});var L5t=s(O1e);yfr=r(L5t,"vit"),L5t.forEach(t),xfr=r(cBe," \u2014 "),TQ=n(cBe,"A",{href:!0});var y5t=s(TQ);$fr=r(y5t,"ViTForMaskedImageModeling"),y5t.forEach(t),kfr=r(cBe," (ViT model)"),cBe.forEach(t),zoe.forEach(t),Sfr=i(Ea),gM=n(Ea,"P",{});var fBe=s(gM);Rfr=r(fBe,"The model is set in evaluation mode by default using "),V1e=n(fBe,"CODE",{});var x5t=s(V1e);Pfr=r(x5t,"model.eval()"),x5t.forEach(t),Bfr=r(fBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X1e=n(fBe,"CODE",{});var $5t=s(X1e);Ifr=r($5t,"model.train()"),$5t.forEach(t),fBe.forEach(t),Nfr=i(Ea),T(hM.$$.fragment,Ea),Ea.forEach(t),_l.forEach(t),gOe=i(f),Gd=n(f,"H2",{class:!0});var FXe=s(Gd);pM=n(FXe,"A",{id:!0,class:!0,href:!0});var k5t=s(pM);z1e=n(k5t,"SPAN",{});var S5t=s(z1e);T(O8.$$.fragment,S5t),S5t.forEach(t),k5t.forEach(t),qfr=i(FXe),W1e=n(FXe,"SPAN",{});var R5t=s(W1e);jfr=r(R5t,"AutoModelForObjectDetection"),R5t.forEach(t),FXe.forEach(t),hOe=i(f),Uo=n(f,"DIV",{class:!0});var bl=s(Uo);T(V8.$$.fragment,bl),Dfr=i(bl),Od=n(bl,"P",{});var Woe=s(Od);Gfr=r(Woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),MQ=n(Woe,"A",{href:!0});var P5t=s(MQ);Ofr=r(P5t,"from_pretrained()"),P5t.forEach(t),Vfr=r(Woe," class method or the "),EQ=n(Woe,"A",{href:!0});var B5t=s(EQ);Xfr=r(B5t,"from_config()"),B5t.forEach(t),zfr=r(Woe,` class
method.`),Woe.forEach(t),Wfr=i(bl),X8=n(bl,"P",{});var TXe=s(X8);Qfr=r(TXe,"This class cannot be instantiated directly using "),Q1e=n(TXe,"CODE",{});var I5t=s(Q1e);Hfr=r(I5t,"__init__()"),I5t.forEach(t),Ufr=r(TXe," (throws an error)."),TXe.forEach(t),Jfr=i(bl),At=n(bl,"DIV",{class:!0});var f6=s(At);T(z8.$$.fragment,f6),Yfr=i(f6),H1e=n(f6,"P",{});var N5t=s(H1e);Kfr=r(N5t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),N5t.forEach(t),Zfr=i(f6),Vd=n(f6,"P",{});var Qoe=s(Vd);emr=r(Qoe,`Note:
Loading a model from its configuration file does `),U1e=n(Qoe,"STRONG",{});var q5t=s(U1e);omr=r(q5t,"not"),q5t.forEach(t),rmr=r(Qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),CQ=n(Qoe,"A",{href:!0});var j5t=s(CQ);tmr=r(j5t,"from_pretrained()"),j5t.forEach(t),amr=r(Qoe," to load the model weights."),Qoe.forEach(t),nmr=i(f6),T(uM.$$.fragment,f6),f6.forEach(t),smr=i(bl),_o=n(bl,"DIV",{class:!0});var Ca=s(_o);T(W8.$$.fragment,Ca),lmr=i(Ca),J1e=n(Ca,"P",{});var D5t=s(J1e);imr=r(D5t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),D5t.forEach(t),dmr=i(Ca),Ka=n(Ca,"P",{});var m6=s(Ka);cmr=r(m6,"The model class to instantiate is selected based on the "),Y1e=n(m6,"CODE",{});var G5t=s(Y1e);fmr=r(G5t,"model_type"),G5t.forEach(t),mmr=r(m6,` property of the config object (either
passed as an argument or loaded from `),K1e=n(m6,"CODE",{});var O5t=s(K1e);gmr=r(O5t,"pretrained_model_name_or_path"),O5t.forEach(t),hmr=r(m6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=n(m6,"CODE",{});var V5t=s(Z1e);pmr=r(V5t,"pretrained_model_name_or_path"),V5t.forEach(t),umr=r(m6,":"),m6.forEach(t),_mr=i(Ca),Q8=n(Ca,"UL",{});var MXe=s(Q8);_M=n(MXe,"LI",{});var mBe=s(_M);ebe=n(mBe,"STRONG",{});var X5t=s(ebe);bmr=r(X5t,"detr"),X5t.forEach(t),vmr=r(mBe," \u2014 "),wQ=n(mBe,"A",{href:!0});var z5t=s(wQ);Fmr=r(z5t,"DetrForObjectDetection"),z5t.forEach(t),Tmr=r(mBe," (DETR model)"),mBe.forEach(t),Mmr=i(MXe),bM=n(MXe,"LI",{});var gBe=s(bM);obe=n(gBe,"STRONG",{});var W5t=s(obe);Emr=r(W5t,"yolos"),W5t.forEach(t),Cmr=r(gBe," \u2014 "),AQ=n(gBe,"A",{href:!0});var Q5t=s(AQ);wmr=r(Q5t,"YolosForObjectDetection"),Q5t.forEach(t),Amr=r(gBe," (YOLOS model)"),gBe.forEach(t),MXe.forEach(t),Lmr=i(Ca),vM=n(Ca,"P",{});var hBe=s(vM);ymr=r(hBe,"The model is set in evaluation mode by default using "),rbe=n(hBe,"CODE",{});var H5t=s(rbe);xmr=r(H5t,"model.eval()"),H5t.forEach(t),$mr=r(hBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tbe=n(hBe,"CODE",{});var U5t=s(tbe);kmr=r(U5t,"model.train()"),U5t.forEach(t),hBe.forEach(t),Smr=i(Ca),T(FM.$$.fragment,Ca),Ca.forEach(t),bl.forEach(t),pOe=i(f),Xd=n(f,"H2",{class:!0});var EXe=s(Xd);TM=n(EXe,"A",{id:!0,class:!0,href:!0});var J5t=s(TM);abe=n(J5t,"SPAN",{});var Y5t=s(abe);T(H8.$$.fragment,Y5t),Y5t.forEach(t),J5t.forEach(t),Rmr=i(EXe),nbe=n(EXe,"SPAN",{});var K5t=s(nbe);Pmr=r(K5t,"AutoModelForImageSegmentation"),K5t.forEach(t),EXe.forEach(t),uOe=i(f),Jo=n(f,"DIV",{class:!0});var vl=s(Jo);T(U8.$$.fragment,vl),Bmr=i(vl),zd=n(vl,"P",{});var Hoe=s(zd);Imr=r(Hoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),LQ=n(Hoe,"A",{href:!0});var Z5t=s(LQ);Nmr=r(Z5t,"from_pretrained()"),Z5t.forEach(t),qmr=r(Hoe," class method or the "),yQ=n(Hoe,"A",{href:!0});var e3t=s(yQ);jmr=r(e3t,"from_config()"),e3t.forEach(t),Dmr=r(Hoe,` class
method.`),Hoe.forEach(t),Gmr=i(vl),J8=n(vl,"P",{});var CXe=s(J8);Omr=r(CXe,"This class cannot be instantiated directly using "),sbe=n(CXe,"CODE",{});var o3t=s(sbe);Vmr=r(o3t,"__init__()"),o3t.forEach(t),Xmr=r(CXe," (throws an error)."),CXe.forEach(t),zmr=i(vl),Lt=n(vl,"DIV",{class:!0});var g6=s(Lt);T(Y8.$$.fragment,g6),Wmr=i(g6),lbe=n(g6,"P",{});var r3t=s(lbe);Qmr=r(r3t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),r3t.forEach(t),Hmr=i(g6),Wd=n(g6,"P",{});var Uoe=s(Wd);Umr=r(Uoe,`Note:
Loading a model from its configuration file does `),ibe=n(Uoe,"STRONG",{});var t3t=s(ibe);Jmr=r(t3t,"not"),t3t.forEach(t),Ymr=r(Uoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),xQ=n(Uoe,"A",{href:!0});var a3t=s(xQ);Kmr=r(a3t,"from_pretrained()"),a3t.forEach(t),Zmr=r(Uoe," to load the model weights."),Uoe.forEach(t),egr=i(g6),T(MM.$$.fragment,g6),g6.forEach(t),ogr=i(vl),bo=n(vl,"DIV",{class:!0});var wa=s(bo);T(K8.$$.fragment,wa),rgr=i(wa),dbe=n(wa,"P",{});var n3t=s(dbe);tgr=r(n3t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),n3t.forEach(t),agr=i(wa),Za=n(wa,"P",{});var h6=s(Za);ngr=r(h6,"The model class to instantiate is selected based on the "),cbe=n(h6,"CODE",{});var s3t=s(cbe);sgr=r(s3t,"model_type"),s3t.forEach(t),lgr=r(h6,` property of the config object (either
passed as an argument or loaded from `),fbe=n(h6,"CODE",{});var l3t=s(fbe);igr=r(l3t,"pretrained_model_name_or_path"),l3t.forEach(t),dgr=r(h6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mbe=n(h6,"CODE",{});var i3t=s(mbe);cgr=r(i3t,"pretrained_model_name_or_path"),i3t.forEach(t),fgr=r(h6,":"),h6.forEach(t),mgr=i(wa),gbe=n(wa,"UL",{});var d3t=s(gbe);EM=n(d3t,"LI",{});var pBe=s(EM);hbe=n(pBe,"STRONG",{});var c3t=s(hbe);ggr=r(c3t,"detr"),c3t.forEach(t),hgr=r(pBe," \u2014 "),$Q=n(pBe,"A",{href:!0});var f3t=s($Q);pgr=r(f3t,"DetrForSegmentation"),f3t.forEach(t),ugr=r(pBe," (DETR model)"),pBe.forEach(t),d3t.forEach(t),_gr=i(wa),CM=n(wa,"P",{});var uBe=s(CM);bgr=r(uBe,"The model is set in evaluation mode by default using "),pbe=n(uBe,"CODE",{});var m3t=s(pbe);vgr=r(m3t,"model.eval()"),m3t.forEach(t),Fgr=r(uBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ube=n(uBe,"CODE",{});var g3t=s(ube);Tgr=r(g3t,"model.train()"),g3t.forEach(t),uBe.forEach(t),Mgr=i(wa),T(wM.$$.fragment,wa),wa.forEach(t),vl.forEach(t),_Oe=i(f),Qd=n(f,"H2",{class:!0});var wXe=s(Qd);AM=n(wXe,"A",{id:!0,class:!0,href:!0});var h3t=s(AM);_be=n(h3t,"SPAN",{});var p3t=s(_be);T(Z8.$$.fragment,p3t),p3t.forEach(t),h3t.forEach(t),Egr=i(wXe),bbe=n(wXe,"SPAN",{});var u3t=s(bbe);Cgr=r(u3t,"AutoModelForSemanticSegmentation"),u3t.forEach(t),wXe.forEach(t),bOe=i(f),Yo=n(f,"DIV",{class:!0});var Fl=s(Yo);T(e9.$$.fragment,Fl),wgr=i(Fl),Hd=n(Fl,"P",{});var Joe=s(Hd);Agr=r(Joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),kQ=n(Joe,"A",{href:!0});var _3t=s(kQ);Lgr=r(_3t,"from_pretrained()"),_3t.forEach(t),ygr=r(Joe," class method or the "),SQ=n(Joe,"A",{href:!0});var b3t=s(SQ);xgr=r(b3t,"from_config()"),b3t.forEach(t),$gr=r(Joe,` class
method.`),Joe.forEach(t),kgr=i(Fl),o9=n(Fl,"P",{});var AXe=s(o9);Sgr=r(AXe,"This class cannot be instantiated directly using "),vbe=n(AXe,"CODE",{});var v3t=s(vbe);Rgr=r(v3t,"__init__()"),v3t.forEach(t),Pgr=r(AXe," (throws an error)."),AXe.forEach(t),Bgr=i(Fl),yt=n(Fl,"DIV",{class:!0});var p6=s(yt);T(r9.$$.fragment,p6),Igr=i(p6),Fbe=n(p6,"P",{});var F3t=s(Fbe);Ngr=r(F3t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),F3t.forEach(t),qgr=i(p6),Ud=n(p6,"P",{});var Yoe=s(Ud);jgr=r(Yoe,`Note:
Loading a model from its configuration file does `),Tbe=n(Yoe,"STRONG",{});var T3t=s(Tbe);Dgr=r(T3t,"not"),T3t.forEach(t),Ggr=r(Yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),RQ=n(Yoe,"A",{href:!0});var M3t=s(RQ);Ogr=r(M3t,"from_pretrained()"),M3t.forEach(t),Vgr=r(Yoe," to load the model weights."),Yoe.forEach(t),Xgr=i(p6),T(LM.$$.fragment,p6),p6.forEach(t),zgr=i(Fl),vo=n(Fl,"DIV",{class:!0});var Aa=s(vo);T(t9.$$.fragment,Aa),Wgr=i(Aa),Mbe=n(Aa,"P",{});var E3t=s(Mbe);Qgr=r(E3t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),E3t.forEach(t),Hgr=i(Aa),en=n(Aa,"P",{});var u6=s(en);Ugr=r(u6,"The model class to instantiate is selected based on the "),Ebe=n(u6,"CODE",{});var C3t=s(Ebe);Jgr=r(C3t,"model_type"),C3t.forEach(t),Ygr=r(u6,` property of the config object (either
passed as an argument or loaded from `),Cbe=n(u6,"CODE",{});var w3t=s(Cbe);Kgr=r(w3t,"pretrained_model_name_or_path"),w3t.forEach(t),Zgr=r(u6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wbe=n(u6,"CODE",{});var A3t=s(wbe);ehr=r(A3t,"pretrained_model_name_or_path"),A3t.forEach(t),ohr=r(u6,":"),u6.forEach(t),rhr=i(Aa),on=n(Aa,"UL",{});var _6=s(on);yM=n(_6,"LI",{});var _Be=s(yM);Abe=n(_Be,"STRONG",{});var L3t=s(Abe);thr=r(L3t,"beit"),L3t.forEach(t),ahr=r(_Be," \u2014 "),PQ=n(_Be,"A",{href:!0});var y3t=s(PQ);nhr=r(y3t,"BeitForSemanticSegmentation"),y3t.forEach(t),shr=r(_Be," (BEiT model)"),_Be.forEach(t),lhr=i(_6),xM=n(_6,"LI",{});var bBe=s(xM);Lbe=n(bBe,"STRONG",{});var x3t=s(Lbe);ihr=r(x3t,"data2vec-vision"),x3t.forEach(t),dhr=r(bBe," \u2014 "),BQ=n(bBe,"A",{href:!0});var $3t=s(BQ);chr=r($3t,"Data2VecVisionForSemanticSegmentation"),$3t.forEach(t),fhr=r(bBe," (Data2VecVision model)"),bBe.forEach(t),mhr=i(_6),$M=n(_6,"LI",{});var vBe=s($M);ybe=n(vBe,"STRONG",{});var k3t=s(ybe);ghr=r(k3t,"dpt"),k3t.forEach(t),hhr=r(vBe," \u2014 "),IQ=n(vBe,"A",{href:!0});var S3t=s(IQ);phr=r(S3t,"DPTForSemanticSegmentation"),S3t.forEach(t),uhr=r(vBe," (DPT model)"),vBe.forEach(t),_hr=i(_6),kM=n(_6,"LI",{});var FBe=s(kM);xbe=n(FBe,"STRONG",{});var R3t=s(xbe);bhr=r(R3t,"segformer"),R3t.forEach(t),vhr=r(FBe," \u2014 "),NQ=n(FBe,"A",{href:!0});var P3t=s(NQ);Fhr=r(P3t,"SegformerForSemanticSegmentation"),P3t.forEach(t),Thr=r(FBe," (SegFormer model)"),FBe.forEach(t),_6.forEach(t),Mhr=i(Aa),SM=n(Aa,"P",{});var TBe=s(SM);Ehr=r(TBe,"The model is set in evaluation mode by default using "),$be=n(TBe,"CODE",{});var B3t=s($be);Chr=r(B3t,"model.eval()"),B3t.forEach(t),whr=r(TBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kbe=n(TBe,"CODE",{});var I3t=s(kbe);Ahr=r(I3t,"model.train()"),I3t.forEach(t),TBe.forEach(t),Lhr=i(Aa),T(RM.$$.fragment,Aa),Aa.forEach(t),Fl.forEach(t),vOe=i(f),Jd=n(f,"H2",{class:!0});var LXe=s(Jd);PM=n(LXe,"A",{id:!0,class:!0,href:!0});var N3t=s(PM);Sbe=n(N3t,"SPAN",{});var q3t=s(Sbe);T(a9.$$.fragment,q3t),q3t.forEach(t),N3t.forEach(t),yhr=i(LXe),Rbe=n(LXe,"SPAN",{});var j3t=s(Rbe);xhr=r(j3t,"AutoModelForInstanceSegmentation"),j3t.forEach(t),LXe.forEach(t),FOe=i(f),Ko=n(f,"DIV",{class:!0});var Tl=s(Ko);T(n9.$$.fragment,Tl),$hr=i(Tl),Yd=n(Tl,"P",{});var Koe=s(Yd);khr=r(Koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),qQ=n(Koe,"A",{href:!0});var D3t=s(qQ);Shr=r(D3t,"from_pretrained()"),D3t.forEach(t),Rhr=r(Koe," class method or the "),jQ=n(Koe,"A",{href:!0});var G3t=s(jQ);Phr=r(G3t,"from_config()"),G3t.forEach(t),Bhr=r(Koe,` class
method.`),Koe.forEach(t),Ihr=i(Tl),s9=n(Tl,"P",{});var yXe=s(s9);Nhr=r(yXe,"This class cannot be instantiated directly using "),Pbe=n(yXe,"CODE",{});var O3t=s(Pbe);qhr=r(O3t,"__init__()"),O3t.forEach(t),jhr=r(yXe," (throws an error)."),yXe.forEach(t),Dhr=i(Tl),xt=n(Tl,"DIV",{class:!0});var b6=s(xt);T(l9.$$.fragment,b6),Ghr=i(b6),Bbe=n(b6,"P",{});var V3t=s(Bbe);Ohr=r(V3t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),V3t.forEach(t),Vhr=i(b6),Kd=n(b6,"P",{});var Zoe=s(Kd);Xhr=r(Zoe,`Note:
Loading a model from its configuration file does `),Ibe=n(Zoe,"STRONG",{});var X3t=s(Ibe);zhr=r(X3t,"not"),X3t.forEach(t),Whr=r(Zoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=n(Zoe,"A",{href:!0});var z3t=s(DQ);Qhr=r(z3t,"from_pretrained()"),z3t.forEach(t),Hhr=r(Zoe," to load the model weights."),Zoe.forEach(t),Uhr=i(b6),T(BM.$$.fragment,b6),b6.forEach(t),Jhr=i(Tl),Fo=n(Tl,"DIV",{class:!0});var La=s(Fo);T(i9.$$.fragment,La),Yhr=i(La),Nbe=n(La,"P",{});var W3t=s(Nbe);Khr=r(W3t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),W3t.forEach(t),Zhr=i(La),rn=n(La,"P",{});var v6=s(rn);epr=r(v6,"The model class to instantiate is selected based on the "),qbe=n(v6,"CODE",{});var Q3t=s(qbe);opr=r(Q3t,"model_type"),Q3t.forEach(t),rpr=r(v6,` property of the config object (either
passed as an argument or loaded from `),jbe=n(v6,"CODE",{});var H3t=s(jbe);tpr=r(H3t,"pretrained_model_name_or_path"),H3t.forEach(t),apr=r(v6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dbe=n(v6,"CODE",{});var U3t=s(Dbe);npr=r(U3t,"pretrained_model_name_or_path"),U3t.forEach(t),spr=r(v6,":"),v6.forEach(t),lpr=i(La),Gbe=n(La,"UL",{});var J3t=s(Gbe);IM=n(J3t,"LI",{});var MBe=s(IM);Obe=n(MBe,"STRONG",{});var Y3t=s(Obe);ipr=r(Y3t,"maskformer"),Y3t.forEach(t),dpr=r(MBe," \u2014 "),GQ=n(MBe,"A",{href:!0});var K3t=s(GQ);cpr=r(K3t,"MaskFormerForInstanceSegmentation"),K3t.forEach(t),fpr=r(MBe," (MaskFormer model)"),MBe.forEach(t),J3t.forEach(t),mpr=i(La),NM=n(La,"P",{});var EBe=s(NM);gpr=r(EBe,"The model is set in evaluation mode by default using "),Vbe=n(EBe,"CODE",{});var Z3t=s(Vbe);hpr=r(Z3t,"model.eval()"),Z3t.forEach(t),ppr=r(EBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xbe=n(EBe,"CODE",{});var e0t=s(Xbe);upr=r(e0t,"model.train()"),e0t.forEach(t),EBe.forEach(t),_pr=i(La),T(qM.$$.fragment,La),La.forEach(t),Tl.forEach(t),TOe=i(f),Zd=n(f,"H2",{class:!0});var xXe=s(Zd);jM=n(xXe,"A",{id:!0,class:!0,href:!0});var o0t=s(jM);zbe=n(o0t,"SPAN",{});var r0t=s(zbe);T(d9.$$.fragment,r0t),r0t.forEach(t),o0t.forEach(t),bpr=i(xXe),Wbe=n(xXe,"SPAN",{});var t0t=s(Wbe);vpr=r(t0t,"TFAutoModel"),t0t.forEach(t),xXe.forEach(t),MOe=i(f),Zo=n(f,"DIV",{class:!0});var Ml=s(Zo);T(c9.$$.fragment,Ml),Fpr=i(Ml),ec=n(Ml,"P",{});var ere=s(ec);Tpr=r(ere,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),OQ=n(ere,"A",{href:!0});var a0t=s(OQ);Mpr=r(a0t,"from_pretrained()"),a0t.forEach(t),Epr=r(ere," class method or the "),VQ=n(ere,"A",{href:!0});var n0t=s(VQ);Cpr=r(n0t,"from_config()"),n0t.forEach(t),wpr=r(ere,` class
method.`),ere.forEach(t),Apr=i(Ml),f9=n(Ml,"P",{});var $Xe=s(f9);Lpr=r($Xe,"This class cannot be instantiated directly using "),Qbe=n($Xe,"CODE",{});var s0t=s(Qbe);ypr=r(s0t,"__init__()"),s0t.forEach(t),xpr=r($Xe," (throws an error)."),$Xe.forEach(t),$pr=i(Ml),$t=n(Ml,"DIV",{class:!0});var F6=s($t);T(m9.$$.fragment,F6),kpr=i(F6),Hbe=n(F6,"P",{});var l0t=s(Hbe);Spr=r(l0t,"Instantiates one of the base model classes of the library from a configuration."),l0t.forEach(t),Rpr=i(F6),oc=n(F6,"P",{});var ore=s(oc);Ppr=r(ore,`Note:
Loading a model from its configuration file does `),Ube=n(ore,"STRONG",{});var i0t=s(Ube);Bpr=r(i0t,"not"),i0t.forEach(t),Ipr=r(ore,` load the model weights. It only affects the
model\u2019s configuration. Use `),XQ=n(ore,"A",{href:!0});var d0t=s(XQ);Npr=r(d0t,"from_pretrained()"),d0t.forEach(t),qpr=r(ore," to load the model weights."),ore.forEach(t),jpr=i(F6),T(DM.$$.fragment,F6),F6.forEach(t),Dpr=i(Ml),Lr=n(Ml,"DIV",{class:!0});var El=s(Lr);T(g9.$$.fragment,El),Gpr=i(El),Jbe=n(El,"P",{});var c0t=s(Jbe);Opr=r(c0t,"Instantiate one of the base model classes of the library from a pretrained model."),c0t.forEach(t),Vpr=i(El),tn=n(El,"P",{});var T6=s(tn);Xpr=r(T6,"The model class to instantiate is selected based on the "),Ybe=n(T6,"CODE",{});var f0t=s(Ybe);zpr=r(f0t,"model_type"),f0t.forEach(t),Wpr=r(T6,` property of the config object (either
passed as an argument or loaded from `),Kbe=n(T6,"CODE",{});var m0t=s(Kbe);Qpr=r(m0t,"pretrained_model_name_or_path"),m0t.forEach(t),Hpr=r(T6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zbe=n(T6,"CODE",{});var g0t=s(Zbe);Upr=r(g0t,"pretrained_model_name_or_path"),g0t.forEach(t),Jpr=r(T6,":"),T6.forEach(t),Ypr=i(El),q=n(El,"UL",{});var D=s(q);GM=n(D,"LI",{});var CBe=s(GM);eve=n(CBe,"STRONG",{});var h0t=s(eve);Kpr=r(h0t,"albert"),h0t.forEach(t),Zpr=r(CBe," \u2014 "),zQ=n(CBe,"A",{href:!0});var p0t=s(zQ);eur=r(p0t,"TFAlbertModel"),p0t.forEach(t),our=r(CBe," (ALBERT model)"),CBe.forEach(t),rur=i(D),OM=n(D,"LI",{});var wBe=s(OM);ove=n(wBe,"STRONG",{});var u0t=s(ove);tur=r(u0t,"bart"),u0t.forEach(t),aur=r(wBe," \u2014 "),WQ=n(wBe,"A",{href:!0});var _0t=s(WQ);nur=r(_0t,"TFBartModel"),_0t.forEach(t),sur=r(wBe," (BART model)"),wBe.forEach(t),lur=i(D),VM=n(D,"LI",{});var ABe=s(VM);rve=n(ABe,"STRONG",{});var b0t=s(rve);iur=r(b0t,"bert"),b0t.forEach(t),dur=r(ABe," \u2014 "),QQ=n(ABe,"A",{href:!0});var v0t=s(QQ);cur=r(v0t,"TFBertModel"),v0t.forEach(t),fur=r(ABe," (BERT model)"),ABe.forEach(t),mur=i(D),XM=n(D,"LI",{});var LBe=s(XM);tve=n(LBe,"STRONG",{});var F0t=s(tve);gur=r(F0t,"blenderbot"),F0t.forEach(t),hur=r(LBe," \u2014 "),HQ=n(LBe,"A",{href:!0});var T0t=s(HQ);pur=r(T0t,"TFBlenderbotModel"),T0t.forEach(t),uur=r(LBe," (Blenderbot model)"),LBe.forEach(t),_ur=i(D),zM=n(D,"LI",{});var yBe=s(zM);ave=n(yBe,"STRONG",{});var M0t=s(ave);bur=r(M0t,"blenderbot-small"),M0t.forEach(t),vur=r(yBe," \u2014 "),UQ=n(yBe,"A",{href:!0});var E0t=s(UQ);Fur=r(E0t,"TFBlenderbotSmallModel"),E0t.forEach(t),Tur=r(yBe," (BlenderbotSmall model)"),yBe.forEach(t),Mur=i(D),WM=n(D,"LI",{});var xBe=s(WM);nve=n(xBe,"STRONG",{});var C0t=s(nve);Eur=r(C0t,"camembert"),C0t.forEach(t),Cur=r(xBe," \u2014 "),JQ=n(xBe,"A",{href:!0});var w0t=s(JQ);wur=r(w0t,"TFCamembertModel"),w0t.forEach(t),Aur=r(xBe," (CamemBERT model)"),xBe.forEach(t),Lur=i(D),QM=n(D,"LI",{});var $Be=s(QM);sve=n($Be,"STRONG",{});var A0t=s(sve);yur=r(A0t,"clip"),A0t.forEach(t),xur=r($Be," \u2014 "),YQ=n($Be,"A",{href:!0});var L0t=s(YQ);$ur=r(L0t,"TFCLIPModel"),L0t.forEach(t),kur=r($Be," (CLIP model)"),$Be.forEach(t),Sur=i(D),HM=n(D,"LI",{});var kBe=s(HM);lve=n(kBe,"STRONG",{});var y0t=s(lve);Rur=r(y0t,"convbert"),y0t.forEach(t),Pur=r(kBe," \u2014 "),KQ=n(kBe,"A",{href:!0});var x0t=s(KQ);Bur=r(x0t,"TFConvBertModel"),x0t.forEach(t),Iur=r(kBe," (ConvBERT model)"),kBe.forEach(t),Nur=i(D),UM=n(D,"LI",{});var SBe=s(UM);ive=n(SBe,"STRONG",{});var $0t=s(ive);qur=r($0t,"convnext"),$0t.forEach(t),jur=r(SBe," \u2014 "),ZQ=n(SBe,"A",{href:!0});var k0t=s(ZQ);Dur=r(k0t,"TFConvNextModel"),k0t.forEach(t),Gur=r(SBe," (ConvNeXT model)"),SBe.forEach(t),Our=i(D),JM=n(D,"LI",{});var RBe=s(JM);dve=n(RBe,"STRONG",{});var S0t=s(dve);Vur=r(S0t,"ctrl"),S0t.forEach(t),Xur=r(RBe," \u2014 "),eH=n(RBe,"A",{href:!0});var R0t=s(eH);zur=r(R0t,"TFCTRLModel"),R0t.forEach(t),Wur=r(RBe," (CTRL model)"),RBe.forEach(t),Qur=i(D),YM=n(D,"LI",{});var PBe=s(YM);cve=n(PBe,"STRONG",{});var P0t=s(cve);Hur=r(P0t,"data2vec-vision"),P0t.forEach(t),Uur=r(PBe," \u2014 "),oH=n(PBe,"A",{href:!0});var B0t=s(oH);Jur=r(B0t,"TFData2VecVisionModel"),B0t.forEach(t),Yur=r(PBe," (Data2VecVision model)"),PBe.forEach(t),Kur=i(D),KM=n(D,"LI",{});var BBe=s(KM);fve=n(BBe,"STRONG",{});var I0t=s(fve);Zur=r(I0t,"deberta"),I0t.forEach(t),e_r=r(BBe," \u2014 "),rH=n(BBe,"A",{href:!0});var N0t=s(rH);o_r=r(N0t,"TFDebertaModel"),N0t.forEach(t),r_r=r(BBe," (DeBERTa model)"),BBe.forEach(t),t_r=i(D),ZM=n(D,"LI",{});var IBe=s(ZM);mve=n(IBe,"STRONG",{});var q0t=s(mve);a_r=r(q0t,"deberta-v2"),q0t.forEach(t),n_r=r(IBe," \u2014 "),tH=n(IBe,"A",{href:!0});var j0t=s(tH);s_r=r(j0t,"TFDebertaV2Model"),j0t.forEach(t),l_r=r(IBe," (DeBERTa-v2 model)"),IBe.forEach(t),i_r=i(D),eE=n(D,"LI",{});var NBe=s(eE);gve=n(NBe,"STRONG",{});var D0t=s(gve);d_r=r(D0t,"distilbert"),D0t.forEach(t),c_r=r(NBe," \u2014 "),aH=n(NBe,"A",{href:!0});var G0t=s(aH);f_r=r(G0t,"TFDistilBertModel"),G0t.forEach(t),m_r=r(NBe," (DistilBERT model)"),NBe.forEach(t),g_r=i(D),oE=n(D,"LI",{});var qBe=s(oE);hve=n(qBe,"STRONG",{});var O0t=s(hve);h_r=r(O0t,"dpr"),O0t.forEach(t),p_r=r(qBe," \u2014 "),nH=n(qBe,"A",{href:!0});var V0t=s(nH);u_r=r(V0t,"TFDPRQuestionEncoder"),V0t.forEach(t),__r=r(qBe," (DPR model)"),qBe.forEach(t),b_r=i(D),rE=n(D,"LI",{});var jBe=s(rE);pve=n(jBe,"STRONG",{});var X0t=s(pve);v_r=r(X0t,"electra"),X0t.forEach(t),F_r=r(jBe," \u2014 "),sH=n(jBe,"A",{href:!0});var z0t=s(sH);T_r=r(z0t,"TFElectraModel"),z0t.forEach(t),M_r=r(jBe," (ELECTRA model)"),jBe.forEach(t),E_r=i(D),tE=n(D,"LI",{});var DBe=s(tE);uve=n(DBe,"STRONG",{});var W0t=s(uve);C_r=r(W0t,"flaubert"),W0t.forEach(t),w_r=r(DBe," \u2014 "),lH=n(DBe,"A",{href:!0});var Q0t=s(lH);A_r=r(Q0t,"TFFlaubertModel"),Q0t.forEach(t),L_r=r(DBe," (FlauBERT model)"),DBe.forEach(t),y_r=i(D),Xs=n(D,"LI",{});var Hk=s(Xs);_ve=n(Hk,"STRONG",{});var H0t=s(_ve);x_r=r(H0t,"funnel"),H0t.forEach(t),$_r=r(Hk," \u2014 "),iH=n(Hk,"A",{href:!0});var U0t=s(iH);k_r=r(U0t,"TFFunnelModel"),U0t.forEach(t),S_r=r(Hk," or "),dH=n(Hk,"A",{href:!0});var J0t=s(dH);R_r=r(J0t,"TFFunnelBaseModel"),J0t.forEach(t),P_r=r(Hk," (Funnel Transformer model)"),Hk.forEach(t),B_r=i(D),aE=n(D,"LI",{});var GBe=s(aE);bve=n(GBe,"STRONG",{});var Y0t=s(bve);I_r=r(Y0t,"gpt2"),Y0t.forEach(t),N_r=r(GBe," \u2014 "),cH=n(GBe,"A",{href:!0});var K0t=s(cH);q_r=r(K0t,"TFGPT2Model"),K0t.forEach(t),j_r=r(GBe," (OpenAI GPT-2 model)"),GBe.forEach(t),D_r=i(D),nE=n(D,"LI",{});var OBe=s(nE);vve=n(OBe,"STRONG",{});var Z0t=s(vve);G_r=r(Z0t,"gptj"),Z0t.forEach(t),O_r=r(OBe," \u2014 "),fH=n(OBe,"A",{href:!0});var ewt=s(fH);V_r=r(ewt,"TFGPTJModel"),ewt.forEach(t),X_r=r(OBe," (GPT-J model)"),OBe.forEach(t),z_r=i(D),sE=n(D,"LI",{});var VBe=s(sE);Fve=n(VBe,"STRONG",{});var owt=s(Fve);W_r=r(owt,"hubert"),owt.forEach(t),Q_r=r(VBe," \u2014 "),mH=n(VBe,"A",{href:!0});var rwt=s(mH);H_r=r(rwt,"TFHubertModel"),rwt.forEach(t),U_r=r(VBe," (Hubert model)"),VBe.forEach(t),J_r=i(D),lE=n(D,"LI",{});var XBe=s(lE);Tve=n(XBe,"STRONG",{});var twt=s(Tve);Y_r=r(twt,"layoutlm"),twt.forEach(t),K_r=r(XBe," \u2014 "),gH=n(XBe,"A",{href:!0});var awt=s(gH);Z_r=r(awt,"TFLayoutLMModel"),awt.forEach(t),e7r=r(XBe," (LayoutLM model)"),XBe.forEach(t),o7r=i(D),iE=n(D,"LI",{});var zBe=s(iE);Mve=n(zBe,"STRONG",{});var nwt=s(Mve);r7r=r(nwt,"led"),nwt.forEach(t),t7r=r(zBe," \u2014 "),hH=n(zBe,"A",{href:!0});var swt=s(hH);a7r=r(swt,"TFLEDModel"),swt.forEach(t),n7r=r(zBe," (LED model)"),zBe.forEach(t),s7r=i(D),dE=n(D,"LI",{});var WBe=s(dE);Eve=n(WBe,"STRONG",{});var lwt=s(Eve);l7r=r(lwt,"longformer"),lwt.forEach(t),i7r=r(WBe," \u2014 "),pH=n(WBe,"A",{href:!0});var iwt=s(pH);d7r=r(iwt,"TFLongformerModel"),iwt.forEach(t),c7r=r(WBe," (Longformer model)"),WBe.forEach(t),f7r=i(D),cE=n(D,"LI",{});var QBe=s(cE);Cve=n(QBe,"STRONG",{});var dwt=s(Cve);m7r=r(dwt,"lxmert"),dwt.forEach(t),g7r=r(QBe," \u2014 "),uH=n(QBe,"A",{href:!0});var cwt=s(uH);h7r=r(cwt,"TFLxmertModel"),cwt.forEach(t),p7r=r(QBe," (LXMERT model)"),QBe.forEach(t),u7r=i(D),fE=n(D,"LI",{});var HBe=s(fE);wve=n(HBe,"STRONG",{});var fwt=s(wve);_7r=r(fwt,"marian"),fwt.forEach(t),b7r=r(HBe," \u2014 "),_H=n(HBe,"A",{href:!0});var mwt=s(_H);v7r=r(mwt,"TFMarianModel"),mwt.forEach(t),F7r=r(HBe," (Marian model)"),HBe.forEach(t),T7r=i(D),mE=n(D,"LI",{});var UBe=s(mE);Ave=n(UBe,"STRONG",{});var gwt=s(Ave);M7r=r(gwt,"mbart"),gwt.forEach(t),E7r=r(UBe," \u2014 "),bH=n(UBe,"A",{href:!0});var hwt=s(bH);C7r=r(hwt,"TFMBartModel"),hwt.forEach(t),w7r=r(UBe," (mBART model)"),UBe.forEach(t),A7r=i(D),gE=n(D,"LI",{});var JBe=s(gE);Lve=n(JBe,"STRONG",{});var pwt=s(Lve);L7r=r(pwt,"mobilebert"),pwt.forEach(t),y7r=r(JBe," \u2014 "),vH=n(JBe,"A",{href:!0});var uwt=s(vH);x7r=r(uwt,"TFMobileBertModel"),uwt.forEach(t),$7r=r(JBe," (MobileBERT model)"),JBe.forEach(t),k7r=i(D),hE=n(D,"LI",{});var YBe=s(hE);yve=n(YBe,"STRONG",{});var _wt=s(yve);S7r=r(_wt,"mpnet"),_wt.forEach(t),R7r=r(YBe," \u2014 "),FH=n(YBe,"A",{href:!0});var bwt=s(FH);P7r=r(bwt,"TFMPNetModel"),bwt.forEach(t),B7r=r(YBe," (MPNet model)"),YBe.forEach(t),I7r=i(D),pE=n(D,"LI",{});var KBe=s(pE);xve=n(KBe,"STRONG",{});var vwt=s(xve);N7r=r(vwt,"mt5"),vwt.forEach(t),q7r=r(KBe," \u2014 "),TH=n(KBe,"A",{href:!0});var Fwt=s(TH);j7r=r(Fwt,"TFMT5Model"),Fwt.forEach(t),D7r=r(KBe," (MT5 model)"),KBe.forEach(t),G7r=i(D),uE=n(D,"LI",{});var ZBe=s(uE);$ve=n(ZBe,"STRONG",{});var Twt=s($ve);O7r=r(Twt,"openai-gpt"),Twt.forEach(t),V7r=r(ZBe," \u2014 "),MH=n(ZBe,"A",{href:!0});var Mwt=s(MH);X7r=r(Mwt,"TFOpenAIGPTModel"),Mwt.forEach(t),z7r=r(ZBe," (OpenAI GPT model)"),ZBe.forEach(t),W7r=i(D),_E=n(D,"LI",{});var eIe=s(_E);kve=n(eIe,"STRONG",{});var Ewt=s(kve);Q7r=r(Ewt,"opt"),Ewt.forEach(t),H7r=r(eIe," \u2014 "),EH=n(eIe,"A",{href:!0});var Cwt=s(EH);U7r=r(Cwt,"TFOPTModel"),Cwt.forEach(t),J7r=r(eIe," (OPT model)"),eIe.forEach(t),Y7r=i(D),bE=n(D,"LI",{});var oIe=s(bE);Sve=n(oIe,"STRONG",{});var wwt=s(Sve);K7r=r(wwt,"pegasus"),wwt.forEach(t),Z7r=r(oIe," \u2014 "),CH=n(oIe,"A",{href:!0});var Awt=s(CH);e2r=r(Awt,"TFPegasusModel"),Awt.forEach(t),o2r=r(oIe," (Pegasus model)"),oIe.forEach(t),r2r=i(D),vE=n(D,"LI",{});var rIe=s(vE);Rve=n(rIe,"STRONG",{});var Lwt=s(Rve);t2r=r(Lwt,"rembert"),Lwt.forEach(t),a2r=r(rIe," \u2014 "),wH=n(rIe,"A",{href:!0});var ywt=s(wH);n2r=r(ywt,"TFRemBertModel"),ywt.forEach(t),s2r=r(rIe," (RemBERT model)"),rIe.forEach(t),l2r=i(D),FE=n(D,"LI",{});var tIe=s(FE);Pve=n(tIe,"STRONG",{});var xwt=s(Pve);i2r=r(xwt,"roberta"),xwt.forEach(t),d2r=r(tIe," \u2014 "),AH=n(tIe,"A",{href:!0});var $wt=s(AH);c2r=r($wt,"TFRobertaModel"),$wt.forEach(t),f2r=r(tIe," (RoBERTa model)"),tIe.forEach(t),m2r=i(D),TE=n(D,"LI",{});var aIe=s(TE);Bve=n(aIe,"STRONG",{});var kwt=s(Bve);g2r=r(kwt,"roformer"),kwt.forEach(t),h2r=r(aIe," \u2014 "),LH=n(aIe,"A",{href:!0});var Swt=s(LH);p2r=r(Swt,"TFRoFormerModel"),Swt.forEach(t),u2r=r(aIe," (RoFormer model)"),aIe.forEach(t),_2r=i(D),ME=n(D,"LI",{});var nIe=s(ME);Ive=n(nIe,"STRONG",{});var Rwt=s(Ive);b2r=r(Rwt,"speech_to_text"),Rwt.forEach(t),v2r=r(nIe," \u2014 "),yH=n(nIe,"A",{href:!0});var Pwt=s(yH);F2r=r(Pwt,"TFSpeech2TextModel"),Pwt.forEach(t),T2r=r(nIe," (Speech2Text model)"),nIe.forEach(t),M2r=i(D),EE=n(D,"LI",{});var sIe=s(EE);Nve=n(sIe,"STRONG",{});var Bwt=s(Nve);E2r=r(Bwt,"swin"),Bwt.forEach(t),C2r=r(sIe," \u2014 "),xH=n(sIe,"A",{href:!0});var Iwt=s(xH);w2r=r(Iwt,"TFSwinModel"),Iwt.forEach(t),A2r=r(sIe," (Swin Transformer model)"),sIe.forEach(t),L2r=i(D),CE=n(D,"LI",{});var lIe=s(CE);qve=n(lIe,"STRONG",{});var Nwt=s(qve);y2r=r(Nwt,"t5"),Nwt.forEach(t),x2r=r(lIe," \u2014 "),$H=n(lIe,"A",{href:!0});var qwt=s($H);$2r=r(qwt,"TFT5Model"),qwt.forEach(t),k2r=r(lIe," (T5 model)"),lIe.forEach(t),S2r=i(D),wE=n(D,"LI",{});var iIe=s(wE);jve=n(iIe,"STRONG",{});var jwt=s(jve);R2r=r(jwt,"tapas"),jwt.forEach(t),P2r=r(iIe," \u2014 "),kH=n(iIe,"A",{href:!0});var Dwt=s(kH);B2r=r(Dwt,"TFTapasModel"),Dwt.forEach(t),I2r=r(iIe," (TAPAS model)"),iIe.forEach(t),N2r=i(D),AE=n(D,"LI",{});var dIe=s(AE);Dve=n(dIe,"STRONG",{});var Gwt=s(Dve);q2r=r(Gwt,"transfo-xl"),Gwt.forEach(t),j2r=r(dIe," \u2014 "),SH=n(dIe,"A",{href:!0});var Owt=s(SH);D2r=r(Owt,"TFTransfoXLModel"),Owt.forEach(t),G2r=r(dIe," (Transformer-XL model)"),dIe.forEach(t),O2r=i(D),LE=n(D,"LI",{});var cIe=s(LE);Gve=n(cIe,"STRONG",{});var Vwt=s(Gve);V2r=r(Vwt,"vit"),Vwt.forEach(t),X2r=r(cIe," \u2014 "),RH=n(cIe,"A",{href:!0});var Xwt=s(RH);z2r=r(Xwt,"TFViTModel"),Xwt.forEach(t),W2r=r(cIe," (ViT model)"),cIe.forEach(t),Q2r=i(D),yE=n(D,"LI",{});var fIe=s(yE);Ove=n(fIe,"STRONG",{});var zwt=s(Ove);H2r=r(zwt,"vit_mae"),zwt.forEach(t),U2r=r(fIe," \u2014 "),PH=n(fIe,"A",{href:!0});var Wwt=s(PH);J2r=r(Wwt,"TFViTMAEModel"),Wwt.forEach(t),Y2r=r(fIe," (ViTMAE model)"),fIe.forEach(t),K2r=i(D),xE=n(D,"LI",{});var mIe=s(xE);Vve=n(mIe,"STRONG",{});var Qwt=s(Vve);Z2r=r(Qwt,"wav2vec2"),Qwt.forEach(t),e1r=r(mIe," \u2014 "),BH=n(mIe,"A",{href:!0});var Hwt=s(BH);o1r=r(Hwt,"TFWav2Vec2Model"),Hwt.forEach(t),r1r=r(mIe," (Wav2Vec2 model)"),mIe.forEach(t),t1r=i(D),$E=n(D,"LI",{});var gIe=s($E);Xve=n(gIe,"STRONG",{});var Uwt=s(Xve);a1r=r(Uwt,"xlm"),Uwt.forEach(t),n1r=r(gIe," \u2014 "),IH=n(gIe,"A",{href:!0});var Jwt=s(IH);s1r=r(Jwt,"TFXLMModel"),Jwt.forEach(t),l1r=r(gIe," (XLM model)"),gIe.forEach(t),i1r=i(D),kE=n(D,"LI",{});var hIe=s(kE);zve=n(hIe,"STRONG",{});var Ywt=s(zve);d1r=r(Ywt,"xlm-roberta"),Ywt.forEach(t),c1r=r(hIe," \u2014 "),NH=n(hIe,"A",{href:!0});var Kwt=s(NH);f1r=r(Kwt,"TFXLMRobertaModel"),Kwt.forEach(t),m1r=r(hIe," (XLM-RoBERTa model)"),hIe.forEach(t),g1r=i(D),SE=n(D,"LI",{});var pIe=s(SE);Wve=n(pIe,"STRONG",{});var Zwt=s(Wve);h1r=r(Zwt,"xlnet"),Zwt.forEach(t),p1r=r(pIe," \u2014 "),qH=n(pIe,"A",{href:!0});var eAt=s(qH);u1r=r(eAt,"TFXLNetModel"),eAt.forEach(t),_1r=r(pIe," (XLNet model)"),pIe.forEach(t),D.forEach(t),b1r=i(El),T(RE.$$.fragment,El),El.forEach(t),Ml.forEach(t),EOe=i(f),rc=n(f,"H2",{class:!0});var kXe=s(rc);PE=n(kXe,"A",{id:!0,class:!0,href:!0});var oAt=s(PE);Qve=n(oAt,"SPAN",{});var rAt=s(Qve);T(h9.$$.fragment,rAt),rAt.forEach(t),oAt.forEach(t),v1r=i(kXe),Hve=n(kXe,"SPAN",{});var tAt=s(Hve);F1r=r(tAt,"TFAutoModelForPreTraining"),tAt.forEach(t),kXe.forEach(t),COe=i(f),er=n(f,"DIV",{class:!0});var Cl=s(er);T(p9.$$.fragment,Cl),T1r=i(Cl),tc=n(Cl,"P",{});var rre=s(tc);M1r=r(rre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),jH=n(rre,"A",{href:!0});var aAt=s(jH);E1r=r(aAt,"from_pretrained()"),aAt.forEach(t),C1r=r(rre," class method or the "),DH=n(rre,"A",{href:!0});var nAt=s(DH);w1r=r(nAt,"from_config()"),nAt.forEach(t),A1r=r(rre,` class
method.`),rre.forEach(t),L1r=i(Cl),u9=n(Cl,"P",{});var SXe=s(u9);y1r=r(SXe,"This class cannot be instantiated directly using "),Uve=n(SXe,"CODE",{});var sAt=s(Uve);x1r=r(sAt,"__init__()"),sAt.forEach(t),$1r=r(SXe," (throws an error)."),SXe.forEach(t),k1r=i(Cl),kt=n(Cl,"DIV",{class:!0});var M6=s(kt);T(_9.$$.fragment,M6),S1r=i(M6),Jve=n(M6,"P",{});var lAt=s(Jve);R1r=r(lAt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),lAt.forEach(t),P1r=i(M6),ac=n(M6,"P",{});var tre=s(ac);B1r=r(tre,`Note:
Loading a model from its configuration file does `),Yve=n(tre,"STRONG",{});var iAt=s(Yve);I1r=r(iAt,"not"),iAt.forEach(t),N1r=r(tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),GH=n(tre,"A",{href:!0});var dAt=s(GH);q1r=r(dAt,"from_pretrained()"),dAt.forEach(t),j1r=r(tre," to load the model weights."),tre.forEach(t),D1r=i(M6),T(BE.$$.fragment,M6),M6.forEach(t),G1r=i(Cl),yr=n(Cl,"DIV",{class:!0});var wl=s(yr);T(b9.$$.fragment,wl),O1r=i(wl),Kve=n(wl,"P",{});var cAt=s(Kve);V1r=r(cAt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),cAt.forEach(t),X1r=i(wl),an=n(wl,"P",{});var E6=s(an);z1r=r(E6,"The model class to instantiate is selected based on the "),Zve=n(E6,"CODE",{});var fAt=s(Zve);W1r=r(fAt,"model_type"),fAt.forEach(t),Q1r=r(E6,` property of the config object (either
passed as an argument or loaded from `),eFe=n(E6,"CODE",{});var mAt=s(eFe);H1r=r(mAt,"pretrained_model_name_or_path"),mAt.forEach(t),U1r=r(E6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oFe=n(E6,"CODE",{});var gAt=s(oFe);J1r=r(gAt,"pretrained_model_name_or_path"),gAt.forEach(t),Y1r=r(E6,":"),E6.forEach(t),K1r=i(wl),se=n(wl,"UL",{});var le=s(se);IE=n(le,"LI",{});var uIe=s(IE);rFe=n(uIe,"STRONG",{});var hAt=s(rFe);Z1r=r(hAt,"albert"),hAt.forEach(t),ebr=r(uIe," \u2014 "),OH=n(uIe,"A",{href:!0});var pAt=s(OH);obr=r(pAt,"TFAlbertForPreTraining"),pAt.forEach(t),rbr=r(uIe," (ALBERT model)"),uIe.forEach(t),tbr=i(le),NE=n(le,"LI",{});var _Ie=s(NE);tFe=n(_Ie,"STRONG",{});var uAt=s(tFe);abr=r(uAt,"bart"),uAt.forEach(t),nbr=r(_Ie," \u2014 "),VH=n(_Ie,"A",{href:!0});var _At=s(VH);sbr=r(_At,"TFBartForConditionalGeneration"),_At.forEach(t),lbr=r(_Ie," (BART model)"),_Ie.forEach(t),ibr=i(le),qE=n(le,"LI",{});var bIe=s(qE);aFe=n(bIe,"STRONG",{});var bAt=s(aFe);dbr=r(bAt,"bert"),bAt.forEach(t),cbr=r(bIe," \u2014 "),XH=n(bIe,"A",{href:!0});var vAt=s(XH);fbr=r(vAt,"TFBertForPreTraining"),vAt.forEach(t),mbr=r(bIe," (BERT model)"),bIe.forEach(t),gbr=i(le),jE=n(le,"LI",{});var vIe=s(jE);nFe=n(vIe,"STRONG",{});var FAt=s(nFe);hbr=r(FAt,"camembert"),FAt.forEach(t),pbr=r(vIe," \u2014 "),zH=n(vIe,"A",{href:!0});var TAt=s(zH);ubr=r(TAt,"TFCamembertForMaskedLM"),TAt.forEach(t),_br=r(vIe," (CamemBERT model)"),vIe.forEach(t),bbr=i(le),DE=n(le,"LI",{});var FIe=s(DE);sFe=n(FIe,"STRONG",{});var MAt=s(sFe);vbr=r(MAt,"ctrl"),MAt.forEach(t),Fbr=r(FIe," \u2014 "),WH=n(FIe,"A",{href:!0});var EAt=s(WH);Tbr=r(EAt,"TFCTRLLMHeadModel"),EAt.forEach(t),Mbr=r(FIe," (CTRL model)"),FIe.forEach(t),Ebr=i(le),GE=n(le,"LI",{});var TIe=s(GE);lFe=n(TIe,"STRONG",{});var CAt=s(lFe);Cbr=r(CAt,"distilbert"),CAt.forEach(t),wbr=r(TIe," \u2014 "),QH=n(TIe,"A",{href:!0});var wAt=s(QH);Abr=r(wAt,"TFDistilBertForMaskedLM"),wAt.forEach(t),Lbr=r(TIe," (DistilBERT model)"),TIe.forEach(t),ybr=i(le),OE=n(le,"LI",{});var MIe=s(OE);iFe=n(MIe,"STRONG",{});var AAt=s(iFe);xbr=r(AAt,"electra"),AAt.forEach(t),$br=r(MIe," \u2014 "),HH=n(MIe,"A",{href:!0});var LAt=s(HH);kbr=r(LAt,"TFElectraForPreTraining"),LAt.forEach(t),Sbr=r(MIe," (ELECTRA model)"),MIe.forEach(t),Rbr=i(le),VE=n(le,"LI",{});var EIe=s(VE);dFe=n(EIe,"STRONG",{});var yAt=s(dFe);Pbr=r(yAt,"flaubert"),yAt.forEach(t),Bbr=r(EIe," \u2014 "),UH=n(EIe,"A",{href:!0});var xAt=s(UH);Ibr=r(xAt,"TFFlaubertWithLMHeadModel"),xAt.forEach(t),Nbr=r(EIe," (FlauBERT model)"),EIe.forEach(t),qbr=i(le),XE=n(le,"LI",{});var CIe=s(XE);cFe=n(CIe,"STRONG",{});var $At=s(cFe);jbr=r($At,"funnel"),$At.forEach(t),Dbr=r(CIe," \u2014 "),JH=n(CIe,"A",{href:!0});var kAt=s(JH);Gbr=r(kAt,"TFFunnelForPreTraining"),kAt.forEach(t),Obr=r(CIe," (Funnel Transformer model)"),CIe.forEach(t),Vbr=i(le),zE=n(le,"LI",{});var wIe=s(zE);fFe=n(wIe,"STRONG",{});var SAt=s(fFe);Xbr=r(SAt,"gpt2"),SAt.forEach(t),zbr=r(wIe," \u2014 "),YH=n(wIe,"A",{href:!0});var RAt=s(YH);Wbr=r(RAt,"TFGPT2LMHeadModel"),RAt.forEach(t),Qbr=r(wIe," (OpenAI GPT-2 model)"),wIe.forEach(t),Hbr=i(le),WE=n(le,"LI",{});var AIe=s(WE);mFe=n(AIe,"STRONG",{});var PAt=s(mFe);Ubr=r(PAt,"layoutlm"),PAt.forEach(t),Jbr=r(AIe," \u2014 "),KH=n(AIe,"A",{href:!0});var BAt=s(KH);Ybr=r(BAt,"TFLayoutLMForMaskedLM"),BAt.forEach(t),Kbr=r(AIe," (LayoutLM model)"),AIe.forEach(t),Zbr=i(le),QE=n(le,"LI",{});var LIe=s(QE);gFe=n(LIe,"STRONG",{});var IAt=s(gFe);evr=r(IAt,"lxmert"),IAt.forEach(t),ovr=r(LIe," \u2014 "),ZH=n(LIe,"A",{href:!0});var NAt=s(ZH);rvr=r(NAt,"TFLxmertForPreTraining"),NAt.forEach(t),tvr=r(LIe," (LXMERT model)"),LIe.forEach(t),avr=i(le),HE=n(le,"LI",{});var yIe=s(HE);hFe=n(yIe,"STRONG",{});var qAt=s(hFe);nvr=r(qAt,"mobilebert"),qAt.forEach(t),svr=r(yIe," \u2014 "),eU=n(yIe,"A",{href:!0});var jAt=s(eU);lvr=r(jAt,"TFMobileBertForPreTraining"),jAt.forEach(t),ivr=r(yIe," (MobileBERT model)"),yIe.forEach(t),dvr=i(le),UE=n(le,"LI",{});var xIe=s(UE);pFe=n(xIe,"STRONG",{});var DAt=s(pFe);cvr=r(DAt,"mpnet"),DAt.forEach(t),fvr=r(xIe," \u2014 "),oU=n(xIe,"A",{href:!0});var GAt=s(oU);mvr=r(GAt,"TFMPNetForMaskedLM"),GAt.forEach(t),gvr=r(xIe," (MPNet model)"),xIe.forEach(t),hvr=i(le),JE=n(le,"LI",{});var $Ie=s(JE);uFe=n($Ie,"STRONG",{});var OAt=s(uFe);pvr=r(OAt,"openai-gpt"),OAt.forEach(t),uvr=r($Ie," \u2014 "),rU=n($Ie,"A",{href:!0});var VAt=s(rU);_vr=r(VAt,"TFOpenAIGPTLMHeadModel"),VAt.forEach(t),bvr=r($Ie," (OpenAI GPT model)"),$Ie.forEach(t),vvr=i(le),YE=n(le,"LI",{});var kIe=s(YE);_Fe=n(kIe,"STRONG",{});var XAt=s(_Fe);Fvr=r(XAt,"roberta"),XAt.forEach(t),Tvr=r(kIe," \u2014 "),tU=n(kIe,"A",{href:!0});var zAt=s(tU);Mvr=r(zAt,"TFRobertaForMaskedLM"),zAt.forEach(t),Evr=r(kIe," (RoBERTa model)"),kIe.forEach(t),Cvr=i(le),KE=n(le,"LI",{});var SIe=s(KE);bFe=n(SIe,"STRONG",{});var WAt=s(bFe);wvr=r(WAt,"t5"),WAt.forEach(t),Avr=r(SIe," \u2014 "),aU=n(SIe,"A",{href:!0});var QAt=s(aU);Lvr=r(QAt,"TFT5ForConditionalGeneration"),QAt.forEach(t),yvr=r(SIe," (T5 model)"),SIe.forEach(t),xvr=i(le),ZE=n(le,"LI",{});var RIe=s(ZE);vFe=n(RIe,"STRONG",{});var HAt=s(vFe);$vr=r(HAt,"tapas"),HAt.forEach(t),kvr=r(RIe," \u2014 "),nU=n(RIe,"A",{href:!0});var UAt=s(nU);Svr=r(UAt,"TFTapasForMaskedLM"),UAt.forEach(t),Rvr=r(RIe," (TAPAS model)"),RIe.forEach(t),Pvr=i(le),e4=n(le,"LI",{});var PIe=s(e4);FFe=n(PIe,"STRONG",{});var JAt=s(FFe);Bvr=r(JAt,"transfo-xl"),JAt.forEach(t),Ivr=r(PIe," \u2014 "),sU=n(PIe,"A",{href:!0});var YAt=s(sU);Nvr=r(YAt,"TFTransfoXLLMHeadModel"),YAt.forEach(t),qvr=r(PIe," (Transformer-XL model)"),PIe.forEach(t),jvr=i(le),o4=n(le,"LI",{});var BIe=s(o4);TFe=n(BIe,"STRONG",{});var KAt=s(TFe);Dvr=r(KAt,"vit_mae"),KAt.forEach(t),Gvr=r(BIe," \u2014 "),lU=n(BIe,"A",{href:!0});var ZAt=s(lU);Ovr=r(ZAt,"TFViTMAEForPreTraining"),ZAt.forEach(t),Vvr=r(BIe," (ViTMAE model)"),BIe.forEach(t),Xvr=i(le),r4=n(le,"LI",{});var IIe=s(r4);MFe=n(IIe,"STRONG",{});var e6t=s(MFe);zvr=r(e6t,"xlm"),e6t.forEach(t),Wvr=r(IIe," \u2014 "),iU=n(IIe,"A",{href:!0});var o6t=s(iU);Qvr=r(o6t,"TFXLMWithLMHeadModel"),o6t.forEach(t),Hvr=r(IIe," (XLM model)"),IIe.forEach(t),Uvr=i(le),t4=n(le,"LI",{});var NIe=s(t4);EFe=n(NIe,"STRONG",{});var r6t=s(EFe);Jvr=r(r6t,"xlm-roberta"),r6t.forEach(t),Yvr=r(NIe," \u2014 "),dU=n(NIe,"A",{href:!0});var t6t=s(dU);Kvr=r(t6t,"TFXLMRobertaForMaskedLM"),t6t.forEach(t),Zvr=r(NIe," (XLM-RoBERTa model)"),NIe.forEach(t),eFr=i(le),a4=n(le,"LI",{});var qIe=s(a4);CFe=n(qIe,"STRONG",{});var a6t=s(CFe);oFr=r(a6t,"xlnet"),a6t.forEach(t),rFr=r(qIe," \u2014 "),cU=n(qIe,"A",{href:!0});var n6t=s(cU);tFr=r(n6t,"TFXLNetLMHeadModel"),n6t.forEach(t),aFr=r(qIe," (XLNet model)"),qIe.forEach(t),le.forEach(t),nFr=i(wl),T(n4.$$.fragment,wl),wl.forEach(t),Cl.forEach(t),wOe=i(f),nc=n(f,"H2",{class:!0});var RXe=s(nc);s4=n(RXe,"A",{id:!0,class:!0,href:!0});var s6t=s(s4);wFe=n(s6t,"SPAN",{});var l6t=s(wFe);T(v9.$$.fragment,l6t),l6t.forEach(t),s6t.forEach(t),sFr=i(RXe),AFe=n(RXe,"SPAN",{});var i6t=s(AFe);lFr=r(i6t,"TFAutoModelForCausalLM"),i6t.forEach(t),RXe.forEach(t),AOe=i(f),or=n(f,"DIV",{class:!0});var Al=s(or);T(F9.$$.fragment,Al),iFr=i(Al),sc=n(Al,"P",{});var are=s(sc);dFr=r(are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),fU=n(are,"A",{href:!0});var d6t=s(fU);cFr=r(d6t,"from_pretrained()"),d6t.forEach(t),fFr=r(are," class method or the "),mU=n(are,"A",{href:!0});var c6t=s(mU);mFr=r(c6t,"from_config()"),c6t.forEach(t),gFr=r(are,` class
method.`),are.forEach(t),hFr=i(Al),T9=n(Al,"P",{});var PXe=s(T9);pFr=r(PXe,"This class cannot be instantiated directly using "),LFe=n(PXe,"CODE",{});var f6t=s(LFe);uFr=r(f6t,"__init__()"),f6t.forEach(t),_Fr=r(PXe," (throws an error)."),PXe.forEach(t),bFr=i(Al),St=n(Al,"DIV",{class:!0});var C6=s(St);T(M9.$$.fragment,C6),vFr=i(C6),yFe=n(C6,"P",{});var m6t=s(yFe);FFr=r(m6t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),m6t.forEach(t),TFr=i(C6),lc=n(C6,"P",{});var nre=s(lc);MFr=r(nre,`Note:
Loading a model from its configuration file does `),xFe=n(nre,"STRONG",{});var g6t=s(xFe);EFr=r(g6t,"not"),g6t.forEach(t),CFr=r(nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),gU=n(nre,"A",{href:!0});var h6t=s(gU);wFr=r(h6t,"from_pretrained()"),h6t.forEach(t),AFr=r(nre," to load the model weights."),nre.forEach(t),LFr=i(C6),T(l4.$$.fragment,C6),C6.forEach(t),yFr=i(Al),xr=n(Al,"DIV",{class:!0});var Ll=s(xr);T(E9.$$.fragment,Ll),xFr=i(Ll),$Fe=n(Ll,"P",{});var p6t=s($Fe);$Fr=r(p6t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),p6t.forEach(t),kFr=i(Ll),nn=n(Ll,"P",{});var w6=s(nn);SFr=r(w6,"The model class to instantiate is selected based on the "),kFe=n(w6,"CODE",{});var u6t=s(kFe);RFr=r(u6t,"model_type"),u6t.forEach(t),PFr=r(w6,` property of the config object (either
passed as an argument or loaded from `),SFe=n(w6,"CODE",{});var _6t=s(SFe);BFr=r(_6t,"pretrained_model_name_or_path"),_6t.forEach(t),IFr=r(w6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RFe=n(w6,"CODE",{});var b6t=s(RFe);NFr=r(b6t,"pretrained_model_name_or_path"),b6t.forEach(t),qFr=r(w6,":"),w6.forEach(t),jFr=i(Ll),Me=n(Ll,"UL",{});var Ce=s(Me);i4=n(Ce,"LI",{});var jIe=s(i4);PFe=n(jIe,"STRONG",{});var v6t=s(PFe);DFr=r(v6t,"bert"),v6t.forEach(t),GFr=r(jIe," \u2014 "),hU=n(jIe,"A",{href:!0});var F6t=s(hU);OFr=r(F6t,"TFBertLMHeadModel"),F6t.forEach(t),VFr=r(jIe," (BERT model)"),jIe.forEach(t),XFr=i(Ce),d4=n(Ce,"LI",{});var DIe=s(d4);BFe=n(DIe,"STRONG",{});var T6t=s(BFe);zFr=r(T6t,"camembert"),T6t.forEach(t),WFr=r(DIe," \u2014 "),pU=n(DIe,"A",{href:!0});var M6t=s(pU);QFr=r(M6t,"TFCamembertForCausalLM"),M6t.forEach(t),HFr=r(DIe," (CamemBERT model)"),DIe.forEach(t),UFr=i(Ce),c4=n(Ce,"LI",{});var GIe=s(c4);IFe=n(GIe,"STRONG",{});var E6t=s(IFe);JFr=r(E6t,"ctrl"),E6t.forEach(t),YFr=r(GIe," \u2014 "),uU=n(GIe,"A",{href:!0});var C6t=s(uU);KFr=r(C6t,"TFCTRLLMHeadModel"),C6t.forEach(t),ZFr=r(GIe," (CTRL model)"),GIe.forEach(t),eTr=i(Ce),f4=n(Ce,"LI",{});var OIe=s(f4);NFe=n(OIe,"STRONG",{});var w6t=s(NFe);oTr=r(w6t,"gpt2"),w6t.forEach(t),rTr=r(OIe," \u2014 "),_U=n(OIe,"A",{href:!0});var A6t=s(_U);tTr=r(A6t,"TFGPT2LMHeadModel"),A6t.forEach(t),aTr=r(OIe," (OpenAI GPT-2 model)"),OIe.forEach(t),nTr=i(Ce),m4=n(Ce,"LI",{});var VIe=s(m4);qFe=n(VIe,"STRONG",{});var L6t=s(qFe);sTr=r(L6t,"gptj"),L6t.forEach(t),lTr=r(VIe," \u2014 "),bU=n(VIe,"A",{href:!0});var y6t=s(bU);iTr=r(y6t,"TFGPTJForCausalLM"),y6t.forEach(t),dTr=r(VIe," (GPT-J model)"),VIe.forEach(t),cTr=i(Ce),g4=n(Ce,"LI",{});var XIe=s(g4);jFe=n(XIe,"STRONG",{});var x6t=s(jFe);fTr=r(x6t,"openai-gpt"),x6t.forEach(t),mTr=r(XIe," \u2014 "),vU=n(XIe,"A",{href:!0});var $6t=s(vU);gTr=r($6t,"TFOpenAIGPTLMHeadModel"),$6t.forEach(t),hTr=r(XIe," (OpenAI GPT model)"),XIe.forEach(t),pTr=i(Ce),h4=n(Ce,"LI",{});var zIe=s(h4);DFe=n(zIe,"STRONG",{});var k6t=s(DFe);uTr=r(k6t,"opt"),k6t.forEach(t),_Tr=r(zIe," \u2014 "),FU=n(zIe,"A",{href:!0});var S6t=s(FU);bTr=r(S6t,"TFOPTForCausalLM"),S6t.forEach(t),vTr=r(zIe," (OPT model)"),zIe.forEach(t),FTr=i(Ce),p4=n(Ce,"LI",{});var WIe=s(p4);GFe=n(WIe,"STRONG",{});var R6t=s(GFe);TTr=r(R6t,"rembert"),R6t.forEach(t),MTr=r(WIe," \u2014 "),TU=n(WIe,"A",{href:!0});var P6t=s(TU);ETr=r(P6t,"TFRemBertForCausalLM"),P6t.forEach(t),CTr=r(WIe," (RemBERT model)"),WIe.forEach(t),wTr=i(Ce),u4=n(Ce,"LI",{});var QIe=s(u4);OFe=n(QIe,"STRONG",{});var B6t=s(OFe);ATr=r(B6t,"roberta"),B6t.forEach(t),LTr=r(QIe," \u2014 "),MU=n(QIe,"A",{href:!0});var I6t=s(MU);yTr=r(I6t,"TFRobertaForCausalLM"),I6t.forEach(t),xTr=r(QIe," (RoBERTa model)"),QIe.forEach(t),$Tr=i(Ce),_4=n(Ce,"LI",{});var HIe=s(_4);VFe=n(HIe,"STRONG",{});var N6t=s(VFe);kTr=r(N6t,"roformer"),N6t.forEach(t),STr=r(HIe," \u2014 "),EU=n(HIe,"A",{href:!0});var q6t=s(EU);RTr=r(q6t,"TFRoFormerForCausalLM"),q6t.forEach(t),PTr=r(HIe," (RoFormer model)"),HIe.forEach(t),BTr=i(Ce),b4=n(Ce,"LI",{});var UIe=s(b4);XFe=n(UIe,"STRONG",{});var j6t=s(XFe);ITr=r(j6t,"transfo-xl"),j6t.forEach(t),NTr=r(UIe," \u2014 "),CU=n(UIe,"A",{href:!0});var D6t=s(CU);qTr=r(D6t,"TFTransfoXLLMHeadModel"),D6t.forEach(t),jTr=r(UIe," (Transformer-XL model)"),UIe.forEach(t),DTr=i(Ce),v4=n(Ce,"LI",{});var JIe=s(v4);zFe=n(JIe,"STRONG",{});var G6t=s(zFe);GTr=r(G6t,"xlm"),G6t.forEach(t),OTr=r(JIe," \u2014 "),wU=n(JIe,"A",{href:!0});var O6t=s(wU);VTr=r(O6t,"TFXLMWithLMHeadModel"),O6t.forEach(t),XTr=r(JIe," (XLM model)"),JIe.forEach(t),zTr=i(Ce),F4=n(Ce,"LI",{});var YIe=s(F4);WFe=n(YIe,"STRONG",{});var V6t=s(WFe);WTr=r(V6t,"xlnet"),V6t.forEach(t),QTr=r(YIe," \u2014 "),AU=n(YIe,"A",{href:!0});var X6t=s(AU);HTr=r(X6t,"TFXLNetLMHeadModel"),X6t.forEach(t),UTr=r(YIe," (XLNet model)"),YIe.forEach(t),Ce.forEach(t),JTr=i(Ll),T(T4.$$.fragment,Ll),Ll.forEach(t),Al.forEach(t),LOe=i(f),ic=n(f,"H2",{class:!0});var BXe=s(ic);M4=n(BXe,"A",{id:!0,class:!0,href:!0});var z6t=s(M4);QFe=n(z6t,"SPAN",{});var W6t=s(QFe);T(C9.$$.fragment,W6t),W6t.forEach(t),z6t.forEach(t),YTr=i(BXe),HFe=n(BXe,"SPAN",{});var Q6t=s(HFe);KTr=r(Q6t,"TFAutoModelForImageClassification"),Q6t.forEach(t),BXe.forEach(t),yOe=i(f),rr=n(f,"DIV",{class:!0});var yl=s(rr);T(w9.$$.fragment,yl),ZTr=i(yl),dc=n(yl,"P",{});var sre=s(dc);eMr=r(sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),LU=n(sre,"A",{href:!0});var H6t=s(LU);oMr=r(H6t,"from_pretrained()"),H6t.forEach(t),rMr=r(sre," class method or the "),yU=n(sre,"A",{href:!0});var U6t=s(yU);tMr=r(U6t,"from_config()"),U6t.forEach(t),aMr=r(sre,` class
method.`),sre.forEach(t),nMr=i(yl),A9=n(yl,"P",{});var IXe=s(A9);sMr=r(IXe,"This class cannot be instantiated directly using "),UFe=n(IXe,"CODE",{});var J6t=s(UFe);lMr=r(J6t,"__init__()"),J6t.forEach(t),iMr=r(IXe," (throws an error)."),IXe.forEach(t),dMr=i(yl),Rt=n(yl,"DIV",{class:!0});var A6=s(Rt);T(L9.$$.fragment,A6),cMr=i(A6),JFe=n(A6,"P",{});var Y6t=s(JFe);fMr=r(Y6t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Y6t.forEach(t),mMr=i(A6),cc=n(A6,"P",{});var lre=s(cc);gMr=r(lre,`Note:
Loading a model from its configuration file does `),YFe=n(lre,"STRONG",{});var K6t=s(YFe);hMr=r(K6t,"not"),K6t.forEach(t),pMr=r(lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=n(lre,"A",{href:!0});var Z6t=s(xU);uMr=r(Z6t,"from_pretrained()"),Z6t.forEach(t),_Mr=r(lre," to load the model weights."),lre.forEach(t),bMr=i(A6),T(E4.$$.fragment,A6),A6.forEach(t),vMr=i(yl),$r=n(yl,"DIV",{class:!0});var xl=s($r);T(y9.$$.fragment,xl),FMr=i(xl),KFe=n(xl,"P",{});var eLt=s(KFe);TMr=r(eLt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),eLt.forEach(t),MMr=i(xl),sn=n(xl,"P",{});var L6=s(sn);EMr=r(L6,"The model class to instantiate is selected based on the "),ZFe=n(L6,"CODE",{});var oLt=s(ZFe);CMr=r(oLt,"model_type"),oLt.forEach(t),wMr=r(L6,` property of the config object (either
passed as an argument or loaded from `),eTe=n(L6,"CODE",{});var rLt=s(eTe);AMr=r(rLt,"pretrained_model_name_or_path"),rLt.forEach(t),LMr=r(L6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oTe=n(L6,"CODE",{});var tLt=s(oTe);yMr=r(tLt,"pretrained_model_name_or_path"),tLt.forEach(t),xMr=r(L6,":"),L6.forEach(t),$Mr=i(xl),ln=n(xl,"UL",{});var y6=s(ln);C4=n(y6,"LI",{});var KIe=s(C4);rTe=n(KIe,"STRONG",{});var aLt=s(rTe);kMr=r(aLt,"convnext"),aLt.forEach(t),SMr=r(KIe," \u2014 "),$U=n(KIe,"A",{href:!0});var nLt=s($U);RMr=r(nLt,"TFConvNextForImageClassification"),nLt.forEach(t),PMr=r(KIe," (ConvNeXT model)"),KIe.forEach(t),BMr=i(y6),w4=n(y6,"LI",{});var ZIe=s(w4);tTe=n(ZIe,"STRONG",{});var sLt=s(tTe);IMr=r(sLt,"data2vec-vision"),sLt.forEach(t),NMr=r(ZIe," \u2014 "),kU=n(ZIe,"A",{href:!0});var lLt=s(kU);qMr=r(lLt,"TFData2VecVisionForImageClassification"),lLt.forEach(t),jMr=r(ZIe," (Data2VecVision model)"),ZIe.forEach(t),DMr=i(y6),A4=n(y6,"LI",{});var eNe=s(A4);aTe=n(eNe,"STRONG",{});var iLt=s(aTe);GMr=r(iLt,"swin"),iLt.forEach(t),OMr=r(eNe," \u2014 "),SU=n(eNe,"A",{href:!0});var dLt=s(SU);VMr=r(dLt,"TFSwinForImageClassification"),dLt.forEach(t),XMr=r(eNe," (Swin Transformer model)"),eNe.forEach(t),zMr=i(y6),L4=n(y6,"LI",{});var oNe=s(L4);nTe=n(oNe,"STRONG",{});var cLt=s(nTe);WMr=r(cLt,"vit"),cLt.forEach(t),QMr=r(oNe," \u2014 "),RU=n(oNe,"A",{href:!0});var fLt=s(RU);HMr=r(fLt,"TFViTForImageClassification"),fLt.forEach(t),UMr=r(oNe," (ViT model)"),oNe.forEach(t),y6.forEach(t),JMr=i(xl),T(y4.$$.fragment,xl),xl.forEach(t),yl.forEach(t),xOe=i(f),fc=n(f,"H2",{class:!0});var NXe=s(fc);x4=n(NXe,"A",{id:!0,class:!0,href:!0});var mLt=s(x4);sTe=n(mLt,"SPAN",{});var gLt=s(sTe);T(x9.$$.fragment,gLt),gLt.forEach(t),mLt.forEach(t),YMr=i(NXe),lTe=n(NXe,"SPAN",{});var hLt=s(lTe);KMr=r(hLt,"TFAutoModelForMaskedLM"),hLt.forEach(t),NXe.forEach(t),$Oe=i(f),tr=n(f,"DIV",{class:!0});var $l=s(tr);T($9.$$.fragment,$l),ZMr=i($l),mc=n($l,"P",{});var ire=s(mc);eEr=r(ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PU=n(ire,"A",{href:!0});var pLt=s(PU);oEr=r(pLt,"from_pretrained()"),pLt.forEach(t),rEr=r(ire," class method or the "),BU=n(ire,"A",{href:!0});var uLt=s(BU);tEr=r(uLt,"from_config()"),uLt.forEach(t),aEr=r(ire,` class
method.`),ire.forEach(t),nEr=i($l),k9=n($l,"P",{});var qXe=s(k9);sEr=r(qXe,"This class cannot be instantiated directly using "),iTe=n(qXe,"CODE",{});var _Lt=s(iTe);lEr=r(_Lt,"__init__()"),_Lt.forEach(t),iEr=r(qXe," (throws an error)."),qXe.forEach(t),dEr=i($l),Pt=n($l,"DIV",{class:!0});var x6=s(Pt);T(S9.$$.fragment,x6),cEr=i(x6),dTe=n(x6,"P",{});var bLt=s(dTe);fEr=r(bLt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),bLt.forEach(t),mEr=i(x6),gc=n(x6,"P",{});var dre=s(gc);gEr=r(dre,`Note:
Loading a model from its configuration file does `),cTe=n(dre,"STRONG",{});var vLt=s(cTe);hEr=r(vLt,"not"),vLt.forEach(t),pEr=r(dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IU=n(dre,"A",{href:!0});var FLt=s(IU);uEr=r(FLt,"from_pretrained()"),FLt.forEach(t),_Er=r(dre," to load the model weights."),dre.forEach(t),bEr=i(x6),T($4.$$.fragment,x6),x6.forEach(t),vEr=i($l),kr=n($l,"DIV",{class:!0});var kl=s(kr);T(R9.$$.fragment,kl),FEr=i(kl),fTe=n(kl,"P",{});var TLt=s(fTe);TEr=r(TLt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),TLt.forEach(t),MEr=i(kl),dn=n(kl,"P",{});var $6=s(dn);EEr=r($6,"The model class to instantiate is selected based on the "),mTe=n($6,"CODE",{});var MLt=s(mTe);CEr=r(MLt,"model_type"),MLt.forEach(t),wEr=r($6,` property of the config object (either
passed as an argument or loaded from `),gTe=n($6,"CODE",{});var ELt=s(gTe);AEr=r(ELt,"pretrained_model_name_or_path"),ELt.forEach(t),LEr=r($6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hTe=n($6,"CODE",{});var CLt=s(hTe);yEr=r(CLt,"pretrained_model_name_or_path"),CLt.forEach(t),xEr=r($6,":"),$6.forEach(t),$Er=i(kl),ie=n(kl,"UL",{});var fe=s(ie);k4=n(fe,"LI",{});var rNe=s(k4);pTe=n(rNe,"STRONG",{});var wLt=s(pTe);kEr=r(wLt,"albert"),wLt.forEach(t),SEr=r(rNe," \u2014 "),NU=n(rNe,"A",{href:!0});var ALt=s(NU);REr=r(ALt,"TFAlbertForMaskedLM"),ALt.forEach(t),PEr=r(rNe," (ALBERT model)"),rNe.forEach(t),BEr=i(fe),S4=n(fe,"LI",{});var tNe=s(S4);uTe=n(tNe,"STRONG",{});var LLt=s(uTe);IEr=r(LLt,"bert"),LLt.forEach(t),NEr=r(tNe," \u2014 "),qU=n(tNe,"A",{href:!0});var yLt=s(qU);qEr=r(yLt,"TFBertForMaskedLM"),yLt.forEach(t),jEr=r(tNe," (BERT model)"),tNe.forEach(t),DEr=i(fe),R4=n(fe,"LI",{});var aNe=s(R4);_Te=n(aNe,"STRONG",{});var xLt=s(_Te);GEr=r(xLt,"camembert"),xLt.forEach(t),OEr=r(aNe," \u2014 "),jU=n(aNe,"A",{href:!0});var $Lt=s(jU);VEr=r($Lt,"TFCamembertForMaskedLM"),$Lt.forEach(t),XEr=r(aNe," (CamemBERT model)"),aNe.forEach(t),zEr=i(fe),P4=n(fe,"LI",{});var nNe=s(P4);bTe=n(nNe,"STRONG",{});var kLt=s(bTe);WEr=r(kLt,"convbert"),kLt.forEach(t),QEr=r(nNe," \u2014 "),DU=n(nNe,"A",{href:!0});var SLt=s(DU);HEr=r(SLt,"TFConvBertForMaskedLM"),SLt.forEach(t),UEr=r(nNe," (ConvBERT model)"),nNe.forEach(t),JEr=i(fe),B4=n(fe,"LI",{});var sNe=s(B4);vTe=n(sNe,"STRONG",{});var RLt=s(vTe);YEr=r(RLt,"deberta"),RLt.forEach(t),KEr=r(sNe," \u2014 "),GU=n(sNe,"A",{href:!0});var PLt=s(GU);ZEr=r(PLt,"TFDebertaForMaskedLM"),PLt.forEach(t),e4r=r(sNe," (DeBERTa model)"),sNe.forEach(t),o4r=i(fe),I4=n(fe,"LI",{});var lNe=s(I4);FTe=n(lNe,"STRONG",{});var BLt=s(FTe);r4r=r(BLt,"deberta-v2"),BLt.forEach(t),t4r=r(lNe," \u2014 "),OU=n(lNe,"A",{href:!0});var ILt=s(OU);a4r=r(ILt,"TFDebertaV2ForMaskedLM"),ILt.forEach(t),n4r=r(lNe," (DeBERTa-v2 model)"),lNe.forEach(t),s4r=i(fe),N4=n(fe,"LI",{});var iNe=s(N4);TTe=n(iNe,"STRONG",{});var NLt=s(TTe);l4r=r(NLt,"distilbert"),NLt.forEach(t),i4r=r(iNe," \u2014 "),VU=n(iNe,"A",{href:!0});var qLt=s(VU);d4r=r(qLt,"TFDistilBertForMaskedLM"),qLt.forEach(t),c4r=r(iNe," (DistilBERT model)"),iNe.forEach(t),f4r=i(fe),q4=n(fe,"LI",{});var dNe=s(q4);MTe=n(dNe,"STRONG",{});var jLt=s(MTe);m4r=r(jLt,"electra"),jLt.forEach(t),g4r=r(dNe," \u2014 "),XU=n(dNe,"A",{href:!0});var DLt=s(XU);h4r=r(DLt,"TFElectraForMaskedLM"),DLt.forEach(t),p4r=r(dNe," (ELECTRA model)"),dNe.forEach(t),u4r=i(fe),j4=n(fe,"LI",{});var cNe=s(j4);ETe=n(cNe,"STRONG",{});var GLt=s(ETe);_4r=r(GLt,"flaubert"),GLt.forEach(t),b4r=r(cNe," \u2014 "),zU=n(cNe,"A",{href:!0});var OLt=s(zU);v4r=r(OLt,"TFFlaubertWithLMHeadModel"),OLt.forEach(t),F4r=r(cNe," (FlauBERT model)"),cNe.forEach(t),T4r=i(fe),D4=n(fe,"LI",{});var fNe=s(D4);CTe=n(fNe,"STRONG",{});var VLt=s(CTe);M4r=r(VLt,"funnel"),VLt.forEach(t),E4r=r(fNe," \u2014 "),WU=n(fNe,"A",{href:!0});var XLt=s(WU);C4r=r(XLt,"TFFunnelForMaskedLM"),XLt.forEach(t),w4r=r(fNe," (Funnel Transformer model)"),fNe.forEach(t),A4r=i(fe),G4=n(fe,"LI",{});var mNe=s(G4);wTe=n(mNe,"STRONG",{});var zLt=s(wTe);L4r=r(zLt,"layoutlm"),zLt.forEach(t),y4r=r(mNe," \u2014 "),QU=n(mNe,"A",{href:!0});var WLt=s(QU);x4r=r(WLt,"TFLayoutLMForMaskedLM"),WLt.forEach(t),$4r=r(mNe," (LayoutLM model)"),mNe.forEach(t),k4r=i(fe),O4=n(fe,"LI",{});var gNe=s(O4);ATe=n(gNe,"STRONG",{});var QLt=s(ATe);S4r=r(QLt,"longformer"),QLt.forEach(t),R4r=r(gNe," \u2014 "),HU=n(gNe,"A",{href:!0});var HLt=s(HU);P4r=r(HLt,"TFLongformerForMaskedLM"),HLt.forEach(t),B4r=r(gNe," (Longformer model)"),gNe.forEach(t),I4r=i(fe),V4=n(fe,"LI",{});var hNe=s(V4);LTe=n(hNe,"STRONG",{});var ULt=s(LTe);N4r=r(ULt,"mobilebert"),ULt.forEach(t),q4r=r(hNe," \u2014 "),UU=n(hNe,"A",{href:!0});var JLt=s(UU);j4r=r(JLt,"TFMobileBertForMaskedLM"),JLt.forEach(t),D4r=r(hNe," (MobileBERT model)"),hNe.forEach(t),G4r=i(fe),X4=n(fe,"LI",{});var pNe=s(X4);yTe=n(pNe,"STRONG",{});var YLt=s(yTe);O4r=r(YLt,"mpnet"),YLt.forEach(t),V4r=r(pNe," \u2014 "),JU=n(pNe,"A",{href:!0});var KLt=s(JU);X4r=r(KLt,"TFMPNetForMaskedLM"),KLt.forEach(t),z4r=r(pNe," (MPNet model)"),pNe.forEach(t),W4r=i(fe),z4=n(fe,"LI",{});var uNe=s(z4);xTe=n(uNe,"STRONG",{});var ZLt=s(xTe);Q4r=r(ZLt,"rembert"),ZLt.forEach(t),H4r=r(uNe," \u2014 "),YU=n(uNe,"A",{href:!0});var eyt=s(YU);U4r=r(eyt,"TFRemBertForMaskedLM"),eyt.forEach(t),J4r=r(uNe," (RemBERT model)"),uNe.forEach(t),Y4r=i(fe),W4=n(fe,"LI",{});var _Ne=s(W4);$Te=n(_Ne,"STRONG",{});var oyt=s($Te);K4r=r(oyt,"roberta"),oyt.forEach(t),Z4r=r(_Ne," \u2014 "),KU=n(_Ne,"A",{href:!0});var ryt=s(KU);eCr=r(ryt,"TFRobertaForMaskedLM"),ryt.forEach(t),oCr=r(_Ne," (RoBERTa model)"),_Ne.forEach(t),rCr=i(fe),Q4=n(fe,"LI",{});var bNe=s(Q4);kTe=n(bNe,"STRONG",{});var tyt=s(kTe);tCr=r(tyt,"roformer"),tyt.forEach(t),aCr=r(bNe," \u2014 "),ZU=n(bNe,"A",{href:!0});var ayt=s(ZU);nCr=r(ayt,"TFRoFormerForMaskedLM"),ayt.forEach(t),sCr=r(bNe," (RoFormer model)"),bNe.forEach(t),lCr=i(fe),H4=n(fe,"LI",{});var vNe=s(H4);STe=n(vNe,"STRONG",{});var nyt=s(STe);iCr=r(nyt,"tapas"),nyt.forEach(t),dCr=r(vNe," \u2014 "),eJ=n(vNe,"A",{href:!0});var syt=s(eJ);cCr=r(syt,"TFTapasForMaskedLM"),syt.forEach(t),fCr=r(vNe," (TAPAS model)"),vNe.forEach(t),mCr=i(fe),U4=n(fe,"LI",{});var FNe=s(U4);RTe=n(FNe,"STRONG",{});var lyt=s(RTe);gCr=r(lyt,"xlm"),lyt.forEach(t),hCr=r(FNe," \u2014 "),oJ=n(FNe,"A",{href:!0});var iyt=s(oJ);pCr=r(iyt,"TFXLMWithLMHeadModel"),iyt.forEach(t),uCr=r(FNe," (XLM model)"),FNe.forEach(t),_Cr=i(fe),J4=n(fe,"LI",{});var TNe=s(J4);PTe=n(TNe,"STRONG",{});var dyt=s(PTe);bCr=r(dyt,"xlm-roberta"),dyt.forEach(t),vCr=r(TNe," \u2014 "),rJ=n(TNe,"A",{href:!0});var cyt=s(rJ);FCr=r(cyt,"TFXLMRobertaForMaskedLM"),cyt.forEach(t),TCr=r(TNe," (XLM-RoBERTa model)"),TNe.forEach(t),fe.forEach(t),MCr=i(kl),T(Y4.$$.fragment,kl),kl.forEach(t),$l.forEach(t),kOe=i(f),hc=n(f,"H2",{class:!0});var jXe=s(hc);K4=n(jXe,"A",{id:!0,class:!0,href:!0});var fyt=s(K4);BTe=n(fyt,"SPAN",{});var myt=s(BTe);T(P9.$$.fragment,myt),myt.forEach(t),fyt.forEach(t),ECr=i(jXe),ITe=n(jXe,"SPAN",{});var gyt=s(ITe);CCr=r(gyt,"TFAutoModelForSeq2SeqLM"),gyt.forEach(t),jXe.forEach(t),SOe=i(f),ar=n(f,"DIV",{class:!0});var Sl=s(ar);T(B9.$$.fragment,Sl),wCr=i(Sl),pc=n(Sl,"P",{});var cre=s(pc);ACr=r(cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tJ=n(cre,"A",{href:!0});var hyt=s(tJ);LCr=r(hyt,"from_pretrained()"),hyt.forEach(t),yCr=r(cre," class method or the "),aJ=n(cre,"A",{href:!0});var pyt=s(aJ);xCr=r(pyt,"from_config()"),pyt.forEach(t),$Cr=r(cre,` class
method.`),cre.forEach(t),kCr=i(Sl),I9=n(Sl,"P",{});var DXe=s(I9);SCr=r(DXe,"This class cannot be instantiated directly using "),NTe=n(DXe,"CODE",{});var uyt=s(NTe);RCr=r(uyt,"__init__()"),uyt.forEach(t),PCr=r(DXe," (throws an error)."),DXe.forEach(t),BCr=i(Sl),Bt=n(Sl,"DIV",{class:!0});var k6=s(Bt);T(N9.$$.fragment,k6),ICr=i(k6),qTe=n(k6,"P",{});var _yt=s(qTe);NCr=r(_yt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_yt.forEach(t),qCr=i(k6),uc=n(k6,"P",{});var fre=s(uc);jCr=r(fre,`Note:
Loading a model from its configuration file does `),jTe=n(fre,"STRONG",{});var byt=s(jTe);DCr=r(byt,"not"),byt.forEach(t),GCr=r(fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),nJ=n(fre,"A",{href:!0});var vyt=s(nJ);OCr=r(vyt,"from_pretrained()"),vyt.forEach(t),VCr=r(fre," to load the model weights."),fre.forEach(t),XCr=i(k6),T(Z4.$$.fragment,k6),k6.forEach(t),zCr=i(Sl),Sr=n(Sl,"DIV",{class:!0});var Rl=s(Sr);T(q9.$$.fragment,Rl),WCr=i(Rl),DTe=n(Rl,"P",{});var Fyt=s(DTe);QCr=r(Fyt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Fyt.forEach(t),HCr=i(Rl),cn=n(Rl,"P",{});var S6=s(cn);UCr=r(S6,"The model class to instantiate is selected based on the "),GTe=n(S6,"CODE",{});var Tyt=s(GTe);JCr=r(Tyt,"model_type"),Tyt.forEach(t),YCr=r(S6,` property of the config object (either
passed as an argument or loaded from `),OTe=n(S6,"CODE",{});var Myt=s(OTe);KCr=r(Myt,"pretrained_model_name_or_path"),Myt.forEach(t),ZCr=r(S6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VTe=n(S6,"CODE",{});var Eyt=s(VTe);e5r=r(Eyt,"pretrained_model_name_or_path"),Eyt.forEach(t),o5r=r(S6,":"),S6.forEach(t),r5r=i(Rl),ye=n(Rl,"UL",{});var Ie=s(ye);eC=n(Ie,"LI",{});var MNe=s(eC);XTe=n(MNe,"STRONG",{});var Cyt=s(XTe);t5r=r(Cyt,"bart"),Cyt.forEach(t),a5r=r(MNe," \u2014 "),sJ=n(MNe,"A",{href:!0});var wyt=s(sJ);n5r=r(wyt,"TFBartForConditionalGeneration"),wyt.forEach(t),s5r=r(MNe," (BART model)"),MNe.forEach(t),l5r=i(Ie),oC=n(Ie,"LI",{});var ENe=s(oC);zTe=n(ENe,"STRONG",{});var Ayt=s(zTe);i5r=r(Ayt,"blenderbot"),Ayt.forEach(t),d5r=r(ENe," \u2014 "),lJ=n(ENe,"A",{href:!0});var Lyt=s(lJ);c5r=r(Lyt,"TFBlenderbotForConditionalGeneration"),Lyt.forEach(t),f5r=r(ENe," (Blenderbot model)"),ENe.forEach(t),m5r=i(Ie),rC=n(Ie,"LI",{});var CNe=s(rC);WTe=n(CNe,"STRONG",{});var yyt=s(WTe);g5r=r(yyt,"blenderbot-small"),yyt.forEach(t),h5r=r(CNe," \u2014 "),iJ=n(CNe,"A",{href:!0});var xyt=s(iJ);p5r=r(xyt,"TFBlenderbotSmallForConditionalGeneration"),xyt.forEach(t),u5r=r(CNe," (BlenderbotSmall model)"),CNe.forEach(t),_5r=i(Ie),tC=n(Ie,"LI",{});var wNe=s(tC);QTe=n(wNe,"STRONG",{});var $yt=s(QTe);b5r=r($yt,"encoder-decoder"),$yt.forEach(t),v5r=r(wNe," \u2014 "),dJ=n(wNe,"A",{href:!0});var kyt=s(dJ);F5r=r(kyt,"TFEncoderDecoderModel"),kyt.forEach(t),T5r=r(wNe," (Encoder decoder model)"),wNe.forEach(t),M5r=i(Ie),aC=n(Ie,"LI",{});var ANe=s(aC);HTe=n(ANe,"STRONG",{});var Syt=s(HTe);E5r=r(Syt,"led"),Syt.forEach(t),C5r=r(ANe," \u2014 "),cJ=n(ANe,"A",{href:!0});var Ryt=s(cJ);w5r=r(Ryt,"TFLEDForConditionalGeneration"),Ryt.forEach(t),A5r=r(ANe," (LED model)"),ANe.forEach(t),L5r=i(Ie),nC=n(Ie,"LI",{});var LNe=s(nC);UTe=n(LNe,"STRONG",{});var Pyt=s(UTe);y5r=r(Pyt,"marian"),Pyt.forEach(t),x5r=r(LNe," \u2014 "),fJ=n(LNe,"A",{href:!0});var Byt=s(fJ);$5r=r(Byt,"TFMarianMTModel"),Byt.forEach(t),k5r=r(LNe," (Marian model)"),LNe.forEach(t),S5r=i(Ie),sC=n(Ie,"LI",{});var yNe=s(sC);JTe=n(yNe,"STRONG",{});var Iyt=s(JTe);R5r=r(Iyt,"mbart"),Iyt.forEach(t),P5r=r(yNe," \u2014 "),mJ=n(yNe,"A",{href:!0});var Nyt=s(mJ);B5r=r(Nyt,"TFMBartForConditionalGeneration"),Nyt.forEach(t),I5r=r(yNe," (mBART model)"),yNe.forEach(t),N5r=i(Ie),lC=n(Ie,"LI",{});var xNe=s(lC);YTe=n(xNe,"STRONG",{});var qyt=s(YTe);q5r=r(qyt,"mt5"),qyt.forEach(t),j5r=r(xNe," \u2014 "),gJ=n(xNe,"A",{href:!0});var jyt=s(gJ);D5r=r(jyt,"TFMT5ForConditionalGeneration"),jyt.forEach(t),G5r=r(xNe," (MT5 model)"),xNe.forEach(t),O5r=i(Ie),iC=n(Ie,"LI",{});var $Ne=s(iC);KTe=n($Ne,"STRONG",{});var Dyt=s(KTe);V5r=r(Dyt,"pegasus"),Dyt.forEach(t),X5r=r($Ne," \u2014 "),hJ=n($Ne,"A",{href:!0});var Gyt=s(hJ);z5r=r(Gyt,"TFPegasusForConditionalGeneration"),Gyt.forEach(t),W5r=r($Ne," (Pegasus model)"),$Ne.forEach(t),Q5r=i(Ie),dC=n(Ie,"LI",{});var kNe=s(dC);ZTe=n(kNe,"STRONG",{});var Oyt=s(ZTe);H5r=r(Oyt,"t5"),Oyt.forEach(t),U5r=r(kNe," \u2014 "),pJ=n(kNe,"A",{href:!0});var Vyt=s(pJ);J5r=r(Vyt,"TFT5ForConditionalGeneration"),Vyt.forEach(t),Y5r=r(kNe," (T5 model)"),kNe.forEach(t),Ie.forEach(t),K5r=i(Rl),T(cC.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),ROe=i(f),_c=n(f,"H2",{class:!0});var GXe=s(_c);fC=n(GXe,"A",{id:!0,class:!0,href:!0});var Xyt=s(fC);eMe=n(Xyt,"SPAN",{});var zyt=s(eMe);T(j9.$$.fragment,zyt),zyt.forEach(t),Xyt.forEach(t),Z5r=i(GXe),oMe=n(GXe,"SPAN",{});var Wyt=s(oMe);e3r=r(Wyt,"TFAutoModelForSequenceClassification"),Wyt.forEach(t),GXe.forEach(t),POe=i(f),nr=n(f,"DIV",{class:!0});var Pl=s(nr);T(D9.$$.fragment,Pl),o3r=i(Pl),bc=n(Pl,"P",{});var mre=s(bc);r3r=r(mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uJ=n(mre,"A",{href:!0});var Qyt=s(uJ);t3r=r(Qyt,"from_pretrained()"),Qyt.forEach(t),a3r=r(mre," class method or the "),_J=n(mre,"A",{href:!0});var Hyt=s(_J);n3r=r(Hyt,"from_config()"),Hyt.forEach(t),s3r=r(mre,` class
method.`),mre.forEach(t),l3r=i(Pl),G9=n(Pl,"P",{});var OXe=s(G9);i3r=r(OXe,"This class cannot be instantiated directly using "),rMe=n(OXe,"CODE",{});var Uyt=s(rMe);d3r=r(Uyt,"__init__()"),Uyt.forEach(t),c3r=r(OXe," (throws an error)."),OXe.forEach(t),f3r=i(Pl),It=n(Pl,"DIV",{class:!0});var R6=s(It);T(O9.$$.fragment,R6),m3r=i(R6),tMe=n(R6,"P",{});var Jyt=s(tMe);g3r=r(Jyt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Jyt.forEach(t),h3r=i(R6),vc=n(R6,"P",{});var gre=s(vc);p3r=r(gre,`Note:
Loading a model from its configuration file does `),aMe=n(gre,"STRONG",{});var Yyt=s(aMe);u3r=r(Yyt,"not"),Yyt.forEach(t),_3r=r(gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),bJ=n(gre,"A",{href:!0});var Kyt=s(bJ);b3r=r(Kyt,"from_pretrained()"),Kyt.forEach(t),v3r=r(gre," to load the model weights."),gre.forEach(t),F3r=i(R6),T(mC.$$.fragment,R6),R6.forEach(t),T3r=i(Pl),Rr=n(Pl,"DIV",{class:!0});var Bl=s(Rr);T(V9.$$.fragment,Bl),M3r=i(Bl),nMe=n(Bl,"P",{});var Zyt=s(nMe);E3r=r(Zyt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Zyt.forEach(t),C3r=i(Bl),fn=n(Bl,"P",{});var P6=s(fn);w3r=r(P6,"The model class to instantiate is selected based on the "),sMe=n(P6,"CODE",{});var e8t=s(sMe);A3r=r(e8t,"model_type"),e8t.forEach(t),L3r=r(P6,` property of the config object (either
passed as an argument or loaded from `),lMe=n(P6,"CODE",{});var o8t=s(lMe);y3r=r(o8t,"pretrained_model_name_or_path"),o8t.forEach(t),x3r=r(P6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iMe=n(P6,"CODE",{});var r8t=s(iMe);$3r=r(r8t,"pretrained_model_name_or_path"),r8t.forEach(t),k3r=r(P6,":"),P6.forEach(t),S3r=i(Bl),te=n(Bl,"UL",{});var ne=s(te);gC=n(ne,"LI",{});var SNe=s(gC);dMe=n(SNe,"STRONG",{});var t8t=s(dMe);R3r=r(t8t,"albert"),t8t.forEach(t),P3r=r(SNe," \u2014 "),vJ=n(SNe,"A",{href:!0});var a8t=s(vJ);B3r=r(a8t,"TFAlbertForSequenceClassification"),a8t.forEach(t),I3r=r(SNe," (ALBERT model)"),SNe.forEach(t),N3r=i(ne),hC=n(ne,"LI",{});var RNe=s(hC);cMe=n(RNe,"STRONG",{});var n8t=s(cMe);q3r=r(n8t,"bert"),n8t.forEach(t),j3r=r(RNe," \u2014 "),FJ=n(RNe,"A",{href:!0});var s8t=s(FJ);D3r=r(s8t,"TFBertForSequenceClassification"),s8t.forEach(t),G3r=r(RNe," (BERT model)"),RNe.forEach(t),O3r=i(ne),pC=n(ne,"LI",{});var PNe=s(pC);fMe=n(PNe,"STRONG",{});var l8t=s(fMe);V3r=r(l8t,"camembert"),l8t.forEach(t),X3r=r(PNe," \u2014 "),TJ=n(PNe,"A",{href:!0});var i8t=s(TJ);z3r=r(i8t,"TFCamembertForSequenceClassification"),i8t.forEach(t),W3r=r(PNe," (CamemBERT model)"),PNe.forEach(t),Q3r=i(ne),uC=n(ne,"LI",{});var BNe=s(uC);mMe=n(BNe,"STRONG",{});var d8t=s(mMe);H3r=r(d8t,"convbert"),d8t.forEach(t),U3r=r(BNe," \u2014 "),MJ=n(BNe,"A",{href:!0});var c8t=s(MJ);J3r=r(c8t,"TFConvBertForSequenceClassification"),c8t.forEach(t),Y3r=r(BNe," (ConvBERT model)"),BNe.forEach(t),K3r=i(ne),_C=n(ne,"LI",{});var INe=s(_C);gMe=n(INe,"STRONG",{});var f8t=s(gMe);Z3r=r(f8t,"ctrl"),f8t.forEach(t),e0r=r(INe," \u2014 "),EJ=n(INe,"A",{href:!0});var m8t=s(EJ);o0r=r(m8t,"TFCTRLForSequenceClassification"),m8t.forEach(t),r0r=r(INe," (CTRL model)"),INe.forEach(t),t0r=i(ne),bC=n(ne,"LI",{});var NNe=s(bC);hMe=n(NNe,"STRONG",{});var g8t=s(hMe);a0r=r(g8t,"deberta"),g8t.forEach(t),n0r=r(NNe," \u2014 "),CJ=n(NNe,"A",{href:!0});var h8t=s(CJ);s0r=r(h8t,"TFDebertaForSequenceClassification"),h8t.forEach(t),l0r=r(NNe," (DeBERTa model)"),NNe.forEach(t),i0r=i(ne),vC=n(ne,"LI",{});var qNe=s(vC);pMe=n(qNe,"STRONG",{});var p8t=s(pMe);d0r=r(p8t,"deberta-v2"),p8t.forEach(t),c0r=r(qNe," \u2014 "),wJ=n(qNe,"A",{href:!0});var u8t=s(wJ);f0r=r(u8t,"TFDebertaV2ForSequenceClassification"),u8t.forEach(t),m0r=r(qNe," (DeBERTa-v2 model)"),qNe.forEach(t),g0r=i(ne),FC=n(ne,"LI",{});var jNe=s(FC);uMe=n(jNe,"STRONG",{});var _8t=s(uMe);h0r=r(_8t,"distilbert"),_8t.forEach(t),p0r=r(jNe," \u2014 "),AJ=n(jNe,"A",{href:!0});var b8t=s(AJ);u0r=r(b8t,"TFDistilBertForSequenceClassification"),b8t.forEach(t),_0r=r(jNe," (DistilBERT model)"),jNe.forEach(t),b0r=i(ne),TC=n(ne,"LI",{});var DNe=s(TC);_Me=n(DNe,"STRONG",{});var v8t=s(_Me);v0r=r(v8t,"electra"),v8t.forEach(t),F0r=r(DNe," \u2014 "),LJ=n(DNe,"A",{href:!0});var F8t=s(LJ);T0r=r(F8t,"TFElectraForSequenceClassification"),F8t.forEach(t),M0r=r(DNe," (ELECTRA model)"),DNe.forEach(t),E0r=i(ne),MC=n(ne,"LI",{});var GNe=s(MC);bMe=n(GNe,"STRONG",{});var T8t=s(bMe);C0r=r(T8t,"flaubert"),T8t.forEach(t),w0r=r(GNe," \u2014 "),yJ=n(GNe,"A",{href:!0});var M8t=s(yJ);A0r=r(M8t,"TFFlaubertForSequenceClassification"),M8t.forEach(t),L0r=r(GNe," (FlauBERT model)"),GNe.forEach(t),y0r=i(ne),EC=n(ne,"LI",{});var ONe=s(EC);vMe=n(ONe,"STRONG",{});var E8t=s(vMe);x0r=r(E8t,"funnel"),E8t.forEach(t),$0r=r(ONe," \u2014 "),xJ=n(ONe,"A",{href:!0});var C8t=s(xJ);k0r=r(C8t,"TFFunnelForSequenceClassification"),C8t.forEach(t),S0r=r(ONe," (Funnel Transformer model)"),ONe.forEach(t),R0r=i(ne),CC=n(ne,"LI",{});var VNe=s(CC);FMe=n(VNe,"STRONG",{});var w8t=s(FMe);P0r=r(w8t,"gpt2"),w8t.forEach(t),B0r=r(VNe," \u2014 "),$J=n(VNe,"A",{href:!0});var A8t=s($J);I0r=r(A8t,"TFGPT2ForSequenceClassification"),A8t.forEach(t),N0r=r(VNe," (OpenAI GPT-2 model)"),VNe.forEach(t),q0r=i(ne),wC=n(ne,"LI",{});var XNe=s(wC);TMe=n(XNe,"STRONG",{});var L8t=s(TMe);j0r=r(L8t,"gptj"),L8t.forEach(t),D0r=r(XNe," \u2014 "),kJ=n(XNe,"A",{href:!0});var y8t=s(kJ);G0r=r(y8t,"TFGPTJForSequenceClassification"),y8t.forEach(t),O0r=r(XNe," (GPT-J model)"),XNe.forEach(t),V0r=i(ne),AC=n(ne,"LI",{});var zNe=s(AC);MMe=n(zNe,"STRONG",{});var x8t=s(MMe);X0r=r(x8t,"layoutlm"),x8t.forEach(t),z0r=r(zNe," \u2014 "),SJ=n(zNe,"A",{href:!0});var $8t=s(SJ);W0r=r($8t,"TFLayoutLMForSequenceClassification"),$8t.forEach(t),Q0r=r(zNe," (LayoutLM model)"),zNe.forEach(t),H0r=i(ne),LC=n(ne,"LI",{});var WNe=s(LC);EMe=n(WNe,"STRONG",{});var k8t=s(EMe);U0r=r(k8t,"longformer"),k8t.forEach(t),J0r=r(WNe," \u2014 "),RJ=n(WNe,"A",{href:!0});var S8t=s(RJ);Y0r=r(S8t,"TFLongformerForSequenceClassification"),S8t.forEach(t),K0r=r(WNe," (Longformer model)"),WNe.forEach(t),Z0r=i(ne),yC=n(ne,"LI",{});var QNe=s(yC);CMe=n(QNe,"STRONG",{});var R8t=s(CMe);ewr=r(R8t,"mobilebert"),R8t.forEach(t),owr=r(QNe," \u2014 "),PJ=n(QNe,"A",{href:!0});var P8t=s(PJ);rwr=r(P8t,"TFMobileBertForSequenceClassification"),P8t.forEach(t),twr=r(QNe," (MobileBERT model)"),QNe.forEach(t),awr=i(ne),xC=n(ne,"LI",{});var HNe=s(xC);wMe=n(HNe,"STRONG",{});var B8t=s(wMe);nwr=r(B8t,"mpnet"),B8t.forEach(t),swr=r(HNe," \u2014 "),BJ=n(HNe,"A",{href:!0});var I8t=s(BJ);lwr=r(I8t,"TFMPNetForSequenceClassification"),I8t.forEach(t),iwr=r(HNe," (MPNet model)"),HNe.forEach(t),dwr=i(ne),$C=n(ne,"LI",{});var UNe=s($C);AMe=n(UNe,"STRONG",{});var N8t=s(AMe);cwr=r(N8t,"openai-gpt"),N8t.forEach(t),fwr=r(UNe," \u2014 "),IJ=n(UNe,"A",{href:!0});var q8t=s(IJ);mwr=r(q8t,"TFOpenAIGPTForSequenceClassification"),q8t.forEach(t),gwr=r(UNe," (OpenAI GPT model)"),UNe.forEach(t),hwr=i(ne),kC=n(ne,"LI",{});var JNe=s(kC);LMe=n(JNe,"STRONG",{});var j8t=s(LMe);pwr=r(j8t,"rembert"),j8t.forEach(t),uwr=r(JNe," \u2014 "),NJ=n(JNe,"A",{href:!0});var D8t=s(NJ);_wr=r(D8t,"TFRemBertForSequenceClassification"),D8t.forEach(t),bwr=r(JNe," (RemBERT model)"),JNe.forEach(t),vwr=i(ne),SC=n(ne,"LI",{});var YNe=s(SC);yMe=n(YNe,"STRONG",{});var G8t=s(yMe);Fwr=r(G8t,"roberta"),G8t.forEach(t),Twr=r(YNe," \u2014 "),qJ=n(YNe,"A",{href:!0});var O8t=s(qJ);Mwr=r(O8t,"TFRobertaForSequenceClassification"),O8t.forEach(t),Ewr=r(YNe," (RoBERTa model)"),YNe.forEach(t),Cwr=i(ne),RC=n(ne,"LI",{});var KNe=s(RC);xMe=n(KNe,"STRONG",{});var V8t=s(xMe);wwr=r(V8t,"roformer"),V8t.forEach(t),Awr=r(KNe," \u2014 "),jJ=n(KNe,"A",{href:!0});var X8t=s(jJ);Lwr=r(X8t,"TFRoFormerForSequenceClassification"),X8t.forEach(t),ywr=r(KNe," (RoFormer model)"),KNe.forEach(t),xwr=i(ne),PC=n(ne,"LI",{});var ZNe=s(PC);$Me=n(ZNe,"STRONG",{});var z8t=s($Me);$wr=r(z8t,"tapas"),z8t.forEach(t),kwr=r(ZNe," \u2014 "),DJ=n(ZNe,"A",{href:!0});var W8t=s(DJ);Swr=r(W8t,"TFTapasForSequenceClassification"),W8t.forEach(t),Rwr=r(ZNe," (TAPAS model)"),ZNe.forEach(t),Pwr=i(ne),BC=n(ne,"LI",{});var eqe=s(BC);kMe=n(eqe,"STRONG",{});var Q8t=s(kMe);Bwr=r(Q8t,"transfo-xl"),Q8t.forEach(t),Iwr=r(eqe," \u2014 "),GJ=n(eqe,"A",{href:!0});var H8t=s(GJ);Nwr=r(H8t,"TFTransfoXLForSequenceClassification"),H8t.forEach(t),qwr=r(eqe," (Transformer-XL model)"),eqe.forEach(t),jwr=i(ne),IC=n(ne,"LI",{});var oqe=s(IC);SMe=n(oqe,"STRONG",{});var U8t=s(SMe);Dwr=r(U8t,"xlm"),U8t.forEach(t),Gwr=r(oqe," \u2014 "),OJ=n(oqe,"A",{href:!0});var J8t=s(OJ);Owr=r(J8t,"TFXLMForSequenceClassification"),J8t.forEach(t),Vwr=r(oqe," (XLM model)"),oqe.forEach(t),Xwr=i(ne),NC=n(ne,"LI",{});var rqe=s(NC);RMe=n(rqe,"STRONG",{});var Y8t=s(RMe);zwr=r(Y8t,"xlm-roberta"),Y8t.forEach(t),Wwr=r(rqe," \u2014 "),VJ=n(rqe,"A",{href:!0});var K8t=s(VJ);Qwr=r(K8t,"TFXLMRobertaForSequenceClassification"),K8t.forEach(t),Hwr=r(rqe," (XLM-RoBERTa model)"),rqe.forEach(t),Uwr=i(ne),qC=n(ne,"LI",{});var tqe=s(qC);PMe=n(tqe,"STRONG",{});var Z8t=s(PMe);Jwr=r(Z8t,"xlnet"),Z8t.forEach(t),Ywr=r(tqe," \u2014 "),XJ=n(tqe,"A",{href:!0});var e9t=s(XJ);Kwr=r(e9t,"TFXLNetForSequenceClassification"),e9t.forEach(t),Zwr=r(tqe," (XLNet model)"),tqe.forEach(t),ne.forEach(t),eAr=i(Bl),T(jC.$$.fragment,Bl),Bl.forEach(t),Pl.forEach(t),BOe=i(f),Fc=n(f,"H2",{class:!0});var VXe=s(Fc);DC=n(VXe,"A",{id:!0,class:!0,href:!0});var o9t=s(DC);BMe=n(o9t,"SPAN",{});var r9t=s(BMe);T(X9.$$.fragment,r9t),r9t.forEach(t),o9t.forEach(t),oAr=i(VXe),IMe=n(VXe,"SPAN",{});var t9t=s(IMe);rAr=r(t9t,"TFAutoModelForMultipleChoice"),t9t.forEach(t),VXe.forEach(t),IOe=i(f),sr=n(f,"DIV",{class:!0});var Il=s(sr);T(z9.$$.fragment,Il),tAr=i(Il),Tc=n(Il,"P",{});var hre=s(Tc);aAr=r(hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zJ=n(hre,"A",{href:!0});var a9t=s(zJ);nAr=r(a9t,"from_pretrained()"),a9t.forEach(t),sAr=r(hre," class method or the "),WJ=n(hre,"A",{href:!0});var n9t=s(WJ);lAr=r(n9t,"from_config()"),n9t.forEach(t),iAr=r(hre,` class
method.`),hre.forEach(t),dAr=i(Il),W9=n(Il,"P",{});var XXe=s(W9);cAr=r(XXe,"This class cannot be instantiated directly using "),NMe=n(XXe,"CODE",{});var s9t=s(NMe);fAr=r(s9t,"__init__()"),s9t.forEach(t),mAr=r(XXe," (throws an error)."),XXe.forEach(t),gAr=i(Il),Nt=n(Il,"DIV",{class:!0});var B6=s(Nt);T(Q9.$$.fragment,B6),hAr=i(B6),qMe=n(B6,"P",{});var l9t=s(qMe);pAr=r(l9t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),l9t.forEach(t),uAr=i(B6),Mc=n(B6,"P",{});var pre=s(Mc);_Ar=r(pre,`Note:
Loading a model from its configuration file does `),jMe=n(pre,"STRONG",{});var i9t=s(jMe);bAr=r(i9t,"not"),i9t.forEach(t),vAr=r(pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=n(pre,"A",{href:!0});var d9t=s(QJ);FAr=r(d9t,"from_pretrained()"),d9t.forEach(t),TAr=r(pre," to load the model weights."),pre.forEach(t),MAr=i(B6),T(GC.$$.fragment,B6),B6.forEach(t),EAr=i(Il),Pr=n(Il,"DIV",{class:!0});var Nl=s(Pr);T(H9.$$.fragment,Nl),CAr=i(Nl),DMe=n(Nl,"P",{});var c9t=s(DMe);wAr=r(c9t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),c9t.forEach(t),AAr=i(Nl),mn=n(Nl,"P",{});var I6=s(mn);LAr=r(I6,"The model class to instantiate is selected based on the "),GMe=n(I6,"CODE",{});var f9t=s(GMe);yAr=r(f9t,"model_type"),f9t.forEach(t),xAr=r(I6,` property of the config object (either
passed as an argument or loaded from `),OMe=n(I6,"CODE",{});var m9t=s(OMe);$Ar=r(m9t,"pretrained_model_name_or_path"),m9t.forEach(t),kAr=r(I6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VMe=n(I6,"CODE",{});var g9t=s(VMe);SAr=r(g9t,"pretrained_model_name_or_path"),g9t.forEach(t),RAr=r(I6,":"),I6.forEach(t),PAr=i(Nl),ue=n(Nl,"UL",{});var Fe=s(ue);OC=n(Fe,"LI",{});var aqe=s(OC);XMe=n(aqe,"STRONG",{});var h9t=s(XMe);BAr=r(h9t,"albert"),h9t.forEach(t),IAr=r(aqe," \u2014 "),HJ=n(aqe,"A",{href:!0});var p9t=s(HJ);NAr=r(p9t,"TFAlbertForMultipleChoice"),p9t.forEach(t),qAr=r(aqe," (ALBERT model)"),aqe.forEach(t),jAr=i(Fe),VC=n(Fe,"LI",{});var nqe=s(VC);zMe=n(nqe,"STRONG",{});var u9t=s(zMe);DAr=r(u9t,"bert"),u9t.forEach(t),GAr=r(nqe," \u2014 "),UJ=n(nqe,"A",{href:!0});var _9t=s(UJ);OAr=r(_9t,"TFBertForMultipleChoice"),_9t.forEach(t),VAr=r(nqe," (BERT model)"),nqe.forEach(t),XAr=i(Fe),XC=n(Fe,"LI",{});var sqe=s(XC);WMe=n(sqe,"STRONG",{});var b9t=s(WMe);zAr=r(b9t,"camembert"),b9t.forEach(t),WAr=r(sqe," \u2014 "),JJ=n(sqe,"A",{href:!0});var v9t=s(JJ);QAr=r(v9t,"TFCamembertForMultipleChoice"),v9t.forEach(t),HAr=r(sqe," (CamemBERT model)"),sqe.forEach(t),UAr=i(Fe),zC=n(Fe,"LI",{});var lqe=s(zC);QMe=n(lqe,"STRONG",{});var F9t=s(QMe);JAr=r(F9t,"convbert"),F9t.forEach(t),YAr=r(lqe," \u2014 "),YJ=n(lqe,"A",{href:!0});var T9t=s(YJ);KAr=r(T9t,"TFConvBertForMultipleChoice"),T9t.forEach(t),ZAr=r(lqe," (ConvBERT model)"),lqe.forEach(t),e6r=i(Fe),WC=n(Fe,"LI",{});var iqe=s(WC);HMe=n(iqe,"STRONG",{});var M9t=s(HMe);o6r=r(M9t,"distilbert"),M9t.forEach(t),r6r=r(iqe," \u2014 "),KJ=n(iqe,"A",{href:!0});var E9t=s(KJ);t6r=r(E9t,"TFDistilBertForMultipleChoice"),E9t.forEach(t),a6r=r(iqe," (DistilBERT model)"),iqe.forEach(t),n6r=i(Fe),QC=n(Fe,"LI",{});var dqe=s(QC);UMe=n(dqe,"STRONG",{});var C9t=s(UMe);s6r=r(C9t,"electra"),C9t.forEach(t),l6r=r(dqe," \u2014 "),ZJ=n(dqe,"A",{href:!0});var w9t=s(ZJ);i6r=r(w9t,"TFElectraForMultipleChoice"),w9t.forEach(t),d6r=r(dqe," (ELECTRA model)"),dqe.forEach(t),c6r=i(Fe),HC=n(Fe,"LI",{});var cqe=s(HC);JMe=n(cqe,"STRONG",{});var A9t=s(JMe);f6r=r(A9t,"flaubert"),A9t.forEach(t),m6r=r(cqe," \u2014 "),eY=n(cqe,"A",{href:!0});var L9t=s(eY);g6r=r(L9t,"TFFlaubertForMultipleChoice"),L9t.forEach(t),h6r=r(cqe," (FlauBERT model)"),cqe.forEach(t),p6r=i(Fe),UC=n(Fe,"LI",{});var fqe=s(UC);YMe=n(fqe,"STRONG",{});var y9t=s(YMe);u6r=r(y9t,"funnel"),y9t.forEach(t),_6r=r(fqe," \u2014 "),oY=n(fqe,"A",{href:!0});var x9t=s(oY);b6r=r(x9t,"TFFunnelForMultipleChoice"),x9t.forEach(t),v6r=r(fqe," (Funnel Transformer model)"),fqe.forEach(t),F6r=i(Fe),JC=n(Fe,"LI",{});var mqe=s(JC);KMe=n(mqe,"STRONG",{});var $9t=s(KMe);T6r=r($9t,"longformer"),$9t.forEach(t),M6r=r(mqe," \u2014 "),rY=n(mqe,"A",{href:!0});var k9t=s(rY);E6r=r(k9t,"TFLongformerForMultipleChoice"),k9t.forEach(t),C6r=r(mqe," (Longformer model)"),mqe.forEach(t),w6r=i(Fe),YC=n(Fe,"LI",{});var gqe=s(YC);ZMe=n(gqe,"STRONG",{});var S9t=s(ZMe);A6r=r(S9t,"mobilebert"),S9t.forEach(t),L6r=r(gqe," \u2014 "),tY=n(gqe,"A",{href:!0});var R9t=s(tY);y6r=r(R9t,"TFMobileBertForMultipleChoice"),R9t.forEach(t),x6r=r(gqe," (MobileBERT model)"),gqe.forEach(t),$6r=i(Fe),KC=n(Fe,"LI",{});var hqe=s(KC);eEe=n(hqe,"STRONG",{});var P9t=s(eEe);k6r=r(P9t,"mpnet"),P9t.forEach(t),S6r=r(hqe," \u2014 "),aY=n(hqe,"A",{href:!0});var B9t=s(aY);R6r=r(B9t,"TFMPNetForMultipleChoice"),B9t.forEach(t),P6r=r(hqe," (MPNet model)"),hqe.forEach(t),B6r=i(Fe),ZC=n(Fe,"LI",{});var pqe=s(ZC);oEe=n(pqe,"STRONG",{});var I9t=s(oEe);I6r=r(I9t,"rembert"),I9t.forEach(t),N6r=r(pqe," \u2014 "),nY=n(pqe,"A",{href:!0});var N9t=s(nY);q6r=r(N9t,"TFRemBertForMultipleChoice"),N9t.forEach(t),j6r=r(pqe," (RemBERT model)"),pqe.forEach(t),D6r=i(Fe),e5=n(Fe,"LI",{});var uqe=s(e5);rEe=n(uqe,"STRONG",{});var q9t=s(rEe);G6r=r(q9t,"roberta"),q9t.forEach(t),O6r=r(uqe," \u2014 "),sY=n(uqe,"A",{href:!0});var j9t=s(sY);V6r=r(j9t,"TFRobertaForMultipleChoice"),j9t.forEach(t),X6r=r(uqe," (RoBERTa model)"),uqe.forEach(t),z6r=i(Fe),o5=n(Fe,"LI",{});var _qe=s(o5);tEe=n(_qe,"STRONG",{});var D9t=s(tEe);W6r=r(D9t,"roformer"),D9t.forEach(t),Q6r=r(_qe," \u2014 "),lY=n(_qe,"A",{href:!0});var G9t=s(lY);H6r=r(G9t,"TFRoFormerForMultipleChoice"),G9t.forEach(t),U6r=r(_qe," (RoFormer model)"),_qe.forEach(t),J6r=i(Fe),r5=n(Fe,"LI",{});var bqe=s(r5);aEe=n(bqe,"STRONG",{});var O9t=s(aEe);Y6r=r(O9t,"xlm"),O9t.forEach(t),K6r=r(bqe," \u2014 "),iY=n(bqe,"A",{href:!0});var V9t=s(iY);Z6r=r(V9t,"TFXLMForMultipleChoice"),V9t.forEach(t),eLr=r(bqe," (XLM model)"),bqe.forEach(t),oLr=i(Fe),t5=n(Fe,"LI",{});var vqe=s(t5);nEe=n(vqe,"STRONG",{});var X9t=s(nEe);rLr=r(X9t,"xlm-roberta"),X9t.forEach(t),tLr=r(vqe," \u2014 "),dY=n(vqe,"A",{href:!0});var z9t=s(dY);aLr=r(z9t,"TFXLMRobertaForMultipleChoice"),z9t.forEach(t),nLr=r(vqe," (XLM-RoBERTa model)"),vqe.forEach(t),sLr=i(Fe),a5=n(Fe,"LI",{});var Fqe=s(a5);sEe=n(Fqe,"STRONG",{});var W9t=s(sEe);lLr=r(W9t,"xlnet"),W9t.forEach(t),iLr=r(Fqe," \u2014 "),cY=n(Fqe,"A",{href:!0});var Q9t=s(cY);dLr=r(Q9t,"TFXLNetForMultipleChoice"),Q9t.forEach(t),cLr=r(Fqe," (XLNet model)"),Fqe.forEach(t),Fe.forEach(t),fLr=i(Nl),T(n5.$$.fragment,Nl),Nl.forEach(t),Il.forEach(t),NOe=i(f),Ec=n(f,"H2",{class:!0});var zXe=s(Ec);s5=n(zXe,"A",{id:!0,class:!0,href:!0});var H9t=s(s5);lEe=n(H9t,"SPAN",{});var U9t=s(lEe);T(U9.$$.fragment,U9t),U9t.forEach(t),H9t.forEach(t),mLr=i(zXe),iEe=n(zXe,"SPAN",{});var J9t=s(iEe);gLr=r(J9t,"TFAutoModelForNextSentencePrediction"),J9t.forEach(t),zXe.forEach(t),qOe=i(f),lr=n(f,"DIV",{class:!0});var ql=s(lr);T(J9.$$.fragment,ql),hLr=i(ql),Cc=n(ql,"P",{});var ure=s(Cc);pLr=r(ure,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fY=n(ure,"A",{href:!0});var Y9t=s(fY);uLr=r(Y9t,"from_pretrained()"),Y9t.forEach(t),_Lr=r(ure," class method or the "),mY=n(ure,"A",{href:!0});var K9t=s(mY);bLr=r(K9t,"from_config()"),K9t.forEach(t),vLr=r(ure,` class
method.`),ure.forEach(t),FLr=i(ql),Y9=n(ql,"P",{});var WXe=s(Y9);TLr=r(WXe,"This class cannot be instantiated directly using "),dEe=n(WXe,"CODE",{});var Z9t=s(dEe);MLr=r(Z9t,"__init__()"),Z9t.forEach(t),ELr=r(WXe," (throws an error)."),WXe.forEach(t),CLr=i(ql),qt=n(ql,"DIV",{class:!0});var N6=s(qt);T(K9.$$.fragment,N6),wLr=i(N6),cEe=n(N6,"P",{});var ext=s(cEe);ALr=r(ext,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ext.forEach(t),LLr=i(N6),wc=n(N6,"P",{});var _re=s(wc);yLr=r(_re,`Note:
Loading a model from its configuration file does `),fEe=n(_re,"STRONG",{});var oxt=s(fEe);xLr=r(oxt,"not"),oxt.forEach(t),$Lr=r(_re,` load the model weights. It only affects the
model\u2019s configuration. Use `),gY=n(_re,"A",{href:!0});var rxt=s(gY);kLr=r(rxt,"from_pretrained()"),rxt.forEach(t),SLr=r(_re," to load the model weights."),_re.forEach(t),RLr=i(N6),T(l5.$$.fragment,N6),N6.forEach(t),PLr=i(ql),Br=n(ql,"DIV",{class:!0});var jl=s(Br);T(Z9.$$.fragment,jl),BLr=i(jl),mEe=n(jl,"P",{});var txt=s(mEe);ILr=r(txt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),txt.forEach(t),NLr=i(jl),gn=n(jl,"P",{});var q6=s(gn);qLr=r(q6,"The model class to instantiate is selected based on the "),gEe=n(q6,"CODE",{});var axt=s(gEe);jLr=r(axt,"model_type"),axt.forEach(t),DLr=r(q6,` property of the config object (either
passed as an argument or loaded from `),hEe=n(q6,"CODE",{});var nxt=s(hEe);GLr=r(nxt,"pretrained_model_name_or_path"),nxt.forEach(t),OLr=r(q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pEe=n(q6,"CODE",{});var sxt=s(pEe);VLr=r(sxt,"pretrained_model_name_or_path"),sxt.forEach(t),XLr=r(q6,":"),q6.forEach(t),zLr=i(jl),ex=n(jl,"UL",{});var QXe=s(ex);i5=n(QXe,"LI",{});var Tqe=s(i5);uEe=n(Tqe,"STRONG",{});var lxt=s(uEe);WLr=r(lxt,"bert"),lxt.forEach(t),QLr=r(Tqe," \u2014 "),hY=n(Tqe,"A",{href:!0});var ixt=s(hY);HLr=r(ixt,"TFBertForNextSentencePrediction"),ixt.forEach(t),ULr=r(Tqe," (BERT model)"),Tqe.forEach(t),JLr=i(QXe),d5=n(QXe,"LI",{});var Mqe=s(d5);_Ee=n(Mqe,"STRONG",{});var dxt=s(_Ee);YLr=r(dxt,"mobilebert"),dxt.forEach(t),KLr=r(Mqe," \u2014 "),pY=n(Mqe,"A",{href:!0});var cxt=s(pY);ZLr=r(cxt,"TFMobileBertForNextSentencePrediction"),cxt.forEach(t),eyr=r(Mqe," (MobileBERT model)"),Mqe.forEach(t),QXe.forEach(t),oyr=i(jl),T(c5.$$.fragment,jl),jl.forEach(t),ql.forEach(t),jOe=i(f),Ac=n(f,"H2",{class:!0});var HXe=s(Ac);f5=n(HXe,"A",{id:!0,class:!0,href:!0});var fxt=s(f5);bEe=n(fxt,"SPAN",{});var mxt=s(bEe);T(ox.$$.fragment,mxt),mxt.forEach(t),fxt.forEach(t),ryr=i(HXe),vEe=n(HXe,"SPAN",{});var gxt=s(vEe);tyr=r(gxt,"TFAutoModelForTableQuestionAnswering"),gxt.forEach(t),HXe.forEach(t),DOe=i(f),ir=n(f,"DIV",{class:!0});var Dl=s(ir);T(rx.$$.fragment,Dl),ayr=i(Dl),Lc=n(Dl,"P",{});var bre=s(Lc);nyr=r(bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),uY=n(bre,"A",{href:!0});var hxt=s(uY);syr=r(hxt,"from_pretrained()"),hxt.forEach(t),lyr=r(bre," class method or the "),_Y=n(bre,"A",{href:!0});var pxt=s(_Y);iyr=r(pxt,"from_config()"),pxt.forEach(t),dyr=r(bre,` class
method.`),bre.forEach(t),cyr=i(Dl),tx=n(Dl,"P",{});var UXe=s(tx);fyr=r(UXe,"This class cannot be instantiated directly using "),FEe=n(UXe,"CODE",{});var uxt=s(FEe);myr=r(uxt,"__init__()"),uxt.forEach(t),gyr=r(UXe," (throws an error)."),UXe.forEach(t),hyr=i(Dl),jt=n(Dl,"DIV",{class:!0});var j6=s(jt);T(ax.$$.fragment,j6),pyr=i(j6),TEe=n(j6,"P",{});var _xt=s(TEe);uyr=r(_xt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),_xt.forEach(t),_yr=i(j6),yc=n(j6,"P",{});var vre=s(yc);byr=r(vre,`Note:
Loading a model from its configuration file does `),MEe=n(vre,"STRONG",{});var bxt=s(MEe);vyr=r(bxt,"not"),bxt.forEach(t),Fyr=r(vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),bY=n(vre,"A",{href:!0});var vxt=s(bY);Tyr=r(vxt,"from_pretrained()"),vxt.forEach(t),Myr=r(vre," to load the model weights."),vre.forEach(t),Eyr=i(j6),T(m5.$$.fragment,j6),j6.forEach(t),Cyr=i(Dl),Ir=n(Dl,"DIV",{class:!0});var Gl=s(Ir);T(nx.$$.fragment,Gl),wyr=i(Gl),EEe=n(Gl,"P",{});var Fxt=s(EEe);Ayr=r(Fxt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Fxt.forEach(t),Lyr=i(Gl),hn=n(Gl,"P",{});var D6=s(hn);yyr=r(D6,"The model class to instantiate is selected based on the "),CEe=n(D6,"CODE",{});var Txt=s(CEe);xyr=r(Txt,"model_type"),Txt.forEach(t),$yr=r(D6,` property of the config object (either
passed as an argument or loaded from `),wEe=n(D6,"CODE",{});var Mxt=s(wEe);kyr=r(Mxt,"pretrained_model_name_or_path"),Mxt.forEach(t),Syr=r(D6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AEe=n(D6,"CODE",{});var Ext=s(AEe);Ryr=r(Ext,"pretrained_model_name_or_path"),Ext.forEach(t),Pyr=r(D6,":"),D6.forEach(t),Byr=i(Gl),LEe=n(Gl,"UL",{});var Cxt=s(LEe);g5=n(Cxt,"LI",{});var Eqe=s(g5);yEe=n(Eqe,"STRONG",{});var wxt=s(yEe);Iyr=r(wxt,"tapas"),wxt.forEach(t),Nyr=r(Eqe," \u2014 "),vY=n(Eqe,"A",{href:!0});var Axt=s(vY);qyr=r(Axt,"TFTapasForQuestionAnswering"),Axt.forEach(t),jyr=r(Eqe," (TAPAS model)"),Eqe.forEach(t),Cxt.forEach(t),Dyr=i(Gl),T(h5.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),GOe=i(f),xc=n(f,"H2",{class:!0});var JXe=s(xc);p5=n(JXe,"A",{id:!0,class:!0,href:!0});var Lxt=s(p5);xEe=n(Lxt,"SPAN",{});var yxt=s(xEe);T(sx.$$.fragment,yxt),yxt.forEach(t),Lxt.forEach(t),Gyr=i(JXe),$Ee=n(JXe,"SPAN",{});var xxt=s($Ee);Oyr=r(xxt,"TFAutoModelForTokenClassification"),xxt.forEach(t),JXe.forEach(t),OOe=i(f),dr=n(f,"DIV",{class:!0});var Ol=s(dr);T(lx.$$.fragment,Ol),Vyr=i(Ol),$c=n(Ol,"P",{});var Fre=s($c);Xyr=r(Fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),FY=n(Fre,"A",{href:!0});var $xt=s(FY);zyr=r($xt,"from_pretrained()"),$xt.forEach(t),Wyr=r(Fre," class method or the "),TY=n(Fre,"A",{href:!0});var kxt=s(TY);Qyr=r(kxt,"from_config()"),kxt.forEach(t),Hyr=r(Fre,` class
method.`),Fre.forEach(t),Uyr=i(Ol),ix=n(Ol,"P",{});var YXe=s(ix);Jyr=r(YXe,"This class cannot be instantiated directly using "),kEe=n(YXe,"CODE",{});var Sxt=s(kEe);Yyr=r(Sxt,"__init__()"),Sxt.forEach(t),Kyr=r(YXe," (throws an error)."),YXe.forEach(t),Zyr=i(Ol),Dt=n(Ol,"DIV",{class:!0});var G6=s(Dt);T(dx.$$.fragment,G6),e8r=i(G6),SEe=n(G6,"P",{});var Rxt=s(SEe);o8r=r(Rxt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Rxt.forEach(t),r8r=i(G6),kc=n(G6,"P",{});var Tre=s(kc);t8r=r(Tre,`Note:
Loading a model from its configuration file does `),REe=n(Tre,"STRONG",{});var Pxt=s(REe);a8r=r(Pxt,"not"),Pxt.forEach(t),n8r=r(Tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),MY=n(Tre,"A",{href:!0});var Bxt=s(MY);s8r=r(Bxt,"from_pretrained()"),Bxt.forEach(t),l8r=r(Tre," to load the model weights."),Tre.forEach(t),i8r=i(G6),T(u5.$$.fragment,G6),G6.forEach(t),d8r=i(Ol),Nr=n(Ol,"DIV",{class:!0});var Vl=s(Nr);T(cx.$$.fragment,Vl),c8r=i(Vl),PEe=n(Vl,"P",{});var Ixt=s(PEe);f8r=r(Ixt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ixt.forEach(t),m8r=i(Vl),pn=n(Vl,"P",{});var O6=s(pn);g8r=r(O6,"The model class to instantiate is selected based on the "),BEe=n(O6,"CODE",{});var Nxt=s(BEe);h8r=r(Nxt,"model_type"),Nxt.forEach(t),p8r=r(O6,` property of the config object (either
passed as an argument or loaded from `),IEe=n(O6,"CODE",{});var qxt=s(IEe);u8r=r(qxt,"pretrained_model_name_or_path"),qxt.forEach(t),_8r=r(O6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NEe=n(O6,"CODE",{});var jxt=s(NEe);b8r=r(jxt,"pretrained_model_name_or_path"),jxt.forEach(t),v8r=r(O6,":"),O6.forEach(t),F8r=i(Vl),de=n(Vl,"UL",{});var me=s(de);_5=n(me,"LI",{});var Cqe=s(_5);qEe=n(Cqe,"STRONG",{});var Dxt=s(qEe);T8r=r(Dxt,"albert"),Dxt.forEach(t),M8r=r(Cqe," \u2014 "),EY=n(Cqe,"A",{href:!0});var Gxt=s(EY);E8r=r(Gxt,"TFAlbertForTokenClassification"),Gxt.forEach(t),C8r=r(Cqe," (ALBERT model)"),Cqe.forEach(t),w8r=i(me),b5=n(me,"LI",{});var wqe=s(b5);jEe=n(wqe,"STRONG",{});var Oxt=s(jEe);A8r=r(Oxt,"bert"),Oxt.forEach(t),L8r=r(wqe," \u2014 "),CY=n(wqe,"A",{href:!0});var Vxt=s(CY);y8r=r(Vxt,"TFBertForTokenClassification"),Vxt.forEach(t),x8r=r(wqe," (BERT model)"),wqe.forEach(t),$8r=i(me),v5=n(me,"LI",{});var Aqe=s(v5);DEe=n(Aqe,"STRONG",{});var Xxt=s(DEe);k8r=r(Xxt,"camembert"),Xxt.forEach(t),S8r=r(Aqe," \u2014 "),wY=n(Aqe,"A",{href:!0});var zxt=s(wY);R8r=r(zxt,"TFCamembertForTokenClassification"),zxt.forEach(t),P8r=r(Aqe," (CamemBERT model)"),Aqe.forEach(t),B8r=i(me),F5=n(me,"LI",{});var Lqe=s(F5);GEe=n(Lqe,"STRONG",{});var Wxt=s(GEe);I8r=r(Wxt,"convbert"),Wxt.forEach(t),N8r=r(Lqe," \u2014 "),AY=n(Lqe,"A",{href:!0});var Qxt=s(AY);q8r=r(Qxt,"TFConvBertForTokenClassification"),Qxt.forEach(t),j8r=r(Lqe," (ConvBERT model)"),Lqe.forEach(t),D8r=i(me),T5=n(me,"LI",{});var yqe=s(T5);OEe=n(yqe,"STRONG",{});var Hxt=s(OEe);G8r=r(Hxt,"deberta"),Hxt.forEach(t),O8r=r(yqe," \u2014 "),LY=n(yqe,"A",{href:!0});var Uxt=s(LY);V8r=r(Uxt,"TFDebertaForTokenClassification"),Uxt.forEach(t),X8r=r(yqe," (DeBERTa model)"),yqe.forEach(t),z8r=i(me),M5=n(me,"LI",{});var xqe=s(M5);VEe=n(xqe,"STRONG",{});var Jxt=s(VEe);W8r=r(Jxt,"deberta-v2"),Jxt.forEach(t),Q8r=r(xqe," \u2014 "),yY=n(xqe,"A",{href:!0});var Yxt=s(yY);H8r=r(Yxt,"TFDebertaV2ForTokenClassification"),Yxt.forEach(t),U8r=r(xqe," (DeBERTa-v2 model)"),xqe.forEach(t),J8r=i(me),E5=n(me,"LI",{});var $qe=s(E5);XEe=n($qe,"STRONG",{});var Kxt=s(XEe);Y8r=r(Kxt,"distilbert"),Kxt.forEach(t),K8r=r($qe," \u2014 "),xY=n($qe,"A",{href:!0});var Zxt=s(xY);Z8r=r(Zxt,"TFDistilBertForTokenClassification"),Zxt.forEach(t),e9r=r($qe," (DistilBERT model)"),$qe.forEach(t),o9r=i(me),C5=n(me,"LI",{});var kqe=s(C5);zEe=n(kqe,"STRONG",{});var e$t=s(zEe);r9r=r(e$t,"electra"),e$t.forEach(t),t9r=r(kqe," \u2014 "),$Y=n(kqe,"A",{href:!0});var o$t=s($Y);a9r=r(o$t,"TFElectraForTokenClassification"),o$t.forEach(t),n9r=r(kqe," (ELECTRA model)"),kqe.forEach(t),s9r=i(me),w5=n(me,"LI",{});var Sqe=s(w5);WEe=n(Sqe,"STRONG",{});var r$t=s(WEe);l9r=r(r$t,"flaubert"),r$t.forEach(t),i9r=r(Sqe," \u2014 "),kY=n(Sqe,"A",{href:!0});var t$t=s(kY);d9r=r(t$t,"TFFlaubertForTokenClassification"),t$t.forEach(t),c9r=r(Sqe," (FlauBERT model)"),Sqe.forEach(t),f9r=i(me),A5=n(me,"LI",{});var Rqe=s(A5);QEe=n(Rqe,"STRONG",{});var a$t=s(QEe);m9r=r(a$t,"funnel"),a$t.forEach(t),g9r=r(Rqe," \u2014 "),SY=n(Rqe,"A",{href:!0});var n$t=s(SY);h9r=r(n$t,"TFFunnelForTokenClassification"),n$t.forEach(t),p9r=r(Rqe," (Funnel Transformer model)"),Rqe.forEach(t),u9r=i(me),L5=n(me,"LI",{});var Pqe=s(L5);HEe=n(Pqe,"STRONG",{});var s$t=s(HEe);_9r=r(s$t,"layoutlm"),s$t.forEach(t),b9r=r(Pqe," \u2014 "),RY=n(Pqe,"A",{href:!0});var l$t=s(RY);v9r=r(l$t,"TFLayoutLMForTokenClassification"),l$t.forEach(t),F9r=r(Pqe," (LayoutLM model)"),Pqe.forEach(t),T9r=i(me),y5=n(me,"LI",{});var Bqe=s(y5);UEe=n(Bqe,"STRONG",{});var i$t=s(UEe);M9r=r(i$t,"longformer"),i$t.forEach(t),E9r=r(Bqe," \u2014 "),PY=n(Bqe,"A",{href:!0});var d$t=s(PY);C9r=r(d$t,"TFLongformerForTokenClassification"),d$t.forEach(t),w9r=r(Bqe," (Longformer model)"),Bqe.forEach(t),A9r=i(me),x5=n(me,"LI",{});var Iqe=s(x5);JEe=n(Iqe,"STRONG",{});var c$t=s(JEe);L9r=r(c$t,"mobilebert"),c$t.forEach(t),y9r=r(Iqe," \u2014 "),BY=n(Iqe,"A",{href:!0});var f$t=s(BY);x9r=r(f$t,"TFMobileBertForTokenClassification"),f$t.forEach(t),$9r=r(Iqe," (MobileBERT model)"),Iqe.forEach(t),k9r=i(me),$5=n(me,"LI",{});var Nqe=s($5);YEe=n(Nqe,"STRONG",{});var m$t=s(YEe);S9r=r(m$t,"mpnet"),m$t.forEach(t),R9r=r(Nqe," \u2014 "),IY=n(Nqe,"A",{href:!0});var g$t=s(IY);P9r=r(g$t,"TFMPNetForTokenClassification"),g$t.forEach(t),B9r=r(Nqe," (MPNet model)"),Nqe.forEach(t),I9r=i(me),k5=n(me,"LI",{});var qqe=s(k5);KEe=n(qqe,"STRONG",{});var h$t=s(KEe);N9r=r(h$t,"rembert"),h$t.forEach(t),q9r=r(qqe," \u2014 "),NY=n(qqe,"A",{href:!0});var p$t=s(NY);j9r=r(p$t,"TFRemBertForTokenClassification"),p$t.forEach(t),D9r=r(qqe," (RemBERT model)"),qqe.forEach(t),G9r=i(me),S5=n(me,"LI",{});var jqe=s(S5);ZEe=n(jqe,"STRONG",{});var u$t=s(ZEe);O9r=r(u$t,"roberta"),u$t.forEach(t),V9r=r(jqe," \u2014 "),qY=n(jqe,"A",{href:!0});var _$t=s(qY);X9r=r(_$t,"TFRobertaForTokenClassification"),_$t.forEach(t),z9r=r(jqe," (RoBERTa model)"),jqe.forEach(t),W9r=i(me),R5=n(me,"LI",{});var Dqe=s(R5);e4e=n(Dqe,"STRONG",{});var b$t=s(e4e);Q9r=r(b$t,"roformer"),b$t.forEach(t),H9r=r(Dqe," \u2014 "),jY=n(Dqe,"A",{href:!0});var v$t=s(jY);U9r=r(v$t,"TFRoFormerForTokenClassification"),v$t.forEach(t),J9r=r(Dqe," (RoFormer model)"),Dqe.forEach(t),Y9r=i(me),P5=n(me,"LI",{});var Gqe=s(P5);o4e=n(Gqe,"STRONG",{});var F$t=s(o4e);K9r=r(F$t,"xlm"),F$t.forEach(t),Z9r=r(Gqe," \u2014 "),DY=n(Gqe,"A",{href:!0});var T$t=s(DY);exr=r(T$t,"TFXLMForTokenClassification"),T$t.forEach(t),oxr=r(Gqe," (XLM model)"),Gqe.forEach(t),rxr=i(me),B5=n(me,"LI",{});var Oqe=s(B5);r4e=n(Oqe,"STRONG",{});var M$t=s(r4e);txr=r(M$t,"xlm-roberta"),M$t.forEach(t),axr=r(Oqe," \u2014 "),GY=n(Oqe,"A",{href:!0});var E$t=s(GY);nxr=r(E$t,"TFXLMRobertaForTokenClassification"),E$t.forEach(t),sxr=r(Oqe," (XLM-RoBERTa model)"),Oqe.forEach(t),lxr=i(me),I5=n(me,"LI",{});var Vqe=s(I5);t4e=n(Vqe,"STRONG",{});var C$t=s(t4e);ixr=r(C$t,"xlnet"),C$t.forEach(t),dxr=r(Vqe," \u2014 "),OY=n(Vqe,"A",{href:!0});var w$t=s(OY);cxr=r(w$t,"TFXLNetForTokenClassification"),w$t.forEach(t),fxr=r(Vqe," (XLNet model)"),Vqe.forEach(t),me.forEach(t),mxr=i(Vl),T(N5.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),VOe=i(f),Sc=n(f,"H2",{class:!0});var KXe=s(Sc);q5=n(KXe,"A",{id:!0,class:!0,href:!0});var A$t=s(q5);a4e=n(A$t,"SPAN",{});var L$t=s(a4e);T(fx.$$.fragment,L$t),L$t.forEach(t),A$t.forEach(t),gxr=i(KXe),n4e=n(KXe,"SPAN",{});var y$t=s(n4e);hxr=r(y$t,"TFAutoModelForQuestionAnswering"),y$t.forEach(t),KXe.forEach(t),XOe=i(f),cr=n(f,"DIV",{class:!0});var Xl=s(cr);T(mx.$$.fragment,Xl),pxr=i(Xl),Rc=n(Xl,"P",{});var Mre=s(Rc);uxr=r(Mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),VY=n(Mre,"A",{href:!0});var x$t=s(VY);_xr=r(x$t,"from_pretrained()"),x$t.forEach(t),bxr=r(Mre," class method or the "),XY=n(Mre,"A",{href:!0});var $$t=s(XY);vxr=r($$t,"from_config()"),$$t.forEach(t),Fxr=r(Mre,` class
method.`),Mre.forEach(t),Txr=i(Xl),gx=n(Xl,"P",{});var ZXe=s(gx);Mxr=r(ZXe,"This class cannot be instantiated directly using "),s4e=n(ZXe,"CODE",{});var k$t=s(s4e);Exr=r(k$t,"__init__()"),k$t.forEach(t),Cxr=r(ZXe," (throws an error)."),ZXe.forEach(t),wxr=i(Xl),Gt=n(Xl,"DIV",{class:!0});var V6=s(Gt);T(hx.$$.fragment,V6),Axr=i(V6),l4e=n(V6,"P",{});var S$t=s(l4e);Lxr=r(S$t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),S$t.forEach(t),yxr=i(V6),Pc=n(V6,"P",{});var Ere=s(Pc);xxr=r(Ere,`Note:
Loading a model from its configuration file does `),i4e=n(Ere,"STRONG",{});var R$t=s(i4e);$xr=r(R$t,"not"),R$t.forEach(t),kxr=r(Ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),zY=n(Ere,"A",{href:!0});var P$t=s(zY);Sxr=r(P$t,"from_pretrained()"),P$t.forEach(t),Rxr=r(Ere," to load the model weights."),Ere.forEach(t),Pxr=i(V6),T(j5.$$.fragment,V6),V6.forEach(t),Bxr=i(Xl),qr=n(Xl,"DIV",{class:!0});var zl=s(qr);T(px.$$.fragment,zl),Ixr=i(zl),d4e=n(zl,"P",{});var B$t=s(d4e);Nxr=r(B$t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),B$t.forEach(t),qxr=i(zl),un=n(zl,"P",{});var X6=s(un);jxr=r(X6,"The model class to instantiate is selected based on the "),c4e=n(X6,"CODE",{});var I$t=s(c4e);Dxr=r(I$t,"model_type"),I$t.forEach(t),Gxr=r(X6,` property of the config object (either
passed as an argument or loaded from `),f4e=n(X6,"CODE",{});var N$t=s(f4e);Oxr=r(N$t,"pretrained_model_name_or_path"),N$t.forEach(t),Vxr=r(X6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m4e=n(X6,"CODE",{});var q$t=s(m4e);Xxr=r(q$t,"pretrained_model_name_or_path"),q$t.forEach(t),zxr=r(X6,":"),X6.forEach(t),Wxr=i(zl),ce=n(zl,"UL",{});var ge=s(ce);D5=n(ge,"LI",{});var Xqe=s(D5);g4e=n(Xqe,"STRONG",{});var j$t=s(g4e);Qxr=r(j$t,"albert"),j$t.forEach(t),Hxr=r(Xqe," \u2014 "),WY=n(Xqe,"A",{href:!0});var D$t=s(WY);Uxr=r(D$t,"TFAlbertForQuestionAnswering"),D$t.forEach(t),Jxr=r(Xqe," (ALBERT model)"),Xqe.forEach(t),Yxr=i(ge),G5=n(ge,"LI",{});var zqe=s(G5);h4e=n(zqe,"STRONG",{});var G$t=s(h4e);Kxr=r(G$t,"bert"),G$t.forEach(t),Zxr=r(zqe," \u2014 "),QY=n(zqe,"A",{href:!0});var O$t=s(QY);e$r=r(O$t,"TFBertForQuestionAnswering"),O$t.forEach(t),o$r=r(zqe," (BERT model)"),zqe.forEach(t),r$r=i(ge),O5=n(ge,"LI",{});var Wqe=s(O5);p4e=n(Wqe,"STRONG",{});var V$t=s(p4e);t$r=r(V$t,"camembert"),V$t.forEach(t),a$r=r(Wqe," \u2014 "),HY=n(Wqe,"A",{href:!0});var X$t=s(HY);n$r=r(X$t,"TFCamembertForQuestionAnswering"),X$t.forEach(t),s$r=r(Wqe," (CamemBERT model)"),Wqe.forEach(t),l$r=i(ge),V5=n(ge,"LI",{});var Qqe=s(V5);u4e=n(Qqe,"STRONG",{});var z$t=s(u4e);i$r=r(z$t,"convbert"),z$t.forEach(t),d$r=r(Qqe," \u2014 "),UY=n(Qqe,"A",{href:!0});var W$t=s(UY);c$r=r(W$t,"TFConvBertForQuestionAnswering"),W$t.forEach(t),f$r=r(Qqe," (ConvBERT model)"),Qqe.forEach(t),m$r=i(ge),X5=n(ge,"LI",{});var Hqe=s(X5);_4e=n(Hqe,"STRONG",{});var Q$t=s(_4e);g$r=r(Q$t,"deberta"),Q$t.forEach(t),h$r=r(Hqe," \u2014 "),JY=n(Hqe,"A",{href:!0});var H$t=s(JY);p$r=r(H$t,"TFDebertaForQuestionAnswering"),H$t.forEach(t),u$r=r(Hqe," (DeBERTa model)"),Hqe.forEach(t),_$r=i(ge),z5=n(ge,"LI",{});var Uqe=s(z5);b4e=n(Uqe,"STRONG",{});var U$t=s(b4e);b$r=r(U$t,"deberta-v2"),U$t.forEach(t),v$r=r(Uqe," \u2014 "),YY=n(Uqe,"A",{href:!0});var J$t=s(YY);F$r=r(J$t,"TFDebertaV2ForQuestionAnswering"),J$t.forEach(t),T$r=r(Uqe," (DeBERTa-v2 model)"),Uqe.forEach(t),M$r=i(ge),W5=n(ge,"LI",{});var Jqe=s(W5);v4e=n(Jqe,"STRONG",{});var Y$t=s(v4e);E$r=r(Y$t,"distilbert"),Y$t.forEach(t),C$r=r(Jqe," \u2014 "),KY=n(Jqe,"A",{href:!0});var K$t=s(KY);w$r=r(K$t,"TFDistilBertForQuestionAnswering"),K$t.forEach(t),A$r=r(Jqe," (DistilBERT model)"),Jqe.forEach(t),L$r=i(ge),Q5=n(ge,"LI",{});var Yqe=s(Q5);F4e=n(Yqe,"STRONG",{});var Z$t=s(F4e);y$r=r(Z$t,"electra"),Z$t.forEach(t),x$r=r(Yqe," \u2014 "),ZY=n(Yqe,"A",{href:!0});var ekt=s(ZY);$$r=r(ekt,"TFElectraForQuestionAnswering"),ekt.forEach(t),k$r=r(Yqe," (ELECTRA model)"),Yqe.forEach(t),S$r=i(ge),H5=n(ge,"LI",{});var Kqe=s(H5);T4e=n(Kqe,"STRONG",{});var okt=s(T4e);R$r=r(okt,"flaubert"),okt.forEach(t),P$r=r(Kqe," \u2014 "),eK=n(Kqe,"A",{href:!0});var rkt=s(eK);B$r=r(rkt,"TFFlaubertForQuestionAnsweringSimple"),rkt.forEach(t),I$r=r(Kqe," (FlauBERT model)"),Kqe.forEach(t),N$r=i(ge),U5=n(ge,"LI",{});var Zqe=s(U5);M4e=n(Zqe,"STRONG",{});var tkt=s(M4e);q$r=r(tkt,"funnel"),tkt.forEach(t),j$r=r(Zqe," \u2014 "),oK=n(Zqe,"A",{href:!0});var akt=s(oK);D$r=r(akt,"TFFunnelForQuestionAnswering"),akt.forEach(t),G$r=r(Zqe," (Funnel Transformer model)"),Zqe.forEach(t),O$r=i(ge),J5=n(ge,"LI",{});var eje=s(J5);E4e=n(eje,"STRONG",{});var nkt=s(E4e);V$r=r(nkt,"gptj"),nkt.forEach(t),X$r=r(eje," \u2014 "),rK=n(eje,"A",{href:!0});var skt=s(rK);z$r=r(skt,"TFGPTJForQuestionAnswering"),skt.forEach(t),W$r=r(eje," (GPT-J model)"),eje.forEach(t),Q$r=i(ge),Y5=n(ge,"LI",{});var oje=s(Y5);C4e=n(oje,"STRONG",{});var lkt=s(C4e);H$r=r(lkt,"longformer"),lkt.forEach(t),U$r=r(oje," \u2014 "),tK=n(oje,"A",{href:!0});var ikt=s(tK);J$r=r(ikt,"TFLongformerForQuestionAnswering"),ikt.forEach(t),Y$r=r(oje," (Longformer model)"),oje.forEach(t),K$r=i(ge),K5=n(ge,"LI",{});var rje=s(K5);w4e=n(rje,"STRONG",{});var dkt=s(w4e);Z$r=r(dkt,"mobilebert"),dkt.forEach(t),ekr=r(rje," \u2014 "),aK=n(rje,"A",{href:!0});var ckt=s(aK);okr=r(ckt,"TFMobileBertForQuestionAnswering"),ckt.forEach(t),rkr=r(rje," (MobileBERT model)"),rje.forEach(t),tkr=i(ge),Z5=n(ge,"LI",{});var tje=s(Z5);A4e=n(tje,"STRONG",{});var fkt=s(A4e);akr=r(fkt,"mpnet"),fkt.forEach(t),nkr=r(tje," \u2014 "),nK=n(tje,"A",{href:!0});var mkt=s(nK);skr=r(mkt,"TFMPNetForQuestionAnswering"),mkt.forEach(t),lkr=r(tje," (MPNet model)"),tje.forEach(t),ikr=i(ge),e3=n(ge,"LI",{});var aje=s(e3);L4e=n(aje,"STRONG",{});var gkt=s(L4e);dkr=r(gkt,"rembert"),gkt.forEach(t),ckr=r(aje," \u2014 "),sK=n(aje,"A",{href:!0});var hkt=s(sK);fkr=r(hkt,"TFRemBertForQuestionAnswering"),hkt.forEach(t),mkr=r(aje," (RemBERT model)"),aje.forEach(t),gkr=i(ge),o3=n(ge,"LI",{});var nje=s(o3);y4e=n(nje,"STRONG",{});var pkt=s(y4e);hkr=r(pkt,"roberta"),pkt.forEach(t),pkr=r(nje," \u2014 "),lK=n(nje,"A",{href:!0});var ukt=s(lK);ukr=r(ukt,"TFRobertaForQuestionAnswering"),ukt.forEach(t),_kr=r(nje," (RoBERTa model)"),nje.forEach(t),bkr=i(ge),r3=n(ge,"LI",{});var sje=s(r3);x4e=n(sje,"STRONG",{});var _kt=s(x4e);vkr=r(_kt,"roformer"),_kt.forEach(t),Fkr=r(sje," \u2014 "),iK=n(sje,"A",{href:!0});var bkt=s(iK);Tkr=r(bkt,"TFRoFormerForQuestionAnswering"),bkt.forEach(t),Mkr=r(sje," (RoFormer model)"),sje.forEach(t),Ekr=i(ge),t3=n(ge,"LI",{});var lje=s(t3);$4e=n(lje,"STRONG",{});var vkt=s($4e);Ckr=r(vkt,"xlm"),vkt.forEach(t),wkr=r(lje," \u2014 "),dK=n(lje,"A",{href:!0});var Fkt=s(dK);Akr=r(Fkt,"TFXLMForQuestionAnsweringSimple"),Fkt.forEach(t),Lkr=r(lje," (XLM model)"),lje.forEach(t),ykr=i(ge),a3=n(ge,"LI",{});var ije=s(a3);k4e=n(ije,"STRONG",{});var Tkt=s(k4e);xkr=r(Tkt,"xlm-roberta"),Tkt.forEach(t),$kr=r(ije," \u2014 "),cK=n(ije,"A",{href:!0});var Mkt=s(cK);kkr=r(Mkt,"TFXLMRobertaForQuestionAnswering"),Mkt.forEach(t),Skr=r(ije," (XLM-RoBERTa model)"),ije.forEach(t),Rkr=i(ge),n3=n(ge,"LI",{});var dje=s(n3);S4e=n(dje,"STRONG",{});var Ekt=s(S4e);Pkr=r(Ekt,"xlnet"),Ekt.forEach(t),Bkr=r(dje," \u2014 "),fK=n(dje,"A",{href:!0});var Ckt=s(fK);Ikr=r(Ckt,"TFXLNetForQuestionAnsweringSimple"),Ckt.forEach(t),Nkr=r(dje," (XLNet model)"),dje.forEach(t),ge.forEach(t),qkr=i(zl),T(s3.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),zOe=i(f),Bc=n(f,"H2",{class:!0});var eze=s(Bc);l3=n(eze,"A",{id:!0,class:!0,href:!0});var wkt=s(l3);R4e=n(wkt,"SPAN",{});var Akt=s(R4e);T(ux.$$.fragment,Akt),Akt.forEach(t),wkt.forEach(t),jkr=i(eze),P4e=n(eze,"SPAN",{});var Lkt=s(P4e);Dkr=r(Lkt,"TFAutoModelForVision2Seq"),Lkt.forEach(t),eze.forEach(t),WOe=i(f),fr=n(f,"DIV",{class:!0});var Wl=s(fr);T(_x.$$.fragment,Wl),Gkr=i(Wl),Ic=n(Wl,"P",{});var Cre=s(Ic);Okr=r(Cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),mK=n(Cre,"A",{href:!0});var ykt=s(mK);Vkr=r(ykt,"from_pretrained()"),ykt.forEach(t),Xkr=r(Cre," class method or the "),gK=n(Cre,"A",{href:!0});var xkt=s(gK);zkr=r(xkt,"from_config()"),xkt.forEach(t),Wkr=r(Cre,` class
method.`),Cre.forEach(t),Qkr=i(Wl),bx=n(Wl,"P",{});var oze=s(bx);Hkr=r(oze,"This class cannot be instantiated directly using "),B4e=n(oze,"CODE",{});var $kt=s(B4e);Ukr=r($kt,"__init__()"),$kt.forEach(t),Jkr=r(oze," (throws an error)."),oze.forEach(t),Ykr=i(Wl),Ot=n(Wl,"DIV",{class:!0});var z6=s(Ot);T(vx.$$.fragment,z6),Kkr=i(z6),I4e=n(z6,"P",{});var kkt=s(I4e);Zkr=r(kkt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),kkt.forEach(t),eSr=i(z6),Nc=n(z6,"P",{});var wre=s(Nc);oSr=r(wre,`Note:
Loading a model from its configuration file does `),N4e=n(wre,"STRONG",{});var Skt=s(N4e);rSr=r(Skt,"not"),Skt.forEach(t),tSr=r(wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),hK=n(wre,"A",{href:!0});var Rkt=s(hK);aSr=r(Rkt,"from_pretrained()"),Rkt.forEach(t),nSr=r(wre," to load the model weights."),wre.forEach(t),sSr=i(z6),T(i3.$$.fragment,z6),z6.forEach(t),lSr=i(Wl),jr=n(Wl,"DIV",{class:!0});var Ql=s(jr);T(Fx.$$.fragment,Ql),iSr=i(Ql),q4e=n(Ql,"P",{});var Pkt=s(q4e);dSr=r(Pkt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Pkt.forEach(t),cSr=i(Ql),_n=n(Ql,"P",{});var W6=s(_n);fSr=r(W6,"The model class to instantiate is selected based on the "),j4e=n(W6,"CODE",{});var Bkt=s(j4e);mSr=r(Bkt,"model_type"),Bkt.forEach(t),gSr=r(W6,` property of the config object (either
passed as an argument or loaded from `),D4e=n(W6,"CODE",{});var Ikt=s(D4e);hSr=r(Ikt,"pretrained_model_name_or_path"),Ikt.forEach(t),pSr=r(W6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G4e=n(W6,"CODE",{});var Nkt=s(G4e);uSr=r(Nkt,"pretrained_model_name_or_path"),Nkt.forEach(t),_Sr=r(W6,":"),W6.forEach(t),bSr=i(Ql),O4e=n(Ql,"UL",{});var qkt=s(O4e);d3=n(qkt,"LI",{});var cje=s(d3);V4e=n(cje,"STRONG",{});var jkt=s(V4e);vSr=r(jkt,"vision-encoder-decoder"),jkt.forEach(t),FSr=r(cje," \u2014 "),pK=n(cje,"A",{href:!0});var Dkt=s(pK);TSr=r(Dkt,"TFVisionEncoderDecoderModel"),Dkt.forEach(t),MSr=r(cje," (Vision Encoder decoder model)"),cje.forEach(t),qkt.forEach(t),ESr=i(Ql),T(c3.$$.fragment,Ql),Ql.forEach(t),Wl.forEach(t),QOe=i(f),qc=n(f,"H2",{class:!0});var rze=s(qc);f3=n(rze,"A",{id:!0,class:!0,href:!0});var Gkt=s(f3);X4e=n(Gkt,"SPAN",{});var Okt=s(X4e);T(Tx.$$.fragment,Okt),Okt.forEach(t),Gkt.forEach(t),CSr=i(rze),z4e=n(rze,"SPAN",{});var Vkt=s(z4e);wSr=r(Vkt,"TFAutoModelForSpeechSeq2Seq"),Vkt.forEach(t),rze.forEach(t),HOe=i(f),mr=n(f,"DIV",{class:!0});var Hl=s(mr);T(Mx.$$.fragment,Hl),ASr=i(Hl),jc=n(Hl,"P",{});var Are=s(jc);LSr=r(Are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uK=n(Are,"A",{href:!0});var Xkt=s(uK);ySr=r(Xkt,"from_pretrained()"),Xkt.forEach(t),xSr=r(Are," class method or the "),_K=n(Are,"A",{href:!0});var zkt=s(_K);$Sr=r(zkt,"from_config()"),zkt.forEach(t),kSr=r(Are,` class
method.`),Are.forEach(t),SSr=i(Hl),Ex=n(Hl,"P",{});var tze=s(Ex);RSr=r(tze,"This class cannot be instantiated directly using "),W4e=n(tze,"CODE",{});var Wkt=s(W4e);PSr=r(Wkt,"__init__()"),Wkt.forEach(t),BSr=r(tze," (throws an error)."),tze.forEach(t),ISr=i(Hl),Vt=n(Hl,"DIV",{class:!0});var Q6=s(Vt);T(Cx.$$.fragment,Q6),NSr=i(Q6),Q4e=n(Q6,"P",{});var Qkt=s(Q4e);qSr=r(Qkt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Qkt.forEach(t),jSr=i(Q6),Dc=n(Q6,"P",{});var Lre=s(Dc);DSr=r(Lre,`Note:
Loading a model from its configuration file does `),H4e=n(Lre,"STRONG",{});var Hkt=s(H4e);GSr=r(Hkt,"not"),Hkt.forEach(t),OSr=r(Lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=n(Lre,"A",{href:!0});var Ukt=s(bK);VSr=r(Ukt,"from_pretrained()"),Ukt.forEach(t),XSr=r(Lre," to load the model weights."),Lre.forEach(t),zSr=i(Q6),T(m3.$$.fragment,Q6),Q6.forEach(t),WSr=i(Hl),Dr=n(Hl,"DIV",{class:!0});var Ul=s(Dr);T(wx.$$.fragment,Ul),QSr=i(Ul),U4e=n(Ul,"P",{});var Jkt=s(U4e);HSr=r(Jkt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Jkt.forEach(t),USr=i(Ul),bn=n(Ul,"P",{});var H6=s(bn);JSr=r(H6,"The model class to instantiate is selected based on the "),J4e=n(H6,"CODE",{});var Ykt=s(J4e);YSr=r(Ykt,"model_type"),Ykt.forEach(t),KSr=r(H6,` property of the config object (either
passed as an argument or loaded from `),Y4e=n(H6,"CODE",{});var Kkt=s(Y4e);ZSr=r(Kkt,"pretrained_model_name_or_path"),Kkt.forEach(t),eRr=r(H6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=n(H6,"CODE",{});var Zkt=s(K4e);oRr=r(Zkt,"pretrained_model_name_or_path"),Zkt.forEach(t),rRr=r(H6,":"),H6.forEach(t),tRr=i(Ul),Z4e=n(Ul,"UL",{});var eSt=s(Z4e);g3=n(eSt,"LI",{});var fje=s(g3);eCe=n(fje,"STRONG",{});var oSt=s(eCe);aRr=r(oSt,"speech_to_text"),oSt.forEach(t),nRr=r(fje," \u2014 "),vK=n(fje,"A",{href:!0});var rSt=s(vK);sRr=r(rSt,"TFSpeech2TextForConditionalGeneration"),rSt.forEach(t),lRr=r(fje," (Speech2Text model)"),fje.forEach(t),eSt.forEach(t),iRr=i(Ul),T(h3.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),UOe=i(f),Gc=n(f,"H2",{class:!0});var aze=s(Gc);p3=n(aze,"A",{id:!0,class:!0,href:!0});var tSt=s(p3);oCe=n(tSt,"SPAN",{});var aSt=s(oCe);T(Ax.$$.fragment,aSt),aSt.forEach(t),tSt.forEach(t),dRr=i(aze),rCe=n(aze,"SPAN",{});var nSt=s(rCe);cRr=r(nSt,"FlaxAutoModel"),nSt.forEach(t),aze.forEach(t),JOe=i(f),gr=n(f,"DIV",{class:!0});var Jl=s(gr);T(Lx.$$.fragment,Jl),fRr=i(Jl),Oc=n(Jl,"P",{});var yre=s(Oc);mRr=r(yre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),FK=n(yre,"A",{href:!0});var sSt=s(FK);gRr=r(sSt,"from_pretrained()"),sSt.forEach(t),hRr=r(yre," class method or the "),TK=n(yre,"A",{href:!0});var lSt=s(TK);pRr=r(lSt,"from_config()"),lSt.forEach(t),uRr=r(yre,` class
method.`),yre.forEach(t),_Rr=i(Jl),yx=n(Jl,"P",{});var nze=s(yx);bRr=r(nze,"This class cannot be instantiated directly using "),tCe=n(nze,"CODE",{});var iSt=s(tCe);vRr=r(iSt,"__init__()"),iSt.forEach(t),FRr=r(nze," (throws an error)."),nze.forEach(t),TRr=i(Jl),Xt=n(Jl,"DIV",{class:!0});var U6=s(Xt);T(xx.$$.fragment,U6),MRr=i(U6),aCe=n(U6,"P",{});var dSt=s(aCe);ERr=r(dSt,"Instantiates one of the base model classes of the library from a configuration."),dSt.forEach(t),CRr=i(U6),Vc=n(U6,"P",{});var xre=s(Vc);wRr=r(xre,`Note:
Loading a model from its configuration file does `),nCe=n(xre,"STRONG",{});var cSt=s(nCe);ARr=r(cSt,"not"),cSt.forEach(t),LRr=r(xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),MK=n(xre,"A",{href:!0});var fSt=s(MK);yRr=r(fSt,"from_pretrained()"),fSt.forEach(t),xRr=r(xre," to load the model weights."),xre.forEach(t),$Rr=i(U6),T(u3.$$.fragment,U6),U6.forEach(t),kRr=i(Jl),Gr=n(Jl,"DIV",{class:!0});var Yl=s(Gr);T($x.$$.fragment,Yl),SRr=i(Yl),sCe=n(Yl,"P",{});var mSt=s(sCe);RRr=r(mSt,"Instantiate one of the base model classes of the library from a pretrained model."),mSt.forEach(t),PRr=i(Yl),vn=n(Yl,"P",{});var J6=s(vn);BRr=r(J6,"The model class to instantiate is selected based on the "),lCe=n(J6,"CODE",{});var gSt=s(lCe);IRr=r(gSt,"model_type"),gSt.forEach(t),NRr=r(J6,` property of the config object (either
passed as an argument or loaded from `),iCe=n(J6,"CODE",{});var hSt=s(iCe);qRr=r(hSt,"pretrained_model_name_or_path"),hSt.forEach(t),jRr=r(J6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dCe=n(J6,"CODE",{});var pSt=s(dCe);DRr=r(pSt,"pretrained_model_name_or_path"),pSt.forEach(t),GRr=r(J6,":"),J6.forEach(t),ORr=i(Yl),oe=n(Yl,"UL",{});var ae=s(oe);_3=n(ae,"LI",{});var mje=s(_3);cCe=n(mje,"STRONG",{});var uSt=s(cCe);VRr=r(uSt,"albert"),uSt.forEach(t),XRr=r(mje," \u2014 "),EK=n(mje,"A",{href:!0});var _St=s(EK);zRr=r(_St,"FlaxAlbertModel"),_St.forEach(t),WRr=r(mje," (ALBERT model)"),mje.forEach(t),QRr=i(ae),b3=n(ae,"LI",{});var gje=s(b3);fCe=n(gje,"STRONG",{});var bSt=s(fCe);HRr=r(bSt,"bart"),bSt.forEach(t),URr=r(gje," \u2014 "),CK=n(gje,"A",{href:!0});var vSt=s(CK);JRr=r(vSt,"FlaxBartModel"),vSt.forEach(t),YRr=r(gje," (BART model)"),gje.forEach(t),KRr=i(ae),v3=n(ae,"LI",{});var hje=s(v3);mCe=n(hje,"STRONG",{});var FSt=s(mCe);ZRr=r(FSt,"beit"),FSt.forEach(t),ePr=r(hje," \u2014 "),wK=n(hje,"A",{href:!0});var TSt=s(wK);oPr=r(TSt,"FlaxBeitModel"),TSt.forEach(t),rPr=r(hje," (BEiT model)"),hje.forEach(t),tPr=i(ae),F3=n(ae,"LI",{});var pje=s(F3);gCe=n(pje,"STRONG",{});var MSt=s(gCe);aPr=r(MSt,"bert"),MSt.forEach(t),nPr=r(pje," \u2014 "),AK=n(pje,"A",{href:!0});var ESt=s(AK);sPr=r(ESt,"FlaxBertModel"),ESt.forEach(t),lPr=r(pje," (BERT model)"),pje.forEach(t),iPr=i(ae),T3=n(ae,"LI",{});var uje=s(T3);hCe=n(uje,"STRONG",{});var CSt=s(hCe);dPr=r(CSt,"big_bird"),CSt.forEach(t),cPr=r(uje," \u2014 "),LK=n(uje,"A",{href:!0});var wSt=s(LK);fPr=r(wSt,"FlaxBigBirdModel"),wSt.forEach(t),mPr=r(uje," (BigBird model)"),uje.forEach(t),gPr=i(ae),M3=n(ae,"LI",{});var _je=s(M3);pCe=n(_je,"STRONG",{});var ASt=s(pCe);hPr=r(ASt,"blenderbot"),ASt.forEach(t),pPr=r(_je," \u2014 "),yK=n(_je,"A",{href:!0});var LSt=s(yK);uPr=r(LSt,"FlaxBlenderbotModel"),LSt.forEach(t),_Pr=r(_je," (Blenderbot model)"),_je.forEach(t),bPr=i(ae),E3=n(ae,"LI",{});var bje=s(E3);uCe=n(bje,"STRONG",{});var ySt=s(uCe);vPr=r(ySt,"blenderbot-small"),ySt.forEach(t),FPr=r(bje," \u2014 "),xK=n(bje,"A",{href:!0});var xSt=s(xK);TPr=r(xSt,"FlaxBlenderbotSmallModel"),xSt.forEach(t),MPr=r(bje," (BlenderbotSmall model)"),bje.forEach(t),EPr=i(ae),C3=n(ae,"LI",{});var vje=s(C3);_Ce=n(vje,"STRONG",{});var $St=s(_Ce);CPr=r($St,"clip"),$St.forEach(t),wPr=r(vje," \u2014 "),$K=n(vje,"A",{href:!0});var kSt=s($K);APr=r(kSt,"FlaxCLIPModel"),kSt.forEach(t),LPr=r(vje," (CLIP model)"),vje.forEach(t),yPr=i(ae),w3=n(ae,"LI",{});var Fje=s(w3);bCe=n(Fje,"STRONG",{});var SSt=s(bCe);xPr=r(SSt,"distilbert"),SSt.forEach(t),$Pr=r(Fje," \u2014 "),kK=n(Fje,"A",{href:!0});var RSt=s(kK);kPr=r(RSt,"FlaxDistilBertModel"),RSt.forEach(t),SPr=r(Fje," (DistilBERT model)"),Fje.forEach(t),RPr=i(ae),A3=n(ae,"LI",{});var Tje=s(A3);vCe=n(Tje,"STRONG",{});var PSt=s(vCe);PPr=r(PSt,"electra"),PSt.forEach(t),BPr=r(Tje," \u2014 "),SK=n(Tje,"A",{href:!0});var BSt=s(SK);IPr=r(BSt,"FlaxElectraModel"),BSt.forEach(t),NPr=r(Tje," (ELECTRA model)"),Tje.forEach(t),qPr=i(ae),L3=n(ae,"LI",{});var Mje=s(L3);FCe=n(Mje,"STRONG",{});var ISt=s(FCe);jPr=r(ISt,"gpt2"),ISt.forEach(t),DPr=r(Mje," \u2014 "),RK=n(Mje,"A",{href:!0});var NSt=s(RK);GPr=r(NSt,"FlaxGPT2Model"),NSt.forEach(t),OPr=r(Mje," (OpenAI GPT-2 model)"),Mje.forEach(t),VPr=i(ae),y3=n(ae,"LI",{});var Eje=s(y3);TCe=n(Eje,"STRONG",{});var qSt=s(TCe);XPr=r(qSt,"gpt_neo"),qSt.forEach(t),zPr=r(Eje," \u2014 "),PK=n(Eje,"A",{href:!0});var jSt=s(PK);WPr=r(jSt,"FlaxGPTNeoModel"),jSt.forEach(t),QPr=r(Eje," (GPT Neo model)"),Eje.forEach(t),HPr=i(ae),x3=n(ae,"LI",{});var Cje=s(x3);MCe=n(Cje,"STRONG",{});var DSt=s(MCe);UPr=r(DSt,"gptj"),DSt.forEach(t),JPr=r(Cje," \u2014 "),BK=n(Cje,"A",{href:!0});var GSt=s(BK);YPr=r(GSt,"FlaxGPTJModel"),GSt.forEach(t),KPr=r(Cje," (GPT-J model)"),Cje.forEach(t),ZPr=i(ae),$3=n(ae,"LI",{});var wje=s($3);ECe=n(wje,"STRONG",{});var OSt=s(ECe);eBr=r(OSt,"longt5"),OSt.forEach(t),oBr=r(wje," \u2014 "),IK=n(wje,"A",{href:!0});var VSt=s(IK);rBr=r(VSt,"FlaxLongT5Model"),VSt.forEach(t),tBr=r(wje," (LongT5 model)"),wje.forEach(t),aBr=i(ae),k3=n(ae,"LI",{});var Aje=s(k3);CCe=n(Aje,"STRONG",{});var XSt=s(CCe);nBr=r(XSt,"marian"),XSt.forEach(t),sBr=r(Aje," \u2014 "),NK=n(Aje,"A",{href:!0});var zSt=s(NK);lBr=r(zSt,"FlaxMarianModel"),zSt.forEach(t),iBr=r(Aje," (Marian model)"),Aje.forEach(t),dBr=i(ae),S3=n(ae,"LI",{});var Lje=s(S3);wCe=n(Lje,"STRONG",{});var WSt=s(wCe);cBr=r(WSt,"mbart"),WSt.forEach(t),fBr=r(Lje," \u2014 "),qK=n(Lje,"A",{href:!0});var QSt=s(qK);mBr=r(QSt,"FlaxMBartModel"),QSt.forEach(t),gBr=r(Lje," (mBART model)"),Lje.forEach(t),hBr=i(ae),R3=n(ae,"LI",{});var yje=s(R3);ACe=n(yje,"STRONG",{});var HSt=s(ACe);pBr=r(HSt,"mt5"),HSt.forEach(t),uBr=r(yje," \u2014 "),jK=n(yje,"A",{href:!0});var USt=s(jK);_Br=r(USt,"FlaxMT5Model"),USt.forEach(t),bBr=r(yje," (MT5 model)"),yje.forEach(t),vBr=i(ae),P3=n(ae,"LI",{});var xje=s(P3);LCe=n(xje,"STRONG",{});var JSt=s(LCe);FBr=r(JSt,"opt"),JSt.forEach(t),TBr=r(xje," \u2014 "),DK=n(xje,"A",{href:!0});var YSt=s(DK);MBr=r(YSt,"FlaxOPTModel"),YSt.forEach(t),EBr=r(xje," (OPT model)"),xje.forEach(t),CBr=i(ae),B3=n(ae,"LI",{});var $je=s(B3);yCe=n($je,"STRONG",{});var KSt=s(yCe);wBr=r(KSt,"pegasus"),KSt.forEach(t),ABr=r($je," \u2014 "),GK=n($je,"A",{href:!0});var ZSt=s(GK);LBr=r(ZSt,"FlaxPegasusModel"),ZSt.forEach(t),yBr=r($je," (Pegasus model)"),$je.forEach(t),xBr=i(ae),I3=n(ae,"LI",{});var kje=s(I3);xCe=n(kje,"STRONG",{});var eRt=s(xCe);$Br=r(eRt,"roberta"),eRt.forEach(t),kBr=r(kje," \u2014 "),OK=n(kje,"A",{href:!0});var oRt=s(OK);SBr=r(oRt,"FlaxRobertaModel"),oRt.forEach(t),RBr=r(kje," (RoBERTa model)"),kje.forEach(t),PBr=i(ae),N3=n(ae,"LI",{});var Sje=s(N3);$Ce=n(Sje,"STRONG",{});var rRt=s($Ce);BBr=r(rRt,"roformer"),rRt.forEach(t),IBr=r(Sje," \u2014 "),VK=n(Sje,"A",{href:!0});var tRt=s(VK);NBr=r(tRt,"FlaxRoFormerModel"),tRt.forEach(t),qBr=r(Sje," (RoFormer model)"),Sje.forEach(t),jBr=i(ae),q3=n(ae,"LI",{});var Rje=s(q3);kCe=n(Rje,"STRONG",{});var aRt=s(kCe);DBr=r(aRt,"t5"),aRt.forEach(t),GBr=r(Rje," \u2014 "),XK=n(Rje,"A",{href:!0});var nRt=s(XK);OBr=r(nRt,"FlaxT5Model"),nRt.forEach(t),VBr=r(Rje," (T5 model)"),Rje.forEach(t),XBr=i(ae),j3=n(ae,"LI",{});var Pje=s(j3);SCe=n(Pje,"STRONG",{});var sRt=s(SCe);zBr=r(sRt,"vision-text-dual-encoder"),sRt.forEach(t),WBr=r(Pje," \u2014 "),zK=n(Pje,"A",{href:!0});var lRt=s(zK);QBr=r(lRt,"FlaxVisionTextDualEncoderModel"),lRt.forEach(t),HBr=r(Pje," (VisionTextDualEncoder model)"),Pje.forEach(t),UBr=i(ae),D3=n(ae,"LI",{});var Bje=s(D3);RCe=n(Bje,"STRONG",{});var iRt=s(RCe);JBr=r(iRt,"vit"),iRt.forEach(t),YBr=r(Bje," \u2014 "),WK=n(Bje,"A",{href:!0});var dRt=s(WK);KBr=r(dRt,"FlaxViTModel"),dRt.forEach(t),ZBr=r(Bje," (ViT model)"),Bje.forEach(t),eIr=i(ae),G3=n(ae,"LI",{});var Ije=s(G3);PCe=n(Ije,"STRONG",{});var cRt=s(PCe);oIr=r(cRt,"wav2vec2"),cRt.forEach(t),rIr=r(Ije," \u2014 "),QK=n(Ije,"A",{href:!0});var fRt=s(QK);tIr=r(fRt,"FlaxWav2Vec2Model"),fRt.forEach(t),aIr=r(Ije," (Wav2Vec2 model)"),Ije.forEach(t),nIr=i(ae),O3=n(ae,"LI",{});var Nje=s(O3);BCe=n(Nje,"STRONG",{});var mRt=s(BCe);sIr=r(mRt,"xglm"),mRt.forEach(t),lIr=r(Nje," \u2014 "),HK=n(Nje,"A",{href:!0});var gRt=s(HK);iIr=r(gRt,"FlaxXGLMModel"),gRt.forEach(t),dIr=r(Nje," (XGLM model)"),Nje.forEach(t),cIr=i(ae),V3=n(ae,"LI",{});var qje=s(V3);ICe=n(qje,"STRONG",{});var hRt=s(ICe);fIr=r(hRt,"xlm-roberta"),hRt.forEach(t),mIr=r(qje," \u2014 "),UK=n(qje,"A",{href:!0});var pRt=s(UK);gIr=r(pRt,"FlaxXLMRobertaModel"),pRt.forEach(t),hIr=r(qje," (XLM-RoBERTa model)"),qje.forEach(t),ae.forEach(t),pIr=i(Yl),T(X3.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),YOe=i(f),Xc=n(f,"H2",{class:!0});var sze=s(Xc);z3=n(sze,"A",{id:!0,class:!0,href:!0});var uRt=s(z3);NCe=n(uRt,"SPAN",{});var _Rt=s(NCe);T(kx.$$.fragment,_Rt),_Rt.forEach(t),uRt.forEach(t),uIr=i(sze),qCe=n(sze,"SPAN",{});var bRt=s(qCe);_Ir=r(bRt,"FlaxAutoModelForCausalLM"),bRt.forEach(t),sze.forEach(t),KOe=i(f),hr=n(f,"DIV",{class:!0});var Kl=s(hr);T(Sx.$$.fragment,Kl),bIr=i(Kl),zc=n(Kl,"P",{});var $re=s(zc);vIr=r($re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),JK=n($re,"A",{href:!0});var vRt=s(JK);FIr=r(vRt,"from_pretrained()"),vRt.forEach(t),TIr=r($re," class method or the "),YK=n($re,"A",{href:!0});var FRt=s(YK);MIr=r(FRt,"from_config()"),FRt.forEach(t),EIr=r($re,` class
method.`),$re.forEach(t),CIr=i(Kl),Rx=n(Kl,"P",{});var lze=s(Rx);wIr=r(lze,"This class cannot be instantiated directly using "),jCe=n(lze,"CODE",{});var TRt=s(jCe);AIr=r(TRt,"__init__()"),TRt.forEach(t),LIr=r(lze," (throws an error)."),lze.forEach(t),yIr=i(Kl),zt=n(Kl,"DIV",{class:!0});var Y6=s(zt);T(Px.$$.fragment,Y6),xIr=i(Y6),DCe=n(Y6,"P",{});var MRt=s(DCe);$Ir=r(MRt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),MRt.forEach(t),kIr=i(Y6),Wc=n(Y6,"P",{});var kre=s(Wc);SIr=r(kre,`Note:
Loading a model from its configuration file does `),GCe=n(kre,"STRONG",{});var ERt=s(GCe);RIr=r(ERt,"not"),ERt.forEach(t),PIr=r(kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),KK=n(kre,"A",{href:!0});var CRt=s(KK);BIr=r(CRt,"from_pretrained()"),CRt.forEach(t),IIr=r(kre," to load the model weights."),kre.forEach(t),NIr=i(Y6),T(W3.$$.fragment,Y6),Y6.forEach(t),qIr=i(Kl),Or=n(Kl,"DIV",{class:!0});var Zl=s(Or);T(Bx.$$.fragment,Zl),jIr=i(Zl),OCe=n(Zl,"P",{});var wRt=s(OCe);DIr=r(wRt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),wRt.forEach(t),GIr=i(Zl),Fn=n(Zl,"P",{});var K6=s(Fn);OIr=r(K6,"The model class to instantiate is selected based on the "),VCe=n(K6,"CODE",{});var ARt=s(VCe);VIr=r(ARt,"model_type"),ARt.forEach(t),XIr=r(K6,` property of the config object (either
passed as an argument or loaded from `),XCe=n(K6,"CODE",{});var LRt=s(XCe);zIr=r(LRt,"pretrained_model_name_or_path"),LRt.forEach(t),WIr=r(K6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zCe=n(K6,"CODE",{});var yRt=s(zCe);QIr=r(yRt,"pretrained_model_name_or_path"),yRt.forEach(t),HIr=r(K6,":"),K6.forEach(t),UIr=i(Zl),xe=n(Zl,"UL",{});var Ne=s(xe);Q3=n(Ne,"LI",{});var jje=s(Q3);WCe=n(jje,"STRONG",{});var xRt=s(WCe);JIr=r(xRt,"bart"),xRt.forEach(t),YIr=r(jje," \u2014 "),ZK=n(jje,"A",{href:!0});var $Rt=s(ZK);KIr=r($Rt,"FlaxBartForCausalLM"),$Rt.forEach(t),ZIr=r(jje," (BART model)"),jje.forEach(t),eNr=i(Ne),H3=n(Ne,"LI",{});var Dje=s(H3);QCe=n(Dje,"STRONG",{});var kRt=s(QCe);oNr=r(kRt,"bert"),kRt.forEach(t),rNr=r(Dje," \u2014 "),eZ=n(Dje,"A",{href:!0});var SRt=s(eZ);tNr=r(SRt,"FlaxBertForCausalLM"),SRt.forEach(t),aNr=r(Dje," (BERT model)"),Dje.forEach(t),nNr=i(Ne),U3=n(Ne,"LI",{});var Gje=s(U3);HCe=n(Gje,"STRONG",{});var RRt=s(HCe);sNr=r(RRt,"big_bird"),RRt.forEach(t),lNr=r(Gje," \u2014 "),oZ=n(Gje,"A",{href:!0});var PRt=s(oZ);iNr=r(PRt,"FlaxBigBirdForCausalLM"),PRt.forEach(t),dNr=r(Gje," (BigBird model)"),Gje.forEach(t),cNr=i(Ne),J3=n(Ne,"LI",{});var Oje=s(J3);UCe=n(Oje,"STRONG",{});var BRt=s(UCe);fNr=r(BRt,"electra"),BRt.forEach(t),mNr=r(Oje," \u2014 "),rZ=n(Oje,"A",{href:!0});var IRt=s(rZ);gNr=r(IRt,"FlaxElectraForCausalLM"),IRt.forEach(t),hNr=r(Oje," (ELECTRA model)"),Oje.forEach(t),pNr=i(Ne),Y3=n(Ne,"LI",{});var Vje=s(Y3);JCe=n(Vje,"STRONG",{});var NRt=s(JCe);uNr=r(NRt,"gpt2"),NRt.forEach(t),_Nr=r(Vje," \u2014 "),tZ=n(Vje,"A",{href:!0});var qRt=s(tZ);bNr=r(qRt,"FlaxGPT2LMHeadModel"),qRt.forEach(t),vNr=r(Vje," (OpenAI GPT-2 model)"),Vje.forEach(t),FNr=i(Ne),K3=n(Ne,"LI",{});var Xje=s(K3);YCe=n(Xje,"STRONG",{});var jRt=s(YCe);TNr=r(jRt,"gpt_neo"),jRt.forEach(t),MNr=r(Xje," \u2014 "),aZ=n(Xje,"A",{href:!0});var DRt=s(aZ);ENr=r(DRt,"FlaxGPTNeoForCausalLM"),DRt.forEach(t),CNr=r(Xje," (GPT Neo model)"),Xje.forEach(t),wNr=i(Ne),Z3=n(Ne,"LI",{});var zje=s(Z3);KCe=n(zje,"STRONG",{});var GRt=s(KCe);ANr=r(GRt,"gptj"),GRt.forEach(t),LNr=r(zje," \u2014 "),nZ=n(zje,"A",{href:!0});var ORt=s(nZ);yNr=r(ORt,"FlaxGPTJForCausalLM"),ORt.forEach(t),xNr=r(zje," (GPT-J model)"),zje.forEach(t),$Nr=i(Ne),e0=n(Ne,"LI",{});var Wje=s(e0);ZCe=n(Wje,"STRONG",{});var VRt=s(ZCe);kNr=r(VRt,"opt"),VRt.forEach(t),SNr=r(Wje," \u2014 "),sZ=n(Wje,"A",{href:!0});var XRt=s(sZ);RNr=r(XRt,"FlaxOPTForCausalLM"),XRt.forEach(t),PNr=r(Wje," (OPT model)"),Wje.forEach(t),BNr=i(Ne),o0=n(Ne,"LI",{});var Qje=s(o0);e5e=n(Qje,"STRONG",{});var zRt=s(e5e);INr=r(zRt,"roberta"),zRt.forEach(t),NNr=r(Qje," \u2014 "),lZ=n(Qje,"A",{href:!0});var WRt=s(lZ);qNr=r(WRt,"FlaxRobertaForCausalLM"),WRt.forEach(t),jNr=r(Qje," (RoBERTa model)"),Qje.forEach(t),DNr=i(Ne),r0=n(Ne,"LI",{});var Hje=s(r0);o5e=n(Hje,"STRONG",{});var QRt=s(o5e);GNr=r(QRt,"xglm"),QRt.forEach(t),ONr=r(Hje," \u2014 "),iZ=n(Hje,"A",{href:!0});var HRt=s(iZ);VNr=r(HRt,"FlaxXGLMForCausalLM"),HRt.forEach(t),XNr=r(Hje," (XGLM model)"),Hje.forEach(t),Ne.forEach(t),zNr=i(Zl),T(t0.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),ZOe=i(f),Qc=n(f,"H2",{class:!0});var ize=s(Qc);a0=n(ize,"A",{id:!0,class:!0,href:!0});var URt=s(a0);r5e=n(URt,"SPAN",{});var JRt=s(r5e);T(Ix.$$.fragment,JRt),JRt.forEach(t),URt.forEach(t),WNr=i(ize),t5e=n(ize,"SPAN",{});var YRt=s(t5e);QNr=r(YRt,"FlaxAutoModelForPreTraining"),YRt.forEach(t),ize.forEach(t),eVe=i(f),pr=n(f,"DIV",{class:!0});var ei=s(pr);T(Nx.$$.fragment,ei),HNr=i(ei),Hc=n(ei,"P",{});var Sre=s(Hc);UNr=r(Sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),dZ=n(Sre,"A",{href:!0});var KRt=s(dZ);JNr=r(KRt,"from_pretrained()"),KRt.forEach(t),YNr=r(Sre," class method or the "),cZ=n(Sre,"A",{href:!0});var ZRt=s(cZ);KNr=r(ZRt,"from_config()"),ZRt.forEach(t),ZNr=r(Sre,` class
method.`),Sre.forEach(t),eqr=i(ei),qx=n(ei,"P",{});var dze=s(qx);oqr=r(dze,"This class cannot be instantiated directly using "),a5e=n(dze,"CODE",{});var ePt=s(a5e);rqr=r(ePt,"__init__()"),ePt.forEach(t),tqr=r(dze," (throws an error)."),dze.forEach(t),aqr=i(ei),Wt=n(ei,"DIV",{class:!0});var Z6=s(Wt);T(jx.$$.fragment,Z6),nqr=i(Z6),n5e=n(Z6,"P",{});var oPt=s(n5e);sqr=r(oPt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),oPt.forEach(t),lqr=i(Z6),Uc=n(Z6,"P",{});var Rre=s(Uc);iqr=r(Rre,`Note:
Loading a model from its configuration file does `),s5e=n(Rre,"STRONG",{});var rPt=s(s5e);dqr=r(rPt,"not"),rPt.forEach(t),cqr=r(Rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),fZ=n(Rre,"A",{href:!0});var tPt=s(fZ);fqr=r(tPt,"from_pretrained()"),tPt.forEach(t),mqr=r(Rre," to load the model weights."),Rre.forEach(t),gqr=i(Z6),T(n0.$$.fragment,Z6),Z6.forEach(t),hqr=i(ei),Vr=n(ei,"DIV",{class:!0});var oi=s(Vr);T(Dx.$$.fragment,oi),pqr=i(oi),l5e=n(oi,"P",{});var aPt=s(l5e);uqr=r(aPt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),aPt.forEach(t),_qr=i(oi),Tn=n(oi,"P",{});var eL=s(Tn);bqr=r(eL,"The model class to instantiate is selected based on the "),i5e=n(eL,"CODE",{});var nPt=s(i5e);vqr=r(nPt,"model_type"),nPt.forEach(t),Fqr=r(eL,` property of the config object (either
passed as an argument or loaded from `),d5e=n(eL,"CODE",{});var sPt=s(d5e);Tqr=r(sPt,"pretrained_model_name_or_path"),sPt.forEach(t),Mqr=r(eL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c5e=n(eL,"CODE",{});var lPt=s(c5e);Eqr=r(lPt,"pretrained_model_name_or_path"),lPt.forEach(t),Cqr=r(eL,":"),eL.forEach(t),wqr=i(oi),Ee=n(oi,"UL",{});var we=s(Ee);s0=n(we,"LI",{});var Uje=s(s0);f5e=n(Uje,"STRONG",{});var iPt=s(f5e);Aqr=r(iPt,"albert"),iPt.forEach(t),Lqr=r(Uje," \u2014 "),mZ=n(Uje,"A",{href:!0});var dPt=s(mZ);yqr=r(dPt,"FlaxAlbertForPreTraining"),dPt.forEach(t),xqr=r(Uje," (ALBERT model)"),Uje.forEach(t),$qr=i(we),l0=n(we,"LI",{});var Jje=s(l0);m5e=n(Jje,"STRONG",{});var cPt=s(m5e);kqr=r(cPt,"bart"),cPt.forEach(t),Sqr=r(Jje," \u2014 "),gZ=n(Jje,"A",{href:!0});var fPt=s(gZ);Rqr=r(fPt,"FlaxBartForConditionalGeneration"),fPt.forEach(t),Pqr=r(Jje," (BART model)"),Jje.forEach(t),Bqr=i(we),i0=n(we,"LI",{});var Yje=s(i0);g5e=n(Yje,"STRONG",{});var mPt=s(g5e);Iqr=r(mPt,"bert"),mPt.forEach(t),Nqr=r(Yje," \u2014 "),hZ=n(Yje,"A",{href:!0});var gPt=s(hZ);qqr=r(gPt,"FlaxBertForPreTraining"),gPt.forEach(t),jqr=r(Yje," (BERT model)"),Yje.forEach(t),Dqr=i(we),d0=n(we,"LI",{});var Kje=s(d0);h5e=n(Kje,"STRONG",{});var hPt=s(h5e);Gqr=r(hPt,"big_bird"),hPt.forEach(t),Oqr=r(Kje," \u2014 "),pZ=n(Kje,"A",{href:!0});var pPt=s(pZ);Vqr=r(pPt,"FlaxBigBirdForPreTraining"),pPt.forEach(t),Xqr=r(Kje," (BigBird model)"),Kje.forEach(t),zqr=i(we),c0=n(we,"LI",{});var Zje=s(c0);p5e=n(Zje,"STRONG",{});var uPt=s(p5e);Wqr=r(uPt,"electra"),uPt.forEach(t),Qqr=r(Zje," \u2014 "),uZ=n(Zje,"A",{href:!0});var _Pt=s(uZ);Hqr=r(_Pt,"FlaxElectraForPreTraining"),_Pt.forEach(t),Uqr=r(Zje," (ELECTRA model)"),Zje.forEach(t),Jqr=i(we),f0=n(we,"LI",{});var eDe=s(f0);u5e=n(eDe,"STRONG",{});var bPt=s(u5e);Yqr=r(bPt,"longt5"),bPt.forEach(t),Kqr=r(eDe," \u2014 "),_Z=n(eDe,"A",{href:!0});var vPt=s(_Z);Zqr=r(vPt,"FlaxLongT5ForConditionalGeneration"),vPt.forEach(t),ejr=r(eDe," (LongT5 model)"),eDe.forEach(t),ojr=i(we),m0=n(we,"LI",{});var oDe=s(m0);_5e=n(oDe,"STRONG",{});var FPt=s(_5e);rjr=r(FPt,"mbart"),FPt.forEach(t),tjr=r(oDe," \u2014 "),bZ=n(oDe,"A",{href:!0});var TPt=s(bZ);ajr=r(TPt,"FlaxMBartForConditionalGeneration"),TPt.forEach(t),njr=r(oDe," (mBART model)"),oDe.forEach(t),sjr=i(we),g0=n(we,"LI",{});var rDe=s(g0);b5e=n(rDe,"STRONG",{});var MPt=s(b5e);ljr=r(MPt,"mt5"),MPt.forEach(t),ijr=r(rDe," \u2014 "),vZ=n(rDe,"A",{href:!0});var EPt=s(vZ);djr=r(EPt,"FlaxMT5ForConditionalGeneration"),EPt.forEach(t),cjr=r(rDe," (MT5 model)"),rDe.forEach(t),fjr=i(we),h0=n(we,"LI",{});var tDe=s(h0);v5e=n(tDe,"STRONG",{});var CPt=s(v5e);mjr=r(CPt,"roberta"),CPt.forEach(t),gjr=r(tDe," \u2014 "),FZ=n(tDe,"A",{href:!0});var wPt=s(FZ);hjr=r(wPt,"FlaxRobertaForMaskedLM"),wPt.forEach(t),pjr=r(tDe," (RoBERTa model)"),tDe.forEach(t),ujr=i(we),p0=n(we,"LI",{});var aDe=s(p0);F5e=n(aDe,"STRONG",{});var APt=s(F5e);_jr=r(APt,"roformer"),APt.forEach(t),bjr=r(aDe," \u2014 "),TZ=n(aDe,"A",{href:!0});var LPt=s(TZ);vjr=r(LPt,"FlaxRoFormerForMaskedLM"),LPt.forEach(t),Fjr=r(aDe," (RoFormer model)"),aDe.forEach(t),Tjr=i(we),u0=n(we,"LI",{});var nDe=s(u0);T5e=n(nDe,"STRONG",{});var yPt=s(T5e);Mjr=r(yPt,"t5"),yPt.forEach(t),Ejr=r(nDe," \u2014 "),MZ=n(nDe,"A",{href:!0});var xPt=s(MZ);Cjr=r(xPt,"FlaxT5ForConditionalGeneration"),xPt.forEach(t),wjr=r(nDe," (T5 model)"),nDe.forEach(t),Ajr=i(we),_0=n(we,"LI",{});var sDe=s(_0);M5e=n(sDe,"STRONG",{});var $Pt=s(M5e);Ljr=r($Pt,"wav2vec2"),$Pt.forEach(t),yjr=r(sDe," \u2014 "),EZ=n(sDe,"A",{href:!0});var kPt=s(EZ);xjr=r(kPt,"FlaxWav2Vec2ForPreTraining"),kPt.forEach(t),$jr=r(sDe," (Wav2Vec2 model)"),sDe.forEach(t),kjr=i(we),b0=n(we,"LI",{});var lDe=s(b0);E5e=n(lDe,"STRONG",{});var SPt=s(E5e);Sjr=r(SPt,"xlm-roberta"),SPt.forEach(t),Rjr=r(lDe," \u2014 "),CZ=n(lDe,"A",{href:!0});var RPt=s(CZ);Pjr=r(RPt,"FlaxXLMRobertaForMaskedLM"),RPt.forEach(t),Bjr=r(lDe," (XLM-RoBERTa model)"),lDe.forEach(t),we.forEach(t),Ijr=i(oi),T(v0.$$.fragment,oi),oi.forEach(t),ei.forEach(t),oVe=i(f),Jc=n(f,"H2",{class:!0});var cze=s(Jc);F0=n(cze,"A",{id:!0,class:!0,href:!0});var PPt=s(F0);C5e=n(PPt,"SPAN",{});var BPt=s(C5e);T(Gx.$$.fragment,BPt),BPt.forEach(t),PPt.forEach(t),Njr=i(cze),w5e=n(cze,"SPAN",{});var IPt=s(w5e);qjr=r(IPt,"FlaxAutoModelForMaskedLM"),IPt.forEach(t),cze.forEach(t),rVe=i(f),ur=n(f,"DIV",{class:!0});var ri=s(ur);T(Ox.$$.fragment,ri),jjr=i(ri),Yc=n(ri,"P",{});var Pre=s(Yc);Djr=r(Pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),wZ=n(Pre,"A",{href:!0});var NPt=s(wZ);Gjr=r(NPt,"from_pretrained()"),NPt.forEach(t),Ojr=r(Pre," class method or the "),AZ=n(Pre,"A",{href:!0});var qPt=s(AZ);Vjr=r(qPt,"from_config()"),qPt.forEach(t),Xjr=r(Pre,` class
method.`),Pre.forEach(t),zjr=i(ri),Vx=n(ri,"P",{});var fze=s(Vx);Wjr=r(fze,"This class cannot be instantiated directly using "),A5e=n(fze,"CODE",{});var jPt=s(A5e);Qjr=r(jPt,"__init__()"),jPt.forEach(t),Hjr=r(fze," (throws an error)."),fze.forEach(t),Ujr=i(ri),Qt=n(ri,"DIV",{class:!0});var oL=s(Qt);T(Xx.$$.fragment,oL),Jjr=i(oL),L5e=n(oL,"P",{});var DPt=s(L5e);Yjr=r(DPt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),DPt.forEach(t),Kjr=i(oL),Kc=n(oL,"P",{});var Bre=s(Kc);Zjr=r(Bre,`Note:
Loading a model from its configuration file does `),y5e=n(Bre,"STRONG",{});var GPt=s(y5e);eDr=r(GPt,"not"),GPt.forEach(t),oDr=r(Bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LZ=n(Bre,"A",{href:!0});var OPt=s(LZ);rDr=r(OPt,"from_pretrained()"),OPt.forEach(t),tDr=r(Bre," to load the model weights."),Bre.forEach(t),aDr=i(oL),T(T0.$$.fragment,oL),oL.forEach(t),nDr=i(ri),Xr=n(ri,"DIV",{class:!0});var ti=s(Xr);T(zx.$$.fragment,ti),sDr=i(ti),x5e=n(ti,"P",{});var VPt=s(x5e);lDr=r(VPt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),VPt.forEach(t),iDr=i(ti),Mn=n(ti,"P",{});var rL=s(Mn);dDr=r(rL,"The model class to instantiate is selected based on the "),$5e=n(rL,"CODE",{});var XPt=s($5e);cDr=r(XPt,"model_type"),XPt.forEach(t),fDr=r(rL,` property of the config object (either
passed as an argument or loaded from `),k5e=n(rL,"CODE",{});var zPt=s(k5e);mDr=r(zPt,"pretrained_model_name_or_path"),zPt.forEach(t),gDr=r(rL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S5e=n(rL,"CODE",{});var WPt=s(S5e);hDr=r(WPt,"pretrained_model_name_or_path"),WPt.forEach(t),pDr=r(rL,":"),rL.forEach(t),uDr=i(ti),$e=n(ti,"UL",{});var qe=s($e);M0=n(qe,"LI",{});var iDe=s(M0);R5e=n(iDe,"STRONG",{});var QPt=s(R5e);_Dr=r(QPt,"albert"),QPt.forEach(t),bDr=r(iDe," \u2014 "),yZ=n(iDe,"A",{href:!0});var HPt=s(yZ);vDr=r(HPt,"FlaxAlbertForMaskedLM"),HPt.forEach(t),FDr=r(iDe," (ALBERT model)"),iDe.forEach(t),TDr=i(qe),E0=n(qe,"LI",{});var dDe=s(E0);P5e=n(dDe,"STRONG",{});var UPt=s(P5e);MDr=r(UPt,"bart"),UPt.forEach(t),EDr=r(dDe," \u2014 "),xZ=n(dDe,"A",{href:!0});var JPt=s(xZ);CDr=r(JPt,"FlaxBartForConditionalGeneration"),JPt.forEach(t),wDr=r(dDe," (BART model)"),dDe.forEach(t),ADr=i(qe),C0=n(qe,"LI",{});var cDe=s(C0);B5e=n(cDe,"STRONG",{});var YPt=s(B5e);LDr=r(YPt,"bert"),YPt.forEach(t),yDr=r(cDe," \u2014 "),$Z=n(cDe,"A",{href:!0});var KPt=s($Z);xDr=r(KPt,"FlaxBertForMaskedLM"),KPt.forEach(t),$Dr=r(cDe," (BERT model)"),cDe.forEach(t),kDr=i(qe),w0=n(qe,"LI",{});var fDe=s(w0);I5e=n(fDe,"STRONG",{});var ZPt=s(I5e);SDr=r(ZPt,"big_bird"),ZPt.forEach(t),RDr=r(fDe," \u2014 "),kZ=n(fDe,"A",{href:!0});var eBt=s(kZ);PDr=r(eBt,"FlaxBigBirdForMaskedLM"),eBt.forEach(t),BDr=r(fDe," (BigBird model)"),fDe.forEach(t),IDr=i(qe),A0=n(qe,"LI",{});var mDe=s(A0);N5e=n(mDe,"STRONG",{});var oBt=s(N5e);NDr=r(oBt,"distilbert"),oBt.forEach(t),qDr=r(mDe," \u2014 "),SZ=n(mDe,"A",{href:!0});var rBt=s(SZ);jDr=r(rBt,"FlaxDistilBertForMaskedLM"),rBt.forEach(t),DDr=r(mDe," (DistilBERT model)"),mDe.forEach(t),GDr=i(qe),L0=n(qe,"LI",{});var gDe=s(L0);q5e=n(gDe,"STRONG",{});var tBt=s(q5e);ODr=r(tBt,"electra"),tBt.forEach(t),VDr=r(gDe," \u2014 "),RZ=n(gDe,"A",{href:!0});var aBt=s(RZ);XDr=r(aBt,"FlaxElectraForMaskedLM"),aBt.forEach(t),zDr=r(gDe," (ELECTRA model)"),gDe.forEach(t),WDr=i(qe),y0=n(qe,"LI",{});var hDe=s(y0);j5e=n(hDe,"STRONG",{});var nBt=s(j5e);QDr=r(nBt,"mbart"),nBt.forEach(t),HDr=r(hDe," \u2014 "),PZ=n(hDe,"A",{href:!0});var sBt=s(PZ);UDr=r(sBt,"FlaxMBartForConditionalGeneration"),sBt.forEach(t),JDr=r(hDe," (mBART model)"),hDe.forEach(t),YDr=i(qe),x0=n(qe,"LI",{});var pDe=s(x0);D5e=n(pDe,"STRONG",{});var lBt=s(D5e);KDr=r(lBt,"roberta"),lBt.forEach(t),ZDr=r(pDe," \u2014 "),BZ=n(pDe,"A",{href:!0});var iBt=s(BZ);eGr=r(iBt,"FlaxRobertaForMaskedLM"),iBt.forEach(t),oGr=r(pDe," (RoBERTa model)"),pDe.forEach(t),rGr=i(qe),$0=n(qe,"LI",{});var uDe=s($0);G5e=n(uDe,"STRONG",{});var dBt=s(G5e);tGr=r(dBt,"roformer"),dBt.forEach(t),aGr=r(uDe," \u2014 "),IZ=n(uDe,"A",{href:!0});var cBt=s(IZ);nGr=r(cBt,"FlaxRoFormerForMaskedLM"),cBt.forEach(t),sGr=r(uDe," (RoFormer model)"),uDe.forEach(t),lGr=i(qe),k0=n(qe,"LI",{});var _De=s(k0);O5e=n(_De,"STRONG",{});var fBt=s(O5e);iGr=r(fBt,"xlm-roberta"),fBt.forEach(t),dGr=r(_De," \u2014 "),NZ=n(_De,"A",{href:!0});var mBt=s(NZ);cGr=r(mBt,"FlaxXLMRobertaForMaskedLM"),mBt.forEach(t),fGr=r(_De," (XLM-RoBERTa model)"),_De.forEach(t),qe.forEach(t),mGr=i(ti),T(S0.$$.fragment,ti),ti.forEach(t),ri.forEach(t),tVe=i(f),Zc=n(f,"H2",{class:!0});var mze=s(Zc);R0=n(mze,"A",{id:!0,class:!0,href:!0});var gBt=s(R0);V5e=n(gBt,"SPAN",{});var hBt=s(V5e);T(Wx.$$.fragment,hBt),hBt.forEach(t),gBt.forEach(t),gGr=i(mze),X5e=n(mze,"SPAN",{});var pBt=s(X5e);hGr=r(pBt,"FlaxAutoModelForSeq2SeqLM"),pBt.forEach(t),mze.forEach(t),aVe=i(f),_r=n(f,"DIV",{class:!0});var ai=s(_r);T(Qx.$$.fragment,ai),pGr=i(ai),ef=n(ai,"P",{});var Ire=s(ef);uGr=r(Ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qZ=n(Ire,"A",{href:!0});var uBt=s(qZ);_Gr=r(uBt,"from_pretrained()"),uBt.forEach(t),bGr=r(Ire," class method or the "),jZ=n(Ire,"A",{href:!0});var _Bt=s(jZ);vGr=r(_Bt,"from_config()"),_Bt.forEach(t),FGr=r(Ire,` class
method.`),Ire.forEach(t),TGr=i(ai),Hx=n(ai,"P",{});var gze=s(Hx);MGr=r(gze,"This class cannot be instantiated directly using "),z5e=n(gze,"CODE",{});var bBt=s(z5e);EGr=r(bBt,"__init__()"),bBt.forEach(t),CGr=r(gze," (throws an error)."),gze.forEach(t),wGr=i(ai),Ht=n(ai,"DIV",{class:!0});var tL=s(Ht);T(Ux.$$.fragment,tL),AGr=i(tL),W5e=n(tL,"P",{});var vBt=s(W5e);LGr=r(vBt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vBt.forEach(t),yGr=i(tL),of=n(tL,"P",{});var Nre=s(of);xGr=r(Nre,`Note:
Loading a model from its configuration file does `),Q5e=n(Nre,"STRONG",{});var FBt=s(Q5e);$Gr=r(FBt,"not"),FBt.forEach(t),kGr=r(Nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),DZ=n(Nre,"A",{href:!0});var TBt=s(DZ);SGr=r(TBt,"from_pretrained()"),TBt.forEach(t),RGr=r(Nre," to load the model weights."),Nre.forEach(t),PGr=i(tL),T(P0.$$.fragment,tL),tL.forEach(t),BGr=i(ai),zr=n(ai,"DIV",{class:!0});var ni=s(zr);T(Jx.$$.fragment,ni),IGr=i(ni),H5e=n(ni,"P",{});var MBt=s(H5e);NGr=r(MBt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),MBt.forEach(t),qGr=i(ni),En=n(ni,"P",{});var aL=s(En);jGr=r(aL,"The model class to instantiate is selected based on the "),U5e=n(aL,"CODE",{});var EBt=s(U5e);DGr=r(EBt,"model_type"),EBt.forEach(t),GGr=r(aL,` property of the config object (either
passed as an argument or loaded from `),J5e=n(aL,"CODE",{});var CBt=s(J5e);OGr=r(CBt,"pretrained_model_name_or_path"),CBt.forEach(t),VGr=r(aL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y5e=n(aL,"CODE",{});var wBt=s(Y5e);XGr=r(wBt,"pretrained_model_name_or_path"),wBt.forEach(t),zGr=r(aL,":"),aL.forEach(t),WGr=i(ni),ke=n(ni,"UL",{});var je=s(ke);B0=n(je,"LI",{});var bDe=s(B0);K5e=n(bDe,"STRONG",{});var ABt=s(K5e);QGr=r(ABt,"bart"),ABt.forEach(t),HGr=r(bDe," \u2014 "),GZ=n(bDe,"A",{href:!0});var LBt=s(GZ);UGr=r(LBt,"FlaxBartForConditionalGeneration"),LBt.forEach(t),JGr=r(bDe," (BART model)"),bDe.forEach(t),YGr=i(je),I0=n(je,"LI",{});var vDe=s(I0);Z5e=n(vDe,"STRONG",{});var yBt=s(Z5e);KGr=r(yBt,"blenderbot"),yBt.forEach(t),ZGr=r(vDe," \u2014 "),OZ=n(vDe,"A",{href:!0});var xBt=s(OZ);eOr=r(xBt,"FlaxBlenderbotForConditionalGeneration"),xBt.forEach(t),oOr=r(vDe," (Blenderbot model)"),vDe.forEach(t),rOr=i(je),N0=n(je,"LI",{});var FDe=s(N0);e3e=n(FDe,"STRONG",{});var $Bt=s(e3e);tOr=r($Bt,"blenderbot-small"),$Bt.forEach(t),aOr=r(FDe," \u2014 "),VZ=n(FDe,"A",{href:!0});var kBt=s(VZ);nOr=r(kBt,"FlaxBlenderbotSmallForConditionalGeneration"),kBt.forEach(t),sOr=r(FDe," (BlenderbotSmall model)"),FDe.forEach(t),lOr=i(je),q0=n(je,"LI",{});var TDe=s(q0);o3e=n(TDe,"STRONG",{});var SBt=s(o3e);iOr=r(SBt,"encoder-decoder"),SBt.forEach(t),dOr=r(TDe," \u2014 "),XZ=n(TDe,"A",{href:!0});var RBt=s(XZ);cOr=r(RBt,"FlaxEncoderDecoderModel"),RBt.forEach(t),fOr=r(TDe," (Encoder decoder model)"),TDe.forEach(t),mOr=i(je),j0=n(je,"LI",{});var MDe=s(j0);r3e=n(MDe,"STRONG",{});var PBt=s(r3e);gOr=r(PBt,"longt5"),PBt.forEach(t),hOr=r(MDe," \u2014 "),zZ=n(MDe,"A",{href:!0});var BBt=s(zZ);pOr=r(BBt,"FlaxLongT5ForConditionalGeneration"),BBt.forEach(t),uOr=r(MDe," (LongT5 model)"),MDe.forEach(t),_Or=i(je),D0=n(je,"LI",{});var EDe=s(D0);t3e=n(EDe,"STRONG",{});var IBt=s(t3e);bOr=r(IBt,"marian"),IBt.forEach(t),vOr=r(EDe," \u2014 "),WZ=n(EDe,"A",{href:!0});var NBt=s(WZ);FOr=r(NBt,"FlaxMarianMTModel"),NBt.forEach(t),TOr=r(EDe," (Marian model)"),EDe.forEach(t),MOr=i(je),G0=n(je,"LI",{});var CDe=s(G0);a3e=n(CDe,"STRONG",{});var qBt=s(a3e);EOr=r(qBt,"mbart"),qBt.forEach(t),COr=r(CDe," \u2014 "),QZ=n(CDe,"A",{href:!0});var jBt=s(QZ);wOr=r(jBt,"FlaxMBartForConditionalGeneration"),jBt.forEach(t),AOr=r(CDe," (mBART model)"),CDe.forEach(t),LOr=i(je),O0=n(je,"LI",{});var wDe=s(O0);n3e=n(wDe,"STRONG",{});var DBt=s(n3e);yOr=r(DBt,"mt5"),DBt.forEach(t),xOr=r(wDe," \u2014 "),HZ=n(wDe,"A",{href:!0});var GBt=s(HZ);$Or=r(GBt,"FlaxMT5ForConditionalGeneration"),GBt.forEach(t),kOr=r(wDe," (MT5 model)"),wDe.forEach(t),SOr=i(je),V0=n(je,"LI",{});var ADe=s(V0);s3e=n(ADe,"STRONG",{});var OBt=s(s3e);ROr=r(OBt,"pegasus"),OBt.forEach(t),POr=r(ADe," \u2014 "),UZ=n(ADe,"A",{href:!0});var VBt=s(UZ);BOr=r(VBt,"FlaxPegasusForConditionalGeneration"),VBt.forEach(t),IOr=r(ADe," (Pegasus model)"),ADe.forEach(t),NOr=i(je),X0=n(je,"LI",{});var LDe=s(X0);l3e=n(LDe,"STRONG",{});var XBt=s(l3e);qOr=r(XBt,"t5"),XBt.forEach(t),jOr=r(LDe," \u2014 "),JZ=n(LDe,"A",{href:!0});var zBt=s(JZ);DOr=r(zBt,"FlaxT5ForConditionalGeneration"),zBt.forEach(t),GOr=r(LDe," (T5 model)"),LDe.forEach(t),je.forEach(t),OOr=i(ni),T(z0.$$.fragment,ni),ni.forEach(t),ai.forEach(t),nVe=i(f),rf=n(f,"H2",{class:!0});var hze=s(rf);W0=n(hze,"A",{id:!0,class:!0,href:!0});var WBt=s(W0);i3e=n(WBt,"SPAN",{});var QBt=s(i3e);T(Yx.$$.fragment,QBt),QBt.forEach(t),WBt.forEach(t),VOr=i(hze),d3e=n(hze,"SPAN",{});var HBt=s(d3e);XOr=r(HBt,"FlaxAutoModelForSequenceClassification"),HBt.forEach(t),hze.forEach(t),sVe=i(f),br=n(f,"DIV",{class:!0});var si=s(br);T(Kx.$$.fragment,si),zOr=i(si),tf=n(si,"P",{});var qre=s(tf);WOr=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),YZ=n(qre,"A",{href:!0});var UBt=s(YZ);QOr=r(UBt,"from_pretrained()"),UBt.forEach(t),HOr=r(qre," class method or the "),KZ=n(qre,"A",{href:!0});var JBt=s(KZ);UOr=r(JBt,"from_config()"),JBt.forEach(t),JOr=r(qre,` class
method.`),qre.forEach(t),YOr=i(si),Zx=n(si,"P",{});var pze=s(Zx);KOr=r(pze,"This class cannot be instantiated directly using "),c3e=n(pze,"CODE",{});var YBt=s(c3e);ZOr=r(YBt,"__init__()"),YBt.forEach(t),eVr=r(pze," (throws an error)."),pze.forEach(t),oVr=i(si),Ut=n(si,"DIV",{class:!0});var nL=s(Ut);T(e$.$$.fragment,nL),rVr=i(nL),f3e=n(nL,"P",{});var KBt=s(f3e);tVr=r(KBt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),KBt.forEach(t),aVr=i(nL),af=n(nL,"P",{});var jre=s(af);nVr=r(jre,`Note:
Loading a model from its configuration file does `),m3e=n(jre,"STRONG",{});var ZBt=s(m3e);sVr=r(ZBt,"not"),ZBt.forEach(t),lVr=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZZ=n(jre,"A",{href:!0});var eIt=s(ZZ);iVr=r(eIt,"from_pretrained()"),eIt.forEach(t),dVr=r(jre," to load the model weights."),jre.forEach(t),cVr=i(nL),T(Q0.$$.fragment,nL),nL.forEach(t),fVr=i(si),Wr=n(si,"DIV",{class:!0});var li=s(Wr);T(o$.$$.fragment,li),mVr=i(li),g3e=n(li,"P",{});var oIt=s(g3e);gVr=r(oIt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),oIt.forEach(t),hVr=i(li),Cn=n(li,"P",{});var sL=s(Cn);pVr=r(sL,"The model class to instantiate is selected based on the "),h3e=n(sL,"CODE",{});var rIt=s(h3e);uVr=r(rIt,"model_type"),rIt.forEach(t),_Vr=r(sL,` property of the config object (either
passed as an argument or loaded from `),p3e=n(sL,"CODE",{});var tIt=s(p3e);bVr=r(tIt,"pretrained_model_name_or_path"),tIt.forEach(t),vVr=r(sL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u3e=n(sL,"CODE",{});var aIt=s(u3e);FVr=r(aIt,"pretrained_model_name_or_path"),aIt.forEach(t),TVr=r(sL,":"),sL.forEach(t),MVr=i(li),Se=n(li,"UL",{});var De=s(Se);H0=n(De,"LI",{});var yDe=s(H0);_3e=n(yDe,"STRONG",{});var nIt=s(_3e);EVr=r(nIt,"albert"),nIt.forEach(t),CVr=r(yDe," \u2014 "),eee=n(yDe,"A",{href:!0});var sIt=s(eee);wVr=r(sIt,"FlaxAlbertForSequenceClassification"),sIt.forEach(t),AVr=r(yDe," (ALBERT model)"),yDe.forEach(t),LVr=i(De),U0=n(De,"LI",{});var xDe=s(U0);b3e=n(xDe,"STRONG",{});var lIt=s(b3e);yVr=r(lIt,"bart"),lIt.forEach(t),xVr=r(xDe," \u2014 "),oee=n(xDe,"A",{href:!0});var iIt=s(oee);$Vr=r(iIt,"FlaxBartForSequenceClassification"),iIt.forEach(t),kVr=r(xDe," (BART model)"),xDe.forEach(t),SVr=i(De),J0=n(De,"LI",{});var $De=s(J0);v3e=n($De,"STRONG",{});var dIt=s(v3e);RVr=r(dIt,"bert"),dIt.forEach(t),PVr=r($De," \u2014 "),ree=n($De,"A",{href:!0});var cIt=s(ree);BVr=r(cIt,"FlaxBertForSequenceClassification"),cIt.forEach(t),IVr=r($De," (BERT model)"),$De.forEach(t),NVr=i(De),Y0=n(De,"LI",{});var kDe=s(Y0);F3e=n(kDe,"STRONG",{});var fIt=s(F3e);qVr=r(fIt,"big_bird"),fIt.forEach(t),jVr=r(kDe," \u2014 "),tee=n(kDe,"A",{href:!0});var mIt=s(tee);DVr=r(mIt,"FlaxBigBirdForSequenceClassification"),mIt.forEach(t),GVr=r(kDe," (BigBird model)"),kDe.forEach(t),OVr=i(De),K0=n(De,"LI",{});var SDe=s(K0);T3e=n(SDe,"STRONG",{});var gIt=s(T3e);VVr=r(gIt,"distilbert"),gIt.forEach(t),XVr=r(SDe," \u2014 "),aee=n(SDe,"A",{href:!0});var hIt=s(aee);zVr=r(hIt,"FlaxDistilBertForSequenceClassification"),hIt.forEach(t),WVr=r(SDe," (DistilBERT model)"),SDe.forEach(t),QVr=i(De),Z0=n(De,"LI",{});var RDe=s(Z0);M3e=n(RDe,"STRONG",{});var pIt=s(M3e);HVr=r(pIt,"electra"),pIt.forEach(t),UVr=r(RDe," \u2014 "),nee=n(RDe,"A",{href:!0});var uIt=s(nee);JVr=r(uIt,"FlaxElectraForSequenceClassification"),uIt.forEach(t),YVr=r(RDe," (ELECTRA model)"),RDe.forEach(t),KVr=i(De),ew=n(De,"LI",{});var PDe=s(ew);E3e=n(PDe,"STRONG",{});var _It=s(E3e);ZVr=r(_It,"mbart"),_It.forEach(t),eXr=r(PDe," \u2014 "),see=n(PDe,"A",{href:!0});var bIt=s(see);oXr=r(bIt,"FlaxMBartForSequenceClassification"),bIt.forEach(t),rXr=r(PDe," (mBART model)"),PDe.forEach(t),tXr=i(De),ow=n(De,"LI",{});var BDe=s(ow);C3e=n(BDe,"STRONG",{});var vIt=s(C3e);aXr=r(vIt,"roberta"),vIt.forEach(t),nXr=r(BDe," \u2014 "),lee=n(BDe,"A",{href:!0});var FIt=s(lee);sXr=r(FIt,"FlaxRobertaForSequenceClassification"),FIt.forEach(t),lXr=r(BDe," (RoBERTa model)"),BDe.forEach(t),iXr=i(De),rw=n(De,"LI",{});var IDe=s(rw);w3e=n(IDe,"STRONG",{});var TIt=s(w3e);dXr=r(TIt,"roformer"),TIt.forEach(t),cXr=r(IDe," \u2014 "),iee=n(IDe,"A",{href:!0});var MIt=s(iee);fXr=r(MIt,"FlaxRoFormerForSequenceClassification"),MIt.forEach(t),mXr=r(IDe," (RoFormer model)"),IDe.forEach(t),gXr=i(De),tw=n(De,"LI",{});var NDe=s(tw);A3e=n(NDe,"STRONG",{});var EIt=s(A3e);hXr=r(EIt,"xlm-roberta"),EIt.forEach(t),pXr=r(NDe," \u2014 "),dee=n(NDe,"A",{href:!0});var CIt=s(dee);uXr=r(CIt,"FlaxXLMRobertaForSequenceClassification"),CIt.forEach(t),_Xr=r(NDe," (XLM-RoBERTa model)"),NDe.forEach(t),De.forEach(t),bXr=i(li),T(aw.$$.fragment,li),li.forEach(t),si.forEach(t),lVe=i(f),nf=n(f,"H2",{class:!0});var uze=s(nf);nw=n(uze,"A",{id:!0,class:!0,href:!0});var wIt=s(nw);L3e=n(wIt,"SPAN",{});var AIt=s(L3e);T(r$.$$.fragment,AIt),AIt.forEach(t),wIt.forEach(t),vXr=i(uze),y3e=n(uze,"SPAN",{});var LIt=s(y3e);FXr=r(LIt,"FlaxAutoModelForQuestionAnswering"),LIt.forEach(t),uze.forEach(t),iVe=i(f),vr=n(f,"DIV",{class:!0});var ii=s(vr);T(t$.$$.fragment,ii),TXr=i(ii),sf=n(ii,"P",{});var Dre=s(sf);MXr=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cee=n(Dre,"A",{href:!0});var yIt=s(cee);EXr=r(yIt,"from_pretrained()"),yIt.forEach(t),CXr=r(Dre," class method or the "),fee=n(Dre,"A",{href:!0});var xIt=s(fee);wXr=r(xIt,"from_config()"),xIt.forEach(t),AXr=r(Dre,` class
method.`),Dre.forEach(t),LXr=i(ii),a$=n(ii,"P",{});var _ze=s(a$);yXr=r(_ze,"This class cannot be instantiated directly using "),x3e=n(_ze,"CODE",{});var $It=s(x3e);xXr=r($It,"__init__()"),$It.forEach(t),$Xr=r(_ze," (throws an error)."),_ze.forEach(t),kXr=i(ii),Jt=n(ii,"DIV",{class:!0});var lL=s(Jt);T(n$.$$.fragment,lL),SXr=i(lL),$3e=n(lL,"P",{});var kIt=s($3e);RXr=r(kIt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),kIt.forEach(t),PXr=i(lL),lf=n(lL,"P",{});var Gre=s(lf);BXr=r(Gre,`Note:
Loading a model from its configuration file does `),k3e=n(Gre,"STRONG",{});var SIt=s(k3e);IXr=r(SIt,"not"),SIt.forEach(t),NXr=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),mee=n(Gre,"A",{href:!0});var RIt=s(mee);qXr=r(RIt,"from_pretrained()"),RIt.forEach(t),jXr=r(Gre," to load the model weights."),Gre.forEach(t),DXr=i(lL),T(sw.$$.fragment,lL),lL.forEach(t),GXr=i(ii),Qr=n(ii,"DIV",{class:!0});var di=s(Qr);T(s$.$$.fragment,di),OXr=i(di),S3e=n(di,"P",{});var PIt=s(S3e);VXr=r(PIt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),PIt.forEach(t),XXr=i(di),wn=n(di,"P",{});var iL=s(wn);zXr=r(iL,"The model class to instantiate is selected based on the "),R3e=n(iL,"CODE",{});var BIt=s(R3e);WXr=r(BIt,"model_type"),BIt.forEach(t),QXr=r(iL,` property of the config object (either
passed as an argument or loaded from `),P3e=n(iL,"CODE",{});var IIt=s(P3e);HXr=r(IIt,"pretrained_model_name_or_path"),IIt.forEach(t),UXr=r(iL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B3e=n(iL,"CODE",{});var NIt=s(B3e);JXr=r(NIt,"pretrained_model_name_or_path"),NIt.forEach(t),YXr=r(iL,":"),iL.forEach(t),KXr=i(di),Re=n(di,"UL",{});var Ge=s(Re);lw=n(Ge,"LI",{});var qDe=s(lw);I3e=n(qDe,"STRONG",{});var qIt=s(I3e);ZXr=r(qIt,"albert"),qIt.forEach(t),ezr=r(qDe," \u2014 "),gee=n(qDe,"A",{href:!0});var jIt=s(gee);ozr=r(jIt,"FlaxAlbertForQuestionAnswering"),jIt.forEach(t),rzr=r(qDe," (ALBERT model)"),qDe.forEach(t),tzr=i(Ge),iw=n(Ge,"LI",{});var jDe=s(iw);N3e=n(jDe,"STRONG",{});var DIt=s(N3e);azr=r(DIt,"bart"),DIt.forEach(t),nzr=r(jDe," \u2014 "),hee=n(jDe,"A",{href:!0});var GIt=s(hee);szr=r(GIt,"FlaxBartForQuestionAnswering"),GIt.forEach(t),lzr=r(jDe," (BART model)"),jDe.forEach(t),izr=i(Ge),dw=n(Ge,"LI",{});var DDe=s(dw);q3e=n(DDe,"STRONG",{});var OIt=s(q3e);dzr=r(OIt,"bert"),OIt.forEach(t),czr=r(DDe," \u2014 "),pee=n(DDe,"A",{href:!0});var VIt=s(pee);fzr=r(VIt,"FlaxBertForQuestionAnswering"),VIt.forEach(t),mzr=r(DDe," (BERT model)"),DDe.forEach(t),gzr=i(Ge),cw=n(Ge,"LI",{});var GDe=s(cw);j3e=n(GDe,"STRONG",{});var XIt=s(j3e);hzr=r(XIt,"big_bird"),XIt.forEach(t),pzr=r(GDe," \u2014 "),uee=n(GDe,"A",{href:!0});var zIt=s(uee);uzr=r(zIt,"FlaxBigBirdForQuestionAnswering"),zIt.forEach(t),_zr=r(GDe," (BigBird model)"),GDe.forEach(t),bzr=i(Ge),fw=n(Ge,"LI",{});var ODe=s(fw);D3e=n(ODe,"STRONG",{});var WIt=s(D3e);vzr=r(WIt,"distilbert"),WIt.forEach(t),Fzr=r(ODe," \u2014 "),_ee=n(ODe,"A",{href:!0});var QIt=s(_ee);Tzr=r(QIt,"FlaxDistilBertForQuestionAnswering"),QIt.forEach(t),Mzr=r(ODe," (DistilBERT model)"),ODe.forEach(t),Ezr=i(Ge),mw=n(Ge,"LI",{});var VDe=s(mw);G3e=n(VDe,"STRONG",{});var HIt=s(G3e);Czr=r(HIt,"electra"),HIt.forEach(t),wzr=r(VDe," \u2014 "),bee=n(VDe,"A",{href:!0});var UIt=s(bee);Azr=r(UIt,"FlaxElectraForQuestionAnswering"),UIt.forEach(t),Lzr=r(VDe," (ELECTRA model)"),VDe.forEach(t),yzr=i(Ge),gw=n(Ge,"LI",{});var XDe=s(gw);O3e=n(XDe,"STRONG",{});var JIt=s(O3e);xzr=r(JIt,"mbart"),JIt.forEach(t),$zr=r(XDe," \u2014 "),vee=n(XDe,"A",{href:!0});var YIt=s(vee);kzr=r(YIt,"FlaxMBartForQuestionAnswering"),YIt.forEach(t),Szr=r(XDe," (mBART model)"),XDe.forEach(t),Rzr=i(Ge),hw=n(Ge,"LI",{});var zDe=s(hw);V3e=n(zDe,"STRONG",{});var KIt=s(V3e);Pzr=r(KIt,"roberta"),KIt.forEach(t),Bzr=r(zDe," \u2014 "),Fee=n(zDe,"A",{href:!0});var ZIt=s(Fee);Izr=r(ZIt,"FlaxRobertaForQuestionAnswering"),ZIt.forEach(t),Nzr=r(zDe," (RoBERTa model)"),zDe.forEach(t),qzr=i(Ge),pw=n(Ge,"LI",{});var WDe=s(pw);X3e=n(WDe,"STRONG",{});var eNt=s(X3e);jzr=r(eNt,"roformer"),eNt.forEach(t),Dzr=r(WDe," \u2014 "),Tee=n(WDe,"A",{href:!0});var oNt=s(Tee);Gzr=r(oNt,"FlaxRoFormerForQuestionAnswering"),oNt.forEach(t),Ozr=r(WDe," (RoFormer model)"),WDe.forEach(t),Vzr=i(Ge),uw=n(Ge,"LI",{});var QDe=s(uw);z3e=n(QDe,"STRONG",{});var rNt=s(z3e);Xzr=r(rNt,"xlm-roberta"),rNt.forEach(t),zzr=r(QDe," \u2014 "),Mee=n(QDe,"A",{href:!0});var tNt=s(Mee);Wzr=r(tNt,"FlaxXLMRobertaForQuestionAnswering"),tNt.forEach(t),Qzr=r(QDe," (XLM-RoBERTa model)"),QDe.forEach(t),Ge.forEach(t),Hzr=i(di),T(_w.$$.fragment,di),di.forEach(t),ii.forEach(t),dVe=i(f),df=n(f,"H2",{class:!0});var bze=s(df);bw=n(bze,"A",{id:!0,class:!0,href:!0});var aNt=s(bw);W3e=n(aNt,"SPAN",{});var nNt=s(W3e);T(l$.$$.fragment,nNt),nNt.forEach(t),aNt.forEach(t),Uzr=i(bze),Q3e=n(bze,"SPAN",{});var sNt=s(Q3e);Jzr=r(sNt,"FlaxAutoModelForTokenClassification"),sNt.forEach(t),bze.forEach(t),cVe=i(f),Fr=n(f,"DIV",{class:!0});var ci=s(Fr);T(i$.$$.fragment,ci),Yzr=i(ci),cf=n(ci,"P",{});var Ore=s(cf);Kzr=r(Ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Eee=n(Ore,"A",{href:!0});var lNt=s(Eee);Zzr=r(lNt,"from_pretrained()"),lNt.forEach(t),eWr=r(Ore," class method or the "),Cee=n(Ore,"A",{href:!0});var iNt=s(Cee);oWr=r(iNt,"from_config()"),iNt.forEach(t),rWr=r(Ore,` class
method.`),Ore.forEach(t),tWr=i(ci),d$=n(ci,"P",{});var vze=s(d$);aWr=r(vze,"This class cannot be instantiated directly using "),H3e=n(vze,"CODE",{});var dNt=s(H3e);nWr=r(dNt,"__init__()"),dNt.forEach(t),sWr=r(vze," (throws an error)."),vze.forEach(t),lWr=i(ci),Yt=n(ci,"DIV",{class:!0});var dL=s(Yt);T(c$.$$.fragment,dL),iWr=i(dL),U3e=n(dL,"P",{});var cNt=s(U3e);dWr=r(cNt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),cNt.forEach(t),cWr=i(dL),ff=n(dL,"P",{});var Vre=s(ff);fWr=r(Vre,`Note:
Loading a model from its configuration file does `),J3e=n(Vre,"STRONG",{});var fNt=s(J3e);mWr=r(fNt,"not"),fNt.forEach(t),gWr=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),wee=n(Vre,"A",{href:!0});var mNt=s(wee);hWr=r(mNt,"from_pretrained()"),mNt.forEach(t),pWr=r(Vre," to load the model weights."),Vre.forEach(t),uWr=i(dL),T(vw.$$.fragment,dL),dL.forEach(t),_Wr=i(ci),Hr=n(ci,"DIV",{class:!0});var fi=s(Hr);T(f$.$$.fragment,fi),bWr=i(fi),Y3e=n(fi,"P",{});var gNt=s(Y3e);vWr=r(gNt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),gNt.forEach(t),FWr=i(fi),An=n(fi,"P",{});var cL=s(An);TWr=r(cL,"The model class to instantiate is selected based on the "),K3e=n(cL,"CODE",{});var hNt=s(K3e);MWr=r(hNt,"model_type"),hNt.forEach(t),EWr=r(cL,` property of the config object (either
passed as an argument or loaded from `),Z3e=n(cL,"CODE",{});var pNt=s(Z3e);CWr=r(pNt,"pretrained_model_name_or_path"),pNt.forEach(t),wWr=r(cL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e0e=n(cL,"CODE",{});var uNt=s(e0e);AWr=r(uNt,"pretrained_model_name_or_path"),uNt.forEach(t),LWr=r(cL,":"),cL.forEach(t),yWr=i(fi),Ve=n(fi,"UL",{});var To=s(Ve);Fw=n(To,"LI",{});var HDe=s(Fw);o0e=n(HDe,"STRONG",{});var _Nt=s(o0e);xWr=r(_Nt,"albert"),_Nt.forEach(t),$Wr=r(HDe," \u2014 "),Aee=n(HDe,"A",{href:!0});var bNt=s(Aee);kWr=r(bNt,"FlaxAlbertForTokenClassification"),bNt.forEach(t),SWr=r(HDe," (ALBERT model)"),HDe.forEach(t),RWr=i(To),Tw=n(To,"LI",{});var UDe=s(Tw);r0e=n(UDe,"STRONG",{});var vNt=s(r0e);PWr=r(vNt,"bert"),vNt.forEach(t),BWr=r(UDe," \u2014 "),Lee=n(UDe,"A",{href:!0});var FNt=s(Lee);IWr=r(FNt,"FlaxBertForTokenClassification"),FNt.forEach(t),NWr=r(UDe," (BERT model)"),UDe.forEach(t),qWr=i(To),Mw=n(To,"LI",{});var JDe=s(Mw);t0e=n(JDe,"STRONG",{});var TNt=s(t0e);jWr=r(TNt,"big_bird"),TNt.forEach(t),DWr=r(JDe," \u2014 "),yee=n(JDe,"A",{href:!0});var MNt=s(yee);GWr=r(MNt,"FlaxBigBirdForTokenClassification"),MNt.forEach(t),OWr=r(JDe," (BigBird model)"),JDe.forEach(t),VWr=i(To),Ew=n(To,"LI",{});var YDe=s(Ew);a0e=n(YDe,"STRONG",{});var ENt=s(a0e);XWr=r(ENt,"distilbert"),ENt.forEach(t),zWr=r(YDe," \u2014 "),xee=n(YDe,"A",{href:!0});var CNt=s(xee);WWr=r(CNt,"FlaxDistilBertForTokenClassification"),CNt.forEach(t),QWr=r(YDe," (DistilBERT model)"),YDe.forEach(t),HWr=i(To),Cw=n(To,"LI",{});var KDe=s(Cw);n0e=n(KDe,"STRONG",{});var wNt=s(n0e);UWr=r(wNt,"electra"),wNt.forEach(t),JWr=r(KDe," \u2014 "),$ee=n(KDe,"A",{href:!0});var ANt=s($ee);YWr=r(ANt,"FlaxElectraForTokenClassification"),ANt.forEach(t),KWr=r(KDe," (ELECTRA model)"),KDe.forEach(t),ZWr=i(To),ww=n(To,"LI",{});var ZDe=s(ww);s0e=n(ZDe,"STRONG",{});var LNt=s(s0e);eQr=r(LNt,"roberta"),LNt.forEach(t),oQr=r(ZDe," \u2014 "),kee=n(ZDe,"A",{href:!0});var yNt=s(kee);rQr=r(yNt,"FlaxRobertaForTokenClassification"),yNt.forEach(t),tQr=r(ZDe," (RoBERTa model)"),ZDe.forEach(t),aQr=i(To),Aw=n(To,"LI",{});var eGe=s(Aw);l0e=n(eGe,"STRONG",{});var xNt=s(l0e);nQr=r(xNt,"roformer"),xNt.forEach(t),sQr=r(eGe," \u2014 "),See=n(eGe,"A",{href:!0});var $Nt=s(See);lQr=r($Nt,"FlaxRoFormerForTokenClassification"),$Nt.forEach(t),iQr=r(eGe," (RoFormer model)"),eGe.forEach(t),dQr=i(To),Lw=n(To,"LI",{});var oGe=s(Lw);i0e=n(oGe,"STRONG",{});var kNt=s(i0e);cQr=r(kNt,"xlm-roberta"),kNt.forEach(t),fQr=r(oGe," \u2014 "),Ree=n(oGe,"A",{href:!0});var SNt=s(Ree);mQr=r(SNt,"FlaxXLMRobertaForTokenClassification"),SNt.forEach(t),gQr=r(oGe," (XLM-RoBERTa model)"),oGe.forEach(t),To.forEach(t),hQr=i(fi),T(yw.$$.fragment,fi),fi.forEach(t),ci.forEach(t),fVe=i(f),mf=n(f,"H2",{class:!0});var Fze=s(mf);xw=n(Fze,"A",{id:!0,class:!0,href:!0});var RNt=s(xw);d0e=n(RNt,"SPAN",{});var PNt=s(d0e);T(m$.$$.fragment,PNt),PNt.forEach(t),RNt.forEach(t),pQr=i(Fze),c0e=n(Fze,"SPAN",{});var BNt=s(c0e);uQr=r(BNt,"FlaxAutoModelForMultipleChoice"),BNt.forEach(t),Fze.forEach(t),mVe=i(f),Tr=n(f,"DIV",{class:!0});var mi=s(Tr);T(g$.$$.fragment,mi),_Qr=i(mi),gf=n(mi,"P",{});var Xre=s(gf);bQr=r(Xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Pee=n(Xre,"A",{href:!0});var INt=s(Pee);vQr=r(INt,"from_pretrained()"),INt.forEach(t),FQr=r(Xre," class method or the "),Bee=n(Xre,"A",{href:!0});var NNt=s(Bee);TQr=r(NNt,"from_config()"),NNt.forEach(t),MQr=r(Xre,` class
method.`),Xre.forEach(t),EQr=i(mi),h$=n(mi,"P",{});var Tze=s(h$);CQr=r(Tze,"This class cannot be instantiated directly using "),f0e=n(Tze,"CODE",{});var qNt=s(f0e);wQr=r(qNt,"__init__()"),qNt.forEach(t),AQr=r(Tze," (throws an error)."),Tze.forEach(t),LQr=i(mi),Kt=n(mi,"DIV",{class:!0});var fL=s(Kt);T(p$.$$.fragment,fL),yQr=i(fL),m0e=n(fL,"P",{});var jNt=s(m0e);xQr=r(jNt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),jNt.forEach(t),$Qr=i(fL),hf=n(fL,"P",{});var zre=s(hf);kQr=r(zre,`Note:
Loading a model from its configuration file does `),g0e=n(zre,"STRONG",{});var DNt=s(g0e);SQr=r(DNt,"not"),DNt.forEach(t),RQr=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),Iee=n(zre,"A",{href:!0});var GNt=s(Iee);PQr=r(GNt,"from_pretrained()"),GNt.forEach(t),BQr=r(zre," to load the model weights."),zre.forEach(t),IQr=i(fL),T($w.$$.fragment,fL),fL.forEach(t),NQr=i(mi),Ur=n(mi,"DIV",{class:!0});var gi=s(Ur);T(u$.$$.fragment,gi),qQr=i(gi),h0e=n(gi,"P",{});var ONt=s(h0e);jQr=r(ONt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ONt.forEach(t),DQr=i(gi),Ln=n(gi,"P",{});var mL=s(Ln);GQr=r(mL,"The model class to instantiate is selected based on the "),p0e=n(mL,"CODE",{});var VNt=s(p0e);OQr=r(VNt,"model_type"),VNt.forEach(t),VQr=r(mL,` property of the config object (either
passed as an argument or loaded from `),u0e=n(mL,"CODE",{});var XNt=s(u0e);XQr=r(XNt,"pretrained_model_name_or_path"),XNt.forEach(t),zQr=r(mL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_0e=n(mL,"CODE",{});var zNt=s(_0e);WQr=r(zNt,"pretrained_model_name_or_path"),zNt.forEach(t),QQr=r(mL,":"),mL.forEach(t),HQr=i(gi),Xe=n(gi,"UL",{});var Mo=s(Xe);kw=n(Mo,"LI",{});var rGe=s(kw);b0e=n(rGe,"STRONG",{});var WNt=s(b0e);UQr=r(WNt,"albert"),WNt.forEach(t),JQr=r(rGe," \u2014 "),Nee=n(rGe,"A",{href:!0});var QNt=s(Nee);YQr=r(QNt,"FlaxAlbertForMultipleChoice"),QNt.forEach(t),KQr=r(rGe," (ALBERT model)"),rGe.forEach(t),ZQr=i(Mo),Sw=n(Mo,"LI",{});var tGe=s(Sw);v0e=n(tGe,"STRONG",{});var HNt=s(v0e);eHr=r(HNt,"bert"),HNt.forEach(t),oHr=r(tGe," \u2014 "),qee=n(tGe,"A",{href:!0});var UNt=s(qee);rHr=r(UNt,"FlaxBertForMultipleChoice"),UNt.forEach(t),tHr=r(tGe," (BERT model)"),tGe.forEach(t),aHr=i(Mo),Rw=n(Mo,"LI",{});var aGe=s(Rw);F0e=n(aGe,"STRONG",{});var JNt=s(F0e);nHr=r(JNt,"big_bird"),JNt.forEach(t),sHr=r(aGe," \u2014 "),jee=n(aGe,"A",{href:!0});var YNt=s(jee);lHr=r(YNt,"FlaxBigBirdForMultipleChoice"),YNt.forEach(t),iHr=r(aGe," (BigBird model)"),aGe.forEach(t),dHr=i(Mo),Pw=n(Mo,"LI",{});var nGe=s(Pw);T0e=n(nGe,"STRONG",{});var KNt=s(T0e);cHr=r(KNt,"distilbert"),KNt.forEach(t),fHr=r(nGe," \u2014 "),Dee=n(nGe,"A",{href:!0});var ZNt=s(Dee);mHr=r(ZNt,"FlaxDistilBertForMultipleChoice"),ZNt.forEach(t),gHr=r(nGe," (DistilBERT model)"),nGe.forEach(t),hHr=i(Mo),Bw=n(Mo,"LI",{});var sGe=s(Bw);M0e=n(sGe,"STRONG",{});var eqt=s(M0e);pHr=r(eqt,"electra"),eqt.forEach(t),uHr=r(sGe," \u2014 "),Gee=n(sGe,"A",{href:!0});var oqt=s(Gee);_Hr=r(oqt,"FlaxElectraForMultipleChoice"),oqt.forEach(t),bHr=r(sGe," (ELECTRA model)"),sGe.forEach(t),vHr=i(Mo),Iw=n(Mo,"LI",{});var lGe=s(Iw);E0e=n(lGe,"STRONG",{});var rqt=s(E0e);FHr=r(rqt,"roberta"),rqt.forEach(t),THr=r(lGe," \u2014 "),Oee=n(lGe,"A",{href:!0});var tqt=s(Oee);MHr=r(tqt,"FlaxRobertaForMultipleChoice"),tqt.forEach(t),EHr=r(lGe," (RoBERTa model)"),lGe.forEach(t),CHr=i(Mo),Nw=n(Mo,"LI",{});var iGe=s(Nw);C0e=n(iGe,"STRONG",{});var aqt=s(C0e);wHr=r(aqt,"roformer"),aqt.forEach(t),AHr=r(iGe," \u2014 "),Vee=n(iGe,"A",{href:!0});var nqt=s(Vee);LHr=r(nqt,"FlaxRoFormerForMultipleChoice"),nqt.forEach(t),yHr=r(iGe," (RoFormer model)"),iGe.forEach(t),xHr=i(Mo),qw=n(Mo,"LI",{});var dGe=s(qw);w0e=n(dGe,"STRONG",{});var sqt=s(w0e);$Hr=r(sqt,"xlm-roberta"),sqt.forEach(t),kHr=r(dGe," \u2014 "),Xee=n(dGe,"A",{href:!0});var lqt=s(Xee);SHr=r(lqt,"FlaxXLMRobertaForMultipleChoice"),lqt.forEach(t),RHr=r(dGe," (XLM-RoBERTa model)"),dGe.forEach(t),Mo.forEach(t),PHr=i(gi),T(jw.$$.fragment,gi),gi.forEach(t),mi.forEach(t),gVe=i(f),pf=n(f,"H2",{class:!0});var Mze=s(pf);Dw=n(Mze,"A",{id:!0,class:!0,href:!0});var iqt=s(Dw);A0e=n(iqt,"SPAN",{});var dqt=s(A0e);T(_$.$$.fragment,dqt),dqt.forEach(t),iqt.forEach(t),BHr=i(Mze),L0e=n(Mze,"SPAN",{});var cqt=s(L0e);IHr=r(cqt,"FlaxAutoModelForNextSentencePrediction"),cqt.forEach(t),Mze.forEach(t),hVe=i(f),Mr=n(f,"DIV",{class:!0});var hi=s(Mr);T(b$.$$.fragment,hi),NHr=i(hi),uf=n(hi,"P",{});var Wre=s(uf);qHr=r(Wre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),zee=n(Wre,"A",{href:!0});var fqt=s(zee);jHr=r(fqt,"from_pretrained()"),fqt.forEach(t),DHr=r(Wre," class method or the "),Wee=n(Wre,"A",{href:!0});var mqt=s(Wee);GHr=r(mqt,"from_config()"),mqt.forEach(t),OHr=r(Wre,` class
method.`),Wre.forEach(t),VHr=i(hi),v$=n(hi,"P",{});var Eze=s(v$);XHr=r(Eze,"This class cannot be instantiated directly using "),y0e=n(Eze,"CODE",{});var gqt=s(y0e);zHr=r(gqt,"__init__()"),gqt.forEach(t),WHr=r(Eze," (throws an error)."),Eze.forEach(t),QHr=i(hi),Zt=n(hi,"DIV",{class:!0});var gL=s(Zt);T(F$.$$.fragment,gL),HHr=i(gL),x0e=n(gL,"P",{});var hqt=s(x0e);UHr=r(hqt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),hqt.forEach(t),JHr=i(gL),_f=n(gL,"P",{});var Qre=s(_f);YHr=r(Qre,`Note:
Loading a model from its configuration file does `),$0e=n(Qre,"STRONG",{});var pqt=s($0e);KHr=r(pqt,"not"),pqt.forEach(t),ZHr=r(Qre,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qee=n(Qre,"A",{href:!0});var uqt=s(Qee);eUr=r(uqt,"from_pretrained()"),uqt.forEach(t),oUr=r(Qre," to load the model weights."),Qre.forEach(t),rUr=i(gL),T(Gw.$$.fragment,gL),gL.forEach(t),tUr=i(hi),Jr=n(hi,"DIV",{class:!0});var pi=s(Jr);T(T$.$$.fragment,pi),aUr=i(pi),k0e=n(pi,"P",{});var _qt=s(k0e);nUr=r(_qt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),_qt.forEach(t),sUr=i(pi),yn=n(pi,"P",{});var hL=s(yn);lUr=r(hL,"The model class to instantiate is selected based on the "),S0e=n(hL,"CODE",{});var bqt=s(S0e);iUr=r(bqt,"model_type"),bqt.forEach(t),dUr=r(hL,` property of the config object (either
passed as an argument or loaded from `),R0e=n(hL,"CODE",{});var vqt=s(R0e);cUr=r(vqt,"pretrained_model_name_or_path"),vqt.forEach(t),fUr=r(hL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P0e=n(hL,"CODE",{});var Fqt=s(P0e);mUr=r(Fqt,"pretrained_model_name_or_path"),Fqt.forEach(t),gUr=r(hL,":"),hL.forEach(t),hUr=i(pi),B0e=n(pi,"UL",{});var Tqt=s(B0e);Ow=n(Tqt,"LI",{});var cGe=s(Ow);I0e=n(cGe,"STRONG",{});var Mqt=s(I0e);pUr=r(Mqt,"bert"),Mqt.forEach(t),uUr=r(cGe," \u2014 "),Hee=n(cGe,"A",{href:!0});var Eqt=s(Hee);_Ur=r(Eqt,"FlaxBertForNextSentencePrediction"),Eqt.forEach(t),bUr=r(cGe," (BERT model)"),cGe.forEach(t),Tqt.forEach(t),vUr=i(pi),T(Vw.$$.fragment,pi),pi.forEach(t),hi.forEach(t),pVe=i(f),bf=n(f,"H2",{class:!0});var Cze=s(bf);Xw=n(Cze,"A",{id:!0,class:!0,href:!0});var Cqt=s(Xw);N0e=n(Cqt,"SPAN",{});var wqt=s(N0e);T(M$.$$.fragment,wqt),wqt.forEach(t),Cqt.forEach(t),FUr=i(Cze),q0e=n(Cze,"SPAN",{});var Aqt=s(q0e);TUr=r(Aqt,"FlaxAutoModelForImageClassification"),Aqt.forEach(t),Cze.forEach(t),uVe=i(f),Er=n(f,"DIV",{class:!0});var ui=s(Er);T(E$.$$.fragment,ui),MUr=i(ui),vf=n(ui,"P",{});var Hre=s(vf);EUr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Uee=n(Hre,"A",{href:!0});var Lqt=s(Uee);CUr=r(Lqt,"from_pretrained()"),Lqt.forEach(t),wUr=r(Hre," class method or the "),Jee=n(Hre,"A",{href:!0});var yqt=s(Jee);AUr=r(yqt,"from_config()"),yqt.forEach(t),LUr=r(Hre,` class
method.`),Hre.forEach(t),yUr=i(ui),C$=n(ui,"P",{});var wze=s(C$);xUr=r(wze,"This class cannot be instantiated directly using "),j0e=n(wze,"CODE",{});var xqt=s(j0e);$Ur=r(xqt,"__init__()"),xqt.forEach(t),kUr=r(wze," (throws an error)."),wze.forEach(t),SUr=i(ui),ea=n(ui,"DIV",{class:!0});var pL=s(ea);T(w$.$$.fragment,pL),RUr=i(pL),D0e=n(pL,"P",{});var $qt=s(D0e);PUr=r($qt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),$qt.forEach(t),BUr=i(pL),Ff=n(pL,"P",{});var Ure=s(Ff);IUr=r(Ure,`Note:
Loading a model from its configuration file does `),G0e=n(Ure,"STRONG",{});var kqt=s(G0e);NUr=r(kqt,"not"),kqt.forEach(t),qUr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=n(Ure,"A",{href:!0});var Sqt=s(Yee);jUr=r(Sqt,"from_pretrained()"),Sqt.forEach(t),DUr=r(Ure," to load the model weights."),Ure.forEach(t),GUr=i(pL),T(zw.$$.fragment,pL),pL.forEach(t),OUr=i(ui),Yr=n(ui,"DIV",{class:!0});var _i=s(Yr);T(A$.$$.fragment,_i),VUr=i(_i),O0e=n(_i,"P",{});var Rqt=s(O0e);XUr=r(Rqt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Rqt.forEach(t),zUr=i(_i),xn=n(_i,"P",{});var uL=s(xn);WUr=r(uL,"The model class to instantiate is selected based on the "),V0e=n(uL,"CODE",{});var Pqt=s(V0e);QUr=r(Pqt,"model_type"),Pqt.forEach(t),HUr=r(uL,` property of the config object (either
passed as an argument or loaded from `),X0e=n(uL,"CODE",{});var Bqt=s(X0e);UUr=r(Bqt,"pretrained_model_name_or_path"),Bqt.forEach(t),JUr=r(uL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z0e=n(uL,"CODE",{});var Iqt=s(z0e);YUr=r(Iqt,"pretrained_model_name_or_path"),Iqt.forEach(t),KUr=r(uL,":"),uL.forEach(t),ZUr=i(_i),L$=n(_i,"UL",{});var Aze=s(L$);Ww=n(Aze,"LI",{});var fGe=s(Ww);W0e=n(fGe,"STRONG",{});var Nqt=s(W0e);eJr=r(Nqt,"beit"),Nqt.forEach(t),oJr=r(fGe," \u2014 "),Kee=n(fGe,"A",{href:!0});var qqt=s(Kee);rJr=r(qqt,"FlaxBeitForImageClassification"),qqt.forEach(t),tJr=r(fGe," (BEiT model)"),fGe.forEach(t),aJr=i(Aze),Qw=n(Aze,"LI",{});var mGe=s(Qw);Q0e=n(mGe,"STRONG",{});var jqt=s(Q0e);nJr=r(jqt,"vit"),jqt.forEach(t),sJr=r(mGe," \u2014 "),Zee=n(mGe,"A",{href:!0});var Dqt=s(Zee);lJr=r(Dqt,"FlaxViTForImageClassification"),Dqt.forEach(t),iJr=r(mGe," (ViT model)"),mGe.forEach(t),Aze.forEach(t),dJr=i(_i),T(Hw.$$.fragment,_i),_i.forEach(t),ui.forEach(t),_Ve=i(f),Tf=n(f,"H2",{class:!0});var Lze=s(Tf);Uw=n(Lze,"A",{id:!0,class:!0,href:!0});var Gqt=s(Uw);H0e=n(Gqt,"SPAN",{});var Oqt=s(H0e);T(y$.$$.fragment,Oqt),Oqt.forEach(t),Gqt.forEach(t),cJr=i(Lze),U0e=n(Lze,"SPAN",{});var Vqt=s(U0e);fJr=r(Vqt,"FlaxAutoModelForVision2Seq"),Vqt.forEach(t),Lze.forEach(t),bVe=i(f),Cr=n(f,"DIV",{class:!0});var bi=s(Cr);T(x$.$$.fragment,bi),mJr=i(bi),Mf=n(bi,"P",{});var Jre=s(Mf);gJr=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eoe=n(Jre,"A",{href:!0});var Xqt=s(eoe);hJr=r(Xqt,"from_pretrained()"),Xqt.forEach(t),pJr=r(Jre," class method or the "),ooe=n(Jre,"A",{href:!0});var zqt=s(ooe);uJr=r(zqt,"from_config()"),zqt.forEach(t),_Jr=r(Jre,` class
method.`),Jre.forEach(t),bJr=i(bi),$$=n(bi,"P",{});var yze=s($$);vJr=r(yze,"This class cannot be instantiated directly using "),J0e=n(yze,"CODE",{});var Wqt=s(J0e);FJr=r(Wqt,"__init__()"),Wqt.forEach(t),TJr=r(yze," (throws an error)."),yze.forEach(t),MJr=i(bi),oa=n(bi,"DIV",{class:!0});var _L=s(oa);T(k$.$$.fragment,_L),EJr=i(_L),Y0e=n(_L,"P",{});var Qqt=s(Y0e);CJr=r(Qqt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Qqt.forEach(t),wJr=i(_L),Ef=n(_L,"P",{});var Yre=s(Ef);AJr=r(Yre,`Note:
Loading a model from its configuration file does `),K0e=n(Yre,"STRONG",{});var Hqt=s(K0e);LJr=r(Hqt,"not"),Hqt.forEach(t),yJr=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),roe=n(Yre,"A",{href:!0});var Uqt=s(roe);xJr=r(Uqt,"from_pretrained()"),Uqt.forEach(t),$Jr=r(Yre," to load the model weights."),Yre.forEach(t),kJr=i(_L),T(Jw.$$.fragment,_L),_L.forEach(t),SJr=i(bi),Kr=n(bi,"DIV",{class:!0});var vi=s(Kr);T(S$.$$.fragment,vi),RJr=i(vi),Z0e=n(vi,"P",{});var Jqt=s(Z0e);PJr=r(Jqt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Jqt.forEach(t),BJr=i(vi),$n=n(vi,"P",{});var bL=s($n);IJr=r(bL,"The model class to instantiate is selected based on the "),ewe=n(bL,"CODE",{});var Yqt=s(ewe);NJr=r(Yqt,"model_type"),Yqt.forEach(t),qJr=r(bL,` property of the config object (either
passed as an argument or loaded from `),owe=n(bL,"CODE",{});var Kqt=s(owe);jJr=r(Kqt,"pretrained_model_name_or_path"),Kqt.forEach(t),DJr=r(bL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rwe=n(bL,"CODE",{});var Zqt=s(rwe);GJr=r(Zqt,"pretrained_model_name_or_path"),Zqt.forEach(t),OJr=r(bL,":"),bL.forEach(t),VJr=i(vi),twe=n(vi,"UL",{});var ejt=s(twe);Yw=n(ejt,"LI",{});var gGe=s(Yw);awe=n(gGe,"STRONG",{});var ojt=s(awe);XJr=r(ojt,"vision-encoder-decoder"),ojt.forEach(t),zJr=r(gGe," \u2014 "),toe=n(gGe,"A",{href:!0});var rjt=s(toe);WJr=r(rjt,"FlaxVisionEncoderDecoderModel"),rjt.forEach(t),QJr=r(gGe," (Vision Encoder decoder model)"),gGe.forEach(t),ejt.forEach(t),HJr=i(vi),T(Kw.$$.fragment,vi),vi.forEach(t),bi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(iGt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Sn,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.AutoConfig"),c(Pn,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.AutoModel"),c(Bn,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.AutoTokenizer"),c(Ai,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertModel"),c(kf,"id","extending-the-auto-classes"),c(kf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kf,"href","#extending-the-auto-classes"),c(Li,"class","relative group"),c(Rf,"id","transformers.AutoConfig"),c(Rf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Rf,"href","#transformers.AutoConfig"),c(yi,"class","relative group"),c(oS,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(rS,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertConfig"),c(tS,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartConfig"),c(aS,"href","/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitConfig"),c(nS,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertConfig"),c(sS,"href","/docs/transformers/pr_17772/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(lS,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdConfig"),c(iS,"href","/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(dS,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(cS,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(fS,"href","/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomConfig"),c(mS,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertConfig"),c(gS,"href","/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineConfig"),c(hS,"href","/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPConfig"),c(pS,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertConfig"),c(uS,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextConfig"),c(_S,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLConfig"),c(bS,"href","/docs/transformers/pr_17772/en/model_doc/cvt#transformers.CvtConfig"),c(vS,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(FS,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(TS,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(MS,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaConfig"),c(ES,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(CS,"href","/docs/transformers/pr_17772/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(wS,"href","/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTConfig"),c(AS,"href","/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrConfig"),c(LS,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertConfig"),c(yS,"href","/docs/transformers/pr_17772/en/model_doc/dpr#transformers.DPRConfig"),c(xS,"href","/docs/transformers/pr_17772/en/model_doc/dpt#transformers.DPTConfig"),c($S,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraConfig"),c(kS,"href","/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(SS,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertConfig"),c(RS,"href","/docs/transformers/pr_17772/en/model_doc/flava#transformers.FlavaConfig"),c(PS,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetConfig"),c(BS,"href","/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTConfig"),c(IS,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelConfig"),c(NS,"href","/docs/transformers/pr_17772/en/model_doc/glpn#transformers.GLPNConfig"),c(qS,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Config"),c(jS,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(DS,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(GS,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJConfig"),c(OS,"href","/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertConfig"),c(VS,"href","/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertConfig"),c(XS,"href","/docs/transformers/pr_17772/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(zS,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(WS,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(QS,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(HS,"href","/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDConfig"),c(US,"href","/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitConfig"),c(JS,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerConfig"),c(YS,"href","/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5Config"),c(KS,"href","/docs/transformers/pr_17772/en/model_doc/luke#transformers.LukeConfig"),c(ZS,"href","/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertConfig"),c(eR,"href","/docs/transformers/pr_17772/en/model_doc/m2m_100#transformers.M2M100Config"),c(oR,"href","/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianConfig"),c(rR,"href","/docs/transformers/pr_17772/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(tR,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartConfig"),c(aR,"href","/docs/transformers/pr_17772/en/model_doc/mctct#transformers.MCTCTConfig"),c(nR,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(sR,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(lR,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetConfig"),c(iR,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Config"),c(dR,"href","/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(cR,"href","/docs/transformers/pr_17772/en/model_doc/omnivore#transformers.OmnivoreConfig"),c(fR,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(mR,"href","/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTConfig"),c(gR,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusConfig"),c(hR,"href","/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverConfig"),c(pR,"href","/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartConfig"),c(uR,"href","/docs/transformers/pr_17772/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(_R,"href","/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(bR,"href","/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(vR,"href","/docs/transformers/pr_17772/en/model_doc/rag#transformers.RagConfig"),c(FR,"href","/docs/transformers/pr_17772/en/model_doc/realm#transformers.RealmConfig"),c(TR,"href","/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerConfig"),c(MR,"href","/docs/transformers/pr_17772/en/model_doc/regnet#transformers.RegNetConfig"),c(ER,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertConfig"),c(CR,"href","/docs/transformers/pr_17772/en/model_doc/resnet#transformers.ResNetConfig"),c(wR,"href","/docs/transformers/pr_17772/en/model_doc/retribert#transformers.RetriBertConfig"),c(AR,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaConfig"),c(LR,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerConfig"),c(yR,"href","/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerConfig"),c(xR,"href","/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWConfig"),c($R,"href","/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDConfig"),c(kR,"href","/docs/transformers/pr_17772/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(SR,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(RR,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(PR,"href","/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterConfig"),c(BR,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(IR,"href","/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinConfig"),c(NR,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Config"),c(qR,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasConfig"),c(jR,"href","/docs/transformers/pr_17772/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(DR,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(GR,"href","/docs/transformers/pr_17772/en/model_doc/trocr#transformers.TrOCRConfig"),c(OR,"href","/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(VR,"href","/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(XR,"href","/docs/transformers/pr_17772/en/model_doc/van#transformers.VanConfig"),c(zR,"href","/docs/transformers/pr_17772/en/model_doc/vilt#transformers.ViltConfig"),c(WR,"href","/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(QR,"href","/docs/transformers/pr_17772/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(HR,"href","/docs/transformers/pr_17772/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(UR,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTConfig"),c(JR,"href","/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(YR,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(KR,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(ZR,"href","/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMConfig"),c(eP,"href","/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMConfig"),c(oP,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMConfig"),c(rP,"href","/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(tP,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(aP,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(nP,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetConfig"),c(sP,"href","/docs/transformers/pr_17772/en/model_doc/yolos#transformers.YolosConfig"),c(lP,"href","/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoConfig"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Og,"id","transformers.AutoTokenizer"),c(Og,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Og,"href","#transformers.AutoTokenizer"),c($i,"class","relative group"),c(iP,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(dP,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertTokenizer"),c(cP,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(fP,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartTokenizer"),c(mP,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartTokenizerFast"),c(gP,"href","/docs/transformers/pr_17772/en/model_doc/barthez#transformers.BarthezTokenizer"),c(hP,"href","/docs/transformers/pr_17772/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(pP,"href","/docs/transformers/pr_17772/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(uP,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizer"),c(_P,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizerFast"),c(bP,"href","/docs/transformers/pr_17772/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(vP,"href","/docs/transformers/pr_17772/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(FP,"href","/docs/transformers/pr_17772/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(TP,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(MP,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(EP,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(CP,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(wP,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(AP,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(LP,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(yP,"href","/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(xP,"href","/docs/transformers/pr_17772/en/model_doc/byt5#transformers.ByT5Tokenizer"),c($P,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertTokenizer"),c(kP,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(SP,"href","/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineTokenizer"),c(RP,"href","/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPTokenizer"),c(PP,"href","/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(BP,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(IP,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(NP,"href","/docs/transformers/pr_17772/en/model_doc/cpm#transformers.CpmTokenizer"),c(qP,"href","/docs/transformers/pr_17772/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(jP,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(DP,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaTokenizer"),c(GP,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(OP,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaTokenizer"),c(VP,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(XP,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(zP,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(WP,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(QP,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(HP,"href","/docs/transformers/pr_17772/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(UP,"href","/docs/transformers/pr_17772/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(JP,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraTokenizer"),c(YP,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(KP,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(ZP,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetTokenizer"),c(eB,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(oB,"href","/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(rB,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelTokenizer"),c(tB,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(aB,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(nB,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(sB,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(lB,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(iB,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(dB,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(cB,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(fB,"href","/docs/transformers/pr_17772/en/model_doc/herbert#transformers.HerbertTokenizer"),c(mB,"href","/docs/transformers/pr_17772/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(gB,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(hB,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaTokenizer"),c(pB,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(uB,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(_B,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(bB,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(vB,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(FB,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(TB,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(MB,"href","/docs/transformers/pr_17772/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(EB,"href","/docs/transformers/pr_17772/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(CB,"href","/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDTokenizer"),c(wB,"href","/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDTokenizerFast"),c(AB,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerTokenizer"),c(LB,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(yB,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.T5Tokenizer"),c(xB,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.T5TokenizerFast"),c($B,"href","/docs/transformers/pr_17772/en/model_doc/luke#transformers.LukeTokenizer"),c(kB,"href","/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(SB,"href","/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(RB,"href","/docs/transformers/pr_17772/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(PB,"href","/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianTokenizer"),c(BB,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartTokenizer"),c(IB,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(NB,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(qB,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(jB,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizer"),c(DB,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizerFast"),c(GB,"href","/docs/transformers/pr_17772/en/model_doc/mluke#transformers.MLukeTokenizer"),c(OB,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(VB,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(XB,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(zB,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(WB,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.T5Tokenizer"),c(QB,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.T5TokenizerFast"),c(HB,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertTokenizer"),c(UB,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(JB,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(YB,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(KB,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ZB,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(eI,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(oI,"href","/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(rI,"href","/docs/transformers/pr_17772/en/model_doc/phobert#transformers.PhobertTokenizer"),c(tI,"href","/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartTokenizer"),c(aI,"href","/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(nI,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizer"),c(sI,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizerFast"),c(lI,"href","/docs/transformers/pr_17772/en/model_doc/rag#transformers.RagTokenizer"),c(iI,"href","/docs/transformers/pr_17772/en/model_doc/realm#transformers.RealmTokenizer"),c(dI,"href","/docs/transformers/pr_17772/en/model_doc/realm#transformers.RealmTokenizerFast"),c(cI,"href","/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerTokenizer"),c(fI,"href","/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(mI,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertTokenizer"),c(gI,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(hI,"href","/docs/transformers/pr_17772/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(pI,"href","/docs/transformers/pr_17772/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(uI,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaTokenizer"),c(_I,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(bI,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(vI,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(FI,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(TI,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(MI,"href","/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterTokenizer"),c(EI,"href","/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(CI,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(wI,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(AI,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.T5Tokenizer"),c(LI,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.T5TokenizerFast"),c(yI,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasTokenizer"),c(xI,"href","/docs/transformers/pr_17772/en/model_doc/tapex#transformers.TapexTokenizer"),c($I,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(kI,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizer"),c(SI,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizerFast"),c(RI,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizer"),c(PI,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertTokenizerFast"),c(BI,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(II,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(NI,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(qI,"href","/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMTokenizer"),c(jI,"href","/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(DI,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMTokenizer"),c(GI,"href","/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(OI,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(VI,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(XI,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaTokenizer"),c(zI,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(WI,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(QI,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(HI,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertTokenizer"),c(UI,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ch,"id","transformers.AutoFeatureExtractor"),c(Ch,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ch,"href","#transformers.AutoFeatureExtractor"),c(ki,"class","relative group"),c(JI,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(YI,"href","/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(KI,"href","/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(ZI,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(eN,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(oN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(rN,"href","/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(tN,"href","/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(aN,"href","/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(nN,"href","/docs/transformers/pr_17772/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(sN,"href","/docs/transformers/pr_17772/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(lN,"href","/docs/transformers/pr_17772/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(iN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(dN,"href","/docs/transformers/pr_17772/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(cN,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(fN,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(mN,"href","/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(gN,"href","/docs/transformers/pr_17772/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(hN,"href","/docs/transformers/pr_17772/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(pN,"href","/docs/transformers/pr_17772/en/model_doc/omnivore#transformers.OmnivoreFeatureExtractor"),c(uN,"href","/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(_N,"href","/docs/transformers/pr_17772/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(bN,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(vN,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(FN,"href","/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(TN,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(MN,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(EN,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(CN,"href","/docs/transformers/pr_17772/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(wN,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(AN,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(LN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(yN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(xN,"href","/docs/transformers/pr_17772/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lp,"id","transformers.AutoProcessor"),c(lp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lp,"href","#transformers.AutoProcessor"),c(Si,"class","relative group"),c($N,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(kN,"href","/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPProcessor"),c(SN,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(RN,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(PN,"href","/docs/transformers/pr_17772/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(BN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(IN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(NN,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(qN,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(jN,"href","/docs/transformers/pr_17772/en/model_doc/trocr#transformers.TrOCRProcessor"),c(DN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(GN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ON,"href","/docs/transformers/pr_17772/en/model_doc/vilt#transformers.ViltProcessor"),c(VN,"href","/docs/transformers/pr_17772/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(XN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(zN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(WN,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yp,"id","transformers.AutoModel"),c(yp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yp,"href","#transformers.AutoModel"),c(Pi,"class","relative group"),c(QN,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HN,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UN,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JN,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertModel"),c(YN,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartModel"),c(KN,"href","/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitModel"),c(ZN,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertModel"),c(eq,"href","/docs/transformers/pr_17772/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(oq,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdModel"),c(rq,"href","/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(tq,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(aq,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(nq,"href","/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomModel"),c(sq,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertModel"),c(lq,"href","/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineModel"),c(iq,"href","/docs/transformers/pr_17772/en/model_doc/clip#transformers.CLIPModel"),c(dq,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertModel"),c(cq,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextModel"),c(fq,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLModel"),c(mq,"href","/docs/transformers/pr_17772/en/model_doc/cvt#transformers.CvtModel"),c(gq,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(hq,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(pq,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(uq,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaModel"),c(_q,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(bq,"href","/docs/transformers/pr_17772/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(vq,"href","/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTModel"),c(Fq,"href","/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrModel"),c(Tq,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertModel"),c(Mq,"href","/docs/transformers/pr_17772/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(Eq,"href","/docs/transformers/pr_17772/en/model_doc/dpt#transformers.DPTModel"),c(Cq,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraModel"),c(wq,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertModel"),c(Aq,"href","/docs/transformers/pr_17772/en/model_doc/flava#transformers.FlavaModel"),c(Lq,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetModel"),c(yq,"href","/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTModel"),c(xq,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelModel"),c($q,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelBaseModel"),c(kq,"href","/docs/transformers/pr_17772/en/model_doc/glpn#transformers.GLPNModel"),c(Sq,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2Model"),c(Rq,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Pq,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Bq,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJModel"),c(Iq,"href","/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertModel"),c(Nq,"href","/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertModel"),c(qq,"href","/docs/transformers/pr_17772/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(jq,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Dq,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Gq,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Oq,"href","/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDModel"),c(Vq,"href","/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitModel"),c(Xq,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerModel"),c(zq,"href","/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5Model"),c(Wq,"href","/docs/transformers/pr_17772/en/model_doc/luke#transformers.LukeModel"),c(Qq,"href","/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertModel"),c(Hq,"href","/docs/transformers/pr_17772/en/model_doc/m2m_100#transformers.M2M100Model"),c(Uq,"href","/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianModel"),c(Jq,"href","/docs/transformers/pr_17772/en/model_doc/maskformer#transformers.MaskFormerModel"),c(Yq,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartModel"),c(Kq,"href","/docs/transformers/pr_17772/en/model_doc/mctct#transformers.MCTCTModel"),c(Zq,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(ej,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertModel"),c(oj,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetModel"),c(rj,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5Model"),c(tj,"href","/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerModel"),c(aj,"href","/docs/transformers/pr_17772/en/model_doc/omnivore#transformers.OmnivoreModel"),c(nj,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(sj,"href","/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTModel"),c(lj,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusModel"),c(ij,"href","/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverModel"),c(dj,"href","/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartModel"),c(cj,"href","/docs/transformers/pr_17772/en/model_doc/poolformer#transformers.PoolFormerModel"),c(fj,"href","/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(mj,"href","/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertModel"),c(gj,"href","/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerModel"),c(hj,"href","/docs/transformers/pr_17772/en/model_doc/regnet#transformers.RegNetModel"),c(pj,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertModel"),c(uj,"href","/docs/transformers/pr_17772/en/model_doc/resnet#transformers.ResNetModel"),c(_j,"href","/docs/transformers/pr_17772/en/model_doc/retribert#transformers.RetriBertModel"),c(bj,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaModel"),c(vj,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerModel"),c(Fj,"href","/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerModel"),c(Tj,"href","/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWModel"),c(Mj,"href","/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDModel"),c(Ej,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Cj,"href","/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterModel"),c(wj,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(Aj,"href","/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinModel"),c(Lj,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5Model"),c(yj,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasModel"),c(xj,"href","/docs/transformers/pr_17772/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c($j,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(kj,"href","/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Sj,"href","/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Rj,"href","/docs/transformers/pr_17772/en/model_doc/van#transformers.VanModel"),c(Pj,"href","/docs/transformers/pr_17772/en/model_doc/vilt#transformers.ViltModel"),c(Bj,"href","/docs/transformers/pr_17772/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Ij,"href","/docs/transformers/pr_17772/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Nj,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTModel"),c(qj,"href","/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(jj,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Dj,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Gj,"href","/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMModel"),c(Oj,"href","/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMModel"),c(Vj,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMModel"),c(Xj,"href","/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(zj,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(Wj,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(Qj,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetModel"),c(Hj,"href","/docs/transformers/pr_17772/en/model_doc/yolos#transformers.YolosModel"),c(Uj,"href","/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($_,"id","transformers.AutoModelForPreTraining"),c($_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($_,"href","#transformers.AutoModelForPreTraining"),c(Ni,"class","relative group"),c(Jj,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yj,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kj,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zj,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForPreTraining"),c(eD,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(oD,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForPreTraining"),c(rD,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(tD,"href","/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomForCausalLM"),c(aD,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(nD,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(sD,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(lD,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(iD,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(dD,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(cD,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForPreTraining"),c(fD,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(mD,"href","/docs/transformers/pr_17772/en/model_doc/flava#transformers.FlavaForPreTraining"),c(gD,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForPreTraining"),c(hD,"href","/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(pD,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(uD,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(_D,"href","/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(bD,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(vD,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(FD,"href","/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(TD,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(MD,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(ED,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(CD,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(wD,"href","/docs/transformers/pr_17772/en/model_doc/retribert#transformers.RetriBertModel"),c(AD,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(LD,"href","/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(yD,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(xD,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c($D,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(kD,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(SD,"href","/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(RD,"href","/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(PD,"href","/docs/transformers/pr_17772/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(BD,"href","/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(ID,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(ND,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(qD,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(jD,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(DD,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(GD,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E7,"id","transformers.AutoModelForCausalLM"),c(E7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E7,"href","#transformers.AutoModelForCausalLM"),c(Di,"class","relative group"),c(OD,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VD,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XD,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zD,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForCausalLM"),c(WD,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertLMHeadModel"),c(QD,"href","/docs/transformers/pr_17772/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(HD,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(UD,"href","/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(JD,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(YD,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(KD,"href","/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomForCausalLM"),c(ZD,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(eG,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(oG,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(rG,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForCausalLM"),c(tG,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(aG,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(nG,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(sG,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(lG,"href","/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianForCausalLM"),c(iG,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForCausalLM"),c(dG,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(cG,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(fG,"href","/docs/transformers/pr_17772/en/model_doc/opt#transformers.OPTForCausalLM"),c(mG,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(gG,"href","/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(hG,"href","/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(pG,"href","/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(uG,"href","/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(_G,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(bG,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(vG,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(FG,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(TG,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(MG,"href","/docs/transformers/pr_17772/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(EG,"href","/docs/transformers/pr_17772/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(CG,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(wG,"href","/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(AG,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(LG,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(yG,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f2,"id","transformers.AutoModelForMaskedLM"),c(f2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f2,"href","#transformers.AutoModelForMaskedLM"),c(Vi,"class","relative group"),c(xG,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($G,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kG,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SG,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(RG,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(PG,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForMaskedLM"),c(BG,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(IG,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(NG,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(qG,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(jG,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(DG,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(GG,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(OG,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(VG,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(XG,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(zG,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(WG,"href","/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(QG,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(HG,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(UG,"href","/docs/transformers/pr_17772/en/model_doc/luke#transformers.LukeForMaskedLM"),c(JG,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(YG,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(KG,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(ZG,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(eO,"href","/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(oO,"href","/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(rO,"href","/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(tO,"href","/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(aO,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(nO,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(sO,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(lO,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(iO,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(dO,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(cO,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(fO,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(mO,"href","/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y2,"id","transformers.AutoModelForSeq2SeqLM"),c(Y2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y2,"href","#transformers.AutoModelForSeq2SeqLM"),c(Wi,"class","relative group"),c(gO,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hO,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pO,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uO,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(_O,"href","/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(bO,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(vO,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(FO,"href","/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(TO,"href","/docs/transformers/pr_17772/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(MO,"href","/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(EO,"href","/docs/transformers/pr_17772/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(CO,"href","/docs/transformers/pr_17772/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(wO,"href","/docs/transformers/pr_17772/en/model_doc/marian#transformers.MarianMTModel"),c(AO,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(LO,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(yO,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(xO,"href","/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c($O,"href","/docs/transformers/pr_17772/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(kO,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(SO,"href","/docs/transformers/pr_17772/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b1,"id","transformers.AutoModelForSequenceClassification"),c(b1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b1,"href","#transformers.AutoModelForSequenceClassification"),c(Ui,"class","relative group"),c(RO,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PO,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BO,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IO,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(NO,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForSequenceClassification"),c(qO,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForSequenceClassification"),c(jO,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(DO,"href","/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(GO,"href","/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(OO,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(VO,"href","/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(XO,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(zO,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(WO,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(QO,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(HO,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(UO,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(JO,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(YO,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(KO,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(ZO,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(eV,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(oV,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(rV,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(tV,"href","/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(aV,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(nV,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(sV,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(lV,"href","/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDForSequenceClassification"),c(iV,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(dV,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(cV,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(fV,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(mV,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(gV,"href","/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(hV,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(pV,"href","/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(uV,"href","/docs/transformers/pr_17772/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(_V,"href","/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(bV,"href","/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(vV,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(FV,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(TV,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(MV,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(EV,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(CV,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(wV,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(AV,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(LV,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(yV,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(xV,"href","/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ub,"id","transformers.AutoModelForMultipleChoice"),c(ub,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ub,"href","#transformers.AutoModelForMultipleChoice"),c(Ki,"class","relative group"),c($V,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kV,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SV,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RV,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(PV,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForMultipleChoice"),c(BV,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(IV,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(NV,"href","/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(qV,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(jV,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(DV,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(GV,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(OV,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(VV,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(XV,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(zV,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(WV,"href","/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(QV,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(HV,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(UV,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(JV,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(YV,"href","/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(KV,"href","/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(ZV,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(eX,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(oX,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(rX,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(tX,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(aX,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(nX,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(sX,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(lX,"href","/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ub,"id","transformers.AutoModelForNextSentencePrediction"),c(Ub,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ub,"href","#transformers.AutoModelForNextSentencePrediction"),c(od,"class","relative group"),c(iX,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dX,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cX,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fX,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(mX,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(gX,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(hX,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(pX,"href","/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(av,"id","transformers.AutoModelForTokenClassification"),c(av,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(av,"href","#transformers.AutoModelForTokenClassification"),c(ad,"class","relative group"),c(uX,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_X,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bX,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vX,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(FX,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForTokenClassification"),c(TX,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(MX,"href","/docs/transformers/pr_17772/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(EX,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(CX,"href","/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineForTokenClassification"),c(wX,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(AX,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(LX,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(yX,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(xX,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c($X,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(kX,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(SX,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(RX,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(PX,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(BX,"href","/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(IX,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(NX,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(qX,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(jX,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(DX,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(GX,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(OX,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(VX,"href","/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(XX,"href","/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(zX,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(WX,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(QX,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(HX,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(UX,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(JX,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(YX,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(KX,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(ZX,"href","/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vv,"id","transformers.AutoModelForQuestionAnswering"),c(Vv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vv,"href","#transformers.AutoModelForQuestionAnswering"),c(ld,"class","relative group"),c(ez,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oz,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rz,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tz,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(az,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(nz,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(sz,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(lz,"href","/docs/transformers/pr_17772/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(iz,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(dz,"href","/docs/transformers/pr_17772/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(cz,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(fz,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(mz,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(gz,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(hz,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(pz,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(uz,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(_z,"href","/docs/transformers/pr_17772/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(bz,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(vz,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(Fz,"href","/docs/transformers/pr_17772/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(Tz,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(Mz,"href","/docs/transformers/pr_17772/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(Ez,"href","/docs/transformers/pr_17772/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(Cz,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(wz,"href","/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(Az,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(Lz,"href","/docs/transformers/pr_17772/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(yz,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(xz,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c($z,"href","/docs/transformers/pr_17772/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(kz,"href","/docs/transformers/pr_17772/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(Sz,"href","/docs/transformers/pr_17772/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(Rz,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(Pz,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(Bz,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(Iz,"href","/docs/transformers/pr_17772/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(Nz,"href","/docs/transformers/pr_17772/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(qz,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(jz,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(Dz,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(Gz,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(Oz,"href","/docs/transformers/pr_17772/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RF,"id","transformers.AutoModelForTableQuestionAnswering"),c(RF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RF,"href","#transformers.AutoModelForTableQuestionAnswering"),c(cd,"class","relative group"),c(Vz,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xz,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zz,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wz,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qF,"id","transformers.AutoModelForImageClassification"),c(qF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qF,"href","#transformers.AutoModelForImageClassification"),c(gd,"class","relative group"),c(Qz,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Hz,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Uz,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jz,"href","/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitForImageClassification"),c(Yz,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(Kz,"href","/docs/transformers/pr_17772/en/model_doc/cvt#transformers.CvtForImageClassification"),c(Zz,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(eW,"href","/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTForImageClassification"),c(oW,"href","/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(rW,"href","/docs/transformers/pr_17772/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(tW,"href","/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitForImageClassification"),c(aW,"href","/docs/transformers/pr_17772/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(nW,"href","/docs/transformers/pr_17772/en/model_doc/omnivore#transformers.OmnivoreForVisionClassification"),c(sW,"href","/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(lW,"href","/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(iW,"href","/docs/transformers/pr_17772/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(dW,"href","/docs/transformers/pr_17772/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(cW,"href","/docs/transformers/pr_17772/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(fW,"href","/docs/transformers/pr_17772/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(mW,"href","/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(gW,"href","/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinForImageClassification"),c(hW,"href","/docs/transformers/pr_17772/en/model_doc/van#transformers.VanForImageClassification"),c(pW,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oT,"id","transformers.AutoModelForVision2Seq"),c(oT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oT,"href","#transformers.AutoModelForVision2Seq"),c(ud,"class","relative group"),c(uW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_W,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vW,"href","/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sT,"id","transformers.AutoModelForVisualQuestionAnswering"),c(sT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sT,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(vd,"class","relative group"),c(FW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EW,"href","/docs/transformers/pr_17772/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fT,"id","transformers.AutoModelForAudioClassification"),c(fT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fT,"href","#transformers.AutoModelForAudioClassification"),c(Md,"class","relative group"),c(CW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LW,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(yW,"href","/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(xW,"href","/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWForSequenceClassification"),c($W,"href","/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(kW,"href","/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(SW,"href","/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(RW,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(PW,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(BW,"href","/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CT,"id","transformers.AutoModelForAudioFrameClassification"),c(CT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CT,"href","#transformers.AutoModelForAudioFrameClassification"),c(wd,"class","relative group"),c(IW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jW,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(DW,"href","/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(GW,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(OW,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(VW,"href","/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RT,"id","transformers.AutoModelForCTC"),c(RT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RT,"href","#transformers.AutoModelForCTC"),c(yd,"class","relative group"),c(XW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WW,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QW,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(HW,"href","/docs/transformers/pr_17772/en/model_doc/hubert#transformers.HubertForCTC"),c(UW,"href","/docs/transformers/pr_17772/en/model_doc/mctct#transformers.MCTCTForCTC"),c(JW,"href","/docs/transformers/pr_17772/en/model_doc/sew#transformers.SEWForCTC"),c(YW,"href","/docs/transformers/pr_17772/en/model_doc/sew-d#transformers.SEWDForCTC"),c(KW,"href","/docs/transformers/pr_17772/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(ZW,"href","/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(eQ,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(oQ,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(rQ,"href","/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QT,"id","transformers.AutoModelForSpeechSeq2Seq"),c(QT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QT,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(kd,"class","relative group"),c(tQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sQ,"href","/docs/transformers/pr_17772/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(lQ,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZT,"id","transformers.AutoModelForAudioXVector"),c(ZT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZT,"href","#transformers.AutoModelForAudioXVector"),c(Pd,"class","relative group"),c(iQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fQ,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(mQ,"href","/docs/transformers/pr_17772/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(gQ,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(hQ,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(pQ,"href","/docs/transformers/pr_17772/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iM,"id","transformers.AutoModelForMaskedImageModeling"),c(iM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(iM,"href","#transformers.AutoModelForMaskedImageModeling"),c(Nd,"class","relative group"),c(uQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_Q,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vQ,"href","/docs/transformers/pr_17772/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(FQ,"href","/docs/transformers/pr_17772/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(TQ,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pM,"id","transformers.AutoModelForObjectDetection"),c(pM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pM,"href","#transformers.AutoModelForObjectDetection"),c(Gd,"class","relative group"),c(MQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wQ,"href","/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrForObjectDetection"),c(AQ,"href","/docs/transformers/pr_17772/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TM,"id","transformers.AutoModelForImageSegmentation"),c(TM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TM,"href","#transformers.AutoModelForImageSegmentation"),c(Xd,"class","relative group"),c(LQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($Q,"href","/docs/transformers/pr_17772/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AM,"id","transformers.AutoModelForSemanticSegmentation"),c(AM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AM,"href","#transformers.AutoModelForSemanticSegmentation"),c(Qd,"class","relative group"),c(kQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PQ,"href","/docs/transformers/pr_17772/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(BQ,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(IQ,"href","/docs/transformers/pr_17772/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(NQ,"href","/docs/transformers/pr_17772/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PM,"id","transformers.AutoModelForInstanceSegmentation"),c(PM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PM,"href","#transformers.AutoModelForInstanceSegmentation"),c(Jd,"class","relative group"),c(qQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GQ,"href","/docs/transformers/pr_17772/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jM,"id","transformers.TFAutoModel"),c(jM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jM,"href","#transformers.TFAutoModel"),c(Zd,"class","relative group"),c(OQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XQ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zQ,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertModel"),c(WQ,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.TFBartModel"),c(QQ,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertModel"),c(HQ,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(UQ,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(JQ,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertModel"),c(YQ,"href","/docs/transformers/pr_17772/en/model_doc/clip#transformers.TFCLIPModel"),c(KQ,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertModel"),c(ZQ,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.TFConvNextModel"),c(eH,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.TFCTRLModel"),c(oH,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(rH,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaModel"),c(tH,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(aH,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(nH,"href","/docs/transformers/pr_17772/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(sH,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraModel"),c(lH,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(iH,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelModel"),c(dH,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(cH,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.TFGPT2Model"),c(fH,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.TFGPTJModel"),c(mH,"href","/docs/transformers/pr_17772/en/model_doc/hubert#transformers.TFHubertModel"),c(gH,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(hH,"href","/docs/transformers/pr_17772/en/model_doc/led#transformers.TFLEDModel"),c(pH,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerModel"),c(uH,"href","/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.TFLxmertModel"),c(_H,"href","/docs/transformers/pr_17772/en/model_doc/marian#transformers.TFMarianModel"),c(bH,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.TFMBartModel"),c(vH,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(FH,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetModel"),c(TH,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.TFMT5Model"),c(MH,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(EH,"href","/docs/transformers/pr_17772/en/model_doc/opt#transformers.TFOPTModel"),c(CH,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.TFPegasusModel"),c(wH,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertModel"),c(AH,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaModel"),c(LH,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerModel"),c(yH,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(xH,"href","/docs/transformers/pr_17772/en/model_doc/swin#transformers.TFSwinModel"),c($H,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.TFT5Model"),c(kH,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasModel"),c(SH,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(RH,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.TFViTModel"),c(PH,"href","/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(BH,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(IH,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMModel"),c(NH,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(qH,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PE,"id","transformers.TFAutoModelForPreTraining"),c(PE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PE,"href","#transformers.TFAutoModelForPreTraining"),c(rc,"class","relative group"),c(jH,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DH,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GH,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OH,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(VH,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(XH,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForPreTraining"),c(zH,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(WH,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(QH,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(HH,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(UH,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(JH,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(YH,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(KH,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(ZH,"href","/docs/transformers/pr_17772/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(eU,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(oU,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(rU,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(tU,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(aU,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(nU,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(sU,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(lU,"href","/docs/transformers/pr_17772/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(iU,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(dU,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(cU,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s4,"id","transformers.TFAutoModelForCausalLM"),c(s4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s4,"href","#transformers.TFAutoModelForCausalLM"),c(nc,"class","relative group"),c(fU,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mU,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gU,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hU,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(pU,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(uU,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(_U,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(bU,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(vU,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(FU,"href","/docs/transformers/pr_17772/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(TU,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(MU,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(EU,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(CU,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(wU,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(AU,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(M4,"id","transformers.TFAutoModelForImageClassification"),c(M4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M4,"href","#transformers.TFAutoModelForImageClassification"),c(ic,"class","relative group"),c(LU,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yU,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xU,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($U,"href","/docs/transformers/pr_17772/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(kU,"href","/docs/transformers/pr_17772/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(SU,"href","/docs/transformers/pr_17772/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(RU,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.TFViTForImageClassification"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x4,"id","transformers.TFAutoModelForMaskedLM"),c(x4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x4,"href","#transformers.TFAutoModelForMaskedLM"),c(fc,"class","relative group"),c(PU,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BU,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IU,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NU,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(qU,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(jU,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(DU,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(GU,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(OU,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(VU,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(XU,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(zU,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(WU,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(QU,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(HU,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(UU,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(JU,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(YU,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(KU,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(ZU,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(eJ,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(oJ,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(rJ,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K4,"id","transformers.TFAutoModelForSeq2SeqLM"),c(K4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K4,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(hc,"class","relative group"),c(tJ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aJ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nJ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sJ,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(lJ,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(iJ,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(dJ,"href","/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(cJ,"href","/docs/transformers/pr_17772/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(fJ,"href","/docs/transformers/pr_17772/en/model_doc/marian#transformers.TFMarianMTModel"),c(mJ,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(gJ,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(hJ,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(pJ,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fC,"id","transformers.TFAutoModelForSequenceClassification"),c(fC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fC,"href","#transformers.TFAutoModelForSequenceClassification"),c(_c,"class","relative group"),c(uJ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_J,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bJ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vJ,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(FJ,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(TJ,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(MJ,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(EJ,"href","/docs/transformers/pr_17772/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(CJ,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(wJ,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(AJ,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(LJ,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(yJ,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(xJ,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c($J,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(kJ,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(SJ,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(RJ,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(PJ,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(BJ,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(IJ,"href","/docs/transformers/pr_17772/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(NJ,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(qJ,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(jJ,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(DJ,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(GJ,"href","/docs/transformers/pr_17772/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(OJ,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(VJ,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(XJ,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DC,"id","transformers.TFAutoModelForMultipleChoice"),c(DC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DC,"href","#transformers.TFAutoModelForMultipleChoice"),c(Fc,"class","relative group"),c(zJ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WJ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QJ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HJ,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(UJ,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(JJ,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(YJ,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(KJ,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(ZJ,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(eY,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(oY,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(rY,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(tY,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(aY,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(nY,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(sY,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(lY,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(iY,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(dY,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(cY,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s5,"id","transformers.TFAutoModelForNextSentencePrediction"),c(s5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s5,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Ec,"class","relative group"),c(fY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hY,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(pY,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f5,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(f5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f5,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Ac,"class","relative group"),c(uY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_Y,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vY,"href","/docs/transformers/pr_17772/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p5,"id","transformers.TFAutoModelForTokenClassification"),c(p5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p5,"href","#transformers.TFAutoModelForTokenClassification"),c(xc,"class","relative group"),c(FY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EY,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(CY,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(wY,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(AY,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(LY,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(yY,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(xY,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c($Y,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(kY,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(SY,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(RY,"href","/docs/transformers/pr_17772/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(PY,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(BY,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(IY,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(NY,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(qY,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(jY,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(DY,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(GY,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(OY,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q5,"id","transformers.TFAutoModelForQuestionAnswering"),c(q5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q5,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Sc,"class","relative group"),c(VY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zY,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WY,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(QY,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(HY,"href","/docs/transformers/pr_17772/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(UY,"href","/docs/transformers/pr_17772/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(JY,"href","/docs/transformers/pr_17772/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(YY,"href","/docs/transformers/pr_17772/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(KY,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(ZY,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(eK,"href","/docs/transformers/pr_17772/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(oK,"href","/docs/transformers/pr_17772/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(rK,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(tK,"href","/docs/transformers/pr_17772/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(aK,"href","/docs/transformers/pr_17772/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(nK,"href","/docs/transformers/pr_17772/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(sK,"href","/docs/transformers/pr_17772/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(lK,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(iK,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(dK,"href","/docs/transformers/pr_17772/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(cK,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(fK,"href","/docs/transformers/pr_17772/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l3,"id","transformers.TFAutoModelForVision2Seq"),c(l3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l3,"href","#transformers.TFAutoModelForVision2Seq"),c(Bc,"class","relative group"),c(mK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pK,"href","/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f3,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(f3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f3,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(qc,"class","relative group"),c(uK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_K,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vK,"href","/docs/transformers/pr_17772/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p3,"id","transformers.FlaxAutoModel"),c(p3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p3,"href","#transformers.FlaxAutoModel"),c(Gc,"class","relative group"),c(FK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EK,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertModel"),c(CK,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartModel"),c(wK,"href","/docs/transformers/pr_17772/en/model_doc/beit#transformers.FlaxBeitModel"),c(AK,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertModel"),c(LK,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(yK,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(xK,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c($K,"href","/docs/transformers/pr_17772/en/model_doc/clip#transformers.FlaxCLIPModel"),c(kK,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(SK,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraModel"),c(RK,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(PK,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(BK,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(IK,"href","/docs/transformers/pr_17772/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(NK,"href","/docs/transformers/pr_17772/en/model_doc/marian#transformers.FlaxMarianModel"),c(qK,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartModel"),c(jK,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.FlaxMT5Model"),c(DK,"href","/docs/transformers/pr_17772/en/model_doc/opt#transformers.FlaxOPTModel"),c(GK,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(OK,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(VK,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(XK,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.FlaxT5Model"),c(zK,"href","/docs/transformers/pr_17772/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(WK,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.FlaxViTModel"),c(QK,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(HK,"href","/docs/transformers/pr_17772/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(UK,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z3,"id","transformers.FlaxAutoModelForCausalLM"),c(z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z3,"href","#transformers.FlaxAutoModelForCausalLM"),c(Xc,"class","relative group"),c(JK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KK,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZK,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(eZ,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(oZ,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(rZ,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(tZ,"href","/docs/transformers/pr_17772/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(aZ,"href","/docs/transformers/pr_17772/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(nZ,"href","/docs/transformers/pr_17772/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(sZ,"href","/docs/transformers/pr_17772/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(lZ,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(iZ,"href","/docs/transformers/pr_17772/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a0,"id","transformers.FlaxAutoModelForPreTraining"),c(a0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a0,"href","#transformers.FlaxAutoModelForPreTraining"),c(Qc,"class","relative group"),c(dZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mZ,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(gZ,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(hZ,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(pZ,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(uZ,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(_Z,"href","/docs/transformers/pr_17772/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(bZ,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(vZ,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(FZ,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(TZ,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(MZ,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(EZ,"href","/docs/transformers/pr_17772/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(CZ,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F0,"id","transformers.FlaxAutoModelForMaskedLM"),c(F0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F0,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Jc,"class","relative group"),c(wZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yZ,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(xZ,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c($Z,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(kZ,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(SZ,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(RZ,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(PZ,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(BZ,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(IZ,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(NZ,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R0,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(R0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R0,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Zc,"class","relative group"),c(qZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GZ,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(OZ,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(VZ,"href","/docs/transformers/pr_17772/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(XZ,"href","/docs/transformers/pr_17772/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(zZ,"href","/docs/transformers/pr_17772/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(WZ,"href","/docs/transformers/pr_17772/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(QZ,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(HZ,"href","/docs/transformers/pr_17772/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(UZ,"href","/docs/transformers/pr_17772/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(JZ,"href","/docs/transformers/pr_17772/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W0,"id","transformers.FlaxAutoModelForSequenceClassification"),c(W0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W0,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(rf,"class","relative group"),c(YZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZZ,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eee,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(oee,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(ree,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(tee,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(aee,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(nee,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(see,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(lee,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(iee,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(dee,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nw,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(nw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nw,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(nf,"class","relative group"),c(cee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gee,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(hee,"href","/docs/transformers/pr_17772/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(pee,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(uee,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(_ee,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(bee,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(vee,"href","/docs/transformers/pr_17772/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Fee,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Tee,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Mee,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bw,"id","transformers.FlaxAutoModelForTokenClassification"),c(bw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bw,"href","#transformers.FlaxAutoModelForTokenClassification"),c(df,"class","relative group"),c(Eee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Cee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Aee,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Lee,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(yee,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(xee,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c($ee,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(kee,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(See,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Ree,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xw,"id","transformers.FlaxAutoModelForMultipleChoice"),c(xw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xw,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(mf,"class","relative group"),c(Pee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Iee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nee,"href","/docs/transformers/pr_17772/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(qee,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(jee,"href","/docs/transformers/pr_17772/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Dee,"href","/docs/transformers/pr_17772/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Gee,"href","/docs/transformers/pr_17772/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Oee,"href","/docs/transformers/pr_17772/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Vee,"href","/docs/transformers/pr_17772/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Xee,"href","/docs/transformers/pr_17772/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dw,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Dw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Dw,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(pf,"class","relative group"),c(zee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hee,"href","/docs/transformers/pr_17772/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xw,"id","transformers.FlaxAutoModelForImageClassification"),c(Xw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xw,"href","#transformers.FlaxAutoModelForImageClassification"),c(bf,"class","relative group"),c(Uee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yee,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kee,"href","/docs/transformers/pr_17772/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Zee,"href","/docs/transformers/pr_17772/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uw,"id","transformers.FlaxAutoModelForVision2Seq"),c(Uw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uw,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Tf,"class","relative group"),c(eoe,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ooe,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(roe,"href","/docs/transformers/pr_17772/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(toe,"href","/docs/transformers/pr_17772/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),b(f,v,_),b(f,p,_),e(p,m),e(m,u),M(d,u,null),e(p,h),e(p,Eo),e(Eo,Fi),b(f,Lf,_),b(f,at,_),e(at,Ti),e(at,Mi),e(Mi,vL),e(at,yf),b(f,Oe,_),b(f,We,_),e(We,Ei),e(We,Sn),e(Sn,FL),e(We,Rn),e(We,Pn),e(Pn,TL),e(We,Ci),e(We,Bn),e(Bn,ML),e(We,wi),b(f,xf,_),M(ya,f,_),b(f,Qe,_),b(f,Ae,_),e(Ae,Uk),e(Ae,Ai),e(Ai,Jk),e(Ae,Yk),b(f,Co,_),b(f,xa,_),e(xa,Kk),e(xa,$f),e($f,Zk),e(xa,xze),b(f,hGe,_),b(f,Li,_),e(Li,kf),e(kf,Kre),M(EL,Kre,null),e(Li,$ze),e(Li,Zre),e(Zre,kze),b(f,pGe,_),b(f,In,_),e(In,Sze),e(In,ete),e(ete,Rze),e(In,Pze),e(In,ote),e(ote,Bze),e(In,Ize),b(f,uGe,_),M(CL,f,_),b(f,_Ge,_),b(f,eS,_),e(eS,Nze),b(f,bGe,_),M(Sf,f,_),b(f,vGe,_),b(f,yi,_),e(yi,Rf),e(Rf,rte),M(wL,rte,null),e(yi,qze),e(yi,tte),e(tte,jze),b(f,FGe,_),b(f,wo,_),M(AL,wo,null),e(wo,Dze),e(wo,LL),e(LL,Gze),e(LL,oS),e(oS,Oze),e(LL,Vze),e(wo,Xze),e(wo,yL),e(yL,zze),e(yL,ate),e(ate,Wze),e(yL,Qze),e(wo,Hze),e(wo,wr),M(xL,wr,null),e(wr,Uze),e(wr,nte),e(nte,Jze),e(wr,Yze),e(wr,xi),e(xi,Kze),e(xi,ste),e(ste,Zze),e(xi,eWe),e(xi,lte),e(lte,oWe),e(xi,rWe),e(wr,tWe),e(wr,A),e(A,Pf),e(Pf,ite),e(ite,aWe),e(Pf,nWe),e(Pf,rS),e(rS,sWe),e(Pf,lWe),e(A,iWe),e(A,Bf),e(Bf,dte),e(dte,dWe),e(Bf,cWe),e(Bf,tS),e(tS,fWe),e(Bf,mWe),e(A,gWe),e(A,If),e(If,cte),e(cte,hWe),e(If,pWe),e(If,aS),e(aS,uWe),e(If,_We),e(A,bWe),e(A,Nf),e(Nf,fte),e(fte,vWe),e(Nf,FWe),e(Nf,nS),e(nS,TWe),e(Nf,MWe),e(A,EWe),e(A,qf),e(qf,mte),e(mte,CWe),e(qf,wWe),e(qf,sS),e(sS,AWe),e(qf,LWe),e(A,yWe),e(A,jf),e(jf,gte),e(gte,xWe),e(jf,$We),e(jf,lS),e(lS,kWe),e(jf,SWe),e(A,RWe),e(A,Df),e(Df,hte),e(hte,PWe),e(Df,BWe),e(Df,iS),e(iS,IWe),e(Df,NWe),e(A,qWe),e(A,Gf),e(Gf,pte),e(pte,jWe),e(Gf,DWe),e(Gf,dS),e(dS,GWe),e(Gf,OWe),e(A,VWe),e(A,Of),e(Of,ute),e(ute,XWe),e(Of,zWe),e(Of,cS),e(cS,WWe),e(Of,QWe),e(A,HWe),e(A,Vf),e(Vf,_te),e(_te,UWe),e(Vf,JWe),e(Vf,fS),e(fS,YWe),e(Vf,KWe),e(A,ZWe),e(A,Xf),e(Xf,bte),e(bte,eQe),e(Xf,oQe),e(Xf,mS),e(mS,rQe),e(Xf,tQe),e(A,aQe),e(A,zf),e(zf,vte),e(vte,nQe),e(zf,sQe),e(zf,gS),e(gS,lQe),e(zf,iQe),e(A,dQe),e(A,Wf),e(Wf,Fte),e(Fte,cQe),e(Wf,fQe),e(Wf,hS),e(hS,mQe),e(Wf,gQe),e(A,hQe),e(A,Qf),e(Qf,Tte),e(Tte,pQe),e(Qf,uQe),e(Qf,pS),e(pS,_Qe),e(Qf,bQe),e(A,vQe),e(A,Hf),e(Hf,Mte),e(Mte,FQe),e(Hf,TQe),e(Hf,uS),e(uS,MQe),e(Hf,EQe),e(A,CQe),e(A,Uf),e(Uf,Ete),e(Ete,wQe),e(Uf,AQe),e(Uf,_S),e(_S,LQe),e(Uf,yQe),e(A,xQe),e(A,Jf),e(Jf,Cte),e(Cte,$Qe),e(Jf,kQe),e(Jf,bS),e(bS,SQe),e(Jf,RQe),e(A,PQe),e(A,Yf),e(Yf,wte),e(wte,BQe),e(Yf,IQe),e(Yf,vS),e(vS,NQe),e(Yf,qQe),e(A,jQe),e(A,Kf),e(Kf,Ate),e(Ate,DQe),e(Kf,GQe),e(Kf,FS),e(FS,OQe),e(Kf,VQe),e(A,XQe),e(A,Zf),e(Zf,Lte),e(Lte,zQe),e(Zf,WQe),e(Zf,TS),e(TS,QQe),e(Zf,HQe),e(A,UQe),e(A,em),e(em,yte),e(yte,JQe),e(em,YQe),e(em,MS),e(MS,KQe),e(em,ZQe),e(A,eHe),e(A,om),e(om,xte),e(xte,oHe),e(om,rHe),e(om,ES),e(ES,tHe),e(om,aHe),e(A,nHe),e(A,rm),e(rm,$te),e($te,sHe),e(rm,lHe),e(rm,CS),e(CS,iHe),e(rm,dHe),e(A,cHe),e(A,tm),e(tm,kte),e(kte,fHe),e(tm,mHe),e(tm,wS),e(wS,gHe),e(tm,hHe),e(A,pHe),e(A,am),e(am,Ste),e(Ste,uHe),e(am,_He),e(am,AS),e(AS,bHe),e(am,vHe),e(A,FHe),e(A,nm),e(nm,Rte),e(Rte,THe),e(nm,MHe),e(nm,LS),e(LS,EHe),e(nm,CHe),e(A,wHe),e(A,sm),e(sm,Pte),e(Pte,AHe),e(sm,LHe),e(sm,yS),e(yS,yHe),e(sm,xHe),e(A,$He),e(A,lm),e(lm,Bte),e(Bte,kHe),e(lm,SHe),e(lm,xS),e(xS,RHe),e(lm,PHe),e(A,BHe),e(A,im),e(im,Ite),e(Ite,IHe),e(im,NHe),e(im,$S),e($S,qHe),e(im,jHe),e(A,DHe),e(A,dm),e(dm,Nte),e(Nte,GHe),e(dm,OHe),e(dm,kS),e(kS,VHe),e(dm,XHe),e(A,zHe),e(A,cm),e(cm,qte),e(qte,WHe),e(cm,QHe),e(cm,SS),e(SS,HHe),e(cm,UHe),e(A,JHe),e(A,fm),e(fm,jte),e(jte,YHe),e(fm,KHe),e(fm,RS),e(RS,ZHe),e(fm,eUe),e(A,oUe),e(A,mm),e(mm,Dte),e(Dte,rUe),e(mm,tUe),e(mm,PS),e(PS,aUe),e(mm,nUe),e(A,sUe),e(A,gm),e(gm,Gte),e(Gte,lUe),e(gm,iUe),e(gm,BS),e(BS,dUe),e(gm,cUe),e(A,fUe),e(A,hm),e(hm,Ote),e(Ote,mUe),e(hm,gUe),e(hm,IS),e(IS,hUe),e(hm,pUe),e(A,uUe),e(A,pm),e(pm,Vte),e(Vte,_Ue),e(pm,bUe),e(pm,NS),e(NS,vUe),e(pm,FUe),e(A,TUe),e(A,um),e(um,Xte),e(Xte,MUe),e(um,EUe),e(um,qS),e(qS,CUe),e(um,wUe),e(A,AUe),e(A,_m),e(_m,zte),e(zte,LUe),e(_m,yUe),e(_m,jS),e(jS,xUe),e(_m,$Ue),e(A,kUe),e(A,bm),e(bm,Wte),e(Wte,SUe),e(bm,RUe),e(bm,DS),e(DS,PUe),e(bm,BUe),e(A,IUe),e(A,vm),e(vm,Qte),e(Qte,NUe),e(vm,qUe),e(vm,GS),e(GS,jUe),e(vm,DUe),e(A,GUe),e(A,Fm),e(Fm,Hte),e(Hte,OUe),e(Fm,VUe),e(Fm,OS),e(OS,XUe),e(Fm,zUe),e(A,WUe),e(A,Tm),e(Tm,Ute),e(Ute,QUe),e(Tm,HUe),e(Tm,VS),e(VS,UUe),e(Tm,JUe),e(A,YUe),e(A,Mm),e(Mm,Jte),e(Jte,KUe),e(Mm,ZUe),e(Mm,XS),e(XS,eJe),e(Mm,oJe),e(A,rJe),e(A,Em),e(Em,Yte),e(Yte,tJe),e(Em,aJe),e(Em,zS),e(zS,nJe),e(Em,sJe),e(A,lJe),e(A,Cm),e(Cm,Kte),e(Kte,iJe),e(Cm,dJe),e(Cm,WS),e(WS,cJe),e(Cm,fJe),e(A,mJe),e(A,wm),e(wm,Zte),e(Zte,gJe),e(wm,hJe),e(wm,QS),e(QS,pJe),e(wm,uJe),e(A,_Je),e(A,Am),e(Am,eae),e(eae,bJe),e(Am,vJe),e(Am,HS),e(HS,FJe),e(Am,TJe),e(A,MJe),e(A,Lm),e(Lm,oae),e(oae,EJe),e(Lm,CJe),e(Lm,US),e(US,wJe),e(Lm,AJe),e(A,LJe),e(A,ym),e(ym,rae),e(rae,yJe),e(ym,xJe),e(ym,JS),e(JS,$Je),e(ym,kJe),e(A,SJe),e(A,xm),e(xm,tae),e(tae,RJe),e(xm,PJe),e(xm,YS),e(YS,BJe),e(xm,IJe),e(A,NJe),e(A,$m),e($m,aae),e(aae,qJe),e($m,jJe),e($m,KS),e(KS,DJe),e($m,GJe),e(A,OJe),e(A,km),e(km,nae),e(nae,VJe),e(km,XJe),e(km,ZS),e(ZS,zJe),e(km,WJe),e(A,QJe),e(A,Sm),e(Sm,sae),e(sae,HJe),e(Sm,UJe),e(Sm,eR),e(eR,JJe),e(Sm,YJe),e(A,KJe),e(A,Rm),e(Rm,lae),e(lae,ZJe),e(Rm,eYe),e(Rm,oR),e(oR,oYe),e(Rm,rYe),e(A,tYe),e(A,Pm),e(Pm,iae),e(iae,aYe),e(Pm,nYe),e(Pm,rR),e(rR,sYe),e(Pm,lYe),e(A,iYe),e(A,Bm),e(Bm,dae),e(dae,dYe),e(Bm,cYe),e(Bm,tR),e(tR,fYe),e(Bm,mYe),e(A,gYe),e(A,Im),e(Im,cae),e(cae,hYe),e(Im,pYe),e(Im,aR),e(aR,uYe),e(Im,_Ye),e(A,bYe),e(A,Nm),e(Nm,fae),e(fae,vYe),e(Nm,FYe),e(Nm,nR),e(nR,TYe),e(Nm,MYe),e(A,EYe),e(A,qm),e(qm,mae),e(mae,CYe),e(qm,wYe),e(qm,sR),e(sR,AYe),e(qm,LYe),e(A,yYe),e(A,jm),e(jm,gae),e(gae,xYe),e(jm,$Ye),e(jm,lR),e(lR,kYe),e(jm,SYe),e(A,RYe),e(A,Dm),e(Dm,hae),e(hae,PYe),e(Dm,BYe),e(Dm,iR),e(iR,IYe),e(Dm,NYe),e(A,qYe),e(A,Gm),e(Gm,pae),e(pae,jYe),e(Gm,DYe),e(Gm,dR),e(dR,GYe),e(Gm,OYe),e(A,VYe),e(A,Om),e(Om,uae),e(uae,XYe),e(Om,zYe),e(Om,cR),e(cR,WYe),e(Om,QYe),e(A,HYe),e(A,Vm),e(Vm,_ae),e(_ae,UYe),e(Vm,JYe),e(Vm,fR),e(fR,YYe),e(Vm,KYe),e(A,ZYe),e(A,Xm),e(Xm,bae),e(bae,eKe),e(Xm,oKe),e(Xm,mR),e(mR,rKe),e(Xm,tKe),e(A,aKe),e(A,zm),e(zm,vae),e(vae,nKe),e(zm,sKe),e(zm,gR),e(gR,lKe),e(zm,iKe),e(A,dKe),e(A,Wm),e(Wm,Fae),e(Fae,cKe),e(Wm,fKe),e(Wm,hR),e(hR,mKe),e(Wm,gKe),e(A,hKe),e(A,Qm),e(Qm,Tae),e(Tae,pKe),e(Qm,uKe),e(Qm,pR),e(pR,_Ke),e(Qm,bKe),e(A,vKe),e(A,Hm),e(Hm,Mae),e(Mae,FKe),e(Hm,TKe),e(Hm,uR),e(uR,MKe),e(Hm,EKe),e(A,CKe),e(A,Um),e(Um,Eae),e(Eae,wKe),e(Um,AKe),e(Um,_R),e(_R,LKe),e(Um,yKe),e(A,xKe),e(A,Jm),e(Jm,Cae),e(Cae,$Ke),e(Jm,kKe),e(Jm,bR),e(bR,SKe),e(Jm,RKe),e(A,PKe),e(A,Ym),e(Ym,wae),e(wae,BKe),e(Ym,IKe),e(Ym,vR),e(vR,NKe),e(Ym,qKe),e(A,jKe),e(A,Km),e(Km,Aae),e(Aae,DKe),e(Km,GKe),e(Km,FR),e(FR,OKe),e(Km,VKe),e(A,XKe),e(A,Zm),e(Zm,Lae),e(Lae,zKe),e(Zm,WKe),e(Zm,TR),e(TR,QKe),e(Zm,HKe),e(A,UKe),e(A,eg),e(eg,yae),e(yae,JKe),e(eg,YKe),e(eg,MR),e(MR,KKe),e(eg,ZKe),e(A,eZe),e(A,og),e(og,xae),e(xae,oZe),e(og,rZe),e(og,ER),e(ER,tZe),e(og,aZe),e(A,nZe),e(A,rg),e(rg,$ae),e($ae,sZe),e(rg,lZe),e(rg,CR),e(CR,iZe),e(rg,dZe),e(A,cZe),e(A,tg),e(tg,kae),e(kae,fZe),e(tg,mZe),e(tg,wR),e(wR,gZe),e(tg,hZe),e(A,pZe),e(A,ag),e(ag,Sae),e(Sae,uZe),e(ag,_Ze),e(ag,AR),e(AR,bZe),e(ag,vZe),e(A,FZe),e(A,ng),e(ng,Rae),e(Rae,TZe),e(ng,MZe),e(ng,LR),e(LR,EZe),e(ng,CZe),e(A,wZe),e(A,sg),e(sg,Pae),e(Pae,AZe),e(sg,LZe),e(sg,yR),e(yR,yZe),e(sg,xZe),e(A,$Ze),e(A,lg),e(lg,Bae),e(Bae,kZe),e(lg,SZe),e(lg,xR),e(xR,RZe),e(lg,PZe),e(A,BZe),e(A,ig),e(ig,Iae),e(Iae,IZe),e(ig,NZe),e(ig,$R),e($R,qZe),e(ig,jZe),e(A,DZe),e(A,dg),e(dg,Nae),e(Nae,GZe),e(dg,OZe),e(dg,kR),e(kR,VZe),e(dg,XZe),e(A,zZe),e(A,cg),e(cg,qae),e(qae,WZe),e(cg,QZe),e(cg,SR),e(SR,HZe),e(cg,UZe),e(A,JZe),e(A,fg),e(fg,jae),e(jae,YZe),e(fg,KZe),e(fg,RR),e(RR,ZZe),e(fg,eeo),e(A,oeo),e(A,mg),e(mg,Dae),e(Dae,reo),e(mg,teo),e(mg,PR),e(PR,aeo),e(mg,neo),e(A,seo),e(A,gg),e(gg,Gae),e(Gae,leo),e(gg,ieo),e(gg,BR),e(BR,deo),e(gg,ceo),e(A,feo),e(A,hg),e(hg,Oae),e(Oae,meo),e(hg,geo),e(hg,IR),e(IR,heo),e(hg,peo),e(A,ueo),e(A,pg),e(pg,Vae),e(Vae,_eo),e(pg,beo),e(pg,NR),e(NR,veo),e(pg,Feo),e(A,Teo),e(A,ug),e(ug,Xae),e(Xae,Meo),e(ug,Eeo),e(ug,qR),e(qR,Ceo),e(ug,weo),e(A,Aeo),e(A,_g),e(_g,zae),e(zae,Leo),e(_g,yeo),e(_g,jR),e(jR,xeo),e(_g,$eo),e(A,keo),e(A,bg),e(bg,Wae),e(Wae,Seo),e(bg,Reo),e(bg,DR),e(DR,Peo),e(bg,Beo),e(A,Ieo),e(A,vg),e(vg,Qae),e(Qae,Neo),e(vg,qeo),e(vg,GR),e(GR,jeo),e(vg,Deo),e(A,Geo),e(A,Fg),e(Fg,Hae),e(Hae,Oeo),e(Fg,Veo),e(Fg,OR),e(OR,Xeo),e(Fg,zeo),e(A,Weo),e(A,Tg),e(Tg,Uae),e(Uae,Qeo),e(Tg,Heo),e(Tg,VR),e(VR,Ueo),e(Tg,Jeo),e(A,Yeo),e(A,Mg),e(Mg,Jae),e(Jae,Keo),e(Mg,Zeo),e(Mg,XR),e(XR,eoo),e(Mg,ooo),e(A,roo),e(A,Eg),e(Eg,Yae),e(Yae,too),e(Eg,aoo),e(Eg,zR),e(zR,noo),e(Eg,soo),e(A,loo),e(A,Cg),e(Cg,Kae),e(Kae,ioo),e(Cg,doo),e(Cg,WR),e(WR,coo),e(Cg,foo),e(A,moo),e(A,wg),e(wg,Zae),e(Zae,goo),e(wg,hoo),e(wg,QR),e(QR,poo),e(wg,uoo),e(A,_oo),e(A,Ag),e(Ag,ene),e(ene,boo),e(Ag,voo),e(Ag,HR),e(HR,Foo),e(Ag,Too),e(A,Moo),e(A,Lg),e(Lg,one),e(one,Eoo),e(Lg,Coo),e(Lg,UR),e(UR,woo),e(Lg,Aoo),e(A,Loo),e(A,yg),e(yg,rne),e(rne,yoo),e(yg,xoo),e(yg,JR),e(JR,$oo),e(yg,koo),e(A,Soo),e(A,xg),e(xg,tne),e(tne,Roo),e(xg,Poo),e(xg,YR),e(YR,Boo),e(xg,Ioo),e(A,Noo),e(A,$g),e($g,ane),e(ane,qoo),e($g,joo),e($g,KR),e(KR,Doo),e($g,Goo),e(A,Ooo),e(A,kg),e(kg,nne),e(nne,Voo),e(kg,Xoo),e(kg,ZR),e(ZR,zoo),e(kg,Woo),e(A,Qoo),e(A,Sg),e(Sg,sne),e(sne,Hoo),e(Sg,Uoo),e(Sg,eP),e(eP,Joo),e(Sg,Yoo),e(A,Koo),e(A,Rg),e(Rg,lne),e(lne,Zoo),e(Rg,ero),e(Rg,oP),e(oP,oro),e(Rg,rro),e(A,tro),e(A,Pg),e(Pg,ine),e(ine,aro),e(Pg,nro),e(Pg,rP),e(rP,sro),e(Pg,lro),e(A,iro),e(A,Bg),e(Bg,dne),e(dne,dro),e(Bg,cro),e(Bg,tP),e(tP,fro),e(Bg,mro),e(A,gro),e(A,Ig),e(Ig,cne),e(cne,hro),e(Ig,pro),e(Ig,aP),e(aP,uro),e(Ig,_ro),e(A,bro),e(A,Ng),e(Ng,fne),e(fne,vro),e(Ng,Fro),e(Ng,nP),e(nP,Tro),e(Ng,Mro),e(A,Ero),e(A,qg),e(qg,mne),e(mne,Cro),e(qg,wro),e(qg,sP),e(sP,Aro),e(qg,Lro),e(A,yro),e(A,jg),e(jg,gne),e(gne,xro),e(jg,$ro),e(jg,lP),e(lP,kro),e(jg,Sro),e(wr,Rro),M(Dg,wr,null),e(wo,Pro),e(wo,Gg),M($L,Gg,null),e(Gg,Bro),e(Gg,hne),e(hne,Iro),b(f,TGe,_),b(f,$i,_),e($i,Og),e(Og,pne),M(kL,pne,null),e($i,Nro),e($i,une),e(une,qro),b(f,MGe,_),b(f,Ao,_),M(SL,Ao,null),e(Ao,jro),e(Ao,RL),e(RL,Dro),e(RL,iP),e(iP,Gro),e(RL,Oro),e(Ao,Vro),e(Ao,PL),e(PL,Xro),e(PL,_ne),e(_ne,zro),e(PL,Wro),e(Ao,Qro),e(Ao,Ar),M(BL,Ar,null),e(Ar,Hro),e(Ar,bne),e(bne,Uro),e(Ar,Jro),e(Ar,$a),e($a,Yro),e($a,vne),e(vne,Kro),e($a,Zro),e($a,Fne),e(Fne,eto),e($a,oto),e($a,Tne),e(Tne,rto),e($a,tto),e(Ar,ato),e(Ar,k),e(k,Nn),e(Nn,Mne),e(Mne,nto),e(Nn,sto),e(Nn,dP),e(dP,lto),e(Nn,ito),e(Nn,cP),e(cP,dto),e(Nn,cto),e(k,fto),e(k,qn),e(qn,Ene),e(Ene,mto),e(qn,gto),e(qn,fP),e(fP,hto),e(qn,pto),e(qn,mP),e(mP,uto),e(qn,_to),e(k,bto),e(k,jn),e(jn,Cne),e(Cne,vto),e(jn,Fto),e(jn,gP),e(gP,Tto),e(jn,Mto),e(jn,hP),e(hP,Eto),e(jn,Cto),e(k,wto),e(k,Vg),e(Vg,wne),e(wne,Ato),e(Vg,Lto),e(Vg,pP),e(pP,yto),e(Vg,xto),e(k,$to),e(k,Dn),e(Dn,Ane),e(Ane,kto),e(Dn,Sto),e(Dn,uP),e(uP,Rto),e(Dn,Pto),e(Dn,_P),e(_P,Bto),e(Dn,Ito),e(k,Nto),e(k,Xg),e(Xg,Lne),e(Lne,qto),e(Xg,jto),e(Xg,bP),e(bP,Dto),e(Xg,Gto),e(k,Oto),e(k,zg),e(zg,yne),e(yne,Vto),e(zg,Xto),e(zg,vP),e(vP,zto),e(zg,Wto),e(k,Qto),e(k,Wg),e(Wg,xne),e(xne,Hto),e(Wg,Uto),e(Wg,FP),e(FP,Jto),e(Wg,Yto),e(k,Kto),e(k,Gn),e(Gn,$ne),e($ne,Zto),e(Gn,eao),e(Gn,TP),e(TP,oao),e(Gn,rao),e(Gn,MP),e(MP,tao),e(Gn,aao),e(k,nao),e(k,On),e(On,kne),e(kne,sao),e(On,lao),e(On,EP),e(EP,iao),e(On,dao),e(On,CP),e(CP,cao),e(On,fao),e(k,mao),e(k,Vn),e(Vn,Sne),e(Sne,gao),e(Vn,hao),e(Vn,wP),e(wP,pao),e(Vn,uao),e(Vn,AP),e(AP,_ao),e(Vn,bao),e(k,vao),e(k,Qg),e(Qg,Rne),e(Rne,Fao),e(Qg,Tao),e(Qg,LP),e(LP,Mao),e(Qg,Eao),e(k,Cao),e(k,Hg),e(Hg,Pne),e(Pne,wao),e(Hg,Aao),e(Hg,yP),e(yP,Lao),e(Hg,yao),e(k,xao),e(k,Ug),e(Ug,Bne),e(Bne,$ao),e(Ug,kao),e(Ug,xP),e(xP,Sao),e(Ug,Rao),e(k,Pao),e(k,Xn),e(Xn,Ine),e(Ine,Bao),e(Xn,Iao),e(Xn,$P),e($P,Nao),e(Xn,qao),e(Xn,kP),e(kP,jao),e(Xn,Dao),e(k,Gao),e(k,Jg),e(Jg,Nne),e(Nne,Oao),e(Jg,Vao),e(Jg,SP),e(SP,Xao),e(Jg,zao),e(k,Wao),e(k,zn),e(zn,qne),e(qne,Qao),e(zn,Hao),e(zn,RP),e(RP,Uao),e(zn,Jao),e(zn,PP),e(PP,Yao),e(zn,Kao),e(k,Zao),e(k,Wn),e(Wn,jne),e(jne,eno),e(Wn,ono),e(Wn,BP),e(BP,rno),e(Wn,tno),e(Wn,IP),e(IP,ano),e(Wn,nno),e(k,sno),e(k,Qn),e(Qn,Dne),e(Dne,lno),e(Qn,ino),e(Qn,NP),e(NP,dno),e(Qn,cno),e(Qn,qP),e(qP,fno),e(Qn,mno),e(k,gno),e(k,Yg),e(Yg,Gne),e(Gne,hno),e(Yg,pno),e(Yg,jP),e(jP,uno),e(Yg,_no),e(k,bno),e(k,Hn),e(Hn,One),e(One,vno),e(Hn,Fno),e(Hn,DP),e(DP,Tno),e(Hn,Mno),e(Hn,GP),e(GP,Eno),e(Hn,Cno),e(k,wno),e(k,Un),e(Un,Vne),e(Vne,Ano),e(Un,Lno),e(Un,OP),e(OP,yno),e(Un,xno),e(Un,VP),e(VP,$no),e(Un,kno),e(k,Sno),e(k,Jn),e(Jn,Xne),e(Xne,Rno),e(Jn,Pno),e(Jn,XP),e(XP,Bno),e(Jn,Ino),e(Jn,zP),e(zP,Nno),e(Jn,qno),e(k,jno),e(k,Yn),e(Yn,zne),e(zne,Dno),e(Yn,Gno),e(Yn,WP),e(WP,Ono),e(Yn,Vno),e(Yn,QP),e(QP,Xno),e(Yn,zno),e(k,Wno),e(k,Kn),e(Kn,Wne),e(Wne,Qno),e(Kn,Hno),e(Kn,HP),e(HP,Uno),e(Kn,Jno),e(Kn,UP),e(UP,Yno),e(Kn,Kno),e(k,Zno),e(k,Zn),e(Zn,Qne),e(Qne,eso),e(Zn,oso),e(Zn,JP),e(JP,rso),e(Zn,tso),e(Zn,YP),e(YP,aso),e(Zn,nso),e(k,sso),e(k,Kg),e(Kg,Hne),e(Hne,lso),e(Kg,iso),e(Kg,KP),e(KP,dso),e(Kg,cso),e(k,fso),e(k,es),e(es,Une),e(Une,mso),e(es,gso),e(es,ZP),e(ZP,hso),e(es,pso),e(es,eB),e(eB,uso),e(es,_so),e(k,bso),e(k,Zg),e(Zg,Jne),e(Jne,vso),e(Zg,Fso),e(Zg,oB),e(oB,Tso),e(Zg,Mso),e(k,Eso),e(k,os),e(os,Yne),e(Yne,Cso),e(os,wso),e(os,rB),e(rB,Aso),e(os,Lso),e(os,tB),e(tB,yso),e(os,xso),e(k,$so),e(k,rs),e(rs,Kne),e(Kne,kso),e(rs,Sso),e(rs,aB),e(aB,Rso),e(rs,Pso),e(rs,nB),e(nB,Bso),e(rs,Iso),e(k,Nso),e(k,ts),e(ts,Zne),e(Zne,qso),e(ts,jso),e(ts,sB),e(sB,Dso),e(ts,Gso),e(ts,lB),e(lB,Oso),e(ts,Vso),e(k,Xso),e(k,eh),e(eh,ese),e(ese,zso),e(eh,Wso),e(eh,iB),e(iB,Qso),e(eh,Hso),e(k,Uso),e(k,as),e(as,ose),e(ose,Jso),e(as,Yso),e(as,dB),e(dB,Kso),e(as,Zso),e(as,cB),e(cB,elo),e(as,olo),e(k,rlo),e(k,ns),e(ns,rse),e(rse,tlo),e(ns,alo),e(ns,fB),e(fB,nlo),e(ns,slo),e(ns,mB),e(mB,llo),e(ns,ilo),e(k,dlo),e(k,oh),e(oh,tse),e(tse,clo),e(oh,flo),e(oh,gB),e(gB,mlo),e(oh,glo),e(k,hlo),e(k,ss),e(ss,ase),e(ase,plo),e(ss,ulo),e(ss,hB),e(hB,_lo),e(ss,blo),e(ss,pB),e(pB,vlo),e(ss,Flo),e(k,Tlo),e(k,ls),e(ls,nse),e(nse,Mlo),e(ls,Elo),e(ls,uB),e(uB,Clo),e(ls,wlo),e(ls,_B),e(_B,Alo),e(ls,Llo),e(k,ylo),e(k,is),e(is,sse),e(sse,xlo),e(is,$lo),e(is,bB),e(bB,klo),e(is,Slo),e(is,vB),e(vB,Rlo),e(is,Plo),e(k,Blo),e(k,ds),e(ds,lse),e(lse,Ilo),e(ds,Nlo),e(ds,FB),e(FB,qlo),e(ds,jlo),e(ds,TB),e(TB,Dlo),e(ds,Glo),e(k,Olo),e(k,cs),e(cs,ise),e(ise,Vlo),e(cs,Xlo),e(cs,MB),e(MB,zlo),e(cs,Wlo),e(cs,EB),e(EB,Qlo),e(cs,Hlo),e(k,Ulo),e(k,fs),e(fs,dse),e(dse,Jlo),e(fs,Ylo),e(fs,CB),e(CB,Klo),e(fs,Zlo),e(fs,wB),e(wB,eio),e(fs,oio),e(k,rio),e(k,ms),e(ms,cse),e(cse,tio),e(ms,aio),e(ms,AB),e(AB,nio),e(ms,sio),e(ms,LB),e(LB,lio),e(ms,iio),e(k,dio),e(k,gs),e(gs,fse),e(fse,cio),e(gs,fio),e(gs,yB),e(yB,mio),e(gs,gio),e(gs,xB),e(xB,hio),e(gs,pio),e(k,uio),e(k,rh),e(rh,mse),e(mse,_io),e(rh,bio),e(rh,$B),e($B,vio),e(rh,Fio),e(k,Tio),e(k,hs),e(hs,gse),e(gse,Mio),e(hs,Eio),e(hs,kB),e(kB,Cio),e(hs,wio),e(hs,SB),e(SB,Aio),e(hs,Lio),e(k,yio),e(k,th),e(th,hse),e(hse,xio),e(th,$io),e(th,RB),e(RB,kio),e(th,Sio),e(k,Rio),e(k,ah),e(ah,pse),e(pse,Pio),e(ah,Bio),e(ah,PB),e(PB,Iio),e(ah,Nio),e(k,qio),e(k,ps),e(ps,use),e(use,jio),e(ps,Dio),e(ps,BB),e(BB,Gio),e(ps,Oio),e(ps,IB),e(IB,Vio),e(ps,Xio),e(k,zio),e(k,us),e(us,_se),e(_se,Wio),e(us,Qio),e(us,NB),e(NB,Hio),e(us,Uio),e(us,qB),e(qB,Jio),e(us,Yio),e(k,Kio),e(k,_s),e(_s,bse),e(bse,Zio),e(_s,edo),e(_s,jB),e(jB,odo),e(_s,rdo),e(_s,DB),e(DB,tdo),e(_s,ado),e(k,ndo),e(k,nh),e(nh,vse),e(vse,sdo),e(nh,ldo),e(nh,GB),e(GB,ido),e(nh,ddo),e(k,cdo),e(k,bs),e(bs,Fse),e(Fse,fdo),e(bs,mdo),e(bs,OB),e(OB,gdo),e(bs,hdo),e(bs,VB),e(VB,pdo),e(bs,udo),e(k,_do),e(k,vs),e(vs,Tse),e(Tse,bdo),e(vs,vdo),e(vs,XB),e(XB,Fdo),e(vs,Tdo),e(vs,zB),e(zB,Mdo),e(vs,Edo),e(k,Cdo),e(k,Fs),e(Fs,Mse),e(Mse,wdo),e(Fs,Ado),e(Fs,WB),e(WB,Ldo),e(Fs,ydo),e(Fs,QB),e(QB,xdo),e(Fs,$do),e(k,kdo),e(k,Ts),e(Ts,Ese),e(Ese,Sdo),e(Ts,Rdo),e(Ts,HB),e(HB,Pdo),e(Ts,Bdo),e(Ts,UB),e(UB,Ido),e(Ts,Ndo),e(k,qdo),e(k,Ms),e(Ms,Cse),e(Cse,jdo),e(Ms,Ddo),e(Ms,JB),e(JB,Gdo),e(Ms,Odo),e(Ms,YB),e(YB,Vdo),e(Ms,Xdo),e(k,zdo),e(k,sh),e(sh,wse),e(wse,Wdo),e(sh,Qdo),e(sh,KB),e(KB,Hdo),e(sh,Udo),e(k,Jdo),e(k,Es),e(Es,Ase),e(Ase,Ydo),e(Es,Kdo),e(Es,ZB),e(ZB,Zdo),e(Es,eco),e(Es,eI),e(eI,oco),e(Es,rco),e(k,tco),e(k,lh),e(lh,Lse),e(Lse,aco),e(lh,nco),e(lh,oI),e(oI,sco),e(lh,lco),e(k,ico),e(k,ih),e(ih,yse),e(yse,dco),e(ih,cco),e(ih,rI),e(rI,fco),e(ih,mco),e(k,gco),e(k,dh),e(dh,xse),e(xse,hco),e(dh,pco),e(dh,tI),e(tI,uco),e(dh,_co),e(k,bco),e(k,ch),e(ch,$se),e($se,vco),e(ch,Fco),e(ch,aI),e(aI,Tco),e(ch,Mco),e(k,Eco),e(k,Cs),e(Cs,kse),e(kse,Cco),e(Cs,wco),e(Cs,nI),e(nI,Aco),e(Cs,Lco),e(Cs,sI),e(sI,yco),e(Cs,xco),e(k,$co),e(k,fh),e(fh,Sse),e(Sse,kco),e(fh,Sco),e(fh,lI),e(lI,Rco),e(fh,Pco),e(k,Bco),e(k,ws),e(ws,Rse),e(Rse,Ico),e(ws,Nco),e(ws,iI),e(iI,qco),e(ws,jco),e(ws,dI),e(dI,Dco),e(ws,Gco),e(k,Oco),e(k,As),e(As,Pse),e(Pse,Vco),e(As,Xco),e(As,cI),e(cI,zco),e(As,Wco),e(As,fI),e(fI,Qco),e(As,Hco),e(k,Uco),e(k,Ls),e(Ls,Bse),e(Bse,Jco),e(Ls,Yco),e(Ls,mI),e(mI,Kco),e(Ls,Zco),e(Ls,gI),e(gI,efo),e(Ls,ofo),e(k,rfo),e(k,ys),e(ys,Ise),e(Ise,tfo),e(ys,afo),e(ys,hI),e(hI,nfo),e(ys,sfo),e(ys,pI),e(pI,lfo),e(ys,ifo),e(k,dfo),e(k,xs),e(xs,Nse),e(Nse,cfo),e(xs,ffo),e(xs,uI),e(uI,mfo),e(xs,gfo),e(xs,_I),e(_I,hfo),e(xs,pfo),e(k,ufo),e(k,$s),e($s,qse),e(qse,_fo),e($s,bfo),e($s,bI),e(bI,vfo),e($s,Ffo),e($s,vI),e(vI,Tfo),e($s,Mfo),e(k,Efo),e(k,mh),e(mh,jse),e(jse,Cfo),e(mh,wfo),e(mh,FI),e(FI,Afo),e(mh,Lfo),e(k,yfo),e(k,gh),e(gh,Dse),e(Dse,xfo),e(gh,$fo),e(gh,TI),e(TI,kfo),e(gh,Sfo),e(k,Rfo),e(k,ks),e(ks,Gse),e(Gse,Pfo),e(ks,Bfo),e(ks,MI),e(MI,Ifo),e(ks,Nfo),e(ks,EI),e(EI,qfo),e(ks,jfo),e(k,Dfo),e(k,Ss),e(Ss,Ose),e(Ose,Gfo),e(Ss,Ofo),e(Ss,CI),e(CI,Vfo),e(Ss,Xfo),e(Ss,wI),e(wI,zfo),e(Ss,Wfo),e(k,Qfo),e(k,Rs),e(Rs,Vse),e(Vse,Hfo),e(Rs,Ufo),e(Rs,AI),e(AI,Jfo),e(Rs,Yfo),e(Rs,LI),e(LI,Kfo),e(Rs,Zfo),e(k,emo),e(k,hh),e(hh,Xse),e(Xse,omo),e(hh,rmo),e(hh,yI),e(yI,tmo),e(hh,amo),e(k,nmo),e(k,ph),e(ph,zse),e(zse,smo),e(ph,lmo),e(ph,xI),e(xI,imo),e(ph,dmo),e(k,cmo),e(k,uh),e(uh,Wse),e(Wse,fmo),e(uh,mmo),e(uh,$I),e($I,gmo),e(uh,hmo),e(k,pmo),e(k,Ps),e(Ps,Qse),e(Qse,umo),e(Ps,_mo),e(Ps,kI),e(kI,bmo),e(Ps,vmo),e(Ps,SI),e(SI,Fmo),e(Ps,Tmo),e(k,Mmo),e(k,Bs),e(Bs,Hse),e(Hse,Emo),e(Bs,Cmo),e(Bs,RI),e(RI,wmo),e(Bs,Amo),e(Bs,PI),e(PI,Lmo),e(Bs,ymo),e(k,xmo),e(k,_h),e(_h,Use),e(Use,$mo),e(_h,kmo),e(_h,BI),e(BI,Smo),e(_h,Rmo),e(k,Pmo),e(k,bh),e(bh,Jse),e(Jse,Bmo),e(bh,Imo),e(bh,II),e(II,Nmo),e(bh,qmo),e(k,jmo),e(k,vh),e(vh,Yse),e(Yse,Dmo),e(vh,Gmo),e(vh,NI),e(NI,Omo),e(vh,Vmo),e(k,Xmo),e(k,Is),e(Is,Kse),e(Kse,zmo),e(Is,Wmo),e(Is,qI),e(qI,Qmo),e(Is,Hmo),e(Is,jI),e(jI,Umo),e(Is,Jmo),e(k,Ymo),e(k,Fh),e(Fh,Zse),e(Zse,Kmo),e(Fh,Zmo),e(Fh,DI),e(DI,ego),e(Fh,ogo),e(k,rgo),e(k,Th),e(Th,ele),e(ele,tgo),e(Th,ago),e(Th,GI),e(GI,ngo),e(Th,sgo),e(k,lgo),e(k,Ns),e(Ns,ole),e(ole,igo),e(Ns,dgo),e(Ns,OI),e(OI,cgo),e(Ns,fgo),e(Ns,VI),e(VI,mgo),e(Ns,ggo),e(k,hgo),e(k,qs),e(qs,rle),e(rle,pgo),e(qs,ugo),e(qs,XI),e(XI,_go),e(qs,bgo),e(qs,zI),e(zI,vgo),e(qs,Fgo),e(k,Tgo),e(k,js),e(js,tle),e(tle,Mgo),e(js,Ego),e(js,WI),e(WI,Cgo),e(js,wgo),e(js,QI),e(QI,Ago),e(js,Lgo),e(k,ygo),e(k,Ds),e(Ds,ale),e(ale,xgo),e(Ds,$go),e(Ds,HI),e(HI,kgo),e(Ds,Sgo),e(Ds,UI),e(UI,Rgo),e(Ds,Pgo),e(Ar,Bgo),M(Mh,Ar,null),e(Ao,Igo),e(Ao,Eh),M(IL,Eh,null),e(Eh,Ngo),e(Eh,nle),e(nle,qgo),b(f,EGe,_),b(f,ki,_),e(ki,Ch),e(Ch,sle),M(NL,sle,null),e(ki,jgo),e(ki,lle),e(lle,Dgo),b(f,CGe,_),b(f,Lo,_),M(qL,Lo,null),e(Lo,Ggo),e(Lo,jL),e(jL,Ogo),e(jL,JI),e(JI,Vgo),e(jL,Xgo),e(Lo,zgo),e(Lo,DL),e(DL,Wgo),e(DL,ile),e(ile,Qgo),e(DL,Hgo),e(Lo,Ugo),e(Lo,He),M(GL,He,null),e(He,Jgo),e(He,dle),e(dle,Ygo),e(He,Kgo),e(He,ka),e(ka,Zgo),e(ka,cle),e(cle,eho),e(ka,oho),e(ka,fle),e(fle,rho),e(ka,tho),e(ka,mle),e(mle,aho),e(ka,nho),e(He,sho),e(He,Y),e(Y,wh),e(wh,gle),e(gle,lho),e(wh,iho),e(wh,YI),e(YI,dho),e(wh,cho),e(Y,fho),e(Y,Ah),e(Ah,hle),e(hle,mho),e(Ah,gho),e(Ah,KI),e(KI,hho),e(Ah,pho),e(Y,uho),e(Y,Lh),e(Lh,ple),e(ple,_ho),e(Lh,bho),e(Lh,ZI),e(ZI,vho),e(Lh,Fho),e(Y,Tho),e(Y,yh),e(yh,ule),e(ule,Mho),e(yh,Eho),e(yh,eN),e(eN,Cho),e(yh,who),e(Y,Aho),e(Y,xh),e(xh,_le),e(_le,Lho),e(xh,yho),e(xh,oN),e(oN,xho),e(xh,$ho),e(Y,kho),e(Y,$h),e($h,ble),e(ble,Sho),e($h,Rho),e($h,rN),e(rN,Pho),e($h,Bho),e(Y,Iho),e(Y,kh),e(kh,vle),e(vle,Nho),e(kh,qho),e(kh,tN),e(tN,jho),e(kh,Dho),e(Y,Gho),e(Y,Sh),e(Sh,Fle),e(Fle,Oho),e(Sh,Vho),e(Sh,aN),e(aN,Xho),e(Sh,zho),e(Y,Who),e(Y,Rh),e(Rh,Tle),e(Tle,Qho),e(Rh,Hho),e(Rh,nN),e(nN,Uho),e(Rh,Jho),e(Y,Yho),e(Y,Ph),e(Ph,Mle),e(Mle,Kho),e(Ph,Zho),e(Ph,sN),e(sN,epo),e(Ph,opo),e(Y,rpo),e(Y,Bh),e(Bh,Ele),e(Ele,tpo),e(Bh,apo),e(Bh,lN),e(lN,npo),e(Bh,spo),e(Y,lpo),e(Y,Ih),e(Ih,Cle),e(Cle,ipo),e(Ih,dpo),e(Ih,iN),e(iN,cpo),e(Ih,fpo),e(Y,mpo),e(Y,Nh),e(Nh,wle),e(wle,gpo),e(Nh,hpo),e(Nh,dN),e(dN,ppo),e(Nh,upo),e(Y,_po),e(Y,qh),e(qh,Ale),e(Ale,bpo),e(qh,vpo),e(qh,cN),e(cN,Fpo),e(qh,Tpo),e(Y,Mpo),e(Y,jh),e(jh,Lle),e(Lle,Epo),e(jh,Cpo),e(jh,fN),e(fN,wpo),e(jh,Apo),e(Y,Lpo),e(Y,Dh),e(Dh,yle),e(yle,ypo),e(Dh,xpo),e(Dh,mN),e(mN,$po),e(Dh,kpo),e(Y,Spo),e(Y,Gh),e(Gh,xle),e(xle,Rpo),e(Gh,Ppo),e(Gh,gN),e(gN,Bpo),e(Gh,Ipo),e(Y,Npo),e(Y,Oh),e(Oh,$le),e($le,qpo),e(Oh,jpo),e(Oh,hN),e(hN,Dpo),e(Oh,Gpo),e(Y,Opo),e(Y,Vh),e(Vh,kle),e(kle,Vpo),e(Vh,Xpo),e(Vh,pN),e(pN,zpo),e(Vh,Wpo),e(Y,Qpo),e(Y,Xh),e(Xh,Sle),e(Sle,Hpo),e(Xh,Upo),e(Xh,uN),e(uN,Jpo),e(Xh,Ypo),e(Y,Kpo),e(Y,zh),e(zh,Rle),e(Rle,Zpo),e(zh,euo),e(zh,_N),e(_N,ouo),e(zh,ruo),e(Y,tuo),e(Y,Wh),e(Wh,Ple),e(Ple,auo),e(Wh,nuo),e(Wh,bN),e(bN,suo),e(Wh,luo),e(Y,iuo),e(Y,Qh),e(Qh,Ble),e(Ble,duo),e(Qh,cuo),e(Qh,vN),e(vN,fuo),e(Qh,muo),e(Y,guo),e(Y,Hh),e(Hh,Ile),e(Ile,huo),e(Hh,puo),e(Hh,FN),e(FN,uuo),e(Hh,_uo),e(Y,buo),e(Y,Uh),e(Uh,Nle),e(Nle,vuo),e(Uh,Fuo),e(Uh,TN),e(TN,Tuo),e(Uh,Muo),e(Y,Euo),e(Y,Jh),e(Jh,qle),e(qle,Cuo),e(Jh,wuo),e(Jh,MN),e(MN,Auo),e(Jh,Luo),e(Y,yuo),e(Y,Yh),e(Yh,jle),e(jle,xuo),e(Yh,$uo),e(Yh,EN),e(EN,kuo),e(Yh,Suo),e(Y,Ruo),e(Y,Kh),e(Kh,Dle),e(Dle,Puo),e(Kh,Buo),e(Kh,CN),e(CN,Iuo),e(Kh,Nuo),e(Y,quo),e(Y,Zh),e(Zh,Gle),e(Gle,juo),e(Zh,Duo),e(Zh,wN),e(wN,Guo),e(Zh,Ouo),e(Y,Vuo),e(Y,ep),e(ep,Ole),e(Ole,Xuo),e(ep,zuo),e(ep,AN),e(AN,Wuo),e(ep,Quo),e(Y,Huo),e(Y,op),e(op,Vle),e(Vle,Uuo),e(op,Juo),e(op,LN),e(LN,Yuo),e(op,Kuo),e(Y,Zuo),e(Y,rp),e(rp,Xle),e(Xle,e_o),e(rp,o_o),e(rp,yN),e(yN,r_o),e(rp,t_o),e(Y,a_o),e(Y,tp),e(tp,zle),e(zle,n_o),e(tp,s_o),e(tp,xN),e(xN,l_o),e(tp,i_o),e(He,d_o),M(ap,He,null),e(He,c_o),M(np,He,null),e(Lo,f_o),e(Lo,sp),M(OL,sp,null),e(sp,m_o),e(sp,Wle),e(Wle,g_o),b(f,wGe,_),b(f,Si,_),e(Si,lp),e(lp,Qle),M(VL,Qle,null),e(Si,h_o),e(Si,Hle),e(Hle,p_o),b(f,AGe,_),b(f,yo,_),M(XL,yo,null),e(yo,u_o),e(yo,zL),e(zL,__o),e(zL,$N),e($N,b_o),e(zL,v_o),e(yo,F_o),e(yo,WL),e(WL,T_o),e(WL,Ule),e(Ule,M_o),e(WL,E_o),e(yo,C_o),e(yo,Ue),M(QL,Ue,null),e(Ue,w_o),e(Ue,Jle),e(Jle,A_o),e(Ue,L_o),e(Ue,Ri),e(Ri,y_o),e(Ri,Yle),e(Yle,x_o),e(Ri,$_o),e(Ri,Kle),e(Kle,k_o),e(Ri,S_o),e(Ue,R_o),e(Ue,he),e(he,ip),e(ip,Zle),e(Zle,P_o),e(ip,B_o),e(ip,kN),e(kN,I_o),e(ip,N_o),e(he,q_o),e(he,dp),e(dp,eie),e(eie,j_o),e(dp,D_o),e(dp,oie),e(oie,G_o),e(dp,O_o),e(he,V_o),e(he,cp),e(cp,rie),e(rie,X_o),e(cp,z_o),e(cp,SN),e(SN,W_o),e(cp,Q_o),e(he,H_o),e(he,fp),e(fp,tie),e(tie,U_o),e(fp,J_o),e(fp,RN),e(RN,Y_o),e(fp,K_o),e(he,Z_o),e(he,mp),e(mp,aie),e(aie,e7o),e(mp,o7o),e(mp,PN),e(PN,r7o),e(mp,t7o),e(he,a7o),e(he,gp),e(gp,nie),e(nie,n7o),e(gp,s7o),e(gp,BN),e(BN,l7o),e(gp,i7o),e(he,d7o),e(he,hp),e(hp,sie),e(sie,c7o),e(hp,f7o),e(hp,IN),e(IN,m7o),e(hp,g7o),e(he,h7o),e(he,pp),e(pp,lie),e(lie,p7o),e(pp,u7o),e(pp,NN),e(NN,_7o),e(pp,b7o),e(he,v7o),e(he,up),e(up,iie),e(iie,F7o),e(up,T7o),e(up,qN),e(qN,M7o),e(up,E7o),e(he,C7o),e(he,_p),e(_p,die),e(die,w7o),e(_p,A7o),e(_p,jN),e(jN,L7o),e(_p,y7o),e(he,x7o),e(he,bp),e(bp,cie),e(cie,$7o),e(bp,k7o),e(bp,DN),e(DN,S7o),e(bp,R7o),e(he,P7o),e(he,vp),e(vp,fie),e(fie,B7o),e(vp,I7o),e(vp,GN),e(GN,N7o),e(vp,q7o),e(he,j7o),e(he,Fp),e(Fp,mie),e(mie,D7o),e(Fp,G7o),e(Fp,ON),e(ON,O7o),e(Fp,V7o),e(he,X7o),e(he,Tp),e(Tp,gie),e(gie,z7o),e(Tp,W7o),e(Tp,VN),e(VN,Q7o),e(Tp,H7o),e(he,U7o),e(he,Mp),e(Mp,hie),e(hie,J7o),e(Mp,Y7o),e(Mp,XN),e(XN,K7o),e(Mp,Z7o),e(he,e2o),e(he,Ep),e(Ep,pie),e(pie,o2o),e(Ep,r2o),e(Ep,zN),e(zN,t2o),e(Ep,a2o),e(he,n2o),e(he,Cp),e(Cp,uie),e(uie,s2o),e(Cp,l2o),e(Cp,WN),e(WN,i2o),e(Cp,d2o),e(Ue,c2o),M(wp,Ue,null),e(Ue,f2o),M(Ap,Ue,null),e(yo,m2o),e(yo,Lp),M(HL,Lp,null),e(Lp,g2o),e(Lp,_ie),e(_ie,h2o),b(f,LGe,_),b(f,Pi,_),e(Pi,yp),e(yp,bie),M(UL,bie,null),e(Pi,p2o),e(Pi,vie),e(vie,u2o),b(f,yGe,_),b(f,xo,_),M(JL,xo,null),e(xo,_2o),e(xo,Bi),e(Bi,b2o),e(Bi,QN),e(QN,v2o),e(Bi,F2o),e(Bi,HN),e(HN,T2o),e(Bi,M2o),e(xo,E2o),e(xo,YL),e(YL,C2o),e(YL,Fie),e(Fie,w2o),e(YL,A2o),e(xo,L2o),e(xo,nt),M(KL,nt,null),e(nt,y2o),e(nt,Tie),e(Tie,x2o),e(nt,$2o),e(nt,Ii),e(Ii,k2o),e(Ii,Mie),e(Mie,S2o),e(Ii,R2o),e(Ii,UN),e(UN,P2o),e(Ii,B2o),e(nt,I2o),M(xp,nt,null),e(xo,N2o),e(xo,Je),M(ZL,Je,null),e(Je,q2o),e(Je,Eie),e(Eie,j2o),e(Je,D2o),e(Je,Sa),e(Sa,G2o),e(Sa,Cie),e(Cie,O2o),e(Sa,V2o),e(Sa,wie),e(wie,X2o),e(Sa,z2o),e(Sa,Aie),e(Aie,W2o),e(Sa,Q2o),e(Je,H2o),e(Je,y),e(y,$p),e($p,Lie),e(Lie,U2o),e($p,J2o),e($p,JN),e(JN,Y2o),e($p,K2o),e(y,Z2o),e(y,kp),e(kp,yie),e(yie,e1o),e(kp,o1o),e(kp,YN),e(YN,r1o),e(kp,t1o),e(y,a1o),e(y,Sp),e(Sp,xie),e(xie,n1o),e(Sp,s1o),e(Sp,KN),e(KN,l1o),e(Sp,i1o),e(y,d1o),e(y,Rp),e(Rp,$ie),e($ie,c1o),e(Rp,f1o),e(Rp,ZN),e(ZN,m1o),e(Rp,g1o),e(y,h1o),e(y,Pp),e(Pp,kie),e(kie,p1o),e(Pp,u1o),e(Pp,eq),e(eq,_1o),e(Pp,b1o),e(y,v1o),e(y,Bp),e(Bp,Sie),e(Sie,F1o),e(Bp,T1o),e(Bp,oq),e(oq,M1o),e(Bp,E1o),e(y,C1o),e(y,Ip),e(Ip,Rie),e(Rie,w1o),e(Ip,A1o),e(Ip,rq),e(rq,L1o),e(Ip,y1o),e(y,x1o),e(y,Np),e(Np,Pie),e(Pie,$1o),e(Np,k1o),e(Np,tq),e(tq,S1o),e(Np,R1o),e(y,P1o),e(y,qp),e(qp,Bie),e(Bie,B1o),e(qp,I1o),e(qp,aq),e(aq,N1o),e(qp,q1o),e(y,j1o),e(y,jp),e(jp,Iie),e(Iie,D1o),e(jp,G1o),e(jp,nq),e(nq,O1o),e(jp,V1o),e(y,X1o),e(y,Dp),e(Dp,Nie),e(Nie,z1o),e(Dp,W1o),e(Dp,sq),e(sq,Q1o),e(Dp,H1o),e(y,U1o),e(y,Gp),e(Gp,qie),e(qie,J1o),e(Gp,Y1o),e(Gp,lq),e(lq,K1o),e(Gp,Z1o),e(y,ebo),e(y,Op),e(Op,jie),e(jie,obo),e(Op,rbo),e(Op,iq),e(iq,tbo),e(Op,abo),e(y,nbo),e(y,Vp),e(Vp,Die),e(Die,sbo),e(Vp,lbo),e(Vp,dq),e(dq,ibo),e(Vp,dbo),e(y,cbo),e(y,Xp),e(Xp,Gie),e(Gie,fbo),e(Xp,mbo),e(Xp,cq),e(cq,gbo),e(Xp,hbo),e(y,pbo),e(y,zp),e(zp,Oie),e(Oie,ubo),e(zp,_bo),e(zp,fq),e(fq,bbo),e(zp,vbo),e(y,Fbo),e(y,Wp),e(Wp,Vie),e(Vie,Tbo),e(Wp,Mbo),e(Wp,mq),e(mq,Ebo),e(Wp,Cbo),e(y,wbo),e(y,Qp),e(Qp,Xie),e(Xie,Abo),e(Qp,Lbo),e(Qp,gq),e(gq,ybo),e(Qp,xbo),e(y,$bo),e(y,Hp),e(Hp,zie),e(zie,kbo),e(Hp,Sbo),e(Hp,hq),e(hq,Rbo),e(Hp,Pbo),e(y,Bbo),e(y,Up),e(Up,Wie),e(Wie,Ibo),e(Up,Nbo),e(Up,pq),e(pq,qbo),e(Up,jbo),e(y,Dbo),e(y,Jp),e(Jp,Qie),e(Qie,Gbo),e(Jp,Obo),e(Jp,uq),e(uq,Vbo),e(Jp,Xbo),e(y,zbo),e(y,Yp),e(Yp,Hie),e(Hie,Wbo),e(Yp,Qbo),e(Yp,_q),e(_q,Hbo),e(Yp,Ubo),e(y,Jbo),e(y,Kp),e(Kp,Uie),e(Uie,Ybo),e(Kp,Kbo),e(Kp,bq),e(bq,Zbo),e(Kp,evo),e(y,ovo),e(y,Zp),e(Zp,Jie),e(Jie,rvo),e(Zp,tvo),e(Zp,vq),e(vq,avo),e(Zp,nvo),e(y,svo),e(y,eu),e(eu,Yie),e(Yie,lvo),e(eu,ivo),e(eu,Fq),e(Fq,dvo),e(eu,cvo),e(y,fvo),e(y,ou),e(ou,Kie),e(Kie,mvo),e(ou,gvo),e(ou,Tq),e(Tq,hvo),e(ou,pvo),e(y,uvo),e(y,ru),e(ru,Zie),e(Zie,_vo),e(ru,bvo),e(ru,Mq),e(Mq,vvo),e(ru,Fvo),e(y,Tvo),e(y,tu),e(tu,ede),e(ede,Mvo),e(tu,Evo),e(tu,Eq),e(Eq,Cvo),e(tu,wvo),e(y,Avo),e(y,au),e(au,ode),e(ode,Lvo),e(au,yvo),e(au,Cq),e(Cq,xvo),e(au,$vo),e(y,kvo),e(y,nu),e(nu,rde),e(rde,Svo),e(nu,Rvo),e(nu,wq),e(wq,Pvo),e(nu,Bvo),e(y,Ivo),e(y,su),e(su,tde),e(tde,Nvo),e(su,qvo),e(su,Aq),e(Aq,jvo),e(su,Dvo),e(y,Gvo),e(y,lu),e(lu,ade),e(ade,Ovo),e(lu,Vvo),e(lu,Lq),e(Lq,Xvo),e(lu,zvo),e(y,Wvo),e(y,iu),e(iu,nde),e(nde,Qvo),e(iu,Hvo),e(iu,yq),e(yq,Uvo),e(iu,Jvo),e(y,Yvo),e(y,Gs),e(Gs,sde),e(sde,Kvo),e(Gs,Zvo),e(Gs,xq),e(xq,eFo),e(Gs,oFo),e(Gs,$q),e($q,rFo),e(Gs,tFo),e(y,aFo),e(y,du),e(du,lde),e(lde,nFo),e(du,sFo),e(du,kq),e(kq,lFo),e(du,iFo),e(y,dFo),e(y,cu),e(cu,ide),e(ide,cFo),e(cu,fFo),e(cu,Sq),e(Sq,mFo),e(cu,gFo),e(y,hFo),e(y,fu),e(fu,dde),e(dde,pFo),e(fu,uFo),e(fu,Rq),e(Rq,_Fo),e(fu,bFo),e(y,vFo),e(y,mu),e(mu,cde),e(cde,FFo),e(mu,TFo),e(mu,Pq),e(Pq,MFo),e(mu,EFo),e(y,CFo),e(y,gu),e(gu,fde),e(fde,wFo),e(gu,AFo),e(gu,Bq),e(Bq,LFo),e(gu,yFo),e(y,xFo),e(y,hu),e(hu,mde),e(mde,$Fo),e(hu,kFo),e(hu,Iq),e(Iq,SFo),e(hu,RFo),e(y,PFo),e(y,pu),e(pu,gde),e(gde,BFo),e(pu,IFo),e(pu,Nq),e(Nq,NFo),e(pu,qFo),e(y,jFo),e(y,uu),e(uu,hde),e(hde,DFo),e(uu,GFo),e(uu,qq),e(qq,OFo),e(uu,VFo),e(y,XFo),e(y,_u),e(_u,pde),e(pde,zFo),e(_u,WFo),e(_u,jq),e(jq,QFo),e(_u,HFo),e(y,UFo),e(y,bu),e(bu,ude),e(ude,JFo),e(bu,YFo),e(bu,Dq),e(Dq,KFo),e(bu,ZFo),e(y,eTo),e(y,vu),e(vu,_de),e(_de,oTo),e(vu,rTo),e(vu,Gq),e(Gq,tTo),e(vu,aTo),e(y,nTo),e(y,Fu),e(Fu,bde),e(bde,sTo),e(Fu,lTo),e(Fu,Oq),e(Oq,iTo),e(Fu,dTo),e(y,cTo),e(y,Tu),e(Tu,vde),e(vde,fTo),e(Tu,mTo),e(Tu,Vq),e(Vq,gTo),e(Tu,hTo),e(y,pTo),e(y,Mu),e(Mu,Fde),e(Fde,uTo),e(Mu,_To),e(Mu,Xq),e(Xq,bTo),e(Mu,vTo),e(y,FTo),e(y,Eu),e(Eu,Tde),e(Tde,TTo),e(Eu,MTo),e(Eu,zq),e(zq,ETo),e(Eu,CTo),e(y,wTo),e(y,Cu),e(Cu,Mde),e(Mde,ATo),e(Cu,LTo),e(Cu,Wq),e(Wq,yTo),e(Cu,xTo),e(y,$To),e(y,wu),e(wu,Ede),e(Ede,kTo),e(wu,STo),e(wu,Qq),e(Qq,RTo),e(wu,PTo),e(y,BTo),e(y,Au),e(Au,Cde),e(Cde,ITo),e(Au,NTo),e(Au,Hq),e(Hq,qTo),e(Au,jTo),e(y,DTo),e(y,Lu),e(Lu,wde),e(wde,GTo),e(Lu,OTo),e(Lu,Uq),e(Uq,VTo),e(Lu,XTo),e(y,zTo),e(y,yu),e(yu,Ade),e(Ade,WTo),e(yu,QTo),e(yu,Jq),e(Jq,HTo),e(yu,UTo),e(y,JTo),e(y,xu),e(xu,Lde),e(Lde,YTo),e(xu,KTo),e(xu,Yq),e(Yq,ZTo),e(xu,eMo),e(y,oMo),e(y,$u),e($u,yde),e(yde,rMo),e($u,tMo),e($u,Kq),e(Kq,aMo),e($u,nMo),e(y,sMo),e(y,ku),e(ku,xde),e(xde,lMo),e(ku,iMo),e(ku,Zq),e(Zq,dMo),e(ku,cMo),e(y,fMo),e(y,Su),e(Su,$de),e($de,mMo),e(Su,gMo),e(Su,ej),e(ej,hMo),e(Su,pMo),e(y,uMo),e(y,Ru),e(Ru,kde),e(kde,_Mo),e(Ru,bMo),e(Ru,oj),e(oj,vMo),e(Ru,FMo),e(y,TMo),e(y,Pu),e(Pu,Sde),e(Sde,MMo),e(Pu,EMo),e(Pu,rj),e(rj,CMo),e(Pu,wMo),e(y,AMo),e(y,Bu),e(Bu,Rde),e(Rde,LMo),e(Bu,yMo),e(Bu,tj),e(tj,xMo),e(Bu,$Mo),e(y,kMo),e(y,Iu),e(Iu,Pde),e(Pde,SMo),e(Iu,RMo),e(Iu,aj),e(aj,PMo),e(Iu,BMo),e(y,IMo),e(y,Nu),e(Nu,Bde),e(Bde,NMo),e(Nu,qMo),e(Nu,nj),e(nj,jMo),e(Nu,DMo),e(y,GMo),e(y,qu),e(qu,Ide),e(Ide,OMo),e(qu,VMo),e(qu,sj),e(sj,XMo),e(qu,zMo),e(y,WMo),e(y,ju),e(ju,Nde),e(Nde,QMo),e(ju,HMo),e(ju,lj),e(lj,UMo),e(ju,JMo),e(y,YMo),e(y,Du),e(Du,qde),e(qde,KMo),e(Du,ZMo),e(Du,ij),e(ij,eEo),e(Du,oEo),e(y,rEo),e(y,Gu),e(Gu,jde),e(jde,tEo),e(Gu,aEo),e(Gu,dj),e(dj,nEo),e(Gu,sEo),e(y,lEo),e(y,Ou),e(Ou,Dde),e(Dde,iEo),e(Ou,dEo),e(Ou,cj),e(cj,cEo),e(Ou,fEo),e(y,mEo),e(y,Vu),e(Vu,Gde),e(Gde,gEo),e(Vu,hEo),e(Vu,fj),e(fj,pEo),e(Vu,uEo),e(y,_Eo),e(y,Xu),e(Xu,Ode),e(Ode,bEo),e(Xu,vEo),e(Xu,mj),e(mj,FEo),e(Xu,TEo),e(y,MEo),e(y,zu),e(zu,Vde),e(Vde,EEo),e(zu,CEo),e(zu,gj),e(gj,wEo),e(zu,AEo),e(y,LEo),e(y,Wu),e(Wu,Xde),e(Xde,yEo),e(Wu,xEo),e(Wu,hj),e(hj,$Eo),e(Wu,kEo),e(y,SEo),e(y,Qu),e(Qu,zde),e(zde,REo),e(Qu,PEo),e(Qu,pj),e(pj,BEo),e(Qu,IEo),e(y,NEo),e(y,Hu),e(Hu,Wde),e(Wde,qEo),e(Hu,jEo),e(Hu,uj),e(uj,DEo),e(Hu,GEo),e(y,OEo),e(y,Uu),e(Uu,Qde),e(Qde,VEo),e(Uu,XEo),e(Uu,_j),e(_j,zEo),e(Uu,WEo),e(y,QEo),e(y,Ju),e(Ju,Hde),e(Hde,HEo),e(Ju,UEo),e(Ju,bj),e(bj,JEo),e(Ju,YEo),e(y,KEo),e(y,Yu),e(Yu,Ude),e(Ude,ZEo),e(Yu,e4o),e(Yu,vj),e(vj,o4o),e(Yu,r4o),e(y,t4o),e(y,Ku),e(Ku,Jde),e(Jde,a4o),e(Ku,n4o),e(Ku,Fj),e(Fj,s4o),e(Ku,l4o),e(y,i4o),e(y,Zu),e(Zu,Yde),e(Yde,d4o),e(Zu,c4o),e(Zu,Tj),e(Tj,f4o),e(Zu,m4o),e(y,g4o),e(y,e_),e(e_,Kde),e(Kde,h4o),e(e_,p4o),e(e_,Mj),e(Mj,u4o),e(e_,_4o),e(y,b4o),e(y,o_),e(o_,Zde),e(Zde,v4o),e(o_,F4o),e(o_,Ej),e(Ej,T4o),e(o_,M4o),e(y,E4o),e(y,r_),e(r_,ece),e(ece,C4o),e(r_,w4o),e(r_,Cj),e(Cj,A4o),e(r_,L4o),e(y,y4o),e(y,t_),e(t_,oce),e(oce,x4o),e(t_,$4o),e(t_,wj),e(wj,k4o),e(t_,S4o),e(y,R4o),e(y,a_),e(a_,rce),e(rce,P4o),e(a_,B4o),e(a_,Aj),e(Aj,I4o),e(a_,N4o),e(y,q4o),e(y,n_),e(n_,tce),e(tce,j4o),e(n_,D4o),e(n_,Lj),e(Lj,G4o),e(n_,O4o),e(y,V4o),e(y,s_),e(s_,ace),e(ace,X4o),e(s_,z4o),e(s_,yj),e(yj,W4o),e(s_,Q4o),e(y,H4o),e(y,l_),e(l_,nce),e(nce,U4o),e(l_,J4o),e(l_,xj),e(xj,Y4o),e(l_,K4o),e(y,Z4o),e(y,i_),e(i_,sce),e(sce,eCo),e(i_,oCo),e(i_,$j),e($j,rCo),e(i_,tCo),e(y,aCo),e(y,d_),e(d_,lce),e(lce,nCo),e(d_,sCo),e(d_,kj),e(kj,lCo),e(d_,iCo),e(y,dCo),e(y,c_),e(c_,ice),e(ice,cCo),e(c_,fCo),e(c_,Sj),e(Sj,mCo),e(c_,gCo),e(y,hCo),e(y,f_),e(f_,dce),e(dce,pCo),e(f_,uCo),e(f_,Rj),e(Rj,_Co),e(f_,bCo),e(y,vCo),e(y,m_),e(m_,cce),e(cce,FCo),e(m_,TCo),e(m_,Pj),e(Pj,MCo),e(m_,ECo),e(y,CCo),e(y,g_),e(g_,fce),e(fce,wCo),e(g_,ACo),e(g_,Bj),e(Bj,LCo),e(g_,yCo),e(y,xCo),e(y,h_),e(h_,mce),e(mce,$Co),e(h_,kCo),e(h_,Ij),e(Ij,SCo),e(h_,RCo),e(y,PCo),e(y,p_),e(p_,gce),e(gce,BCo),e(p_,ICo),e(p_,Nj),e(Nj,NCo),e(p_,qCo),e(y,jCo),e(y,u_),e(u_,hce),e(hce,DCo),e(u_,GCo),e(u_,qj),e(qj,OCo),e(u_,VCo),e(y,XCo),e(y,__),e(__,pce),e(pce,zCo),e(__,WCo),e(__,jj),e(jj,QCo),e(__,HCo),e(y,UCo),e(y,b_),e(b_,uce),e(uce,JCo),e(b_,YCo),e(b_,Dj),e(Dj,KCo),e(b_,ZCo),e(y,e5o),e(y,v_),e(v_,_ce),e(_ce,o5o),e(v_,r5o),e(v_,Gj),e(Gj,t5o),e(v_,a5o),e(y,n5o),e(y,F_),e(F_,bce),e(bce,s5o),e(F_,l5o),e(F_,Oj),e(Oj,i5o),e(F_,d5o),e(y,c5o),e(y,T_),e(T_,vce),e(vce,f5o),e(T_,m5o),e(T_,Vj),e(Vj,g5o),e(T_,h5o),e(y,p5o),e(y,M_),e(M_,Fce),e(Fce,u5o),e(M_,_5o),e(M_,Xj),e(Xj,b5o),e(M_,v5o),e(y,F5o),e(y,E_),e(E_,Tce),e(Tce,T5o),e(E_,M5o),e(E_,zj),e(zj,E5o),e(E_,C5o),e(y,w5o),e(y,C_),e(C_,Mce),e(Mce,A5o),e(C_,L5o),e(C_,Wj),e(Wj,y5o),e(C_,x5o),e(y,$5o),e(y,w_),e(w_,Ece),e(Ece,k5o),e(w_,S5o),e(w_,Qj),e(Qj,R5o),e(w_,P5o),e(y,B5o),e(y,A_),e(A_,Cce),e(Cce,I5o),e(A_,N5o),e(A_,Hj),e(Hj,q5o),e(A_,j5o),e(y,D5o),e(y,L_),e(L_,wce),e(wce,G5o),e(L_,O5o),e(L_,Uj),e(Uj,V5o),e(L_,X5o),e(Je,z5o),e(Je,y_),e(y_,W5o),e(y_,Ace),e(Ace,Q5o),e(y_,H5o),e(y_,Lce),e(Lce,U5o),e(Je,J5o),M(x_,Je,null),b(f,xGe,_),b(f,Ni,_),e(Ni,$_),e($_,yce),M(ey,yce,null),e(Ni,Y5o),e(Ni,xce),e(xce,K5o),b(f,$Ge,_),b(f,$o,_),M(oy,$o,null),e($o,Z5o),e($o,qi),e(qi,e3o),e(qi,Jj),e(Jj,o3o),e(qi,r3o),e(qi,Yj),e(Yj,t3o),e(qi,a3o),e($o,n3o),e($o,ry),e(ry,s3o),e(ry,$ce),e($ce,l3o),e(ry,i3o),e($o,d3o),e($o,st),M(ty,st,null),e(st,c3o),e(st,kce),e(kce,f3o),e(st,m3o),e(st,ji),e(ji,g3o),e(ji,Sce),e(Sce,h3o),e(ji,p3o),e(ji,Kj),e(Kj,u3o),e(ji,_3o),e(st,b3o),M(k_,st,null),e($o,v3o),e($o,Ye),M(ay,Ye,null),e(Ye,F3o),e(Ye,Rce),e(Rce,T3o),e(Ye,M3o),e(Ye,Ra),e(Ra,E3o),e(Ra,Pce),e(Pce,C3o),e(Ra,w3o),e(Ra,Bce),e(Bce,A3o),e(Ra,L3o),e(Ra,Ice),e(Ice,y3o),e(Ra,x3o),e(Ye,$3o),e(Ye,G),e(G,S_),e(S_,Nce),e(Nce,k3o),e(S_,S3o),e(S_,Zj),e(Zj,R3o),e(S_,P3o),e(G,B3o),e(G,R_),e(R_,qce),e(qce,I3o),e(R_,N3o),e(R_,eD),e(eD,q3o),e(R_,j3o),e(G,D3o),e(G,P_),e(P_,jce),e(jce,G3o),e(P_,O3o),e(P_,oD),e(oD,V3o),e(P_,X3o),e(G,z3o),e(G,B_),e(B_,Dce),e(Dce,W3o),e(B_,Q3o),e(B_,rD),e(rD,H3o),e(B_,U3o),e(G,J3o),e(G,I_),e(I_,Gce),e(Gce,Y3o),e(I_,K3o),e(I_,tD),e(tD,Z3o),e(I_,e0o),e(G,o0o),e(G,N_),e(N_,Oce),e(Oce,r0o),e(N_,t0o),e(N_,aD),e(aD,a0o),e(N_,n0o),e(G,s0o),e(G,q_),e(q_,Vce),e(Vce,l0o),e(q_,i0o),e(q_,nD),e(nD,d0o),e(q_,c0o),e(G,f0o),e(G,j_),e(j_,Xce),e(Xce,m0o),e(j_,g0o),e(j_,sD),e(sD,h0o),e(j_,p0o),e(G,u0o),e(G,D_),e(D_,zce),e(zce,_0o),e(D_,b0o),e(D_,lD),e(lD,v0o),e(D_,F0o),e(G,T0o),e(G,G_),e(G_,Wce),e(Wce,M0o),e(G_,E0o),e(G_,iD),e(iD,C0o),e(G_,w0o),e(G,A0o),e(G,O_),e(O_,Qce),e(Qce,L0o),e(O_,y0o),e(O_,dD),e(dD,x0o),e(O_,$0o),e(G,k0o),e(G,V_),e(V_,Hce),e(Hce,S0o),e(V_,R0o),e(V_,cD),e(cD,P0o),e(V_,B0o),e(G,I0o),e(G,X_),e(X_,Uce),e(Uce,N0o),e(X_,q0o),e(X_,fD),e(fD,j0o),e(X_,D0o),e(G,G0o),e(G,z_),e(z_,Jce),e(Jce,O0o),e(z_,V0o),e(z_,mD),e(mD,X0o),e(z_,z0o),e(G,W0o),e(G,W_),e(W_,Yce),e(Yce,Q0o),e(W_,H0o),e(W_,gD),e(gD,U0o),e(W_,J0o),e(G,Y0o),e(G,Q_),e(Q_,Kce),e(Kce,K0o),e(Q_,Z0o),e(Q_,hD),e(hD,ewo),e(Q_,owo),e(G,rwo),e(G,H_),e(H_,Zce),e(Zce,two),e(H_,awo),e(H_,pD),e(pD,nwo),e(H_,swo),e(G,lwo),e(G,U_),e(U_,efe),e(efe,iwo),e(U_,dwo),e(U_,uD),e(uD,cwo),e(U_,fwo),e(G,mwo),e(G,J_),e(J_,ofe),e(ofe,gwo),e(J_,hwo),e(J_,_D),e(_D,pwo),e(J_,uwo),e(G,_wo),e(G,Y_),e(Y_,rfe),e(rfe,bwo),e(Y_,vwo),e(Y_,bD),e(bD,Fwo),e(Y_,Two),e(G,Mwo),e(G,K_),e(K_,tfe),e(tfe,Ewo),e(K_,Cwo),e(K_,vD),e(vD,wwo),e(K_,Awo),e(G,Lwo),e(G,Z_),e(Z_,afe),e(afe,ywo),e(Z_,xwo),e(Z_,FD),e(FD,$wo),e(Z_,kwo),e(G,Swo),e(G,e7),e(e7,nfe),e(nfe,Rwo),e(e7,Pwo),e(e7,TD),e(TD,Bwo),e(e7,Iwo),e(G,Nwo),e(G,o7),e(o7,sfe),e(sfe,qwo),e(o7,jwo),e(o7,MD),e(MD,Dwo),e(o7,Gwo),e(G,Owo),e(G,r7),e(r7,lfe),e(lfe,Vwo),e(r7,Xwo),e(r7,ED),e(ED,zwo),e(r7,Wwo),e(G,Qwo),e(G,t7),e(t7,ife),e(ife,Hwo),e(t7,Uwo),e(t7,CD),e(CD,Jwo),e(t7,Ywo),e(G,Kwo),e(G,a7),e(a7,dfe),e(dfe,Zwo),e(a7,eAo),e(a7,wD),e(wD,oAo),e(a7,rAo),e(G,tAo),e(G,n7),e(n7,cfe),e(cfe,aAo),e(n7,nAo),e(n7,AD),e(AD,sAo),e(n7,lAo),e(G,iAo),e(G,s7),e(s7,ffe),e(ffe,dAo),e(s7,cAo),e(s7,LD),e(LD,fAo),e(s7,mAo),e(G,gAo),e(G,l7),e(l7,mfe),e(mfe,hAo),e(l7,pAo),e(l7,yD),e(yD,uAo),e(l7,_Ao),e(G,bAo),e(G,i7),e(i7,gfe),e(gfe,vAo),e(i7,FAo),e(i7,xD),e(xD,TAo),e(i7,MAo),e(G,EAo),e(G,d7),e(d7,hfe),e(hfe,CAo),e(d7,wAo),e(d7,$D),e($D,AAo),e(d7,LAo),e(G,yAo),e(G,c7),e(c7,pfe),e(pfe,xAo),e(c7,$Ao),e(c7,kD),e(kD,kAo),e(c7,SAo),e(G,RAo),e(G,f7),e(f7,ufe),e(ufe,PAo),e(f7,BAo),e(f7,SD),e(SD,IAo),e(f7,NAo),e(G,qAo),e(G,m7),e(m7,_fe),e(_fe,jAo),e(m7,DAo),e(m7,RD),e(RD,GAo),e(m7,OAo),e(G,VAo),e(G,g7),e(g7,bfe),e(bfe,XAo),e(g7,zAo),e(g7,PD),e(PD,WAo),e(g7,QAo),e(G,HAo),e(G,h7),e(h7,vfe),e(vfe,UAo),e(h7,JAo),e(h7,BD),e(BD,YAo),e(h7,KAo),e(G,ZAo),e(G,p7),e(p7,Ffe),e(Ffe,e6o),e(p7,o6o),e(p7,ID),e(ID,r6o),e(p7,t6o),e(G,a6o),e(G,u7),e(u7,Tfe),e(Tfe,n6o),e(u7,s6o),e(u7,ND),e(ND,l6o),e(u7,i6o),e(G,d6o),e(G,_7),e(_7,Mfe),e(Mfe,c6o),e(_7,f6o),e(_7,qD),e(qD,m6o),e(_7,g6o),e(G,h6o),e(G,b7),e(b7,Efe),e(Efe,p6o),e(b7,u6o),e(b7,jD),e(jD,_6o),e(b7,b6o),e(G,v6o),e(G,v7),e(v7,Cfe),e(Cfe,F6o),e(v7,T6o),e(v7,DD),e(DD,M6o),e(v7,E6o),e(G,C6o),e(G,F7),e(F7,wfe),e(wfe,w6o),e(F7,A6o),e(F7,GD),e(GD,L6o),e(F7,y6o),e(Ye,x6o),e(Ye,T7),e(T7,$6o),e(T7,Afe),e(Afe,k6o),e(T7,S6o),e(T7,Lfe),e(Lfe,R6o),e(Ye,P6o),M(M7,Ye,null),b(f,kGe,_),b(f,Di,_),e(Di,E7),e(E7,yfe),M(ny,yfe,null),e(Di,B6o),e(Di,xfe),e(xfe,I6o),b(f,SGe,_),b(f,ko,_),M(sy,ko,null),e(ko,N6o),e(ko,Gi),e(Gi,q6o),e(Gi,OD),e(OD,j6o),e(Gi,D6o),e(Gi,VD),e(VD,G6o),e(Gi,O6o),e(ko,V6o),e(ko,ly),e(ly,X6o),e(ly,$fe),e($fe,z6o),e(ly,W6o),e(ko,Q6o),e(ko,lt),M(iy,lt,null),e(lt,H6o),e(lt,kfe),e(kfe,U6o),e(lt,J6o),e(lt,Oi),e(Oi,Y6o),e(Oi,Sfe),e(Sfe,K6o),e(Oi,Z6o),e(Oi,XD),e(XD,eLo),e(Oi,oLo),e(lt,rLo),M(C7,lt,null),e(ko,tLo),e(ko,Ke),M(dy,Ke,null),e(Ke,aLo),e(Ke,Rfe),e(Rfe,nLo),e(Ke,sLo),e(Ke,Pa),e(Pa,lLo),e(Pa,Pfe),e(Pfe,iLo),e(Pa,dLo),e(Pa,Bfe),e(Bfe,cLo),e(Pa,fLo),e(Pa,Ife),e(Ife,mLo),e(Pa,gLo),e(Ke,hLo),e(Ke,z),e(z,w7),e(w7,Nfe),e(Nfe,pLo),e(w7,uLo),e(w7,zD),e(zD,_Lo),e(w7,bLo),e(z,vLo),e(z,A7),e(A7,qfe),e(qfe,FLo),e(A7,TLo),e(A7,WD),e(WD,MLo),e(A7,ELo),e(z,CLo),e(z,L7),e(L7,jfe),e(jfe,wLo),e(L7,ALo),e(L7,QD),e(QD,LLo),e(L7,yLo),e(z,xLo),e(z,y7),e(y7,Dfe),e(Dfe,$Lo),e(y7,kLo),e(y7,HD),e(HD,SLo),e(y7,RLo),e(z,PLo),e(z,x7),e(x7,Gfe),e(Gfe,BLo),e(x7,ILo),e(x7,UD),e(UD,NLo),e(x7,qLo),e(z,jLo),e(z,$7),e($7,Ofe),e(Ofe,DLo),e($7,GLo),e($7,JD),e(JD,OLo),e($7,VLo),e(z,XLo),e(z,k7),e(k7,Vfe),e(Vfe,zLo),e(k7,WLo),e(k7,YD),e(YD,QLo),e(k7,HLo),e(z,ULo),e(z,S7),e(S7,Xfe),e(Xfe,JLo),e(S7,YLo),e(S7,KD),e(KD,KLo),e(S7,ZLo),e(z,eyo),e(z,R7),e(R7,zfe),e(zfe,oyo),e(R7,ryo),e(R7,ZD),e(ZD,tyo),e(R7,ayo),e(z,nyo),e(z,P7),e(P7,Wfe),e(Wfe,syo),e(P7,lyo),e(P7,eG),e(eG,iyo),e(P7,dyo),e(z,cyo),e(z,B7),e(B7,Qfe),e(Qfe,fyo),e(B7,myo),e(B7,oG),e(oG,gyo),e(B7,hyo),e(z,pyo),e(z,I7),e(I7,Hfe),e(Hfe,uyo),e(I7,_yo),e(I7,rG),e(rG,byo),e(I7,vyo),e(z,Fyo),e(z,N7),e(N7,Ufe),e(Ufe,Tyo),e(N7,Myo),e(N7,tG),e(tG,Eyo),e(N7,Cyo),e(z,wyo),e(z,q7),e(q7,Jfe),e(Jfe,Ayo),e(q7,Lyo),e(q7,aG),e(aG,yyo),e(q7,xyo),e(z,$yo),e(z,j7),e(j7,Yfe),e(Yfe,kyo),e(j7,Syo),e(j7,nG),e(nG,Ryo),e(j7,Pyo),e(z,Byo),e(z,D7),e(D7,Kfe),e(Kfe,Iyo),e(D7,Nyo),e(D7,sG),e(sG,qyo),e(D7,jyo),e(z,Dyo),e(z,G7),e(G7,Zfe),e(Zfe,Gyo),e(G7,Oyo),e(G7,lG),e(lG,Vyo),e(G7,Xyo),e(z,zyo),e(z,O7),e(O7,eme),e(eme,Wyo),e(O7,Qyo),e(O7,iG),e(iG,Hyo),e(O7,Uyo),e(z,Jyo),e(z,V7),e(V7,ome),e(ome,Yyo),e(V7,Kyo),e(V7,dG),e(dG,Zyo),e(V7,e8o),e(z,o8o),e(z,X7),e(X7,rme),e(rme,r8o),e(X7,t8o),e(X7,cG),e(cG,a8o),e(X7,n8o),e(z,s8o),e(z,z7),e(z7,tme),e(tme,l8o),e(z7,i8o),e(z7,fG),e(fG,d8o),e(z7,c8o),e(z,f8o),e(z,W7),e(W7,ame),e(ame,m8o),e(W7,g8o),e(W7,mG),e(mG,h8o),e(W7,p8o),e(z,u8o),e(z,Q7),e(Q7,nme),e(nme,_8o),e(Q7,b8o),e(Q7,gG),e(gG,v8o),e(Q7,F8o),e(z,T8o),e(z,H7),e(H7,sme),e(sme,M8o),e(H7,E8o),e(H7,hG),e(hG,C8o),e(H7,w8o),e(z,A8o),e(z,U7),e(U7,lme),e(lme,L8o),e(U7,y8o),e(U7,pG),e(pG,x8o),e(U7,$8o),e(z,k8o),e(z,J7),e(J7,ime),e(ime,S8o),e(J7,R8o),e(J7,uG),e(uG,P8o),e(J7,B8o),e(z,I8o),e(z,Y7),e(Y7,dme),e(dme,N8o),e(Y7,q8o),e(Y7,_G),e(_G,j8o),e(Y7,D8o),e(z,G8o),e(z,K7),e(K7,cme),e(cme,O8o),e(K7,V8o),e(K7,bG),e(bG,X8o),e(K7,z8o),e(z,W8o),e(z,Z7),e(Z7,fme),e(fme,Q8o),e(Z7,H8o),e(Z7,vG),e(vG,U8o),e(Z7,J8o),e(z,Y8o),e(z,e2),e(e2,mme),e(mme,K8o),e(e2,Z8o),e(e2,FG),e(FG,e9o),e(e2,o9o),e(z,r9o),e(z,o2),e(o2,gme),e(gme,t9o),e(o2,a9o),e(o2,TG),e(TG,n9o),e(o2,s9o),e(z,l9o),e(z,r2),e(r2,hme),e(hme,i9o),e(r2,d9o),e(r2,MG),e(MG,c9o),e(r2,f9o),e(z,m9o),e(z,t2),e(t2,pme),e(pme,g9o),e(t2,h9o),e(t2,EG),e(EG,p9o),e(t2,u9o),e(z,_9o),e(z,a2),e(a2,ume),e(ume,b9o),e(a2,v9o),e(a2,CG),e(CG,F9o),e(a2,T9o),e(z,M9o),e(z,n2),e(n2,_me),e(_me,E9o),e(n2,C9o),e(n2,wG),e(wG,w9o),e(n2,A9o),e(z,L9o),e(z,s2),e(s2,bme),e(bme,y9o),e(s2,x9o),e(s2,AG),e(AG,$9o),e(s2,k9o),e(z,S9o),e(z,l2),e(l2,vme),e(vme,R9o),e(l2,P9o),e(l2,LG),e(LG,B9o),e(l2,I9o),e(z,N9o),e(z,i2),e(i2,Fme),e(Fme,q9o),e(i2,j9o),e(i2,yG),e(yG,D9o),e(i2,G9o),e(Ke,O9o),e(Ke,d2),e(d2,V9o),e(d2,Tme),e(Tme,X9o),e(d2,z9o),e(d2,Mme),e(Mme,W9o),e(Ke,Q9o),M(c2,Ke,null),b(f,RGe,_),b(f,Vi,_),e(Vi,f2),e(f2,Eme),M(cy,Eme,null),e(Vi,H9o),e(Vi,Cme),e(Cme,U9o),b(f,PGe,_),b(f,So,_),M(fy,So,null),e(So,J9o),e(So,Xi),e(Xi,Y9o),e(Xi,xG),e(xG,K9o),e(Xi,Z9o),e(Xi,$G),e($G,exo),e(Xi,oxo),e(So,rxo),e(So,my),e(my,txo),e(my,wme),e(wme,axo),e(my,nxo),e(So,sxo),e(So,it),M(gy,it,null),e(it,lxo),e(it,Ame),e(Ame,ixo),e(it,dxo),e(it,zi),e(zi,cxo),e(zi,Lme),e(Lme,fxo),e(zi,mxo),e(zi,kG),e(kG,gxo),e(zi,hxo),e(it,pxo),M(m2,it,null),e(So,uxo),e(So,Ze),M(hy,Ze,null),e(Ze,_xo),e(Ze,yme),e(yme,bxo),e(Ze,vxo),e(Ze,Ba),e(Ba,Fxo),e(Ba,xme),e(xme,Txo),e(Ba,Mxo),e(Ba,$me),e($me,Exo),e(Ba,Cxo),e(Ba,kme),e(kme,wxo),e(Ba,Axo),e(Ze,Lxo),e(Ze,Q),e(Q,g2),e(g2,Sme),e(Sme,yxo),e(g2,xxo),e(g2,SG),e(SG,$xo),e(g2,kxo),e(Q,Sxo),e(Q,h2),e(h2,Rme),e(Rme,Rxo),e(h2,Pxo),e(h2,RG),e(RG,Bxo),e(h2,Ixo),e(Q,Nxo),e(Q,p2),e(p2,Pme),e(Pme,qxo),e(p2,jxo),e(p2,PG),e(PG,Dxo),e(p2,Gxo),e(Q,Oxo),e(Q,u2),e(u2,Bme),e(Bme,Vxo),e(u2,Xxo),e(u2,BG),e(BG,zxo),e(u2,Wxo),e(Q,Qxo),e(Q,_2),e(_2,Ime),e(Ime,Hxo),e(_2,Uxo),e(_2,IG),e(IG,Jxo),e(_2,Yxo),e(Q,Kxo),e(Q,b2),e(b2,Nme),e(Nme,Zxo),e(b2,e$o),e(b2,NG),e(NG,o$o),e(b2,r$o),e(Q,t$o),e(Q,v2),e(v2,qme),e(qme,a$o),e(v2,n$o),e(v2,qG),e(qG,s$o),e(v2,l$o),e(Q,i$o),e(Q,F2),e(F2,jme),e(jme,d$o),e(F2,c$o),e(F2,jG),e(jG,f$o),e(F2,m$o),e(Q,g$o),e(Q,T2),e(T2,Dme),e(Dme,h$o),e(T2,p$o),e(T2,DG),e(DG,u$o),e(T2,_$o),e(Q,b$o),e(Q,M2),e(M2,Gme),e(Gme,v$o),e(M2,F$o),e(M2,GG),e(GG,T$o),e(M2,M$o),e(Q,E$o),e(Q,E2),e(E2,Ome),e(Ome,C$o),e(E2,w$o),e(E2,OG),e(OG,A$o),e(E2,L$o),e(Q,y$o),e(Q,C2),e(C2,Vme),e(Vme,x$o),e(C2,$$o),e(C2,VG),e(VG,k$o),e(C2,S$o),e(Q,R$o),e(Q,w2),e(w2,Xme),e(Xme,P$o),e(w2,B$o),e(w2,XG),e(XG,I$o),e(w2,N$o),e(Q,q$o),e(Q,A2),e(A2,zme),e(zme,j$o),e(A2,D$o),e(A2,zG),e(zG,G$o),e(A2,O$o),e(Q,V$o),e(Q,L2),e(L2,Wme),e(Wme,X$o),e(L2,z$o),e(L2,WG),e(WG,W$o),e(L2,Q$o),e(Q,H$o),e(Q,y2),e(y2,Qme),e(Qme,U$o),e(y2,J$o),e(y2,QG),e(QG,Y$o),e(y2,K$o),e(Q,Z$o),e(Q,x2),e(x2,Hme),e(Hme,eko),e(x2,oko),e(x2,HG),e(HG,rko),e(x2,tko),e(Q,ako),e(Q,$2),e($2,Ume),e(Ume,nko),e($2,sko),e($2,UG),e(UG,lko),e($2,iko),e(Q,dko),e(Q,k2),e(k2,Jme),e(Jme,cko),e(k2,fko),e(k2,JG),e(JG,mko),e(k2,gko),e(Q,hko),e(Q,S2),e(S2,Yme),e(Yme,pko),e(S2,uko),e(S2,YG),e(YG,_ko),e(S2,bko),e(Q,vko),e(Q,R2),e(R2,Kme),e(Kme,Fko),e(R2,Tko),e(R2,KG),e(KG,Mko),e(R2,Eko),e(Q,Cko),e(Q,P2),e(P2,Zme),e(Zme,wko),e(P2,Ako),e(P2,ZG),e(ZG,Lko),e(P2,yko),e(Q,xko),e(Q,B2),e(B2,ege),e(ege,$ko),e(B2,kko),e(B2,eO),e(eO,Sko),e(B2,Rko),e(Q,Pko),e(Q,I2),e(I2,oge),e(oge,Bko),e(I2,Iko),e(I2,oO),e(oO,Nko),e(I2,qko),e(Q,jko),e(Q,N2),e(N2,rge),e(rge,Dko),e(N2,Gko),e(N2,rO),e(rO,Oko),e(N2,Vko),e(Q,Xko),e(Q,q2),e(q2,tge),e(tge,zko),e(q2,Wko),e(q2,tO),e(tO,Qko),e(q2,Hko),e(Q,Uko),e(Q,j2),e(j2,age),e(age,Jko),e(j2,Yko),e(j2,aO),e(aO,Kko),e(j2,Zko),e(Q,eSo),e(Q,D2),e(D2,nge),e(nge,oSo),e(D2,rSo),e(D2,nO),e(nO,tSo),e(D2,aSo),e(Q,nSo),e(Q,G2),e(G2,sge),e(sge,sSo),e(G2,lSo),e(G2,sO),e(sO,iSo),e(G2,dSo),e(Q,cSo),e(Q,O2),e(O2,lge),e(lge,fSo),e(O2,mSo),e(O2,lO),e(lO,gSo),e(O2,hSo),e(Q,pSo),e(Q,V2),e(V2,ige),e(ige,uSo),e(V2,_So),e(V2,iO),e(iO,bSo),e(V2,vSo),e(Q,FSo),e(Q,X2),e(X2,dge),e(dge,TSo),e(X2,MSo),e(X2,cge),e(cge,ESo),e(X2,CSo),e(Q,wSo),e(Q,z2),e(z2,fge),e(fge,ASo),e(z2,LSo),e(z2,dO),e(dO,ySo),e(z2,xSo),e(Q,$So),e(Q,W2),e(W2,mge),e(mge,kSo),e(W2,SSo),e(W2,cO),e(cO,RSo),e(W2,PSo),e(Q,BSo),e(Q,Q2),e(Q2,gge),e(gge,ISo),e(Q2,NSo),e(Q2,fO),e(fO,qSo),e(Q2,jSo),e(Q,DSo),e(Q,H2),e(H2,hge),e(hge,GSo),e(H2,OSo),e(H2,mO),e(mO,VSo),e(H2,XSo),e(Ze,zSo),e(Ze,U2),e(U2,WSo),e(U2,pge),e(pge,QSo),e(U2,HSo),e(U2,uge),e(uge,USo),e(Ze,JSo),M(J2,Ze,null),b(f,BGe,_),b(f,Wi,_),e(Wi,Y2),e(Y2,_ge),M(py,_ge,null),e(Wi,YSo),e(Wi,bge),e(bge,KSo),b(f,IGe,_),b(f,Ro,_),M(uy,Ro,null),e(Ro,ZSo),e(Ro,Qi),e(Qi,eRo),e(Qi,gO),e(gO,oRo),e(Qi,rRo),e(Qi,hO),e(hO,tRo),e(Qi,aRo),e(Ro,nRo),e(Ro,_y),e(_y,sRo),e(_y,vge),e(vge,lRo),e(_y,iRo),e(Ro,dRo),e(Ro,dt),M(by,dt,null),e(dt,cRo),e(dt,Fge),e(Fge,fRo),e(dt,mRo),e(dt,Hi),e(Hi,gRo),e(Hi,Tge),e(Tge,hRo),e(Hi,pRo),e(Hi,pO),e(pO,uRo),e(Hi,_Ro),e(dt,bRo),M(K2,dt,null),e(Ro,vRo),e(Ro,eo),M(vy,eo,null),e(eo,FRo),e(eo,Mge),e(Mge,TRo),e(eo,MRo),e(eo,Ia),e(Ia,ERo),e(Ia,Ege),e(Ege,CRo),e(Ia,wRo),e(Ia,Cge),e(Cge,ARo),e(Ia,LRo),e(Ia,wge),e(wge,yRo),e(Ia,xRo),e(eo,$Ro),e(eo,pe),e(pe,Z2),e(Z2,Age),e(Age,kRo),e(Z2,SRo),e(Z2,uO),e(uO,RRo),e(Z2,PRo),e(pe,BRo),e(pe,e1),e(e1,Lge),e(Lge,IRo),e(e1,NRo),e(e1,_O),e(_O,qRo),e(e1,jRo),e(pe,DRo),e(pe,o1),e(o1,yge),e(yge,GRo),e(o1,ORo),e(o1,bO),e(bO,VRo),e(o1,XRo),e(pe,zRo),e(pe,r1),e(r1,xge),e(xge,WRo),e(r1,QRo),e(r1,vO),e(vO,HRo),e(r1,URo),e(pe,JRo),e(pe,t1),e(t1,$ge),e($ge,YRo),e(t1,KRo),e(t1,FO),e(FO,ZRo),e(t1,ePo),e(pe,oPo),e(pe,a1),e(a1,kge),e(kge,rPo),e(a1,tPo),e(a1,TO),e(TO,aPo),e(a1,nPo),e(pe,sPo),e(pe,n1),e(n1,Sge),e(Sge,lPo),e(n1,iPo),e(n1,MO),e(MO,dPo),e(n1,cPo),e(pe,fPo),e(pe,s1),e(s1,Rge),e(Rge,mPo),e(s1,gPo),e(s1,EO),e(EO,hPo),e(s1,pPo),e(pe,uPo),e(pe,l1),e(l1,Pge),e(Pge,_Po),e(l1,bPo),e(l1,CO),e(CO,vPo),e(l1,FPo),e(pe,TPo),e(pe,i1),e(i1,Bge),e(Bge,MPo),e(i1,EPo),e(i1,wO),e(wO,CPo),e(i1,wPo),e(pe,APo),e(pe,d1),e(d1,Ige),e(Ige,LPo),e(d1,yPo),e(d1,AO),e(AO,xPo),e(d1,$Po),e(pe,kPo),e(pe,c1),e(c1,Nge),e(Nge,SPo),e(c1,RPo),e(c1,LO),e(LO,PPo),e(c1,BPo),e(pe,IPo),e(pe,f1),e(f1,qge),e(qge,NPo),e(f1,qPo),e(f1,yO),e(yO,jPo),e(f1,DPo),e(pe,GPo),e(pe,m1),e(m1,jge),e(jge,OPo),e(m1,VPo),e(m1,xO),e(xO,XPo),e(m1,zPo),e(pe,WPo),e(pe,g1),e(g1,Dge),e(Dge,QPo),e(g1,HPo),e(g1,$O),e($O,UPo),e(g1,JPo),e(pe,YPo),e(pe,h1),e(h1,Gge),e(Gge,KPo),e(h1,ZPo),e(h1,kO),e(kO,eBo),e(h1,oBo),e(pe,rBo),e(pe,p1),e(p1,Oge),e(Oge,tBo),e(p1,aBo),e(p1,SO),e(SO,nBo),e(p1,sBo),e(eo,lBo),e(eo,u1),e(u1,iBo),e(u1,Vge),e(Vge,dBo),e(u1,cBo),e(u1,Xge),e(Xge,fBo),e(eo,mBo),M(_1,eo,null),b(f,NGe,_),b(f,Ui,_),e(Ui,b1),e(b1,zge),M(Fy,zge,null),e(Ui,gBo),e(Ui,Wge),e(Wge,hBo),b(f,qGe,_),b(f,Po,_),M(Ty,Po,null),e(Po,pBo),e(Po,Ji),e(Ji,uBo),e(Ji,RO),e(RO,_Bo),e(Ji,bBo),e(Ji,PO),e(PO,vBo),e(Ji,FBo),e(Po,TBo),e(Po,My),e(My,MBo),e(My,Qge),e(Qge,EBo),e(My,CBo),e(Po,wBo),e(Po,ct),M(Ey,ct,null),e(ct,ABo),e(ct,Hge),e(Hge,LBo),e(ct,yBo),e(ct,Yi),e(Yi,xBo),e(Yi,Uge),e(Uge,$Bo),e(Yi,kBo),e(Yi,BO),e(BO,SBo),e(Yi,RBo),e(ct,PBo),M(v1,ct,null),e(Po,BBo),e(Po,oo),M(Cy,oo,null),e(oo,IBo),e(oo,Jge),e(Jge,NBo),e(oo,qBo),e(oo,Na),e(Na,jBo),e(Na,Yge),e(Yge,DBo),e(Na,GBo),e(Na,Kge),e(Kge,OBo),e(Na,VBo),e(Na,Zge),e(Zge,XBo),e(Na,zBo),e(oo,WBo),e(oo,N),e(N,F1),e(F1,ehe),e(ehe,QBo),e(F1,HBo),e(F1,IO),e(IO,UBo),e(F1,JBo),e(N,YBo),e(N,T1),e(T1,ohe),e(ohe,KBo),e(T1,ZBo),e(T1,NO),e(NO,eIo),e(T1,oIo),e(N,rIo),e(N,M1),e(M1,rhe),e(rhe,tIo),e(M1,aIo),e(M1,qO),e(qO,nIo),e(M1,sIo),e(N,lIo),e(N,E1),e(E1,the),e(the,iIo),e(E1,dIo),e(E1,jO),e(jO,cIo),e(E1,fIo),e(N,mIo),e(N,C1),e(C1,ahe),e(ahe,gIo),e(C1,hIo),e(C1,DO),e(DO,pIo),e(C1,uIo),e(N,_Io),e(N,w1),e(w1,nhe),e(nhe,bIo),e(w1,vIo),e(w1,GO),e(GO,FIo),e(w1,TIo),e(N,MIo),e(N,A1),e(A1,she),e(she,EIo),e(A1,CIo),e(A1,OO),e(OO,wIo),e(A1,AIo),e(N,LIo),e(N,L1),e(L1,lhe),e(lhe,yIo),e(L1,xIo),e(L1,VO),e(VO,$Io),e(L1,kIo),e(N,SIo),e(N,y1),e(y1,ihe),e(ihe,RIo),e(y1,PIo),e(y1,XO),e(XO,BIo),e(y1,IIo),e(N,NIo),e(N,x1),e(x1,dhe),e(dhe,qIo),e(x1,jIo),e(x1,zO),e(zO,DIo),e(x1,GIo),e(N,OIo),e(N,$1),e($1,che),e(che,VIo),e($1,XIo),e($1,WO),e(WO,zIo),e($1,WIo),e(N,QIo),e(N,k1),e(k1,fhe),e(fhe,HIo),e(k1,UIo),e(k1,QO),e(QO,JIo),e(k1,YIo),e(N,KIo),e(N,S1),e(S1,mhe),e(mhe,ZIo),e(S1,eNo),e(S1,HO),e(HO,oNo),e(S1,rNo),e(N,tNo),e(N,R1),e(R1,ghe),e(ghe,aNo),e(R1,nNo),e(R1,UO),e(UO,sNo),e(R1,lNo),e(N,iNo),e(N,P1),e(P1,hhe),e(hhe,dNo),e(P1,cNo),e(P1,JO),e(JO,fNo),e(P1,mNo),e(N,gNo),e(N,B1),e(B1,phe),e(phe,hNo),e(B1,pNo),e(B1,YO),e(YO,uNo),e(B1,_No),e(N,bNo),e(N,I1),e(I1,uhe),e(uhe,vNo),e(I1,FNo),e(I1,KO),e(KO,TNo),e(I1,MNo),e(N,ENo),e(N,N1),e(N1,_he),e(_he,CNo),e(N1,wNo),e(N1,ZO),e(ZO,ANo),e(N1,LNo),e(N,yNo),e(N,q1),e(q1,bhe),e(bhe,xNo),e(q1,$No),e(q1,eV),e(eV,kNo),e(q1,SNo),e(N,RNo),e(N,j1),e(j1,vhe),e(vhe,PNo),e(j1,BNo),e(j1,oV),e(oV,INo),e(j1,NNo),e(N,qNo),e(N,D1),e(D1,Fhe),e(Fhe,jNo),e(D1,DNo),e(D1,rV),e(rV,GNo),e(D1,ONo),e(N,VNo),e(N,G1),e(G1,The),e(The,XNo),e(G1,zNo),e(G1,tV),e(tV,WNo),e(G1,QNo),e(N,HNo),e(N,O1),e(O1,Mhe),e(Mhe,UNo),e(O1,JNo),e(O1,aV),e(aV,YNo),e(O1,KNo),e(N,ZNo),e(N,V1),e(V1,Ehe),e(Ehe,eqo),e(V1,oqo),e(V1,nV),e(nV,rqo),e(V1,tqo),e(N,aqo),e(N,X1),e(X1,Che),e(Che,nqo),e(X1,sqo),e(X1,sV),e(sV,lqo),e(X1,iqo),e(N,dqo),e(N,z1),e(z1,whe),e(whe,cqo),e(z1,fqo),e(z1,lV),e(lV,mqo),e(z1,gqo),e(N,hqo),e(N,W1),e(W1,Ahe),e(Ahe,pqo),e(W1,uqo),e(W1,iV),e(iV,_qo),e(W1,bqo),e(N,vqo),e(N,Q1),e(Q1,Lhe),e(Lhe,Fqo),e(Q1,Tqo),e(Q1,dV),e(dV,Mqo),e(Q1,Eqo),e(N,Cqo),e(N,H1),e(H1,yhe),e(yhe,wqo),e(H1,Aqo),e(H1,cV),e(cV,Lqo),e(H1,yqo),e(N,xqo),e(N,U1),e(U1,xhe),e(xhe,$qo),e(U1,kqo),e(U1,fV),e(fV,Sqo),e(U1,Rqo),e(N,Pqo),e(N,J1),e(J1,$he),e($he,Bqo),e(J1,Iqo),e(J1,mV),e(mV,Nqo),e(J1,qqo),e(N,jqo),e(N,Y1),e(Y1,khe),e(khe,Dqo),e(Y1,Gqo),e(Y1,gV),e(gV,Oqo),e(Y1,Vqo),e(N,Xqo),e(N,K1),e(K1,She),e(She,zqo),e(K1,Wqo),e(K1,hV),e(hV,Qqo),e(K1,Hqo),e(N,Uqo),e(N,Z1),e(Z1,Rhe),e(Rhe,Jqo),e(Z1,Yqo),e(Z1,pV),e(pV,Kqo),e(Z1,Zqo),e(N,ejo),e(N,eb),e(eb,Phe),e(Phe,ojo),e(eb,rjo),e(eb,uV),e(uV,tjo),e(eb,ajo),e(N,njo),e(N,ob),e(ob,Bhe),e(Bhe,sjo),e(ob,ljo),e(ob,_V),e(_V,ijo),e(ob,djo),e(N,cjo),e(N,rb),e(rb,Ihe),e(Ihe,fjo),e(rb,mjo),e(rb,bV),e(bV,gjo),e(rb,hjo),e(N,pjo),e(N,tb),e(tb,Nhe),e(Nhe,ujo),e(tb,_jo),e(tb,vV),e(vV,bjo),e(tb,vjo),e(N,Fjo),e(N,ab),e(ab,qhe),e(qhe,Tjo),e(ab,Mjo),e(ab,FV),e(FV,Ejo),e(ab,Cjo),e(N,wjo),e(N,nb),e(nb,jhe),e(jhe,Ajo),e(nb,Ljo),e(nb,TV),e(TV,yjo),e(nb,xjo),e(N,$jo),e(N,sb),e(sb,Dhe),e(Dhe,kjo),e(sb,Sjo),e(sb,MV),e(MV,Rjo),e(sb,Pjo),e(N,Bjo),e(N,lb),e(lb,Ghe),e(Ghe,Ijo),e(lb,Njo),e(lb,EV),e(EV,qjo),e(lb,jjo),e(N,Djo),e(N,ib),e(ib,Ohe),e(Ohe,Gjo),e(ib,Ojo),e(ib,CV),e(CV,Vjo),e(ib,Xjo),e(N,zjo),e(N,db),e(db,Vhe),e(Vhe,Wjo),e(db,Qjo),e(db,wV),e(wV,Hjo),e(db,Ujo),e(N,Jjo),e(N,cb),e(cb,Xhe),e(Xhe,Yjo),e(cb,Kjo),e(cb,AV),e(AV,Zjo),e(cb,eDo),e(N,oDo),e(N,fb),e(fb,zhe),e(zhe,rDo),e(fb,tDo),e(fb,LV),e(LV,aDo),e(fb,nDo),e(N,sDo),e(N,mb),e(mb,Whe),e(Whe,lDo),e(mb,iDo),e(mb,yV),e(yV,dDo),e(mb,cDo),e(N,fDo),e(N,gb),e(gb,Qhe),e(Qhe,mDo),e(gb,gDo),e(gb,xV),e(xV,hDo),e(gb,pDo),e(oo,uDo),e(oo,hb),e(hb,_Do),e(hb,Hhe),e(Hhe,bDo),e(hb,vDo),e(hb,Uhe),e(Uhe,FDo),e(oo,TDo),M(pb,oo,null),b(f,jGe,_),b(f,Ki,_),e(Ki,ub),e(ub,Jhe),M(wy,Jhe,null),e(Ki,MDo),e(Ki,Yhe),e(Yhe,EDo),b(f,DGe,_),b(f,Bo,_),M(Ay,Bo,null),e(Bo,CDo),e(Bo,Zi),e(Zi,wDo),e(Zi,$V),e($V,ADo),e(Zi,LDo),e(Zi,kV),e(kV,yDo),e(Zi,xDo),e(Bo,$Do),e(Bo,Ly),e(Ly,kDo),e(Ly,Khe),e(Khe,SDo),e(Ly,RDo),e(Bo,PDo),e(Bo,ft),M(yy,ft,null),e(ft,BDo),e(ft,Zhe),e(Zhe,IDo),e(ft,NDo),e(ft,ed),e(ed,qDo),e(ed,epe),e(epe,jDo),e(ed,DDo),e(ed,SV),e(SV,GDo),e(ed,ODo),e(ft,VDo),M(_b,ft,null),e(Bo,XDo),e(Bo,ro),M(xy,ro,null),e(ro,zDo),e(ro,ope),e(ope,WDo),e(ro,QDo),e(ro,qa),e(qa,HDo),e(qa,rpe),e(rpe,UDo),e(qa,JDo),e(qa,tpe),e(tpe,YDo),e(qa,KDo),e(qa,ape),e(ape,ZDo),e(qa,eGo),e(ro,oGo),e(ro,Z),e(Z,bb),e(bb,npe),e(npe,rGo),e(bb,tGo),e(bb,RV),e(RV,aGo),e(bb,nGo),e(Z,sGo),e(Z,vb),e(vb,spe),e(spe,lGo),e(vb,iGo),e(vb,PV),e(PV,dGo),e(vb,cGo),e(Z,fGo),e(Z,Fb),e(Fb,lpe),e(lpe,mGo),e(Fb,gGo),e(Fb,BV),e(BV,hGo),e(Fb,pGo),e(Z,uGo),e(Z,Tb),e(Tb,ipe),e(ipe,_Go),e(Tb,bGo),e(Tb,IV),e(IV,vGo),e(Tb,FGo),e(Z,TGo),e(Z,Mb),e(Mb,dpe),e(dpe,MGo),e(Mb,EGo),e(Mb,NV),e(NV,CGo),e(Mb,wGo),e(Z,AGo),e(Z,Eb),e(Eb,cpe),e(cpe,LGo),e(Eb,yGo),e(Eb,qV),e(qV,xGo),e(Eb,$Go),e(Z,kGo),e(Z,Cb),e(Cb,fpe),e(fpe,SGo),e(Cb,RGo),e(Cb,jV),e(jV,PGo),e(Cb,BGo),e(Z,IGo),e(Z,wb),e(wb,mpe),e(mpe,NGo),e(wb,qGo),e(wb,DV),e(DV,jGo),e(wb,DGo),e(Z,GGo),e(Z,Ab),e(Ab,gpe),e(gpe,OGo),e(Ab,VGo),e(Ab,GV),e(GV,XGo),e(Ab,zGo),e(Z,WGo),e(Z,Lb),e(Lb,hpe),e(hpe,QGo),e(Lb,HGo),e(Lb,OV),e(OV,UGo),e(Lb,JGo),e(Z,YGo),e(Z,yb),e(yb,ppe),e(ppe,KGo),e(yb,ZGo),e(yb,VV),e(VV,eOo),e(yb,oOo),e(Z,rOo),e(Z,xb),e(xb,upe),e(upe,tOo),e(xb,aOo),e(xb,XV),e(XV,nOo),e(xb,sOo),e(Z,lOo),e(Z,$b),e($b,_pe),e(_pe,iOo),e($b,dOo),e($b,zV),e(zV,cOo),e($b,fOo),e(Z,mOo),e(Z,kb),e(kb,bpe),e(bpe,gOo),e(kb,hOo),e(kb,WV),e(WV,pOo),e(kb,uOo),e(Z,_Oo),e(Z,Sb),e(Sb,vpe),e(vpe,bOo),e(Sb,vOo),e(Sb,QV),e(QV,FOo),e(Sb,TOo),e(Z,MOo),e(Z,Rb),e(Rb,Fpe),e(Fpe,EOo),e(Rb,COo),e(Rb,HV),e(HV,wOo),e(Rb,AOo),e(Z,LOo),e(Z,Pb),e(Pb,Tpe),e(Tpe,yOo),e(Pb,xOo),e(Pb,UV),e(UV,$Oo),e(Pb,kOo),e(Z,SOo),e(Z,Bb),e(Bb,Mpe),e(Mpe,ROo),e(Bb,POo),e(Bb,JV),e(JV,BOo),e(Bb,IOo),e(Z,NOo),e(Z,Ib),e(Ib,Epe),e(Epe,qOo),e(Ib,jOo),e(Ib,YV),e(YV,DOo),e(Ib,GOo),e(Z,OOo),e(Z,Nb),e(Nb,Cpe),e(Cpe,VOo),e(Nb,XOo),e(Nb,KV),e(KV,zOo),e(Nb,WOo),e(Z,QOo),e(Z,qb),e(qb,wpe),e(wpe,HOo),e(qb,UOo),e(qb,ZV),e(ZV,JOo),e(qb,YOo),e(Z,KOo),e(Z,jb),e(jb,Ape),e(Ape,ZOo),e(jb,eVo),e(jb,eX),e(eX,oVo),e(jb,rVo),e(Z,tVo),e(Z,Db),e(Db,Lpe),e(Lpe,aVo),e(Db,nVo),e(Db,oX),e(oX,sVo),e(Db,lVo),e(Z,iVo),e(Z,Gb),e(Gb,ype),e(ype,dVo),e(Gb,cVo),e(Gb,rX),e(rX,fVo),e(Gb,mVo),e(Z,gVo),e(Z,Ob),e(Ob,xpe),e(xpe,hVo),e(Ob,pVo),e(Ob,tX),e(tX,uVo),e(Ob,_Vo),e(Z,bVo),e(Z,Vb),e(Vb,$pe),e($pe,vVo),e(Vb,FVo),e(Vb,aX),e(aX,TVo),e(Vb,MVo),e(Z,EVo),e(Z,Xb),e(Xb,kpe),e(kpe,CVo),e(Xb,wVo),e(Xb,nX),e(nX,AVo),e(Xb,LVo),e(Z,yVo),e(Z,zb),e(zb,Spe),e(Spe,xVo),e(zb,$Vo),e(zb,sX),e(sX,kVo),e(zb,SVo),e(Z,RVo),e(Z,Wb),e(Wb,Rpe),e(Rpe,PVo),e(Wb,BVo),e(Wb,lX),e(lX,IVo),e(Wb,NVo),e(ro,qVo),e(ro,Qb),e(Qb,jVo),e(Qb,Ppe),e(Ppe,DVo),e(Qb,GVo),e(Qb,Bpe),e(Bpe,OVo),e(ro,VVo),M(Hb,ro,null),b(f,GGe,_),b(f,od,_),e(od,Ub),e(Ub,Ipe),M($y,Ipe,null),e(od,XVo),e(od,Npe),e(Npe,zVo),b(f,OGe,_),b(f,Io,_),M(ky,Io,null),e(Io,WVo),e(Io,rd),e(rd,QVo),e(rd,iX),e(iX,HVo),e(rd,UVo),e(rd,dX),e(dX,JVo),e(rd,YVo),e(Io,KVo),e(Io,Sy),e(Sy,ZVo),e(Sy,qpe),e(qpe,eXo),e(Sy,oXo),e(Io,rXo),e(Io,mt),M(Ry,mt,null),e(mt,tXo),e(mt,jpe),e(jpe,aXo),e(mt,nXo),e(mt,td),e(td,sXo),e(td,Dpe),e(Dpe,lXo),e(td,iXo),e(td,cX),e(cX,dXo),e(td,cXo),e(mt,fXo),M(Jb,mt,null),e(Io,mXo),e(Io,to),M(Py,to,null),e(to,gXo),e(to,Gpe),e(Gpe,hXo),e(to,pXo),e(to,ja),e(ja,uXo),e(ja,Ope),e(Ope,_Xo),e(ja,bXo),e(ja,Vpe),e(Vpe,vXo),e(ja,FXo),e(ja,Xpe),e(Xpe,TXo),e(ja,MXo),e(to,EXo),e(to,Zr),e(Zr,Yb),e(Yb,zpe),e(zpe,CXo),e(Yb,wXo),e(Yb,fX),e(fX,AXo),e(Yb,LXo),e(Zr,yXo),e(Zr,Kb),e(Kb,Wpe),e(Wpe,xXo),e(Kb,$Xo),e(Kb,mX),e(mX,kXo),e(Kb,SXo),e(Zr,RXo),e(Zr,Zb),e(Zb,Qpe),e(Qpe,PXo),e(Zb,BXo),e(Zb,gX),e(gX,IXo),e(Zb,NXo),e(Zr,qXo),e(Zr,ev),e(ev,Hpe),e(Hpe,jXo),e(ev,DXo),e(ev,hX),e(hX,GXo),e(ev,OXo),e(Zr,VXo),e(Zr,ov),e(ov,Upe),e(Upe,XXo),e(ov,zXo),e(ov,pX),e(pX,WXo),e(ov,QXo),e(to,HXo),e(to,rv),e(rv,UXo),e(rv,Jpe),e(Jpe,JXo),e(rv,YXo),e(rv,Ype),e(Ype,KXo),e(to,ZXo),M(tv,to,null),b(f,VGe,_),b(f,ad,_),e(ad,av),e(av,Kpe),M(By,Kpe,null),e(ad,ezo),e(ad,Zpe),e(Zpe,ozo),b(f,XGe,_),b(f,No,_),M(Iy,No,null),e(No,rzo),e(No,nd),e(nd,tzo),e(nd,uX),e(uX,azo),e(nd,nzo),e(nd,_X),e(_X,szo),e(nd,lzo),e(No,izo),e(No,Ny),e(Ny,dzo),e(Ny,eue),e(eue,czo),e(Ny,fzo),e(No,mzo),e(No,gt),M(qy,gt,null),e(gt,gzo),e(gt,oue),e(oue,hzo),e(gt,pzo),e(gt,sd),e(sd,uzo),e(sd,rue),e(rue,_zo),e(sd,bzo),e(sd,bX),e(bX,vzo),e(sd,Fzo),e(gt,Tzo),M(nv,gt,null),e(No,Mzo),e(No,ao),M(jy,ao,null),e(ao,Ezo),e(ao,tue),e(tue,Czo),e(ao,wzo),e(ao,Da),e(Da,Azo),e(Da,aue),e(aue,Lzo),e(Da,yzo),e(Da,nue),e(nue,xzo),e(Da,$zo),e(Da,sue),e(sue,kzo),e(Da,Szo),e(ao,Rzo),e(ao,H),e(H,sv),e(sv,lue),e(lue,Pzo),e(sv,Bzo),e(sv,vX),e(vX,Izo),e(sv,Nzo),e(H,qzo),e(H,lv),e(lv,iue),e(iue,jzo),e(lv,Dzo),e(lv,FX),e(FX,Gzo),e(lv,Ozo),e(H,Vzo),e(H,iv),e(iv,due),e(due,Xzo),e(iv,zzo),e(iv,TX),e(TX,Wzo),e(iv,Qzo),e(H,Hzo),e(H,dv),e(dv,cue),e(cue,Uzo),e(dv,Jzo),e(dv,MX),e(MX,Yzo),e(dv,Kzo),e(H,Zzo),e(H,cv),e(cv,fue),e(fue,eWo),e(cv,oWo),e(cv,EX),e(EX,rWo),e(cv,tWo),e(H,aWo),e(H,fv),e(fv,mue),e(mue,nWo),e(fv,sWo),e(fv,CX),e(CX,lWo),e(fv,iWo),e(H,dWo),e(H,mv),e(mv,gue),e(gue,cWo),e(mv,fWo),e(mv,wX),e(wX,mWo),e(mv,gWo),e(H,hWo),e(H,gv),e(gv,hue),e(hue,pWo),e(gv,uWo),e(gv,AX),e(AX,_Wo),e(gv,bWo),e(H,vWo),e(H,hv),e(hv,pue),e(pue,FWo),e(hv,TWo),e(hv,LX),e(LX,MWo),e(hv,EWo),e(H,CWo),e(H,pv),e(pv,uue),e(uue,wWo),e(pv,AWo),e(pv,yX),e(yX,LWo),e(pv,yWo),e(H,xWo),e(H,uv),e(uv,_ue),e(_ue,$Wo),e(uv,kWo),e(uv,xX),e(xX,SWo),e(uv,RWo),e(H,PWo),e(H,_v),e(_v,bue),e(bue,BWo),e(_v,IWo),e(_v,$X),e($X,NWo),e(_v,qWo),e(H,jWo),e(H,bv),e(bv,vue),e(vue,DWo),e(bv,GWo),e(bv,kX),e(kX,OWo),e(bv,VWo),e(H,XWo),e(H,vv),e(vv,Fue),e(Fue,zWo),e(vv,WWo),e(vv,SX),e(SX,QWo),e(vv,HWo),e(H,UWo),e(H,Fv),e(Fv,Tue),e(Tue,JWo),e(Fv,YWo),e(Fv,RX),e(RX,KWo),e(Fv,ZWo),e(H,eQo),e(H,Tv),e(Tv,Mue),e(Mue,oQo),e(Tv,rQo),e(Tv,PX),e(PX,tQo),e(Tv,aQo),e(H,nQo),e(H,Mv),e(Mv,Eue),e(Eue,sQo),e(Mv,lQo),e(Mv,BX),e(BX,iQo),e(Mv,dQo),e(H,cQo),e(H,Ev),e(Ev,Cue),e(Cue,fQo),e(Ev,mQo),e(Ev,IX),e(IX,gQo),e(Ev,hQo),e(H,pQo),e(H,Cv),e(Cv,wue),e(wue,uQo),e(Cv,_Qo),e(Cv,NX),e(NX,bQo),e(Cv,vQo),e(H,FQo),e(H,wv),e(wv,Aue),e(Aue,TQo),e(wv,MQo),e(wv,qX),e(qX,EQo),e(wv,CQo),e(H,wQo),e(H,Av),e(Av,Lue),e(Lue,AQo),e(Av,LQo),e(Av,jX),e(jX,yQo),e(Av,xQo),e(H,$Qo),e(H,Lv),e(Lv,yue),e(yue,kQo),e(Lv,SQo),e(Lv,DX),e(DX,RQo),e(Lv,PQo),e(H,BQo),e(H,yv),e(yv,xue),e(xue,IQo),e(yv,NQo),e(yv,GX),e(GX,qQo),e(yv,jQo),e(H,DQo),e(H,xv),e(xv,$ue),e($ue,GQo),e(xv,OQo),e(xv,OX),e(OX,VQo),e(xv,XQo),e(H,zQo),e(H,$v),e($v,kue),e(kue,WQo),e($v,QQo),e($v,VX),e(VX,HQo),e($v,UQo),e(H,JQo),e(H,kv),e(kv,Sue),e(Sue,YQo),e(kv,KQo),e(kv,XX),e(XX,ZQo),e(kv,eHo),e(H,oHo),e(H,Sv),e(Sv,Rue),e(Rue,rHo),e(Sv,tHo),e(Sv,zX),e(zX,aHo),e(Sv,nHo),e(H,sHo),e(H,Rv),e(Rv,Pue),e(Pue,lHo),e(Rv,iHo),e(Rv,WX),e(WX,dHo),e(Rv,cHo),e(H,fHo),e(H,Pv),e(Pv,Bue),e(Bue,mHo),e(Pv,gHo),e(Pv,QX),e(QX,hHo),e(Pv,pHo),e(H,uHo),e(H,Bv),e(Bv,Iue),e(Iue,_Ho),e(Bv,bHo),e(Bv,HX),e(HX,vHo),e(Bv,FHo),e(H,THo),e(H,Iv),e(Iv,Nue),e(Nue,MHo),e(Iv,EHo),e(Iv,UX),e(UX,CHo),e(Iv,wHo),e(H,AHo),e(H,Nv),e(Nv,que),e(que,LHo),e(Nv,yHo),e(Nv,JX),e(JX,xHo),e(Nv,$Ho),e(H,kHo),e(H,qv),e(qv,jue),e(jue,SHo),e(qv,RHo),e(qv,YX),e(YX,PHo),e(qv,BHo),e(H,IHo),e(H,jv),e(jv,Due),e(Due,NHo),e(jv,qHo),e(jv,KX),e(KX,jHo),e(jv,DHo),e(H,GHo),e(H,Dv),e(Dv,Gue),e(Gue,OHo),e(Dv,VHo),e(Dv,ZX),e(ZX,XHo),e(Dv,zHo),e(ao,WHo),e(ao,Gv),e(Gv,QHo),e(Gv,Oue),e(Oue,HHo),e(Gv,UHo),e(Gv,Vue),e(Vue,JHo),e(ao,YHo),M(Ov,ao,null),b(f,zGe,_),b(f,ld,_),e(ld,Vv),e(Vv,Xue),M(Dy,Xue,null),e(ld,KHo),e(ld,zue),e(zue,ZHo),b(f,WGe,_),b(f,qo,_),M(Gy,qo,null),e(qo,eUo),e(qo,id),e(id,oUo),e(id,ez),e(ez,rUo),e(id,tUo),e(id,oz),e(oz,aUo),e(id,nUo),e(qo,sUo),e(qo,Oy),e(Oy,lUo),e(Oy,Wue),e(Wue,iUo),e(Oy,dUo),e(qo,cUo),e(qo,ht),M(Vy,ht,null),e(ht,fUo),e(ht,Que),e(Que,mUo),e(ht,gUo),e(ht,dd),e(dd,hUo),e(dd,Hue),e(Hue,pUo),e(dd,uUo),e(dd,rz),e(rz,_Uo),e(dd,bUo),e(ht,vUo),M(Xv,ht,null),e(qo,FUo),e(qo,no),M(Xy,no,null),e(no,TUo),e(no,Uue),e(Uue,MUo),e(no,EUo),e(no,Ga),e(Ga,CUo),e(Ga,Jue),e(Jue,wUo),e(Ga,AUo),e(Ga,Yue),e(Yue,LUo),e(Ga,yUo),e(Ga,Kue),e(Kue,xUo),e(Ga,$Uo),e(no,kUo),e(no,V),e(V,zv),e(zv,Zue),e(Zue,SUo),e(zv,RUo),e(zv,tz),e(tz,PUo),e(zv,BUo),e(V,IUo),e(V,Wv),e(Wv,e_e),e(e_e,NUo),e(Wv,qUo),e(Wv,az),e(az,jUo),e(Wv,DUo),e(V,GUo),e(V,Qv),e(Qv,o_e),e(o_e,OUo),e(Qv,VUo),e(Qv,nz),e(nz,XUo),e(Qv,zUo),e(V,WUo),e(V,Hv),e(Hv,r_e),e(r_e,QUo),e(Hv,HUo),e(Hv,sz),e(sz,UUo),e(Hv,JUo),e(V,YUo),e(V,Uv),e(Uv,t_e),e(t_e,KUo),e(Uv,ZUo),e(Uv,lz),e(lz,eJo),e(Uv,oJo),e(V,rJo),e(V,Jv),e(Jv,a_e),e(a_e,tJo),e(Jv,aJo),e(Jv,iz),e(iz,nJo),e(Jv,sJo),e(V,lJo),e(V,Yv),e(Yv,n_e),e(n_e,iJo),e(Yv,dJo),e(Yv,dz),e(dz,cJo),e(Yv,fJo),e(V,mJo),e(V,Kv),e(Kv,s_e),e(s_e,gJo),e(Kv,hJo),e(Kv,cz),e(cz,pJo),e(Kv,uJo),e(V,_Jo),e(V,Zv),e(Zv,l_e),e(l_e,bJo),e(Zv,vJo),e(Zv,fz),e(fz,FJo),e(Zv,TJo),e(V,MJo),e(V,eF),e(eF,i_e),e(i_e,EJo),e(eF,CJo),e(eF,mz),e(mz,wJo),e(eF,AJo),e(V,LJo),e(V,oF),e(oF,d_e),e(d_e,yJo),e(oF,xJo),e(oF,gz),e(gz,$Jo),e(oF,kJo),e(V,SJo),e(V,rF),e(rF,c_e),e(c_e,RJo),e(rF,PJo),e(rF,hz),e(hz,BJo),e(rF,IJo),e(V,NJo),e(V,tF),e(tF,f_e),e(f_e,qJo),e(tF,jJo),e(tF,pz),e(pz,DJo),e(tF,GJo),e(V,OJo),e(V,aF),e(aF,m_e),e(m_e,VJo),e(aF,XJo),e(aF,uz),e(uz,zJo),e(aF,WJo),e(V,QJo),e(V,nF),e(nF,g_e),e(g_e,HJo),e(nF,UJo),e(nF,_z),e(_z,JJo),e(nF,YJo),e(V,KJo),e(V,sF),e(sF,h_e),e(h_e,ZJo),e(sF,eYo),e(sF,bz),e(bz,oYo),e(sF,rYo),e(V,tYo),e(V,lF),e(lF,p_e),e(p_e,aYo),e(lF,nYo),e(lF,vz),e(vz,sYo),e(lF,lYo),e(V,iYo),e(V,iF),e(iF,u_e),e(u_e,dYo),e(iF,cYo),e(iF,Fz),e(Fz,fYo),e(iF,mYo),e(V,gYo),e(V,dF),e(dF,__e),e(__e,hYo),e(dF,pYo),e(dF,Tz),e(Tz,uYo),e(dF,_Yo),e(V,bYo),e(V,cF),e(cF,b_e),e(b_e,vYo),e(cF,FYo),e(cF,Mz),e(Mz,TYo),e(cF,MYo),e(V,EYo),e(V,fF),e(fF,v_e),e(v_e,CYo),e(fF,wYo),e(fF,Ez),e(Ez,AYo),e(fF,LYo),e(V,yYo),e(V,mF),e(mF,F_e),e(F_e,xYo),e(mF,$Yo),e(mF,Cz),e(Cz,kYo),e(mF,SYo),e(V,RYo),e(V,gF),e(gF,T_e),e(T_e,PYo),e(gF,BYo),e(gF,wz),e(wz,IYo),e(gF,NYo),e(V,qYo),e(V,hF),e(hF,M_e),e(M_e,jYo),e(hF,DYo),e(hF,Az),e(Az,GYo),e(hF,OYo),e(V,VYo),e(V,pF),e(pF,E_e),e(E_e,XYo),e(pF,zYo),e(pF,Lz),e(Lz,WYo),e(pF,QYo),e(V,HYo),e(V,uF),e(uF,C_e),e(C_e,UYo),e(uF,JYo),e(uF,yz),e(yz,YYo),e(uF,KYo),e(V,ZYo),e(V,_F),e(_F,w_e),e(w_e,eKo),e(_F,oKo),e(_F,xz),e(xz,rKo),e(_F,tKo),e(V,aKo),e(V,bF),e(bF,A_e),e(A_e,nKo),e(bF,sKo),e(bF,$z),e($z,lKo),e(bF,iKo),e(V,dKo),e(V,vF),e(vF,L_e),e(L_e,cKo),e(vF,fKo),e(vF,kz),e(kz,mKo),e(vF,gKo),e(V,hKo),e(V,FF),e(FF,y_e),e(y_e,pKo),e(FF,uKo),e(FF,Sz),e(Sz,_Ko),e(FF,bKo),e(V,vKo),e(V,TF),e(TF,x_e),e(x_e,FKo),e(TF,TKo),e(TF,Rz),e(Rz,MKo),e(TF,EKo),e(V,CKo),e(V,MF),e(MF,$_e),e($_e,wKo),e(MF,AKo),e(MF,Pz),e(Pz,LKo),e(MF,yKo),e(V,xKo),e(V,EF),e(EF,k_e),e(k_e,$Ko),e(EF,kKo),e(EF,Bz),e(Bz,SKo),e(EF,RKo),e(V,PKo),e(V,CF),e(CF,S_e),e(S_e,BKo),e(CF,IKo),e(CF,Iz),e(Iz,NKo),e(CF,qKo),e(V,jKo),e(V,wF),e(wF,R_e),e(R_e,DKo),e(wF,GKo),e(wF,Nz),e(Nz,OKo),e(wF,VKo),e(V,XKo),e(V,AF),e(AF,P_e),e(P_e,zKo),e(AF,WKo),e(AF,qz),e(qz,QKo),e(AF,HKo),e(V,UKo),e(V,LF),e(LF,B_e),e(B_e,JKo),e(LF,YKo),e(LF,jz),e(jz,KKo),e(LF,ZKo),e(V,eZo),e(V,yF),e(yF,I_e),e(I_e,oZo),e(yF,rZo),e(yF,Dz),e(Dz,tZo),e(yF,aZo),e(V,nZo),e(V,xF),e(xF,N_e),e(N_e,sZo),e(xF,lZo),e(xF,Gz),e(Gz,iZo),e(xF,dZo),e(V,cZo),e(V,$F),e($F,q_e),e(q_e,fZo),e($F,mZo),e($F,Oz),e(Oz,gZo),e($F,hZo),e(no,pZo),e(no,kF),e(kF,uZo),e(kF,j_e),e(j_e,_Zo),e(kF,bZo),e(kF,D_e),e(D_e,vZo),e(no,FZo),M(SF,no,null),b(f,QGe,_),b(f,cd,_),e(cd,RF),e(RF,G_e),M(zy,G_e,null),e(cd,TZo),e(cd,O_e),e(O_e,MZo),b(f,HGe,_),b(f,jo,_),M(Wy,jo,null),e(jo,EZo),e(jo,fd),e(fd,CZo),e(fd,Vz),e(Vz,wZo),e(fd,AZo),e(fd,Xz),e(Xz,LZo),e(fd,yZo),e(jo,xZo),e(jo,Qy),e(Qy,$Zo),e(Qy,V_e),e(V_e,kZo),e(Qy,SZo),e(jo,RZo),e(jo,pt),M(Hy,pt,null),e(pt,PZo),e(pt,X_e),e(X_e,BZo),e(pt,IZo),e(pt,md),e(md,NZo),e(md,z_e),e(z_e,qZo),e(md,jZo),e(md,zz),e(zz,DZo),e(md,GZo),e(pt,OZo),M(PF,pt,null),e(jo,VZo),e(jo,so),M(Uy,so,null),e(so,XZo),e(so,W_e),e(W_e,zZo),e(so,WZo),e(so,Oa),e(Oa,QZo),e(Oa,Q_e),e(Q_e,HZo),e(Oa,UZo),e(Oa,H_e),e(H_e,JZo),e(Oa,YZo),e(Oa,U_e),e(U_e,KZo),e(Oa,ZZo),e(so,eer),e(so,J_e),e(J_e,BF),e(BF,Y_e),e(Y_e,oer),e(BF,rer),e(BF,Wz),e(Wz,ter),e(BF,aer),e(so,ner),e(so,IF),e(IF,ser),e(IF,K_e),e(K_e,ler),e(IF,ier),e(IF,Z_e),e(Z_e,der),e(so,cer),M(NF,so,null),b(f,UGe,_),b(f,gd,_),e(gd,qF),e(qF,e7e),M(Jy,e7e,null),e(gd,fer),e(gd,o7e),e(o7e,mer),b(f,JGe,_),b(f,Do,_),M(Yy,Do,null),e(Do,ger),e(Do,hd),e(hd,her),e(hd,Qz),e(Qz,per),e(hd,uer),e(hd,Hz),e(Hz,_er),e(hd,ber),e(Do,ver),e(Do,Ky),e(Ky,Fer),e(Ky,r7e),e(r7e,Ter),e(Ky,Mer),e(Do,Eer),e(Do,ut),M(Zy,ut,null),e(ut,Cer),e(ut,t7e),e(t7e,wer),e(ut,Aer),e(ut,pd),e(pd,Ler),e(pd,a7e),e(a7e,yer),e(pd,xer),e(pd,Uz),e(Uz,$er),e(pd,ker),e(ut,Ser),M(jF,ut,null),e(Do,Rer),e(Do,lo),M(e8,lo,null),e(lo,Per),e(lo,n7e),e(n7e,Ber),e(lo,Ier),e(lo,Va),e(Va,Ner),e(Va,s7e),e(s7e,qer),e(Va,jer),e(Va,l7e),e(l7e,Der),e(Va,Ger),e(Va,i7e),e(i7e,Oer),e(Va,Ver),e(lo,Xer),e(lo,_e),e(_e,DF),e(DF,d7e),e(d7e,zer),e(DF,Wer),e(DF,Jz),e(Jz,Qer),e(DF,Her),e(_e,Uer),e(_e,GF),e(GF,c7e),e(c7e,Jer),e(GF,Yer),e(GF,Yz),e(Yz,Ker),e(GF,Zer),e(_e,eor),e(_e,OF),e(OF,f7e),e(f7e,oor),e(OF,ror),e(OF,Kz),e(Kz,tor),e(OF,aor),e(_e,nor),e(_e,VF),e(VF,m7e),e(m7e,sor),e(VF,lor),e(VF,Zz),e(Zz,ior),e(VF,dor),e(_e,cor),e(_e,Os),e(Os,g7e),e(g7e,mor),e(Os,gor),e(Os,eW),e(eW,hor),e(Os,por),e(Os,oW),e(oW,uor),e(Os,_or),e(_e,bor),e(_e,XF),e(XF,h7e),e(h7e,vor),e(XF,For),e(XF,rW),e(rW,Tor),e(XF,Mor),e(_e,Eor),e(_e,Vs),e(Vs,p7e),e(p7e,Cor),e(Vs,wor),e(Vs,tW),e(tW,Aor),e(Vs,Lor),e(Vs,aW),e(aW,yor),e(Vs,xor),e(_e,$or),e(_e,zF),e(zF,u7e),e(u7e,kor),e(zF,Sor),e(zF,nW),e(nW,Ror),e(zF,Por),e(_e,Bor),e(_e,_t),e(_t,_7e),e(_7e,Ior),e(_t,Nor),e(_t,sW),e(sW,qor),e(_t,jor),e(_t,lW),e(lW,Dor),e(_t,Gor),e(_t,iW),e(iW,Oor),e(_t,Vor),e(_e,Xor),e(_e,WF),e(WF,b7e),e(b7e,zor),e(WF,Wor),e(WF,dW),e(dW,Qor),e(WF,Hor),e(_e,Uor),e(_e,QF),e(QF,v7e),e(v7e,Jor),e(QF,Yor),e(QF,cW),e(cW,Kor),e(QF,Zor),e(_e,err),e(_e,HF),e(HF,F7e),e(F7e,orr),e(HF,rrr),e(HF,fW),e(fW,trr),e(HF,arr),e(_e,nrr),e(_e,UF),e(UF,T7e),e(T7e,srr),e(UF,lrr),e(UF,mW),e(mW,irr),e(UF,drr),e(_e,crr),e(_e,JF),e(JF,M7e),e(M7e,frr),e(JF,mrr),e(JF,gW),e(gW,grr),e(JF,hrr),e(_e,prr),e(_e,YF),e(YF,E7e),e(E7e,urr),e(YF,_rr),e(YF,hW),e(hW,brr),e(YF,vrr),e(_e,Frr),e(_e,KF),e(KF,C7e),e(C7e,Trr),e(KF,Mrr),e(KF,pW),e(pW,Err),e(KF,Crr),e(lo,wrr),e(lo,ZF),e(ZF,Arr),e(ZF,w7e),e(w7e,Lrr),e(ZF,yrr),e(ZF,A7e),e(A7e,xrr),e(lo,$rr),M(eT,lo,null),b(f,YGe,_),b(f,ud,_),e(ud,oT),e(oT,L7e),M(o8,L7e,null),e(ud,krr),e(ud,y7e),e(y7e,Srr),b(f,KGe,_),b(f,Go,_),M(r8,Go,null),e(Go,Rrr),e(Go,_d),e(_d,Prr),e(_d,uW),e(uW,Brr),e(_d,Irr),e(_d,_W),e(_W,Nrr),e(_d,qrr),e(Go,jrr),e(Go,t8),e(t8,Drr),e(t8,x7e),e(x7e,Grr),e(t8,Orr),e(Go,Vrr),e(Go,bt),M(a8,bt,null),e(bt,Xrr),e(bt,$7e),e($7e,zrr),e(bt,Wrr),e(bt,bd),e(bd,Qrr),e(bd,k7e),e(k7e,Hrr),e(bd,Urr),e(bd,bW),e(bW,Jrr),e(bd,Yrr),e(bt,Krr),M(rT,bt,null),e(Go,Zrr),e(Go,io),M(n8,io,null),e(io,etr),e(io,S7e),e(S7e,otr),e(io,rtr),e(io,Xa),e(Xa,ttr),e(Xa,R7e),e(R7e,atr),e(Xa,ntr),e(Xa,P7e),e(P7e,str),e(Xa,ltr),e(Xa,B7e),e(B7e,itr),e(Xa,dtr),e(io,ctr),e(io,I7e),e(I7e,tT),e(tT,N7e),e(N7e,ftr),e(tT,mtr),e(tT,vW),e(vW,gtr),e(tT,htr),e(io,ptr),e(io,aT),e(aT,utr),e(aT,q7e),e(q7e,_tr),e(aT,btr),e(aT,j7e),e(j7e,vtr),e(io,Ftr),M(nT,io,null),b(f,ZGe,_),b(f,vd,_),e(vd,sT),e(sT,D7e),M(s8,D7e,null),e(vd,Ttr),e(vd,G7e),e(G7e,Mtr),b(f,eOe,_),b(f,Oo,_),M(l8,Oo,null),e(Oo,Etr),e(Oo,Fd),e(Fd,Ctr),e(Fd,FW),e(FW,wtr),e(Fd,Atr),e(Fd,TW),e(TW,Ltr),e(Fd,ytr),e(Oo,xtr),e(Oo,i8),e(i8,$tr),e(i8,O7e),e(O7e,ktr),e(i8,Str),e(Oo,Rtr),e(Oo,vt),M(d8,vt,null),e(vt,Ptr),e(vt,V7e),e(V7e,Btr),e(vt,Itr),e(vt,Td),e(Td,Ntr),e(Td,X7e),e(X7e,qtr),e(Td,jtr),e(Td,MW),e(MW,Dtr),e(Td,Gtr),e(vt,Otr),M(lT,vt,null),e(Oo,Vtr),e(Oo,co),M(c8,co,null),e(co,Xtr),e(co,z7e),e(z7e,ztr),e(co,Wtr),e(co,za),e(za,Qtr),e(za,W7e),e(W7e,Htr),e(za,Utr),e(za,Q7e),e(Q7e,Jtr),e(za,Ytr),e(za,H7e),e(H7e,Ktr),e(za,Ztr),e(co,ear),e(co,U7e),e(U7e,iT),e(iT,J7e),e(J7e,oar),e(iT,rar),e(iT,EW),e(EW,tar),e(iT,aar),e(co,nar),e(co,dT),e(dT,sar),e(dT,Y7e),e(Y7e,lar),e(dT,iar),e(dT,K7e),e(K7e,dar),e(co,car),M(cT,co,null),b(f,oOe,_),b(f,Md,_),e(Md,fT),e(fT,Z7e),M(f8,Z7e,null),e(Md,far),e(Md,e2e),e(e2e,mar),b(f,rOe,_),b(f,Vo,_),M(m8,Vo,null),e(Vo,gar),e(Vo,Ed),e(Ed,har),e(Ed,CW),e(CW,par),e(Ed,uar),e(Ed,wW),e(wW,_ar),e(Ed,bar),e(Vo,Far),e(Vo,g8),e(g8,Tar),e(g8,o2e),e(o2e,Mar),e(g8,Ear),e(Vo,Car),e(Vo,Ft),M(h8,Ft,null),e(Ft,war),e(Ft,r2e),e(r2e,Aar),e(Ft,Lar),e(Ft,Cd),e(Cd,yar),e(Cd,t2e),e(t2e,xar),e(Cd,$ar),e(Cd,AW),e(AW,kar),e(Cd,Sar),e(Ft,Rar),M(mT,Ft,null),e(Vo,Par),e(Vo,fo),M(p8,fo,null),e(fo,Bar),e(fo,a2e),e(a2e,Iar),e(fo,Nar),e(fo,Wa),e(Wa,qar),e(Wa,n2e),e(n2e,jar),e(Wa,Dar),e(Wa,s2e),e(s2e,Gar),e(Wa,Oar),e(Wa,l2e),e(l2e,Var),e(Wa,Xar),e(fo,zar),e(fo,Pe),e(Pe,gT),e(gT,i2e),e(i2e,War),e(gT,Qar),e(gT,LW),e(LW,Har),e(gT,Uar),e(Pe,Jar),e(Pe,hT),e(hT,d2e),e(d2e,Yar),e(hT,Kar),e(hT,yW),e(yW,Zar),e(hT,enr),e(Pe,onr),e(Pe,pT),e(pT,c2e),e(c2e,rnr),e(pT,tnr),e(pT,xW),e(xW,anr),e(pT,nnr),e(Pe,snr),e(Pe,uT),e(uT,f2e),e(f2e,lnr),e(uT,inr),e(uT,$W),e($W,dnr),e(uT,cnr),e(Pe,fnr),e(Pe,_T),e(_T,m2e),e(m2e,mnr),e(_T,gnr),e(_T,kW),e(kW,hnr),e(_T,pnr),e(Pe,unr),e(Pe,bT),e(bT,g2e),e(g2e,_nr),e(bT,bnr),e(bT,SW),e(SW,vnr),e(bT,Fnr),e(Pe,Tnr),e(Pe,vT),e(vT,h2e),e(h2e,Mnr),e(vT,Enr),e(vT,RW),e(RW,Cnr),e(vT,wnr),e(Pe,Anr),e(Pe,FT),e(FT,p2e),e(p2e,Lnr),e(FT,ynr),e(FT,PW),e(PW,xnr),e(FT,$nr),e(Pe,knr),e(Pe,TT),e(TT,u2e),e(u2e,Snr),e(TT,Rnr),e(TT,BW),e(BW,Pnr),e(TT,Bnr),e(fo,Inr),e(fo,MT),e(MT,Nnr),e(MT,_2e),e(_2e,qnr),e(MT,jnr),e(MT,b2e),e(b2e,Dnr),e(fo,Gnr),M(ET,fo,null),b(f,tOe,_),b(f,wd,_),e(wd,CT),e(CT,v2e),M(u8,v2e,null),e(wd,Onr),e(wd,F2e),e(F2e,Vnr),b(f,aOe,_),b(f,Xo,_),M(_8,Xo,null),e(Xo,Xnr),e(Xo,Ad),e(Ad,znr),e(Ad,IW),e(IW,Wnr),e(Ad,Qnr),e(Ad,NW),e(NW,Hnr),e(Ad,Unr),e(Xo,Jnr),e(Xo,b8),e(b8,Ynr),e(b8,T2e),e(T2e,Knr),e(b8,Znr),e(Xo,esr),e(Xo,Tt),M(v8,Tt,null),e(Tt,osr),e(Tt,M2e),e(M2e,rsr),e(Tt,tsr),e(Tt,Ld),e(Ld,asr),e(Ld,E2e),e(E2e,nsr),e(Ld,ssr),e(Ld,qW),e(qW,lsr),e(Ld,isr),e(Tt,dsr),M(wT,Tt,null),e(Xo,csr),e(Xo,mo),M(F8,mo,null),e(mo,fsr),e(mo,C2e),e(C2e,msr),e(mo,gsr),e(mo,Qa),e(Qa,hsr),e(Qa,w2e),e(w2e,psr),e(Qa,usr),e(Qa,A2e),e(A2e,_sr),e(Qa,bsr),e(Qa,L2e),e(L2e,vsr),e(Qa,Fsr),e(mo,Tsr),e(mo,et),e(et,AT),e(AT,y2e),e(y2e,Msr),e(AT,Esr),e(AT,jW),e(jW,Csr),e(AT,wsr),e(et,Asr),e(et,LT),e(LT,x2e),e(x2e,Lsr),e(LT,ysr),e(LT,DW),e(DW,xsr),e(LT,$sr),e(et,ksr),e(et,yT),e(yT,$2e),e($2e,Ssr),e(yT,Rsr),e(yT,GW),e(GW,Psr),e(yT,Bsr),e(et,Isr),e(et,xT),e(xT,k2e),e(k2e,Nsr),e(xT,qsr),e(xT,OW),e(OW,jsr),e(xT,Dsr),e(et,Gsr),e(et,$T),e($T,S2e),e(S2e,Osr),e($T,Vsr),e($T,VW),e(VW,Xsr),e($T,zsr),e(mo,Wsr),e(mo,kT),e(kT,Qsr),e(kT,R2e),e(R2e,Hsr),e(kT,Usr),e(kT,P2e),e(P2e,Jsr),e(mo,Ysr),M(ST,mo,null),b(f,nOe,_),b(f,yd,_),e(yd,RT),e(RT,B2e),M(T8,B2e,null),e(yd,Ksr),e(yd,I2e),e(I2e,Zsr),b(f,sOe,_),b(f,zo,_),M(M8,zo,null),e(zo,elr),e(zo,xd),e(xd,olr),e(xd,XW),e(XW,rlr),e(xd,tlr),e(xd,zW),e(zW,alr),e(xd,nlr),e(zo,slr),e(zo,E8),e(E8,llr),e(E8,N2e),e(N2e,ilr),e(E8,dlr),e(zo,clr),e(zo,Mt),M(C8,Mt,null),e(Mt,flr),e(Mt,q2e),e(q2e,mlr),e(Mt,glr),e(Mt,$d),e($d,hlr),e($d,j2e),e(j2e,plr),e($d,ulr),e($d,WW),e(WW,_lr),e($d,blr),e(Mt,vlr),M(PT,Mt,null),e(zo,Flr),e(zo,go),M(w8,go,null),e(go,Tlr),e(go,D2e),e(D2e,Mlr),e(go,Elr),e(go,Ha),e(Ha,Clr),e(Ha,G2e),e(G2e,wlr),e(Ha,Alr),e(Ha,O2e),e(O2e,Llr),e(Ha,ylr),e(Ha,V2e),e(V2e,xlr),e(Ha,$lr),e(go,klr),e(go,Le),e(Le,BT),e(BT,X2e),e(X2e,Slr),e(BT,Rlr),e(BT,QW),e(QW,Plr),e(BT,Blr),e(Le,Ilr),e(Le,IT),e(IT,z2e),e(z2e,Nlr),e(IT,qlr),e(IT,HW),e(HW,jlr),e(IT,Dlr),e(Le,Glr),e(Le,NT),e(NT,W2e),e(W2e,Olr),e(NT,Vlr),e(NT,UW),e(UW,Xlr),e(NT,zlr),e(Le,Wlr),e(Le,qT),e(qT,Q2e),e(Q2e,Qlr),e(qT,Hlr),e(qT,JW),e(JW,Ulr),e(qT,Jlr),e(Le,Ylr),e(Le,jT),e(jT,H2e),e(H2e,Klr),e(jT,Zlr),e(jT,YW),e(YW,eir),e(jT,oir),e(Le,rir),e(Le,DT),e(DT,U2e),e(U2e,tir),e(DT,air),e(DT,KW),e(KW,nir),e(DT,sir),e(Le,lir),e(Le,GT),e(GT,J2e),e(J2e,iir),e(GT,dir),e(GT,ZW),e(ZW,cir),e(GT,fir),e(Le,mir),e(Le,OT),e(OT,Y2e),e(Y2e,gir),e(OT,hir),e(OT,eQ),e(eQ,pir),e(OT,uir),e(Le,_ir),e(Le,VT),e(VT,K2e),e(K2e,bir),e(VT,vir),e(VT,oQ),e(oQ,Fir),e(VT,Tir),e(Le,Mir),e(Le,XT),e(XT,Z2e),e(Z2e,Eir),e(XT,Cir),e(XT,rQ),e(rQ,wir),e(XT,Air),e(go,Lir),e(go,zT),e(zT,yir),e(zT,e1e),e(e1e,xir),e(zT,$ir),e(zT,o1e),e(o1e,kir),e(go,Sir),M(WT,go,null),b(f,lOe,_),b(f,kd,_),e(kd,QT),e(QT,r1e),M(A8,r1e,null),e(kd,Rir),e(kd,t1e),e(t1e,Pir),b(f,iOe,_),b(f,Wo,_),M(L8,Wo,null),e(Wo,Bir),e(Wo,Sd),e(Sd,Iir),e(Sd,tQ),e(tQ,Nir),e(Sd,qir),e(Sd,aQ),e(aQ,jir),e(Sd,Dir),e(Wo,Gir),e(Wo,y8),e(y8,Oir),e(y8,a1e),e(a1e,Vir),e(y8,Xir),e(Wo,zir),e(Wo,Et),M(x8,Et,null),e(Et,Wir),e(Et,n1e),e(n1e,Qir),e(Et,Hir),e(Et,Rd),e(Rd,Uir),e(Rd,s1e),e(s1e,Jir),e(Rd,Yir),e(Rd,nQ),e(nQ,Kir),e(Rd,Zir),e(Et,edr),M(HT,Et,null),e(Wo,odr),e(Wo,ho),M($8,ho,null),e(ho,rdr),e(ho,l1e),e(l1e,tdr),e(ho,adr),e(ho,Ua),e(Ua,ndr),e(Ua,i1e),e(i1e,sdr),e(Ua,ldr),e(Ua,d1e),e(d1e,idr),e(Ua,ddr),e(Ua,c1e),e(c1e,cdr),e(Ua,fdr),e(ho,mdr),e(ho,k8),e(k8,UT),e(UT,f1e),e(f1e,gdr),e(UT,hdr),e(UT,sQ),e(sQ,pdr),e(UT,udr),e(k8,_dr),e(k8,JT),e(JT,m1e),e(m1e,bdr),e(JT,vdr),e(JT,lQ),e(lQ,Fdr),e(JT,Tdr),e(ho,Mdr),e(ho,YT),e(YT,Edr),e(YT,g1e),e(g1e,Cdr),e(YT,wdr),e(YT,h1e),e(h1e,Adr),e(ho,Ldr),M(KT,ho,null),b(f,dOe,_),b(f,Pd,_),e(Pd,ZT),e(ZT,p1e),M(S8,p1e,null),e(Pd,ydr),e(Pd,u1e),e(u1e,xdr),b(f,cOe,_),b(f,Qo,_),M(R8,Qo,null),e(Qo,$dr),e(Qo,Bd),e(Bd,kdr),e(Bd,iQ),e(iQ,Sdr),e(Bd,Rdr),e(Bd,dQ),e(dQ,Pdr),e(Bd,Bdr),e(Qo,Idr),e(Qo,P8),e(P8,Ndr),e(P8,_1e),e(_1e,qdr),e(P8,jdr),e(Qo,Ddr),e(Qo,Ct),M(B8,Ct,null),e(Ct,Gdr),e(Ct,b1e),e(b1e,Odr),e(Ct,Vdr),e(Ct,Id),e(Id,Xdr),e(Id,v1e),e(v1e,zdr),e(Id,Wdr),e(Id,cQ),e(cQ,Qdr),e(Id,Hdr),e(Ct,Udr),M(eM,Ct,null),e(Qo,Jdr),e(Qo,po),M(I8,po,null),e(po,Ydr),e(po,F1e),e(F1e,Kdr),e(po,Zdr),e(po,Ja),e(Ja,ecr),e(Ja,T1e),e(T1e,ocr),e(Ja,rcr),e(Ja,M1e),e(M1e,tcr),e(Ja,acr),e(Ja,E1e),e(E1e,ncr),e(Ja,scr),e(po,lcr),e(po,ot),e(ot,oM),e(oM,C1e),e(C1e,icr),e(oM,dcr),e(oM,fQ),e(fQ,ccr),e(oM,fcr),e(ot,mcr),e(ot,rM),e(rM,w1e),e(w1e,gcr),e(rM,hcr),e(rM,mQ),e(mQ,pcr),e(rM,ucr),e(ot,_cr),e(ot,tM),e(tM,A1e),e(A1e,bcr),e(tM,vcr),e(tM,gQ),e(gQ,Fcr),e(tM,Tcr),e(ot,Mcr),e(ot,aM),e(aM,L1e),e(L1e,Ecr),e(aM,Ccr),e(aM,hQ),e(hQ,wcr),e(aM,Acr),e(ot,Lcr),e(ot,nM),e(nM,y1e),e(y1e,ycr),e(nM,xcr),e(nM,pQ),e(pQ,$cr),e(nM,kcr),e(po,Scr),e(po,sM),e(sM,Rcr),e(sM,x1e),e(x1e,Pcr),e(sM,Bcr),e(sM,$1e),e($1e,Icr),e(po,Ncr),M(lM,po,null),b(f,fOe,_),b(f,Nd,_),e(Nd,iM),e(iM,k1e),M(N8,k1e,null),e(Nd,qcr),e(Nd,S1e),e(S1e,jcr),b(f,mOe,_),b(f,Ho,_),M(q8,Ho,null),e(Ho,Dcr),e(Ho,qd),e(qd,Gcr),e(qd,uQ),e(uQ,Ocr),e(qd,Vcr),e(qd,_Q),e(_Q,Xcr),e(qd,zcr),e(Ho,Wcr),e(Ho,j8),e(j8,Qcr),e(j8,R1e),e(R1e,Hcr),e(j8,Ucr),e(Ho,Jcr),e(Ho,wt),M(D8,wt,null),e(wt,Ycr),e(wt,P1e),e(P1e,Kcr),e(wt,Zcr),e(wt,jd),e(jd,efr),e(jd,B1e),e(B1e,ofr),e(jd,rfr),e(jd,bQ),e(bQ,tfr),e(jd,afr),e(wt,nfr),M(dM,wt,null),e(Ho,sfr),e(Ho,uo),M(G8,uo,null),e(uo,lfr),e(uo,I1e),e(I1e,ifr),e(uo,dfr),e(uo,Ya),e(Ya,cfr),e(Ya,N1e),e(N1e,ffr),e(Ya,mfr),e(Ya,q1e),e(q1e,gfr),e(Ya,hfr),e(Ya,j1e),e(j1e,pfr),e(Ya,ufr),e(uo,_fr),e(uo,Dd),e(Dd,cM),e(cM,D1e),e(D1e,bfr),e(cM,vfr),e(cM,vQ),e(vQ,Ffr),e(cM,Tfr),e(Dd,Mfr),e(Dd,fM),e(fM,G1e),e(G1e,Efr),e(fM,Cfr),e(fM,FQ),e(FQ,wfr),e(fM,Afr),e(Dd,Lfr),e(Dd,mM),e(mM,O1e),e(O1e,yfr),e(mM,xfr),e(mM,TQ),e(TQ,$fr),e(mM,kfr),e(uo,Sfr),e(uo,gM),e(gM,Rfr),e(gM,V1e),e(V1e,Pfr),e(gM,Bfr),e(gM,X1e),e(X1e,Ifr),e(uo,Nfr),M(hM,uo,null),b(f,gOe,_),b(f,Gd,_),e(Gd,pM),e(pM,z1e),M(O8,z1e,null),e(Gd,qfr),e(Gd,W1e),e(W1e,jfr),b(f,hOe,_),b(f,Uo,_),M(V8,Uo,null),e(Uo,Dfr),e(Uo,Od),e(Od,Gfr),e(Od,MQ),e(MQ,Ofr),e(Od,Vfr),e(Od,EQ),e(EQ,Xfr),e(Od,zfr),e(Uo,Wfr),e(Uo,X8),e(X8,Qfr),e(X8,Q1e),e(Q1e,Hfr),e(X8,Ufr),e(Uo,Jfr),e(Uo,At),M(z8,At,null),e(At,Yfr),e(At,H1e),e(H1e,Kfr),e(At,Zfr),e(At,Vd),e(Vd,emr),e(Vd,U1e),e(U1e,omr),e(Vd,rmr),e(Vd,CQ),e(CQ,tmr),e(Vd,amr),e(At,nmr),M(uM,At,null),e(Uo,smr),e(Uo,_o),M(W8,_o,null),e(_o,lmr),e(_o,J1e),e(J1e,imr),e(_o,dmr),e(_o,Ka),e(Ka,cmr),e(Ka,Y1e),e(Y1e,fmr),e(Ka,mmr),e(Ka,K1e),e(K1e,gmr),e(Ka,hmr),e(Ka,Z1e),e(Z1e,pmr),e(Ka,umr),e(_o,_mr),e(_o,Q8),e(Q8,_M),e(_M,ebe),e(ebe,bmr),e(_M,vmr),e(_M,wQ),e(wQ,Fmr),e(_M,Tmr),e(Q8,Mmr),e(Q8,bM),e(bM,obe),e(obe,Emr),e(bM,Cmr),e(bM,AQ),e(AQ,wmr),e(bM,Amr),e(_o,Lmr),e(_o,vM),e(vM,ymr),e(vM,rbe),e(rbe,xmr),e(vM,$mr),e(vM,tbe),e(tbe,kmr),e(_o,Smr),M(FM,_o,null),b(f,pOe,_),b(f,Xd,_),e(Xd,TM),e(TM,abe),M(H8,abe,null),e(Xd,Rmr),e(Xd,nbe),e(nbe,Pmr),b(f,uOe,_),b(f,Jo,_),M(U8,Jo,null),e(Jo,Bmr),e(Jo,zd),e(zd,Imr),e(zd,LQ),e(LQ,Nmr),e(zd,qmr),e(zd,yQ),e(yQ,jmr),e(zd,Dmr),e(Jo,Gmr),e(Jo,J8),e(J8,Omr),e(J8,sbe),e(sbe,Vmr),e(J8,Xmr),e(Jo,zmr),e(Jo,Lt),M(Y8,Lt,null),e(Lt,Wmr),e(Lt,lbe),e(lbe,Qmr),e(Lt,Hmr),e(Lt,Wd),e(Wd,Umr),e(Wd,ibe),e(ibe,Jmr),e(Wd,Ymr),e(Wd,xQ),e(xQ,Kmr),e(Wd,Zmr),e(Lt,egr),M(MM,Lt,null),e(Jo,ogr),e(Jo,bo),M(K8,bo,null),e(bo,rgr),e(bo,dbe),e(dbe,tgr),e(bo,agr),e(bo,Za),e(Za,ngr),e(Za,cbe),e(cbe,sgr),e(Za,lgr),e(Za,fbe),e(fbe,igr),e(Za,dgr),e(Za,mbe),e(mbe,cgr),e(Za,fgr),e(bo,mgr),e(bo,gbe),e(gbe,EM),e(EM,hbe),e(hbe,ggr),e(EM,hgr),e(EM,$Q),e($Q,pgr),e(EM,ugr),e(bo,_gr),e(bo,CM),e(CM,bgr),e(CM,pbe),e(pbe,vgr),e(CM,Fgr),e(CM,ube),e(ube,Tgr),e(bo,Mgr),M(wM,bo,null),b(f,_Oe,_),b(f,Qd,_),e(Qd,AM),e(AM,_be),M(Z8,_be,null),e(Qd,Egr),e(Qd,bbe),e(bbe,Cgr),b(f,bOe,_),b(f,Yo,_),M(e9,Yo,null),e(Yo,wgr),e(Yo,Hd),e(Hd,Agr),e(Hd,kQ),e(kQ,Lgr),e(Hd,ygr),e(Hd,SQ),e(SQ,xgr),e(Hd,$gr),e(Yo,kgr),e(Yo,o9),e(o9,Sgr),e(o9,vbe),e(vbe,Rgr),e(o9,Pgr),e(Yo,Bgr),e(Yo,yt),M(r9,yt,null),e(yt,Igr),e(yt,Fbe),e(Fbe,Ngr),e(yt,qgr),e(yt,Ud),e(Ud,jgr),e(Ud,Tbe),e(Tbe,Dgr),e(Ud,Ggr),e(Ud,RQ),e(RQ,Ogr),e(Ud,Vgr),e(yt,Xgr),M(LM,yt,null),e(Yo,zgr),e(Yo,vo),M(t9,vo,null),e(vo,Wgr),e(vo,Mbe),e(Mbe,Qgr),e(vo,Hgr),e(vo,en),e(en,Ugr),e(en,Ebe),e(Ebe,Jgr),e(en,Ygr),e(en,Cbe),e(Cbe,Kgr),e(en,Zgr),e(en,wbe),e(wbe,ehr),e(en,ohr),e(vo,rhr),e(vo,on),e(on,yM),e(yM,Abe),e(Abe,thr),e(yM,ahr),e(yM,PQ),e(PQ,nhr),e(yM,shr),e(on,lhr),e(on,xM),e(xM,Lbe),e(Lbe,ihr),e(xM,dhr),e(xM,BQ),e(BQ,chr),e(xM,fhr),e(on,mhr),e(on,$M),e($M,ybe),e(ybe,ghr),e($M,hhr),e($M,IQ),e(IQ,phr),e($M,uhr),e(on,_hr),e(on,kM),e(kM,xbe),e(xbe,bhr),e(kM,vhr),e(kM,NQ),e(NQ,Fhr),e(kM,Thr),e(vo,Mhr),e(vo,SM),e(SM,Ehr),e(SM,$be),e($be,Chr),e(SM,whr),e(SM,kbe),e(kbe,Ahr),e(vo,Lhr),M(RM,vo,null),b(f,vOe,_),b(f,Jd,_),e(Jd,PM),e(PM,Sbe),M(a9,Sbe,null),e(Jd,yhr),e(Jd,Rbe),e(Rbe,xhr),b(f,FOe,_),b(f,Ko,_),M(n9,Ko,null),e(Ko,$hr),e(Ko,Yd),e(Yd,khr),e(Yd,qQ),e(qQ,Shr),e(Yd,Rhr),e(Yd,jQ),e(jQ,Phr),e(Yd,Bhr),e(Ko,Ihr),e(Ko,s9),e(s9,Nhr),e(s9,Pbe),e(Pbe,qhr),e(s9,jhr),e(Ko,Dhr),e(Ko,xt),M(l9,xt,null),e(xt,Ghr),e(xt,Bbe),e(Bbe,Ohr),e(xt,Vhr),e(xt,Kd),e(Kd,Xhr),e(Kd,Ibe),e(Ibe,zhr),e(Kd,Whr),e(Kd,DQ),e(DQ,Qhr),e(Kd,Hhr),e(xt,Uhr),M(BM,xt,null),e(Ko,Jhr),e(Ko,Fo),M(i9,Fo,null),e(Fo,Yhr),e(Fo,Nbe),e(Nbe,Khr),e(Fo,Zhr),e(Fo,rn),e(rn,epr),e(rn,qbe),e(qbe,opr),e(rn,rpr),e(rn,jbe),e(jbe,tpr),e(rn,apr),e(rn,Dbe),e(Dbe,npr),e(rn,spr),e(Fo,lpr),e(Fo,Gbe),e(Gbe,IM),e(IM,Obe),e(Obe,ipr),e(IM,dpr),e(IM,GQ),e(GQ,cpr),e(IM,fpr),e(Fo,mpr),e(Fo,NM),e(NM,gpr),e(NM,Vbe),e(Vbe,hpr),e(NM,ppr),e(NM,Xbe),e(Xbe,upr),e(Fo,_pr),M(qM,Fo,null),b(f,TOe,_),b(f,Zd,_),e(Zd,jM),e(jM,zbe),M(d9,zbe,null),e(Zd,bpr),e(Zd,Wbe),e(Wbe,vpr),b(f,MOe,_),b(f,Zo,_),M(c9,Zo,null),e(Zo,Fpr),e(Zo,ec),e(ec,Tpr),e(ec,OQ),e(OQ,Mpr),e(ec,Epr),e(ec,VQ),e(VQ,Cpr),e(ec,wpr),e(Zo,Apr),e(Zo,f9),e(f9,Lpr),e(f9,Qbe),e(Qbe,ypr),e(f9,xpr),e(Zo,$pr),e(Zo,$t),M(m9,$t,null),e($t,kpr),e($t,Hbe),e(Hbe,Spr),e($t,Rpr),e($t,oc),e(oc,Ppr),e(oc,Ube),e(Ube,Bpr),e(oc,Ipr),e(oc,XQ),e(XQ,Npr),e(oc,qpr),e($t,jpr),M(DM,$t,null),e(Zo,Dpr),e(Zo,Lr),M(g9,Lr,null),e(Lr,Gpr),e(Lr,Jbe),e(Jbe,Opr),e(Lr,Vpr),e(Lr,tn),e(tn,Xpr),e(tn,Ybe),e(Ybe,zpr),e(tn,Wpr),e(tn,Kbe),e(Kbe,Qpr),e(tn,Hpr),e(tn,Zbe),e(Zbe,Upr),e(tn,Jpr),e(Lr,Ypr),e(Lr,q),e(q,GM),e(GM,eve),e(eve,Kpr),e(GM,Zpr),e(GM,zQ),e(zQ,eur),e(GM,our),e(q,rur),e(q,OM),e(OM,ove),e(ove,tur),e(OM,aur),e(OM,WQ),e(WQ,nur),e(OM,sur),e(q,lur),e(q,VM),e(VM,rve),e(rve,iur),e(VM,dur),e(VM,QQ),e(QQ,cur),e(VM,fur),e(q,mur),e(q,XM),e(XM,tve),e(tve,gur),e(XM,hur),e(XM,HQ),e(HQ,pur),e(XM,uur),e(q,_ur),e(q,zM),e(zM,ave),e(ave,bur),e(zM,vur),e(zM,UQ),e(UQ,Fur),e(zM,Tur),e(q,Mur),e(q,WM),e(WM,nve),e(nve,Eur),e(WM,Cur),e(WM,JQ),e(JQ,wur),e(WM,Aur),e(q,Lur),e(q,QM),e(QM,sve),e(sve,yur),e(QM,xur),e(QM,YQ),e(YQ,$ur),e(QM,kur),e(q,Sur),e(q,HM),e(HM,lve),e(lve,Rur),e(HM,Pur),e(HM,KQ),e(KQ,Bur),e(HM,Iur),e(q,Nur),e(q,UM),e(UM,ive),e(ive,qur),e(UM,jur),e(UM,ZQ),e(ZQ,Dur),e(UM,Gur),e(q,Our),e(q,JM),e(JM,dve),e(dve,Vur),e(JM,Xur),e(JM,eH),e(eH,zur),e(JM,Wur),e(q,Qur),e(q,YM),e(YM,cve),e(cve,Hur),e(YM,Uur),e(YM,oH),e(oH,Jur),e(YM,Yur),e(q,Kur),e(q,KM),e(KM,fve),e(fve,Zur),e(KM,e_r),e(KM,rH),e(rH,o_r),e(KM,r_r),e(q,t_r),e(q,ZM),e(ZM,mve),e(mve,a_r),e(ZM,n_r),e(ZM,tH),e(tH,s_r),e(ZM,l_r),e(q,i_r),e(q,eE),e(eE,gve),e(gve,d_r),e(eE,c_r),e(eE,aH),e(aH,f_r),e(eE,m_r),e(q,g_r),e(q,oE),e(oE,hve),e(hve,h_r),e(oE,p_r),e(oE,nH),e(nH,u_r),e(oE,__r),e(q,b_r),e(q,rE),e(rE,pve),e(pve,v_r),e(rE,F_r),e(rE,sH),e(sH,T_r),e(rE,M_r),e(q,E_r),e(q,tE),e(tE,uve),e(uve,C_r),e(tE,w_r),e(tE,lH),e(lH,A_r),e(tE,L_r),e(q,y_r),e(q,Xs),e(Xs,_ve),e(_ve,x_r),e(Xs,$_r),e(Xs,iH),e(iH,k_r),e(Xs,S_r),e(Xs,dH),e(dH,R_r),e(Xs,P_r),e(q,B_r),e(q,aE),e(aE,bve),e(bve,I_r),e(aE,N_r),e(aE,cH),e(cH,q_r),e(aE,j_r),e(q,D_r),e(q,nE),e(nE,vve),e(vve,G_r),e(nE,O_r),e(nE,fH),e(fH,V_r),e(nE,X_r),e(q,z_r),e(q,sE),e(sE,Fve),e(Fve,W_r),e(sE,Q_r),e(sE,mH),e(mH,H_r),e(sE,U_r),e(q,J_r),e(q,lE),e(lE,Tve),e(Tve,Y_r),e(lE,K_r),e(lE,gH),e(gH,Z_r),e(lE,e7r),e(q,o7r),e(q,iE),e(iE,Mve),e(Mve,r7r),e(iE,t7r),e(iE,hH),e(hH,a7r),e(iE,n7r),e(q,s7r),e(q,dE),e(dE,Eve),e(Eve,l7r),e(dE,i7r),e(dE,pH),e(pH,d7r),e(dE,c7r),e(q,f7r),e(q,cE),e(cE,Cve),e(Cve,m7r),e(cE,g7r),e(cE,uH),e(uH,h7r),e(cE,p7r),e(q,u7r),e(q,fE),e(fE,wve),e(wve,_7r),e(fE,b7r),e(fE,_H),e(_H,v7r),e(fE,F7r),e(q,T7r),e(q,mE),e(mE,Ave),e(Ave,M7r),e(mE,E7r),e(mE,bH),e(bH,C7r),e(mE,w7r),e(q,A7r),e(q,gE),e(gE,Lve),e(Lve,L7r),e(gE,y7r),e(gE,vH),e(vH,x7r),e(gE,$7r),e(q,k7r),e(q,hE),e(hE,yve),e(yve,S7r),e(hE,R7r),e(hE,FH),e(FH,P7r),e(hE,B7r),e(q,I7r),e(q,pE),e(pE,xve),e(xve,N7r),e(pE,q7r),e(pE,TH),e(TH,j7r),e(pE,D7r),e(q,G7r),e(q,uE),e(uE,$ve),e($ve,O7r),e(uE,V7r),e(uE,MH),e(MH,X7r),e(uE,z7r),e(q,W7r),e(q,_E),e(_E,kve),e(kve,Q7r),e(_E,H7r),e(_E,EH),e(EH,U7r),e(_E,J7r),e(q,Y7r),e(q,bE),e(bE,Sve),e(Sve,K7r),e(bE,Z7r),e(bE,CH),e(CH,e2r),e(bE,o2r),e(q,r2r),e(q,vE),e(vE,Rve),e(Rve,t2r),e(vE,a2r),e(vE,wH),e(wH,n2r),e(vE,s2r),e(q,l2r),e(q,FE),e(FE,Pve),e(Pve,i2r),e(FE,d2r),e(FE,AH),e(AH,c2r),e(FE,f2r),e(q,m2r),e(q,TE),e(TE,Bve),e(Bve,g2r),e(TE,h2r),e(TE,LH),e(LH,p2r),e(TE,u2r),e(q,_2r),e(q,ME),e(ME,Ive),e(Ive,b2r),e(ME,v2r),e(ME,yH),e(yH,F2r),e(ME,T2r),e(q,M2r),e(q,EE),e(EE,Nve),e(Nve,E2r),e(EE,C2r),e(EE,xH),e(xH,w2r),e(EE,A2r),e(q,L2r),e(q,CE),e(CE,qve),e(qve,y2r),e(CE,x2r),e(CE,$H),e($H,$2r),e(CE,k2r),e(q,S2r),e(q,wE),e(wE,jve),e(jve,R2r),e(wE,P2r),e(wE,kH),e(kH,B2r),e(wE,I2r),e(q,N2r),e(q,AE),e(AE,Dve),e(Dve,q2r),e(AE,j2r),e(AE,SH),e(SH,D2r),e(AE,G2r),e(q,O2r),e(q,LE),e(LE,Gve),e(Gve,V2r),e(LE,X2r),e(LE,RH),e(RH,z2r),e(LE,W2r),e(q,Q2r),e(q,yE),e(yE,Ove),e(Ove,H2r),e(yE,U2r),e(yE,PH),e(PH,J2r),e(yE,Y2r),e(q,K2r),e(q,xE),e(xE,Vve),e(Vve,Z2r),e(xE,e1r),e(xE,BH),e(BH,o1r),e(xE,r1r),e(q,t1r),e(q,$E),e($E,Xve),e(Xve,a1r),e($E,n1r),e($E,IH),e(IH,s1r),e($E,l1r),e(q,i1r),e(q,kE),e(kE,zve),e(zve,d1r),e(kE,c1r),e(kE,NH),e(NH,f1r),e(kE,m1r),e(q,g1r),e(q,SE),e(SE,Wve),e(Wve,h1r),e(SE,p1r),e(SE,qH),e(qH,u1r),e(SE,_1r),e(Lr,b1r),M(RE,Lr,null),b(f,EOe,_),b(f,rc,_),e(rc,PE),e(PE,Qve),M(h9,Qve,null),e(rc,v1r),e(rc,Hve),e(Hve,F1r),b(f,COe,_),b(f,er,_),M(p9,er,null),e(er,T1r),e(er,tc),e(tc,M1r),e(tc,jH),e(jH,E1r),e(tc,C1r),e(tc,DH),e(DH,w1r),e(tc,A1r),e(er,L1r),e(er,u9),e(u9,y1r),e(u9,Uve),e(Uve,x1r),e(u9,$1r),e(er,k1r),e(er,kt),M(_9,kt,null),e(kt,S1r),e(kt,Jve),e(Jve,R1r),e(kt,P1r),e(kt,ac),e(ac,B1r),e(ac,Yve),e(Yve,I1r),e(ac,N1r),e(ac,GH),e(GH,q1r),e(ac,j1r),e(kt,D1r),M(BE,kt,null),e(er,G1r),e(er,yr),M(b9,yr,null),e(yr,O1r),e(yr,Kve),e(Kve,V1r),e(yr,X1r),e(yr,an),e(an,z1r),e(an,Zve),e(Zve,W1r),e(an,Q1r),e(an,eFe),e(eFe,H1r),e(an,U1r),e(an,oFe),e(oFe,J1r),e(an,Y1r),e(yr,K1r),e(yr,se),e(se,IE),e(IE,rFe),e(rFe,Z1r),e(IE,ebr),e(IE,OH),e(OH,obr),e(IE,rbr),e(se,tbr),e(se,NE),e(NE,tFe),e(tFe,abr),e(NE,nbr),e(NE,VH),e(VH,sbr),e(NE,lbr),e(se,ibr),e(se,qE),e(qE,aFe),e(aFe,dbr),e(qE,cbr),e(qE,XH),e(XH,fbr),e(qE,mbr),e(se,gbr),e(se,jE),e(jE,nFe),e(nFe,hbr),e(jE,pbr),e(jE,zH),e(zH,ubr),e(jE,_br),e(se,bbr),e(se,DE),e(DE,sFe),e(sFe,vbr),e(DE,Fbr),e(DE,WH),e(WH,Tbr),e(DE,Mbr),e(se,Ebr),e(se,GE),e(GE,lFe),e(lFe,Cbr),e(GE,wbr),e(GE,QH),e(QH,Abr),e(GE,Lbr),e(se,ybr),e(se,OE),e(OE,iFe),e(iFe,xbr),e(OE,$br),e(OE,HH),e(HH,kbr),e(OE,Sbr),e(se,Rbr),e(se,VE),e(VE,dFe),e(dFe,Pbr),e(VE,Bbr),e(VE,UH),e(UH,Ibr),e(VE,Nbr),e(se,qbr),e(se,XE),e(XE,cFe),e(cFe,jbr),e(XE,Dbr),e(XE,JH),e(JH,Gbr),e(XE,Obr),e(se,Vbr),e(se,zE),e(zE,fFe),e(fFe,Xbr),e(zE,zbr),e(zE,YH),e(YH,Wbr),e(zE,Qbr),e(se,Hbr),e(se,WE),e(WE,mFe),e(mFe,Ubr),e(WE,Jbr),e(WE,KH),e(KH,Ybr),e(WE,Kbr),e(se,Zbr),e(se,QE),e(QE,gFe),e(gFe,evr),e(QE,ovr),e(QE,ZH),e(ZH,rvr),e(QE,tvr),e(se,avr),e(se,HE),e(HE,hFe),e(hFe,nvr),e(HE,svr),e(HE,eU),e(eU,lvr),e(HE,ivr),e(se,dvr),e(se,UE),e(UE,pFe),e(pFe,cvr),e(UE,fvr),e(UE,oU),e(oU,mvr),e(UE,gvr),e(se,hvr),e(se,JE),e(JE,uFe),e(uFe,pvr),e(JE,uvr),e(JE,rU),e(rU,_vr),e(JE,bvr),e(se,vvr),e(se,YE),e(YE,_Fe),e(_Fe,Fvr),e(YE,Tvr),e(YE,tU),e(tU,Mvr),e(YE,Evr),e(se,Cvr),e(se,KE),e(KE,bFe),e(bFe,wvr),e(KE,Avr),e(KE,aU),e(aU,Lvr),e(KE,yvr),e(se,xvr),e(se,ZE),e(ZE,vFe),e(vFe,$vr),e(ZE,kvr),e(ZE,nU),e(nU,Svr),e(ZE,Rvr),e(se,Pvr),e(se,e4),e(e4,FFe),e(FFe,Bvr),e(e4,Ivr),e(e4,sU),e(sU,Nvr),e(e4,qvr),e(se,jvr),e(se,o4),e(o4,TFe),e(TFe,Dvr),e(o4,Gvr),e(o4,lU),e(lU,Ovr),e(o4,Vvr),e(se,Xvr),e(se,r4),e(r4,MFe),e(MFe,zvr),e(r4,Wvr),e(r4,iU),e(iU,Qvr),e(r4,Hvr),e(se,Uvr),e(se,t4),e(t4,EFe),e(EFe,Jvr),e(t4,Yvr),e(t4,dU),e(dU,Kvr),e(t4,Zvr),e(se,eFr),e(se,a4),e(a4,CFe),e(CFe,oFr),e(a4,rFr),e(a4,cU),e(cU,tFr),e(a4,aFr),e(yr,nFr),M(n4,yr,null),b(f,wOe,_),b(f,nc,_),e(nc,s4),e(s4,wFe),M(v9,wFe,null),e(nc,sFr),e(nc,AFe),e(AFe,lFr),b(f,AOe,_),b(f,or,_),M(F9,or,null),e(or,iFr),e(or,sc),e(sc,dFr),e(sc,fU),e(fU,cFr),e(sc,fFr),e(sc,mU),e(mU,mFr),e(sc,gFr),e(or,hFr),e(or,T9),e(T9,pFr),e(T9,LFe),e(LFe,uFr),e(T9,_Fr),e(or,bFr),e(or,St),M(M9,St,null),e(St,vFr),e(St,yFe),e(yFe,FFr),e(St,TFr),e(St,lc),e(lc,MFr),e(lc,xFe),e(xFe,EFr),e(lc,CFr),e(lc,gU),e(gU,wFr),e(lc,AFr),e(St,LFr),M(l4,St,null),e(or,yFr),e(or,xr),M(E9,xr,null),e(xr,xFr),e(xr,$Fe),e($Fe,$Fr),e(xr,kFr),e(xr,nn),e(nn,SFr),e(nn,kFe),e(kFe,RFr),e(nn,PFr),e(nn,SFe),e(SFe,BFr),e(nn,IFr),e(nn,RFe),e(RFe,NFr),e(nn,qFr),e(xr,jFr),e(xr,Me),e(Me,i4),e(i4,PFe),e(PFe,DFr),e(i4,GFr),e(i4,hU),e(hU,OFr),e(i4,VFr),e(Me,XFr),e(Me,d4),e(d4,BFe),e(BFe,zFr),e(d4,WFr),e(d4,pU),e(pU,QFr),e(d4,HFr),e(Me,UFr),e(Me,c4),e(c4,IFe),e(IFe,JFr),e(c4,YFr),e(c4,uU),e(uU,KFr),e(c4,ZFr),e(Me,eTr),e(Me,f4),e(f4,NFe),e(NFe,oTr),e(f4,rTr),e(f4,_U),e(_U,tTr),e(f4,aTr),e(Me,nTr),e(Me,m4),e(m4,qFe),e(qFe,sTr),e(m4,lTr),e(m4,bU),e(bU,iTr),e(m4,dTr),e(Me,cTr),e(Me,g4),e(g4,jFe),e(jFe,fTr),e(g4,mTr),e(g4,vU),e(vU,gTr),e(g4,hTr),e(Me,pTr),e(Me,h4),e(h4,DFe),e(DFe,uTr),e(h4,_Tr),e(h4,FU),e(FU,bTr),e(h4,vTr),e(Me,FTr),e(Me,p4),e(p4,GFe),e(GFe,TTr),e(p4,MTr),e(p4,TU),e(TU,ETr),e(p4,CTr),e(Me,wTr),e(Me,u4),e(u4,OFe),e(OFe,ATr),e(u4,LTr),e(u4,MU),e(MU,yTr),e(u4,xTr),e(Me,$Tr),e(Me,_4),e(_4,VFe),e(VFe,kTr),e(_4,STr),e(_4,EU),e(EU,RTr),e(_4,PTr),e(Me,BTr),e(Me,b4),e(b4,XFe),e(XFe,ITr),e(b4,NTr),e(b4,CU),e(CU,qTr),e(b4,jTr),e(Me,DTr),e(Me,v4),e(v4,zFe),e(zFe,GTr),e(v4,OTr),e(v4,wU),e(wU,VTr),e(v4,XTr),e(Me,zTr),e(Me,F4),e(F4,WFe),e(WFe,WTr),e(F4,QTr),e(F4,AU),e(AU,HTr),e(F4,UTr),e(xr,JTr),M(T4,xr,null),b(f,LOe,_),b(f,ic,_),e(ic,M4),e(M4,QFe),M(C9,QFe,null),e(ic,YTr),e(ic,HFe),e(HFe,KTr),b(f,yOe,_),b(f,rr,_),M(w9,rr,null),e(rr,ZTr),e(rr,dc),e(dc,eMr),e(dc,LU),e(LU,oMr),e(dc,rMr),e(dc,yU),e(yU,tMr),e(dc,aMr),e(rr,nMr),e(rr,A9),e(A9,sMr),e(A9,UFe),e(UFe,lMr),e(A9,iMr),e(rr,dMr),e(rr,Rt),M(L9,Rt,null),e(Rt,cMr),e(Rt,JFe),e(JFe,fMr),e(Rt,mMr),e(Rt,cc),e(cc,gMr),e(cc,YFe),e(YFe,hMr),e(cc,pMr),e(cc,xU),e(xU,uMr),e(cc,_Mr),e(Rt,bMr),M(E4,Rt,null),e(rr,vMr),e(rr,$r),M(y9,$r,null),e($r,FMr),e($r,KFe),e(KFe,TMr),e($r,MMr),e($r,sn),e(sn,EMr),e(sn,ZFe),e(ZFe,CMr),e(sn,wMr),e(sn,eTe),e(eTe,AMr),e(sn,LMr),e(sn,oTe),e(oTe,yMr),e(sn,xMr),e($r,$Mr),e($r,ln),e(ln,C4),e(C4,rTe),e(rTe,kMr),e(C4,SMr),e(C4,$U),e($U,RMr),e(C4,PMr),e(ln,BMr),e(ln,w4),e(w4,tTe),e(tTe,IMr),e(w4,NMr),e(w4,kU),e(kU,qMr),e(w4,jMr),e(ln,DMr),e(ln,A4),e(A4,aTe),e(aTe,GMr),e(A4,OMr),e(A4,SU),e(SU,VMr),e(A4,XMr),e(ln,zMr),e(ln,L4),e(L4,nTe),e(nTe,WMr),e(L4,QMr),e(L4,RU),e(RU,HMr),e(L4,UMr),e($r,JMr),M(y4,$r,null),b(f,xOe,_),b(f,fc,_),e(fc,x4),e(x4,sTe),M(x9,sTe,null),e(fc,YMr),e(fc,lTe),e(lTe,KMr),b(f,$Oe,_),b(f,tr,_),M($9,tr,null),e(tr,ZMr),e(tr,mc),e(mc,eEr),e(mc,PU),e(PU,oEr),e(mc,rEr),e(mc,BU),e(BU,tEr),e(mc,aEr),e(tr,nEr),e(tr,k9),e(k9,sEr),e(k9,iTe),e(iTe,lEr),e(k9,iEr),e(tr,dEr),e(tr,Pt),M(S9,Pt,null),e(Pt,cEr),e(Pt,dTe),e(dTe,fEr),e(Pt,mEr),e(Pt,gc),e(gc,gEr),e(gc,cTe),e(cTe,hEr),e(gc,pEr),e(gc,IU),e(IU,uEr),e(gc,_Er),e(Pt,bEr),M($4,Pt,null),e(tr,vEr),e(tr,kr),M(R9,kr,null),e(kr,FEr),e(kr,fTe),e(fTe,TEr),e(kr,MEr),e(kr,dn),e(dn,EEr),e(dn,mTe),e(mTe,CEr),e(dn,wEr),e(dn,gTe),e(gTe,AEr),e(dn,LEr),e(dn,hTe),e(hTe,yEr),e(dn,xEr),e(kr,$Er),e(kr,ie),e(ie,k4),e(k4,pTe),e(pTe,kEr),e(k4,SEr),e(k4,NU),e(NU,REr),e(k4,PEr),e(ie,BEr),e(ie,S4),e(S4,uTe),e(uTe,IEr),e(S4,NEr),e(S4,qU),e(qU,qEr),e(S4,jEr),e(ie,DEr),e(ie,R4),e(R4,_Te),e(_Te,GEr),e(R4,OEr),e(R4,jU),e(jU,VEr),e(R4,XEr),e(ie,zEr),e(ie,P4),e(P4,bTe),e(bTe,WEr),e(P4,QEr),e(P4,DU),e(DU,HEr),e(P4,UEr),e(ie,JEr),e(ie,B4),e(B4,vTe),e(vTe,YEr),e(B4,KEr),e(B4,GU),e(GU,ZEr),e(B4,e4r),e(ie,o4r),e(ie,I4),e(I4,FTe),e(FTe,r4r),e(I4,t4r),e(I4,OU),e(OU,a4r),e(I4,n4r),e(ie,s4r),e(ie,N4),e(N4,TTe),e(TTe,l4r),e(N4,i4r),e(N4,VU),e(VU,d4r),e(N4,c4r),e(ie,f4r),e(ie,q4),e(q4,MTe),e(MTe,m4r),e(q4,g4r),e(q4,XU),e(XU,h4r),e(q4,p4r),e(ie,u4r),e(ie,j4),e(j4,ETe),e(ETe,_4r),e(j4,b4r),e(j4,zU),e(zU,v4r),e(j4,F4r),e(ie,T4r),e(ie,D4),e(D4,CTe),e(CTe,M4r),e(D4,E4r),e(D4,WU),e(WU,C4r),e(D4,w4r),e(ie,A4r),e(ie,G4),e(G4,wTe),e(wTe,L4r),e(G4,y4r),e(G4,QU),e(QU,x4r),e(G4,$4r),e(ie,k4r),e(ie,O4),e(O4,ATe),e(ATe,S4r),e(O4,R4r),e(O4,HU),e(HU,P4r),e(O4,B4r),e(ie,I4r),e(ie,V4),e(V4,LTe),e(LTe,N4r),e(V4,q4r),e(V4,UU),e(UU,j4r),e(V4,D4r),e(ie,G4r),e(ie,X4),e(X4,yTe),e(yTe,O4r),e(X4,V4r),e(X4,JU),e(JU,X4r),e(X4,z4r),e(ie,W4r),e(ie,z4),e(z4,xTe),e(xTe,Q4r),e(z4,H4r),e(z4,YU),e(YU,U4r),e(z4,J4r),e(ie,Y4r),e(ie,W4),e(W4,$Te),e($Te,K4r),e(W4,Z4r),e(W4,KU),e(KU,eCr),e(W4,oCr),e(ie,rCr),e(ie,Q4),e(Q4,kTe),e(kTe,tCr),e(Q4,aCr),e(Q4,ZU),e(ZU,nCr),e(Q4,sCr),e(ie,lCr),e(ie,H4),e(H4,STe),e(STe,iCr),e(H4,dCr),e(H4,eJ),e(eJ,cCr),e(H4,fCr),e(ie,mCr),e(ie,U4),e(U4,RTe),e(RTe,gCr),e(U4,hCr),e(U4,oJ),e(oJ,pCr),e(U4,uCr),e(ie,_Cr),e(ie,J4),e(J4,PTe),e(PTe,bCr),e(J4,vCr),e(J4,rJ),e(rJ,FCr),e(J4,TCr),e(kr,MCr),M(Y4,kr,null),b(f,kOe,_),b(f,hc,_),e(hc,K4),e(K4,BTe),M(P9,BTe,null),e(hc,ECr),e(hc,ITe),e(ITe,CCr),b(f,SOe,_),b(f,ar,_),M(B9,ar,null),e(ar,wCr),e(ar,pc),e(pc,ACr),e(pc,tJ),e(tJ,LCr),e(pc,yCr),e(pc,aJ),e(aJ,xCr),e(pc,$Cr),e(ar,kCr),e(ar,I9),e(I9,SCr),e(I9,NTe),e(NTe,RCr),e(I9,PCr),e(ar,BCr),e(ar,Bt),M(N9,Bt,null),e(Bt,ICr),e(Bt,qTe),e(qTe,NCr),e(Bt,qCr),e(Bt,uc),e(uc,jCr),e(uc,jTe),e(jTe,DCr),e(uc,GCr),e(uc,nJ),e(nJ,OCr),e(uc,VCr),e(Bt,XCr),M(Z4,Bt,null),e(ar,zCr),e(ar,Sr),M(q9,Sr,null),e(Sr,WCr),e(Sr,DTe),e(DTe,QCr),e(Sr,HCr),e(Sr,cn),e(cn,UCr),e(cn,GTe),e(GTe,JCr),e(cn,YCr),e(cn,OTe),e(OTe,KCr),e(cn,ZCr),e(cn,VTe),e(VTe,e5r),e(cn,o5r),e(Sr,r5r),e(Sr,ye),e(ye,eC),e(eC,XTe),e(XTe,t5r),e(eC,a5r),e(eC,sJ),e(sJ,n5r),e(eC,s5r),e(ye,l5r),e(ye,oC),e(oC,zTe),e(zTe,i5r),e(oC,d5r),e(oC,lJ),e(lJ,c5r),e(oC,f5r),e(ye,m5r),e(ye,rC),e(rC,WTe),e(WTe,g5r),e(rC,h5r),e(rC,iJ),e(iJ,p5r),e(rC,u5r),e(ye,_5r),e(ye,tC),e(tC,QTe),e(QTe,b5r),e(tC,v5r),e(tC,dJ),e(dJ,F5r),e(tC,T5r),e(ye,M5r),e(ye,aC),e(aC,HTe),e(HTe,E5r),e(aC,C5r),e(aC,cJ),e(cJ,w5r),e(aC,A5r),e(ye,L5r),e(ye,nC),e(nC,UTe),e(UTe,y5r),e(nC,x5r),e(nC,fJ),e(fJ,$5r),e(nC,k5r),e(ye,S5r),e(ye,sC),e(sC,JTe),e(JTe,R5r),e(sC,P5r),e(sC,mJ),e(mJ,B5r),e(sC,I5r),e(ye,N5r),e(ye,lC),e(lC,YTe),e(YTe,q5r),e(lC,j5r),e(lC,gJ),e(gJ,D5r),e(lC,G5r),e(ye,O5r),e(ye,iC),e(iC,KTe),e(KTe,V5r),e(iC,X5r),e(iC,hJ),e(hJ,z5r),e(iC,W5r),e(ye,Q5r),e(ye,dC),e(dC,ZTe),e(ZTe,H5r),e(dC,U5r),e(dC,pJ),e(pJ,J5r),e(dC,Y5r),e(Sr,K5r),M(cC,Sr,null),b(f,ROe,_),b(f,_c,_),e(_c,fC),e(fC,eMe),M(j9,eMe,null),e(_c,Z5r),e(_c,oMe),e(oMe,e3r),b(f,POe,_),b(f,nr,_),M(D9,nr,null),e(nr,o3r),e(nr,bc),e(bc,r3r),e(bc,uJ),e(uJ,t3r),e(bc,a3r),e(bc,_J),e(_J,n3r),e(bc,s3r),e(nr,l3r),e(nr,G9),e(G9,i3r),e(G9,rMe),e(rMe,d3r),e(G9,c3r),e(nr,f3r),e(nr,It),M(O9,It,null),e(It,m3r),e(It,tMe),e(tMe,g3r),e(It,h3r),e(It,vc),e(vc,p3r),e(vc,aMe),e(aMe,u3r),e(vc,_3r),e(vc,bJ),e(bJ,b3r),e(vc,v3r),e(It,F3r),M(mC,It,null),e(nr,T3r),e(nr,Rr),M(V9,Rr,null),e(Rr,M3r),e(Rr,nMe),e(nMe,E3r),e(Rr,C3r),e(Rr,fn),e(fn,w3r),e(fn,sMe),e(sMe,A3r),e(fn,L3r),e(fn,lMe),e(lMe,y3r),e(fn,x3r),e(fn,iMe),e(iMe,$3r),e(fn,k3r),e(Rr,S3r),e(Rr,te),e(te,gC),e(gC,dMe),e(dMe,R3r),e(gC,P3r),e(gC,vJ),e(vJ,B3r),e(gC,I3r),e(te,N3r),e(te,hC),e(hC,cMe),e(cMe,q3r),e(hC,j3r),e(hC,FJ),e(FJ,D3r),e(hC,G3r),e(te,O3r),e(te,pC),e(pC,fMe),e(fMe,V3r),e(pC,X3r),e(pC,TJ),e(TJ,z3r),e(pC,W3r),e(te,Q3r),e(te,uC),e(uC,mMe),e(mMe,H3r),e(uC,U3r),e(uC,MJ),e(MJ,J3r),e(uC,Y3r),e(te,K3r),e(te,_C),e(_C,gMe),e(gMe,Z3r),e(_C,e0r),e(_C,EJ),e(EJ,o0r),e(_C,r0r),e(te,t0r),e(te,bC),e(bC,hMe),e(hMe,a0r),e(bC,n0r),e(bC,CJ),e(CJ,s0r),e(bC,l0r),e(te,i0r),e(te,vC),e(vC,pMe),e(pMe,d0r),e(vC,c0r),e(vC,wJ),e(wJ,f0r),e(vC,m0r),e(te,g0r),e(te,FC),e(FC,uMe),e(uMe,h0r),e(FC,p0r),e(FC,AJ),e(AJ,u0r),e(FC,_0r),e(te,b0r),e(te,TC),e(TC,_Me),e(_Me,v0r),e(TC,F0r),e(TC,LJ),e(LJ,T0r),e(TC,M0r),e(te,E0r),e(te,MC),e(MC,bMe),e(bMe,C0r),e(MC,w0r),e(MC,yJ),e(yJ,A0r),e(MC,L0r),e(te,y0r),e(te,EC),e(EC,vMe),e(vMe,x0r),e(EC,$0r),e(EC,xJ),e(xJ,k0r),e(EC,S0r),e(te,R0r),e(te,CC),e(CC,FMe),e(FMe,P0r),e(CC,B0r),e(CC,$J),e($J,I0r),e(CC,N0r),e(te,q0r),e(te,wC),e(wC,TMe),e(TMe,j0r),e(wC,D0r),e(wC,kJ),e(kJ,G0r),e(wC,O0r),e(te,V0r),e(te,AC),e(AC,MMe),e(MMe,X0r),e(AC,z0r),e(AC,SJ),e(SJ,W0r),e(AC,Q0r),e(te,H0r),e(te,LC),e(LC,EMe),e(EMe,U0r),e(LC,J0r),e(LC,RJ),e(RJ,Y0r),e(LC,K0r),e(te,Z0r),e(te,yC),e(yC,CMe),e(CMe,ewr),e(yC,owr),e(yC,PJ),e(PJ,rwr),e(yC,twr),e(te,awr),e(te,xC),e(xC,wMe),e(wMe,nwr),e(xC,swr),e(xC,BJ),e(BJ,lwr),e(xC,iwr),e(te,dwr),e(te,$C),e($C,AMe),e(AMe,cwr),e($C,fwr),e($C,IJ),e(IJ,mwr),e($C,gwr),e(te,hwr),e(te,kC),e(kC,LMe),e(LMe,pwr),e(kC,uwr),e(kC,NJ),e(NJ,_wr),e(kC,bwr),e(te,vwr),e(te,SC),e(SC,yMe),e(yMe,Fwr),e(SC,Twr),e(SC,qJ),e(qJ,Mwr),e(SC,Ewr),e(te,Cwr),e(te,RC),e(RC,xMe),e(xMe,wwr),e(RC,Awr),e(RC,jJ),e(jJ,Lwr),e(RC,ywr),e(te,xwr),e(te,PC),e(PC,$Me),e($Me,$wr),e(PC,kwr),e(PC,DJ),e(DJ,Swr),e(PC,Rwr),e(te,Pwr),e(te,BC),e(BC,kMe),e(kMe,Bwr),e(BC,Iwr),e(BC,GJ),e(GJ,Nwr),e(BC,qwr),e(te,jwr),e(te,IC),e(IC,SMe),e(SMe,Dwr),e(IC,Gwr),e(IC,OJ),e(OJ,Owr),e(IC,Vwr),e(te,Xwr),e(te,NC),e(NC,RMe),e(RMe,zwr),e(NC,Wwr),e(NC,VJ),e(VJ,Qwr),e(NC,Hwr),e(te,Uwr),e(te,qC),e(qC,PMe),e(PMe,Jwr),e(qC,Ywr),e(qC,XJ),e(XJ,Kwr),e(qC,Zwr),e(Rr,eAr),M(jC,Rr,null),b(f,BOe,_),b(f,Fc,_),e(Fc,DC),e(DC,BMe),M(X9,BMe,null),e(Fc,oAr),e(Fc,IMe),e(IMe,rAr),b(f,IOe,_),b(f,sr,_),M(z9,sr,null),e(sr,tAr),e(sr,Tc),e(Tc,aAr),e(Tc,zJ),e(zJ,nAr),e(Tc,sAr),e(Tc,WJ),e(WJ,lAr),e(Tc,iAr),e(sr,dAr),e(sr,W9),e(W9,cAr),e(W9,NMe),e(NMe,fAr),e(W9,mAr),e(sr,gAr),e(sr,Nt),M(Q9,Nt,null),e(Nt,hAr),e(Nt,qMe),e(qMe,pAr),e(Nt,uAr),e(Nt,Mc),e(Mc,_Ar),e(Mc,jMe),e(jMe,bAr),e(Mc,vAr),e(Mc,QJ),e(QJ,FAr),e(Mc,TAr),e(Nt,MAr),M(GC,Nt,null),e(sr,EAr),e(sr,Pr),M(H9,Pr,null),e(Pr,CAr),e(Pr,DMe),e(DMe,wAr),e(Pr,AAr),e(Pr,mn),e(mn,LAr),e(mn,GMe),e(GMe,yAr),e(mn,xAr),e(mn,OMe),e(OMe,$Ar),e(mn,kAr),e(mn,VMe),e(VMe,SAr),e(mn,RAr),e(Pr,PAr),e(Pr,ue),e(ue,OC),e(OC,XMe),e(XMe,BAr),e(OC,IAr),e(OC,HJ),e(HJ,NAr),e(OC,qAr),e(ue,jAr),e(ue,VC),e(VC,zMe),e(zMe,DAr),e(VC,GAr),e(VC,UJ),e(UJ,OAr),e(VC,VAr),e(ue,XAr),e(ue,XC),e(XC,WMe),e(WMe,zAr),e(XC,WAr),e(XC,JJ),e(JJ,QAr),e(XC,HAr),e(ue,UAr),e(ue,zC),e(zC,QMe),e(QMe,JAr),e(zC,YAr),e(zC,YJ),e(YJ,KAr),e(zC,ZAr),e(ue,e6r),e(ue,WC),e(WC,HMe),e(HMe,o6r),e(WC,r6r),e(WC,KJ),e(KJ,t6r),e(WC,a6r),e(ue,n6r),e(ue,QC),e(QC,UMe),e(UMe,s6r),e(QC,l6r),e(QC,ZJ),e(ZJ,i6r),e(QC,d6r),e(ue,c6r),e(ue,HC),e(HC,JMe),e(JMe,f6r),e(HC,m6r),e(HC,eY),e(eY,g6r),e(HC,h6r),e(ue,p6r),e(ue,UC),e(UC,YMe),e(YMe,u6r),e(UC,_6r),e(UC,oY),e(oY,b6r),e(UC,v6r),e(ue,F6r),e(ue,JC),e(JC,KMe),e(KMe,T6r),e(JC,M6r),e(JC,rY),e(rY,E6r),e(JC,C6r),e(ue,w6r),e(ue,YC),e(YC,ZMe),e(ZMe,A6r),e(YC,L6r),e(YC,tY),e(tY,y6r),e(YC,x6r),e(ue,$6r),e(ue,KC),e(KC,eEe),e(eEe,k6r),e(KC,S6r),e(KC,aY),e(aY,R6r),e(KC,P6r),e(ue,B6r),e(ue,ZC),e(ZC,oEe),e(oEe,I6r),e(ZC,N6r),e(ZC,nY),e(nY,q6r),e(ZC,j6r),e(ue,D6r),e(ue,e5),e(e5,rEe),e(rEe,G6r),e(e5,O6r),e(e5,sY),e(sY,V6r),e(e5,X6r),e(ue,z6r),e(ue,o5),e(o5,tEe),e(tEe,W6r),e(o5,Q6r),e(o5,lY),e(lY,H6r),e(o5,U6r),e(ue,J6r),e(ue,r5),e(r5,aEe),e(aEe,Y6r),e(r5,K6r),e(r5,iY),e(iY,Z6r),e(r5,eLr),e(ue,oLr),e(ue,t5),e(t5,nEe),e(nEe,rLr),e(t5,tLr),e(t5,dY),e(dY,aLr),e(t5,nLr),e(ue,sLr),e(ue,a5),e(a5,sEe),e(sEe,lLr),e(a5,iLr),e(a5,cY),e(cY,dLr),e(a5,cLr),e(Pr,fLr),M(n5,Pr,null),b(f,NOe,_),b(f,Ec,_),e(Ec,s5),e(s5,lEe),M(U9,lEe,null),e(Ec,mLr),e(Ec,iEe),e(iEe,gLr),b(f,qOe,_),b(f,lr,_),M(J9,lr,null),e(lr,hLr),e(lr,Cc),e(Cc,pLr),e(Cc,fY),e(fY,uLr),e(Cc,_Lr),e(Cc,mY),e(mY,bLr),e(Cc,vLr),e(lr,FLr),e(lr,Y9),e(Y9,TLr),e(Y9,dEe),e(dEe,MLr),e(Y9,ELr),e(lr,CLr),e(lr,qt),M(K9,qt,null),e(qt,wLr),e(qt,cEe),e(cEe,ALr),e(qt,LLr),e(qt,wc),e(wc,yLr),e(wc,fEe),e(fEe,xLr),e(wc,$Lr),e(wc,gY),e(gY,kLr),e(wc,SLr),e(qt,RLr),M(l5,qt,null),e(lr,PLr),e(lr,Br),M(Z9,Br,null),e(Br,BLr),e(Br,mEe),e(mEe,ILr),e(Br,NLr),e(Br,gn),e(gn,qLr),e(gn,gEe),e(gEe,jLr),e(gn,DLr),e(gn,hEe),e(hEe,GLr),e(gn,OLr),e(gn,pEe),e(pEe,VLr),e(gn,XLr),e(Br,zLr),e(Br,ex),e(ex,i5),e(i5,uEe),e(uEe,WLr),e(i5,QLr),e(i5,hY),e(hY,HLr),e(i5,ULr),e(ex,JLr),e(ex,d5),e(d5,_Ee),e(_Ee,YLr),e(d5,KLr),e(d5,pY),e(pY,ZLr),e(d5,eyr),e(Br,oyr),M(c5,Br,null),b(f,jOe,_),b(f,Ac,_),e(Ac,f5),e(f5,bEe),M(ox,bEe,null),e(Ac,ryr),e(Ac,vEe),e(vEe,tyr),b(f,DOe,_),b(f,ir,_),M(rx,ir,null),e(ir,ayr),e(ir,Lc),e(Lc,nyr),e(Lc,uY),e(uY,syr),e(Lc,lyr),e(Lc,_Y),e(_Y,iyr),e(Lc,dyr),e(ir,cyr),e(ir,tx),e(tx,fyr),e(tx,FEe),e(FEe,myr),e(tx,gyr),e(ir,hyr),e(ir,jt),M(ax,jt,null),e(jt,pyr),e(jt,TEe),e(TEe,uyr),e(jt,_yr),e(jt,yc),e(yc,byr),e(yc,MEe),e(MEe,vyr),e(yc,Fyr),e(yc,bY),e(bY,Tyr),e(yc,Myr),e(jt,Eyr),M(m5,jt,null),e(ir,Cyr),e(ir,Ir),M(nx,Ir,null),e(Ir,wyr),e(Ir,EEe),e(EEe,Ayr),e(Ir,Lyr),e(Ir,hn),e(hn,yyr),e(hn,CEe),e(CEe,xyr),e(hn,$yr),e(hn,wEe),e(wEe,kyr),e(hn,Syr),e(hn,AEe),e(AEe,Ryr),e(hn,Pyr),e(Ir,Byr),e(Ir,LEe),e(LEe,g5),e(g5,yEe),e(yEe,Iyr),e(g5,Nyr),e(g5,vY),e(vY,qyr),e(g5,jyr),e(Ir,Dyr),M(h5,Ir,null),b(f,GOe,_),b(f,xc,_),e(xc,p5),e(p5,xEe),M(sx,xEe,null),e(xc,Gyr),e(xc,$Ee),e($Ee,Oyr),b(f,OOe,_),b(f,dr,_),M(lx,dr,null),e(dr,Vyr),e(dr,$c),e($c,Xyr),e($c,FY),e(FY,zyr),e($c,Wyr),e($c,TY),e(TY,Qyr),e($c,Hyr),e(dr,Uyr),e(dr,ix),e(ix,Jyr),e(ix,kEe),e(kEe,Yyr),e(ix,Kyr),e(dr,Zyr),e(dr,Dt),M(dx,Dt,null),e(Dt,e8r),e(Dt,SEe),e(SEe,o8r),e(Dt,r8r),e(Dt,kc),e(kc,t8r),e(kc,REe),e(REe,a8r),e(kc,n8r),e(kc,MY),e(MY,s8r),e(kc,l8r),e(Dt,i8r),M(u5,Dt,null),e(dr,d8r),e(dr,Nr),M(cx,Nr,null),e(Nr,c8r),e(Nr,PEe),e(PEe,f8r),e(Nr,m8r),e(Nr,pn),e(pn,g8r),e(pn,BEe),e(BEe,h8r),e(pn,p8r),e(pn,IEe),e(IEe,u8r),e(pn,_8r),e(pn,NEe),e(NEe,b8r),e(pn,v8r),e(Nr,F8r),e(Nr,de),e(de,_5),e(_5,qEe),e(qEe,T8r),e(_5,M8r),e(_5,EY),e(EY,E8r),e(_5,C8r),e(de,w8r),e(de,b5),e(b5,jEe),e(jEe,A8r),e(b5,L8r),e(b5,CY),e(CY,y8r),e(b5,x8r),e(de,$8r),e(de,v5),e(v5,DEe),e(DEe,k8r),e(v5,S8r),e(v5,wY),e(wY,R8r),e(v5,P8r),e(de,B8r),e(de,F5),e(F5,GEe),e(GEe,I8r),e(F5,N8r),e(F5,AY),e(AY,q8r),e(F5,j8r),e(de,D8r),e(de,T5),e(T5,OEe),e(OEe,G8r),e(T5,O8r),e(T5,LY),e(LY,V8r),e(T5,X8r),e(de,z8r),e(de,M5),e(M5,VEe),e(VEe,W8r),e(M5,Q8r),e(M5,yY),e(yY,H8r),e(M5,U8r),e(de,J8r),e(de,E5),e(E5,XEe),e(XEe,Y8r),e(E5,K8r),e(E5,xY),e(xY,Z8r),e(E5,e9r),e(de,o9r),e(de,C5),e(C5,zEe),e(zEe,r9r),e(C5,t9r),e(C5,$Y),e($Y,a9r),e(C5,n9r),e(de,s9r),e(de,w5),e(w5,WEe),e(WEe,l9r),e(w5,i9r),e(w5,kY),e(kY,d9r),e(w5,c9r),e(de,f9r),e(de,A5),e(A5,QEe),e(QEe,m9r),e(A5,g9r),e(A5,SY),e(SY,h9r),e(A5,p9r),e(de,u9r),e(de,L5),e(L5,HEe),e(HEe,_9r),e(L5,b9r),e(L5,RY),e(RY,v9r),e(L5,F9r),e(de,T9r),e(de,y5),e(y5,UEe),e(UEe,M9r),e(y5,E9r),e(y5,PY),e(PY,C9r),e(y5,w9r),e(de,A9r),e(de,x5),e(x5,JEe),e(JEe,L9r),e(x5,y9r),e(x5,BY),e(BY,x9r),e(x5,$9r),e(de,k9r),e(de,$5),e($5,YEe),e(YEe,S9r),e($5,R9r),e($5,IY),e(IY,P9r),e($5,B9r),e(de,I9r),e(de,k5),e(k5,KEe),e(KEe,N9r),e(k5,q9r),e(k5,NY),e(NY,j9r),e(k5,D9r),e(de,G9r),e(de,S5),e(S5,ZEe),e(ZEe,O9r),e(S5,V9r),e(S5,qY),e(qY,X9r),e(S5,z9r),e(de,W9r),e(de,R5),e(R5,e4e),e(e4e,Q9r),e(R5,H9r),e(R5,jY),e(jY,U9r),e(R5,J9r),e(de,Y9r),e(de,P5),e(P5,o4e),e(o4e,K9r),e(P5,Z9r),e(P5,DY),e(DY,exr),e(P5,oxr),e(de,rxr),e(de,B5),e(B5,r4e),e(r4e,txr),e(B5,axr),e(B5,GY),e(GY,nxr),e(B5,sxr),e(de,lxr),e(de,I5),e(I5,t4e),e(t4e,ixr),e(I5,dxr),e(I5,OY),e(OY,cxr),e(I5,fxr),e(Nr,mxr),M(N5,Nr,null),b(f,VOe,_),b(f,Sc,_),e(Sc,q5),e(q5,a4e),M(fx,a4e,null),e(Sc,gxr),e(Sc,n4e),e(n4e,hxr),b(f,XOe,_),b(f,cr,_),M(mx,cr,null),e(cr,pxr),e(cr,Rc),e(Rc,uxr),e(Rc,VY),e(VY,_xr),e(Rc,bxr),e(Rc,XY),e(XY,vxr),e(Rc,Fxr),e(cr,Txr),e(cr,gx),e(gx,Mxr),e(gx,s4e),e(s4e,Exr),e(gx,Cxr),e(cr,wxr),e(cr,Gt),M(hx,Gt,null),e(Gt,Axr),e(Gt,l4e),e(l4e,Lxr),e(Gt,yxr),e(Gt,Pc),e(Pc,xxr),e(Pc,i4e),e(i4e,$xr),e(Pc,kxr),e(Pc,zY),e(zY,Sxr),e(Pc,Rxr),e(Gt,Pxr),M(j5,Gt,null),e(cr,Bxr),e(cr,qr),M(px,qr,null),e(qr,Ixr),e(qr,d4e),e(d4e,Nxr),e(qr,qxr),e(qr,un),e(un,jxr),e(un,c4e),e(c4e,Dxr),e(un,Gxr),e(un,f4e),e(f4e,Oxr),e(un,Vxr),e(un,m4e),e(m4e,Xxr),e(un,zxr),e(qr,Wxr),e(qr,ce),e(ce,D5),e(D5,g4e),e(g4e,Qxr),e(D5,Hxr),e(D5,WY),e(WY,Uxr),e(D5,Jxr),e(ce,Yxr),e(ce,G5),e(G5,h4e),e(h4e,Kxr),e(G5,Zxr),e(G5,QY),e(QY,e$r),e(G5,o$r),e(ce,r$r),e(ce,O5),e(O5,p4e),e(p4e,t$r),e(O5,a$r),e(O5,HY),e(HY,n$r),e(O5,s$r),e(ce,l$r),e(ce,V5),e(V5,u4e),e(u4e,i$r),e(V5,d$r),e(V5,UY),e(UY,c$r),e(V5,f$r),e(ce,m$r),e(ce,X5),e(X5,_4e),e(_4e,g$r),e(X5,h$r),e(X5,JY),e(JY,p$r),e(X5,u$r),e(ce,_$r),e(ce,z5),e(z5,b4e),e(b4e,b$r),e(z5,v$r),e(z5,YY),e(YY,F$r),e(z5,T$r),e(ce,M$r),e(ce,W5),e(W5,v4e),e(v4e,E$r),e(W5,C$r),e(W5,KY),e(KY,w$r),e(W5,A$r),e(ce,L$r),e(ce,Q5),e(Q5,F4e),e(F4e,y$r),e(Q5,x$r),e(Q5,ZY),e(ZY,$$r),e(Q5,k$r),e(ce,S$r),e(ce,H5),e(H5,T4e),e(T4e,R$r),e(H5,P$r),e(H5,eK),e(eK,B$r),e(H5,I$r),e(ce,N$r),e(ce,U5),e(U5,M4e),e(M4e,q$r),e(U5,j$r),e(U5,oK),e(oK,D$r),e(U5,G$r),e(ce,O$r),e(ce,J5),e(J5,E4e),e(E4e,V$r),e(J5,X$r),e(J5,rK),e(rK,z$r),e(J5,W$r),e(ce,Q$r),e(ce,Y5),e(Y5,C4e),e(C4e,H$r),e(Y5,U$r),e(Y5,tK),e(tK,J$r),e(Y5,Y$r),e(ce,K$r),e(ce,K5),e(K5,w4e),e(w4e,Z$r),e(K5,ekr),e(K5,aK),e(aK,okr),e(K5,rkr),e(ce,tkr),e(ce,Z5),e(Z5,A4e),e(A4e,akr),e(Z5,nkr),e(Z5,nK),e(nK,skr),e(Z5,lkr),e(ce,ikr),e(ce,e3),e(e3,L4e),e(L4e,dkr),e(e3,ckr),e(e3,sK),e(sK,fkr),e(e3,mkr),e(ce,gkr),e(ce,o3),e(o3,y4e),e(y4e,hkr),e(o3,pkr),e(o3,lK),e(lK,ukr),e(o3,_kr),e(ce,bkr),e(ce,r3),e(r3,x4e),e(x4e,vkr),e(r3,Fkr),e(r3,iK),e(iK,Tkr),e(r3,Mkr),e(ce,Ekr),e(ce,t3),e(t3,$4e),e($4e,Ckr),e(t3,wkr),e(t3,dK),e(dK,Akr),e(t3,Lkr),e(ce,ykr),e(ce,a3),e(a3,k4e),e(k4e,xkr),e(a3,$kr),e(a3,cK),e(cK,kkr),e(a3,Skr),e(ce,Rkr),e(ce,n3),e(n3,S4e),e(S4e,Pkr),e(n3,Bkr),e(n3,fK),e(fK,Ikr),e(n3,Nkr),e(qr,qkr),M(s3,qr,null),b(f,zOe,_),b(f,Bc,_),e(Bc,l3),e(l3,R4e),M(ux,R4e,null),e(Bc,jkr),e(Bc,P4e),e(P4e,Dkr),b(f,WOe,_),b(f,fr,_),M(_x,fr,null),e(fr,Gkr),e(fr,Ic),e(Ic,Okr),e(Ic,mK),e(mK,Vkr),e(Ic,Xkr),e(Ic,gK),e(gK,zkr),e(Ic,Wkr),e(fr,Qkr),e(fr,bx),e(bx,Hkr),e(bx,B4e),e(B4e,Ukr),e(bx,Jkr),e(fr,Ykr),e(fr,Ot),M(vx,Ot,null),e(Ot,Kkr),e(Ot,I4e),e(I4e,Zkr),e(Ot,eSr),e(Ot,Nc),e(Nc,oSr),e(Nc,N4e),e(N4e,rSr),e(Nc,tSr),e(Nc,hK),e(hK,aSr),e(Nc,nSr),e(Ot,sSr),M(i3,Ot,null),e(fr,lSr),e(fr,jr),M(Fx,jr,null),e(jr,iSr),e(jr,q4e),e(q4e,dSr),e(jr,cSr),e(jr,_n),e(_n,fSr),e(_n,j4e),e(j4e,mSr),e(_n,gSr),e(_n,D4e),e(D4e,hSr),e(_n,pSr),e(_n,G4e),e(G4e,uSr),e(_n,_Sr),e(jr,bSr),e(jr,O4e),e(O4e,d3),e(d3,V4e),e(V4e,vSr),e(d3,FSr),e(d3,pK),e(pK,TSr),e(d3,MSr),e(jr,ESr),M(c3,jr,null),b(f,QOe,_),b(f,qc,_),e(qc,f3),e(f3,X4e),M(Tx,X4e,null),e(qc,CSr),e(qc,z4e),e(z4e,wSr),b(f,HOe,_),b(f,mr,_),M(Mx,mr,null),e(mr,ASr),e(mr,jc),e(jc,LSr),e(jc,uK),e(uK,ySr),e(jc,xSr),e(jc,_K),e(_K,$Sr),e(jc,kSr),e(mr,SSr),e(mr,Ex),e(Ex,RSr),e(Ex,W4e),e(W4e,PSr),e(Ex,BSr),e(mr,ISr),e(mr,Vt),M(Cx,Vt,null),e(Vt,NSr),e(Vt,Q4e),e(Q4e,qSr),e(Vt,jSr),e(Vt,Dc),e(Dc,DSr),e(Dc,H4e),e(H4e,GSr),e(Dc,OSr),e(Dc,bK),e(bK,VSr),e(Dc,XSr),e(Vt,zSr),M(m3,Vt,null),e(mr,WSr),e(mr,Dr),M(wx,Dr,null),e(Dr,QSr),e(Dr,U4e),e(U4e,HSr),e(Dr,USr),e(Dr,bn),e(bn,JSr),e(bn,J4e),e(J4e,YSr),e(bn,KSr),e(bn,Y4e),e(Y4e,ZSr),e(bn,eRr),e(bn,K4e),e(K4e,oRr),e(bn,rRr),e(Dr,tRr),e(Dr,Z4e),e(Z4e,g3),e(g3,eCe),e(eCe,aRr),e(g3,nRr),e(g3,vK),e(vK,sRr),e(g3,lRr),e(Dr,iRr),M(h3,Dr,null),b(f,UOe,_),b(f,Gc,_),e(Gc,p3),e(p3,oCe),M(Ax,oCe,null),e(Gc,dRr),e(Gc,rCe),e(rCe,cRr),b(f,JOe,_),b(f,gr,_),M(Lx,gr,null),e(gr,fRr),e(gr,Oc),e(Oc,mRr),e(Oc,FK),e(FK,gRr),e(Oc,hRr),e(Oc,TK),e(TK,pRr),e(Oc,uRr),e(gr,_Rr),e(gr,yx),e(yx,bRr),e(yx,tCe),e(tCe,vRr),e(yx,FRr),e(gr,TRr),e(gr,Xt),M(xx,Xt,null),e(Xt,MRr),e(Xt,aCe),e(aCe,ERr),e(Xt,CRr),e(Xt,Vc),e(Vc,wRr),e(Vc,nCe),e(nCe,ARr),e(Vc,LRr),e(Vc,MK),e(MK,yRr),e(Vc,xRr),e(Xt,$Rr),M(u3,Xt,null),e(gr,kRr),e(gr,Gr),M($x,Gr,null),e(Gr,SRr),e(Gr,sCe),e(sCe,RRr),e(Gr,PRr),e(Gr,vn),e(vn,BRr),e(vn,lCe),e(lCe,IRr),e(vn,NRr),e(vn,iCe),e(iCe,qRr),e(vn,jRr),e(vn,dCe),e(dCe,DRr),e(vn,GRr),e(Gr,ORr),e(Gr,oe),e(oe,_3),e(_3,cCe),e(cCe,VRr),e(_3,XRr),e(_3,EK),e(EK,zRr),e(_3,WRr),e(oe,QRr),e(oe,b3),e(b3,fCe),e(fCe,HRr),e(b3,URr),e(b3,CK),e(CK,JRr),e(b3,YRr),e(oe,KRr),e(oe,v3),e(v3,mCe),e(mCe,ZRr),e(v3,ePr),e(v3,wK),e(wK,oPr),e(v3,rPr),e(oe,tPr),e(oe,F3),e(F3,gCe),e(gCe,aPr),e(F3,nPr),e(F3,AK),e(AK,sPr),e(F3,lPr),e(oe,iPr),e(oe,T3),e(T3,hCe),e(hCe,dPr),e(T3,cPr),e(T3,LK),e(LK,fPr),e(T3,mPr),e(oe,gPr),e(oe,M3),e(M3,pCe),e(pCe,hPr),e(M3,pPr),e(M3,yK),e(yK,uPr),e(M3,_Pr),e(oe,bPr),e(oe,E3),e(E3,uCe),e(uCe,vPr),e(E3,FPr),e(E3,xK),e(xK,TPr),e(E3,MPr),e(oe,EPr),e(oe,C3),e(C3,_Ce),e(_Ce,CPr),e(C3,wPr),e(C3,$K),e($K,APr),e(C3,LPr),e(oe,yPr),e(oe,w3),e(w3,bCe),e(bCe,xPr),e(w3,$Pr),e(w3,kK),e(kK,kPr),e(w3,SPr),e(oe,RPr),e(oe,A3),e(A3,vCe),e(vCe,PPr),e(A3,BPr),e(A3,SK),e(SK,IPr),e(A3,NPr),e(oe,qPr),e(oe,L3),e(L3,FCe),e(FCe,jPr),e(L3,DPr),e(L3,RK),e(RK,GPr),e(L3,OPr),e(oe,VPr),e(oe,y3),e(y3,TCe),e(TCe,XPr),e(y3,zPr),e(y3,PK),e(PK,WPr),e(y3,QPr),e(oe,HPr),e(oe,x3),e(x3,MCe),e(MCe,UPr),e(x3,JPr),e(x3,BK),e(BK,YPr),e(x3,KPr),e(oe,ZPr),e(oe,$3),e($3,ECe),e(ECe,eBr),e($3,oBr),e($3,IK),e(IK,rBr),e($3,tBr),e(oe,aBr),e(oe,k3),e(k3,CCe),e(CCe,nBr),e(k3,sBr),e(k3,NK),e(NK,lBr),e(k3,iBr),e(oe,dBr),e(oe,S3),e(S3,wCe),e(wCe,cBr),e(S3,fBr),e(S3,qK),e(qK,mBr),e(S3,gBr),e(oe,hBr),e(oe,R3),e(R3,ACe),e(ACe,pBr),e(R3,uBr),e(R3,jK),e(jK,_Br),e(R3,bBr),e(oe,vBr),e(oe,P3),e(P3,LCe),e(LCe,FBr),e(P3,TBr),e(P3,DK),e(DK,MBr),e(P3,EBr),e(oe,CBr),e(oe,B3),e(B3,yCe),e(yCe,wBr),e(B3,ABr),e(B3,GK),e(GK,LBr),e(B3,yBr),e(oe,xBr),e(oe,I3),e(I3,xCe),e(xCe,$Br),e(I3,kBr),e(I3,OK),e(OK,SBr),e(I3,RBr),e(oe,PBr),e(oe,N3),e(N3,$Ce),e($Ce,BBr),e(N3,IBr),e(N3,VK),e(VK,NBr),e(N3,qBr),e(oe,jBr),e(oe,q3),e(q3,kCe),e(kCe,DBr),e(q3,GBr),e(q3,XK),e(XK,OBr),e(q3,VBr),e(oe,XBr),e(oe,j3),e(j3,SCe),e(SCe,zBr),e(j3,WBr),e(j3,zK),e(zK,QBr),e(j3,HBr),e(oe,UBr),e(oe,D3),e(D3,RCe),e(RCe,JBr),e(D3,YBr),e(D3,WK),e(WK,KBr),e(D3,ZBr),e(oe,eIr),e(oe,G3),e(G3,PCe),e(PCe,oIr),e(G3,rIr),e(G3,QK),e(QK,tIr),e(G3,aIr),e(oe,nIr),e(oe,O3),e(O3,BCe),e(BCe,sIr),e(O3,lIr),e(O3,HK),e(HK,iIr),e(O3,dIr),e(oe,cIr),e(oe,V3),e(V3,ICe),e(ICe,fIr),e(V3,mIr),e(V3,UK),e(UK,gIr),e(V3,hIr),e(Gr,pIr),M(X3,Gr,null),b(f,YOe,_),b(f,Xc,_),e(Xc,z3),e(z3,NCe),M(kx,NCe,null),e(Xc,uIr),e(Xc,qCe),e(qCe,_Ir),b(f,KOe,_),b(f,hr,_),M(Sx,hr,null),e(hr,bIr),e(hr,zc),e(zc,vIr),e(zc,JK),e(JK,FIr),e(zc,TIr),e(zc,YK),e(YK,MIr),e(zc,EIr),e(hr,CIr),e(hr,Rx),e(Rx,wIr),e(Rx,jCe),e(jCe,AIr),e(Rx,LIr),e(hr,yIr),e(hr,zt),M(Px,zt,null),e(zt,xIr),e(zt,DCe),e(DCe,$Ir),e(zt,kIr),e(zt,Wc),e(Wc,SIr),e(Wc,GCe),e(GCe,RIr),e(Wc,PIr),e(Wc,KK),e(KK,BIr),e(Wc,IIr),e(zt,NIr),M(W3,zt,null),e(hr,qIr),e(hr,Or),M(Bx,Or,null),e(Or,jIr),e(Or,OCe),e(OCe,DIr),e(Or,GIr),e(Or,Fn),e(Fn,OIr),e(Fn,VCe),e(VCe,VIr),e(Fn,XIr),e(Fn,XCe),e(XCe,zIr),e(Fn,WIr),e(Fn,zCe),e(zCe,QIr),e(Fn,HIr),e(Or,UIr),e(Or,xe),e(xe,Q3),e(Q3,WCe),e(WCe,JIr),e(Q3,YIr),e(Q3,ZK),e(ZK,KIr),e(Q3,ZIr),e(xe,eNr),e(xe,H3),e(H3,QCe),e(QCe,oNr),e(H3,rNr),e(H3,eZ),e(eZ,tNr),e(H3,aNr),e(xe,nNr),e(xe,U3),e(U3,HCe),e(HCe,sNr),e(U3,lNr),e(U3,oZ),e(oZ,iNr),e(U3,dNr),e(xe,cNr),e(xe,J3),e(J3,UCe),e(UCe,fNr),e(J3,mNr),e(J3,rZ),e(rZ,gNr),e(J3,hNr),e(xe,pNr),e(xe,Y3),e(Y3,JCe),e(JCe,uNr),e(Y3,_Nr),e(Y3,tZ),e(tZ,bNr),e(Y3,vNr),e(xe,FNr),e(xe,K3),e(K3,YCe),e(YCe,TNr),e(K3,MNr),e(K3,aZ),e(aZ,ENr),e(K3,CNr),e(xe,wNr),e(xe,Z3),e(Z3,KCe),e(KCe,ANr),e(Z3,LNr),e(Z3,nZ),e(nZ,yNr),e(Z3,xNr),e(xe,$Nr),e(xe,e0),e(e0,ZCe),e(ZCe,kNr),e(e0,SNr),e(e0,sZ),e(sZ,RNr),e(e0,PNr),e(xe,BNr),e(xe,o0),e(o0,e5e),e(e5e,INr),e(o0,NNr),e(o0,lZ),e(lZ,qNr),e(o0,jNr),e(xe,DNr),e(xe,r0),e(r0,o5e),e(o5e,GNr),e(r0,ONr),e(r0,iZ),e(iZ,VNr),e(r0,XNr),e(Or,zNr),M(t0,Or,null),b(f,ZOe,_),b(f,Qc,_),e(Qc,a0),e(a0,r5e),M(Ix,r5e,null),e(Qc,WNr),e(Qc,t5e),e(t5e,QNr),b(f,eVe,_),b(f,pr,_),M(Nx,pr,null),e(pr,HNr),e(pr,Hc),e(Hc,UNr),e(Hc,dZ),e(dZ,JNr),e(Hc,YNr),e(Hc,cZ),e(cZ,KNr),e(Hc,ZNr),e(pr,eqr),e(pr,qx),e(qx,oqr),e(qx,a5e),e(a5e,rqr),e(qx,tqr),e(pr,aqr),e(pr,Wt),M(jx,Wt,null),e(Wt,nqr),e(Wt,n5e),e(n5e,sqr),e(Wt,lqr),e(Wt,Uc),e(Uc,iqr),e(Uc,s5e),e(s5e,dqr),e(Uc,cqr),e(Uc,fZ),e(fZ,fqr),e(Uc,mqr),e(Wt,gqr),M(n0,Wt,null),e(pr,hqr),e(pr,Vr),M(Dx,Vr,null),e(Vr,pqr),e(Vr,l5e),e(l5e,uqr),e(Vr,_qr),e(Vr,Tn),e(Tn,bqr),e(Tn,i5e),e(i5e,vqr),e(Tn,Fqr),e(Tn,d5e),e(d5e,Tqr),e(Tn,Mqr),e(Tn,c5e),e(c5e,Eqr),e(Tn,Cqr),e(Vr,wqr),e(Vr,Ee),e(Ee,s0),e(s0,f5e),e(f5e,Aqr),e(s0,Lqr),e(s0,mZ),e(mZ,yqr),e(s0,xqr),e(Ee,$qr),e(Ee,l0),e(l0,m5e),e(m5e,kqr),e(l0,Sqr),e(l0,gZ),e(gZ,Rqr),e(l0,Pqr),e(Ee,Bqr),e(Ee,i0),e(i0,g5e),e(g5e,Iqr),e(i0,Nqr),e(i0,hZ),e(hZ,qqr),e(i0,jqr),e(Ee,Dqr),e(Ee,d0),e(d0,h5e),e(h5e,Gqr),e(d0,Oqr),e(d0,pZ),e(pZ,Vqr),e(d0,Xqr),e(Ee,zqr),e(Ee,c0),e(c0,p5e),e(p5e,Wqr),e(c0,Qqr),e(c0,uZ),e(uZ,Hqr),e(c0,Uqr),e(Ee,Jqr),e(Ee,f0),e(f0,u5e),e(u5e,Yqr),e(f0,Kqr),e(f0,_Z),e(_Z,Zqr),e(f0,ejr),e(Ee,ojr),e(Ee,m0),e(m0,_5e),e(_5e,rjr),e(m0,tjr),e(m0,bZ),e(bZ,ajr),e(m0,njr),e(Ee,sjr),e(Ee,g0),e(g0,b5e),e(b5e,ljr),e(g0,ijr),e(g0,vZ),e(vZ,djr),e(g0,cjr),e(Ee,fjr),e(Ee,h0),e(h0,v5e),e(v5e,mjr),e(h0,gjr),e(h0,FZ),e(FZ,hjr),e(h0,pjr),e(Ee,ujr),e(Ee,p0),e(p0,F5e),e(F5e,_jr),e(p0,bjr),e(p0,TZ),e(TZ,vjr),e(p0,Fjr),e(Ee,Tjr),e(Ee,u0),e(u0,T5e),e(T5e,Mjr),e(u0,Ejr),e(u0,MZ),e(MZ,Cjr),e(u0,wjr),e(Ee,Ajr),e(Ee,_0),e(_0,M5e),e(M5e,Ljr),e(_0,yjr),e(_0,EZ),e(EZ,xjr),e(_0,$jr),e(Ee,kjr),e(Ee,b0),e(b0,E5e),e(E5e,Sjr),e(b0,Rjr),e(b0,CZ),e(CZ,Pjr),e(b0,Bjr),e(Vr,Ijr),M(v0,Vr,null),b(f,oVe,_),b(f,Jc,_),e(Jc,F0),e(F0,C5e),M(Gx,C5e,null),e(Jc,Njr),e(Jc,w5e),e(w5e,qjr),b(f,rVe,_),b(f,ur,_),M(Ox,ur,null),e(ur,jjr),e(ur,Yc),e(Yc,Djr),e(Yc,wZ),e(wZ,Gjr),e(Yc,Ojr),e(Yc,AZ),e(AZ,Vjr),e(Yc,Xjr),e(ur,zjr),e(ur,Vx),e(Vx,Wjr),e(Vx,A5e),e(A5e,Qjr),e(Vx,Hjr),e(ur,Ujr),e(ur,Qt),M(Xx,Qt,null),e(Qt,Jjr),e(Qt,L5e),e(L5e,Yjr),e(Qt,Kjr),e(Qt,Kc),e(Kc,Zjr),e(Kc,y5e),e(y5e,eDr),e(Kc,oDr),e(Kc,LZ),e(LZ,rDr),e(Kc,tDr),e(Qt,aDr),M(T0,Qt,null),e(ur,nDr),e(ur,Xr),M(zx,Xr,null),e(Xr,sDr),e(Xr,x5e),e(x5e,lDr),e(Xr,iDr),e(Xr,Mn),e(Mn,dDr),e(Mn,$5e),e($5e,cDr),e(Mn,fDr),e(Mn,k5e),e(k5e,mDr),e(Mn,gDr),e(Mn,S5e),e(S5e,hDr),e(Mn,pDr),e(Xr,uDr),e(Xr,$e),e($e,M0),e(M0,R5e),e(R5e,_Dr),e(M0,bDr),e(M0,yZ),e(yZ,vDr),e(M0,FDr),e($e,TDr),e($e,E0),e(E0,P5e),e(P5e,MDr),e(E0,EDr),e(E0,xZ),e(xZ,CDr),e(E0,wDr),e($e,ADr),e($e,C0),e(C0,B5e),e(B5e,LDr),e(C0,yDr),e(C0,$Z),e($Z,xDr),e(C0,$Dr),e($e,kDr),e($e,w0),e(w0,I5e),e(I5e,SDr),e(w0,RDr),e(w0,kZ),e(kZ,PDr),e(w0,BDr),e($e,IDr),e($e,A0),e(A0,N5e),e(N5e,NDr),e(A0,qDr),e(A0,SZ),e(SZ,jDr),e(A0,DDr),e($e,GDr),e($e,L0),e(L0,q5e),e(q5e,ODr),e(L0,VDr),e(L0,RZ),e(RZ,XDr),e(L0,zDr),e($e,WDr),e($e,y0),e(y0,j5e),e(j5e,QDr),e(y0,HDr),e(y0,PZ),e(PZ,UDr),e(y0,JDr),e($e,YDr),e($e,x0),e(x0,D5e),e(D5e,KDr),e(x0,ZDr),e(x0,BZ),e(BZ,eGr),e(x0,oGr),e($e,rGr),e($e,$0),e($0,G5e),e(G5e,tGr),e($0,aGr),e($0,IZ),e(IZ,nGr),e($0,sGr),e($e,lGr),e($e,k0),e(k0,O5e),e(O5e,iGr),e(k0,dGr),e(k0,NZ),e(NZ,cGr),e(k0,fGr),e(Xr,mGr),M(S0,Xr,null),b(f,tVe,_),b(f,Zc,_),e(Zc,R0),e(R0,V5e),M(Wx,V5e,null),e(Zc,gGr),e(Zc,X5e),e(X5e,hGr),b(f,aVe,_),b(f,_r,_),M(Qx,_r,null),e(_r,pGr),e(_r,ef),e(ef,uGr),e(ef,qZ),e(qZ,_Gr),e(ef,bGr),e(ef,jZ),e(jZ,vGr),e(ef,FGr),e(_r,TGr),e(_r,Hx),e(Hx,MGr),e(Hx,z5e),e(z5e,EGr),e(Hx,CGr),e(_r,wGr),e(_r,Ht),M(Ux,Ht,null),e(Ht,AGr),e(Ht,W5e),e(W5e,LGr),e(Ht,yGr),e(Ht,of),e(of,xGr),e(of,Q5e),e(Q5e,$Gr),e(of,kGr),e(of,DZ),e(DZ,SGr),e(of,RGr),e(Ht,PGr),M(P0,Ht,null),e(_r,BGr),e(_r,zr),M(Jx,zr,null),e(zr,IGr),e(zr,H5e),e(H5e,NGr),e(zr,qGr),e(zr,En),e(En,jGr),e(En,U5e),e(U5e,DGr),e(En,GGr),e(En,J5e),e(J5e,OGr),e(En,VGr),e(En,Y5e),e(Y5e,XGr),e(En,zGr),e(zr,WGr),e(zr,ke),e(ke,B0),e(B0,K5e),e(K5e,QGr),e(B0,HGr),e(B0,GZ),e(GZ,UGr),e(B0,JGr),e(ke,YGr),e(ke,I0),e(I0,Z5e),e(Z5e,KGr),e(I0,ZGr),e(I0,OZ),e(OZ,eOr),e(I0,oOr),e(ke,rOr),e(ke,N0),e(N0,e3e),e(e3e,tOr),e(N0,aOr),e(N0,VZ),e(VZ,nOr),e(N0,sOr),e(ke,lOr),e(ke,q0),e(q0,o3e),e(o3e,iOr),e(q0,dOr),e(q0,XZ),e(XZ,cOr),e(q0,fOr),e(ke,mOr),e(ke,j0),e(j0,r3e),e(r3e,gOr),e(j0,hOr),e(j0,zZ),e(zZ,pOr),e(j0,uOr),e(ke,_Or),e(ke,D0),e(D0,t3e),e(t3e,bOr),e(D0,vOr),e(D0,WZ),e(WZ,FOr),e(D0,TOr),e(ke,MOr),e(ke,G0),e(G0,a3e),e(a3e,EOr),e(G0,COr),e(G0,QZ),e(QZ,wOr),e(G0,AOr),e(ke,LOr),e(ke,O0),e(O0,n3e),e(n3e,yOr),e(O0,xOr),e(O0,HZ),e(HZ,$Or),e(O0,kOr),e(ke,SOr),e(ke,V0),e(V0,s3e),e(s3e,ROr),e(V0,POr),e(V0,UZ),e(UZ,BOr),e(V0,IOr),e(ke,NOr),e(ke,X0),e(X0,l3e),e(l3e,qOr),e(X0,jOr),e(X0,JZ),e(JZ,DOr),e(X0,GOr),e(zr,OOr),M(z0,zr,null),b(f,nVe,_),b(f,rf,_),e(rf,W0),e(W0,i3e),M(Yx,i3e,null),e(rf,VOr),e(rf,d3e),e(d3e,XOr),b(f,sVe,_),b(f,br,_),M(Kx,br,null),e(br,zOr),e(br,tf),e(tf,WOr),e(tf,YZ),e(YZ,QOr),e(tf,HOr),e(tf,KZ),e(KZ,UOr),e(tf,JOr),e(br,YOr),e(br,Zx),e(Zx,KOr),e(Zx,c3e),e(c3e,ZOr),e(Zx,eVr),e(br,oVr),e(br,Ut),M(e$,Ut,null),e(Ut,rVr),e(Ut,f3e),e(f3e,tVr),e(Ut,aVr),e(Ut,af),e(af,nVr),e(af,m3e),e(m3e,sVr),e(af,lVr),e(af,ZZ),e(ZZ,iVr),e(af,dVr),e(Ut,cVr),M(Q0,Ut,null),e(br,fVr),e(br,Wr),M(o$,Wr,null),e(Wr,mVr),e(Wr,g3e),e(g3e,gVr),e(Wr,hVr),e(Wr,Cn),e(Cn,pVr),e(Cn,h3e),e(h3e,uVr),e(Cn,_Vr),e(Cn,p3e),e(p3e,bVr),e(Cn,vVr),e(Cn,u3e),e(u3e,FVr),e(Cn,TVr),e(Wr,MVr),e(Wr,Se),e(Se,H0),e(H0,_3e),e(_3e,EVr),e(H0,CVr),e(H0,eee),e(eee,wVr),e(H0,AVr),e(Se,LVr),e(Se,U0),e(U0,b3e),e(b3e,yVr),e(U0,xVr),e(U0,oee),e(oee,$Vr),e(U0,kVr),e(Se,SVr),e(Se,J0),e(J0,v3e),e(v3e,RVr),e(J0,PVr),e(J0,ree),e(ree,BVr),e(J0,IVr),e(Se,NVr),e(Se,Y0),e(Y0,F3e),e(F3e,qVr),e(Y0,jVr),e(Y0,tee),e(tee,DVr),e(Y0,GVr),e(Se,OVr),e(Se,K0),e(K0,T3e),e(T3e,VVr),e(K0,XVr),e(K0,aee),e(aee,zVr),e(K0,WVr),e(Se,QVr),e(Se,Z0),e(Z0,M3e),e(M3e,HVr),e(Z0,UVr),e(Z0,nee),e(nee,JVr),e(Z0,YVr),e(Se,KVr),e(Se,ew),e(ew,E3e),e(E3e,ZVr),e(ew,eXr),e(ew,see),e(see,oXr),e(ew,rXr),e(Se,tXr),e(Se,ow),e(ow,C3e),e(C3e,aXr),e(ow,nXr),e(ow,lee),e(lee,sXr),e(ow,lXr),e(Se,iXr),e(Se,rw),e(rw,w3e),e(w3e,dXr),e(rw,cXr),e(rw,iee),e(iee,fXr),e(rw,mXr),e(Se,gXr),e(Se,tw),e(tw,A3e),e(A3e,hXr),e(tw,pXr),e(tw,dee),e(dee,uXr),e(tw,_Xr),e(Wr,bXr),M(aw,Wr,null),b(f,lVe,_),b(f,nf,_),e(nf,nw),e(nw,L3e),M(r$,L3e,null),e(nf,vXr),e(nf,y3e),e(y3e,FXr),b(f,iVe,_),b(f,vr,_),M(t$,vr,null),e(vr,TXr),e(vr,sf),e(sf,MXr),e(sf,cee),e(cee,EXr),e(sf,CXr),e(sf,fee),e(fee,wXr),e(sf,AXr),e(vr,LXr),e(vr,a$),e(a$,yXr),e(a$,x3e),e(x3e,xXr),e(a$,$Xr),e(vr,kXr),e(vr,Jt),M(n$,Jt,null),e(Jt,SXr),e(Jt,$3e),e($3e,RXr),e(Jt,PXr),e(Jt,lf),e(lf,BXr),e(lf,k3e),e(k3e,IXr),e(lf,NXr),e(lf,mee),e(mee,qXr),e(lf,jXr),e(Jt,DXr),M(sw,Jt,null),e(vr,GXr),e(vr,Qr),M(s$,Qr,null),e(Qr,OXr),e(Qr,S3e),e(S3e,VXr),e(Qr,XXr),e(Qr,wn),e(wn,zXr),e(wn,R3e),e(R3e,WXr),e(wn,QXr),e(wn,P3e),e(P3e,HXr),e(wn,UXr),e(wn,B3e),e(B3e,JXr),e(wn,YXr),e(Qr,KXr),e(Qr,Re),e(Re,lw),e(lw,I3e),e(I3e,ZXr),e(lw,ezr),e(lw,gee),e(gee,ozr),e(lw,rzr),e(Re,tzr),e(Re,iw),e(iw,N3e),e(N3e,azr),e(iw,nzr),e(iw,hee),e(hee,szr),e(iw,lzr),e(Re,izr),e(Re,dw),e(dw,q3e),e(q3e,dzr),e(dw,czr),e(dw,pee),e(pee,fzr),e(dw,mzr),e(Re,gzr),e(Re,cw),e(cw,j3e),e(j3e,hzr),e(cw,pzr),e(cw,uee),e(uee,uzr),e(cw,_zr),e(Re,bzr),e(Re,fw),e(fw,D3e),e(D3e,vzr),e(fw,Fzr),e(fw,_ee),e(_ee,Tzr),e(fw,Mzr),e(Re,Ezr),e(Re,mw),e(mw,G3e),e(G3e,Czr),e(mw,wzr),e(mw,bee),e(bee,Azr),e(mw,Lzr),e(Re,yzr),e(Re,gw),e(gw,O3e),e(O3e,xzr),e(gw,$zr),e(gw,vee),e(vee,kzr),e(gw,Szr),e(Re,Rzr),e(Re,hw),e(hw,V3e),e(V3e,Pzr),e(hw,Bzr),e(hw,Fee),e(Fee,Izr),e(hw,Nzr),e(Re,qzr),e(Re,pw),e(pw,X3e),e(X3e,jzr),e(pw,Dzr),e(pw,Tee),e(Tee,Gzr),e(pw,Ozr),e(Re,Vzr),e(Re,uw),e(uw,z3e),e(z3e,Xzr),e(uw,zzr),e(uw,Mee),e(Mee,Wzr),e(uw,Qzr),e(Qr,Hzr),M(_w,Qr,null),b(f,dVe,_),b(f,df,_),e(df,bw),e(bw,W3e),M(l$,W3e,null),e(df,Uzr),e(df,Q3e),e(Q3e,Jzr),b(f,cVe,_),b(f,Fr,_),M(i$,Fr,null),e(Fr,Yzr),e(Fr,cf),e(cf,Kzr),e(cf,Eee),e(Eee,Zzr),e(cf,eWr),e(cf,Cee),e(Cee,oWr),e(cf,rWr),e(Fr,tWr),e(Fr,d$),e(d$,aWr),e(d$,H3e),e(H3e,nWr),e(d$,sWr),e(Fr,lWr),e(Fr,Yt),M(c$,Yt,null),e(Yt,iWr),e(Yt,U3e),e(U3e,dWr),e(Yt,cWr),e(Yt,ff),e(ff,fWr),e(ff,J3e),e(J3e,mWr),e(ff,gWr),e(ff,wee),e(wee,hWr),e(ff,pWr),e(Yt,uWr),M(vw,Yt,null),e(Fr,_Wr),e(Fr,Hr),M(f$,Hr,null),e(Hr,bWr),e(Hr,Y3e),e(Y3e,vWr),e(Hr,FWr),e(Hr,An),e(An,TWr),e(An,K3e),e(K3e,MWr),e(An,EWr),e(An,Z3e),e(Z3e,CWr),e(An,wWr),e(An,e0e),e(e0e,AWr),e(An,LWr),e(Hr,yWr),e(Hr,Ve),e(Ve,Fw),e(Fw,o0e),e(o0e,xWr),e(Fw,$Wr),e(Fw,Aee),e(Aee,kWr),e(Fw,SWr),e(Ve,RWr),e(Ve,Tw),e(Tw,r0e),e(r0e,PWr),e(Tw,BWr),e(Tw,Lee),e(Lee,IWr),e(Tw,NWr),e(Ve,qWr),e(Ve,Mw),e(Mw,t0e),e(t0e,jWr),e(Mw,DWr),e(Mw,yee),e(yee,GWr),e(Mw,OWr),e(Ve,VWr),e(Ve,Ew),e(Ew,a0e),e(a0e,XWr),e(Ew,zWr),e(Ew,xee),e(xee,WWr),e(Ew,QWr),e(Ve,HWr),e(Ve,Cw),e(Cw,n0e),e(n0e,UWr),e(Cw,JWr),e(Cw,$ee),e($ee,YWr),e(Cw,KWr),e(Ve,ZWr),e(Ve,ww),e(ww,s0e),e(s0e,eQr),e(ww,oQr),e(ww,kee),e(kee,rQr),e(ww,tQr),e(Ve,aQr),e(Ve,Aw),e(Aw,l0e),e(l0e,nQr),e(Aw,sQr),e(Aw,See),e(See,lQr),e(Aw,iQr),e(Ve,dQr),e(Ve,Lw),e(Lw,i0e),e(i0e,cQr),e(Lw,fQr),e(Lw,Ree),e(Ree,mQr),e(Lw,gQr),e(Hr,hQr),M(yw,Hr,null),b(f,fVe,_),b(f,mf,_),e(mf,xw),e(xw,d0e),M(m$,d0e,null),e(mf,pQr),e(mf,c0e),e(c0e,uQr),b(f,mVe,_),b(f,Tr,_),M(g$,Tr,null),e(Tr,_Qr),e(Tr,gf),e(gf,bQr),e(gf,Pee),e(Pee,vQr),e(gf,FQr),e(gf,Bee),e(Bee,TQr),e(gf,MQr),e(Tr,EQr),e(Tr,h$),e(h$,CQr),e(h$,f0e),e(f0e,wQr),e(h$,AQr),e(Tr,LQr),e(Tr,Kt),M(p$,Kt,null),e(Kt,yQr),e(Kt,m0e),e(m0e,xQr),e(Kt,$Qr),e(Kt,hf),e(hf,kQr),e(hf,g0e),e(g0e,SQr),e(hf,RQr),e(hf,Iee),e(Iee,PQr),e(hf,BQr),e(Kt,IQr),M($w,Kt,null),e(Tr,NQr),e(Tr,Ur),M(u$,Ur,null),e(Ur,qQr),e(Ur,h0e),e(h0e,jQr),e(Ur,DQr),e(Ur,Ln),e(Ln,GQr),e(Ln,p0e),e(p0e,OQr),e(Ln,VQr),e(Ln,u0e),e(u0e,XQr),e(Ln,zQr),e(Ln,_0e),e(_0e,WQr),e(Ln,QQr),e(Ur,HQr),e(Ur,Xe),e(Xe,kw),e(kw,b0e),e(b0e,UQr),e(kw,JQr),e(kw,Nee),e(Nee,YQr),e(kw,KQr),e(Xe,ZQr),e(Xe,Sw),e(Sw,v0e),e(v0e,eHr),e(Sw,oHr),e(Sw,qee),e(qee,rHr),e(Sw,tHr),e(Xe,aHr),e(Xe,Rw),e(Rw,F0e),e(F0e,nHr),e(Rw,sHr),e(Rw,jee),e(jee,lHr),e(Rw,iHr),e(Xe,dHr),e(Xe,Pw),e(Pw,T0e),e(T0e,cHr),e(Pw,fHr),e(Pw,Dee),e(Dee,mHr),e(Pw,gHr),e(Xe,hHr),e(Xe,Bw),e(Bw,M0e),e(M0e,pHr),e(Bw,uHr),e(Bw,Gee),e(Gee,_Hr),e(Bw,bHr),e(Xe,vHr),e(Xe,Iw),e(Iw,E0e),e(E0e,FHr),e(Iw,THr),e(Iw,Oee),e(Oee,MHr),e(Iw,EHr),e(Xe,CHr),e(Xe,Nw),e(Nw,C0e),e(C0e,wHr),e(Nw,AHr),e(Nw,Vee),e(Vee,LHr),e(Nw,yHr),e(Xe,xHr),e(Xe,qw),e(qw,w0e),e(w0e,$Hr),e(qw,kHr),e(qw,Xee),e(Xee,SHr),e(qw,RHr),e(Ur,PHr),M(jw,Ur,null),b(f,gVe,_),b(f,pf,_),e(pf,Dw),e(Dw,A0e),M(_$,A0e,null),e(pf,BHr),e(pf,L0e),e(L0e,IHr),b(f,hVe,_),b(f,Mr,_),M(b$,Mr,null),e(Mr,NHr),e(Mr,uf),e(uf,qHr),e(uf,zee),e(zee,jHr),e(uf,DHr),e(uf,Wee),e(Wee,GHr),e(uf,OHr),e(Mr,VHr),e(Mr,v$),e(v$,XHr),e(v$,y0e),e(y0e,zHr),e(v$,WHr),e(Mr,QHr),e(Mr,Zt),M(F$,Zt,null),e(Zt,HHr),e(Zt,x0e),e(x0e,UHr),e(Zt,JHr),e(Zt,_f),e(_f,YHr),e(_f,$0e),e($0e,KHr),e(_f,ZHr),e(_f,Qee),e(Qee,eUr),e(_f,oUr),e(Zt,rUr),M(Gw,Zt,null),e(Mr,tUr),e(Mr,Jr),M(T$,Jr,null),e(Jr,aUr),e(Jr,k0e),e(k0e,nUr),e(Jr,sUr),e(Jr,yn),e(yn,lUr),e(yn,S0e),e(S0e,iUr),e(yn,dUr),e(yn,R0e),e(R0e,cUr),e(yn,fUr),e(yn,P0e),e(P0e,mUr),e(yn,gUr),e(Jr,hUr),e(Jr,B0e),e(B0e,Ow),e(Ow,I0e),e(I0e,pUr),e(Ow,uUr),e(Ow,Hee),e(Hee,_Ur),e(Ow,bUr),e(Jr,vUr),M(Vw,Jr,null),b(f,pVe,_),b(f,bf,_),e(bf,Xw),e(Xw,N0e),M(M$,N0e,null),e(bf,FUr),e(bf,q0e),e(q0e,TUr),b(f,uVe,_),b(f,Er,_),M(E$,Er,null),e(Er,MUr),e(Er,vf),e(vf,EUr),e(vf,Uee),e(Uee,CUr),e(vf,wUr),e(vf,Jee),e(Jee,AUr),e(vf,LUr),e(Er,yUr),e(Er,C$),e(C$,xUr),e(C$,j0e),e(j0e,$Ur),e(C$,kUr),e(Er,SUr),e(Er,ea),M(w$,ea,null),e(ea,RUr),e(ea,D0e),e(D0e,PUr),e(ea,BUr),e(ea,Ff),e(Ff,IUr),e(Ff,G0e),e(G0e,NUr),e(Ff,qUr),e(Ff,Yee),e(Yee,jUr),e(Ff,DUr),e(ea,GUr),M(zw,ea,null),e(Er,OUr),e(Er,Yr),M(A$,Yr,null),e(Yr,VUr),e(Yr,O0e),e(O0e,XUr),e(Yr,zUr),e(Yr,xn),e(xn,WUr),e(xn,V0e),e(V0e,QUr),e(xn,HUr),e(xn,X0e),e(X0e,UUr),e(xn,JUr),e(xn,z0e),e(z0e,YUr),e(xn,KUr),e(Yr,ZUr),e(Yr,L$),e(L$,Ww),e(Ww,W0e),e(W0e,eJr),e(Ww,oJr),e(Ww,Kee),e(Kee,rJr),e(Ww,tJr),e(L$,aJr),e(L$,Qw),e(Qw,Q0e),e(Q0e,nJr),e(Qw,sJr),e(Qw,Zee),e(Zee,lJr),e(Qw,iJr),e(Yr,dJr),M(Hw,Yr,null),b(f,_Ve,_),b(f,Tf,_),e(Tf,Uw),e(Uw,H0e),M(y$,H0e,null),e(Tf,cJr),e(Tf,U0e),e(U0e,fJr),b(f,bVe,_),b(f,Cr,_),M(x$,Cr,null),e(Cr,mJr),e(Cr,Mf),e(Mf,gJr),e(Mf,eoe),e(eoe,hJr),e(Mf,pJr),e(Mf,ooe),e(ooe,uJr),e(Mf,_Jr),e(Cr,bJr),e(Cr,$$),e($$,vJr),e($$,J0e),e(J0e,FJr),e($$,TJr),e(Cr,MJr),e(Cr,oa),M(k$,oa,null),e(oa,EJr),e(oa,Y0e),e(Y0e,CJr),e(oa,wJr),e(oa,Ef),e(Ef,AJr),e(Ef,K0e),e(K0e,LJr),e(Ef,yJr),e(Ef,roe),e(roe,xJr),e(Ef,$Jr),e(oa,kJr),M(Jw,oa,null),e(Cr,SJr),e(Cr,Kr),M(S$,Kr,null),e(Kr,RJr),e(Kr,Z0e),e(Z0e,PJr),e(Kr,BJr),e(Kr,$n),e($n,IJr),e($n,ewe),e(ewe,NJr),e($n,qJr),e($n,owe),e(owe,jJr),e($n,DJr),e($n,rwe),e(rwe,GJr),e($n,OJr),e(Kr,VJr),e(Kr,twe),e(twe,Yw),e(Yw,awe),e(awe,XJr),e(Yw,zJr),e(Yw,toe),e(toe,WJr),e(Yw,QJr),e(Kr,HJr),M(Kw,Kr,null),vVe=!0},p(f,[_]){const R$={};_&2&&(R$.$$scope={dirty:_,ctx:f}),Sf.$set(R$);const nwe={};_&2&&(nwe.$$scope={dirty:_,ctx:f}),Dg.$set(nwe);const swe={};_&2&&(swe.$$scope={dirty:_,ctx:f}),Mh.$set(swe);const lwe={};_&2&&(lwe.$$scope={dirty:_,ctx:f}),ap.$set(lwe);const P$={};_&2&&(P$.$$scope={dirty:_,ctx:f}),np.$set(P$);const iwe={};_&2&&(iwe.$$scope={dirty:_,ctx:f}),wp.$set(iwe);const kn={};_&2&&(kn.$$scope={dirty:_,ctx:f}),Ap.$set(kn);const dwe={};_&2&&(dwe.$$scope={dirty:_,ctx:f}),xp.$set(dwe);const cwe={};_&2&&(cwe.$$scope={dirty:_,ctx:f}),x_.$set(cwe);const fwe={};_&2&&(fwe.$$scope={dirty:_,ctx:f}),k_.$set(fwe);const B$={};_&2&&(B$.$$scope={dirty:_,ctx:f}),M7.$set(B$);const mwe={};_&2&&(mwe.$$scope={dirty:_,ctx:f}),C7.$set(mwe);const I$={};_&2&&(I$.$$scope={dirty:_,ctx:f}),c2.$set(I$);const gwe={};_&2&&(gwe.$$scope={dirty:_,ctx:f}),m2.$set(gwe);const N$={};_&2&&(N$.$$scope={dirty:_,ctx:f}),J2.$set(N$);const hwe={};_&2&&(hwe.$$scope={dirty:_,ctx:f}),K2.$set(hwe);const pwe={};_&2&&(pwe.$$scope={dirty:_,ctx:f}),_1.$set(pwe);const uwe={};_&2&&(uwe.$$scope={dirty:_,ctx:f}),v1.$set(uwe);const Cf={};_&2&&(Cf.$$scope={dirty:_,ctx:f}),pb.$set(Cf);const _we={};_&2&&(_we.$$scope={dirty:_,ctx:f}),_b.$set(_we);const bwe={};_&2&&(bwe.$$scope={dirty:_,ctx:f}),Hb.$set(bwe);const vwe={};_&2&&(vwe.$$scope={dirty:_,ctx:f}),Jb.$set(vwe);const q$={};_&2&&(q$.$$scope={dirty:_,ctx:f}),tv.$set(q$);const Fwe={};_&2&&(Fwe.$$scope={dirty:_,ctx:f}),nv.$set(Fwe);const Twe={};_&2&&(Twe.$$scope={dirty:_,ctx:f}),Ov.$set(Twe);const Mwe={};_&2&&(Mwe.$$scope={dirty:_,ctx:f}),Xv.$set(Mwe);const rt={};_&2&&(rt.$$scope={dirty:_,ctx:f}),SF.$set(rt);const j$={};_&2&&(j$.$$scope={dirty:_,ctx:f}),PF.$set(j$);const Ewe={};_&2&&(Ewe.$$scope={dirty:_,ctx:f}),NF.$set(Ewe);const D$={};_&2&&(D$.$$scope={dirty:_,ctx:f}),jF.$set(D$);const Cwe={};_&2&&(Cwe.$$scope={dirty:_,ctx:f}),eT.$set(Cwe);const tt={};_&2&&(tt.$$scope={dirty:_,ctx:f}),rT.$set(tt);const wwe={};_&2&&(wwe.$$scope={dirty:_,ctx:f}),nT.$set(wwe);const wf={};_&2&&(wf.$$scope={dirty:_,ctx:f}),lT.$set(wf);const Awe={};_&2&&(Awe.$$scope={dirty:_,ctx:f}),cT.$set(Awe);const Lwe={};_&2&&(Lwe.$$scope={dirty:_,ctx:f}),mT.$set(Lwe);const L={};_&2&&(L.$$scope={dirty:_,ctx:f}),ET.$set(L);const Zw={};_&2&&(Zw.$$scope={dirty:_,ctx:f}),wT.$set(Zw);const ywe={};_&2&&(ywe.$$scope={dirty:_,ctx:f}),ST.$set(ywe);const xwe={};_&2&&(xwe.$$scope={dirty:_,ctx:f}),PT.$set(xwe);const eA={};_&2&&(eA.$$scope={dirty:_,ctx:f}),WT.$set(eA);const $we={};_&2&&($we.$$scope={dirty:_,ctx:f}),HT.$set($we);const kwe={};_&2&&(kwe.$$scope={dirty:_,ctx:f}),KT.$set(kwe);const oA={};_&2&&(oA.$$scope={dirty:_,ctx:f}),eM.$set(oA);const Swe={};_&2&&(Swe.$$scope={dirty:_,ctx:f}),lM.$set(Swe);const Rwe={};_&2&&(Rwe.$$scope={dirty:_,ctx:f}),dM.$set(Rwe);const rA={};_&2&&(rA.$$scope={dirty:_,ctx:f}),hM.$set(rA);const Pwe={};_&2&&(Pwe.$$scope={dirty:_,ctx:f}),uM.$set(Pwe);const Bwe={};_&2&&(Bwe.$$scope={dirty:_,ctx:f}),FM.$set(Bwe);const tA={};_&2&&(tA.$$scope={dirty:_,ctx:f}),MM.$set(tA);const Iwe={};_&2&&(Iwe.$$scope={dirty:_,ctx:f}),wM.$set(Iwe);const Nwe={};_&2&&(Nwe.$$scope={dirty:_,ctx:f}),LM.$set(Nwe);const aA={};_&2&&(aA.$$scope={dirty:_,ctx:f}),RM.$set(aA);const qwe={};_&2&&(qwe.$$scope={dirty:_,ctx:f}),BM.$set(qwe);const jwe={};_&2&&(jwe.$$scope={dirty:_,ctx:f}),qM.$set(jwe);const nA={};_&2&&(nA.$$scope={dirty:_,ctx:f}),DM.$set(nA);const Dwe={};_&2&&(Dwe.$$scope={dirty:_,ctx:f}),RE.$set(Dwe);const Gwe={};_&2&&(Gwe.$$scope={dirty:_,ctx:f}),BE.$set(Gwe);const sA={};_&2&&(sA.$$scope={dirty:_,ctx:f}),n4.$set(sA);const Owe={};_&2&&(Owe.$$scope={dirty:_,ctx:f}),l4.$set(Owe);const Vwe={};_&2&&(Vwe.$$scope={dirty:_,ctx:f}),T4.$set(Vwe);const lA={};_&2&&(lA.$$scope={dirty:_,ctx:f}),E4.$set(lA);const Xwe={};_&2&&(Xwe.$$scope={dirty:_,ctx:f}),y4.$set(Xwe);const zwe={};_&2&&(zwe.$$scope={dirty:_,ctx:f}),$4.$set(zwe);const iA={};_&2&&(iA.$$scope={dirty:_,ctx:f}),Y4.$set(iA);const Wwe={};_&2&&(Wwe.$$scope={dirty:_,ctx:f}),Z4.$set(Wwe);const Qwe={};_&2&&(Qwe.$$scope={dirty:_,ctx:f}),cC.$set(Qwe);const dA={};_&2&&(dA.$$scope={dirty:_,ctx:f}),mC.$set(dA);const Hwe={};_&2&&(Hwe.$$scope={dirty:_,ctx:f}),jC.$set(Hwe);const Uwe={};_&2&&(Uwe.$$scope={dirty:_,ctx:f}),GC.$set(Uwe);const cA={};_&2&&(cA.$$scope={dirty:_,ctx:f}),n5.$set(cA);const Jwe={};_&2&&(Jwe.$$scope={dirty:_,ctx:f}),l5.$set(Jwe);const Ywe={};_&2&&(Ywe.$$scope={dirty:_,ctx:f}),c5.$set(Ywe);const fA={};_&2&&(fA.$$scope={dirty:_,ctx:f}),m5.$set(fA);const Kwe={};_&2&&(Kwe.$$scope={dirty:_,ctx:f}),h5.$set(Kwe);const Zwe={};_&2&&(Zwe.$$scope={dirty:_,ctx:f}),u5.$set(Zwe);const mA={};_&2&&(mA.$$scope={dirty:_,ctx:f}),N5.$set(mA);const eAe={};_&2&&(eAe.$$scope={dirty:_,ctx:f}),j5.$set(eAe);const oAe={};_&2&&(oAe.$$scope={dirty:_,ctx:f}),s3.$set(oAe);const gA={};_&2&&(gA.$$scope={dirty:_,ctx:f}),i3.$set(gA);const rAe={};_&2&&(rAe.$$scope={dirty:_,ctx:f}),c3.$set(rAe);const tAe={};_&2&&(tAe.$$scope={dirty:_,ctx:f}),m3.$set(tAe);const hA={};_&2&&(hA.$$scope={dirty:_,ctx:f}),h3.$set(hA);const aAe={};_&2&&(aAe.$$scope={dirty:_,ctx:f}),u3.$set(aAe);const nAe={};_&2&&(nAe.$$scope={dirty:_,ctx:f}),X3.$set(nAe);const pA={};_&2&&(pA.$$scope={dirty:_,ctx:f}),W3.$set(pA);const sAe={};_&2&&(sAe.$$scope={dirty:_,ctx:f}),t0.$set(sAe);const lAe={};_&2&&(lAe.$$scope={dirty:_,ctx:f}),n0.$set(lAe);const uA={};_&2&&(uA.$$scope={dirty:_,ctx:f}),v0.$set(uA);const iAe={};_&2&&(iAe.$$scope={dirty:_,ctx:f}),T0.$set(iAe);const dAe={};_&2&&(dAe.$$scope={dirty:_,ctx:f}),S0.$set(dAe);const _A={};_&2&&(_A.$$scope={dirty:_,ctx:f}),P0.$set(_A);const cAe={};_&2&&(cAe.$$scope={dirty:_,ctx:f}),z0.$set(cAe);const fAe={};_&2&&(fAe.$$scope={dirty:_,ctx:f}),Q0.$set(fAe);const bA={};_&2&&(bA.$$scope={dirty:_,ctx:f}),aw.$set(bA);const mAe={};_&2&&(mAe.$$scope={dirty:_,ctx:f}),sw.$set(mAe);const gAe={};_&2&&(gAe.$$scope={dirty:_,ctx:f}),_w.$set(gAe);const vA={};_&2&&(vA.$$scope={dirty:_,ctx:f}),vw.$set(vA);const hAe={};_&2&&(hAe.$$scope={dirty:_,ctx:f}),yw.$set(hAe);const pAe={};_&2&&(pAe.$$scope={dirty:_,ctx:f}),$w.$set(pAe);const FA={};_&2&&(FA.$$scope={dirty:_,ctx:f}),jw.$set(FA);const uAe={};_&2&&(uAe.$$scope={dirty:_,ctx:f}),Gw.$set(uAe);const _Ae={};_&2&&(_Ae.$$scope={dirty:_,ctx:f}),Vw.$set(_Ae);const TA={};_&2&&(TA.$$scope={dirty:_,ctx:f}),zw.$set(TA);const bAe={};_&2&&(bAe.$$scope={dirty:_,ctx:f}),Hw.$set(bAe);const vAe={};_&2&&(vAe.$$scope={dirty:_,ctx:f}),Jw.$set(vAe);const MA={};_&2&&(MA.$$scope={dirty:_,ctx:f}),Kw.$set(MA)},i(f){vVe||(E(d.$$.fragment,f),E(ya.$$.fragment,f),E(EL.$$.fragment,f),E(CL.$$.fragment,f),E(Sf.$$.fragment,f),E(wL.$$.fragment,f),E(AL.$$.fragment,f),E(xL.$$.fragment,f),E(Dg.$$.fragment,f),E($L.$$.fragment,f),E(kL.$$.fragment,f),E(SL.$$.fragment,f),E(BL.$$.fragment,f),E(Mh.$$.fragment,f),E(IL.$$.fragment,f),E(NL.$$.fragment,f),E(qL.$$.fragment,f),E(GL.$$.fragment,f),E(ap.$$.fragment,f),E(np.$$.fragment,f),E(OL.$$.fragment,f),E(VL.$$.fragment,f),E(XL.$$.fragment,f),E(QL.$$.fragment,f),E(wp.$$.fragment,f),E(Ap.$$.fragment,f),E(HL.$$.fragment,f),E(UL.$$.fragment,f),E(JL.$$.fragment,f),E(KL.$$.fragment,f),E(xp.$$.fragment,f),E(ZL.$$.fragment,f),E(x_.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ty.$$.fragment,f),E(k_.$$.fragment,f),E(ay.$$.fragment,f),E(M7.$$.fragment,f),E(ny.$$.fragment,f),E(sy.$$.fragment,f),E(iy.$$.fragment,f),E(C7.$$.fragment,f),E(dy.$$.fragment,f),E(c2.$$.fragment,f),E(cy.$$.fragment,f),E(fy.$$.fragment,f),E(gy.$$.fragment,f),E(m2.$$.fragment,f),E(hy.$$.fragment,f),E(J2.$$.fragment,f),E(py.$$.fragment,f),E(uy.$$.fragment,f),E(by.$$.fragment,f),E(K2.$$.fragment,f),E(vy.$$.fragment,f),E(_1.$$.fragment,f),E(Fy.$$.fragment,f),E(Ty.$$.fragment,f),E(Ey.$$.fragment,f),E(v1.$$.fragment,f),E(Cy.$$.fragment,f),E(pb.$$.fragment,f),E(wy.$$.fragment,f),E(Ay.$$.fragment,f),E(yy.$$.fragment,f),E(_b.$$.fragment,f),E(xy.$$.fragment,f),E(Hb.$$.fragment,f),E($y.$$.fragment,f),E(ky.$$.fragment,f),E(Ry.$$.fragment,f),E(Jb.$$.fragment,f),E(Py.$$.fragment,f),E(tv.$$.fragment,f),E(By.$$.fragment,f),E(Iy.$$.fragment,f),E(qy.$$.fragment,f),E(nv.$$.fragment,f),E(jy.$$.fragment,f),E(Ov.$$.fragment,f),E(Dy.$$.fragment,f),E(Gy.$$.fragment,f),E(Vy.$$.fragment,f),E(Xv.$$.fragment,f),E(Xy.$$.fragment,f),E(SF.$$.fragment,f),E(zy.$$.fragment,f),E(Wy.$$.fragment,f),E(Hy.$$.fragment,f),E(PF.$$.fragment,f),E(Uy.$$.fragment,f),E(NF.$$.fragment,f),E(Jy.$$.fragment,f),E(Yy.$$.fragment,f),E(Zy.$$.fragment,f),E(jF.$$.fragment,f),E(e8.$$.fragment,f),E(eT.$$.fragment,f),E(o8.$$.fragment,f),E(r8.$$.fragment,f),E(a8.$$.fragment,f),E(rT.$$.fragment,f),E(n8.$$.fragment,f),E(nT.$$.fragment,f),E(s8.$$.fragment,f),E(l8.$$.fragment,f),E(d8.$$.fragment,f),E(lT.$$.fragment,f),E(c8.$$.fragment,f),E(cT.$$.fragment,f),E(f8.$$.fragment,f),E(m8.$$.fragment,f),E(h8.$$.fragment,f),E(mT.$$.fragment,f),E(p8.$$.fragment,f),E(ET.$$.fragment,f),E(u8.$$.fragment,f),E(_8.$$.fragment,f),E(v8.$$.fragment,f),E(wT.$$.fragment,f),E(F8.$$.fragment,f),E(ST.$$.fragment,f),E(T8.$$.fragment,f),E(M8.$$.fragment,f),E(C8.$$.fragment,f),E(PT.$$.fragment,f),E(w8.$$.fragment,f),E(WT.$$.fragment,f),E(A8.$$.fragment,f),E(L8.$$.fragment,f),E(x8.$$.fragment,f),E(HT.$$.fragment,f),E($8.$$.fragment,f),E(KT.$$.fragment,f),E(S8.$$.fragment,f),E(R8.$$.fragment,f),E(B8.$$.fragment,f),E(eM.$$.fragment,f),E(I8.$$.fragment,f),E(lM.$$.fragment,f),E(N8.$$.fragment,f),E(q8.$$.fragment,f),E(D8.$$.fragment,f),E(dM.$$.fragment,f),E(G8.$$.fragment,f),E(hM.$$.fragment,f),E(O8.$$.fragment,f),E(V8.$$.fragment,f),E(z8.$$.fragment,f),E(uM.$$.fragment,f),E(W8.$$.fragment,f),E(FM.$$.fragment,f),E(H8.$$.fragment,f),E(U8.$$.fragment,f),E(Y8.$$.fragment,f),E(MM.$$.fragment,f),E(K8.$$.fragment,f),E(wM.$$.fragment,f),E(Z8.$$.fragment,f),E(e9.$$.fragment,f),E(r9.$$.fragment,f),E(LM.$$.fragment,f),E(t9.$$.fragment,f),E(RM.$$.fragment,f),E(a9.$$.fragment,f),E(n9.$$.fragment,f),E(l9.$$.fragment,f),E(BM.$$.fragment,f),E(i9.$$.fragment,f),E(qM.$$.fragment,f),E(d9.$$.fragment,f),E(c9.$$.fragment,f),E(m9.$$.fragment,f),E(DM.$$.fragment,f),E(g9.$$.fragment,f),E(RE.$$.fragment,f),E(h9.$$.fragment,f),E(p9.$$.fragment,f),E(_9.$$.fragment,f),E(BE.$$.fragment,f),E(b9.$$.fragment,f),E(n4.$$.fragment,f),E(v9.$$.fragment,f),E(F9.$$.fragment,f),E(M9.$$.fragment,f),E(l4.$$.fragment,f),E(E9.$$.fragment,f),E(T4.$$.fragment,f),E(C9.$$.fragment,f),E(w9.$$.fragment,f),E(L9.$$.fragment,f),E(E4.$$.fragment,f),E(y9.$$.fragment,f),E(y4.$$.fragment,f),E(x9.$$.fragment,f),E($9.$$.fragment,f),E(S9.$$.fragment,f),E($4.$$.fragment,f),E(R9.$$.fragment,f),E(Y4.$$.fragment,f),E(P9.$$.fragment,f),E(B9.$$.fragment,f),E(N9.$$.fragment,f),E(Z4.$$.fragment,f),E(q9.$$.fragment,f),E(cC.$$.fragment,f),E(j9.$$.fragment,f),E(D9.$$.fragment,f),E(O9.$$.fragment,f),E(mC.$$.fragment,f),E(V9.$$.fragment,f),E(jC.$$.fragment,f),E(X9.$$.fragment,f),E(z9.$$.fragment,f),E(Q9.$$.fragment,f),E(GC.$$.fragment,f),E(H9.$$.fragment,f),E(n5.$$.fragment,f),E(U9.$$.fragment,f),E(J9.$$.fragment,f),E(K9.$$.fragment,f),E(l5.$$.fragment,f),E(Z9.$$.fragment,f),E(c5.$$.fragment,f),E(ox.$$.fragment,f),E(rx.$$.fragment,f),E(ax.$$.fragment,f),E(m5.$$.fragment,f),E(nx.$$.fragment,f),E(h5.$$.fragment,f),E(sx.$$.fragment,f),E(lx.$$.fragment,f),E(dx.$$.fragment,f),E(u5.$$.fragment,f),E(cx.$$.fragment,f),E(N5.$$.fragment,f),E(fx.$$.fragment,f),E(mx.$$.fragment,f),E(hx.$$.fragment,f),E(j5.$$.fragment,f),E(px.$$.fragment,f),E(s3.$$.fragment,f),E(ux.$$.fragment,f),E(_x.$$.fragment,f),E(vx.$$.fragment,f),E(i3.$$.fragment,f),E(Fx.$$.fragment,f),E(c3.$$.fragment,f),E(Tx.$$.fragment,f),E(Mx.$$.fragment,f),E(Cx.$$.fragment,f),E(m3.$$.fragment,f),E(wx.$$.fragment,f),E(h3.$$.fragment,f),E(Ax.$$.fragment,f),E(Lx.$$.fragment,f),E(xx.$$.fragment,f),E(u3.$$.fragment,f),E($x.$$.fragment,f),E(X3.$$.fragment,f),E(kx.$$.fragment,f),E(Sx.$$.fragment,f),E(Px.$$.fragment,f),E(W3.$$.fragment,f),E(Bx.$$.fragment,f),E(t0.$$.fragment,f),E(Ix.$$.fragment,f),E(Nx.$$.fragment,f),E(jx.$$.fragment,f),E(n0.$$.fragment,f),E(Dx.$$.fragment,f),E(v0.$$.fragment,f),E(Gx.$$.fragment,f),E(Ox.$$.fragment,f),E(Xx.$$.fragment,f),E(T0.$$.fragment,f),E(zx.$$.fragment,f),E(S0.$$.fragment,f),E(Wx.$$.fragment,f),E(Qx.$$.fragment,f),E(Ux.$$.fragment,f),E(P0.$$.fragment,f),E(Jx.$$.fragment,f),E(z0.$$.fragment,f),E(Yx.$$.fragment,f),E(Kx.$$.fragment,f),E(e$.$$.fragment,f),E(Q0.$$.fragment,f),E(o$.$$.fragment,f),E(aw.$$.fragment,f),E(r$.$$.fragment,f),E(t$.$$.fragment,f),E(n$.$$.fragment,f),E(sw.$$.fragment,f),E(s$.$$.fragment,f),E(_w.$$.fragment,f),E(l$.$$.fragment,f),E(i$.$$.fragment,f),E(c$.$$.fragment,f),E(vw.$$.fragment,f),E(f$.$$.fragment,f),E(yw.$$.fragment,f),E(m$.$$.fragment,f),E(g$.$$.fragment,f),E(p$.$$.fragment,f),E($w.$$.fragment,f),E(u$.$$.fragment,f),E(jw.$$.fragment,f),E(_$.$$.fragment,f),E(b$.$$.fragment,f),E(F$.$$.fragment,f),E(Gw.$$.fragment,f),E(T$.$$.fragment,f),E(Vw.$$.fragment,f),E(M$.$$.fragment,f),E(E$.$$.fragment,f),E(w$.$$.fragment,f),E(zw.$$.fragment,f),E(A$.$$.fragment,f),E(Hw.$$.fragment,f),E(y$.$$.fragment,f),E(x$.$$.fragment,f),E(k$.$$.fragment,f),E(Jw.$$.fragment,f),E(S$.$$.fragment,f),E(Kw.$$.fragment,f),vVe=!0)},o(f){C(d.$$.fragment,f),C(ya.$$.fragment,f),C(EL.$$.fragment,f),C(CL.$$.fragment,f),C(Sf.$$.fragment,f),C(wL.$$.fragment,f),C(AL.$$.fragment,f),C(xL.$$.fragment,f),C(Dg.$$.fragment,f),C($L.$$.fragment,f),C(kL.$$.fragment,f),C(SL.$$.fragment,f),C(BL.$$.fragment,f),C(Mh.$$.fragment,f),C(IL.$$.fragment,f),C(NL.$$.fragment,f),C(qL.$$.fragment,f),C(GL.$$.fragment,f),C(ap.$$.fragment,f),C(np.$$.fragment,f),C(OL.$$.fragment,f),C(VL.$$.fragment,f),C(XL.$$.fragment,f),C(QL.$$.fragment,f),C(wp.$$.fragment,f),C(Ap.$$.fragment,f),C(HL.$$.fragment,f),C(UL.$$.fragment,f),C(JL.$$.fragment,f),C(KL.$$.fragment,f),C(xp.$$.fragment,f),C(ZL.$$.fragment,f),C(x_.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ty.$$.fragment,f),C(k_.$$.fragment,f),C(ay.$$.fragment,f),C(M7.$$.fragment,f),C(ny.$$.fragment,f),C(sy.$$.fragment,f),C(iy.$$.fragment,f),C(C7.$$.fragment,f),C(dy.$$.fragment,f),C(c2.$$.fragment,f),C(cy.$$.fragment,f),C(fy.$$.fragment,f),C(gy.$$.fragment,f),C(m2.$$.fragment,f),C(hy.$$.fragment,f),C(J2.$$.fragment,f),C(py.$$.fragment,f),C(uy.$$.fragment,f),C(by.$$.fragment,f),C(K2.$$.fragment,f),C(vy.$$.fragment,f),C(_1.$$.fragment,f),C(Fy.$$.fragment,f),C(Ty.$$.fragment,f),C(Ey.$$.fragment,f),C(v1.$$.fragment,f),C(Cy.$$.fragment,f),C(pb.$$.fragment,f),C(wy.$$.fragment,f),C(Ay.$$.fragment,f),C(yy.$$.fragment,f),C(_b.$$.fragment,f),C(xy.$$.fragment,f),C(Hb.$$.fragment,f),C($y.$$.fragment,f),C(ky.$$.fragment,f),C(Ry.$$.fragment,f),C(Jb.$$.fragment,f),C(Py.$$.fragment,f),C(tv.$$.fragment,f),C(By.$$.fragment,f),C(Iy.$$.fragment,f),C(qy.$$.fragment,f),C(nv.$$.fragment,f),C(jy.$$.fragment,f),C(Ov.$$.fragment,f),C(Dy.$$.fragment,f),C(Gy.$$.fragment,f),C(Vy.$$.fragment,f),C(Xv.$$.fragment,f),C(Xy.$$.fragment,f),C(SF.$$.fragment,f),C(zy.$$.fragment,f),C(Wy.$$.fragment,f),C(Hy.$$.fragment,f),C(PF.$$.fragment,f),C(Uy.$$.fragment,f),C(NF.$$.fragment,f),C(Jy.$$.fragment,f),C(Yy.$$.fragment,f),C(Zy.$$.fragment,f),C(jF.$$.fragment,f),C(e8.$$.fragment,f),C(eT.$$.fragment,f),C(o8.$$.fragment,f),C(r8.$$.fragment,f),C(a8.$$.fragment,f),C(rT.$$.fragment,f),C(n8.$$.fragment,f),C(nT.$$.fragment,f),C(s8.$$.fragment,f),C(l8.$$.fragment,f),C(d8.$$.fragment,f),C(lT.$$.fragment,f),C(c8.$$.fragment,f),C(cT.$$.fragment,f),C(f8.$$.fragment,f),C(m8.$$.fragment,f),C(h8.$$.fragment,f),C(mT.$$.fragment,f),C(p8.$$.fragment,f),C(ET.$$.fragment,f),C(u8.$$.fragment,f),C(_8.$$.fragment,f),C(v8.$$.fragment,f),C(wT.$$.fragment,f),C(F8.$$.fragment,f),C(ST.$$.fragment,f),C(T8.$$.fragment,f),C(M8.$$.fragment,f),C(C8.$$.fragment,f),C(PT.$$.fragment,f),C(w8.$$.fragment,f),C(WT.$$.fragment,f),C(A8.$$.fragment,f),C(L8.$$.fragment,f),C(x8.$$.fragment,f),C(HT.$$.fragment,f),C($8.$$.fragment,f),C(KT.$$.fragment,f),C(S8.$$.fragment,f),C(R8.$$.fragment,f),C(B8.$$.fragment,f),C(eM.$$.fragment,f),C(I8.$$.fragment,f),C(lM.$$.fragment,f),C(N8.$$.fragment,f),C(q8.$$.fragment,f),C(D8.$$.fragment,f),C(dM.$$.fragment,f),C(G8.$$.fragment,f),C(hM.$$.fragment,f),C(O8.$$.fragment,f),C(V8.$$.fragment,f),C(z8.$$.fragment,f),C(uM.$$.fragment,f),C(W8.$$.fragment,f),C(FM.$$.fragment,f),C(H8.$$.fragment,f),C(U8.$$.fragment,f),C(Y8.$$.fragment,f),C(MM.$$.fragment,f),C(K8.$$.fragment,f),C(wM.$$.fragment,f),C(Z8.$$.fragment,f),C(e9.$$.fragment,f),C(r9.$$.fragment,f),C(LM.$$.fragment,f),C(t9.$$.fragment,f),C(RM.$$.fragment,f),C(a9.$$.fragment,f),C(n9.$$.fragment,f),C(l9.$$.fragment,f),C(BM.$$.fragment,f),C(i9.$$.fragment,f),C(qM.$$.fragment,f),C(d9.$$.fragment,f),C(c9.$$.fragment,f),C(m9.$$.fragment,f),C(DM.$$.fragment,f),C(g9.$$.fragment,f),C(RE.$$.fragment,f),C(h9.$$.fragment,f),C(p9.$$.fragment,f),C(_9.$$.fragment,f),C(BE.$$.fragment,f),C(b9.$$.fragment,f),C(n4.$$.fragment,f),C(v9.$$.fragment,f),C(F9.$$.fragment,f),C(M9.$$.fragment,f),C(l4.$$.fragment,f),C(E9.$$.fragment,f),C(T4.$$.fragment,f),C(C9.$$.fragment,f),C(w9.$$.fragment,f),C(L9.$$.fragment,f),C(E4.$$.fragment,f),C(y9.$$.fragment,f),C(y4.$$.fragment,f),C(x9.$$.fragment,f),C($9.$$.fragment,f),C(S9.$$.fragment,f),C($4.$$.fragment,f),C(R9.$$.fragment,f),C(Y4.$$.fragment,f),C(P9.$$.fragment,f),C(B9.$$.fragment,f),C(N9.$$.fragment,f),C(Z4.$$.fragment,f),C(q9.$$.fragment,f),C(cC.$$.fragment,f),C(j9.$$.fragment,f),C(D9.$$.fragment,f),C(O9.$$.fragment,f),C(mC.$$.fragment,f),C(V9.$$.fragment,f),C(jC.$$.fragment,f),C(X9.$$.fragment,f),C(z9.$$.fragment,f),C(Q9.$$.fragment,f),C(GC.$$.fragment,f),C(H9.$$.fragment,f),C(n5.$$.fragment,f),C(U9.$$.fragment,f),C(J9.$$.fragment,f),C(K9.$$.fragment,f),C(l5.$$.fragment,f),C(Z9.$$.fragment,f),C(c5.$$.fragment,f),C(ox.$$.fragment,f),C(rx.$$.fragment,f),C(ax.$$.fragment,f),C(m5.$$.fragment,f),C(nx.$$.fragment,f),C(h5.$$.fragment,f),C(sx.$$.fragment,f),C(lx.$$.fragment,f),C(dx.$$.fragment,f),C(u5.$$.fragment,f),C(cx.$$.fragment,f),C(N5.$$.fragment,f),C(fx.$$.fragment,f),C(mx.$$.fragment,f),C(hx.$$.fragment,f),C(j5.$$.fragment,f),C(px.$$.fragment,f),C(s3.$$.fragment,f),C(ux.$$.fragment,f),C(_x.$$.fragment,f),C(vx.$$.fragment,f),C(i3.$$.fragment,f),C(Fx.$$.fragment,f),C(c3.$$.fragment,f),C(Tx.$$.fragment,f),C(Mx.$$.fragment,f),C(Cx.$$.fragment,f),C(m3.$$.fragment,f),C(wx.$$.fragment,f),C(h3.$$.fragment,f),C(Ax.$$.fragment,f),C(Lx.$$.fragment,f),C(xx.$$.fragment,f),C(u3.$$.fragment,f),C($x.$$.fragment,f),C(X3.$$.fragment,f),C(kx.$$.fragment,f),C(Sx.$$.fragment,f),C(Px.$$.fragment,f),C(W3.$$.fragment,f),C(Bx.$$.fragment,f),C(t0.$$.fragment,f),C(Ix.$$.fragment,f),C(Nx.$$.fragment,f),C(jx.$$.fragment,f),C(n0.$$.fragment,f),C(Dx.$$.fragment,f),C(v0.$$.fragment,f),C(Gx.$$.fragment,f),C(Ox.$$.fragment,f),C(Xx.$$.fragment,f),C(T0.$$.fragment,f),C(zx.$$.fragment,f),C(S0.$$.fragment,f),C(Wx.$$.fragment,f),C(Qx.$$.fragment,f),C(Ux.$$.fragment,f),C(P0.$$.fragment,f),C(Jx.$$.fragment,f),C(z0.$$.fragment,f),C(Yx.$$.fragment,f),C(Kx.$$.fragment,f),C(e$.$$.fragment,f),C(Q0.$$.fragment,f),C(o$.$$.fragment,f),C(aw.$$.fragment,f),C(r$.$$.fragment,f),C(t$.$$.fragment,f),C(n$.$$.fragment,f),C(sw.$$.fragment,f),C(s$.$$.fragment,f),C(_w.$$.fragment,f),C(l$.$$.fragment,f),C(i$.$$.fragment,f),C(c$.$$.fragment,f),C(vw.$$.fragment,f),C(f$.$$.fragment,f),C(yw.$$.fragment,f),C(m$.$$.fragment,f),C(g$.$$.fragment,f),C(p$.$$.fragment,f),C($w.$$.fragment,f),C(u$.$$.fragment,f),C(jw.$$.fragment,f),C(_$.$$.fragment,f),C(b$.$$.fragment,f),C(F$.$$.fragment,f),C(Gw.$$.fragment,f),C(T$.$$.fragment,f),C(Vw.$$.fragment,f),C(M$.$$.fragment,f),C(E$.$$.fragment,f),C(w$.$$.fragment,f),C(zw.$$.fragment,f),C(A$.$$.fragment,f),C(Hw.$$.fragment,f),C(y$.$$.fragment,f),C(x$.$$.fragment,f),C(k$.$$.fragment,f),C(Jw.$$.fragment,f),C(S$.$$.fragment,f),C(Kw.$$.fragment,f),vVe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(Lf),f&&t(at),f&&t(Oe),f&&t(We),f&&t(xf),w(ya,f),f&&t(Qe),f&&t(Ae),f&&t(Co),f&&t(xa),f&&t(hGe),f&&t(Li),w(EL),f&&t(pGe),f&&t(In),f&&t(uGe),w(CL,f),f&&t(_Ge),f&&t(eS),f&&t(bGe),w(Sf,f),f&&t(vGe),f&&t(yi),w(wL),f&&t(FGe),f&&t(wo),w(AL),w(xL),w(Dg),w($L),f&&t(TGe),f&&t($i),w(kL),f&&t(MGe),f&&t(Ao),w(SL),w(BL),w(Mh),w(IL),f&&t(EGe),f&&t(ki),w(NL),f&&t(CGe),f&&t(Lo),w(qL),w(GL),w(ap),w(np),w(OL),f&&t(wGe),f&&t(Si),w(VL),f&&t(AGe),f&&t(yo),w(XL),w(QL),w(wp),w(Ap),w(HL),f&&t(LGe),f&&t(Pi),w(UL),f&&t(yGe),f&&t(xo),w(JL),w(KL),w(xp),w(ZL),w(x_),f&&t(xGe),f&&t(Ni),w(ey),f&&t($Ge),f&&t($o),w(oy),w(ty),w(k_),w(ay),w(M7),f&&t(kGe),f&&t(Di),w(ny),f&&t(SGe),f&&t(ko),w(sy),w(iy),w(C7),w(dy),w(c2),f&&t(RGe),f&&t(Vi),w(cy),f&&t(PGe),f&&t(So),w(fy),w(gy),w(m2),w(hy),w(J2),f&&t(BGe),f&&t(Wi),w(py),f&&t(IGe),f&&t(Ro),w(uy),w(by),w(K2),w(vy),w(_1),f&&t(NGe),f&&t(Ui),w(Fy),f&&t(qGe),f&&t(Po),w(Ty),w(Ey),w(v1),w(Cy),w(pb),f&&t(jGe),f&&t(Ki),w(wy),f&&t(DGe),f&&t(Bo),w(Ay),w(yy),w(_b),w(xy),w(Hb),f&&t(GGe),f&&t(od),w($y),f&&t(OGe),f&&t(Io),w(ky),w(Ry),w(Jb),w(Py),w(tv),f&&t(VGe),f&&t(ad),w(By),f&&t(XGe),f&&t(No),w(Iy),w(qy),w(nv),w(jy),w(Ov),f&&t(zGe),f&&t(ld),w(Dy),f&&t(WGe),f&&t(qo),w(Gy),w(Vy),w(Xv),w(Xy),w(SF),f&&t(QGe),f&&t(cd),w(zy),f&&t(HGe),f&&t(jo),w(Wy),w(Hy),w(PF),w(Uy),w(NF),f&&t(UGe),f&&t(gd),w(Jy),f&&t(JGe),f&&t(Do),w(Yy),w(Zy),w(jF),w(e8),w(eT),f&&t(YGe),f&&t(ud),w(o8),f&&t(KGe),f&&t(Go),w(r8),w(a8),w(rT),w(n8),w(nT),f&&t(ZGe),f&&t(vd),w(s8),f&&t(eOe),f&&t(Oo),w(l8),w(d8),w(lT),w(c8),w(cT),f&&t(oOe),f&&t(Md),w(f8),f&&t(rOe),f&&t(Vo),w(m8),w(h8),w(mT),w(p8),w(ET),f&&t(tOe),f&&t(wd),w(u8),f&&t(aOe),f&&t(Xo),w(_8),w(v8),w(wT),w(F8),w(ST),f&&t(nOe),f&&t(yd),w(T8),f&&t(sOe),f&&t(zo),w(M8),w(C8),w(PT),w(w8),w(WT),f&&t(lOe),f&&t(kd),w(A8),f&&t(iOe),f&&t(Wo),w(L8),w(x8),w(HT),w($8),w(KT),f&&t(dOe),f&&t(Pd),w(S8),f&&t(cOe),f&&t(Qo),w(R8),w(B8),w(eM),w(I8),w(lM),f&&t(fOe),f&&t(Nd),w(N8),f&&t(mOe),f&&t(Ho),w(q8),w(D8),w(dM),w(G8),w(hM),f&&t(gOe),f&&t(Gd),w(O8),f&&t(hOe),f&&t(Uo),w(V8),w(z8),w(uM),w(W8),w(FM),f&&t(pOe),f&&t(Xd),w(H8),f&&t(uOe),f&&t(Jo),w(U8),w(Y8),w(MM),w(K8),w(wM),f&&t(_Oe),f&&t(Qd),w(Z8),f&&t(bOe),f&&t(Yo),w(e9),w(r9),w(LM),w(t9),w(RM),f&&t(vOe),f&&t(Jd),w(a9),f&&t(FOe),f&&t(Ko),w(n9),w(l9),w(BM),w(i9),w(qM),f&&t(TOe),f&&t(Zd),w(d9),f&&t(MOe),f&&t(Zo),w(c9),w(m9),w(DM),w(g9),w(RE),f&&t(EOe),f&&t(rc),w(h9),f&&t(COe),f&&t(er),w(p9),w(_9),w(BE),w(b9),w(n4),f&&t(wOe),f&&t(nc),w(v9),f&&t(AOe),f&&t(or),w(F9),w(M9),w(l4),w(E9),w(T4),f&&t(LOe),f&&t(ic),w(C9),f&&t(yOe),f&&t(rr),w(w9),w(L9),w(E4),w(y9),w(y4),f&&t(xOe),f&&t(fc),w(x9),f&&t($Oe),f&&t(tr),w($9),w(S9),w($4),w(R9),w(Y4),f&&t(kOe),f&&t(hc),w(P9),f&&t(SOe),f&&t(ar),w(B9),w(N9),w(Z4),w(q9),w(cC),f&&t(ROe),f&&t(_c),w(j9),f&&t(POe),f&&t(nr),w(D9),w(O9),w(mC),w(V9),w(jC),f&&t(BOe),f&&t(Fc),w(X9),f&&t(IOe),f&&t(sr),w(z9),w(Q9),w(GC),w(H9),w(n5),f&&t(NOe),f&&t(Ec),w(U9),f&&t(qOe),f&&t(lr),w(J9),w(K9),w(l5),w(Z9),w(c5),f&&t(jOe),f&&t(Ac),w(ox),f&&t(DOe),f&&t(ir),w(rx),w(ax),w(m5),w(nx),w(h5),f&&t(GOe),f&&t(xc),w(sx),f&&t(OOe),f&&t(dr),w(lx),w(dx),w(u5),w(cx),w(N5),f&&t(VOe),f&&t(Sc),w(fx),f&&t(XOe),f&&t(cr),w(mx),w(hx),w(j5),w(px),w(s3),f&&t(zOe),f&&t(Bc),w(ux),f&&t(WOe),f&&t(fr),w(_x),w(vx),w(i3),w(Fx),w(c3),f&&t(QOe),f&&t(qc),w(Tx),f&&t(HOe),f&&t(mr),w(Mx),w(Cx),w(m3),w(wx),w(h3),f&&t(UOe),f&&t(Gc),w(Ax),f&&t(JOe),f&&t(gr),w(Lx),w(xx),w(u3),w($x),w(X3),f&&t(YOe),f&&t(Xc),w(kx),f&&t(KOe),f&&t(hr),w(Sx),w(Px),w(W3),w(Bx),w(t0),f&&t(ZOe),f&&t(Qc),w(Ix),f&&t(eVe),f&&t(pr),w(Nx),w(jx),w(n0),w(Dx),w(v0),f&&t(oVe),f&&t(Jc),w(Gx),f&&t(rVe),f&&t(ur),w(Ox),w(Xx),w(T0),w(zx),w(S0),f&&t(tVe),f&&t(Zc),w(Wx),f&&t(aVe),f&&t(_r),w(Qx),w(Ux),w(P0),w(Jx),w(z0),f&&t(nVe),f&&t(rf),w(Yx),f&&t(sVe),f&&t(br),w(Kx),w(e$),w(Q0),w(o$),w(aw),f&&t(lVe),f&&t(nf),w(r$),f&&t(iVe),f&&t(vr),w(t$),w(n$),w(sw),w(s$),w(_w),f&&t(dVe),f&&t(df),w(l$),f&&t(cVe),f&&t(Fr),w(i$),w(c$),w(vw),w(f$),w(yw),f&&t(fVe),f&&t(mf),w(m$),f&&t(mVe),f&&t(Tr),w(g$),w(p$),w($w),w(u$),w(jw),f&&t(gVe),f&&t(pf),w(_$),f&&t(hVe),f&&t(Mr),w(b$),w(F$),w(Gw),w(T$),w(Vw),f&&t(pVe),f&&t(bf),w(M$),f&&t(uVe),f&&t(Er),w(E$),w(w$),w(zw),w(A$),w(Hw),f&&t(_Ve),f&&t(Tf),w(y$),f&&t(bVe),f&&t(Cr),w(x$),w(k$),w(Jw),w(S$),w(Kw)}}}const iGt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function dGt(x){return ljt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class uGt extends tjt{constructor(g){super();ajt(this,g,dGt,lGt,njt,{})}}export{uGt as default,iGt as metadata};
