import{S as bjt,i as vjt,s as Fjt,e as a,k as l,w as F,t as o,M as Tjt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as Mjt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as lYr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Ejt(x){let g,v,p,m,u,d,h,Eo,Ti,yf,at,Mi,Ei,FL,xf,Oe,We,Ci,Sn,TL,Rn,Pn,ML,wi,Bn,EL,Ai,$f,ya;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),u=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Ti=a("code"),yf=o("model_type"),at=o(" attribute is set to the same key you use when registering the config (here "),Mi=a("code"),Ei=o('"new-model"'),FL=o(")."),xf=l(),Oe=a("p"),We=o("Likewise, if your "),Ci=a("code"),Sn=o("NewModel"),TL=o(" is a subclass of "),Rn=a("a"),Pn=o("PreTrainedModel"),ML=o(`, make sure its
`),wi=a("code"),Bn=o("config_class"),EL=o(` attribute is set to the same class you use when registering the model (here
`),Ai=a("code"),$f=o("NewModelConfig"),ya=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var Yk=s(p);m=r(Yk,"NewModelConfig"),Yk.forEach(t),u=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Li=s(d);h=r(Li,"PretrainedConfig"),Li.forEach(t),Eo=r(Ae,`, make sure its
`),Ti=n(Ae,"CODE",{});var Kk=s(Ti);yf=r(Kk,"model_type"),Kk.forEach(t),at=r(Ae," attribute is set to the same key you use when registering the config (here "),Mi=n(Ae,"CODE",{});var Zk=s(Mi);Ei=r(Zk,'"new-model"'),Zk.forEach(t),FL=r(Ae,")."),Ae.forEach(t),xf=i(Qe),Oe=n(Qe,"P",{});var Co=s(Oe);We=r(Co,"Likewise, if your "),Ci=n(Co,"CODE",{});var xa=s(Ci);Sn=r(xa,"NewModel"),xa.forEach(t),TL=r(Co," is a subclass of "),Rn=n(Co,"A",{href:!0});var eS=s(Rn);Pn=r(eS,"PreTrainedModel"),eS.forEach(t),ML=r(Co,`, make sure its
`),wi=n(Co,"CODE",{});var kf=s(wi);Bn=r(kf,"config_class"),kf.forEach(t),EL=r(Co,` attribute is set to the same class you use when registering the model (here
`),Ai=n(Co,"CODE",{});var oS=s(Ai);$f=r(oS,"NewModelConfig"),oS.forEach(t),ya=r(Co,")."),Co.forEach(t),this.h()},h(){c(Rn,"href","/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,u),e(g,d),e(d,h),e(g,Eo),e(g,Ti),e(Ti,yf),e(g,at),e(g,Mi),e(Mi,Ei),e(g,FL),b(Qe,xf,Ae),b(Qe,Oe,Ae),e(Oe,We),e(Oe,Ci),e(Ci,Sn),e(Oe,TL),e(Oe,Rn),e(Rn,Pn),e(Oe,ML),e(Oe,wi),e(wi,Bn),e(Oe,EL),e(Oe,Ai),e(Ai,$f),e(Oe,ya)},d(Qe){Qe&&t(g),Qe&&t(xf),Qe&&t(Oe)}}}function Cjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ajt(x){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function Ljt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yjt(x){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function xjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $jt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Sjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ijt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Njt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Djt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ojt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ujt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zjt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Dt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ADt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Dt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ODt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZDt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Gt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TGt(x){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MGt(x){let g,v,p,m,u,d,h,Eo,Ti,yf,at,Mi,Ei,FL,xf,Oe,We,Ci,Sn,TL,Rn,Pn,ML,wi,Bn,EL,Ai,$f,ya,Qe,Ae,Yk,Li,Kk,Zk,Co,xa,eS,kf,oS,Pze,vGe,yi,Sf,rte,CL,Bze,tte,Ize,FGe,In,Nze,ate,qze,jze,nte,Dze,Gze,TGe,wL,MGe,rS,Oze,EGe,Rf,CGe,xi,Pf,ste,AL,Vze,lte,Xze,wGe,wo,LL,zze,yL,Wze,tS,Qze,Hze,Uze,xL,Jze,ite,Yze,Kze,Zze,wr,$L,eWe,dte,oWe,rWe,$i,tWe,cte,aWe,nWe,fte,sWe,lWe,iWe,A,Bf,mte,dWe,cWe,aS,fWe,mWe,gWe,If,gte,hWe,pWe,nS,uWe,_We,bWe,Nf,hte,vWe,FWe,sS,TWe,MWe,EWe,qf,pte,CWe,wWe,lS,AWe,LWe,yWe,jf,ute,xWe,$We,iS,kWe,SWe,RWe,Df,_te,PWe,BWe,dS,IWe,NWe,qWe,Gf,bte,jWe,DWe,cS,GWe,OWe,VWe,Of,vte,XWe,zWe,fS,WWe,QWe,HWe,Vf,Fte,UWe,JWe,mS,YWe,KWe,ZWe,Xf,Tte,eQe,oQe,gS,rQe,tQe,aQe,zf,Mte,nQe,sQe,hS,lQe,iQe,dQe,Wf,Ete,cQe,fQe,pS,mQe,gQe,hQe,Qf,Cte,pQe,uQe,uS,_Qe,bQe,vQe,Hf,wte,FQe,TQe,_S,MQe,EQe,CQe,Uf,Ate,wQe,AQe,bS,LQe,yQe,xQe,Jf,Lte,$Qe,kQe,vS,SQe,RQe,PQe,Yf,yte,BQe,IQe,FS,NQe,qQe,jQe,Kf,xte,DQe,GQe,TS,OQe,VQe,XQe,Zf,$te,zQe,WQe,MS,QQe,HQe,UQe,em,kte,JQe,YQe,ES,KQe,ZQe,eHe,om,Ste,oHe,rHe,CS,tHe,aHe,nHe,rm,Rte,sHe,lHe,wS,iHe,dHe,cHe,tm,Pte,fHe,mHe,AS,gHe,hHe,pHe,am,Bte,uHe,_He,LS,bHe,vHe,FHe,nm,Ite,THe,MHe,yS,EHe,CHe,wHe,sm,Nte,AHe,LHe,xS,yHe,xHe,$He,lm,qte,kHe,SHe,$S,RHe,PHe,BHe,im,jte,IHe,NHe,kS,qHe,jHe,DHe,dm,Dte,GHe,OHe,SS,VHe,XHe,zHe,cm,Gte,WHe,QHe,RS,HHe,UHe,JHe,fm,Ote,YHe,KHe,PS,ZHe,eUe,oUe,mm,Vte,rUe,tUe,BS,aUe,nUe,sUe,gm,Xte,lUe,iUe,IS,dUe,cUe,fUe,hm,zte,mUe,gUe,NS,hUe,pUe,uUe,pm,Wte,_Ue,bUe,qS,vUe,FUe,TUe,um,Qte,MUe,EUe,jS,CUe,wUe,AUe,_m,Hte,LUe,yUe,DS,xUe,$Ue,kUe,bm,Ute,SUe,RUe,GS,PUe,BUe,IUe,vm,Jte,NUe,qUe,OS,jUe,DUe,GUe,Fm,Yte,OUe,VUe,VS,XUe,zUe,WUe,Tm,Kte,QUe,HUe,XS,UUe,JUe,YUe,Mm,Zte,KUe,ZUe,zS,eJe,oJe,rJe,Em,eae,tJe,aJe,WS,nJe,sJe,lJe,Cm,oae,iJe,dJe,QS,cJe,fJe,mJe,wm,rae,gJe,hJe,HS,pJe,uJe,_Je,Am,tae,bJe,vJe,US,FJe,TJe,MJe,Lm,aae,EJe,CJe,JS,wJe,AJe,LJe,ym,nae,yJe,xJe,YS,$Je,kJe,SJe,xm,sae,RJe,PJe,KS,BJe,IJe,NJe,$m,lae,qJe,jJe,ZS,DJe,GJe,OJe,km,iae,VJe,XJe,eR,zJe,WJe,QJe,Sm,dae,HJe,UJe,oR,JJe,YJe,KJe,Rm,cae,ZJe,eYe,rR,oYe,rYe,tYe,Pm,fae,aYe,nYe,tR,sYe,lYe,iYe,Bm,mae,dYe,cYe,aR,fYe,mYe,gYe,Im,gae,hYe,pYe,nR,uYe,_Ye,bYe,Nm,hae,vYe,FYe,sR,TYe,MYe,EYe,qm,pae,CYe,wYe,lR,AYe,LYe,yYe,jm,uae,xYe,$Ye,iR,kYe,SYe,RYe,Dm,_ae,PYe,BYe,dR,IYe,NYe,qYe,Gm,bae,jYe,DYe,cR,GYe,OYe,VYe,Om,vae,XYe,zYe,fR,WYe,QYe,HYe,Vm,Fae,UYe,JYe,mR,YYe,KYe,ZYe,Xm,Tae,eKe,oKe,gR,rKe,tKe,aKe,zm,Mae,nKe,sKe,hR,lKe,iKe,dKe,Wm,Eae,cKe,fKe,pR,mKe,gKe,hKe,Qm,Cae,pKe,uKe,uR,_Ke,bKe,vKe,Hm,wae,FKe,TKe,_R,MKe,EKe,CKe,Um,Aae,wKe,AKe,bR,LKe,yKe,xKe,Jm,Lae,$Ke,kKe,vR,SKe,RKe,PKe,Ym,yae,BKe,IKe,FR,NKe,qKe,jKe,Km,xae,DKe,GKe,TR,OKe,VKe,XKe,Zm,$ae,zKe,WKe,MR,QKe,HKe,UKe,eg,kae,JKe,YKe,ER,KKe,ZKe,eZe,og,Sae,oZe,rZe,CR,tZe,aZe,nZe,rg,Rae,sZe,lZe,wR,iZe,dZe,cZe,tg,Pae,fZe,mZe,AR,gZe,hZe,pZe,ag,Bae,uZe,_Ze,LR,bZe,vZe,FZe,ng,Iae,TZe,MZe,yR,EZe,CZe,wZe,sg,Nae,AZe,LZe,xR,yZe,xZe,$Ze,lg,qae,kZe,SZe,$R,RZe,PZe,BZe,ig,jae,IZe,NZe,kR,qZe,jZe,DZe,dg,Dae,GZe,OZe,SR,VZe,XZe,zZe,cg,Gae,WZe,QZe,RR,HZe,UZe,JZe,fg,Oae,YZe,KZe,PR,ZZe,eeo,oeo,mg,Vae,reo,teo,BR,aeo,neo,seo,gg,Xae,leo,ieo,IR,deo,ceo,feo,hg,zae,meo,geo,NR,heo,peo,ueo,pg,Wae,_eo,beo,qR,veo,Feo,Teo,ug,Qae,Meo,Eeo,jR,Ceo,weo,Aeo,_g,Hae,Leo,yeo,DR,xeo,$eo,keo,bg,Uae,Seo,Reo,GR,Peo,Beo,Ieo,vg,Jae,Neo,qeo,OR,jeo,Deo,Geo,Fg,Yae,Oeo,Veo,VR,Xeo,zeo,Weo,Tg,Kae,Qeo,Heo,XR,Ueo,Jeo,Yeo,Mg,Zae,Keo,Zeo,zR,eoo,ooo,roo,Eg,ene,too,aoo,WR,noo,soo,loo,Cg,one,ioo,doo,QR,coo,foo,moo,wg,rne,goo,hoo,HR,poo,uoo,_oo,Ag,tne,boo,voo,UR,Foo,Too,Moo,Lg,ane,Eoo,Coo,JR,woo,Aoo,Loo,yg,nne,yoo,xoo,YR,$oo,koo,Soo,xg,sne,Roo,Poo,KR,Boo,Ioo,Noo,$g,lne,qoo,joo,ZR,Doo,Goo,Ooo,kg,ine,Voo,Xoo,eP,zoo,Woo,Qoo,Sg,dne,Hoo,Uoo,oP,Joo,Yoo,Koo,Rg,cne,Zoo,ero,rP,oro,rro,tro,Pg,fne,aro,nro,tP,sro,lro,iro,Bg,mne,dro,cro,aP,fro,mro,gro,Ig,gne,hro,pro,nP,uro,_ro,bro,Ng,hne,vro,Fro,sP,Tro,Mro,Ero,qg,pne,Cro,wro,lP,Aro,Lro,yro,jg,une,xro,$ro,iP,kro,Sro,Rro,Dg,_ne,Pro,Bro,dP,Iro,Nro,qro,Gg,jro,Og,kL,Dro,bne,Gro,AGe,ki,Vg,vne,SL,Oro,Fne,Vro,LGe,Ao,RL,Xro,PL,zro,cP,Wro,Qro,Hro,BL,Uro,Tne,Jro,Yro,Kro,Ar,IL,Zro,Mne,eto,oto,$a,rto,Ene,tto,ato,Cne,nto,sto,wne,lto,ito,dto,k,Nn,Ane,cto,fto,fP,mto,gto,mP,hto,pto,uto,qn,Lne,_to,bto,gP,vto,Fto,hP,Tto,Mto,Eto,jn,yne,Cto,wto,pP,Ato,Lto,uP,yto,xto,$to,Xg,xne,kto,Sto,_P,Rto,Pto,Bto,Dn,$ne,Ito,Nto,bP,qto,jto,vP,Dto,Gto,Oto,zg,kne,Vto,Xto,FP,zto,Wto,Qto,Wg,Sne,Hto,Uto,TP,Jto,Yto,Kto,Qg,Rne,Zto,eao,MP,oao,rao,tao,Gn,Pne,aao,nao,EP,sao,lao,CP,iao,dao,cao,On,Bne,fao,mao,wP,gao,hao,AP,pao,uao,_ao,Vn,Ine,bao,vao,LP,Fao,Tao,yP,Mao,Eao,Cao,Hg,Nne,wao,Aao,xP,Lao,yao,xao,Ug,qne,$ao,kao,$P,Sao,Rao,Pao,Jg,jne,Bao,Iao,kP,Nao,qao,jao,Xn,Dne,Dao,Gao,SP,Oao,Vao,RP,Xao,zao,Wao,Yg,Gne,Qao,Hao,PP,Uao,Jao,Yao,zn,One,Kao,Zao,BP,eno,ono,IP,rno,tno,ano,Wn,Vne,nno,sno,NP,lno,ino,qP,dno,cno,fno,Qn,Xne,mno,gno,jP,hno,pno,DP,uno,_no,bno,Kg,zne,vno,Fno,GP,Tno,Mno,Eno,Hn,Wne,Cno,wno,OP,Ano,Lno,VP,yno,xno,$no,Un,Qne,kno,Sno,XP,Rno,Pno,zP,Bno,Ino,Nno,Jn,Hne,qno,jno,WP,Dno,Gno,QP,Ono,Vno,Xno,Yn,Une,zno,Wno,HP,Qno,Hno,UP,Uno,Jno,Yno,Kn,Jne,Kno,Zno,JP,eso,oso,YP,rso,tso,aso,Zn,Yne,nso,sso,KP,lso,iso,ZP,dso,cso,fso,Zg,Kne,mso,gso,eB,hso,pso,uso,es,Zne,_so,bso,oB,vso,Fso,rB,Tso,Mso,Eso,eh,ese,Cso,wso,tB,Aso,Lso,yso,os,ose,xso,$so,aB,kso,Sso,nB,Rso,Pso,Bso,rs,rse,Iso,Nso,sB,qso,jso,lB,Dso,Gso,Oso,ts,tse,Vso,Xso,iB,zso,Wso,dB,Qso,Hso,Uso,oh,ase,Jso,Yso,cB,Kso,Zso,elo,as,nse,olo,rlo,fB,tlo,alo,mB,nlo,slo,llo,ns,sse,ilo,dlo,gB,clo,flo,hB,mlo,glo,hlo,ss,lse,plo,ulo,pB,_lo,blo,uB,vlo,Flo,Tlo,rh,ise,Mlo,Elo,_B,Clo,wlo,Alo,ls,dse,Llo,ylo,bB,xlo,$lo,vB,klo,Slo,Rlo,is,cse,Plo,Blo,FB,Ilo,Nlo,TB,qlo,jlo,Dlo,ds,fse,Glo,Olo,MB,Vlo,Xlo,EB,zlo,Wlo,Qlo,cs,mse,Hlo,Ulo,CB,Jlo,Ylo,wB,Klo,Zlo,eio,fs,gse,oio,rio,AB,tio,aio,LB,nio,sio,lio,ms,hse,iio,dio,yB,cio,fio,xB,mio,gio,hio,gs,pse,pio,uio,$B,_io,bio,kB,vio,Fio,Tio,hs,use,Mio,Eio,SB,Cio,wio,RB,Aio,Lio,yio,th,_se,xio,$io,PB,kio,Sio,Rio,ps,bse,Pio,Bio,BB,Iio,Nio,IB,qio,jio,Dio,ah,vse,Gio,Oio,NB,Vio,Xio,zio,nh,Fse,Wio,Qio,qB,Hio,Uio,Jio,us,Tse,Yio,Kio,jB,Zio,edo,DB,odo,rdo,tdo,_s,Mse,ado,ndo,GB,sdo,ldo,OB,ido,ddo,cdo,bs,Ese,fdo,mdo,VB,gdo,hdo,XB,pdo,udo,_do,sh,Cse,bdo,vdo,zB,Fdo,Tdo,Mdo,vs,wse,Edo,Cdo,WB,wdo,Ado,QB,Ldo,ydo,xdo,Fs,Ase,$do,kdo,HB,Sdo,Rdo,UB,Pdo,Bdo,Ido,Ts,Lse,Ndo,qdo,JB,jdo,Ddo,YB,Gdo,Odo,Vdo,Ms,yse,Xdo,zdo,KB,Wdo,Qdo,ZB,Hdo,Udo,Jdo,Es,xse,Ydo,Kdo,eI,Zdo,eco,oI,oco,rco,tco,lh,$se,aco,nco,rI,sco,lco,ico,Cs,kse,dco,cco,tI,fco,mco,aI,gco,hco,pco,ih,Sse,uco,_co,nI,bco,vco,Fco,dh,Rse,Tco,Mco,sI,Eco,Cco,wco,ch,Pse,Aco,Lco,lI,yco,xco,$co,fh,Bse,kco,Sco,iI,Rco,Pco,Bco,ws,Ise,Ico,Nco,dI,qco,jco,cI,Dco,Gco,Oco,mh,Nse,Vco,Xco,fI,zco,Wco,Qco,As,qse,Hco,Uco,mI,Jco,Yco,gI,Kco,Zco,efo,Ls,jse,ofo,rfo,hI,tfo,afo,pI,nfo,sfo,lfo,ys,Dse,ifo,dfo,uI,cfo,ffo,_I,mfo,gfo,hfo,xs,Gse,pfo,ufo,bI,_fo,bfo,vI,vfo,Ffo,Tfo,$s,Ose,Mfo,Efo,FI,Cfo,wfo,TI,Afo,Lfo,yfo,ks,Vse,xfo,$fo,MI,kfo,Sfo,EI,Rfo,Pfo,Bfo,gh,Xse,Ifo,Nfo,CI,qfo,jfo,Dfo,hh,zse,Gfo,Ofo,wI,Vfo,Xfo,zfo,Ss,Wse,Wfo,Qfo,AI,Hfo,Ufo,LI,Jfo,Yfo,Kfo,Rs,Qse,Zfo,emo,yI,omo,rmo,xI,tmo,amo,nmo,Ps,Hse,smo,lmo,$I,imo,dmo,kI,cmo,fmo,mmo,ph,Use,gmo,hmo,SI,pmo,umo,_mo,uh,Jse,bmo,vmo,RI,Fmo,Tmo,Mmo,_h,Yse,Emo,Cmo,PI,wmo,Amo,Lmo,Bs,Kse,ymo,xmo,BI,$mo,kmo,II,Smo,Rmo,Pmo,Is,Zse,Bmo,Imo,NI,Nmo,qmo,qI,jmo,Dmo,Gmo,bh,ele,Omo,Vmo,jI,Xmo,zmo,Wmo,vh,ole,Qmo,Hmo,DI,Umo,Jmo,Ymo,Fh,rle,Kmo,Zmo,GI,ego,ogo,rgo,Ns,tle,tgo,ago,OI,ngo,sgo,VI,lgo,igo,dgo,Th,ale,cgo,fgo,XI,mgo,ggo,hgo,Mh,nle,pgo,ugo,zI,_go,bgo,vgo,qs,sle,Fgo,Tgo,WI,Mgo,Ego,QI,Cgo,wgo,Ago,js,lle,Lgo,ygo,HI,xgo,$go,UI,kgo,Sgo,Rgo,Ds,ile,Pgo,Bgo,JI,Igo,Ngo,YI,qgo,jgo,Dgo,Gs,dle,Ggo,Ogo,KI,Vgo,Xgo,ZI,zgo,Wgo,Qgo,Eh,Hgo,Ch,NL,Ugo,cle,Jgo,yGe,Si,wh,fle,qL,Ygo,mle,Kgo,xGe,Lo,jL,Zgo,DL,eho,eN,oho,rho,tho,GL,aho,gle,nho,sho,lho,He,OL,iho,hle,dho,cho,ka,fho,ple,mho,gho,ule,hho,pho,_le,uho,_ho,bho,Y,Ah,ble,vho,Fho,oN,Tho,Mho,Eho,Lh,vle,Cho,who,rN,Aho,Lho,yho,yh,Fle,xho,$ho,tN,kho,Sho,Rho,xh,Tle,Pho,Bho,aN,Iho,Nho,qho,$h,Mle,jho,Dho,nN,Gho,Oho,Vho,kh,Ele,Xho,zho,sN,Who,Qho,Hho,Sh,Cle,Uho,Jho,lN,Yho,Kho,Zho,Rh,wle,epo,opo,iN,rpo,tpo,apo,Ph,Ale,npo,spo,dN,lpo,ipo,dpo,Bh,Lle,cpo,fpo,cN,mpo,gpo,hpo,Ih,yle,ppo,upo,fN,_po,bpo,vpo,Nh,xle,Fpo,Tpo,mN,Mpo,Epo,Cpo,qh,$le,wpo,Apo,gN,Lpo,ypo,xpo,jh,kle,$po,kpo,hN,Spo,Rpo,Ppo,Dh,Sle,Bpo,Ipo,pN,Npo,qpo,jpo,Gh,Rle,Dpo,Gpo,uN,Opo,Vpo,Xpo,Oh,Ple,zpo,Wpo,_N,Qpo,Hpo,Upo,Vh,Ble,Jpo,Ypo,bN,Kpo,Zpo,euo,Xh,Ile,ouo,ruo,vN,tuo,auo,nuo,zh,Nle,suo,luo,FN,iuo,duo,cuo,Wh,qle,fuo,muo,TN,guo,huo,puo,Qh,jle,uuo,_uo,MN,buo,vuo,Fuo,Hh,Dle,Tuo,Muo,EN,Euo,Cuo,wuo,Uh,Gle,Auo,Luo,CN,yuo,xuo,$uo,Jh,Ole,kuo,Suo,wN,Ruo,Puo,Buo,Yh,Vle,Iuo,Nuo,AN,quo,juo,Duo,Kh,Xle,Guo,Ouo,LN,Vuo,Xuo,zuo,Zh,zle,Wuo,Quo,yN,Huo,Uuo,Juo,ep,Wle,Yuo,Kuo,xN,Zuo,e_o,o_o,op,Qle,r_o,t_o,$N,a_o,n_o,s_o,rp,Hle,l_o,i_o,kN,d_o,c_o,f_o,tp,Ule,m_o,g_o,SN,h_o,p_o,u_o,ap,Jle,__o,b_o,RN,v_o,F_o,T_o,np,M_o,sp,E_o,lp,VL,C_o,Yle,w_o,$Ge,Ri,ip,Kle,XL,A_o,Zle,L_o,kGe,yo,zL,y_o,WL,x_o,PN,$_o,k_o,S_o,QL,R_o,eie,P_o,B_o,I_o,Ue,HL,N_o,oie,q_o,j_o,Pi,D_o,rie,G_o,O_o,tie,V_o,X_o,z_o,he,dp,aie,W_o,Q_o,BN,H_o,U_o,J_o,cp,nie,Y_o,K_o,sie,Z_o,e1o,o1o,fp,lie,r1o,t1o,IN,a1o,n1o,s1o,mp,iie,l1o,i1o,NN,d1o,c1o,f1o,gp,die,m1o,g1o,qN,h1o,p1o,u1o,hp,cie,_1o,b1o,jN,v1o,F1o,T1o,pp,fie,M1o,E1o,DN,C1o,w1o,A1o,up,mie,L1o,y1o,GN,x1o,$1o,k1o,_p,gie,S1o,R1o,ON,P1o,B1o,I1o,bp,hie,N1o,q1o,VN,j1o,D1o,G1o,vp,pie,O1o,V1o,XN,X1o,z1o,W1o,Fp,uie,Q1o,H1o,zN,U1o,J1o,Y1o,Tp,_ie,K1o,Z1o,WN,e3o,o3o,r3o,Mp,bie,t3o,a3o,QN,n3o,s3o,l3o,Ep,vie,i3o,d3o,HN,c3o,f3o,m3o,Cp,Fie,g3o,h3o,UN,p3o,u3o,_3o,wp,Tie,b3o,v3o,JN,F3o,T3o,M3o,Ap,Mie,E3o,C3o,YN,w3o,A3o,L3o,Lp,y3o,yp,x3o,xp,UL,$3o,Eie,k3o,SGe,Bi,$p,Cie,JL,S3o,wie,R3o,RGe,xo,YL,P3o,Ii,B3o,KN,I3o,N3o,ZN,q3o,j3o,D3o,KL,G3o,Aie,O3o,V3o,X3o,nt,ZL,z3o,Lie,W3o,Q3o,Ni,H3o,yie,U3o,J3o,eq,Y3o,K3o,Z3o,kp,e2o,Je,ey,o2o,xie,r2o,t2o,Sa,a2o,$ie,n2o,s2o,kie,l2o,i2o,Sie,d2o,c2o,f2o,y,Sp,Rie,m2o,g2o,oq,h2o,p2o,u2o,Rp,Pie,_2o,b2o,rq,v2o,F2o,T2o,Pp,Bie,M2o,E2o,tq,C2o,w2o,A2o,Bp,Iie,L2o,y2o,aq,x2o,$2o,k2o,Ip,Nie,S2o,R2o,nq,P2o,B2o,I2o,Np,qie,N2o,q2o,sq,j2o,D2o,G2o,qp,jie,O2o,V2o,lq,X2o,z2o,W2o,jp,Die,Q2o,H2o,iq,U2o,J2o,Y2o,Dp,Gie,K2o,Z2o,dq,ebo,obo,rbo,Gp,Oie,tbo,abo,cq,nbo,sbo,lbo,Op,Vie,ibo,dbo,fq,cbo,fbo,mbo,Vp,Xie,gbo,hbo,mq,pbo,ubo,_bo,Xp,zie,bbo,vbo,gq,Fbo,Tbo,Mbo,zp,Wie,Ebo,Cbo,hq,wbo,Abo,Lbo,Wp,Qie,ybo,xbo,pq,$bo,kbo,Sbo,Qp,Hie,Rbo,Pbo,uq,Bbo,Ibo,Nbo,Hp,Uie,qbo,jbo,_q,Dbo,Gbo,Obo,Up,Jie,Vbo,Xbo,bq,zbo,Wbo,Qbo,Jp,Yie,Hbo,Ubo,vq,Jbo,Ybo,Kbo,Yp,Kie,Zbo,evo,Fq,ovo,rvo,tvo,Kp,Zie,avo,nvo,Tq,svo,lvo,ivo,Zp,ede,dvo,cvo,Mq,fvo,mvo,gvo,eu,ode,hvo,pvo,Eq,uvo,_vo,bvo,ou,rde,vvo,Fvo,Cq,Tvo,Mvo,Evo,ru,tde,Cvo,wvo,wq,Avo,Lvo,yvo,tu,ade,xvo,$vo,Aq,kvo,Svo,Rvo,au,nde,Pvo,Bvo,Lq,Ivo,Nvo,qvo,nu,sde,jvo,Dvo,yq,Gvo,Ovo,Vvo,su,lde,Xvo,zvo,xq,Wvo,Qvo,Hvo,lu,ide,Uvo,Jvo,$q,Yvo,Kvo,Zvo,iu,dde,eFo,oFo,kq,rFo,tFo,aFo,du,cde,nFo,sFo,Sq,lFo,iFo,dFo,cu,fde,cFo,fFo,Rq,mFo,gFo,hFo,Os,mde,pFo,uFo,Pq,_Fo,bFo,Bq,vFo,FFo,TFo,fu,gde,MFo,EFo,Iq,CFo,wFo,AFo,mu,hde,LFo,yFo,Nq,xFo,$Fo,kFo,gu,pde,SFo,RFo,qq,PFo,BFo,IFo,hu,ude,NFo,qFo,jq,jFo,DFo,GFo,pu,_de,OFo,VFo,Dq,XFo,zFo,WFo,uu,bde,QFo,HFo,Gq,UFo,JFo,YFo,_u,vde,KFo,ZFo,Oq,eTo,oTo,rTo,bu,Fde,tTo,aTo,Vq,nTo,sTo,lTo,vu,Tde,iTo,dTo,Xq,cTo,fTo,mTo,Fu,Mde,gTo,hTo,zq,pTo,uTo,_To,Tu,Ede,bTo,vTo,Wq,FTo,TTo,MTo,Mu,Cde,ETo,CTo,Qq,wTo,ATo,LTo,Eu,wde,yTo,xTo,Hq,$To,kTo,STo,Cu,Ade,RTo,PTo,Uq,BTo,ITo,NTo,wu,Lde,qTo,jTo,Jq,DTo,GTo,OTo,Au,yde,VTo,XTo,Yq,zTo,WTo,QTo,Lu,xde,HTo,UTo,Kq,JTo,YTo,KTo,yu,$de,ZTo,e7o,Zq,o7o,r7o,t7o,xu,kde,a7o,n7o,ej,s7o,l7o,i7o,$u,Sde,d7o,c7o,oj,f7o,m7o,g7o,ku,Rde,h7o,p7o,rj,u7o,_7o,b7o,Su,Pde,v7o,F7o,tj,T7o,M7o,E7o,Ru,Bde,C7o,w7o,aj,A7o,L7o,y7o,Pu,Ide,x7o,$7o,nj,k7o,S7o,R7o,Bu,Nde,P7o,B7o,sj,I7o,N7o,q7o,Iu,qde,j7o,D7o,lj,G7o,O7o,V7o,Nu,jde,X7o,z7o,ij,W7o,Q7o,H7o,qu,Dde,U7o,J7o,dj,Y7o,K7o,Z7o,ju,Gde,eMo,oMo,cj,rMo,tMo,aMo,Du,Ode,nMo,sMo,fj,lMo,iMo,dMo,Gu,Vde,cMo,fMo,mj,mMo,gMo,hMo,Ou,Xde,pMo,uMo,gj,_Mo,bMo,vMo,Vu,zde,FMo,TMo,hj,MMo,EMo,CMo,Xu,Wde,wMo,AMo,pj,LMo,yMo,xMo,zu,Qde,$Mo,kMo,uj,SMo,RMo,PMo,Wu,Hde,BMo,IMo,_j,NMo,qMo,jMo,Qu,Ude,DMo,GMo,bj,OMo,VMo,XMo,Hu,Jde,zMo,WMo,vj,QMo,HMo,UMo,Uu,Yde,JMo,YMo,Fj,KMo,ZMo,eEo,Ju,Kde,oEo,rEo,Tj,tEo,aEo,nEo,Yu,Zde,sEo,lEo,Mj,iEo,dEo,cEo,Ku,ece,fEo,mEo,Ej,gEo,hEo,pEo,Zu,oce,uEo,_Eo,Cj,bEo,vEo,FEo,e_,rce,TEo,MEo,wj,EEo,CEo,wEo,o_,tce,AEo,LEo,Aj,yEo,xEo,$Eo,r_,ace,kEo,SEo,Lj,REo,PEo,BEo,t_,nce,IEo,NEo,yj,qEo,jEo,DEo,a_,sce,GEo,OEo,xj,VEo,XEo,zEo,n_,lce,WEo,QEo,$j,HEo,UEo,JEo,s_,ice,YEo,KEo,kj,ZEo,e4o,o4o,l_,dce,r4o,t4o,Sj,a4o,n4o,s4o,i_,cce,l4o,i4o,Rj,d4o,c4o,f4o,d_,fce,m4o,g4o,Pj,h4o,p4o,u4o,c_,mce,_4o,b4o,Bj,v4o,F4o,T4o,f_,gce,M4o,E4o,Ij,C4o,w4o,A4o,m_,hce,L4o,y4o,Nj,x4o,$4o,k4o,g_,pce,S4o,R4o,qj,P4o,B4o,I4o,h_,uce,N4o,q4o,jj,j4o,D4o,G4o,p_,_ce,O4o,V4o,Dj,X4o,z4o,W4o,u_,bce,Q4o,H4o,Gj,U4o,J4o,Y4o,__,vce,K4o,Z4o,Oj,eCo,oCo,rCo,b_,Fce,tCo,aCo,Vj,nCo,sCo,lCo,v_,Tce,iCo,dCo,Xj,cCo,fCo,mCo,F_,Mce,gCo,hCo,zj,pCo,uCo,_Co,T_,Ece,bCo,vCo,Wj,FCo,TCo,MCo,M_,Cce,ECo,CCo,Qj,wCo,ACo,LCo,E_,wce,yCo,xCo,Hj,$Co,kCo,SCo,C_,Ace,RCo,PCo,Uj,BCo,ICo,NCo,w_,Lce,qCo,jCo,Jj,DCo,GCo,OCo,A_,yce,VCo,XCo,Yj,zCo,WCo,QCo,L_,xce,HCo,UCo,Kj,JCo,YCo,KCo,y_,$ce,ZCo,e5o,Zj,o5o,r5o,t5o,x_,kce,a5o,n5o,eD,s5o,l5o,i5o,$_,d5o,Sce,c5o,f5o,Rce,m5o,g5o,k_,PGe,qi,S_,Pce,oy,h5o,Bce,p5o,BGe,$o,ry,u5o,ji,_5o,oD,b5o,v5o,rD,F5o,T5o,M5o,ty,E5o,Ice,C5o,w5o,A5o,st,ay,L5o,Nce,y5o,x5o,Di,$5o,qce,k5o,S5o,tD,R5o,P5o,B5o,R_,I5o,Ye,ny,N5o,jce,q5o,j5o,Ra,D5o,Dce,G5o,O5o,Gce,V5o,X5o,Oce,z5o,W5o,Q5o,G,P_,Vce,H5o,U5o,aD,J5o,Y5o,K5o,B_,Xce,Z5o,e0o,nD,o0o,r0o,t0o,I_,zce,a0o,n0o,sD,s0o,l0o,i0o,N_,Wce,d0o,c0o,lD,f0o,m0o,g0o,q_,Qce,h0o,p0o,iD,u0o,_0o,b0o,j_,Hce,v0o,F0o,dD,T0o,M0o,E0o,D_,Uce,C0o,w0o,cD,A0o,L0o,y0o,G_,Jce,x0o,$0o,fD,k0o,S0o,R0o,O_,Yce,P0o,B0o,mD,I0o,N0o,q0o,V_,Kce,j0o,D0o,gD,G0o,O0o,V0o,X_,Zce,X0o,z0o,hD,W0o,Q0o,H0o,z_,efe,U0o,J0o,pD,Y0o,K0o,Z0o,W_,ofe,ewo,owo,uD,rwo,two,awo,Q_,rfe,nwo,swo,_D,lwo,iwo,dwo,H_,tfe,cwo,fwo,bD,mwo,gwo,hwo,U_,afe,pwo,uwo,vD,_wo,bwo,vwo,J_,nfe,Fwo,Two,FD,Mwo,Ewo,Cwo,Y_,sfe,wwo,Awo,TD,Lwo,ywo,xwo,K_,lfe,$wo,kwo,MD,Swo,Rwo,Pwo,Z_,ife,Bwo,Iwo,ED,Nwo,qwo,jwo,e1,dfe,Dwo,Gwo,CD,Owo,Vwo,Xwo,o1,cfe,zwo,Wwo,wD,Qwo,Hwo,Uwo,r1,ffe,Jwo,Ywo,AD,Kwo,Zwo,eAo,t1,mfe,oAo,rAo,LD,tAo,aAo,nAo,a1,gfe,sAo,lAo,yD,iAo,dAo,cAo,n1,hfe,fAo,mAo,xD,gAo,hAo,pAo,s1,pfe,uAo,_Ao,$D,bAo,vAo,FAo,l1,ufe,TAo,MAo,kD,EAo,CAo,wAo,i1,_fe,AAo,LAo,SD,yAo,xAo,$Ao,d1,bfe,kAo,SAo,RD,RAo,PAo,BAo,c1,vfe,IAo,NAo,PD,qAo,jAo,DAo,f1,Ffe,GAo,OAo,BD,VAo,XAo,zAo,m1,Tfe,WAo,QAo,ID,HAo,UAo,JAo,g1,Mfe,YAo,KAo,ND,ZAo,e6o,o6o,h1,Efe,r6o,t6o,qD,a6o,n6o,s6o,p1,Cfe,l6o,i6o,jD,d6o,c6o,f6o,u1,wfe,m6o,g6o,DD,h6o,p6o,u6o,_1,Afe,_6o,b6o,GD,v6o,F6o,T6o,b1,Lfe,M6o,E6o,OD,C6o,w6o,A6o,v1,yfe,L6o,y6o,VD,x6o,$6o,k6o,F1,xfe,S6o,R6o,XD,P6o,B6o,I6o,T1,$fe,N6o,q6o,zD,j6o,D6o,G6o,M1,kfe,O6o,V6o,WD,X6o,z6o,W6o,E1,Q6o,Sfe,H6o,U6o,Rfe,J6o,Y6o,C1,IGe,Gi,w1,Pfe,sy,K6o,Bfe,Z6o,NGe,ko,ly,eLo,Oi,oLo,QD,rLo,tLo,HD,aLo,nLo,sLo,iy,lLo,Ife,iLo,dLo,cLo,lt,dy,fLo,Nfe,mLo,gLo,Vi,hLo,qfe,pLo,uLo,UD,_Lo,bLo,vLo,A1,FLo,Ke,cy,TLo,jfe,MLo,ELo,Pa,CLo,Dfe,wLo,ALo,Gfe,LLo,yLo,Ofe,xLo,$Lo,kLo,z,L1,Vfe,SLo,RLo,JD,PLo,BLo,ILo,y1,Xfe,NLo,qLo,YD,jLo,DLo,GLo,x1,zfe,OLo,VLo,KD,XLo,zLo,WLo,$1,Wfe,QLo,HLo,ZD,ULo,JLo,YLo,k1,Qfe,KLo,ZLo,eG,eyo,oyo,ryo,S1,Hfe,tyo,ayo,oG,nyo,syo,lyo,R1,Ufe,iyo,dyo,rG,cyo,fyo,myo,P1,Jfe,gyo,hyo,tG,pyo,uyo,_yo,B1,Yfe,byo,vyo,aG,Fyo,Tyo,Myo,I1,Kfe,Eyo,Cyo,nG,wyo,Ayo,Lyo,N1,Zfe,yyo,xyo,sG,$yo,kyo,Syo,q1,eme,Ryo,Pyo,lG,Byo,Iyo,Nyo,j1,ome,qyo,jyo,iG,Dyo,Gyo,Oyo,D1,rme,Vyo,Xyo,dG,zyo,Wyo,Qyo,G1,tme,Hyo,Uyo,cG,Jyo,Yyo,Kyo,O1,ame,Zyo,e8o,fG,o8o,r8o,t8o,V1,nme,a8o,n8o,mG,s8o,l8o,i8o,X1,sme,d8o,c8o,gG,f8o,m8o,g8o,z1,lme,h8o,p8o,hG,u8o,_8o,b8o,W1,ime,v8o,F8o,pG,T8o,M8o,E8o,Q1,dme,C8o,w8o,uG,A8o,L8o,y8o,H1,cme,x8o,$8o,_G,k8o,S8o,R8o,U1,fme,P8o,B8o,bG,I8o,N8o,q8o,J1,mme,j8o,D8o,vG,G8o,O8o,V8o,Y1,gme,X8o,z8o,FG,W8o,Q8o,H8o,K1,hme,U8o,J8o,TG,Y8o,K8o,Z8o,Z1,pme,e9o,o9o,MG,r9o,t9o,a9o,e3,ume,n9o,s9o,EG,l9o,i9o,d9o,o3,_me,c9o,f9o,CG,m9o,g9o,h9o,r3,bme,p9o,u9o,wG,_9o,b9o,v9o,t3,vme,F9o,T9o,AG,M9o,E9o,C9o,a3,Fme,w9o,A9o,LG,L9o,y9o,x9o,n3,Tme,$9o,k9o,yG,S9o,R9o,P9o,s3,Mme,B9o,I9o,xG,N9o,q9o,j9o,l3,Eme,D9o,G9o,$G,O9o,V9o,X9o,i3,Cme,z9o,W9o,kG,Q9o,H9o,U9o,d3,wme,J9o,Y9o,SG,K9o,Z9o,exo,c3,Ame,oxo,rxo,RG,txo,axo,nxo,f3,sxo,Lme,lxo,ixo,yme,dxo,cxo,m3,qGe,Xi,g3,xme,fy,fxo,$me,mxo,jGe,So,my,gxo,zi,hxo,PG,pxo,uxo,BG,_xo,bxo,vxo,gy,Fxo,kme,Txo,Mxo,Exo,it,hy,Cxo,Sme,wxo,Axo,Wi,Lxo,Rme,yxo,xxo,IG,$xo,kxo,Sxo,h3,Rxo,Ze,py,Pxo,Pme,Bxo,Ixo,Ba,Nxo,Bme,qxo,jxo,Ime,Dxo,Gxo,Nme,Oxo,Vxo,Xxo,Q,p3,qme,zxo,Wxo,NG,Qxo,Hxo,Uxo,u3,jme,Jxo,Yxo,qG,Kxo,Zxo,e$o,_3,Dme,o$o,r$o,jG,t$o,a$o,n$o,b3,Gme,s$o,l$o,DG,i$o,d$o,c$o,v3,Ome,f$o,m$o,GG,g$o,h$o,p$o,F3,Vme,u$o,_$o,OG,b$o,v$o,F$o,T3,Xme,T$o,M$o,VG,E$o,C$o,w$o,M3,zme,A$o,L$o,XG,y$o,x$o,$$o,E3,Wme,k$o,S$o,zG,R$o,P$o,B$o,C3,Qme,I$o,N$o,WG,q$o,j$o,D$o,w3,Hme,G$o,O$o,QG,V$o,X$o,z$o,A3,Ume,W$o,Q$o,HG,H$o,U$o,J$o,L3,Jme,Y$o,K$o,UG,Z$o,eko,oko,y3,Yme,rko,tko,JG,ako,nko,sko,x3,Kme,lko,iko,YG,dko,cko,fko,$3,Zme,mko,gko,KG,hko,pko,uko,k3,ege,_ko,bko,ZG,vko,Fko,Tko,S3,oge,Mko,Eko,eO,Cko,wko,Ako,R3,rge,Lko,yko,oO,xko,$ko,kko,P3,tge,Sko,Rko,rO,Pko,Bko,Iko,B3,age,Nko,qko,tO,jko,Dko,Gko,I3,nge,Oko,Vko,aO,Xko,zko,Wko,N3,sge,Qko,Hko,nO,Uko,Jko,Yko,q3,lge,Kko,Zko,sO,eSo,oSo,rSo,j3,ige,tSo,aSo,lO,nSo,sSo,lSo,D3,dge,iSo,dSo,iO,cSo,fSo,mSo,G3,cge,gSo,hSo,dO,pSo,uSo,_So,O3,fge,bSo,vSo,cO,FSo,TSo,MSo,V3,mge,ESo,CSo,fO,wSo,ASo,LSo,X3,gge,ySo,xSo,mO,$So,kSo,SSo,z3,hge,RSo,PSo,gO,BSo,ISo,NSo,W3,pge,qSo,jSo,uge,DSo,GSo,OSo,Q3,_ge,VSo,XSo,hO,zSo,WSo,QSo,H3,bge,HSo,USo,pO,JSo,YSo,KSo,U3,vge,ZSo,eRo,uO,oRo,rRo,tRo,J3,Fge,aRo,nRo,_O,sRo,lRo,iRo,Y3,dRo,Tge,cRo,fRo,Mge,mRo,gRo,K3,DGe,Qi,Z3,Ege,uy,hRo,Cge,pRo,GGe,Ro,_y,uRo,Hi,_Ro,bO,bRo,vRo,vO,FRo,TRo,MRo,by,ERo,wge,CRo,wRo,ARo,dt,vy,LRo,Age,yRo,xRo,Ui,$Ro,Lge,kRo,SRo,FO,RRo,PRo,BRo,e2,IRo,eo,Fy,NRo,yge,qRo,jRo,Ia,DRo,xge,GRo,ORo,$ge,VRo,XRo,kge,zRo,WRo,QRo,pe,o2,Sge,HRo,URo,TO,JRo,YRo,KRo,r2,Rge,ZRo,ePo,MO,oPo,rPo,tPo,t2,Pge,aPo,nPo,EO,sPo,lPo,iPo,a2,Bge,dPo,cPo,CO,fPo,mPo,gPo,n2,Ige,hPo,pPo,wO,uPo,_Po,bPo,s2,Nge,vPo,FPo,AO,TPo,MPo,EPo,l2,qge,CPo,wPo,LO,APo,LPo,yPo,i2,jge,xPo,$Po,yO,kPo,SPo,RPo,d2,Dge,PPo,BPo,xO,IPo,NPo,qPo,c2,Gge,jPo,DPo,$O,GPo,OPo,VPo,f2,Oge,XPo,zPo,kO,WPo,QPo,HPo,m2,Vge,UPo,JPo,SO,YPo,KPo,ZPo,g2,Xge,eBo,oBo,RO,rBo,tBo,aBo,h2,zge,nBo,sBo,PO,lBo,iBo,dBo,p2,Wge,cBo,fBo,BO,mBo,gBo,hBo,u2,Qge,pBo,uBo,IO,_Bo,bBo,vBo,_2,Hge,FBo,TBo,NO,MBo,EBo,CBo,b2,wBo,Uge,ABo,LBo,Jge,yBo,xBo,v2,OGe,Ji,F2,Yge,Ty,$Bo,Kge,kBo,VGe,Po,My,SBo,Yi,RBo,qO,PBo,BBo,jO,IBo,NBo,qBo,Ey,jBo,Zge,DBo,GBo,OBo,ct,Cy,VBo,ehe,XBo,zBo,Ki,WBo,ohe,QBo,HBo,DO,UBo,JBo,YBo,T2,KBo,oo,wy,ZBo,rhe,eIo,oIo,Na,rIo,the,tIo,aIo,ahe,nIo,sIo,nhe,lIo,iIo,dIo,N,M2,she,cIo,fIo,GO,mIo,gIo,hIo,E2,lhe,pIo,uIo,OO,_Io,bIo,vIo,C2,ihe,FIo,TIo,VO,MIo,EIo,CIo,w2,dhe,wIo,AIo,XO,LIo,yIo,xIo,A2,che,$Io,kIo,zO,SIo,RIo,PIo,L2,fhe,BIo,IIo,WO,NIo,qIo,jIo,y2,mhe,DIo,GIo,QO,OIo,VIo,XIo,x2,ghe,zIo,WIo,HO,QIo,HIo,UIo,$2,hhe,JIo,YIo,UO,KIo,ZIo,eNo,k2,phe,oNo,rNo,JO,tNo,aNo,nNo,S2,uhe,sNo,lNo,YO,iNo,dNo,cNo,R2,_he,fNo,mNo,KO,gNo,hNo,pNo,P2,bhe,uNo,_No,ZO,bNo,vNo,FNo,B2,vhe,TNo,MNo,eV,ENo,CNo,wNo,I2,Fhe,ANo,LNo,oV,yNo,xNo,$No,N2,The,kNo,SNo,rV,RNo,PNo,BNo,q2,Mhe,INo,NNo,tV,qNo,jNo,DNo,j2,Ehe,GNo,ONo,aV,VNo,XNo,zNo,D2,Che,WNo,QNo,nV,HNo,UNo,JNo,G2,whe,YNo,KNo,sV,ZNo,eqo,oqo,O2,Ahe,rqo,tqo,lV,aqo,nqo,sqo,V2,Lhe,lqo,iqo,iV,dqo,cqo,fqo,X2,yhe,mqo,gqo,dV,hqo,pqo,uqo,z2,xhe,_qo,bqo,cV,vqo,Fqo,Tqo,W2,$he,Mqo,Eqo,fV,Cqo,wqo,Aqo,Q2,khe,Lqo,yqo,mV,xqo,$qo,kqo,H2,She,Sqo,Rqo,gV,Pqo,Bqo,Iqo,U2,Rhe,Nqo,qqo,hV,jqo,Dqo,Gqo,J2,Phe,Oqo,Vqo,pV,Xqo,zqo,Wqo,Y2,Bhe,Qqo,Hqo,uV,Uqo,Jqo,Yqo,K2,Ihe,Kqo,Zqo,_V,ejo,ojo,rjo,Z2,Nhe,tjo,ajo,bV,njo,sjo,ljo,eb,qhe,ijo,djo,vV,cjo,fjo,mjo,ob,jhe,gjo,hjo,FV,pjo,ujo,_jo,rb,Dhe,bjo,vjo,TV,Fjo,Tjo,Mjo,tb,Ghe,Ejo,Cjo,MV,wjo,Ajo,Ljo,ab,Ohe,yjo,xjo,EV,$jo,kjo,Sjo,nb,Vhe,Rjo,Pjo,CV,Bjo,Ijo,Njo,sb,Xhe,qjo,jjo,wV,Djo,Gjo,Ojo,lb,zhe,Vjo,Xjo,AV,zjo,Wjo,Qjo,ib,Whe,Hjo,Ujo,LV,Jjo,Yjo,Kjo,db,Qhe,Zjo,eDo,yV,oDo,rDo,tDo,cb,Hhe,aDo,nDo,xV,sDo,lDo,iDo,fb,Uhe,dDo,cDo,$V,fDo,mDo,gDo,mb,Jhe,hDo,pDo,kV,uDo,_Do,bDo,gb,Yhe,vDo,FDo,SV,TDo,MDo,EDo,hb,Khe,CDo,wDo,RV,ADo,LDo,yDo,pb,Zhe,xDo,$Do,PV,kDo,SDo,RDo,ub,PDo,epe,BDo,IDo,ope,NDo,qDo,_b,XGe,Zi,bb,rpe,Ay,jDo,tpe,DDo,zGe,Bo,Ly,GDo,ed,ODo,BV,VDo,XDo,IV,zDo,WDo,QDo,yy,HDo,ape,UDo,JDo,YDo,ft,xy,KDo,npe,ZDo,eGo,od,oGo,spe,rGo,tGo,NV,aGo,nGo,sGo,vb,lGo,ro,$y,iGo,lpe,dGo,cGo,qa,fGo,ipe,mGo,gGo,dpe,hGo,pGo,cpe,uGo,_Go,bGo,Z,Fb,fpe,vGo,FGo,qV,TGo,MGo,EGo,Tb,mpe,CGo,wGo,jV,AGo,LGo,yGo,Mb,gpe,xGo,$Go,DV,kGo,SGo,RGo,Eb,hpe,PGo,BGo,GV,IGo,NGo,qGo,Cb,ppe,jGo,DGo,OV,GGo,OGo,VGo,wb,upe,XGo,zGo,VV,WGo,QGo,HGo,Ab,_pe,UGo,JGo,XV,YGo,KGo,ZGo,Lb,bpe,eOo,oOo,zV,rOo,tOo,aOo,yb,vpe,nOo,sOo,WV,lOo,iOo,dOo,xb,Fpe,cOo,fOo,QV,mOo,gOo,hOo,$b,Tpe,pOo,uOo,HV,_Oo,bOo,vOo,kb,Mpe,FOo,TOo,UV,MOo,EOo,COo,Sb,Epe,wOo,AOo,JV,LOo,yOo,xOo,Rb,Cpe,$Oo,kOo,YV,SOo,ROo,POo,Pb,wpe,BOo,IOo,KV,NOo,qOo,jOo,Bb,Ape,DOo,GOo,ZV,OOo,VOo,XOo,Ib,Lpe,zOo,WOo,eX,QOo,HOo,UOo,Nb,ype,JOo,YOo,oX,KOo,ZOo,eVo,qb,xpe,oVo,rVo,rX,tVo,aVo,nVo,jb,$pe,sVo,lVo,tX,iVo,dVo,cVo,Db,kpe,fVo,mVo,aX,gVo,hVo,pVo,Gb,Spe,uVo,_Vo,nX,bVo,vVo,FVo,Ob,Rpe,TVo,MVo,sX,EVo,CVo,wVo,Vb,Ppe,AVo,LVo,lX,yVo,xVo,$Vo,Xb,Bpe,kVo,SVo,iX,RVo,PVo,BVo,zb,Ipe,IVo,NVo,dX,qVo,jVo,DVo,Wb,Npe,GVo,OVo,cX,VVo,XVo,zVo,Qb,qpe,WVo,QVo,fX,HVo,UVo,JVo,Hb,jpe,YVo,KVo,mX,ZVo,eXo,oXo,Ub,rXo,Dpe,tXo,aXo,Gpe,nXo,sXo,Jb,WGe,rd,Yb,Ope,ky,lXo,Vpe,iXo,QGe,Io,Sy,dXo,td,cXo,gX,fXo,mXo,hX,gXo,hXo,pXo,Ry,uXo,Xpe,_Xo,bXo,vXo,mt,Py,FXo,zpe,TXo,MXo,ad,EXo,Wpe,CXo,wXo,pX,AXo,LXo,yXo,Kb,xXo,to,By,$Xo,Qpe,kXo,SXo,ja,RXo,Hpe,PXo,BXo,Upe,IXo,NXo,Jpe,qXo,jXo,DXo,Zr,Zb,Ype,GXo,OXo,uX,VXo,XXo,zXo,ev,Kpe,WXo,QXo,_X,HXo,UXo,JXo,ov,Zpe,YXo,KXo,bX,ZXo,ezo,ozo,rv,eue,rzo,tzo,vX,azo,nzo,szo,tv,oue,lzo,izo,FX,dzo,czo,fzo,av,mzo,rue,gzo,hzo,tue,pzo,uzo,nv,HGe,nd,sv,aue,Iy,_zo,nue,bzo,UGe,No,Ny,vzo,sd,Fzo,TX,Tzo,Mzo,MX,Ezo,Czo,wzo,qy,Azo,sue,Lzo,yzo,xzo,gt,jy,$zo,lue,kzo,Szo,ld,Rzo,iue,Pzo,Bzo,EX,Izo,Nzo,qzo,lv,jzo,ao,Dy,Dzo,due,Gzo,Ozo,Da,Vzo,cue,Xzo,zzo,fue,Wzo,Qzo,mue,Hzo,Uzo,Jzo,H,iv,gue,Yzo,Kzo,CX,Zzo,eWo,oWo,dv,hue,rWo,tWo,wX,aWo,nWo,sWo,cv,pue,lWo,iWo,AX,dWo,cWo,fWo,fv,uue,mWo,gWo,LX,hWo,pWo,uWo,mv,_ue,_Wo,bWo,yX,vWo,FWo,TWo,gv,bue,MWo,EWo,xX,CWo,wWo,AWo,hv,vue,LWo,yWo,$X,xWo,$Wo,kWo,pv,Fue,SWo,RWo,kX,PWo,BWo,IWo,uv,Tue,NWo,qWo,SX,jWo,DWo,GWo,_v,Mue,OWo,VWo,RX,XWo,zWo,WWo,bv,Eue,QWo,HWo,PX,UWo,JWo,YWo,vv,Cue,KWo,ZWo,BX,eQo,oQo,rQo,Fv,wue,tQo,aQo,IX,nQo,sQo,lQo,Tv,Aue,iQo,dQo,NX,cQo,fQo,mQo,Mv,Lue,gQo,hQo,qX,pQo,uQo,_Qo,Ev,yue,bQo,vQo,jX,FQo,TQo,MQo,Cv,xue,EQo,CQo,DX,wQo,AQo,LQo,wv,$ue,yQo,xQo,GX,$Qo,kQo,SQo,Av,kue,RQo,PQo,OX,BQo,IQo,NQo,Lv,Sue,qQo,jQo,VX,DQo,GQo,OQo,yv,Rue,VQo,XQo,XX,zQo,WQo,QQo,xv,Pue,HQo,UQo,zX,JQo,YQo,KQo,$v,Bue,ZQo,eHo,WX,oHo,rHo,tHo,kv,Iue,aHo,nHo,QX,sHo,lHo,iHo,Sv,Nue,dHo,cHo,HX,fHo,mHo,gHo,Rv,que,hHo,pHo,UX,uHo,_Ho,bHo,Pv,jue,vHo,FHo,JX,THo,MHo,EHo,Bv,Due,CHo,wHo,YX,AHo,LHo,yHo,Iv,Gue,xHo,$Ho,KX,kHo,SHo,RHo,Nv,Oue,PHo,BHo,ZX,IHo,NHo,qHo,qv,Vue,jHo,DHo,ez,GHo,OHo,VHo,jv,Xue,XHo,zHo,oz,WHo,QHo,HHo,Dv,zue,UHo,JHo,rz,YHo,KHo,ZHo,Gv,Wue,eUo,oUo,tz,rUo,tUo,aUo,Ov,Que,nUo,sUo,az,lUo,iUo,dUo,Vv,cUo,Hue,fUo,mUo,Uue,gUo,hUo,Xv,JGe,id,zv,Jue,Gy,pUo,Yue,uUo,YGe,qo,Oy,_Uo,dd,bUo,nz,vUo,FUo,sz,TUo,MUo,EUo,Vy,CUo,Kue,wUo,AUo,LUo,ht,Xy,yUo,Zue,xUo,$Uo,cd,kUo,e_e,SUo,RUo,lz,PUo,BUo,IUo,Wv,NUo,no,zy,qUo,o_e,jUo,DUo,Ga,GUo,r_e,OUo,VUo,t_e,XUo,zUo,a_e,WUo,QUo,HUo,V,Qv,n_e,UUo,JUo,iz,YUo,KUo,ZUo,Hv,s_e,eJo,oJo,dz,rJo,tJo,aJo,Uv,l_e,nJo,sJo,cz,lJo,iJo,dJo,Jv,i_e,cJo,fJo,fz,mJo,gJo,hJo,Yv,d_e,pJo,uJo,mz,_Jo,bJo,vJo,Kv,c_e,FJo,TJo,gz,MJo,EJo,CJo,Zv,f_e,wJo,AJo,hz,LJo,yJo,xJo,eF,m_e,$Jo,kJo,pz,SJo,RJo,PJo,oF,g_e,BJo,IJo,uz,NJo,qJo,jJo,rF,h_e,DJo,GJo,_z,OJo,VJo,XJo,tF,p_e,zJo,WJo,bz,QJo,HJo,UJo,aF,u_e,JJo,YJo,vz,KJo,ZJo,eYo,nF,__e,oYo,rYo,Fz,tYo,aYo,nYo,sF,b_e,sYo,lYo,Tz,iYo,dYo,cYo,lF,v_e,fYo,mYo,Mz,gYo,hYo,pYo,iF,F_e,uYo,_Yo,Ez,bYo,vYo,FYo,dF,T_e,TYo,MYo,Cz,EYo,CYo,wYo,cF,M_e,AYo,LYo,wz,yYo,xYo,$Yo,fF,E_e,kYo,SYo,Az,RYo,PYo,BYo,mF,C_e,IYo,NYo,Lz,qYo,jYo,DYo,gF,w_e,GYo,OYo,yz,VYo,XYo,zYo,hF,A_e,WYo,QYo,xz,HYo,UYo,JYo,pF,L_e,YYo,KYo,$z,ZYo,eKo,oKo,uF,y_e,rKo,tKo,kz,aKo,nKo,sKo,_F,x_e,lKo,iKo,Sz,dKo,cKo,fKo,bF,$_e,mKo,gKo,Rz,hKo,pKo,uKo,vF,k_e,_Ko,bKo,Pz,vKo,FKo,TKo,FF,S_e,MKo,EKo,Bz,CKo,wKo,AKo,TF,R_e,LKo,yKo,Iz,xKo,$Ko,kKo,MF,P_e,SKo,RKo,Nz,PKo,BKo,IKo,EF,B_e,NKo,qKo,qz,jKo,DKo,GKo,CF,I_e,OKo,VKo,jz,XKo,zKo,WKo,wF,N_e,QKo,HKo,Dz,UKo,JKo,YKo,AF,q_e,KKo,ZKo,Gz,eZo,oZo,rZo,LF,j_e,tZo,aZo,Oz,nZo,sZo,lZo,yF,D_e,iZo,dZo,Vz,cZo,fZo,mZo,xF,G_e,gZo,hZo,Xz,pZo,uZo,_Zo,$F,O_e,bZo,vZo,zz,FZo,TZo,MZo,kF,V_e,EZo,CZo,Wz,wZo,AZo,LZo,SF,X_e,yZo,xZo,Qz,$Zo,kZo,SZo,RF,RZo,z_e,PZo,BZo,W_e,IZo,NZo,PF,KGe,fd,BF,Q_e,Wy,qZo,H_e,jZo,ZGe,jo,Qy,DZo,md,GZo,Hz,OZo,VZo,Uz,XZo,zZo,WZo,Hy,QZo,U_e,HZo,UZo,JZo,pt,Uy,YZo,J_e,KZo,ZZo,gd,eer,Y_e,oer,rer,Jz,ter,aer,ner,IF,ser,so,Jy,ler,K_e,ier,der,Oa,cer,Z_e,fer,mer,e1e,ger,her,o1e,per,uer,_er,r1e,NF,t1e,ber,ver,Yz,Fer,Ter,Mer,qF,Eer,a1e,Cer,wer,n1e,Aer,Ler,jF,eOe,hd,DF,s1e,Yy,yer,l1e,xer,oOe,Do,Ky,$er,pd,ker,Kz,Ser,Rer,Zz,Per,Ber,Ier,Zy,Ner,i1e,qer,jer,Der,ut,e8,Ger,d1e,Oer,Ver,ud,Xer,c1e,zer,Wer,eW,Qer,Her,Uer,GF,Jer,lo,o8,Yer,f1e,Ker,Zer,Va,eor,m1e,oor,ror,g1e,tor,aor,h1e,nor,sor,lor,Fe,OF,p1e,ior,dor,oW,cor,mor,gor,VF,u1e,hor,por,rW,uor,_or,bor,XF,_1e,vor,For,tW,Tor,Mor,Eor,zF,b1e,Cor,wor,aW,Aor,Lor,yor,Vs,v1e,xor,$or,nW,kor,Sor,sW,Ror,Por,Bor,WF,F1e,Ior,Nor,lW,qor,jor,Dor,Xs,T1e,Gor,Oor,iW,Vor,Xor,dW,zor,Wor,Qor,_t,M1e,Hor,Uor,cW,Jor,Yor,fW,Kor,Zor,mW,err,orr,rrr,QF,E1e,trr,arr,gW,nrr,srr,lrr,HF,C1e,irr,drr,hW,crr,frr,mrr,UF,w1e,grr,hrr,pW,prr,urr,_rr,JF,A1e,brr,vrr,uW,Frr,Trr,Mrr,YF,L1e,Err,Crr,_W,wrr,Arr,Lrr,KF,y1e,yrr,xrr,bW,$rr,krr,Srr,ZF,x1e,Rrr,Prr,vW,Brr,Irr,Nrr,eT,qrr,$1e,jrr,Drr,k1e,Grr,Orr,oT,rOe,_d,rT,S1e,r8,Vrr,R1e,Xrr,tOe,Go,t8,zrr,bd,Wrr,FW,Qrr,Hrr,TW,Urr,Jrr,Yrr,a8,Krr,P1e,Zrr,etr,otr,bt,n8,rtr,B1e,ttr,atr,vd,ntr,I1e,str,ltr,MW,itr,dtr,ctr,tT,ftr,io,s8,mtr,N1e,gtr,htr,Xa,ptr,q1e,utr,_tr,j1e,btr,vtr,D1e,Ftr,Ttr,Mtr,G1e,aT,O1e,Etr,Ctr,EW,wtr,Atr,Ltr,nT,ytr,V1e,xtr,$tr,X1e,ktr,Str,sT,aOe,Fd,lT,z1e,l8,Rtr,W1e,Ptr,nOe,Oo,i8,Btr,Td,Itr,CW,Ntr,qtr,wW,jtr,Dtr,Gtr,d8,Otr,Q1e,Vtr,Xtr,ztr,vt,c8,Wtr,H1e,Qtr,Htr,Md,Utr,U1e,Jtr,Ytr,AW,Ktr,Ztr,ear,iT,oar,co,f8,rar,J1e,tar,aar,za,nar,Y1e,sar,lar,K1e,iar,dar,Z1e,car,far,mar,e3e,dT,o3e,gar,har,LW,par,uar,_ar,cT,bar,r3e,Far,Tar,t3e,Mar,Ear,fT,sOe,Ed,mT,a3e,m8,Car,n3e,war,lOe,Vo,g8,Aar,Cd,Lar,yW,yar,xar,xW,$ar,kar,Sar,h8,Rar,s3e,Par,Bar,Iar,Ft,p8,Nar,l3e,qar,jar,wd,Dar,i3e,Gar,Oar,$W,Var,Xar,zar,gT,War,fo,u8,Qar,d3e,Har,Uar,Wa,Jar,c3e,Yar,Kar,f3e,Zar,enr,m3e,onr,rnr,tnr,Pe,hT,g3e,anr,nnr,kW,snr,lnr,inr,pT,h3e,dnr,cnr,SW,fnr,mnr,gnr,uT,p3e,hnr,pnr,RW,unr,_nr,bnr,_T,u3e,vnr,Fnr,PW,Tnr,Mnr,Enr,bT,_3e,Cnr,wnr,BW,Anr,Lnr,ynr,vT,b3e,xnr,$nr,IW,knr,Snr,Rnr,FT,v3e,Pnr,Bnr,NW,Inr,Nnr,qnr,TT,F3e,jnr,Dnr,qW,Gnr,Onr,Vnr,MT,T3e,Xnr,znr,jW,Wnr,Qnr,Hnr,ET,Unr,M3e,Jnr,Ynr,E3e,Knr,Znr,CT,iOe,Ad,wT,C3e,_8,esr,w3e,osr,dOe,Xo,b8,rsr,Ld,tsr,DW,asr,nsr,GW,ssr,lsr,isr,v8,dsr,A3e,csr,fsr,msr,Tt,F8,gsr,L3e,hsr,psr,yd,usr,y3e,_sr,bsr,OW,vsr,Fsr,Tsr,AT,Msr,mo,T8,Esr,x3e,Csr,wsr,Qa,Asr,$3e,Lsr,ysr,k3e,xsr,$sr,S3e,ksr,Ssr,Rsr,et,LT,R3e,Psr,Bsr,VW,Isr,Nsr,qsr,yT,P3e,jsr,Dsr,XW,Gsr,Osr,Vsr,xT,B3e,Xsr,zsr,zW,Wsr,Qsr,Hsr,$T,I3e,Usr,Jsr,WW,Ysr,Ksr,Zsr,kT,N3e,elr,olr,QW,rlr,tlr,alr,ST,nlr,q3e,slr,llr,j3e,ilr,dlr,RT,cOe,xd,PT,D3e,M8,clr,G3e,flr,fOe,zo,E8,mlr,$d,glr,HW,hlr,plr,UW,ulr,_lr,blr,C8,vlr,O3e,Flr,Tlr,Mlr,Mt,w8,Elr,V3e,Clr,wlr,kd,Alr,X3e,Llr,ylr,JW,xlr,$lr,klr,BT,Slr,go,A8,Rlr,z3e,Plr,Blr,Ha,Ilr,W3e,Nlr,qlr,Q3e,jlr,Dlr,H3e,Glr,Olr,Vlr,Le,IT,U3e,Xlr,zlr,YW,Wlr,Qlr,Hlr,NT,J3e,Ulr,Jlr,KW,Ylr,Klr,Zlr,qT,Y3e,eir,oir,ZW,rir,tir,air,jT,K3e,nir,sir,eQ,lir,iir,dir,DT,Z3e,cir,fir,oQ,mir,gir,hir,GT,e2e,pir,uir,rQ,_ir,bir,vir,OT,o2e,Fir,Tir,tQ,Mir,Eir,Cir,VT,r2e,wir,Air,aQ,Lir,yir,xir,XT,t2e,$ir,kir,nQ,Sir,Rir,Pir,zT,a2e,Bir,Iir,sQ,Nir,qir,jir,WT,Dir,n2e,Gir,Oir,s2e,Vir,Xir,QT,mOe,Sd,HT,l2e,L8,zir,i2e,Wir,gOe,Wo,y8,Qir,Rd,Hir,lQ,Uir,Jir,iQ,Yir,Kir,Zir,x8,edr,d2e,odr,rdr,tdr,Et,$8,adr,c2e,ndr,sdr,Pd,ldr,f2e,idr,ddr,dQ,cdr,fdr,mdr,UT,gdr,ho,k8,hdr,m2e,pdr,udr,Ua,_dr,g2e,bdr,vdr,h2e,Fdr,Tdr,p2e,Mdr,Edr,Cdr,S8,JT,u2e,wdr,Adr,cQ,Ldr,ydr,xdr,YT,_2e,$dr,kdr,fQ,Sdr,Rdr,Pdr,KT,Bdr,b2e,Idr,Ndr,v2e,qdr,jdr,ZT,hOe,Bd,e7,F2e,R8,Ddr,T2e,Gdr,pOe,Qo,P8,Odr,Id,Vdr,mQ,Xdr,zdr,gQ,Wdr,Qdr,Hdr,B8,Udr,M2e,Jdr,Ydr,Kdr,Ct,I8,Zdr,E2e,ecr,ocr,Nd,rcr,C2e,tcr,acr,hQ,ncr,scr,lcr,o7,icr,po,N8,dcr,w2e,ccr,fcr,Ja,mcr,A2e,gcr,hcr,L2e,pcr,ucr,y2e,_cr,bcr,vcr,ot,r7,x2e,Fcr,Tcr,pQ,Mcr,Ecr,Ccr,t7,$2e,wcr,Acr,uQ,Lcr,ycr,xcr,a7,k2e,$cr,kcr,_Q,Scr,Rcr,Pcr,n7,S2e,Bcr,Icr,bQ,Ncr,qcr,jcr,s7,R2e,Dcr,Gcr,vQ,Ocr,Vcr,Xcr,l7,zcr,P2e,Wcr,Qcr,B2e,Hcr,Ucr,i7,uOe,qd,d7,I2e,q8,Jcr,N2e,Ycr,_Oe,Ho,j8,Kcr,jd,Zcr,FQ,efr,ofr,TQ,rfr,tfr,afr,D8,nfr,q2e,sfr,lfr,ifr,wt,G8,dfr,j2e,cfr,ffr,Dd,mfr,D2e,gfr,hfr,MQ,pfr,ufr,_fr,c7,bfr,uo,O8,vfr,G2e,Ffr,Tfr,Ya,Mfr,O2e,Efr,Cfr,V2e,wfr,Afr,X2e,Lfr,yfr,xfr,Gd,f7,z2e,$fr,kfr,EQ,Sfr,Rfr,Pfr,m7,W2e,Bfr,Ifr,CQ,Nfr,qfr,jfr,g7,Q2e,Dfr,Gfr,wQ,Ofr,Vfr,Xfr,h7,zfr,H2e,Wfr,Qfr,U2e,Hfr,Ufr,p7,bOe,Od,u7,J2e,V8,Jfr,Y2e,Yfr,vOe,Uo,X8,Kfr,Vd,Zfr,AQ,emr,omr,LQ,rmr,tmr,amr,z8,nmr,K2e,smr,lmr,imr,At,W8,dmr,Z2e,cmr,fmr,Xd,mmr,ebe,gmr,hmr,yQ,pmr,umr,_mr,_7,bmr,_o,Q8,vmr,obe,Fmr,Tmr,Ka,Mmr,rbe,Emr,Cmr,tbe,wmr,Amr,abe,Lmr,ymr,xmr,H8,b7,nbe,$mr,kmr,xQ,Smr,Rmr,Pmr,v7,sbe,Bmr,Imr,$Q,Nmr,qmr,jmr,F7,Dmr,lbe,Gmr,Omr,ibe,Vmr,Xmr,T7,FOe,zd,M7,dbe,U8,zmr,cbe,Wmr,TOe,Jo,J8,Qmr,Wd,Hmr,kQ,Umr,Jmr,SQ,Ymr,Kmr,Zmr,Y8,egr,fbe,ogr,rgr,tgr,Lt,K8,agr,mbe,ngr,sgr,Qd,lgr,gbe,igr,dgr,RQ,cgr,fgr,mgr,E7,ggr,bo,Z8,hgr,hbe,pgr,ugr,Za,_gr,pbe,bgr,vgr,ube,Fgr,Tgr,_be,Mgr,Egr,Cgr,bbe,C7,vbe,wgr,Agr,PQ,Lgr,ygr,xgr,w7,$gr,Fbe,kgr,Sgr,Tbe,Rgr,Pgr,A7,MOe,Hd,L7,Mbe,e9,Bgr,Ebe,Igr,EOe,Yo,o9,Ngr,Ud,qgr,BQ,jgr,Dgr,IQ,Ggr,Ogr,Vgr,r9,Xgr,Cbe,zgr,Wgr,Qgr,yt,t9,Hgr,wbe,Ugr,Jgr,Jd,Ygr,Abe,Kgr,Zgr,NQ,ehr,ohr,rhr,y7,thr,vo,a9,ahr,Lbe,nhr,shr,en,lhr,ybe,ihr,dhr,xbe,chr,fhr,$be,mhr,ghr,hhr,on,x7,kbe,phr,uhr,qQ,_hr,bhr,vhr,$7,Sbe,Fhr,Thr,jQ,Mhr,Ehr,Chr,k7,Rbe,whr,Ahr,DQ,Lhr,yhr,xhr,S7,Pbe,$hr,khr,GQ,Shr,Rhr,Phr,R7,Bhr,Bbe,Ihr,Nhr,Ibe,qhr,jhr,P7,COe,Yd,B7,Nbe,n9,Dhr,qbe,Ghr,wOe,Ko,s9,Ohr,Kd,Vhr,OQ,Xhr,zhr,VQ,Whr,Qhr,Hhr,l9,Uhr,jbe,Jhr,Yhr,Khr,xt,i9,Zhr,Dbe,epr,opr,Zd,rpr,Gbe,tpr,apr,XQ,npr,spr,lpr,I7,ipr,Fo,d9,dpr,Obe,cpr,fpr,rn,mpr,Vbe,gpr,hpr,Xbe,ppr,upr,zbe,_pr,bpr,vpr,Wbe,N7,Qbe,Fpr,Tpr,zQ,Mpr,Epr,Cpr,q7,wpr,Hbe,Apr,Lpr,Ube,ypr,xpr,j7,AOe,ec,D7,Jbe,c9,$pr,Ybe,kpr,LOe,Zo,f9,Spr,oc,Rpr,WQ,Ppr,Bpr,QQ,Ipr,Npr,qpr,m9,jpr,Kbe,Dpr,Gpr,Opr,$t,g9,Vpr,Zbe,Xpr,zpr,rc,Wpr,eve,Qpr,Hpr,HQ,Upr,Jpr,Ypr,G7,Kpr,Lr,h9,Zpr,ove,eur,our,tn,rur,rve,tur,aur,tve,nur,sur,ave,lur,iur,dur,q,O7,nve,cur,fur,UQ,mur,gur,hur,V7,sve,pur,uur,JQ,_ur,bur,vur,X7,lve,Fur,Tur,YQ,Mur,Eur,Cur,z7,ive,wur,Aur,KQ,Lur,yur,xur,W7,dve,$ur,kur,ZQ,Sur,Rur,Pur,Q7,cve,Bur,Iur,eH,Nur,qur,jur,H7,fve,Dur,Gur,oH,Our,Vur,Xur,U7,mve,zur,Wur,rH,Qur,Hur,Uur,J7,gve,Jur,Yur,tH,Kur,Zur,e_r,Y7,hve,o_r,r_r,aH,t_r,a_r,n_r,K7,pve,s_r,l_r,nH,i_r,d_r,c_r,Z7,uve,f_r,m_r,sH,g_r,h_r,p_r,eM,_ve,u_r,__r,lH,b_r,v_r,F_r,oM,bve,T_r,M_r,iH,E_r,C_r,w_r,rM,vve,A_r,L_r,dH,y_r,x_r,$_r,tM,Fve,k_r,S_r,cH,R_r,P_r,B_r,aM,Tve,I_r,N_r,fH,q_r,j_r,D_r,zs,Mve,G_r,O_r,mH,V_r,X_r,gH,z_r,W_r,Q_r,nM,Eve,H_r,U_r,hH,J_r,Y_r,K_r,sM,Cve,Z_r,e1r,pH,o1r,r1r,t1r,lM,wve,a1r,n1r,uH,s1r,l1r,i1r,iM,Ave,d1r,c1r,_H,f1r,m1r,g1r,dM,Lve,h1r,p1r,bH,u1r,_1r,b1r,cM,yve,v1r,F1r,vH,T1r,M1r,E1r,fM,xve,C1r,w1r,FH,A1r,L1r,y1r,mM,$ve,x1r,$1r,TH,k1r,S1r,R1r,gM,kve,P1r,B1r,MH,I1r,N1r,q1r,hM,Sve,j1r,D1r,EH,G1r,O1r,V1r,pM,Rve,X1r,z1r,CH,W1r,Q1r,H1r,uM,Pve,U1r,J1r,wH,Y1r,K1r,Z1r,_M,Bve,e3r,o3r,AH,r3r,t3r,a3r,bM,Ive,n3r,s3r,LH,l3r,i3r,d3r,vM,Nve,c3r,f3r,yH,m3r,g3r,h3r,FM,qve,p3r,u3r,xH,_3r,b3r,v3r,TM,jve,F3r,T3r,$H,M3r,E3r,C3r,MM,Dve,w3r,A3r,kH,L3r,y3r,x3r,EM,Gve,$3r,k3r,SH,S3r,R3r,P3r,CM,Ove,B3r,I3r,RH,N3r,q3r,j3r,wM,Vve,D3r,G3r,PH,O3r,V3r,X3r,AM,Xve,z3r,W3r,BH,Q3r,H3r,U3r,LM,zve,J3r,Y3r,IH,K3r,Z3r,e2r,yM,Wve,o2r,r2r,NH,t2r,a2r,n2r,xM,Qve,s2r,l2r,qH,i2r,d2r,c2r,$M,Hve,f2r,m2r,jH,g2r,h2r,p2r,kM,Uve,u2r,_2r,DH,b2r,v2r,F2r,SM,Jve,T2r,M2r,GH,E2r,C2r,w2r,RM,Yve,A2r,L2r,OH,y2r,x2r,$2r,PM,yOe,tc,BM,Kve,p9,k2r,Zve,S2r,xOe,er,u9,R2r,ac,P2r,VH,B2r,I2r,XH,N2r,q2r,j2r,_9,D2r,eFe,G2r,O2r,V2r,kt,b9,X2r,oFe,z2r,W2r,nc,Q2r,rFe,H2r,U2r,zH,J2r,Y2r,K2r,IM,Z2r,yr,v9,ebr,tFe,obr,rbr,an,tbr,aFe,abr,nbr,nFe,sbr,lbr,sFe,ibr,dbr,cbr,se,NM,lFe,fbr,mbr,WH,gbr,hbr,pbr,qM,iFe,ubr,_br,QH,bbr,vbr,Fbr,jM,dFe,Tbr,Mbr,HH,Ebr,Cbr,wbr,DM,cFe,Abr,Lbr,UH,ybr,xbr,$br,GM,fFe,kbr,Sbr,JH,Rbr,Pbr,Bbr,OM,mFe,Ibr,Nbr,YH,qbr,jbr,Dbr,VM,gFe,Gbr,Obr,KH,Vbr,Xbr,zbr,XM,hFe,Wbr,Qbr,ZH,Hbr,Ubr,Jbr,zM,pFe,Ybr,Kbr,eU,Zbr,evr,ovr,WM,uFe,rvr,tvr,oU,avr,nvr,svr,QM,_Fe,lvr,ivr,rU,dvr,cvr,fvr,HM,bFe,mvr,gvr,tU,hvr,pvr,uvr,UM,vFe,_vr,bvr,aU,vvr,Fvr,Tvr,JM,FFe,Mvr,Evr,nU,Cvr,wvr,Avr,YM,TFe,Lvr,yvr,sU,xvr,$vr,kvr,KM,MFe,Svr,Rvr,lU,Pvr,Bvr,Ivr,ZM,EFe,Nvr,qvr,iU,jvr,Dvr,Gvr,eE,CFe,Ovr,Vvr,dU,Xvr,zvr,Wvr,oE,wFe,Qvr,Hvr,cU,Uvr,Jvr,Yvr,rE,AFe,Kvr,Zvr,fU,eFr,oFr,rFr,tE,LFe,tFr,aFr,mU,nFr,sFr,lFr,aE,yFe,iFr,dFr,gU,cFr,fFr,mFr,nE,xFe,gFr,hFr,hU,pFr,uFr,_Fr,sE,$Oe,sc,lE,$Fe,F9,bFr,kFe,vFr,kOe,or,T9,FFr,lc,TFr,pU,MFr,EFr,uU,CFr,wFr,AFr,M9,LFr,SFe,yFr,xFr,$Fr,St,E9,kFr,RFe,SFr,RFr,ic,PFr,PFe,BFr,IFr,_U,NFr,qFr,jFr,iE,DFr,xr,C9,GFr,BFe,OFr,VFr,nn,XFr,IFe,zFr,WFr,NFe,QFr,HFr,qFe,UFr,JFr,YFr,Me,dE,jFe,KFr,ZFr,bU,eTr,oTr,rTr,cE,DFe,tTr,aTr,vU,nTr,sTr,lTr,fE,GFe,iTr,dTr,FU,cTr,fTr,mTr,mE,OFe,gTr,hTr,TU,pTr,uTr,_Tr,gE,VFe,bTr,vTr,MU,FTr,TTr,MTr,hE,XFe,ETr,CTr,EU,wTr,ATr,LTr,pE,zFe,yTr,xTr,CU,$Tr,kTr,STr,uE,WFe,RTr,PTr,wU,BTr,ITr,NTr,_E,QFe,qTr,jTr,AU,DTr,GTr,OTr,bE,HFe,VTr,XTr,LU,zTr,WTr,QTr,vE,UFe,HTr,UTr,yU,JTr,YTr,KTr,FE,JFe,ZTr,e7r,xU,o7r,r7r,t7r,TE,YFe,a7r,n7r,$U,s7r,l7r,i7r,ME,SOe,dc,EE,KFe,w9,d7r,ZFe,c7r,ROe,rr,A9,f7r,cc,m7r,kU,g7r,h7r,SU,p7r,u7r,_7r,L9,b7r,eTe,v7r,F7r,T7r,Rt,y9,M7r,oTe,E7r,C7r,fc,w7r,rTe,A7r,L7r,RU,y7r,x7r,$7r,CE,k7r,$r,x9,S7r,tTe,R7r,P7r,sn,B7r,aTe,I7r,N7r,nTe,q7r,j7r,sTe,D7r,G7r,O7r,ln,wE,lTe,V7r,X7r,PU,z7r,W7r,Q7r,AE,iTe,H7r,U7r,BU,J7r,Y7r,K7r,LE,dTe,Z7r,eMr,IU,oMr,rMr,tMr,yE,cTe,aMr,nMr,NU,sMr,lMr,iMr,xE,POe,mc,$E,fTe,$9,dMr,mTe,cMr,BOe,tr,k9,fMr,gc,mMr,qU,gMr,hMr,jU,pMr,uMr,_Mr,S9,bMr,gTe,vMr,FMr,TMr,Pt,R9,MMr,hTe,EMr,CMr,hc,wMr,pTe,AMr,LMr,DU,yMr,xMr,$Mr,kE,kMr,kr,P9,SMr,uTe,RMr,PMr,dn,BMr,_Te,IMr,NMr,bTe,qMr,jMr,vTe,DMr,GMr,OMr,ie,SE,FTe,VMr,XMr,GU,zMr,WMr,QMr,RE,TTe,HMr,UMr,OU,JMr,YMr,KMr,PE,MTe,ZMr,eEr,VU,oEr,rEr,tEr,BE,ETe,aEr,nEr,XU,sEr,lEr,iEr,IE,CTe,dEr,cEr,zU,fEr,mEr,gEr,NE,wTe,hEr,pEr,WU,uEr,_Er,bEr,qE,ATe,vEr,FEr,QU,TEr,MEr,EEr,jE,LTe,CEr,wEr,HU,AEr,LEr,yEr,DE,yTe,xEr,$Er,UU,kEr,SEr,REr,GE,xTe,PEr,BEr,JU,IEr,NEr,qEr,OE,$Te,jEr,DEr,YU,GEr,OEr,VEr,VE,kTe,XEr,zEr,KU,WEr,QEr,HEr,XE,STe,UEr,JEr,ZU,YEr,KEr,ZEr,zE,RTe,e4r,o4r,eJ,r4r,t4r,a4r,WE,PTe,n4r,s4r,oJ,l4r,i4r,d4r,QE,BTe,c4r,f4r,rJ,m4r,g4r,h4r,HE,ITe,p4r,u4r,tJ,_4r,b4r,v4r,UE,NTe,F4r,T4r,aJ,M4r,E4r,C4r,JE,qTe,w4r,A4r,nJ,L4r,y4r,x4r,YE,jTe,$4r,k4r,sJ,S4r,R4r,P4r,KE,IOe,pc,ZE,DTe,B9,B4r,GTe,I4r,NOe,ar,I9,N4r,uc,q4r,lJ,j4r,D4r,iJ,G4r,O4r,V4r,N9,X4r,OTe,z4r,W4r,Q4r,Bt,q9,H4r,VTe,U4r,J4r,_c,Y4r,XTe,K4r,Z4r,dJ,eCr,oCr,rCr,e4,tCr,Sr,j9,aCr,zTe,nCr,sCr,cn,lCr,WTe,iCr,dCr,QTe,cCr,fCr,HTe,mCr,gCr,hCr,ye,o4,UTe,pCr,uCr,cJ,_Cr,bCr,vCr,r4,JTe,FCr,TCr,fJ,MCr,ECr,CCr,t4,YTe,wCr,ACr,mJ,LCr,yCr,xCr,a4,KTe,$Cr,kCr,gJ,SCr,RCr,PCr,n4,ZTe,BCr,ICr,hJ,NCr,qCr,jCr,s4,e7e,DCr,GCr,pJ,OCr,VCr,XCr,l4,o7e,zCr,WCr,uJ,QCr,HCr,UCr,i4,r7e,JCr,YCr,_J,KCr,ZCr,e5r,d4,t7e,o5r,r5r,bJ,t5r,a5r,n5r,c4,a7e,s5r,l5r,vJ,i5r,d5r,c5r,f4,qOe,bc,m4,n7e,D9,f5r,s7e,m5r,jOe,nr,G9,g5r,vc,h5r,FJ,p5r,u5r,TJ,_5r,b5r,v5r,O9,F5r,l7e,T5r,M5r,E5r,It,V9,C5r,i7e,w5r,A5r,Fc,L5r,d7e,y5r,x5r,MJ,$5r,k5r,S5r,g4,R5r,Rr,X9,P5r,c7e,B5r,I5r,fn,N5r,f7e,q5r,j5r,m7e,D5r,G5r,g7e,O5r,V5r,X5r,te,h4,h7e,z5r,W5r,EJ,Q5r,H5r,U5r,p4,p7e,J5r,Y5r,CJ,K5r,Z5r,e0r,u4,u7e,o0r,r0r,wJ,t0r,a0r,n0r,_4,_7e,s0r,l0r,AJ,i0r,d0r,c0r,b4,b7e,f0r,m0r,LJ,g0r,h0r,p0r,v4,v7e,u0r,_0r,yJ,b0r,v0r,F0r,F4,F7e,T0r,M0r,xJ,E0r,C0r,w0r,T4,T7e,A0r,L0r,$J,y0r,x0r,$0r,M4,M7e,k0r,S0r,kJ,R0r,P0r,B0r,E4,E7e,I0r,N0r,SJ,q0r,j0r,D0r,C4,C7e,G0r,O0r,RJ,V0r,X0r,z0r,w4,w7e,W0r,Q0r,PJ,H0r,U0r,J0r,A4,A7e,Y0r,K0r,BJ,Z0r,ewr,owr,L4,L7e,rwr,twr,IJ,awr,nwr,swr,y4,y7e,lwr,iwr,NJ,dwr,cwr,fwr,x4,x7e,mwr,gwr,qJ,hwr,pwr,uwr,$4,$7e,_wr,bwr,jJ,vwr,Fwr,Twr,k4,k7e,Mwr,Ewr,DJ,Cwr,wwr,Awr,S4,S7e,Lwr,ywr,GJ,xwr,$wr,kwr,R4,R7e,Swr,Rwr,OJ,Pwr,Bwr,Iwr,P4,P7e,Nwr,qwr,VJ,jwr,Dwr,Gwr,B4,B7e,Owr,Vwr,XJ,Xwr,zwr,Wwr,I4,I7e,Qwr,Hwr,zJ,Uwr,Jwr,Ywr,N4,N7e,Kwr,Zwr,WJ,eAr,oAr,rAr,q4,q7e,tAr,aAr,QJ,nAr,sAr,lAr,j4,j7e,iAr,dAr,HJ,cAr,fAr,mAr,D4,DOe,Tc,G4,D7e,z9,gAr,G7e,hAr,GOe,sr,W9,pAr,Mc,uAr,UJ,_Ar,bAr,JJ,vAr,FAr,TAr,Q9,MAr,O7e,EAr,CAr,wAr,Nt,H9,AAr,V7e,LAr,yAr,Ec,xAr,X7e,$Ar,kAr,YJ,SAr,RAr,PAr,O4,BAr,Pr,U9,IAr,z7e,NAr,qAr,mn,jAr,W7e,DAr,GAr,Q7e,OAr,VAr,H7e,XAr,zAr,WAr,ue,V4,U7e,QAr,HAr,KJ,UAr,JAr,YAr,X4,J7e,KAr,ZAr,ZJ,e6r,o6r,r6r,z4,Y7e,t6r,a6r,eY,n6r,s6r,l6r,W4,K7e,i6r,d6r,oY,c6r,f6r,m6r,Q4,Z7e,g6r,h6r,rY,p6r,u6r,_6r,H4,eMe,b6r,v6r,tY,F6r,T6r,M6r,U4,oMe,E6r,C6r,aY,w6r,A6r,L6r,J4,rMe,y6r,x6r,nY,$6r,k6r,S6r,Y4,tMe,R6r,P6r,sY,B6r,I6r,N6r,K4,aMe,q6r,j6r,lY,D6r,G6r,O6r,Z4,nMe,V6r,X6r,iY,z6r,W6r,Q6r,eC,sMe,H6r,U6r,dY,J6r,Y6r,K6r,oC,lMe,Z6r,eLr,cY,oLr,rLr,tLr,rC,iMe,aLr,nLr,fY,sLr,lLr,iLr,tC,dMe,dLr,cLr,mY,fLr,mLr,gLr,aC,cMe,hLr,pLr,gY,uLr,_Lr,bLr,nC,fMe,vLr,FLr,hY,TLr,MLr,ELr,sC,OOe,Cc,lC,mMe,J9,CLr,gMe,wLr,VOe,lr,Y9,ALr,wc,LLr,pY,yLr,xLr,uY,$Lr,kLr,SLr,K9,RLr,hMe,PLr,BLr,ILr,qt,Z9,NLr,pMe,qLr,jLr,Ac,DLr,uMe,GLr,OLr,_Y,VLr,XLr,zLr,iC,WLr,Br,ex,QLr,_Me,HLr,ULr,gn,JLr,bMe,YLr,KLr,vMe,ZLr,eyr,FMe,oyr,ryr,tyr,ox,dC,TMe,ayr,nyr,bY,syr,lyr,iyr,cC,MMe,dyr,cyr,vY,fyr,myr,gyr,fC,XOe,Lc,mC,EMe,rx,hyr,CMe,pyr,zOe,ir,tx,uyr,yc,_yr,FY,byr,vyr,TY,Fyr,Tyr,Myr,ax,Eyr,wMe,Cyr,wyr,Ayr,jt,nx,Lyr,AMe,yyr,xyr,xc,$yr,LMe,kyr,Syr,MY,Ryr,Pyr,Byr,gC,Iyr,Ir,sx,Nyr,yMe,qyr,jyr,hn,Dyr,xMe,Gyr,Oyr,$Me,Vyr,Xyr,kMe,zyr,Wyr,Qyr,SMe,hC,RMe,Hyr,Uyr,EY,Jyr,Yyr,Kyr,pC,WOe,$c,uC,PMe,lx,Zyr,BMe,e8r,QOe,dr,ix,o8r,kc,r8r,CY,t8r,a8r,wY,n8r,s8r,l8r,dx,i8r,IMe,d8r,c8r,f8r,Dt,cx,m8r,NMe,g8r,h8r,Sc,p8r,qMe,u8r,_8r,AY,b8r,v8r,F8r,_C,T8r,Nr,fx,M8r,jMe,E8r,C8r,pn,w8r,DMe,A8r,L8r,GMe,y8r,x8r,OMe,$8r,k8r,S8r,de,bC,VMe,R8r,P8r,LY,B8r,I8r,N8r,vC,XMe,q8r,j8r,yY,D8r,G8r,O8r,FC,zMe,V8r,X8r,xY,z8r,W8r,Q8r,TC,WMe,H8r,U8r,$Y,J8r,Y8r,K8r,MC,QMe,Z8r,e9r,kY,o9r,r9r,t9r,EC,HMe,a9r,n9r,SY,s9r,l9r,i9r,CC,UMe,d9r,c9r,RY,f9r,m9r,g9r,wC,JMe,h9r,p9r,PY,u9r,_9r,b9r,AC,YMe,v9r,F9r,BY,T9r,M9r,E9r,LC,KMe,C9r,w9r,IY,A9r,L9r,y9r,yC,ZMe,x9r,$9r,NY,k9r,S9r,R9r,xC,eEe,P9r,B9r,qY,I9r,N9r,q9r,$C,oEe,j9r,D9r,jY,G9r,O9r,V9r,kC,rEe,X9r,z9r,DY,W9r,Q9r,H9r,SC,tEe,U9r,J9r,GY,Y9r,K9r,Z9r,RC,aEe,exr,oxr,OY,rxr,txr,axr,PC,nEe,nxr,sxr,VY,lxr,ixr,dxr,BC,sEe,cxr,fxr,XY,mxr,gxr,hxr,IC,lEe,pxr,uxr,zY,_xr,bxr,vxr,NC,iEe,Fxr,Txr,WY,Mxr,Exr,Cxr,qC,HOe,Rc,jC,dEe,mx,wxr,cEe,Axr,UOe,cr,gx,Lxr,Pc,yxr,QY,xxr,$xr,HY,kxr,Sxr,Rxr,hx,Pxr,fEe,Bxr,Ixr,Nxr,Gt,px,qxr,mEe,jxr,Dxr,Bc,Gxr,gEe,Oxr,Vxr,UY,Xxr,zxr,Wxr,DC,Qxr,qr,ux,Hxr,hEe,Uxr,Jxr,un,Yxr,pEe,Kxr,Zxr,uEe,e$r,o$r,_Ee,r$r,t$r,a$r,ce,GC,bEe,n$r,s$r,JY,l$r,i$r,d$r,OC,vEe,c$r,f$r,YY,m$r,g$r,h$r,VC,FEe,p$r,u$r,KY,_$r,b$r,v$r,XC,TEe,F$r,T$r,ZY,M$r,E$r,C$r,zC,MEe,w$r,A$r,eK,L$r,y$r,x$r,WC,EEe,$$r,k$r,oK,S$r,R$r,P$r,QC,CEe,B$r,I$r,rK,N$r,q$r,j$r,HC,wEe,D$r,G$r,tK,O$r,V$r,X$r,UC,AEe,z$r,W$r,aK,Q$r,H$r,U$r,JC,LEe,J$r,Y$r,nK,K$r,Z$r,ekr,YC,yEe,okr,rkr,sK,tkr,akr,nkr,KC,xEe,skr,lkr,lK,ikr,dkr,ckr,ZC,$Ee,fkr,mkr,iK,gkr,hkr,pkr,e5,kEe,ukr,_kr,dK,bkr,vkr,Fkr,o5,SEe,Tkr,Mkr,cK,Ekr,Ckr,wkr,r5,REe,Akr,Lkr,fK,ykr,xkr,$kr,t5,PEe,kkr,Skr,mK,Rkr,Pkr,Bkr,a5,BEe,Ikr,Nkr,gK,qkr,jkr,Dkr,n5,IEe,Gkr,Okr,hK,Vkr,Xkr,zkr,s5,NEe,Wkr,Qkr,pK,Hkr,Ukr,Jkr,l5,JOe,Ic,i5,qEe,_x,Ykr,jEe,Kkr,YOe,fr,bx,Zkr,Nc,eSr,uK,oSr,rSr,_K,tSr,aSr,nSr,vx,sSr,DEe,lSr,iSr,dSr,Ot,Fx,cSr,GEe,fSr,mSr,qc,gSr,OEe,hSr,pSr,bK,uSr,_Sr,bSr,d5,vSr,jr,Tx,FSr,VEe,TSr,MSr,_n,ESr,XEe,CSr,wSr,zEe,ASr,LSr,WEe,ySr,xSr,$Sr,QEe,c5,HEe,kSr,SSr,vK,RSr,PSr,BSr,f5,KOe,jc,m5,UEe,Mx,ISr,JEe,NSr,ZOe,mr,Ex,qSr,Dc,jSr,FK,DSr,GSr,TK,OSr,VSr,XSr,Cx,zSr,YEe,WSr,QSr,HSr,Vt,wx,USr,KEe,JSr,YSr,Gc,KSr,ZEe,ZSr,eRr,MK,oRr,rRr,tRr,g5,aRr,Dr,Ax,nRr,e4e,sRr,lRr,bn,iRr,o4e,dRr,cRr,r4e,fRr,mRr,t4e,gRr,hRr,pRr,a4e,h5,n4e,uRr,_Rr,EK,bRr,vRr,FRr,p5,eVe,Oc,u5,s4e,Lx,TRr,l4e,MRr,oVe,gr,yx,ERr,Vc,CRr,CK,wRr,ARr,wK,LRr,yRr,xRr,xx,$Rr,i4e,kRr,SRr,RRr,Xt,$x,PRr,d4e,BRr,IRr,Xc,NRr,c4e,qRr,jRr,AK,DRr,GRr,ORr,_5,VRr,Gr,kx,XRr,f4e,zRr,WRr,vn,QRr,m4e,HRr,URr,g4e,JRr,YRr,h4e,KRr,ZRr,ePr,oe,b5,p4e,oPr,rPr,LK,tPr,aPr,nPr,v5,u4e,sPr,lPr,yK,iPr,dPr,cPr,F5,_4e,fPr,mPr,xK,gPr,hPr,pPr,T5,b4e,uPr,_Pr,$K,bPr,vPr,FPr,M5,v4e,TPr,MPr,kK,EPr,CPr,wPr,E5,F4e,APr,LPr,SK,yPr,xPr,$Pr,C5,T4e,kPr,SPr,RK,RPr,PPr,BPr,w5,M4e,IPr,NPr,PK,qPr,jPr,DPr,A5,E4e,GPr,OPr,BK,VPr,XPr,zPr,L5,C4e,WPr,QPr,IK,HPr,UPr,JPr,y5,w4e,YPr,KPr,NK,ZPr,eBr,oBr,x5,A4e,rBr,tBr,qK,aBr,nBr,sBr,$5,L4e,lBr,iBr,jK,dBr,cBr,fBr,k5,y4e,mBr,gBr,DK,hBr,pBr,uBr,S5,x4e,_Br,bBr,GK,vBr,FBr,TBr,R5,$4e,MBr,EBr,OK,CBr,wBr,ABr,P5,k4e,LBr,yBr,VK,xBr,$Br,kBr,B5,S4e,SBr,RBr,XK,PBr,BBr,IBr,I5,R4e,NBr,qBr,zK,jBr,DBr,GBr,N5,P4e,OBr,VBr,WK,XBr,zBr,WBr,q5,B4e,QBr,HBr,QK,UBr,JBr,YBr,j5,I4e,KBr,ZBr,HK,eIr,oIr,rIr,D5,N4e,tIr,aIr,UK,nIr,sIr,lIr,G5,q4e,iIr,dIr,JK,cIr,fIr,mIr,O5,j4e,gIr,hIr,YK,pIr,uIr,_Ir,V5,D4e,bIr,vIr,KK,FIr,TIr,MIr,X5,G4e,EIr,CIr,ZK,wIr,AIr,LIr,z5,rVe,zc,W5,O4e,Sx,yIr,V4e,xIr,tVe,hr,Rx,$Ir,Wc,kIr,eZ,SIr,RIr,oZ,PIr,BIr,IIr,Px,NIr,X4e,qIr,jIr,DIr,zt,Bx,GIr,z4e,OIr,VIr,Qc,XIr,W4e,zIr,WIr,rZ,QIr,HIr,UIr,Q5,JIr,Or,Ix,YIr,Q4e,KIr,ZIr,Fn,eNr,H4e,oNr,rNr,U4e,tNr,aNr,J4e,nNr,sNr,lNr,xe,H5,Y4e,iNr,dNr,tZ,cNr,fNr,mNr,U5,K4e,gNr,hNr,aZ,pNr,uNr,_Nr,J5,Z4e,bNr,vNr,nZ,FNr,TNr,MNr,Y5,eCe,ENr,CNr,sZ,wNr,ANr,LNr,K5,oCe,yNr,xNr,lZ,$Nr,kNr,SNr,Z5,rCe,RNr,PNr,iZ,BNr,INr,NNr,e0,tCe,qNr,jNr,dZ,DNr,GNr,ONr,o0,aCe,VNr,XNr,cZ,zNr,WNr,QNr,r0,nCe,HNr,UNr,fZ,JNr,YNr,KNr,t0,sCe,ZNr,eqr,mZ,oqr,rqr,tqr,a0,aVe,Hc,n0,lCe,Nx,aqr,iCe,nqr,nVe,pr,qx,sqr,Uc,lqr,gZ,iqr,dqr,hZ,cqr,fqr,mqr,jx,gqr,dCe,hqr,pqr,uqr,Wt,Dx,_qr,cCe,bqr,vqr,Jc,Fqr,fCe,Tqr,Mqr,pZ,Eqr,Cqr,wqr,s0,Aqr,Vr,Gx,Lqr,mCe,yqr,xqr,Tn,$qr,gCe,kqr,Sqr,hCe,Rqr,Pqr,pCe,Bqr,Iqr,Nqr,Ee,l0,uCe,qqr,jqr,uZ,Dqr,Gqr,Oqr,i0,_Ce,Vqr,Xqr,_Z,zqr,Wqr,Qqr,d0,bCe,Hqr,Uqr,bZ,Jqr,Yqr,Kqr,c0,vCe,Zqr,ejr,vZ,ojr,rjr,tjr,f0,FCe,ajr,njr,FZ,sjr,ljr,ijr,m0,TCe,djr,cjr,TZ,fjr,mjr,gjr,g0,MCe,hjr,pjr,MZ,ujr,_jr,bjr,h0,ECe,vjr,Fjr,EZ,Tjr,Mjr,Ejr,p0,CCe,Cjr,wjr,CZ,Ajr,Ljr,yjr,u0,wCe,xjr,$jr,wZ,kjr,Sjr,Rjr,_0,ACe,Pjr,Bjr,AZ,Ijr,Njr,qjr,b0,LCe,jjr,Djr,LZ,Gjr,Ojr,Vjr,v0,yCe,Xjr,zjr,yZ,Wjr,Qjr,Hjr,F0,sVe,Yc,T0,xCe,Ox,Ujr,$Ce,Jjr,lVe,ur,Vx,Yjr,Kc,Kjr,xZ,Zjr,eDr,$Z,oDr,rDr,tDr,Xx,aDr,kCe,nDr,sDr,lDr,Qt,zx,iDr,SCe,dDr,cDr,Zc,fDr,RCe,mDr,gDr,kZ,hDr,pDr,uDr,M0,_Dr,Xr,Wx,bDr,PCe,vDr,FDr,Mn,TDr,BCe,MDr,EDr,ICe,CDr,wDr,NCe,ADr,LDr,yDr,$e,E0,qCe,xDr,$Dr,SZ,kDr,SDr,RDr,C0,jCe,PDr,BDr,RZ,IDr,NDr,qDr,w0,DCe,jDr,DDr,PZ,GDr,ODr,VDr,A0,GCe,XDr,zDr,BZ,WDr,QDr,HDr,L0,OCe,UDr,JDr,IZ,YDr,KDr,ZDr,y0,VCe,eGr,oGr,NZ,rGr,tGr,aGr,x0,XCe,nGr,sGr,qZ,lGr,iGr,dGr,$0,zCe,cGr,fGr,jZ,mGr,gGr,hGr,k0,WCe,pGr,uGr,DZ,_Gr,bGr,vGr,S0,QCe,FGr,TGr,GZ,MGr,EGr,CGr,R0,iVe,ef,P0,HCe,Qx,wGr,UCe,AGr,dVe,_r,Hx,LGr,of,yGr,OZ,xGr,$Gr,VZ,kGr,SGr,RGr,Ux,PGr,JCe,BGr,IGr,NGr,Ht,Jx,qGr,YCe,jGr,DGr,rf,GGr,KCe,OGr,VGr,XZ,XGr,zGr,WGr,B0,QGr,zr,Yx,HGr,ZCe,UGr,JGr,En,YGr,e5e,KGr,ZGr,o5e,eOr,oOr,r5e,rOr,tOr,aOr,ke,I0,t5e,nOr,sOr,zZ,lOr,iOr,dOr,N0,a5e,cOr,fOr,WZ,mOr,gOr,hOr,q0,n5e,pOr,uOr,QZ,_Or,bOr,vOr,j0,s5e,FOr,TOr,HZ,MOr,EOr,COr,D0,l5e,wOr,AOr,UZ,LOr,yOr,xOr,G0,i5e,$Or,kOr,JZ,SOr,ROr,POr,O0,d5e,BOr,IOr,YZ,NOr,qOr,jOr,V0,c5e,DOr,GOr,KZ,OOr,VOr,XOr,X0,f5e,zOr,WOr,ZZ,QOr,HOr,UOr,z0,m5e,JOr,YOr,eee,KOr,ZOr,eVr,W0,cVe,tf,Q0,g5e,Kx,oVr,h5e,rVr,fVe,br,Zx,tVr,af,aVr,oee,nVr,sVr,ree,lVr,iVr,dVr,e$,cVr,p5e,fVr,mVr,gVr,Ut,o$,hVr,u5e,pVr,uVr,nf,_Vr,_5e,bVr,vVr,tee,FVr,TVr,MVr,H0,EVr,Wr,r$,CVr,b5e,wVr,AVr,Cn,LVr,v5e,yVr,xVr,F5e,$Vr,kVr,T5e,SVr,RVr,PVr,Se,U0,M5e,BVr,IVr,aee,NVr,qVr,jVr,J0,E5e,DVr,GVr,nee,OVr,VVr,XVr,Y0,C5e,zVr,WVr,see,QVr,HVr,UVr,K0,w5e,JVr,YVr,lee,KVr,ZVr,eXr,Z0,A5e,oXr,rXr,iee,tXr,aXr,nXr,ew,L5e,sXr,lXr,dee,iXr,dXr,cXr,ow,y5e,fXr,mXr,cee,gXr,hXr,pXr,rw,x5e,uXr,_Xr,fee,bXr,vXr,FXr,tw,$5e,TXr,MXr,mee,EXr,CXr,wXr,aw,k5e,AXr,LXr,gee,yXr,xXr,$Xr,nw,mVe,sf,sw,S5e,t$,kXr,R5e,SXr,gVe,vr,a$,RXr,lf,PXr,hee,BXr,IXr,pee,NXr,qXr,jXr,n$,DXr,P5e,GXr,OXr,VXr,Jt,s$,XXr,B5e,zXr,WXr,df,QXr,I5e,HXr,UXr,uee,JXr,YXr,KXr,lw,ZXr,Qr,l$,ezr,N5e,ozr,rzr,wn,tzr,q5e,azr,nzr,j5e,szr,lzr,D5e,izr,dzr,czr,Re,iw,G5e,fzr,mzr,_ee,gzr,hzr,pzr,dw,O5e,uzr,_zr,bee,bzr,vzr,Fzr,cw,V5e,Tzr,Mzr,vee,Ezr,Czr,wzr,fw,X5e,Azr,Lzr,Fee,yzr,xzr,$zr,mw,z5e,kzr,Szr,Tee,Rzr,Pzr,Bzr,gw,W5e,Izr,Nzr,Mee,qzr,jzr,Dzr,hw,Q5e,Gzr,Ozr,Eee,Vzr,Xzr,zzr,pw,H5e,Wzr,Qzr,Cee,Hzr,Uzr,Jzr,uw,U5e,Yzr,Kzr,wee,Zzr,eWr,oWr,_w,J5e,rWr,tWr,Aee,aWr,nWr,sWr,bw,hVe,cf,vw,Y5e,i$,lWr,K5e,iWr,pVe,Fr,d$,dWr,ff,cWr,Lee,fWr,mWr,yee,gWr,hWr,pWr,c$,uWr,Z5e,_Wr,bWr,vWr,Yt,f$,FWr,e0e,TWr,MWr,mf,EWr,o0e,CWr,wWr,xee,AWr,LWr,yWr,Fw,xWr,Hr,m$,$Wr,r0e,kWr,SWr,An,RWr,t0e,PWr,BWr,a0e,IWr,NWr,n0e,qWr,jWr,DWr,Ve,Tw,s0e,GWr,OWr,$ee,VWr,XWr,zWr,Mw,l0e,WWr,QWr,kee,HWr,UWr,JWr,Ew,i0e,YWr,KWr,See,ZWr,eQr,oQr,Cw,d0e,rQr,tQr,Ree,aQr,nQr,sQr,ww,c0e,lQr,iQr,Pee,dQr,cQr,fQr,Aw,f0e,mQr,gQr,Bee,hQr,pQr,uQr,Lw,m0e,_Qr,bQr,Iee,vQr,FQr,TQr,yw,g0e,MQr,EQr,Nee,CQr,wQr,AQr,xw,uVe,gf,$w,h0e,g$,LQr,p0e,yQr,_Ve,Tr,h$,xQr,hf,$Qr,qee,kQr,SQr,jee,RQr,PQr,BQr,p$,IQr,u0e,NQr,qQr,jQr,Kt,u$,DQr,_0e,GQr,OQr,pf,VQr,b0e,XQr,zQr,Dee,WQr,QQr,HQr,kw,UQr,Ur,_$,JQr,v0e,YQr,KQr,Ln,ZQr,F0e,eHr,oHr,T0e,rHr,tHr,M0e,aHr,nHr,sHr,Xe,Sw,E0e,lHr,iHr,Gee,dHr,cHr,fHr,Rw,C0e,mHr,gHr,Oee,hHr,pHr,uHr,Pw,w0e,_Hr,bHr,Vee,vHr,FHr,THr,Bw,A0e,MHr,EHr,Xee,CHr,wHr,AHr,Iw,L0e,LHr,yHr,zee,xHr,$Hr,kHr,Nw,y0e,SHr,RHr,Wee,PHr,BHr,IHr,qw,x0e,NHr,qHr,Qee,jHr,DHr,GHr,jw,$0e,OHr,VHr,Hee,XHr,zHr,WHr,Dw,bVe,uf,Gw,k0e,b$,QHr,S0e,HHr,vVe,Mr,v$,UHr,_f,JHr,Uee,YHr,KHr,Jee,ZHr,eUr,oUr,F$,rUr,R0e,tUr,aUr,nUr,Zt,T$,sUr,P0e,lUr,iUr,bf,dUr,B0e,cUr,fUr,Yee,mUr,gUr,hUr,Ow,pUr,Jr,M$,uUr,I0e,_Ur,bUr,yn,vUr,N0e,FUr,TUr,q0e,MUr,EUr,j0e,CUr,wUr,AUr,D0e,Vw,G0e,LUr,yUr,Kee,xUr,$Ur,kUr,Xw,FVe,vf,zw,O0e,E$,SUr,V0e,RUr,TVe,Er,C$,PUr,Ff,BUr,Zee,IUr,NUr,eoe,qUr,jUr,DUr,w$,GUr,X0e,OUr,VUr,XUr,ea,A$,zUr,z0e,WUr,QUr,Tf,HUr,W0e,UUr,JUr,ooe,YUr,KUr,ZUr,Ww,eJr,Yr,L$,oJr,Q0e,rJr,tJr,xn,aJr,H0e,nJr,sJr,U0e,lJr,iJr,J0e,dJr,cJr,fJr,y$,Qw,Y0e,mJr,gJr,roe,hJr,pJr,uJr,Hw,K0e,_Jr,bJr,toe,vJr,FJr,TJr,Uw,MVe,Mf,Jw,Z0e,x$,MJr,ewe,EJr,EVe,Cr,$$,CJr,Ef,wJr,aoe,AJr,LJr,noe,yJr,xJr,$Jr,k$,kJr,owe,SJr,RJr,PJr,oa,S$,BJr,rwe,IJr,NJr,Cf,qJr,twe,jJr,DJr,soe,GJr,OJr,VJr,Yw,XJr,Kr,R$,zJr,awe,WJr,QJr,$n,HJr,nwe,UJr,JJr,swe,YJr,KJr,lwe,ZJr,eYr,oYr,iwe,Kw,dwe,rYr,tYr,loe,aYr,nYr,sYr,Zw,CVe;return d=new re({}),ya=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),CL=new re({}),wL=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Rf=new lYr({props:{warning:!0,$$slots:{default:[Ejt]},$$scope:{ctx:x}}}),AL=new re({}),LL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/configuration_auto.py#L598"}}),$L=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/configuration_auto.py#L621"}}),Gg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[Cjt]},$$scope:{ctx:x}}}),kL=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/configuration_auto.py#L744"}}),SL=new re({}),RL=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/tokenization_auto.py#L400"}}),IL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17313/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/tokenization_auto.py#L414"}}),Eh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[wjt]},$$scope:{ctx:x}}}),NL=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/tokenization_auto.py#L613"}}),qL=new re({}),jL=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/feature_extraction_auto.py#L194"}}),OL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17313/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/feature_extraction_auto.py#L208"}}),np=new lYr({props:{$$slots:{default:[Ajt]},$$scope:{ctx:x}}}),sp=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[Ljt]},$$scope:{ctx:x}}}),VL=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/feature_extraction_auto.py#L335"}}),XL=new re({}),zL=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/processing_auto.py#L89"}}),HL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/processing_auto.py#L103"}}),Lp=new lYr({props:{$$slots:{default:[yjt]},$$scope:{ctx:x}}}),yp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[xjt]},$$scope:{ctx:x}}}),UL=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/processing_auto.py#L256"}}),JL=new re({}),YL=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L759"}}),ZL=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),kp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[$jt]},$$scope:{ctx:x}}}),ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),k_=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[kjt]},$$scope:{ctx:x}}}),oy=new re({}),ry=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L766"}}),ay=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),R_=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[Sjt]},$$scope:{ctx:x}}}),ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),C1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Rjt]},$$scope:{ctx:x}}}),sy=new re({}),ly=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L781"}}),dy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),A1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[Pjt]},$$scope:{ctx:x}}}),cy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),m3=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Bjt]},$$scope:{ctx:x}}}),fy=new re({}),my=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L788"}}),hy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),h3=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[Ijt]},$$scope:{ctx:x}}}),py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),K3=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Njt]},$$scope:{ctx:x}}}),uy=new re({}),_y=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L795"}}),vy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),e2=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[qjt]},$$scope:{ctx:x}}}),Fy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),v2=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[jjt]},$$scope:{ctx:x}}}),Ty=new re({}),My=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L804"}}),Cy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),T2=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Djt]},$$scope:{ctx:x}}}),wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),_b=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Gjt]},$$scope:{ctx:x}}}),Ay=new re({}),Ly=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L849"}}),xy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),vb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Ojt]},$$scope:{ctx:x}}}),$y=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),Jb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Vjt]},$$scope:{ctx:x}}}),ky=new re({}),Sy=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L856"}}),Py=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),Kb=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Xjt]},$$scope:{ctx:x}}}),By=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),nv=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[zjt]},$$scope:{ctx:x}}}),Iy=new re({}),Ny=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L842"}}),jy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),lv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[Wjt]},$$scope:{ctx:x}}}),Dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),Xv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Qjt]},$$scope:{ctx:x}}}),Gy=new re({}),Oy=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L813"}}),Xy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),Wv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Hjt]},$$scope:{ctx:x}}}),zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),PF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Ujt]},$$scope:{ctx:x}}}),Wy=new re({}),Qy=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L820"}}),Uy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),IF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Jjt]},$$scope:{ctx:x}}}),Jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),jF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Yjt]},$$scope:{ctx:x}}}),Yy=new re({}),Ky=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L865"}}),e8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),GF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[Kjt]},$$scope:{ctx:x}}}),o8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),oT=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Zjt]},$$scope:{ctx:x}}}),r8=new re({}),t8=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L904"}}),n8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),tT=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[eDt]},$$scope:{ctx:x}}}),s8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),sT=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[oDt]},$$scope:{ctx:x}}}),l8=new re({}),i8=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L831"}}),c8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),iT=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[rDt]},$$scope:{ctx:x}}}),f8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),fT=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[tDt]},$$scope:{ctx:x}}}),m8=new re({}),g8=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L911"}}),p8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),gT=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[aDt]},$$scope:{ctx:x}}}),u8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),CT=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[nDt]},$$scope:{ctx:x}}}),_8=new re({}),b8=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L934"}}),F8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),AT=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[sDt]},$$scope:{ctx:x}}}),T8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),RT=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[lDt]},$$scope:{ctx:x}}}),M8=new re({}),E8=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L918"}}),w8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),BT=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[iDt]},$$scope:{ctx:x}}}),A8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),QT=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[dDt]},$$scope:{ctx:x}}}),L8=new re({}),y8=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L925"}}),$8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),UT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[cDt]},$$scope:{ctx:x}}}),k8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),ZT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[fDt]},$$scope:{ctx:x}}}),R8=new re({}),P8=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L943"}}),I8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),o7=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[mDt]},$$scope:{ctx:x}}}),N8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),i7=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[gDt]},$$scope:{ctx:x}}}),q8=new re({}),j8=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L950"}}),G8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),c7=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[hDt]},$$scope:{ctx:x}}}),O8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),p7=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[pDt]},$$scope:{ctx:x}}}),V8=new re({}),X8=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L897"}}),W8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),_7=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[uDt]},$$scope:{ctx:x}}}),Q8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),T7=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[_Dt]},$$scope:{ctx:x}}}),U8=new re({}),J8=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L872"}}),K8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),E7=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[bDt]},$$scope:{ctx:x}}}),Z8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),A7=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[vDt]},$$scope:{ctx:x}}}),e9=new re({}),o9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L879"}}),t9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),y7=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[FDt]},$$scope:{ctx:x}}}),a9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),P7=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[TDt]},$$scope:{ctx:x}}}),n9=new re({}),s9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_auto.py#L888"}}),i9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),I7=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[MDt]},$$scope:{ctx:x}}}),d9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),j7=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[EDt]},$$scope:{ctx:x}}}),c9=new re({}),f9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L406"}}),g9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),G7=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[CDt]},$$scope:{ctx:x}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),PM=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[wDt]},$$scope:{ctx:x}}}),p9=new re({}),u9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L413"}}),b9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),IM=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[ADt]},$$scope:{ctx:x}}}),v9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),sE=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[LDt]},$$scope:{ctx:x}}}),F9=new re({}),T9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),E9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),iE=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[yDt]},$$scope:{ctx:x}}}),C9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),ME=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[xDt]},$$scope:{ctx:x}}}),w9=new re({}),A9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),CE=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[$Dt]},$$scope:{ctx:x}}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),xE=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[kDt]},$$scope:{ctx:x}}}),$9=new re({}),k9=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),R9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),kE=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[SDt]},$$scope:{ctx:x}}}),P9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),KE=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[RDt]},$$scope:{ctx:x}}}),B9=new re({}),I9=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),q9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),e4=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[PDt]},$$scope:{ctx:x}}}),j9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),f4=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[BDt]},$$scope:{ctx:x}}}),D9=new re({}),G9=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),V9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),g4=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[IDt]},$$scope:{ctx:x}}}),X9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),D4=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[NDt]},$$scope:{ctx:x}}}),z9=new re({}),W9=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),H9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),O4=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[qDt]},$$scope:{ctx:x}}}),U9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),sC=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[jDt]},$$scope:{ctx:x}}}),J9=new re({}),Y9=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),Z9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),iC=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[DDt]},$$scope:{ctx:x}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),fC=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[GDt]},$$scope:{ctx:x}}}),rx=new re({}),tx=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),nx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),gC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[ODt]},$$scope:{ctx:x}}}),sx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),pC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[VDt]},$$scope:{ctx:x}}}),lx=new re({}),ix=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),cx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),_C=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[XDt]},$$scope:{ctx:x}}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),qC=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[zDt]},$$scope:{ctx:x}}}),mx=new re({}),gx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L494"}}),px=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),DC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[WDt]},$$scope:{ctx:x}}}),ux=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),l5=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[QDt]},$$scope:{ctx:x}}}),_x=new re({}),bx=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),d5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[HDt]},$$scope:{ctx:x}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),f5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[UDt]},$$scope:{ctx:x}}}),Mx=new re({}),Ex=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_tf_auto.py#L537"}}),wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),g5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[JDt]},$$scope:{ctx:x}}}),Ax=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),p5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[YDt]},$$scope:{ctx:x}}}),Lx=new re({}),yx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),$x=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),_5=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[KDt]},$$scope:{ctx:x}}}),kx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),z5=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[ZDt]},$$scope:{ctx:x}}}),Sx=new re({}),Rx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),Q5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[eGt]},$$scope:{ctx:x}}}),Ix=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),a0=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[oGt]},$$scope:{ctx:x}}}),Nx=new re({}),qx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),Dx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),s0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[rGt]},$$scope:{ctx:x}}}),Gx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),F0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[tGt]},$$scope:{ctx:x}}}),Ox=new re({}),Vx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),M0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[aGt]},$$scope:{ctx:x}}}),Wx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),R0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[nGt]},$$scope:{ctx:x}}}),Qx=new re({}),Hx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),Jx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),B0=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[sGt]},$$scope:{ctx:x}}}),Yx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),W0=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[lGt]},$$scope:{ctx:x}}}),Kx=new re({}),Zx=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),o$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),H0=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[iGt]},$$scope:{ctx:x}}}),r$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),nw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[dGt]},$$scope:{ctx:x}}}),t$=new re({}),a$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),s$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),lw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[cGt]},$$scope:{ctx:x}}}),l$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),bw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[fGt]},$$scope:{ctx:x}}}),i$=new re({}),d$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),f$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),Fw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[mGt]},$$scope:{ctx:x}}}),m$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),xw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[gGt]},$$scope:{ctx:x}}}),g$=new re({}),h$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),u$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),kw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[hGt]},$$scope:{ctx:x}}}),_$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),Dw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[pGt]},$$scope:{ctx:x}}}),b$=new re({}),v$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),T$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),Ow=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[uGt]},$$scope:{ctx:x}}}),M$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),Xw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[_Gt]},$$scope:{ctx:x}}}),E$=new re({}),C$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),A$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),Ww=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[bGt]},$$scope:{ctx:x}}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),Uw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[vGt]},$$scope:{ctx:x}}}),x$=new re({}),$$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),S$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L389"}}),Yw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[FGt]},$$scope:{ctx:x}}}),R$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17313/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17313/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17313/src/transformers/models/auto/auto_factory.py#L417"}}),Zw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[TGt]},$$scope:{ctx:x}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),u=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Ti=o("Auto Classes"),yf=l(),at=a("p"),Mi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=a("code"),FL=o("from_pretrained()"),xf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),We=a("p"),Ci=o("Instantiating one of "),Sn=a("a"),TL=o("AutoConfig"),Rn=o(", "),Pn=a("a"),ML=o("AutoModel"),wi=o(`, and
`),Bn=a("a"),EL=o("AutoTokenizer"),Ai=o(" will directly create a class of the relevant architecture. For instance"),$f=l(),F(ya.$$.fragment),Qe=l(),Ae=a("p"),Yk=o("will create a model that is an instance of "),Li=a("a"),Kk=o("BertModel"),Zk=o("."),Co=l(),xa=a("p"),eS=o("There is one class of "),kf=a("code"),oS=o("AutoModel"),Pze=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),vGe=l(),yi=a("h2"),Sf=a("a"),rte=a("span"),F(CL.$$.fragment),Bze=l(),tte=a("span"),Ize=o("Extending the Auto Classes"),FGe=l(),In=a("p"),Nze=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ate=a("code"),qze=o("NewModel"),jze=o(", make sure you have a "),nte=a("code"),Dze=o("NewModelConfig"),Gze=o(` then you can add those to the auto
classes like this:`),TGe=l(),F(wL.$$.fragment),MGe=l(),rS=a("p"),Oze=o("You will then be able to use the auto classes like you would usually do!"),EGe=l(),F(Rf.$$.fragment),CGe=l(),xi=a("h2"),Pf=a("a"),ste=a("span"),F(AL.$$.fragment),Vze=l(),lte=a("span"),Xze=o("AutoConfig"),wGe=l(),wo=a("div"),F(LL.$$.fragment),zze=l(),yL=a("p"),Wze=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),tS=a("a"),Qze=o("from_pretrained()"),Hze=o(" class method."),Uze=l(),xL=a("p"),Jze=o("This class cannot be instantiated directly using "),ite=a("code"),Yze=o("__init__()"),Kze=o(" (throws an error)."),Zze=l(),wr=a("div"),F($L.$$.fragment),eWe=l(),dte=a("p"),oWe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),rWe=l(),$i=a("p"),tWe=o("The configuration class to instantiate is selected based on the "),cte=a("code"),aWe=o("model_type"),nWe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),fte=a("code"),sWe=o("pretrained_model_name_or_path"),lWe=o(":"),iWe=l(),A=a("ul"),Bf=a("li"),mte=a("strong"),dWe=o("albert"),cWe=o(" \u2014 "),aS=a("a"),fWe=o("AlbertConfig"),mWe=o(" (ALBERT model)"),gWe=l(),If=a("li"),gte=a("strong"),hWe=o("bart"),pWe=o(" \u2014 "),nS=a("a"),uWe=o("BartConfig"),_We=o(" (BART model)"),bWe=l(),Nf=a("li"),hte=a("strong"),vWe=o("beit"),FWe=o(" \u2014 "),sS=a("a"),TWe=o("BeitConfig"),MWe=o(" (BEiT model)"),EWe=l(),qf=a("li"),pte=a("strong"),CWe=o("bert"),wWe=o(" \u2014 "),lS=a("a"),AWe=o("BertConfig"),LWe=o(" (BERT model)"),yWe=l(),jf=a("li"),ute=a("strong"),xWe=o("bert-generation"),$We=o(" \u2014 "),iS=a("a"),kWe=o("BertGenerationConfig"),SWe=o(" (Bert Generation model)"),RWe=l(),Df=a("li"),_te=a("strong"),PWe=o("big_bird"),BWe=o(" \u2014 "),dS=a("a"),IWe=o("BigBirdConfig"),NWe=o(" (BigBird model)"),qWe=l(),Gf=a("li"),bte=a("strong"),jWe=o("bigbird_pegasus"),DWe=o(" \u2014 "),cS=a("a"),GWe=o("BigBirdPegasusConfig"),OWe=o(" (BigBird-Pegasus model)"),VWe=l(),Of=a("li"),vte=a("strong"),XWe=o("blenderbot"),zWe=o(" \u2014 "),fS=a("a"),WWe=o("BlenderbotConfig"),QWe=o(" (Blenderbot model)"),HWe=l(),Vf=a("li"),Fte=a("strong"),UWe=o("blenderbot-small"),JWe=o(" \u2014 "),mS=a("a"),YWe=o("BlenderbotSmallConfig"),KWe=o(" (BlenderbotSmall model)"),ZWe=l(),Xf=a("li"),Tte=a("strong"),eQe=o("bloom"),oQe=o(" \u2014 "),gS=a("a"),rQe=o("BloomConfig"),tQe=o(" (BLOOM model)"),aQe=l(),zf=a("li"),Mte=a("strong"),nQe=o("camembert"),sQe=o(" \u2014 "),hS=a("a"),lQe=o("CamembertConfig"),iQe=o(" (CamemBERT model)"),dQe=l(),Wf=a("li"),Ete=a("strong"),cQe=o("canine"),fQe=o(" \u2014 "),pS=a("a"),mQe=o("CanineConfig"),gQe=o(" (CANINE model)"),hQe=l(),Qf=a("li"),Cte=a("strong"),pQe=o("clip"),uQe=o(" \u2014 "),uS=a("a"),_Qe=o("CLIPConfig"),bQe=o(" (CLIP model)"),vQe=l(),Hf=a("li"),wte=a("strong"),FQe=o("convbert"),TQe=o(" \u2014 "),_S=a("a"),MQe=o("ConvBertConfig"),EQe=o(" (ConvBERT model)"),CQe=l(),Uf=a("li"),Ate=a("strong"),wQe=o("convnext"),AQe=o(" \u2014 "),bS=a("a"),LQe=o("ConvNextConfig"),yQe=o(" (ConvNeXT model)"),xQe=l(),Jf=a("li"),Lte=a("strong"),$Qe=o("ctrl"),kQe=o(" \u2014 "),vS=a("a"),SQe=o("CTRLConfig"),RQe=o(" (CTRL model)"),PQe=l(),Yf=a("li"),yte=a("strong"),BQe=o("cvt"),IQe=o(" \u2014 "),FS=a("a"),NQe=o("CvtConfig"),qQe=o(" (CvT model)"),jQe=l(),Kf=a("li"),xte=a("strong"),DQe=o("data2vec-audio"),GQe=o(" \u2014 "),TS=a("a"),OQe=o("Data2VecAudioConfig"),VQe=o(" (Data2VecAudio model)"),XQe=l(),Zf=a("li"),$te=a("strong"),zQe=o("data2vec-text"),WQe=o(" \u2014 "),MS=a("a"),QQe=o("Data2VecTextConfig"),HQe=o(" (Data2VecText model)"),UQe=l(),em=a("li"),kte=a("strong"),JQe=o("data2vec-vision"),YQe=o(" \u2014 "),ES=a("a"),KQe=o("Data2VecVisionConfig"),ZQe=o(" (Data2VecVision model)"),eHe=l(),om=a("li"),Ste=a("strong"),oHe=o("deberta"),rHe=o(" \u2014 "),CS=a("a"),tHe=o("DebertaConfig"),aHe=o(" (DeBERTa model)"),nHe=l(),rm=a("li"),Rte=a("strong"),sHe=o("deberta-v2"),lHe=o(" \u2014 "),wS=a("a"),iHe=o("DebertaV2Config"),dHe=o(" (DeBERTa-v2 model)"),cHe=l(),tm=a("li"),Pte=a("strong"),fHe=o("decision_transformer"),mHe=o(" \u2014 "),AS=a("a"),gHe=o("DecisionTransformerConfig"),hHe=o(" (Decision Transformer model)"),pHe=l(),am=a("li"),Bte=a("strong"),uHe=o("deit"),_He=o(" \u2014 "),LS=a("a"),bHe=o("DeiTConfig"),vHe=o(" (DeiT model)"),FHe=l(),nm=a("li"),Ite=a("strong"),THe=o("detr"),MHe=o(" \u2014 "),yS=a("a"),EHe=o("DetrConfig"),CHe=o(" (DETR model)"),wHe=l(),sm=a("li"),Nte=a("strong"),AHe=o("distilbert"),LHe=o(" \u2014 "),xS=a("a"),yHe=o("DistilBertConfig"),xHe=o(" (DistilBERT model)"),$He=l(),lm=a("li"),qte=a("strong"),kHe=o("dpr"),SHe=o(" \u2014 "),$S=a("a"),RHe=o("DPRConfig"),PHe=o(" (DPR model)"),BHe=l(),im=a("li"),jte=a("strong"),IHe=o("dpt"),NHe=o(" \u2014 "),kS=a("a"),qHe=o("DPTConfig"),jHe=o(" (DPT model)"),DHe=l(),dm=a("li"),Dte=a("strong"),GHe=o("electra"),OHe=o(" \u2014 "),SS=a("a"),VHe=o("ElectraConfig"),XHe=o(" (ELECTRA model)"),zHe=l(),cm=a("li"),Gte=a("strong"),WHe=o("encoder-decoder"),QHe=o(" \u2014 "),RS=a("a"),HHe=o("EncoderDecoderConfig"),UHe=o(" (Encoder decoder model)"),JHe=l(),fm=a("li"),Ote=a("strong"),YHe=o("flaubert"),KHe=o(" \u2014 "),PS=a("a"),ZHe=o("FlaubertConfig"),eUe=o(" (FlauBERT model)"),oUe=l(),mm=a("li"),Vte=a("strong"),rUe=o("flava"),tUe=o(" \u2014 "),BS=a("a"),aUe=o("FlavaConfig"),nUe=o(" (FLAVA model)"),sUe=l(),gm=a("li"),Xte=a("strong"),lUe=o("fnet"),iUe=o(" \u2014 "),IS=a("a"),dUe=o("FNetConfig"),cUe=o(" (FNet model)"),fUe=l(),hm=a("li"),zte=a("strong"),mUe=o("fsmt"),gUe=o(" \u2014 "),NS=a("a"),hUe=o("FSMTConfig"),pUe=o(" (FairSeq Machine-Translation model)"),uUe=l(),pm=a("li"),Wte=a("strong"),_Ue=o("funnel"),bUe=o(" \u2014 "),qS=a("a"),vUe=o("FunnelConfig"),FUe=o(" (Funnel Transformer model)"),TUe=l(),um=a("li"),Qte=a("strong"),MUe=o("glpn"),EUe=o(" \u2014 "),jS=a("a"),CUe=o("GLPNConfig"),wUe=o(" (GLPN model)"),AUe=l(),_m=a("li"),Hte=a("strong"),LUe=o("gpt2"),yUe=o(" \u2014 "),DS=a("a"),xUe=o("GPT2Config"),$Ue=o(" (OpenAI GPT-2 model)"),kUe=l(),bm=a("li"),Ute=a("strong"),SUe=o("gpt_neo"),RUe=o(" \u2014 "),GS=a("a"),PUe=o("GPTNeoConfig"),BUe=o(" (GPT Neo model)"),IUe=l(),vm=a("li"),Jte=a("strong"),NUe=o("gpt_neox"),qUe=o(" \u2014 "),OS=a("a"),jUe=o("GPTNeoXConfig"),DUe=o(" (GPT NeoX model)"),GUe=l(),Fm=a("li"),Yte=a("strong"),OUe=o("gptj"),VUe=o(" \u2014 "),VS=a("a"),XUe=o("GPTJConfig"),zUe=o(" (GPT-J model)"),WUe=l(),Tm=a("li"),Kte=a("strong"),QUe=o("groupvit"),HUe=o(" \u2014 "),XS=a("a"),UUe=o("GroupViTConfig"),JUe=o(" (GroupViT model)"),YUe=l(),Mm=a("li"),Zte=a("strong"),KUe=o("hubert"),ZUe=o(" \u2014 "),zS=a("a"),eJe=o("HubertConfig"),oJe=o(" (Hubert model)"),rJe=l(),Em=a("li"),eae=a("strong"),tJe=o("ibert"),aJe=o(" \u2014 "),WS=a("a"),nJe=o("IBertConfig"),sJe=o(" (I-BERT model)"),lJe=l(),Cm=a("li"),oae=a("strong"),iJe=o("imagegpt"),dJe=o(" \u2014 "),QS=a("a"),cJe=o("ImageGPTConfig"),fJe=o(" (ImageGPT model)"),mJe=l(),wm=a("li"),rae=a("strong"),gJe=o("layoutlm"),hJe=o(" \u2014 "),HS=a("a"),pJe=o("LayoutLMConfig"),uJe=o(" (LayoutLM model)"),_Je=l(),Am=a("li"),tae=a("strong"),bJe=o("layoutlmv2"),vJe=o(" \u2014 "),US=a("a"),FJe=o("LayoutLMv2Config"),TJe=o(" (LayoutLMv2 model)"),MJe=l(),Lm=a("li"),aae=a("strong"),EJe=o("layoutlmv3"),CJe=o(" \u2014 "),JS=a("a"),wJe=o("LayoutLMv3Config"),AJe=o(" (LayoutLMv3 model)"),LJe=l(),ym=a("li"),nae=a("strong"),yJe=o("led"),xJe=o(" \u2014 "),YS=a("a"),$Je=o("LEDConfig"),kJe=o(" (LED model)"),SJe=l(),xm=a("li"),sae=a("strong"),RJe=o("levit"),PJe=o(" \u2014 "),KS=a("a"),BJe=o("LevitConfig"),IJe=o(" (LeViT model)"),NJe=l(),$m=a("li"),lae=a("strong"),qJe=o("longformer"),jJe=o(" \u2014 "),ZS=a("a"),DJe=o("LongformerConfig"),GJe=o(" (Longformer model)"),OJe=l(),km=a("li"),iae=a("strong"),VJe=o("longt5"),XJe=o(" \u2014 "),eR=a("a"),zJe=o("LongT5Config"),WJe=o(" (LongT5 model)"),QJe=l(),Sm=a("li"),dae=a("strong"),HJe=o("luke"),UJe=o(" \u2014 "),oR=a("a"),JJe=o("LukeConfig"),YJe=o(" (LUKE model)"),KJe=l(),Rm=a("li"),cae=a("strong"),ZJe=o("lxmert"),eYe=o(" \u2014 "),rR=a("a"),oYe=o("LxmertConfig"),rYe=o(" (LXMERT model)"),tYe=l(),Pm=a("li"),fae=a("strong"),aYe=o("m2m_100"),nYe=o(" \u2014 "),tR=a("a"),sYe=o("M2M100Config"),lYe=o(" (M2M100 model)"),iYe=l(),Bm=a("li"),mae=a("strong"),dYe=o("marian"),cYe=o(" \u2014 "),aR=a("a"),fYe=o("MarianConfig"),mYe=o(" (Marian model)"),gYe=l(),Im=a("li"),gae=a("strong"),hYe=o("maskformer"),pYe=o(" \u2014 "),nR=a("a"),uYe=o("MaskFormerConfig"),_Ye=o(" (MaskFormer model)"),bYe=l(),Nm=a("li"),hae=a("strong"),vYe=o("mbart"),FYe=o(" \u2014 "),sR=a("a"),TYe=o("MBartConfig"),MYe=o(" (mBART model)"),EYe=l(),qm=a("li"),pae=a("strong"),CYe=o("mctct"),wYe=o(" \u2014 "),lR=a("a"),AYe=o("MCTCTConfig"),LYe=o(" (M-CTC-T model)"),yYe=l(),jm=a("li"),uae=a("strong"),xYe=o("megatron-bert"),$Ye=o(" \u2014 "),iR=a("a"),kYe=o("MegatronBertConfig"),SYe=o(" (Megatron-BERT model)"),RYe=l(),Dm=a("li"),_ae=a("strong"),PYe=o("mobilebert"),BYe=o(" \u2014 "),dR=a("a"),IYe=o("MobileBertConfig"),NYe=o(" (MobileBERT model)"),qYe=l(),Gm=a("li"),bae=a("strong"),jYe=o("mpnet"),DYe=o(" \u2014 "),cR=a("a"),GYe=o("MPNetConfig"),OYe=o(" (MPNet model)"),VYe=l(),Om=a("li"),vae=a("strong"),XYe=o("mt5"),zYe=o(" \u2014 "),fR=a("a"),WYe=o("MT5Config"),QYe=o(" (MT5 model)"),HYe=l(),Vm=a("li"),Fae=a("strong"),UYe=o("nystromformer"),JYe=o(" \u2014 "),mR=a("a"),YYe=o("NystromformerConfig"),KYe=o(" (Nystr\xF6mformer model)"),ZYe=l(),Xm=a("li"),Tae=a("strong"),eKe=o("openai-gpt"),oKe=o(" \u2014 "),gR=a("a"),rKe=o("OpenAIGPTConfig"),tKe=o(" (OpenAI GPT model)"),aKe=l(),zm=a("li"),Mae=a("strong"),nKe=o("opt"),sKe=o(" \u2014 "),hR=a("a"),lKe=o("OPTConfig"),iKe=o(" (OPT model)"),dKe=l(),Wm=a("li"),Eae=a("strong"),cKe=o("pegasus"),fKe=o(" \u2014 "),pR=a("a"),mKe=o("PegasusConfig"),gKe=o(" (Pegasus model)"),hKe=l(),Qm=a("li"),Cae=a("strong"),pKe=o("perceiver"),uKe=o(" \u2014 "),uR=a("a"),_Ke=o("PerceiverConfig"),bKe=o(" (Perceiver model)"),vKe=l(),Hm=a("li"),wae=a("strong"),FKe=o("plbart"),TKe=o(" \u2014 "),_R=a("a"),MKe=o("PLBartConfig"),EKe=o(" (PLBart model)"),CKe=l(),Um=a("li"),Aae=a("strong"),wKe=o("poolformer"),AKe=o(" \u2014 "),bR=a("a"),LKe=o("PoolFormerConfig"),yKe=o(" (PoolFormer model)"),xKe=l(),Jm=a("li"),Lae=a("strong"),$Ke=o("prophetnet"),kKe=o(" \u2014 "),vR=a("a"),SKe=o("ProphetNetConfig"),RKe=o(" (ProphetNet model)"),PKe=l(),Ym=a("li"),yae=a("strong"),BKe=o("qdqbert"),IKe=o(" \u2014 "),FR=a("a"),NKe=o("QDQBertConfig"),qKe=o(" (QDQBert model)"),jKe=l(),Km=a("li"),xae=a("strong"),DKe=o("rag"),GKe=o(" \u2014 "),TR=a("a"),OKe=o("RagConfig"),VKe=o(" (RAG model)"),XKe=l(),Zm=a("li"),$ae=a("strong"),zKe=o("realm"),WKe=o(" \u2014 "),MR=a("a"),QKe=o("RealmConfig"),HKe=o(" (REALM model)"),UKe=l(),eg=a("li"),kae=a("strong"),JKe=o("reformer"),YKe=o(" \u2014 "),ER=a("a"),KKe=o("ReformerConfig"),ZKe=o(" (Reformer model)"),eZe=l(),og=a("li"),Sae=a("strong"),oZe=o("regnet"),rZe=o(" \u2014 "),CR=a("a"),tZe=o("RegNetConfig"),aZe=o(" (RegNet model)"),nZe=l(),rg=a("li"),Rae=a("strong"),sZe=o("rembert"),lZe=o(" \u2014 "),wR=a("a"),iZe=o("RemBertConfig"),dZe=o(" (RemBERT model)"),cZe=l(),tg=a("li"),Pae=a("strong"),fZe=o("resnet"),mZe=o(" \u2014 "),AR=a("a"),gZe=o("ResNetConfig"),hZe=o(" (ResNet model)"),pZe=l(),ag=a("li"),Bae=a("strong"),uZe=o("retribert"),_Ze=o(" \u2014 "),LR=a("a"),bZe=o("RetriBertConfig"),vZe=o(" (RetriBERT model)"),FZe=l(),ng=a("li"),Iae=a("strong"),TZe=o("roberta"),MZe=o(" \u2014 "),yR=a("a"),EZe=o("RobertaConfig"),CZe=o(" (RoBERTa model)"),wZe=l(),sg=a("li"),Nae=a("strong"),AZe=o("roformer"),LZe=o(" \u2014 "),xR=a("a"),yZe=o("RoFormerConfig"),xZe=o(" (RoFormer model)"),$Ze=l(),lg=a("li"),qae=a("strong"),kZe=o("segformer"),SZe=o(" \u2014 "),$R=a("a"),RZe=o("SegformerConfig"),PZe=o(" (SegFormer model)"),BZe=l(),ig=a("li"),jae=a("strong"),IZe=o("sew"),NZe=o(" \u2014 "),kR=a("a"),qZe=o("SEWConfig"),jZe=o(" (SEW model)"),DZe=l(),dg=a("li"),Dae=a("strong"),GZe=o("sew-d"),OZe=o(" \u2014 "),SR=a("a"),VZe=o("SEWDConfig"),XZe=o(" (SEW-D model)"),zZe=l(),cg=a("li"),Gae=a("strong"),WZe=o("speech-encoder-decoder"),QZe=o(" \u2014 "),RR=a("a"),HZe=o("SpeechEncoderDecoderConfig"),UZe=o(" (Speech Encoder decoder model)"),JZe=l(),fg=a("li"),Oae=a("strong"),YZe=o("speech_to_text"),KZe=o(" \u2014 "),PR=a("a"),ZZe=o("Speech2TextConfig"),eeo=o(" (Speech2Text model)"),oeo=l(),mg=a("li"),Vae=a("strong"),reo=o("speech_to_text_2"),teo=o(" \u2014 "),BR=a("a"),aeo=o("Speech2Text2Config"),neo=o(" (Speech2Text2 model)"),seo=l(),gg=a("li"),Xae=a("strong"),leo=o("splinter"),ieo=o(" \u2014 "),IR=a("a"),deo=o("SplinterConfig"),ceo=o(" (Splinter model)"),feo=l(),hg=a("li"),zae=a("strong"),meo=o("squeezebert"),geo=o(" \u2014 "),NR=a("a"),heo=o("SqueezeBertConfig"),peo=o(" (SqueezeBERT model)"),ueo=l(),pg=a("li"),Wae=a("strong"),_eo=o("swin"),beo=o(" \u2014 "),qR=a("a"),veo=o("SwinConfig"),Feo=o(" (Swin Transformer model)"),Teo=l(),ug=a("li"),Qae=a("strong"),Meo=o("t5"),Eeo=o(" \u2014 "),jR=a("a"),Ceo=o("T5Config"),weo=o(" (T5 model)"),Aeo=l(),_g=a("li"),Hae=a("strong"),Leo=o("tapas"),yeo=o(" \u2014 "),DR=a("a"),xeo=o("TapasConfig"),$eo=o(" (TAPAS model)"),keo=l(),bg=a("li"),Uae=a("strong"),Seo=o("trajectory_transformer"),Reo=o(" \u2014 "),GR=a("a"),Peo=o("TrajectoryTransformerConfig"),Beo=o(" (Trajectory Transformer model)"),Ieo=l(),vg=a("li"),Jae=a("strong"),Neo=o("transfo-xl"),qeo=o(" \u2014 "),OR=a("a"),jeo=o("TransfoXLConfig"),Deo=o(" (Transformer-XL model)"),Geo=l(),Fg=a("li"),Yae=a("strong"),Oeo=o("trocr"),Veo=o(" \u2014 "),VR=a("a"),Xeo=o("TrOCRConfig"),zeo=o(" (TrOCR model)"),Weo=l(),Tg=a("li"),Kae=a("strong"),Qeo=o("unispeech"),Heo=o(" \u2014 "),XR=a("a"),Ueo=o("UniSpeechConfig"),Jeo=o(" (UniSpeech model)"),Yeo=l(),Mg=a("li"),Zae=a("strong"),Keo=o("unispeech-sat"),Zeo=o(" \u2014 "),zR=a("a"),eoo=o("UniSpeechSatConfig"),ooo=o(" (UniSpeechSat model)"),roo=l(),Eg=a("li"),ene=a("strong"),too=o("van"),aoo=o(" \u2014 "),WR=a("a"),noo=o("VanConfig"),soo=o(" (VAN model)"),loo=l(),Cg=a("li"),one=a("strong"),ioo=o("vilt"),doo=o(" \u2014 "),QR=a("a"),coo=o("ViltConfig"),foo=o(" (ViLT model)"),moo=l(),wg=a("li"),rne=a("strong"),goo=o("vision-encoder-decoder"),hoo=o(" \u2014 "),HR=a("a"),poo=o("VisionEncoderDecoderConfig"),uoo=o(" (Vision Encoder decoder model)"),_oo=l(),Ag=a("li"),tne=a("strong"),boo=o("vision-text-dual-encoder"),voo=o(" \u2014 "),UR=a("a"),Foo=o("VisionTextDualEncoderConfig"),Too=o(" (VisionTextDualEncoder model)"),Moo=l(),Lg=a("li"),ane=a("strong"),Eoo=o("visual_bert"),Coo=o(" \u2014 "),JR=a("a"),woo=o("VisualBertConfig"),Aoo=o(" (VisualBERT model)"),Loo=l(),yg=a("li"),nne=a("strong"),yoo=o("vit"),xoo=o(" \u2014 "),YR=a("a"),$oo=o("ViTConfig"),koo=o(" (ViT model)"),Soo=l(),xg=a("li"),sne=a("strong"),Roo=o("vit_mae"),Poo=o(" \u2014 "),KR=a("a"),Boo=o("ViTMAEConfig"),Ioo=o(" (ViTMAE model)"),Noo=l(),$g=a("li"),lne=a("strong"),qoo=o("wav2vec2"),joo=o(" \u2014 "),ZR=a("a"),Doo=o("Wav2Vec2Config"),Goo=o(" (Wav2Vec2 model)"),Ooo=l(),kg=a("li"),ine=a("strong"),Voo=o("wav2vec2-conformer"),Xoo=o(" \u2014 "),eP=a("a"),zoo=o("Wav2Vec2ConformerConfig"),Woo=o(" (Wav2Vec2-Conformer model)"),Qoo=l(),Sg=a("li"),dne=a("strong"),Hoo=o("wavlm"),Uoo=o(" \u2014 "),oP=a("a"),Joo=o("WavLMConfig"),Yoo=o(" (WavLM model)"),Koo=l(),Rg=a("li"),cne=a("strong"),Zoo=o("xglm"),ero=o(" \u2014 "),rP=a("a"),oro=o("XGLMConfig"),rro=o(" (XGLM model)"),tro=l(),Pg=a("li"),fne=a("strong"),aro=o("xlm"),nro=o(" \u2014 "),tP=a("a"),sro=o("XLMConfig"),lro=o(" (XLM model)"),iro=l(),Bg=a("li"),mne=a("strong"),dro=o("xlm-prophetnet"),cro=o(" \u2014 "),aP=a("a"),fro=o("XLMProphetNetConfig"),mro=o(" (XLM-ProphetNet model)"),gro=l(),Ig=a("li"),gne=a("strong"),hro=o("xlm-roberta"),pro=o(" \u2014 "),nP=a("a"),uro=o("XLMRobertaConfig"),_ro=o(" (XLM-RoBERTa model)"),bro=l(),Ng=a("li"),hne=a("strong"),vro=o("xlm-roberta-xl"),Fro=o(" \u2014 "),sP=a("a"),Tro=o("XLMRobertaXLConfig"),Mro=o(" (XLM-RoBERTa-XL model)"),Ero=l(),qg=a("li"),pne=a("strong"),Cro=o("xlnet"),wro=o(" \u2014 "),lP=a("a"),Aro=o("XLNetConfig"),Lro=o(" (XLNet model)"),yro=l(),jg=a("li"),une=a("strong"),xro=o("yolos"),$ro=o(" \u2014 "),iP=a("a"),kro=o("YolosConfig"),Sro=o(" (YOLOS model)"),Rro=l(),Dg=a("li"),_ne=a("strong"),Pro=o("yoso"),Bro=o(" \u2014 "),dP=a("a"),Iro=o("YosoConfig"),Nro=o(" (YOSO model)"),qro=l(),F(Gg.$$.fragment),jro=l(),Og=a("div"),F(kL.$$.fragment),Dro=l(),bne=a("p"),Gro=o("Register a new configuration for this class."),AGe=l(),ki=a("h2"),Vg=a("a"),vne=a("span"),F(SL.$$.fragment),Oro=l(),Fne=a("span"),Vro=o("AutoTokenizer"),LGe=l(),Ao=a("div"),F(RL.$$.fragment),Xro=l(),PL=a("p"),zro=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),cP=a("a"),Wro=o("AutoTokenizer.from_pretrained()"),Qro=o(" class method."),Hro=l(),BL=a("p"),Uro=o("This class cannot be instantiated directly using "),Tne=a("code"),Jro=o("__init__()"),Yro=o(" (throws an error)."),Kro=l(),Ar=a("div"),F(IL.$$.fragment),Zro=l(),Mne=a("p"),eto=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),oto=l(),$a=a("p"),rto=o("The tokenizer class to instantiate is selected based on the "),Ene=a("code"),tto=o("model_type"),ato=o(` property of the config object (either
passed as an argument or loaded from `),Cne=a("code"),nto=o("pretrained_model_name_or_path"),sto=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wne=a("code"),lto=o("pretrained_model_name_or_path"),ito=o(":"),dto=l(),k=a("ul"),Nn=a("li"),Ane=a("strong"),cto=o("albert"),fto=o(" \u2014 "),fP=a("a"),mto=o("AlbertTokenizer"),gto=o(" or "),mP=a("a"),hto=o("AlbertTokenizerFast"),pto=o(" (ALBERT model)"),uto=l(),qn=a("li"),Lne=a("strong"),_to=o("bart"),bto=o(" \u2014 "),gP=a("a"),vto=o("BartTokenizer"),Fto=o(" or "),hP=a("a"),Tto=o("BartTokenizerFast"),Mto=o(" (BART model)"),Eto=l(),jn=a("li"),yne=a("strong"),Cto=o("barthez"),wto=o(" \u2014 "),pP=a("a"),Ato=o("BarthezTokenizer"),Lto=o(" or "),uP=a("a"),yto=o("BarthezTokenizerFast"),xto=o(" (BARThez model)"),$to=l(),Xg=a("li"),xne=a("strong"),kto=o("bartpho"),Sto=o(" \u2014 "),_P=a("a"),Rto=o("BartphoTokenizer"),Pto=o(" (BARTpho model)"),Bto=l(),Dn=a("li"),$ne=a("strong"),Ito=o("bert"),Nto=o(" \u2014 "),bP=a("a"),qto=o("BertTokenizer"),jto=o(" or "),vP=a("a"),Dto=o("BertTokenizerFast"),Gto=o(" (BERT model)"),Oto=l(),zg=a("li"),kne=a("strong"),Vto=o("bert-generation"),Xto=o(" \u2014 "),FP=a("a"),zto=o("BertGenerationTokenizer"),Wto=o(" (Bert Generation model)"),Qto=l(),Wg=a("li"),Sne=a("strong"),Hto=o("bert-japanese"),Uto=o(" \u2014 "),TP=a("a"),Jto=o("BertJapaneseTokenizer"),Yto=o(" (BertJapanese model)"),Kto=l(),Qg=a("li"),Rne=a("strong"),Zto=o("bertweet"),eao=o(" \u2014 "),MP=a("a"),oao=o("BertweetTokenizer"),rao=o(" (BERTweet model)"),tao=l(),Gn=a("li"),Pne=a("strong"),aao=o("big_bird"),nao=o(" \u2014 "),EP=a("a"),sao=o("BigBirdTokenizer"),lao=o(" or "),CP=a("a"),iao=o("BigBirdTokenizerFast"),dao=o(" (BigBird model)"),cao=l(),On=a("li"),Bne=a("strong"),fao=o("bigbird_pegasus"),mao=o(" \u2014 "),wP=a("a"),gao=o("PegasusTokenizer"),hao=o(" or "),AP=a("a"),pao=o("PegasusTokenizerFast"),uao=o(" (BigBird-Pegasus model)"),_ao=l(),Vn=a("li"),Ine=a("strong"),bao=o("blenderbot"),vao=o(" \u2014 "),LP=a("a"),Fao=o("BlenderbotTokenizer"),Tao=o(" or "),yP=a("a"),Mao=o("BlenderbotTokenizerFast"),Eao=o(" (Blenderbot model)"),Cao=l(),Hg=a("li"),Nne=a("strong"),wao=o("blenderbot-small"),Aao=o(" \u2014 "),xP=a("a"),Lao=o("BlenderbotSmallTokenizer"),yao=o(" (BlenderbotSmall model)"),xao=l(),Ug=a("li"),qne=a("strong"),$ao=o("bloom"),kao=o(" \u2014 "),$P=a("a"),Sao=o("BloomTokenizerFast"),Rao=o(" (BLOOM model)"),Pao=l(),Jg=a("li"),jne=a("strong"),Bao=o("byt5"),Iao=o(" \u2014 "),kP=a("a"),Nao=o("ByT5Tokenizer"),qao=o(" (ByT5 model)"),jao=l(),Xn=a("li"),Dne=a("strong"),Dao=o("camembert"),Gao=o(" \u2014 "),SP=a("a"),Oao=o("CamembertTokenizer"),Vao=o(" or "),RP=a("a"),Xao=o("CamembertTokenizerFast"),zao=o(" (CamemBERT model)"),Wao=l(),Yg=a("li"),Gne=a("strong"),Qao=o("canine"),Hao=o(" \u2014 "),PP=a("a"),Uao=o("CanineTokenizer"),Jao=o(" (CANINE model)"),Yao=l(),zn=a("li"),One=a("strong"),Kao=o("clip"),Zao=o(" \u2014 "),BP=a("a"),eno=o("CLIPTokenizer"),ono=o(" or "),IP=a("a"),rno=o("CLIPTokenizerFast"),tno=o(" (CLIP model)"),ano=l(),Wn=a("li"),Vne=a("strong"),nno=o("convbert"),sno=o(" \u2014 "),NP=a("a"),lno=o("ConvBertTokenizer"),ino=o(" or "),qP=a("a"),dno=o("ConvBertTokenizerFast"),cno=o(" (ConvBERT model)"),fno=l(),Qn=a("li"),Xne=a("strong"),mno=o("cpm"),gno=o(" \u2014 "),jP=a("a"),hno=o("CpmTokenizer"),pno=o(" or "),DP=a("a"),uno=o("CpmTokenizerFast"),_no=o(" (CPM model)"),bno=l(),Kg=a("li"),zne=a("strong"),vno=o("ctrl"),Fno=o(" \u2014 "),GP=a("a"),Tno=o("CTRLTokenizer"),Mno=o(" (CTRL model)"),Eno=l(),Hn=a("li"),Wne=a("strong"),Cno=o("data2vec-text"),wno=o(" \u2014 "),OP=a("a"),Ano=o("RobertaTokenizer"),Lno=o(" or "),VP=a("a"),yno=o("RobertaTokenizerFast"),xno=o(" (Data2VecText model)"),$no=l(),Un=a("li"),Qne=a("strong"),kno=o("deberta"),Sno=o(" \u2014 "),XP=a("a"),Rno=o("DebertaTokenizer"),Pno=o(" or "),zP=a("a"),Bno=o("DebertaTokenizerFast"),Ino=o(" (DeBERTa model)"),Nno=l(),Jn=a("li"),Hne=a("strong"),qno=o("deberta-v2"),jno=o(" \u2014 "),WP=a("a"),Dno=o("DebertaV2Tokenizer"),Gno=o(" or "),QP=a("a"),Ono=o("DebertaV2TokenizerFast"),Vno=o(" (DeBERTa-v2 model)"),Xno=l(),Yn=a("li"),Une=a("strong"),zno=o("distilbert"),Wno=o(" \u2014 "),HP=a("a"),Qno=o("DistilBertTokenizer"),Hno=o(" or "),UP=a("a"),Uno=o("DistilBertTokenizerFast"),Jno=o(" (DistilBERT model)"),Yno=l(),Kn=a("li"),Jne=a("strong"),Kno=o("dpr"),Zno=o(" \u2014 "),JP=a("a"),eso=o("DPRQuestionEncoderTokenizer"),oso=o(" or "),YP=a("a"),rso=o("DPRQuestionEncoderTokenizerFast"),tso=o(" (DPR model)"),aso=l(),Zn=a("li"),Yne=a("strong"),nso=o("electra"),sso=o(" \u2014 "),KP=a("a"),lso=o("ElectraTokenizer"),iso=o(" or "),ZP=a("a"),dso=o("ElectraTokenizerFast"),cso=o(" (ELECTRA model)"),fso=l(),Zg=a("li"),Kne=a("strong"),mso=o("flaubert"),gso=o(" \u2014 "),eB=a("a"),hso=o("FlaubertTokenizer"),pso=o(" (FlauBERT model)"),uso=l(),es=a("li"),Zne=a("strong"),_so=o("fnet"),bso=o(" \u2014 "),oB=a("a"),vso=o("FNetTokenizer"),Fso=o(" or "),rB=a("a"),Tso=o("FNetTokenizerFast"),Mso=o(" (FNet model)"),Eso=l(),eh=a("li"),ese=a("strong"),Cso=o("fsmt"),wso=o(" \u2014 "),tB=a("a"),Aso=o("FSMTTokenizer"),Lso=o(" (FairSeq Machine-Translation model)"),yso=l(),os=a("li"),ose=a("strong"),xso=o("funnel"),$so=o(" \u2014 "),aB=a("a"),kso=o("FunnelTokenizer"),Sso=o(" or "),nB=a("a"),Rso=o("FunnelTokenizerFast"),Pso=o(" (Funnel Transformer model)"),Bso=l(),rs=a("li"),rse=a("strong"),Iso=o("gpt2"),Nso=o(" \u2014 "),sB=a("a"),qso=o("GPT2Tokenizer"),jso=o(" or "),lB=a("a"),Dso=o("GPT2TokenizerFast"),Gso=o(" (OpenAI GPT-2 model)"),Oso=l(),ts=a("li"),tse=a("strong"),Vso=o("gpt_neo"),Xso=o(" \u2014 "),iB=a("a"),zso=o("GPT2Tokenizer"),Wso=o(" or "),dB=a("a"),Qso=o("GPT2TokenizerFast"),Hso=o(" (GPT Neo model)"),Uso=l(),oh=a("li"),ase=a("strong"),Jso=o("gpt_neox"),Yso=o(" \u2014 "),cB=a("a"),Kso=o("GPTNeoXTokenizerFast"),Zso=o(" (GPT NeoX model)"),elo=l(),as=a("li"),nse=a("strong"),olo=o("gptj"),rlo=o(" \u2014 "),fB=a("a"),tlo=o("GPT2Tokenizer"),alo=o(" or "),mB=a("a"),nlo=o("GPT2TokenizerFast"),slo=o(" (GPT-J model)"),llo=l(),ns=a("li"),sse=a("strong"),ilo=o("groupvit"),dlo=o(" \u2014 "),gB=a("a"),clo=o("CLIPTokenizer"),flo=o(" or "),hB=a("a"),mlo=o("CLIPTokenizerFast"),glo=o(" (GroupViT model)"),hlo=l(),ss=a("li"),lse=a("strong"),plo=o("herbert"),ulo=o(" \u2014 "),pB=a("a"),_lo=o("HerbertTokenizer"),blo=o(" or "),uB=a("a"),vlo=o("HerbertTokenizerFast"),Flo=o(" (HerBERT model)"),Tlo=l(),rh=a("li"),ise=a("strong"),Mlo=o("hubert"),Elo=o(" \u2014 "),_B=a("a"),Clo=o("Wav2Vec2CTCTokenizer"),wlo=o(" (Hubert model)"),Alo=l(),ls=a("li"),dse=a("strong"),Llo=o("ibert"),ylo=o(" \u2014 "),bB=a("a"),xlo=o("RobertaTokenizer"),$lo=o(" or "),vB=a("a"),klo=o("RobertaTokenizerFast"),Slo=o(" (I-BERT model)"),Rlo=l(),is=a("li"),cse=a("strong"),Plo=o("layoutlm"),Blo=o(" \u2014 "),FB=a("a"),Ilo=o("LayoutLMTokenizer"),Nlo=o(" or "),TB=a("a"),qlo=o("LayoutLMTokenizerFast"),jlo=o(" (LayoutLM model)"),Dlo=l(),ds=a("li"),fse=a("strong"),Glo=o("layoutlmv2"),Olo=o(" \u2014 "),MB=a("a"),Vlo=o("LayoutLMv2Tokenizer"),Xlo=o(" or "),EB=a("a"),zlo=o("LayoutLMv2TokenizerFast"),Wlo=o(" (LayoutLMv2 model)"),Qlo=l(),cs=a("li"),mse=a("strong"),Hlo=o("layoutlmv3"),Ulo=o(" \u2014 "),CB=a("a"),Jlo=o("LayoutLMv3Tokenizer"),Ylo=o(" or "),wB=a("a"),Klo=o("LayoutLMv3TokenizerFast"),Zlo=o(" (LayoutLMv3 model)"),eio=l(),fs=a("li"),gse=a("strong"),oio=o("layoutxlm"),rio=o(" \u2014 "),AB=a("a"),tio=o("LayoutXLMTokenizer"),aio=o(" or "),LB=a("a"),nio=o("LayoutXLMTokenizerFast"),sio=o(" (LayoutXLM model)"),lio=l(),ms=a("li"),hse=a("strong"),iio=o("led"),dio=o(" \u2014 "),yB=a("a"),cio=o("LEDTokenizer"),fio=o(" or "),xB=a("a"),mio=o("LEDTokenizerFast"),gio=o(" (LED model)"),hio=l(),gs=a("li"),pse=a("strong"),pio=o("longformer"),uio=o(" \u2014 "),$B=a("a"),_io=o("LongformerTokenizer"),bio=o(" or "),kB=a("a"),vio=o("LongformerTokenizerFast"),Fio=o(" (Longformer model)"),Tio=l(),hs=a("li"),use=a("strong"),Mio=o("longt5"),Eio=o(" \u2014 "),SB=a("a"),Cio=o("T5Tokenizer"),wio=o(" or "),RB=a("a"),Aio=o("T5TokenizerFast"),Lio=o(" (LongT5 model)"),yio=l(),th=a("li"),_se=a("strong"),xio=o("luke"),$io=o(" \u2014 "),PB=a("a"),kio=o("LukeTokenizer"),Sio=o(" (LUKE model)"),Rio=l(),ps=a("li"),bse=a("strong"),Pio=o("lxmert"),Bio=o(" \u2014 "),BB=a("a"),Iio=o("LxmertTokenizer"),Nio=o(" or "),IB=a("a"),qio=o("LxmertTokenizerFast"),jio=o(" (LXMERT model)"),Dio=l(),ah=a("li"),vse=a("strong"),Gio=o("m2m_100"),Oio=o(" \u2014 "),NB=a("a"),Vio=o("M2M100Tokenizer"),Xio=o(" (M2M100 model)"),zio=l(),nh=a("li"),Fse=a("strong"),Wio=o("marian"),Qio=o(" \u2014 "),qB=a("a"),Hio=o("MarianTokenizer"),Uio=o(" (Marian model)"),Jio=l(),us=a("li"),Tse=a("strong"),Yio=o("mbart"),Kio=o(" \u2014 "),jB=a("a"),Zio=o("MBartTokenizer"),edo=o(" or "),DB=a("a"),odo=o("MBartTokenizerFast"),rdo=o(" (mBART model)"),tdo=l(),_s=a("li"),Mse=a("strong"),ado=o("mbart50"),ndo=o(" \u2014 "),GB=a("a"),sdo=o("MBart50Tokenizer"),ldo=o(" or "),OB=a("a"),ido=o("MBart50TokenizerFast"),ddo=o(" (mBART-50 model)"),cdo=l(),bs=a("li"),Ese=a("strong"),fdo=o("megatron-bert"),mdo=o(" \u2014 "),VB=a("a"),gdo=o("BertTokenizer"),hdo=o(" or "),XB=a("a"),pdo=o("BertTokenizerFast"),udo=o(" (Megatron-BERT model)"),_do=l(),sh=a("li"),Cse=a("strong"),bdo=o("mluke"),vdo=o(" \u2014 "),zB=a("a"),Fdo=o("MLukeTokenizer"),Tdo=o(" (mLUKE model)"),Mdo=l(),vs=a("li"),wse=a("strong"),Edo=o("mobilebert"),Cdo=o(" \u2014 "),WB=a("a"),wdo=o("MobileBertTokenizer"),Ado=o(" or "),QB=a("a"),Ldo=o("MobileBertTokenizerFast"),ydo=o(" (MobileBERT model)"),xdo=l(),Fs=a("li"),Ase=a("strong"),$do=o("mpnet"),kdo=o(" \u2014 "),HB=a("a"),Sdo=o("MPNetTokenizer"),Rdo=o(" or "),UB=a("a"),Pdo=o("MPNetTokenizerFast"),Bdo=o(" (MPNet model)"),Ido=l(),Ts=a("li"),Lse=a("strong"),Ndo=o("mt5"),qdo=o(" \u2014 "),JB=a("a"),jdo=o("MT5Tokenizer"),Ddo=o(" or "),YB=a("a"),Gdo=o("MT5TokenizerFast"),Odo=o(" (MT5 model)"),Vdo=l(),Ms=a("li"),yse=a("strong"),Xdo=o("nystromformer"),zdo=o(" \u2014 "),KB=a("a"),Wdo=o("AlbertTokenizer"),Qdo=o(" or "),ZB=a("a"),Hdo=o("AlbertTokenizerFast"),Udo=o(" (Nystr\xF6mformer model)"),Jdo=l(),Es=a("li"),xse=a("strong"),Ydo=o("openai-gpt"),Kdo=o(" \u2014 "),eI=a("a"),Zdo=o("OpenAIGPTTokenizer"),eco=o(" or "),oI=a("a"),oco=o("OpenAIGPTTokenizerFast"),rco=o(" (OpenAI GPT model)"),tco=l(),lh=a("li"),$se=a("strong"),aco=o("opt"),nco=o(" \u2014 "),rI=a("a"),sco=o("GPT2Tokenizer"),lco=o(" (OPT model)"),ico=l(),Cs=a("li"),kse=a("strong"),dco=o("pegasus"),cco=o(" \u2014 "),tI=a("a"),fco=o("PegasusTokenizer"),mco=o(" or "),aI=a("a"),gco=o("PegasusTokenizerFast"),hco=o(" (Pegasus model)"),pco=l(),ih=a("li"),Sse=a("strong"),uco=o("perceiver"),_co=o(" \u2014 "),nI=a("a"),bco=o("PerceiverTokenizer"),vco=o(" (Perceiver model)"),Fco=l(),dh=a("li"),Rse=a("strong"),Tco=o("phobert"),Mco=o(" \u2014 "),sI=a("a"),Eco=o("PhobertTokenizer"),Cco=o(" (PhoBERT model)"),wco=l(),ch=a("li"),Pse=a("strong"),Aco=o("plbart"),Lco=o(" \u2014 "),lI=a("a"),yco=o("PLBartTokenizer"),xco=o(" (PLBart model)"),$co=l(),fh=a("li"),Bse=a("strong"),kco=o("prophetnet"),Sco=o(" \u2014 "),iI=a("a"),Rco=o("ProphetNetTokenizer"),Pco=o(" (ProphetNet model)"),Bco=l(),ws=a("li"),Ise=a("strong"),Ico=o("qdqbert"),Nco=o(" \u2014 "),dI=a("a"),qco=o("BertTokenizer"),jco=o(" or "),cI=a("a"),Dco=o("BertTokenizerFast"),Gco=o(" (QDQBert model)"),Oco=l(),mh=a("li"),Nse=a("strong"),Vco=o("rag"),Xco=o(" \u2014 "),fI=a("a"),zco=o("RagTokenizer"),Wco=o(" (RAG model)"),Qco=l(),As=a("li"),qse=a("strong"),Hco=o("realm"),Uco=o(" \u2014 "),mI=a("a"),Jco=o("RealmTokenizer"),Yco=o(" or "),gI=a("a"),Kco=o("RealmTokenizerFast"),Zco=o(" (REALM model)"),efo=l(),Ls=a("li"),jse=a("strong"),ofo=o("reformer"),rfo=o(" \u2014 "),hI=a("a"),tfo=o("ReformerTokenizer"),afo=o(" or "),pI=a("a"),nfo=o("ReformerTokenizerFast"),sfo=o(" (Reformer model)"),lfo=l(),ys=a("li"),Dse=a("strong"),ifo=o("rembert"),dfo=o(" \u2014 "),uI=a("a"),cfo=o("RemBertTokenizer"),ffo=o(" or "),_I=a("a"),mfo=o("RemBertTokenizerFast"),gfo=o(" (RemBERT model)"),hfo=l(),xs=a("li"),Gse=a("strong"),pfo=o("retribert"),ufo=o(" \u2014 "),bI=a("a"),_fo=o("RetriBertTokenizer"),bfo=o(" or "),vI=a("a"),vfo=o("RetriBertTokenizerFast"),Ffo=o(" (RetriBERT model)"),Tfo=l(),$s=a("li"),Ose=a("strong"),Mfo=o("roberta"),Efo=o(" \u2014 "),FI=a("a"),Cfo=o("RobertaTokenizer"),wfo=o(" or "),TI=a("a"),Afo=o("RobertaTokenizerFast"),Lfo=o(" (RoBERTa model)"),yfo=l(),ks=a("li"),Vse=a("strong"),xfo=o("roformer"),$fo=o(" \u2014 "),MI=a("a"),kfo=o("RoFormerTokenizer"),Sfo=o(" or "),EI=a("a"),Rfo=o("RoFormerTokenizerFast"),Pfo=o(" (RoFormer model)"),Bfo=l(),gh=a("li"),Xse=a("strong"),Ifo=o("speech_to_text"),Nfo=o(" \u2014 "),CI=a("a"),qfo=o("Speech2TextTokenizer"),jfo=o(" (Speech2Text model)"),Dfo=l(),hh=a("li"),zse=a("strong"),Gfo=o("speech_to_text_2"),Ofo=o(" \u2014 "),wI=a("a"),Vfo=o("Speech2Text2Tokenizer"),Xfo=o(" (Speech2Text2 model)"),zfo=l(),Ss=a("li"),Wse=a("strong"),Wfo=o("splinter"),Qfo=o(" \u2014 "),AI=a("a"),Hfo=o("SplinterTokenizer"),Ufo=o(" or "),LI=a("a"),Jfo=o("SplinterTokenizerFast"),Yfo=o(" (Splinter model)"),Kfo=l(),Rs=a("li"),Qse=a("strong"),Zfo=o("squeezebert"),emo=o(" \u2014 "),yI=a("a"),omo=o("SqueezeBertTokenizer"),rmo=o(" or "),xI=a("a"),tmo=o("SqueezeBertTokenizerFast"),amo=o(" (SqueezeBERT model)"),nmo=l(),Ps=a("li"),Hse=a("strong"),smo=o("t5"),lmo=o(" \u2014 "),$I=a("a"),imo=o("T5Tokenizer"),dmo=o(" or "),kI=a("a"),cmo=o("T5TokenizerFast"),fmo=o(" (T5 model)"),mmo=l(),ph=a("li"),Use=a("strong"),gmo=o("tapas"),hmo=o(" \u2014 "),SI=a("a"),pmo=o("TapasTokenizer"),umo=o(" (TAPAS model)"),_mo=l(),uh=a("li"),Jse=a("strong"),bmo=o("tapex"),vmo=o(" \u2014 "),RI=a("a"),Fmo=o("TapexTokenizer"),Tmo=o(" (TAPEX model)"),Mmo=l(),_h=a("li"),Yse=a("strong"),Emo=o("transfo-xl"),Cmo=o(" \u2014 "),PI=a("a"),wmo=o("TransfoXLTokenizer"),Amo=o(" (Transformer-XL model)"),Lmo=l(),Bs=a("li"),Kse=a("strong"),ymo=o("vilt"),xmo=o(" \u2014 "),BI=a("a"),$mo=o("BertTokenizer"),kmo=o(" or "),II=a("a"),Smo=o("BertTokenizerFast"),Rmo=o(" (ViLT model)"),Pmo=l(),Is=a("li"),Zse=a("strong"),Bmo=o("visual_bert"),Imo=o(" \u2014 "),NI=a("a"),Nmo=o("BertTokenizer"),qmo=o(" or "),qI=a("a"),jmo=o("BertTokenizerFast"),Dmo=o(" (VisualBERT model)"),Gmo=l(),bh=a("li"),ele=a("strong"),Omo=o("wav2vec2"),Vmo=o(" \u2014 "),jI=a("a"),Xmo=o("Wav2Vec2CTCTokenizer"),zmo=o(" (Wav2Vec2 model)"),Wmo=l(),vh=a("li"),ole=a("strong"),Qmo=o("wav2vec2-conformer"),Hmo=o(" \u2014 "),DI=a("a"),Umo=o("Wav2Vec2CTCTokenizer"),Jmo=o(" (Wav2Vec2-Conformer model)"),Ymo=l(),Fh=a("li"),rle=a("strong"),Kmo=o("wav2vec2_phoneme"),Zmo=o(" \u2014 "),GI=a("a"),ego=o("Wav2Vec2PhonemeCTCTokenizer"),ogo=o(" (Wav2Vec2Phoneme model)"),rgo=l(),Ns=a("li"),tle=a("strong"),tgo=o("xglm"),ago=o(" \u2014 "),OI=a("a"),ngo=o("XGLMTokenizer"),sgo=o(" or "),VI=a("a"),lgo=o("XGLMTokenizerFast"),igo=o(" (XGLM model)"),dgo=l(),Th=a("li"),ale=a("strong"),cgo=o("xlm"),fgo=o(" \u2014 "),XI=a("a"),mgo=o("XLMTokenizer"),ggo=o(" (XLM model)"),hgo=l(),Mh=a("li"),nle=a("strong"),pgo=o("xlm-prophetnet"),ugo=o(" \u2014 "),zI=a("a"),_go=o("XLMProphetNetTokenizer"),bgo=o(" (XLM-ProphetNet model)"),vgo=l(),qs=a("li"),sle=a("strong"),Fgo=o("xlm-roberta"),Tgo=o(" \u2014 "),WI=a("a"),Mgo=o("XLMRobertaTokenizer"),Ego=o(" or "),QI=a("a"),Cgo=o("XLMRobertaTokenizerFast"),wgo=o(" (XLM-RoBERTa model)"),Ago=l(),js=a("li"),lle=a("strong"),Lgo=o("xlm-roberta-xl"),ygo=o(" \u2014 "),HI=a("a"),xgo=o("RobertaTokenizer"),$go=o(" or "),UI=a("a"),kgo=o("RobertaTokenizerFast"),Sgo=o(" (XLM-RoBERTa-XL model)"),Rgo=l(),Ds=a("li"),ile=a("strong"),Pgo=o("xlnet"),Bgo=o(" \u2014 "),JI=a("a"),Igo=o("XLNetTokenizer"),Ngo=o(" or "),YI=a("a"),qgo=o("XLNetTokenizerFast"),jgo=o(" (XLNet model)"),Dgo=l(),Gs=a("li"),dle=a("strong"),Ggo=o("yoso"),Ogo=o(" \u2014 "),KI=a("a"),Vgo=o("AlbertTokenizer"),Xgo=o(" or "),ZI=a("a"),zgo=o("AlbertTokenizerFast"),Wgo=o(" (YOSO model)"),Qgo=l(),F(Eh.$$.fragment),Hgo=l(),Ch=a("div"),F(NL.$$.fragment),Ugo=l(),cle=a("p"),Jgo=o("Register a new tokenizer in this mapping."),yGe=l(),Si=a("h2"),wh=a("a"),fle=a("span"),F(qL.$$.fragment),Ygo=l(),mle=a("span"),Kgo=o("AutoFeatureExtractor"),xGe=l(),Lo=a("div"),F(jL.$$.fragment),Zgo=l(),DL=a("p"),eho=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),eN=a("a"),oho=o("AutoFeatureExtractor.from_pretrained()"),rho=o(" class method."),tho=l(),GL=a("p"),aho=o("This class cannot be instantiated directly using "),gle=a("code"),nho=o("__init__()"),sho=o(" (throws an error)."),lho=l(),He=a("div"),F(OL.$$.fragment),iho=l(),hle=a("p"),dho=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),cho=l(),ka=a("p"),fho=o("The feature extractor class to instantiate is selected based on the "),ple=a("code"),mho=o("model_type"),gho=o(` property of the config object
(either passed as an argument or loaded from `),ule=a("code"),hho=o("pretrained_model_name_or_path"),pho=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),_le=a("code"),uho=o("pretrained_model_name_or_path"),_ho=o(":"),bho=l(),Y=a("ul"),Ah=a("li"),ble=a("strong"),vho=o("beit"),Fho=o(" \u2014 "),oN=a("a"),Tho=o("BeitFeatureExtractor"),Mho=o(" (BEiT model)"),Eho=l(),Lh=a("li"),vle=a("strong"),Cho=o("clip"),who=o(" \u2014 "),rN=a("a"),Aho=o("CLIPFeatureExtractor"),Lho=o(" (CLIP model)"),yho=l(),yh=a("li"),Fle=a("strong"),xho=o("convnext"),$ho=o(" \u2014 "),tN=a("a"),kho=o("ConvNextFeatureExtractor"),Sho=o(" (ConvNeXT model)"),Rho=l(),xh=a("li"),Tle=a("strong"),Pho=o("cvt"),Bho=o(" \u2014 "),aN=a("a"),Iho=o("ConvNextFeatureExtractor"),Nho=o(" (CvT model)"),qho=l(),$h=a("li"),Mle=a("strong"),jho=o("data2vec-audio"),Dho=o(" \u2014 "),nN=a("a"),Gho=o("Wav2Vec2FeatureExtractor"),Oho=o(" (Data2VecAudio model)"),Vho=l(),kh=a("li"),Ele=a("strong"),Xho=o("data2vec-vision"),zho=o(" \u2014 "),sN=a("a"),Who=o("BeitFeatureExtractor"),Qho=o(" (Data2VecVision model)"),Hho=l(),Sh=a("li"),Cle=a("strong"),Uho=o("deit"),Jho=o(" \u2014 "),lN=a("a"),Yho=o("DeiTFeatureExtractor"),Kho=o(" (DeiT model)"),Zho=l(),Rh=a("li"),wle=a("strong"),epo=o("detr"),opo=o(" \u2014 "),iN=a("a"),rpo=o("DetrFeatureExtractor"),tpo=o(" (DETR model)"),apo=l(),Ph=a("li"),Ale=a("strong"),npo=o("dpt"),spo=o(" \u2014 "),dN=a("a"),lpo=o("DPTFeatureExtractor"),ipo=o(" (DPT model)"),dpo=l(),Bh=a("li"),Lle=a("strong"),cpo=o("flava"),fpo=o(" \u2014 "),cN=a("a"),mpo=o("FlavaFeatureExtractor"),gpo=o(" (FLAVA model)"),hpo=l(),Ih=a("li"),yle=a("strong"),ppo=o("glpn"),upo=o(" \u2014 "),fN=a("a"),_po=o("GLPNFeatureExtractor"),bpo=o(" (GLPN model)"),vpo=l(),Nh=a("li"),xle=a("strong"),Fpo=o("groupvit"),Tpo=o(" \u2014 "),mN=a("a"),Mpo=o("CLIPFeatureExtractor"),Epo=o(" (GroupViT model)"),Cpo=l(),qh=a("li"),$le=a("strong"),wpo=o("hubert"),Apo=o(" \u2014 "),gN=a("a"),Lpo=o("Wav2Vec2FeatureExtractor"),ypo=o(" (Hubert model)"),xpo=l(),jh=a("li"),kle=a("strong"),$po=o("imagegpt"),kpo=o(" \u2014 "),hN=a("a"),Spo=o("ImageGPTFeatureExtractor"),Rpo=o(" (ImageGPT model)"),Ppo=l(),Dh=a("li"),Sle=a("strong"),Bpo=o("layoutlmv2"),Ipo=o(" \u2014 "),pN=a("a"),Npo=o("LayoutLMv2FeatureExtractor"),qpo=o(" (LayoutLMv2 model)"),jpo=l(),Gh=a("li"),Rle=a("strong"),Dpo=o("layoutlmv3"),Gpo=o(" \u2014 "),uN=a("a"),Opo=o("LayoutLMv3FeatureExtractor"),Vpo=o(" (LayoutLMv3 model)"),Xpo=l(),Oh=a("li"),Ple=a("strong"),zpo=o("levit"),Wpo=o(" \u2014 "),_N=a("a"),Qpo=o("LevitFeatureExtractor"),Hpo=o(" (LeViT model)"),Upo=l(),Vh=a("li"),Ble=a("strong"),Jpo=o("maskformer"),Ypo=o(" \u2014 "),bN=a("a"),Kpo=o("MaskFormerFeatureExtractor"),Zpo=o(" (MaskFormer model)"),euo=l(),Xh=a("li"),Ile=a("strong"),ouo=o("mctct"),ruo=o(" \u2014 "),vN=a("a"),tuo=o("MCTCTFeatureExtractor"),auo=o(" (M-CTC-T model)"),nuo=l(),zh=a("li"),Nle=a("strong"),suo=o("perceiver"),luo=o(" \u2014 "),FN=a("a"),iuo=o("PerceiverFeatureExtractor"),duo=o(" (Perceiver model)"),cuo=l(),Wh=a("li"),qle=a("strong"),fuo=o("poolformer"),muo=o(" \u2014 "),TN=a("a"),guo=o("PoolFormerFeatureExtractor"),huo=o(" (PoolFormer model)"),puo=l(),Qh=a("li"),jle=a("strong"),uuo=o("regnet"),_uo=o(" \u2014 "),MN=a("a"),buo=o("ConvNextFeatureExtractor"),vuo=o(" (RegNet model)"),Fuo=l(),Hh=a("li"),Dle=a("strong"),Tuo=o("resnet"),Muo=o(" \u2014 "),EN=a("a"),Euo=o("ConvNextFeatureExtractor"),Cuo=o(" (ResNet model)"),wuo=l(),Uh=a("li"),Gle=a("strong"),Auo=o("segformer"),Luo=o(" \u2014 "),CN=a("a"),yuo=o("SegformerFeatureExtractor"),xuo=o(" (SegFormer model)"),$uo=l(),Jh=a("li"),Ole=a("strong"),kuo=o("speech_to_text"),Suo=o(" \u2014 "),wN=a("a"),Ruo=o("Speech2TextFeatureExtractor"),Puo=o(" (Speech2Text model)"),Buo=l(),Yh=a("li"),Vle=a("strong"),Iuo=o("swin"),Nuo=o(" \u2014 "),AN=a("a"),quo=o("ViTFeatureExtractor"),juo=o(" (Swin Transformer model)"),Duo=l(),Kh=a("li"),Xle=a("strong"),Guo=o("van"),Ouo=o(" \u2014 "),LN=a("a"),Vuo=o("ConvNextFeatureExtractor"),Xuo=o(" (VAN model)"),zuo=l(),Zh=a("li"),zle=a("strong"),Wuo=o("vilt"),Quo=o(" \u2014 "),yN=a("a"),Huo=o("ViltFeatureExtractor"),Uuo=o(" (ViLT model)"),Juo=l(),ep=a("li"),Wle=a("strong"),Yuo=o("vit"),Kuo=o(" \u2014 "),xN=a("a"),Zuo=o("ViTFeatureExtractor"),e_o=o(" (ViT model)"),o_o=l(),op=a("li"),Qle=a("strong"),r_o=o("vit_mae"),t_o=o(" \u2014 "),$N=a("a"),a_o=o("ViTFeatureExtractor"),n_o=o(" (ViTMAE model)"),s_o=l(),rp=a("li"),Hle=a("strong"),l_o=o("wav2vec2"),i_o=o(" \u2014 "),kN=a("a"),d_o=o("Wav2Vec2FeatureExtractor"),c_o=o(" (Wav2Vec2 model)"),f_o=l(),tp=a("li"),Ule=a("strong"),m_o=o("wav2vec2-conformer"),g_o=o(" \u2014 "),SN=a("a"),h_o=o("Wav2Vec2FeatureExtractor"),p_o=o(" (Wav2Vec2-Conformer model)"),u_o=l(),ap=a("li"),Jle=a("strong"),__o=o("yolos"),b_o=o(" \u2014 "),RN=a("a"),v_o=o("YolosFeatureExtractor"),F_o=o(" (YOLOS model)"),T_o=l(),F(np.$$.fragment),M_o=l(),F(sp.$$.fragment),E_o=l(),lp=a("div"),F(VL.$$.fragment),C_o=l(),Yle=a("p"),w_o=o("Register a new feature extractor for this class."),$Ge=l(),Ri=a("h2"),ip=a("a"),Kle=a("span"),F(XL.$$.fragment),A_o=l(),Zle=a("span"),L_o=o("AutoProcessor"),kGe=l(),yo=a("div"),F(zL.$$.fragment),y_o=l(),WL=a("p"),x_o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),PN=a("a"),$_o=o("AutoProcessor.from_pretrained()"),k_o=o(" class method."),S_o=l(),QL=a("p"),R_o=o("This class cannot be instantiated directly using "),eie=a("code"),P_o=o("__init__()"),B_o=o(" (throws an error)."),I_o=l(),Ue=a("div"),F(HL.$$.fragment),N_o=l(),oie=a("p"),q_o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),j_o=l(),Pi=a("p"),D_o=o("The processor class to instantiate is selected based on the "),rie=a("code"),G_o=o("model_type"),O_o=o(` property of the config object (either
passed as an argument or loaded from `),tie=a("code"),V_o=o("pretrained_model_name_or_path"),X_o=o(" if possible):"),z_o=l(),he=a("ul"),dp=a("li"),aie=a("strong"),W_o=o("clip"),Q_o=o(" \u2014 "),BN=a("a"),H_o=o("CLIPProcessor"),U_o=o(" (CLIP model)"),J_o=l(),cp=a("li"),nie=a("strong"),Y_o=o("flava"),K_o=o(" \u2014 "),sie=a("code"),Z_o=o("FLAVAProcessor"),e1o=o(" (FLAVA model)"),o1o=l(),fp=a("li"),lie=a("strong"),r1o=o("groupvit"),t1o=o(" \u2014 "),IN=a("a"),a1o=o("CLIPProcessor"),n1o=o(" (GroupViT model)"),s1o=l(),mp=a("li"),iie=a("strong"),l1o=o("layoutlmv2"),i1o=o(" \u2014 "),NN=a("a"),d1o=o("LayoutLMv2Processor"),c1o=o(" (LayoutLMv2 model)"),f1o=l(),gp=a("li"),die=a("strong"),m1o=o("layoutlmv3"),g1o=o(" \u2014 "),qN=a("a"),h1o=o("LayoutLMv3Processor"),p1o=o(" (LayoutLMv3 model)"),u1o=l(),hp=a("li"),cie=a("strong"),_1o=o("layoutxlm"),b1o=o(" \u2014 "),jN=a("a"),v1o=o("LayoutXLMProcessor"),F1o=o(" (LayoutXLM model)"),T1o=l(),pp=a("li"),fie=a("strong"),M1o=o("sew"),E1o=o(" \u2014 "),DN=a("a"),C1o=o("Wav2Vec2Processor"),w1o=o(" (SEW model)"),A1o=l(),up=a("li"),mie=a("strong"),L1o=o("sew-d"),y1o=o(" \u2014 "),GN=a("a"),x1o=o("Wav2Vec2Processor"),$1o=o(" (SEW-D model)"),k1o=l(),_p=a("li"),gie=a("strong"),S1o=o("speech_to_text"),R1o=o(" \u2014 "),ON=a("a"),P1o=o("Speech2TextProcessor"),B1o=o(" (Speech2Text model)"),I1o=l(),bp=a("li"),hie=a("strong"),N1o=o("speech_to_text_2"),q1o=o(" \u2014 "),VN=a("a"),j1o=o("Speech2Text2Processor"),D1o=o(" (Speech2Text2 model)"),G1o=l(),vp=a("li"),pie=a("strong"),O1o=o("trocr"),V1o=o(" \u2014 "),XN=a("a"),X1o=o("TrOCRProcessor"),z1o=o(" (TrOCR model)"),W1o=l(),Fp=a("li"),uie=a("strong"),Q1o=o("unispeech"),H1o=o(" \u2014 "),zN=a("a"),U1o=o("Wav2Vec2Processor"),J1o=o(" (UniSpeech model)"),Y1o=l(),Tp=a("li"),_ie=a("strong"),K1o=o("unispeech-sat"),Z1o=o(" \u2014 "),WN=a("a"),e3o=o("Wav2Vec2Processor"),o3o=o(" (UniSpeechSat model)"),r3o=l(),Mp=a("li"),bie=a("strong"),t3o=o("vilt"),a3o=o(" \u2014 "),QN=a("a"),n3o=o("ViltProcessor"),s3o=o(" (ViLT model)"),l3o=l(),Ep=a("li"),vie=a("strong"),i3o=o("vision-text-dual-encoder"),d3o=o(" \u2014 "),HN=a("a"),c3o=o("VisionTextDualEncoderProcessor"),f3o=o(" (VisionTextDualEncoder model)"),m3o=l(),Cp=a("li"),Fie=a("strong"),g3o=o("wav2vec2"),h3o=o(" \u2014 "),UN=a("a"),p3o=o("Wav2Vec2Processor"),u3o=o(" (Wav2Vec2 model)"),_3o=l(),wp=a("li"),Tie=a("strong"),b3o=o("wav2vec2-conformer"),v3o=o(" \u2014 "),JN=a("a"),F3o=o("Wav2Vec2Processor"),T3o=o(" (Wav2Vec2-Conformer model)"),M3o=l(),Ap=a("li"),Mie=a("strong"),E3o=o("wavlm"),C3o=o(" \u2014 "),YN=a("a"),w3o=o("Wav2Vec2Processor"),A3o=o(" (WavLM model)"),L3o=l(),F(Lp.$$.fragment),y3o=l(),F(yp.$$.fragment),x3o=l(),xp=a("div"),F(UL.$$.fragment),$3o=l(),Eie=a("p"),k3o=o("Register a new processor for this class."),SGe=l(),Bi=a("h2"),$p=a("a"),Cie=a("span"),F(JL.$$.fragment),S3o=l(),wie=a("span"),R3o=o("AutoModel"),RGe=l(),xo=a("div"),F(YL.$$.fragment),P3o=l(),Ii=a("p"),B3o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),KN=a("a"),I3o=o("from_pretrained()"),N3o=o(" class method or the "),ZN=a("a"),q3o=o("from_config()"),j3o=o(` class
method.`),D3o=l(),KL=a("p"),G3o=o("This class cannot be instantiated directly using "),Aie=a("code"),O3o=o("__init__()"),V3o=o(" (throws an error)."),X3o=l(),nt=a("div"),F(ZL.$$.fragment),z3o=l(),Lie=a("p"),W3o=o("Instantiates one of the base model classes of the library from a configuration."),Q3o=l(),Ni=a("p"),H3o=o(`Note:
Loading a model from its configuration file does `),yie=a("strong"),U3o=o("not"),J3o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eq=a("a"),Y3o=o("from_pretrained()"),K3o=o(" to load the model weights."),Z3o=l(),F(kp.$$.fragment),e2o=l(),Je=a("div"),F(ey.$$.fragment),o2o=l(),xie=a("p"),r2o=o("Instantiate one of the base model classes of the library from a pretrained model."),t2o=l(),Sa=a("p"),a2o=o("The model class to instantiate is selected based on the "),$ie=a("code"),n2o=o("model_type"),s2o=o(` property of the config object (either
passed as an argument or loaded from `),kie=a("code"),l2o=o("pretrained_model_name_or_path"),i2o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sie=a("code"),d2o=o("pretrained_model_name_or_path"),c2o=o(":"),f2o=l(),y=a("ul"),Sp=a("li"),Rie=a("strong"),m2o=o("albert"),g2o=o(" \u2014 "),oq=a("a"),h2o=o("AlbertModel"),p2o=o(" (ALBERT model)"),u2o=l(),Rp=a("li"),Pie=a("strong"),_2o=o("bart"),b2o=o(" \u2014 "),rq=a("a"),v2o=o("BartModel"),F2o=o(" (BART model)"),T2o=l(),Pp=a("li"),Bie=a("strong"),M2o=o("beit"),E2o=o(" \u2014 "),tq=a("a"),C2o=o("BeitModel"),w2o=o(" (BEiT model)"),A2o=l(),Bp=a("li"),Iie=a("strong"),L2o=o("bert"),y2o=o(" \u2014 "),aq=a("a"),x2o=o("BertModel"),$2o=o(" (BERT model)"),k2o=l(),Ip=a("li"),Nie=a("strong"),S2o=o("bert-generation"),R2o=o(" \u2014 "),nq=a("a"),P2o=o("BertGenerationEncoder"),B2o=o(" (Bert Generation model)"),I2o=l(),Np=a("li"),qie=a("strong"),N2o=o("big_bird"),q2o=o(" \u2014 "),sq=a("a"),j2o=o("BigBirdModel"),D2o=o(" (BigBird model)"),G2o=l(),qp=a("li"),jie=a("strong"),O2o=o("bigbird_pegasus"),V2o=o(" \u2014 "),lq=a("a"),X2o=o("BigBirdPegasusModel"),z2o=o(" (BigBird-Pegasus model)"),W2o=l(),jp=a("li"),Die=a("strong"),Q2o=o("blenderbot"),H2o=o(" \u2014 "),iq=a("a"),U2o=o("BlenderbotModel"),J2o=o(" (Blenderbot model)"),Y2o=l(),Dp=a("li"),Gie=a("strong"),K2o=o("blenderbot-small"),Z2o=o(" \u2014 "),dq=a("a"),ebo=o("BlenderbotSmallModel"),obo=o(" (BlenderbotSmall model)"),rbo=l(),Gp=a("li"),Oie=a("strong"),tbo=o("bloom"),abo=o(" \u2014 "),cq=a("a"),nbo=o("BloomModel"),sbo=o(" (BLOOM model)"),lbo=l(),Op=a("li"),Vie=a("strong"),ibo=o("camembert"),dbo=o(" \u2014 "),fq=a("a"),cbo=o("CamembertModel"),fbo=o(" (CamemBERT model)"),mbo=l(),Vp=a("li"),Xie=a("strong"),gbo=o("canine"),hbo=o(" \u2014 "),mq=a("a"),pbo=o("CanineModel"),ubo=o(" (CANINE model)"),_bo=l(),Xp=a("li"),zie=a("strong"),bbo=o("clip"),vbo=o(" \u2014 "),gq=a("a"),Fbo=o("CLIPModel"),Tbo=o(" (CLIP model)"),Mbo=l(),zp=a("li"),Wie=a("strong"),Ebo=o("convbert"),Cbo=o(" \u2014 "),hq=a("a"),wbo=o("ConvBertModel"),Abo=o(" (ConvBERT model)"),Lbo=l(),Wp=a("li"),Qie=a("strong"),ybo=o("convnext"),xbo=o(" \u2014 "),pq=a("a"),$bo=o("ConvNextModel"),kbo=o(" (ConvNeXT model)"),Sbo=l(),Qp=a("li"),Hie=a("strong"),Rbo=o("ctrl"),Pbo=o(" \u2014 "),uq=a("a"),Bbo=o("CTRLModel"),Ibo=o(" (CTRL model)"),Nbo=l(),Hp=a("li"),Uie=a("strong"),qbo=o("cvt"),jbo=o(" \u2014 "),_q=a("a"),Dbo=o("CvtModel"),Gbo=o(" (CvT model)"),Obo=l(),Up=a("li"),Jie=a("strong"),Vbo=o("data2vec-audio"),Xbo=o(" \u2014 "),bq=a("a"),zbo=o("Data2VecAudioModel"),Wbo=o(" (Data2VecAudio model)"),Qbo=l(),Jp=a("li"),Yie=a("strong"),Hbo=o("data2vec-text"),Ubo=o(" \u2014 "),vq=a("a"),Jbo=o("Data2VecTextModel"),Ybo=o(" (Data2VecText model)"),Kbo=l(),Yp=a("li"),Kie=a("strong"),Zbo=o("data2vec-vision"),evo=o(" \u2014 "),Fq=a("a"),ovo=o("Data2VecVisionModel"),rvo=o(" (Data2VecVision model)"),tvo=l(),Kp=a("li"),Zie=a("strong"),avo=o("deberta"),nvo=o(" \u2014 "),Tq=a("a"),svo=o("DebertaModel"),lvo=o(" (DeBERTa model)"),ivo=l(),Zp=a("li"),ede=a("strong"),dvo=o("deberta-v2"),cvo=o(" \u2014 "),Mq=a("a"),fvo=o("DebertaV2Model"),mvo=o(" (DeBERTa-v2 model)"),gvo=l(),eu=a("li"),ode=a("strong"),hvo=o("decision_transformer"),pvo=o(" \u2014 "),Eq=a("a"),uvo=o("DecisionTransformerModel"),_vo=o(" (Decision Transformer model)"),bvo=l(),ou=a("li"),rde=a("strong"),vvo=o("deit"),Fvo=o(" \u2014 "),Cq=a("a"),Tvo=o("DeiTModel"),Mvo=o(" (DeiT model)"),Evo=l(),ru=a("li"),tde=a("strong"),Cvo=o("detr"),wvo=o(" \u2014 "),wq=a("a"),Avo=o("DetrModel"),Lvo=o(" (DETR model)"),yvo=l(),tu=a("li"),ade=a("strong"),xvo=o("distilbert"),$vo=o(" \u2014 "),Aq=a("a"),kvo=o("DistilBertModel"),Svo=o(" (DistilBERT model)"),Rvo=l(),au=a("li"),nde=a("strong"),Pvo=o("dpr"),Bvo=o(" \u2014 "),Lq=a("a"),Ivo=o("DPRQuestionEncoder"),Nvo=o(" (DPR model)"),qvo=l(),nu=a("li"),sde=a("strong"),jvo=o("dpt"),Dvo=o(" \u2014 "),yq=a("a"),Gvo=o("DPTModel"),Ovo=o(" (DPT model)"),Vvo=l(),su=a("li"),lde=a("strong"),Xvo=o("electra"),zvo=o(" \u2014 "),xq=a("a"),Wvo=o("ElectraModel"),Qvo=o(" (ELECTRA model)"),Hvo=l(),lu=a("li"),ide=a("strong"),Uvo=o("flaubert"),Jvo=o(" \u2014 "),$q=a("a"),Yvo=o("FlaubertModel"),Kvo=o(" (FlauBERT model)"),Zvo=l(),iu=a("li"),dde=a("strong"),eFo=o("flava"),oFo=o(" \u2014 "),kq=a("a"),rFo=o("FlavaModel"),tFo=o(" (FLAVA model)"),aFo=l(),du=a("li"),cde=a("strong"),nFo=o("fnet"),sFo=o(" \u2014 "),Sq=a("a"),lFo=o("FNetModel"),iFo=o(" (FNet model)"),dFo=l(),cu=a("li"),fde=a("strong"),cFo=o("fsmt"),fFo=o(" \u2014 "),Rq=a("a"),mFo=o("FSMTModel"),gFo=o(" (FairSeq Machine-Translation model)"),hFo=l(),Os=a("li"),mde=a("strong"),pFo=o("funnel"),uFo=o(" \u2014 "),Pq=a("a"),_Fo=o("FunnelModel"),bFo=o(" or "),Bq=a("a"),vFo=o("FunnelBaseModel"),FFo=o(" (Funnel Transformer model)"),TFo=l(),fu=a("li"),gde=a("strong"),MFo=o("glpn"),EFo=o(" \u2014 "),Iq=a("a"),CFo=o("GLPNModel"),wFo=o(" (GLPN model)"),AFo=l(),mu=a("li"),hde=a("strong"),LFo=o("gpt2"),yFo=o(" \u2014 "),Nq=a("a"),xFo=o("GPT2Model"),$Fo=o(" (OpenAI GPT-2 model)"),kFo=l(),gu=a("li"),pde=a("strong"),SFo=o("gpt_neo"),RFo=o(" \u2014 "),qq=a("a"),PFo=o("GPTNeoModel"),BFo=o(" (GPT Neo model)"),IFo=l(),hu=a("li"),ude=a("strong"),NFo=o("gpt_neox"),qFo=o(" \u2014 "),jq=a("a"),jFo=o("GPTNeoXModel"),DFo=o(" (GPT NeoX model)"),GFo=l(),pu=a("li"),_de=a("strong"),OFo=o("gptj"),VFo=o(" \u2014 "),Dq=a("a"),XFo=o("GPTJModel"),zFo=o(" (GPT-J model)"),WFo=l(),uu=a("li"),bde=a("strong"),QFo=o("groupvit"),HFo=o(" \u2014 "),Gq=a("a"),UFo=o("GroupViTModel"),JFo=o(" (GroupViT model)"),YFo=l(),_u=a("li"),vde=a("strong"),KFo=o("hubert"),ZFo=o(" \u2014 "),Oq=a("a"),eTo=o("HubertModel"),oTo=o(" (Hubert model)"),rTo=l(),bu=a("li"),Fde=a("strong"),tTo=o("ibert"),aTo=o(" \u2014 "),Vq=a("a"),nTo=o("IBertModel"),sTo=o(" (I-BERT model)"),lTo=l(),vu=a("li"),Tde=a("strong"),iTo=o("imagegpt"),dTo=o(" \u2014 "),Xq=a("a"),cTo=o("ImageGPTModel"),fTo=o(" (ImageGPT model)"),mTo=l(),Fu=a("li"),Mde=a("strong"),gTo=o("layoutlm"),hTo=o(" \u2014 "),zq=a("a"),pTo=o("LayoutLMModel"),uTo=o(" (LayoutLM model)"),_To=l(),Tu=a("li"),Ede=a("strong"),bTo=o("layoutlmv2"),vTo=o(" \u2014 "),Wq=a("a"),FTo=o("LayoutLMv2Model"),TTo=o(" (LayoutLMv2 model)"),MTo=l(),Mu=a("li"),Cde=a("strong"),ETo=o("layoutlmv3"),CTo=o(" \u2014 "),Qq=a("a"),wTo=o("LayoutLMv3Model"),ATo=o(" (LayoutLMv3 model)"),LTo=l(),Eu=a("li"),wde=a("strong"),yTo=o("led"),xTo=o(" \u2014 "),Hq=a("a"),$To=o("LEDModel"),kTo=o(" (LED model)"),STo=l(),Cu=a("li"),Ade=a("strong"),RTo=o("levit"),PTo=o(" \u2014 "),Uq=a("a"),BTo=o("LevitModel"),ITo=o(" (LeViT model)"),NTo=l(),wu=a("li"),Lde=a("strong"),qTo=o("longformer"),jTo=o(" \u2014 "),Jq=a("a"),DTo=o("LongformerModel"),GTo=o(" (Longformer model)"),OTo=l(),Au=a("li"),yde=a("strong"),VTo=o("longt5"),XTo=o(" \u2014 "),Yq=a("a"),zTo=o("LongT5Model"),WTo=o(" (LongT5 model)"),QTo=l(),Lu=a("li"),xde=a("strong"),HTo=o("luke"),UTo=o(" \u2014 "),Kq=a("a"),JTo=o("LukeModel"),YTo=o(" (LUKE model)"),KTo=l(),yu=a("li"),$de=a("strong"),ZTo=o("lxmert"),e7o=o(" \u2014 "),Zq=a("a"),o7o=o("LxmertModel"),r7o=o(" (LXMERT model)"),t7o=l(),xu=a("li"),kde=a("strong"),a7o=o("m2m_100"),n7o=o(" \u2014 "),ej=a("a"),s7o=o("M2M100Model"),l7o=o(" (M2M100 model)"),i7o=l(),$u=a("li"),Sde=a("strong"),d7o=o("marian"),c7o=o(" \u2014 "),oj=a("a"),f7o=o("MarianModel"),m7o=o(" (Marian model)"),g7o=l(),ku=a("li"),Rde=a("strong"),h7o=o("maskformer"),p7o=o(" \u2014 "),rj=a("a"),u7o=o("MaskFormerModel"),_7o=o(" (MaskFormer model)"),b7o=l(),Su=a("li"),Pde=a("strong"),v7o=o("mbart"),F7o=o(" \u2014 "),tj=a("a"),T7o=o("MBartModel"),M7o=o(" (mBART model)"),E7o=l(),Ru=a("li"),Bde=a("strong"),C7o=o("mctct"),w7o=o(" \u2014 "),aj=a("a"),A7o=o("MCTCTModel"),L7o=o(" (M-CTC-T model)"),y7o=l(),Pu=a("li"),Ide=a("strong"),x7o=o("megatron-bert"),$7o=o(" \u2014 "),nj=a("a"),k7o=o("MegatronBertModel"),S7o=o(" (Megatron-BERT model)"),R7o=l(),Bu=a("li"),Nde=a("strong"),P7o=o("mobilebert"),B7o=o(" \u2014 "),sj=a("a"),I7o=o("MobileBertModel"),N7o=o(" (MobileBERT model)"),q7o=l(),Iu=a("li"),qde=a("strong"),j7o=o("mpnet"),D7o=o(" \u2014 "),lj=a("a"),G7o=o("MPNetModel"),O7o=o(" (MPNet model)"),V7o=l(),Nu=a("li"),jde=a("strong"),X7o=o("mt5"),z7o=o(" \u2014 "),ij=a("a"),W7o=o("MT5Model"),Q7o=o(" (MT5 model)"),H7o=l(),qu=a("li"),Dde=a("strong"),U7o=o("nystromformer"),J7o=o(" \u2014 "),dj=a("a"),Y7o=o("NystromformerModel"),K7o=o(" (Nystr\xF6mformer model)"),Z7o=l(),ju=a("li"),Gde=a("strong"),eMo=o("openai-gpt"),oMo=o(" \u2014 "),cj=a("a"),rMo=o("OpenAIGPTModel"),tMo=o(" (OpenAI GPT model)"),aMo=l(),Du=a("li"),Ode=a("strong"),nMo=o("opt"),sMo=o(" \u2014 "),fj=a("a"),lMo=o("OPTModel"),iMo=o(" (OPT model)"),dMo=l(),Gu=a("li"),Vde=a("strong"),cMo=o("pegasus"),fMo=o(" \u2014 "),mj=a("a"),mMo=o("PegasusModel"),gMo=o(" (Pegasus model)"),hMo=l(),Ou=a("li"),Xde=a("strong"),pMo=o("perceiver"),uMo=o(" \u2014 "),gj=a("a"),_Mo=o("PerceiverModel"),bMo=o(" (Perceiver model)"),vMo=l(),Vu=a("li"),zde=a("strong"),FMo=o("plbart"),TMo=o(" \u2014 "),hj=a("a"),MMo=o("PLBartModel"),EMo=o(" (PLBart model)"),CMo=l(),Xu=a("li"),Wde=a("strong"),wMo=o("poolformer"),AMo=o(" \u2014 "),pj=a("a"),LMo=o("PoolFormerModel"),yMo=o(" (PoolFormer model)"),xMo=l(),zu=a("li"),Qde=a("strong"),$Mo=o("prophetnet"),kMo=o(" \u2014 "),uj=a("a"),SMo=o("ProphetNetModel"),RMo=o(" (ProphetNet model)"),PMo=l(),Wu=a("li"),Hde=a("strong"),BMo=o("qdqbert"),IMo=o(" \u2014 "),_j=a("a"),NMo=o("QDQBertModel"),qMo=o(" (QDQBert model)"),jMo=l(),Qu=a("li"),Ude=a("strong"),DMo=o("reformer"),GMo=o(" \u2014 "),bj=a("a"),OMo=o("ReformerModel"),VMo=o(" (Reformer model)"),XMo=l(),Hu=a("li"),Jde=a("strong"),zMo=o("regnet"),WMo=o(" \u2014 "),vj=a("a"),QMo=o("RegNetModel"),HMo=o(" (RegNet model)"),UMo=l(),Uu=a("li"),Yde=a("strong"),JMo=o("rembert"),YMo=o(" \u2014 "),Fj=a("a"),KMo=o("RemBertModel"),ZMo=o(" (RemBERT model)"),eEo=l(),Ju=a("li"),Kde=a("strong"),oEo=o("resnet"),rEo=o(" \u2014 "),Tj=a("a"),tEo=o("ResNetModel"),aEo=o(" (ResNet model)"),nEo=l(),Yu=a("li"),Zde=a("strong"),sEo=o("retribert"),lEo=o(" \u2014 "),Mj=a("a"),iEo=o("RetriBertModel"),dEo=o(" (RetriBERT model)"),cEo=l(),Ku=a("li"),ece=a("strong"),fEo=o("roberta"),mEo=o(" \u2014 "),Ej=a("a"),gEo=o("RobertaModel"),hEo=o(" (RoBERTa model)"),pEo=l(),Zu=a("li"),oce=a("strong"),uEo=o("roformer"),_Eo=o(" \u2014 "),Cj=a("a"),bEo=o("RoFormerModel"),vEo=o(" (RoFormer model)"),FEo=l(),e_=a("li"),rce=a("strong"),TEo=o("segformer"),MEo=o(" \u2014 "),wj=a("a"),EEo=o("SegformerModel"),CEo=o(" (SegFormer model)"),wEo=l(),o_=a("li"),tce=a("strong"),AEo=o("sew"),LEo=o(" \u2014 "),Aj=a("a"),yEo=o("SEWModel"),xEo=o(" (SEW model)"),$Eo=l(),r_=a("li"),ace=a("strong"),kEo=o("sew-d"),SEo=o(" \u2014 "),Lj=a("a"),REo=o("SEWDModel"),PEo=o(" (SEW-D model)"),BEo=l(),t_=a("li"),nce=a("strong"),IEo=o("speech_to_text"),NEo=o(" \u2014 "),yj=a("a"),qEo=o("Speech2TextModel"),jEo=o(" (Speech2Text model)"),DEo=l(),a_=a("li"),sce=a("strong"),GEo=o("splinter"),OEo=o(" \u2014 "),xj=a("a"),VEo=o("SplinterModel"),XEo=o(" (Splinter model)"),zEo=l(),n_=a("li"),lce=a("strong"),WEo=o("squeezebert"),QEo=o(" \u2014 "),$j=a("a"),HEo=o("SqueezeBertModel"),UEo=o(" (SqueezeBERT model)"),JEo=l(),s_=a("li"),ice=a("strong"),YEo=o("swin"),KEo=o(" \u2014 "),kj=a("a"),ZEo=o("SwinModel"),e4o=o(" (Swin Transformer model)"),o4o=l(),l_=a("li"),dce=a("strong"),r4o=o("t5"),t4o=o(" \u2014 "),Sj=a("a"),a4o=o("T5Model"),n4o=o(" (T5 model)"),s4o=l(),i_=a("li"),cce=a("strong"),l4o=o("tapas"),i4o=o(" \u2014 "),Rj=a("a"),d4o=o("TapasModel"),c4o=o(" (TAPAS model)"),f4o=l(),d_=a("li"),fce=a("strong"),m4o=o("trajectory_transformer"),g4o=o(" \u2014 "),Pj=a("a"),h4o=o("TrajectoryTransformerModel"),p4o=o(" (Trajectory Transformer model)"),u4o=l(),c_=a("li"),mce=a("strong"),_4o=o("transfo-xl"),b4o=o(" \u2014 "),Bj=a("a"),v4o=o("TransfoXLModel"),F4o=o(" (Transformer-XL model)"),T4o=l(),f_=a("li"),gce=a("strong"),M4o=o("unispeech"),E4o=o(" \u2014 "),Ij=a("a"),C4o=o("UniSpeechModel"),w4o=o(" (UniSpeech model)"),A4o=l(),m_=a("li"),hce=a("strong"),L4o=o("unispeech-sat"),y4o=o(" \u2014 "),Nj=a("a"),x4o=o("UniSpeechSatModel"),$4o=o(" (UniSpeechSat model)"),k4o=l(),g_=a("li"),pce=a("strong"),S4o=o("van"),R4o=o(" \u2014 "),qj=a("a"),P4o=o("VanModel"),B4o=o(" (VAN model)"),I4o=l(),h_=a("li"),uce=a("strong"),N4o=o("vilt"),q4o=o(" \u2014 "),jj=a("a"),j4o=o("ViltModel"),D4o=o(" (ViLT model)"),G4o=l(),p_=a("li"),_ce=a("strong"),O4o=o("vision-text-dual-encoder"),V4o=o(" \u2014 "),Dj=a("a"),X4o=o("VisionTextDualEncoderModel"),z4o=o(" (VisionTextDualEncoder model)"),W4o=l(),u_=a("li"),bce=a("strong"),Q4o=o("visual_bert"),H4o=o(" \u2014 "),Gj=a("a"),U4o=o("VisualBertModel"),J4o=o(" (VisualBERT model)"),Y4o=l(),__=a("li"),vce=a("strong"),K4o=o("vit"),Z4o=o(" \u2014 "),Oj=a("a"),eCo=o("ViTModel"),oCo=o(" (ViT model)"),rCo=l(),b_=a("li"),Fce=a("strong"),tCo=o("vit_mae"),aCo=o(" \u2014 "),Vj=a("a"),nCo=o("ViTMAEModel"),sCo=o(" (ViTMAE model)"),lCo=l(),v_=a("li"),Tce=a("strong"),iCo=o("wav2vec2"),dCo=o(" \u2014 "),Xj=a("a"),cCo=o("Wav2Vec2Model"),fCo=o(" (Wav2Vec2 model)"),mCo=l(),F_=a("li"),Mce=a("strong"),gCo=o("wav2vec2-conformer"),hCo=o(" \u2014 "),zj=a("a"),pCo=o("Wav2Vec2ConformerModel"),uCo=o(" (Wav2Vec2-Conformer model)"),_Co=l(),T_=a("li"),Ece=a("strong"),bCo=o("wavlm"),vCo=o(" \u2014 "),Wj=a("a"),FCo=o("WavLMModel"),TCo=o(" (WavLM model)"),MCo=l(),M_=a("li"),Cce=a("strong"),ECo=o("xglm"),CCo=o(" \u2014 "),Qj=a("a"),wCo=o("XGLMModel"),ACo=o(" (XGLM model)"),LCo=l(),E_=a("li"),wce=a("strong"),yCo=o("xlm"),xCo=o(" \u2014 "),Hj=a("a"),$Co=o("XLMModel"),kCo=o(" (XLM model)"),SCo=l(),C_=a("li"),Ace=a("strong"),RCo=o("xlm-prophetnet"),PCo=o(" \u2014 "),Uj=a("a"),BCo=o("XLMProphetNetModel"),ICo=o(" (XLM-ProphetNet model)"),NCo=l(),w_=a("li"),Lce=a("strong"),qCo=o("xlm-roberta"),jCo=o(" \u2014 "),Jj=a("a"),DCo=o("XLMRobertaModel"),GCo=o(" (XLM-RoBERTa model)"),OCo=l(),A_=a("li"),yce=a("strong"),VCo=o("xlm-roberta-xl"),XCo=o(" \u2014 "),Yj=a("a"),zCo=o("XLMRobertaXLModel"),WCo=o(" (XLM-RoBERTa-XL model)"),QCo=l(),L_=a("li"),xce=a("strong"),HCo=o("xlnet"),UCo=o(" \u2014 "),Kj=a("a"),JCo=o("XLNetModel"),YCo=o(" (XLNet model)"),KCo=l(),y_=a("li"),$ce=a("strong"),ZCo=o("yolos"),e5o=o(" \u2014 "),Zj=a("a"),o5o=o("YolosModel"),r5o=o(" (YOLOS model)"),t5o=l(),x_=a("li"),kce=a("strong"),a5o=o("yoso"),n5o=o(" \u2014 "),eD=a("a"),s5o=o("YosoModel"),l5o=o(" (YOSO model)"),i5o=l(),$_=a("p"),d5o=o("The model is set in evaluation mode by default using "),Sce=a("code"),c5o=o("model.eval()"),f5o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rce=a("code"),m5o=o("model.train()"),g5o=l(),F(k_.$$.fragment),PGe=l(),qi=a("h2"),S_=a("a"),Pce=a("span"),F(oy.$$.fragment),h5o=l(),Bce=a("span"),p5o=o("AutoModelForPreTraining"),BGe=l(),$o=a("div"),F(ry.$$.fragment),u5o=l(),ji=a("p"),_5o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),oD=a("a"),b5o=o("from_pretrained()"),v5o=o(" class method or the "),rD=a("a"),F5o=o("from_config()"),T5o=o(` class
method.`),M5o=l(),ty=a("p"),E5o=o("This class cannot be instantiated directly using "),Ice=a("code"),C5o=o("__init__()"),w5o=o(" (throws an error)."),A5o=l(),st=a("div"),F(ay.$$.fragment),L5o=l(),Nce=a("p"),y5o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),x5o=l(),Di=a("p"),$5o=o(`Note:
Loading a model from its configuration file does `),qce=a("strong"),k5o=o("not"),S5o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tD=a("a"),R5o=o("from_pretrained()"),P5o=o(" to load the model weights."),B5o=l(),F(R_.$$.fragment),I5o=l(),Ye=a("div"),F(ny.$$.fragment),N5o=l(),jce=a("p"),q5o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),j5o=l(),Ra=a("p"),D5o=o("The model class to instantiate is selected based on the "),Dce=a("code"),G5o=o("model_type"),O5o=o(` property of the config object (either
passed as an argument or loaded from `),Gce=a("code"),V5o=o("pretrained_model_name_or_path"),X5o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oce=a("code"),z5o=o("pretrained_model_name_or_path"),W5o=o(":"),Q5o=l(),G=a("ul"),P_=a("li"),Vce=a("strong"),H5o=o("albert"),U5o=o(" \u2014 "),aD=a("a"),J5o=o("AlbertForPreTraining"),Y5o=o(" (ALBERT model)"),K5o=l(),B_=a("li"),Xce=a("strong"),Z5o=o("bart"),e0o=o(" \u2014 "),nD=a("a"),o0o=o("BartForConditionalGeneration"),r0o=o(" (BART model)"),t0o=l(),I_=a("li"),zce=a("strong"),a0o=o("bert"),n0o=o(" \u2014 "),sD=a("a"),s0o=o("BertForPreTraining"),l0o=o(" (BERT model)"),i0o=l(),N_=a("li"),Wce=a("strong"),d0o=o("big_bird"),c0o=o(" \u2014 "),lD=a("a"),f0o=o("BigBirdForPreTraining"),m0o=o(" (BigBird model)"),g0o=l(),q_=a("li"),Qce=a("strong"),h0o=o("bloom"),p0o=o(" \u2014 "),iD=a("a"),u0o=o("BloomForCausalLM"),_0o=o(" (BLOOM model)"),b0o=l(),j_=a("li"),Hce=a("strong"),v0o=o("camembert"),F0o=o(" \u2014 "),dD=a("a"),T0o=o("CamembertForMaskedLM"),M0o=o(" (CamemBERT model)"),E0o=l(),D_=a("li"),Uce=a("strong"),C0o=o("ctrl"),w0o=o(" \u2014 "),cD=a("a"),A0o=o("CTRLLMHeadModel"),L0o=o(" (CTRL model)"),y0o=l(),G_=a("li"),Jce=a("strong"),x0o=o("data2vec-text"),$0o=o(" \u2014 "),fD=a("a"),k0o=o("Data2VecTextForMaskedLM"),S0o=o(" (Data2VecText model)"),R0o=l(),O_=a("li"),Yce=a("strong"),P0o=o("deberta"),B0o=o(" \u2014 "),mD=a("a"),I0o=o("DebertaForMaskedLM"),N0o=o(" (DeBERTa model)"),q0o=l(),V_=a("li"),Kce=a("strong"),j0o=o("deberta-v2"),D0o=o(" \u2014 "),gD=a("a"),G0o=o("DebertaV2ForMaskedLM"),O0o=o(" (DeBERTa-v2 model)"),V0o=l(),X_=a("li"),Zce=a("strong"),X0o=o("distilbert"),z0o=o(" \u2014 "),hD=a("a"),W0o=o("DistilBertForMaskedLM"),Q0o=o(" (DistilBERT model)"),H0o=l(),z_=a("li"),efe=a("strong"),U0o=o("electra"),J0o=o(" \u2014 "),pD=a("a"),Y0o=o("ElectraForPreTraining"),K0o=o(" (ELECTRA model)"),Z0o=l(),W_=a("li"),ofe=a("strong"),ewo=o("flaubert"),owo=o(" \u2014 "),uD=a("a"),rwo=o("FlaubertWithLMHeadModel"),two=o(" (FlauBERT model)"),awo=l(),Q_=a("li"),rfe=a("strong"),nwo=o("flava"),swo=o(" \u2014 "),_D=a("a"),lwo=o("FlavaForPreTraining"),iwo=o(" (FLAVA model)"),dwo=l(),H_=a("li"),tfe=a("strong"),cwo=o("fnet"),fwo=o(" \u2014 "),bD=a("a"),mwo=o("FNetForPreTraining"),gwo=o(" (FNet model)"),hwo=l(),U_=a("li"),afe=a("strong"),pwo=o("fsmt"),uwo=o(" \u2014 "),vD=a("a"),_wo=o("FSMTForConditionalGeneration"),bwo=o(" (FairSeq Machine-Translation model)"),vwo=l(),J_=a("li"),nfe=a("strong"),Fwo=o("funnel"),Two=o(" \u2014 "),FD=a("a"),Mwo=o("FunnelForPreTraining"),Ewo=o(" (Funnel Transformer model)"),Cwo=l(),Y_=a("li"),sfe=a("strong"),wwo=o("gpt2"),Awo=o(" \u2014 "),TD=a("a"),Lwo=o("GPT2LMHeadModel"),ywo=o(" (OpenAI GPT-2 model)"),xwo=l(),K_=a("li"),lfe=a("strong"),$wo=o("ibert"),kwo=o(" \u2014 "),MD=a("a"),Swo=o("IBertForMaskedLM"),Rwo=o(" (I-BERT model)"),Pwo=l(),Z_=a("li"),ife=a("strong"),Bwo=o("layoutlm"),Iwo=o(" \u2014 "),ED=a("a"),Nwo=o("LayoutLMForMaskedLM"),qwo=o(" (LayoutLM model)"),jwo=l(),e1=a("li"),dfe=a("strong"),Dwo=o("longformer"),Gwo=o(" \u2014 "),CD=a("a"),Owo=o("LongformerForMaskedLM"),Vwo=o(" (Longformer model)"),Xwo=l(),o1=a("li"),cfe=a("strong"),zwo=o("lxmert"),Wwo=o(" \u2014 "),wD=a("a"),Qwo=o("LxmertForPreTraining"),Hwo=o(" (LXMERT model)"),Uwo=l(),r1=a("li"),ffe=a("strong"),Jwo=o("megatron-bert"),Ywo=o(" \u2014 "),AD=a("a"),Kwo=o("MegatronBertForPreTraining"),Zwo=o(" (Megatron-BERT model)"),eAo=l(),t1=a("li"),mfe=a("strong"),oAo=o("mobilebert"),rAo=o(" \u2014 "),LD=a("a"),tAo=o("MobileBertForPreTraining"),aAo=o(" (MobileBERT model)"),nAo=l(),a1=a("li"),gfe=a("strong"),sAo=o("mpnet"),lAo=o(" \u2014 "),yD=a("a"),iAo=o("MPNetForMaskedLM"),dAo=o(" (MPNet model)"),cAo=l(),n1=a("li"),hfe=a("strong"),fAo=o("openai-gpt"),mAo=o(" \u2014 "),xD=a("a"),gAo=o("OpenAIGPTLMHeadModel"),hAo=o(" (OpenAI GPT model)"),pAo=l(),s1=a("li"),pfe=a("strong"),uAo=o("retribert"),_Ao=o(" \u2014 "),$D=a("a"),bAo=o("RetriBertModel"),vAo=o(" (RetriBERT model)"),FAo=l(),l1=a("li"),ufe=a("strong"),TAo=o("roberta"),MAo=o(" \u2014 "),kD=a("a"),EAo=o("RobertaForMaskedLM"),CAo=o(" (RoBERTa model)"),wAo=l(),i1=a("li"),_fe=a("strong"),AAo=o("splinter"),LAo=o(" \u2014 "),SD=a("a"),yAo=o("SplinterForPreTraining"),xAo=o(" (Splinter model)"),$Ao=l(),d1=a("li"),bfe=a("strong"),kAo=o("squeezebert"),SAo=o(" \u2014 "),RD=a("a"),RAo=o("SqueezeBertForMaskedLM"),PAo=o(" (SqueezeBERT model)"),BAo=l(),c1=a("li"),vfe=a("strong"),IAo=o("t5"),NAo=o(" \u2014 "),PD=a("a"),qAo=o("T5ForConditionalGeneration"),jAo=o(" (T5 model)"),DAo=l(),f1=a("li"),Ffe=a("strong"),GAo=o("tapas"),OAo=o(" \u2014 "),BD=a("a"),VAo=o("TapasForMaskedLM"),XAo=o(" (TAPAS model)"),zAo=l(),m1=a("li"),Tfe=a("strong"),WAo=o("transfo-xl"),QAo=o(" \u2014 "),ID=a("a"),HAo=o("TransfoXLLMHeadModel"),UAo=o(" (Transformer-XL model)"),JAo=l(),g1=a("li"),Mfe=a("strong"),YAo=o("unispeech"),KAo=o(" \u2014 "),ND=a("a"),ZAo=o("UniSpeechForPreTraining"),e6o=o(" (UniSpeech model)"),o6o=l(),h1=a("li"),Efe=a("strong"),r6o=o("unispeech-sat"),t6o=o(" \u2014 "),qD=a("a"),a6o=o("UniSpeechSatForPreTraining"),n6o=o(" (UniSpeechSat model)"),s6o=l(),p1=a("li"),Cfe=a("strong"),l6o=o("visual_bert"),i6o=o(" \u2014 "),jD=a("a"),d6o=o("VisualBertForPreTraining"),c6o=o(" (VisualBERT model)"),f6o=l(),u1=a("li"),wfe=a("strong"),m6o=o("vit_mae"),g6o=o(" \u2014 "),DD=a("a"),h6o=o("ViTMAEForPreTraining"),p6o=o(" (ViTMAE model)"),u6o=l(),_1=a("li"),Afe=a("strong"),_6o=o("wav2vec2"),b6o=o(" \u2014 "),GD=a("a"),v6o=o("Wav2Vec2ForPreTraining"),F6o=o(" (Wav2Vec2 model)"),T6o=l(),b1=a("li"),Lfe=a("strong"),M6o=o("wav2vec2-conformer"),E6o=o(" \u2014 "),OD=a("a"),C6o=o("Wav2Vec2ConformerForPreTraining"),w6o=o(" (Wav2Vec2-Conformer model)"),A6o=l(),v1=a("li"),yfe=a("strong"),L6o=o("xlm"),y6o=o(" \u2014 "),VD=a("a"),x6o=o("XLMWithLMHeadModel"),$6o=o(" (XLM model)"),k6o=l(),F1=a("li"),xfe=a("strong"),S6o=o("xlm-roberta"),R6o=o(" \u2014 "),XD=a("a"),P6o=o("XLMRobertaForMaskedLM"),B6o=o(" (XLM-RoBERTa model)"),I6o=l(),T1=a("li"),$fe=a("strong"),N6o=o("xlm-roberta-xl"),q6o=o(" \u2014 "),zD=a("a"),j6o=o("XLMRobertaXLForMaskedLM"),D6o=o(" (XLM-RoBERTa-XL model)"),G6o=l(),M1=a("li"),kfe=a("strong"),O6o=o("xlnet"),V6o=o(" \u2014 "),WD=a("a"),X6o=o("XLNetLMHeadModel"),z6o=o(" (XLNet model)"),W6o=l(),E1=a("p"),Q6o=o("The model is set in evaluation mode by default using "),Sfe=a("code"),H6o=o("model.eval()"),U6o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rfe=a("code"),J6o=o("model.train()"),Y6o=l(),F(C1.$$.fragment),IGe=l(),Gi=a("h2"),w1=a("a"),Pfe=a("span"),F(sy.$$.fragment),K6o=l(),Bfe=a("span"),Z6o=o("AutoModelForCausalLM"),NGe=l(),ko=a("div"),F(ly.$$.fragment),eLo=l(),Oi=a("p"),oLo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),QD=a("a"),rLo=o("from_pretrained()"),tLo=o(" class method or the "),HD=a("a"),aLo=o("from_config()"),nLo=o(` class
method.`),sLo=l(),iy=a("p"),lLo=o("This class cannot be instantiated directly using "),Ife=a("code"),iLo=o("__init__()"),dLo=o(" (throws an error)."),cLo=l(),lt=a("div"),F(dy.$$.fragment),fLo=l(),Nfe=a("p"),mLo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),gLo=l(),Vi=a("p"),hLo=o(`Note:
Loading a model from its configuration file does `),qfe=a("strong"),pLo=o("not"),uLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UD=a("a"),_Lo=o("from_pretrained()"),bLo=o(" to load the model weights."),vLo=l(),F(A1.$$.fragment),FLo=l(),Ke=a("div"),F(cy.$$.fragment),TLo=l(),jfe=a("p"),MLo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ELo=l(),Pa=a("p"),CLo=o("The model class to instantiate is selected based on the "),Dfe=a("code"),wLo=o("model_type"),ALo=o(` property of the config object (either
passed as an argument or loaded from `),Gfe=a("code"),LLo=o("pretrained_model_name_or_path"),yLo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ofe=a("code"),xLo=o("pretrained_model_name_or_path"),$Lo=o(":"),kLo=l(),z=a("ul"),L1=a("li"),Vfe=a("strong"),SLo=o("bart"),RLo=o(" \u2014 "),JD=a("a"),PLo=o("BartForCausalLM"),BLo=o(" (BART model)"),ILo=l(),y1=a("li"),Xfe=a("strong"),NLo=o("bert"),qLo=o(" \u2014 "),YD=a("a"),jLo=o("BertLMHeadModel"),DLo=o(" (BERT model)"),GLo=l(),x1=a("li"),zfe=a("strong"),OLo=o("bert-generation"),VLo=o(" \u2014 "),KD=a("a"),XLo=o("BertGenerationDecoder"),zLo=o(" (Bert Generation model)"),WLo=l(),$1=a("li"),Wfe=a("strong"),QLo=o("big_bird"),HLo=o(" \u2014 "),ZD=a("a"),ULo=o("BigBirdForCausalLM"),JLo=o(" (BigBird model)"),YLo=l(),k1=a("li"),Qfe=a("strong"),KLo=o("bigbird_pegasus"),ZLo=o(" \u2014 "),eG=a("a"),eyo=o("BigBirdPegasusForCausalLM"),oyo=o(" (BigBird-Pegasus model)"),ryo=l(),S1=a("li"),Hfe=a("strong"),tyo=o("blenderbot"),ayo=o(" \u2014 "),oG=a("a"),nyo=o("BlenderbotForCausalLM"),syo=o(" (Blenderbot model)"),lyo=l(),R1=a("li"),Ufe=a("strong"),iyo=o("blenderbot-small"),dyo=o(" \u2014 "),rG=a("a"),cyo=o("BlenderbotSmallForCausalLM"),fyo=o(" (BlenderbotSmall model)"),myo=l(),P1=a("li"),Jfe=a("strong"),gyo=o("bloom"),hyo=o(" \u2014 "),tG=a("a"),pyo=o("BloomForCausalLM"),uyo=o(" (BLOOM model)"),_yo=l(),B1=a("li"),Yfe=a("strong"),byo=o("camembert"),vyo=o(" \u2014 "),aG=a("a"),Fyo=o("CamembertForCausalLM"),Tyo=o(" (CamemBERT model)"),Myo=l(),I1=a("li"),Kfe=a("strong"),Eyo=o("ctrl"),Cyo=o(" \u2014 "),nG=a("a"),wyo=o("CTRLLMHeadModel"),Ayo=o(" (CTRL model)"),Lyo=l(),N1=a("li"),Zfe=a("strong"),yyo=o("data2vec-text"),xyo=o(" \u2014 "),sG=a("a"),$yo=o("Data2VecTextForCausalLM"),kyo=o(" (Data2VecText model)"),Syo=l(),q1=a("li"),eme=a("strong"),Ryo=o("electra"),Pyo=o(" \u2014 "),lG=a("a"),Byo=o("ElectraForCausalLM"),Iyo=o(" (ELECTRA model)"),Nyo=l(),j1=a("li"),ome=a("strong"),qyo=o("gpt2"),jyo=o(" \u2014 "),iG=a("a"),Dyo=o("GPT2LMHeadModel"),Gyo=o(" (OpenAI GPT-2 model)"),Oyo=l(),D1=a("li"),rme=a("strong"),Vyo=o("gpt_neo"),Xyo=o(" \u2014 "),dG=a("a"),zyo=o("GPTNeoForCausalLM"),Wyo=o(" (GPT Neo model)"),Qyo=l(),G1=a("li"),tme=a("strong"),Hyo=o("gpt_neox"),Uyo=o(" \u2014 "),cG=a("a"),Jyo=o("GPTNeoXForCausalLM"),Yyo=o(" (GPT NeoX model)"),Kyo=l(),O1=a("li"),ame=a("strong"),Zyo=o("gptj"),e8o=o(" \u2014 "),fG=a("a"),o8o=o("GPTJForCausalLM"),r8o=o(" (GPT-J model)"),t8o=l(),V1=a("li"),nme=a("strong"),a8o=o("marian"),n8o=o(" \u2014 "),mG=a("a"),s8o=o("MarianForCausalLM"),l8o=o(" (Marian model)"),i8o=l(),X1=a("li"),sme=a("strong"),d8o=o("mbart"),c8o=o(" \u2014 "),gG=a("a"),f8o=o("MBartForCausalLM"),m8o=o(" (mBART model)"),g8o=l(),z1=a("li"),lme=a("strong"),h8o=o("megatron-bert"),p8o=o(" \u2014 "),hG=a("a"),u8o=o("MegatronBertForCausalLM"),_8o=o(" (Megatron-BERT model)"),b8o=l(),W1=a("li"),ime=a("strong"),v8o=o("openai-gpt"),F8o=o(" \u2014 "),pG=a("a"),T8o=o("OpenAIGPTLMHeadModel"),M8o=o(" (OpenAI GPT model)"),E8o=l(),Q1=a("li"),dme=a("strong"),C8o=o("opt"),w8o=o(" \u2014 "),uG=a("a"),A8o=o("OPTForCausalLM"),L8o=o(" (OPT model)"),y8o=l(),H1=a("li"),cme=a("strong"),x8o=o("pegasus"),$8o=o(" \u2014 "),_G=a("a"),k8o=o("PegasusForCausalLM"),S8o=o(" (Pegasus model)"),R8o=l(),U1=a("li"),fme=a("strong"),P8o=o("plbart"),B8o=o(" \u2014 "),bG=a("a"),I8o=o("PLBartForCausalLM"),N8o=o(" (PLBart model)"),q8o=l(),J1=a("li"),mme=a("strong"),j8o=o("prophetnet"),D8o=o(" \u2014 "),vG=a("a"),G8o=o("ProphetNetForCausalLM"),O8o=o(" (ProphetNet model)"),V8o=l(),Y1=a("li"),gme=a("strong"),X8o=o("qdqbert"),z8o=o(" \u2014 "),FG=a("a"),W8o=o("QDQBertLMHeadModel"),Q8o=o(" (QDQBert model)"),H8o=l(),K1=a("li"),hme=a("strong"),U8o=o("reformer"),J8o=o(" \u2014 "),TG=a("a"),Y8o=o("ReformerModelWithLMHead"),K8o=o(" (Reformer model)"),Z8o=l(),Z1=a("li"),pme=a("strong"),e9o=o("rembert"),o9o=o(" \u2014 "),MG=a("a"),r9o=o("RemBertForCausalLM"),t9o=o(" (RemBERT model)"),a9o=l(),e3=a("li"),ume=a("strong"),n9o=o("roberta"),s9o=o(" \u2014 "),EG=a("a"),l9o=o("RobertaForCausalLM"),i9o=o(" (RoBERTa model)"),d9o=l(),o3=a("li"),_me=a("strong"),c9o=o("roformer"),f9o=o(" \u2014 "),CG=a("a"),m9o=o("RoFormerForCausalLM"),g9o=o(" (RoFormer model)"),h9o=l(),r3=a("li"),bme=a("strong"),p9o=o("speech_to_text_2"),u9o=o(" \u2014 "),wG=a("a"),_9o=o("Speech2Text2ForCausalLM"),b9o=o(" (Speech2Text2 model)"),v9o=l(),t3=a("li"),vme=a("strong"),F9o=o("transfo-xl"),T9o=o(" \u2014 "),AG=a("a"),M9o=o("TransfoXLLMHeadModel"),E9o=o(" (Transformer-XL model)"),C9o=l(),a3=a("li"),Fme=a("strong"),w9o=o("trocr"),A9o=o(" \u2014 "),LG=a("a"),L9o=o("TrOCRForCausalLM"),y9o=o(" (TrOCR model)"),x9o=l(),n3=a("li"),Tme=a("strong"),$9o=o("xglm"),k9o=o(" \u2014 "),yG=a("a"),S9o=o("XGLMForCausalLM"),R9o=o(" (XGLM model)"),P9o=l(),s3=a("li"),Mme=a("strong"),B9o=o("xlm"),I9o=o(" \u2014 "),xG=a("a"),N9o=o("XLMWithLMHeadModel"),q9o=o(" (XLM model)"),j9o=l(),l3=a("li"),Eme=a("strong"),D9o=o("xlm-prophetnet"),G9o=o(" \u2014 "),$G=a("a"),O9o=o("XLMProphetNetForCausalLM"),V9o=o(" (XLM-ProphetNet model)"),X9o=l(),i3=a("li"),Cme=a("strong"),z9o=o("xlm-roberta"),W9o=o(" \u2014 "),kG=a("a"),Q9o=o("XLMRobertaForCausalLM"),H9o=o(" (XLM-RoBERTa model)"),U9o=l(),d3=a("li"),wme=a("strong"),J9o=o("xlm-roberta-xl"),Y9o=o(" \u2014 "),SG=a("a"),K9o=o("XLMRobertaXLForCausalLM"),Z9o=o(" (XLM-RoBERTa-XL model)"),exo=l(),c3=a("li"),Ame=a("strong"),oxo=o("xlnet"),rxo=o(" \u2014 "),RG=a("a"),txo=o("XLNetLMHeadModel"),axo=o(" (XLNet model)"),nxo=l(),f3=a("p"),sxo=o("The model is set in evaluation mode by default using "),Lme=a("code"),lxo=o("model.eval()"),ixo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yme=a("code"),dxo=o("model.train()"),cxo=l(),F(m3.$$.fragment),qGe=l(),Xi=a("h2"),g3=a("a"),xme=a("span"),F(fy.$$.fragment),fxo=l(),$me=a("span"),mxo=o("AutoModelForMaskedLM"),jGe=l(),So=a("div"),F(my.$$.fragment),gxo=l(),zi=a("p"),hxo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PG=a("a"),pxo=o("from_pretrained()"),uxo=o(" class method or the "),BG=a("a"),_xo=o("from_config()"),bxo=o(` class
method.`),vxo=l(),gy=a("p"),Fxo=o("This class cannot be instantiated directly using "),kme=a("code"),Txo=o("__init__()"),Mxo=o(" (throws an error)."),Exo=l(),it=a("div"),F(hy.$$.fragment),Cxo=l(),Sme=a("p"),wxo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Axo=l(),Wi=a("p"),Lxo=o(`Note:
Loading a model from its configuration file does `),Rme=a("strong"),yxo=o("not"),xxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IG=a("a"),$xo=o("from_pretrained()"),kxo=o(" to load the model weights."),Sxo=l(),F(h3.$$.fragment),Rxo=l(),Ze=a("div"),F(py.$$.fragment),Pxo=l(),Pme=a("p"),Bxo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Ixo=l(),Ba=a("p"),Nxo=o("The model class to instantiate is selected based on the "),Bme=a("code"),qxo=o("model_type"),jxo=o(` property of the config object (either
passed as an argument or loaded from `),Ime=a("code"),Dxo=o("pretrained_model_name_or_path"),Gxo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nme=a("code"),Oxo=o("pretrained_model_name_or_path"),Vxo=o(":"),Xxo=l(),Q=a("ul"),p3=a("li"),qme=a("strong"),zxo=o("albert"),Wxo=o(" \u2014 "),NG=a("a"),Qxo=o("AlbertForMaskedLM"),Hxo=o(" (ALBERT model)"),Uxo=l(),u3=a("li"),jme=a("strong"),Jxo=o("bart"),Yxo=o(" \u2014 "),qG=a("a"),Kxo=o("BartForConditionalGeneration"),Zxo=o(" (BART model)"),e$o=l(),_3=a("li"),Dme=a("strong"),o$o=o("bert"),r$o=o(" \u2014 "),jG=a("a"),t$o=o("BertForMaskedLM"),a$o=o(" (BERT model)"),n$o=l(),b3=a("li"),Gme=a("strong"),s$o=o("big_bird"),l$o=o(" \u2014 "),DG=a("a"),i$o=o("BigBirdForMaskedLM"),d$o=o(" (BigBird model)"),c$o=l(),v3=a("li"),Ome=a("strong"),f$o=o("camembert"),m$o=o(" \u2014 "),GG=a("a"),g$o=o("CamembertForMaskedLM"),h$o=o(" (CamemBERT model)"),p$o=l(),F3=a("li"),Vme=a("strong"),u$o=o("convbert"),_$o=o(" \u2014 "),OG=a("a"),b$o=o("ConvBertForMaskedLM"),v$o=o(" (ConvBERT model)"),F$o=l(),T3=a("li"),Xme=a("strong"),T$o=o("data2vec-text"),M$o=o(" \u2014 "),VG=a("a"),E$o=o("Data2VecTextForMaskedLM"),C$o=o(" (Data2VecText model)"),w$o=l(),M3=a("li"),zme=a("strong"),A$o=o("deberta"),L$o=o(" \u2014 "),XG=a("a"),y$o=o("DebertaForMaskedLM"),x$o=o(" (DeBERTa model)"),$$o=l(),E3=a("li"),Wme=a("strong"),k$o=o("deberta-v2"),S$o=o(" \u2014 "),zG=a("a"),R$o=o("DebertaV2ForMaskedLM"),P$o=o(" (DeBERTa-v2 model)"),B$o=l(),C3=a("li"),Qme=a("strong"),I$o=o("distilbert"),N$o=o(" \u2014 "),WG=a("a"),q$o=o("DistilBertForMaskedLM"),j$o=o(" (DistilBERT model)"),D$o=l(),w3=a("li"),Hme=a("strong"),G$o=o("electra"),O$o=o(" \u2014 "),QG=a("a"),V$o=o("ElectraForMaskedLM"),X$o=o(" (ELECTRA model)"),z$o=l(),A3=a("li"),Ume=a("strong"),W$o=o("flaubert"),Q$o=o(" \u2014 "),HG=a("a"),H$o=o("FlaubertWithLMHeadModel"),U$o=o(" (FlauBERT model)"),J$o=l(),L3=a("li"),Jme=a("strong"),Y$o=o("fnet"),K$o=o(" \u2014 "),UG=a("a"),Z$o=o("FNetForMaskedLM"),eko=o(" (FNet model)"),oko=l(),y3=a("li"),Yme=a("strong"),rko=o("funnel"),tko=o(" \u2014 "),JG=a("a"),ako=o("FunnelForMaskedLM"),nko=o(" (Funnel Transformer model)"),sko=l(),x3=a("li"),Kme=a("strong"),lko=o("ibert"),iko=o(" \u2014 "),YG=a("a"),dko=o("IBertForMaskedLM"),cko=o(" (I-BERT model)"),fko=l(),$3=a("li"),Zme=a("strong"),mko=o("layoutlm"),gko=o(" \u2014 "),KG=a("a"),hko=o("LayoutLMForMaskedLM"),pko=o(" (LayoutLM model)"),uko=l(),k3=a("li"),ege=a("strong"),_ko=o("longformer"),bko=o(" \u2014 "),ZG=a("a"),vko=o("LongformerForMaskedLM"),Fko=o(" (Longformer model)"),Tko=l(),S3=a("li"),oge=a("strong"),Mko=o("luke"),Eko=o(" \u2014 "),eO=a("a"),Cko=o("LukeForMaskedLM"),wko=o(" (LUKE model)"),Ako=l(),R3=a("li"),rge=a("strong"),Lko=o("mbart"),yko=o(" \u2014 "),oO=a("a"),xko=o("MBartForConditionalGeneration"),$ko=o(" (mBART model)"),kko=l(),P3=a("li"),tge=a("strong"),Sko=o("megatron-bert"),Rko=o(" \u2014 "),rO=a("a"),Pko=o("MegatronBertForMaskedLM"),Bko=o(" (Megatron-BERT model)"),Iko=l(),B3=a("li"),age=a("strong"),Nko=o("mobilebert"),qko=o(" \u2014 "),tO=a("a"),jko=o("MobileBertForMaskedLM"),Dko=o(" (MobileBERT model)"),Gko=l(),I3=a("li"),nge=a("strong"),Oko=o("mpnet"),Vko=o(" \u2014 "),aO=a("a"),Xko=o("MPNetForMaskedLM"),zko=o(" (MPNet model)"),Wko=l(),N3=a("li"),sge=a("strong"),Qko=o("nystromformer"),Hko=o(" \u2014 "),nO=a("a"),Uko=o("NystromformerForMaskedLM"),Jko=o(" (Nystr\xF6mformer model)"),Yko=l(),q3=a("li"),lge=a("strong"),Kko=o("perceiver"),Zko=o(" \u2014 "),sO=a("a"),eSo=o("PerceiverForMaskedLM"),oSo=o(" (Perceiver model)"),rSo=l(),j3=a("li"),ige=a("strong"),tSo=o("qdqbert"),aSo=o(" \u2014 "),lO=a("a"),nSo=o("QDQBertForMaskedLM"),sSo=o(" (QDQBert model)"),lSo=l(),D3=a("li"),dge=a("strong"),iSo=o("reformer"),dSo=o(" \u2014 "),iO=a("a"),cSo=o("ReformerForMaskedLM"),fSo=o(" (Reformer model)"),mSo=l(),G3=a("li"),cge=a("strong"),gSo=o("rembert"),hSo=o(" \u2014 "),dO=a("a"),pSo=o("RemBertForMaskedLM"),uSo=o(" (RemBERT model)"),_So=l(),O3=a("li"),fge=a("strong"),bSo=o("roberta"),vSo=o(" \u2014 "),cO=a("a"),FSo=o("RobertaForMaskedLM"),TSo=o(" (RoBERTa model)"),MSo=l(),V3=a("li"),mge=a("strong"),ESo=o("roformer"),CSo=o(" \u2014 "),fO=a("a"),wSo=o("RoFormerForMaskedLM"),ASo=o(" (RoFormer model)"),LSo=l(),X3=a("li"),gge=a("strong"),ySo=o("squeezebert"),xSo=o(" \u2014 "),mO=a("a"),$So=o("SqueezeBertForMaskedLM"),kSo=o(" (SqueezeBERT model)"),SSo=l(),z3=a("li"),hge=a("strong"),RSo=o("tapas"),PSo=o(" \u2014 "),gO=a("a"),BSo=o("TapasForMaskedLM"),ISo=o(" (TAPAS model)"),NSo=l(),W3=a("li"),pge=a("strong"),qSo=o("wav2vec2"),jSo=o(" \u2014 "),uge=a("code"),DSo=o("Wav2Vec2ForMaskedLM"),GSo=o(" (Wav2Vec2 model)"),OSo=l(),Q3=a("li"),_ge=a("strong"),VSo=o("xlm"),XSo=o(" \u2014 "),hO=a("a"),zSo=o("XLMWithLMHeadModel"),WSo=o(" (XLM model)"),QSo=l(),H3=a("li"),bge=a("strong"),HSo=o("xlm-roberta"),USo=o(" \u2014 "),pO=a("a"),JSo=o("XLMRobertaForMaskedLM"),YSo=o(" (XLM-RoBERTa model)"),KSo=l(),U3=a("li"),vge=a("strong"),ZSo=o("xlm-roberta-xl"),eRo=o(" \u2014 "),uO=a("a"),oRo=o("XLMRobertaXLForMaskedLM"),rRo=o(" (XLM-RoBERTa-XL model)"),tRo=l(),J3=a("li"),Fge=a("strong"),aRo=o("yoso"),nRo=o(" \u2014 "),_O=a("a"),sRo=o("YosoForMaskedLM"),lRo=o(" (YOSO model)"),iRo=l(),Y3=a("p"),dRo=o("The model is set in evaluation mode by default using "),Tge=a("code"),cRo=o("model.eval()"),fRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mge=a("code"),mRo=o("model.train()"),gRo=l(),F(K3.$$.fragment),DGe=l(),Qi=a("h2"),Z3=a("a"),Ege=a("span"),F(uy.$$.fragment),hRo=l(),Cge=a("span"),pRo=o("AutoModelForSeq2SeqLM"),GGe=l(),Ro=a("div"),F(_y.$$.fragment),uRo=l(),Hi=a("p"),_Ro=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),bO=a("a"),bRo=o("from_pretrained()"),vRo=o(" class method or the "),vO=a("a"),FRo=o("from_config()"),TRo=o(` class
method.`),MRo=l(),by=a("p"),ERo=o("This class cannot be instantiated directly using "),wge=a("code"),CRo=o("__init__()"),wRo=o(" (throws an error)."),ARo=l(),dt=a("div"),F(vy.$$.fragment),LRo=l(),Age=a("p"),yRo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),xRo=l(),Ui=a("p"),$Ro=o(`Note:
Loading a model from its configuration file does `),Lge=a("strong"),kRo=o("not"),SRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FO=a("a"),RRo=o("from_pretrained()"),PRo=o(" to load the model weights."),BRo=l(),F(e2.$$.fragment),IRo=l(),eo=a("div"),F(Fy.$$.fragment),NRo=l(),yge=a("p"),qRo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),jRo=l(),Ia=a("p"),DRo=o("The model class to instantiate is selected based on the "),xge=a("code"),GRo=o("model_type"),ORo=o(` property of the config object (either
passed as an argument or loaded from `),$ge=a("code"),VRo=o("pretrained_model_name_or_path"),XRo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kge=a("code"),zRo=o("pretrained_model_name_or_path"),WRo=o(":"),QRo=l(),pe=a("ul"),o2=a("li"),Sge=a("strong"),HRo=o("bart"),URo=o(" \u2014 "),TO=a("a"),JRo=o("BartForConditionalGeneration"),YRo=o(" (BART model)"),KRo=l(),r2=a("li"),Rge=a("strong"),ZRo=o("bigbird_pegasus"),ePo=o(" \u2014 "),MO=a("a"),oPo=o("BigBirdPegasusForConditionalGeneration"),rPo=o(" (BigBird-Pegasus model)"),tPo=l(),t2=a("li"),Pge=a("strong"),aPo=o("blenderbot"),nPo=o(" \u2014 "),EO=a("a"),sPo=o("BlenderbotForConditionalGeneration"),lPo=o(" (Blenderbot model)"),iPo=l(),a2=a("li"),Bge=a("strong"),dPo=o("blenderbot-small"),cPo=o(" \u2014 "),CO=a("a"),fPo=o("BlenderbotSmallForConditionalGeneration"),mPo=o(" (BlenderbotSmall model)"),gPo=l(),n2=a("li"),Ige=a("strong"),hPo=o("encoder-decoder"),pPo=o(" \u2014 "),wO=a("a"),uPo=o("EncoderDecoderModel"),_Po=o(" (Encoder decoder model)"),bPo=l(),s2=a("li"),Nge=a("strong"),vPo=o("fsmt"),FPo=o(" \u2014 "),AO=a("a"),TPo=o("FSMTForConditionalGeneration"),MPo=o(" (FairSeq Machine-Translation model)"),EPo=l(),l2=a("li"),qge=a("strong"),CPo=o("led"),wPo=o(" \u2014 "),LO=a("a"),APo=o("LEDForConditionalGeneration"),LPo=o(" (LED model)"),yPo=l(),i2=a("li"),jge=a("strong"),xPo=o("longt5"),$Po=o(" \u2014 "),yO=a("a"),kPo=o("LongT5ForConditionalGeneration"),SPo=o(" (LongT5 model)"),RPo=l(),d2=a("li"),Dge=a("strong"),PPo=o("m2m_100"),BPo=o(" \u2014 "),xO=a("a"),IPo=o("M2M100ForConditionalGeneration"),NPo=o(" (M2M100 model)"),qPo=l(),c2=a("li"),Gge=a("strong"),jPo=o("marian"),DPo=o(" \u2014 "),$O=a("a"),GPo=o("MarianMTModel"),OPo=o(" (Marian model)"),VPo=l(),f2=a("li"),Oge=a("strong"),XPo=o("mbart"),zPo=o(" \u2014 "),kO=a("a"),WPo=o("MBartForConditionalGeneration"),QPo=o(" (mBART model)"),HPo=l(),m2=a("li"),Vge=a("strong"),UPo=o("mt5"),JPo=o(" \u2014 "),SO=a("a"),YPo=o("MT5ForConditionalGeneration"),KPo=o(" (MT5 model)"),ZPo=l(),g2=a("li"),Xge=a("strong"),eBo=o("pegasus"),oBo=o(" \u2014 "),RO=a("a"),rBo=o("PegasusForConditionalGeneration"),tBo=o(" (Pegasus model)"),aBo=l(),h2=a("li"),zge=a("strong"),nBo=o("plbart"),sBo=o(" \u2014 "),PO=a("a"),lBo=o("PLBartForConditionalGeneration"),iBo=o(" (PLBart model)"),dBo=l(),p2=a("li"),Wge=a("strong"),cBo=o("prophetnet"),fBo=o(" \u2014 "),BO=a("a"),mBo=o("ProphetNetForConditionalGeneration"),gBo=o(" (ProphetNet model)"),hBo=l(),u2=a("li"),Qge=a("strong"),pBo=o("t5"),uBo=o(" \u2014 "),IO=a("a"),_Bo=o("T5ForConditionalGeneration"),bBo=o(" (T5 model)"),vBo=l(),_2=a("li"),Hge=a("strong"),FBo=o("xlm-prophetnet"),TBo=o(" \u2014 "),NO=a("a"),MBo=o("XLMProphetNetForConditionalGeneration"),EBo=o(" (XLM-ProphetNet model)"),CBo=l(),b2=a("p"),wBo=o("The model is set in evaluation mode by default using "),Uge=a("code"),ABo=o("model.eval()"),LBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jge=a("code"),yBo=o("model.train()"),xBo=l(),F(v2.$$.fragment),OGe=l(),Ji=a("h2"),F2=a("a"),Yge=a("span"),F(Ty.$$.fragment),$Bo=l(),Kge=a("span"),kBo=o("AutoModelForSequenceClassification"),VGe=l(),Po=a("div"),F(My.$$.fragment),SBo=l(),Yi=a("p"),RBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),qO=a("a"),PBo=o("from_pretrained()"),BBo=o(" class method or the "),jO=a("a"),IBo=o("from_config()"),NBo=o(` class
method.`),qBo=l(),Ey=a("p"),jBo=o("This class cannot be instantiated directly using "),Zge=a("code"),DBo=o("__init__()"),GBo=o(" (throws an error)."),OBo=l(),ct=a("div"),F(Cy.$$.fragment),VBo=l(),ehe=a("p"),XBo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),zBo=l(),Ki=a("p"),WBo=o(`Note:
Loading a model from its configuration file does `),ohe=a("strong"),QBo=o("not"),HBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DO=a("a"),UBo=o("from_pretrained()"),JBo=o(" to load the model weights."),YBo=l(),F(T2.$$.fragment),KBo=l(),oo=a("div"),F(wy.$$.fragment),ZBo=l(),rhe=a("p"),eIo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),oIo=l(),Na=a("p"),rIo=o("The model class to instantiate is selected based on the "),the=a("code"),tIo=o("model_type"),aIo=o(` property of the config object (either
passed as an argument or loaded from `),ahe=a("code"),nIo=o("pretrained_model_name_or_path"),sIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nhe=a("code"),lIo=o("pretrained_model_name_or_path"),iIo=o(":"),dIo=l(),N=a("ul"),M2=a("li"),she=a("strong"),cIo=o("albert"),fIo=o(" \u2014 "),GO=a("a"),mIo=o("AlbertForSequenceClassification"),gIo=o(" (ALBERT model)"),hIo=l(),E2=a("li"),lhe=a("strong"),pIo=o("bart"),uIo=o(" \u2014 "),OO=a("a"),_Io=o("BartForSequenceClassification"),bIo=o(" (BART model)"),vIo=l(),C2=a("li"),ihe=a("strong"),FIo=o("bert"),TIo=o(" \u2014 "),VO=a("a"),MIo=o("BertForSequenceClassification"),EIo=o(" (BERT model)"),CIo=l(),w2=a("li"),dhe=a("strong"),wIo=o("big_bird"),AIo=o(" \u2014 "),XO=a("a"),LIo=o("BigBirdForSequenceClassification"),yIo=o(" (BigBird model)"),xIo=l(),A2=a("li"),che=a("strong"),$Io=o("bigbird_pegasus"),kIo=o(" \u2014 "),zO=a("a"),SIo=o("BigBirdPegasusForSequenceClassification"),RIo=o(" (BigBird-Pegasus model)"),PIo=l(),L2=a("li"),fhe=a("strong"),BIo=o("bloom"),IIo=o(" \u2014 "),WO=a("a"),NIo=o("BloomForSequenceClassification"),qIo=o(" (BLOOM model)"),jIo=l(),y2=a("li"),mhe=a("strong"),DIo=o("camembert"),GIo=o(" \u2014 "),QO=a("a"),OIo=o("CamembertForSequenceClassification"),VIo=o(" (CamemBERT model)"),XIo=l(),x2=a("li"),ghe=a("strong"),zIo=o("canine"),WIo=o(" \u2014 "),HO=a("a"),QIo=o("CanineForSequenceClassification"),HIo=o(" (CANINE model)"),UIo=l(),$2=a("li"),hhe=a("strong"),JIo=o("convbert"),YIo=o(" \u2014 "),UO=a("a"),KIo=o("ConvBertForSequenceClassification"),ZIo=o(" (ConvBERT model)"),eNo=l(),k2=a("li"),phe=a("strong"),oNo=o("ctrl"),rNo=o(" \u2014 "),JO=a("a"),tNo=o("CTRLForSequenceClassification"),aNo=o(" (CTRL model)"),nNo=l(),S2=a("li"),uhe=a("strong"),sNo=o("data2vec-text"),lNo=o(" \u2014 "),YO=a("a"),iNo=o("Data2VecTextForSequenceClassification"),dNo=o(" (Data2VecText model)"),cNo=l(),R2=a("li"),_he=a("strong"),fNo=o("deberta"),mNo=o(" \u2014 "),KO=a("a"),gNo=o("DebertaForSequenceClassification"),hNo=o(" (DeBERTa model)"),pNo=l(),P2=a("li"),bhe=a("strong"),uNo=o("deberta-v2"),_No=o(" \u2014 "),ZO=a("a"),bNo=o("DebertaV2ForSequenceClassification"),vNo=o(" (DeBERTa-v2 model)"),FNo=l(),B2=a("li"),vhe=a("strong"),TNo=o("distilbert"),MNo=o(" \u2014 "),eV=a("a"),ENo=o("DistilBertForSequenceClassification"),CNo=o(" (DistilBERT model)"),wNo=l(),I2=a("li"),Fhe=a("strong"),ANo=o("electra"),LNo=o(" \u2014 "),oV=a("a"),yNo=o("ElectraForSequenceClassification"),xNo=o(" (ELECTRA model)"),$No=l(),N2=a("li"),The=a("strong"),kNo=o("flaubert"),SNo=o(" \u2014 "),rV=a("a"),RNo=o("FlaubertForSequenceClassification"),PNo=o(" (FlauBERT model)"),BNo=l(),q2=a("li"),Mhe=a("strong"),INo=o("fnet"),NNo=o(" \u2014 "),tV=a("a"),qNo=o("FNetForSequenceClassification"),jNo=o(" (FNet model)"),DNo=l(),j2=a("li"),Ehe=a("strong"),GNo=o("funnel"),ONo=o(" \u2014 "),aV=a("a"),VNo=o("FunnelForSequenceClassification"),XNo=o(" (Funnel Transformer model)"),zNo=l(),D2=a("li"),Che=a("strong"),WNo=o("gpt2"),QNo=o(" \u2014 "),nV=a("a"),HNo=o("GPT2ForSequenceClassification"),UNo=o(" (OpenAI GPT-2 model)"),JNo=l(),G2=a("li"),whe=a("strong"),YNo=o("gpt_neo"),KNo=o(" \u2014 "),sV=a("a"),ZNo=o("GPTNeoForSequenceClassification"),eqo=o(" (GPT Neo model)"),oqo=l(),O2=a("li"),Ahe=a("strong"),rqo=o("gptj"),tqo=o(" \u2014 "),lV=a("a"),aqo=o("GPTJForSequenceClassification"),nqo=o(" (GPT-J model)"),sqo=l(),V2=a("li"),Lhe=a("strong"),lqo=o("ibert"),iqo=o(" \u2014 "),iV=a("a"),dqo=o("IBertForSequenceClassification"),cqo=o(" (I-BERT model)"),fqo=l(),X2=a("li"),yhe=a("strong"),mqo=o("layoutlm"),gqo=o(" \u2014 "),dV=a("a"),hqo=o("LayoutLMForSequenceClassification"),pqo=o(" (LayoutLM model)"),uqo=l(),z2=a("li"),xhe=a("strong"),_qo=o("layoutlmv2"),bqo=o(" \u2014 "),cV=a("a"),vqo=o("LayoutLMv2ForSequenceClassification"),Fqo=o(" (LayoutLMv2 model)"),Tqo=l(),W2=a("li"),$he=a("strong"),Mqo=o("layoutlmv3"),Eqo=o(" \u2014 "),fV=a("a"),Cqo=o("LayoutLMv3ForSequenceClassification"),wqo=o(" (LayoutLMv3 model)"),Aqo=l(),Q2=a("li"),khe=a("strong"),Lqo=o("led"),yqo=o(" \u2014 "),mV=a("a"),xqo=o("LEDForSequenceClassification"),$qo=o(" (LED model)"),kqo=l(),H2=a("li"),She=a("strong"),Sqo=o("longformer"),Rqo=o(" \u2014 "),gV=a("a"),Pqo=o("LongformerForSequenceClassification"),Bqo=o(" (Longformer model)"),Iqo=l(),U2=a("li"),Rhe=a("strong"),Nqo=o("mbart"),qqo=o(" \u2014 "),hV=a("a"),jqo=o("MBartForSequenceClassification"),Dqo=o(" (mBART model)"),Gqo=l(),J2=a("li"),Phe=a("strong"),Oqo=o("megatron-bert"),Vqo=o(" \u2014 "),pV=a("a"),Xqo=o("MegatronBertForSequenceClassification"),zqo=o(" (Megatron-BERT model)"),Wqo=l(),Y2=a("li"),Bhe=a("strong"),Qqo=o("mobilebert"),Hqo=o(" \u2014 "),uV=a("a"),Uqo=o("MobileBertForSequenceClassification"),Jqo=o(" (MobileBERT model)"),Yqo=l(),K2=a("li"),Ihe=a("strong"),Kqo=o("mpnet"),Zqo=o(" \u2014 "),_V=a("a"),ejo=o("MPNetForSequenceClassification"),ojo=o(" (MPNet model)"),rjo=l(),Z2=a("li"),Nhe=a("strong"),tjo=o("nystromformer"),ajo=o(" \u2014 "),bV=a("a"),njo=o("NystromformerForSequenceClassification"),sjo=o(" (Nystr\xF6mformer model)"),ljo=l(),eb=a("li"),qhe=a("strong"),ijo=o("openai-gpt"),djo=o(" \u2014 "),vV=a("a"),cjo=o("OpenAIGPTForSequenceClassification"),fjo=o(" (OpenAI GPT model)"),mjo=l(),ob=a("li"),jhe=a("strong"),gjo=o("perceiver"),hjo=o(" \u2014 "),FV=a("a"),pjo=o("PerceiverForSequenceClassification"),ujo=o(" (Perceiver model)"),_jo=l(),rb=a("li"),Dhe=a("strong"),bjo=o("plbart"),vjo=o(" \u2014 "),TV=a("a"),Fjo=o("PLBartForSequenceClassification"),Tjo=o(" (PLBart model)"),Mjo=l(),tb=a("li"),Ghe=a("strong"),Ejo=o("qdqbert"),Cjo=o(" \u2014 "),MV=a("a"),wjo=o("QDQBertForSequenceClassification"),Ajo=o(" (QDQBert model)"),Ljo=l(),ab=a("li"),Ohe=a("strong"),yjo=o("reformer"),xjo=o(" \u2014 "),EV=a("a"),$jo=o("ReformerForSequenceClassification"),kjo=o(" (Reformer model)"),Sjo=l(),nb=a("li"),Vhe=a("strong"),Rjo=o("rembert"),Pjo=o(" \u2014 "),CV=a("a"),Bjo=o("RemBertForSequenceClassification"),Ijo=o(" (RemBERT model)"),Njo=l(),sb=a("li"),Xhe=a("strong"),qjo=o("roberta"),jjo=o(" \u2014 "),wV=a("a"),Djo=o("RobertaForSequenceClassification"),Gjo=o(" (RoBERTa model)"),Ojo=l(),lb=a("li"),zhe=a("strong"),Vjo=o("roformer"),Xjo=o(" \u2014 "),AV=a("a"),zjo=o("RoFormerForSequenceClassification"),Wjo=o(" (RoFormer model)"),Qjo=l(),ib=a("li"),Whe=a("strong"),Hjo=o("squeezebert"),Ujo=o(" \u2014 "),LV=a("a"),Jjo=o("SqueezeBertForSequenceClassification"),Yjo=o(" (SqueezeBERT model)"),Kjo=l(),db=a("li"),Qhe=a("strong"),Zjo=o("tapas"),eDo=o(" \u2014 "),yV=a("a"),oDo=o("TapasForSequenceClassification"),rDo=o(" (TAPAS model)"),tDo=l(),cb=a("li"),Hhe=a("strong"),aDo=o("transfo-xl"),nDo=o(" \u2014 "),xV=a("a"),sDo=o("TransfoXLForSequenceClassification"),lDo=o(" (Transformer-XL model)"),iDo=l(),fb=a("li"),Uhe=a("strong"),dDo=o("xlm"),cDo=o(" \u2014 "),$V=a("a"),fDo=o("XLMForSequenceClassification"),mDo=o(" (XLM model)"),gDo=l(),mb=a("li"),Jhe=a("strong"),hDo=o("xlm-roberta"),pDo=o(" \u2014 "),kV=a("a"),uDo=o("XLMRobertaForSequenceClassification"),_Do=o(" (XLM-RoBERTa model)"),bDo=l(),gb=a("li"),Yhe=a("strong"),vDo=o("xlm-roberta-xl"),FDo=o(" \u2014 "),SV=a("a"),TDo=o("XLMRobertaXLForSequenceClassification"),MDo=o(" (XLM-RoBERTa-XL model)"),EDo=l(),hb=a("li"),Khe=a("strong"),CDo=o("xlnet"),wDo=o(" \u2014 "),RV=a("a"),ADo=o("XLNetForSequenceClassification"),LDo=o(" (XLNet model)"),yDo=l(),pb=a("li"),Zhe=a("strong"),xDo=o("yoso"),$Do=o(" \u2014 "),PV=a("a"),kDo=o("YosoForSequenceClassification"),SDo=o(" (YOSO model)"),RDo=l(),ub=a("p"),PDo=o("The model is set in evaluation mode by default using "),epe=a("code"),BDo=o("model.eval()"),IDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ope=a("code"),NDo=o("model.train()"),qDo=l(),F(_b.$$.fragment),XGe=l(),Zi=a("h2"),bb=a("a"),rpe=a("span"),F(Ay.$$.fragment),jDo=l(),tpe=a("span"),DDo=o("AutoModelForMultipleChoice"),zGe=l(),Bo=a("div"),F(Ly.$$.fragment),GDo=l(),ed=a("p"),ODo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),BV=a("a"),VDo=o("from_pretrained()"),XDo=o(" class method or the "),IV=a("a"),zDo=o("from_config()"),WDo=o(` class
method.`),QDo=l(),yy=a("p"),HDo=o("This class cannot be instantiated directly using "),ape=a("code"),UDo=o("__init__()"),JDo=o(" (throws an error)."),YDo=l(),ft=a("div"),F(xy.$$.fragment),KDo=l(),npe=a("p"),ZDo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),eGo=l(),od=a("p"),oGo=o(`Note:
Loading a model from its configuration file does `),spe=a("strong"),rGo=o("not"),tGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NV=a("a"),aGo=o("from_pretrained()"),nGo=o(" to load the model weights."),sGo=l(),F(vb.$$.fragment),lGo=l(),ro=a("div"),F($y.$$.fragment),iGo=l(),lpe=a("p"),dGo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),cGo=l(),qa=a("p"),fGo=o("The model class to instantiate is selected based on the "),ipe=a("code"),mGo=o("model_type"),gGo=o(` property of the config object (either
passed as an argument or loaded from `),dpe=a("code"),hGo=o("pretrained_model_name_or_path"),pGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cpe=a("code"),uGo=o("pretrained_model_name_or_path"),_Go=o(":"),bGo=l(),Z=a("ul"),Fb=a("li"),fpe=a("strong"),vGo=o("albert"),FGo=o(" \u2014 "),qV=a("a"),TGo=o("AlbertForMultipleChoice"),MGo=o(" (ALBERT model)"),EGo=l(),Tb=a("li"),mpe=a("strong"),CGo=o("bert"),wGo=o(" \u2014 "),jV=a("a"),AGo=o("BertForMultipleChoice"),LGo=o(" (BERT model)"),yGo=l(),Mb=a("li"),gpe=a("strong"),xGo=o("big_bird"),$Go=o(" \u2014 "),DV=a("a"),kGo=o("BigBirdForMultipleChoice"),SGo=o(" (BigBird model)"),RGo=l(),Eb=a("li"),hpe=a("strong"),PGo=o("camembert"),BGo=o(" \u2014 "),GV=a("a"),IGo=o("CamembertForMultipleChoice"),NGo=o(" (CamemBERT model)"),qGo=l(),Cb=a("li"),ppe=a("strong"),jGo=o("canine"),DGo=o(" \u2014 "),OV=a("a"),GGo=o("CanineForMultipleChoice"),OGo=o(" (CANINE model)"),VGo=l(),wb=a("li"),upe=a("strong"),XGo=o("convbert"),zGo=o(" \u2014 "),VV=a("a"),WGo=o("ConvBertForMultipleChoice"),QGo=o(" (ConvBERT model)"),HGo=l(),Ab=a("li"),_pe=a("strong"),UGo=o("data2vec-text"),JGo=o(" \u2014 "),XV=a("a"),YGo=o("Data2VecTextForMultipleChoice"),KGo=o(" (Data2VecText model)"),ZGo=l(),Lb=a("li"),bpe=a("strong"),eOo=o("deberta-v2"),oOo=o(" \u2014 "),zV=a("a"),rOo=o("DebertaV2ForMultipleChoice"),tOo=o(" (DeBERTa-v2 model)"),aOo=l(),yb=a("li"),vpe=a("strong"),nOo=o("distilbert"),sOo=o(" \u2014 "),WV=a("a"),lOo=o("DistilBertForMultipleChoice"),iOo=o(" (DistilBERT model)"),dOo=l(),xb=a("li"),Fpe=a("strong"),cOo=o("electra"),fOo=o(" \u2014 "),QV=a("a"),mOo=o("ElectraForMultipleChoice"),gOo=o(" (ELECTRA model)"),hOo=l(),$b=a("li"),Tpe=a("strong"),pOo=o("flaubert"),uOo=o(" \u2014 "),HV=a("a"),_Oo=o("FlaubertForMultipleChoice"),bOo=o(" (FlauBERT model)"),vOo=l(),kb=a("li"),Mpe=a("strong"),FOo=o("fnet"),TOo=o(" \u2014 "),UV=a("a"),MOo=o("FNetForMultipleChoice"),EOo=o(" (FNet model)"),COo=l(),Sb=a("li"),Epe=a("strong"),wOo=o("funnel"),AOo=o(" \u2014 "),JV=a("a"),LOo=o("FunnelForMultipleChoice"),yOo=o(" (Funnel Transformer model)"),xOo=l(),Rb=a("li"),Cpe=a("strong"),$Oo=o("ibert"),kOo=o(" \u2014 "),YV=a("a"),SOo=o("IBertForMultipleChoice"),ROo=o(" (I-BERT model)"),POo=l(),Pb=a("li"),wpe=a("strong"),BOo=o("longformer"),IOo=o(" \u2014 "),KV=a("a"),NOo=o("LongformerForMultipleChoice"),qOo=o(" (Longformer model)"),jOo=l(),Bb=a("li"),Ape=a("strong"),DOo=o("megatron-bert"),GOo=o(" \u2014 "),ZV=a("a"),OOo=o("MegatronBertForMultipleChoice"),VOo=o(" (Megatron-BERT model)"),XOo=l(),Ib=a("li"),Lpe=a("strong"),zOo=o("mobilebert"),WOo=o(" \u2014 "),eX=a("a"),QOo=o("MobileBertForMultipleChoice"),HOo=o(" (MobileBERT model)"),UOo=l(),Nb=a("li"),ype=a("strong"),JOo=o("mpnet"),YOo=o(" \u2014 "),oX=a("a"),KOo=o("MPNetForMultipleChoice"),ZOo=o(" (MPNet model)"),eVo=l(),qb=a("li"),xpe=a("strong"),oVo=o("nystromformer"),rVo=o(" \u2014 "),rX=a("a"),tVo=o("NystromformerForMultipleChoice"),aVo=o(" (Nystr\xF6mformer model)"),nVo=l(),jb=a("li"),$pe=a("strong"),sVo=o("qdqbert"),lVo=o(" \u2014 "),tX=a("a"),iVo=o("QDQBertForMultipleChoice"),dVo=o(" (QDQBert model)"),cVo=l(),Db=a("li"),kpe=a("strong"),fVo=o("rembert"),mVo=o(" \u2014 "),aX=a("a"),gVo=o("RemBertForMultipleChoice"),hVo=o(" (RemBERT model)"),pVo=l(),Gb=a("li"),Spe=a("strong"),uVo=o("roberta"),_Vo=o(" \u2014 "),nX=a("a"),bVo=o("RobertaForMultipleChoice"),vVo=o(" (RoBERTa model)"),FVo=l(),Ob=a("li"),Rpe=a("strong"),TVo=o("roformer"),MVo=o(" \u2014 "),sX=a("a"),EVo=o("RoFormerForMultipleChoice"),CVo=o(" (RoFormer model)"),wVo=l(),Vb=a("li"),Ppe=a("strong"),AVo=o("squeezebert"),LVo=o(" \u2014 "),lX=a("a"),yVo=o("SqueezeBertForMultipleChoice"),xVo=o(" (SqueezeBERT model)"),$Vo=l(),Xb=a("li"),Bpe=a("strong"),kVo=o("xlm"),SVo=o(" \u2014 "),iX=a("a"),RVo=o("XLMForMultipleChoice"),PVo=o(" (XLM model)"),BVo=l(),zb=a("li"),Ipe=a("strong"),IVo=o("xlm-roberta"),NVo=o(" \u2014 "),dX=a("a"),qVo=o("XLMRobertaForMultipleChoice"),jVo=o(" (XLM-RoBERTa model)"),DVo=l(),Wb=a("li"),Npe=a("strong"),GVo=o("xlm-roberta-xl"),OVo=o(" \u2014 "),cX=a("a"),VVo=o("XLMRobertaXLForMultipleChoice"),XVo=o(" (XLM-RoBERTa-XL model)"),zVo=l(),Qb=a("li"),qpe=a("strong"),WVo=o("xlnet"),QVo=o(" \u2014 "),fX=a("a"),HVo=o("XLNetForMultipleChoice"),UVo=o(" (XLNet model)"),JVo=l(),Hb=a("li"),jpe=a("strong"),YVo=o("yoso"),KVo=o(" \u2014 "),mX=a("a"),ZVo=o("YosoForMultipleChoice"),eXo=o(" (YOSO model)"),oXo=l(),Ub=a("p"),rXo=o("The model is set in evaluation mode by default using "),Dpe=a("code"),tXo=o("model.eval()"),aXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gpe=a("code"),nXo=o("model.train()"),sXo=l(),F(Jb.$$.fragment),WGe=l(),rd=a("h2"),Yb=a("a"),Ope=a("span"),F(ky.$$.fragment),lXo=l(),Vpe=a("span"),iXo=o("AutoModelForNextSentencePrediction"),QGe=l(),Io=a("div"),F(Sy.$$.fragment),dXo=l(),td=a("p"),cXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),gX=a("a"),fXo=o("from_pretrained()"),mXo=o(" class method or the "),hX=a("a"),gXo=o("from_config()"),hXo=o(` class
method.`),pXo=l(),Ry=a("p"),uXo=o("This class cannot be instantiated directly using "),Xpe=a("code"),_Xo=o("__init__()"),bXo=o(" (throws an error)."),vXo=l(),mt=a("div"),F(Py.$$.fragment),FXo=l(),zpe=a("p"),TXo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),MXo=l(),ad=a("p"),EXo=o(`Note:
Loading a model from its configuration file does `),Wpe=a("strong"),CXo=o("not"),wXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pX=a("a"),AXo=o("from_pretrained()"),LXo=o(" to load the model weights."),yXo=l(),F(Kb.$$.fragment),xXo=l(),to=a("div"),F(By.$$.fragment),$Xo=l(),Qpe=a("p"),kXo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),SXo=l(),ja=a("p"),RXo=o("The model class to instantiate is selected based on the "),Hpe=a("code"),PXo=o("model_type"),BXo=o(` property of the config object (either
passed as an argument or loaded from `),Upe=a("code"),IXo=o("pretrained_model_name_or_path"),NXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jpe=a("code"),qXo=o("pretrained_model_name_or_path"),jXo=o(":"),DXo=l(),Zr=a("ul"),Zb=a("li"),Ype=a("strong"),GXo=o("bert"),OXo=o(" \u2014 "),uX=a("a"),VXo=o("BertForNextSentencePrediction"),XXo=o(" (BERT model)"),zXo=l(),ev=a("li"),Kpe=a("strong"),WXo=o("fnet"),QXo=o(" \u2014 "),_X=a("a"),HXo=o("FNetForNextSentencePrediction"),UXo=o(" (FNet model)"),JXo=l(),ov=a("li"),Zpe=a("strong"),YXo=o("megatron-bert"),KXo=o(" \u2014 "),bX=a("a"),ZXo=o("MegatronBertForNextSentencePrediction"),ezo=o(" (Megatron-BERT model)"),ozo=l(),rv=a("li"),eue=a("strong"),rzo=o("mobilebert"),tzo=o(" \u2014 "),vX=a("a"),azo=o("MobileBertForNextSentencePrediction"),nzo=o(" (MobileBERT model)"),szo=l(),tv=a("li"),oue=a("strong"),lzo=o("qdqbert"),izo=o(" \u2014 "),FX=a("a"),dzo=o("QDQBertForNextSentencePrediction"),czo=o(" (QDQBert model)"),fzo=l(),av=a("p"),mzo=o("The model is set in evaluation mode by default using "),rue=a("code"),gzo=o("model.eval()"),hzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tue=a("code"),pzo=o("model.train()"),uzo=l(),F(nv.$$.fragment),HGe=l(),nd=a("h2"),sv=a("a"),aue=a("span"),F(Iy.$$.fragment),_zo=l(),nue=a("span"),bzo=o("AutoModelForTokenClassification"),UGe=l(),No=a("div"),F(Ny.$$.fragment),vzo=l(),sd=a("p"),Fzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),TX=a("a"),Tzo=o("from_pretrained()"),Mzo=o(" class method or the "),MX=a("a"),Ezo=o("from_config()"),Czo=o(` class
method.`),wzo=l(),qy=a("p"),Azo=o("This class cannot be instantiated directly using "),sue=a("code"),Lzo=o("__init__()"),yzo=o(" (throws an error)."),xzo=l(),gt=a("div"),F(jy.$$.fragment),$zo=l(),lue=a("p"),kzo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Szo=l(),ld=a("p"),Rzo=o(`Note:
Loading a model from its configuration file does `),iue=a("strong"),Pzo=o("not"),Bzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=a("a"),Izo=o("from_pretrained()"),Nzo=o(" to load the model weights."),qzo=l(),F(lv.$$.fragment),jzo=l(),ao=a("div"),F(Dy.$$.fragment),Dzo=l(),due=a("p"),Gzo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ozo=l(),Da=a("p"),Vzo=o("The model class to instantiate is selected based on the "),cue=a("code"),Xzo=o("model_type"),zzo=o(` property of the config object (either
passed as an argument or loaded from `),fue=a("code"),Wzo=o("pretrained_model_name_or_path"),Qzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mue=a("code"),Hzo=o("pretrained_model_name_or_path"),Uzo=o(":"),Jzo=l(),H=a("ul"),iv=a("li"),gue=a("strong"),Yzo=o("albert"),Kzo=o(" \u2014 "),CX=a("a"),Zzo=o("AlbertForTokenClassification"),eWo=o(" (ALBERT model)"),oWo=l(),dv=a("li"),hue=a("strong"),rWo=o("bert"),tWo=o(" \u2014 "),wX=a("a"),aWo=o("BertForTokenClassification"),nWo=o(" (BERT model)"),sWo=l(),cv=a("li"),pue=a("strong"),lWo=o("big_bird"),iWo=o(" \u2014 "),AX=a("a"),dWo=o("BigBirdForTokenClassification"),cWo=o(" (BigBird model)"),fWo=l(),fv=a("li"),uue=a("strong"),mWo=o("bloom"),gWo=o(" \u2014 "),LX=a("a"),hWo=o("BloomForTokenClassification"),pWo=o(" (BLOOM model)"),uWo=l(),mv=a("li"),_ue=a("strong"),_Wo=o("camembert"),bWo=o(" \u2014 "),yX=a("a"),vWo=o("CamembertForTokenClassification"),FWo=o(" (CamemBERT model)"),TWo=l(),gv=a("li"),bue=a("strong"),MWo=o("canine"),EWo=o(" \u2014 "),xX=a("a"),CWo=o("CanineForTokenClassification"),wWo=o(" (CANINE model)"),AWo=l(),hv=a("li"),vue=a("strong"),LWo=o("convbert"),yWo=o(" \u2014 "),$X=a("a"),xWo=o("ConvBertForTokenClassification"),$Wo=o(" (ConvBERT model)"),kWo=l(),pv=a("li"),Fue=a("strong"),SWo=o("data2vec-text"),RWo=o(" \u2014 "),kX=a("a"),PWo=o("Data2VecTextForTokenClassification"),BWo=o(" (Data2VecText model)"),IWo=l(),uv=a("li"),Tue=a("strong"),NWo=o("deberta"),qWo=o(" \u2014 "),SX=a("a"),jWo=o("DebertaForTokenClassification"),DWo=o(" (DeBERTa model)"),GWo=l(),_v=a("li"),Mue=a("strong"),OWo=o("deberta-v2"),VWo=o(" \u2014 "),RX=a("a"),XWo=o("DebertaV2ForTokenClassification"),zWo=o(" (DeBERTa-v2 model)"),WWo=l(),bv=a("li"),Eue=a("strong"),QWo=o("distilbert"),HWo=o(" \u2014 "),PX=a("a"),UWo=o("DistilBertForTokenClassification"),JWo=o(" (DistilBERT model)"),YWo=l(),vv=a("li"),Cue=a("strong"),KWo=o("electra"),ZWo=o(" \u2014 "),BX=a("a"),eQo=o("ElectraForTokenClassification"),oQo=o(" (ELECTRA model)"),rQo=l(),Fv=a("li"),wue=a("strong"),tQo=o("flaubert"),aQo=o(" \u2014 "),IX=a("a"),nQo=o("FlaubertForTokenClassification"),sQo=o(" (FlauBERT model)"),lQo=l(),Tv=a("li"),Aue=a("strong"),iQo=o("fnet"),dQo=o(" \u2014 "),NX=a("a"),cQo=o("FNetForTokenClassification"),fQo=o(" (FNet model)"),mQo=l(),Mv=a("li"),Lue=a("strong"),gQo=o("funnel"),hQo=o(" \u2014 "),qX=a("a"),pQo=o("FunnelForTokenClassification"),uQo=o(" (Funnel Transformer model)"),_Qo=l(),Ev=a("li"),yue=a("strong"),bQo=o("gpt2"),vQo=o(" \u2014 "),jX=a("a"),FQo=o("GPT2ForTokenClassification"),TQo=o(" (OpenAI GPT-2 model)"),MQo=l(),Cv=a("li"),xue=a("strong"),EQo=o("ibert"),CQo=o(" \u2014 "),DX=a("a"),wQo=o("IBertForTokenClassification"),AQo=o(" (I-BERT model)"),LQo=l(),wv=a("li"),$ue=a("strong"),yQo=o("layoutlm"),xQo=o(" \u2014 "),GX=a("a"),$Qo=o("LayoutLMForTokenClassification"),kQo=o(" (LayoutLM model)"),SQo=l(),Av=a("li"),kue=a("strong"),RQo=o("layoutlmv2"),PQo=o(" \u2014 "),OX=a("a"),BQo=o("LayoutLMv2ForTokenClassification"),IQo=o(" (LayoutLMv2 model)"),NQo=l(),Lv=a("li"),Sue=a("strong"),qQo=o("layoutlmv3"),jQo=o(" \u2014 "),VX=a("a"),DQo=o("LayoutLMv3ForTokenClassification"),GQo=o(" (LayoutLMv3 model)"),OQo=l(),yv=a("li"),Rue=a("strong"),VQo=o("longformer"),XQo=o(" \u2014 "),XX=a("a"),zQo=o("LongformerForTokenClassification"),WQo=o(" (Longformer model)"),QQo=l(),xv=a("li"),Pue=a("strong"),HQo=o("megatron-bert"),UQo=o(" \u2014 "),zX=a("a"),JQo=o("MegatronBertForTokenClassification"),YQo=o(" (Megatron-BERT model)"),KQo=l(),$v=a("li"),Bue=a("strong"),ZQo=o("mobilebert"),eHo=o(" \u2014 "),WX=a("a"),oHo=o("MobileBertForTokenClassification"),rHo=o(" (MobileBERT model)"),tHo=l(),kv=a("li"),Iue=a("strong"),aHo=o("mpnet"),nHo=o(" \u2014 "),QX=a("a"),sHo=o("MPNetForTokenClassification"),lHo=o(" (MPNet model)"),iHo=l(),Sv=a("li"),Nue=a("strong"),dHo=o("nystromformer"),cHo=o(" \u2014 "),HX=a("a"),fHo=o("NystromformerForTokenClassification"),mHo=o(" (Nystr\xF6mformer model)"),gHo=l(),Rv=a("li"),que=a("strong"),hHo=o("qdqbert"),pHo=o(" \u2014 "),UX=a("a"),uHo=o("QDQBertForTokenClassification"),_Ho=o(" (QDQBert model)"),bHo=l(),Pv=a("li"),jue=a("strong"),vHo=o("rembert"),FHo=o(" \u2014 "),JX=a("a"),THo=o("RemBertForTokenClassification"),MHo=o(" (RemBERT model)"),EHo=l(),Bv=a("li"),Due=a("strong"),CHo=o("roberta"),wHo=o(" \u2014 "),YX=a("a"),AHo=o("RobertaForTokenClassification"),LHo=o(" (RoBERTa model)"),yHo=l(),Iv=a("li"),Gue=a("strong"),xHo=o("roformer"),$Ho=o(" \u2014 "),KX=a("a"),kHo=o("RoFormerForTokenClassification"),SHo=o(" (RoFormer model)"),RHo=l(),Nv=a("li"),Oue=a("strong"),PHo=o("squeezebert"),BHo=o(" \u2014 "),ZX=a("a"),IHo=o("SqueezeBertForTokenClassification"),NHo=o(" (SqueezeBERT model)"),qHo=l(),qv=a("li"),Vue=a("strong"),jHo=o("xlm"),DHo=o(" \u2014 "),ez=a("a"),GHo=o("XLMForTokenClassification"),OHo=o(" (XLM model)"),VHo=l(),jv=a("li"),Xue=a("strong"),XHo=o("xlm-roberta"),zHo=o(" \u2014 "),oz=a("a"),WHo=o("XLMRobertaForTokenClassification"),QHo=o(" (XLM-RoBERTa model)"),HHo=l(),Dv=a("li"),zue=a("strong"),UHo=o("xlm-roberta-xl"),JHo=o(" \u2014 "),rz=a("a"),YHo=o("XLMRobertaXLForTokenClassification"),KHo=o(" (XLM-RoBERTa-XL model)"),ZHo=l(),Gv=a("li"),Wue=a("strong"),eUo=o("xlnet"),oUo=o(" \u2014 "),tz=a("a"),rUo=o("XLNetForTokenClassification"),tUo=o(" (XLNet model)"),aUo=l(),Ov=a("li"),Que=a("strong"),nUo=o("yoso"),sUo=o(" \u2014 "),az=a("a"),lUo=o("YosoForTokenClassification"),iUo=o(" (YOSO model)"),dUo=l(),Vv=a("p"),cUo=o("The model is set in evaluation mode by default using "),Hue=a("code"),fUo=o("model.eval()"),mUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uue=a("code"),gUo=o("model.train()"),hUo=l(),F(Xv.$$.fragment),JGe=l(),id=a("h2"),zv=a("a"),Jue=a("span"),F(Gy.$$.fragment),pUo=l(),Yue=a("span"),uUo=o("AutoModelForQuestionAnswering"),YGe=l(),qo=a("div"),F(Oy.$$.fragment),_Uo=l(),dd=a("p"),bUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),nz=a("a"),vUo=o("from_pretrained()"),FUo=o(" class method or the "),sz=a("a"),TUo=o("from_config()"),MUo=o(` class
method.`),EUo=l(),Vy=a("p"),CUo=o("This class cannot be instantiated directly using "),Kue=a("code"),wUo=o("__init__()"),AUo=o(" (throws an error)."),LUo=l(),ht=a("div"),F(Xy.$$.fragment),yUo=l(),Zue=a("p"),xUo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),$Uo=l(),cd=a("p"),kUo=o(`Note:
Loading a model from its configuration file does `),e_e=a("strong"),SUo=o("not"),RUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lz=a("a"),PUo=o("from_pretrained()"),BUo=o(" to load the model weights."),IUo=l(),F(Wv.$$.fragment),NUo=l(),no=a("div"),F(zy.$$.fragment),qUo=l(),o_e=a("p"),jUo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),DUo=l(),Ga=a("p"),GUo=o("The model class to instantiate is selected based on the "),r_e=a("code"),OUo=o("model_type"),VUo=o(` property of the config object (either
passed as an argument or loaded from `),t_e=a("code"),XUo=o("pretrained_model_name_or_path"),zUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a_e=a("code"),WUo=o("pretrained_model_name_or_path"),QUo=o(":"),HUo=l(),V=a("ul"),Qv=a("li"),n_e=a("strong"),UUo=o("albert"),JUo=o(" \u2014 "),iz=a("a"),YUo=o("AlbertForQuestionAnswering"),KUo=o(" (ALBERT model)"),ZUo=l(),Hv=a("li"),s_e=a("strong"),eJo=o("bart"),oJo=o(" \u2014 "),dz=a("a"),rJo=o("BartForQuestionAnswering"),tJo=o(" (BART model)"),aJo=l(),Uv=a("li"),l_e=a("strong"),nJo=o("bert"),sJo=o(" \u2014 "),cz=a("a"),lJo=o("BertForQuestionAnswering"),iJo=o(" (BERT model)"),dJo=l(),Jv=a("li"),i_e=a("strong"),cJo=o("big_bird"),fJo=o(" \u2014 "),fz=a("a"),mJo=o("BigBirdForQuestionAnswering"),gJo=o(" (BigBird model)"),hJo=l(),Yv=a("li"),d_e=a("strong"),pJo=o("bigbird_pegasus"),uJo=o(" \u2014 "),mz=a("a"),_Jo=o("BigBirdPegasusForQuestionAnswering"),bJo=o(" (BigBird-Pegasus model)"),vJo=l(),Kv=a("li"),c_e=a("strong"),FJo=o("camembert"),TJo=o(" \u2014 "),gz=a("a"),MJo=o("CamembertForQuestionAnswering"),EJo=o(" (CamemBERT model)"),CJo=l(),Zv=a("li"),f_e=a("strong"),wJo=o("canine"),AJo=o(" \u2014 "),hz=a("a"),LJo=o("CanineForQuestionAnswering"),yJo=o(" (CANINE model)"),xJo=l(),eF=a("li"),m_e=a("strong"),$Jo=o("convbert"),kJo=o(" \u2014 "),pz=a("a"),SJo=o("ConvBertForQuestionAnswering"),RJo=o(" (ConvBERT model)"),PJo=l(),oF=a("li"),g_e=a("strong"),BJo=o("data2vec-text"),IJo=o(" \u2014 "),uz=a("a"),NJo=o("Data2VecTextForQuestionAnswering"),qJo=o(" (Data2VecText model)"),jJo=l(),rF=a("li"),h_e=a("strong"),DJo=o("deberta"),GJo=o(" \u2014 "),_z=a("a"),OJo=o("DebertaForQuestionAnswering"),VJo=o(" (DeBERTa model)"),XJo=l(),tF=a("li"),p_e=a("strong"),zJo=o("deberta-v2"),WJo=o(" \u2014 "),bz=a("a"),QJo=o("DebertaV2ForQuestionAnswering"),HJo=o(" (DeBERTa-v2 model)"),UJo=l(),aF=a("li"),u_e=a("strong"),JJo=o("distilbert"),YJo=o(" \u2014 "),vz=a("a"),KJo=o("DistilBertForQuestionAnswering"),ZJo=o(" (DistilBERT model)"),eYo=l(),nF=a("li"),__e=a("strong"),oYo=o("electra"),rYo=o(" \u2014 "),Fz=a("a"),tYo=o("ElectraForQuestionAnswering"),aYo=o(" (ELECTRA model)"),nYo=l(),sF=a("li"),b_e=a("strong"),sYo=o("flaubert"),lYo=o(" \u2014 "),Tz=a("a"),iYo=o("FlaubertForQuestionAnsweringSimple"),dYo=o(" (FlauBERT model)"),cYo=l(),lF=a("li"),v_e=a("strong"),fYo=o("fnet"),mYo=o(" \u2014 "),Mz=a("a"),gYo=o("FNetForQuestionAnswering"),hYo=o(" (FNet model)"),pYo=l(),iF=a("li"),F_e=a("strong"),uYo=o("funnel"),_Yo=o(" \u2014 "),Ez=a("a"),bYo=o("FunnelForQuestionAnswering"),vYo=o(" (Funnel Transformer model)"),FYo=l(),dF=a("li"),T_e=a("strong"),TYo=o("gptj"),MYo=o(" \u2014 "),Cz=a("a"),EYo=o("GPTJForQuestionAnswering"),CYo=o(" (GPT-J model)"),wYo=l(),cF=a("li"),M_e=a("strong"),AYo=o("ibert"),LYo=o(" \u2014 "),wz=a("a"),yYo=o("IBertForQuestionAnswering"),xYo=o(" (I-BERT model)"),$Yo=l(),fF=a("li"),E_e=a("strong"),kYo=o("layoutlmv2"),SYo=o(" \u2014 "),Az=a("a"),RYo=o("LayoutLMv2ForQuestionAnswering"),PYo=o(" (LayoutLMv2 model)"),BYo=l(),mF=a("li"),C_e=a("strong"),IYo=o("layoutlmv3"),NYo=o(" \u2014 "),Lz=a("a"),qYo=o("LayoutLMv3ForQuestionAnswering"),jYo=o(" (LayoutLMv3 model)"),DYo=l(),gF=a("li"),w_e=a("strong"),GYo=o("led"),OYo=o(" \u2014 "),yz=a("a"),VYo=o("LEDForQuestionAnswering"),XYo=o(" (LED model)"),zYo=l(),hF=a("li"),A_e=a("strong"),WYo=o("longformer"),QYo=o(" \u2014 "),xz=a("a"),HYo=o("LongformerForQuestionAnswering"),UYo=o(" (Longformer model)"),JYo=l(),pF=a("li"),L_e=a("strong"),YYo=o("lxmert"),KYo=o(" \u2014 "),$z=a("a"),ZYo=o("LxmertForQuestionAnswering"),eKo=o(" (LXMERT model)"),oKo=l(),uF=a("li"),y_e=a("strong"),rKo=o("mbart"),tKo=o(" \u2014 "),kz=a("a"),aKo=o("MBartForQuestionAnswering"),nKo=o(" (mBART model)"),sKo=l(),_F=a("li"),x_e=a("strong"),lKo=o("megatron-bert"),iKo=o(" \u2014 "),Sz=a("a"),dKo=o("MegatronBertForQuestionAnswering"),cKo=o(" (Megatron-BERT model)"),fKo=l(),bF=a("li"),$_e=a("strong"),mKo=o("mobilebert"),gKo=o(" \u2014 "),Rz=a("a"),hKo=o("MobileBertForQuestionAnswering"),pKo=o(" (MobileBERT model)"),uKo=l(),vF=a("li"),k_e=a("strong"),_Ko=o("mpnet"),bKo=o(" \u2014 "),Pz=a("a"),vKo=o("MPNetForQuestionAnswering"),FKo=o(" (MPNet model)"),TKo=l(),FF=a("li"),S_e=a("strong"),MKo=o("nystromformer"),EKo=o(" \u2014 "),Bz=a("a"),CKo=o("NystromformerForQuestionAnswering"),wKo=o(" (Nystr\xF6mformer model)"),AKo=l(),TF=a("li"),R_e=a("strong"),LKo=o("qdqbert"),yKo=o(" \u2014 "),Iz=a("a"),xKo=o("QDQBertForQuestionAnswering"),$Ko=o(" (QDQBert model)"),kKo=l(),MF=a("li"),P_e=a("strong"),SKo=o("reformer"),RKo=o(" \u2014 "),Nz=a("a"),PKo=o("ReformerForQuestionAnswering"),BKo=o(" (Reformer model)"),IKo=l(),EF=a("li"),B_e=a("strong"),NKo=o("rembert"),qKo=o(" \u2014 "),qz=a("a"),jKo=o("RemBertForQuestionAnswering"),DKo=o(" (RemBERT model)"),GKo=l(),CF=a("li"),I_e=a("strong"),OKo=o("roberta"),VKo=o(" \u2014 "),jz=a("a"),XKo=o("RobertaForQuestionAnswering"),zKo=o(" (RoBERTa model)"),WKo=l(),wF=a("li"),N_e=a("strong"),QKo=o("roformer"),HKo=o(" \u2014 "),Dz=a("a"),UKo=o("RoFormerForQuestionAnswering"),JKo=o(" (RoFormer model)"),YKo=l(),AF=a("li"),q_e=a("strong"),KKo=o("splinter"),ZKo=o(" \u2014 "),Gz=a("a"),eZo=o("SplinterForQuestionAnswering"),oZo=o(" (Splinter model)"),rZo=l(),LF=a("li"),j_e=a("strong"),tZo=o("squeezebert"),aZo=o(" \u2014 "),Oz=a("a"),nZo=o("SqueezeBertForQuestionAnswering"),sZo=o(" (SqueezeBERT model)"),lZo=l(),yF=a("li"),D_e=a("strong"),iZo=o("xlm"),dZo=o(" \u2014 "),Vz=a("a"),cZo=o("XLMForQuestionAnsweringSimple"),fZo=o(" (XLM model)"),mZo=l(),xF=a("li"),G_e=a("strong"),gZo=o("xlm-roberta"),hZo=o(" \u2014 "),Xz=a("a"),pZo=o("XLMRobertaForQuestionAnswering"),uZo=o(" (XLM-RoBERTa model)"),_Zo=l(),$F=a("li"),O_e=a("strong"),bZo=o("xlm-roberta-xl"),vZo=o(" \u2014 "),zz=a("a"),FZo=o("XLMRobertaXLForQuestionAnswering"),TZo=o(" (XLM-RoBERTa-XL model)"),MZo=l(),kF=a("li"),V_e=a("strong"),EZo=o("xlnet"),CZo=o(" \u2014 "),Wz=a("a"),wZo=o("XLNetForQuestionAnsweringSimple"),AZo=o(" (XLNet model)"),LZo=l(),SF=a("li"),X_e=a("strong"),yZo=o("yoso"),xZo=o(" \u2014 "),Qz=a("a"),$Zo=o("YosoForQuestionAnswering"),kZo=o(" (YOSO model)"),SZo=l(),RF=a("p"),RZo=o("The model is set in evaluation mode by default using "),z_e=a("code"),PZo=o("model.eval()"),BZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W_e=a("code"),IZo=o("model.train()"),NZo=l(),F(PF.$$.fragment),KGe=l(),fd=a("h2"),BF=a("a"),Q_e=a("span"),F(Wy.$$.fragment),qZo=l(),H_e=a("span"),jZo=o("AutoModelForTableQuestionAnswering"),ZGe=l(),jo=a("div"),F(Qy.$$.fragment),DZo=l(),md=a("p"),GZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Hz=a("a"),OZo=o("from_pretrained()"),VZo=o(" class method or the "),Uz=a("a"),XZo=o("from_config()"),zZo=o(` class
method.`),WZo=l(),Hy=a("p"),QZo=o("This class cannot be instantiated directly using "),U_e=a("code"),HZo=o("__init__()"),UZo=o(" (throws an error)."),JZo=l(),pt=a("div"),F(Uy.$$.fragment),YZo=l(),J_e=a("p"),KZo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),ZZo=l(),gd=a("p"),eer=o(`Note:
Loading a model from its configuration file does `),Y_e=a("strong"),oer=o("not"),rer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jz=a("a"),ter=o("from_pretrained()"),aer=o(" to load the model weights."),ner=l(),F(IF.$$.fragment),ser=l(),so=a("div"),F(Jy.$$.fragment),ler=l(),K_e=a("p"),ier=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),der=l(),Oa=a("p"),cer=o("The model class to instantiate is selected based on the "),Z_e=a("code"),fer=o("model_type"),mer=o(` property of the config object (either
passed as an argument or loaded from `),e1e=a("code"),ger=o("pretrained_model_name_or_path"),her=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o1e=a("code"),per=o("pretrained_model_name_or_path"),uer=o(":"),_er=l(),r1e=a("ul"),NF=a("li"),t1e=a("strong"),ber=o("tapas"),ver=o(" \u2014 "),Yz=a("a"),Fer=o("TapasForQuestionAnswering"),Ter=o(" (TAPAS model)"),Mer=l(),qF=a("p"),Eer=o("The model is set in evaluation mode by default using "),a1e=a("code"),Cer=o("model.eval()"),wer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n1e=a("code"),Aer=o("model.train()"),Ler=l(),F(jF.$$.fragment),eOe=l(),hd=a("h2"),DF=a("a"),s1e=a("span"),F(Yy.$$.fragment),yer=l(),l1e=a("span"),xer=o("AutoModelForImageClassification"),oOe=l(),Do=a("div"),F(Ky.$$.fragment),$er=l(),pd=a("p"),ker=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Kz=a("a"),Ser=o("from_pretrained()"),Rer=o(" class method or the "),Zz=a("a"),Per=o("from_config()"),Ber=o(` class
method.`),Ier=l(),Zy=a("p"),Ner=o("This class cannot be instantiated directly using "),i1e=a("code"),qer=o("__init__()"),jer=o(" (throws an error)."),Der=l(),ut=a("div"),F(e8.$$.fragment),Ger=l(),d1e=a("p"),Oer=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Ver=l(),ud=a("p"),Xer=o(`Note:
Loading a model from its configuration file does `),c1e=a("strong"),zer=o("not"),Wer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eW=a("a"),Qer=o("from_pretrained()"),Her=o(" to load the model weights."),Uer=l(),F(GF.$$.fragment),Jer=l(),lo=a("div"),F(o8.$$.fragment),Yer=l(),f1e=a("p"),Ker=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Zer=l(),Va=a("p"),eor=o("The model class to instantiate is selected based on the "),m1e=a("code"),oor=o("model_type"),ror=o(` property of the config object (either
passed as an argument or loaded from `),g1e=a("code"),tor=o("pretrained_model_name_or_path"),aor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h1e=a("code"),nor=o("pretrained_model_name_or_path"),sor=o(":"),lor=l(),Fe=a("ul"),OF=a("li"),p1e=a("strong"),ior=o("beit"),dor=o(" \u2014 "),oW=a("a"),cor=o("BeitForImageClassification"),mor=o(" (BEiT model)"),gor=l(),VF=a("li"),u1e=a("strong"),hor=o("convnext"),por=o(" \u2014 "),rW=a("a"),uor=o("ConvNextForImageClassification"),_or=o(" (ConvNeXT model)"),bor=l(),XF=a("li"),_1e=a("strong"),vor=o("cvt"),For=o(" \u2014 "),tW=a("a"),Tor=o("CvtForImageClassification"),Mor=o(" (CvT model)"),Eor=l(),zF=a("li"),b1e=a("strong"),Cor=o("data2vec-vision"),wor=o(" \u2014 "),aW=a("a"),Aor=o("Data2VecVisionForImageClassification"),Lor=o(" (Data2VecVision model)"),yor=l(),Vs=a("li"),v1e=a("strong"),xor=o("deit"),$or=o(" \u2014 "),nW=a("a"),kor=o("DeiTForImageClassification"),Sor=o(" or "),sW=a("a"),Ror=o("DeiTForImageClassificationWithTeacher"),Por=o(" (DeiT model)"),Bor=l(),WF=a("li"),F1e=a("strong"),Ior=o("imagegpt"),Nor=o(" \u2014 "),lW=a("a"),qor=o("ImageGPTForImageClassification"),jor=o(" (ImageGPT model)"),Dor=l(),Xs=a("li"),T1e=a("strong"),Gor=o("levit"),Oor=o(" \u2014 "),iW=a("a"),Vor=o("LevitForImageClassification"),Xor=o(" or "),dW=a("a"),zor=o("LevitForImageClassificationWithTeacher"),Wor=o(" (LeViT model)"),Qor=l(),_t=a("li"),M1e=a("strong"),Hor=o("perceiver"),Uor=o(" \u2014 "),cW=a("a"),Jor=o("PerceiverForImageClassificationLearned"),Yor=o(" or "),fW=a("a"),Kor=o("PerceiverForImageClassificationFourier"),Zor=o(" or "),mW=a("a"),err=o("PerceiverForImageClassificationConvProcessing"),orr=o(" (Perceiver model)"),rrr=l(),QF=a("li"),E1e=a("strong"),trr=o("poolformer"),arr=o(" \u2014 "),gW=a("a"),nrr=o("PoolFormerForImageClassification"),srr=o(" (PoolFormer model)"),lrr=l(),HF=a("li"),C1e=a("strong"),irr=o("regnet"),drr=o(" \u2014 "),hW=a("a"),crr=o("RegNetForImageClassification"),frr=o(" (RegNet model)"),mrr=l(),UF=a("li"),w1e=a("strong"),grr=o("resnet"),hrr=o(" \u2014 "),pW=a("a"),prr=o("ResNetForImageClassification"),urr=o(" (ResNet model)"),_rr=l(),JF=a("li"),A1e=a("strong"),brr=o("segformer"),vrr=o(" \u2014 "),uW=a("a"),Frr=o("SegformerForImageClassification"),Trr=o(" (SegFormer model)"),Mrr=l(),YF=a("li"),L1e=a("strong"),Err=o("swin"),Crr=o(" \u2014 "),_W=a("a"),wrr=o("SwinForImageClassification"),Arr=o(" (Swin Transformer model)"),Lrr=l(),KF=a("li"),y1e=a("strong"),yrr=o("van"),xrr=o(" \u2014 "),bW=a("a"),$rr=o("VanForImageClassification"),krr=o(" (VAN model)"),Srr=l(),ZF=a("li"),x1e=a("strong"),Rrr=o("vit"),Prr=o(" \u2014 "),vW=a("a"),Brr=o("ViTForImageClassification"),Irr=o(" (ViT model)"),Nrr=l(),eT=a("p"),qrr=o("The model is set in evaluation mode by default using "),$1e=a("code"),jrr=o("model.eval()"),Drr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k1e=a("code"),Grr=o("model.train()"),Orr=l(),F(oT.$$.fragment),rOe=l(),_d=a("h2"),rT=a("a"),S1e=a("span"),F(r8.$$.fragment),Vrr=l(),R1e=a("span"),Xrr=o("AutoModelForVision2Seq"),tOe=l(),Go=a("div"),F(t8.$$.fragment),zrr=l(),bd=a("p"),Wrr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),FW=a("a"),Qrr=o("from_pretrained()"),Hrr=o(" class method or the "),TW=a("a"),Urr=o("from_config()"),Jrr=o(` class
method.`),Yrr=l(),a8=a("p"),Krr=o("This class cannot be instantiated directly using "),P1e=a("code"),Zrr=o("__init__()"),etr=o(" (throws an error)."),otr=l(),bt=a("div"),F(n8.$$.fragment),rtr=l(),B1e=a("p"),ttr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),atr=l(),vd=a("p"),ntr=o(`Note:
Loading a model from its configuration file does `),I1e=a("strong"),str=o("not"),ltr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MW=a("a"),itr=o("from_pretrained()"),dtr=o(" to load the model weights."),ctr=l(),F(tT.$$.fragment),ftr=l(),io=a("div"),F(s8.$$.fragment),mtr=l(),N1e=a("p"),gtr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),htr=l(),Xa=a("p"),ptr=o("The model class to instantiate is selected based on the "),q1e=a("code"),utr=o("model_type"),_tr=o(` property of the config object (either
passed as an argument or loaded from `),j1e=a("code"),btr=o("pretrained_model_name_or_path"),vtr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D1e=a("code"),Ftr=o("pretrained_model_name_or_path"),Ttr=o(":"),Mtr=l(),G1e=a("ul"),aT=a("li"),O1e=a("strong"),Etr=o("vision-encoder-decoder"),Ctr=o(" \u2014 "),EW=a("a"),wtr=o("VisionEncoderDecoderModel"),Atr=o(" (Vision Encoder decoder model)"),Ltr=l(),nT=a("p"),ytr=o("The model is set in evaluation mode by default using "),V1e=a("code"),xtr=o("model.eval()"),$tr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X1e=a("code"),ktr=o("model.train()"),Str=l(),F(sT.$$.fragment),aOe=l(),Fd=a("h2"),lT=a("a"),z1e=a("span"),F(l8.$$.fragment),Rtr=l(),W1e=a("span"),Ptr=o("AutoModelForVisualQuestionAnswering"),nOe=l(),Oo=a("div"),F(i8.$$.fragment),Btr=l(),Td=a("p"),Itr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),CW=a("a"),Ntr=o("from_pretrained()"),qtr=o(" class method or the "),wW=a("a"),jtr=o("from_config()"),Dtr=o(` class
method.`),Gtr=l(),d8=a("p"),Otr=o("This class cannot be instantiated directly using "),Q1e=a("code"),Vtr=o("__init__()"),Xtr=o(" (throws an error)."),ztr=l(),vt=a("div"),F(c8.$$.fragment),Wtr=l(),H1e=a("p"),Qtr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Htr=l(),Md=a("p"),Utr=o(`Note:
Loading a model from its configuration file does `),U1e=a("strong"),Jtr=o("not"),Ytr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AW=a("a"),Ktr=o("from_pretrained()"),Ztr=o(" to load the model weights."),ear=l(),F(iT.$$.fragment),oar=l(),co=a("div"),F(f8.$$.fragment),rar=l(),J1e=a("p"),tar=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),aar=l(),za=a("p"),nar=o("The model class to instantiate is selected based on the "),Y1e=a("code"),sar=o("model_type"),lar=o(` property of the config object (either
passed as an argument or loaded from `),K1e=a("code"),iar=o("pretrained_model_name_or_path"),dar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=a("code"),car=o("pretrained_model_name_or_path"),far=o(":"),mar=l(),e3e=a("ul"),dT=a("li"),o3e=a("strong"),gar=o("vilt"),har=o(" \u2014 "),LW=a("a"),par=o("ViltForQuestionAnswering"),uar=o(" (ViLT model)"),_ar=l(),cT=a("p"),bar=o("The model is set in evaluation mode by default using "),r3e=a("code"),Far=o("model.eval()"),Tar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t3e=a("code"),Mar=o("model.train()"),Ear=l(),F(fT.$$.fragment),sOe=l(),Ed=a("h2"),mT=a("a"),a3e=a("span"),F(m8.$$.fragment),Car=l(),n3e=a("span"),war=o("AutoModelForAudioClassification"),lOe=l(),Vo=a("div"),F(g8.$$.fragment),Aar=l(),Cd=a("p"),Lar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),yW=a("a"),yar=o("from_pretrained()"),xar=o(" class method or the "),xW=a("a"),$ar=o("from_config()"),kar=o(` class
method.`),Sar=l(),h8=a("p"),Rar=o("This class cannot be instantiated directly using "),s3e=a("code"),Par=o("__init__()"),Bar=o(" (throws an error)."),Iar=l(),Ft=a("div"),F(p8.$$.fragment),Nar=l(),l3e=a("p"),qar=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),jar=l(),wd=a("p"),Dar=o(`Note:
Loading a model from its configuration file does `),i3e=a("strong"),Gar=o("not"),Oar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$W=a("a"),Var=o("from_pretrained()"),Xar=o(" to load the model weights."),zar=l(),F(gT.$$.fragment),War=l(),fo=a("div"),F(u8.$$.fragment),Qar=l(),d3e=a("p"),Har=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Uar=l(),Wa=a("p"),Jar=o("The model class to instantiate is selected based on the "),c3e=a("code"),Yar=o("model_type"),Kar=o(` property of the config object (either
passed as an argument or loaded from `),f3e=a("code"),Zar=o("pretrained_model_name_or_path"),enr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m3e=a("code"),onr=o("pretrained_model_name_or_path"),rnr=o(":"),tnr=l(),Pe=a("ul"),hT=a("li"),g3e=a("strong"),anr=o("data2vec-audio"),nnr=o(" \u2014 "),kW=a("a"),snr=o("Data2VecAudioForSequenceClassification"),lnr=o(" (Data2VecAudio model)"),inr=l(),pT=a("li"),h3e=a("strong"),dnr=o("hubert"),cnr=o(" \u2014 "),SW=a("a"),fnr=o("HubertForSequenceClassification"),mnr=o(" (Hubert model)"),gnr=l(),uT=a("li"),p3e=a("strong"),hnr=o("sew"),pnr=o(" \u2014 "),RW=a("a"),unr=o("SEWForSequenceClassification"),_nr=o(" (SEW model)"),bnr=l(),_T=a("li"),u3e=a("strong"),vnr=o("sew-d"),Fnr=o(" \u2014 "),PW=a("a"),Tnr=o("SEWDForSequenceClassification"),Mnr=o(" (SEW-D model)"),Enr=l(),bT=a("li"),_3e=a("strong"),Cnr=o("unispeech"),wnr=o(" \u2014 "),BW=a("a"),Anr=o("UniSpeechForSequenceClassification"),Lnr=o(" (UniSpeech model)"),ynr=l(),vT=a("li"),b3e=a("strong"),xnr=o("unispeech-sat"),$nr=o(" \u2014 "),IW=a("a"),knr=o("UniSpeechSatForSequenceClassification"),Snr=o(" (UniSpeechSat model)"),Rnr=l(),FT=a("li"),v3e=a("strong"),Pnr=o("wav2vec2"),Bnr=o(" \u2014 "),NW=a("a"),Inr=o("Wav2Vec2ForSequenceClassification"),Nnr=o(" (Wav2Vec2 model)"),qnr=l(),TT=a("li"),F3e=a("strong"),jnr=o("wav2vec2-conformer"),Dnr=o(" \u2014 "),qW=a("a"),Gnr=o("Wav2Vec2ConformerForSequenceClassification"),Onr=o(" (Wav2Vec2-Conformer model)"),Vnr=l(),MT=a("li"),T3e=a("strong"),Xnr=o("wavlm"),znr=o(" \u2014 "),jW=a("a"),Wnr=o("WavLMForSequenceClassification"),Qnr=o(" (WavLM model)"),Hnr=l(),ET=a("p"),Unr=o("The model is set in evaluation mode by default using "),M3e=a("code"),Jnr=o("model.eval()"),Ynr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E3e=a("code"),Knr=o("model.train()"),Znr=l(),F(CT.$$.fragment),iOe=l(),Ad=a("h2"),wT=a("a"),C3e=a("span"),F(_8.$$.fragment),esr=l(),w3e=a("span"),osr=o("AutoModelForAudioFrameClassification"),dOe=l(),Xo=a("div"),F(b8.$$.fragment),rsr=l(),Ld=a("p"),tsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),DW=a("a"),asr=o("from_pretrained()"),nsr=o(" class method or the "),GW=a("a"),ssr=o("from_config()"),lsr=o(` class
method.`),isr=l(),v8=a("p"),dsr=o("This class cannot be instantiated directly using "),A3e=a("code"),csr=o("__init__()"),fsr=o(" (throws an error)."),msr=l(),Tt=a("div"),F(F8.$$.fragment),gsr=l(),L3e=a("p"),hsr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),psr=l(),yd=a("p"),usr=o(`Note:
Loading a model from its configuration file does `),y3e=a("strong"),_sr=o("not"),bsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=a("a"),vsr=o("from_pretrained()"),Fsr=o(" to load the model weights."),Tsr=l(),F(AT.$$.fragment),Msr=l(),mo=a("div"),F(T8.$$.fragment),Esr=l(),x3e=a("p"),Csr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),wsr=l(),Qa=a("p"),Asr=o("The model class to instantiate is selected based on the "),$3e=a("code"),Lsr=o("model_type"),ysr=o(` property of the config object (either
passed as an argument or loaded from `),k3e=a("code"),xsr=o("pretrained_model_name_or_path"),$sr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S3e=a("code"),ksr=o("pretrained_model_name_or_path"),Ssr=o(":"),Rsr=l(),et=a("ul"),LT=a("li"),R3e=a("strong"),Psr=o("data2vec-audio"),Bsr=o(" \u2014 "),VW=a("a"),Isr=o("Data2VecAudioForAudioFrameClassification"),Nsr=o(" (Data2VecAudio model)"),qsr=l(),yT=a("li"),P3e=a("strong"),jsr=o("unispeech-sat"),Dsr=o(" \u2014 "),XW=a("a"),Gsr=o("UniSpeechSatForAudioFrameClassification"),Osr=o(" (UniSpeechSat model)"),Vsr=l(),xT=a("li"),B3e=a("strong"),Xsr=o("wav2vec2"),zsr=o(" \u2014 "),zW=a("a"),Wsr=o("Wav2Vec2ForAudioFrameClassification"),Qsr=o(" (Wav2Vec2 model)"),Hsr=l(),$T=a("li"),I3e=a("strong"),Usr=o("wav2vec2-conformer"),Jsr=o(" \u2014 "),WW=a("a"),Ysr=o("Wav2Vec2ConformerForAudioFrameClassification"),Ksr=o(" (Wav2Vec2-Conformer model)"),Zsr=l(),kT=a("li"),N3e=a("strong"),elr=o("wavlm"),olr=o(" \u2014 "),QW=a("a"),rlr=o("WavLMForAudioFrameClassification"),tlr=o(" (WavLM model)"),alr=l(),ST=a("p"),nlr=o("The model is set in evaluation mode by default using "),q3e=a("code"),slr=o("model.eval()"),llr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j3e=a("code"),ilr=o("model.train()"),dlr=l(),F(RT.$$.fragment),cOe=l(),xd=a("h2"),PT=a("a"),D3e=a("span"),F(M8.$$.fragment),clr=l(),G3e=a("span"),flr=o("AutoModelForCTC"),fOe=l(),zo=a("div"),F(E8.$$.fragment),mlr=l(),$d=a("p"),glr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),HW=a("a"),hlr=o("from_pretrained()"),plr=o(" class method or the "),UW=a("a"),ulr=o("from_config()"),_lr=o(` class
method.`),blr=l(),C8=a("p"),vlr=o("This class cannot be instantiated directly using "),O3e=a("code"),Flr=o("__init__()"),Tlr=o(" (throws an error)."),Mlr=l(),Mt=a("div"),F(w8.$$.fragment),Elr=l(),V3e=a("p"),Clr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),wlr=l(),kd=a("p"),Alr=o(`Note:
Loading a model from its configuration file does `),X3e=a("strong"),Llr=o("not"),ylr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JW=a("a"),xlr=o("from_pretrained()"),$lr=o(" to load the model weights."),klr=l(),F(BT.$$.fragment),Slr=l(),go=a("div"),F(A8.$$.fragment),Rlr=l(),z3e=a("p"),Plr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Blr=l(),Ha=a("p"),Ilr=o("The model class to instantiate is selected based on the "),W3e=a("code"),Nlr=o("model_type"),qlr=o(` property of the config object (either
passed as an argument or loaded from `),Q3e=a("code"),jlr=o("pretrained_model_name_or_path"),Dlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H3e=a("code"),Glr=o("pretrained_model_name_or_path"),Olr=o(":"),Vlr=l(),Le=a("ul"),IT=a("li"),U3e=a("strong"),Xlr=o("data2vec-audio"),zlr=o(" \u2014 "),YW=a("a"),Wlr=o("Data2VecAudioForCTC"),Qlr=o(" (Data2VecAudio model)"),Hlr=l(),NT=a("li"),J3e=a("strong"),Ulr=o("hubert"),Jlr=o(" \u2014 "),KW=a("a"),Ylr=o("HubertForCTC"),Klr=o(" (Hubert model)"),Zlr=l(),qT=a("li"),Y3e=a("strong"),eir=o("mctct"),oir=o(" \u2014 "),ZW=a("a"),rir=o("MCTCTForCTC"),tir=o(" (M-CTC-T model)"),air=l(),jT=a("li"),K3e=a("strong"),nir=o("sew"),sir=o(" \u2014 "),eQ=a("a"),lir=o("SEWForCTC"),iir=o(" (SEW model)"),dir=l(),DT=a("li"),Z3e=a("strong"),cir=o("sew-d"),fir=o(" \u2014 "),oQ=a("a"),mir=o("SEWDForCTC"),gir=o(" (SEW-D model)"),hir=l(),GT=a("li"),e2e=a("strong"),pir=o("unispeech"),uir=o(" \u2014 "),rQ=a("a"),_ir=o("UniSpeechForCTC"),bir=o(" (UniSpeech model)"),vir=l(),OT=a("li"),o2e=a("strong"),Fir=o("unispeech-sat"),Tir=o(" \u2014 "),tQ=a("a"),Mir=o("UniSpeechSatForCTC"),Eir=o(" (UniSpeechSat model)"),Cir=l(),VT=a("li"),r2e=a("strong"),wir=o("wav2vec2"),Air=o(" \u2014 "),aQ=a("a"),Lir=o("Wav2Vec2ForCTC"),yir=o(" (Wav2Vec2 model)"),xir=l(),XT=a("li"),t2e=a("strong"),$ir=o("wav2vec2-conformer"),kir=o(" \u2014 "),nQ=a("a"),Sir=o("Wav2Vec2ConformerForCTC"),Rir=o(" (Wav2Vec2-Conformer model)"),Pir=l(),zT=a("li"),a2e=a("strong"),Bir=o("wavlm"),Iir=o(" \u2014 "),sQ=a("a"),Nir=o("WavLMForCTC"),qir=o(" (WavLM model)"),jir=l(),WT=a("p"),Dir=o("The model is set in evaluation mode by default using "),n2e=a("code"),Gir=o("model.eval()"),Oir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s2e=a("code"),Vir=o("model.train()"),Xir=l(),F(QT.$$.fragment),mOe=l(),Sd=a("h2"),HT=a("a"),l2e=a("span"),F(L8.$$.fragment),zir=l(),i2e=a("span"),Wir=o("AutoModelForSpeechSeq2Seq"),gOe=l(),Wo=a("div"),F(y8.$$.fragment),Qir=l(),Rd=a("p"),Hir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),lQ=a("a"),Uir=o("from_pretrained()"),Jir=o(" class method or the "),iQ=a("a"),Yir=o("from_config()"),Kir=o(` class
method.`),Zir=l(),x8=a("p"),edr=o("This class cannot be instantiated directly using "),d2e=a("code"),odr=o("__init__()"),rdr=o(" (throws an error)."),tdr=l(),Et=a("div"),F($8.$$.fragment),adr=l(),c2e=a("p"),ndr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),sdr=l(),Pd=a("p"),ldr=o(`Note:
Loading a model from its configuration file does `),f2e=a("strong"),idr=o("not"),ddr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dQ=a("a"),cdr=o("from_pretrained()"),fdr=o(" to load the model weights."),mdr=l(),F(UT.$$.fragment),gdr=l(),ho=a("div"),F(k8.$$.fragment),hdr=l(),m2e=a("p"),pdr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),udr=l(),Ua=a("p"),_dr=o("The model class to instantiate is selected based on the "),g2e=a("code"),bdr=o("model_type"),vdr=o(` property of the config object (either
passed as an argument or loaded from `),h2e=a("code"),Fdr=o("pretrained_model_name_or_path"),Tdr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p2e=a("code"),Mdr=o("pretrained_model_name_or_path"),Edr=o(":"),Cdr=l(),S8=a("ul"),JT=a("li"),u2e=a("strong"),wdr=o("speech-encoder-decoder"),Adr=o(" \u2014 "),cQ=a("a"),Ldr=o("SpeechEncoderDecoderModel"),ydr=o(" (Speech Encoder decoder model)"),xdr=l(),YT=a("li"),_2e=a("strong"),$dr=o("speech_to_text"),kdr=o(" \u2014 "),fQ=a("a"),Sdr=o("Speech2TextForConditionalGeneration"),Rdr=o(" (Speech2Text model)"),Pdr=l(),KT=a("p"),Bdr=o("The model is set in evaluation mode by default using "),b2e=a("code"),Idr=o("model.eval()"),Ndr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v2e=a("code"),qdr=o("model.train()"),jdr=l(),F(ZT.$$.fragment),hOe=l(),Bd=a("h2"),e7=a("a"),F2e=a("span"),F(R8.$$.fragment),Ddr=l(),T2e=a("span"),Gdr=o("AutoModelForAudioXVector"),pOe=l(),Qo=a("div"),F(P8.$$.fragment),Odr=l(),Id=a("p"),Vdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),mQ=a("a"),Xdr=o("from_pretrained()"),zdr=o(" class method or the "),gQ=a("a"),Wdr=o("from_config()"),Qdr=o(` class
method.`),Hdr=l(),B8=a("p"),Udr=o("This class cannot be instantiated directly using "),M2e=a("code"),Jdr=o("__init__()"),Ydr=o(" (throws an error)."),Kdr=l(),Ct=a("div"),F(I8.$$.fragment),Zdr=l(),E2e=a("p"),ecr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),ocr=l(),Nd=a("p"),rcr=o(`Note:
Loading a model from its configuration file does `),C2e=a("strong"),tcr=o("not"),acr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hQ=a("a"),ncr=o("from_pretrained()"),scr=o(" to load the model weights."),lcr=l(),F(o7.$$.fragment),icr=l(),po=a("div"),F(N8.$$.fragment),dcr=l(),w2e=a("p"),ccr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),fcr=l(),Ja=a("p"),mcr=o("The model class to instantiate is selected based on the "),A2e=a("code"),gcr=o("model_type"),hcr=o(` property of the config object (either
passed as an argument or loaded from `),L2e=a("code"),pcr=o("pretrained_model_name_or_path"),ucr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y2e=a("code"),_cr=o("pretrained_model_name_or_path"),bcr=o(":"),vcr=l(),ot=a("ul"),r7=a("li"),x2e=a("strong"),Fcr=o("data2vec-audio"),Tcr=o(" \u2014 "),pQ=a("a"),Mcr=o("Data2VecAudioForXVector"),Ecr=o(" (Data2VecAudio model)"),Ccr=l(),t7=a("li"),$2e=a("strong"),wcr=o("unispeech-sat"),Acr=o(" \u2014 "),uQ=a("a"),Lcr=o("UniSpeechSatForXVector"),ycr=o(" (UniSpeechSat model)"),xcr=l(),a7=a("li"),k2e=a("strong"),$cr=o("wav2vec2"),kcr=o(" \u2014 "),_Q=a("a"),Scr=o("Wav2Vec2ForXVector"),Rcr=o(" (Wav2Vec2 model)"),Pcr=l(),n7=a("li"),S2e=a("strong"),Bcr=o("wav2vec2-conformer"),Icr=o(" \u2014 "),bQ=a("a"),Ncr=o("Wav2Vec2ConformerForXVector"),qcr=o(" (Wav2Vec2-Conformer model)"),jcr=l(),s7=a("li"),R2e=a("strong"),Dcr=o("wavlm"),Gcr=o(" \u2014 "),vQ=a("a"),Ocr=o("WavLMForXVector"),Vcr=o(" (WavLM model)"),Xcr=l(),l7=a("p"),zcr=o("The model is set in evaluation mode by default using "),P2e=a("code"),Wcr=o("model.eval()"),Qcr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B2e=a("code"),Hcr=o("model.train()"),Ucr=l(),F(i7.$$.fragment),uOe=l(),qd=a("h2"),d7=a("a"),I2e=a("span"),F(q8.$$.fragment),Jcr=l(),N2e=a("span"),Ycr=o("AutoModelForMaskedImageModeling"),_Oe=l(),Ho=a("div"),F(j8.$$.fragment),Kcr=l(),jd=a("p"),Zcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),FQ=a("a"),efr=o("from_pretrained()"),ofr=o(" class method or the "),TQ=a("a"),rfr=o("from_config()"),tfr=o(` class
method.`),afr=l(),D8=a("p"),nfr=o("This class cannot be instantiated directly using "),q2e=a("code"),sfr=o("__init__()"),lfr=o(" (throws an error)."),ifr=l(),wt=a("div"),F(G8.$$.fragment),dfr=l(),j2e=a("p"),cfr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),ffr=l(),Dd=a("p"),mfr=o(`Note:
Loading a model from its configuration file does `),D2e=a("strong"),gfr=o("not"),hfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MQ=a("a"),pfr=o("from_pretrained()"),ufr=o(" to load the model weights."),_fr=l(),F(c7.$$.fragment),bfr=l(),uo=a("div"),F(O8.$$.fragment),vfr=l(),G2e=a("p"),Ffr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Tfr=l(),Ya=a("p"),Mfr=o("The model class to instantiate is selected based on the "),O2e=a("code"),Efr=o("model_type"),Cfr=o(` property of the config object (either
passed as an argument or loaded from `),V2e=a("code"),wfr=o("pretrained_model_name_or_path"),Afr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X2e=a("code"),Lfr=o("pretrained_model_name_or_path"),yfr=o(":"),xfr=l(),Gd=a("ul"),f7=a("li"),z2e=a("strong"),$fr=o("deit"),kfr=o(" \u2014 "),EQ=a("a"),Sfr=o("DeiTForMaskedImageModeling"),Rfr=o(" (DeiT model)"),Pfr=l(),m7=a("li"),W2e=a("strong"),Bfr=o("swin"),Ifr=o(" \u2014 "),CQ=a("a"),Nfr=o("SwinForMaskedImageModeling"),qfr=o(" (Swin Transformer model)"),jfr=l(),g7=a("li"),Q2e=a("strong"),Dfr=o("vit"),Gfr=o(" \u2014 "),wQ=a("a"),Ofr=o("ViTForMaskedImageModeling"),Vfr=o(" (ViT model)"),Xfr=l(),h7=a("p"),zfr=o("The model is set in evaluation mode by default using "),H2e=a("code"),Wfr=o("model.eval()"),Qfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U2e=a("code"),Hfr=o("model.train()"),Ufr=l(),F(p7.$$.fragment),bOe=l(),Od=a("h2"),u7=a("a"),J2e=a("span"),F(V8.$$.fragment),Jfr=l(),Y2e=a("span"),Yfr=o("AutoModelForObjectDetection"),vOe=l(),Uo=a("div"),F(X8.$$.fragment),Kfr=l(),Vd=a("p"),Zfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),AQ=a("a"),emr=o("from_pretrained()"),omr=o(" class method or the "),LQ=a("a"),rmr=o("from_config()"),tmr=o(` class
method.`),amr=l(),z8=a("p"),nmr=o("This class cannot be instantiated directly using "),K2e=a("code"),smr=o("__init__()"),lmr=o(" (throws an error)."),imr=l(),At=a("div"),F(W8.$$.fragment),dmr=l(),Z2e=a("p"),cmr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),fmr=l(),Xd=a("p"),mmr=o(`Note:
Loading a model from its configuration file does `),ebe=a("strong"),gmr=o("not"),hmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yQ=a("a"),pmr=o("from_pretrained()"),umr=o(" to load the model weights."),_mr=l(),F(_7.$$.fragment),bmr=l(),_o=a("div"),F(Q8.$$.fragment),vmr=l(),obe=a("p"),Fmr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Tmr=l(),Ka=a("p"),Mmr=o("The model class to instantiate is selected based on the "),rbe=a("code"),Emr=o("model_type"),Cmr=o(` property of the config object (either
passed as an argument or loaded from `),tbe=a("code"),wmr=o("pretrained_model_name_or_path"),Amr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),abe=a("code"),Lmr=o("pretrained_model_name_or_path"),ymr=o(":"),xmr=l(),H8=a("ul"),b7=a("li"),nbe=a("strong"),$mr=o("detr"),kmr=o(" \u2014 "),xQ=a("a"),Smr=o("DetrForObjectDetection"),Rmr=o(" (DETR model)"),Pmr=l(),v7=a("li"),sbe=a("strong"),Bmr=o("yolos"),Imr=o(" \u2014 "),$Q=a("a"),Nmr=o("YolosForObjectDetection"),qmr=o(" (YOLOS model)"),jmr=l(),F7=a("p"),Dmr=o("The model is set in evaluation mode by default using "),lbe=a("code"),Gmr=o("model.eval()"),Omr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ibe=a("code"),Vmr=o("model.train()"),Xmr=l(),F(T7.$$.fragment),FOe=l(),zd=a("h2"),M7=a("a"),dbe=a("span"),F(U8.$$.fragment),zmr=l(),cbe=a("span"),Wmr=o("AutoModelForImageSegmentation"),TOe=l(),Jo=a("div"),F(J8.$$.fragment),Qmr=l(),Wd=a("p"),Hmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),kQ=a("a"),Umr=o("from_pretrained()"),Jmr=o(" class method or the "),SQ=a("a"),Ymr=o("from_config()"),Kmr=o(` class
method.`),Zmr=l(),Y8=a("p"),egr=o("This class cannot be instantiated directly using "),fbe=a("code"),ogr=o("__init__()"),rgr=o(" (throws an error)."),tgr=l(),Lt=a("div"),F(K8.$$.fragment),agr=l(),mbe=a("p"),ngr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),sgr=l(),Qd=a("p"),lgr=o(`Note:
Loading a model from its configuration file does `),gbe=a("strong"),igr=o("not"),dgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RQ=a("a"),cgr=o("from_pretrained()"),fgr=o(" to load the model weights."),mgr=l(),F(E7.$$.fragment),ggr=l(),bo=a("div"),F(Z8.$$.fragment),hgr=l(),hbe=a("p"),pgr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),ugr=l(),Za=a("p"),_gr=o("The model class to instantiate is selected based on the "),pbe=a("code"),bgr=o("model_type"),vgr=o(` property of the config object (either
passed as an argument or loaded from `),ube=a("code"),Fgr=o("pretrained_model_name_or_path"),Tgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_be=a("code"),Mgr=o("pretrained_model_name_or_path"),Egr=o(":"),Cgr=l(),bbe=a("ul"),C7=a("li"),vbe=a("strong"),wgr=o("detr"),Agr=o(" \u2014 "),PQ=a("a"),Lgr=o("DetrForSegmentation"),ygr=o(" (DETR model)"),xgr=l(),w7=a("p"),$gr=o("The model is set in evaluation mode by default using "),Fbe=a("code"),kgr=o("model.eval()"),Sgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tbe=a("code"),Rgr=o("model.train()"),Pgr=l(),F(A7.$$.fragment),MOe=l(),Hd=a("h2"),L7=a("a"),Mbe=a("span"),F(e9.$$.fragment),Bgr=l(),Ebe=a("span"),Igr=o("AutoModelForSemanticSegmentation"),EOe=l(),Yo=a("div"),F(o9.$$.fragment),Ngr=l(),Ud=a("p"),qgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),BQ=a("a"),jgr=o("from_pretrained()"),Dgr=o(" class method or the "),IQ=a("a"),Ggr=o("from_config()"),Ogr=o(` class
method.`),Vgr=l(),r9=a("p"),Xgr=o("This class cannot be instantiated directly using "),Cbe=a("code"),zgr=o("__init__()"),Wgr=o(" (throws an error)."),Qgr=l(),yt=a("div"),F(t9.$$.fragment),Hgr=l(),wbe=a("p"),Ugr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Jgr=l(),Jd=a("p"),Ygr=o(`Note:
Loading a model from its configuration file does `),Abe=a("strong"),Kgr=o("not"),Zgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NQ=a("a"),ehr=o("from_pretrained()"),ohr=o(" to load the model weights."),rhr=l(),F(y7.$$.fragment),thr=l(),vo=a("div"),F(a9.$$.fragment),ahr=l(),Lbe=a("p"),nhr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),shr=l(),en=a("p"),lhr=o("The model class to instantiate is selected based on the "),ybe=a("code"),ihr=o("model_type"),dhr=o(` property of the config object (either
passed as an argument or loaded from `),xbe=a("code"),chr=o("pretrained_model_name_or_path"),fhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$be=a("code"),mhr=o("pretrained_model_name_or_path"),ghr=o(":"),hhr=l(),on=a("ul"),x7=a("li"),kbe=a("strong"),phr=o("beit"),uhr=o(" \u2014 "),qQ=a("a"),_hr=o("BeitForSemanticSegmentation"),bhr=o(" (BEiT model)"),vhr=l(),$7=a("li"),Sbe=a("strong"),Fhr=o("data2vec-vision"),Thr=o(" \u2014 "),jQ=a("a"),Mhr=o("Data2VecVisionForSemanticSegmentation"),Ehr=o(" (Data2VecVision model)"),Chr=l(),k7=a("li"),Rbe=a("strong"),whr=o("dpt"),Ahr=o(" \u2014 "),DQ=a("a"),Lhr=o("DPTForSemanticSegmentation"),yhr=o(" (DPT model)"),xhr=l(),S7=a("li"),Pbe=a("strong"),$hr=o("segformer"),khr=o(" \u2014 "),GQ=a("a"),Shr=o("SegformerForSemanticSegmentation"),Rhr=o(" (SegFormer model)"),Phr=l(),R7=a("p"),Bhr=o("The model is set in evaluation mode by default using "),Bbe=a("code"),Ihr=o("model.eval()"),Nhr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=a("code"),qhr=o("model.train()"),jhr=l(),F(P7.$$.fragment),COe=l(),Yd=a("h2"),B7=a("a"),Nbe=a("span"),F(n9.$$.fragment),Dhr=l(),qbe=a("span"),Ghr=o("AutoModelForInstanceSegmentation"),wOe=l(),Ko=a("div"),F(s9.$$.fragment),Ohr=l(),Kd=a("p"),Vhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),OQ=a("a"),Xhr=o("from_pretrained()"),zhr=o(" class method or the "),VQ=a("a"),Whr=o("from_config()"),Qhr=o(` class
method.`),Hhr=l(),l9=a("p"),Uhr=o("This class cannot be instantiated directly using "),jbe=a("code"),Jhr=o("__init__()"),Yhr=o(" (throws an error)."),Khr=l(),xt=a("div"),F(i9.$$.fragment),Zhr=l(),Dbe=a("p"),epr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),opr=l(),Zd=a("p"),rpr=o(`Note:
Loading a model from its configuration file does `),Gbe=a("strong"),tpr=o("not"),apr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XQ=a("a"),npr=o("from_pretrained()"),spr=o(" to load the model weights."),lpr=l(),F(I7.$$.fragment),ipr=l(),Fo=a("div"),F(d9.$$.fragment),dpr=l(),Obe=a("p"),cpr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),fpr=l(),rn=a("p"),mpr=o("The model class to instantiate is selected based on the "),Vbe=a("code"),gpr=o("model_type"),hpr=o(` property of the config object (either
passed as an argument or loaded from `),Xbe=a("code"),ppr=o("pretrained_model_name_or_path"),upr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=a("code"),_pr=o("pretrained_model_name_or_path"),bpr=o(":"),vpr=l(),Wbe=a("ul"),N7=a("li"),Qbe=a("strong"),Fpr=o("maskformer"),Tpr=o(" \u2014 "),zQ=a("a"),Mpr=o("MaskFormerForInstanceSegmentation"),Epr=o(" (MaskFormer model)"),Cpr=l(),q7=a("p"),wpr=o("The model is set in evaluation mode by default using "),Hbe=a("code"),Apr=o("model.eval()"),Lpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ube=a("code"),ypr=o("model.train()"),xpr=l(),F(j7.$$.fragment),AOe=l(),ec=a("h2"),D7=a("a"),Jbe=a("span"),F(c9.$$.fragment),$pr=l(),Ybe=a("span"),kpr=o("TFAutoModel"),LOe=l(),Zo=a("div"),F(f9.$$.fragment),Spr=l(),oc=a("p"),Rpr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),WQ=a("a"),Ppr=o("from_pretrained()"),Bpr=o(" class method or the "),QQ=a("a"),Ipr=o("from_config()"),Npr=o(` class
method.`),qpr=l(),m9=a("p"),jpr=o("This class cannot be instantiated directly using "),Kbe=a("code"),Dpr=o("__init__()"),Gpr=o(" (throws an error)."),Opr=l(),$t=a("div"),F(g9.$$.fragment),Vpr=l(),Zbe=a("p"),Xpr=o("Instantiates one of the base model classes of the library from a configuration."),zpr=l(),rc=a("p"),Wpr=o(`Note:
Loading a model from its configuration file does `),eve=a("strong"),Qpr=o("not"),Hpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HQ=a("a"),Upr=o("from_pretrained()"),Jpr=o(" to load the model weights."),Ypr=l(),F(G7.$$.fragment),Kpr=l(),Lr=a("div"),F(h9.$$.fragment),Zpr=l(),ove=a("p"),eur=o("Instantiate one of the base model classes of the library from a pretrained model."),our=l(),tn=a("p"),rur=o("The model class to instantiate is selected based on the "),rve=a("code"),tur=o("model_type"),aur=o(` property of the config object (either
passed as an argument or loaded from `),tve=a("code"),nur=o("pretrained_model_name_or_path"),sur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ave=a("code"),lur=o("pretrained_model_name_or_path"),iur=o(":"),dur=l(),q=a("ul"),O7=a("li"),nve=a("strong"),cur=o("albert"),fur=o(" \u2014 "),UQ=a("a"),mur=o("TFAlbertModel"),gur=o(" (ALBERT model)"),hur=l(),V7=a("li"),sve=a("strong"),pur=o("bart"),uur=o(" \u2014 "),JQ=a("a"),_ur=o("TFBartModel"),bur=o(" (BART model)"),vur=l(),X7=a("li"),lve=a("strong"),Fur=o("bert"),Tur=o(" \u2014 "),YQ=a("a"),Mur=o("TFBertModel"),Eur=o(" (BERT model)"),Cur=l(),z7=a("li"),ive=a("strong"),wur=o("blenderbot"),Aur=o(" \u2014 "),KQ=a("a"),Lur=o("TFBlenderbotModel"),yur=o(" (Blenderbot model)"),xur=l(),W7=a("li"),dve=a("strong"),$ur=o("blenderbot-small"),kur=o(" \u2014 "),ZQ=a("a"),Sur=o("TFBlenderbotSmallModel"),Rur=o(" (BlenderbotSmall model)"),Pur=l(),Q7=a("li"),cve=a("strong"),Bur=o("camembert"),Iur=o(" \u2014 "),eH=a("a"),Nur=o("TFCamembertModel"),qur=o(" (CamemBERT model)"),jur=l(),H7=a("li"),fve=a("strong"),Dur=o("clip"),Gur=o(" \u2014 "),oH=a("a"),Our=o("TFCLIPModel"),Vur=o(" (CLIP model)"),Xur=l(),U7=a("li"),mve=a("strong"),zur=o("convbert"),Wur=o(" \u2014 "),rH=a("a"),Qur=o("TFConvBertModel"),Hur=o(" (ConvBERT model)"),Uur=l(),J7=a("li"),gve=a("strong"),Jur=o("convnext"),Yur=o(" \u2014 "),tH=a("a"),Kur=o("TFConvNextModel"),Zur=o(" (ConvNeXT model)"),e_r=l(),Y7=a("li"),hve=a("strong"),o_r=o("ctrl"),r_r=o(" \u2014 "),aH=a("a"),t_r=o("TFCTRLModel"),a_r=o(" (CTRL model)"),n_r=l(),K7=a("li"),pve=a("strong"),s_r=o("data2vec-vision"),l_r=o(" \u2014 "),nH=a("a"),i_r=o("TFData2VecVisionModel"),d_r=o(" (Data2VecVision model)"),c_r=l(),Z7=a("li"),uve=a("strong"),f_r=o("deberta"),m_r=o(" \u2014 "),sH=a("a"),g_r=o("TFDebertaModel"),h_r=o(" (DeBERTa model)"),p_r=l(),eM=a("li"),_ve=a("strong"),u_r=o("deberta-v2"),__r=o(" \u2014 "),lH=a("a"),b_r=o("TFDebertaV2Model"),v_r=o(" (DeBERTa-v2 model)"),F_r=l(),oM=a("li"),bve=a("strong"),T_r=o("distilbert"),M_r=o(" \u2014 "),iH=a("a"),E_r=o("TFDistilBertModel"),C_r=o(" (DistilBERT model)"),w_r=l(),rM=a("li"),vve=a("strong"),A_r=o("dpr"),L_r=o(" \u2014 "),dH=a("a"),y_r=o("TFDPRQuestionEncoder"),x_r=o(" (DPR model)"),$_r=l(),tM=a("li"),Fve=a("strong"),k_r=o("electra"),S_r=o(" \u2014 "),cH=a("a"),R_r=o("TFElectraModel"),P_r=o(" (ELECTRA model)"),B_r=l(),aM=a("li"),Tve=a("strong"),I_r=o("flaubert"),N_r=o(" \u2014 "),fH=a("a"),q_r=o("TFFlaubertModel"),j_r=o(" (FlauBERT model)"),D_r=l(),zs=a("li"),Mve=a("strong"),G_r=o("funnel"),O_r=o(" \u2014 "),mH=a("a"),V_r=o("TFFunnelModel"),X_r=o(" or "),gH=a("a"),z_r=o("TFFunnelBaseModel"),W_r=o(" (Funnel Transformer model)"),Q_r=l(),nM=a("li"),Eve=a("strong"),H_r=o("gpt2"),U_r=o(" \u2014 "),hH=a("a"),J_r=o("TFGPT2Model"),Y_r=o(" (OpenAI GPT-2 model)"),K_r=l(),sM=a("li"),Cve=a("strong"),Z_r=o("gptj"),e1r=o(" \u2014 "),pH=a("a"),o1r=o("TFGPTJModel"),r1r=o(" (GPT-J model)"),t1r=l(),lM=a("li"),wve=a("strong"),a1r=o("hubert"),n1r=o(" \u2014 "),uH=a("a"),s1r=o("TFHubertModel"),l1r=o(" (Hubert model)"),i1r=l(),iM=a("li"),Ave=a("strong"),d1r=o("layoutlm"),c1r=o(" \u2014 "),_H=a("a"),f1r=o("TFLayoutLMModel"),m1r=o(" (LayoutLM model)"),g1r=l(),dM=a("li"),Lve=a("strong"),h1r=o("led"),p1r=o(" \u2014 "),bH=a("a"),u1r=o("TFLEDModel"),_1r=o(" (LED model)"),b1r=l(),cM=a("li"),yve=a("strong"),v1r=o("longformer"),F1r=o(" \u2014 "),vH=a("a"),T1r=o("TFLongformerModel"),M1r=o(" (Longformer model)"),E1r=l(),fM=a("li"),xve=a("strong"),C1r=o("lxmert"),w1r=o(" \u2014 "),FH=a("a"),A1r=o("TFLxmertModel"),L1r=o(" (LXMERT model)"),y1r=l(),mM=a("li"),$ve=a("strong"),x1r=o("marian"),$1r=o(" \u2014 "),TH=a("a"),k1r=o("TFMarianModel"),S1r=o(" (Marian model)"),R1r=l(),gM=a("li"),kve=a("strong"),P1r=o("mbart"),B1r=o(" \u2014 "),MH=a("a"),I1r=o("TFMBartModel"),N1r=o(" (mBART model)"),q1r=l(),hM=a("li"),Sve=a("strong"),j1r=o("mobilebert"),D1r=o(" \u2014 "),EH=a("a"),G1r=o("TFMobileBertModel"),O1r=o(" (MobileBERT model)"),V1r=l(),pM=a("li"),Rve=a("strong"),X1r=o("mpnet"),z1r=o(" \u2014 "),CH=a("a"),W1r=o("TFMPNetModel"),Q1r=o(" (MPNet model)"),H1r=l(),uM=a("li"),Pve=a("strong"),U1r=o("mt5"),J1r=o(" \u2014 "),wH=a("a"),Y1r=o("TFMT5Model"),K1r=o(" (MT5 model)"),Z1r=l(),_M=a("li"),Bve=a("strong"),e3r=o("openai-gpt"),o3r=o(" \u2014 "),AH=a("a"),r3r=o("TFOpenAIGPTModel"),t3r=o(" (OpenAI GPT model)"),a3r=l(),bM=a("li"),Ive=a("strong"),n3r=o("opt"),s3r=o(" \u2014 "),LH=a("a"),l3r=o("TFOPTModel"),i3r=o(" (OPT model)"),d3r=l(),vM=a("li"),Nve=a("strong"),c3r=o("pegasus"),f3r=o(" \u2014 "),yH=a("a"),m3r=o("TFPegasusModel"),g3r=o(" (Pegasus model)"),h3r=l(),FM=a("li"),qve=a("strong"),p3r=o("rembert"),u3r=o(" \u2014 "),xH=a("a"),_3r=o("TFRemBertModel"),b3r=o(" (RemBERT model)"),v3r=l(),TM=a("li"),jve=a("strong"),F3r=o("roberta"),T3r=o(" \u2014 "),$H=a("a"),M3r=o("TFRobertaModel"),E3r=o(" (RoBERTa model)"),C3r=l(),MM=a("li"),Dve=a("strong"),w3r=o("roformer"),A3r=o(" \u2014 "),kH=a("a"),L3r=o("TFRoFormerModel"),y3r=o(" (RoFormer model)"),x3r=l(),EM=a("li"),Gve=a("strong"),$3r=o("speech_to_text"),k3r=o(" \u2014 "),SH=a("a"),S3r=o("TFSpeech2TextModel"),R3r=o(" (Speech2Text model)"),P3r=l(),CM=a("li"),Ove=a("strong"),B3r=o("swin"),I3r=o(" \u2014 "),RH=a("a"),N3r=o("TFSwinModel"),q3r=o(" (Swin Transformer model)"),j3r=l(),wM=a("li"),Vve=a("strong"),D3r=o("t5"),G3r=o(" \u2014 "),PH=a("a"),O3r=o("TFT5Model"),V3r=o(" (T5 model)"),X3r=l(),AM=a("li"),Xve=a("strong"),z3r=o("tapas"),W3r=o(" \u2014 "),BH=a("a"),Q3r=o("TFTapasModel"),H3r=o(" (TAPAS model)"),U3r=l(),LM=a("li"),zve=a("strong"),J3r=o("transfo-xl"),Y3r=o(" \u2014 "),IH=a("a"),K3r=o("TFTransfoXLModel"),Z3r=o(" (Transformer-XL model)"),e2r=l(),yM=a("li"),Wve=a("strong"),o2r=o("vit"),r2r=o(" \u2014 "),NH=a("a"),t2r=o("TFViTModel"),a2r=o(" (ViT model)"),n2r=l(),xM=a("li"),Qve=a("strong"),s2r=o("vit_mae"),l2r=o(" \u2014 "),qH=a("a"),i2r=o("TFViTMAEModel"),d2r=o(" (ViTMAE model)"),c2r=l(),$M=a("li"),Hve=a("strong"),f2r=o("wav2vec2"),m2r=o(" \u2014 "),jH=a("a"),g2r=o("TFWav2Vec2Model"),h2r=o(" (Wav2Vec2 model)"),p2r=l(),kM=a("li"),Uve=a("strong"),u2r=o("xlm"),_2r=o(" \u2014 "),DH=a("a"),b2r=o("TFXLMModel"),v2r=o(" (XLM model)"),F2r=l(),SM=a("li"),Jve=a("strong"),T2r=o("xlm-roberta"),M2r=o(" \u2014 "),GH=a("a"),E2r=o("TFXLMRobertaModel"),C2r=o(" (XLM-RoBERTa model)"),w2r=l(),RM=a("li"),Yve=a("strong"),A2r=o("xlnet"),L2r=o(" \u2014 "),OH=a("a"),y2r=o("TFXLNetModel"),x2r=o(" (XLNet model)"),$2r=l(),F(PM.$$.fragment),yOe=l(),tc=a("h2"),BM=a("a"),Kve=a("span"),F(p9.$$.fragment),k2r=l(),Zve=a("span"),S2r=o("TFAutoModelForPreTraining"),xOe=l(),er=a("div"),F(u9.$$.fragment),R2r=l(),ac=a("p"),P2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),VH=a("a"),B2r=o("from_pretrained()"),I2r=o(" class method or the "),XH=a("a"),N2r=o("from_config()"),q2r=o(` class
method.`),j2r=l(),_9=a("p"),D2r=o("This class cannot be instantiated directly using "),eFe=a("code"),G2r=o("__init__()"),O2r=o(" (throws an error)."),V2r=l(),kt=a("div"),F(b9.$$.fragment),X2r=l(),oFe=a("p"),z2r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),W2r=l(),nc=a("p"),Q2r=o(`Note:
Loading a model from its configuration file does `),rFe=a("strong"),H2r=o("not"),U2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zH=a("a"),J2r=o("from_pretrained()"),Y2r=o(" to load the model weights."),K2r=l(),F(IM.$$.fragment),Z2r=l(),yr=a("div"),F(v9.$$.fragment),ebr=l(),tFe=a("p"),obr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),rbr=l(),an=a("p"),tbr=o("The model class to instantiate is selected based on the "),aFe=a("code"),abr=o("model_type"),nbr=o(` property of the config object (either
passed as an argument or loaded from `),nFe=a("code"),sbr=o("pretrained_model_name_or_path"),lbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=a("code"),ibr=o("pretrained_model_name_or_path"),dbr=o(":"),cbr=l(),se=a("ul"),NM=a("li"),lFe=a("strong"),fbr=o("albert"),mbr=o(" \u2014 "),WH=a("a"),gbr=o("TFAlbertForPreTraining"),hbr=o(" (ALBERT model)"),pbr=l(),qM=a("li"),iFe=a("strong"),ubr=o("bart"),_br=o(" \u2014 "),QH=a("a"),bbr=o("TFBartForConditionalGeneration"),vbr=o(" (BART model)"),Fbr=l(),jM=a("li"),dFe=a("strong"),Tbr=o("bert"),Mbr=o(" \u2014 "),HH=a("a"),Ebr=o("TFBertForPreTraining"),Cbr=o(" (BERT model)"),wbr=l(),DM=a("li"),cFe=a("strong"),Abr=o("camembert"),Lbr=o(" \u2014 "),UH=a("a"),ybr=o("TFCamembertForMaskedLM"),xbr=o(" (CamemBERT model)"),$br=l(),GM=a("li"),fFe=a("strong"),kbr=o("ctrl"),Sbr=o(" \u2014 "),JH=a("a"),Rbr=o("TFCTRLLMHeadModel"),Pbr=o(" (CTRL model)"),Bbr=l(),OM=a("li"),mFe=a("strong"),Ibr=o("distilbert"),Nbr=o(" \u2014 "),YH=a("a"),qbr=o("TFDistilBertForMaskedLM"),jbr=o(" (DistilBERT model)"),Dbr=l(),VM=a("li"),gFe=a("strong"),Gbr=o("electra"),Obr=o(" \u2014 "),KH=a("a"),Vbr=o("TFElectraForPreTraining"),Xbr=o(" (ELECTRA model)"),zbr=l(),XM=a("li"),hFe=a("strong"),Wbr=o("flaubert"),Qbr=o(" \u2014 "),ZH=a("a"),Hbr=o("TFFlaubertWithLMHeadModel"),Ubr=o(" (FlauBERT model)"),Jbr=l(),zM=a("li"),pFe=a("strong"),Ybr=o("funnel"),Kbr=o(" \u2014 "),eU=a("a"),Zbr=o("TFFunnelForPreTraining"),evr=o(" (Funnel Transformer model)"),ovr=l(),WM=a("li"),uFe=a("strong"),rvr=o("gpt2"),tvr=o(" \u2014 "),oU=a("a"),avr=o("TFGPT2LMHeadModel"),nvr=o(" (OpenAI GPT-2 model)"),svr=l(),QM=a("li"),_Fe=a("strong"),lvr=o("layoutlm"),ivr=o(" \u2014 "),rU=a("a"),dvr=o("TFLayoutLMForMaskedLM"),cvr=o(" (LayoutLM model)"),fvr=l(),HM=a("li"),bFe=a("strong"),mvr=o("lxmert"),gvr=o(" \u2014 "),tU=a("a"),hvr=o("TFLxmertForPreTraining"),pvr=o(" (LXMERT model)"),uvr=l(),UM=a("li"),vFe=a("strong"),_vr=o("mobilebert"),bvr=o(" \u2014 "),aU=a("a"),vvr=o("TFMobileBertForPreTraining"),Fvr=o(" (MobileBERT model)"),Tvr=l(),JM=a("li"),FFe=a("strong"),Mvr=o("mpnet"),Evr=o(" \u2014 "),nU=a("a"),Cvr=o("TFMPNetForMaskedLM"),wvr=o(" (MPNet model)"),Avr=l(),YM=a("li"),TFe=a("strong"),Lvr=o("openai-gpt"),yvr=o(" \u2014 "),sU=a("a"),xvr=o("TFOpenAIGPTLMHeadModel"),$vr=o(" (OpenAI GPT model)"),kvr=l(),KM=a("li"),MFe=a("strong"),Svr=o("roberta"),Rvr=o(" \u2014 "),lU=a("a"),Pvr=o("TFRobertaForMaskedLM"),Bvr=o(" (RoBERTa model)"),Ivr=l(),ZM=a("li"),EFe=a("strong"),Nvr=o("t5"),qvr=o(" \u2014 "),iU=a("a"),jvr=o("TFT5ForConditionalGeneration"),Dvr=o(" (T5 model)"),Gvr=l(),eE=a("li"),CFe=a("strong"),Ovr=o("tapas"),Vvr=o(" \u2014 "),dU=a("a"),Xvr=o("TFTapasForMaskedLM"),zvr=o(" (TAPAS model)"),Wvr=l(),oE=a("li"),wFe=a("strong"),Qvr=o("transfo-xl"),Hvr=o(" \u2014 "),cU=a("a"),Uvr=o("TFTransfoXLLMHeadModel"),Jvr=o(" (Transformer-XL model)"),Yvr=l(),rE=a("li"),AFe=a("strong"),Kvr=o("vit_mae"),Zvr=o(" \u2014 "),fU=a("a"),eFr=o("TFViTMAEForPreTraining"),oFr=o(" (ViTMAE model)"),rFr=l(),tE=a("li"),LFe=a("strong"),tFr=o("xlm"),aFr=o(" \u2014 "),mU=a("a"),nFr=o("TFXLMWithLMHeadModel"),sFr=o(" (XLM model)"),lFr=l(),aE=a("li"),yFe=a("strong"),iFr=o("xlm-roberta"),dFr=o(" \u2014 "),gU=a("a"),cFr=o("TFXLMRobertaForMaskedLM"),fFr=o(" (XLM-RoBERTa model)"),mFr=l(),nE=a("li"),xFe=a("strong"),gFr=o("xlnet"),hFr=o(" \u2014 "),hU=a("a"),pFr=o("TFXLNetLMHeadModel"),uFr=o(" (XLNet model)"),_Fr=l(),F(sE.$$.fragment),$Oe=l(),sc=a("h2"),lE=a("a"),$Fe=a("span"),F(F9.$$.fragment),bFr=l(),kFe=a("span"),vFr=o("TFAutoModelForCausalLM"),kOe=l(),or=a("div"),F(T9.$$.fragment),FFr=l(),lc=a("p"),TFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),pU=a("a"),MFr=o("from_pretrained()"),EFr=o(" class method or the "),uU=a("a"),CFr=o("from_config()"),wFr=o(` class
method.`),AFr=l(),M9=a("p"),LFr=o("This class cannot be instantiated directly using "),SFe=a("code"),yFr=o("__init__()"),xFr=o(" (throws an error)."),$Fr=l(),St=a("div"),F(E9.$$.fragment),kFr=l(),RFe=a("p"),SFr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),RFr=l(),ic=a("p"),PFr=o(`Note:
Loading a model from its configuration file does `),PFe=a("strong"),BFr=o("not"),IFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_U=a("a"),NFr=o("from_pretrained()"),qFr=o(" to load the model weights."),jFr=l(),F(iE.$$.fragment),DFr=l(),xr=a("div"),F(C9.$$.fragment),GFr=l(),BFe=a("p"),OFr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),VFr=l(),nn=a("p"),XFr=o("The model class to instantiate is selected based on the "),IFe=a("code"),zFr=o("model_type"),WFr=o(` property of the config object (either
passed as an argument or loaded from `),NFe=a("code"),QFr=o("pretrained_model_name_or_path"),HFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qFe=a("code"),UFr=o("pretrained_model_name_or_path"),JFr=o(":"),YFr=l(),Me=a("ul"),dE=a("li"),jFe=a("strong"),KFr=o("bert"),ZFr=o(" \u2014 "),bU=a("a"),eTr=o("TFBertLMHeadModel"),oTr=o(" (BERT model)"),rTr=l(),cE=a("li"),DFe=a("strong"),tTr=o("camembert"),aTr=o(" \u2014 "),vU=a("a"),nTr=o("TFCamembertForCausalLM"),sTr=o(" (CamemBERT model)"),lTr=l(),fE=a("li"),GFe=a("strong"),iTr=o("ctrl"),dTr=o(" \u2014 "),FU=a("a"),cTr=o("TFCTRLLMHeadModel"),fTr=o(" (CTRL model)"),mTr=l(),mE=a("li"),OFe=a("strong"),gTr=o("gpt2"),hTr=o(" \u2014 "),TU=a("a"),pTr=o("TFGPT2LMHeadModel"),uTr=o(" (OpenAI GPT-2 model)"),_Tr=l(),gE=a("li"),VFe=a("strong"),bTr=o("gptj"),vTr=o(" \u2014 "),MU=a("a"),FTr=o("TFGPTJForCausalLM"),TTr=o(" (GPT-J model)"),MTr=l(),hE=a("li"),XFe=a("strong"),ETr=o("openai-gpt"),CTr=o(" \u2014 "),EU=a("a"),wTr=o("TFOpenAIGPTLMHeadModel"),ATr=o(" (OpenAI GPT model)"),LTr=l(),pE=a("li"),zFe=a("strong"),yTr=o("opt"),xTr=o(" \u2014 "),CU=a("a"),$Tr=o("TFOPTForCausalLM"),kTr=o(" (OPT model)"),STr=l(),uE=a("li"),WFe=a("strong"),RTr=o("rembert"),PTr=o(" \u2014 "),wU=a("a"),BTr=o("TFRemBertForCausalLM"),ITr=o(" (RemBERT model)"),NTr=l(),_E=a("li"),QFe=a("strong"),qTr=o("roberta"),jTr=o(" \u2014 "),AU=a("a"),DTr=o("TFRobertaForCausalLM"),GTr=o(" (RoBERTa model)"),OTr=l(),bE=a("li"),HFe=a("strong"),VTr=o("roformer"),XTr=o(" \u2014 "),LU=a("a"),zTr=o("TFRoFormerForCausalLM"),WTr=o(" (RoFormer model)"),QTr=l(),vE=a("li"),UFe=a("strong"),HTr=o("transfo-xl"),UTr=o(" \u2014 "),yU=a("a"),JTr=o("TFTransfoXLLMHeadModel"),YTr=o(" (Transformer-XL model)"),KTr=l(),FE=a("li"),JFe=a("strong"),ZTr=o("xlm"),e7r=o(" \u2014 "),xU=a("a"),o7r=o("TFXLMWithLMHeadModel"),r7r=o(" (XLM model)"),t7r=l(),TE=a("li"),YFe=a("strong"),a7r=o("xlnet"),n7r=o(" \u2014 "),$U=a("a"),s7r=o("TFXLNetLMHeadModel"),l7r=o(" (XLNet model)"),i7r=l(),F(ME.$$.fragment),SOe=l(),dc=a("h2"),EE=a("a"),KFe=a("span"),F(w9.$$.fragment),d7r=l(),ZFe=a("span"),c7r=o("TFAutoModelForImageClassification"),ROe=l(),rr=a("div"),F(A9.$$.fragment),f7r=l(),cc=a("p"),m7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),kU=a("a"),g7r=o("from_pretrained()"),h7r=o(" class method or the "),SU=a("a"),p7r=o("from_config()"),u7r=o(` class
method.`),_7r=l(),L9=a("p"),b7r=o("This class cannot be instantiated directly using "),eTe=a("code"),v7r=o("__init__()"),F7r=o(" (throws an error)."),T7r=l(),Rt=a("div"),F(y9.$$.fragment),M7r=l(),oTe=a("p"),E7r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),C7r=l(),fc=a("p"),w7r=o(`Note:
Loading a model from its configuration file does `),rTe=a("strong"),A7r=o("not"),L7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=a("a"),y7r=o("from_pretrained()"),x7r=o(" to load the model weights."),$7r=l(),F(CE.$$.fragment),k7r=l(),$r=a("div"),F(x9.$$.fragment),S7r=l(),tTe=a("p"),R7r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),P7r=l(),sn=a("p"),B7r=o("The model class to instantiate is selected based on the "),aTe=a("code"),I7r=o("model_type"),N7r=o(` property of the config object (either
passed as an argument or loaded from `),nTe=a("code"),q7r=o("pretrained_model_name_or_path"),j7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sTe=a("code"),D7r=o("pretrained_model_name_or_path"),G7r=o(":"),O7r=l(),ln=a("ul"),wE=a("li"),lTe=a("strong"),V7r=o("convnext"),X7r=o(" \u2014 "),PU=a("a"),z7r=o("TFConvNextForImageClassification"),W7r=o(" (ConvNeXT model)"),Q7r=l(),AE=a("li"),iTe=a("strong"),H7r=o("data2vec-vision"),U7r=o(" \u2014 "),BU=a("a"),J7r=o("TFData2VecVisionForImageClassification"),Y7r=o(" (Data2VecVision model)"),K7r=l(),LE=a("li"),dTe=a("strong"),Z7r=o("swin"),eMr=o(" \u2014 "),IU=a("a"),oMr=o("TFSwinForImageClassification"),rMr=o(" (Swin Transformer model)"),tMr=l(),yE=a("li"),cTe=a("strong"),aMr=o("vit"),nMr=o(" \u2014 "),NU=a("a"),sMr=o("TFViTForImageClassification"),lMr=o(" (ViT model)"),iMr=l(),F(xE.$$.fragment),POe=l(),mc=a("h2"),$E=a("a"),fTe=a("span"),F($9.$$.fragment),dMr=l(),mTe=a("span"),cMr=o("TFAutoModelForMaskedLM"),BOe=l(),tr=a("div"),F(k9.$$.fragment),fMr=l(),gc=a("p"),mMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qU=a("a"),gMr=o("from_pretrained()"),hMr=o(" class method or the "),jU=a("a"),pMr=o("from_config()"),uMr=o(` class
method.`),_Mr=l(),S9=a("p"),bMr=o("This class cannot be instantiated directly using "),gTe=a("code"),vMr=o("__init__()"),FMr=o(" (throws an error)."),TMr=l(),Pt=a("div"),F(R9.$$.fragment),MMr=l(),hTe=a("p"),EMr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),CMr=l(),hc=a("p"),wMr=o(`Note:
Loading a model from its configuration file does `),pTe=a("strong"),AMr=o("not"),LMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DU=a("a"),yMr=o("from_pretrained()"),xMr=o(" to load the model weights."),$Mr=l(),F(kE.$$.fragment),kMr=l(),kr=a("div"),F(P9.$$.fragment),SMr=l(),uTe=a("p"),RMr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),PMr=l(),dn=a("p"),BMr=o("The model class to instantiate is selected based on the "),_Te=a("code"),IMr=o("model_type"),NMr=o(` property of the config object (either
passed as an argument or loaded from `),bTe=a("code"),qMr=o("pretrained_model_name_or_path"),jMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vTe=a("code"),DMr=o("pretrained_model_name_or_path"),GMr=o(":"),OMr=l(),ie=a("ul"),SE=a("li"),FTe=a("strong"),VMr=o("albert"),XMr=o(" \u2014 "),GU=a("a"),zMr=o("TFAlbertForMaskedLM"),WMr=o(" (ALBERT model)"),QMr=l(),RE=a("li"),TTe=a("strong"),HMr=o("bert"),UMr=o(" \u2014 "),OU=a("a"),JMr=o("TFBertForMaskedLM"),YMr=o(" (BERT model)"),KMr=l(),PE=a("li"),MTe=a("strong"),ZMr=o("camembert"),eEr=o(" \u2014 "),VU=a("a"),oEr=o("TFCamembertForMaskedLM"),rEr=o(" (CamemBERT model)"),tEr=l(),BE=a("li"),ETe=a("strong"),aEr=o("convbert"),nEr=o(" \u2014 "),XU=a("a"),sEr=o("TFConvBertForMaskedLM"),lEr=o(" (ConvBERT model)"),iEr=l(),IE=a("li"),CTe=a("strong"),dEr=o("deberta"),cEr=o(" \u2014 "),zU=a("a"),fEr=o("TFDebertaForMaskedLM"),mEr=o(" (DeBERTa model)"),gEr=l(),NE=a("li"),wTe=a("strong"),hEr=o("deberta-v2"),pEr=o(" \u2014 "),WU=a("a"),uEr=o("TFDebertaV2ForMaskedLM"),_Er=o(" (DeBERTa-v2 model)"),bEr=l(),qE=a("li"),ATe=a("strong"),vEr=o("distilbert"),FEr=o(" \u2014 "),QU=a("a"),TEr=o("TFDistilBertForMaskedLM"),MEr=o(" (DistilBERT model)"),EEr=l(),jE=a("li"),LTe=a("strong"),CEr=o("electra"),wEr=o(" \u2014 "),HU=a("a"),AEr=o("TFElectraForMaskedLM"),LEr=o(" (ELECTRA model)"),yEr=l(),DE=a("li"),yTe=a("strong"),xEr=o("flaubert"),$Er=o(" \u2014 "),UU=a("a"),kEr=o("TFFlaubertWithLMHeadModel"),SEr=o(" (FlauBERT model)"),REr=l(),GE=a("li"),xTe=a("strong"),PEr=o("funnel"),BEr=o(" \u2014 "),JU=a("a"),IEr=o("TFFunnelForMaskedLM"),NEr=o(" (Funnel Transformer model)"),qEr=l(),OE=a("li"),$Te=a("strong"),jEr=o("layoutlm"),DEr=o(" \u2014 "),YU=a("a"),GEr=o("TFLayoutLMForMaskedLM"),OEr=o(" (LayoutLM model)"),VEr=l(),VE=a("li"),kTe=a("strong"),XEr=o("longformer"),zEr=o(" \u2014 "),KU=a("a"),WEr=o("TFLongformerForMaskedLM"),QEr=o(" (Longformer model)"),HEr=l(),XE=a("li"),STe=a("strong"),UEr=o("mobilebert"),JEr=o(" \u2014 "),ZU=a("a"),YEr=o("TFMobileBertForMaskedLM"),KEr=o(" (MobileBERT model)"),ZEr=l(),zE=a("li"),RTe=a("strong"),e4r=o("mpnet"),o4r=o(" \u2014 "),eJ=a("a"),r4r=o("TFMPNetForMaskedLM"),t4r=o(" (MPNet model)"),a4r=l(),WE=a("li"),PTe=a("strong"),n4r=o("rembert"),s4r=o(" \u2014 "),oJ=a("a"),l4r=o("TFRemBertForMaskedLM"),i4r=o(" (RemBERT model)"),d4r=l(),QE=a("li"),BTe=a("strong"),c4r=o("roberta"),f4r=o(" \u2014 "),rJ=a("a"),m4r=o("TFRobertaForMaskedLM"),g4r=o(" (RoBERTa model)"),h4r=l(),HE=a("li"),ITe=a("strong"),p4r=o("roformer"),u4r=o(" \u2014 "),tJ=a("a"),_4r=o("TFRoFormerForMaskedLM"),b4r=o(" (RoFormer model)"),v4r=l(),UE=a("li"),NTe=a("strong"),F4r=o("tapas"),T4r=o(" \u2014 "),aJ=a("a"),M4r=o("TFTapasForMaskedLM"),E4r=o(" (TAPAS model)"),C4r=l(),JE=a("li"),qTe=a("strong"),w4r=o("xlm"),A4r=o(" \u2014 "),nJ=a("a"),L4r=o("TFXLMWithLMHeadModel"),y4r=o(" (XLM model)"),x4r=l(),YE=a("li"),jTe=a("strong"),$4r=o("xlm-roberta"),k4r=o(" \u2014 "),sJ=a("a"),S4r=o("TFXLMRobertaForMaskedLM"),R4r=o(" (XLM-RoBERTa model)"),P4r=l(),F(KE.$$.fragment),IOe=l(),pc=a("h2"),ZE=a("a"),DTe=a("span"),F(B9.$$.fragment),B4r=l(),GTe=a("span"),I4r=o("TFAutoModelForSeq2SeqLM"),NOe=l(),ar=a("div"),F(I9.$$.fragment),N4r=l(),uc=a("p"),q4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),lJ=a("a"),j4r=o("from_pretrained()"),D4r=o(" class method or the "),iJ=a("a"),G4r=o("from_config()"),O4r=o(` class
method.`),V4r=l(),N9=a("p"),X4r=o("This class cannot be instantiated directly using "),OTe=a("code"),z4r=o("__init__()"),W4r=o(" (throws an error)."),Q4r=l(),Bt=a("div"),F(q9.$$.fragment),H4r=l(),VTe=a("p"),U4r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),J4r=l(),_c=a("p"),Y4r=o(`Note:
Loading a model from its configuration file does `),XTe=a("strong"),K4r=o("not"),Z4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dJ=a("a"),eCr=o("from_pretrained()"),oCr=o(" to load the model weights."),rCr=l(),F(e4.$$.fragment),tCr=l(),Sr=a("div"),F(j9.$$.fragment),aCr=l(),zTe=a("p"),nCr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),sCr=l(),cn=a("p"),lCr=o("The model class to instantiate is selected based on the "),WTe=a("code"),iCr=o("model_type"),dCr=o(` property of the config object (either
passed as an argument or loaded from `),QTe=a("code"),cCr=o("pretrained_model_name_or_path"),fCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HTe=a("code"),mCr=o("pretrained_model_name_or_path"),gCr=o(":"),hCr=l(),ye=a("ul"),o4=a("li"),UTe=a("strong"),pCr=o("bart"),uCr=o(" \u2014 "),cJ=a("a"),_Cr=o("TFBartForConditionalGeneration"),bCr=o(" (BART model)"),vCr=l(),r4=a("li"),JTe=a("strong"),FCr=o("blenderbot"),TCr=o(" \u2014 "),fJ=a("a"),MCr=o("TFBlenderbotForConditionalGeneration"),ECr=o(" (Blenderbot model)"),CCr=l(),t4=a("li"),YTe=a("strong"),wCr=o("blenderbot-small"),ACr=o(" \u2014 "),mJ=a("a"),LCr=o("TFBlenderbotSmallForConditionalGeneration"),yCr=o(" (BlenderbotSmall model)"),xCr=l(),a4=a("li"),KTe=a("strong"),$Cr=o("encoder-decoder"),kCr=o(" \u2014 "),gJ=a("a"),SCr=o("TFEncoderDecoderModel"),RCr=o(" (Encoder decoder model)"),PCr=l(),n4=a("li"),ZTe=a("strong"),BCr=o("led"),ICr=o(" \u2014 "),hJ=a("a"),NCr=o("TFLEDForConditionalGeneration"),qCr=o(" (LED model)"),jCr=l(),s4=a("li"),e7e=a("strong"),DCr=o("marian"),GCr=o(" \u2014 "),pJ=a("a"),OCr=o("TFMarianMTModel"),VCr=o(" (Marian model)"),XCr=l(),l4=a("li"),o7e=a("strong"),zCr=o("mbart"),WCr=o(" \u2014 "),uJ=a("a"),QCr=o("TFMBartForConditionalGeneration"),HCr=o(" (mBART model)"),UCr=l(),i4=a("li"),r7e=a("strong"),JCr=o("mt5"),YCr=o(" \u2014 "),_J=a("a"),KCr=o("TFMT5ForConditionalGeneration"),ZCr=o(" (MT5 model)"),e5r=l(),d4=a("li"),t7e=a("strong"),o5r=o("pegasus"),r5r=o(" \u2014 "),bJ=a("a"),t5r=o("TFPegasusForConditionalGeneration"),a5r=o(" (Pegasus model)"),n5r=l(),c4=a("li"),a7e=a("strong"),s5r=o("t5"),l5r=o(" \u2014 "),vJ=a("a"),i5r=o("TFT5ForConditionalGeneration"),d5r=o(" (T5 model)"),c5r=l(),F(f4.$$.fragment),qOe=l(),bc=a("h2"),m4=a("a"),n7e=a("span"),F(D9.$$.fragment),f5r=l(),s7e=a("span"),m5r=o("TFAutoModelForSequenceClassification"),jOe=l(),nr=a("div"),F(G9.$$.fragment),g5r=l(),vc=a("p"),h5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),FJ=a("a"),p5r=o("from_pretrained()"),u5r=o(" class method or the "),TJ=a("a"),_5r=o("from_config()"),b5r=o(` class
method.`),v5r=l(),O9=a("p"),F5r=o("This class cannot be instantiated directly using "),l7e=a("code"),T5r=o("__init__()"),M5r=o(" (throws an error)."),E5r=l(),It=a("div"),F(V9.$$.fragment),C5r=l(),i7e=a("p"),w5r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),A5r=l(),Fc=a("p"),L5r=o(`Note:
Loading a model from its configuration file does `),d7e=a("strong"),y5r=o("not"),x5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MJ=a("a"),$5r=o("from_pretrained()"),k5r=o(" to load the model weights."),S5r=l(),F(g4.$$.fragment),R5r=l(),Rr=a("div"),F(X9.$$.fragment),P5r=l(),c7e=a("p"),B5r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),I5r=l(),fn=a("p"),N5r=o("The model class to instantiate is selected based on the "),f7e=a("code"),q5r=o("model_type"),j5r=o(` property of the config object (either
passed as an argument or loaded from `),m7e=a("code"),D5r=o("pretrained_model_name_or_path"),G5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g7e=a("code"),O5r=o("pretrained_model_name_or_path"),V5r=o(":"),X5r=l(),te=a("ul"),h4=a("li"),h7e=a("strong"),z5r=o("albert"),W5r=o(" \u2014 "),EJ=a("a"),Q5r=o("TFAlbertForSequenceClassification"),H5r=o(" (ALBERT model)"),U5r=l(),p4=a("li"),p7e=a("strong"),J5r=o("bert"),Y5r=o(" \u2014 "),CJ=a("a"),K5r=o("TFBertForSequenceClassification"),Z5r=o(" (BERT model)"),e0r=l(),u4=a("li"),u7e=a("strong"),o0r=o("camembert"),r0r=o(" \u2014 "),wJ=a("a"),t0r=o("TFCamembertForSequenceClassification"),a0r=o(" (CamemBERT model)"),n0r=l(),_4=a("li"),_7e=a("strong"),s0r=o("convbert"),l0r=o(" \u2014 "),AJ=a("a"),i0r=o("TFConvBertForSequenceClassification"),d0r=o(" (ConvBERT model)"),c0r=l(),b4=a("li"),b7e=a("strong"),f0r=o("ctrl"),m0r=o(" \u2014 "),LJ=a("a"),g0r=o("TFCTRLForSequenceClassification"),h0r=o(" (CTRL model)"),p0r=l(),v4=a("li"),v7e=a("strong"),u0r=o("deberta"),_0r=o(" \u2014 "),yJ=a("a"),b0r=o("TFDebertaForSequenceClassification"),v0r=o(" (DeBERTa model)"),F0r=l(),F4=a("li"),F7e=a("strong"),T0r=o("deberta-v2"),M0r=o(" \u2014 "),xJ=a("a"),E0r=o("TFDebertaV2ForSequenceClassification"),C0r=o(" (DeBERTa-v2 model)"),w0r=l(),T4=a("li"),T7e=a("strong"),A0r=o("distilbert"),L0r=o(" \u2014 "),$J=a("a"),y0r=o("TFDistilBertForSequenceClassification"),x0r=o(" (DistilBERT model)"),$0r=l(),M4=a("li"),M7e=a("strong"),k0r=o("electra"),S0r=o(" \u2014 "),kJ=a("a"),R0r=o("TFElectraForSequenceClassification"),P0r=o(" (ELECTRA model)"),B0r=l(),E4=a("li"),E7e=a("strong"),I0r=o("flaubert"),N0r=o(" \u2014 "),SJ=a("a"),q0r=o("TFFlaubertForSequenceClassification"),j0r=o(" (FlauBERT model)"),D0r=l(),C4=a("li"),C7e=a("strong"),G0r=o("funnel"),O0r=o(" \u2014 "),RJ=a("a"),V0r=o("TFFunnelForSequenceClassification"),X0r=o(" (Funnel Transformer model)"),z0r=l(),w4=a("li"),w7e=a("strong"),W0r=o("gpt2"),Q0r=o(" \u2014 "),PJ=a("a"),H0r=o("TFGPT2ForSequenceClassification"),U0r=o(" (OpenAI GPT-2 model)"),J0r=l(),A4=a("li"),A7e=a("strong"),Y0r=o("gptj"),K0r=o(" \u2014 "),BJ=a("a"),Z0r=o("TFGPTJForSequenceClassification"),ewr=o(" (GPT-J model)"),owr=l(),L4=a("li"),L7e=a("strong"),rwr=o("layoutlm"),twr=o(" \u2014 "),IJ=a("a"),awr=o("TFLayoutLMForSequenceClassification"),nwr=o(" (LayoutLM model)"),swr=l(),y4=a("li"),y7e=a("strong"),lwr=o("longformer"),iwr=o(" \u2014 "),NJ=a("a"),dwr=o("TFLongformerForSequenceClassification"),cwr=o(" (Longformer model)"),fwr=l(),x4=a("li"),x7e=a("strong"),mwr=o("mobilebert"),gwr=o(" \u2014 "),qJ=a("a"),hwr=o("TFMobileBertForSequenceClassification"),pwr=o(" (MobileBERT model)"),uwr=l(),$4=a("li"),$7e=a("strong"),_wr=o("mpnet"),bwr=o(" \u2014 "),jJ=a("a"),vwr=o("TFMPNetForSequenceClassification"),Fwr=o(" (MPNet model)"),Twr=l(),k4=a("li"),k7e=a("strong"),Mwr=o("openai-gpt"),Ewr=o(" \u2014 "),DJ=a("a"),Cwr=o("TFOpenAIGPTForSequenceClassification"),wwr=o(" (OpenAI GPT model)"),Awr=l(),S4=a("li"),S7e=a("strong"),Lwr=o("rembert"),ywr=o(" \u2014 "),GJ=a("a"),xwr=o("TFRemBertForSequenceClassification"),$wr=o(" (RemBERT model)"),kwr=l(),R4=a("li"),R7e=a("strong"),Swr=o("roberta"),Rwr=o(" \u2014 "),OJ=a("a"),Pwr=o("TFRobertaForSequenceClassification"),Bwr=o(" (RoBERTa model)"),Iwr=l(),P4=a("li"),P7e=a("strong"),Nwr=o("roformer"),qwr=o(" \u2014 "),VJ=a("a"),jwr=o("TFRoFormerForSequenceClassification"),Dwr=o(" (RoFormer model)"),Gwr=l(),B4=a("li"),B7e=a("strong"),Owr=o("tapas"),Vwr=o(" \u2014 "),XJ=a("a"),Xwr=o("TFTapasForSequenceClassification"),zwr=o(" (TAPAS model)"),Wwr=l(),I4=a("li"),I7e=a("strong"),Qwr=o("transfo-xl"),Hwr=o(" \u2014 "),zJ=a("a"),Uwr=o("TFTransfoXLForSequenceClassification"),Jwr=o(" (Transformer-XL model)"),Ywr=l(),N4=a("li"),N7e=a("strong"),Kwr=o("xlm"),Zwr=o(" \u2014 "),WJ=a("a"),eAr=o("TFXLMForSequenceClassification"),oAr=o(" (XLM model)"),rAr=l(),q4=a("li"),q7e=a("strong"),tAr=o("xlm-roberta"),aAr=o(" \u2014 "),QJ=a("a"),nAr=o("TFXLMRobertaForSequenceClassification"),sAr=o(" (XLM-RoBERTa model)"),lAr=l(),j4=a("li"),j7e=a("strong"),iAr=o("xlnet"),dAr=o(" \u2014 "),HJ=a("a"),cAr=o("TFXLNetForSequenceClassification"),fAr=o(" (XLNet model)"),mAr=l(),F(D4.$$.fragment),DOe=l(),Tc=a("h2"),G4=a("a"),D7e=a("span"),F(z9.$$.fragment),gAr=l(),G7e=a("span"),hAr=o("TFAutoModelForMultipleChoice"),GOe=l(),sr=a("div"),F(W9.$$.fragment),pAr=l(),Mc=a("p"),uAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),UJ=a("a"),_Ar=o("from_pretrained()"),bAr=o(" class method or the "),JJ=a("a"),vAr=o("from_config()"),FAr=o(` class
method.`),TAr=l(),Q9=a("p"),MAr=o("This class cannot be instantiated directly using "),O7e=a("code"),EAr=o("__init__()"),CAr=o(" (throws an error)."),wAr=l(),Nt=a("div"),F(H9.$$.fragment),AAr=l(),V7e=a("p"),LAr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),yAr=l(),Ec=a("p"),xAr=o(`Note:
Loading a model from its configuration file does `),X7e=a("strong"),$Ar=o("not"),kAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=a("a"),SAr=o("from_pretrained()"),RAr=o(" to load the model weights."),PAr=l(),F(O4.$$.fragment),BAr=l(),Pr=a("div"),F(U9.$$.fragment),IAr=l(),z7e=a("p"),NAr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),qAr=l(),mn=a("p"),jAr=o("The model class to instantiate is selected based on the "),W7e=a("code"),DAr=o("model_type"),GAr=o(` property of the config object (either
passed as an argument or loaded from `),Q7e=a("code"),OAr=o("pretrained_model_name_or_path"),VAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H7e=a("code"),XAr=o("pretrained_model_name_or_path"),zAr=o(":"),WAr=l(),ue=a("ul"),V4=a("li"),U7e=a("strong"),QAr=o("albert"),HAr=o(" \u2014 "),KJ=a("a"),UAr=o("TFAlbertForMultipleChoice"),JAr=o(" (ALBERT model)"),YAr=l(),X4=a("li"),J7e=a("strong"),KAr=o("bert"),ZAr=o(" \u2014 "),ZJ=a("a"),e6r=o("TFBertForMultipleChoice"),o6r=o(" (BERT model)"),r6r=l(),z4=a("li"),Y7e=a("strong"),t6r=o("camembert"),a6r=o(" \u2014 "),eY=a("a"),n6r=o("TFCamembertForMultipleChoice"),s6r=o(" (CamemBERT model)"),l6r=l(),W4=a("li"),K7e=a("strong"),i6r=o("convbert"),d6r=o(" \u2014 "),oY=a("a"),c6r=o("TFConvBertForMultipleChoice"),f6r=o(" (ConvBERT model)"),m6r=l(),Q4=a("li"),Z7e=a("strong"),g6r=o("distilbert"),h6r=o(" \u2014 "),rY=a("a"),p6r=o("TFDistilBertForMultipleChoice"),u6r=o(" (DistilBERT model)"),_6r=l(),H4=a("li"),eMe=a("strong"),b6r=o("electra"),v6r=o(" \u2014 "),tY=a("a"),F6r=o("TFElectraForMultipleChoice"),T6r=o(" (ELECTRA model)"),M6r=l(),U4=a("li"),oMe=a("strong"),E6r=o("flaubert"),C6r=o(" \u2014 "),aY=a("a"),w6r=o("TFFlaubertForMultipleChoice"),A6r=o(" (FlauBERT model)"),L6r=l(),J4=a("li"),rMe=a("strong"),y6r=o("funnel"),x6r=o(" \u2014 "),nY=a("a"),$6r=o("TFFunnelForMultipleChoice"),k6r=o(" (Funnel Transformer model)"),S6r=l(),Y4=a("li"),tMe=a("strong"),R6r=o("longformer"),P6r=o(" \u2014 "),sY=a("a"),B6r=o("TFLongformerForMultipleChoice"),I6r=o(" (Longformer model)"),N6r=l(),K4=a("li"),aMe=a("strong"),q6r=o("mobilebert"),j6r=o(" \u2014 "),lY=a("a"),D6r=o("TFMobileBertForMultipleChoice"),G6r=o(" (MobileBERT model)"),O6r=l(),Z4=a("li"),nMe=a("strong"),V6r=o("mpnet"),X6r=o(" \u2014 "),iY=a("a"),z6r=o("TFMPNetForMultipleChoice"),W6r=o(" (MPNet model)"),Q6r=l(),eC=a("li"),sMe=a("strong"),H6r=o("rembert"),U6r=o(" \u2014 "),dY=a("a"),J6r=o("TFRemBertForMultipleChoice"),Y6r=o(" (RemBERT model)"),K6r=l(),oC=a("li"),lMe=a("strong"),Z6r=o("roberta"),eLr=o(" \u2014 "),cY=a("a"),oLr=o("TFRobertaForMultipleChoice"),rLr=o(" (RoBERTa model)"),tLr=l(),rC=a("li"),iMe=a("strong"),aLr=o("roformer"),nLr=o(" \u2014 "),fY=a("a"),sLr=o("TFRoFormerForMultipleChoice"),lLr=o(" (RoFormer model)"),iLr=l(),tC=a("li"),dMe=a("strong"),dLr=o("xlm"),cLr=o(" \u2014 "),mY=a("a"),fLr=o("TFXLMForMultipleChoice"),mLr=o(" (XLM model)"),gLr=l(),aC=a("li"),cMe=a("strong"),hLr=o("xlm-roberta"),pLr=o(" \u2014 "),gY=a("a"),uLr=o("TFXLMRobertaForMultipleChoice"),_Lr=o(" (XLM-RoBERTa model)"),bLr=l(),nC=a("li"),fMe=a("strong"),vLr=o("xlnet"),FLr=o(" \u2014 "),hY=a("a"),TLr=o("TFXLNetForMultipleChoice"),MLr=o(" (XLNet model)"),ELr=l(),F(sC.$$.fragment),OOe=l(),Cc=a("h2"),lC=a("a"),mMe=a("span"),F(J9.$$.fragment),CLr=l(),gMe=a("span"),wLr=o("TFAutoModelForNextSentencePrediction"),VOe=l(),lr=a("div"),F(Y9.$$.fragment),ALr=l(),wc=a("p"),LLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),pY=a("a"),yLr=o("from_pretrained()"),xLr=o(" class method or the "),uY=a("a"),$Lr=o("from_config()"),kLr=o(` class
method.`),SLr=l(),K9=a("p"),RLr=o("This class cannot be instantiated directly using "),hMe=a("code"),PLr=o("__init__()"),BLr=o(" (throws an error)."),ILr=l(),qt=a("div"),F(Z9.$$.fragment),NLr=l(),pMe=a("p"),qLr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),jLr=l(),Ac=a("p"),DLr=o(`Note:
Loading a model from its configuration file does `),uMe=a("strong"),GLr=o("not"),OLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_Y=a("a"),VLr=o("from_pretrained()"),XLr=o(" to load the model weights."),zLr=l(),F(iC.$$.fragment),WLr=l(),Br=a("div"),F(ex.$$.fragment),QLr=l(),_Me=a("p"),HLr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),ULr=l(),gn=a("p"),JLr=o("The model class to instantiate is selected based on the "),bMe=a("code"),YLr=o("model_type"),KLr=o(` property of the config object (either
passed as an argument or loaded from `),vMe=a("code"),ZLr=o("pretrained_model_name_or_path"),eyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FMe=a("code"),oyr=o("pretrained_model_name_or_path"),ryr=o(":"),tyr=l(),ox=a("ul"),dC=a("li"),TMe=a("strong"),ayr=o("bert"),nyr=o(" \u2014 "),bY=a("a"),syr=o("TFBertForNextSentencePrediction"),lyr=o(" (BERT model)"),iyr=l(),cC=a("li"),MMe=a("strong"),dyr=o("mobilebert"),cyr=o(" \u2014 "),vY=a("a"),fyr=o("TFMobileBertForNextSentencePrediction"),myr=o(" (MobileBERT model)"),gyr=l(),F(fC.$$.fragment),XOe=l(),Lc=a("h2"),mC=a("a"),EMe=a("span"),F(rx.$$.fragment),hyr=l(),CMe=a("span"),pyr=o("TFAutoModelForTableQuestionAnswering"),zOe=l(),ir=a("div"),F(tx.$$.fragment),uyr=l(),yc=a("p"),_yr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),FY=a("a"),byr=o("from_pretrained()"),vyr=o(" class method or the "),TY=a("a"),Fyr=o("from_config()"),Tyr=o(` class
method.`),Myr=l(),ax=a("p"),Eyr=o("This class cannot be instantiated directly using "),wMe=a("code"),Cyr=o("__init__()"),wyr=o(" (throws an error)."),Ayr=l(),jt=a("div"),F(nx.$$.fragment),Lyr=l(),AMe=a("p"),yyr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),xyr=l(),xc=a("p"),$yr=o(`Note:
Loading a model from its configuration file does `),LMe=a("strong"),kyr=o("not"),Syr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MY=a("a"),Ryr=o("from_pretrained()"),Pyr=o(" to load the model weights."),Byr=l(),F(gC.$$.fragment),Iyr=l(),Ir=a("div"),F(sx.$$.fragment),Nyr=l(),yMe=a("p"),qyr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),jyr=l(),hn=a("p"),Dyr=o("The model class to instantiate is selected based on the "),xMe=a("code"),Gyr=o("model_type"),Oyr=o(` property of the config object (either
passed as an argument or loaded from `),$Me=a("code"),Vyr=o("pretrained_model_name_or_path"),Xyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kMe=a("code"),zyr=o("pretrained_model_name_or_path"),Wyr=o(":"),Qyr=l(),SMe=a("ul"),hC=a("li"),RMe=a("strong"),Hyr=o("tapas"),Uyr=o(" \u2014 "),EY=a("a"),Jyr=o("TFTapasForQuestionAnswering"),Yyr=o(" (TAPAS model)"),Kyr=l(),F(pC.$$.fragment),WOe=l(),$c=a("h2"),uC=a("a"),PMe=a("span"),F(lx.$$.fragment),Zyr=l(),BMe=a("span"),e8r=o("TFAutoModelForTokenClassification"),QOe=l(),dr=a("div"),F(ix.$$.fragment),o8r=l(),kc=a("p"),r8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),CY=a("a"),t8r=o("from_pretrained()"),a8r=o(" class method or the "),wY=a("a"),n8r=o("from_config()"),s8r=o(` class
method.`),l8r=l(),dx=a("p"),i8r=o("This class cannot be instantiated directly using "),IMe=a("code"),d8r=o("__init__()"),c8r=o(" (throws an error)."),f8r=l(),Dt=a("div"),F(cx.$$.fragment),m8r=l(),NMe=a("p"),g8r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),h8r=l(),Sc=a("p"),p8r=o(`Note:
Loading a model from its configuration file does `),qMe=a("strong"),u8r=o("not"),_8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AY=a("a"),b8r=o("from_pretrained()"),v8r=o(" to load the model weights."),F8r=l(),F(_C.$$.fragment),T8r=l(),Nr=a("div"),F(fx.$$.fragment),M8r=l(),jMe=a("p"),E8r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),C8r=l(),pn=a("p"),w8r=o("The model class to instantiate is selected based on the "),DMe=a("code"),A8r=o("model_type"),L8r=o(` property of the config object (either
passed as an argument or loaded from `),GMe=a("code"),y8r=o("pretrained_model_name_or_path"),x8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OMe=a("code"),$8r=o("pretrained_model_name_or_path"),k8r=o(":"),S8r=l(),de=a("ul"),bC=a("li"),VMe=a("strong"),R8r=o("albert"),P8r=o(" \u2014 "),LY=a("a"),B8r=o("TFAlbertForTokenClassification"),I8r=o(" (ALBERT model)"),N8r=l(),vC=a("li"),XMe=a("strong"),q8r=o("bert"),j8r=o(" \u2014 "),yY=a("a"),D8r=o("TFBertForTokenClassification"),G8r=o(" (BERT model)"),O8r=l(),FC=a("li"),zMe=a("strong"),V8r=o("camembert"),X8r=o(" \u2014 "),xY=a("a"),z8r=o("TFCamembertForTokenClassification"),W8r=o(" (CamemBERT model)"),Q8r=l(),TC=a("li"),WMe=a("strong"),H8r=o("convbert"),U8r=o(" \u2014 "),$Y=a("a"),J8r=o("TFConvBertForTokenClassification"),Y8r=o(" (ConvBERT model)"),K8r=l(),MC=a("li"),QMe=a("strong"),Z8r=o("deberta"),e9r=o(" \u2014 "),kY=a("a"),o9r=o("TFDebertaForTokenClassification"),r9r=o(" (DeBERTa model)"),t9r=l(),EC=a("li"),HMe=a("strong"),a9r=o("deberta-v2"),n9r=o(" \u2014 "),SY=a("a"),s9r=o("TFDebertaV2ForTokenClassification"),l9r=o(" (DeBERTa-v2 model)"),i9r=l(),CC=a("li"),UMe=a("strong"),d9r=o("distilbert"),c9r=o(" \u2014 "),RY=a("a"),f9r=o("TFDistilBertForTokenClassification"),m9r=o(" (DistilBERT model)"),g9r=l(),wC=a("li"),JMe=a("strong"),h9r=o("electra"),p9r=o(" \u2014 "),PY=a("a"),u9r=o("TFElectraForTokenClassification"),_9r=o(" (ELECTRA model)"),b9r=l(),AC=a("li"),YMe=a("strong"),v9r=o("flaubert"),F9r=o(" \u2014 "),BY=a("a"),T9r=o("TFFlaubertForTokenClassification"),M9r=o(" (FlauBERT model)"),E9r=l(),LC=a("li"),KMe=a("strong"),C9r=o("funnel"),w9r=o(" \u2014 "),IY=a("a"),A9r=o("TFFunnelForTokenClassification"),L9r=o(" (Funnel Transformer model)"),y9r=l(),yC=a("li"),ZMe=a("strong"),x9r=o("layoutlm"),$9r=o(" \u2014 "),NY=a("a"),k9r=o("TFLayoutLMForTokenClassification"),S9r=o(" (LayoutLM model)"),R9r=l(),xC=a("li"),eEe=a("strong"),P9r=o("longformer"),B9r=o(" \u2014 "),qY=a("a"),I9r=o("TFLongformerForTokenClassification"),N9r=o(" (Longformer model)"),q9r=l(),$C=a("li"),oEe=a("strong"),j9r=o("mobilebert"),D9r=o(" \u2014 "),jY=a("a"),G9r=o("TFMobileBertForTokenClassification"),O9r=o(" (MobileBERT model)"),V9r=l(),kC=a("li"),rEe=a("strong"),X9r=o("mpnet"),z9r=o(" \u2014 "),DY=a("a"),W9r=o("TFMPNetForTokenClassification"),Q9r=o(" (MPNet model)"),H9r=l(),SC=a("li"),tEe=a("strong"),U9r=o("rembert"),J9r=o(" \u2014 "),GY=a("a"),Y9r=o("TFRemBertForTokenClassification"),K9r=o(" (RemBERT model)"),Z9r=l(),RC=a("li"),aEe=a("strong"),exr=o("roberta"),oxr=o(" \u2014 "),OY=a("a"),rxr=o("TFRobertaForTokenClassification"),txr=o(" (RoBERTa model)"),axr=l(),PC=a("li"),nEe=a("strong"),nxr=o("roformer"),sxr=o(" \u2014 "),VY=a("a"),lxr=o("TFRoFormerForTokenClassification"),ixr=o(" (RoFormer model)"),dxr=l(),BC=a("li"),sEe=a("strong"),cxr=o("xlm"),fxr=o(" \u2014 "),XY=a("a"),mxr=o("TFXLMForTokenClassification"),gxr=o(" (XLM model)"),hxr=l(),IC=a("li"),lEe=a("strong"),pxr=o("xlm-roberta"),uxr=o(" \u2014 "),zY=a("a"),_xr=o("TFXLMRobertaForTokenClassification"),bxr=o(" (XLM-RoBERTa model)"),vxr=l(),NC=a("li"),iEe=a("strong"),Fxr=o("xlnet"),Txr=o(" \u2014 "),WY=a("a"),Mxr=o("TFXLNetForTokenClassification"),Exr=o(" (XLNet model)"),Cxr=l(),F(qC.$$.fragment),HOe=l(),Rc=a("h2"),jC=a("a"),dEe=a("span"),F(mx.$$.fragment),wxr=l(),cEe=a("span"),Axr=o("TFAutoModelForQuestionAnswering"),UOe=l(),cr=a("div"),F(gx.$$.fragment),Lxr=l(),Pc=a("p"),yxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),QY=a("a"),xxr=o("from_pretrained()"),$xr=o(" class method or the "),HY=a("a"),kxr=o("from_config()"),Sxr=o(` class
method.`),Rxr=l(),hx=a("p"),Pxr=o("This class cannot be instantiated directly using "),fEe=a("code"),Bxr=o("__init__()"),Ixr=o(" (throws an error)."),Nxr=l(),Gt=a("div"),F(px.$$.fragment),qxr=l(),mEe=a("p"),jxr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Dxr=l(),Bc=a("p"),Gxr=o(`Note:
Loading a model from its configuration file does `),gEe=a("strong"),Oxr=o("not"),Vxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UY=a("a"),Xxr=o("from_pretrained()"),zxr=o(" to load the model weights."),Wxr=l(),F(DC.$$.fragment),Qxr=l(),qr=a("div"),F(ux.$$.fragment),Hxr=l(),hEe=a("p"),Uxr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Jxr=l(),un=a("p"),Yxr=o("The model class to instantiate is selected based on the "),pEe=a("code"),Kxr=o("model_type"),Zxr=o(` property of the config object (either
passed as an argument or loaded from `),uEe=a("code"),e$r=o("pretrained_model_name_or_path"),o$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ee=a("code"),r$r=o("pretrained_model_name_or_path"),t$r=o(":"),a$r=l(),ce=a("ul"),GC=a("li"),bEe=a("strong"),n$r=o("albert"),s$r=o(" \u2014 "),JY=a("a"),l$r=o("TFAlbertForQuestionAnswering"),i$r=o(" (ALBERT model)"),d$r=l(),OC=a("li"),vEe=a("strong"),c$r=o("bert"),f$r=o(" \u2014 "),YY=a("a"),m$r=o("TFBertForQuestionAnswering"),g$r=o(" (BERT model)"),h$r=l(),VC=a("li"),FEe=a("strong"),p$r=o("camembert"),u$r=o(" \u2014 "),KY=a("a"),_$r=o("TFCamembertForQuestionAnswering"),b$r=o(" (CamemBERT model)"),v$r=l(),XC=a("li"),TEe=a("strong"),F$r=o("convbert"),T$r=o(" \u2014 "),ZY=a("a"),M$r=o("TFConvBertForQuestionAnswering"),E$r=o(" (ConvBERT model)"),C$r=l(),zC=a("li"),MEe=a("strong"),w$r=o("deberta"),A$r=o(" \u2014 "),eK=a("a"),L$r=o("TFDebertaForQuestionAnswering"),y$r=o(" (DeBERTa model)"),x$r=l(),WC=a("li"),EEe=a("strong"),$$r=o("deberta-v2"),k$r=o(" \u2014 "),oK=a("a"),S$r=o("TFDebertaV2ForQuestionAnswering"),R$r=o(" (DeBERTa-v2 model)"),P$r=l(),QC=a("li"),CEe=a("strong"),B$r=o("distilbert"),I$r=o(" \u2014 "),rK=a("a"),N$r=o("TFDistilBertForQuestionAnswering"),q$r=o(" (DistilBERT model)"),j$r=l(),HC=a("li"),wEe=a("strong"),D$r=o("electra"),G$r=o(" \u2014 "),tK=a("a"),O$r=o("TFElectraForQuestionAnswering"),V$r=o(" (ELECTRA model)"),X$r=l(),UC=a("li"),AEe=a("strong"),z$r=o("flaubert"),W$r=o(" \u2014 "),aK=a("a"),Q$r=o("TFFlaubertForQuestionAnsweringSimple"),H$r=o(" (FlauBERT model)"),U$r=l(),JC=a("li"),LEe=a("strong"),J$r=o("funnel"),Y$r=o(" \u2014 "),nK=a("a"),K$r=o("TFFunnelForQuestionAnswering"),Z$r=o(" (Funnel Transformer model)"),ekr=l(),YC=a("li"),yEe=a("strong"),okr=o("gptj"),rkr=o(" \u2014 "),sK=a("a"),tkr=o("TFGPTJForQuestionAnswering"),akr=o(" (GPT-J model)"),nkr=l(),KC=a("li"),xEe=a("strong"),skr=o("longformer"),lkr=o(" \u2014 "),lK=a("a"),ikr=o("TFLongformerForQuestionAnswering"),dkr=o(" (Longformer model)"),ckr=l(),ZC=a("li"),$Ee=a("strong"),fkr=o("mobilebert"),mkr=o(" \u2014 "),iK=a("a"),gkr=o("TFMobileBertForQuestionAnswering"),hkr=o(" (MobileBERT model)"),pkr=l(),e5=a("li"),kEe=a("strong"),ukr=o("mpnet"),_kr=o(" \u2014 "),dK=a("a"),bkr=o("TFMPNetForQuestionAnswering"),vkr=o(" (MPNet model)"),Fkr=l(),o5=a("li"),SEe=a("strong"),Tkr=o("rembert"),Mkr=o(" \u2014 "),cK=a("a"),Ekr=o("TFRemBertForQuestionAnswering"),Ckr=o(" (RemBERT model)"),wkr=l(),r5=a("li"),REe=a("strong"),Akr=o("roberta"),Lkr=o(" \u2014 "),fK=a("a"),ykr=o("TFRobertaForQuestionAnswering"),xkr=o(" (RoBERTa model)"),$kr=l(),t5=a("li"),PEe=a("strong"),kkr=o("roformer"),Skr=o(" \u2014 "),mK=a("a"),Rkr=o("TFRoFormerForQuestionAnswering"),Pkr=o(" (RoFormer model)"),Bkr=l(),a5=a("li"),BEe=a("strong"),Ikr=o("xlm"),Nkr=o(" \u2014 "),gK=a("a"),qkr=o("TFXLMForQuestionAnsweringSimple"),jkr=o(" (XLM model)"),Dkr=l(),n5=a("li"),IEe=a("strong"),Gkr=o("xlm-roberta"),Okr=o(" \u2014 "),hK=a("a"),Vkr=o("TFXLMRobertaForQuestionAnswering"),Xkr=o(" (XLM-RoBERTa model)"),zkr=l(),s5=a("li"),NEe=a("strong"),Wkr=o("xlnet"),Qkr=o(" \u2014 "),pK=a("a"),Hkr=o("TFXLNetForQuestionAnsweringSimple"),Ukr=o(" (XLNet model)"),Jkr=l(),F(l5.$$.fragment),JOe=l(),Ic=a("h2"),i5=a("a"),qEe=a("span"),F(_x.$$.fragment),Ykr=l(),jEe=a("span"),Kkr=o("TFAutoModelForVision2Seq"),YOe=l(),fr=a("div"),F(bx.$$.fragment),Zkr=l(),Nc=a("p"),eSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),uK=a("a"),oSr=o("from_pretrained()"),rSr=o(" class method or the "),_K=a("a"),tSr=o("from_config()"),aSr=o(` class
method.`),nSr=l(),vx=a("p"),sSr=o("This class cannot be instantiated directly using "),DEe=a("code"),lSr=o("__init__()"),iSr=o(" (throws an error)."),dSr=l(),Ot=a("div"),F(Fx.$$.fragment),cSr=l(),GEe=a("p"),fSr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),mSr=l(),qc=a("p"),gSr=o(`Note:
Loading a model from its configuration file does `),OEe=a("strong"),hSr=o("not"),pSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=a("a"),uSr=o("from_pretrained()"),_Sr=o(" to load the model weights."),bSr=l(),F(d5.$$.fragment),vSr=l(),jr=a("div"),F(Tx.$$.fragment),FSr=l(),VEe=a("p"),TSr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),MSr=l(),_n=a("p"),ESr=o("The model class to instantiate is selected based on the "),XEe=a("code"),CSr=o("model_type"),wSr=o(` property of the config object (either
passed as an argument or loaded from `),zEe=a("code"),ASr=o("pretrained_model_name_or_path"),LSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WEe=a("code"),ySr=o("pretrained_model_name_or_path"),xSr=o(":"),$Sr=l(),QEe=a("ul"),c5=a("li"),HEe=a("strong"),kSr=o("vision-encoder-decoder"),SSr=o(" \u2014 "),vK=a("a"),RSr=o("TFVisionEncoderDecoderModel"),PSr=o(" (Vision Encoder decoder model)"),BSr=l(),F(f5.$$.fragment),KOe=l(),jc=a("h2"),m5=a("a"),UEe=a("span"),F(Mx.$$.fragment),ISr=l(),JEe=a("span"),NSr=o("TFAutoModelForSpeechSeq2Seq"),ZOe=l(),mr=a("div"),F(Ex.$$.fragment),qSr=l(),Dc=a("p"),jSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),FK=a("a"),DSr=o("from_pretrained()"),GSr=o(" class method or the "),TK=a("a"),OSr=o("from_config()"),VSr=o(` class
method.`),XSr=l(),Cx=a("p"),zSr=o("This class cannot be instantiated directly using "),YEe=a("code"),WSr=o("__init__()"),QSr=o(" (throws an error)."),HSr=l(),Vt=a("div"),F(wx.$$.fragment),USr=l(),KEe=a("p"),JSr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),YSr=l(),Gc=a("p"),KSr=o(`Note:
Loading a model from its configuration file does `),ZEe=a("strong"),ZSr=o("not"),eRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MK=a("a"),oRr=o("from_pretrained()"),rRr=o(" to load the model weights."),tRr=l(),F(g5.$$.fragment),aRr=l(),Dr=a("div"),F(Ax.$$.fragment),nRr=l(),e4e=a("p"),sRr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),lRr=l(),bn=a("p"),iRr=o("The model class to instantiate is selected based on the "),o4e=a("code"),dRr=o("model_type"),cRr=o(` property of the config object (either
passed as an argument or loaded from `),r4e=a("code"),fRr=o("pretrained_model_name_or_path"),mRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t4e=a("code"),gRr=o("pretrained_model_name_or_path"),hRr=o(":"),pRr=l(),a4e=a("ul"),h5=a("li"),n4e=a("strong"),uRr=o("speech_to_text"),_Rr=o(" \u2014 "),EK=a("a"),bRr=o("TFSpeech2TextForConditionalGeneration"),vRr=o(" (Speech2Text model)"),FRr=l(),F(p5.$$.fragment),eVe=l(),Oc=a("h2"),u5=a("a"),s4e=a("span"),F(Lx.$$.fragment),TRr=l(),l4e=a("span"),MRr=o("FlaxAutoModel"),oVe=l(),gr=a("div"),F(yx.$$.fragment),ERr=l(),Vc=a("p"),CRr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),CK=a("a"),wRr=o("from_pretrained()"),ARr=o(" class method or the "),wK=a("a"),LRr=o("from_config()"),yRr=o(` class
method.`),xRr=l(),xx=a("p"),$Rr=o("This class cannot be instantiated directly using "),i4e=a("code"),kRr=o("__init__()"),SRr=o(" (throws an error)."),RRr=l(),Xt=a("div"),F($x.$$.fragment),PRr=l(),d4e=a("p"),BRr=o("Instantiates one of the base model classes of the library from a configuration."),IRr=l(),Xc=a("p"),NRr=o(`Note:
Loading a model from its configuration file does `),c4e=a("strong"),qRr=o("not"),jRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AK=a("a"),DRr=o("from_pretrained()"),GRr=o(" to load the model weights."),ORr=l(),F(_5.$$.fragment),VRr=l(),Gr=a("div"),F(kx.$$.fragment),XRr=l(),f4e=a("p"),zRr=o("Instantiate one of the base model classes of the library from a pretrained model."),WRr=l(),vn=a("p"),QRr=o("The model class to instantiate is selected based on the "),m4e=a("code"),HRr=o("model_type"),URr=o(` property of the config object (either
passed as an argument or loaded from `),g4e=a("code"),JRr=o("pretrained_model_name_or_path"),YRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h4e=a("code"),KRr=o("pretrained_model_name_or_path"),ZRr=o(":"),ePr=l(),oe=a("ul"),b5=a("li"),p4e=a("strong"),oPr=o("albert"),rPr=o(" \u2014 "),LK=a("a"),tPr=o("FlaxAlbertModel"),aPr=o(" (ALBERT model)"),nPr=l(),v5=a("li"),u4e=a("strong"),sPr=o("bart"),lPr=o(" \u2014 "),yK=a("a"),iPr=o("FlaxBartModel"),dPr=o(" (BART model)"),cPr=l(),F5=a("li"),_4e=a("strong"),fPr=o("beit"),mPr=o(" \u2014 "),xK=a("a"),gPr=o("FlaxBeitModel"),hPr=o(" (BEiT model)"),pPr=l(),T5=a("li"),b4e=a("strong"),uPr=o("bert"),_Pr=o(" \u2014 "),$K=a("a"),bPr=o("FlaxBertModel"),vPr=o(" (BERT model)"),FPr=l(),M5=a("li"),v4e=a("strong"),TPr=o("big_bird"),MPr=o(" \u2014 "),kK=a("a"),EPr=o("FlaxBigBirdModel"),CPr=o(" (BigBird model)"),wPr=l(),E5=a("li"),F4e=a("strong"),APr=o("blenderbot"),LPr=o(" \u2014 "),SK=a("a"),yPr=o("FlaxBlenderbotModel"),xPr=o(" (Blenderbot model)"),$Pr=l(),C5=a("li"),T4e=a("strong"),kPr=o("blenderbot-small"),SPr=o(" \u2014 "),RK=a("a"),RPr=o("FlaxBlenderbotSmallModel"),PPr=o(" (BlenderbotSmall model)"),BPr=l(),w5=a("li"),M4e=a("strong"),IPr=o("clip"),NPr=o(" \u2014 "),PK=a("a"),qPr=o("FlaxCLIPModel"),jPr=o(" (CLIP model)"),DPr=l(),A5=a("li"),E4e=a("strong"),GPr=o("distilbert"),OPr=o(" \u2014 "),BK=a("a"),VPr=o("FlaxDistilBertModel"),XPr=o(" (DistilBERT model)"),zPr=l(),L5=a("li"),C4e=a("strong"),WPr=o("electra"),QPr=o(" \u2014 "),IK=a("a"),HPr=o("FlaxElectraModel"),UPr=o(" (ELECTRA model)"),JPr=l(),y5=a("li"),w4e=a("strong"),YPr=o("gpt2"),KPr=o(" \u2014 "),NK=a("a"),ZPr=o("FlaxGPT2Model"),eBr=o(" (OpenAI GPT-2 model)"),oBr=l(),x5=a("li"),A4e=a("strong"),rBr=o("gpt_neo"),tBr=o(" \u2014 "),qK=a("a"),aBr=o("FlaxGPTNeoModel"),nBr=o(" (GPT Neo model)"),sBr=l(),$5=a("li"),L4e=a("strong"),lBr=o("gptj"),iBr=o(" \u2014 "),jK=a("a"),dBr=o("FlaxGPTJModel"),cBr=o(" (GPT-J model)"),fBr=l(),k5=a("li"),y4e=a("strong"),mBr=o("longt5"),gBr=o(" \u2014 "),DK=a("a"),hBr=o("FlaxLongT5Model"),pBr=o(" (LongT5 model)"),uBr=l(),S5=a("li"),x4e=a("strong"),_Br=o("marian"),bBr=o(" \u2014 "),GK=a("a"),vBr=o("FlaxMarianModel"),FBr=o(" (Marian model)"),TBr=l(),R5=a("li"),$4e=a("strong"),MBr=o("mbart"),EBr=o(" \u2014 "),OK=a("a"),CBr=o("FlaxMBartModel"),wBr=o(" (mBART model)"),ABr=l(),P5=a("li"),k4e=a("strong"),LBr=o("mt5"),yBr=o(" \u2014 "),VK=a("a"),xBr=o("FlaxMT5Model"),$Br=o(" (MT5 model)"),kBr=l(),B5=a("li"),S4e=a("strong"),SBr=o("opt"),RBr=o(" \u2014 "),XK=a("a"),PBr=o("FlaxOPTModel"),BBr=o(" (OPT model)"),IBr=l(),I5=a("li"),R4e=a("strong"),NBr=o("pegasus"),qBr=o(" \u2014 "),zK=a("a"),jBr=o("FlaxPegasusModel"),DBr=o(" (Pegasus model)"),GBr=l(),N5=a("li"),P4e=a("strong"),OBr=o("roberta"),VBr=o(" \u2014 "),WK=a("a"),XBr=o("FlaxRobertaModel"),zBr=o(" (RoBERTa model)"),WBr=l(),q5=a("li"),B4e=a("strong"),QBr=o("roformer"),HBr=o(" \u2014 "),QK=a("a"),UBr=o("FlaxRoFormerModel"),JBr=o(" (RoFormer model)"),YBr=l(),j5=a("li"),I4e=a("strong"),KBr=o("t5"),ZBr=o(" \u2014 "),HK=a("a"),eIr=o("FlaxT5Model"),oIr=o(" (T5 model)"),rIr=l(),D5=a("li"),N4e=a("strong"),tIr=o("vision-text-dual-encoder"),aIr=o(" \u2014 "),UK=a("a"),nIr=o("FlaxVisionTextDualEncoderModel"),sIr=o(" (VisionTextDualEncoder model)"),lIr=l(),G5=a("li"),q4e=a("strong"),iIr=o("vit"),dIr=o(" \u2014 "),JK=a("a"),cIr=o("FlaxViTModel"),fIr=o(" (ViT model)"),mIr=l(),O5=a("li"),j4e=a("strong"),gIr=o("wav2vec2"),hIr=o(" \u2014 "),YK=a("a"),pIr=o("FlaxWav2Vec2Model"),uIr=o(" (Wav2Vec2 model)"),_Ir=l(),V5=a("li"),D4e=a("strong"),bIr=o("xglm"),vIr=o(" \u2014 "),KK=a("a"),FIr=o("FlaxXGLMModel"),TIr=o(" (XGLM model)"),MIr=l(),X5=a("li"),G4e=a("strong"),EIr=o("xlm-roberta"),CIr=o(" \u2014 "),ZK=a("a"),wIr=o("FlaxXLMRobertaModel"),AIr=o(" (XLM-RoBERTa model)"),LIr=l(),F(z5.$$.fragment),rVe=l(),zc=a("h2"),W5=a("a"),O4e=a("span"),F(Sx.$$.fragment),yIr=l(),V4e=a("span"),xIr=o("FlaxAutoModelForCausalLM"),tVe=l(),hr=a("div"),F(Rx.$$.fragment),$Ir=l(),Wc=a("p"),kIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),eZ=a("a"),SIr=o("from_pretrained()"),RIr=o(" class method or the "),oZ=a("a"),PIr=o("from_config()"),BIr=o(` class
method.`),IIr=l(),Px=a("p"),NIr=o("This class cannot be instantiated directly using "),X4e=a("code"),qIr=o("__init__()"),jIr=o(" (throws an error)."),DIr=l(),zt=a("div"),F(Bx.$$.fragment),GIr=l(),z4e=a("p"),OIr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),VIr=l(),Qc=a("p"),XIr=o(`Note:
Loading a model from its configuration file does `),W4e=a("strong"),zIr=o("not"),WIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rZ=a("a"),QIr=o("from_pretrained()"),HIr=o(" to load the model weights."),UIr=l(),F(Q5.$$.fragment),JIr=l(),Or=a("div"),F(Ix.$$.fragment),YIr=l(),Q4e=a("p"),KIr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ZIr=l(),Fn=a("p"),eNr=o("The model class to instantiate is selected based on the "),H4e=a("code"),oNr=o("model_type"),rNr=o(` property of the config object (either
passed as an argument or loaded from `),U4e=a("code"),tNr=o("pretrained_model_name_or_path"),aNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J4e=a("code"),nNr=o("pretrained_model_name_or_path"),sNr=o(":"),lNr=l(),xe=a("ul"),H5=a("li"),Y4e=a("strong"),iNr=o("bart"),dNr=o(" \u2014 "),tZ=a("a"),cNr=o("FlaxBartForCausalLM"),fNr=o(" (BART model)"),mNr=l(),U5=a("li"),K4e=a("strong"),gNr=o("bert"),hNr=o(" \u2014 "),aZ=a("a"),pNr=o("FlaxBertForCausalLM"),uNr=o(" (BERT model)"),_Nr=l(),J5=a("li"),Z4e=a("strong"),bNr=o("big_bird"),vNr=o(" \u2014 "),nZ=a("a"),FNr=o("FlaxBigBirdForCausalLM"),TNr=o(" (BigBird model)"),MNr=l(),Y5=a("li"),eCe=a("strong"),ENr=o("electra"),CNr=o(" \u2014 "),sZ=a("a"),wNr=o("FlaxElectraForCausalLM"),ANr=o(" (ELECTRA model)"),LNr=l(),K5=a("li"),oCe=a("strong"),yNr=o("gpt2"),xNr=o(" \u2014 "),lZ=a("a"),$Nr=o("FlaxGPT2LMHeadModel"),kNr=o(" (OpenAI GPT-2 model)"),SNr=l(),Z5=a("li"),rCe=a("strong"),RNr=o("gpt_neo"),PNr=o(" \u2014 "),iZ=a("a"),BNr=o("FlaxGPTNeoForCausalLM"),INr=o(" (GPT Neo model)"),NNr=l(),e0=a("li"),tCe=a("strong"),qNr=o("gptj"),jNr=o(" \u2014 "),dZ=a("a"),DNr=o("FlaxGPTJForCausalLM"),GNr=o(" (GPT-J model)"),ONr=l(),o0=a("li"),aCe=a("strong"),VNr=o("opt"),XNr=o(" \u2014 "),cZ=a("a"),zNr=o("FlaxOPTForCausalLM"),WNr=o(" (OPT model)"),QNr=l(),r0=a("li"),nCe=a("strong"),HNr=o("roberta"),UNr=o(" \u2014 "),fZ=a("a"),JNr=o("FlaxRobertaForCausalLM"),YNr=o(" (RoBERTa model)"),KNr=l(),t0=a("li"),sCe=a("strong"),ZNr=o("xglm"),eqr=o(" \u2014 "),mZ=a("a"),oqr=o("FlaxXGLMForCausalLM"),rqr=o(" (XGLM model)"),tqr=l(),F(a0.$$.fragment),aVe=l(),Hc=a("h2"),n0=a("a"),lCe=a("span"),F(Nx.$$.fragment),aqr=l(),iCe=a("span"),nqr=o("FlaxAutoModelForPreTraining"),nVe=l(),pr=a("div"),F(qx.$$.fragment),sqr=l(),Uc=a("p"),lqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gZ=a("a"),iqr=o("from_pretrained()"),dqr=o(" class method or the "),hZ=a("a"),cqr=o("from_config()"),fqr=o(` class
method.`),mqr=l(),jx=a("p"),gqr=o("This class cannot be instantiated directly using "),dCe=a("code"),hqr=o("__init__()"),pqr=o(" (throws an error)."),uqr=l(),Wt=a("div"),F(Dx.$$.fragment),_qr=l(),cCe=a("p"),bqr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),vqr=l(),Jc=a("p"),Fqr=o(`Note:
Loading a model from its configuration file does `),fCe=a("strong"),Tqr=o("not"),Mqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pZ=a("a"),Eqr=o("from_pretrained()"),Cqr=o(" to load the model weights."),wqr=l(),F(s0.$$.fragment),Aqr=l(),Vr=a("div"),F(Gx.$$.fragment),Lqr=l(),mCe=a("p"),yqr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),xqr=l(),Tn=a("p"),$qr=o("The model class to instantiate is selected based on the "),gCe=a("code"),kqr=o("model_type"),Sqr=o(` property of the config object (either
passed as an argument or loaded from `),hCe=a("code"),Rqr=o("pretrained_model_name_or_path"),Pqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pCe=a("code"),Bqr=o("pretrained_model_name_or_path"),Iqr=o(":"),Nqr=l(),Ee=a("ul"),l0=a("li"),uCe=a("strong"),qqr=o("albert"),jqr=o(" \u2014 "),uZ=a("a"),Dqr=o("FlaxAlbertForPreTraining"),Gqr=o(" (ALBERT model)"),Oqr=l(),i0=a("li"),_Ce=a("strong"),Vqr=o("bart"),Xqr=o(" \u2014 "),_Z=a("a"),zqr=o("FlaxBartForConditionalGeneration"),Wqr=o(" (BART model)"),Qqr=l(),d0=a("li"),bCe=a("strong"),Hqr=o("bert"),Uqr=o(" \u2014 "),bZ=a("a"),Jqr=o("FlaxBertForPreTraining"),Yqr=o(" (BERT model)"),Kqr=l(),c0=a("li"),vCe=a("strong"),Zqr=o("big_bird"),ejr=o(" \u2014 "),vZ=a("a"),ojr=o("FlaxBigBirdForPreTraining"),rjr=o(" (BigBird model)"),tjr=l(),f0=a("li"),FCe=a("strong"),ajr=o("electra"),njr=o(" \u2014 "),FZ=a("a"),sjr=o("FlaxElectraForPreTraining"),ljr=o(" (ELECTRA model)"),ijr=l(),m0=a("li"),TCe=a("strong"),djr=o("longt5"),cjr=o(" \u2014 "),TZ=a("a"),fjr=o("FlaxLongT5ForConditionalGeneration"),mjr=o(" (LongT5 model)"),gjr=l(),g0=a("li"),MCe=a("strong"),hjr=o("mbart"),pjr=o(" \u2014 "),MZ=a("a"),ujr=o("FlaxMBartForConditionalGeneration"),_jr=o(" (mBART model)"),bjr=l(),h0=a("li"),ECe=a("strong"),vjr=o("mt5"),Fjr=o(" \u2014 "),EZ=a("a"),Tjr=o("FlaxMT5ForConditionalGeneration"),Mjr=o(" (MT5 model)"),Ejr=l(),p0=a("li"),CCe=a("strong"),Cjr=o("roberta"),wjr=o(" \u2014 "),CZ=a("a"),Ajr=o("FlaxRobertaForMaskedLM"),Ljr=o(" (RoBERTa model)"),yjr=l(),u0=a("li"),wCe=a("strong"),xjr=o("roformer"),$jr=o(" \u2014 "),wZ=a("a"),kjr=o("FlaxRoFormerForMaskedLM"),Sjr=o(" (RoFormer model)"),Rjr=l(),_0=a("li"),ACe=a("strong"),Pjr=o("t5"),Bjr=o(" \u2014 "),AZ=a("a"),Ijr=o("FlaxT5ForConditionalGeneration"),Njr=o(" (T5 model)"),qjr=l(),b0=a("li"),LCe=a("strong"),jjr=o("wav2vec2"),Djr=o(" \u2014 "),LZ=a("a"),Gjr=o("FlaxWav2Vec2ForPreTraining"),Ojr=o(" (Wav2Vec2 model)"),Vjr=l(),v0=a("li"),yCe=a("strong"),Xjr=o("xlm-roberta"),zjr=o(" \u2014 "),yZ=a("a"),Wjr=o("FlaxXLMRobertaForMaskedLM"),Qjr=o(" (XLM-RoBERTa model)"),Hjr=l(),F(F0.$$.fragment),sVe=l(),Yc=a("h2"),T0=a("a"),xCe=a("span"),F(Ox.$$.fragment),Ujr=l(),$Ce=a("span"),Jjr=o("FlaxAutoModelForMaskedLM"),lVe=l(),ur=a("div"),F(Vx.$$.fragment),Yjr=l(),Kc=a("p"),Kjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),xZ=a("a"),Zjr=o("from_pretrained()"),eDr=o(" class method or the "),$Z=a("a"),oDr=o("from_config()"),rDr=o(` class
method.`),tDr=l(),Xx=a("p"),aDr=o("This class cannot be instantiated directly using "),kCe=a("code"),nDr=o("__init__()"),sDr=o(" (throws an error)."),lDr=l(),Qt=a("div"),F(zx.$$.fragment),iDr=l(),SCe=a("p"),dDr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),cDr=l(),Zc=a("p"),fDr=o(`Note:
Loading a model from its configuration file does `),RCe=a("strong"),mDr=o("not"),gDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kZ=a("a"),hDr=o("from_pretrained()"),pDr=o(" to load the model weights."),uDr=l(),F(M0.$$.fragment),_Dr=l(),Xr=a("div"),F(Wx.$$.fragment),bDr=l(),PCe=a("p"),vDr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),FDr=l(),Mn=a("p"),TDr=o("The model class to instantiate is selected based on the "),BCe=a("code"),MDr=o("model_type"),EDr=o(` property of the config object (either
passed as an argument or loaded from `),ICe=a("code"),CDr=o("pretrained_model_name_or_path"),wDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NCe=a("code"),ADr=o("pretrained_model_name_or_path"),LDr=o(":"),yDr=l(),$e=a("ul"),E0=a("li"),qCe=a("strong"),xDr=o("albert"),$Dr=o(" \u2014 "),SZ=a("a"),kDr=o("FlaxAlbertForMaskedLM"),SDr=o(" (ALBERT model)"),RDr=l(),C0=a("li"),jCe=a("strong"),PDr=o("bart"),BDr=o(" \u2014 "),RZ=a("a"),IDr=o("FlaxBartForConditionalGeneration"),NDr=o(" (BART model)"),qDr=l(),w0=a("li"),DCe=a("strong"),jDr=o("bert"),DDr=o(" \u2014 "),PZ=a("a"),GDr=o("FlaxBertForMaskedLM"),ODr=o(" (BERT model)"),VDr=l(),A0=a("li"),GCe=a("strong"),XDr=o("big_bird"),zDr=o(" \u2014 "),BZ=a("a"),WDr=o("FlaxBigBirdForMaskedLM"),QDr=o(" (BigBird model)"),HDr=l(),L0=a("li"),OCe=a("strong"),UDr=o("distilbert"),JDr=o(" \u2014 "),IZ=a("a"),YDr=o("FlaxDistilBertForMaskedLM"),KDr=o(" (DistilBERT model)"),ZDr=l(),y0=a("li"),VCe=a("strong"),eGr=o("electra"),oGr=o(" \u2014 "),NZ=a("a"),rGr=o("FlaxElectraForMaskedLM"),tGr=o(" (ELECTRA model)"),aGr=l(),x0=a("li"),XCe=a("strong"),nGr=o("mbart"),sGr=o(" \u2014 "),qZ=a("a"),lGr=o("FlaxMBartForConditionalGeneration"),iGr=o(" (mBART model)"),dGr=l(),$0=a("li"),zCe=a("strong"),cGr=o("roberta"),fGr=o(" \u2014 "),jZ=a("a"),mGr=o("FlaxRobertaForMaskedLM"),gGr=o(" (RoBERTa model)"),hGr=l(),k0=a("li"),WCe=a("strong"),pGr=o("roformer"),uGr=o(" \u2014 "),DZ=a("a"),_Gr=o("FlaxRoFormerForMaskedLM"),bGr=o(" (RoFormer model)"),vGr=l(),S0=a("li"),QCe=a("strong"),FGr=o("xlm-roberta"),TGr=o(" \u2014 "),GZ=a("a"),MGr=o("FlaxXLMRobertaForMaskedLM"),EGr=o(" (XLM-RoBERTa model)"),CGr=l(),F(R0.$$.fragment),iVe=l(),ef=a("h2"),P0=a("a"),HCe=a("span"),F(Qx.$$.fragment),wGr=l(),UCe=a("span"),AGr=o("FlaxAutoModelForSeq2SeqLM"),dVe=l(),_r=a("div"),F(Hx.$$.fragment),LGr=l(),of=a("p"),yGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),OZ=a("a"),xGr=o("from_pretrained()"),$Gr=o(" class method or the "),VZ=a("a"),kGr=o("from_config()"),SGr=o(` class
method.`),RGr=l(),Ux=a("p"),PGr=o("This class cannot be instantiated directly using "),JCe=a("code"),BGr=o("__init__()"),IGr=o(" (throws an error)."),NGr=l(),Ht=a("div"),F(Jx.$$.fragment),qGr=l(),YCe=a("p"),jGr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),DGr=l(),rf=a("p"),GGr=o(`Note:
Loading a model from its configuration file does `),KCe=a("strong"),OGr=o("not"),VGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XZ=a("a"),XGr=o("from_pretrained()"),zGr=o(" to load the model weights."),WGr=l(),F(B0.$$.fragment),QGr=l(),zr=a("div"),F(Yx.$$.fragment),HGr=l(),ZCe=a("p"),UGr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),JGr=l(),En=a("p"),YGr=o("The model class to instantiate is selected based on the "),e5e=a("code"),KGr=o("model_type"),ZGr=o(` property of the config object (either
passed as an argument or loaded from `),o5e=a("code"),eOr=o("pretrained_model_name_or_path"),oOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r5e=a("code"),rOr=o("pretrained_model_name_or_path"),tOr=o(":"),aOr=l(),ke=a("ul"),I0=a("li"),t5e=a("strong"),nOr=o("bart"),sOr=o(" \u2014 "),zZ=a("a"),lOr=o("FlaxBartForConditionalGeneration"),iOr=o(" (BART model)"),dOr=l(),N0=a("li"),a5e=a("strong"),cOr=o("blenderbot"),fOr=o(" \u2014 "),WZ=a("a"),mOr=o("FlaxBlenderbotForConditionalGeneration"),gOr=o(" (Blenderbot model)"),hOr=l(),q0=a("li"),n5e=a("strong"),pOr=o("blenderbot-small"),uOr=o(" \u2014 "),QZ=a("a"),_Or=o("FlaxBlenderbotSmallForConditionalGeneration"),bOr=o(" (BlenderbotSmall model)"),vOr=l(),j0=a("li"),s5e=a("strong"),FOr=o("encoder-decoder"),TOr=o(" \u2014 "),HZ=a("a"),MOr=o("FlaxEncoderDecoderModel"),EOr=o(" (Encoder decoder model)"),COr=l(),D0=a("li"),l5e=a("strong"),wOr=o("longt5"),AOr=o(" \u2014 "),UZ=a("a"),LOr=o("FlaxLongT5ForConditionalGeneration"),yOr=o(" (LongT5 model)"),xOr=l(),G0=a("li"),i5e=a("strong"),$Or=o("marian"),kOr=o(" \u2014 "),JZ=a("a"),SOr=o("FlaxMarianMTModel"),ROr=o(" (Marian model)"),POr=l(),O0=a("li"),d5e=a("strong"),BOr=o("mbart"),IOr=o(" \u2014 "),YZ=a("a"),NOr=o("FlaxMBartForConditionalGeneration"),qOr=o(" (mBART model)"),jOr=l(),V0=a("li"),c5e=a("strong"),DOr=o("mt5"),GOr=o(" \u2014 "),KZ=a("a"),OOr=o("FlaxMT5ForConditionalGeneration"),VOr=o(" (MT5 model)"),XOr=l(),X0=a("li"),f5e=a("strong"),zOr=o("pegasus"),WOr=o(" \u2014 "),ZZ=a("a"),QOr=o("FlaxPegasusForConditionalGeneration"),HOr=o(" (Pegasus model)"),UOr=l(),z0=a("li"),m5e=a("strong"),JOr=o("t5"),YOr=o(" \u2014 "),eee=a("a"),KOr=o("FlaxT5ForConditionalGeneration"),ZOr=o(" (T5 model)"),eVr=l(),F(W0.$$.fragment),cVe=l(),tf=a("h2"),Q0=a("a"),g5e=a("span"),F(Kx.$$.fragment),oVr=l(),h5e=a("span"),rVr=o("FlaxAutoModelForSequenceClassification"),fVe=l(),br=a("div"),F(Zx.$$.fragment),tVr=l(),af=a("p"),aVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),oee=a("a"),nVr=o("from_pretrained()"),sVr=o(" class method or the "),ree=a("a"),lVr=o("from_config()"),iVr=o(` class
method.`),dVr=l(),e$=a("p"),cVr=o("This class cannot be instantiated directly using "),p5e=a("code"),fVr=o("__init__()"),mVr=o(" (throws an error)."),gVr=l(),Ut=a("div"),F(o$.$$.fragment),hVr=l(),u5e=a("p"),pVr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),uVr=l(),nf=a("p"),_Vr=o(`Note:
Loading a model from its configuration file does `),_5e=a("strong"),bVr=o("not"),vVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tee=a("a"),FVr=o("from_pretrained()"),TVr=o(" to load the model weights."),MVr=l(),F(H0.$$.fragment),EVr=l(),Wr=a("div"),F(r$.$$.fragment),CVr=l(),b5e=a("p"),wVr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),AVr=l(),Cn=a("p"),LVr=o("The model class to instantiate is selected based on the "),v5e=a("code"),yVr=o("model_type"),xVr=o(` property of the config object (either
passed as an argument or loaded from `),F5e=a("code"),$Vr=o("pretrained_model_name_or_path"),kVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T5e=a("code"),SVr=o("pretrained_model_name_or_path"),RVr=o(":"),PVr=l(),Se=a("ul"),U0=a("li"),M5e=a("strong"),BVr=o("albert"),IVr=o(" \u2014 "),aee=a("a"),NVr=o("FlaxAlbertForSequenceClassification"),qVr=o(" (ALBERT model)"),jVr=l(),J0=a("li"),E5e=a("strong"),DVr=o("bart"),GVr=o(" \u2014 "),nee=a("a"),OVr=o("FlaxBartForSequenceClassification"),VVr=o(" (BART model)"),XVr=l(),Y0=a("li"),C5e=a("strong"),zVr=o("bert"),WVr=o(" \u2014 "),see=a("a"),QVr=o("FlaxBertForSequenceClassification"),HVr=o(" (BERT model)"),UVr=l(),K0=a("li"),w5e=a("strong"),JVr=o("big_bird"),YVr=o(" \u2014 "),lee=a("a"),KVr=o("FlaxBigBirdForSequenceClassification"),ZVr=o(" (BigBird model)"),eXr=l(),Z0=a("li"),A5e=a("strong"),oXr=o("distilbert"),rXr=o(" \u2014 "),iee=a("a"),tXr=o("FlaxDistilBertForSequenceClassification"),aXr=o(" (DistilBERT model)"),nXr=l(),ew=a("li"),L5e=a("strong"),sXr=o("electra"),lXr=o(" \u2014 "),dee=a("a"),iXr=o("FlaxElectraForSequenceClassification"),dXr=o(" (ELECTRA model)"),cXr=l(),ow=a("li"),y5e=a("strong"),fXr=o("mbart"),mXr=o(" \u2014 "),cee=a("a"),gXr=o("FlaxMBartForSequenceClassification"),hXr=o(" (mBART model)"),pXr=l(),rw=a("li"),x5e=a("strong"),uXr=o("roberta"),_Xr=o(" \u2014 "),fee=a("a"),bXr=o("FlaxRobertaForSequenceClassification"),vXr=o(" (RoBERTa model)"),FXr=l(),tw=a("li"),$5e=a("strong"),TXr=o("roformer"),MXr=o(" \u2014 "),mee=a("a"),EXr=o("FlaxRoFormerForSequenceClassification"),CXr=o(" (RoFormer model)"),wXr=l(),aw=a("li"),k5e=a("strong"),AXr=o("xlm-roberta"),LXr=o(" \u2014 "),gee=a("a"),yXr=o("FlaxXLMRobertaForSequenceClassification"),xXr=o(" (XLM-RoBERTa model)"),$Xr=l(),F(nw.$$.fragment),mVe=l(),sf=a("h2"),sw=a("a"),S5e=a("span"),F(t$.$$.fragment),kXr=l(),R5e=a("span"),SXr=o("FlaxAutoModelForQuestionAnswering"),gVe=l(),vr=a("div"),F(a$.$$.fragment),RXr=l(),lf=a("p"),PXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hee=a("a"),BXr=o("from_pretrained()"),IXr=o(" class method or the "),pee=a("a"),NXr=o("from_config()"),qXr=o(` class
method.`),jXr=l(),n$=a("p"),DXr=o("This class cannot be instantiated directly using "),P5e=a("code"),GXr=o("__init__()"),OXr=o(" (throws an error)."),VXr=l(),Jt=a("div"),F(s$.$$.fragment),XXr=l(),B5e=a("p"),zXr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),WXr=l(),df=a("p"),QXr=o(`Note:
Loading a model from its configuration file does `),I5e=a("strong"),HXr=o("not"),UXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=a("a"),JXr=o("from_pretrained()"),YXr=o(" to load the model weights."),KXr=l(),F(lw.$$.fragment),ZXr=l(),Qr=a("div"),F(l$.$$.fragment),ezr=l(),N5e=a("p"),ozr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),rzr=l(),wn=a("p"),tzr=o("The model class to instantiate is selected based on the "),q5e=a("code"),azr=o("model_type"),nzr=o(` property of the config object (either
passed as an argument or loaded from `),j5e=a("code"),szr=o("pretrained_model_name_or_path"),lzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D5e=a("code"),izr=o("pretrained_model_name_or_path"),dzr=o(":"),czr=l(),Re=a("ul"),iw=a("li"),G5e=a("strong"),fzr=o("albert"),mzr=o(" \u2014 "),_ee=a("a"),gzr=o("FlaxAlbertForQuestionAnswering"),hzr=o(" (ALBERT model)"),pzr=l(),dw=a("li"),O5e=a("strong"),uzr=o("bart"),_zr=o(" \u2014 "),bee=a("a"),bzr=o("FlaxBartForQuestionAnswering"),vzr=o(" (BART model)"),Fzr=l(),cw=a("li"),V5e=a("strong"),Tzr=o("bert"),Mzr=o(" \u2014 "),vee=a("a"),Ezr=o("FlaxBertForQuestionAnswering"),Czr=o(" (BERT model)"),wzr=l(),fw=a("li"),X5e=a("strong"),Azr=o("big_bird"),Lzr=o(" \u2014 "),Fee=a("a"),yzr=o("FlaxBigBirdForQuestionAnswering"),xzr=o(" (BigBird model)"),$zr=l(),mw=a("li"),z5e=a("strong"),kzr=o("distilbert"),Szr=o(" \u2014 "),Tee=a("a"),Rzr=o("FlaxDistilBertForQuestionAnswering"),Pzr=o(" (DistilBERT model)"),Bzr=l(),gw=a("li"),W5e=a("strong"),Izr=o("electra"),Nzr=o(" \u2014 "),Mee=a("a"),qzr=o("FlaxElectraForQuestionAnswering"),jzr=o(" (ELECTRA model)"),Dzr=l(),hw=a("li"),Q5e=a("strong"),Gzr=o("mbart"),Ozr=o(" \u2014 "),Eee=a("a"),Vzr=o("FlaxMBartForQuestionAnswering"),Xzr=o(" (mBART model)"),zzr=l(),pw=a("li"),H5e=a("strong"),Wzr=o("roberta"),Qzr=o(" \u2014 "),Cee=a("a"),Hzr=o("FlaxRobertaForQuestionAnswering"),Uzr=o(" (RoBERTa model)"),Jzr=l(),uw=a("li"),U5e=a("strong"),Yzr=o("roformer"),Kzr=o(" \u2014 "),wee=a("a"),Zzr=o("FlaxRoFormerForQuestionAnswering"),eWr=o(" (RoFormer model)"),oWr=l(),_w=a("li"),J5e=a("strong"),rWr=o("xlm-roberta"),tWr=o(" \u2014 "),Aee=a("a"),aWr=o("FlaxXLMRobertaForQuestionAnswering"),nWr=o(" (XLM-RoBERTa model)"),sWr=l(),F(bw.$$.fragment),hVe=l(),cf=a("h2"),vw=a("a"),Y5e=a("span"),F(i$.$$.fragment),lWr=l(),K5e=a("span"),iWr=o("FlaxAutoModelForTokenClassification"),pVe=l(),Fr=a("div"),F(d$.$$.fragment),dWr=l(),ff=a("p"),cWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Lee=a("a"),fWr=o("from_pretrained()"),mWr=o(" class method or the "),yee=a("a"),gWr=o("from_config()"),hWr=o(` class
method.`),pWr=l(),c$=a("p"),uWr=o("This class cannot be instantiated directly using "),Z5e=a("code"),_Wr=o("__init__()"),bWr=o(" (throws an error)."),vWr=l(),Yt=a("div"),F(f$.$$.fragment),FWr=l(),e0e=a("p"),TWr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),MWr=l(),mf=a("p"),EWr=o(`Note:
Loading a model from its configuration file does `),o0e=a("strong"),CWr=o("not"),wWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=a("a"),AWr=o("from_pretrained()"),LWr=o(" to load the model weights."),yWr=l(),F(Fw.$$.fragment),xWr=l(),Hr=a("div"),F(m$.$$.fragment),$Wr=l(),r0e=a("p"),kWr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),SWr=l(),An=a("p"),RWr=o("The model class to instantiate is selected based on the "),t0e=a("code"),PWr=o("model_type"),BWr=o(` property of the config object (either
passed as an argument or loaded from `),a0e=a("code"),IWr=o("pretrained_model_name_or_path"),NWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n0e=a("code"),qWr=o("pretrained_model_name_or_path"),jWr=o(":"),DWr=l(),Ve=a("ul"),Tw=a("li"),s0e=a("strong"),GWr=o("albert"),OWr=o(" \u2014 "),$ee=a("a"),VWr=o("FlaxAlbertForTokenClassification"),XWr=o(" (ALBERT model)"),zWr=l(),Mw=a("li"),l0e=a("strong"),WWr=o("bert"),QWr=o(" \u2014 "),kee=a("a"),HWr=o("FlaxBertForTokenClassification"),UWr=o(" (BERT model)"),JWr=l(),Ew=a("li"),i0e=a("strong"),YWr=o("big_bird"),KWr=o(" \u2014 "),See=a("a"),ZWr=o("FlaxBigBirdForTokenClassification"),eQr=o(" (BigBird model)"),oQr=l(),Cw=a("li"),d0e=a("strong"),rQr=o("distilbert"),tQr=o(" \u2014 "),Ree=a("a"),aQr=o("FlaxDistilBertForTokenClassification"),nQr=o(" (DistilBERT model)"),sQr=l(),ww=a("li"),c0e=a("strong"),lQr=o("electra"),iQr=o(" \u2014 "),Pee=a("a"),dQr=o("FlaxElectraForTokenClassification"),cQr=o(" (ELECTRA model)"),fQr=l(),Aw=a("li"),f0e=a("strong"),mQr=o("roberta"),gQr=o(" \u2014 "),Bee=a("a"),hQr=o("FlaxRobertaForTokenClassification"),pQr=o(" (RoBERTa model)"),uQr=l(),Lw=a("li"),m0e=a("strong"),_Qr=o("roformer"),bQr=o(" \u2014 "),Iee=a("a"),vQr=o("FlaxRoFormerForTokenClassification"),FQr=o(" (RoFormer model)"),TQr=l(),yw=a("li"),g0e=a("strong"),MQr=o("xlm-roberta"),EQr=o(" \u2014 "),Nee=a("a"),CQr=o("FlaxXLMRobertaForTokenClassification"),wQr=o(" (XLM-RoBERTa model)"),AQr=l(),F(xw.$$.fragment),uVe=l(),gf=a("h2"),$w=a("a"),h0e=a("span"),F(g$.$$.fragment),LQr=l(),p0e=a("span"),yQr=o("FlaxAutoModelForMultipleChoice"),_Ve=l(),Tr=a("div"),F(h$.$$.fragment),xQr=l(),hf=a("p"),$Qr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),qee=a("a"),kQr=o("from_pretrained()"),SQr=o(" class method or the "),jee=a("a"),RQr=o("from_config()"),PQr=o(` class
method.`),BQr=l(),p$=a("p"),IQr=o("This class cannot be instantiated directly using "),u0e=a("code"),NQr=o("__init__()"),qQr=o(" (throws an error)."),jQr=l(),Kt=a("div"),F(u$.$$.fragment),DQr=l(),_0e=a("p"),GQr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),OQr=l(),pf=a("p"),VQr=o(`Note:
Loading a model from its configuration file does `),b0e=a("strong"),XQr=o("not"),zQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dee=a("a"),WQr=o("from_pretrained()"),QQr=o(" to load the model weights."),HQr=l(),F(kw.$$.fragment),UQr=l(),Ur=a("div"),F(_$.$$.fragment),JQr=l(),v0e=a("p"),YQr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),KQr=l(),Ln=a("p"),ZQr=o("The model class to instantiate is selected based on the "),F0e=a("code"),eHr=o("model_type"),oHr=o(` property of the config object (either
passed as an argument or loaded from `),T0e=a("code"),rHr=o("pretrained_model_name_or_path"),tHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M0e=a("code"),aHr=o("pretrained_model_name_or_path"),nHr=o(":"),sHr=l(),Xe=a("ul"),Sw=a("li"),E0e=a("strong"),lHr=o("albert"),iHr=o(" \u2014 "),Gee=a("a"),dHr=o("FlaxAlbertForMultipleChoice"),cHr=o(" (ALBERT model)"),fHr=l(),Rw=a("li"),C0e=a("strong"),mHr=o("bert"),gHr=o(" \u2014 "),Oee=a("a"),hHr=o("FlaxBertForMultipleChoice"),pHr=o(" (BERT model)"),uHr=l(),Pw=a("li"),w0e=a("strong"),_Hr=o("big_bird"),bHr=o(" \u2014 "),Vee=a("a"),vHr=o("FlaxBigBirdForMultipleChoice"),FHr=o(" (BigBird model)"),THr=l(),Bw=a("li"),A0e=a("strong"),MHr=o("distilbert"),EHr=o(" \u2014 "),Xee=a("a"),CHr=o("FlaxDistilBertForMultipleChoice"),wHr=o(" (DistilBERT model)"),AHr=l(),Iw=a("li"),L0e=a("strong"),LHr=o("electra"),yHr=o(" \u2014 "),zee=a("a"),xHr=o("FlaxElectraForMultipleChoice"),$Hr=o(" (ELECTRA model)"),kHr=l(),Nw=a("li"),y0e=a("strong"),SHr=o("roberta"),RHr=o(" \u2014 "),Wee=a("a"),PHr=o("FlaxRobertaForMultipleChoice"),BHr=o(" (RoBERTa model)"),IHr=l(),qw=a("li"),x0e=a("strong"),NHr=o("roformer"),qHr=o(" \u2014 "),Qee=a("a"),jHr=o("FlaxRoFormerForMultipleChoice"),DHr=o(" (RoFormer model)"),GHr=l(),jw=a("li"),$0e=a("strong"),OHr=o("xlm-roberta"),VHr=o(" \u2014 "),Hee=a("a"),XHr=o("FlaxXLMRobertaForMultipleChoice"),zHr=o(" (XLM-RoBERTa model)"),WHr=l(),F(Dw.$$.fragment),bVe=l(),uf=a("h2"),Gw=a("a"),k0e=a("span"),F(b$.$$.fragment),QHr=l(),S0e=a("span"),HHr=o("FlaxAutoModelForNextSentencePrediction"),vVe=l(),Mr=a("div"),F(v$.$$.fragment),UHr=l(),_f=a("p"),JHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Uee=a("a"),YHr=o("from_pretrained()"),KHr=o(" class method or the "),Jee=a("a"),ZHr=o("from_config()"),eUr=o(` class
method.`),oUr=l(),F$=a("p"),rUr=o("This class cannot be instantiated directly using "),R0e=a("code"),tUr=o("__init__()"),aUr=o(" (throws an error)."),nUr=l(),Zt=a("div"),F(T$.$$.fragment),sUr=l(),P0e=a("p"),lUr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),iUr=l(),bf=a("p"),dUr=o(`Note:
Loading a model from its configuration file does `),B0e=a("strong"),cUr=o("not"),fUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=a("a"),mUr=o("from_pretrained()"),gUr=o(" to load the model weights."),hUr=l(),F(Ow.$$.fragment),pUr=l(),Jr=a("div"),F(M$.$$.fragment),uUr=l(),I0e=a("p"),_Ur=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),bUr=l(),yn=a("p"),vUr=o("The model class to instantiate is selected based on the "),N0e=a("code"),FUr=o("model_type"),TUr=o(` property of the config object (either
passed as an argument or loaded from `),q0e=a("code"),MUr=o("pretrained_model_name_or_path"),EUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j0e=a("code"),CUr=o("pretrained_model_name_or_path"),wUr=o(":"),AUr=l(),D0e=a("ul"),Vw=a("li"),G0e=a("strong"),LUr=o("bert"),yUr=o(" \u2014 "),Kee=a("a"),xUr=o("FlaxBertForNextSentencePrediction"),$Ur=o(" (BERT model)"),kUr=l(),F(Xw.$$.fragment),FVe=l(),vf=a("h2"),zw=a("a"),O0e=a("span"),F(E$.$$.fragment),SUr=l(),V0e=a("span"),RUr=o("FlaxAutoModelForImageClassification"),TVe=l(),Er=a("div"),F(C$.$$.fragment),PUr=l(),Ff=a("p"),BUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Zee=a("a"),IUr=o("from_pretrained()"),NUr=o(" class method or the "),eoe=a("a"),qUr=o("from_config()"),jUr=o(` class
method.`),DUr=l(),w$=a("p"),GUr=o("This class cannot be instantiated directly using "),X0e=a("code"),OUr=o("__init__()"),VUr=o(" (throws an error)."),XUr=l(),ea=a("div"),F(A$.$$.fragment),zUr=l(),z0e=a("p"),WUr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),QUr=l(),Tf=a("p"),HUr=o(`Note:
Loading a model from its configuration file does `),W0e=a("strong"),UUr=o("not"),JUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ooe=a("a"),YUr=o("from_pretrained()"),KUr=o(" to load the model weights."),ZUr=l(),F(Ww.$$.fragment),eJr=l(),Yr=a("div"),F(L$.$$.fragment),oJr=l(),Q0e=a("p"),rJr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),tJr=l(),xn=a("p"),aJr=o("The model class to instantiate is selected based on the "),H0e=a("code"),nJr=o("model_type"),sJr=o(` property of the config object (either
passed as an argument or loaded from `),U0e=a("code"),lJr=o("pretrained_model_name_or_path"),iJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J0e=a("code"),dJr=o("pretrained_model_name_or_path"),cJr=o(":"),fJr=l(),y$=a("ul"),Qw=a("li"),Y0e=a("strong"),mJr=o("beit"),gJr=o(" \u2014 "),roe=a("a"),hJr=o("FlaxBeitForImageClassification"),pJr=o(" (BEiT model)"),uJr=l(),Hw=a("li"),K0e=a("strong"),_Jr=o("vit"),bJr=o(" \u2014 "),toe=a("a"),vJr=o("FlaxViTForImageClassification"),FJr=o(" (ViT model)"),TJr=l(),F(Uw.$$.fragment),MVe=l(),Mf=a("h2"),Jw=a("a"),Z0e=a("span"),F(x$.$$.fragment),MJr=l(),ewe=a("span"),EJr=o("FlaxAutoModelForVision2Seq"),EVe=l(),Cr=a("div"),F($$.$$.fragment),CJr=l(),Ef=a("p"),wJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),aoe=a("a"),AJr=o("from_pretrained()"),LJr=o(" class method or the "),noe=a("a"),yJr=o("from_config()"),xJr=o(` class
method.`),$Jr=l(),k$=a("p"),kJr=o("This class cannot be instantiated directly using "),owe=a("code"),SJr=o("__init__()"),RJr=o(" (throws an error)."),PJr=l(),oa=a("div"),F(S$.$$.fragment),BJr=l(),rwe=a("p"),IJr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),NJr=l(),Cf=a("p"),qJr=o(`Note:
Loading a model from its configuration file does `),twe=a("strong"),jJr=o("not"),DJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),soe=a("a"),GJr=o("from_pretrained()"),OJr=o(" to load the model weights."),VJr=l(),F(Yw.$$.fragment),XJr=l(),Kr=a("div"),F(R$.$$.fragment),zJr=l(),awe=a("p"),WJr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),QJr=l(),$n=a("p"),HJr=o("The model class to instantiate is selected based on the "),nwe=a("code"),UJr=o("model_type"),JJr=o(` property of the config object (either
passed as an argument or loaded from `),swe=a("code"),YJr=o("pretrained_model_name_or_path"),KJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lwe=a("code"),ZJr=o("pretrained_model_name_or_path"),eYr=o(":"),oYr=l(),iwe=a("ul"),Kw=a("li"),dwe=a("strong"),rYr=o("vision-encoder-decoder"),tYr=o(" \u2014 "),loe=a("a"),aYr=o("FlaxVisionEncoderDecoderModel"),nYr=o(" (Vision Encoder decoder model)"),sYr=l(),F(Zw.$$.fragment),this.h()},l(f){const _=Tjt('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var P$=s(p);m=n(P$,"A",{id:!0,class:!0,href:!0});var cwe=s(m);u=n(cwe,"SPAN",{});var fwe=s(u);T(d.$$.fragment,fwe),fwe.forEach(t),cwe.forEach(t),h=i(P$),Eo=n(P$,"SPAN",{});var mwe=s(Eo);Ti=r(mwe,"Auto Classes"),mwe.forEach(t),P$.forEach(t),yf=i(f),at=n(f,"P",{});var B$=s(at);Mi=r(B$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=n(B$,"CODE",{});var gwe=s(Ei);FL=r(gwe,"from_pretrained()"),gwe.forEach(t),xf=r(B$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),B$.forEach(t),Oe=i(f),We=n(f,"P",{});var kn=s(We);Ci=r(kn,"Instantiating one of "),Sn=n(kn,"A",{href:!0});var hwe=s(Sn);TL=r(hwe,"AutoConfig"),hwe.forEach(t),Rn=r(kn,", "),Pn=n(kn,"A",{href:!0});var pwe=s(Pn);ML=r(pwe,"AutoModel"),pwe.forEach(t),wi=r(kn,`, and
`),Bn=n(kn,"A",{href:!0});var uwe=s(Bn);EL=r(uwe,"AutoTokenizer"),uwe.forEach(t),Ai=r(kn," will directly create a class of the relevant architecture. For instance"),kn.forEach(t),$f=i(f),T(ya.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var I$=s(Ae);Yk=r(I$,"will create a model that is an instance of "),Li=n(I$,"A",{href:!0});var _we=s(Li);Kk=r(_we,"BertModel"),_we.forEach(t),Zk=r(I$,"."),I$.forEach(t),Co=i(f),xa=n(f,"P",{});var N$=s(xa);eS=r(N$,"There is one class of "),kf=n(N$,"CODE",{});var bwe=s(kf);oS=r(bwe,"AutoModel"),bwe.forEach(t),Pze=r(N$," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),N$.forEach(t),vGe=i(f),yi=n(f,"H2",{class:!0});var q$=s(yi);Sf=n(q$,"A",{id:!0,class:!0,href:!0});var vwe=s(Sf);rte=n(vwe,"SPAN",{});var Fwe=s(rte);T(CL.$$.fragment,Fwe),Fwe.forEach(t),vwe.forEach(t),Bze=i(q$),tte=n(q$,"SPAN",{});var Twe=s(tte);Ize=r(Twe,"Extending the Auto Classes"),Twe.forEach(t),q$.forEach(t),FGe=i(f),In=n(f,"P",{});var wf=s(In);Nze=r(wf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ate=n(wf,"CODE",{});var Mwe=s(ate);qze=r(Mwe,"NewModel"),Mwe.forEach(t),jze=r(wf,", make sure you have a "),nte=n(wf,"CODE",{});var Ewe=s(nte);Dze=r(Ewe,"NewModelConfig"),Ewe.forEach(t),Gze=r(wf,` then you can add those to the auto
classes like this:`),wf.forEach(t),TGe=i(f),T(wL.$$.fragment,f),MGe=i(f),rS=n(f,"P",{});var Cwe=s(rS);Oze=r(Cwe,"You will then be able to use the auto classes like you would usually do!"),Cwe.forEach(t),EGe=i(f),T(Rf.$$.fragment,f),CGe=i(f),xi=n(f,"H2",{class:!0});var j$=s(xi);Pf=n(j$,"A",{id:!0,class:!0,href:!0});var wwe=s(Pf);ste=n(wwe,"SPAN",{});var Awe=s(ste);T(AL.$$.fragment,Awe),Awe.forEach(t),wwe.forEach(t),Vze=i(j$),lte=n(j$,"SPAN",{});var Lwe=s(lte);Xze=r(Lwe,"AutoConfig"),Lwe.forEach(t),j$.forEach(t),wGe=i(f),wo=n(f,"DIV",{class:!0});var rt=s(wo);T(LL.$$.fragment,rt),zze=i(rt),yL=n(rt,"P",{});var D$=s(yL);Wze=r(D$,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),tS=n(D$,"A",{href:!0});var ywe=s(tS);Qze=r(ywe,"from_pretrained()"),ywe.forEach(t),Hze=r(D$," class method."),D$.forEach(t),Uze=i(rt),xL=n(rt,"P",{});var G$=s(xL);Jze=r(G$,"This class cannot be instantiated directly using "),ite=n(G$,"CODE",{});var xwe=s(ite);Yze=r(xwe,"__init__()"),xwe.forEach(t),Kze=r(G$," (throws an error)."),G$.forEach(t),Zze=i(rt),wr=n(rt,"DIV",{class:!0});var tt=s(wr);T($L.$$.fragment,tt),eWe=i(tt),dte=n(tt,"P",{});var $we=s(dte);oWe=r($we,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),$we.forEach(t),rWe=i(tt),$i=n(tt,"P",{});var Af=s($i);tWe=r(Af,"The configuration class to instantiate is selected based on the "),cte=n(Af,"CODE",{});var kwe=s(cte);aWe=r(kwe,"model_type"),kwe.forEach(t),nWe=r(Af,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),fte=n(Af,"CODE",{});var Swe=s(fte);sWe=r(Swe,"pretrained_model_name_or_path"),Swe.forEach(t),lWe=r(Af,":"),Af.forEach(t),iWe=i(tt),A=n(tt,"UL",{});var L=s(A);Bf=n(L,"LI",{});var eA=s(Bf);mte=n(eA,"STRONG",{});var Rwe=s(mte);dWe=r(Rwe,"albert"),Rwe.forEach(t),cWe=r(eA," \u2014 "),aS=n(eA,"A",{href:!0});var Pwe=s(aS);fWe=r(Pwe,"AlbertConfig"),Pwe.forEach(t),mWe=r(eA," (ALBERT model)"),eA.forEach(t),gWe=i(L),If=n(L,"LI",{});var oA=s(If);gte=n(oA,"STRONG",{});var Bwe=s(gte);hWe=r(Bwe,"bart"),Bwe.forEach(t),pWe=r(oA," \u2014 "),nS=n(oA,"A",{href:!0});var Iwe=s(nS);uWe=r(Iwe,"BartConfig"),Iwe.forEach(t),_We=r(oA," (BART model)"),oA.forEach(t),bWe=i(L),Nf=n(L,"LI",{});var rA=s(Nf);hte=n(rA,"STRONG",{});var Nwe=s(hte);vWe=r(Nwe,"beit"),Nwe.forEach(t),FWe=r(rA," \u2014 "),sS=n(rA,"A",{href:!0});var qwe=s(sS);TWe=r(qwe,"BeitConfig"),qwe.forEach(t),MWe=r(rA," (BEiT model)"),rA.forEach(t),EWe=i(L),qf=n(L,"LI",{});var tA=s(qf);pte=n(tA,"STRONG",{});var jwe=s(pte);CWe=r(jwe,"bert"),jwe.forEach(t),wWe=r(tA," \u2014 "),lS=n(tA,"A",{href:!0});var Dwe=s(lS);AWe=r(Dwe,"BertConfig"),Dwe.forEach(t),LWe=r(tA," (BERT model)"),tA.forEach(t),yWe=i(L),jf=n(L,"LI",{});var aA=s(jf);ute=n(aA,"STRONG",{});var Gwe=s(ute);xWe=r(Gwe,"bert-generation"),Gwe.forEach(t),$We=r(aA," \u2014 "),iS=n(aA,"A",{href:!0});var Owe=s(iS);kWe=r(Owe,"BertGenerationConfig"),Owe.forEach(t),SWe=r(aA," (Bert Generation model)"),aA.forEach(t),RWe=i(L),Df=n(L,"LI",{});var nA=s(Df);_te=n(nA,"STRONG",{});var Vwe=s(_te);PWe=r(Vwe,"big_bird"),Vwe.forEach(t),BWe=r(nA," \u2014 "),dS=n(nA,"A",{href:!0});var Xwe=s(dS);IWe=r(Xwe,"BigBirdConfig"),Xwe.forEach(t),NWe=r(nA," (BigBird model)"),nA.forEach(t),qWe=i(L),Gf=n(L,"LI",{});var sA=s(Gf);bte=n(sA,"STRONG",{});var zwe=s(bte);jWe=r(zwe,"bigbird_pegasus"),zwe.forEach(t),DWe=r(sA," \u2014 "),cS=n(sA,"A",{href:!0});var Wwe=s(cS);GWe=r(Wwe,"BigBirdPegasusConfig"),Wwe.forEach(t),OWe=r(sA," (BigBird-Pegasus model)"),sA.forEach(t),VWe=i(L),Of=n(L,"LI",{});var lA=s(Of);vte=n(lA,"STRONG",{});var Qwe=s(vte);XWe=r(Qwe,"blenderbot"),Qwe.forEach(t),zWe=r(lA," \u2014 "),fS=n(lA,"A",{href:!0});var Hwe=s(fS);WWe=r(Hwe,"BlenderbotConfig"),Hwe.forEach(t),QWe=r(lA," (Blenderbot model)"),lA.forEach(t),HWe=i(L),Vf=n(L,"LI",{});var iA=s(Vf);Fte=n(iA,"STRONG",{});var Uwe=s(Fte);UWe=r(Uwe,"blenderbot-small"),Uwe.forEach(t),JWe=r(iA," \u2014 "),mS=n(iA,"A",{href:!0});var Jwe=s(mS);YWe=r(Jwe,"BlenderbotSmallConfig"),Jwe.forEach(t),KWe=r(iA," (BlenderbotSmall model)"),iA.forEach(t),ZWe=i(L),Xf=n(L,"LI",{});var dA=s(Xf);Tte=n(dA,"STRONG",{});var Ywe=s(Tte);eQe=r(Ywe,"bloom"),Ywe.forEach(t),oQe=r(dA," \u2014 "),gS=n(dA,"A",{href:!0});var Kwe=s(gS);rQe=r(Kwe,"BloomConfig"),Kwe.forEach(t),tQe=r(dA," (BLOOM model)"),dA.forEach(t),aQe=i(L),zf=n(L,"LI",{});var cA=s(zf);Mte=n(cA,"STRONG",{});var Zwe=s(Mte);nQe=r(Zwe,"camembert"),Zwe.forEach(t),sQe=r(cA," \u2014 "),hS=n(cA,"A",{href:!0});var eAe=s(hS);lQe=r(eAe,"CamembertConfig"),eAe.forEach(t),iQe=r(cA," (CamemBERT model)"),cA.forEach(t),dQe=i(L),Wf=n(L,"LI",{});var fA=s(Wf);Ete=n(fA,"STRONG",{});var oAe=s(Ete);cQe=r(oAe,"canine"),oAe.forEach(t),fQe=r(fA," \u2014 "),pS=n(fA,"A",{href:!0});var rAe=s(pS);mQe=r(rAe,"CanineConfig"),rAe.forEach(t),gQe=r(fA," (CANINE model)"),fA.forEach(t),hQe=i(L),Qf=n(L,"LI",{});var mA=s(Qf);Cte=n(mA,"STRONG",{});var tAe=s(Cte);pQe=r(tAe,"clip"),tAe.forEach(t),uQe=r(mA," \u2014 "),uS=n(mA,"A",{href:!0});var aAe=s(uS);_Qe=r(aAe,"CLIPConfig"),aAe.forEach(t),bQe=r(mA," (CLIP model)"),mA.forEach(t),vQe=i(L),Hf=n(L,"LI",{});var gA=s(Hf);wte=n(gA,"STRONG",{});var nAe=s(wte);FQe=r(nAe,"convbert"),nAe.forEach(t),TQe=r(gA," \u2014 "),_S=n(gA,"A",{href:!0});var sAe=s(_S);MQe=r(sAe,"ConvBertConfig"),sAe.forEach(t),EQe=r(gA," (ConvBERT model)"),gA.forEach(t),CQe=i(L),Uf=n(L,"LI",{});var hA=s(Uf);Ate=n(hA,"STRONG",{});var lAe=s(Ate);wQe=r(lAe,"convnext"),lAe.forEach(t),AQe=r(hA," \u2014 "),bS=n(hA,"A",{href:!0});var iAe=s(bS);LQe=r(iAe,"ConvNextConfig"),iAe.forEach(t),yQe=r(hA," (ConvNeXT model)"),hA.forEach(t),xQe=i(L),Jf=n(L,"LI",{});var pA=s(Jf);Lte=n(pA,"STRONG",{});var dAe=s(Lte);$Qe=r(dAe,"ctrl"),dAe.forEach(t),kQe=r(pA," \u2014 "),vS=n(pA,"A",{href:!0});var cAe=s(vS);SQe=r(cAe,"CTRLConfig"),cAe.forEach(t),RQe=r(pA," (CTRL model)"),pA.forEach(t),PQe=i(L),Yf=n(L,"LI",{});var uA=s(Yf);yte=n(uA,"STRONG",{});var fAe=s(yte);BQe=r(fAe,"cvt"),fAe.forEach(t),IQe=r(uA," \u2014 "),FS=n(uA,"A",{href:!0});var mAe=s(FS);NQe=r(mAe,"CvtConfig"),mAe.forEach(t),qQe=r(uA," (CvT model)"),uA.forEach(t),jQe=i(L),Kf=n(L,"LI",{});var _A=s(Kf);xte=n(_A,"STRONG",{});var gAe=s(xte);DQe=r(gAe,"data2vec-audio"),gAe.forEach(t),GQe=r(_A," \u2014 "),TS=n(_A,"A",{href:!0});var hAe=s(TS);OQe=r(hAe,"Data2VecAudioConfig"),hAe.forEach(t),VQe=r(_A," (Data2VecAudio model)"),_A.forEach(t),XQe=i(L),Zf=n(L,"LI",{});var bA=s(Zf);$te=n(bA,"STRONG",{});var pAe=s($te);zQe=r(pAe,"data2vec-text"),pAe.forEach(t),WQe=r(bA," \u2014 "),MS=n(bA,"A",{href:!0});var uAe=s(MS);QQe=r(uAe,"Data2VecTextConfig"),uAe.forEach(t),HQe=r(bA," (Data2VecText model)"),bA.forEach(t),UQe=i(L),em=n(L,"LI",{});var vA=s(em);kte=n(vA,"STRONG",{});var _Ae=s(kte);JQe=r(_Ae,"data2vec-vision"),_Ae.forEach(t),YQe=r(vA," \u2014 "),ES=n(vA,"A",{href:!0});var bAe=s(ES);KQe=r(bAe,"Data2VecVisionConfig"),bAe.forEach(t),ZQe=r(vA," (Data2VecVision model)"),vA.forEach(t),eHe=i(L),om=n(L,"LI",{});var FA=s(om);Ste=n(FA,"STRONG",{});var vAe=s(Ste);oHe=r(vAe,"deberta"),vAe.forEach(t),rHe=r(FA," \u2014 "),CS=n(FA,"A",{href:!0});var FAe=s(CS);tHe=r(FAe,"DebertaConfig"),FAe.forEach(t),aHe=r(FA," (DeBERTa model)"),FA.forEach(t),nHe=i(L),rm=n(L,"LI",{});var TA=s(rm);Rte=n(TA,"STRONG",{});var TAe=s(Rte);sHe=r(TAe,"deberta-v2"),TAe.forEach(t),lHe=r(TA," \u2014 "),wS=n(TA,"A",{href:!0});var MAe=s(wS);iHe=r(MAe,"DebertaV2Config"),MAe.forEach(t),dHe=r(TA," (DeBERTa-v2 model)"),TA.forEach(t),cHe=i(L),tm=n(L,"LI",{});var MA=s(tm);Pte=n(MA,"STRONG",{});var EAe=s(Pte);fHe=r(EAe,"decision_transformer"),EAe.forEach(t),mHe=r(MA," \u2014 "),AS=n(MA,"A",{href:!0});var CAe=s(AS);gHe=r(CAe,"DecisionTransformerConfig"),CAe.forEach(t),hHe=r(MA," (Decision Transformer model)"),MA.forEach(t),pHe=i(L),am=n(L,"LI",{});var EA=s(am);Bte=n(EA,"STRONG",{});var iYr=s(Bte);uHe=r(iYr,"deit"),iYr.forEach(t),_He=r(EA," \u2014 "),LS=n(EA,"A",{href:!0});var dYr=s(LS);bHe=r(dYr,"DeiTConfig"),dYr.forEach(t),vHe=r(EA," (DeiT model)"),EA.forEach(t),FHe=i(L),nm=n(L,"LI",{});var wAe=s(nm);Ite=n(wAe,"STRONG",{});var cYr=s(Ite);THe=r(cYr,"detr"),cYr.forEach(t),MHe=r(wAe," \u2014 "),yS=n(wAe,"A",{href:!0});var fYr=s(yS);EHe=r(fYr,"DetrConfig"),fYr.forEach(t),CHe=r(wAe," (DETR model)"),wAe.forEach(t),wHe=i(L),sm=n(L,"LI",{});var AAe=s(sm);Nte=n(AAe,"STRONG",{});var mYr=s(Nte);AHe=r(mYr,"distilbert"),mYr.forEach(t),LHe=r(AAe," \u2014 "),xS=n(AAe,"A",{href:!0});var gYr=s(xS);yHe=r(gYr,"DistilBertConfig"),gYr.forEach(t),xHe=r(AAe," (DistilBERT model)"),AAe.forEach(t),$He=i(L),lm=n(L,"LI",{});var LAe=s(lm);qte=n(LAe,"STRONG",{});var hYr=s(qte);kHe=r(hYr,"dpr"),hYr.forEach(t),SHe=r(LAe," \u2014 "),$S=n(LAe,"A",{href:!0});var pYr=s($S);RHe=r(pYr,"DPRConfig"),pYr.forEach(t),PHe=r(LAe," (DPR model)"),LAe.forEach(t),BHe=i(L),im=n(L,"LI",{});var yAe=s(im);jte=n(yAe,"STRONG",{});var uYr=s(jte);IHe=r(uYr,"dpt"),uYr.forEach(t),NHe=r(yAe," \u2014 "),kS=n(yAe,"A",{href:!0});var _Yr=s(kS);qHe=r(_Yr,"DPTConfig"),_Yr.forEach(t),jHe=r(yAe," (DPT model)"),yAe.forEach(t),DHe=i(L),dm=n(L,"LI",{});var xAe=s(dm);Dte=n(xAe,"STRONG",{});var bYr=s(Dte);GHe=r(bYr,"electra"),bYr.forEach(t),OHe=r(xAe," \u2014 "),SS=n(xAe,"A",{href:!0});var vYr=s(SS);VHe=r(vYr,"ElectraConfig"),vYr.forEach(t),XHe=r(xAe," (ELECTRA model)"),xAe.forEach(t),zHe=i(L),cm=n(L,"LI",{});var $Ae=s(cm);Gte=n($Ae,"STRONG",{});var FYr=s(Gte);WHe=r(FYr,"encoder-decoder"),FYr.forEach(t),QHe=r($Ae," \u2014 "),RS=n($Ae,"A",{href:!0});var TYr=s(RS);HHe=r(TYr,"EncoderDecoderConfig"),TYr.forEach(t),UHe=r($Ae," (Encoder decoder model)"),$Ae.forEach(t),JHe=i(L),fm=n(L,"LI",{});var kAe=s(fm);Ote=n(kAe,"STRONG",{});var MYr=s(Ote);YHe=r(MYr,"flaubert"),MYr.forEach(t),KHe=r(kAe," \u2014 "),PS=n(kAe,"A",{href:!0});var EYr=s(PS);ZHe=r(EYr,"FlaubertConfig"),EYr.forEach(t),eUe=r(kAe," (FlauBERT model)"),kAe.forEach(t),oUe=i(L),mm=n(L,"LI",{});var SAe=s(mm);Vte=n(SAe,"STRONG",{});var CYr=s(Vte);rUe=r(CYr,"flava"),CYr.forEach(t),tUe=r(SAe," \u2014 "),BS=n(SAe,"A",{href:!0});var wYr=s(BS);aUe=r(wYr,"FlavaConfig"),wYr.forEach(t),nUe=r(SAe," (FLAVA model)"),SAe.forEach(t),sUe=i(L),gm=n(L,"LI",{});var RAe=s(gm);Xte=n(RAe,"STRONG",{});var AYr=s(Xte);lUe=r(AYr,"fnet"),AYr.forEach(t),iUe=r(RAe," \u2014 "),IS=n(RAe,"A",{href:!0});var LYr=s(IS);dUe=r(LYr,"FNetConfig"),LYr.forEach(t),cUe=r(RAe," (FNet model)"),RAe.forEach(t),fUe=i(L),hm=n(L,"LI",{});var PAe=s(hm);zte=n(PAe,"STRONG",{});var yYr=s(zte);mUe=r(yYr,"fsmt"),yYr.forEach(t),gUe=r(PAe," \u2014 "),NS=n(PAe,"A",{href:!0});var xYr=s(NS);hUe=r(xYr,"FSMTConfig"),xYr.forEach(t),pUe=r(PAe," (FairSeq Machine-Translation model)"),PAe.forEach(t),uUe=i(L),pm=n(L,"LI",{});var BAe=s(pm);Wte=n(BAe,"STRONG",{});var $Yr=s(Wte);_Ue=r($Yr,"funnel"),$Yr.forEach(t),bUe=r(BAe," \u2014 "),qS=n(BAe,"A",{href:!0});var kYr=s(qS);vUe=r(kYr,"FunnelConfig"),kYr.forEach(t),FUe=r(BAe," (Funnel Transformer model)"),BAe.forEach(t),TUe=i(L),um=n(L,"LI",{});var IAe=s(um);Qte=n(IAe,"STRONG",{});var SYr=s(Qte);MUe=r(SYr,"glpn"),SYr.forEach(t),EUe=r(IAe," \u2014 "),jS=n(IAe,"A",{href:!0});var RYr=s(jS);CUe=r(RYr,"GLPNConfig"),RYr.forEach(t),wUe=r(IAe," (GLPN model)"),IAe.forEach(t),AUe=i(L),_m=n(L,"LI",{});var NAe=s(_m);Hte=n(NAe,"STRONG",{});var PYr=s(Hte);LUe=r(PYr,"gpt2"),PYr.forEach(t),yUe=r(NAe," \u2014 "),DS=n(NAe,"A",{href:!0});var BYr=s(DS);xUe=r(BYr,"GPT2Config"),BYr.forEach(t),$Ue=r(NAe," (OpenAI GPT-2 model)"),NAe.forEach(t),kUe=i(L),bm=n(L,"LI",{});var qAe=s(bm);Ute=n(qAe,"STRONG",{});var IYr=s(Ute);SUe=r(IYr,"gpt_neo"),IYr.forEach(t),RUe=r(qAe," \u2014 "),GS=n(qAe,"A",{href:!0});var NYr=s(GS);PUe=r(NYr,"GPTNeoConfig"),NYr.forEach(t),BUe=r(qAe," (GPT Neo model)"),qAe.forEach(t),IUe=i(L),vm=n(L,"LI",{});var jAe=s(vm);Jte=n(jAe,"STRONG",{});var qYr=s(Jte);NUe=r(qYr,"gpt_neox"),qYr.forEach(t),qUe=r(jAe," \u2014 "),OS=n(jAe,"A",{href:!0});var jYr=s(OS);jUe=r(jYr,"GPTNeoXConfig"),jYr.forEach(t),DUe=r(jAe," (GPT NeoX model)"),jAe.forEach(t),GUe=i(L),Fm=n(L,"LI",{});var DAe=s(Fm);Yte=n(DAe,"STRONG",{});var DYr=s(Yte);OUe=r(DYr,"gptj"),DYr.forEach(t),VUe=r(DAe," \u2014 "),VS=n(DAe,"A",{href:!0});var GYr=s(VS);XUe=r(GYr,"GPTJConfig"),GYr.forEach(t),zUe=r(DAe," (GPT-J model)"),DAe.forEach(t),WUe=i(L),Tm=n(L,"LI",{});var GAe=s(Tm);Kte=n(GAe,"STRONG",{});var OYr=s(Kte);QUe=r(OYr,"groupvit"),OYr.forEach(t),HUe=r(GAe," \u2014 "),XS=n(GAe,"A",{href:!0});var VYr=s(XS);UUe=r(VYr,"GroupViTConfig"),VYr.forEach(t),JUe=r(GAe," (GroupViT model)"),GAe.forEach(t),YUe=i(L),Mm=n(L,"LI",{});var OAe=s(Mm);Zte=n(OAe,"STRONG",{});var XYr=s(Zte);KUe=r(XYr,"hubert"),XYr.forEach(t),ZUe=r(OAe," \u2014 "),zS=n(OAe,"A",{href:!0});var zYr=s(zS);eJe=r(zYr,"HubertConfig"),zYr.forEach(t),oJe=r(OAe," (Hubert model)"),OAe.forEach(t),rJe=i(L),Em=n(L,"LI",{});var VAe=s(Em);eae=n(VAe,"STRONG",{});var WYr=s(eae);tJe=r(WYr,"ibert"),WYr.forEach(t),aJe=r(VAe," \u2014 "),WS=n(VAe,"A",{href:!0});var QYr=s(WS);nJe=r(QYr,"IBertConfig"),QYr.forEach(t),sJe=r(VAe," (I-BERT model)"),VAe.forEach(t),lJe=i(L),Cm=n(L,"LI",{});var XAe=s(Cm);oae=n(XAe,"STRONG",{});var HYr=s(oae);iJe=r(HYr,"imagegpt"),HYr.forEach(t),dJe=r(XAe," \u2014 "),QS=n(XAe,"A",{href:!0});var UYr=s(QS);cJe=r(UYr,"ImageGPTConfig"),UYr.forEach(t),fJe=r(XAe," (ImageGPT model)"),XAe.forEach(t),mJe=i(L),wm=n(L,"LI",{});var zAe=s(wm);rae=n(zAe,"STRONG",{});var JYr=s(rae);gJe=r(JYr,"layoutlm"),JYr.forEach(t),hJe=r(zAe," \u2014 "),HS=n(zAe,"A",{href:!0});var YYr=s(HS);pJe=r(YYr,"LayoutLMConfig"),YYr.forEach(t),uJe=r(zAe," (LayoutLM model)"),zAe.forEach(t),_Je=i(L),Am=n(L,"LI",{});var WAe=s(Am);tae=n(WAe,"STRONG",{});var KYr=s(tae);bJe=r(KYr,"layoutlmv2"),KYr.forEach(t),vJe=r(WAe," \u2014 "),US=n(WAe,"A",{href:!0});var ZYr=s(US);FJe=r(ZYr,"LayoutLMv2Config"),ZYr.forEach(t),TJe=r(WAe," (LayoutLMv2 model)"),WAe.forEach(t),MJe=i(L),Lm=n(L,"LI",{});var QAe=s(Lm);aae=n(QAe,"STRONG",{});var eKr=s(aae);EJe=r(eKr,"layoutlmv3"),eKr.forEach(t),CJe=r(QAe," \u2014 "),JS=n(QAe,"A",{href:!0});var oKr=s(JS);wJe=r(oKr,"LayoutLMv3Config"),oKr.forEach(t),AJe=r(QAe," (LayoutLMv3 model)"),QAe.forEach(t),LJe=i(L),ym=n(L,"LI",{});var HAe=s(ym);nae=n(HAe,"STRONG",{});var rKr=s(nae);yJe=r(rKr,"led"),rKr.forEach(t),xJe=r(HAe," \u2014 "),YS=n(HAe,"A",{href:!0});var tKr=s(YS);$Je=r(tKr,"LEDConfig"),tKr.forEach(t),kJe=r(HAe," (LED model)"),HAe.forEach(t),SJe=i(L),xm=n(L,"LI",{});var UAe=s(xm);sae=n(UAe,"STRONG",{});var aKr=s(sae);RJe=r(aKr,"levit"),aKr.forEach(t),PJe=r(UAe," \u2014 "),KS=n(UAe,"A",{href:!0});var nKr=s(KS);BJe=r(nKr,"LevitConfig"),nKr.forEach(t),IJe=r(UAe," (LeViT model)"),UAe.forEach(t),NJe=i(L),$m=n(L,"LI",{});var JAe=s($m);lae=n(JAe,"STRONG",{});var sKr=s(lae);qJe=r(sKr,"longformer"),sKr.forEach(t),jJe=r(JAe," \u2014 "),ZS=n(JAe,"A",{href:!0});var lKr=s(ZS);DJe=r(lKr,"LongformerConfig"),lKr.forEach(t),GJe=r(JAe," (Longformer model)"),JAe.forEach(t),OJe=i(L),km=n(L,"LI",{});var YAe=s(km);iae=n(YAe,"STRONG",{});var iKr=s(iae);VJe=r(iKr,"longt5"),iKr.forEach(t),XJe=r(YAe," \u2014 "),eR=n(YAe,"A",{href:!0});var dKr=s(eR);zJe=r(dKr,"LongT5Config"),dKr.forEach(t),WJe=r(YAe," (LongT5 model)"),YAe.forEach(t),QJe=i(L),Sm=n(L,"LI",{});var KAe=s(Sm);dae=n(KAe,"STRONG",{});var cKr=s(dae);HJe=r(cKr,"luke"),cKr.forEach(t),UJe=r(KAe," \u2014 "),oR=n(KAe,"A",{href:!0});var fKr=s(oR);JJe=r(fKr,"LukeConfig"),fKr.forEach(t),YJe=r(KAe," (LUKE model)"),KAe.forEach(t),KJe=i(L),Rm=n(L,"LI",{});var ZAe=s(Rm);cae=n(ZAe,"STRONG",{});var mKr=s(cae);ZJe=r(mKr,"lxmert"),mKr.forEach(t),eYe=r(ZAe," \u2014 "),rR=n(ZAe,"A",{href:!0});var gKr=s(rR);oYe=r(gKr,"LxmertConfig"),gKr.forEach(t),rYe=r(ZAe," (LXMERT model)"),ZAe.forEach(t),tYe=i(L),Pm=n(L,"LI",{});var e6e=s(Pm);fae=n(e6e,"STRONG",{});var hKr=s(fae);aYe=r(hKr,"m2m_100"),hKr.forEach(t),nYe=r(e6e," \u2014 "),tR=n(e6e,"A",{href:!0});var pKr=s(tR);sYe=r(pKr,"M2M100Config"),pKr.forEach(t),lYe=r(e6e," (M2M100 model)"),e6e.forEach(t),iYe=i(L),Bm=n(L,"LI",{});var o6e=s(Bm);mae=n(o6e,"STRONG",{});var uKr=s(mae);dYe=r(uKr,"marian"),uKr.forEach(t),cYe=r(o6e," \u2014 "),aR=n(o6e,"A",{href:!0});var _Kr=s(aR);fYe=r(_Kr,"MarianConfig"),_Kr.forEach(t),mYe=r(o6e," (Marian model)"),o6e.forEach(t),gYe=i(L),Im=n(L,"LI",{});var r6e=s(Im);gae=n(r6e,"STRONG",{});var bKr=s(gae);hYe=r(bKr,"maskformer"),bKr.forEach(t),pYe=r(r6e," \u2014 "),nR=n(r6e,"A",{href:!0});var vKr=s(nR);uYe=r(vKr,"MaskFormerConfig"),vKr.forEach(t),_Ye=r(r6e," (MaskFormer model)"),r6e.forEach(t),bYe=i(L),Nm=n(L,"LI",{});var t6e=s(Nm);hae=n(t6e,"STRONG",{});var FKr=s(hae);vYe=r(FKr,"mbart"),FKr.forEach(t),FYe=r(t6e," \u2014 "),sR=n(t6e,"A",{href:!0});var TKr=s(sR);TYe=r(TKr,"MBartConfig"),TKr.forEach(t),MYe=r(t6e," (mBART model)"),t6e.forEach(t),EYe=i(L),qm=n(L,"LI",{});var a6e=s(qm);pae=n(a6e,"STRONG",{});var MKr=s(pae);CYe=r(MKr,"mctct"),MKr.forEach(t),wYe=r(a6e," \u2014 "),lR=n(a6e,"A",{href:!0});var EKr=s(lR);AYe=r(EKr,"MCTCTConfig"),EKr.forEach(t),LYe=r(a6e," (M-CTC-T model)"),a6e.forEach(t),yYe=i(L),jm=n(L,"LI",{});var n6e=s(jm);uae=n(n6e,"STRONG",{});var CKr=s(uae);xYe=r(CKr,"megatron-bert"),CKr.forEach(t),$Ye=r(n6e," \u2014 "),iR=n(n6e,"A",{href:!0});var wKr=s(iR);kYe=r(wKr,"MegatronBertConfig"),wKr.forEach(t),SYe=r(n6e," (Megatron-BERT model)"),n6e.forEach(t),RYe=i(L),Dm=n(L,"LI",{});var s6e=s(Dm);_ae=n(s6e,"STRONG",{});var AKr=s(_ae);PYe=r(AKr,"mobilebert"),AKr.forEach(t),BYe=r(s6e," \u2014 "),dR=n(s6e,"A",{href:!0});var LKr=s(dR);IYe=r(LKr,"MobileBertConfig"),LKr.forEach(t),NYe=r(s6e," (MobileBERT model)"),s6e.forEach(t),qYe=i(L),Gm=n(L,"LI",{});var l6e=s(Gm);bae=n(l6e,"STRONG",{});var yKr=s(bae);jYe=r(yKr,"mpnet"),yKr.forEach(t),DYe=r(l6e," \u2014 "),cR=n(l6e,"A",{href:!0});var xKr=s(cR);GYe=r(xKr,"MPNetConfig"),xKr.forEach(t),OYe=r(l6e," (MPNet model)"),l6e.forEach(t),VYe=i(L),Om=n(L,"LI",{});var i6e=s(Om);vae=n(i6e,"STRONG",{});var $Kr=s(vae);XYe=r($Kr,"mt5"),$Kr.forEach(t),zYe=r(i6e," \u2014 "),fR=n(i6e,"A",{href:!0});var kKr=s(fR);WYe=r(kKr,"MT5Config"),kKr.forEach(t),QYe=r(i6e," (MT5 model)"),i6e.forEach(t),HYe=i(L),Vm=n(L,"LI",{});var d6e=s(Vm);Fae=n(d6e,"STRONG",{});var SKr=s(Fae);UYe=r(SKr,"nystromformer"),SKr.forEach(t),JYe=r(d6e," \u2014 "),mR=n(d6e,"A",{href:!0});var RKr=s(mR);YYe=r(RKr,"NystromformerConfig"),RKr.forEach(t),KYe=r(d6e," (Nystr\xF6mformer model)"),d6e.forEach(t),ZYe=i(L),Xm=n(L,"LI",{});var c6e=s(Xm);Tae=n(c6e,"STRONG",{});var PKr=s(Tae);eKe=r(PKr,"openai-gpt"),PKr.forEach(t),oKe=r(c6e," \u2014 "),gR=n(c6e,"A",{href:!0});var BKr=s(gR);rKe=r(BKr,"OpenAIGPTConfig"),BKr.forEach(t),tKe=r(c6e," (OpenAI GPT model)"),c6e.forEach(t),aKe=i(L),zm=n(L,"LI",{});var f6e=s(zm);Mae=n(f6e,"STRONG",{});var IKr=s(Mae);nKe=r(IKr,"opt"),IKr.forEach(t),sKe=r(f6e," \u2014 "),hR=n(f6e,"A",{href:!0});var NKr=s(hR);lKe=r(NKr,"OPTConfig"),NKr.forEach(t),iKe=r(f6e," (OPT model)"),f6e.forEach(t),dKe=i(L),Wm=n(L,"LI",{});var m6e=s(Wm);Eae=n(m6e,"STRONG",{});var qKr=s(Eae);cKe=r(qKr,"pegasus"),qKr.forEach(t),fKe=r(m6e," \u2014 "),pR=n(m6e,"A",{href:!0});var jKr=s(pR);mKe=r(jKr,"PegasusConfig"),jKr.forEach(t),gKe=r(m6e," (Pegasus model)"),m6e.forEach(t),hKe=i(L),Qm=n(L,"LI",{});var g6e=s(Qm);Cae=n(g6e,"STRONG",{});var DKr=s(Cae);pKe=r(DKr,"perceiver"),DKr.forEach(t),uKe=r(g6e," \u2014 "),uR=n(g6e,"A",{href:!0});var GKr=s(uR);_Ke=r(GKr,"PerceiverConfig"),GKr.forEach(t),bKe=r(g6e," (Perceiver model)"),g6e.forEach(t),vKe=i(L),Hm=n(L,"LI",{});var h6e=s(Hm);wae=n(h6e,"STRONG",{});var OKr=s(wae);FKe=r(OKr,"plbart"),OKr.forEach(t),TKe=r(h6e," \u2014 "),_R=n(h6e,"A",{href:!0});var VKr=s(_R);MKe=r(VKr,"PLBartConfig"),VKr.forEach(t),EKe=r(h6e," (PLBart model)"),h6e.forEach(t),CKe=i(L),Um=n(L,"LI",{});var p6e=s(Um);Aae=n(p6e,"STRONG",{});var XKr=s(Aae);wKe=r(XKr,"poolformer"),XKr.forEach(t),AKe=r(p6e," \u2014 "),bR=n(p6e,"A",{href:!0});var zKr=s(bR);LKe=r(zKr,"PoolFormerConfig"),zKr.forEach(t),yKe=r(p6e," (PoolFormer model)"),p6e.forEach(t),xKe=i(L),Jm=n(L,"LI",{});var u6e=s(Jm);Lae=n(u6e,"STRONG",{});var WKr=s(Lae);$Ke=r(WKr,"prophetnet"),WKr.forEach(t),kKe=r(u6e," \u2014 "),vR=n(u6e,"A",{href:!0});var QKr=s(vR);SKe=r(QKr,"ProphetNetConfig"),QKr.forEach(t),RKe=r(u6e," (ProphetNet model)"),u6e.forEach(t),PKe=i(L),Ym=n(L,"LI",{});var _6e=s(Ym);yae=n(_6e,"STRONG",{});var HKr=s(yae);BKe=r(HKr,"qdqbert"),HKr.forEach(t),IKe=r(_6e," \u2014 "),FR=n(_6e,"A",{href:!0});var UKr=s(FR);NKe=r(UKr,"QDQBertConfig"),UKr.forEach(t),qKe=r(_6e," (QDQBert model)"),_6e.forEach(t),jKe=i(L),Km=n(L,"LI",{});var b6e=s(Km);xae=n(b6e,"STRONG",{});var JKr=s(xae);DKe=r(JKr,"rag"),JKr.forEach(t),GKe=r(b6e," \u2014 "),TR=n(b6e,"A",{href:!0});var YKr=s(TR);OKe=r(YKr,"RagConfig"),YKr.forEach(t),VKe=r(b6e," (RAG model)"),b6e.forEach(t),XKe=i(L),Zm=n(L,"LI",{});var v6e=s(Zm);$ae=n(v6e,"STRONG",{});var KKr=s($ae);zKe=r(KKr,"realm"),KKr.forEach(t),WKe=r(v6e," \u2014 "),MR=n(v6e,"A",{href:!0});var ZKr=s(MR);QKe=r(ZKr,"RealmConfig"),ZKr.forEach(t),HKe=r(v6e," (REALM model)"),v6e.forEach(t),UKe=i(L),eg=n(L,"LI",{});var F6e=s(eg);kae=n(F6e,"STRONG",{});var eZr=s(kae);JKe=r(eZr,"reformer"),eZr.forEach(t),YKe=r(F6e," \u2014 "),ER=n(F6e,"A",{href:!0});var oZr=s(ER);KKe=r(oZr,"ReformerConfig"),oZr.forEach(t),ZKe=r(F6e," (Reformer model)"),F6e.forEach(t),eZe=i(L),og=n(L,"LI",{});var T6e=s(og);Sae=n(T6e,"STRONG",{});var rZr=s(Sae);oZe=r(rZr,"regnet"),rZr.forEach(t),rZe=r(T6e," \u2014 "),CR=n(T6e,"A",{href:!0});var tZr=s(CR);tZe=r(tZr,"RegNetConfig"),tZr.forEach(t),aZe=r(T6e," (RegNet model)"),T6e.forEach(t),nZe=i(L),rg=n(L,"LI",{});var M6e=s(rg);Rae=n(M6e,"STRONG",{});var aZr=s(Rae);sZe=r(aZr,"rembert"),aZr.forEach(t),lZe=r(M6e," \u2014 "),wR=n(M6e,"A",{href:!0});var nZr=s(wR);iZe=r(nZr,"RemBertConfig"),nZr.forEach(t),dZe=r(M6e," (RemBERT model)"),M6e.forEach(t),cZe=i(L),tg=n(L,"LI",{});var E6e=s(tg);Pae=n(E6e,"STRONG",{});var sZr=s(Pae);fZe=r(sZr,"resnet"),sZr.forEach(t),mZe=r(E6e," \u2014 "),AR=n(E6e,"A",{href:!0});var lZr=s(AR);gZe=r(lZr,"ResNetConfig"),lZr.forEach(t),hZe=r(E6e," (ResNet model)"),E6e.forEach(t),pZe=i(L),ag=n(L,"LI",{});var C6e=s(ag);Bae=n(C6e,"STRONG",{});var iZr=s(Bae);uZe=r(iZr,"retribert"),iZr.forEach(t),_Ze=r(C6e," \u2014 "),LR=n(C6e,"A",{href:!0});var dZr=s(LR);bZe=r(dZr,"RetriBertConfig"),dZr.forEach(t),vZe=r(C6e," (RetriBERT model)"),C6e.forEach(t),FZe=i(L),ng=n(L,"LI",{});var w6e=s(ng);Iae=n(w6e,"STRONG",{});var cZr=s(Iae);TZe=r(cZr,"roberta"),cZr.forEach(t),MZe=r(w6e," \u2014 "),yR=n(w6e,"A",{href:!0});var fZr=s(yR);EZe=r(fZr,"RobertaConfig"),fZr.forEach(t),CZe=r(w6e," (RoBERTa model)"),w6e.forEach(t),wZe=i(L),sg=n(L,"LI",{});var A6e=s(sg);Nae=n(A6e,"STRONG",{});var mZr=s(Nae);AZe=r(mZr,"roformer"),mZr.forEach(t),LZe=r(A6e," \u2014 "),xR=n(A6e,"A",{href:!0});var gZr=s(xR);yZe=r(gZr,"RoFormerConfig"),gZr.forEach(t),xZe=r(A6e," (RoFormer model)"),A6e.forEach(t),$Ze=i(L),lg=n(L,"LI",{});var L6e=s(lg);qae=n(L6e,"STRONG",{});var hZr=s(qae);kZe=r(hZr,"segformer"),hZr.forEach(t),SZe=r(L6e," \u2014 "),$R=n(L6e,"A",{href:!0});var pZr=s($R);RZe=r(pZr,"SegformerConfig"),pZr.forEach(t),PZe=r(L6e," (SegFormer model)"),L6e.forEach(t),BZe=i(L),ig=n(L,"LI",{});var y6e=s(ig);jae=n(y6e,"STRONG",{});var uZr=s(jae);IZe=r(uZr,"sew"),uZr.forEach(t),NZe=r(y6e," \u2014 "),kR=n(y6e,"A",{href:!0});var _Zr=s(kR);qZe=r(_Zr,"SEWConfig"),_Zr.forEach(t),jZe=r(y6e," (SEW model)"),y6e.forEach(t),DZe=i(L),dg=n(L,"LI",{});var x6e=s(dg);Dae=n(x6e,"STRONG",{});var bZr=s(Dae);GZe=r(bZr,"sew-d"),bZr.forEach(t),OZe=r(x6e," \u2014 "),SR=n(x6e,"A",{href:!0});var vZr=s(SR);VZe=r(vZr,"SEWDConfig"),vZr.forEach(t),XZe=r(x6e," (SEW-D model)"),x6e.forEach(t),zZe=i(L),cg=n(L,"LI",{});var $6e=s(cg);Gae=n($6e,"STRONG",{});var FZr=s(Gae);WZe=r(FZr,"speech-encoder-decoder"),FZr.forEach(t),QZe=r($6e," \u2014 "),RR=n($6e,"A",{href:!0});var TZr=s(RR);HZe=r(TZr,"SpeechEncoderDecoderConfig"),TZr.forEach(t),UZe=r($6e," (Speech Encoder decoder model)"),$6e.forEach(t),JZe=i(L),fg=n(L,"LI",{});var k6e=s(fg);Oae=n(k6e,"STRONG",{});var MZr=s(Oae);YZe=r(MZr,"speech_to_text"),MZr.forEach(t),KZe=r(k6e," \u2014 "),PR=n(k6e,"A",{href:!0});var EZr=s(PR);ZZe=r(EZr,"Speech2TextConfig"),EZr.forEach(t),eeo=r(k6e," (Speech2Text model)"),k6e.forEach(t),oeo=i(L),mg=n(L,"LI",{});var S6e=s(mg);Vae=n(S6e,"STRONG",{});var CZr=s(Vae);reo=r(CZr,"speech_to_text_2"),CZr.forEach(t),teo=r(S6e," \u2014 "),BR=n(S6e,"A",{href:!0});var wZr=s(BR);aeo=r(wZr,"Speech2Text2Config"),wZr.forEach(t),neo=r(S6e," (Speech2Text2 model)"),S6e.forEach(t),seo=i(L),gg=n(L,"LI",{});var R6e=s(gg);Xae=n(R6e,"STRONG",{});var AZr=s(Xae);leo=r(AZr,"splinter"),AZr.forEach(t),ieo=r(R6e," \u2014 "),IR=n(R6e,"A",{href:!0});var LZr=s(IR);deo=r(LZr,"SplinterConfig"),LZr.forEach(t),ceo=r(R6e," (Splinter model)"),R6e.forEach(t),feo=i(L),hg=n(L,"LI",{});var P6e=s(hg);zae=n(P6e,"STRONG",{});var yZr=s(zae);meo=r(yZr,"squeezebert"),yZr.forEach(t),geo=r(P6e," \u2014 "),NR=n(P6e,"A",{href:!0});var xZr=s(NR);heo=r(xZr,"SqueezeBertConfig"),xZr.forEach(t),peo=r(P6e," (SqueezeBERT model)"),P6e.forEach(t),ueo=i(L),pg=n(L,"LI",{});var B6e=s(pg);Wae=n(B6e,"STRONG",{});var $Zr=s(Wae);_eo=r($Zr,"swin"),$Zr.forEach(t),beo=r(B6e," \u2014 "),qR=n(B6e,"A",{href:!0});var kZr=s(qR);veo=r(kZr,"SwinConfig"),kZr.forEach(t),Feo=r(B6e," (Swin Transformer model)"),B6e.forEach(t),Teo=i(L),ug=n(L,"LI",{});var I6e=s(ug);Qae=n(I6e,"STRONG",{});var SZr=s(Qae);Meo=r(SZr,"t5"),SZr.forEach(t),Eeo=r(I6e," \u2014 "),jR=n(I6e,"A",{href:!0});var RZr=s(jR);Ceo=r(RZr,"T5Config"),RZr.forEach(t),weo=r(I6e," (T5 model)"),I6e.forEach(t),Aeo=i(L),_g=n(L,"LI",{});var N6e=s(_g);Hae=n(N6e,"STRONG",{});var PZr=s(Hae);Leo=r(PZr,"tapas"),PZr.forEach(t),yeo=r(N6e," \u2014 "),DR=n(N6e,"A",{href:!0});var BZr=s(DR);xeo=r(BZr,"TapasConfig"),BZr.forEach(t),$eo=r(N6e," (TAPAS model)"),N6e.forEach(t),keo=i(L),bg=n(L,"LI",{});var q6e=s(bg);Uae=n(q6e,"STRONG",{});var IZr=s(Uae);Seo=r(IZr,"trajectory_transformer"),IZr.forEach(t),Reo=r(q6e," \u2014 "),GR=n(q6e,"A",{href:!0});var NZr=s(GR);Peo=r(NZr,"TrajectoryTransformerConfig"),NZr.forEach(t),Beo=r(q6e," (Trajectory Transformer model)"),q6e.forEach(t),Ieo=i(L),vg=n(L,"LI",{});var j6e=s(vg);Jae=n(j6e,"STRONG",{});var qZr=s(Jae);Neo=r(qZr,"transfo-xl"),qZr.forEach(t),qeo=r(j6e," \u2014 "),OR=n(j6e,"A",{href:!0});var jZr=s(OR);jeo=r(jZr,"TransfoXLConfig"),jZr.forEach(t),Deo=r(j6e," (Transformer-XL model)"),j6e.forEach(t),Geo=i(L),Fg=n(L,"LI",{});var D6e=s(Fg);Yae=n(D6e,"STRONG",{});var DZr=s(Yae);Oeo=r(DZr,"trocr"),DZr.forEach(t),Veo=r(D6e," \u2014 "),VR=n(D6e,"A",{href:!0});var GZr=s(VR);Xeo=r(GZr,"TrOCRConfig"),GZr.forEach(t),zeo=r(D6e," (TrOCR model)"),D6e.forEach(t),Weo=i(L),Tg=n(L,"LI",{});var G6e=s(Tg);Kae=n(G6e,"STRONG",{});var OZr=s(Kae);Qeo=r(OZr,"unispeech"),OZr.forEach(t),Heo=r(G6e," \u2014 "),XR=n(G6e,"A",{href:!0});var VZr=s(XR);Ueo=r(VZr,"UniSpeechConfig"),VZr.forEach(t),Jeo=r(G6e," (UniSpeech model)"),G6e.forEach(t),Yeo=i(L),Mg=n(L,"LI",{});var O6e=s(Mg);Zae=n(O6e,"STRONG",{});var XZr=s(Zae);Keo=r(XZr,"unispeech-sat"),XZr.forEach(t),Zeo=r(O6e," \u2014 "),zR=n(O6e,"A",{href:!0});var zZr=s(zR);eoo=r(zZr,"UniSpeechSatConfig"),zZr.forEach(t),ooo=r(O6e," (UniSpeechSat model)"),O6e.forEach(t),roo=i(L),Eg=n(L,"LI",{});var V6e=s(Eg);ene=n(V6e,"STRONG",{});var WZr=s(ene);too=r(WZr,"van"),WZr.forEach(t),aoo=r(V6e," \u2014 "),WR=n(V6e,"A",{href:!0});var QZr=s(WR);noo=r(QZr,"VanConfig"),QZr.forEach(t),soo=r(V6e," (VAN model)"),V6e.forEach(t),loo=i(L),Cg=n(L,"LI",{});var X6e=s(Cg);one=n(X6e,"STRONG",{});var HZr=s(one);ioo=r(HZr,"vilt"),HZr.forEach(t),doo=r(X6e," \u2014 "),QR=n(X6e,"A",{href:!0});var UZr=s(QR);coo=r(UZr,"ViltConfig"),UZr.forEach(t),foo=r(X6e," (ViLT model)"),X6e.forEach(t),moo=i(L),wg=n(L,"LI",{});var z6e=s(wg);rne=n(z6e,"STRONG",{});var JZr=s(rne);goo=r(JZr,"vision-encoder-decoder"),JZr.forEach(t),hoo=r(z6e," \u2014 "),HR=n(z6e,"A",{href:!0});var YZr=s(HR);poo=r(YZr,"VisionEncoderDecoderConfig"),YZr.forEach(t),uoo=r(z6e," (Vision Encoder decoder model)"),z6e.forEach(t),_oo=i(L),Ag=n(L,"LI",{});var W6e=s(Ag);tne=n(W6e,"STRONG",{});var KZr=s(tne);boo=r(KZr,"vision-text-dual-encoder"),KZr.forEach(t),voo=r(W6e," \u2014 "),UR=n(W6e,"A",{href:!0});var ZZr=s(UR);Foo=r(ZZr,"VisionTextDualEncoderConfig"),ZZr.forEach(t),Too=r(W6e," (VisionTextDualEncoder model)"),W6e.forEach(t),Moo=i(L),Lg=n(L,"LI",{});var Q6e=s(Lg);ane=n(Q6e,"STRONG",{});var eet=s(ane);Eoo=r(eet,"visual_bert"),eet.forEach(t),Coo=r(Q6e," \u2014 "),JR=n(Q6e,"A",{href:!0});var oet=s(JR);woo=r(oet,"VisualBertConfig"),oet.forEach(t),Aoo=r(Q6e," (VisualBERT model)"),Q6e.forEach(t),Loo=i(L),yg=n(L,"LI",{});var H6e=s(yg);nne=n(H6e,"STRONG",{});var ret=s(nne);yoo=r(ret,"vit"),ret.forEach(t),xoo=r(H6e," \u2014 "),YR=n(H6e,"A",{href:!0});var tet=s(YR);$oo=r(tet,"ViTConfig"),tet.forEach(t),koo=r(H6e," (ViT model)"),H6e.forEach(t),Soo=i(L),xg=n(L,"LI",{});var U6e=s(xg);sne=n(U6e,"STRONG",{});var aet=s(sne);Roo=r(aet,"vit_mae"),aet.forEach(t),Poo=r(U6e," \u2014 "),KR=n(U6e,"A",{href:!0});var net=s(KR);Boo=r(net,"ViTMAEConfig"),net.forEach(t),Ioo=r(U6e," (ViTMAE model)"),U6e.forEach(t),Noo=i(L),$g=n(L,"LI",{});var J6e=s($g);lne=n(J6e,"STRONG",{});var set=s(lne);qoo=r(set,"wav2vec2"),set.forEach(t),joo=r(J6e," \u2014 "),ZR=n(J6e,"A",{href:!0});var iet=s(ZR);Doo=r(iet,"Wav2Vec2Config"),iet.forEach(t),Goo=r(J6e," (Wav2Vec2 model)"),J6e.forEach(t),Ooo=i(L),kg=n(L,"LI",{});var Y6e=s(kg);ine=n(Y6e,"STRONG",{});var det=s(ine);Voo=r(det,"wav2vec2-conformer"),det.forEach(t),Xoo=r(Y6e," \u2014 "),eP=n(Y6e,"A",{href:!0});var cet=s(eP);zoo=r(cet,"Wav2Vec2ConformerConfig"),cet.forEach(t),Woo=r(Y6e," (Wav2Vec2-Conformer model)"),Y6e.forEach(t),Qoo=i(L),Sg=n(L,"LI",{});var K6e=s(Sg);dne=n(K6e,"STRONG",{});var fet=s(dne);Hoo=r(fet,"wavlm"),fet.forEach(t),Uoo=r(K6e," \u2014 "),oP=n(K6e,"A",{href:!0});var met=s(oP);Joo=r(met,"WavLMConfig"),met.forEach(t),Yoo=r(K6e," (WavLM model)"),K6e.forEach(t),Koo=i(L),Rg=n(L,"LI",{});var Z6e=s(Rg);cne=n(Z6e,"STRONG",{});var get=s(cne);Zoo=r(get,"xglm"),get.forEach(t),ero=r(Z6e," \u2014 "),rP=n(Z6e,"A",{href:!0});var het=s(rP);oro=r(het,"XGLMConfig"),het.forEach(t),rro=r(Z6e," (XGLM model)"),Z6e.forEach(t),tro=i(L),Pg=n(L,"LI",{});var eLe=s(Pg);fne=n(eLe,"STRONG",{});var pet=s(fne);aro=r(pet,"xlm"),pet.forEach(t),nro=r(eLe," \u2014 "),tP=n(eLe,"A",{href:!0});var uet=s(tP);sro=r(uet,"XLMConfig"),uet.forEach(t),lro=r(eLe," (XLM model)"),eLe.forEach(t),iro=i(L),Bg=n(L,"LI",{});var oLe=s(Bg);mne=n(oLe,"STRONG",{});var _et=s(mne);dro=r(_et,"xlm-prophetnet"),_et.forEach(t),cro=r(oLe," \u2014 "),aP=n(oLe,"A",{href:!0});var bet=s(aP);fro=r(bet,"XLMProphetNetConfig"),bet.forEach(t),mro=r(oLe," (XLM-ProphetNet model)"),oLe.forEach(t),gro=i(L),Ig=n(L,"LI",{});var rLe=s(Ig);gne=n(rLe,"STRONG",{});var vet=s(gne);hro=r(vet,"xlm-roberta"),vet.forEach(t),pro=r(rLe," \u2014 "),nP=n(rLe,"A",{href:!0});var Fet=s(nP);uro=r(Fet,"XLMRobertaConfig"),Fet.forEach(t),_ro=r(rLe," (XLM-RoBERTa model)"),rLe.forEach(t),bro=i(L),Ng=n(L,"LI",{});var tLe=s(Ng);hne=n(tLe,"STRONG",{});var Tet=s(hne);vro=r(Tet,"xlm-roberta-xl"),Tet.forEach(t),Fro=r(tLe," \u2014 "),sP=n(tLe,"A",{href:!0});var Met=s(sP);Tro=r(Met,"XLMRobertaXLConfig"),Met.forEach(t),Mro=r(tLe," (XLM-RoBERTa-XL model)"),tLe.forEach(t),Ero=i(L),qg=n(L,"LI",{});var aLe=s(qg);pne=n(aLe,"STRONG",{});var Eet=s(pne);Cro=r(Eet,"xlnet"),Eet.forEach(t),wro=r(aLe," \u2014 "),lP=n(aLe,"A",{href:!0});var Cet=s(lP);Aro=r(Cet,"XLNetConfig"),Cet.forEach(t),Lro=r(aLe," (XLNet model)"),aLe.forEach(t),yro=i(L),jg=n(L,"LI",{});var nLe=s(jg);une=n(nLe,"STRONG",{});var wet=s(une);xro=r(wet,"yolos"),wet.forEach(t),$ro=r(nLe," \u2014 "),iP=n(nLe,"A",{href:!0});var Aet=s(iP);kro=r(Aet,"YolosConfig"),Aet.forEach(t),Sro=r(nLe," (YOLOS model)"),nLe.forEach(t),Rro=i(L),Dg=n(L,"LI",{});var sLe=s(Dg);_ne=n(sLe,"STRONG",{});var Let=s(_ne);Pro=r(Let,"yoso"),Let.forEach(t),Bro=r(sLe," \u2014 "),dP=n(sLe,"A",{href:!0});var yet=s(dP);Iro=r(yet,"YosoConfig"),yet.forEach(t),Nro=r(sLe," (YOSO model)"),sLe.forEach(t),L.forEach(t),qro=i(tt),T(Gg.$$.fragment,tt),tt.forEach(t),jro=i(rt),Og=n(rt,"DIV",{class:!0});var wVe=s(Og);T(kL.$$.fragment,wVe),Dro=i(wVe),bne=n(wVe,"P",{});var xet=s(bne);Gro=r(xet,"Register a new configuration for this class."),xet.forEach(t),wVe.forEach(t),rt.forEach(t),AGe=i(f),ki=n(f,"H2",{class:!0});var AVe=s(ki);Vg=n(AVe,"A",{id:!0,class:!0,href:!0});var $et=s(Vg);vne=n($et,"SPAN",{});var ket=s(vne);T(SL.$$.fragment,ket),ket.forEach(t),$et.forEach(t),Oro=i(AVe),Fne=n(AVe,"SPAN",{});var Set=s(Fne);Vro=r(Set,"AutoTokenizer"),Set.forEach(t),AVe.forEach(t),LGe=i(f),Ao=n(f,"DIV",{class:!0});var Ws=s(Ao);T(RL.$$.fragment,Ws),Xro=i(Ws),PL=n(Ws,"P",{});var LVe=s(PL);zro=r(LVe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),cP=n(LVe,"A",{href:!0});var Ret=s(cP);Wro=r(Ret,"AutoTokenizer.from_pretrained()"),Ret.forEach(t),Qro=r(LVe," class method."),LVe.forEach(t),Hro=i(Ws),BL=n(Ws,"P",{});var yVe=s(BL);Uro=r(yVe,"This class cannot be instantiated directly using "),Tne=n(yVe,"CODE",{});var Pet=s(Tne);Jro=r(Pet,"__init__()"),Pet.forEach(t),Yro=r(yVe," (throws an error)."),yVe.forEach(t),Kro=i(Ws),Ar=n(Ws,"DIV",{class:!0});var Qs=s(Ar);T(IL.$$.fragment,Qs),Zro=i(Qs),Mne=n(Qs,"P",{});var Bet=s(Mne);eto=r(Bet,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Bet.forEach(t),oto=i(Qs),$a=n(Qs,"P",{});var CA=s($a);rto=r(CA,"The tokenizer class to instantiate is selected based on the "),Ene=n(CA,"CODE",{});var Iet=s(Ene);tto=r(Iet,"model_type"),Iet.forEach(t),ato=r(CA,` property of the config object (either
passed as an argument or loaded from `),Cne=n(CA,"CODE",{});var Net=s(Cne);nto=r(Net,"pretrained_model_name_or_path"),Net.forEach(t),sto=r(CA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wne=n(CA,"CODE",{});var qet=s(wne);lto=r(qet,"pretrained_model_name_or_path"),qet.forEach(t),ito=r(CA,":"),CA.forEach(t),dto=i(Qs),k=n(Qs,"UL",{});var S=s(k);Nn=n(S,"LI",{});var O$=s(Nn);Ane=n(O$,"STRONG",{});var jet=s(Ane);cto=r(jet,"albert"),jet.forEach(t),fto=r(O$," \u2014 "),fP=n(O$,"A",{href:!0});var Det=s(fP);mto=r(Det,"AlbertTokenizer"),Det.forEach(t),gto=r(O$," or "),mP=n(O$,"A",{href:!0});var Get=s(mP);hto=r(Get,"AlbertTokenizerFast"),Get.forEach(t),pto=r(O$," (ALBERT model)"),O$.forEach(t),uto=i(S),qn=n(S,"LI",{});var V$=s(qn);Lne=n(V$,"STRONG",{});var Oet=s(Lne);_to=r(Oet,"bart"),Oet.forEach(t),bto=r(V$," \u2014 "),gP=n(V$,"A",{href:!0});var Vet=s(gP);vto=r(Vet,"BartTokenizer"),Vet.forEach(t),Fto=r(V$," or "),hP=n(V$,"A",{href:!0});var Xet=s(hP);Tto=r(Xet,"BartTokenizerFast"),Xet.forEach(t),Mto=r(V$," (BART model)"),V$.forEach(t),Eto=i(S),jn=n(S,"LI",{});var X$=s(jn);yne=n(X$,"STRONG",{});var zet=s(yne);Cto=r(zet,"barthez"),zet.forEach(t),wto=r(X$," \u2014 "),pP=n(X$,"A",{href:!0});var Wet=s(pP);Ato=r(Wet,"BarthezTokenizer"),Wet.forEach(t),Lto=r(X$," or "),uP=n(X$,"A",{href:!0});var Qet=s(uP);yto=r(Qet,"BarthezTokenizerFast"),Qet.forEach(t),xto=r(X$," (BARThez model)"),X$.forEach(t),$to=i(S),Xg=n(S,"LI",{});var lLe=s(Xg);xne=n(lLe,"STRONG",{});var Het=s(xne);kto=r(Het,"bartpho"),Het.forEach(t),Sto=r(lLe," \u2014 "),_P=n(lLe,"A",{href:!0});var Uet=s(_P);Rto=r(Uet,"BartphoTokenizer"),Uet.forEach(t),Pto=r(lLe," (BARTpho model)"),lLe.forEach(t),Bto=i(S),Dn=n(S,"LI",{});var z$=s(Dn);$ne=n(z$,"STRONG",{});var Jet=s($ne);Ito=r(Jet,"bert"),Jet.forEach(t),Nto=r(z$," \u2014 "),bP=n(z$,"A",{href:!0});var Yet=s(bP);qto=r(Yet,"BertTokenizer"),Yet.forEach(t),jto=r(z$," or "),vP=n(z$,"A",{href:!0});var Ket=s(vP);Dto=r(Ket,"BertTokenizerFast"),Ket.forEach(t),Gto=r(z$," (BERT model)"),z$.forEach(t),Oto=i(S),zg=n(S,"LI",{});var iLe=s(zg);kne=n(iLe,"STRONG",{});var Zet=s(kne);Vto=r(Zet,"bert-generation"),Zet.forEach(t),Xto=r(iLe," \u2014 "),FP=n(iLe,"A",{href:!0});var eot=s(FP);zto=r(eot,"BertGenerationTokenizer"),eot.forEach(t),Wto=r(iLe," (Bert Generation model)"),iLe.forEach(t),Qto=i(S),Wg=n(S,"LI",{});var dLe=s(Wg);Sne=n(dLe,"STRONG",{});var oot=s(Sne);Hto=r(oot,"bert-japanese"),oot.forEach(t),Uto=r(dLe," \u2014 "),TP=n(dLe,"A",{href:!0});var rot=s(TP);Jto=r(rot,"BertJapaneseTokenizer"),rot.forEach(t),Yto=r(dLe," (BertJapanese model)"),dLe.forEach(t),Kto=i(S),Qg=n(S,"LI",{});var cLe=s(Qg);Rne=n(cLe,"STRONG",{});var tot=s(Rne);Zto=r(tot,"bertweet"),tot.forEach(t),eao=r(cLe," \u2014 "),MP=n(cLe,"A",{href:!0});var aot=s(MP);oao=r(aot,"BertweetTokenizer"),aot.forEach(t),rao=r(cLe," (BERTweet model)"),cLe.forEach(t),tao=i(S),Gn=n(S,"LI",{});var W$=s(Gn);Pne=n(W$,"STRONG",{});var not=s(Pne);aao=r(not,"big_bird"),not.forEach(t),nao=r(W$," \u2014 "),EP=n(W$,"A",{href:!0});var sot=s(EP);sao=r(sot,"BigBirdTokenizer"),sot.forEach(t),lao=r(W$," or "),CP=n(W$,"A",{href:!0});var lot=s(CP);iao=r(lot,"BigBirdTokenizerFast"),lot.forEach(t),dao=r(W$," (BigBird model)"),W$.forEach(t),cao=i(S),On=n(S,"LI",{});var Q$=s(On);Bne=n(Q$,"STRONG",{});var iot=s(Bne);fao=r(iot,"bigbird_pegasus"),iot.forEach(t),mao=r(Q$," \u2014 "),wP=n(Q$,"A",{href:!0});var dot=s(wP);gao=r(dot,"PegasusTokenizer"),dot.forEach(t),hao=r(Q$," or "),AP=n(Q$,"A",{href:!0});var cot=s(AP);pao=r(cot,"PegasusTokenizerFast"),cot.forEach(t),uao=r(Q$," (BigBird-Pegasus model)"),Q$.forEach(t),_ao=i(S),Vn=n(S,"LI",{});var H$=s(Vn);Ine=n(H$,"STRONG",{});var fot=s(Ine);bao=r(fot,"blenderbot"),fot.forEach(t),vao=r(H$," \u2014 "),LP=n(H$,"A",{href:!0});var mot=s(LP);Fao=r(mot,"BlenderbotTokenizer"),mot.forEach(t),Tao=r(H$," or "),yP=n(H$,"A",{href:!0});var got=s(yP);Mao=r(got,"BlenderbotTokenizerFast"),got.forEach(t),Eao=r(H$," (Blenderbot model)"),H$.forEach(t),Cao=i(S),Hg=n(S,"LI",{});var fLe=s(Hg);Nne=n(fLe,"STRONG",{});var hot=s(Nne);wao=r(hot,"blenderbot-small"),hot.forEach(t),Aao=r(fLe," \u2014 "),xP=n(fLe,"A",{href:!0});var pot=s(xP);Lao=r(pot,"BlenderbotSmallTokenizer"),pot.forEach(t),yao=r(fLe," (BlenderbotSmall model)"),fLe.forEach(t),xao=i(S),Ug=n(S,"LI",{});var mLe=s(Ug);qne=n(mLe,"STRONG",{});var uot=s(qne);$ao=r(uot,"bloom"),uot.forEach(t),kao=r(mLe," \u2014 "),$P=n(mLe,"A",{href:!0});var _ot=s($P);Sao=r(_ot,"BloomTokenizerFast"),_ot.forEach(t),Rao=r(mLe," (BLOOM model)"),mLe.forEach(t),Pao=i(S),Jg=n(S,"LI",{});var gLe=s(Jg);jne=n(gLe,"STRONG",{});var bot=s(jne);Bao=r(bot,"byt5"),bot.forEach(t),Iao=r(gLe," \u2014 "),kP=n(gLe,"A",{href:!0});var vot=s(kP);Nao=r(vot,"ByT5Tokenizer"),vot.forEach(t),qao=r(gLe," (ByT5 model)"),gLe.forEach(t),jao=i(S),Xn=n(S,"LI",{});var U$=s(Xn);Dne=n(U$,"STRONG",{});var Fot=s(Dne);Dao=r(Fot,"camembert"),Fot.forEach(t),Gao=r(U$," \u2014 "),SP=n(U$,"A",{href:!0});var Tot=s(SP);Oao=r(Tot,"CamembertTokenizer"),Tot.forEach(t),Vao=r(U$," or "),RP=n(U$,"A",{href:!0});var Mot=s(RP);Xao=r(Mot,"CamembertTokenizerFast"),Mot.forEach(t),zao=r(U$," (CamemBERT model)"),U$.forEach(t),Wao=i(S),Yg=n(S,"LI",{});var hLe=s(Yg);Gne=n(hLe,"STRONG",{});var Eot=s(Gne);Qao=r(Eot,"canine"),Eot.forEach(t),Hao=r(hLe," \u2014 "),PP=n(hLe,"A",{href:!0});var Cot=s(PP);Uao=r(Cot,"CanineTokenizer"),Cot.forEach(t),Jao=r(hLe," (CANINE model)"),hLe.forEach(t),Yao=i(S),zn=n(S,"LI",{});var J$=s(zn);One=n(J$,"STRONG",{});var wot=s(One);Kao=r(wot,"clip"),wot.forEach(t),Zao=r(J$," \u2014 "),BP=n(J$,"A",{href:!0});var Aot=s(BP);eno=r(Aot,"CLIPTokenizer"),Aot.forEach(t),ono=r(J$," or "),IP=n(J$,"A",{href:!0});var Lot=s(IP);rno=r(Lot,"CLIPTokenizerFast"),Lot.forEach(t),tno=r(J$," (CLIP model)"),J$.forEach(t),ano=i(S),Wn=n(S,"LI",{});var Y$=s(Wn);Vne=n(Y$,"STRONG",{});var yot=s(Vne);nno=r(yot,"convbert"),yot.forEach(t),sno=r(Y$," \u2014 "),NP=n(Y$,"A",{href:!0});var xot=s(NP);lno=r(xot,"ConvBertTokenizer"),xot.forEach(t),ino=r(Y$," or "),qP=n(Y$,"A",{href:!0});var $ot=s(qP);dno=r($ot,"ConvBertTokenizerFast"),$ot.forEach(t),cno=r(Y$," (ConvBERT model)"),Y$.forEach(t),fno=i(S),Qn=n(S,"LI",{});var K$=s(Qn);Xne=n(K$,"STRONG",{});var kot=s(Xne);mno=r(kot,"cpm"),kot.forEach(t),gno=r(K$," \u2014 "),jP=n(K$,"A",{href:!0});var Sot=s(jP);hno=r(Sot,"CpmTokenizer"),Sot.forEach(t),pno=r(K$," or "),DP=n(K$,"A",{href:!0});var Rot=s(DP);uno=r(Rot,"CpmTokenizerFast"),Rot.forEach(t),_no=r(K$," (CPM model)"),K$.forEach(t),bno=i(S),Kg=n(S,"LI",{});var pLe=s(Kg);zne=n(pLe,"STRONG",{});var Pot=s(zne);vno=r(Pot,"ctrl"),Pot.forEach(t),Fno=r(pLe," \u2014 "),GP=n(pLe,"A",{href:!0});var Bot=s(GP);Tno=r(Bot,"CTRLTokenizer"),Bot.forEach(t),Mno=r(pLe," (CTRL model)"),pLe.forEach(t),Eno=i(S),Hn=n(S,"LI",{});var Z$=s(Hn);Wne=n(Z$,"STRONG",{});var Iot=s(Wne);Cno=r(Iot,"data2vec-text"),Iot.forEach(t),wno=r(Z$," \u2014 "),OP=n(Z$,"A",{href:!0});var Not=s(OP);Ano=r(Not,"RobertaTokenizer"),Not.forEach(t),Lno=r(Z$," or "),VP=n(Z$,"A",{href:!0});var qot=s(VP);yno=r(qot,"RobertaTokenizerFast"),qot.forEach(t),xno=r(Z$," (Data2VecText model)"),Z$.forEach(t),$no=i(S),Un=n(S,"LI",{});var ek=s(Un);Qne=n(ek,"STRONG",{});var jot=s(Qne);kno=r(jot,"deberta"),jot.forEach(t),Sno=r(ek," \u2014 "),XP=n(ek,"A",{href:!0});var Dot=s(XP);Rno=r(Dot,"DebertaTokenizer"),Dot.forEach(t),Pno=r(ek," or "),zP=n(ek,"A",{href:!0});var Got=s(zP);Bno=r(Got,"DebertaTokenizerFast"),Got.forEach(t),Ino=r(ek," (DeBERTa model)"),ek.forEach(t),Nno=i(S),Jn=n(S,"LI",{});var ok=s(Jn);Hne=n(ok,"STRONG",{});var Oot=s(Hne);qno=r(Oot,"deberta-v2"),Oot.forEach(t),jno=r(ok," \u2014 "),WP=n(ok,"A",{href:!0});var Vot=s(WP);Dno=r(Vot,"DebertaV2Tokenizer"),Vot.forEach(t),Gno=r(ok," or "),QP=n(ok,"A",{href:!0});var Xot=s(QP);Ono=r(Xot,"DebertaV2TokenizerFast"),Xot.forEach(t),Vno=r(ok," (DeBERTa-v2 model)"),ok.forEach(t),Xno=i(S),Yn=n(S,"LI",{});var rk=s(Yn);Une=n(rk,"STRONG",{});var zot=s(Une);zno=r(zot,"distilbert"),zot.forEach(t),Wno=r(rk," \u2014 "),HP=n(rk,"A",{href:!0});var Wot=s(HP);Qno=r(Wot,"DistilBertTokenizer"),Wot.forEach(t),Hno=r(rk," or "),UP=n(rk,"A",{href:!0});var Qot=s(UP);Uno=r(Qot,"DistilBertTokenizerFast"),Qot.forEach(t),Jno=r(rk," (DistilBERT model)"),rk.forEach(t),Yno=i(S),Kn=n(S,"LI",{});var tk=s(Kn);Jne=n(tk,"STRONG",{});var Hot=s(Jne);Kno=r(Hot,"dpr"),Hot.forEach(t),Zno=r(tk," \u2014 "),JP=n(tk,"A",{href:!0});var Uot=s(JP);eso=r(Uot,"DPRQuestionEncoderTokenizer"),Uot.forEach(t),oso=r(tk," or "),YP=n(tk,"A",{href:!0});var Jot=s(YP);rso=r(Jot,"DPRQuestionEncoderTokenizerFast"),Jot.forEach(t),tso=r(tk," (DPR model)"),tk.forEach(t),aso=i(S),Zn=n(S,"LI",{});var ak=s(Zn);Yne=n(ak,"STRONG",{});var Yot=s(Yne);nso=r(Yot,"electra"),Yot.forEach(t),sso=r(ak," \u2014 "),KP=n(ak,"A",{href:!0});var Kot=s(KP);lso=r(Kot,"ElectraTokenizer"),Kot.forEach(t),iso=r(ak," or "),ZP=n(ak,"A",{href:!0});var Zot=s(ZP);dso=r(Zot,"ElectraTokenizerFast"),Zot.forEach(t),cso=r(ak," (ELECTRA model)"),ak.forEach(t),fso=i(S),Zg=n(S,"LI",{});var uLe=s(Zg);Kne=n(uLe,"STRONG",{});var ert=s(Kne);mso=r(ert,"flaubert"),ert.forEach(t),gso=r(uLe," \u2014 "),eB=n(uLe,"A",{href:!0});var ort=s(eB);hso=r(ort,"FlaubertTokenizer"),ort.forEach(t),pso=r(uLe," (FlauBERT model)"),uLe.forEach(t),uso=i(S),es=n(S,"LI",{});var nk=s(es);Zne=n(nk,"STRONG",{});var rrt=s(Zne);_so=r(rrt,"fnet"),rrt.forEach(t),bso=r(nk," \u2014 "),oB=n(nk,"A",{href:!0});var trt=s(oB);vso=r(trt,"FNetTokenizer"),trt.forEach(t),Fso=r(nk," or "),rB=n(nk,"A",{href:!0});var art=s(rB);Tso=r(art,"FNetTokenizerFast"),art.forEach(t),Mso=r(nk," (FNet model)"),nk.forEach(t),Eso=i(S),eh=n(S,"LI",{});var _Le=s(eh);ese=n(_Le,"STRONG",{});var nrt=s(ese);Cso=r(nrt,"fsmt"),nrt.forEach(t),wso=r(_Le," \u2014 "),tB=n(_Le,"A",{href:!0});var srt=s(tB);Aso=r(srt,"FSMTTokenizer"),srt.forEach(t),Lso=r(_Le," (FairSeq Machine-Translation model)"),_Le.forEach(t),yso=i(S),os=n(S,"LI",{});var sk=s(os);ose=n(sk,"STRONG",{});var lrt=s(ose);xso=r(lrt,"funnel"),lrt.forEach(t),$so=r(sk," \u2014 "),aB=n(sk,"A",{href:!0});var irt=s(aB);kso=r(irt,"FunnelTokenizer"),irt.forEach(t),Sso=r(sk," or "),nB=n(sk,"A",{href:!0});var drt=s(nB);Rso=r(drt,"FunnelTokenizerFast"),drt.forEach(t),Pso=r(sk," (Funnel Transformer model)"),sk.forEach(t),Bso=i(S),rs=n(S,"LI",{});var lk=s(rs);rse=n(lk,"STRONG",{});var crt=s(rse);Iso=r(crt,"gpt2"),crt.forEach(t),Nso=r(lk," \u2014 "),sB=n(lk,"A",{href:!0});var frt=s(sB);qso=r(frt,"GPT2Tokenizer"),frt.forEach(t),jso=r(lk," or "),lB=n(lk,"A",{href:!0});var mrt=s(lB);Dso=r(mrt,"GPT2TokenizerFast"),mrt.forEach(t),Gso=r(lk," (OpenAI GPT-2 model)"),lk.forEach(t),Oso=i(S),ts=n(S,"LI",{});var ik=s(ts);tse=n(ik,"STRONG",{});var grt=s(tse);Vso=r(grt,"gpt_neo"),grt.forEach(t),Xso=r(ik," \u2014 "),iB=n(ik,"A",{href:!0});var hrt=s(iB);zso=r(hrt,"GPT2Tokenizer"),hrt.forEach(t),Wso=r(ik," or "),dB=n(ik,"A",{href:!0});var prt=s(dB);Qso=r(prt,"GPT2TokenizerFast"),prt.forEach(t),Hso=r(ik," (GPT Neo model)"),ik.forEach(t),Uso=i(S),oh=n(S,"LI",{});var bLe=s(oh);ase=n(bLe,"STRONG",{});var urt=s(ase);Jso=r(urt,"gpt_neox"),urt.forEach(t),Yso=r(bLe," \u2014 "),cB=n(bLe,"A",{href:!0});var _rt=s(cB);Kso=r(_rt,"GPTNeoXTokenizerFast"),_rt.forEach(t),Zso=r(bLe," (GPT NeoX model)"),bLe.forEach(t),elo=i(S),as=n(S,"LI",{});var dk=s(as);nse=n(dk,"STRONG",{});var brt=s(nse);olo=r(brt,"gptj"),brt.forEach(t),rlo=r(dk," \u2014 "),fB=n(dk,"A",{href:!0});var vrt=s(fB);tlo=r(vrt,"GPT2Tokenizer"),vrt.forEach(t),alo=r(dk," or "),mB=n(dk,"A",{href:!0});var Frt=s(mB);nlo=r(Frt,"GPT2TokenizerFast"),Frt.forEach(t),slo=r(dk," (GPT-J model)"),dk.forEach(t),llo=i(S),ns=n(S,"LI",{});var ck=s(ns);sse=n(ck,"STRONG",{});var Trt=s(sse);ilo=r(Trt,"groupvit"),Trt.forEach(t),dlo=r(ck," \u2014 "),gB=n(ck,"A",{href:!0});var Mrt=s(gB);clo=r(Mrt,"CLIPTokenizer"),Mrt.forEach(t),flo=r(ck," or "),hB=n(ck,"A",{href:!0});var Ert=s(hB);mlo=r(Ert,"CLIPTokenizerFast"),Ert.forEach(t),glo=r(ck," (GroupViT model)"),ck.forEach(t),hlo=i(S),ss=n(S,"LI",{});var fk=s(ss);lse=n(fk,"STRONG",{});var Crt=s(lse);plo=r(Crt,"herbert"),Crt.forEach(t),ulo=r(fk," \u2014 "),pB=n(fk,"A",{href:!0});var wrt=s(pB);_lo=r(wrt,"HerbertTokenizer"),wrt.forEach(t),blo=r(fk," or "),uB=n(fk,"A",{href:!0});var Art=s(uB);vlo=r(Art,"HerbertTokenizerFast"),Art.forEach(t),Flo=r(fk," (HerBERT model)"),fk.forEach(t),Tlo=i(S),rh=n(S,"LI",{});var vLe=s(rh);ise=n(vLe,"STRONG",{});var Lrt=s(ise);Mlo=r(Lrt,"hubert"),Lrt.forEach(t),Elo=r(vLe," \u2014 "),_B=n(vLe,"A",{href:!0});var yrt=s(_B);Clo=r(yrt,"Wav2Vec2CTCTokenizer"),yrt.forEach(t),wlo=r(vLe," (Hubert model)"),vLe.forEach(t),Alo=i(S),ls=n(S,"LI",{});var mk=s(ls);dse=n(mk,"STRONG",{});var xrt=s(dse);Llo=r(xrt,"ibert"),xrt.forEach(t),ylo=r(mk," \u2014 "),bB=n(mk,"A",{href:!0});var $rt=s(bB);xlo=r($rt,"RobertaTokenizer"),$rt.forEach(t),$lo=r(mk," or "),vB=n(mk,"A",{href:!0});var krt=s(vB);klo=r(krt,"RobertaTokenizerFast"),krt.forEach(t),Slo=r(mk," (I-BERT model)"),mk.forEach(t),Rlo=i(S),is=n(S,"LI",{});var gk=s(is);cse=n(gk,"STRONG",{});var Srt=s(cse);Plo=r(Srt,"layoutlm"),Srt.forEach(t),Blo=r(gk," \u2014 "),FB=n(gk,"A",{href:!0});var Rrt=s(FB);Ilo=r(Rrt,"LayoutLMTokenizer"),Rrt.forEach(t),Nlo=r(gk," or "),TB=n(gk,"A",{href:!0});var Prt=s(TB);qlo=r(Prt,"LayoutLMTokenizerFast"),Prt.forEach(t),jlo=r(gk," (LayoutLM model)"),gk.forEach(t),Dlo=i(S),ds=n(S,"LI",{});var hk=s(ds);fse=n(hk,"STRONG",{});var Brt=s(fse);Glo=r(Brt,"layoutlmv2"),Brt.forEach(t),Olo=r(hk," \u2014 "),MB=n(hk,"A",{href:!0});var Irt=s(MB);Vlo=r(Irt,"LayoutLMv2Tokenizer"),Irt.forEach(t),Xlo=r(hk," or "),EB=n(hk,"A",{href:!0});var Nrt=s(EB);zlo=r(Nrt,"LayoutLMv2TokenizerFast"),Nrt.forEach(t),Wlo=r(hk," (LayoutLMv2 model)"),hk.forEach(t),Qlo=i(S),cs=n(S,"LI",{});var pk=s(cs);mse=n(pk,"STRONG",{});var qrt=s(mse);Hlo=r(qrt,"layoutlmv3"),qrt.forEach(t),Ulo=r(pk," \u2014 "),CB=n(pk,"A",{href:!0});var jrt=s(CB);Jlo=r(jrt,"LayoutLMv3Tokenizer"),jrt.forEach(t),Ylo=r(pk," or "),wB=n(pk,"A",{href:!0});var Drt=s(wB);Klo=r(Drt,"LayoutLMv3TokenizerFast"),Drt.forEach(t),Zlo=r(pk," (LayoutLMv3 model)"),pk.forEach(t),eio=i(S),fs=n(S,"LI",{});var uk=s(fs);gse=n(uk,"STRONG",{});var Grt=s(gse);oio=r(Grt,"layoutxlm"),Grt.forEach(t),rio=r(uk," \u2014 "),AB=n(uk,"A",{href:!0});var Ort=s(AB);tio=r(Ort,"LayoutXLMTokenizer"),Ort.forEach(t),aio=r(uk," or "),LB=n(uk,"A",{href:!0});var Vrt=s(LB);nio=r(Vrt,"LayoutXLMTokenizerFast"),Vrt.forEach(t),sio=r(uk," (LayoutXLM model)"),uk.forEach(t),lio=i(S),ms=n(S,"LI",{});var _k=s(ms);hse=n(_k,"STRONG",{});var Xrt=s(hse);iio=r(Xrt,"led"),Xrt.forEach(t),dio=r(_k," \u2014 "),yB=n(_k,"A",{href:!0});var zrt=s(yB);cio=r(zrt,"LEDTokenizer"),zrt.forEach(t),fio=r(_k," or "),xB=n(_k,"A",{href:!0});var Wrt=s(xB);mio=r(Wrt,"LEDTokenizerFast"),Wrt.forEach(t),gio=r(_k," (LED model)"),_k.forEach(t),hio=i(S),gs=n(S,"LI",{});var bk=s(gs);pse=n(bk,"STRONG",{});var Qrt=s(pse);pio=r(Qrt,"longformer"),Qrt.forEach(t),uio=r(bk," \u2014 "),$B=n(bk,"A",{href:!0});var Hrt=s($B);_io=r(Hrt,"LongformerTokenizer"),Hrt.forEach(t),bio=r(bk," or "),kB=n(bk,"A",{href:!0});var Urt=s(kB);vio=r(Urt,"LongformerTokenizerFast"),Urt.forEach(t),Fio=r(bk," (Longformer model)"),bk.forEach(t),Tio=i(S),hs=n(S,"LI",{});var vk=s(hs);use=n(vk,"STRONG",{});var Jrt=s(use);Mio=r(Jrt,"longt5"),Jrt.forEach(t),Eio=r(vk," \u2014 "),SB=n(vk,"A",{href:!0});var Yrt=s(SB);Cio=r(Yrt,"T5Tokenizer"),Yrt.forEach(t),wio=r(vk," or "),RB=n(vk,"A",{href:!0});var Krt=s(RB);Aio=r(Krt,"T5TokenizerFast"),Krt.forEach(t),Lio=r(vk," (LongT5 model)"),vk.forEach(t),yio=i(S),th=n(S,"LI",{});var FLe=s(th);_se=n(FLe,"STRONG",{});var Zrt=s(_se);xio=r(Zrt,"luke"),Zrt.forEach(t),$io=r(FLe," \u2014 "),PB=n(FLe,"A",{href:!0});var ett=s(PB);kio=r(ett,"LukeTokenizer"),ett.forEach(t),Sio=r(FLe," (LUKE model)"),FLe.forEach(t),Rio=i(S),ps=n(S,"LI",{});var Fk=s(ps);bse=n(Fk,"STRONG",{});var ott=s(bse);Pio=r(ott,"lxmert"),ott.forEach(t),Bio=r(Fk," \u2014 "),BB=n(Fk,"A",{href:!0});var rtt=s(BB);Iio=r(rtt,"LxmertTokenizer"),rtt.forEach(t),Nio=r(Fk," or "),IB=n(Fk,"A",{href:!0});var ttt=s(IB);qio=r(ttt,"LxmertTokenizerFast"),ttt.forEach(t),jio=r(Fk," (LXMERT model)"),Fk.forEach(t),Dio=i(S),ah=n(S,"LI",{});var TLe=s(ah);vse=n(TLe,"STRONG",{});var att=s(vse);Gio=r(att,"m2m_100"),att.forEach(t),Oio=r(TLe," \u2014 "),NB=n(TLe,"A",{href:!0});var ntt=s(NB);Vio=r(ntt,"M2M100Tokenizer"),ntt.forEach(t),Xio=r(TLe," (M2M100 model)"),TLe.forEach(t),zio=i(S),nh=n(S,"LI",{});var MLe=s(nh);Fse=n(MLe,"STRONG",{});var stt=s(Fse);Wio=r(stt,"marian"),stt.forEach(t),Qio=r(MLe," \u2014 "),qB=n(MLe,"A",{href:!0});var ltt=s(qB);Hio=r(ltt,"MarianTokenizer"),ltt.forEach(t),Uio=r(MLe," (Marian model)"),MLe.forEach(t),Jio=i(S),us=n(S,"LI",{});var Tk=s(us);Tse=n(Tk,"STRONG",{});var itt=s(Tse);Yio=r(itt,"mbart"),itt.forEach(t),Kio=r(Tk," \u2014 "),jB=n(Tk,"A",{href:!0});var dtt=s(jB);Zio=r(dtt,"MBartTokenizer"),dtt.forEach(t),edo=r(Tk," or "),DB=n(Tk,"A",{href:!0});var ctt=s(DB);odo=r(ctt,"MBartTokenizerFast"),ctt.forEach(t),rdo=r(Tk," (mBART model)"),Tk.forEach(t),tdo=i(S),_s=n(S,"LI",{});var Mk=s(_s);Mse=n(Mk,"STRONG",{});var ftt=s(Mse);ado=r(ftt,"mbart50"),ftt.forEach(t),ndo=r(Mk," \u2014 "),GB=n(Mk,"A",{href:!0});var mtt=s(GB);sdo=r(mtt,"MBart50Tokenizer"),mtt.forEach(t),ldo=r(Mk," or "),OB=n(Mk,"A",{href:!0});var gtt=s(OB);ido=r(gtt,"MBart50TokenizerFast"),gtt.forEach(t),ddo=r(Mk," (mBART-50 model)"),Mk.forEach(t),cdo=i(S),bs=n(S,"LI",{});var Ek=s(bs);Ese=n(Ek,"STRONG",{});var htt=s(Ese);fdo=r(htt,"megatron-bert"),htt.forEach(t),mdo=r(Ek," \u2014 "),VB=n(Ek,"A",{href:!0});var ptt=s(VB);gdo=r(ptt,"BertTokenizer"),ptt.forEach(t),hdo=r(Ek," or "),XB=n(Ek,"A",{href:!0});var utt=s(XB);pdo=r(utt,"BertTokenizerFast"),utt.forEach(t),udo=r(Ek," (Megatron-BERT model)"),Ek.forEach(t),_do=i(S),sh=n(S,"LI",{});var ELe=s(sh);Cse=n(ELe,"STRONG",{});var _tt=s(Cse);bdo=r(_tt,"mluke"),_tt.forEach(t),vdo=r(ELe," \u2014 "),zB=n(ELe,"A",{href:!0});var btt=s(zB);Fdo=r(btt,"MLukeTokenizer"),btt.forEach(t),Tdo=r(ELe," (mLUKE model)"),ELe.forEach(t),Mdo=i(S),vs=n(S,"LI",{});var Ck=s(vs);wse=n(Ck,"STRONG",{});var vtt=s(wse);Edo=r(vtt,"mobilebert"),vtt.forEach(t),Cdo=r(Ck," \u2014 "),WB=n(Ck,"A",{href:!0});var Ftt=s(WB);wdo=r(Ftt,"MobileBertTokenizer"),Ftt.forEach(t),Ado=r(Ck," or "),QB=n(Ck,"A",{href:!0});var Ttt=s(QB);Ldo=r(Ttt,"MobileBertTokenizerFast"),Ttt.forEach(t),ydo=r(Ck," (MobileBERT model)"),Ck.forEach(t),xdo=i(S),Fs=n(S,"LI",{});var wk=s(Fs);Ase=n(wk,"STRONG",{});var Mtt=s(Ase);$do=r(Mtt,"mpnet"),Mtt.forEach(t),kdo=r(wk," \u2014 "),HB=n(wk,"A",{href:!0});var Ett=s(HB);Sdo=r(Ett,"MPNetTokenizer"),Ett.forEach(t),Rdo=r(wk," or "),UB=n(wk,"A",{href:!0});var Ctt=s(UB);Pdo=r(Ctt,"MPNetTokenizerFast"),Ctt.forEach(t),Bdo=r(wk," (MPNet model)"),wk.forEach(t),Ido=i(S),Ts=n(S,"LI",{});var Ak=s(Ts);Lse=n(Ak,"STRONG",{});var wtt=s(Lse);Ndo=r(wtt,"mt5"),wtt.forEach(t),qdo=r(Ak," \u2014 "),JB=n(Ak,"A",{href:!0});var Att=s(JB);jdo=r(Att,"MT5Tokenizer"),Att.forEach(t),Ddo=r(Ak," or "),YB=n(Ak,"A",{href:!0});var Ltt=s(YB);Gdo=r(Ltt,"MT5TokenizerFast"),Ltt.forEach(t),Odo=r(Ak," (MT5 model)"),Ak.forEach(t),Vdo=i(S),Ms=n(S,"LI",{});var Lk=s(Ms);yse=n(Lk,"STRONG",{});var ytt=s(yse);Xdo=r(ytt,"nystromformer"),ytt.forEach(t),zdo=r(Lk," \u2014 "),KB=n(Lk,"A",{href:!0});var xtt=s(KB);Wdo=r(xtt,"AlbertTokenizer"),xtt.forEach(t),Qdo=r(Lk," or "),ZB=n(Lk,"A",{href:!0});var $tt=s(ZB);Hdo=r($tt,"AlbertTokenizerFast"),$tt.forEach(t),Udo=r(Lk," (Nystr\xF6mformer model)"),Lk.forEach(t),Jdo=i(S),Es=n(S,"LI",{});var yk=s(Es);xse=n(yk,"STRONG",{});var ktt=s(xse);Ydo=r(ktt,"openai-gpt"),ktt.forEach(t),Kdo=r(yk," \u2014 "),eI=n(yk,"A",{href:!0});var Stt=s(eI);Zdo=r(Stt,"OpenAIGPTTokenizer"),Stt.forEach(t),eco=r(yk," or "),oI=n(yk,"A",{href:!0});var Rtt=s(oI);oco=r(Rtt,"OpenAIGPTTokenizerFast"),Rtt.forEach(t),rco=r(yk," (OpenAI GPT model)"),yk.forEach(t),tco=i(S),lh=n(S,"LI",{});var CLe=s(lh);$se=n(CLe,"STRONG",{});var Ptt=s($se);aco=r(Ptt,"opt"),Ptt.forEach(t),nco=r(CLe," \u2014 "),rI=n(CLe,"A",{href:!0});var Btt=s(rI);sco=r(Btt,"GPT2Tokenizer"),Btt.forEach(t),lco=r(CLe," (OPT model)"),CLe.forEach(t),ico=i(S),Cs=n(S,"LI",{});var xk=s(Cs);kse=n(xk,"STRONG",{});var Itt=s(kse);dco=r(Itt,"pegasus"),Itt.forEach(t),cco=r(xk," \u2014 "),tI=n(xk,"A",{href:!0});var Ntt=s(tI);fco=r(Ntt,"PegasusTokenizer"),Ntt.forEach(t),mco=r(xk," or "),aI=n(xk,"A",{href:!0});var qtt=s(aI);gco=r(qtt,"PegasusTokenizerFast"),qtt.forEach(t),hco=r(xk," (Pegasus model)"),xk.forEach(t),pco=i(S),ih=n(S,"LI",{});var wLe=s(ih);Sse=n(wLe,"STRONG",{});var jtt=s(Sse);uco=r(jtt,"perceiver"),jtt.forEach(t),_co=r(wLe," \u2014 "),nI=n(wLe,"A",{href:!0});var Dtt=s(nI);bco=r(Dtt,"PerceiverTokenizer"),Dtt.forEach(t),vco=r(wLe," (Perceiver model)"),wLe.forEach(t),Fco=i(S),dh=n(S,"LI",{});var ALe=s(dh);Rse=n(ALe,"STRONG",{});var Gtt=s(Rse);Tco=r(Gtt,"phobert"),Gtt.forEach(t),Mco=r(ALe," \u2014 "),sI=n(ALe,"A",{href:!0});var Ott=s(sI);Eco=r(Ott,"PhobertTokenizer"),Ott.forEach(t),Cco=r(ALe," (PhoBERT model)"),ALe.forEach(t),wco=i(S),ch=n(S,"LI",{});var LLe=s(ch);Pse=n(LLe,"STRONG",{});var Vtt=s(Pse);Aco=r(Vtt,"plbart"),Vtt.forEach(t),Lco=r(LLe," \u2014 "),lI=n(LLe,"A",{href:!0});var Xtt=s(lI);yco=r(Xtt,"PLBartTokenizer"),Xtt.forEach(t),xco=r(LLe," (PLBart model)"),LLe.forEach(t),$co=i(S),fh=n(S,"LI",{});var yLe=s(fh);Bse=n(yLe,"STRONG",{});var ztt=s(Bse);kco=r(ztt,"prophetnet"),ztt.forEach(t),Sco=r(yLe," \u2014 "),iI=n(yLe,"A",{href:!0});var Wtt=s(iI);Rco=r(Wtt,"ProphetNetTokenizer"),Wtt.forEach(t),Pco=r(yLe," (ProphetNet model)"),yLe.forEach(t),Bco=i(S),ws=n(S,"LI",{});var $k=s(ws);Ise=n($k,"STRONG",{});var Qtt=s(Ise);Ico=r(Qtt,"qdqbert"),Qtt.forEach(t),Nco=r($k," \u2014 "),dI=n($k,"A",{href:!0});var Htt=s(dI);qco=r(Htt,"BertTokenizer"),Htt.forEach(t),jco=r($k," or "),cI=n($k,"A",{href:!0});var Utt=s(cI);Dco=r(Utt,"BertTokenizerFast"),Utt.forEach(t),Gco=r($k," (QDQBert model)"),$k.forEach(t),Oco=i(S),mh=n(S,"LI",{});var xLe=s(mh);Nse=n(xLe,"STRONG",{});var Jtt=s(Nse);Vco=r(Jtt,"rag"),Jtt.forEach(t),Xco=r(xLe," \u2014 "),fI=n(xLe,"A",{href:!0});var Ytt=s(fI);zco=r(Ytt,"RagTokenizer"),Ytt.forEach(t),Wco=r(xLe," (RAG model)"),xLe.forEach(t),Qco=i(S),As=n(S,"LI",{});var kk=s(As);qse=n(kk,"STRONG",{});var Ktt=s(qse);Hco=r(Ktt,"realm"),Ktt.forEach(t),Uco=r(kk," \u2014 "),mI=n(kk,"A",{href:!0});var Ztt=s(mI);Jco=r(Ztt,"RealmTokenizer"),Ztt.forEach(t),Yco=r(kk," or "),gI=n(kk,"A",{href:!0});var eat=s(gI);Kco=r(eat,"RealmTokenizerFast"),eat.forEach(t),Zco=r(kk," (REALM model)"),kk.forEach(t),efo=i(S),Ls=n(S,"LI",{});var Sk=s(Ls);jse=n(Sk,"STRONG",{});var oat=s(jse);ofo=r(oat,"reformer"),oat.forEach(t),rfo=r(Sk," \u2014 "),hI=n(Sk,"A",{href:!0});var rat=s(hI);tfo=r(rat,"ReformerTokenizer"),rat.forEach(t),afo=r(Sk," or "),pI=n(Sk,"A",{href:!0});var tat=s(pI);nfo=r(tat,"ReformerTokenizerFast"),tat.forEach(t),sfo=r(Sk," (Reformer model)"),Sk.forEach(t),lfo=i(S),ys=n(S,"LI",{});var Rk=s(ys);Dse=n(Rk,"STRONG",{});var aat=s(Dse);ifo=r(aat,"rembert"),aat.forEach(t),dfo=r(Rk," \u2014 "),uI=n(Rk,"A",{href:!0});var nat=s(uI);cfo=r(nat,"RemBertTokenizer"),nat.forEach(t),ffo=r(Rk," or "),_I=n(Rk,"A",{href:!0});var sat=s(_I);mfo=r(sat,"RemBertTokenizerFast"),sat.forEach(t),gfo=r(Rk," (RemBERT model)"),Rk.forEach(t),hfo=i(S),xs=n(S,"LI",{});var Pk=s(xs);Gse=n(Pk,"STRONG",{});var lat=s(Gse);pfo=r(lat,"retribert"),lat.forEach(t),ufo=r(Pk," \u2014 "),bI=n(Pk,"A",{href:!0});var iat=s(bI);_fo=r(iat,"RetriBertTokenizer"),iat.forEach(t),bfo=r(Pk," or "),vI=n(Pk,"A",{href:!0});var dat=s(vI);vfo=r(dat,"RetriBertTokenizerFast"),dat.forEach(t),Ffo=r(Pk," (RetriBERT model)"),Pk.forEach(t),Tfo=i(S),$s=n(S,"LI",{});var Bk=s($s);Ose=n(Bk,"STRONG",{});var cat=s(Ose);Mfo=r(cat,"roberta"),cat.forEach(t),Efo=r(Bk," \u2014 "),FI=n(Bk,"A",{href:!0});var fat=s(FI);Cfo=r(fat,"RobertaTokenizer"),fat.forEach(t),wfo=r(Bk," or "),TI=n(Bk,"A",{href:!0});var mat=s(TI);Afo=r(mat,"RobertaTokenizerFast"),mat.forEach(t),Lfo=r(Bk," (RoBERTa model)"),Bk.forEach(t),yfo=i(S),ks=n(S,"LI",{});var Ik=s(ks);Vse=n(Ik,"STRONG",{});var gat=s(Vse);xfo=r(gat,"roformer"),gat.forEach(t),$fo=r(Ik," \u2014 "),MI=n(Ik,"A",{href:!0});var hat=s(MI);kfo=r(hat,"RoFormerTokenizer"),hat.forEach(t),Sfo=r(Ik," or "),EI=n(Ik,"A",{href:!0});var pat=s(EI);Rfo=r(pat,"RoFormerTokenizerFast"),pat.forEach(t),Pfo=r(Ik," (RoFormer model)"),Ik.forEach(t),Bfo=i(S),gh=n(S,"LI",{});var $Le=s(gh);Xse=n($Le,"STRONG",{});var uat=s(Xse);Ifo=r(uat,"speech_to_text"),uat.forEach(t),Nfo=r($Le," \u2014 "),CI=n($Le,"A",{href:!0});var _at=s(CI);qfo=r(_at,"Speech2TextTokenizer"),_at.forEach(t),jfo=r($Le," (Speech2Text model)"),$Le.forEach(t),Dfo=i(S),hh=n(S,"LI",{});var kLe=s(hh);zse=n(kLe,"STRONG",{});var bat=s(zse);Gfo=r(bat,"speech_to_text_2"),bat.forEach(t),Ofo=r(kLe," \u2014 "),wI=n(kLe,"A",{href:!0});var vat=s(wI);Vfo=r(vat,"Speech2Text2Tokenizer"),vat.forEach(t),Xfo=r(kLe," (Speech2Text2 model)"),kLe.forEach(t),zfo=i(S),Ss=n(S,"LI",{});var Nk=s(Ss);Wse=n(Nk,"STRONG",{});var Fat=s(Wse);Wfo=r(Fat,"splinter"),Fat.forEach(t),Qfo=r(Nk," \u2014 "),AI=n(Nk,"A",{href:!0});var Tat=s(AI);Hfo=r(Tat,"SplinterTokenizer"),Tat.forEach(t),Ufo=r(Nk," or "),LI=n(Nk,"A",{href:!0});var Mat=s(LI);Jfo=r(Mat,"SplinterTokenizerFast"),Mat.forEach(t),Yfo=r(Nk," (Splinter model)"),Nk.forEach(t),Kfo=i(S),Rs=n(S,"LI",{});var qk=s(Rs);Qse=n(qk,"STRONG",{});var Eat=s(Qse);Zfo=r(Eat,"squeezebert"),Eat.forEach(t),emo=r(qk," \u2014 "),yI=n(qk,"A",{href:!0});var Cat=s(yI);omo=r(Cat,"SqueezeBertTokenizer"),Cat.forEach(t),rmo=r(qk," or "),xI=n(qk,"A",{href:!0});var wat=s(xI);tmo=r(wat,"SqueezeBertTokenizerFast"),wat.forEach(t),amo=r(qk," (SqueezeBERT model)"),qk.forEach(t),nmo=i(S),Ps=n(S,"LI",{});var jk=s(Ps);Hse=n(jk,"STRONG",{});var Aat=s(Hse);smo=r(Aat,"t5"),Aat.forEach(t),lmo=r(jk," \u2014 "),$I=n(jk,"A",{href:!0});var Lat=s($I);imo=r(Lat,"T5Tokenizer"),Lat.forEach(t),dmo=r(jk," or "),kI=n(jk,"A",{href:!0});var yat=s(kI);cmo=r(yat,"T5TokenizerFast"),yat.forEach(t),fmo=r(jk," (T5 model)"),jk.forEach(t),mmo=i(S),ph=n(S,"LI",{});var SLe=s(ph);Use=n(SLe,"STRONG",{});var xat=s(Use);gmo=r(xat,"tapas"),xat.forEach(t),hmo=r(SLe," \u2014 "),SI=n(SLe,"A",{href:!0});var $at=s(SI);pmo=r($at,"TapasTokenizer"),$at.forEach(t),umo=r(SLe," (TAPAS model)"),SLe.forEach(t),_mo=i(S),uh=n(S,"LI",{});var RLe=s(uh);Jse=n(RLe,"STRONG",{});var kat=s(Jse);bmo=r(kat,"tapex"),kat.forEach(t),vmo=r(RLe," \u2014 "),RI=n(RLe,"A",{href:!0});var Sat=s(RI);Fmo=r(Sat,"TapexTokenizer"),Sat.forEach(t),Tmo=r(RLe," (TAPEX model)"),RLe.forEach(t),Mmo=i(S),_h=n(S,"LI",{});var PLe=s(_h);Yse=n(PLe,"STRONG",{});var Rat=s(Yse);Emo=r(Rat,"transfo-xl"),Rat.forEach(t),Cmo=r(PLe," \u2014 "),PI=n(PLe,"A",{href:!0});var Pat=s(PI);wmo=r(Pat,"TransfoXLTokenizer"),Pat.forEach(t),Amo=r(PLe," (Transformer-XL model)"),PLe.forEach(t),Lmo=i(S),Bs=n(S,"LI",{});var Dk=s(Bs);Kse=n(Dk,"STRONG",{});var Bat=s(Kse);ymo=r(Bat,"vilt"),Bat.forEach(t),xmo=r(Dk," \u2014 "),BI=n(Dk,"A",{href:!0});var Iat=s(BI);$mo=r(Iat,"BertTokenizer"),Iat.forEach(t),kmo=r(Dk," or "),II=n(Dk,"A",{href:!0});var Nat=s(II);Smo=r(Nat,"BertTokenizerFast"),Nat.forEach(t),Rmo=r(Dk," (ViLT model)"),Dk.forEach(t),Pmo=i(S),Is=n(S,"LI",{});var Gk=s(Is);Zse=n(Gk,"STRONG",{});var qat=s(Zse);Bmo=r(qat,"visual_bert"),qat.forEach(t),Imo=r(Gk," \u2014 "),NI=n(Gk,"A",{href:!0});var jat=s(NI);Nmo=r(jat,"BertTokenizer"),jat.forEach(t),qmo=r(Gk," or "),qI=n(Gk,"A",{href:!0});var Dat=s(qI);jmo=r(Dat,"BertTokenizerFast"),Dat.forEach(t),Dmo=r(Gk," (VisualBERT model)"),Gk.forEach(t),Gmo=i(S),bh=n(S,"LI",{});var BLe=s(bh);ele=n(BLe,"STRONG",{});var Gat=s(ele);Omo=r(Gat,"wav2vec2"),Gat.forEach(t),Vmo=r(BLe," \u2014 "),jI=n(BLe,"A",{href:!0});var Oat=s(jI);Xmo=r(Oat,"Wav2Vec2CTCTokenizer"),Oat.forEach(t),zmo=r(BLe," (Wav2Vec2 model)"),BLe.forEach(t),Wmo=i(S),vh=n(S,"LI",{});var ILe=s(vh);ole=n(ILe,"STRONG",{});var Vat=s(ole);Qmo=r(Vat,"wav2vec2-conformer"),Vat.forEach(t),Hmo=r(ILe," \u2014 "),DI=n(ILe,"A",{href:!0});var Xat=s(DI);Umo=r(Xat,"Wav2Vec2CTCTokenizer"),Xat.forEach(t),Jmo=r(ILe," (Wav2Vec2-Conformer model)"),ILe.forEach(t),Ymo=i(S),Fh=n(S,"LI",{});var NLe=s(Fh);rle=n(NLe,"STRONG",{});var zat=s(rle);Kmo=r(zat,"wav2vec2_phoneme"),zat.forEach(t),Zmo=r(NLe," \u2014 "),GI=n(NLe,"A",{href:!0});var Wat=s(GI);ego=r(Wat,"Wav2Vec2PhonemeCTCTokenizer"),Wat.forEach(t),ogo=r(NLe," (Wav2Vec2Phoneme model)"),NLe.forEach(t),rgo=i(S),Ns=n(S,"LI",{});var Ok=s(Ns);tle=n(Ok,"STRONG",{});var Qat=s(tle);tgo=r(Qat,"xglm"),Qat.forEach(t),ago=r(Ok," \u2014 "),OI=n(Ok,"A",{href:!0});var Hat=s(OI);ngo=r(Hat,"XGLMTokenizer"),Hat.forEach(t),sgo=r(Ok," or "),VI=n(Ok,"A",{href:!0});var Uat=s(VI);lgo=r(Uat,"XGLMTokenizerFast"),Uat.forEach(t),igo=r(Ok," (XGLM model)"),Ok.forEach(t),dgo=i(S),Th=n(S,"LI",{});var qLe=s(Th);ale=n(qLe,"STRONG",{});var Jat=s(ale);cgo=r(Jat,"xlm"),Jat.forEach(t),fgo=r(qLe," \u2014 "),XI=n(qLe,"A",{href:!0});var Yat=s(XI);mgo=r(Yat,"XLMTokenizer"),Yat.forEach(t),ggo=r(qLe," (XLM model)"),qLe.forEach(t),hgo=i(S),Mh=n(S,"LI",{});var jLe=s(Mh);nle=n(jLe,"STRONG",{});var Kat=s(nle);pgo=r(Kat,"xlm-prophetnet"),Kat.forEach(t),ugo=r(jLe," \u2014 "),zI=n(jLe,"A",{href:!0});var Zat=s(zI);_go=r(Zat,"XLMProphetNetTokenizer"),Zat.forEach(t),bgo=r(jLe," (XLM-ProphetNet model)"),jLe.forEach(t),vgo=i(S),qs=n(S,"LI",{});var Vk=s(qs);sle=n(Vk,"STRONG",{});var ent=s(sle);Fgo=r(ent,"xlm-roberta"),ent.forEach(t),Tgo=r(Vk," \u2014 "),WI=n(Vk,"A",{href:!0});var ont=s(WI);Mgo=r(ont,"XLMRobertaTokenizer"),ont.forEach(t),Ego=r(Vk," or "),QI=n(Vk,"A",{href:!0});var rnt=s(QI);Cgo=r(rnt,"XLMRobertaTokenizerFast"),rnt.forEach(t),wgo=r(Vk," (XLM-RoBERTa model)"),Vk.forEach(t),Ago=i(S),js=n(S,"LI",{});var Xk=s(js);lle=n(Xk,"STRONG",{});var tnt=s(lle);Lgo=r(tnt,"xlm-roberta-xl"),tnt.forEach(t),ygo=r(Xk," \u2014 "),HI=n(Xk,"A",{href:!0});var ant=s(HI);xgo=r(ant,"RobertaTokenizer"),ant.forEach(t),$go=r(Xk," or "),UI=n(Xk,"A",{href:!0});var nnt=s(UI);kgo=r(nnt,"RobertaTokenizerFast"),nnt.forEach(t),Sgo=r(Xk," (XLM-RoBERTa-XL model)"),Xk.forEach(t),Rgo=i(S),Ds=n(S,"LI",{});var zk=s(Ds);ile=n(zk,"STRONG",{});var snt=s(ile);Pgo=r(snt,"xlnet"),snt.forEach(t),Bgo=r(zk," \u2014 "),JI=n(zk,"A",{href:!0});var lnt=s(JI);Igo=r(lnt,"XLNetTokenizer"),lnt.forEach(t),Ngo=r(zk," or "),YI=n(zk,"A",{href:!0});var int=s(YI);qgo=r(int,"XLNetTokenizerFast"),int.forEach(t),jgo=r(zk," (XLNet model)"),zk.forEach(t),Dgo=i(S),Gs=n(S,"LI",{});var Wk=s(Gs);dle=n(Wk,"STRONG",{});var dnt=s(dle);Ggo=r(dnt,"yoso"),dnt.forEach(t),Ogo=r(Wk," \u2014 "),KI=n(Wk,"A",{href:!0});var cnt=s(KI);Vgo=r(cnt,"AlbertTokenizer"),cnt.forEach(t),Xgo=r(Wk," or "),ZI=n(Wk,"A",{href:!0});var fnt=s(ZI);zgo=r(fnt,"AlbertTokenizerFast"),fnt.forEach(t),Wgo=r(Wk," (YOSO model)"),Wk.forEach(t),S.forEach(t),Qgo=i(Qs),T(Eh.$$.fragment,Qs),Qs.forEach(t),Hgo=i(Ws),Ch=n(Ws,"DIV",{class:!0});var xVe=s(Ch);T(NL.$$.fragment,xVe),Ugo=i(xVe),cle=n(xVe,"P",{});var mnt=s(cle);Jgo=r(mnt,"Register a new tokenizer in this mapping."),mnt.forEach(t),xVe.forEach(t),Ws.forEach(t),yGe=i(f),Si=n(f,"H2",{class:!0});var $Ve=s(Si);wh=n($Ve,"A",{id:!0,class:!0,href:!0});var gnt=s(wh);fle=n(gnt,"SPAN",{});var hnt=s(fle);T(qL.$$.fragment,hnt),hnt.forEach(t),gnt.forEach(t),Ygo=i($Ve),mle=n($Ve,"SPAN",{});var pnt=s(mle);Kgo=r(pnt,"AutoFeatureExtractor"),pnt.forEach(t),$Ve.forEach(t),xGe=i(f),Lo=n(f,"DIV",{class:!0});var Hs=s(Lo);T(jL.$$.fragment,Hs),Zgo=i(Hs),DL=n(Hs,"P",{});var kVe=s(DL);eho=r(kVe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),eN=n(kVe,"A",{href:!0});var unt=s(eN);oho=r(unt,"AutoFeatureExtractor.from_pretrained()"),unt.forEach(t),rho=r(kVe," class method."),kVe.forEach(t),tho=i(Hs),GL=n(Hs,"P",{});var SVe=s(GL);aho=r(SVe,"This class cannot be instantiated directly using "),gle=n(SVe,"CODE",{});var _nt=s(gle);nho=r(_nt,"__init__()"),_nt.forEach(t),sho=r(SVe," (throws an error)."),SVe.forEach(t),lho=i(Hs),He=n(Hs,"DIV",{class:!0});var ra=s(He);T(OL.$$.fragment,ra),iho=i(ra),hle=n(ra,"P",{});var bnt=s(hle);dho=r(bnt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),bnt.forEach(t),cho=i(ra),ka=n(ra,"P",{});var wA=s(ka);fho=r(wA,"The feature extractor class to instantiate is selected based on the "),ple=n(wA,"CODE",{});var vnt=s(ple);mho=r(vnt,"model_type"),vnt.forEach(t),gho=r(wA,` property of the config object
(either passed as an argument or loaded from `),ule=n(wA,"CODE",{});var Fnt=s(ule);hho=r(Fnt,"pretrained_model_name_or_path"),Fnt.forEach(t),pho=r(wA,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),_le=n(wA,"CODE",{});var Tnt=s(_le);uho=r(Tnt,"pretrained_model_name_or_path"),Tnt.forEach(t),_ho=r(wA,":"),wA.forEach(t),bho=i(ra),Y=n(ra,"UL",{});var K=s(Y);Ah=n(K,"LI",{});var DLe=s(Ah);ble=n(DLe,"STRONG",{});var Mnt=s(ble);vho=r(Mnt,"beit"),Mnt.forEach(t),Fho=r(DLe," \u2014 "),oN=n(DLe,"A",{href:!0});var Ent=s(oN);Tho=r(Ent,"BeitFeatureExtractor"),Ent.forEach(t),Mho=r(DLe," (BEiT model)"),DLe.forEach(t),Eho=i(K),Lh=n(K,"LI",{});var GLe=s(Lh);vle=n(GLe,"STRONG",{});var Cnt=s(vle);Cho=r(Cnt,"clip"),Cnt.forEach(t),who=r(GLe," \u2014 "),rN=n(GLe,"A",{href:!0});var wnt=s(rN);Aho=r(wnt,"CLIPFeatureExtractor"),wnt.forEach(t),Lho=r(GLe," (CLIP model)"),GLe.forEach(t),yho=i(K),yh=n(K,"LI",{});var OLe=s(yh);Fle=n(OLe,"STRONG",{});var Ant=s(Fle);xho=r(Ant,"convnext"),Ant.forEach(t),$ho=r(OLe," \u2014 "),tN=n(OLe,"A",{href:!0});var Lnt=s(tN);kho=r(Lnt,"ConvNextFeatureExtractor"),Lnt.forEach(t),Sho=r(OLe," (ConvNeXT model)"),OLe.forEach(t),Rho=i(K),xh=n(K,"LI",{});var VLe=s(xh);Tle=n(VLe,"STRONG",{});var ynt=s(Tle);Pho=r(ynt,"cvt"),ynt.forEach(t),Bho=r(VLe," \u2014 "),aN=n(VLe,"A",{href:!0});var xnt=s(aN);Iho=r(xnt,"ConvNextFeatureExtractor"),xnt.forEach(t),Nho=r(VLe," (CvT model)"),VLe.forEach(t),qho=i(K),$h=n(K,"LI",{});var XLe=s($h);Mle=n(XLe,"STRONG",{});var $nt=s(Mle);jho=r($nt,"data2vec-audio"),$nt.forEach(t),Dho=r(XLe," \u2014 "),nN=n(XLe,"A",{href:!0});var knt=s(nN);Gho=r(knt,"Wav2Vec2FeatureExtractor"),knt.forEach(t),Oho=r(XLe," (Data2VecAudio model)"),XLe.forEach(t),Vho=i(K),kh=n(K,"LI",{});var zLe=s(kh);Ele=n(zLe,"STRONG",{});var Snt=s(Ele);Xho=r(Snt,"data2vec-vision"),Snt.forEach(t),zho=r(zLe," \u2014 "),sN=n(zLe,"A",{href:!0});var Rnt=s(sN);Who=r(Rnt,"BeitFeatureExtractor"),Rnt.forEach(t),Qho=r(zLe," (Data2VecVision model)"),zLe.forEach(t),Hho=i(K),Sh=n(K,"LI",{});var WLe=s(Sh);Cle=n(WLe,"STRONG",{});var Pnt=s(Cle);Uho=r(Pnt,"deit"),Pnt.forEach(t),Jho=r(WLe," \u2014 "),lN=n(WLe,"A",{href:!0});var Bnt=s(lN);Yho=r(Bnt,"DeiTFeatureExtractor"),Bnt.forEach(t),Kho=r(WLe," (DeiT model)"),WLe.forEach(t),Zho=i(K),Rh=n(K,"LI",{});var QLe=s(Rh);wle=n(QLe,"STRONG",{});var Int=s(wle);epo=r(Int,"detr"),Int.forEach(t),opo=r(QLe," \u2014 "),iN=n(QLe,"A",{href:!0});var Nnt=s(iN);rpo=r(Nnt,"DetrFeatureExtractor"),Nnt.forEach(t),tpo=r(QLe," (DETR model)"),QLe.forEach(t),apo=i(K),Ph=n(K,"LI",{});var HLe=s(Ph);Ale=n(HLe,"STRONG",{});var qnt=s(Ale);npo=r(qnt,"dpt"),qnt.forEach(t),spo=r(HLe," \u2014 "),dN=n(HLe,"A",{href:!0});var jnt=s(dN);lpo=r(jnt,"DPTFeatureExtractor"),jnt.forEach(t),ipo=r(HLe," (DPT model)"),HLe.forEach(t),dpo=i(K),Bh=n(K,"LI",{});var ULe=s(Bh);Lle=n(ULe,"STRONG",{});var Dnt=s(Lle);cpo=r(Dnt,"flava"),Dnt.forEach(t),fpo=r(ULe," \u2014 "),cN=n(ULe,"A",{href:!0});var Gnt=s(cN);mpo=r(Gnt,"FlavaFeatureExtractor"),Gnt.forEach(t),gpo=r(ULe," (FLAVA model)"),ULe.forEach(t),hpo=i(K),Ih=n(K,"LI",{});var JLe=s(Ih);yle=n(JLe,"STRONG",{});var Ont=s(yle);ppo=r(Ont,"glpn"),Ont.forEach(t),upo=r(JLe," \u2014 "),fN=n(JLe,"A",{href:!0});var Vnt=s(fN);_po=r(Vnt,"GLPNFeatureExtractor"),Vnt.forEach(t),bpo=r(JLe," (GLPN model)"),JLe.forEach(t),vpo=i(K),Nh=n(K,"LI",{});var YLe=s(Nh);xle=n(YLe,"STRONG",{});var Xnt=s(xle);Fpo=r(Xnt,"groupvit"),Xnt.forEach(t),Tpo=r(YLe," \u2014 "),mN=n(YLe,"A",{href:!0});var znt=s(mN);Mpo=r(znt,"CLIPFeatureExtractor"),znt.forEach(t),Epo=r(YLe," (GroupViT model)"),YLe.forEach(t),Cpo=i(K),qh=n(K,"LI",{});var KLe=s(qh);$le=n(KLe,"STRONG",{});var Wnt=s($le);wpo=r(Wnt,"hubert"),Wnt.forEach(t),Apo=r(KLe," \u2014 "),gN=n(KLe,"A",{href:!0});var Qnt=s(gN);Lpo=r(Qnt,"Wav2Vec2FeatureExtractor"),Qnt.forEach(t),ypo=r(KLe," (Hubert model)"),KLe.forEach(t),xpo=i(K),jh=n(K,"LI",{});var ZLe=s(jh);kle=n(ZLe,"STRONG",{});var Hnt=s(kle);$po=r(Hnt,"imagegpt"),Hnt.forEach(t),kpo=r(ZLe," \u2014 "),hN=n(ZLe,"A",{href:!0});var Unt=s(hN);Spo=r(Unt,"ImageGPTFeatureExtractor"),Unt.forEach(t),Rpo=r(ZLe," (ImageGPT model)"),ZLe.forEach(t),Ppo=i(K),Dh=n(K,"LI",{});var eye=s(Dh);Sle=n(eye,"STRONG",{});var Jnt=s(Sle);Bpo=r(Jnt,"layoutlmv2"),Jnt.forEach(t),Ipo=r(eye," \u2014 "),pN=n(eye,"A",{href:!0});var Ynt=s(pN);Npo=r(Ynt,"LayoutLMv2FeatureExtractor"),Ynt.forEach(t),qpo=r(eye," (LayoutLMv2 model)"),eye.forEach(t),jpo=i(K),Gh=n(K,"LI",{});var oye=s(Gh);Rle=n(oye,"STRONG",{});var Knt=s(Rle);Dpo=r(Knt,"layoutlmv3"),Knt.forEach(t),Gpo=r(oye," \u2014 "),uN=n(oye,"A",{href:!0});var Znt=s(uN);Opo=r(Znt,"LayoutLMv3FeatureExtractor"),Znt.forEach(t),Vpo=r(oye," (LayoutLMv3 model)"),oye.forEach(t),Xpo=i(K),Oh=n(K,"LI",{});var rye=s(Oh);Ple=n(rye,"STRONG",{});var est=s(Ple);zpo=r(est,"levit"),est.forEach(t),Wpo=r(rye," \u2014 "),_N=n(rye,"A",{href:!0});var ost=s(_N);Qpo=r(ost,"LevitFeatureExtractor"),ost.forEach(t),Hpo=r(rye," (LeViT model)"),rye.forEach(t),Upo=i(K),Vh=n(K,"LI",{});var tye=s(Vh);Ble=n(tye,"STRONG",{});var rst=s(Ble);Jpo=r(rst,"maskformer"),rst.forEach(t),Ypo=r(tye," \u2014 "),bN=n(tye,"A",{href:!0});var tst=s(bN);Kpo=r(tst,"MaskFormerFeatureExtractor"),tst.forEach(t),Zpo=r(tye," (MaskFormer model)"),tye.forEach(t),euo=i(K),Xh=n(K,"LI",{});var aye=s(Xh);Ile=n(aye,"STRONG",{});var ast=s(Ile);ouo=r(ast,"mctct"),ast.forEach(t),ruo=r(aye," \u2014 "),vN=n(aye,"A",{href:!0});var nst=s(vN);tuo=r(nst,"MCTCTFeatureExtractor"),nst.forEach(t),auo=r(aye," (M-CTC-T model)"),aye.forEach(t),nuo=i(K),zh=n(K,"LI",{});var nye=s(zh);Nle=n(nye,"STRONG",{});var sst=s(Nle);suo=r(sst,"perceiver"),sst.forEach(t),luo=r(nye," \u2014 "),FN=n(nye,"A",{href:!0});var lst=s(FN);iuo=r(lst,"PerceiverFeatureExtractor"),lst.forEach(t),duo=r(nye," (Perceiver model)"),nye.forEach(t),cuo=i(K),Wh=n(K,"LI",{});var sye=s(Wh);qle=n(sye,"STRONG",{});var ist=s(qle);fuo=r(ist,"poolformer"),ist.forEach(t),muo=r(sye," \u2014 "),TN=n(sye,"A",{href:!0});var dst=s(TN);guo=r(dst,"PoolFormerFeatureExtractor"),dst.forEach(t),huo=r(sye," (PoolFormer model)"),sye.forEach(t),puo=i(K),Qh=n(K,"LI",{});var lye=s(Qh);jle=n(lye,"STRONG",{});var cst=s(jle);uuo=r(cst,"regnet"),cst.forEach(t),_uo=r(lye," \u2014 "),MN=n(lye,"A",{href:!0});var fst=s(MN);buo=r(fst,"ConvNextFeatureExtractor"),fst.forEach(t),vuo=r(lye," (RegNet model)"),lye.forEach(t),Fuo=i(K),Hh=n(K,"LI",{});var iye=s(Hh);Dle=n(iye,"STRONG",{});var mst=s(Dle);Tuo=r(mst,"resnet"),mst.forEach(t),Muo=r(iye," \u2014 "),EN=n(iye,"A",{href:!0});var gst=s(EN);Euo=r(gst,"ConvNextFeatureExtractor"),gst.forEach(t),Cuo=r(iye," (ResNet model)"),iye.forEach(t),wuo=i(K),Uh=n(K,"LI",{});var dye=s(Uh);Gle=n(dye,"STRONG",{});var hst=s(Gle);Auo=r(hst,"segformer"),hst.forEach(t),Luo=r(dye," \u2014 "),CN=n(dye,"A",{href:!0});var pst=s(CN);yuo=r(pst,"SegformerFeatureExtractor"),pst.forEach(t),xuo=r(dye," (SegFormer model)"),dye.forEach(t),$uo=i(K),Jh=n(K,"LI",{});var cye=s(Jh);Ole=n(cye,"STRONG",{});var ust=s(Ole);kuo=r(ust,"speech_to_text"),ust.forEach(t),Suo=r(cye," \u2014 "),wN=n(cye,"A",{href:!0});var _st=s(wN);Ruo=r(_st,"Speech2TextFeatureExtractor"),_st.forEach(t),Puo=r(cye," (Speech2Text model)"),cye.forEach(t),Buo=i(K),Yh=n(K,"LI",{});var fye=s(Yh);Vle=n(fye,"STRONG",{});var bst=s(Vle);Iuo=r(bst,"swin"),bst.forEach(t),Nuo=r(fye," \u2014 "),AN=n(fye,"A",{href:!0});var vst=s(AN);quo=r(vst,"ViTFeatureExtractor"),vst.forEach(t),juo=r(fye," (Swin Transformer model)"),fye.forEach(t),Duo=i(K),Kh=n(K,"LI",{});var mye=s(Kh);Xle=n(mye,"STRONG",{});var Fst=s(Xle);Guo=r(Fst,"van"),Fst.forEach(t),Ouo=r(mye," \u2014 "),LN=n(mye,"A",{href:!0});var Tst=s(LN);Vuo=r(Tst,"ConvNextFeatureExtractor"),Tst.forEach(t),Xuo=r(mye," (VAN model)"),mye.forEach(t),zuo=i(K),Zh=n(K,"LI",{});var gye=s(Zh);zle=n(gye,"STRONG",{});var Mst=s(zle);Wuo=r(Mst,"vilt"),Mst.forEach(t),Quo=r(gye," \u2014 "),yN=n(gye,"A",{href:!0});var Est=s(yN);Huo=r(Est,"ViltFeatureExtractor"),Est.forEach(t),Uuo=r(gye," (ViLT model)"),gye.forEach(t),Juo=i(K),ep=n(K,"LI",{});var hye=s(ep);Wle=n(hye,"STRONG",{});var Cst=s(Wle);Yuo=r(Cst,"vit"),Cst.forEach(t),Kuo=r(hye," \u2014 "),xN=n(hye,"A",{href:!0});var wst=s(xN);Zuo=r(wst,"ViTFeatureExtractor"),wst.forEach(t),e_o=r(hye," (ViT model)"),hye.forEach(t),o_o=i(K),op=n(K,"LI",{});var pye=s(op);Qle=n(pye,"STRONG",{});var Ast=s(Qle);r_o=r(Ast,"vit_mae"),Ast.forEach(t),t_o=r(pye," \u2014 "),$N=n(pye,"A",{href:!0});var Lst=s($N);a_o=r(Lst,"ViTFeatureExtractor"),Lst.forEach(t),n_o=r(pye," (ViTMAE model)"),pye.forEach(t),s_o=i(K),rp=n(K,"LI",{});var uye=s(rp);Hle=n(uye,"STRONG",{});var yst=s(Hle);l_o=r(yst,"wav2vec2"),yst.forEach(t),i_o=r(uye," \u2014 "),kN=n(uye,"A",{href:!0});var xst=s(kN);d_o=r(xst,"Wav2Vec2FeatureExtractor"),xst.forEach(t),c_o=r(uye," (Wav2Vec2 model)"),uye.forEach(t),f_o=i(K),tp=n(K,"LI",{});var _ye=s(tp);Ule=n(_ye,"STRONG",{});var $st=s(Ule);m_o=r($st,"wav2vec2-conformer"),$st.forEach(t),g_o=r(_ye," \u2014 "),SN=n(_ye,"A",{href:!0});var kst=s(SN);h_o=r(kst,"Wav2Vec2FeatureExtractor"),kst.forEach(t),p_o=r(_ye," (Wav2Vec2-Conformer model)"),_ye.forEach(t),u_o=i(K),ap=n(K,"LI",{});var bye=s(ap);Jle=n(bye,"STRONG",{});var Sst=s(Jle);__o=r(Sst,"yolos"),Sst.forEach(t),b_o=r(bye," \u2014 "),RN=n(bye,"A",{href:!0});var Rst=s(RN);v_o=r(Rst,"YolosFeatureExtractor"),Rst.forEach(t),F_o=r(bye," (YOLOS model)"),bye.forEach(t),K.forEach(t),T_o=i(ra),T(np.$$.fragment,ra),M_o=i(ra),T(sp.$$.fragment,ra),ra.forEach(t),E_o=i(Hs),lp=n(Hs,"DIV",{class:!0});var RVe=s(lp);T(VL.$$.fragment,RVe),C_o=i(RVe),Yle=n(RVe,"P",{});var Pst=s(Yle);w_o=r(Pst,"Register a new feature extractor for this class."),Pst.forEach(t),RVe.forEach(t),Hs.forEach(t),$Ge=i(f),Ri=n(f,"H2",{class:!0});var PVe=s(Ri);ip=n(PVe,"A",{id:!0,class:!0,href:!0});var Bst=s(ip);Kle=n(Bst,"SPAN",{});var Ist=s(Kle);T(XL.$$.fragment,Ist),Ist.forEach(t),Bst.forEach(t),A_o=i(PVe),Zle=n(PVe,"SPAN",{});var Nst=s(Zle);L_o=r(Nst,"AutoProcessor"),Nst.forEach(t),PVe.forEach(t),kGe=i(f),yo=n(f,"DIV",{class:!0});var Us=s(yo);T(zL.$$.fragment,Us),y_o=i(Us),WL=n(Us,"P",{});var BVe=s(WL);x_o=r(BVe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),PN=n(BVe,"A",{href:!0});var qst=s(PN);$_o=r(qst,"AutoProcessor.from_pretrained()"),qst.forEach(t),k_o=r(BVe," class method."),BVe.forEach(t),S_o=i(Us),QL=n(Us,"P",{});var IVe=s(QL);R_o=r(IVe,"This class cannot be instantiated directly using "),eie=n(IVe,"CODE",{});var jst=s(eie);P_o=r(jst,"__init__()"),jst.forEach(t),B_o=r(IVe," (throws an error)."),IVe.forEach(t),I_o=i(Us),Ue=n(Us,"DIV",{class:!0});var ta=s(Ue);T(HL.$$.fragment,ta),N_o=i(ta),oie=n(ta,"P",{});var Dst=s(oie);q_o=r(Dst,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Dst.forEach(t),j_o=i(ta),Pi=n(ta,"P",{});var ioe=s(Pi);D_o=r(ioe,"The processor class to instantiate is selected based on the "),rie=n(ioe,"CODE",{});var Gst=s(rie);G_o=r(Gst,"model_type"),Gst.forEach(t),O_o=r(ioe,` property of the config object (either
passed as an argument or loaded from `),tie=n(ioe,"CODE",{});var Ost=s(tie);V_o=r(Ost,"pretrained_model_name_or_path"),Ost.forEach(t),X_o=r(ioe," if possible):"),ioe.forEach(t),z_o=i(ta),he=n(ta,"UL",{});var _e=s(he);dp=n(_e,"LI",{});var vye=s(dp);aie=n(vye,"STRONG",{});var Vst=s(aie);W_o=r(Vst,"clip"),Vst.forEach(t),Q_o=r(vye," \u2014 "),BN=n(vye,"A",{href:!0});var Xst=s(BN);H_o=r(Xst,"CLIPProcessor"),Xst.forEach(t),U_o=r(vye," (CLIP model)"),vye.forEach(t),J_o=i(_e),cp=n(_e,"LI",{});var Fye=s(cp);nie=n(Fye,"STRONG",{});var zst=s(nie);Y_o=r(zst,"flava"),zst.forEach(t),K_o=r(Fye," \u2014 "),sie=n(Fye,"CODE",{});var Wst=s(sie);Z_o=r(Wst,"FLAVAProcessor"),Wst.forEach(t),e1o=r(Fye," (FLAVA model)"),Fye.forEach(t),o1o=i(_e),fp=n(_e,"LI",{});var Tye=s(fp);lie=n(Tye,"STRONG",{});var Qst=s(lie);r1o=r(Qst,"groupvit"),Qst.forEach(t),t1o=r(Tye," \u2014 "),IN=n(Tye,"A",{href:!0});var Hst=s(IN);a1o=r(Hst,"CLIPProcessor"),Hst.forEach(t),n1o=r(Tye," (GroupViT model)"),Tye.forEach(t),s1o=i(_e),mp=n(_e,"LI",{});var Mye=s(mp);iie=n(Mye,"STRONG",{});var Ust=s(iie);l1o=r(Ust,"layoutlmv2"),Ust.forEach(t),i1o=r(Mye," \u2014 "),NN=n(Mye,"A",{href:!0});var Jst=s(NN);d1o=r(Jst,"LayoutLMv2Processor"),Jst.forEach(t),c1o=r(Mye," (LayoutLMv2 model)"),Mye.forEach(t),f1o=i(_e),gp=n(_e,"LI",{});var Eye=s(gp);die=n(Eye,"STRONG",{});var Yst=s(die);m1o=r(Yst,"layoutlmv3"),Yst.forEach(t),g1o=r(Eye," \u2014 "),qN=n(Eye,"A",{href:!0});var Kst=s(qN);h1o=r(Kst,"LayoutLMv3Processor"),Kst.forEach(t),p1o=r(Eye," (LayoutLMv3 model)"),Eye.forEach(t),u1o=i(_e),hp=n(_e,"LI",{});var Cye=s(hp);cie=n(Cye,"STRONG",{});var Zst=s(cie);_1o=r(Zst,"layoutxlm"),Zst.forEach(t),b1o=r(Cye," \u2014 "),jN=n(Cye,"A",{href:!0});var elt=s(jN);v1o=r(elt,"LayoutXLMProcessor"),elt.forEach(t),F1o=r(Cye," (LayoutXLM model)"),Cye.forEach(t),T1o=i(_e),pp=n(_e,"LI",{});var wye=s(pp);fie=n(wye,"STRONG",{});var olt=s(fie);M1o=r(olt,"sew"),olt.forEach(t),E1o=r(wye," \u2014 "),DN=n(wye,"A",{href:!0});var rlt=s(DN);C1o=r(rlt,"Wav2Vec2Processor"),rlt.forEach(t),w1o=r(wye," (SEW model)"),wye.forEach(t),A1o=i(_e),up=n(_e,"LI",{});var Aye=s(up);mie=n(Aye,"STRONG",{});var tlt=s(mie);L1o=r(tlt,"sew-d"),tlt.forEach(t),y1o=r(Aye," \u2014 "),GN=n(Aye,"A",{href:!0});var alt=s(GN);x1o=r(alt,"Wav2Vec2Processor"),alt.forEach(t),$1o=r(Aye," (SEW-D model)"),Aye.forEach(t),k1o=i(_e),_p=n(_e,"LI",{});var Lye=s(_p);gie=n(Lye,"STRONG",{});var nlt=s(gie);S1o=r(nlt,"speech_to_text"),nlt.forEach(t),R1o=r(Lye," \u2014 "),ON=n(Lye,"A",{href:!0});var slt=s(ON);P1o=r(slt,"Speech2TextProcessor"),slt.forEach(t),B1o=r(Lye," (Speech2Text model)"),Lye.forEach(t),I1o=i(_e),bp=n(_e,"LI",{});var yye=s(bp);hie=n(yye,"STRONG",{});var llt=s(hie);N1o=r(llt,"speech_to_text_2"),llt.forEach(t),q1o=r(yye," \u2014 "),VN=n(yye,"A",{href:!0});var ilt=s(VN);j1o=r(ilt,"Speech2Text2Processor"),ilt.forEach(t),D1o=r(yye," (Speech2Text2 model)"),yye.forEach(t),G1o=i(_e),vp=n(_e,"LI",{});var xye=s(vp);pie=n(xye,"STRONG",{});var dlt=s(pie);O1o=r(dlt,"trocr"),dlt.forEach(t),V1o=r(xye," \u2014 "),XN=n(xye,"A",{href:!0});var clt=s(XN);X1o=r(clt,"TrOCRProcessor"),clt.forEach(t),z1o=r(xye," (TrOCR model)"),xye.forEach(t),W1o=i(_e),Fp=n(_e,"LI",{});var $ye=s(Fp);uie=n($ye,"STRONG",{});var flt=s(uie);Q1o=r(flt,"unispeech"),flt.forEach(t),H1o=r($ye," \u2014 "),zN=n($ye,"A",{href:!0});var mlt=s(zN);U1o=r(mlt,"Wav2Vec2Processor"),mlt.forEach(t),J1o=r($ye," (UniSpeech model)"),$ye.forEach(t),Y1o=i(_e),Tp=n(_e,"LI",{});var kye=s(Tp);_ie=n(kye,"STRONG",{});var glt=s(_ie);K1o=r(glt,"unispeech-sat"),glt.forEach(t),Z1o=r(kye," \u2014 "),WN=n(kye,"A",{href:!0});var hlt=s(WN);e3o=r(hlt,"Wav2Vec2Processor"),hlt.forEach(t),o3o=r(kye," (UniSpeechSat model)"),kye.forEach(t),r3o=i(_e),Mp=n(_e,"LI",{});var Sye=s(Mp);bie=n(Sye,"STRONG",{});var plt=s(bie);t3o=r(plt,"vilt"),plt.forEach(t),a3o=r(Sye," \u2014 "),QN=n(Sye,"A",{href:!0});var ult=s(QN);n3o=r(ult,"ViltProcessor"),ult.forEach(t),s3o=r(Sye," (ViLT model)"),Sye.forEach(t),l3o=i(_e),Ep=n(_e,"LI",{});var Rye=s(Ep);vie=n(Rye,"STRONG",{});var _lt=s(vie);i3o=r(_lt,"vision-text-dual-encoder"),_lt.forEach(t),d3o=r(Rye," \u2014 "),HN=n(Rye,"A",{href:!0});var blt=s(HN);c3o=r(blt,"VisionTextDualEncoderProcessor"),blt.forEach(t),f3o=r(Rye," (VisionTextDualEncoder model)"),Rye.forEach(t),m3o=i(_e),Cp=n(_e,"LI",{});var Pye=s(Cp);Fie=n(Pye,"STRONG",{});var vlt=s(Fie);g3o=r(vlt,"wav2vec2"),vlt.forEach(t),h3o=r(Pye," \u2014 "),UN=n(Pye,"A",{href:!0});var Flt=s(UN);p3o=r(Flt,"Wav2Vec2Processor"),Flt.forEach(t),u3o=r(Pye," (Wav2Vec2 model)"),Pye.forEach(t),_3o=i(_e),wp=n(_e,"LI",{});var Bye=s(wp);Tie=n(Bye,"STRONG",{});var Tlt=s(Tie);b3o=r(Tlt,"wav2vec2-conformer"),Tlt.forEach(t),v3o=r(Bye," \u2014 "),JN=n(Bye,"A",{href:!0});var Mlt=s(JN);F3o=r(Mlt,"Wav2Vec2Processor"),Mlt.forEach(t),T3o=r(Bye," (Wav2Vec2-Conformer model)"),Bye.forEach(t),M3o=i(_e),Ap=n(_e,"LI",{});var Iye=s(Ap);Mie=n(Iye,"STRONG",{});var Elt=s(Mie);E3o=r(Elt,"wavlm"),Elt.forEach(t),C3o=r(Iye," \u2014 "),YN=n(Iye,"A",{href:!0});var Clt=s(YN);w3o=r(Clt,"Wav2Vec2Processor"),Clt.forEach(t),A3o=r(Iye," (WavLM model)"),Iye.forEach(t),_e.forEach(t),L3o=i(ta),T(Lp.$$.fragment,ta),y3o=i(ta),T(yp.$$.fragment,ta),ta.forEach(t),x3o=i(Us),xp=n(Us,"DIV",{class:!0});var NVe=s(xp);T(UL.$$.fragment,NVe),$3o=i(NVe),Eie=n(NVe,"P",{});var wlt=s(Eie);k3o=r(wlt,"Register a new processor for this class."),wlt.forEach(t),NVe.forEach(t),Us.forEach(t),SGe=i(f),Bi=n(f,"H2",{class:!0});var qVe=s(Bi);$p=n(qVe,"A",{id:!0,class:!0,href:!0});var Alt=s($p);Cie=n(Alt,"SPAN",{});var Llt=s(Cie);T(JL.$$.fragment,Llt),Llt.forEach(t),Alt.forEach(t),S3o=i(qVe),wie=n(qVe,"SPAN",{});var ylt=s(wie);R3o=r(ylt,"AutoModel"),ylt.forEach(t),qVe.forEach(t),RGe=i(f),xo=n(f,"DIV",{class:!0});var Js=s(xo);T(YL.$$.fragment,Js),P3o=i(Js),Ii=n(Js,"P",{});var doe=s(Ii);B3o=r(doe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),KN=n(doe,"A",{href:!0});var xlt=s(KN);I3o=r(xlt,"from_pretrained()"),xlt.forEach(t),N3o=r(doe," class method or the "),ZN=n(doe,"A",{href:!0});var $lt=s(ZN);q3o=r($lt,"from_config()"),$lt.forEach(t),j3o=r(doe,` class
method.`),doe.forEach(t),D3o=i(Js),KL=n(Js,"P",{});var jVe=s(KL);G3o=r(jVe,"This class cannot be instantiated directly using "),Aie=n(jVe,"CODE",{});var klt=s(Aie);O3o=r(klt,"__init__()"),klt.forEach(t),V3o=r(jVe," (throws an error)."),jVe.forEach(t),X3o=i(Js),nt=n(Js,"DIV",{class:!0});var AA=s(nt);T(ZL.$$.fragment,AA),z3o=i(AA),Lie=n(AA,"P",{});var Slt=s(Lie);W3o=r(Slt,"Instantiates one of the base model classes of the library from a configuration."),Slt.forEach(t),Q3o=i(AA),Ni=n(AA,"P",{});var coe=s(Ni);H3o=r(coe,`Note:
Loading a model from its configuration file does `),yie=n(coe,"STRONG",{});var Rlt=s(yie);U3o=r(Rlt,"not"),Rlt.forEach(t),J3o=r(coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),eq=n(coe,"A",{href:!0});var Plt=s(eq);Y3o=r(Plt,"from_pretrained()"),Plt.forEach(t),K3o=r(coe," to load the model weights."),coe.forEach(t),Z3o=i(AA),T(kp.$$.fragment,AA),AA.forEach(t),e2o=i(Js),Je=n(Js,"DIV",{class:!0});var aa=s(Je);T(ey.$$.fragment,aa),o2o=i(aa),xie=n(aa,"P",{});var Blt=s(xie);r2o=r(Blt,"Instantiate one of the base model classes of the library from a pretrained model."),Blt.forEach(t),t2o=i(aa),Sa=n(aa,"P",{});var LA=s(Sa);a2o=r(LA,"The model class to instantiate is selected based on the "),$ie=n(LA,"CODE",{});var Ilt=s($ie);n2o=r(Ilt,"model_type"),Ilt.forEach(t),s2o=r(LA,` property of the config object (either
passed as an argument or loaded from `),kie=n(LA,"CODE",{});var Nlt=s(kie);l2o=r(Nlt,"pretrained_model_name_or_path"),Nlt.forEach(t),i2o=r(LA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sie=n(LA,"CODE",{});var qlt=s(Sie);d2o=r(qlt,"pretrained_model_name_or_path"),qlt.forEach(t),c2o=r(LA,":"),LA.forEach(t),f2o=i(aa),y=n(aa,"UL",{});var $=s(y);Sp=n($,"LI",{});var Nye=s(Sp);Rie=n(Nye,"STRONG",{});var jlt=s(Rie);m2o=r(jlt,"albert"),jlt.forEach(t),g2o=r(Nye," \u2014 "),oq=n(Nye,"A",{href:!0});var Dlt=s(oq);h2o=r(Dlt,"AlbertModel"),Dlt.forEach(t),p2o=r(Nye," (ALBERT model)"),Nye.forEach(t),u2o=i($),Rp=n($,"LI",{});var qye=s(Rp);Pie=n(qye,"STRONG",{});var Glt=s(Pie);_2o=r(Glt,"bart"),Glt.forEach(t),b2o=r(qye," \u2014 "),rq=n(qye,"A",{href:!0});var Olt=s(rq);v2o=r(Olt,"BartModel"),Olt.forEach(t),F2o=r(qye," (BART model)"),qye.forEach(t),T2o=i($),Pp=n($,"LI",{});var jye=s(Pp);Bie=n(jye,"STRONG",{});var Vlt=s(Bie);M2o=r(Vlt,"beit"),Vlt.forEach(t),E2o=r(jye," \u2014 "),tq=n(jye,"A",{href:!0});var Xlt=s(tq);C2o=r(Xlt,"BeitModel"),Xlt.forEach(t),w2o=r(jye," (BEiT model)"),jye.forEach(t),A2o=i($),Bp=n($,"LI",{});var Dye=s(Bp);Iie=n(Dye,"STRONG",{});var zlt=s(Iie);L2o=r(zlt,"bert"),zlt.forEach(t),y2o=r(Dye," \u2014 "),aq=n(Dye,"A",{href:!0});var Wlt=s(aq);x2o=r(Wlt,"BertModel"),Wlt.forEach(t),$2o=r(Dye," (BERT model)"),Dye.forEach(t),k2o=i($),Ip=n($,"LI",{});var Gye=s(Ip);Nie=n(Gye,"STRONG",{});var Qlt=s(Nie);S2o=r(Qlt,"bert-generation"),Qlt.forEach(t),R2o=r(Gye," \u2014 "),nq=n(Gye,"A",{href:!0});var Hlt=s(nq);P2o=r(Hlt,"BertGenerationEncoder"),Hlt.forEach(t),B2o=r(Gye," (Bert Generation model)"),Gye.forEach(t),I2o=i($),Np=n($,"LI",{});var Oye=s(Np);qie=n(Oye,"STRONG",{});var Ult=s(qie);N2o=r(Ult,"big_bird"),Ult.forEach(t),q2o=r(Oye," \u2014 "),sq=n(Oye,"A",{href:!0});var Jlt=s(sq);j2o=r(Jlt,"BigBirdModel"),Jlt.forEach(t),D2o=r(Oye," (BigBird model)"),Oye.forEach(t),G2o=i($),qp=n($,"LI",{});var Vye=s(qp);jie=n(Vye,"STRONG",{});var Ylt=s(jie);O2o=r(Ylt,"bigbird_pegasus"),Ylt.forEach(t),V2o=r(Vye," \u2014 "),lq=n(Vye,"A",{href:!0});var Klt=s(lq);X2o=r(Klt,"BigBirdPegasusModel"),Klt.forEach(t),z2o=r(Vye," (BigBird-Pegasus model)"),Vye.forEach(t),W2o=i($),jp=n($,"LI",{});var Xye=s(jp);Die=n(Xye,"STRONG",{});var Zlt=s(Die);Q2o=r(Zlt,"blenderbot"),Zlt.forEach(t),H2o=r(Xye," \u2014 "),iq=n(Xye,"A",{href:!0});var eit=s(iq);U2o=r(eit,"BlenderbotModel"),eit.forEach(t),J2o=r(Xye," (Blenderbot model)"),Xye.forEach(t),Y2o=i($),Dp=n($,"LI",{});var zye=s(Dp);Gie=n(zye,"STRONG",{});var oit=s(Gie);K2o=r(oit,"blenderbot-small"),oit.forEach(t),Z2o=r(zye," \u2014 "),dq=n(zye,"A",{href:!0});var rit=s(dq);ebo=r(rit,"BlenderbotSmallModel"),rit.forEach(t),obo=r(zye," (BlenderbotSmall model)"),zye.forEach(t),rbo=i($),Gp=n($,"LI",{});var Wye=s(Gp);Oie=n(Wye,"STRONG",{});var tit=s(Oie);tbo=r(tit,"bloom"),tit.forEach(t),abo=r(Wye," \u2014 "),cq=n(Wye,"A",{href:!0});var ait=s(cq);nbo=r(ait,"BloomModel"),ait.forEach(t),sbo=r(Wye," (BLOOM model)"),Wye.forEach(t),lbo=i($),Op=n($,"LI",{});var Qye=s(Op);Vie=n(Qye,"STRONG",{});var nit=s(Vie);ibo=r(nit,"camembert"),nit.forEach(t),dbo=r(Qye," \u2014 "),fq=n(Qye,"A",{href:!0});var sit=s(fq);cbo=r(sit,"CamembertModel"),sit.forEach(t),fbo=r(Qye," (CamemBERT model)"),Qye.forEach(t),mbo=i($),Vp=n($,"LI",{});var Hye=s(Vp);Xie=n(Hye,"STRONG",{});var lit=s(Xie);gbo=r(lit,"canine"),lit.forEach(t),hbo=r(Hye," \u2014 "),mq=n(Hye,"A",{href:!0});var iit=s(mq);pbo=r(iit,"CanineModel"),iit.forEach(t),ubo=r(Hye," (CANINE model)"),Hye.forEach(t),_bo=i($),Xp=n($,"LI",{});var Uye=s(Xp);zie=n(Uye,"STRONG",{});var dit=s(zie);bbo=r(dit,"clip"),dit.forEach(t),vbo=r(Uye," \u2014 "),gq=n(Uye,"A",{href:!0});var cit=s(gq);Fbo=r(cit,"CLIPModel"),cit.forEach(t),Tbo=r(Uye," (CLIP model)"),Uye.forEach(t),Mbo=i($),zp=n($,"LI",{});var Jye=s(zp);Wie=n(Jye,"STRONG",{});var fit=s(Wie);Ebo=r(fit,"convbert"),fit.forEach(t),Cbo=r(Jye," \u2014 "),hq=n(Jye,"A",{href:!0});var mit=s(hq);wbo=r(mit,"ConvBertModel"),mit.forEach(t),Abo=r(Jye," (ConvBERT model)"),Jye.forEach(t),Lbo=i($),Wp=n($,"LI",{});var Yye=s(Wp);Qie=n(Yye,"STRONG",{});var git=s(Qie);ybo=r(git,"convnext"),git.forEach(t),xbo=r(Yye," \u2014 "),pq=n(Yye,"A",{href:!0});var hit=s(pq);$bo=r(hit,"ConvNextModel"),hit.forEach(t),kbo=r(Yye," (ConvNeXT model)"),Yye.forEach(t),Sbo=i($),Qp=n($,"LI",{});var Kye=s(Qp);Hie=n(Kye,"STRONG",{});var pit=s(Hie);Rbo=r(pit,"ctrl"),pit.forEach(t),Pbo=r(Kye," \u2014 "),uq=n(Kye,"A",{href:!0});var uit=s(uq);Bbo=r(uit,"CTRLModel"),uit.forEach(t),Ibo=r(Kye," (CTRL model)"),Kye.forEach(t),Nbo=i($),Hp=n($,"LI",{});var Zye=s(Hp);Uie=n(Zye,"STRONG",{});var _it=s(Uie);qbo=r(_it,"cvt"),_it.forEach(t),jbo=r(Zye," \u2014 "),_q=n(Zye,"A",{href:!0});var bit=s(_q);Dbo=r(bit,"CvtModel"),bit.forEach(t),Gbo=r(Zye," (CvT model)"),Zye.forEach(t),Obo=i($),Up=n($,"LI",{});var e8e=s(Up);Jie=n(e8e,"STRONG",{});var vit=s(Jie);Vbo=r(vit,"data2vec-audio"),vit.forEach(t),Xbo=r(e8e," \u2014 "),bq=n(e8e,"A",{href:!0});var Fit=s(bq);zbo=r(Fit,"Data2VecAudioModel"),Fit.forEach(t),Wbo=r(e8e," (Data2VecAudio model)"),e8e.forEach(t),Qbo=i($),Jp=n($,"LI",{});var o8e=s(Jp);Yie=n(o8e,"STRONG",{});var Tit=s(Yie);Hbo=r(Tit,"data2vec-text"),Tit.forEach(t),Ubo=r(o8e," \u2014 "),vq=n(o8e,"A",{href:!0});var Mit=s(vq);Jbo=r(Mit,"Data2VecTextModel"),Mit.forEach(t),Ybo=r(o8e," (Data2VecText model)"),o8e.forEach(t),Kbo=i($),Yp=n($,"LI",{});var r8e=s(Yp);Kie=n(r8e,"STRONG",{});var Eit=s(Kie);Zbo=r(Eit,"data2vec-vision"),Eit.forEach(t),evo=r(r8e," \u2014 "),Fq=n(r8e,"A",{href:!0});var Cit=s(Fq);ovo=r(Cit,"Data2VecVisionModel"),Cit.forEach(t),rvo=r(r8e," (Data2VecVision model)"),r8e.forEach(t),tvo=i($),Kp=n($,"LI",{});var t8e=s(Kp);Zie=n(t8e,"STRONG",{});var wit=s(Zie);avo=r(wit,"deberta"),wit.forEach(t),nvo=r(t8e," \u2014 "),Tq=n(t8e,"A",{href:!0});var Ait=s(Tq);svo=r(Ait,"DebertaModel"),Ait.forEach(t),lvo=r(t8e," (DeBERTa model)"),t8e.forEach(t),ivo=i($),Zp=n($,"LI",{});var a8e=s(Zp);ede=n(a8e,"STRONG",{});var Lit=s(ede);dvo=r(Lit,"deberta-v2"),Lit.forEach(t),cvo=r(a8e," \u2014 "),Mq=n(a8e,"A",{href:!0});var yit=s(Mq);fvo=r(yit,"DebertaV2Model"),yit.forEach(t),mvo=r(a8e," (DeBERTa-v2 model)"),a8e.forEach(t),gvo=i($),eu=n($,"LI",{});var n8e=s(eu);ode=n(n8e,"STRONG",{});var xit=s(ode);hvo=r(xit,"decision_transformer"),xit.forEach(t),pvo=r(n8e," \u2014 "),Eq=n(n8e,"A",{href:!0});var $it=s(Eq);uvo=r($it,"DecisionTransformerModel"),$it.forEach(t),_vo=r(n8e," (Decision Transformer model)"),n8e.forEach(t),bvo=i($),ou=n($,"LI",{});var s8e=s(ou);rde=n(s8e,"STRONG",{});var kit=s(rde);vvo=r(kit,"deit"),kit.forEach(t),Fvo=r(s8e," \u2014 "),Cq=n(s8e,"A",{href:!0});var Sit=s(Cq);Tvo=r(Sit,"DeiTModel"),Sit.forEach(t),Mvo=r(s8e," (DeiT model)"),s8e.forEach(t),Evo=i($),ru=n($,"LI",{});var l8e=s(ru);tde=n(l8e,"STRONG",{});var Rit=s(tde);Cvo=r(Rit,"detr"),Rit.forEach(t),wvo=r(l8e," \u2014 "),wq=n(l8e,"A",{href:!0});var Pit=s(wq);Avo=r(Pit,"DetrModel"),Pit.forEach(t),Lvo=r(l8e," (DETR model)"),l8e.forEach(t),yvo=i($),tu=n($,"LI",{});var i8e=s(tu);ade=n(i8e,"STRONG",{});var Bit=s(ade);xvo=r(Bit,"distilbert"),Bit.forEach(t),$vo=r(i8e," \u2014 "),Aq=n(i8e,"A",{href:!0});var Iit=s(Aq);kvo=r(Iit,"DistilBertModel"),Iit.forEach(t),Svo=r(i8e," (DistilBERT model)"),i8e.forEach(t),Rvo=i($),au=n($,"LI",{});var d8e=s(au);nde=n(d8e,"STRONG",{});var Nit=s(nde);Pvo=r(Nit,"dpr"),Nit.forEach(t),Bvo=r(d8e," \u2014 "),Lq=n(d8e,"A",{href:!0});var qit=s(Lq);Ivo=r(qit,"DPRQuestionEncoder"),qit.forEach(t),Nvo=r(d8e," (DPR model)"),d8e.forEach(t),qvo=i($),nu=n($,"LI",{});var c8e=s(nu);sde=n(c8e,"STRONG",{});var jit=s(sde);jvo=r(jit,"dpt"),jit.forEach(t),Dvo=r(c8e," \u2014 "),yq=n(c8e,"A",{href:!0});var Dit=s(yq);Gvo=r(Dit,"DPTModel"),Dit.forEach(t),Ovo=r(c8e," (DPT model)"),c8e.forEach(t),Vvo=i($),su=n($,"LI",{});var f8e=s(su);lde=n(f8e,"STRONG",{});var Git=s(lde);Xvo=r(Git,"electra"),Git.forEach(t),zvo=r(f8e," \u2014 "),xq=n(f8e,"A",{href:!0});var Oit=s(xq);Wvo=r(Oit,"ElectraModel"),Oit.forEach(t),Qvo=r(f8e," (ELECTRA model)"),f8e.forEach(t),Hvo=i($),lu=n($,"LI",{});var m8e=s(lu);ide=n(m8e,"STRONG",{});var Vit=s(ide);Uvo=r(Vit,"flaubert"),Vit.forEach(t),Jvo=r(m8e," \u2014 "),$q=n(m8e,"A",{href:!0});var Xit=s($q);Yvo=r(Xit,"FlaubertModel"),Xit.forEach(t),Kvo=r(m8e," (FlauBERT model)"),m8e.forEach(t),Zvo=i($),iu=n($,"LI",{});var g8e=s(iu);dde=n(g8e,"STRONG",{});var zit=s(dde);eFo=r(zit,"flava"),zit.forEach(t),oFo=r(g8e," \u2014 "),kq=n(g8e,"A",{href:!0});var Wit=s(kq);rFo=r(Wit,"FlavaModel"),Wit.forEach(t),tFo=r(g8e," (FLAVA model)"),g8e.forEach(t),aFo=i($),du=n($,"LI",{});var h8e=s(du);cde=n(h8e,"STRONG",{});var Qit=s(cde);nFo=r(Qit,"fnet"),Qit.forEach(t),sFo=r(h8e," \u2014 "),Sq=n(h8e,"A",{href:!0});var Hit=s(Sq);lFo=r(Hit,"FNetModel"),Hit.forEach(t),iFo=r(h8e," (FNet model)"),h8e.forEach(t),dFo=i($),cu=n($,"LI",{});var p8e=s(cu);fde=n(p8e,"STRONG",{});var Uit=s(fde);cFo=r(Uit,"fsmt"),Uit.forEach(t),fFo=r(p8e," \u2014 "),Rq=n(p8e,"A",{href:!0});var Jit=s(Rq);mFo=r(Jit,"FSMTModel"),Jit.forEach(t),gFo=r(p8e," (FairSeq Machine-Translation model)"),p8e.forEach(t),hFo=i($),Os=n($,"LI",{});var Qk=s(Os);mde=n(Qk,"STRONG",{});var Yit=s(mde);pFo=r(Yit,"funnel"),Yit.forEach(t),uFo=r(Qk," \u2014 "),Pq=n(Qk,"A",{href:!0});var Kit=s(Pq);_Fo=r(Kit,"FunnelModel"),Kit.forEach(t),bFo=r(Qk," or "),Bq=n(Qk,"A",{href:!0});var Zit=s(Bq);vFo=r(Zit,"FunnelBaseModel"),Zit.forEach(t),FFo=r(Qk," (Funnel Transformer model)"),Qk.forEach(t),TFo=i($),fu=n($,"LI",{});var u8e=s(fu);gde=n(u8e,"STRONG",{});var edt=s(gde);MFo=r(edt,"glpn"),edt.forEach(t),EFo=r(u8e," \u2014 "),Iq=n(u8e,"A",{href:!0});var odt=s(Iq);CFo=r(odt,"GLPNModel"),odt.forEach(t),wFo=r(u8e," (GLPN model)"),u8e.forEach(t),AFo=i($),mu=n($,"LI",{});var _8e=s(mu);hde=n(_8e,"STRONG",{});var rdt=s(hde);LFo=r(rdt,"gpt2"),rdt.forEach(t),yFo=r(_8e," \u2014 "),Nq=n(_8e,"A",{href:!0});var tdt=s(Nq);xFo=r(tdt,"GPT2Model"),tdt.forEach(t),$Fo=r(_8e," (OpenAI GPT-2 model)"),_8e.forEach(t),kFo=i($),gu=n($,"LI",{});var b8e=s(gu);pde=n(b8e,"STRONG",{});var adt=s(pde);SFo=r(adt,"gpt_neo"),adt.forEach(t),RFo=r(b8e," \u2014 "),qq=n(b8e,"A",{href:!0});var ndt=s(qq);PFo=r(ndt,"GPTNeoModel"),ndt.forEach(t),BFo=r(b8e," (GPT Neo model)"),b8e.forEach(t),IFo=i($),hu=n($,"LI",{});var v8e=s(hu);ude=n(v8e,"STRONG",{});var sdt=s(ude);NFo=r(sdt,"gpt_neox"),sdt.forEach(t),qFo=r(v8e," \u2014 "),jq=n(v8e,"A",{href:!0});var ldt=s(jq);jFo=r(ldt,"GPTNeoXModel"),ldt.forEach(t),DFo=r(v8e," (GPT NeoX model)"),v8e.forEach(t),GFo=i($),pu=n($,"LI",{});var F8e=s(pu);_de=n(F8e,"STRONG",{});var idt=s(_de);OFo=r(idt,"gptj"),idt.forEach(t),VFo=r(F8e," \u2014 "),Dq=n(F8e,"A",{href:!0});var ddt=s(Dq);XFo=r(ddt,"GPTJModel"),ddt.forEach(t),zFo=r(F8e," (GPT-J model)"),F8e.forEach(t),WFo=i($),uu=n($,"LI",{});var T8e=s(uu);bde=n(T8e,"STRONG",{});var cdt=s(bde);QFo=r(cdt,"groupvit"),cdt.forEach(t),HFo=r(T8e," \u2014 "),Gq=n(T8e,"A",{href:!0});var fdt=s(Gq);UFo=r(fdt,"GroupViTModel"),fdt.forEach(t),JFo=r(T8e," (GroupViT model)"),T8e.forEach(t),YFo=i($),_u=n($,"LI",{});var M8e=s(_u);vde=n(M8e,"STRONG",{});var mdt=s(vde);KFo=r(mdt,"hubert"),mdt.forEach(t),ZFo=r(M8e," \u2014 "),Oq=n(M8e,"A",{href:!0});var gdt=s(Oq);eTo=r(gdt,"HubertModel"),gdt.forEach(t),oTo=r(M8e," (Hubert model)"),M8e.forEach(t),rTo=i($),bu=n($,"LI",{});var E8e=s(bu);Fde=n(E8e,"STRONG",{});var hdt=s(Fde);tTo=r(hdt,"ibert"),hdt.forEach(t),aTo=r(E8e," \u2014 "),Vq=n(E8e,"A",{href:!0});var pdt=s(Vq);nTo=r(pdt,"IBertModel"),pdt.forEach(t),sTo=r(E8e," (I-BERT model)"),E8e.forEach(t),lTo=i($),vu=n($,"LI",{});var C8e=s(vu);Tde=n(C8e,"STRONG",{});var udt=s(Tde);iTo=r(udt,"imagegpt"),udt.forEach(t),dTo=r(C8e," \u2014 "),Xq=n(C8e,"A",{href:!0});var _dt=s(Xq);cTo=r(_dt,"ImageGPTModel"),_dt.forEach(t),fTo=r(C8e," (ImageGPT model)"),C8e.forEach(t),mTo=i($),Fu=n($,"LI",{});var w8e=s(Fu);Mde=n(w8e,"STRONG",{});var bdt=s(Mde);gTo=r(bdt,"layoutlm"),bdt.forEach(t),hTo=r(w8e," \u2014 "),zq=n(w8e,"A",{href:!0});var vdt=s(zq);pTo=r(vdt,"LayoutLMModel"),vdt.forEach(t),uTo=r(w8e," (LayoutLM model)"),w8e.forEach(t),_To=i($),Tu=n($,"LI",{});var A8e=s(Tu);Ede=n(A8e,"STRONG",{});var Fdt=s(Ede);bTo=r(Fdt,"layoutlmv2"),Fdt.forEach(t),vTo=r(A8e," \u2014 "),Wq=n(A8e,"A",{href:!0});var Tdt=s(Wq);FTo=r(Tdt,"LayoutLMv2Model"),Tdt.forEach(t),TTo=r(A8e," (LayoutLMv2 model)"),A8e.forEach(t),MTo=i($),Mu=n($,"LI",{});var L8e=s(Mu);Cde=n(L8e,"STRONG",{});var Mdt=s(Cde);ETo=r(Mdt,"layoutlmv3"),Mdt.forEach(t),CTo=r(L8e," \u2014 "),Qq=n(L8e,"A",{href:!0});var Edt=s(Qq);wTo=r(Edt,"LayoutLMv3Model"),Edt.forEach(t),ATo=r(L8e," (LayoutLMv3 model)"),L8e.forEach(t),LTo=i($),Eu=n($,"LI",{});var y8e=s(Eu);wde=n(y8e,"STRONG",{});var Cdt=s(wde);yTo=r(Cdt,"led"),Cdt.forEach(t),xTo=r(y8e," \u2014 "),Hq=n(y8e,"A",{href:!0});var wdt=s(Hq);$To=r(wdt,"LEDModel"),wdt.forEach(t),kTo=r(y8e," (LED model)"),y8e.forEach(t),STo=i($),Cu=n($,"LI",{});var x8e=s(Cu);Ade=n(x8e,"STRONG",{});var Adt=s(Ade);RTo=r(Adt,"levit"),Adt.forEach(t),PTo=r(x8e," \u2014 "),Uq=n(x8e,"A",{href:!0});var Ldt=s(Uq);BTo=r(Ldt,"LevitModel"),Ldt.forEach(t),ITo=r(x8e," (LeViT model)"),x8e.forEach(t),NTo=i($),wu=n($,"LI",{});var $8e=s(wu);Lde=n($8e,"STRONG",{});var ydt=s(Lde);qTo=r(ydt,"longformer"),ydt.forEach(t),jTo=r($8e," \u2014 "),Jq=n($8e,"A",{href:!0});var xdt=s(Jq);DTo=r(xdt,"LongformerModel"),xdt.forEach(t),GTo=r($8e," (Longformer model)"),$8e.forEach(t),OTo=i($),Au=n($,"LI",{});var k8e=s(Au);yde=n(k8e,"STRONG",{});var $dt=s(yde);VTo=r($dt,"longt5"),$dt.forEach(t),XTo=r(k8e," \u2014 "),Yq=n(k8e,"A",{href:!0});var kdt=s(Yq);zTo=r(kdt,"LongT5Model"),kdt.forEach(t),WTo=r(k8e," (LongT5 model)"),k8e.forEach(t),QTo=i($),Lu=n($,"LI",{});var S8e=s(Lu);xde=n(S8e,"STRONG",{});var Sdt=s(xde);HTo=r(Sdt,"luke"),Sdt.forEach(t),UTo=r(S8e," \u2014 "),Kq=n(S8e,"A",{href:!0});var Rdt=s(Kq);JTo=r(Rdt,"LukeModel"),Rdt.forEach(t),YTo=r(S8e," (LUKE model)"),S8e.forEach(t),KTo=i($),yu=n($,"LI",{});var R8e=s(yu);$de=n(R8e,"STRONG",{});var Pdt=s($de);ZTo=r(Pdt,"lxmert"),Pdt.forEach(t),e7o=r(R8e," \u2014 "),Zq=n(R8e,"A",{href:!0});var Bdt=s(Zq);o7o=r(Bdt,"LxmertModel"),Bdt.forEach(t),r7o=r(R8e," (LXMERT model)"),R8e.forEach(t),t7o=i($),xu=n($,"LI",{});var P8e=s(xu);kde=n(P8e,"STRONG",{});var Idt=s(kde);a7o=r(Idt,"m2m_100"),Idt.forEach(t),n7o=r(P8e," \u2014 "),ej=n(P8e,"A",{href:!0});var Ndt=s(ej);s7o=r(Ndt,"M2M100Model"),Ndt.forEach(t),l7o=r(P8e," (M2M100 model)"),P8e.forEach(t),i7o=i($),$u=n($,"LI",{});var B8e=s($u);Sde=n(B8e,"STRONG",{});var qdt=s(Sde);d7o=r(qdt,"marian"),qdt.forEach(t),c7o=r(B8e," \u2014 "),oj=n(B8e,"A",{href:!0});var jdt=s(oj);f7o=r(jdt,"MarianModel"),jdt.forEach(t),m7o=r(B8e," (Marian model)"),B8e.forEach(t),g7o=i($),ku=n($,"LI",{});var I8e=s(ku);Rde=n(I8e,"STRONG",{});var Ddt=s(Rde);h7o=r(Ddt,"maskformer"),Ddt.forEach(t),p7o=r(I8e," \u2014 "),rj=n(I8e,"A",{href:!0});var Gdt=s(rj);u7o=r(Gdt,"MaskFormerModel"),Gdt.forEach(t),_7o=r(I8e," (MaskFormer model)"),I8e.forEach(t),b7o=i($),Su=n($,"LI",{});var N8e=s(Su);Pde=n(N8e,"STRONG",{});var Odt=s(Pde);v7o=r(Odt,"mbart"),Odt.forEach(t),F7o=r(N8e," \u2014 "),tj=n(N8e,"A",{href:!0});var Vdt=s(tj);T7o=r(Vdt,"MBartModel"),Vdt.forEach(t),M7o=r(N8e," (mBART model)"),N8e.forEach(t),E7o=i($),Ru=n($,"LI",{});var q8e=s(Ru);Bde=n(q8e,"STRONG",{});var Xdt=s(Bde);C7o=r(Xdt,"mctct"),Xdt.forEach(t),w7o=r(q8e," \u2014 "),aj=n(q8e,"A",{href:!0});var zdt=s(aj);A7o=r(zdt,"MCTCTModel"),zdt.forEach(t),L7o=r(q8e," (M-CTC-T model)"),q8e.forEach(t),y7o=i($),Pu=n($,"LI",{});var j8e=s(Pu);Ide=n(j8e,"STRONG",{});var Wdt=s(Ide);x7o=r(Wdt,"megatron-bert"),Wdt.forEach(t),$7o=r(j8e," \u2014 "),nj=n(j8e,"A",{href:!0});var Qdt=s(nj);k7o=r(Qdt,"MegatronBertModel"),Qdt.forEach(t),S7o=r(j8e," (Megatron-BERT model)"),j8e.forEach(t),R7o=i($),Bu=n($,"LI",{});var D8e=s(Bu);Nde=n(D8e,"STRONG",{});var Hdt=s(Nde);P7o=r(Hdt,"mobilebert"),Hdt.forEach(t),B7o=r(D8e," \u2014 "),sj=n(D8e,"A",{href:!0});var Udt=s(sj);I7o=r(Udt,"MobileBertModel"),Udt.forEach(t),N7o=r(D8e," (MobileBERT model)"),D8e.forEach(t),q7o=i($),Iu=n($,"LI",{});var G8e=s(Iu);qde=n(G8e,"STRONG",{});var Jdt=s(qde);j7o=r(Jdt,"mpnet"),Jdt.forEach(t),D7o=r(G8e," \u2014 "),lj=n(G8e,"A",{href:!0});var Ydt=s(lj);G7o=r(Ydt,"MPNetModel"),Ydt.forEach(t),O7o=r(G8e," (MPNet model)"),G8e.forEach(t),V7o=i($),Nu=n($,"LI",{});var O8e=s(Nu);jde=n(O8e,"STRONG",{});var Kdt=s(jde);X7o=r(Kdt,"mt5"),Kdt.forEach(t),z7o=r(O8e," \u2014 "),ij=n(O8e,"A",{href:!0});var Zdt=s(ij);W7o=r(Zdt,"MT5Model"),Zdt.forEach(t),Q7o=r(O8e," (MT5 model)"),O8e.forEach(t),H7o=i($),qu=n($,"LI",{});var V8e=s(qu);Dde=n(V8e,"STRONG",{});var ect=s(Dde);U7o=r(ect,"nystromformer"),ect.forEach(t),J7o=r(V8e," \u2014 "),dj=n(V8e,"A",{href:!0});var oct=s(dj);Y7o=r(oct,"NystromformerModel"),oct.forEach(t),K7o=r(V8e," (Nystr\xF6mformer model)"),V8e.forEach(t),Z7o=i($),ju=n($,"LI",{});var X8e=s(ju);Gde=n(X8e,"STRONG",{});var rct=s(Gde);eMo=r(rct,"openai-gpt"),rct.forEach(t),oMo=r(X8e," \u2014 "),cj=n(X8e,"A",{href:!0});var tct=s(cj);rMo=r(tct,"OpenAIGPTModel"),tct.forEach(t),tMo=r(X8e," (OpenAI GPT model)"),X8e.forEach(t),aMo=i($),Du=n($,"LI",{});var z8e=s(Du);Ode=n(z8e,"STRONG",{});var act=s(Ode);nMo=r(act,"opt"),act.forEach(t),sMo=r(z8e," \u2014 "),fj=n(z8e,"A",{href:!0});var nct=s(fj);lMo=r(nct,"OPTModel"),nct.forEach(t),iMo=r(z8e," (OPT model)"),z8e.forEach(t),dMo=i($),Gu=n($,"LI",{});var W8e=s(Gu);Vde=n(W8e,"STRONG",{});var sct=s(Vde);cMo=r(sct,"pegasus"),sct.forEach(t),fMo=r(W8e," \u2014 "),mj=n(W8e,"A",{href:!0});var lct=s(mj);mMo=r(lct,"PegasusModel"),lct.forEach(t),gMo=r(W8e," (Pegasus model)"),W8e.forEach(t),hMo=i($),Ou=n($,"LI",{});var Q8e=s(Ou);Xde=n(Q8e,"STRONG",{});var ict=s(Xde);pMo=r(ict,"perceiver"),ict.forEach(t),uMo=r(Q8e," \u2014 "),gj=n(Q8e,"A",{href:!0});var dct=s(gj);_Mo=r(dct,"PerceiverModel"),dct.forEach(t),bMo=r(Q8e," (Perceiver model)"),Q8e.forEach(t),vMo=i($),Vu=n($,"LI",{});var H8e=s(Vu);zde=n(H8e,"STRONG",{});var cct=s(zde);FMo=r(cct,"plbart"),cct.forEach(t),TMo=r(H8e," \u2014 "),hj=n(H8e,"A",{href:!0});var fct=s(hj);MMo=r(fct,"PLBartModel"),fct.forEach(t),EMo=r(H8e," (PLBart model)"),H8e.forEach(t),CMo=i($),Xu=n($,"LI",{});var U8e=s(Xu);Wde=n(U8e,"STRONG",{});var mct=s(Wde);wMo=r(mct,"poolformer"),mct.forEach(t),AMo=r(U8e," \u2014 "),pj=n(U8e,"A",{href:!0});var gct=s(pj);LMo=r(gct,"PoolFormerModel"),gct.forEach(t),yMo=r(U8e," (PoolFormer model)"),U8e.forEach(t),xMo=i($),zu=n($,"LI",{});var J8e=s(zu);Qde=n(J8e,"STRONG",{});var hct=s(Qde);$Mo=r(hct,"prophetnet"),hct.forEach(t),kMo=r(J8e," \u2014 "),uj=n(J8e,"A",{href:!0});var pct=s(uj);SMo=r(pct,"ProphetNetModel"),pct.forEach(t),RMo=r(J8e," (ProphetNet model)"),J8e.forEach(t),PMo=i($),Wu=n($,"LI",{});var Y8e=s(Wu);Hde=n(Y8e,"STRONG",{});var uct=s(Hde);BMo=r(uct,"qdqbert"),uct.forEach(t),IMo=r(Y8e," \u2014 "),_j=n(Y8e,"A",{href:!0});var _ct=s(_j);NMo=r(_ct,"QDQBertModel"),_ct.forEach(t),qMo=r(Y8e," (QDQBert model)"),Y8e.forEach(t),jMo=i($),Qu=n($,"LI",{});var K8e=s(Qu);Ude=n(K8e,"STRONG",{});var bct=s(Ude);DMo=r(bct,"reformer"),bct.forEach(t),GMo=r(K8e," \u2014 "),bj=n(K8e,"A",{href:!0});var vct=s(bj);OMo=r(vct,"ReformerModel"),vct.forEach(t),VMo=r(K8e," (Reformer model)"),K8e.forEach(t),XMo=i($),Hu=n($,"LI",{});var Z8e=s(Hu);Jde=n(Z8e,"STRONG",{});var Fct=s(Jde);zMo=r(Fct,"regnet"),Fct.forEach(t),WMo=r(Z8e," \u2014 "),vj=n(Z8e,"A",{href:!0});var Tct=s(vj);QMo=r(Tct,"RegNetModel"),Tct.forEach(t),HMo=r(Z8e," (RegNet model)"),Z8e.forEach(t),UMo=i($),Uu=n($,"LI",{});var e9e=s(Uu);Yde=n(e9e,"STRONG",{});var Mct=s(Yde);JMo=r(Mct,"rembert"),Mct.forEach(t),YMo=r(e9e," \u2014 "),Fj=n(e9e,"A",{href:!0});var Ect=s(Fj);KMo=r(Ect,"RemBertModel"),Ect.forEach(t),ZMo=r(e9e," (RemBERT model)"),e9e.forEach(t),eEo=i($),Ju=n($,"LI",{});var o9e=s(Ju);Kde=n(o9e,"STRONG",{});var Cct=s(Kde);oEo=r(Cct,"resnet"),Cct.forEach(t),rEo=r(o9e," \u2014 "),Tj=n(o9e,"A",{href:!0});var wct=s(Tj);tEo=r(wct,"ResNetModel"),wct.forEach(t),aEo=r(o9e," (ResNet model)"),o9e.forEach(t),nEo=i($),Yu=n($,"LI",{});var r9e=s(Yu);Zde=n(r9e,"STRONG",{});var Act=s(Zde);sEo=r(Act,"retribert"),Act.forEach(t),lEo=r(r9e," \u2014 "),Mj=n(r9e,"A",{href:!0});var Lct=s(Mj);iEo=r(Lct,"RetriBertModel"),Lct.forEach(t),dEo=r(r9e," (RetriBERT model)"),r9e.forEach(t),cEo=i($),Ku=n($,"LI",{});var t9e=s(Ku);ece=n(t9e,"STRONG",{});var yct=s(ece);fEo=r(yct,"roberta"),yct.forEach(t),mEo=r(t9e," \u2014 "),Ej=n(t9e,"A",{href:!0});var xct=s(Ej);gEo=r(xct,"RobertaModel"),xct.forEach(t),hEo=r(t9e," (RoBERTa model)"),t9e.forEach(t),pEo=i($),Zu=n($,"LI",{});var a9e=s(Zu);oce=n(a9e,"STRONG",{});var $ct=s(oce);uEo=r($ct,"roformer"),$ct.forEach(t),_Eo=r(a9e," \u2014 "),Cj=n(a9e,"A",{href:!0});var kct=s(Cj);bEo=r(kct,"RoFormerModel"),kct.forEach(t),vEo=r(a9e," (RoFormer model)"),a9e.forEach(t),FEo=i($),e_=n($,"LI",{});var n9e=s(e_);rce=n(n9e,"STRONG",{});var Sct=s(rce);TEo=r(Sct,"segformer"),Sct.forEach(t),MEo=r(n9e," \u2014 "),wj=n(n9e,"A",{href:!0});var Rct=s(wj);EEo=r(Rct,"SegformerModel"),Rct.forEach(t),CEo=r(n9e," (SegFormer model)"),n9e.forEach(t),wEo=i($),o_=n($,"LI",{});var s9e=s(o_);tce=n(s9e,"STRONG",{});var Pct=s(tce);AEo=r(Pct,"sew"),Pct.forEach(t),LEo=r(s9e," \u2014 "),Aj=n(s9e,"A",{href:!0});var Bct=s(Aj);yEo=r(Bct,"SEWModel"),Bct.forEach(t),xEo=r(s9e," (SEW model)"),s9e.forEach(t),$Eo=i($),r_=n($,"LI",{});var l9e=s(r_);ace=n(l9e,"STRONG",{});var Ict=s(ace);kEo=r(Ict,"sew-d"),Ict.forEach(t),SEo=r(l9e," \u2014 "),Lj=n(l9e,"A",{href:!0});var Nct=s(Lj);REo=r(Nct,"SEWDModel"),Nct.forEach(t),PEo=r(l9e," (SEW-D model)"),l9e.forEach(t),BEo=i($),t_=n($,"LI",{});var i9e=s(t_);nce=n(i9e,"STRONG",{});var qct=s(nce);IEo=r(qct,"speech_to_text"),qct.forEach(t),NEo=r(i9e," \u2014 "),yj=n(i9e,"A",{href:!0});var jct=s(yj);qEo=r(jct,"Speech2TextModel"),jct.forEach(t),jEo=r(i9e," (Speech2Text model)"),i9e.forEach(t),DEo=i($),a_=n($,"LI",{});var d9e=s(a_);sce=n(d9e,"STRONG",{});var Dct=s(sce);GEo=r(Dct,"splinter"),Dct.forEach(t),OEo=r(d9e," \u2014 "),xj=n(d9e,"A",{href:!0});var Gct=s(xj);VEo=r(Gct,"SplinterModel"),Gct.forEach(t),XEo=r(d9e," (Splinter model)"),d9e.forEach(t),zEo=i($),n_=n($,"LI",{});var c9e=s(n_);lce=n(c9e,"STRONG",{});var Oct=s(lce);WEo=r(Oct,"squeezebert"),Oct.forEach(t),QEo=r(c9e," \u2014 "),$j=n(c9e,"A",{href:!0});var Vct=s($j);HEo=r(Vct,"SqueezeBertModel"),Vct.forEach(t),UEo=r(c9e," (SqueezeBERT model)"),c9e.forEach(t),JEo=i($),s_=n($,"LI",{});var f9e=s(s_);ice=n(f9e,"STRONG",{});var Xct=s(ice);YEo=r(Xct,"swin"),Xct.forEach(t),KEo=r(f9e," \u2014 "),kj=n(f9e,"A",{href:!0});var zct=s(kj);ZEo=r(zct,"SwinModel"),zct.forEach(t),e4o=r(f9e," (Swin Transformer model)"),f9e.forEach(t),o4o=i($),l_=n($,"LI",{});var m9e=s(l_);dce=n(m9e,"STRONG",{});var Wct=s(dce);r4o=r(Wct,"t5"),Wct.forEach(t),t4o=r(m9e," \u2014 "),Sj=n(m9e,"A",{href:!0});var Qct=s(Sj);a4o=r(Qct,"T5Model"),Qct.forEach(t),n4o=r(m9e," (T5 model)"),m9e.forEach(t),s4o=i($),i_=n($,"LI",{});var g9e=s(i_);cce=n(g9e,"STRONG",{});var Hct=s(cce);l4o=r(Hct,"tapas"),Hct.forEach(t),i4o=r(g9e," \u2014 "),Rj=n(g9e,"A",{href:!0});var Uct=s(Rj);d4o=r(Uct,"TapasModel"),Uct.forEach(t),c4o=r(g9e," (TAPAS model)"),g9e.forEach(t),f4o=i($),d_=n($,"LI",{});var h9e=s(d_);fce=n(h9e,"STRONG",{});var Jct=s(fce);m4o=r(Jct,"trajectory_transformer"),Jct.forEach(t),g4o=r(h9e," \u2014 "),Pj=n(h9e,"A",{href:!0});var Yct=s(Pj);h4o=r(Yct,"TrajectoryTransformerModel"),Yct.forEach(t),p4o=r(h9e," (Trajectory Transformer model)"),h9e.forEach(t),u4o=i($),c_=n($,"LI",{});var p9e=s(c_);mce=n(p9e,"STRONG",{});var Kct=s(mce);_4o=r(Kct,"transfo-xl"),Kct.forEach(t),b4o=r(p9e," \u2014 "),Bj=n(p9e,"A",{href:!0});var Zct=s(Bj);v4o=r(Zct,"TransfoXLModel"),Zct.forEach(t),F4o=r(p9e," (Transformer-XL model)"),p9e.forEach(t),T4o=i($),f_=n($,"LI",{});var u9e=s(f_);gce=n(u9e,"STRONG",{});var eft=s(gce);M4o=r(eft,"unispeech"),eft.forEach(t),E4o=r(u9e," \u2014 "),Ij=n(u9e,"A",{href:!0});var oft=s(Ij);C4o=r(oft,"UniSpeechModel"),oft.forEach(t),w4o=r(u9e," (UniSpeech model)"),u9e.forEach(t),A4o=i($),m_=n($,"LI",{});var _9e=s(m_);hce=n(_9e,"STRONG",{});var rft=s(hce);L4o=r(rft,"unispeech-sat"),rft.forEach(t),y4o=r(_9e," \u2014 "),Nj=n(_9e,"A",{href:!0});var tft=s(Nj);x4o=r(tft,"UniSpeechSatModel"),tft.forEach(t),$4o=r(_9e," (UniSpeechSat model)"),_9e.forEach(t),k4o=i($),g_=n($,"LI",{});var b9e=s(g_);pce=n(b9e,"STRONG",{});var aft=s(pce);S4o=r(aft,"van"),aft.forEach(t),R4o=r(b9e," \u2014 "),qj=n(b9e,"A",{href:!0});var nft=s(qj);P4o=r(nft,"VanModel"),nft.forEach(t),B4o=r(b9e," (VAN model)"),b9e.forEach(t),I4o=i($),h_=n($,"LI",{});var v9e=s(h_);uce=n(v9e,"STRONG",{});var sft=s(uce);N4o=r(sft,"vilt"),sft.forEach(t),q4o=r(v9e," \u2014 "),jj=n(v9e,"A",{href:!0});var lft=s(jj);j4o=r(lft,"ViltModel"),lft.forEach(t),D4o=r(v9e," (ViLT model)"),v9e.forEach(t),G4o=i($),p_=n($,"LI",{});var F9e=s(p_);_ce=n(F9e,"STRONG",{});var ift=s(_ce);O4o=r(ift,"vision-text-dual-encoder"),ift.forEach(t),V4o=r(F9e," \u2014 "),Dj=n(F9e,"A",{href:!0});var dft=s(Dj);X4o=r(dft,"VisionTextDualEncoderModel"),dft.forEach(t),z4o=r(F9e," (VisionTextDualEncoder model)"),F9e.forEach(t),W4o=i($),u_=n($,"LI",{});var T9e=s(u_);bce=n(T9e,"STRONG",{});var cft=s(bce);Q4o=r(cft,"visual_bert"),cft.forEach(t),H4o=r(T9e," \u2014 "),Gj=n(T9e,"A",{href:!0});var fft=s(Gj);U4o=r(fft,"VisualBertModel"),fft.forEach(t),J4o=r(T9e," (VisualBERT model)"),T9e.forEach(t),Y4o=i($),__=n($,"LI",{});var M9e=s(__);vce=n(M9e,"STRONG",{});var mft=s(vce);K4o=r(mft,"vit"),mft.forEach(t),Z4o=r(M9e," \u2014 "),Oj=n(M9e,"A",{href:!0});var gft=s(Oj);eCo=r(gft,"ViTModel"),gft.forEach(t),oCo=r(M9e," (ViT model)"),M9e.forEach(t),rCo=i($),b_=n($,"LI",{});var E9e=s(b_);Fce=n(E9e,"STRONG",{});var hft=s(Fce);tCo=r(hft,"vit_mae"),hft.forEach(t),aCo=r(E9e," \u2014 "),Vj=n(E9e,"A",{href:!0});var pft=s(Vj);nCo=r(pft,"ViTMAEModel"),pft.forEach(t),sCo=r(E9e," (ViTMAE model)"),E9e.forEach(t),lCo=i($),v_=n($,"LI",{});var C9e=s(v_);Tce=n(C9e,"STRONG",{});var uft=s(Tce);iCo=r(uft,"wav2vec2"),uft.forEach(t),dCo=r(C9e," \u2014 "),Xj=n(C9e,"A",{href:!0});var _ft=s(Xj);cCo=r(_ft,"Wav2Vec2Model"),_ft.forEach(t),fCo=r(C9e," (Wav2Vec2 model)"),C9e.forEach(t),mCo=i($),F_=n($,"LI",{});var w9e=s(F_);Mce=n(w9e,"STRONG",{});var bft=s(Mce);gCo=r(bft,"wav2vec2-conformer"),bft.forEach(t),hCo=r(w9e," \u2014 "),zj=n(w9e,"A",{href:!0});var vft=s(zj);pCo=r(vft,"Wav2Vec2ConformerModel"),vft.forEach(t),uCo=r(w9e," (Wav2Vec2-Conformer model)"),w9e.forEach(t),_Co=i($),T_=n($,"LI",{});var A9e=s(T_);Ece=n(A9e,"STRONG",{});var Fft=s(Ece);bCo=r(Fft,"wavlm"),Fft.forEach(t),vCo=r(A9e," \u2014 "),Wj=n(A9e,"A",{href:!0});var Tft=s(Wj);FCo=r(Tft,"WavLMModel"),Tft.forEach(t),TCo=r(A9e," (WavLM model)"),A9e.forEach(t),MCo=i($),M_=n($,"LI",{});var L9e=s(M_);Cce=n(L9e,"STRONG",{});var Mft=s(Cce);ECo=r(Mft,"xglm"),Mft.forEach(t),CCo=r(L9e," \u2014 "),Qj=n(L9e,"A",{href:!0});var Eft=s(Qj);wCo=r(Eft,"XGLMModel"),Eft.forEach(t),ACo=r(L9e," (XGLM model)"),L9e.forEach(t),LCo=i($),E_=n($,"LI",{});var y9e=s(E_);wce=n(y9e,"STRONG",{});var Cft=s(wce);yCo=r(Cft,"xlm"),Cft.forEach(t),xCo=r(y9e," \u2014 "),Hj=n(y9e,"A",{href:!0});var wft=s(Hj);$Co=r(wft,"XLMModel"),wft.forEach(t),kCo=r(y9e," (XLM model)"),y9e.forEach(t),SCo=i($),C_=n($,"LI",{});var x9e=s(C_);Ace=n(x9e,"STRONG",{});var Aft=s(Ace);RCo=r(Aft,"xlm-prophetnet"),Aft.forEach(t),PCo=r(x9e," \u2014 "),Uj=n(x9e,"A",{href:!0});var Lft=s(Uj);BCo=r(Lft,"XLMProphetNetModel"),Lft.forEach(t),ICo=r(x9e," (XLM-ProphetNet model)"),x9e.forEach(t),NCo=i($),w_=n($,"LI",{});var $9e=s(w_);Lce=n($9e,"STRONG",{});var yft=s(Lce);qCo=r(yft,"xlm-roberta"),yft.forEach(t),jCo=r($9e," \u2014 "),Jj=n($9e,"A",{href:!0});var xft=s(Jj);DCo=r(xft,"XLMRobertaModel"),xft.forEach(t),GCo=r($9e," (XLM-RoBERTa model)"),$9e.forEach(t),OCo=i($),A_=n($,"LI",{});var k9e=s(A_);yce=n(k9e,"STRONG",{});var $ft=s(yce);VCo=r($ft,"xlm-roberta-xl"),$ft.forEach(t),XCo=r(k9e," \u2014 "),Yj=n(k9e,"A",{href:!0});var kft=s(Yj);zCo=r(kft,"XLMRobertaXLModel"),kft.forEach(t),WCo=r(k9e," (XLM-RoBERTa-XL model)"),k9e.forEach(t),QCo=i($),L_=n($,"LI",{});var S9e=s(L_);xce=n(S9e,"STRONG",{});var Sft=s(xce);HCo=r(Sft,"xlnet"),Sft.forEach(t),UCo=r(S9e," \u2014 "),Kj=n(S9e,"A",{href:!0});var Rft=s(Kj);JCo=r(Rft,"XLNetModel"),Rft.forEach(t),YCo=r(S9e," (XLNet model)"),S9e.forEach(t),KCo=i($),y_=n($,"LI",{});var R9e=s(y_);$ce=n(R9e,"STRONG",{});var Pft=s($ce);ZCo=r(Pft,"yolos"),Pft.forEach(t),e5o=r(R9e," \u2014 "),Zj=n(R9e,"A",{href:!0});var Bft=s(Zj);o5o=r(Bft,"YolosModel"),Bft.forEach(t),r5o=r(R9e," (YOLOS model)"),R9e.forEach(t),t5o=i($),x_=n($,"LI",{});var P9e=s(x_);kce=n(P9e,"STRONG",{});var Ift=s(kce);a5o=r(Ift,"yoso"),Ift.forEach(t),n5o=r(P9e," \u2014 "),eD=n(P9e,"A",{href:!0});var Nft=s(eD);s5o=r(Nft,"YosoModel"),Nft.forEach(t),l5o=r(P9e," (YOSO model)"),P9e.forEach(t),$.forEach(t),i5o=i(aa),$_=n(aa,"P",{});var B9e=s($_);d5o=r(B9e,"The model is set in evaluation mode by default using "),Sce=n(B9e,"CODE",{});var qft=s(Sce);c5o=r(qft,"model.eval()"),qft.forEach(t),f5o=r(B9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rce=n(B9e,"CODE",{});var jft=s(Rce);m5o=r(jft,"model.train()"),jft.forEach(t),B9e.forEach(t),g5o=i(aa),T(k_.$$.fragment,aa),aa.forEach(t),Js.forEach(t),PGe=i(f),qi=n(f,"H2",{class:!0});var DVe=s(qi);S_=n(DVe,"A",{id:!0,class:!0,href:!0});var Dft=s(S_);Pce=n(Dft,"SPAN",{});var Gft=s(Pce);T(oy.$$.fragment,Gft),Gft.forEach(t),Dft.forEach(t),h5o=i(DVe),Bce=n(DVe,"SPAN",{});var Oft=s(Bce);p5o=r(Oft,"AutoModelForPreTraining"),Oft.forEach(t),DVe.forEach(t),BGe=i(f),$o=n(f,"DIV",{class:!0});var Ys=s($o);T(ry.$$.fragment,Ys),u5o=i(Ys),ji=n(Ys,"P",{});var foe=s(ji);_5o=r(foe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),oD=n(foe,"A",{href:!0});var Vft=s(oD);b5o=r(Vft,"from_pretrained()"),Vft.forEach(t),v5o=r(foe," class method or the "),rD=n(foe,"A",{href:!0});var Xft=s(rD);F5o=r(Xft,"from_config()"),Xft.forEach(t),T5o=r(foe,` class
method.`),foe.forEach(t),M5o=i(Ys),ty=n(Ys,"P",{});var GVe=s(ty);E5o=r(GVe,"This class cannot be instantiated directly using "),Ice=n(GVe,"CODE",{});var zft=s(Ice);C5o=r(zft,"__init__()"),zft.forEach(t),w5o=r(GVe," (throws an error)."),GVe.forEach(t),A5o=i(Ys),st=n(Ys,"DIV",{class:!0});var yA=s(st);T(ay.$$.fragment,yA),L5o=i(yA),Nce=n(yA,"P",{});var Wft=s(Nce);y5o=r(Wft,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Wft.forEach(t),x5o=i(yA),Di=n(yA,"P",{});var moe=s(Di);$5o=r(moe,`Note:
Loading a model from its configuration file does `),qce=n(moe,"STRONG",{});var Qft=s(qce);k5o=r(Qft,"not"),Qft.forEach(t),S5o=r(moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tD=n(moe,"A",{href:!0});var Hft=s(tD);R5o=r(Hft,"from_pretrained()"),Hft.forEach(t),P5o=r(moe," to load the model weights."),moe.forEach(t),B5o=i(yA),T(R_.$$.fragment,yA),yA.forEach(t),I5o=i(Ys),Ye=n(Ys,"DIV",{class:!0});var na=s(Ye);T(ny.$$.fragment,na),N5o=i(na),jce=n(na,"P",{});var Uft=s(jce);q5o=r(Uft,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Uft.forEach(t),j5o=i(na),Ra=n(na,"P",{});var xA=s(Ra);D5o=r(xA,"The model class to instantiate is selected based on the "),Dce=n(xA,"CODE",{});var Jft=s(Dce);G5o=r(Jft,"model_type"),Jft.forEach(t),O5o=r(xA,` property of the config object (either
passed as an argument or loaded from `),Gce=n(xA,"CODE",{});var Yft=s(Gce);V5o=r(Yft,"pretrained_model_name_or_path"),Yft.forEach(t),X5o=r(xA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oce=n(xA,"CODE",{});var Kft=s(Oce);z5o=r(Kft,"pretrained_model_name_or_path"),Kft.forEach(t),W5o=r(xA,":"),xA.forEach(t),Q5o=i(na),G=n(na,"UL",{});var O=s(G);P_=n(O,"LI",{});var I9e=s(P_);Vce=n(I9e,"STRONG",{});var Zft=s(Vce);H5o=r(Zft,"albert"),Zft.forEach(t),U5o=r(I9e," \u2014 "),aD=n(I9e,"A",{href:!0});var emt=s(aD);J5o=r(emt,"AlbertForPreTraining"),emt.forEach(t),Y5o=r(I9e," (ALBERT model)"),I9e.forEach(t),K5o=i(O),B_=n(O,"LI",{});var N9e=s(B_);Xce=n(N9e,"STRONG",{});var omt=s(Xce);Z5o=r(omt,"bart"),omt.forEach(t),e0o=r(N9e," \u2014 "),nD=n(N9e,"A",{href:!0});var rmt=s(nD);o0o=r(rmt,"BartForConditionalGeneration"),rmt.forEach(t),r0o=r(N9e," (BART model)"),N9e.forEach(t),t0o=i(O),I_=n(O,"LI",{});var q9e=s(I_);zce=n(q9e,"STRONG",{});var tmt=s(zce);a0o=r(tmt,"bert"),tmt.forEach(t),n0o=r(q9e," \u2014 "),sD=n(q9e,"A",{href:!0});var amt=s(sD);s0o=r(amt,"BertForPreTraining"),amt.forEach(t),l0o=r(q9e," (BERT model)"),q9e.forEach(t),i0o=i(O),N_=n(O,"LI",{});var j9e=s(N_);Wce=n(j9e,"STRONG",{});var nmt=s(Wce);d0o=r(nmt,"big_bird"),nmt.forEach(t),c0o=r(j9e," \u2014 "),lD=n(j9e,"A",{href:!0});var smt=s(lD);f0o=r(smt,"BigBirdForPreTraining"),smt.forEach(t),m0o=r(j9e," (BigBird model)"),j9e.forEach(t),g0o=i(O),q_=n(O,"LI",{});var D9e=s(q_);Qce=n(D9e,"STRONG",{});var lmt=s(Qce);h0o=r(lmt,"bloom"),lmt.forEach(t),p0o=r(D9e," \u2014 "),iD=n(D9e,"A",{href:!0});var imt=s(iD);u0o=r(imt,"BloomForCausalLM"),imt.forEach(t),_0o=r(D9e," (BLOOM model)"),D9e.forEach(t),b0o=i(O),j_=n(O,"LI",{});var G9e=s(j_);Hce=n(G9e,"STRONG",{});var dmt=s(Hce);v0o=r(dmt,"camembert"),dmt.forEach(t),F0o=r(G9e," \u2014 "),dD=n(G9e,"A",{href:!0});var cmt=s(dD);T0o=r(cmt,"CamembertForMaskedLM"),cmt.forEach(t),M0o=r(G9e," (CamemBERT model)"),G9e.forEach(t),E0o=i(O),D_=n(O,"LI",{});var O9e=s(D_);Uce=n(O9e,"STRONG",{});var fmt=s(Uce);C0o=r(fmt,"ctrl"),fmt.forEach(t),w0o=r(O9e," \u2014 "),cD=n(O9e,"A",{href:!0});var mmt=s(cD);A0o=r(mmt,"CTRLLMHeadModel"),mmt.forEach(t),L0o=r(O9e," (CTRL model)"),O9e.forEach(t),y0o=i(O),G_=n(O,"LI",{});var V9e=s(G_);Jce=n(V9e,"STRONG",{});var gmt=s(Jce);x0o=r(gmt,"data2vec-text"),gmt.forEach(t),$0o=r(V9e," \u2014 "),fD=n(V9e,"A",{href:!0});var hmt=s(fD);k0o=r(hmt,"Data2VecTextForMaskedLM"),hmt.forEach(t),S0o=r(V9e," (Data2VecText model)"),V9e.forEach(t),R0o=i(O),O_=n(O,"LI",{});var X9e=s(O_);Yce=n(X9e,"STRONG",{});var pmt=s(Yce);P0o=r(pmt,"deberta"),pmt.forEach(t),B0o=r(X9e," \u2014 "),mD=n(X9e,"A",{href:!0});var umt=s(mD);I0o=r(umt,"DebertaForMaskedLM"),umt.forEach(t),N0o=r(X9e," (DeBERTa model)"),X9e.forEach(t),q0o=i(O),V_=n(O,"LI",{});var z9e=s(V_);Kce=n(z9e,"STRONG",{});var _mt=s(Kce);j0o=r(_mt,"deberta-v2"),_mt.forEach(t),D0o=r(z9e," \u2014 "),gD=n(z9e,"A",{href:!0});var bmt=s(gD);G0o=r(bmt,"DebertaV2ForMaskedLM"),bmt.forEach(t),O0o=r(z9e," (DeBERTa-v2 model)"),z9e.forEach(t),V0o=i(O),X_=n(O,"LI",{});var W9e=s(X_);Zce=n(W9e,"STRONG",{});var vmt=s(Zce);X0o=r(vmt,"distilbert"),vmt.forEach(t),z0o=r(W9e," \u2014 "),hD=n(W9e,"A",{href:!0});var Fmt=s(hD);W0o=r(Fmt,"DistilBertForMaskedLM"),Fmt.forEach(t),Q0o=r(W9e," (DistilBERT model)"),W9e.forEach(t),H0o=i(O),z_=n(O,"LI",{});var Q9e=s(z_);efe=n(Q9e,"STRONG",{});var Tmt=s(efe);U0o=r(Tmt,"electra"),Tmt.forEach(t),J0o=r(Q9e," \u2014 "),pD=n(Q9e,"A",{href:!0});var Mmt=s(pD);Y0o=r(Mmt,"ElectraForPreTraining"),Mmt.forEach(t),K0o=r(Q9e," (ELECTRA model)"),Q9e.forEach(t),Z0o=i(O),W_=n(O,"LI",{});var H9e=s(W_);ofe=n(H9e,"STRONG",{});var Emt=s(ofe);ewo=r(Emt,"flaubert"),Emt.forEach(t),owo=r(H9e," \u2014 "),uD=n(H9e,"A",{href:!0});var Cmt=s(uD);rwo=r(Cmt,"FlaubertWithLMHeadModel"),Cmt.forEach(t),two=r(H9e," (FlauBERT model)"),H9e.forEach(t),awo=i(O),Q_=n(O,"LI",{});var U9e=s(Q_);rfe=n(U9e,"STRONG",{});var wmt=s(rfe);nwo=r(wmt,"flava"),wmt.forEach(t),swo=r(U9e," \u2014 "),_D=n(U9e,"A",{href:!0});var Amt=s(_D);lwo=r(Amt,"FlavaForPreTraining"),Amt.forEach(t),iwo=r(U9e," (FLAVA model)"),U9e.forEach(t),dwo=i(O),H_=n(O,"LI",{});var J9e=s(H_);tfe=n(J9e,"STRONG",{});var Lmt=s(tfe);cwo=r(Lmt,"fnet"),Lmt.forEach(t),fwo=r(J9e," \u2014 "),bD=n(J9e,"A",{href:!0});var ymt=s(bD);mwo=r(ymt,"FNetForPreTraining"),ymt.forEach(t),gwo=r(J9e," (FNet model)"),J9e.forEach(t),hwo=i(O),U_=n(O,"LI",{});var Y9e=s(U_);afe=n(Y9e,"STRONG",{});var xmt=s(afe);pwo=r(xmt,"fsmt"),xmt.forEach(t),uwo=r(Y9e," \u2014 "),vD=n(Y9e,"A",{href:!0});var $mt=s(vD);_wo=r($mt,"FSMTForConditionalGeneration"),$mt.forEach(t),bwo=r(Y9e," (FairSeq Machine-Translation model)"),Y9e.forEach(t),vwo=i(O),J_=n(O,"LI",{});var K9e=s(J_);nfe=n(K9e,"STRONG",{});var kmt=s(nfe);Fwo=r(kmt,"funnel"),kmt.forEach(t),Two=r(K9e," \u2014 "),FD=n(K9e,"A",{href:!0});var Smt=s(FD);Mwo=r(Smt,"FunnelForPreTraining"),Smt.forEach(t),Ewo=r(K9e," (Funnel Transformer model)"),K9e.forEach(t),Cwo=i(O),Y_=n(O,"LI",{});var Z9e=s(Y_);sfe=n(Z9e,"STRONG",{});var Rmt=s(sfe);wwo=r(Rmt,"gpt2"),Rmt.forEach(t),Awo=r(Z9e," \u2014 "),TD=n(Z9e,"A",{href:!0});var Pmt=s(TD);Lwo=r(Pmt,"GPT2LMHeadModel"),Pmt.forEach(t),ywo=r(Z9e," (OpenAI GPT-2 model)"),Z9e.forEach(t),xwo=i(O),K_=n(O,"LI",{});var exe=s(K_);lfe=n(exe,"STRONG",{});var Bmt=s(lfe);$wo=r(Bmt,"ibert"),Bmt.forEach(t),kwo=r(exe," \u2014 "),MD=n(exe,"A",{href:!0});var Imt=s(MD);Swo=r(Imt,"IBertForMaskedLM"),Imt.forEach(t),Rwo=r(exe," (I-BERT model)"),exe.forEach(t),Pwo=i(O),Z_=n(O,"LI",{});var oxe=s(Z_);ife=n(oxe,"STRONG",{});var Nmt=s(ife);Bwo=r(Nmt,"layoutlm"),Nmt.forEach(t),Iwo=r(oxe," \u2014 "),ED=n(oxe,"A",{href:!0});var qmt=s(ED);Nwo=r(qmt,"LayoutLMForMaskedLM"),qmt.forEach(t),qwo=r(oxe," (LayoutLM model)"),oxe.forEach(t),jwo=i(O),e1=n(O,"LI",{});var rxe=s(e1);dfe=n(rxe,"STRONG",{});var jmt=s(dfe);Dwo=r(jmt,"longformer"),jmt.forEach(t),Gwo=r(rxe," \u2014 "),CD=n(rxe,"A",{href:!0});var Dmt=s(CD);Owo=r(Dmt,"LongformerForMaskedLM"),Dmt.forEach(t),Vwo=r(rxe," (Longformer model)"),rxe.forEach(t),Xwo=i(O),o1=n(O,"LI",{});var txe=s(o1);cfe=n(txe,"STRONG",{});var Gmt=s(cfe);zwo=r(Gmt,"lxmert"),Gmt.forEach(t),Wwo=r(txe," \u2014 "),wD=n(txe,"A",{href:!0});var Omt=s(wD);Qwo=r(Omt,"LxmertForPreTraining"),Omt.forEach(t),Hwo=r(txe," (LXMERT model)"),txe.forEach(t),Uwo=i(O),r1=n(O,"LI",{});var axe=s(r1);ffe=n(axe,"STRONG",{});var Vmt=s(ffe);Jwo=r(Vmt,"megatron-bert"),Vmt.forEach(t),Ywo=r(axe," \u2014 "),AD=n(axe,"A",{href:!0});var Xmt=s(AD);Kwo=r(Xmt,"MegatronBertForPreTraining"),Xmt.forEach(t),Zwo=r(axe," (Megatron-BERT model)"),axe.forEach(t),eAo=i(O),t1=n(O,"LI",{});var nxe=s(t1);mfe=n(nxe,"STRONG",{});var zmt=s(mfe);oAo=r(zmt,"mobilebert"),zmt.forEach(t),rAo=r(nxe," \u2014 "),LD=n(nxe,"A",{href:!0});var Wmt=s(LD);tAo=r(Wmt,"MobileBertForPreTraining"),Wmt.forEach(t),aAo=r(nxe," (MobileBERT model)"),nxe.forEach(t),nAo=i(O),a1=n(O,"LI",{});var sxe=s(a1);gfe=n(sxe,"STRONG",{});var Qmt=s(gfe);sAo=r(Qmt,"mpnet"),Qmt.forEach(t),lAo=r(sxe," \u2014 "),yD=n(sxe,"A",{href:!0});var Hmt=s(yD);iAo=r(Hmt,"MPNetForMaskedLM"),Hmt.forEach(t),dAo=r(sxe," (MPNet model)"),sxe.forEach(t),cAo=i(O),n1=n(O,"LI",{});var lxe=s(n1);hfe=n(lxe,"STRONG",{});var Umt=s(hfe);fAo=r(Umt,"openai-gpt"),Umt.forEach(t),mAo=r(lxe," \u2014 "),xD=n(lxe,"A",{href:!0});var Jmt=s(xD);gAo=r(Jmt,"OpenAIGPTLMHeadModel"),Jmt.forEach(t),hAo=r(lxe," (OpenAI GPT model)"),lxe.forEach(t),pAo=i(O),s1=n(O,"LI",{});var ixe=s(s1);pfe=n(ixe,"STRONG",{});var Ymt=s(pfe);uAo=r(Ymt,"retribert"),Ymt.forEach(t),_Ao=r(ixe," \u2014 "),$D=n(ixe,"A",{href:!0});var Kmt=s($D);bAo=r(Kmt,"RetriBertModel"),Kmt.forEach(t),vAo=r(ixe," (RetriBERT model)"),ixe.forEach(t),FAo=i(O),l1=n(O,"LI",{});var dxe=s(l1);ufe=n(dxe,"STRONG",{});var Zmt=s(ufe);TAo=r(Zmt,"roberta"),Zmt.forEach(t),MAo=r(dxe," \u2014 "),kD=n(dxe,"A",{href:!0});var egt=s(kD);EAo=r(egt,"RobertaForMaskedLM"),egt.forEach(t),CAo=r(dxe," (RoBERTa model)"),dxe.forEach(t),wAo=i(O),i1=n(O,"LI",{});var cxe=s(i1);_fe=n(cxe,"STRONG",{});var ogt=s(_fe);AAo=r(ogt,"splinter"),ogt.forEach(t),LAo=r(cxe," \u2014 "),SD=n(cxe,"A",{href:!0});var rgt=s(SD);yAo=r(rgt,"SplinterForPreTraining"),rgt.forEach(t),xAo=r(cxe," (Splinter model)"),cxe.forEach(t),$Ao=i(O),d1=n(O,"LI",{});var fxe=s(d1);bfe=n(fxe,"STRONG",{});var tgt=s(bfe);kAo=r(tgt,"squeezebert"),tgt.forEach(t),SAo=r(fxe," \u2014 "),RD=n(fxe,"A",{href:!0});var agt=s(RD);RAo=r(agt,"SqueezeBertForMaskedLM"),agt.forEach(t),PAo=r(fxe," (SqueezeBERT model)"),fxe.forEach(t),BAo=i(O),c1=n(O,"LI",{});var mxe=s(c1);vfe=n(mxe,"STRONG",{});var ngt=s(vfe);IAo=r(ngt,"t5"),ngt.forEach(t),NAo=r(mxe," \u2014 "),PD=n(mxe,"A",{href:!0});var sgt=s(PD);qAo=r(sgt,"T5ForConditionalGeneration"),sgt.forEach(t),jAo=r(mxe," (T5 model)"),mxe.forEach(t),DAo=i(O),f1=n(O,"LI",{});var gxe=s(f1);Ffe=n(gxe,"STRONG",{});var lgt=s(Ffe);GAo=r(lgt,"tapas"),lgt.forEach(t),OAo=r(gxe," \u2014 "),BD=n(gxe,"A",{href:!0});var igt=s(BD);VAo=r(igt,"TapasForMaskedLM"),igt.forEach(t),XAo=r(gxe," (TAPAS model)"),gxe.forEach(t),zAo=i(O),m1=n(O,"LI",{});var hxe=s(m1);Tfe=n(hxe,"STRONG",{});var dgt=s(Tfe);WAo=r(dgt,"transfo-xl"),dgt.forEach(t),QAo=r(hxe," \u2014 "),ID=n(hxe,"A",{href:!0});var cgt=s(ID);HAo=r(cgt,"TransfoXLLMHeadModel"),cgt.forEach(t),UAo=r(hxe," (Transformer-XL model)"),hxe.forEach(t),JAo=i(O),g1=n(O,"LI",{});var pxe=s(g1);Mfe=n(pxe,"STRONG",{});var fgt=s(Mfe);YAo=r(fgt,"unispeech"),fgt.forEach(t),KAo=r(pxe," \u2014 "),ND=n(pxe,"A",{href:!0});var mgt=s(ND);ZAo=r(mgt,"UniSpeechForPreTraining"),mgt.forEach(t),e6o=r(pxe," (UniSpeech model)"),pxe.forEach(t),o6o=i(O),h1=n(O,"LI",{});var uxe=s(h1);Efe=n(uxe,"STRONG",{});var ggt=s(Efe);r6o=r(ggt,"unispeech-sat"),ggt.forEach(t),t6o=r(uxe," \u2014 "),qD=n(uxe,"A",{href:!0});var hgt=s(qD);a6o=r(hgt,"UniSpeechSatForPreTraining"),hgt.forEach(t),n6o=r(uxe," (UniSpeechSat model)"),uxe.forEach(t),s6o=i(O),p1=n(O,"LI",{});var _xe=s(p1);Cfe=n(_xe,"STRONG",{});var pgt=s(Cfe);l6o=r(pgt,"visual_bert"),pgt.forEach(t),i6o=r(_xe," \u2014 "),jD=n(_xe,"A",{href:!0});var ugt=s(jD);d6o=r(ugt,"VisualBertForPreTraining"),ugt.forEach(t),c6o=r(_xe," (VisualBERT model)"),_xe.forEach(t),f6o=i(O),u1=n(O,"LI",{});var bxe=s(u1);wfe=n(bxe,"STRONG",{});var _gt=s(wfe);m6o=r(_gt,"vit_mae"),_gt.forEach(t),g6o=r(bxe," \u2014 "),DD=n(bxe,"A",{href:!0});var bgt=s(DD);h6o=r(bgt,"ViTMAEForPreTraining"),bgt.forEach(t),p6o=r(bxe," (ViTMAE model)"),bxe.forEach(t),u6o=i(O),_1=n(O,"LI",{});var vxe=s(_1);Afe=n(vxe,"STRONG",{});var vgt=s(Afe);_6o=r(vgt,"wav2vec2"),vgt.forEach(t),b6o=r(vxe," \u2014 "),GD=n(vxe,"A",{href:!0});var Fgt=s(GD);v6o=r(Fgt,"Wav2Vec2ForPreTraining"),Fgt.forEach(t),F6o=r(vxe," (Wav2Vec2 model)"),vxe.forEach(t),T6o=i(O),b1=n(O,"LI",{});var Fxe=s(b1);Lfe=n(Fxe,"STRONG",{});var Tgt=s(Lfe);M6o=r(Tgt,"wav2vec2-conformer"),Tgt.forEach(t),E6o=r(Fxe," \u2014 "),OD=n(Fxe,"A",{href:!0});var Mgt=s(OD);C6o=r(Mgt,"Wav2Vec2ConformerForPreTraining"),Mgt.forEach(t),w6o=r(Fxe," (Wav2Vec2-Conformer model)"),Fxe.forEach(t),A6o=i(O),v1=n(O,"LI",{});var Txe=s(v1);yfe=n(Txe,"STRONG",{});var Egt=s(yfe);L6o=r(Egt,"xlm"),Egt.forEach(t),y6o=r(Txe," \u2014 "),VD=n(Txe,"A",{href:!0});var Cgt=s(VD);x6o=r(Cgt,"XLMWithLMHeadModel"),Cgt.forEach(t),$6o=r(Txe," (XLM model)"),Txe.forEach(t),k6o=i(O),F1=n(O,"LI",{});var Mxe=s(F1);xfe=n(Mxe,"STRONG",{});var wgt=s(xfe);S6o=r(wgt,"xlm-roberta"),wgt.forEach(t),R6o=r(Mxe," \u2014 "),XD=n(Mxe,"A",{href:!0});var Agt=s(XD);P6o=r(Agt,"XLMRobertaForMaskedLM"),Agt.forEach(t),B6o=r(Mxe," (XLM-RoBERTa model)"),Mxe.forEach(t),I6o=i(O),T1=n(O,"LI",{});var Exe=s(T1);$fe=n(Exe,"STRONG",{});var Lgt=s($fe);N6o=r(Lgt,"xlm-roberta-xl"),Lgt.forEach(t),q6o=r(Exe," \u2014 "),zD=n(Exe,"A",{href:!0});var ygt=s(zD);j6o=r(ygt,"XLMRobertaXLForMaskedLM"),ygt.forEach(t),D6o=r(Exe," (XLM-RoBERTa-XL model)"),Exe.forEach(t),G6o=i(O),M1=n(O,"LI",{});var Cxe=s(M1);kfe=n(Cxe,"STRONG",{});var xgt=s(kfe);O6o=r(xgt,"xlnet"),xgt.forEach(t),V6o=r(Cxe," \u2014 "),WD=n(Cxe,"A",{href:!0});var $gt=s(WD);X6o=r($gt,"XLNetLMHeadModel"),$gt.forEach(t),z6o=r(Cxe," (XLNet model)"),Cxe.forEach(t),O.forEach(t),W6o=i(na),E1=n(na,"P",{});var wxe=s(E1);Q6o=r(wxe,"The model is set in evaluation mode by default using "),Sfe=n(wxe,"CODE",{});var kgt=s(Sfe);H6o=r(kgt,"model.eval()"),kgt.forEach(t),U6o=r(wxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rfe=n(wxe,"CODE",{});var Sgt=s(Rfe);J6o=r(Sgt,"model.train()"),Sgt.forEach(t),wxe.forEach(t),Y6o=i(na),T(C1.$$.fragment,na),na.forEach(t),Ys.forEach(t),IGe=i(f),Gi=n(f,"H2",{class:!0});var OVe=s(Gi);w1=n(OVe,"A",{id:!0,class:!0,href:!0});var Rgt=s(w1);Pfe=n(Rgt,"SPAN",{});var Pgt=s(Pfe);T(sy.$$.fragment,Pgt),Pgt.forEach(t),Rgt.forEach(t),K6o=i(OVe),Bfe=n(OVe,"SPAN",{});var Bgt=s(Bfe);Z6o=r(Bgt,"AutoModelForCausalLM"),Bgt.forEach(t),OVe.forEach(t),NGe=i(f),ko=n(f,"DIV",{class:!0});var Ks=s(ko);T(ly.$$.fragment,Ks),eLo=i(Ks),Oi=n(Ks,"P",{});var goe=s(Oi);oLo=r(goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),QD=n(goe,"A",{href:!0});var Igt=s(QD);rLo=r(Igt,"from_pretrained()"),Igt.forEach(t),tLo=r(goe," class method or the "),HD=n(goe,"A",{href:!0});var Ngt=s(HD);aLo=r(Ngt,"from_config()"),Ngt.forEach(t),nLo=r(goe,` class
method.`),goe.forEach(t),sLo=i(Ks),iy=n(Ks,"P",{});var VVe=s(iy);lLo=r(VVe,"This class cannot be instantiated directly using "),Ife=n(VVe,"CODE",{});var qgt=s(Ife);iLo=r(qgt,"__init__()"),qgt.forEach(t),dLo=r(VVe," (throws an error)."),VVe.forEach(t),cLo=i(Ks),lt=n(Ks,"DIV",{class:!0});var $A=s(lt);T(dy.$$.fragment,$A),fLo=i($A),Nfe=n($A,"P",{});var jgt=s(Nfe);mLo=r(jgt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),jgt.forEach(t),gLo=i($A),Vi=n($A,"P",{});var hoe=s(Vi);hLo=r(hoe,`Note:
Loading a model from its configuration file does `),qfe=n(hoe,"STRONG",{});var Dgt=s(qfe);pLo=r(Dgt,"not"),Dgt.forEach(t),uLo=r(hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),UD=n(hoe,"A",{href:!0});var Ggt=s(UD);_Lo=r(Ggt,"from_pretrained()"),Ggt.forEach(t),bLo=r(hoe," to load the model weights."),hoe.forEach(t),vLo=i($A),T(A1.$$.fragment,$A),$A.forEach(t),FLo=i(Ks),Ke=n(Ks,"DIV",{class:!0});var sa=s(Ke);T(cy.$$.fragment,sa),TLo=i(sa),jfe=n(sa,"P",{});var Ogt=s(jfe);MLo=r(Ogt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Ogt.forEach(t),ELo=i(sa),Pa=n(sa,"P",{});var kA=s(Pa);CLo=r(kA,"The model class to instantiate is selected based on the "),Dfe=n(kA,"CODE",{});var Vgt=s(Dfe);wLo=r(Vgt,"model_type"),Vgt.forEach(t),ALo=r(kA,` property of the config object (either
passed as an argument or loaded from `),Gfe=n(kA,"CODE",{});var Xgt=s(Gfe);LLo=r(Xgt,"pretrained_model_name_or_path"),Xgt.forEach(t),yLo=r(kA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ofe=n(kA,"CODE",{});var zgt=s(Ofe);xLo=r(zgt,"pretrained_model_name_or_path"),zgt.forEach(t),$Lo=r(kA,":"),kA.forEach(t),kLo=i(sa),z=n(sa,"UL",{});var W=s(z);L1=n(W,"LI",{});var Axe=s(L1);Vfe=n(Axe,"STRONG",{});var Wgt=s(Vfe);SLo=r(Wgt,"bart"),Wgt.forEach(t),RLo=r(Axe," \u2014 "),JD=n(Axe,"A",{href:!0});var Qgt=s(JD);PLo=r(Qgt,"BartForCausalLM"),Qgt.forEach(t),BLo=r(Axe," (BART model)"),Axe.forEach(t),ILo=i(W),y1=n(W,"LI",{});var Lxe=s(y1);Xfe=n(Lxe,"STRONG",{});var Hgt=s(Xfe);NLo=r(Hgt,"bert"),Hgt.forEach(t),qLo=r(Lxe," \u2014 "),YD=n(Lxe,"A",{href:!0});var Ugt=s(YD);jLo=r(Ugt,"BertLMHeadModel"),Ugt.forEach(t),DLo=r(Lxe," (BERT model)"),Lxe.forEach(t),GLo=i(W),x1=n(W,"LI",{});var yxe=s(x1);zfe=n(yxe,"STRONG",{});var Jgt=s(zfe);OLo=r(Jgt,"bert-generation"),Jgt.forEach(t),VLo=r(yxe," \u2014 "),KD=n(yxe,"A",{href:!0});var Ygt=s(KD);XLo=r(Ygt,"BertGenerationDecoder"),Ygt.forEach(t),zLo=r(yxe," (Bert Generation model)"),yxe.forEach(t),WLo=i(W),$1=n(W,"LI",{});var xxe=s($1);Wfe=n(xxe,"STRONG",{});var Kgt=s(Wfe);QLo=r(Kgt,"big_bird"),Kgt.forEach(t),HLo=r(xxe," \u2014 "),ZD=n(xxe,"A",{href:!0});var Zgt=s(ZD);ULo=r(Zgt,"BigBirdForCausalLM"),Zgt.forEach(t),JLo=r(xxe," (BigBird model)"),xxe.forEach(t),YLo=i(W),k1=n(W,"LI",{});var $xe=s(k1);Qfe=n($xe,"STRONG",{});var eht=s(Qfe);KLo=r(eht,"bigbird_pegasus"),eht.forEach(t),ZLo=r($xe," \u2014 "),eG=n($xe,"A",{href:!0});var oht=s(eG);eyo=r(oht,"BigBirdPegasusForCausalLM"),oht.forEach(t),oyo=r($xe," (BigBird-Pegasus model)"),$xe.forEach(t),ryo=i(W),S1=n(W,"LI",{});var kxe=s(S1);Hfe=n(kxe,"STRONG",{});var rht=s(Hfe);tyo=r(rht,"blenderbot"),rht.forEach(t),ayo=r(kxe," \u2014 "),oG=n(kxe,"A",{href:!0});var tht=s(oG);nyo=r(tht,"BlenderbotForCausalLM"),tht.forEach(t),syo=r(kxe," (Blenderbot model)"),kxe.forEach(t),lyo=i(W),R1=n(W,"LI",{});var Sxe=s(R1);Ufe=n(Sxe,"STRONG",{});var aht=s(Ufe);iyo=r(aht,"blenderbot-small"),aht.forEach(t),dyo=r(Sxe," \u2014 "),rG=n(Sxe,"A",{href:!0});var nht=s(rG);cyo=r(nht,"BlenderbotSmallForCausalLM"),nht.forEach(t),fyo=r(Sxe," (BlenderbotSmall model)"),Sxe.forEach(t),myo=i(W),P1=n(W,"LI",{});var Rxe=s(P1);Jfe=n(Rxe,"STRONG",{});var sht=s(Jfe);gyo=r(sht,"bloom"),sht.forEach(t),hyo=r(Rxe," \u2014 "),tG=n(Rxe,"A",{href:!0});var lht=s(tG);pyo=r(lht,"BloomForCausalLM"),lht.forEach(t),uyo=r(Rxe," (BLOOM model)"),Rxe.forEach(t),_yo=i(W),B1=n(W,"LI",{});var Pxe=s(B1);Yfe=n(Pxe,"STRONG",{});var iht=s(Yfe);byo=r(iht,"camembert"),iht.forEach(t),vyo=r(Pxe," \u2014 "),aG=n(Pxe,"A",{href:!0});var dht=s(aG);Fyo=r(dht,"CamembertForCausalLM"),dht.forEach(t),Tyo=r(Pxe," (CamemBERT model)"),Pxe.forEach(t),Myo=i(W),I1=n(W,"LI",{});var Bxe=s(I1);Kfe=n(Bxe,"STRONG",{});var cht=s(Kfe);Eyo=r(cht,"ctrl"),cht.forEach(t),Cyo=r(Bxe," \u2014 "),nG=n(Bxe,"A",{href:!0});var fht=s(nG);wyo=r(fht,"CTRLLMHeadModel"),fht.forEach(t),Ayo=r(Bxe," (CTRL model)"),Bxe.forEach(t),Lyo=i(W),N1=n(W,"LI",{});var Ixe=s(N1);Zfe=n(Ixe,"STRONG",{});var mht=s(Zfe);yyo=r(mht,"data2vec-text"),mht.forEach(t),xyo=r(Ixe," \u2014 "),sG=n(Ixe,"A",{href:!0});var ght=s(sG);$yo=r(ght,"Data2VecTextForCausalLM"),ght.forEach(t),kyo=r(Ixe," (Data2VecText model)"),Ixe.forEach(t),Syo=i(W),q1=n(W,"LI",{});var Nxe=s(q1);eme=n(Nxe,"STRONG",{});var hht=s(eme);Ryo=r(hht,"electra"),hht.forEach(t),Pyo=r(Nxe," \u2014 "),lG=n(Nxe,"A",{href:!0});var pht=s(lG);Byo=r(pht,"ElectraForCausalLM"),pht.forEach(t),Iyo=r(Nxe," (ELECTRA model)"),Nxe.forEach(t),Nyo=i(W),j1=n(W,"LI",{});var qxe=s(j1);ome=n(qxe,"STRONG",{});var uht=s(ome);qyo=r(uht,"gpt2"),uht.forEach(t),jyo=r(qxe," \u2014 "),iG=n(qxe,"A",{href:!0});var _ht=s(iG);Dyo=r(_ht,"GPT2LMHeadModel"),_ht.forEach(t),Gyo=r(qxe," (OpenAI GPT-2 model)"),qxe.forEach(t),Oyo=i(W),D1=n(W,"LI",{});var jxe=s(D1);rme=n(jxe,"STRONG",{});var bht=s(rme);Vyo=r(bht,"gpt_neo"),bht.forEach(t),Xyo=r(jxe," \u2014 "),dG=n(jxe,"A",{href:!0});var vht=s(dG);zyo=r(vht,"GPTNeoForCausalLM"),vht.forEach(t),Wyo=r(jxe," (GPT Neo model)"),jxe.forEach(t),Qyo=i(W),G1=n(W,"LI",{});var Dxe=s(G1);tme=n(Dxe,"STRONG",{});var Fht=s(tme);Hyo=r(Fht,"gpt_neox"),Fht.forEach(t),Uyo=r(Dxe," \u2014 "),cG=n(Dxe,"A",{href:!0});var Tht=s(cG);Jyo=r(Tht,"GPTNeoXForCausalLM"),Tht.forEach(t),Yyo=r(Dxe," (GPT NeoX model)"),Dxe.forEach(t),Kyo=i(W),O1=n(W,"LI",{});var Gxe=s(O1);ame=n(Gxe,"STRONG",{});var Mht=s(ame);Zyo=r(Mht,"gptj"),Mht.forEach(t),e8o=r(Gxe," \u2014 "),fG=n(Gxe,"A",{href:!0});var Eht=s(fG);o8o=r(Eht,"GPTJForCausalLM"),Eht.forEach(t),r8o=r(Gxe," (GPT-J model)"),Gxe.forEach(t),t8o=i(W),V1=n(W,"LI",{});var Oxe=s(V1);nme=n(Oxe,"STRONG",{});var Cht=s(nme);a8o=r(Cht,"marian"),Cht.forEach(t),n8o=r(Oxe," \u2014 "),mG=n(Oxe,"A",{href:!0});var wht=s(mG);s8o=r(wht,"MarianForCausalLM"),wht.forEach(t),l8o=r(Oxe," (Marian model)"),Oxe.forEach(t),i8o=i(W),X1=n(W,"LI",{});var Vxe=s(X1);sme=n(Vxe,"STRONG",{});var Aht=s(sme);d8o=r(Aht,"mbart"),Aht.forEach(t),c8o=r(Vxe," \u2014 "),gG=n(Vxe,"A",{href:!0});var Lht=s(gG);f8o=r(Lht,"MBartForCausalLM"),Lht.forEach(t),m8o=r(Vxe," (mBART model)"),Vxe.forEach(t),g8o=i(W),z1=n(W,"LI",{});var Xxe=s(z1);lme=n(Xxe,"STRONG",{});var yht=s(lme);h8o=r(yht,"megatron-bert"),yht.forEach(t),p8o=r(Xxe," \u2014 "),hG=n(Xxe,"A",{href:!0});var xht=s(hG);u8o=r(xht,"MegatronBertForCausalLM"),xht.forEach(t),_8o=r(Xxe," (Megatron-BERT model)"),Xxe.forEach(t),b8o=i(W),W1=n(W,"LI",{});var zxe=s(W1);ime=n(zxe,"STRONG",{});var $ht=s(ime);v8o=r($ht,"openai-gpt"),$ht.forEach(t),F8o=r(zxe," \u2014 "),pG=n(zxe,"A",{href:!0});var kht=s(pG);T8o=r(kht,"OpenAIGPTLMHeadModel"),kht.forEach(t),M8o=r(zxe," (OpenAI GPT model)"),zxe.forEach(t),E8o=i(W),Q1=n(W,"LI",{});var Wxe=s(Q1);dme=n(Wxe,"STRONG",{});var Sht=s(dme);C8o=r(Sht,"opt"),Sht.forEach(t),w8o=r(Wxe," \u2014 "),uG=n(Wxe,"A",{href:!0});var Rht=s(uG);A8o=r(Rht,"OPTForCausalLM"),Rht.forEach(t),L8o=r(Wxe," (OPT model)"),Wxe.forEach(t),y8o=i(W),H1=n(W,"LI",{});var Qxe=s(H1);cme=n(Qxe,"STRONG",{});var Pht=s(cme);x8o=r(Pht,"pegasus"),Pht.forEach(t),$8o=r(Qxe," \u2014 "),_G=n(Qxe,"A",{href:!0});var Bht=s(_G);k8o=r(Bht,"PegasusForCausalLM"),Bht.forEach(t),S8o=r(Qxe," (Pegasus model)"),Qxe.forEach(t),R8o=i(W),U1=n(W,"LI",{});var Hxe=s(U1);fme=n(Hxe,"STRONG",{});var Iht=s(fme);P8o=r(Iht,"plbart"),Iht.forEach(t),B8o=r(Hxe," \u2014 "),bG=n(Hxe,"A",{href:!0});var Nht=s(bG);I8o=r(Nht,"PLBartForCausalLM"),Nht.forEach(t),N8o=r(Hxe," (PLBart model)"),Hxe.forEach(t),q8o=i(W),J1=n(W,"LI",{});var Uxe=s(J1);mme=n(Uxe,"STRONG",{});var qht=s(mme);j8o=r(qht,"prophetnet"),qht.forEach(t),D8o=r(Uxe," \u2014 "),vG=n(Uxe,"A",{href:!0});var jht=s(vG);G8o=r(jht,"ProphetNetForCausalLM"),jht.forEach(t),O8o=r(Uxe," (ProphetNet model)"),Uxe.forEach(t),V8o=i(W),Y1=n(W,"LI",{});var Jxe=s(Y1);gme=n(Jxe,"STRONG",{});var Dht=s(gme);X8o=r(Dht,"qdqbert"),Dht.forEach(t),z8o=r(Jxe," \u2014 "),FG=n(Jxe,"A",{href:!0});var Ght=s(FG);W8o=r(Ght,"QDQBertLMHeadModel"),Ght.forEach(t),Q8o=r(Jxe," (QDQBert model)"),Jxe.forEach(t),H8o=i(W),K1=n(W,"LI",{});var Yxe=s(K1);hme=n(Yxe,"STRONG",{});var Oht=s(hme);U8o=r(Oht,"reformer"),Oht.forEach(t),J8o=r(Yxe," \u2014 "),TG=n(Yxe,"A",{href:!0});var Vht=s(TG);Y8o=r(Vht,"ReformerModelWithLMHead"),Vht.forEach(t),K8o=r(Yxe," (Reformer model)"),Yxe.forEach(t),Z8o=i(W),Z1=n(W,"LI",{});var Kxe=s(Z1);pme=n(Kxe,"STRONG",{});var Xht=s(pme);e9o=r(Xht,"rembert"),Xht.forEach(t),o9o=r(Kxe," \u2014 "),MG=n(Kxe,"A",{href:!0});var zht=s(MG);r9o=r(zht,"RemBertForCausalLM"),zht.forEach(t),t9o=r(Kxe," (RemBERT model)"),Kxe.forEach(t),a9o=i(W),e3=n(W,"LI",{});var Zxe=s(e3);ume=n(Zxe,"STRONG",{});var Wht=s(ume);n9o=r(Wht,"roberta"),Wht.forEach(t),s9o=r(Zxe," \u2014 "),EG=n(Zxe,"A",{href:!0});var Qht=s(EG);l9o=r(Qht,"RobertaForCausalLM"),Qht.forEach(t),i9o=r(Zxe," (RoBERTa model)"),Zxe.forEach(t),d9o=i(W),o3=n(W,"LI",{});var e$e=s(o3);_me=n(e$e,"STRONG",{});var Hht=s(_me);c9o=r(Hht,"roformer"),Hht.forEach(t),f9o=r(e$e," \u2014 "),CG=n(e$e,"A",{href:!0});var Uht=s(CG);m9o=r(Uht,"RoFormerForCausalLM"),Uht.forEach(t),g9o=r(e$e," (RoFormer model)"),e$e.forEach(t),h9o=i(W),r3=n(W,"LI",{});var o$e=s(r3);bme=n(o$e,"STRONG",{});var Jht=s(bme);p9o=r(Jht,"speech_to_text_2"),Jht.forEach(t),u9o=r(o$e," \u2014 "),wG=n(o$e,"A",{href:!0});var Yht=s(wG);_9o=r(Yht,"Speech2Text2ForCausalLM"),Yht.forEach(t),b9o=r(o$e," (Speech2Text2 model)"),o$e.forEach(t),v9o=i(W),t3=n(W,"LI",{});var r$e=s(t3);vme=n(r$e,"STRONG",{});var Kht=s(vme);F9o=r(Kht,"transfo-xl"),Kht.forEach(t),T9o=r(r$e," \u2014 "),AG=n(r$e,"A",{href:!0});var Zht=s(AG);M9o=r(Zht,"TransfoXLLMHeadModel"),Zht.forEach(t),E9o=r(r$e," (Transformer-XL model)"),r$e.forEach(t),C9o=i(W),a3=n(W,"LI",{});var t$e=s(a3);Fme=n(t$e,"STRONG",{});var ept=s(Fme);w9o=r(ept,"trocr"),ept.forEach(t),A9o=r(t$e," \u2014 "),LG=n(t$e,"A",{href:!0});var opt=s(LG);L9o=r(opt,"TrOCRForCausalLM"),opt.forEach(t),y9o=r(t$e," (TrOCR model)"),t$e.forEach(t),x9o=i(W),n3=n(W,"LI",{});var a$e=s(n3);Tme=n(a$e,"STRONG",{});var rpt=s(Tme);$9o=r(rpt,"xglm"),rpt.forEach(t),k9o=r(a$e," \u2014 "),yG=n(a$e,"A",{href:!0});var tpt=s(yG);S9o=r(tpt,"XGLMForCausalLM"),tpt.forEach(t),R9o=r(a$e," (XGLM model)"),a$e.forEach(t),P9o=i(W),s3=n(W,"LI",{});var n$e=s(s3);Mme=n(n$e,"STRONG",{});var apt=s(Mme);B9o=r(apt,"xlm"),apt.forEach(t),I9o=r(n$e," \u2014 "),xG=n(n$e,"A",{href:!0});var npt=s(xG);N9o=r(npt,"XLMWithLMHeadModel"),npt.forEach(t),q9o=r(n$e," (XLM model)"),n$e.forEach(t),j9o=i(W),l3=n(W,"LI",{});var s$e=s(l3);Eme=n(s$e,"STRONG",{});var spt=s(Eme);D9o=r(spt,"xlm-prophetnet"),spt.forEach(t),G9o=r(s$e," \u2014 "),$G=n(s$e,"A",{href:!0});var lpt=s($G);O9o=r(lpt,"XLMProphetNetForCausalLM"),lpt.forEach(t),V9o=r(s$e," (XLM-ProphetNet model)"),s$e.forEach(t),X9o=i(W),i3=n(W,"LI",{});var l$e=s(i3);Cme=n(l$e,"STRONG",{});var ipt=s(Cme);z9o=r(ipt,"xlm-roberta"),ipt.forEach(t),W9o=r(l$e," \u2014 "),kG=n(l$e,"A",{href:!0});var dpt=s(kG);Q9o=r(dpt,"XLMRobertaForCausalLM"),dpt.forEach(t),H9o=r(l$e," (XLM-RoBERTa model)"),l$e.forEach(t),U9o=i(W),d3=n(W,"LI",{});var i$e=s(d3);wme=n(i$e,"STRONG",{});var cpt=s(wme);J9o=r(cpt,"xlm-roberta-xl"),cpt.forEach(t),Y9o=r(i$e," \u2014 "),SG=n(i$e,"A",{href:!0});var fpt=s(SG);K9o=r(fpt,"XLMRobertaXLForCausalLM"),fpt.forEach(t),Z9o=r(i$e," (XLM-RoBERTa-XL model)"),i$e.forEach(t),exo=i(W),c3=n(W,"LI",{});var d$e=s(c3);Ame=n(d$e,"STRONG",{});var mpt=s(Ame);oxo=r(mpt,"xlnet"),mpt.forEach(t),rxo=r(d$e," \u2014 "),RG=n(d$e,"A",{href:!0});var gpt=s(RG);txo=r(gpt,"XLNetLMHeadModel"),gpt.forEach(t),axo=r(d$e," (XLNet model)"),d$e.forEach(t),W.forEach(t),nxo=i(sa),f3=n(sa,"P",{});var c$e=s(f3);sxo=r(c$e,"The model is set in evaluation mode by default using "),Lme=n(c$e,"CODE",{});var hpt=s(Lme);lxo=r(hpt,"model.eval()"),hpt.forEach(t),ixo=r(c$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yme=n(c$e,"CODE",{});var ppt=s(yme);dxo=r(ppt,"model.train()"),ppt.forEach(t),c$e.forEach(t),cxo=i(sa),T(m3.$$.fragment,sa),sa.forEach(t),Ks.forEach(t),qGe=i(f),Xi=n(f,"H2",{class:!0});var XVe=s(Xi);g3=n(XVe,"A",{id:!0,class:!0,href:!0});var upt=s(g3);xme=n(upt,"SPAN",{});var _pt=s(xme);T(fy.$$.fragment,_pt),_pt.forEach(t),upt.forEach(t),fxo=i(XVe),$me=n(XVe,"SPAN",{});var bpt=s($me);mxo=r(bpt,"AutoModelForMaskedLM"),bpt.forEach(t),XVe.forEach(t),jGe=i(f),So=n(f,"DIV",{class:!0});var Zs=s(So);T(my.$$.fragment,Zs),gxo=i(Zs),zi=n(Zs,"P",{});var poe=s(zi);hxo=r(poe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PG=n(poe,"A",{href:!0});var vpt=s(PG);pxo=r(vpt,"from_pretrained()"),vpt.forEach(t),uxo=r(poe," class method or the "),BG=n(poe,"A",{href:!0});var Fpt=s(BG);_xo=r(Fpt,"from_config()"),Fpt.forEach(t),bxo=r(poe,` class
method.`),poe.forEach(t),vxo=i(Zs),gy=n(Zs,"P",{});var zVe=s(gy);Fxo=r(zVe,"This class cannot be instantiated directly using "),kme=n(zVe,"CODE",{});var Tpt=s(kme);Txo=r(Tpt,"__init__()"),Tpt.forEach(t),Mxo=r(zVe," (throws an error)."),zVe.forEach(t),Exo=i(Zs),it=n(Zs,"DIV",{class:!0});var SA=s(it);T(hy.$$.fragment,SA),Cxo=i(SA),Sme=n(SA,"P",{});var Mpt=s(Sme);wxo=r(Mpt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Mpt.forEach(t),Axo=i(SA),Wi=n(SA,"P",{});var uoe=s(Wi);Lxo=r(uoe,`Note:
Loading a model from its configuration file does `),Rme=n(uoe,"STRONG",{});var Ept=s(Rme);yxo=r(Ept,"not"),Ept.forEach(t),xxo=r(uoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),IG=n(uoe,"A",{href:!0});var Cpt=s(IG);$xo=r(Cpt,"from_pretrained()"),Cpt.forEach(t),kxo=r(uoe," to load the model weights."),uoe.forEach(t),Sxo=i(SA),T(h3.$$.fragment,SA),SA.forEach(t),Rxo=i(Zs),Ze=n(Zs,"DIV",{class:!0});var la=s(Ze);T(py.$$.fragment,la),Pxo=i(la),Pme=n(la,"P",{});var wpt=s(Pme);Bxo=r(wpt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),wpt.forEach(t),Ixo=i(la),Ba=n(la,"P",{});var RA=s(Ba);Nxo=r(RA,"The model class to instantiate is selected based on the "),Bme=n(RA,"CODE",{});var Apt=s(Bme);qxo=r(Apt,"model_type"),Apt.forEach(t),jxo=r(RA,` property of the config object (either
passed as an argument or loaded from `),Ime=n(RA,"CODE",{});var Lpt=s(Ime);Dxo=r(Lpt,"pretrained_model_name_or_path"),Lpt.forEach(t),Gxo=r(RA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nme=n(RA,"CODE",{});var ypt=s(Nme);Oxo=r(ypt,"pretrained_model_name_or_path"),ypt.forEach(t),Vxo=r(RA,":"),RA.forEach(t),Xxo=i(la),Q=n(la,"UL",{});var U=s(Q);p3=n(U,"LI",{});var f$e=s(p3);qme=n(f$e,"STRONG",{});var xpt=s(qme);zxo=r(xpt,"albert"),xpt.forEach(t),Wxo=r(f$e," \u2014 "),NG=n(f$e,"A",{href:!0});var $pt=s(NG);Qxo=r($pt,"AlbertForMaskedLM"),$pt.forEach(t),Hxo=r(f$e," (ALBERT model)"),f$e.forEach(t),Uxo=i(U),u3=n(U,"LI",{});var m$e=s(u3);jme=n(m$e,"STRONG",{});var kpt=s(jme);Jxo=r(kpt,"bart"),kpt.forEach(t),Yxo=r(m$e," \u2014 "),qG=n(m$e,"A",{href:!0});var Spt=s(qG);Kxo=r(Spt,"BartForConditionalGeneration"),Spt.forEach(t),Zxo=r(m$e," (BART model)"),m$e.forEach(t),e$o=i(U),_3=n(U,"LI",{});var g$e=s(_3);Dme=n(g$e,"STRONG",{});var Rpt=s(Dme);o$o=r(Rpt,"bert"),Rpt.forEach(t),r$o=r(g$e," \u2014 "),jG=n(g$e,"A",{href:!0});var Ppt=s(jG);t$o=r(Ppt,"BertForMaskedLM"),Ppt.forEach(t),a$o=r(g$e," (BERT model)"),g$e.forEach(t),n$o=i(U),b3=n(U,"LI",{});var h$e=s(b3);Gme=n(h$e,"STRONG",{});var Bpt=s(Gme);s$o=r(Bpt,"big_bird"),Bpt.forEach(t),l$o=r(h$e," \u2014 "),DG=n(h$e,"A",{href:!0});var Ipt=s(DG);i$o=r(Ipt,"BigBirdForMaskedLM"),Ipt.forEach(t),d$o=r(h$e," (BigBird model)"),h$e.forEach(t),c$o=i(U),v3=n(U,"LI",{});var p$e=s(v3);Ome=n(p$e,"STRONG",{});var Npt=s(Ome);f$o=r(Npt,"camembert"),Npt.forEach(t),m$o=r(p$e," \u2014 "),GG=n(p$e,"A",{href:!0});var qpt=s(GG);g$o=r(qpt,"CamembertForMaskedLM"),qpt.forEach(t),h$o=r(p$e," (CamemBERT model)"),p$e.forEach(t),p$o=i(U),F3=n(U,"LI",{});var u$e=s(F3);Vme=n(u$e,"STRONG",{});var jpt=s(Vme);u$o=r(jpt,"convbert"),jpt.forEach(t),_$o=r(u$e," \u2014 "),OG=n(u$e,"A",{href:!0});var Dpt=s(OG);b$o=r(Dpt,"ConvBertForMaskedLM"),Dpt.forEach(t),v$o=r(u$e," (ConvBERT model)"),u$e.forEach(t),F$o=i(U),T3=n(U,"LI",{});var _$e=s(T3);Xme=n(_$e,"STRONG",{});var Gpt=s(Xme);T$o=r(Gpt,"data2vec-text"),Gpt.forEach(t),M$o=r(_$e," \u2014 "),VG=n(_$e,"A",{href:!0});var Opt=s(VG);E$o=r(Opt,"Data2VecTextForMaskedLM"),Opt.forEach(t),C$o=r(_$e," (Data2VecText model)"),_$e.forEach(t),w$o=i(U),M3=n(U,"LI",{});var b$e=s(M3);zme=n(b$e,"STRONG",{});var Vpt=s(zme);A$o=r(Vpt,"deberta"),Vpt.forEach(t),L$o=r(b$e," \u2014 "),XG=n(b$e,"A",{href:!0});var Xpt=s(XG);y$o=r(Xpt,"DebertaForMaskedLM"),Xpt.forEach(t),x$o=r(b$e," (DeBERTa model)"),b$e.forEach(t),$$o=i(U),E3=n(U,"LI",{});var v$e=s(E3);Wme=n(v$e,"STRONG",{});var zpt=s(Wme);k$o=r(zpt,"deberta-v2"),zpt.forEach(t),S$o=r(v$e," \u2014 "),zG=n(v$e,"A",{href:!0});var Wpt=s(zG);R$o=r(Wpt,"DebertaV2ForMaskedLM"),Wpt.forEach(t),P$o=r(v$e," (DeBERTa-v2 model)"),v$e.forEach(t),B$o=i(U),C3=n(U,"LI",{});var F$e=s(C3);Qme=n(F$e,"STRONG",{});var Qpt=s(Qme);I$o=r(Qpt,"distilbert"),Qpt.forEach(t),N$o=r(F$e," \u2014 "),WG=n(F$e,"A",{href:!0});var Hpt=s(WG);q$o=r(Hpt,"DistilBertForMaskedLM"),Hpt.forEach(t),j$o=r(F$e," (DistilBERT model)"),F$e.forEach(t),D$o=i(U),w3=n(U,"LI",{});var T$e=s(w3);Hme=n(T$e,"STRONG",{});var Upt=s(Hme);G$o=r(Upt,"electra"),Upt.forEach(t),O$o=r(T$e," \u2014 "),QG=n(T$e,"A",{href:!0});var Jpt=s(QG);V$o=r(Jpt,"ElectraForMaskedLM"),Jpt.forEach(t),X$o=r(T$e," (ELECTRA model)"),T$e.forEach(t),z$o=i(U),A3=n(U,"LI",{});var M$e=s(A3);Ume=n(M$e,"STRONG",{});var Ypt=s(Ume);W$o=r(Ypt,"flaubert"),Ypt.forEach(t),Q$o=r(M$e," \u2014 "),HG=n(M$e,"A",{href:!0});var Kpt=s(HG);H$o=r(Kpt,"FlaubertWithLMHeadModel"),Kpt.forEach(t),U$o=r(M$e," (FlauBERT model)"),M$e.forEach(t),J$o=i(U),L3=n(U,"LI",{});var E$e=s(L3);Jme=n(E$e,"STRONG",{});var Zpt=s(Jme);Y$o=r(Zpt,"fnet"),Zpt.forEach(t),K$o=r(E$e," \u2014 "),UG=n(E$e,"A",{href:!0});var eut=s(UG);Z$o=r(eut,"FNetForMaskedLM"),eut.forEach(t),eko=r(E$e," (FNet model)"),E$e.forEach(t),oko=i(U),y3=n(U,"LI",{});var C$e=s(y3);Yme=n(C$e,"STRONG",{});var out=s(Yme);rko=r(out,"funnel"),out.forEach(t),tko=r(C$e," \u2014 "),JG=n(C$e,"A",{href:!0});var rut=s(JG);ako=r(rut,"FunnelForMaskedLM"),rut.forEach(t),nko=r(C$e," (Funnel Transformer model)"),C$e.forEach(t),sko=i(U),x3=n(U,"LI",{});var w$e=s(x3);Kme=n(w$e,"STRONG",{});var tut=s(Kme);lko=r(tut,"ibert"),tut.forEach(t),iko=r(w$e," \u2014 "),YG=n(w$e,"A",{href:!0});var aut=s(YG);dko=r(aut,"IBertForMaskedLM"),aut.forEach(t),cko=r(w$e," (I-BERT model)"),w$e.forEach(t),fko=i(U),$3=n(U,"LI",{});var A$e=s($3);Zme=n(A$e,"STRONG",{});var nut=s(Zme);mko=r(nut,"layoutlm"),nut.forEach(t),gko=r(A$e," \u2014 "),KG=n(A$e,"A",{href:!0});var sut=s(KG);hko=r(sut,"LayoutLMForMaskedLM"),sut.forEach(t),pko=r(A$e," (LayoutLM model)"),A$e.forEach(t),uko=i(U),k3=n(U,"LI",{});var L$e=s(k3);ege=n(L$e,"STRONG",{});var lut=s(ege);_ko=r(lut,"longformer"),lut.forEach(t),bko=r(L$e," \u2014 "),ZG=n(L$e,"A",{href:!0});var iut=s(ZG);vko=r(iut,"LongformerForMaskedLM"),iut.forEach(t),Fko=r(L$e," (Longformer model)"),L$e.forEach(t),Tko=i(U),S3=n(U,"LI",{});var y$e=s(S3);oge=n(y$e,"STRONG",{});var dut=s(oge);Mko=r(dut,"luke"),dut.forEach(t),Eko=r(y$e," \u2014 "),eO=n(y$e,"A",{href:!0});var cut=s(eO);Cko=r(cut,"LukeForMaskedLM"),cut.forEach(t),wko=r(y$e," (LUKE model)"),y$e.forEach(t),Ako=i(U),R3=n(U,"LI",{});var x$e=s(R3);rge=n(x$e,"STRONG",{});var fut=s(rge);Lko=r(fut,"mbart"),fut.forEach(t),yko=r(x$e," \u2014 "),oO=n(x$e,"A",{href:!0});var mut=s(oO);xko=r(mut,"MBartForConditionalGeneration"),mut.forEach(t),$ko=r(x$e," (mBART model)"),x$e.forEach(t),kko=i(U),P3=n(U,"LI",{});var $$e=s(P3);tge=n($$e,"STRONG",{});var gut=s(tge);Sko=r(gut,"megatron-bert"),gut.forEach(t),Rko=r($$e," \u2014 "),rO=n($$e,"A",{href:!0});var hut=s(rO);Pko=r(hut,"MegatronBertForMaskedLM"),hut.forEach(t),Bko=r($$e," (Megatron-BERT model)"),$$e.forEach(t),Iko=i(U),B3=n(U,"LI",{});var k$e=s(B3);age=n(k$e,"STRONG",{});var put=s(age);Nko=r(put,"mobilebert"),put.forEach(t),qko=r(k$e," \u2014 "),tO=n(k$e,"A",{href:!0});var uut=s(tO);jko=r(uut,"MobileBertForMaskedLM"),uut.forEach(t),Dko=r(k$e," (MobileBERT model)"),k$e.forEach(t),Gko=i(U),I3=n(U,"LI",{});var S$e=s(I3);nge=n(S$e,"STRONG",{});var _ut=s(nge);Oko=r(_ut,"mpnet"),_ut.forEach(t),Vko=r(S$e," \u2014 "),aO=n(S$e,"A",{href:!0});var but=s(aO);Xko=r(but,"MPNetForMaskedLM"),but.forEach(t),zko=r(S$e," (MPNet model)"),S$e.forEach(t),Wko=i(U),N3=n(U,"LI",{});var R$e=s(N3);sge=n(R$e,"STRONG",{});var vut=s(sge);Qko=r(vut,"nystromformer"),vut.forEach(t),Hko=r(R$e," \u2014 "),nO=n(R$e,"A",{href:!0});var Fut=s(nO);Uko=r(Fut,"NystromformerForMaskedLM"),Fut.forEach(t),Jko=r(R$e," (Nystr\xF6mformer model)"),R$e.forEach(t),Yko=i(U),q3=n(U,"LI",{});var P$e=s(q3);lge=n(P$e,"STRONG",{});var Tut=s(lge);Kko=r(Tut,"perceiver"),Tut.forEach(t),Zko=r(P$e," \u2014 "),sO=n(P$e,"A",{href:!0});var Mut=s(sO);eSo=r(Mut,"PerceiverForMaskedLM"),Mut.forEach(t),oSo=r(P$e," (Perceiver model)"),P$e.forEach(t),rSo=i(U),j3=n(U,"LI",{});var B$e=s(j3);ige=n(B$e,"STRONG",{});var Eut=s(ige);tSo=r(Eut,"qdqbert"),Eut.forEach(t),aSo=r(B$e," \u2014 "),lO=n(B$e,"A",{href:!0});var Cut=s(lO);nSo=r(Cut,"QDQBertForMaskedLM"),Cut.forEach(t),sSo=r(B$e," (QDQBert model)"),B$e.forEach(t),lSo=i(U),D3=n(U,"LI",{});var I$e=s(D3);dge=n(I$e,"STRONG",{});var wut=s(dge);iSo=r(wut,"reformer"),wut.forEach(t),dSo=r(I$e," \u2014 "),iO=n(I$e,"A",{href:!0});var Aut=s(iO);cSo=r(Aut,"ReformerForMaskedLM"),Aut.forEach(t),fSo=r(I$e," (Reformer model)"),I$e.forEach(t),mSo=i(U),G3=n(U,"LI",{});var N$e=s(G3);cge=n(N$e,"STRONG",{});var Lut=s(cge);gSo=r(Lut,"rembert"),Lut.forEach(t),hSo=r(N$e," \u2014 "),dO=n(N$e,"A",{href:!0});var yut=s(dO);pSo=r(yut,"RemBertForMaskedLM"),yut.forEach(t),uSo=r(N$e," (RemBERT model)"),N$e.forEach(t),_So=i(U),O3=n(U,"LI",{});var q$e=s(O3);fge=n(q$e,"STRONG",{});var xut=s(fge);bSo=r(xut,"roberta"),xut.forEach(t),vSo=r(q$e," \u2014 "),cO=n(q$e,"A",{href:!0});var $ut=s(cO);FSo=r($ut,"RobertaForMaskedLM"),$ut.forEach(t),TSo=r(q$e," (RoBERTa model)"),q$e.forEach(t),MSo=i(U),V3=n(U,"LI",{});var j$e=s(V3);mge=n(j$e,"STRONG",{});var kut=s(mge);ESo=r(kut,"roformer"),kut.forEach(t),CSo=r(j$e," \u2014 "),fO=n(j$e,"A",{href:!0});var Sut=s(fO);wSo=r(Sut,"RoFormerForMaskedLM"),Sut.forEach(t),ASo=r(j$e," (RoFormer model)"),j$e.forEach(t),LSo=i(U),X3=n(U,"LI",{});var D$e=s(X3);gge=n(D$e,"STRONG",{});var Rut=s(gge);ySo=r(Rut,"squeezebert"),Rut.forEach(t),xSo=r(D$e," \u2014 "),mO=n(D$e,"A",{href:!0});var Put=s(mO);$So=r(Put,"SqueezeBertForMaskedLM"),Put.forEach(t),kSo=r(D$e," (SqueezeBERT model)"),D$e.forEach(t),SSo=i(U),z3=n(U,"LI",{});var G$e=s(z3);hge=n(G$e,"STRONG",{});var But=s(hge);RSo=r(But,"tapas"),But.forEach(t),PSo=r(G$e," \u2014 "),gO=n(G$e,"A",{href:!0});var Iut=s(gO);BSo=r(Iut,"TapasForMaskedLM"),Iut.forEach(t),ISo=r(G$e," (TAPAS model)"),G$e.forEach(t),NSo=i(U),W3=n(U,"LI",{});var O$e=s(W3);pge=n(O$e,"STRONG",{});var Nut=s(pge);qSo=r(Nut,"wav2vec2"),Nut.forEach(t),jSo=r(O$e," \u2014 "),uge=n(O$e,"CODE",{});var qut=s(uge);DSo=r(qut,"Wav2Vec2ForMaskedLM"),qut.forEach(t),GSo=r(O$e," (Wav2Vec2 model)"),O$e.forEach(t),OSo=i(U),Q3=n(U,"LI",{});var V$e=s(Q3);_ge=n(V$e,"STRONG",{});var jut=s(_ge);VSo=r(jut,"xlm"),jut.forEach(t),XSo=r(V$e," \u2014 "),hO=n(V$e,"A",{href:!0});var Dut=s(hO);zSo=r(Dut,"XLMWithLMHeadModel"),Dut.forEach(t),WSo=r(V$e," (XLM model)"),V$e.forEach(t),QSo=i(U),H3=n(U,"LI",{});var X$e=s(H3);bge=n(X$e,"STRONG",{});var Gut=s(bge);HSo=r(Gut,"xlm-roberta"),Gut.forEach(t),USo=r(X$e," \u2014 "),pO=n(X$e,"A",{href:!0});var Out=s(pO);JSo=r(Out,"XLMRobertaForMaskedLM"),Out.forEach(t),YSo=r(X$e," (XLM-RoBERTa model)"),X$e.forEach(t),KSo=i(U),U3=n(U,"LI",{});var z$e=s(U3);vge=n(z$e,"STRONG",{});var Vut=s(vge);ZSo=r(Vut,"xlm-roberta-xl"),Vut.forEach(t),eRo=r(z$e," \u2014 "),uO=n(z$e,"A",{href:!0});var Xut=s(uO);oRo=r(Xut,"XLMRobertaXLForMaskedLM"),Xut.forEach(t),rRo=r(z$e," (XLM-RoBERTa-XL model)"),z$e.forEach(t),tRo=i(U),J3=n(U,"LI",{});var W$e=s(J3);Fge=n(W$e,"STRONG",{});var zut=s(Fge);aRo=r(zut,"yoso"),zut.forEach(t),nRo=r(W$e," \u2014 "),_O=n(W$e,"A",{href:!0});var Wut=s(_O);sRo=r(Wut,"YosoForMaskedLM"),Wut.forEach(t),lRo=r(W$e," (YOSO model)"),W$e.forEach(t),U.forEach(t),iRo=i(la),Y3=n(la,"P",{});var Q$e=s(Y3);dRo=r(Q$e,"The model is set in evaluation mode by default using "),Tge=n(Q$e,"CODE",{});var Qut=s(Tge);cRo=r(Qut,"model.eval()"),Qut.forEach(t),fRo=r(Q$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mge=n(Q$e,"CODE",{});var Hut=s(Mge);mRo=r(Hut,"model.train()"),Hut.forEach(t),Q$e.forEach(t),gRo=i(la),T(K3.$$.fragment,la),la.forEach(t),Zs.forEach(t),DGe=i(f),Qi=n(f,"H2",{class:!0});var WVe=s(Qi);Z3=n(WVe,"A",{id:!0,class:!0,href:!0});var Uut=s(Z3);Ege=n(Uut,"SPAN",{});var Jut=s(Ege);T(uy.$$.fragment,Jut),Jut.forEach(t),Uut.forEach(t),hRo=i(WVe),Cge=n(WVe,"SPAN",{});var Yut=s(Cge);pRo=r(Yut,"AutoModelForSeq2SeqLM"),Yut.forEach(t),WVe.forEach(t),GGe=i(f),Ro=n(f,"DIV",{class:!0});var el=s(Ro);T(_y.$$.fragment,el),uRo=i(el),Hi=n(el,"P",{});var _oe=s(Hi);_Ro=r(_oe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),bO=n(_oe,"A",{href:!0});var Kut=s(bO);bRo=r(Kut,"from_pretrained()"),Kut.forEach(t),vRo=r(_oe," class method or the "),vO=n(_oe,"A",{href:!0});var Zut=s(vO);FRo=r(Zut,"from_config()"),Zut.forEach(t),TRo=r(_oe,` class
method.`),_oe.forEach(t),MRo=i(el),by=n(el,"P",{});var QVe=s(by);ERo=r(QVe,"This class cannot be instantiated directly using "),wge=n(QVe,"CODE",{});var e_t=s(wge);CRo=r(e_t,"__init__()"),e_t.forEach(t),wRo=r(QVe," (throws an error)."),QVe.forEach(t),ARo=i(el),dt=n(el,"DIV",{class:!0});var PA=s(dt);T(vy.$$.fragment,PA),LRo=i(PA),Age=n(PA,"P",{});var o_t=s(Age);yRo=r(o_t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),o_t.forEach(t),xRo=i(PA),Ui=n(PA,"P",{});var boe=s(Ui);$Ro=r(boe,`Note:
Loading a model from its configuration file does `),Lge=n(boe,"STRONG",{});var r_t=s(Lge);kRo=r(r_t,"not"),r_t.forEach(t),SRo=r(boe,` load the model weights. It only affects the
model\u2019s configuration. Use `),FO=n(boe,"A",{href:!0});var t_t=s(FO);RRo=r(t_t,"from_pretrained()"),t_t.forEach(t),PRo=r(boe," to load the model weights."),boe.forEach(t),BRo=i(PA),T(e2.$$.fragment,PA),PA.forEach(t),IRo=i(el),eo=n(el,"DIV",{class:!0});var ia=s(eo);T(Fy.$$.fragment,ia),NRo=i(ia),yge=n(ia,"P",{});var a_t=s(yge);qRo=r(a_t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),a_t.forEach(t),jRo=i(ia),Ia=n(ia,"P",{});var BA=s(Ia);DRo=r(BA,"The model class to instantiate is selected based on the "),xge=n(BA,"CODE",{});var n_t=s(xge);GRo=r(n_t,"model_type"),n_t.forEach(t),ORo=r(BA,` property of the config object (either
passed as an argument or loaded from `),$ge=n(BA,"CODE",{});var s_t=s($ge);VRo=r(s_t,"pretrained_model_name_or_path"),s_t.forEach(t),XRo=r(BA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kge=n(BA,"CODE",{});var l_t=s(kge);zRo=r(l_t,"pretrained_model_name_or_path"),l_t.forEach(t),WRo=r(BA,":"),BA.forEach(t),QRo=i(ia),pe=n(ia,"UL",{});var be=s(pe);o2=n(be,"LI",{});var H$e=s(o2);Sge=n(H$e,"STRONG",{});var i_t=s(Sge);HRo=r(i_t,"bart"),i_t.forEach(t),URo=r(H$e," \u2014 "),TO=n(H$e,"A",{href:!0});var d_t=s(TO);JRo=r(d_t,"BartForConditionalGeneration"),d_t.forEach(t),YRo=r(H$e," (BART model)"),H$e.forEach(t),KRo=i(be),r2=n(be,"LI",{});var U$e=s(r2);Rge=n(U$e,"STRONG",{});var c_t=s(Rge);ZRo=r(c_t,"bigbird_pegasus"),c_t.forEach(t),ePo=r(U$e," \u2014 "),MO=n(U$e,"A",{href:!0});var f_t=s(MO);oPo=r(f_t,"BigBirdPegasusForConditionalGeneration"),f_t.forEach(t),rPo=r(U$e," (BigBird-Pegasus model)"),U$e.forEach(t),tPo=i(be),t2=n(be,"LI",{});var J$e=s(t2);Pge=n(J$e,"STRONG",{});var m_t=s(Pge);aPo=r(m_t,"blenderbot"),m_t.forEach(t),nPo=r(J$e," \u2014 "),EO=n(J$e,"A",{href:!0});var g_t=s(EO);sPo=r(g_t,"BlenderbotForConditionalGeneration"),g_t.forEach(t),lPo=r(J$e," (Blenderbot model)"),J$e.forEach(t),iPo=i(be),a2=n(be,"LI",{});var Y$e=s(a2);Bge=n(Y$e,"STRONG",{});var h_t=s(Bge);dPo=r(h_t,"blenderbot-small"),h_t.forEach(t),cPo=r(Y$e," \u2014 "),CO=n(Y$e,"A",{href:!0});var p_t=s(CO);fPo=r(p_t,"BlenderbotSmallForConditionalGeneration"),p_t.forEach(t),mPo=r(Y$e," (BlenderbotSmall model)"),Y$e.forEach(t),gPo=i(be),n2=n(be,"LI",{});var K$e=s(n2);Ige=n(K$e,"STRONG",{});var u_t=s(Ige);hPo=r(u_t,"encoder-decoder"),u_t.forEach(t),pPo=r(K$e," \u2014 "),wO=n(K$e,"A",{href:!0});var __t=s(wO);uPo=r(__t,"EncoderDecoderModel"),__t.forEach(t),_Po=r(K$e," (Encoder decoder model)"),K$e.forEach(t),bPo=i(be),s2=n(be,"LI",{});var Z$e=s(s2);Nge=n(Z$e,"STRONG",{});var b_t=s(Nge);vPo=r(b_t,"fsmt"),b_t.forEach(t),FPo=r(Z$e," \u2014 "),AO=n(Z$e,"A",{href:!0});var v_t=s(AO);TPo=r(v_t,"FSMTForConditionalGeneration"),v_t.forEach(t),MPo=r(Z$e," (FairSeq Machine-Translation model)"),Z$e.forEach(t),EPo=i(be),l2=n(be,"LI",{});var eke=s(l2);qge=n(eke,"STRONG",{});var F_t=s(qge);CPo=r(F_t,"led"),F_t.forEach(t),wPo=r(eke," \u2014 "),LO=n(eke,"A",{href:!0});var T_t=s(LO);APo=r(T_t,"LEDForConditionalGeneration"),T_t.forEach(t),LPo=r(eke," (LED model)"),eke.forEach(t),yPo=i(be),i2=n(be,"LI",{});var oke=s(i2);jge=n(oke,"STRONG",{});var M_t=s(jge);xPo=r(M_t,"longt5"),M_t.forEach(t),$Po=r(oke," \u2014 "),yO=n(oke,"A",{href:!0});var E_t=s(yO);kPo=r(E_t,"LongT5ForConditionalGeneration"),E_t.forEach(t),SPo=r(oke," (LongT5 model)"),oke.forEach(t),RPo=i(be),d2=n(be,"LI",{});var rke=s(d2);Dge=n(rke,"STRONG",{});var C_t=s(Dge);PPo=r(C_t,"m2m_100"),C_t.forEach(t),BPo=r(rke," \u2014 "),xO=n(rke,"A",{href:!0});var w_t=s(xO);IPo=r(w_t,"M2M100ForConditionalGeneration"),w_t.forEach(t),NPo=r(rke," (M2M100 model)"),rke.forEach(t),qPo=i(be),c2=n(be,"LI",{});var tke=s(c2);Gge=n(tke,"STRONG",{});var A_t=s(Gge);jPo=r(A_t,"marian"),A_t.forEach(t),DPo=r(tke," \u2014 "),$O=n(tke,"A",{href:!0});var L_t=s($O);GPo=r(L_t,"MarianMTModel"),L_t.forEach(t),OPo=r(tke," (Marian model)"),tke.forEach(t),VPo=i(be),f2=n(be,"LI",{});var ake=s(f2);Oge=n(ake,"STRONG",{});var y_t=s(Oge);XPo=r(y_t,"mbart"),y_t.forEach(t),zPo=r(ake," \u2014 "),kO=n(ake,"A",{href:!0});var x_t=s(kO);WPo=r(x_t,"MBartForConditionalGeneration"),x_t.forEach(t),QPo=r(ake," (mBART model)"),ake.forEach(t),HPo=i(be),m2=n(be,"LI",{});var nke=s(m2);Vge=n(nke,"STRONG",{});var $_t=s(Vge);UPo=r($_t,"mt5"),$_t.forEach(t),JPo=r(nke," \u2014 "),SO=n(nke,"A",{href:!0});var k_t=s(SO);YPo=r(k_t,"MT5ForConditionalGeneration"),k_t.forEach(t),KPo=r(nke," (MT5 model)"),nke.forEach(t),ZPo=i(be),g2=n(be,"LI",{});var ske=s(g2);Xge=n(ske,"STRONG",{});var S_t=s(Xge);eBo=r(S_t,"pegasus"),S_t.forEach(t),oBo=r(ske," \u2014 "),RO=n(ske,"A",{href:!0});var R_t=s(RO);rBo=r(R_t,"PegasusForConditionalGeneration"),R_t.forEach(t),tBo=r(ske," (Pegasus model)"),ske.forEach(t),aBo=i(be),h2=n(be,"LI",{});var lke=s(h2);zge=n(lke,"STRONG",{});var P_t=s(zge);nBo=r(P_t,"plbart"),P_t.forEach(t),sBo=r(lke," \u2014 "),PO=n(lke,"A",{href:!0});var B_t=s(PO);lBo=r(B_t,"PLBartForConditionalGeneration"),B_t.forEach(t),iBo=r(lke," (PLBart model)"),lke.forEach(t),dBo=i(be),p2=n(be,"LI",{});var ike=s(p2);Wge=n(ike,"STRONG",{});var I_t=s(Wge);cBo=r(I_t,"prophetnet"),I_t.forEach(t),fBo=r(ike," \u2014 "),BO=n(ike,"A",{href:!0});var N_t=s(BO);mBo=r(N_t,"ProphetNetForConditionalGeneration"),N_t.forEach(t),gBo=r(ike," (ProphetNet model)"),ike.forEach(t),hBo=i(be),u2=n(be,"LI",{});var dke=s(u2);Qge=n(dke,"STRONG",{});var q_t=s(Qge);pBo=r(q_t,"t5"),q_t.forEach(t),uBo=r(dke," \u2014 "),IO=n(dke,"A",{href:!0});var j_t=s(IO);_Bo=r(j_t,"T5ForConditionalGeneration"),j_t.forEach(t),bBo=r(dke," (T5 model)"),dke.forEach(t),vBo=i(be),_2=n(be,"LI",{});var cke=s(_2);Hge=n(cke,"STRONG",{});var D_t=s(Hge);FBo=r(D_t,"xlm-prophetnet"),D_t.forEach(t),TBo=r(cke," \u2014 "),NO=n(cke,"A",{href:!0});var G_t=s(NO);MBo=r(G_t,"XLMProphetNetForConditionalGeneration"),G_t.forEach(t),EBo=r(cke," (XLM-ProphetNet model)"),cke.forEach(t),be.forEach(t),CBo=i(ia),b2=n(ia,"P",{});var fke=s(b2);wBo=r(fke,"The model is set in evaluation mode by default using "),Uge=n(fke,"CODE",{});var O_t=s(Uge);ABo=r(O_t,"model.eval()"),O_t.forEach(t),LBo=r(fke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jge=n(fke,"CODE",{});var V_t=s(Jge);yBo=r(V_t,"model.train()"),V_t.forEach(t),fke.forEach(t),xBo=i(ia),T(v2.$$.fragment,ia),ia.forEach(t),el.forEach(t),OGe=i(f),Ji=n(f,"H2",{class:!0});var HVe=s(Ji);F2=n(HVe,"A",{id:!0,class:!0,href:!0});var X_t=s(F2);Yge=n(X_t,"SPAN",{});var z_t=s(Yge);T(Ty.$$.fragment,z_t),z_t.forEach(t),X_t.forEach(t),$Bo=i(HVe),Kge=n(HVe,"SPAN",{});var W_t=s(Kge);kBo=r(W_t,"AutoModelForSequenceClassification"),W_t.forEach(t),HVe.forEach(t),VGe=i(f),Po=n(f,"DIV",{class:!0});var ol=s(Po);T(My.$$.fragment,ol),SBo=i(ol),Yi=n(ol,"P",{});var voe=s(Yi);RBo=r(voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),qO=n(voe,"A",{href:!0});var Q_t=s(qO);PBo=r(Q_t,"from_pretrained()"),Q_t.forEach(t),BBo=r(voe," class method or the "),jO=n(voe,"A",{href:!0});var H_t=s(jO);IBo=r(H_t,"from_config()"),H_t.forEach(t),NBo=r(voe,` class
method.`),voe.forEach(t),qBo=i(ol),Ey=n(ol,"P",{});var UVe=s(Ey);jBo=r(UVe,"This class cannot be instantiated directly using "),Zge=n(UVe,"CODE",{});var U_t=s(Zge);DBo=r(U_t,"__init__()"),U_t.forEach(t),GBo=r(UVe," (throws an error)."),UVe.forEach(t),OBo=i(ol),ct=n(ol,"DIV",{class:!0});var IA=s(ct);T(Cy.$$.fragment,IA),VBo=i(IA),ehe=n(IA,"P",{});var J_t=s(ehe);XBo=r(J_t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),J_t.forEach(t),zBo=i(IA),Ki=n(IA,"P",{});var Foe=s(Ki);WBo=r(Foe,`Note:
Loading a model from its configuration file does `),ohe=n(Foe,"STRONG",{});var Y_t=s(ohe);QBo=r(Y_t,"not"),Y_t.forEach(t),HBo=r(Foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DO=n(Foe,"A",{href:!0});var K_t=s(DO);UBo=r(K_t,"from_pretrained()"),K_t.forEach(t),JBo=r(Foe," to load the model weights."),Foe.forEach(t),YBo=i(IA),T(T2.$$.fragment,IA),IA.forEach(t),KBo=i(ol),oo=n(ol,"DIV",{class:!0});var da=s(oo);T(wy.$$.fragment,da),ZBo=i(da),rhe=n(da,"P",{});var Z_t=s(rhe);eIo=r(Z_t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Z_t.forEach(t),oIo=i(da),Na=n(da,"P",{});var NA=s(Na);rIo=r(NA,"The model class to instantiate is selected based on the "),the=n(NA,"CODE",{});var e1t=s(the);tIo=r(e1t,"model_type"),e1t.forEach(t),aIo=r(NA,` property of the config object (either
passed as an argument or loaded from `),ahe=n(NA,"CODE",{});var o1t=s(ahe);nIo=r(o1t,"pretrained_model_name_or_path"),o1t.forEach(t),sIo=r(NA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nhe=n(NA,"CODE",{});var r1t=s(nhe);lIo=r(r1t,"pretrained_model_name_or_path"),r1t.forEach(t),iIo=r(NA,":"),NA.forEach(t),dIo=i(da),N=n(da,"UL",{});var j=s(N);M2=n(j,"LI",{});var mke=s(M2);she=n(mke,"STRONG",{});var t1t=s(she);cIo=r(t1t,"albert"),t1t.forEach(t),fIo=r(mke," \u2014 "),GO=n(mke,"A",{href:!0});var a1t=s(GO);mIo=r(a1t,"AlbertForSequenceClassification"),a1t.forEach(t),gIo=r(mke," (ALBERT model)"),mke.forEach(t),hIo=i(j),E2=n(j,"LI",{});var gke=s(E2);lhe=n(gke,"STRONG",{});var n1t=s(lhe);pIo=r(n1t,"bart"),n1t.forEach(t),uIo=r(gke," \u2014 "),OO=n(gke,"A",{href:!0});var s1t=s(OO);_Io=r(s1t,"BartForSequenceClassification"),s1t.forEach(t),bIo=r(gke," (BART model)"),gke.forEach(t),vIo=i(j),C2=n(j,"LI",{});var hke=s(C2);ihe=n(hke,"STRONG",{});var l1t=s(ihe);FIo=r(l1t,"bert"),l1t.forEach(t),TIo=r(hke," \u2014 "),VO=n(hke,"A",{href:!0});var i1t=s(VO);MIo=r(i1t,"BertForSequenceClassification"),i1t.forEach(t),EIo=r(hke," (BERT model)"),hke.forEach(t),CIo=i(j),w2=n(j,"LI",{});var pke=s(w2);dhe=n(pke,"STRONG",{});var d1t=s(dhe);wIo=r(d1t,"big_bird"),d1t.forEach(t),AIo=r(pke," \u2014 "),XO=n(pke,"A",{href:!0});var c1t=s(XO);LIo=r(c1t,"BigBirdForSequenceClassification"),c1t.forEach(t),yIo=r(pke," (BigBird model)"),pke.forEach(t),xIo=i(j),A2=n(j,"LI",{});var uke=s(A2);che=n(uke,"STRONG",{});var f1t=s(che);$Io=r(f1t,"bigbird_pegasus"),f1t.forEach(t),kIo=r(uke," \u2014 "),zO=n(uke,"A",{href:!0});var m1t=s(zO);SIo=r(m1t,"BigBirdPegasusForSequenceClassification"),m1t.forEach(t),RIo=r(uke," (BigBird-Pegasus model)"),uke.forEach(t),PIo=i(j),L2=n(j,"LI",{});var _ke=s(L2);fhe=n(_ke,"STRONG",{});var g1t=s(fhe);BIo=r(g1t,"bloom"),g1t.forEach(t),IIo=r(_ke," \u2014 "),WO=n(_ke,"A",{href:!0});var h1t=s(WO);NIo=r(h1t,"BloomForSequenceClassification"),h1t.forEach(t),qIo=r(_ke," (BLOOM model)"),_ke.forEach(t),jIo=i(j),y2=n(j,"LI",{});var bke=s(y2);mhe=n(bke,"STRONG",{});var p1t=s(mhe);DIo=r(p1t,"camembert"),p1t.forEach(t),GIo=r(bke," \u2014 "),QO=n(bke,"A",{href:!0});var u1t=s(QO);OIo=r(u1t,"CamembertForSequenceClassification"),u1t.forEach(t),VIo=r(bke," (CamemBERT model)"),bke.forEach(t),XIo=i(j),x2=n(j,"LI",{});var vke=s(x2);ghe=n(vke,"STRONG",{});var _1t=s(ghe);zIo=r(_1t,"canine"),_1t.forEach(t),WIo=r(vke," \u2014 "),HO=n(vke,"A",{href:!0});var b1t=s(HO);QIo=r(b1t,"CanineForSequenceClassification"),b1t.forEach(t),HIo=r(vke," (CANINE model)"),vke.forEach(t),UIo=i(j),$2=n(j,"LI",{});var Fke=s($2);hhe=n(Fke,"STRONG",{});var v1t=s(hhe);JIo=r(v1t,"convbert"),v1t.forEach(t),YIo=r(Fke," \u2014 "),UO=n(Fke,"A",{href:!0});var F1t=s(UO);KIo=r(F1t,"ConvBertForSequenceClassification"),F1t.forEach(t),ZIo=r(Fke," (ConvBERT model)"),Fke.forEach(t),eNo=i(j),k2=n(j,"LI",{});var Tke=s(k2);phe=n(Tke,"STRONG",{});var T1t=s(phe);oNo=r(T1t,"ctrl"),T1t.forEach(t),rNo=r(Tke," \u2014 "),JO=n(Tke,"A",{href:!0});var M1t=s(JO);tNo=r(M1t,"CTRLForSequenceClassification"),M1t.forEach(t),aNo=r(Tke," (CTRL model)"),Tke.forEach(t),nNo=i(j),S2=n(j,"LI",{});var Mke=s(S2);uhe=n(Mke,"STRONG",{});var E1t=s(uhe);sNo=r(E1t,"data2vec-text"),E1t.forEach(t),lNo=r(Mke," \u2014 "),YO=n(Mke,"A",{href:!0});var C1t=s(YO);iNo=r(C1t,"Data2VecTextForSequenceClassification"),C1t.forEach(t),dNo=r(Mke," (Data2VecText model)"),Mke.forEach(t),cNo=i(j),R2=n(j,"LI",{});var Eke=s(R2);_he=n(Eke,"STRONG",{});var w1t=s(_he);fNo=r(w1t,"deberta"),w1t.forEach(t),mNo=r(Eke," \u2014 "),KO=n(Eke,"A",{href:!0});var A1t=s(KO);gNo=r(A1t,"DebertaForSequenceClassification"),A1t.forEach(t),hNo=r(Eke," (DeBERTa model)"),Eke.forEach(t),pNo=i(j),P2=n(j,"LI",{});var Cke=s(P2);bhe=n(Cke,"STRONG",{});var L1t=s(bhe);uNo=r(L1t,"deberta-v2"),L1t.forEach(t),_No=r(Cke," \u2014 "),ZO=n(Cke,"A",{href:!0});var y1t=s(ZO);bNo=r(y1t,"DebertaV2ForSequenceClassification"),y1t.forEach(t),vNo=r(Cke," (DeBERTa-v2 model)"),Cke.forEach(t),FNo=i(j),B2=n(j,"LI",{});var wke=s(B2);vhe=n(wke,"STRONG",{});var x1t=s(vhe);TNo=r(x1t,"distilbert"),x1t.forEach(t),MNo=r(wke," \u2014 "),eV=n(wke,"A",{href:!0});var $1t=s(eV);ENo=r($1t,"DistilBertForSequenceClassification"),$1t.forEach(t),CNo=r(wke," (DistilBERT model)"),wke.forEach(t),wNo=i(j),I2=n(j,"LI",{});var Ake=s(I2);Fhe=n(Ake,"STRONG",{});var k1t=s(Fhe);ANo=r(k1t,"electra"),k1t.forEach(t),LNo=r(Ake," \u2014 "),oV=n(Ake,"A",{href:!0});var S1t=s(oV);yNo=r(S1t,"ElectraForSequenceClassification"),S1t.forEach(t),xNo=r(Ake," (ELECTRA model)"),Ake.forEach(t),$No=i(j),N2=n(j,"LI",{});var Lke=s(N2);The=n(Lke,"STRONG",{});var R1t=s(The);kNo=r(R1t,"flaubert"),R1t.forEach(t),SNo=r(Lke," \u2014 "),rV=n(Lke,"A",{href:!0});var P1t=s(rV);RNo=r(P1t,"FlaubertForSequenceClassification"),P1t.forEach(t),PNo=r(Lke," (FlauBERT model)"),Lke.forEach(t),BNo=i(j),q2=n(j,"LI",{});var yke=s(q2);Mhe=n(yke,"STRONG",{});var B1t=s(Mhe);INo=r(B1t,"fnet"),B1t.forEach(t),NNo=r(yke," \u2014 "),tV=n(yke,"A",{href:!0});var I1t=s(tV);qNo=r(I1t,"FNetForSequenceClassification"),I1t.forEach(t),jNo=r(yke," (FNet model)"),yke.forEach(t),DNo=i(j),j2=n(j,"LI",{});var xke=s(j2);Ehe=n(xke,"STRONG",{});var N1t=s(Ehe);GNo=r(N1t,"funnel"),N1t.forEach(t),ONo=r(xke," \u2014 "),aV=n(xke,"A",{href:!0});var q1t=s(aV);VNo=r(q1t,"FunnelForSequenceClassification"),q1t.forEach(t),XNo=r(xke," (Funnel Transformer model)"),xke.forEach(t),zNo=i(j),D2=n(j,"LI",{});var $ke=s(D2);Che=n($ke,"STRONG",{});var j1t=s(Che);WNo=r(j1t,"gpt2"),j1t.forEach(t),QNo=r($ke," \u2014 "),nV=n($ke,"A",{href:!0});var D1t=s(nV);HNo=r(D1t,"GPT2ForSequenceClassification"),D1t.forEach(t),UNo=r($ke," (OpenAI GPT-2 model)"),$ke.forEach(t),JNo=i(j),G2=n(j,"LI",{});var kke=s(G2);whe=n(kke,"STRONG",{});var G1t=s(whe);YNo=r(G1t,"gpt_neo"),G1t.forEach(t),KNo=r(kke," \u2014 "),sV=n(kke,"A",{href:!0});var O1t=s(sV);ZNo=r(O1t,"GPTNeoForSequenceClassification"),O1t.forEach(t),eqo=r(kke," (GPT Neo model)"),kke.forEach(t),oqo=i(j),O2=n(j,"LI",{});var Ske=s(O2);Ahe=n(Ske,"STRONG",{});var V1t=s(Ahe);rqo=r(V1t,"gptj"),V1t.forEach(t),tqo=r(Ske," \u2014 "),lV=n(Ske,"A",{href:!0});var X1t=s(lV);aqo=r(X1t,"GPTJForSequenceClassification"),X1t.forEach(t),nqo=r(Ske," (GPT-J model)"),Ske.forEach(t),sqo=i(j),V2=n(j,"LI",{});var Rke=s(V2);Lhe=n(Rke,"STRONG",{});var z1t=s(Lhe);lqo=r(z1t,"ibert"),z1t.forEach(t),iqo=r(Rke," \u2014 "),iV=n(Rke,"A",{href:!0});var W1t=s(iV);dqo=r(W1t,"IBertForSequenceClassification"),W1t.forEach(t),cqo=r(Rke," (I-BERT model)"),Rke.forEach(t),fqo=i(j),X2=n(j,"LI",{});var Pke=s(X2);yhe=n(Pke,"STRONG",{});var Q1t=s(yhe);mqo=r(Q1t,"layoutlm"),Q1t.forEach(t),gqo=r(Pke," \u2014 "),dV=n(Pke,"A",{href:!0});var H1t=s(dV);hqo=r(H1t,"LayoutLMForSequenceClassification"),H1t.forEach(t),pqo=r(Pke," (LayoutLM model)"),Pke.forEach(t),uqo=i(j),z2=n(j,"LI",{});var Bke=s(z2);xhe=n(Bke,"STRONG",{});var U1t=s(xhe);_qo=r(U1t,"layoutlmv2"),U1t.forEach(t),bqo=r(Bke," \u2014 "),cV=n(Bke,"A",{href:!0});var J1t=s(cV);vqo=r(J1t,"LayoutLMv2ForSequenceClassification"),J1t.forEach(t),Fqo=r(Bke," (LayoutLMv2 model)"),Bke.forEach(t),Tqo=i(j),W2=n(j,"LI",{});var Ike=s(W2);$he=n(Ike,"STRONG",{});var Y1t=s($he);Mqo=r(Y1t,"layoutlmv3"),Y1t.forEach(t),Eqo=r(Ike," \u2014 "),fV=n(Ike,"A",{href:!0});var K1t=s(fV);Cqo=r(K1t,"LayoutLMv3ForSequenceClassification"),K1t.forEach(t),wqo=r(Ike," (LayoutLMv3 model)"),Ike.forEach(t),Aqo=i(j),Q2=n(j,"LI",{});var Nke=s(Q2);khe=n(Nke,"STRONG",{});var Z1t=s(khe);Lqo=r(Z1t,"led"),Z1t.forEach(t),yqo=r(Nke," \u2014 "),mV=n(Nke,"A",{href:!0});var e3t=s(mV);xqo=r(e3t,"LEDForSequenceClassification"),e3t.forEach(t),$qo=r(Nke," (LED model)"),Nke.forEach(t),kqo=i(j),H2=n(j,"LI",{});var qke=s(H2);She=n(qke,"STRONG",{});var o3t=s(She);Sqo=r(o3t,"longformer"),o3t.forEach(t),Rqo=r(qke," \u2014 "),gV=n(qke,"A",{href:!0});var r3t=s(gV);Pqo=r(r3t,"LongformerForSequenceClassification"),r3t.forEach(t),Bqo=r(qke," (Longformer model)"),qke.forEach(t),Iqo=i(j),U2=n(j,"LI",{});var jke=s(U2);Rhe=n(jke,"STRONG",{});var t3t=s(Rhe);Nqo=r(t3t,"mbart"),t3t.forEach(t),qqo=r(jke," \u2014 "),hV=n(jke,"A",{href:!0});var a3t=s(hV);jqo=r(a3t,"MBartForSequenceClassification"),a3t.forEach(t),Dqo=r(jke," (mBART model)"),jke.forEach(t),Gqo=i(j),J2=n(j,"LI",{});var Dke=s(J2);Phe=n(Dke,"STRONG",{});var n3t=s(Phe);Oqo=r(n3t,"megatron-bert"),n3t.forEach(t),Vqo=r(Dke," \u2014 "),pV=n(Dke,"A",{href:!0});var s3t=s(pV);Xqo=r(s3t,"MegatronBertForSequenceClassification"),s3t.forEach(t),zqo=r(Dke," (Megatron-BERT model)"),Dke.forEach(t),Wqo=i(j),Y2=n(j,"LI",{});var Gke=s(Y2);Bhe=n(Gke,"STRONG",{});var l3t=s(Bhe);Qqo=r(l3t,"mobilebert"),l3t.forEach(t),Hqo=r(Gke," \u2014 "),uV=n(Gke,"A",{href:!0});var i3t=s(uV);Uqo=r(i3t,"MobileBertForSequenceClassification"),i3t.forEach(t),Jqo=r(Gke," (MobileBERT model)"),Gke.forEach(t),Yqo=i(j),K2=n(j,"LI",{});var Oke=s(K2);Ihe=n(Oke,"STRONG",{});var d3t=s(Ihe);Kqo=r(d3t,"mpnet"),d3t.forEach(t),Zqo=r(Oke," \u2014 "),_V=n(Oke,"A",{href:!0});var c3t=s(_V);ejo=r(c3t,"MPNetForSequenceClassification"),c3t.forEach(t),ojo=r(Oke," (MPNet model)"),Oke.forEach(t),rjo=i(j),Z2=n(j,"LI",{});var Vke=s(Z2);Nhe=n(Vke,"STRONG",{});var f3t=s(Nhe);tjo=r(f3t,"nystromformer"),f3t.forEach(t),ajo=r(Vke," \u2014 "),bV=n(Vke,"A",{href:!0});var m3t=s(bV);njo=r(m3t,"NystromformerForSequenceClassification"),m3t.forEach(t),sjo=r(Vke," (Nystr\xF6mformer model)"),Vke.forEach(t),ljo=i(j),eb=n(j,"LI",{});var Xke=s(eb);qhe=n(Xke,"STRONG",{});var g3t=s(qhe);ijo=r(g3t,"openai-gpt"),g3t.forEach(t),djo=r(Xke," \u2014 "),vV=n(Xke,"A",{href:!0});var h3t=s(vV);cjo=r(h3t,"OpenAIGPTForSequenceClassification"),h3t.forEach(t),fjo=r(Xke," (OpenAI GPT model)"),Xke.forEach(t),mjo=i(j),ob=n(j,"LI",{});var zke=s(ob);jhe=n(zke,"STRONG",{});var p3t=s(jhe);gjo=r(p3t,"perceiver"),p3t.forEach(t),hjo=r(zke," \u2014 "),FV=n(zke,"A",{href:!0});var u3t=s(FV);pjo=r(u3t,"PerceiverForSequenceClassification"),u3t.forEach(t),ujo=r(zke," (Perceiver model)"),zke.forEach(t),_jo=i(j),rb=n(j,"LI",{});var Wke=s(rb);Dhe=n(Wke,"STRONG",{});var _3t=s(Dhe);bjo=r(_3t,"plbart"),_3t.forEach(t),vjo=r(Wke," \u2014 "),TV=n(Wke,"A",{href:!0});var b3t=s(TV);Fjo=r(b3t,"PLBartForSequenceClassification"),b3t.forEach(t),Tjo=r(Wke," (PLBart model)"),Wke.forEach(t),Mjo=i(j),tb=n(j,"LI",{});var Qke=s(tb);Ghe=n(Qke,"STRONG",{});var v3t=s(Ghe);Ejo=r(v3t,"qdqbert"),v3t.forEach(t),Cjo=r(Qke," \u2014 "),MV=n(Qke,"A",{href:!0});var F3t=s(MV);wjo=r(F3t,"QDQBertForSequenceClassification"),F3t.forEach(t),Ajo=r(Qke," (QDQBert model)"),Qke.forEach(t),Ljo=i(j),ab=n(j,"LI",{});var Hke=s(ab);Ohe=n(Hke,"STRONG",{});var T3t=s(Ohe);yjo=r(T3t,"reformer"),T3t.forEach(t),xjo=r(Hke," \u2014 "),EV=n(Hke,"A",{href:!0});var M3t=s(EV);$jo=r(M3t,"ReformerForSequenceClassification"),M3t.forEach(t),kjo=r(Hke," (Reformer model)"),Hke.forEach(t),Sjo=i(j),nb=n(j,"LI",{});var Uke=s(nb);Vhe=n(Uke,"STRONG",{});var E3t=s(Vhe);Rjo=r(E3t,"rembert"),E3t.forEach(t),Pjo=r(Uke," \u2014 "),CV=n(Uke,"A",{href:!0});var C3t=s(CV);Bjo=r(C3t,"RemBertForSequenceClassification"),C3t.forEach(t),Ijo=r(Uke," (RemBERT model)"),Uke.forEach(t),Njo=i(j),sb=n(j,"LI",{});var Jke=s(sb);Xhe=n(Jke,"STRONG",{});var w3t=s(Xhe);qjo=r(w3t,"roberta"),w3t.forEach(t),jjo=r(Jke," \u2014 "),wV=n(Jke,"A",{href:!0});var A3t=s(wV);Djo=r(A3t,"RobertaForSequenceClassification"),A3t.forEach(t),Gjo=r(Jke," (RoBERTa model)"),Jke.forEach(t),Ojo=i(j),lb=n(j,"LI",{});var Yke=s(lb);zhe=n(Yke,"STRONG",{});var L3t=s(zhe);Vjo=r(L3t,"roformer"),L3t.forEach(t),Xjo=r(Yke," \u2014 "),AV=n(Yke,"A",{href:!0});var y3t=s(AV);zjo=r(y3t,"RoFormerForSequenceClassification"),y3t.forEach(t),Wjo=r(Yke," (RoFormer model)"),Yke.forEach(t),Qjo=i(j),ib=n(j,"LI",{});var Kke=s(ib);Whe=n(Kke,"STRONG",{});var x3t=s(Whe);Hjo=r(x3t,"squeezebert"),x3t.forEach(t),Ujo=r(Kke," \u2014 "),LV=n(Kke,"A",{href:!0});var $3t=s(LV);Jjo=r($3t,"SqueezeBertForSequenceClassification"),$3t.forEach(t),Yjo=r(Kke," (SqueezeBERT model)"),Kke.forEach(t),Kjo=i(j),db=n(j,"LI",{});var Zke=s(db);Qhe=n(Zke,"STRONG",{});var k3t=s(Qhe);Zjo=r(k3t,"tapas"),k3t.forEach(t),eDo=r(Zke," \u2014 "),yV=n(Zke,"A",{href:!0});var S3t=s(yV);oDo=r(S3t,"TapasForSequenceClassification"),S3t.forEach(t),rDo=r(Zke," (TAPAS model)"),Zke.forEach(t),tDo=i(j),cb=n(j,"LI",{});var eSe=s(cb);Hhe=n(eSe,"STRONG",{});var R3t=s(Hhe);aDo=r(R3t,"transfo-xl"),R3t.forEach(t),nDo=r(eSe," \u2014 "),xV=n(eSe,"A",{href:!0});var P3t=s(xV);sDo=r(P3t,"TransfoXLForSequenceClassification"),P3t.forEach(t),lDo=r(eSe," (Transformer-XL model)"),eSe.forEach(t),iDo=i(j),fb=n(j,"LI",{});var oSe=s(fb);Uhe=n(oSe,"STRONG",{});var B3t=s(Uhe);dDo=r(B3t,"xlm"),B3t.forEach(t),cDo=r(oSe," \u2014 "),$V=n(oSe,"A",{href:!0});var I3t=s($V);fDo=r(I3t,"XLMForSequenceClassification"),I3t.forEach(t),mDo=r(oSe," (XLM model)"),oSe.forEach(t),gDo=i(j),mb=n(j,"LI",{});var rSe=s(mb);Jhe=n(rSe,"STRONG",{});var N3t=s(Jhe);hDo=r(N3t,"xlm-roberta"),N3t.forEach(t),pDo=r(rSe," \u2014 "),kV=n(rSe,"A",{href:!0});var q3t=s(kV);uDo=r(q3t,"XLMRobertaForSequenceClassification"),q3t.forEach(t),_Do=r(rSe," (XLM-RoBERTa model)"),rSe.forEach(t),bDo=i(j),gb=n(j,"LI",{});var tSe=s(gb);Yhe=n(tSe,"STRONG",{});var j3t=s(Yhe);vDo=r(j3t,"xlm-roberta-xl"),j3t.forEach(t),FDo=r(tSe," \u2014 "),SV=n(tSe,"A",{href:!0});var D3t=s(SV);TDo=r(D3t,"XLMRobertaXLForSequenceClassification"),D3t.forEach(t),MDo=r(tSe," (XLM-RoBERTa-XL model)"),tSe.forEach(t),EDo=i(j),hb=n(j,"LI",{});var aSe=s(hb);Khe=n(aSe,"STRONG",{});var G3t=s(Khe);CDo=r(G3t,"xlnet"),G3t.forEach(t),wDo=r(aSe," \u2014 "),RV=n(aSe,"A",{href:!0});var O3t=s(RV);ADo=r(O3t,"XLNetForSequenceClassification"),O3t.forEach(t),LDo=r(aSe," (XLNet model)"),aSe.forEach(t),yDo=i(j),pb=n(j,"LI",{});var nSe=s(pb);Zhe=n(nSe,"STRONG",{});var V3t=s(Zhe);xDo=r(V3t,"yoso"),V3t.forEach(t),$Do=r(nSe," \u2014 "),PV=n(nSe,"A",{href:!0});var X3t=s(PV);kDo=r(X3t,"YosoForSequenceClassification"),X3t.forEach(t),SDo=r(nSe," (YOSO model)"),nSe.forEach(t),j.forEach(t),RDo=i(da),ub=n(da,"P",{});var sSe=s(ub);PDo=r(sSe,"The model is set in evaluation mode by default using "),epe=n(sSe,"CODE",{});var z3t=s(epe);BDo=r(z3t,"model.eval()"),z3t.forEach(t),IDo=r(sSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ope=n(sSe,"CODE",{});var W3t=s(ope);NDo=r(W3t,"model.train()"),W3t.forEach(t),sSe.forEach(t),qDo=i(da),T(_b.$$.fragment,da),da.forEach(t),ol.forEach(t),XGe=i(f),Zi=n(f,"H2",{class:!0});var JVe=s(Zi);bb=n(JVe,"A",{id:!0,class:!0,href:!0});var Q3t=s(bb);rpe=n(Q3t,"SPAN",{});var H3t=s(rpe);T(Ay.$$.fragment,H3t),H3t.forEach(t),Q3t.forEach(t),jDo=i(JVe),tpe=n(JVe,"SPAN",{});var U3t=s(tpe);DDo=r(U3t,"AutoModelForMultipleChoice"),U3t.forEach(t),JVe.forEach(t),zGe=i(f),Bo=n(f,"DIV",{class:!0});var rl=s(Bo);T(Ly.$$.fragment,rl),GDo=i(rl),ed=n(rl,"P",{});var Toe=s(ed);ODo=r(Toe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),BV=n(Toe,"A",{href:!0});var J3t=s(BV);VDo=r(J3t,"from_pretrained()"),J3t.forEach(t),XDo=r(Toe," class method or the "),IV=n(Toe,"A",{href:!0});var Y3t=s(IV);zDo=r(Y3t,"from_config()"),Y3t.forEach(t),WDo=r(Toe,` class
method.`),Toe.forEach(t),QDo=i(rl),yy=n(rl,"P",{});var YVe=s(yy);HDo=r(YVe,"This class cannot be instantiated directly using "),ape=n(YVe,"CODE",{});var K3t=s(ape);UDo=r(K3t,"__init__()"),K3t.forEach(t),JDo=r(YVe," (throws an error)."),YVe.forEach(t),YDo=i(rl),ft=n(rl,"DIV",{class:!0});var qA=s(ft);T(xy.$$.fragment,qA),KDo=i(qA),npe=n(qA,"P",{});var Z3t=s(npe);ZDo=r(Z3t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Z3t.forEach(t),eGo=i(qA),od=n(qA,"P",{});var Moe=s(od);oGo=r(Moe,`Note:
Loading a model from its configuration file does `),spe=n(Moe,"STRONG",{});var e2t=s(spe);rGo=r(e2t,"not"),e2t.forEach(t),tGo=r(Moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),NV=n(Moe,"A",{href:!0});var o2t=s(NV);aGo=r(o2t,"from_pretrained()"),o2t.forEach(t),nGo=r(Moe," to load the model weights."),Moe.forEach(t),sGo=i(qA),T(vb.$$.fragment,qA),qA.forEach(t),lGo=i(rl),ro=n(rl,"DIV",{class:!0});var ca=s(ro);T($y.$$.fragment,ca),iGo=i(ca),lpe=n(ca,"P",{});var r2t=s(lpe);dGo=r(r2t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),r2t.forEach(t),cGo=i(ca),qa=n(ca,"P",{});var jA=s(qa);fGo=r(jA,"The model class to instantiate is selected based on the "),ipe=n(jA,"CODE",{});var t2t=s(ipe);mGo=r(t2t,"model_type"),t2t.forEach(t),gGo=r(jA,` property of the config object (either
passed as an argument or loaded from `),dpe=n(jA,"CODE",{});var a2t=s(dpe);hGo=r(a2t,"pretrained_model_name_or_path"),a2t.forEach(t),pGo=r(jA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cpe=n(jA,"CODE",{});var n2t=s(cpe);uGo=r(n2t,"pretrained_model_name_or_path"),n2t.forEach(t),_Go=r(jA,":"),jA.forEach(t),bGo=i(ca),Z=n(ca,"UL",{});var ee=s(Z);Fb=n(ee,"LI",{});var lSe=s(Fb);fpe=n(lSe,"STRONG",{});var s2t=s(fpe);vGo=r(s2t,"albert"),s2t.forEach(t),FGo=r(lSe," \u2014 "),qV=n(lSe,"A",{href:!0});var l2t=s(qV);TGo=r(l2t,"AlbertForMultipleChoice"),l2t.forEach(t),MGo=r(lSe," (ALBERT model)"),lSe.forEach(t),EGo=i(ee),Tb=n(ee,"LI",{});var iSe=s(Tb);mpe=n(iSe,"STRONG",{});var i2t=s(mpe);CGo=r(i2t,"bert"),i2t.forEach(t),wGo=r(iSe," \u2014 "),jV=n(iSe,"A",{href:!0});var d2t=s(jV);AGo=r(d2t,"BertForMultipleChoice"),d2t.forEach(t),LGo=r(iSe," (BERT model)"),iSe.forEach(t),yGo=i(ee),Mb=n(ee,"LI",{});var dSe=s(Mb);gpe=n(dSe,"STRONG",{});var c2t=s(gpe);xGo=r(c2t,"big_bird"),c2t.forEach(t),$Go=r(dSe," \u2014 "),DV=n(dSe,"A",{href:!0});var f2t=s(DV);kGo=r(f2t,"BigBirdForMultipleChoice"),f2t.forEach(t),SGo=r(dSe," (BigBird model)"),dSe.forEach(t),RGo=i(ee),Eb=n(ee,"LI",{});var cSe=s(Eb);hpe=n(cSe,"STRONG",{});var m2t=s(hpe);PGo=r(m2t,"camembert"),m2t.forEach(t),BGo=r(cSe," \u2014 "),GV=n(cSe,"A",{href:!0});var g2t=s(GV);IGo=r(g2t,"CamembertForMultipleChoice"),g2t.forEach(t),NGo=r(cSe," (CamemBERT model)"),cSe.forEach(t),qGo=i(ee),Cb=n(ee,"LI",{});var fSe=s(Cb);ppe=n(fSe,"STRONG",{});var h2t=s(ppe);jGo=r(h2t,"canine"),h2t.forEach(t),DGo=r(fSe," \u2014 "),OV=n(fSe,"A",{href:!0});var p2t=s(OV);GGo=r(p2t,"CanineForMultipleChoice"),p2t.forEach(t),OGo=r(fSe," (CANINE model)"),fSe.forEach(t),VGo=i(ee),wb=n(ee,"LI",{});var mSe=s(wb);upe=n(mSe,"STRONG",{});var u2t=s(upe);XGo=r(u2t,"convbert"),u2t.forEach(t),zGo=r(mSe," \u2014 "),VV=n(mSe,"A",{href:!0});var _2t=s(VV);WGo=r(_2t,"ConvBertForMultipleChoice"),_2t.forEach(t),QGo=r(mSe," (ConvBERT model)"),mSe.forEach(t),HGo=i(ee),Ab=n(ee,"LI",{});var gSe=s(Ab);_pe=n(gSe,"STRONG",{});var b2t=s(_pe);UGo=r(b2t,"data2vec-text"),b2t.forEach(t),JGo=r(gSe," \u2014 "),XV=n(gSe,"A",{href:!0});var v2t=s(XV);YGo=r(v2t,"Data2VecTextForMultipleChoice"),v2t.forEach(t),KGo=r(gSe," (Data2VecText model)"),gSe.forEach(t),ZGo=i(ee),Lb=n(ee,"LI",{});var hSe=s(Lb);bpe=n(hSe,"STRONG",{});var F2t=s(bpe);eOo=r(F2t,"deberta-v2"),F2t.forEach(t),oOo=r(hSe," \u2014 "),zV=n(hSe,"A",{href:!0});var T2t=s(zV);rOo=r(T2t,"DebertaV2ForMultipleChoice"),T2t.forEach(t),tOo=r(hSe," (DeBERTa-v2 model)"),hSe.forEach(t),aOo=i(ee),yb=n(ee,"LI",{});var pSe=s(yb);vpe=n(pSe,"STRONG",{});var M2t=s(vpe);nOo=r(M2t,"distilbert"),M2t.forEach(t),sOo=r(pSe," \u2014 "),WV=n(pSe,"A",{href:!0});var E2t=s(WV);lOo=r(E2t,"DistilBertForMultipleChoice"),E2t.forEach(t),iOo=r(pSe," (DistilBERT model)"),pSe.forEach(t),dOo=i(ee),xb=n(ee,"LI",{});var uSe=s(xb);Fpe=n(uSe,"STRONG",{});var C2t=s(Fpe);cOo=r(C2t,"electra"),C2t.forEach(t),fOo=r(uSe," \u2014 "),QV=n(uSe,"A",{href:!0});var w2t=s(QV);mOo=r(w2t,"ElectraForMultipleChoice"),w2t.forEach(t),gOo=r(uSe," (ELECTRA model)"),uSe.forEach(t),hOo=i(ee),$b=n(ee,"LI",{});var _Se=s($b);Tpe=n(_Se,"STRONG",{});var A2t=s(Tpe);pOo=r(A2t,"flaubert"),A2t.forEach(t),uOo=r(_Se," \u2014 "),HV=n(_Se,"A",{href:!0});var L2t=s(HV);_Oo=r(L2t,"FlaubertForMultipleChoice"),L2t.forEach(t),bOo=r(_Se," (FlauBERT model)"),_Se.forEach(t),vOo=i(ee),kb=n(ee,"LI",{});var bSe=s(kb);Mpe=n(bSe,"STRONG",{});var y2t=s(Mpe);FOo=r(y2t,"fnet"),y2t.forEach(t),TOo=r(bSe," \u2014 "),UV=n(bSe,"A",{href:!0});var x2t=s(UV);MOo=r(x2t,"FNetForMultipleChoice"),x2t.forEach(t),EOo=r(bSe," (FNet model)"),bSe.forEach(t),COo=i(ee),Sb=n(ee,"LI",{});var vSe=s(Sb);Epe=n(vSe,"STRONG",{});var $2t=s(Epe);wOo=r($2t,"funnel"),$2t.forEach(t),AOo=r(vSe," \u2014 "),JV=n(vSe,"A",{href:!0});var k2t=s(JV);LOo=r(k2t,"FunnelForMultipleChoice"),k2t.forEach(t),yOo=r(vSe," (Funnel Transformer model)"),vSe.forEach(t),xOo=i(ee),Rb=n(ee,"LI",{});var FSe=s(Rb);Cpe=n(FSe,"STRONG",{});var S2t=s(Cpe);$Oo=r(S2t,"ibert"),S2t.forEach(t),kOo=r(FSe," \u2014 "),YV=n(FSe,"A",{href:!0});var R2t=s(YV);SOo=r(R2t,"IBertForMultipleChoice"),R2t.forEach(t),ROo=r(FSe," (I-BERT model)"),FSe.forEach(t),POo=i(ee),Pb=n(ee,"LI",{});var TSe=s(Pb);wpe=n(TSe,"STRONG",{});var P2t=s(wpe);BOo=r(P2t,"longformer"),P2t.forEach(t),IOo=r(TSe," \u2014 "),KV=n(TSe,"A",{href:!0});var B2t=s(KV);NOo=r(B2t,"LongformerForMultipleChoice"),B2t.forEach(t),qOo=r(TSe," (Longformer model)"),TSe.forEach(t),jOo=i(ee),Bb=n(ee,"LI",{});var MSe=s(Bb);Ape=n(MSe,"STRONG",{});var I2t=s(Ape);DOo=r(I2t,"megatron-bert"),I2t.forEach(t),GOo=r(MSe," \u2014 "),ZV=n(MSe,"A",{href:!0});var N2t=s(ZV);OOo=r(N2t,"MegatronBertForMultipleChoice"),N2t.forEach(t),VOo=r(MSe," (Megatron-BERT model)"),MSe.forEach(t),XOo=i(ee),Ib=n(ee,"LI",{});var ESe=s(Ib);Lpe=n(ESe,"STRONG",{});var q2t=s(Lpe);zOo=r(q2t,"mobilebert"),q2t.forEach(t),WOo=r(ESe," \u2014 "),eX=n(ESe,"A",{href:!0});var j2t=s(eX);QOo=r(j2t,"MobileBertForMultipleChoice"),j2t.forEach(t),HOo=r(ESe," (MobileBERT model)"),ESe.forEach(t),UOo=i(ee),Nb=n(ee,"LI",{});var CSe=s(Nb);ype=n(CSe,"STRONG",{});var D2t=s(ype);JOo=r(D2t,"mpnet"),D2t.forEach(t),YOo=r(CSe," \u2014 "),oX=n(CSe,"A",{href:!0});var G2t=s(oX);KOo=r(G2t,"MPNetForMultipleChoice"),G2t.forEach(t),ZOo=r(CSe," (MPNet model)"),CSe.forEach(t),eVo=i(ee),qb=n(ee,"LI",{});var wSe=s(qb);xpe=n(wSe,"STRONG",{});var O2t=s(xpe);oVo=r(O2t,"nystromformer"),O2t.forEach(t),rVo=r(wSe," \u2014 "),rX=n(wSe,"A",{href:!0});var V2t=s(rX);tVo=r(V2t,"NystromformerForMultipleChoice"),V2t.forEach(t),aVo=r(wSe," (Nystr\xF6mformer model)"),wSe.forEach(t),nVo=i(ee),jb=n(ee,"LI",{});var ASe=s(jb);$pe=n(ASe,"STRONG",{});var X2t=s($pe);sVo=r(X2t,"qdqbert"),X2t.forEach(t),lVo=r(ASe," \u2014 "),tX=n(ASe,"A",{href:!0});var z2t=s(tX);iVo=r(z2t,"QDQBertForMultipleChoice"),z2t.forEach(t),dVo=r(ASe," (QDQBert model)"),ASe.forEach(t),cVo=i(ee),Db=n(ee,"LI",{});var LSe=s(Db);kpe=n(LSe,"STRONG",{});var W2t=s(kpe);fVo=r(W2t,"rembert"),W2t.forEach(t),mVo=r(LSe," \u2014 "),aX=n(LSe,"A",{href:!0});var Q2t=s(aX);gVo=r(Q2t,"RemBertForMultipleChoice"),Q2t.forEach(t),hVo=r(LSe," (RemBERT model)"),LSe.forEach(t),pVo=i(ee),Gb=n(ee,"LI",{});var ySe=s(Gb);Spe=n(ySe,"STRONG",{});var H2t=s(Spe);uVo=r(H2t,"roberta"),H2t.forEach(t),_Vo=r(ySe," \u2014 "),nX=n(ySe,"A",{href:!0});var U2t=s(nX);bVo=r(U2t,"RobertaForMultipleChoice"),U2t.forEach(t),vVo=r(ySe," (RoBERTa model)"),ySe.forEach(t),FVo=i(ee),Ob=n(ee,"LI",{});var xSe=s(Ob);Rpe=n(xSe,"STRONG",{});var J2t=s(Rpe);TVo=r(J2t,"roformer"),J2t.forEach(t),MVo=r(xSe," \u2014 "),sX=n(xSe,"A",{href:!0});var Y2t=s(sX);EVo=r(Y2t,"RoFormerForMultipleChoice"),Y2t.forEach(t),CVo=r(xSe," (RoFormer model)"),xSe.forEach(t),wVo=i(ee),Vb=n(ee,"LI",{});var $Se=s(Vb);Ppe=n($Se,"STRONG",{});var K2t=s(Ppe);AVo=r(K2t,"squeezebert"),K2t.forEach(t),LVo=r($Se," \u2014 "),lX=n($Se,"A",{href:!0});var Z2t=s(lX);yVo=r(Z2t,"SqueezeBertForMultipleChoice"),Z2t.forEach(t),xVo=r($Se," (SqueezeBERT model)"),$Se.forEach(t),$Vo=i(ee),Xb=n(ee,"LI",{});var kSe=s(Xb);Bpe=n(kSe,"STRONG",{});var ebt=s(Bpe);kVo=r(ebt,"xlm"),ebt.forEach(t),SVo=r(kSe," \u2014 "),iX=n(kSe,"A",{href:!0});var obt=s(iX);RVo=r(obt,"XLMForMultipleChoice"),obt.forEach(t),PVo=r(kSe," (XLM model)"),kSe.forEach(t),BVo=i(ee),zb=n(ee,"LI",{});var SSe=s(zb);Ipe=n(SSe,"STRONG",{});var rbt=s(Ipe);IVo=r(rbt,"xlm-roberta"),rbt.forEach(t),NVo=r(SSe," \u2014 "),dX=n(SSe,"A",{href:!0});var tbt=s(dX);qVo=r(tbt,"XLMRobertaForMultipleChoice"),tbt.forEach(t),jVo=r(SSe," (XLM-RoBERTa model)"),SSe.forEach(t),DVo=i(ee),Wb=n(ee,"LI",{});var RSe=s(Wb);Npe=n(RSe,"STRONG",{});var abt=s(Npe);GVo=r(abt,"xlm-roberta-xl"),abt.forEach(t),OVo=r(RSe," \u2014 "),cX=n(RSe,"A",{href:!0});var nbt=s(cX);VVo=r(nbt,"XLMRobertaXLForMultipleChoice"),nbt.forEach(t),XVo=r(RSe," (XLM-RoBERTa-XL model)"),RSe.forEach(t),zVo=i(ee),Qb=n(ee,"LI",{});var PSe=s(Qb);qpe=n(PSe,"STRONG",{});var sbt=s(qpe);WVo=r(sbt,"xlnet"),sbt.forEach(t),QVo=r(PSe," \u2014 "),fX=n(PSe,"A",{href:!0});var lbt=s(fX);HVo=r(lbt,"XLNetForMultipleChoice"),lbt.forEach(t),UVo=r(PSe," (XLNet model)"),PSe.forEach(t),JVo=i(ee),Hb=n(ee,"LI",{});var BSe=s(Hb);jpe=n(BSe,"STRONG",{});var ibt=s(jpe);YVo=r(ibt,"yoso"),ibt.forEach(t),KVo=r(BSe," \u2014 "),mX=n(BSe,"A",{href:!0});var dbt=s(mX);ZVo=r(dbt,"YosoForMultipleChoice"),dbt.forEach(t),eXo=r(BSe," (YOSO model)"),BSe.forEach(t),ee.forEach(t),oXo=i(ca),Ub=n(ca,"P",{});var ISe=s(Ub);rXo=r(ISe,"The model is set in evaluation mode by default using "),Dpe=n(ISe,"CODE",{});var cbt=s(Dpe);tXo=r(cbt,"model.eval()"),cbt.forEach(t),aXo=r(ISe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gpe=n(ISe,"CODE",{});var fbt=s(Gpe);nXo=r(fbt,"model.train()"),fbt.forEach(t),ISe.forEach(t),sXo=i(ca),T(Jb.$$.fragment,ca),ca.forEach(t),rl.forEach(t),WGe=i(f),rd=n(f,"H2",{class:!0});var KVe=s(rd);Yb=n(KVe,"A",{id:!0,class:!0,href:!0});var mbt=s(Yb);Ope=n(mbt,"SPAN",{});var gbt=s(Ope);T(ky.$$.fragment,gbt),gbt.forEach(t),mbt.forEach(t),lXo=i(KVe),Vpe=n(KVe,"SPAN",{});var hbt=s(Vpe);iXo=r(hbt,"AutoModelForNextSentencePrediction"),hbt.forEach(t),KVe.forEach(t),QGe=i(f),Io=n(f,"DIV",{class:!0});var tl=s(Io);T(Sy.$$.fragment,tl),dXo=i(tl),td=n(tl,"P",{});var Eoe=s(td);cXo=r(Eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),gX=n(Eoe,"A",{href:!0});var pbt=s(gX);fXo=r(pbt,"from_pretrained()"),pbt.forEach(t),mXo=r(Eoe," class method or the "),hX=n(Eoe,"A",{href:!0});var ubt=s(hX);gXo=r(ubt,"from_config()"),ubt.forEach(t),hXo=r(Eoe,` class
method.`),Eoe.forEach(t),pXo=i(tl),Ry=n(tl,"P",{});var ZVe=s(Ry);uXo=r(ZVe,"This class cannot be instantiated directly using "),Xpe=n(ZVe,"CODE",{});var _bt=s(Xpe);_Xo=r(_bt,"__init__()"),_bt.forEach(t),bXo=r(ZVe," (throws an error)."),ZVe.forEach(t),vXo=i(tl),mt=n(tl,"DIV",{class:!0});var DA=s(mt);T(Py.$$.fragment,DA),FXo=i(DA),zpe=n(DA,"P",{});var bbt=s(zpe);TXo=r(bbt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),bbt.forEach(t),MXo=i(DA),ad=n(DA,"P",{});var Coe=s(ad);EXo=r(Coe,`Note:
Loading a model from its configuration file does `),Wpe=n(Coe,"STRONG",{});var vbt=s(Wpe);CXo=r(vbt,"not"),vbt.forEach(t),wXo=r(Coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),pX=n(Coe,"A",{href:!0});var Fbt=s(pX);AXo=r(Fbt,"from_pretrained()"),Fbt.forEach(t),LXo=r(Coe," to load the model weights."),Coe.forEach(t),yXo=i(DA),T(Kb.$$.fragment,DA),DA.forEach(t),xXo=i(tl),to=n(tl,"DIV",{class:!0});var fa=s(to);T(By.$$.fragment,fa),$Xo=i(fa),Qpe=n(fa,"P",{});var Tbt=s(Qpe);kXo=r(Tbt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Tbt.forEach(t),SXo=i(fa),ja=n(fa,"P",{});var GA=s(ja);RXo=r(GA,"The model class to instantiate is selected based on the "),Hpe=n(GA,"CODE",{});var Mbt=s(Hpe);PXo=r(Mbt,"model_type"),Mbt.forEach(t),BXo=r(GA,` property of the config object (either
passed as an argument or loaded from `),Upe=n(GA,"CODE",{});var Ebt=s(Upe);IXo=r(Ebt,"pretrained_model_name_or_path"),Ebt.forEach(t),NXo=r(GA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jpe=n(GA,"CODE",{});var Cbt=s(Jpe);qXo=r(Cbt,"pretrained_model_name_or_path"),Cbt.forEach(t),jXo=r(GA,":"),GA.forEach(t),DXo=i(fa),Zr=n(fa,"UL",{});var al=s(Zr);Zb=n(al,"LI",{});var NSe=s(Zb);Ype=n(NSe,"STRONG",{});var wbt=s(Ype);GXo=r(wbt,"bert"),wbt.forEach(t),OXo=r(NSe," \u2014 "),uX=n(NSe,"A",{href:!0});var Abt=s(uX);VXo=r(Abt,"BertForNextSentencePrediction"),Abt.forEach(t),XXo=r(NSe," (BERT model)"),NSe.forEach(t),zXo=i(al),ev=n(al,"LI",{});var qSe=s(ev);Kpe=n(qSe,"STRONG",{});var Lbt=s(Kpe);WXo=r(Lbt,"fnet"),Lbt.forEach(t),QXo=r(qSe," \u2014 "),_X=n(qSe,"A",{href:!0});var ybt=s(_X);HXo=r(ybt,"FNetForNextSentencePrediction"),ybt.forEach(t),UXo=r(qSe," (FNet model)"),qSe.forEach(t),JXo=i(al),ov=n(al,"LI",{});var jSe=s(ov);Zpe=n(jSe,"STRONG",{});var xbt=s(Zpe);YXo=r(xbt,"megatron-bert"),xbt.forEach(t),KXo=r(jSe," \u2014 "),bX=n(jSe,"A",{href:!0});var $bt=s(bX);ZXo=r($bt,"MegatronBertForNextSentencePrediction"),$bt.forEach(t),ezo=r(jSe," (Megatron-BERT model)"),jSe.forEach(t),ozo=i(al),rv=n(al,"LI",{});var DSe=s(rv);eue=n(DSe,"STRONG",{});var kbt=s(eue);rzo=r(kbt,"mobilebert"),kbt.forEach(t),tzo=r(DSe," \u2014 "),vX=n(DSe,"A",{href:!0});var Sbt=s(vX);azo=r(Sbt,"MobileBertForNextSentencePrediction"),Sbt.forEach(t),nzo=r(DSe," (MobileBERT model)"),DSe.forEach(t),szo=i(al),tv=n(al,"LI",{});var GSe=s(tv);oue=n(GSe,"STRONG",{});var Rbt=s(oue);lzo=r(Rbt,"qdqbert"),Rbt.forEach(t),izo=r(GSe," \u2014 "),FX=n(GSe,"A",{href:!0});var Pbt=s(FX);dzo=r(Pbt,"QDQBertForNextSentencePrediction"),Pbt.forEach(t),czo=r(GSe," (QDQBert model)"),GSe.forEach(t),al.forEach(t),fzo=i(fa),av=n(fa,"P",{});var OSe=s(av);mzo=r(OSe,"The model is set in evaluation mode by default using "),rue=n(OSe,"CODE",{});var Bbt=s(rue);gzo=r(Bbt,"model.eval()"),Bbt.forEach(t),hzo=r(OSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tue=n(OSe,"CODE",{});var Ibt=s(tue);pzo=r(Ibt,"model.train()"),Ibt.forEach(t),OSe.forEach(t),uzo=i(fa),T(nv.$$.fragment,fa),fa.forEach(t),tl.forEach(t),HGe=i(f),nd=n(f,"H2",{class:!0});var eXe=s(nd);sv=n(eXe,"A",{id:!0,class:!0,href:!0});var Nbt=s(sv);aue=n(Nbt,"SPAN",{});var qbt=s(aue);T(Iy.$$.fragment,qbt),qbt.forEach(t),Nbt.forEach(t),_zo=i(eXe),nue=n(eXe,"SPAN",{});var jbt=s(nue);bzo=r(jbt,"AutoModelForTokenClassification"),jbt.forEach(t),eXe.forEach(t),UGe=i(f),No=n(f,"DIV",{class:!0});var nl=s(No);T(Ny.$$.fragment,nl),vzo=i(nl),sd=n(nl,"P",{});var woe=s(sd);Fzo=r(woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),TX=n(woe,"A",{href:!0});var Dbt=s(TX);Tzo=r(Dbt,"from_pretrained()"),Dbt.forEach(t),Mzo=r(woe," class method or the "),MX=n(woe,"A",{href:!0});var Gbt=s(MX);Ezo=r(Gbt,"from_config()"),Gbt.forEach(t),Czo=r(woe,` class
method.`),woe.forEach(t),wzo=i(nl),qy=n(nl,"P",{});var oXe=s(qy);Azo=r(oXe,"This class cannot be instantiated directly using "),sue=n(oXe,"CODE",{});var Obt=s(sue);Lzo=r(Obt,"__init__()"),Obt.forEach(t),yzo=r(oXe," (throws an error)."),oXe.forEach(t),xzo=i(nl),gt=n(nl,"DIV",{class:!0});var OA=s(gt);T(jy.$$.fragment,OA),$zo=i(OA),lue=n(OA,"P",{});var Vbt=s(lue);kzo=r(Vbt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Vbt.forEach(t),Szo=i(OA),ld=n(OA,"P",{});var Aoe=s(ld);Rzo=r(Aoe,`Note:
Loading a model from its configuration file does `),iue=n(Aoe,"STRONG",{});var Xbt=s(iue);Pzo=r(Xbt,"not"),Xbt.forEach(t),Bzo=r(Aoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=n(Aoe,"A",{href:!0});var zbt=s(EX);Izo=r(zbt,"from_pretrained()"),zbt.forEach(t),Nzo=r(Aoe," to load the model weights."),Aoe.forEach(t),qzo=i(OA),T(lv.$$.fragment,OA),OA.forEach(t),jzo=i(nl),ao=n(nl,"DIV",{class:!0});var ma=s(ao);T(Dy.$$.fragment,ma),Dzo=i(ma),due=n(ma,"P",{});var Wbt=s(due);Gzo=r(Wbt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Wbt.forEach(t),Ozo=i(ma),Da=n(ma,"P",{});var VA=s(Da);Vzo=r(VA,"The model class to instantiate is selected based on the "),cue=n(VA,"CODE",{});var Qbt=s(cue);Xzo=r(Qbt,"model_type"),Qbt.forEach(t),zzo=r(VA,` property of the config object (either
passed as an argument or loaded from `),fue=n(VA,"CODE",{});var Hbt=s(fue);Wzo=r(Hbt,"pretrained_model_name_or_path"),Hbt.forEach(t),Qzo=r(VA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mue=n(VA,"CODE",{});var Ubt=s(mue);Hzo=r(Ubt,"pretrained_model_name_or_path"),Ubt.forEach(t),Uzo=r(VA,":"),VA.forEach(t),Jzo=i(ma),H=n(ma,"UL",{});var J=s(H);iv=n(J,"LI",{});var VSe=s(iv);gue=n(VSe,"STRONG",{});var Jbt=s(gue);Yzo=r(Jbt,"albert"),Jbt.forEach(t),Kzo=r(VSe," \u2014 "),CX=n(VSe,"A",{href:!0});var Ybt=s(CX);Zzo=r(Ybt,"AlbertForTokenClassification"),Ybt.forEach(t),eWo=r(VSe," (ALBERT model)"),VSe.forEach(t),oWo=i(J),dv=n(J,"LI",{});var XSe=s(dv);hue=n(XSe,"STRONG",{});var Kbt=s(hue);rWo=r(Kbt,"bert"),Kbt.forEach(t),tWo=r(XSe," \u2014 "),wX=n(XSe,"A",{href:!0});var Zbt=s(wX);aWo=r(Zbt,"BertForTokenClassification"),Zbt.forEach(t),nWo=r(XSe," (BERT model)"),XSe.forEach(t),sWo=i(J),cv=n(J,"LI",{});var zSe=s(cv);pue=n(zSe,"STRONG",{});var evt=s(pue);lWo=r(evt,"big_bird"),evt.forEach(t),iWo=r(zSe," \u2014 "),AX=n(zSe,"A",{href:!0});var ovt=s(AX);dWo=r(ovt,"BigBirdForTokenClassification"),ovt.forEach(t),cWo=r(zSe," (BigBird model)"),zSe.forEach(t),fWo=i(J),fv=n(J,"LI",{});var WSe=s(fv);uue=n(WSe,"STRONG",{});var rvt=s(uue);mWo=r(rvt,"bloom"),rvt.forEach(t),gWo=r(WSe," \u2014 "),LX=n(WSe,"A",{href:!0});var tvt=s(LX);hWo=r(tvt,"BloomForTokenClassification"),tvt.forEach(t),pWo=r(WSe," (BLOOM model)"),WSe.forEach(t),uWo=i(J),mv=n(J,"LI",{});var QSe=s(mv);_ue=n(QSe,"STRONG",{});var avt=s(_ue);_Wo=r(avt,"camembert"),avt.forEach(t),bWo=r(QSe," \u2014 "),yX=n(QSe,"A",{href:!0});var nvt=s(yX);vWo=r(nvt,"CamembertForTokenClassification"),nvt.forEach(t),FWo=r(QSe," (CamemBERT model)"),QSe.forEach(t),TWo=i(J),gv=n(J,"LI",{});var HSe=s(gv);bue=n(HSe,"STRONG",{});var svt=s(bue);MWo=r(svt,"canine"),svt.forEach(t),EWo=r(HSe," \u2014 "),xX=n(HSe,"A",{href:!0});var lvt=s(xX);CWo=r(lvt,"CanineForTokenClassification"),lvt.forEach(t),wWo=r(HSe," (CANINE model)"),HSe.forEach(t),AWo=i(J),hv=n(J,"LI",{});var USe=s(hv);vue=n(USe,"STRONG",{});var ivt=s(vue);LWo=r(ivt,"convbert"),ivt.forEach(t),yWo=r(USe," \u2014 "),$X=n(USe,"A",{href:!0});var dvt=s($X);xWo=r(dvt,"ConvBertForTokenClassification"),dvt.forEach(t),$Wo=r(USe," (ConvBERT model)"),USe.forEach(t),kWo=i(J),pv=n(J,"LI",{});var JSe=s(pv);Fue=n(JSe,"STRONG",{});var cvt=s(Fue);SWo=r(cvt,"data2vec-text"),cvt.forEach(t),RWo=r(JSe," \u2014 "),kX=n(JSe,"A",{href:!0});var fvt=s(kX);PWo=r(fvt,"Data2VecTextForTokenClassification"),fvt.forEach(t),BWo=r(JSe," (Data2VecText model)"),JSe.forEach(t),IWo=i(J),uv=n(J,"LI",{});var YSe=s(uv);Tue=n(YSe,"STRONG",{});var mvt=s(Tue);NWo=r(mvt,"deberta"),mvt.forEach(t),qWo=r(YSe," \u2014 "),SX=n(YSe,"A",{href:!0});var gvt=s(SX);jWo=r(gvt,"DebertaForTokenClassification"),gvt.forEach(t),DWo=r(YSe," (DeBERTa model)"),YSe.forEach(t),GWo=i(J),_v=n(J,"LI",{});var KSe=s(_v);Mue=n(KSe,"STRONG",{});var hvt=s(Mue);OWo=r(hvt,"deberta-v2"),hvt.forEach(t),VWo=r(KSe," \u2014 "),RX=n(KSe,"A",{href:!0});var pvt=s(RX);XWo=r(pvt,"DebertaV2ForTokenClassification"),pvt.forEach(t),zWo=r(KSe," (DeBERTa-v2 model)"),KSe.forEach(t),WWo=i(J),bv=n(J,"LI",{});var ZSe=s(bv);Eue=n(ZSe,"STRONG",{});var uvt=s(Eue);QWo=r(uvt,"distilbert"),uvt.forEach(t),HWo=r(ZSe," \u2014 "),PX=n(ZSe,"A",{href:!0});var _vt=s(PX);UWo=r(_vt,"DistilBertForTokenClassification"),_vt.forEach(t),JWo=r(ZSe," (DistilBERT model)"),ZSe.forEach(t),YWo=i(J),vv=n(J,"LI",{});var eRe=s(vv);Cue=n(eRe,"STRONG",{});var bvt=s(Cue);KWo=r(bvt,"electra"),bvt.forEach(t),ZWo=r(eRe," \u2014 "),BX=n(eRe,"A",{href:!0});var vvt=s(BX);eQo=r(vvt,"ElectraForTokenClassification"),vvt.forEach(t),oQo=r(eRe," (ELECTRA model)"),eRe.forEach(t),rQo=i(J),Fv=n(J,"LI",{});var oRe=s(Fv);wue=n(oRe,"STRONG",{});var Fvt=s(wue);tQo=r(Fvt,"flaubert"),Fvt.forEach(t),aQo=r(oRe," \u2014 "),IX=n(oRe,"A",{href:!0});var Tvt=s(IX);nQo=r(Tvt,"FlaubertForTokenClassification"),Tvt.forEach(t),sQo=r(oRe," (FlauBERT model)"),oRe.forEach(t),lQo=i(J),Tv=n(J,"LI",{});var rRe=s(Tv);Aue=n(rRe,"STRONG",{});var Mvt=s(Aue);iQo=r(Mvt,"fnet"),Mvt.forEach(t),dQo=r(rRe," \u2014 "),NX=n(rRe,"A",{href:!0});var Evt=s(NX);cQo=r(Evt,"FNetForTokenClassification"),Evt.forEach(t),fQo=r(rRe," (FNet model)"),rRe.forEach(t),mQo=i(J),Mv=n(J,"LI",{});var tRe=s(Mv);Lue=n(tRe,"STRONG",{});var Cvt=s(Lue);gQo=r(Cvt,"funnel"),Cvt.forEach(t),hQo=r(tRe," \u2014 "),qX=n(tRe,"A",{href:!0});var wvt=s(qX);pQo=r(wvt,"FunnelForTokenClassification"),wvt.forEach(t),uQo=r(tRe," (Funnel Transformer model)"),tRe.forEach(t),_Qo=i(J),Ev=n(J,"LI",{});var aRe=s(Ev);yue=n(aRe,"STRONG",{});var Avt=s(yue);bQo=r(Avt,"gpt2"),Avt.forEach(t),vQo=r(aRe," \u2014 "),jX=n(aRe,"A",{href:!0});var Lvt=s(jX);FQo=r(Lvt,"GPT2ForTokenClassification"),Lvt.forEach(t),TQo=r(aRe," (OpenAI GPT-2 model)"),aRe.forEach(t),MQo=i(J),Cv=n(J,"LI",{});var nRe=s(Cv);xue=n(nRe,"STRONG",{});var yvt=s(xue);EQo=r(yvt,"ibert"),yvt.forEach(t),CQo=r(nRe," \u2014 "),DX=n(nRe,"A",{href:!0});var xvt=s(DX);wQo=r(xvt,"IBertForTokenClassification"),xvt.forEach(t),AQo=r(nRe," (I-BERT model)"),nRe.forEach(t),LQo=i(J),wv=n(J,"LI",{});var sRe=s(wv);$ue=n(sRe,"STRONG",{});var $vt=s($ue);yQo=r($vt,"layoutlm"),$vt.forEach(t),xQo=r(sRe," \u2014 "),GX=n(sRe,"A",{href:!0});var kvt=s(GX);$Qo=r(kvt,"LayoutLMForTokenClassification"),kvt.forEach(t),kQo=r(sRe," (LayoutLM model)"),sRe.forEach(t),SQo=i(J),Av=n(J,"LI",{});var lRe=s(Av);kue=n(lRe,"STRONG",{});var Svt=s(kue);RQo=r(Svt,"layoutlmv2"),Svt.forEach(t),PQo=r(lRe," \u2014 "),OX=n(lRe,"A",{href:!0});var Rvt=s(OX);BQo=r(Rvt,"LayoutLMv2ForTokenClassification"),Rvt.forEach(t),IQo=r(lRe," (LayoutLMv2 model)"),lRe.forEach(t),NQo=i(J),Lv=n(J,"LI",{});var iRe=s(Lv);Sue=n(iRe,"STRONG",{});var Pvt=s(Sue);qQo=r(Pvt,"layoutlmv3"),Pvt.forEach(t),jQo=r(iRe," \u2014 "),VX=n(iRe,"A",{href:!0});var Bvt=s(VX);DQo=r(Bvt,"LayoutLMv3ForTokenClassification"),Bvt.forEach(t),GQo=r(iRe," (LayoutLMv3 model)"),iRe.forEach(t),OQo=i(J),yv=n(J,"LI",{});var dRe=s(yv);Rue=n(dRe,"STRONG",{});var Ivt=s(Rue);VQo=r(Ivt,"longformer"),Ivt.forEach(t),XQo=r(dRe," \u2014 "),XX=n(dRe,"A",{href:!0});var Nvt=s(XX);zQo=r(Nvt,"LongformerForTokenClassification"),Nvt.forEach(t),WQo=r(dRe," (Longformer model)"),dRe.forEach(t),QQo=i(J),xv=n(J,"LI",{});var cRe=s(xv);Pue=n(cRe,"STRONG",{});var qvt=s(Pue);HQo=r(qvt,"megatron-bert"),qvt.forEach(t),UQo=r(cRe," \u2014 "),zX=n(cRe,"A",{href:!0});var jvt=s(zX);JQo=r(jvt,"MegatronBertForTokenClassification"),jvt.forEach(t),YQo=r(cRe," (Megatron-BERT model)"),cRe.forEach(t),KQo=i(J),$v=n(J,"LI",{});var fRe=s($v);Bue=n(fRe,"STRONG",{});var Dvt=s(Bue);ZQo=r(Dvt,"mobilebert"),Dvt.forEach(t),eHo=r(fRe," \u2014 "),WX=n(fRe,"A",{href:!0});var Gvt=s(WX);oHo=r(Gvt,"MobileBertForTokenClassification"),Gvt.forEach(t),rHo=r(fRe," (MobileBERT model)"),fRe.forEach(t),tHo=i(J),kv=n(J,"LI",{});var mRe=s(kv);Iue=n(mRe,"STRONG",{});var Ovt=s(Iue);aHo=r(Ovt,"mpnet"),Ovt.forEach(t),nHo=r(mRe," \u2014 "),QX=n(mRe,"A",{href:!0});var Vvt=s(QX);sHo=r(Vvt,"MPNetForTokenClassification"),Vvt.forEach(t),lHo=r(mRe," (MPNet model)"),mRe.forEach(t),iHo=i(J),Sv=n(J,"LI",{});var gRe=s(Sv);Nue=n(gRe,"STRONG",{});var Xvt=s(Nue);dHo=r(Xvt,"nystromformer"),Xvt.forEach(t),cHo=r(gRe," \u2014 "),HX=n(gRe,"A",{href:!0});var zvt=s(HX);fHo=r(zvt,"NystromformerForTokenClassification"),zvt.forEach(t),mHo=r(gRe," (Nystr\xF6mformer model)"),gRe.forEach(t),gHo=i(J),Rv=n(J,"LI",{});var hRe=s(Rv);que=n(hRe,"STRONG",{});var Wvt=s(que);hHo=r(Wvt,"qdqbert"),Wvt.forEach(t),pHo=r(hRe," \u2014 "),UX=n(hRe,"A",{href:!0});var Qvt=s(UX);uHo=r(Qvt,"QDQBertForTokenClassification"),Qvt.forEach(t),_Ho=r(hRe," (QDQBert model)"),hRe.forEach(t),bHo=i(J),Pv=n(J,"LI",{});var pRe=s(Pv);jue=n(pRe,"STRONG",{});var Hvt=s(jue);vHo=r(Hvt,"rembert"),Hvt.forEach(t),FHo=r(pRe," \u2014 "),JX=n(pRe,"A",{href:!0});var Uvt=s(JX);THo=r(Uvt,"RemBertForTokenClassification"),Uvt.forEach(t),MHo=r(pRe," (RemBERT model)"),pRe.forEach(t),EHo=i(J),Bv=n(J,"LI",{});var uRe=s(Bv);Due=n(uRe,"STRONG",{});var Jvt=s(Due);CHo=r(Jvt,"roberta"),Jvt.forEach(t),wHo=r(uRe," \u2014 "),YX=n(uRe,"A",{href:!0});var Yvt=s(YX);AHo=r(Yvt,"RobertaForTokenClassification"),Yvt.forEach(t),LHo=r(uRe," (RoBERTa model)"),uRe.forEach(t),yHo=i(J),Iv=n(J,"LI",{});var _Re=s(Iv);Gue=n(_Re,"STRONG",{});var Kvt=s(Gue);xHo=r(Kvt,"roformer"),Kvt.forEach(t),$Ho=r(_Re," \u2014 "),KX=n(_Re,"A",{href:!0});var Zvt=s(KX);kHo=r(Zvt,"RoFormerForTokenClassification"),Zvt.forEach(t),SHo=r(_Re," (RoFormer model)"),_Re.forEach(t),RHo=i(J),Nv=n(J,"LI",{});var bRe=s(Nv);Oue=n(bRe,"STRONG",{});var eFt=s(Oue);PHo=r(eFt,"squeezebert"),eFt.forEach(t),BHo=r(bRe," \u2014 "),ZX=n(bRe,"A",{href:!0});var oFt=s(ZX);IHo=r(oFt,"SqueezeBertForTokenClassification"),oFt.forEach(t),NHo=r(bRe," (SqueezeBERT model)"),bRe.forEach(t),qHo=i(J),qv=n(J,"LI",{});var vRe=s(qv);Vue=n(vRe,"STRONG",{});var rFt=s(Vue);jHo=r(rFt,"xlm"),rFt.forEach(t),DHo=r(vRe," \u2014 "),ez=n(vRe,"A",{href:!0});var tFt=s(ez);GHo=r(tFt,"XLMForTokenClassification"),tFt.forEach(t),OHo=r(vRe," (XLM model)"),vRe.forEach(t),VHo=i(J),jv=n(J,"LI",{});var FRe=s(jv);Xue=n(FRe,"STRONG",{});var aFt=s(Xue);XHo=r(aFt,"xlm-roberta"),aFt.forEach(t),zHo=r(FRe," \u2014 "),oz=n(FRe,"A",{href:!0});var nFt=s(oz);WHo=r(nFt,"XLMRobertaForTokenClassification"),nFt.forEach(t),QHo=r(FRe," (XLM-RoBERTa model)"),FRe.forEach(t),HHo=i(J),Dv=n(J,"LI",{});var TRe=s(Dv);zue=n(TRe,"STRONG",{});var sFt=s(zue);UHo=r(sFt,"xlm-roberta-xl"),sFt.forEach(t),JHo=r(TRe," \u2014 "),rz=n(TRe,"A",{href:!0});var lFt=s(rz);YHo=r(lFt,"XLMRobertaXLForTokenClassification"),lFt.forEach(t),KHo=r(TRe," (XLM-RoBERTa-XL model)"),TRe.forEach(t),ZHo=i(J),Gv=n(J,"LI",{});var MRe=s(Gv);Wue=n(MRe,"STRONG",{});var iFt=s(Wue);eUo=r(iFt,"xlnet"),iFt.forEach(t),oUo=r(MRe," \u2014 "),tz=n(MRe,"A",{href:!0});var dFt=s(tz);rUo=r(dFt,"XLNetForTokenClassification"),dFt.forEach(t),tUo=r(MRe," (XLNet model)"),MRe.forEach(t),aUo=i(J),Ov=n(J,"LI",{});var ERe=s(Ov);Que=n(ERe,"STRONG",{});var cFt=s(Que);nUo=r(cFt,"yoso"),cFt.forEach(t),sUo=r(ERe," \u2014 "),az=n(ERe,"A",{href:!0});var fFt=s(az);lUo=r(fFt,"YosoForTokenClassification"),fFt.forEach(t),iUo=r(ERe," (YOSO model)"),ERe.forEach(t),J.forEach(t),dUo=i(ma),Vv=n(ma,"P",{});var CRe=s(Vv);cUo=r(CRe,"The model is set in evaluation mode by default using "),Hue=n(CRe,"CODE",{});var mFt=s(Hue);fUo=r(mFt,"model.eval()"),mFt.forEach(t),mUo=r(CRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uue=n(CRe,"CODE",{});var gFt=s(Uue);gUo=r(gFt,"model.train()"),gFt.forEach(t),CRe.forEach(t),hUo=i(ma),T(Xv.$$.fragment,ma),ma.forEach(t),nl.forEach(t),JGe=i(f),id=n(f,"H2",{class:!0});var rXe=s(id);zv=n(rXe,"A",{id:!0,class:!0,href:!0});var hFt=s(zv);Jue=n(hFt,"SPAN",{});var pFt=s(Jue);T(Gy.$$.fragment,pFt),pFt.forEach(t),hFt.forEach(t),pUo=i(rXe),Yue=n(rXe,"SPAN",{});var uFt=s(Yue);uUo=r(uFt,"AutoModelForQuestionAnswering"),uFt.forEach(t),rXe.forEach(t),YGe=i(f),qo=n(f,"DIV",{class:!0});var sl=s(qo);T(Oy.$$.fragment,sl),_Uo=i(sl),dd=n(sl,"P",{});var Loe=s(dd);bUo=r(Loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),nz=n(Loe,"A",{href:!0});var _Ft=s(nz);vUo=r(_Ft,"from_pretrained()"),_Ft.forEach(t),FUo=r(Loe," class method or the "),sz=n(Loe,"A",{href:!0});var bFt=s(sz);TUo=r(bFt,"from_config()"),bFt.forEach(t),MUo=r(Loe,` class
method.`),Loe.forEach(t),EUo=i(sl),Vy=n(sl,"P",{});var tXe=s(Vy);CUo=r(tXe,"This class cannot be instantiated directly using "),Kue=n(tXe,"CODE",{});var vFt=s(Kue);wUo=r(vFt,"__init__()"),vFt.forEach(t),AUo=r(tXe," (throws an error)."),tXe.forEach(t),LUo=i(sl),ht=n(sl,"DIV",{class:!0});var XA=s(ht);T(Xy.$$.fragment,XA),yUo=i(XA),Zue=n(XA,"P",{});var FFt=s(Zue);xUo=r(FFt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),FFt.forEach(t),$Uo=i(XA),cd=n(XA,"P",{});var yoe=s(cd);kUo=r(yoe,`Note:
Loading a model from its configuration file does `),e_e=n(yoe,"STRONG",{});var TFt=s(e_e);SUo=r(TFt,"not"),TFt.forEach(t),RUo=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),lz=n(yoe,"A",{href:!0});var MFt=s(lz);PUo=r(MFt,"from_pretrained()"),MFt.forEach(t),BUo=r(yoe," to load the model weights."),yoe.forEach(t),IUo=i(XA),T(Wv.$$.fragment,XA),XA.forEach(t),NUo=i(sl),no=n(sl,"DIV",{class:!0});var ga=s(no);T(zy.$$.fragment,ga),qUo=i(ga),o_e=n(ga,"P",{});var EFt=s(o_e);jUo=r(EFt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),EFt.forEach(t),DUo=i(ga),Ga=n(ga,"P",{});var zA=s(Ga);GUo=r(zA,"The model class to instantiate is selected based on the "),r_e=n(zA,"CODE",{});var CFt=s(r_e);OUo=r(CFt,"model_type"),CFt.forEach(t),VUo=r(zA,` property of the config object (either
passed as an argument or loaded from `),t_e=n(zA,"CODE",{});var wFt=s(t_e);XUo=r(wFt,"pretrained_model_name_or_path"),wFt.forEach(t),zUo=r(zA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a_e=n(zA,"CODE",{});var AFt=s(a_e);WUo=r(AFt,"pretrained_model_name_or_path"),AFt.forEach(t),QUo=r(zA,":"),zA.forEach(t),HUo=i(ga),V=n(ga,"UL",{});var X=s(V);Qv=n(X,"LI",{});var wRe=s(Qv);n_e=n(wRe,"STRONG",{});var LFt=s(n_e);UUo=r(LFt,"albert"),LFt.forEach(t),JUo=r(wRe," \u2014 "),iz=n(wRe,"A",{href:!0});var yFt=s(iz);YUo=r(yFt,"AlbertForQuestionAnswering"),yFt.forEach(t),KUo=r(wRe," (ALBERT model)"),wRe.forEach(t),ZUo=i(X),Hv=n(X,"LI",{});var ARe=s(Hv);s_e=n(ARe,"STRONG",{});var xFt=s(s_e);eJo=r(xFt,"bart"),xFt.forEach(t),oJo=r(ARe," \u2014 "),dz=n(ARe,"A",{href:!0});var $Ft=s(dz);rJo=r($Ft,"BartForQuestionAnswering"),$Ft.forEach(t),tJo=r(ARe," (BART model)"),ARe.forEach(t),aJo=i(X),Uv=n(X,"LI",{});var LRe=s(Uv);l_e=n(LRe,"STRONG",{});var kFt=s(l_e);nJo=r(kFt,"bert"),kFt.forEach(t),sJo=r(LRe," \u2014 "),cz=n(LRe,"A",{href:!0});var SFt=s(cz);lJo=r(SFt,"BertForQuestionAnswering"),SFt.forEach(t),iJo=r(LRe," (BERT model)"),LRe.forEach(t),dJo=i(X),Jv=n(X,"LI",{});var yRe=s(Jv);i_e=n(yRe,"STRONG",{});var RFt=s(i_e);cJo=r(RFt,"big_bird"),RFt.forEach(t),fJo=r(yRe," \u2014 "),fz=n(yRe,"A",{href:!0});var PFt=s(fz);mJo=r(PFt,"BigBirdForQuestionAnswering"),PFt.forEach(t),gJo=r(yRe," (BigBird model)"),yRe.forEach(t),hJo=i(X),Yv=n(X,"LI",{});var xRe=s(Yv);d_e=n(xRe,"STRONG",{});var BFt=s(d_e);pJo=r(BFt,"bigbird_pegasus"),BFt.forEach(t),uJo=r(xRe," \u2014 "),mz=n(xRe,"A",{href:!0});var IFt=s(mz);_Jo=r(IFt,"BigBirdPegasusForQuestionAnswering"),IFt.forEach(t),bJo=r(xRe," (BigBird-Pegasus model)"),xRe.forEach(t),vJo=i(X),Kv=n(X,"LI",{});var $Re=s(Kv);c_e=n($Re,"STRONG",{});var NFt=s(c_e);FJo=r(NFt,"camembert"),NFt.forEach(t),TJo=r($Re," \u2014 "),gz=n($Re,"A",{href:!0});var qFt=s(gz);MJo=r(qFt,"CamembertForQuestionAnswering"),qFt.forEach(t),EJo=r($Re," (CamemBERT model)"),$Re.forEach(t),CJo=i(X),Zv=n(X,"LI",{});var kRe=s(Zv);f_e=n(kRe,"STRONG",{});var jFt=s(f_e);wJo=r(jFt,"canine"),jFt.forEach(t),AJo=r(kRe," \u2014 "),hz=n(kRe,"A",{href:!0});var DFt=s(hz);LJo=r(DFt,"CanineForQuestionAnswering"),DFt.forEach(t),yJo=r(kRe," (CANINE model)"),kRe.forEach(t),xJo=i(X),eF=n(X,"LI",{});var SRe=s(eF);m_e=n(SRe,"STRONG",{});var GFt=s(m_e);$Jo=r(GFt,"convbert"),GFt.forEach(t),kJo=r(SRe," \u2014 "),pz=n(SRe,"A",{href:!0});var OFt=s(pz);SJo=r(OFt,"ConvBertForQuestionAnswering"),OFt.forEach(t),RJo=r(SRe," (ConvBERT model)"),SRe.forEach(t),PJo=i(X),oF=n(X,"LI",{});var RRe=s(oF);g_e=n(RRe,"STRONG",{});var VFt=s(g_e);BJo=r(VFt,"data2vec-text"),VFt.forEach(t),IJo=r(RRe," \u2014 "),uz=n(RRe,"A",{href:!0});var XFt=s(uz);NJo=r(XFt,"Data2VecTextForQuestionAnswering"),XFt.forEach(t),qJo=r(RRe," (Data2VecText model)"),RRe.forEach(t),jJo=i(X),rF=n(X,"LI",{});var PRe=s(rF);h_e=n(PRe,"STRONG",{});var zFt=s(h_e);DJo=r(zFt,"deberta"),zFt.forEach(t),GJo=r(PRe," \u2014 "),_z=n(PRe,"A",{href:!0});var WFt=s(_z);OJo=r(WFt,"DebertaForQuestionAnswering"),WFt.forEach(t),VJo=r(PRe," (DeBERTa model)"),PRe.forEach(t),XJo=i(X),tF=n(X,"LI",{});var BRe=s(tF);p_e=n(BRe,"STRONG",{});var QFt=s(p_e);zJo=r(QFt,"deberta-v2"),QFt.forEach(t),WJo=r(BRe," \u2014 "),bz=n(BRe,"A",{href:!0});var HFt=s(bz);QJo=r(HFt,"DebertaV2ForQuestionAnswering"),HFt.forEach(t),HJo=r(BRe," (DeBERTa-v2 model)"),BRe.forEach(t),UJo=i(X),aF=n(X,"LI",{});var IRe=s(aF);u_e=n(IRe,"STRONG",{});var UFt=s(u_e);JJo=r(UFt,"distilbert"),UFt.forEach(t),YJo=r(IRe," \u2014 "),vz=n(IRe,"A",{href:!0});var JFt=s(vz);KJo=r(JFt,"DistilBertForQuestionAnswering"),JFt.forEach(t),ZJo=r(IRe," (DistilBERT model)"),IRe.forEach(t),eYo=i(X),nF=n(X,"LI",{});var NRe=s(nF);__e=n(NRe,"STRONG",{});var YFt=s(__e);oYo=r(YFt,"electra"),YFt.forEach(t),rYo=r(NRe," \u2014 "),Fz=n(NRe,"A",{href:!0});var KFt=s(Fz);tYo=r(KFt,"ElectraForQuestionAnswering"),KFt.forEach(t),aYo=r(NRe," (ELECTRA model)"),NRe.forEach(t),nYo=i(X),sF=n(X,"LI",{});var qRe=s(sF);b_e=n(qRe,"STRONG",{});var ZFt=s(b_e);sYo=r(ZFt,"flaubert"),ZFt.forEach(t),lYo=r(qRe," \u2014 "),Tz=n(qRe,"A",{href:!0});var eTt=s(Tz);iYo=r(eTt,"FlaubertForQuestionAnsweringSimple"),eTt.forEach(t),dYo=r(qRe," (FlauBERT model)"),qRe.forEach(t),cYo=i(X),lF=n(X,"LI",{});var jRe=s(lF);v_e=n(jRe,"STRONG",{});var oTt=s(v_e);fYo=r(oTt,"fnet"),oTt.forEach(t),mYo=r(jRe," \u2014 "),Mz=n(jRe,"A",{href:!0});var rTt=s(Mz);gYo=r(rTt,"FNetForQuestionAnswering"),rTt.forEach(t),hYo=r(jRe," (FNet model)"),jRe.forEach(t),pYo=i(X),iF=n(X,"LI",{});var DRe=s(iF);F_e=n(DRe,"STRONG",{});var tTt=s(F_e);uYo=r(tTt,"funnel"),tTt.forEach(t),_Yo=r(DRe," \u2014 "),Ez=n(DRe,"A",{href:!0});var aTt=s(Ez);bYo=r(aTt,"FunnelForQuestionAnswering"),aTt.forEach(t),vYo=r(DRe," (Funnel Transformer model)"),DRe.forEach(t),FYo=i(X),dF=n(X,"LI",{});var GRe=s(dF);T_e=n(GRe,"STRONG",{});var nTt=s(T_e);TYo=r(nTt,"gptj"),nTt.forEach(t),MYo=r(GRe," \u2014 "),Cz=n(GRe,"A",{href:!0});var sTt=s(Cz);EYo=r(sTt,"GPTJForQuestionAnswering"),sTt.forEach(t),CYo=r(GRe," (GPT-J model)"),GRe.forEach(t),wYo=i(X),cF=n(X,"LI",{});var ORe=s(cF);M_e=n(ORe,"STRONG",{});var lTt=s(M_e);AYo=r(lTt,"ibert"),lTt.forEach(t),LYo=r(ORe," \u2014 "),wz=n(ORe,"A",{href:!0});var iTt=s(wz);yYo=r(iTt,"IBertForQuestionAnswering"),iTt.forEach(t),xYo=r(ORe," (I-BERT model)"),ORe.forEach(t),$Yo=i(X),fF=n(X,"LI",{});var VRe=s(fF);E_e=n(VRe,"STRONG",{});var dTt=s(E_e);kYo=r(dTt,"layoutlmv2"),dTt.forEach(t),SYo=r(VRe," \u2014 "),Az=n(VRe,"A",{href:!0});var cTt=s(Az);RYo=r(cTt,"LayoutLMv2ForQuestionAnswering"),cTt.forEach(t),PYo=r(VRe," (LayoutLMv2 model)"),VRe.forEach(t),BYo=i(X),mF=n(X,"LI",{});var XRe=s(mF);C_e=n(XRe,"STRONG",{});var fTt=s(C_e);IYo=r(fTt,"layoutlmv3"),fTt.forEach(t),NYo=r(XRe," \u2014 "),Lz=n(XRe,"A",{href:!0});var mTt=s(Lz);qYo=r(mTt,"LayoutLMv3ForQuestionAnswering"),mTt.forEach(t),jYo=r(XRe," (LayoutLMv3 model)"),XRe.forEach(t),DYo=i(X),gF=n(X,"LI",{});var zRe=s(gF);w_e=n(zRe,"STRONG",{});var gTt=s(w_e);GYo=r(gTt,"led"),gTt.forEach(t),OYo=r(zRe," \u2014 "),yz=n(zRe,"A",{href:!0});var hTt=s(yz);VYo=r(hTt,"LEDForQuestionAnswering"),hTt.forEach(t),XYo=r(zRe," (LED model)"),zRe.forEach(t),zYo=i(X),hF=n(X,"LI",{});var WRe=s(hF);A_e=n(WRe,"STRONG",{});var pTt=s(A_e);WYo=r(pTt,"longformer"),pTt.forEach(t),QYo=r(WRe," \u2014 "),xz=n(WRe,"A",{href:!0});var uTt=s(xz);HYo=r(uTt,"LongformerForQuestionAnswering"),uTt.forEach(t),UYo=r(WRe," (Longformer model)"),WRe.forEach(t),JYo=i(X),pF=n(X,"LI",{});var QRe=s(pF);L_e=n(QRe,"STRONG",{});var _Tt=s(L_e);YYo=r(_Tt,"lxmert"),_Tt.forEach(t),KYo=r(QRe," \u2014 "),$z=n(QRe,"A",{href:!0});var bTt=s($z);ZYo=r(bTt,"LxmertForQuestionAnswering"),bTt.forEach(t),eKo=r(QRe," (LXMERT model)"),QRe.forEach(t),oKo=i(X),uF=n(X,"LI",{});var HRe=s(uF);y_e=n(HRe,"STRONG",{});var vTt=s(y_e);rKo=r(vTt,"mbart"),vTt.forEach(t),tKo=r(HRe," \u2014 "),kz=n(HRe,"A",{href:!0});var FTt=s(kz);aKo=r(FTt,"MBartForQuestionAnswering"),FTt.forEach(t),nKo=r(HRe," (mBART model)"),HRe.forEach(t),sKo=i(X),_F=n(X,"LI",{});var URe=s(_F);x_e=n(URe,"STRONG",{});var TTt=s(x_e);lKo=r(TTt,"megatron-bert"),TTt.forEach(t),iKo=r(URe," \u2014 "),Sz=n(URe,"A",{href:!0});var MTt=s(Sz);dKo=r(MTt,"MegatronBertForQuestionAnswering"),MTt.forEach(t),cKo=r(URe," (Megatron-BERT model)"),URe.forEach(t),fKo=i(X),bF=n(X,"LI",{});var JRe=s(bF);$_e=n(JRe,"STRONG",{});var ETt=s($_e);mKo=r(ETt,"mobilebert"),ETt.forEach(t),gKo=r(JRe," \u2014 "),Rz=n(JRe,"A",{href:!0});var CTt=s(Rz);hKo=r(CTt,"MobileBertForQuestionAnswering"),CTt.forEach(t),pKo=r(JRe," (MobileBERT model)"),JRe.forEach(t),uKo=i(X),vF=n(X,"LI",{});var YRe=s(vF);k_e=n(YRe,"STRONG",{});var wTt=s(k_e);_Ko=r(wTt,"mpnet"),wTt.forEach(t),bKo=r(YRe," \u2014 "),Pz=n(YRe,"A",{href:!0});var ATt=s(Pz);vKo=r(ATt,"MPNetForQuestionAnswering"),ATt.forEach(t),FKo=r(YRe," (MPNet model)"),YRe.forEach(t),TKo=i(X),FF=n(X,"LI",{});var KRe=s(FF);S_e=n(KRe,"STRONG",{});var LTt=s(S_e);MKo=r(LTt,"nystromformer"),LTt.forEach(t),EKo=r(KRe," \u2014 "),Bz=n(KRe,"A",{href:!0});var yTt=s(Bz);CKo=r(yTt,"NystromformerForQuestionAnswering"),yTt.forEach(t),wKo=r(KRe," (Nystr\xF6mformer model)"),KRe.forEach(t),AKo=i(X),TF=n(X,"LI",{});var ZRe=s(TF);R_e=n(ZRe,"STRONG",{});var xTt=s(R_e);LKo=r(xTt,"qdqbert"),xTt.forEach(t),yKo=r(ZRe," \u2014 "),Iz=n(ZRe,"A",{href:!0});var $Tt=s(Iz);xKo=r($Tt,"QDQBertForQuestionAnswering"),$Tt.forEach(t),$Ko=r(ZRe," (QDQBert model)"),ZRe.forEach(t),kKo=i(X),MF=n(X,"LI",{});var ePe=s(MF);P_e=n(ePe,"STRONG",{});var kTt=s(P_e);SKo=r(kTt,"reformer"),kTt.forEach(t),RKo=r(ePe," \u2014 "),Nz=n(ePe,"A",{href:!0});var STt=s(Nz);PKo=r(STt,"ReformerForQuestionAnswering"),STt.forEach(t),BKo=r(ePe," (Reformer model)"),ePe.forEach(t),IKo=i(X),EF=n(X,"LI",{});var oPe=s(EF);B_e=n(oPe,"STRONG",{});var RTt=s(B_e);NKo=r(RTt,"rembert"),RTt.forEach(t),qKo=r(oPe," \u2014 "),qz=n(oPe,"A",{href:!0});var PTt=s(qz);jKo=r(PTt,"RemBertForQuestionAnswering"),PTt.forEach(t),DKo=r(oPe," (RemBERT model)"),oPe.forEach(t),GKo=i(X),CF=n(X,"LI",{});var rPe=s(CF);I_e=n(rPe,"STRONG",{});var BTt=s(I_e);OKo=r(BTt,"roberta"),BTt.forEach(t),VKo=r(rPe," \u2014 "),jz=n(rPe,"A",{href:!0});var ITt=s(jz);XKo=r(ITt,"RobertaForQuestionAnswering"),ITt.forEach(t),zKo=r(rPe," (RoBERTa model)"),rPe.forEach(t),WKo=i(X),wF=n(X,"LI",{});var tPe=s(wF);N_e=n(tPe,"STRONG",{});var NTt=s(N_e);QKo=r(NTt,"roformer"),NTt.forEach(t),HKo=r(tPe," \u2014 "),Dz=n(tPe,"A",{href:!0});var qTt=s(Dz);UKo=r(qTt,"RoFormerForQuestionAnswering"),qTt.forEach(t),JKo=r(tPe," (RoFormer model)"),tPe.forEach(t),YKo=i(X),AF=n(X,"LI",{});var aPe=s(AF);q_e=n(aPe,"STRONG",{});var jTt=s(q_e);KKo=r(jTt,"splinter"),jTt.forEach(t),ZKo=r(aPe," \u2014 "),Gz=n(aPe,"A",{href:!0});var DTt=s(Gz);eZo=r(DTt,"SplinterForQuestionAnswering"),DTt.forEach(t),oZo=r(aPe," (Splinter model)"),aPe.forEach(t),rZo=i(X),LF=n(X,"LI",{});var nPe=s(LF);j_e=n(nPe,"STRONG",{});var GTt=s(j_e);tZo=r(GTt,"squeezebert"),GTt.forEach(t),aZo=r(nPe," \u2014 "),Oz=n(nPe,"A",{href:!0});var OTt=s(Oz);nZo=r(OTt,"SqueezeBertForQuestionAnswering"),OTt.forEach(t),sZo=r(nPe," (SqueezeBERT model)"),nPe.forEach(t),lZo=i(X),yF=n(X,"LI",{});var sPe=s(yF);D_e=n(sPe,"STRONG",{});var VTt=s(D_e);iZo=r(VTt,"xlm"),VTt.forEach(t),dZo=r(sPe," \u2014 "),Vz=n(sPe,"A",{href:!0});var XTt=s(Vz);cZo=r(XTt,"XLMForQuestionAnsweringSimple"),XTt.forEach(t),fZo=r(sPe," (XLM model)"),sPe.forEach(t),mZo=i(X),xF=n(X,"LI",{});var lPe=s(xF);G_e=n(lPe,"STRONG",{});var zTt=s(G_e);gZo=r(zTt,"xlm-roberta"),zTt.forEach(t),hZo=r(lPe," \u2014 "),Xz=n(lPe,"A",{href:!0});var WTt=s(Xz);pZo=r(WTt,"XLMRobertaForQuestionAnswering"),WTt.forEach(t),uZo=r(lPe," (XLM-RoBERTa model)"),lPe.forEach(t),_Zo=i(X),$F=n(X,"LI",{});var iPe=s($F);O_e=n(iPe,"STRONG",{});var QTt=s(O_e);bZo=r(QTt,"xlm-roberta-xl"),QTt.forEach(t),vZo=r(iPe," \u2014 "),zz=n(iPe,"A",{href:!0});var HTt=s(zz);FZo=r(HTt,"XLMRobertaXLForQuestionAnswering"),HTt.forEach(t),TZo=r(iPe," (XLM-RoBERTa-XL model)"),iPe.forEach(t),MZo=i(X),kF=n(X,"LI",{});var dPe=s(kF);V_e=n(dPe,"STRONG",{});var UTt=s(V_e);EZo=r(UTt,"xlnet"),UTt.forEach(t),CZo=r(dPe," \u2014 "),Wz=n(dPe,"A",{href:!0});var JTt=s(Wz);wZo=r(JTt,"XLNetForQuestionAnsweringSimple"),JTt.forEach(t),AZo=r(dPe," (XLNet model)"),dPe.forEach(t),LZo=i(X),SF=n(X,"LI",{});var cPe=s(SF);X_e=n(cPe,"STRONG",{});var YTt=s(X_e);yZo=r(YTt,"yoso"),YTt.forEach(t),xZo=r(cPe," \u2014 "),Qz=n(cPe,"A",{href:!0});var KTt=s(Qz);$Zo=r(KTt,"YosoForQuestionAnswering"),KTt.forEach(t),kZo=r(cPe," (YOSO model)"),cPe.forEach(t),X.forEach(t),SZo=i(ga),RF=n(ga,"P",{});var fPe=s(RF);RZo=r(fPe,"The model is set in evaluation mode by default using "),z_e=n(fPe,"CODE",{});var ZTt=s(z_e);PZo=r(ZTt,"model.eval()"),ZTt.forEach(t),BZo=r(fPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W_e=n(fPe,"CODE",{});var e7t=s(W_e);IZo=r(e7t,"model.train()"),e7t.forEach(t),fPe.forEach(t),NZo=i(ga),T(PF.$$.fragment,ga),ga.forEach(t),sl.forEach(t),KGe=i(f),fd=n(f,"H2",{class:!0});var aXe=s(fd);BF=n(aXe,"A",{id:!0,class:!0,href:!0});var o7t=s(BF);Q_e=n(o7t,"SPAN",{});var r7t=s(Q_e);T(Wy.$$.fragment,r7t),r7t.forEach(t),o7t.forEach(t),qZo=i(aXe),H_e=n(aXe,"SPAN",{});var t7t=s(H_e);jZo=r(t7t,"AutoModelForTableQuestionAnswering"),t7t.forEach(t),aXe.forEach(t),ZGe=i(f),jo=n(f,"DIV",{class:!0});var ll=s(jo);T(Qy.$$.fragment,ll),DZo=i(ll),md=n(ll,"P",{});var xoe=s(md);GZo=r(xoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Hz=n(xoe,"A",{href:!0});var a7t=s(Hz);OZo=r(a7t,"from_pretrained()"),a7t.forEach(t),VZo=r(xoe," class method or the "),Uz=n(xoe,"A",{href:!0});var n7t=s(Uz);XZo=r(n7t,"from_config()"),n7t.forEach(t),zZo=r(xoe,` class
method.`),xoe.forEach(t),WZo=i(ll),Hy=n(ll,"P",{});var nXe=s(Hy);QZo=r(nXe,"This class cannot be instantiated directly using "),U_e=n(nXe,"CODE",{});var s7t=s(U_e);HZo=r(s7t,"__init__()"),s7t.forEach(t),UZo=r(nXe," (throws an error)."),nXe.forEach(t),JZo=i(ll),pt=n(ll,"DIV",{class:!0});var WA=s(pt);T(Uy.$$.fragment,WA),YZo=i(WA),J_e=n(WA,"P",{});var l7t=s(J_e);KZo=r(l7t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),l7t.forEach(t),ZZo=i(WA),gd=n(WA,"P",{});var $oe=s(gd);eer=r($oe,`Note:
Loading a model from its configuration file does `),Y_e=n($oe,"STRONG",{});var i7t=s(Y_e);oer=r(i7t,"not"),i7t.forEach(t),rer=r($oe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jz=n($oe,"A",{href:!0});var d7t=s(Jz);ter=r(d7t,"from_pretrained()"),d7t.forEach(t),aer=r($oe," to load the model weights."),$oe.forEach(t),ner=i(WA),T(IF.$$.fragment,WA),WA.forEach(t),ser=i(ll),so=n(ll,"DIV",{class:!0});var ha=s(so);T(Jy.$$.fragment,ha),ler=i(ha),K_e=n(ha,"P",{});var c7t=s(K_e);ier=r(c7t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),c7t.forEach(t),der=i(ha),Oa=n(ha,"P",{});var QA=s(Oa);cer=r(QA,"The model class to instantiate is selected based on the "),Z_e=n(QA,"CODE",{});var f7t=s(Z_e);fer=r(f7t,"model_type"),f7t.forEach(t),mer=r(QA,` property of the config object (either
passed as an argument or loaded from `),e1e=n(QA,"CODE",{});var m7t=s(e1e);ger=r(m7t,"pretrained_model_name_or_path"),m7t.forEach(t),her=r(QA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o1e=n(QA,"CODE",{});var g7t=s(o1e);per=r(g7t,"pretrained_model_name_or_path"),g7t.forEach(t),uer=r(QA,":"),QA.forEach(t),_er=i(ha),r1e=n(ha,"UL",{});var h7t=s(r1e);NF=n(h7t,"LI",{});var mPe=s(NF);t1e=n(mPe,"STRONG",{});var p7t=s(t1e);ber=r(p7t,"tapas"),p7t.forEach(t),ver=r(mPe," \u2014 "),Yz=n(mPe,"A",{href:!0});var u7t=s(Yz);Fer=r(u7t,"TapasForQuestionAnswering"),u7t.forEach(t),Ter=r(mPe," (TAPAS model)"),mPe.forEach(t),h7t.forEach(t),Mer=i(ha),qF=n(ha,"P",{});var gPe=s(qF);Eer=r(gPe,"The model is set in evaluation mode by default using "),a1e=n(gPe,"CODE",{});var _7t=s(a1e);Cer=r(_7t,"model.eval()"),_7t.forEach(t),wer=r(gPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n1e=n(gPe,"CODE",{});var b7t=s(n1e);Aer=r(b7t,"model.train()"),b7t.forEach(t),gPe.forEach(t),Ler=i(ha),T(jF.$$.fragment,ha),ha.forEach(t),ll.forEach(t),eOe=i(f),hd=n(f,"H2",{class:!0});var sXe=s(hd);DF=n(sXe,"A",{id:!0,class:!0,href:!0});var v7t=s(DF);s1e=n(v7t,"SPAN",{});var F7t=s(s1e);T(Yy.$$.fragment,F7t),F7t.forEach(t),v7t.forEach(t),yer=i(sXe),l1e=n(sXe,"SPAN",{});var T7t=s(l1e);xer=r(T7t,"AutoModelForImageClassification"),T7t.forEach(t),sXe.forEach(t),oOe=i(f),Do=n(f,"DIV",{class:!0});var il=s(Do);T(Ky.$$.fragment,il),$er=i(il),pd=n(il,"P",{});var koe=s(pd);ker=r(koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Kz=n(koe,"A",{href:!0});var M7t=s(Kz);Ser=r(M7t,"from_pretrained()"),M7t.forEach(t),Rer=r(koe," class method or the "),Zz=n(koe,"A",{href:!0});var E7t=s(Zz);Per=r(E7t,"from_config()"),E7t.forEach(t),Ber=r(koe,` class
method.`),koe.forEach(t),Ier=i(il),Zy=n(il,"P",{});var lXe=s(Zy);Ner=r(lXe,"This class cannot be instantiated directly using "),i1e=n(lXe,"CODE",{});var C7t=s(i1e);qer=r(C7t,"__init__()"),C7t.forEach(t),jer=r(lXe," (throws an error)."),lXe.forEach(t),Der=i(il),ut=n(il,"DIV",{class:!0});var HA=s(ut);T(e8.$$.fragment,HA),Ger=i(HA),d1e=n(HA,"P",{});var w7t=s(d1e);Oer=r(w7t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),w7t.forEach(t),Ver=i(HA),ud=n(HA,"P",{});var Soe=s(ud);Xer=r(Soe,`Note:
Loading a model from its configuration file does `),c1e=n(Soe,"STRONG",{});var A7t=s(c1e);zer=r(A7t,"not"),A7t.forEach(t),Wer=r(Soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),eW=n(Soe,"A",{href:!0});var L7t=s(eW);Qer=r(L7t,"from_pretrained()"),L7t.forEach(t),Her=r(Soe," to load the model weights."),Soe.forEach(t),Uer=i(HA),T(GF.$$.fragment,HA),HA.forEach(t),Jer=i(il),lo=n(il,"DIV",{class:!0});var pa=s(lo);T(o8.$$.fragment,pa),Yer=i(pa),f1e=n(pa,"P",{});var y7t=s(f1e);Ker=r(y7t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),y7t.forEach(t),Zer=i(pa),Va=n(pa,"P",{});var UA=s(Va);eor=r(UA,"The model class to instantiate is selected based on the "),m1e=n(UA,"CODE",{});var x7t=s(m1e);oor=r(x7t,"model_type"),x7t.forEach(t),ror=r(UA,` property of the config object (either
passed as an argument or loaded from `),g1e=n(UA,"CODE",{});var $7t=s(g1e);tor=r($7t,"pretrained_model_name_or_path"),$7t.forEach(t),aor=r(UA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h1e=n(UA,"CODE",{});var k7t=s(h1e);nor=r(k7t,"pretrained_model_name_or_path"),k7t.forEach(t),sor=r(UA,":"),UA.forEach(t),lor=i(pa),Fe=n(pa,"UL",{});var Te=s(Fe);OF=n(Te,"LI",{});var hPe=s(OF);p1e=n(hPe,"STRONG",{});var S7t=s(p1e);ior=r(S7t,"beit"),S7t.forEach(t),dor=r(hPe," \u2014 "),oW=n(hPe,"A",{href:!0});var R7t=s(oW);cor=r(R7t,"BeitForImageClassification"),R7t.forEach(t),mor=r(hPe," (BEiT model)"),hPe.forEach(t),gor=i(Te),VF=n(Te,"LI",{});var pPe=s(VF);u1e=n(pPe,"STRONG",{});var P7t=s(u1e);hor=r(P7t,"convnext"),P7t.forEach(t),por=r(pPe," \u2014 "),rW=n(pPe,"A",{href:!0});var B7t=s(rW);uor=r(B7t,"ConvNextForImageClassification"),B7t.forEach(t),_or=r(pPe," (ConvNeXT model)"),pPe.forEach(t),bor=i(Te),XF=n(Te,"LI",{});var uPe=s(XF);_1e=n(uPe,"STRONG",{});var I7t=s(_1e);vor=r(I7t,"cvt"),I7t.forEach(t),For=r(uPe," \u2014 "),tW=n(uPe,"A",{href:!0});var N7t=s(tW);Tor=r(N7t,"CvtForImageClassification"),N7t.forEach(t),Mor=r(uPe," (CvT model)"),uPe.forEach(t),Eor=i(Te),zF=n(Te,"LI",{});var _Pe=s(zF);b1e=n(_Pe,"STRONG",{});var q7t=s(b1e);Cor=r(q7t,"data2vec-vision"),q7t.forEach(t),wor=r(_Pe," \u2014 "),aW=n(_Pe,"A",{href:!0});var j7t=s(aW);Aor=r(j7t,"Data2VecVisionForImageClassification"),j7t.forEach(t),Lor=r(_Pe," (Data2VecVision model)"),_Pe.forEach(t),yor=i(Te),Vs=n(Te,"LI",{});var Hk=s(Vs);v1e=n(Hk,"STRONG",{});var D7t=s(v1e);xor=r(D7t,"deit"),D7t.forEach(t),$or=r(Hk," \u2014 "),nW=n(Hk,"A",{href:!0});var G7t=s(nW);kor=r(G7t,"DeiTForImageClassification"),G7t.forEach(t),Sor=r(Hk," or "),sW=n(Hk,"A",{href:!0});var O7t=s(sW);Ror=r(O7t,"DeiTForImageClassificationWithTeacher"),O7t.forEach(t),Por=r(Hk," (DeiT model)"),Hk.forEach(t),Bor=i(Te),WF=n(Te,"LI",{});var bPe=s(WF);F1e=n(bPe,"STRONG",{});var V7t=s(F1e);Ior=r(V7t,"imagegpt"),V7t.forEach(t),Nor=r(bPe," \u2014 "),lW=n(bPe,"A",{href:!0});var X7t=s(lW);qor=r(X7t,"ImageGPTForImageClassification"),X7t.forEach(t),jor=r(bPe," (ImageGPT model)"),bPe.forEach(t),Dor=i(Te),Xs=n(Te,"LI",{});var Uk=s(Xs);T1e=n(Uk,"STRONG",{});var z7t=s(T1e);Gor=r(z7t,"levit"),z7t.forEach(t),Oor=r(Uk," \u2014 "),iW=n(Uk,"A",{href:!0});var W7t=s(iW);Vor=r(W7t,"LevitForImageClassification"),W7t.forEach(t),Xor=r(Uk," or "),dW=n(Uk,"A",{href:!0});var Q7t=s(dW);zor=r(Q7t,"LevitForImageClassificationWithTeacher"),Q7t.forEach(t),Wor=r(Uk," (LeViT model)"),Uk.forEach(t),Qor=i(Te),_t=n(Te,"LI",{});var Lf=s(_t);M1e=n(Lf,"STRONG",{});var H7t=s(M1e);Hor=r(H7t,"perceiver"),H7t.forEach(t),Uor=r(Lf," \u2014 "),cW=n(Lf,"A",{href:!0});var U7t=s(cW);Jor=r(U7t,"PerceiverForImageClassificationLearned"),U7t.forEach(t),Yor=r(Lf," or "),fW=n(Lf,"A",{href:!0});var J7t=s(fW);Kor=r(J7t,"PerceiverForImageClassificationFourier"),J7t.forEach(t),Zor=r(Lf," or "),mW=n(Lf,"A",{href:!0});var Y7t=s(mW);err=r(Y7t,"PerceiverForImageClassificationConvProcessing"),Y7t.forEach(t),orr=r(Lf," (Perceiver model)"),Lf.forEach(t),rrr=i(Te),QF=n(Te,"LI",{});var vPe=s(QF);E1e=n(vPe,"STRONG",{});var K7t=s(E1e);trr=r(K7t,"poolformer"),K7t.forEach(t),arr=r(vPe," \u2014 "),gW=n(vPe,"A",{href:!0});var Z7t=s(gW);nrr=r(Z7t,"PoolFormerForImageClassification"),Z7t.forEach(t),srr=r(vPe," (PoolFormer model)"),vPe.forEach(t),lrr=i(Te),HF=n(Te,"LI",{});var FPe=s(HF);C1e=n(FPe,"STRONG",{});var eMt=s(C1e);irr=r(eMt,"regnet"),eMt.forEach(t),drr=r(FPe," \u2014 "),hW=n(FPe,"A",{href:!0});var oMt=s(hW);crr=r(oMt,"RegNetForImageClassification"),oMt.forEach(t),frr=r(FPe," (RegNet model)"),FPe.forEach(t),mrr=i(Te),UF=n(Te,"LI",{});var TPe=s(UF);w1e=n(TPe,"STRONG",{});var rMt=s(w1e);grr=r(rMt,"resnet"),rMt.forEach(t),hrr=r(TPe," \u2014 "),pW=n(TPe,"A",{href:!0});var tMt=s(pW);prr=r(tMt,"ResNetForImageClassification"),tMt.forEach(t),urr=r(TPe," (ResNet model)"),TPe.forEach(t),_rr=i(Te),JF=n(Te,"LI",{});var MPe=s(JF);A1e=n(MPe,"STRONG",{});var aMt=s(A1e);brr=r(aMt,"segformer"),aMt.forEach(t),vrr=r(MPe," \u2014 "),uW=n(MPe,"A",{href:!0});var nMt=s(uW);Frr=r(nMt,"SegformerForImageClassification"),nMt.forEach(t),Trr=r(MPe," (SegFormer model)"),MPe.forEach(t),Mrr=i(Te),YF=n(Te,"LI",{});var EPe=s(YF);L1e=n(EPe,"STRONG",{});var sMt=s(L1e);Err=r(sMt,"swin"),sMt.forEach(t),Crr=r(EPe," \u2014 "),_W=n(EPe,"A",{href:!0});var lMt=s(_W);wrr=r(lMt,"SwinForImageClassification"),lMt.forEach(t),Arr=r(EPe," (Swin Transformer model)"),EPe.forEach(t),Lrr=i(Te),KF=n(Te,"LI",{});var CPe=s(KF);y1e=n(CPe,"STRONG",{});var iMt=s(y1e);yrr=r(iMt,"van"),iMt.forEach(t),xrr=r(CPe," \u2014 "),bW=n(CPe,"A",{href:!0});var dMt=s(bW);$rr=r(dMt,"VanForImageClassification"),dMt.forEach(t),krr=r(CPe," (VAN model)"),CPe.forEach(t),Srr=i(Te),ZF=n(Te,"LI",{});var wPe=s(ZF);x1e=n(wPe,"STRONG",{});var cMt=s(x1e);Rrr=r(cMt,"vit"),cMt.forEach(t),Prr=r(wPe," \u2014 "),vW=n(wPe,"A",{href:!0});var fMt=s(vW);Brr=r(fMt,"ViTForImageClassification"),fMt.forEach(t),Irr=r(wPe," (ViT model)"),wPe.forEach(t),Te.forEach(t),Nrr=i(pa),eT=n(pa,"P",{});var APe=s(eT);qrr=r(APe,"The model is set in evaluation mode by default using "),$1e=n(APe,"CODE",{});var mMt=s($1e);jrr=r(mMt,"model.eval()"),mMt.forEach(t),Drr=r(APe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k1e=n(APe,"CODE",{});var gMt=s(k1e);Grr=r(gMt,"model.train()"),gMt.forEach(t),APe.forEach(t),Orr=i(pa),T(oT.$$.fragment,pa),pa.forEach(t),il.forEach(t),rOe=i(f),_d=n(f,"H2",{class:!0});var iXe=s(_d);rT=n(iXe,"A",{id:!0,class:!0,href:!0});var hMt=s(rT);S1e=n(hMt,"SPAN",{});var pMt=s(S1e);T(r8.$$.fragment,pMt),pMt.forEach(t),hMt.forEach(t),Vrr=i(iXe),R1e=n(iXe,"SPAN",{});var uMt=s(R1e);Xrr=r(uMt,"AutoModelForVision2Seq"),uMt.forEach(t),iXe.forEach(t),tOe=i(f),Go=n(f,"DIV",{class:!0});var dl=s(Go);T(t8.$$.fragment,dl),zrr=i(dl),bd=n(dl,"P",{});var Roe=s(bd);Wrr=r(Roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),FW=n(Roe,"A",{href:!0});var _Mt=s(FW);Qrr=r(_Mt,"from_pretrained()"),_Mt.forEach(t),Hrr=r(Roe," class method or the "),TW=n(Roe,"A",{href:!0});var bMt=s(TW);Urr=r(bMt,"from_config()"),bMt.forEach(t),Jrr=r(Roe,` class
method.`),Roe.forEach(t),Yrr=i(dl),a8=n(dl,"P",{});var dXe=s(a8);Krr=r(dXe,"This class cannot be instantiated directly using "),P1e=n(dXe,"CODE",{});var vMt=s(P1e);Zrr=r(vMt,"__init__()"),vMt.forEach(t),etr=r(dXe," (throws an error)."),dXe.forEach(t),otr=i(dl),bt=n(dl,"DIV",{class:!0});var JA=s(bt);T(n8.$$.fragment,JA),rtr=i(JA),B1e=n(JA,"P",{});var FMt=s(B1e);ttr=r(FMt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),FMt.forEach(t),atr=i(JA),vd=n(JA,"P",{});var Poe=s(vd);ntr=r(Poe,`Note:
Loading a model from its configuration file does `),I1e=n(Poe,"STRONG",{});var TMt=s(I1e);str=r(TMt,"not"),TMt.forEach(t),ltr=r(Poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MW=n(Poe,"A",{href:!0});var MMt=s(MW);itr=r(MMt,"from_pretrained()"),MMt.forEach(t),dtr=r(Poe," to load the model weights."),Poe.forEach(t),ctr=i(JA),T(tT.$$.fragment,JA),JA.forEach(t),ftr=i(dl),io=n(dl,"DIV",{class:!0});var ua=s(io);T(s8.$$.fragment,ua),mtr=i(ua),N1e=n(ua,"P",{});var EMt=s(N1e);gtr=r(EMt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),EMt.forEach(t),htr=i(ua),Xa=n(ua,"P",{});var YA=s(Xa);ptr=r(YA,"The model class to instantiate is selected based on the "),q1e=n(YA,"CODE",{});var CMt=s(q1e);utr=r(CMt,"model_type"),CMt.forEach(t),_tr=r(YA,` property of the config object (either
passed as an argument or loaded from `),j1e=n(YA,"CODE",{});var wMt=s(j1e);btr=r(wMt,"pretrained_model_name_or_path"),wMt.forEach(t),vtr=r(YA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D1e=n(YA,"CODE",{});var AMt=s(D1e);Ftr=r(AMt,"pretrained_model_name_or_path"),AMt.forEach(t),Ttr=r(YA,":"),YA.forEach(t),Mtr=i(ua),G1e=n(ua,"UL",{});var LMt=s(G1e);aT=n(LMt,"LI",{});var LPe=s(aT);O1e=n(LPe,"STRONG",{});var yMt=s(O1e);Etr=r(yMt,"vision-encoder-decoder"),yMt.forEach(t),Ctr=r(LPe," \u2014 "),EW=n(LPe,"A",{href:!0});var xMt=s(EW);wtr=r(xMt,"VisionEncoderDecoderModel"),xMt.forEach(t),Atr=r(LPe," (Vision Encoder decoder model)"),LPe.forEach(t),LMt.forEach(t),Ltr=i(ua),nT=n(ua,"P",{});var yPe=s(nT);ytr=r(yPe,"The model is set in evaluation mode by default using "),V1e=n(yPe,"CODE",{});var $Mt=s(V1e);xtr=r($Mt,"model.eval()"),$Mt.forEach(t),$tr=r(yPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X1e=n(yPe,"CODE",{});var kMt=s(X1e);ktr=r(kMt,"model.train()"),kMt.forEach(t),yPe.forEach(t),Str=i(ua),T(sT.$$.fragment,ua),ua.forEach(t),dl.forEach(t),aOe=i(f),Fd=n(f,"H2",{class:!0});var cXe=s(Fd);lT=n(cXe,"A",{id:!0,class:!0,href:!0});var SMt=s(lT);z1e=n(SMt,"SPAN",{});var RMt=s(z1e);T(l8.$$.fragment,RMt),RMt.forEach(t),SMt.forEach(t),Rtr=i(cXe),W1e=n(cXe,"SPAN",{});var PMt=s(W1e);Ptr=r(PMt,"AutoModelForVisualQuestionAnswering"),PMt.forEach(t),cXe.forEach(t),nOe=i(f),Oo=n(f,"DIV",{class:!0});var cl=s(Oo);T(i8.$$.fragment,cl),Btr=i(cl),Td=n(cl,"P",{});var Boe=s(Td);Itr=r(Boe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),CW=n(Boe,"A",{href:!0});var BMt=s(CW);Ntr=r(BMt,"from_pretrained()"),BMt.forEach(t),qtr=r(Boe," class method or the "),wW=n(Boe,"A",{href:!0});var IMt=s(wW);jtr=r(IMt,"from_config()"),IMt.forEach(t),Dtr=r(Boe,` class
method.`),Boe.forEach(t),Gtr=i(cl),d8=n(cl,"P",{});var fXe=s(d8);Otr=r(fXe,"This class cannot be instantiated directly using "),Q1e=n(fXe,"CODE",{});var NMt=s(Q1e);Vtr=r(NMt,"__init__()"),NMt.forEach(t),Xtr=r(fXe," (throws an error)."),fXe.forEach(t),ztr=i(cl),vt=n(cl,"DIV",{class:!0});var KA=s(vt);T(c8.$$.fragment,KA),Wtr=i(KA),H1e=n(KA,"P",{});var qMt=s(H1e);Qtr=r(qMt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),qMt.forEach(t),Htr=i(KA),Md=n(KA,"P",{});var Ioe=s(Md);Utr=r(Ioe,`Note:
Loading a model from its configuration file does `),U1e=n(Ioe,"STRONG",{});var jMt=s(U1e);Jtr=r(jMt,"not"),jMt.forEach(t),Ytr=r(Ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),AW=n(Ioe,"A",{href:!0});var DMt=s(AW);Ktr=r(DMt,"from_pretrained()"),DMt.forEach(t),Ztr=r(Ioe," to load the model weights."),Ioe.forEach(t),ear=i(KA),T(iT.$$.fragment,KA),KA.forEach(t),oar=i(cl),co=n(cl,"DIV",{class:!0});var _a=s(co);T(f8.$$.fragment,_a),rar=i(_a),J1e=n(_a,"P",{});var GMt=s(J1e);tar=r(GMt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),GMt.forEach(t),aar=i(_a),za=n(_a,"P",{});var ZA=s(za);nar=r(ZA,"The model class to instantiate is selected based on the "),Y1e=n(ZA,"CODE",{});var OMt=s(Y1e);sar=r(OMt,"model_type"),OMt.forEach(t),lar=r(ZA,` property of the config object (either
passed as an argument or loaded from `),K1e=n(ZA,"CODE",{});var VMt=s(K1e);iar=r(VMt,"pretrained_model_name_or_path"),VMt.forEach(t),dar=r(ZA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=n(ZA,"CODE",{});var XMt=s(Z1e);car=r(XMt,"pretrained_model_name_or_path"),XMt.forEach(t),far=r(ZA,":"),ZA.forEach(t),mar=i(_a),e3e=n(_a,"UL",{});var zMt=s(e3e);dT=n(zMt,"LI",{});var xPe=s(dT);o3e=n(xPe,"STRONG",{});var WMt=s(o3e);gar=r(WMt,"vilt"),WMt.forEach(t),har=r(xPe," \u2014 "),LW=n(xPe,"A",{href:!0});var QMt=s(LW);par=r(QMt,"ViltForQuestionAnswering"),QMt.forEach(t),uar=r(xPe," (ViLT model)"),xPe.forEach(t),zMt.forEach(t),_ar=i(_a),cT=n(_a,"P",{});var $Pe=s(cT);bar=r($Pe,"The model is set in evaluation mode by default using "),r3e=n($Pe,"CODE",{});var HMt=s(r3e);Far=r(HMt,"model.eval()"),HMt.forEach(t),Tar=r($Pe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t3e=n($Pe,"CODE",{});var UMt=s(t3e);Mar=r(UMt,"model.train()"),UMt.forEach(t),$Pe.forEach(t),Ear=i(_a),T(fT.$$.fragment,_a),_a.forEach(t),cl.forEach(t),sOe=i(f),Ed=n(f,"H2",{class:!0});var mXe=s(Ed);mT=n(mXe,"A",{id:!0,class:!0,href:!0});var JMt=s(mT);a3e=n(JMt,"SPAN",{});var YMt=s(a3e);T(m8.$$.fragment,YMt),YMt.forEach(t),JMt.forEach(t),Car=i(mXe),n3e=n(mXe,"SPAN",{});var KMt=s(n3e);war=r(KMt,"AutoModelForAudioClassification"),KMt.forEach(t),mXe.forEach(t),lOe=i(f),Vo=n(f,"DIV",{class:!0});var fl=s(Vo);T(g8.$$.fragment,fl),Aar=i(fl),Cd=n(fl,"P",{});var Noe=s(Cd);Lar=r(Noe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),yW=n(Noe,"A",{href:!0});var ZMt=s(yW);yar=r(ZMt,"from_pretrained()"),ZMt.forEach(t),xar=r(Noe," class method or the "),xW=n(Noe,"A",{href:!0});var eEt=s(xW);$ar=r(eEt,"from_config()"),eEt.forEach(t),kar=r(Noe,` class
method.`),Noe.forEach(t),Sar=i(fl),h8=n(fl,"P",{});var gXe=s(h8);Rar=r(gXe,"This class cannot be instantiated directly using "),s3e=n(gXe,"CODE",{});var oEt=s(s3e);Par=r(oEt,"__init__()"),oEt.forEach(t),Bar=r(gXe," (throws an error)."),gXe.forEach(t),Iar=i(fl),Ft=n(fl,"DIV",{class:!0});var e6=s(Ft);T(p8.$$.fragment,e6),Nar=i(e6),l3e=n(e6,"P",{});var rEt=s(l3e);qar=r(rEt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),rEt.forEach(t),jar=i(e6),wd=n(e6,"P",{});var qoe=s(wd);Dar=r(qoe,`Note:
Loading a model from its configuration file does `),i3e=n(qoe,"STRONG",{});var tEt=s(i3e);Gar=r(tEt,"not"),tEt.forEach(t),Oar=r(qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),$W=n(qoe,"A",{href:!0});var aEt=s($W);Var=r(aEt,"from_pretrained()"),aEt.forEach(t),Xar=r(qoe," to load the model weights."),qoe.forEach(t),zar=i(e6),T(gT.$$.fragment,e6),e6.forEach(t),War=i(fl),fo=n(fl,"DIV",{class:!0});var ba=s(fo);T(u8.$$.fragment,ba),Qar=i(ba),d3e=n(ba,"P",{});var nEt=s(d3e);Har=r(nEt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),nEt.forEach(t),Uar=i(ba),Wa=n(ba,"P",{});var o6=s(Wa);Jar=r(o6,"The model class to instantiate is selected based on the "),c3e=n(o6,"CODE",{});var sEt=s(c3e);Yar=r(sEt,"model_type"),sEt.forEach(t),Kar=r(o6,` property of the config object (either
passed as an argument or loaded from `),f3e=n(o6,"CODE",{});var lEt=s(f3e);Zar=r(lEt,"pretrained_model_name_or_path"),lEt.forEach(t),enr=r(o6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m3e=n(o6,"CODE",{});var iEt=s(m3e);onr=r(iEt,"pretrained_model_name_or_path"),iEt.forEach(t),rnr=r(o6,":"),o6.forEach(t),tnr=i(ba),Pe=n(ba,"UL",{});var ze=s(Pe);hT=n(ze,"LI",{});var kPe=s(hT);g3e=n(kPe,"STRONG",{});var dEt=s(g3e);anr=r(dEt,"data2vec-audio"),dEt.forEach(t),nnr=r(kPe," \u2014 "),kW=n(kPe,"A",{href:!0});var cEt=s(kW);snr=r(cEt,"Data2VecAudioForSequenceClassification"),cEt.forEach(t),lnr=r(kPe," (Data2VecAudio model)"),kPe.forEach(t),inr=i(ze),pT=n(ze,"LI",{});var SPe=s(pT);h3e=n(SPe,"STRONG",{});var fEt=s(h3e);dnr=r(fEt,"hubert"),fEt.forEach(t),cnr=r(SPe," \u2014 "),SW=n(SPe,"A",{href:!0});var mEt=s(SW);fnr=r(mEt,"HubertForSequenceClassification"),mEt.forEach(t),mnr=r(SPe," (Hubert model)"),SPe.forEach(t),gnr=i(ze),uT=n(ze,"LI",{});var RPe=s(uT);p3e=n(RPe,"STRONG",{});var gEt=s(p3e);hnr=r(gEt,"sew"),gEt.forEach(t),pnr=r(RPe," \u2014 "),RW=n(RPe,"A",{href:!0});var hEt=s(RW);unr=r(hEt,"SEWForSequenceClassification"),hEt.forEach(t),_nr=r(RPe," (SEW model)"),RPe.forEach(t),bnr=i(ze),_T=n(ze,"LI",{});var PPe=s(_T);u3e=n(PPe,"STRONG",{});var pEt=s(u3e);vnr=r(pEt,"sew-d"),pEt.forEach(t),Fnr=r(PPe," \u2014 "),PW=n(PPe,"A",{href:!0});var uEt=s(PW);Tnr=r(uEt,"SEWDForSequenceClassification"),uEt.forEach(t),Mnr=r(PPe," (SEW-D model)"),PPe.forEach(t),Enr=i(ze),bT=n(ze,"LI",{});var BPe=s(bT);_3e=n(BPe,"STRONG",{});var _Et=s(_3e);Cnr=r(_Et,"unispeech"),_Et.forEach(t),wnr=r(BPe," \u2014 "),BW=n(BPe,"A",{href:!0});var bEt=s(BW);Anr=r(bEt,"UniSpeechForSequenceClassification"),bEt.forEach(t),Lnr=r(BPe," (UniSpeech model)"),BPe.forEach(t),ynr=i(ze),vT=n(ze,"LI",{});var IPe=s(vT);b3e=n(IPe,"STRONG",{});var vEt=s(b3e);xnr=r(vEt,"unispeech-sat"),vEt.forEach(t),$nr=r(IPe," \u2014 "),IW=n(IPe,"A",{href:!0});var FEt=s(IW);knr=r(FEt,"UniSpeechSatForSequenceClassification"),FEt.forEach(t),Snr=r(IPe," (UniSpeechSat model)"),IPe.forEach(t),Rnr=i(ze),FT=n(ze,"LI",{});var NPe=s(FT);v3e=n(NPe,"STRONG",{});var TEt=s(v3e);Pnr=r(TEt,"wav2vec2"),TEt.forEach(t),Bnr=r(NPe," \u2014 "),NW=n(NPe,"A",{href:!0});var MEt=s(NW);Inr=r(MEt,"Wav2Vec2ForSequenceClassification"),MEt.forEach(t),Nnr=r(NPe," (Wav2Vec2 model)"),NPe.forEach(t),qnr=i(ze),TT=n(ze,"LI",{});var qPe=s(TT);F3e=n(qPe,"STRONG",{});var EEt=s(F3e);jnr=r(EEt,"wav2vec2-conformer"),EEt.forEach(t),Dnr=r(qPe," \u2014 "),qW=n(qPe,"A",{href:!0});var CEt=s(qW);Gnr=r(CEt,"Wav2Vec2ConformerForSequenceClassification"),CEt.forEach(t),Onr=r(qPe," (Wav2Vec2-Conformer model)"),qPe.forEach(t),Vnr=i(ze),MT=n(ze,"LI",{});var jPe=s(MT);T3e=n(jPe,"STRONG",{});var wEt=s(T3e);Xnr=r(wEt,"wavlm"),wEt.forEach(t),znr=r(jPe," \u2014 "),jW=n(jPe,"A",{href:!0});var AEt=s(jW);Wnr=r(AEt,"WavLMForSequenceClassification"),AEt.forEach(t),Qnr=r(jPe," (WavLM model)"),jPe.forEach(t),ze.forEach(t),Hnr=i(ba),ET=n(ba,"P",{});var DPe=s(ET);Unr=r(DPe,"The model is set in evaluation mode by default using "),M3e=n(DPe,"CODE",{});var LEt=s(M3e);Jnr=r(LEt,"model.eval()"),LEt.forEach(t),Ynr=r(DPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E3e=n(DPe,"CODE",{});var yEt=s(E3e);Knr=r(yEt,"model.train()"),yEt.forEach(t),DPe.forEach(t),Znr=i(ba),T(CT.$$.fragment,ba),ba.forEach(t),fl.forEach(t),iOe=i(f),Ad=n(f,"H2",{class:!0});var hXe=s(Ad);wT=n(hXe,"A",{id:!0,class:!0,href:!0});var xEt=s(wT);C3e=n(xEt,"SPAN",{});var $Et=s(C3e);T(_8.$$.fragment,$Et),$Et.forEach(t),xEt.forEach(t),esr=i(hXe),w3e=n(hXe,"SPAN",{});var kEt=s(w3e);osr=r(kEt,"AutoModelForAudioFrameClassification"),kEt.forEach(t),hXe.forEach(t),dOe=i(f),Xo=n(f,"DIV",{class:!0});var ml=s(Xo);T(b8.$$.fragment,ml),rsr=i(ml),Ld=n(ml,"P",{});var joe=s(Ld);tsr=r(joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),DW=n(joe,"A",{href:!0});var SEt=s(DW);asr=r(SEt,"from_pretrained()"),SEt.forEach(t),nsr=r(joe," class method or the "),GW=n(joe,"A",{href:!0});var REt=s(GW);ssr=r(REt,"from_config()"),REt.forEach(t),lsr=r(joe,` class
method.`),joe.forEach(t),isr=i(ml),v8=n(ml,"P",{});var pXe=s(v8);dsr=r(pXe,"This class cannot be instantiated directly using "),A3e=n(pXe,"CODE",{});var PEt=s(A3e);csr=r(PEt,"__init__()"),PEt.forEach(t),fsr=r(pXe," (throws an error)."),pXe.forEach(t),msr=i(ml),Tt=n(ml,"DIV",{class:!0});var r6=s(Tt);T(F8.$$.fragment,r6),gsr=i(r6),L3e=n(r6,"P",{});var BEt=s(L3e);hsr=r(BEt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),BEt.forEach(t),psr=i(r6),yd=n(r6,"P",{});var Doe=s(yd);usr=r(Doe,`Note:
Loading a model from its configuration file does `),y3e=n(Doe,"STRONG",{});var IEt=s(y3e);_sr=r(IEt,"not"),IEt.forEach(t),bsr=r(Doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=n(Doe,"A",{href:!0});var NEt=s(OW);vsr=r(NEt,"from_pretrained()"),NEt.forEach(t),Fsr=r(Doe," to load the model weights."),Doe.forEach(t),Tsr=i(r6),T(AT.$$.fragment,r6),r6.forEach(t),Msr=i(ml),mo=n(ml,"DIV",{class:!0});var va=s(mo);T(T8.$$.fragment,va),Esr=i(va),x3e=n(va,"P",{});var qEt=s(x3e);Csr=r(qEt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),qEt.forEach(t),wsr=i(va),Qa=n(va,"P",{});var t6=s(Qa);Asr=r(t6,"The model class to instantiate is selected based on the "),$3e=n(t6,"CODE",{});var jEt=s($3e);Lsr=r(jEt,"model_type"),jEt.forEach(t),ysr=r(t6,` property of the config object (either
passed as an argument or loaded from `),k3e=n(t6,"CODE",{});var DEt=s(k3e);xsr=r(DEt,"pretrained_model_name_or_path"),DEt.forEach(t),$sr=r(t6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S3e=n(t6,"CODE",{});var GEt=s(S3e);ksr=r(GEt,"pretrained_model_name_or_path"),GEt.forEach(t),Ssr=r(t6,":"),t6.forEach(t),Rsr=i(va),et=n(va,"UL",{});var gl=s(et);LT=n(gl,"LI",{});var GPe=s(LT);R3e=n(GPe,"STRONG",{});var OEt=s(R3e);Psr=r(OEt,"data2vec-audio"),OEt.forEach(t),Bsr=r(GPe," \u2014 "),VW=n(GPe,"A",{href:!0});var VEt=s(VW);Isr=r(VEt,"Data2VecAudioForAudioFrameClassification"),VEt.forEach(t),Nsr=r(GPe," (Data2VecAudio model)"),GPe.forEach(t),qsr=i(gl),yT=n(gl,"LI",{});var OPe=s(yT);P3e=n(OPe,"STRONG",{});var XEt=s(P3e);jsr=r(XEt,"unispeech-sat"),XEt.forEach(t),Dsr=r(OPe," \u2014 "),XW=n(OPe,"A",{href:!0});var zEt=s(XW);Gsr=r(zEt,"UniSpeechSatForAudioFrameClassification"),zEt.forEach(t),Osr=r(OPe," (UniSpeechSat model)"),OPe.forEach(t),Vsr=i(gl),xT=n(gl,"LI",{});var VPe=s(xT);B3e=n(VPe,"STRONG",{});var WEt=s(B3e);Xsr=r(WEt,"wav2vec2"),WEt.forEach(t),zsr=r(VPe," \u2014 "),zW=n(VPe,"A",{href:!0});var QEt=s(zW);Wsr=r(QEt,"Wav2Vec2ForAudioFrameClassification"),QEt.forEach(t),Qsr=r(VPe," (Wav2Vec2 model)"),VPe.forEach(t),Hsr=i(gl),$T=n(gl,"LI",{});var XPe=s($T);I3e=n(XPe,"STRONG",{});var HEt=s(I3e);Usr=r(HEt,"wav2vec2-conformer"),HEt.forEach(t),Jsr=r(XPe," \u2014 "),WW=n(XPe,"A",{href:!0});var UEt=s(WW);Ysr=r(UEt,"Wav2Vec2ConformerForAudioFrameClassification"),UEt.forEach(t),Ksr=r(XPe," (Wav2Vec2-Conformer model)"),XPe.forEach(t),Zsr=i(gl),kT=n(gl,"LI",{});var zPe=s(kT);N3e=n(zPe,"STRONG",{});var JEt=s(N3e);elr=r(JEt,"wavlm"),JEt.forEach(t),olr=r(zPe," \u2014 "),QW=n(zPe,"A",{href:!0});var YEt=s(QW);rlr=r(YEt,"WavLMForAudioFrameClassification"),YEt.forEach(t),tlr=r(zPe," (WavLM model)"),zPe.forEach(t),gl.forEach(t),alr=i(va),ST=n(va,"P",{});var WPe=s(ST);nlr=r(WPe,"The model is set in evaluation mode by default using "),q3e=n(WPe,"CODE",{});var KEt=s(q3e);slr=r(KEt,"model.eval()"),KEt.forEach(t),llr=r(WPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j3e=n(WPe,"CODE",{});var ZEt=s(j3e);ilr=r(ZEt,"model.train()"),ZEt.forEach(t),WPe.forEach(t),dlr=i(va),T(RT.$$.fragment,va),va.forEach(t),ml.forEach(t),cOe=i(f),xd=n(f,"H2",{class:!0});var uXe=s(xd);PT=n(uXe,"A",{id:!0,class:!0,href:!0});var e4t=s(PT);D3e=n(e4t,"SPAN",{});var o4t=s(D3e);T(M8.$$.fragment,o4t),o4t.forEach(t),e4t.forEach(t),clr=i(uXe),G3e=n(uXe,"SPAN",{});var r4t=s(G3e);flr=r(r4t,"AutoModelForCTC"),r4t.forEach(t),uXe.forEach(t),fOe=i(f),zo=n(f,"DIV",{class:!0});var hl=s(zo);T(E8.$$.fragment,hl),mlr=i(hl),$d=n(hl,"P",{});var Goe=s($d);glr=r(Goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),HW=n(Goe,"A",{href:!0});var t4t=s(HW);hlr=r(t4t,"from_pretrained()"),t4t.forEach(t),plr=r(Goe," class method or the "),UW=n(Goe,"A",{href:!0});var a4t=s(UW);ulr=r(a4t,"from_config()"),a4t.forEach(t),_lr=r(Goe,` class
method.`),Goe.forEach(t),blr=i(hl),C8=n(hl,"P",{});var _Xe=s(C8);vlr=r(_Xe,"This class cannot be instantiated directly using "),O3e=n(_Xe,"CODE",{});var n4t=s(O3e);Flr=r(n4t,"__init__()"),n4t.forEach(t),Tlr=r(_Xe," (throws an error)."),_Xe.forEach(t),Mlr=i(hl),Mt=n(hl,"DIV",{class:!0});var a6=s(Mt);T(w8.$$.fragment,a6),Elr=i(a6),V3e=n(a6,"P",{});var s4t=s(V3e);Clr=r(s4t,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),s4t.forEach(t),wlr=i(a6),kd=n(a6,"P",{});var Ooe=s(kd);Alr=r(Ooe,`Note:
Loading a model from its configuration file does `),X3e=n(Ooe,"STRONG",{});var l4t=s(X3e);Llr=r(l4t,"not"),l4t.forEach(t),ylr=r(Ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),JW=n(Ooe,"A",{href:!0});var i4t=s(JW);xlr=r(i4t,"from_pretrained()"),i4t.forEach(t),$lr=r(Ooe," to load the model weights."),Ooe.forEach(t),klr=i(a6),T(BT.$$.fragment,a6),a6.forEach(t),Slr=i(hl),go=n(hl,"DIV",{class:!0});var Fa=s(go);T(A8.$$.fragment,Fa),Rlr=i(Fa),z3e=n(Fa,"P",{});var d4t=s(z3e);Plr=r(d4t,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),d4t.forEach(t),Blr=i(Fa),Ha=n(Fa,"P",{});var n6=s(Ha);Ilr=r(n6,"The model class to instantiate is selected based on the "),W3e=n(n6,"CODE",{});var c4t=s(W3e);Nlr=r(c4t,"model_type"),c4t.forEach(t),qlr=r(n6,` property of the config object (either
passed as an argument or loaded from `),Q3e=n(n6,"CODE",{});var f4t=s(Q3e);jlr=r(f4t,"pretrained_model_name_or_path"),f4t.forEach(t),Dlr=r(n6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H3e=n(n6,"CODE",{});var m4t=s(H3e);Glr=r(m4t,"pretrained_model_name_or_path"),m4t.forEach(t),Olr=r(n6,":"),n6.forEach(t),Vlr=i(Fa),Le=n(Fa,"UL",{});var Be=s(Le);IT=n(Be,"LI",{});var QPe=s(IT);U3e=n(QPe,"STRONG",{});var g4t=s(U3e);Xlr=r(g4t,"data2vec-audio"),g4t.forEach(t),zlr=r(QPe," \u2014 "),YW=n(QPe,"A",{href:!0});var h4t=s(YW);Wlr=r(h4t,"Data2VecAudioForCTC"),h4t.forEach(t),Qlr=r(QPe," (Data2VecAudio model)"),QPe.forEach(t),Hlr=i(Be),NT=n(Be,"LI",{});var HPe=s(NT);J3e=n(HPe,"STRONG",{});var p4t=s(J3e);Ulr=r(p4t,"hubert"),p4t.forEach(t),Jlr=r(HPe," \u2014 "),KW=n(HPe,"A",{href:!0});var u4t=s(KW);Ylr=r(u4t,"HubertForCTC"),u4t.forEach(t),Klr=r(HPe," (Hubert model)"),HPe.forEach(t),Zlr=i(Be),qT=n(Be,"LI",{});var UPe=s(qT);Y3e=n(UPe,"STRONG",{});var _4t=s(Y3e);eir=r(_4t,"mctct"),_4t.forEach(t),oir=r(UPe," \u2014 "),ZW=n(UPe,"A",{href:!0});var b4t=s(ZW);rir=r(b4t,"MCTCTForCTC"),b4t.forEach(t),tir=r(UPe," (M-CTC-T model)"),UPe.forEach(t),air=i(Be),jT=n(Be,"LI",{});var JPe=s(jT);K3e=n(JPe,"STRONG",{});var v4t=s(K3e);nir=r(v4t,"sew"),v4t.forEach(t),sir=r(JPe," \u2014 "),eQ=n(JPe,"A",{href:!0});var F4t=s(eQ);lir=r(F4t,"SEWForCTC"),F4t.forEach(t),iir=r(JPe," (SEW model)"),JPe.forEach(t),dir=i(Be),DT=n(Be,"LI",{});var YPe=s(DT);Z3e=n(YPe,"STRONG",{});var T4t=s(Z3e);cir=r(T4t,"sew-d"),T4t.forEach(t),fir=r(YPe," \u2014 "),oQ=n(YPe,"A",{href:!0});var M4t=s(oQ);mir=r(M4t,"SEWDForCTC"),M4t.forEach(t),gir=r(YPe," (SEW-D model)"),YPe.forEach(t),hir=i(Be),GT=n(Be,"LI",{});var KPe=s(GT);e2e=n(KPe,"STRONG",{});var E4t=s(e2e);pir=r(E4t,"unispeech"),E4t.forEach(t),uir=r(KPe," \u2014 "),rQ=n(KPe,"A",{href:!0});var C4t=s(rQ);_ir=r(C4t,"UniSpeechForCTC"),C4t.forEach(t),bir=r(KPe," (UniSpeech model)"),KPe.forEach(t),vir=i(Be),OT=n(Be,"LI",{});var ZPe=s(OT);o2e=n(ZPe,"STRONG",{});var w4t=s(o2e);Fir=r(w4t,"unispeech-sat"),w4t.forEach(t),Tir=r(ZPe," \u2014 "),tQ=n(ZPe,"A",{href:!0});var A4t=s(tQ);Mir=r(A4t,"UniSpeechSatForCTC"),A4t.forEach(t),Eir=r(ZPe," (UniSpeechSat model)"),ZPe.forEach(t),Cir=i(Be),VT=n(Be,"LI",{});var eBe=s(VT);r2e=n(eBe,"STRONG",{});var L4t=s(r2e);wir=r(L4t,"wav2vec2"),L4t.forEach(t),Air=r(eBe," \u2014 "),aQ=n(eBe,"A",{href:!0});var y4t=s(aQ);Lir=r(y4t,"Wav2Vec2ForCTC"),y4t.forEach(t),yir=r(eBe," (Wav2Vec2 model)"),eBe.forEach(t),xir=i(Be),XT=n(Be,"LI",{});var oBe=s(XT);t2e=n(oBe,"STRONG",{});var x4t=s(t2e);$ir=r(x4t,"wav2vec2-conformer"),x4t.forEach(t),kir=r(oBe," \u2014 "),nQ=n(oBe,"A",{href:!0});var $4t=s(nQ);Sir=r($4t,"Wav2Vec2ConformerForCTC"),$4t.forEach(t),Rir=r(oBe," (Wav2Vec2-Conformer model)"),oBe.forEach(t),Pir=i(Be),zT=n(Be,"LI",{});var rBe=s(zT);a2e=n(rBe,"STRONG",{});var k4t=s(a2e);Bir=r(k4t,"wavlm"),k4t.forEach(t),Iir=r(rBe," \u2014 "),sQ=n(rBe,"A",{href:!0});var S4t=s(sQ);Nir=r(S4t,"WavLMForCTC"),S4t.forEach(t),qir=r(rBe," (WavLM model)"),rBe.forEach(t),Be.forEach(t),jir=i(Fa),WT=n(Fa,"P",{});var tBe=s(WT);Dir=r(tBe,"The model is set in evaluation mode by default using "),n2e=n(tBe,"CODE",{});var R4t=s(n2e);Gir=r(R4t,"model.eval()"),R4t.forEach(t),Oir=r(tBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s2e=n(tBe,"CODE",{});var P4t=s(s2e);Vir=r(P4t,"model.train()"),P4t.forEach(t),tBe.forEach(t),Xir=i(Fa),T(QT.$$.fragment,Fa),Fa.forEach(t),hl.forEach(t),mOe=i(f),Sd=n(f,"H2",{class:!0});var bXe=s(Sd);HT=n(bXe,"A",{id:!0,class:!0,href:!0});var B4t=s(HT);l2e=n(B4t,"SPAN",{});var I4t=s(l2e);T(L8.$$.fragment,I4t),I4t.forEach(t),B4t.forEach(t),zir=i(bXe),i2e=n(bXe,"SPAN",{});var N4t=s(i2e);Wir=r(N4t,"AutoModelForSpeechSeq2Seq"),N4t.forEach(t),bXe.forEach(t),gOe=i(f),Wo=n(f,"DIV",{class:!0});var pl=s(Wo);T(y8.$$.fragment,pl),Qir=i(pl),Rd=n(pl,"P",{});var Voe=s(Rd);Hir=r(Voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),lQ=n(Voe,"A",{href:!0});var q4t=s(lQ);Uir=r(q4t,"from_pretrained()"),q4t.forEach(t),Jir=r(Voe," class method or the "),iQ=n(Voe,"A",{href:!0});var j4t=s(iQ);Yir=r(j4t,"from_config()"),j4t.forEach(t),Kir=r(Voe,` class
method.`),Voe.forEach(t),Zir=i(pl),x8=n(pl,"P",{});var vXe=s(x8);edr=r(vXe,"This class cannot be instantiated directly using "),d2e=n(vXe,"CODE",{});var D4t=s(d2e);odr=r(D4t,"__init__()"),D4t.forEach(t),rdr=r(vXe," (throws an error)."),vXe.forEach(t),tdr=i(pl),Et=n(pl,"DIV",{class:!0});var s6=s(Et);T($8.$$.fragment,s6),adr=i(s6),c2e=n(s6,"P",{});var G4t=s(c2e);ndr=r(G4t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),G4t.forEach(t),sdr=i(s6),Pd=n(s6,"P",{});var Xoe=s(Pd);ldr=r(Xoe,`Note:
Loading a model from its configuration file does `),f2e=n(Xoe,"STRONG",{});var O4t=s(f2e);idr=r(O4t,"not"),O4t.forEach(t),ddr=r(Xoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),dQ=n(Xoe,"A",{href:!0});var V4t=s(dQ);cdr=r(V4t,"from_pretrained()"),V4t.forEach(t),fdr=r(Xoe," to load the model weights."),Xoe.forEach(t),mdr=i(s6),T(UT.$$.fragment,s6),s6.forEach(t),gdr=i(pl),ho=n(pl,"DIV",{class:!0});var Ta=s(ho);T(k8.$$.fragment,Ta),hdr=i(Ta),m2e=n(Ta,"P",{});var X4t=s(m2e);pdr=r(X4t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),X4t.forEach(t),udr=i(Ta),Ua=n(Ta,"P",{});var l6=s(Ua);_dr=r(l6,"The model class to instantiate is selected based on the "),g2e=n(l6,"CODE",{});var z4t=s(g2e);bdr=r(z4t,"model_type"),z4t.forEach(t),vdr=r(l6,` property of the config object (either
passed as an argument or loaded from `),h2e=n(l6,"CODE",{});var W4t=s(h2e);Fdr=r(W4t,"pretrained_model_name_or_path"),W4t.forEach(t),Tdr=r(l6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p2e=n(l6,"CODE",{});var Q4t=s(p2e);Mdr=r(Q4t,"pretrained_model_name_or_path"),Q4t.forEach(t),Edr=r(l6,":"),l6.forEach(t),Cdr=i(Ta),S8=n(Ta,"UL",{});var FXe=s(S8);JT=n(FXe,"LI",{});var aBe=s(JT);u2e=n(aBe,"STRONG",{});var H4t=s(u2e);wdr=r(H4t,"speech-encoder-decoder"),H4t.forEach(t),Adr=r(aBe," \u2014 "),cQ=n(aBe,"A",{href:!0});var U4t=s(cQ);Ldr=r(U4t,"SpeechEncoderDecoderModel"),U4t.forEach(t),ydr=r(aBe," (Speech Encoder decoder model)"),aBe.forEach(t),xdr=i(FXe),YT=n(FXe,"LI",{});var nBe=s(YT);_2e=n(nBe,"STRONG",{});var J4t=s(_2e);$dr=r(J4t,"speech_to_text"),J4t.forEach(t),kdr=r(nBe," \u2014 "),fQ=n(nBe,"A",{href:!0});var Y4t=s(fQ);Sdr=r(Y4t,"Speech2TextForConditionalGeneration"),Y4t.forEach(t),Rdr=r(nBe," (Speech2Text model)"),nBe.forEach(t),FXe.forEach(t),Pdr=i(Ta),KT=n(Ta,"P",{});var sBe=s(KT);Bdr=r(sBe,"The model is set in evaluation mode by default using "),b2e=n(sBe,"CODE",{});var K4t=s(b2e);Idr=r(K4t,"model.eval()"),K4t.forEach(t),Ndr=r(sBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v2e=n(sBe,"CODE",{});var Z4t=s(v2e);qdr=r(Z4t,"model.train()"),Z4t.forEach(t),sBe.forEach(t),jdr=i(Ta),T(ZT.$$.fragment,Ta),Ta.forEach(t),pl.forEach(t),hOe=i(f),Bd=n(f,"H2",{class:!0});var TXe=s(Bd);e7=n(TXe,"A",{id:!0,class:!0,href:!0});var eCt=s(e7);F2e=n(eCt,"SPAN",{});var oCt=s(F2e);T(R8.$$.fragment,oCt),oCt.forEach(t),eCt.forEach(t),Ddr=i(TXe),T2e=n(TXe,"SPAN",{});var rCt=s(T2e);Gdr=r(rCt,"AutoModelForAudioXVector"),rCt.forEach(t),TXe.forEach(t),pOe=i(f),Qo=n(f,"DIV",{class:!0});var ul=s(Qo);T(P8.$$.fragment,ul),Odr=i(ul),Id=n(ul,"P",{});var zoe=s(Id);Vdr=r(zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),mQ=n(zoe,"A",{href:!0});var tCt=s(mQ);Xdr=r(tCt,"from_pretrained()"),tCt.forEach(t),zdr=r(zoe," class method or the "),gQ=n(zoe,"A",{href:!0});var aCt=s(gQ);Wdr=r(aCt,"from_config()"),aCt.forEach(t),Qdr=r(zoe,` class
method.`),zoe.forEach(t),Hdr=i(ul),B8=n(ul,"P",{});var MXe=s(B8);Udr=r(MXe,"This class cannot be instantiated directly using "),M2e=n(MXe,"CODE",{});var nCt=s(M2e);Jdr=r(nCt,"__init__()"),nCt.forEach(t),Ydr=r(MXe," (throws an error)."),MXe.forEach(t),Kdr=i(ul),Ct=n(ul,"DIV",{class:!0});var i6=s(Ct);T(I8.$$.fragment,i6),Zdr=i(i6),E2e=n(i6,"P",{});var sCt=s(E2e);ecr=r(sCt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),sCt.forEach(t),ocr=i(i6),Nd=n(i6,"P",{});var Woe=s(Nd);rcr=r(Woe,`Note:
Loading a model from its configuration file does `),C2e=n(Woe,"STRONG",{});var lCt=s(C2e);tcr=r(lCt,"not"),lCt.forEach(t),acr=r(Woe,` load the model weights. It only affects the
model\u2019s configuration. Use `),hQ=n(Woe,"A",{href:!0});var iCt=s(hQ);ncr=r(iCt,"from_pretrained()"),iCt.forEach(t),scr=r(Woe," to load the model weights."),Woe.forEach(t),lcr=i(i6),T(o7.$$.fragment,i6),i6.forEach(t),icr=i(ul),po=n(ul,"DIV",{class:!0});var Ma=s(po);T(N8.$$.fragment,Ma),dcr=i(Ma),w2e=n(Ma,"P",{});var dCt=s(w2e);ccr=r(dCt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),dCt.forEach(t),fcr=i(Ma),Ja=n(Ma,"P",{});var d6=s(Ja);mcr=r(d6,"The model class to instantiate is selected based on the "),A2e=n(d6,"CODE",{});var cCt=s(A2e);gcr=r(cCt,"model_type"),cCt.forEach(t),hcr=r(d6,` property of the config object (either
passed as an argument or loaded from `),L2e=n(d6,"CODE",{});var fCt=s(L2e);pcr=r(fCt,"pretrained_model_name_or_path"),fCt.forEach(t),ucr=r(d6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y2e=n(d6,"CODE",{});var mCt=s(y2e);_cr=r(mCt,"pretrained_model_name_or_path"),mCt.forEach(t),bcr=r(d6,":"),d6.forEach(t),vcr=i(Ma),ot=n(Ma,"UL",{});var _l=s(ot);r7=n(_l,"LI",{});var lBe=s(r7);x2e=n(lBe,"STRONG",{});var gCt=s(x2e);Fcr=r(gCt,"data2vec-audio"),gCt.forEach(t),Tcr=r(lBe," \u2014 "),pQ=n(lBe,"A",{href:!0});var hCt=s(pQ);Mcr=r(hCt,"Data2VecAudioForXVector"),hCt.forEach(t),Ecr=r(lBe," (Data2VecAudio model)"),lBe.forEach(t),Ccr=i(_l),t7=n(_l,"LI",{});var iBe=s(t7);$2e=n(iBe,"STRONG",{});var pCt=s($2e);wcr=r(pCt,"unispeech-sat"),pCt.forEach(t),Acr=r(iBe," \u2014 "),uQ=n(iBe,"A",{href:!0});var uCt=s(uQ);Lcr=r(uCt,"UniSpeechSatForXVector"),uCt.forEach(t),ycr=r(iBe," (UniSpeechSat model)"),iBe.forEach(t),xcr=i(_l),a7=n(_l,"LI",{});var dBe=s(a7);k2e=n(dBe,"STRONG",{});var _Ct=s(k2e);$cr=r(_Ct,"wav2vec2"),_Ct.forEach(t),kcr=r(dBe," \u2014 "),_Q=n(dBe,"A",{href:!0});var bCt=s(_Q);Scr=r(bCt,"Wav2Vec2ForXVector"),bCt.forEach(t),Rcr=r(dBe," (Wav2Vec2 model)"),dBe.forEach(t),Pcr=i(_l),n7=n(_l,"LI",{});var cBe=s(n7);S2e=n(cBe,"STRONG",{});var vCt=s(S2e);Bcr=r(vCt,"wav2vec2-conformer"),vCt.forEach(t),Icr=r(cBe," \u2014 "),bQ=n(cBe,"A",{href:!0});var FCt=s(bQ);Ncr=r(FCt,"Wav2Vec2ConformerForXVector"),FCt.forEach(t),qcr=r(cBe," (Wav2Vec2-Conformer model)"),cBe.forEach(t),jcr=i(_l),s7=n(_l,"LI",{});var fBe=s(s7);R2e=n(fBe,"STRONG",{});var TCt=s(R2e);Dcr=r(TCt,"wavlm"),TCt.forEach(t),Gcr=r(fBe," \u2014 "),vQ=n(fBe,"A",{href:!0});var MCt=s(vQ);Ocr=r(MCt,"WavLMForXVector"),MCt.forEach(t),Vcr=r(fBe," (WavLM model)"),fBe.forEach(t),_l.forEach(t),Xcr=i(Ma),l7=n(Ma,"P",{});var mBe=s(l7);zcr=r(mBe,"The model is set in evaluation mode by default using "),P2e=n(mBe,"CODE",{});var ECt=s(P2e);Wcr=r(ECt,"model.eval()"),ECt.forEach(t),Qcr=r(mBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B2e=n(mBe,"CODE",{});var CCt=s(B2e);Hcr=r(CCt,"model.train()"),CCt.forEach(t),mBe.forEach(t),Ucr=i(Ma),T(i7.$$.fragment,Ma),Ma.forEach(t),ul.forEach(t),uOe=i(f),qd=n(f,"H2",{class:!0});var EXe=s(qd);d7=n(EXe,"A",{id:!0,class:!0,href:!0});var wCt=s(d7);I2e=n(wCt,"SPAN",{});var ACt=s(I2e);T(q8.$$.fragment,ACt),ACt.forEach(t),wCt.forEach(t),Jcr=i(EXe),N2e=n(EXe,"SPAN",{});var LCt=s(N2e);Ycr=r(LCt,"AutoModelForMaskedImageModeling"),LCt.forEach(t),EXe.forEach(t),_Oe=i(f),Ho=n(f,"DIV",{class:!0});var bl=s(Ho);T(j8.$$.fragment,bl),Kcr=i(bl),jd=n(bl,"P",{});var Qoe=s(jd);Zcr=r(Qoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),FQ=n(Qoe,"A",{href:!0});var yCt=s(FQ);efr=r(yCt,"from_pretrained()"),yCt.forEach(t),ofr=r(Qoe," class method or the "),TQ=n(Qoe,"A",{href:!0});var xCt=s(TQ);rfr=r(xCt,"from_config()"),xCt.forEach(t),tfr=r(Qoe,` class
method.`),Qoe.forEach(t),afr=i(bl),D8=n(bl,"P",{});var CXe=s(D8);nfr=r(CXe,"This class cannot be instantiated directly using "),q2e=n(CXe,"CODE",{});var $Ct=s(q2e);sfr=r($Ct,"__init__()"),$Ct.forEach(t),lfr=r(CXe," (throws an error)."),CXe.forEach(t),ifr=i(bl),wt=n(bl,"DIV",{class:!0});var c6=s(wt);T(G8.$$.fragment,c6),dfr=i(c6),j2e=n(c6,"P",{});var kCt=s(j2e);cfr=r(kCt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),kCt.forEach(t),ffr=i(c6),Dd=n(c6,"P",{});var Hoe=s(Dd);mfr=r(Hoe,`Note:
Loading a model from its configuration file does `),D2e=n(Hoe,"STRONG",{});var SCt=s(D2e);gfr=r(SCt,"not"),SCt.forEach(t),hfr=r(Hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MQ=n(Hoe,"A",{href:!0});var RCt=s(MQ);pfr=r(RCt,"from_pretrained()"),RCt.forEach(t),ufr=r(Hoe," to load the model weights."),Hoe.forEach(t),_fr=i(c6),T(c7.$$.fragment,c6),c6.forEach(t),bfr=i(bl),uo=n(bl,"DIV",{class:!0});var Ea=s(uo);T(O8.$$.fragment,Ea),vfr=i(Ea),G2e=n(Ea,"P",{});var PCt=s(G2e);Ffr=r(PCt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),PCt.forEach(t),Tfr=i(Ea),Ya=n(Ea,"P",{});var f6=s(Ya);Mfr=r(f6,"The model class to instantiate is selected based on the "),O2e=n(f6,"CODE",{});var BCt=s(O2e);Efr=r(BCt,"model_type"),BCt.forEach(t),Cfr=r(f6,` property of the config object (either
passed as an argument or loaded from `),V2e=n(f6,"CODE",{});var ICt=s(V2e);wfr=r(ICt,"pretrained_model_name_or_path"),ICt.forEach(t),Afr=r(f6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X2e=n(f6,"CODE",{});var NCt=s(X2e);Lfr=r(NCt,"pretrained_model_name_or_path"),NCt.forEach(t),yfr=r(f6,":"),f6.forEach(t),xfr=i(Ea),Gd=n(Ea,"UL",{});var Uoe=s(Gd);f7=n(Uoe,"LI",{});var gBe=s(f7);z2e=n(gBe,"STRONG",{});var qCt=s(z2e);$fr=r(qCt,"deit"),qCt.forEach(t),kfr=r(gBe," \u2014 "),EQ=n(gBe,"A",{href:!0});var jCt=s(EQ);Sfr=r(jCt,"DeiTForMaskedImageModeling"),jCt.forEach(t),Rfr=r(gBe," (DeiT model)"),gBe.forEach(t),Pfr=i(Uoe),m7=n(Uoe,"LI",{});var hBe=s(m7);W2e=n(hBe,"STRONG",{});var DCt=s(W2e);Bfr=r(DCt,"swin"),DCt.forEach(t),Ifr=r(hBe," \u2014 "),CQ=n(hBe,"A",{href:!0});var GCt=s(CQ);Nfr=r(GCt,"SwinForMaskedImageModeling"),GCt.forEach(t),qfr=r(hBe," (Swin Transformer model)"),hBe.forEach(t),jfr=i(Uoe),g7=n(Uoe,"LI",{});var pBe=s(g7);Q2e=n(pBe,"STRONG",{});var OCt=s(Q2e);Dfr=r(OCt,"vit"),OCt.forEach(t),Gfr=r(pBe," \u2014 "),wQ=n(pBe,"A",{href:!0});var VCt=s(wQ);Ofr=r(VCt,"ViTForMaskedImageModeling"),VCt.forEach(t),Vfr=r(pBe," (ViT model)"),pBe.forEach(t),Uoe.forEach(t),Xfr=i(Ea),h7=n(Ea,"P",{});var uBe=s(h7);zfr=r(uBe,"The model is set in evaluation mode by default using "),H2e=n(uBe,"CODE",{});var XCt=s(H2e);Wfr=r(XCt,"model.eval()"),XCt.forEach(t),Qfr=r(uBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U2e=n(uBe,"CODE",{});var zCt=s(U2e);Hfr=r(zCt,"model.train()"),zCt.forEach(t),uBe.forEach(t),Ufr=i(Ea),T(p7.$$.fragment,Ea),Ea.forEach(t),bl.forEach(t),bOe=i(f),Od=n(f,"H2",{class:!0});var wXe=s(Od);u7=n(wXe,"A",{id:!0,class:!0,href:!0});var WCt=s(u7);J2e=n(WCt,"SPAN",{});var QCt=s(J2e);T(V8.$$.fragment,QCt),QCt.forEach(t),WCt.forEach(t),Jfr=i(wXe),Y2e=n(wXe,"SPAN",{});var HCt=s(Y2e);Yfr=r(HCt,"AutoModelForObjectDetection"),HCt.forEach(t),wXe.forEach(t),vOe=i(f),Uo=n(f,"DIV",{class:!0});var vl=s(Uo);T(X8.$$.fragment,vl),Kfr=i(vl),Vd=n(vl,"P",{});var Joe=s(Vd);Zfr=r(Joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),AQ=n(Joe,"A",{href:!0});var UCt=s(AQ);emr=r(UCt,"from_pretrained()"),UCt.forEach(t),omr=r(Joe," class method or the "),LQ=n(Joe,"A",{href:!0});var JCt=s(LQ);rmr=r(JCt,"from_config()"),JCt.forEach(t),tmr=r(Joe,` class
method.`),Joe.forEach(t),amr=i(vl),z8=n(vl,"P",{});var AXe=s(z8);nmr=r(AXe,"This class cannot be instantiated directly using "),K2e=n(AXe,"CODE",{});var YCt=s(K2e);smr=r(YCt,"__init__()"),YCt.forEach(t),lmr=r(AXe," (throws an error)."),AXe.forEach(t),imr=i(vl),At=n(vl,"DIV",{class:!0});var m6=s(At);T(W8.$$.fragment,m6),dmr=i(m6),Z2e=n(m6,"P",{});var KCt=s(Z2e);cmr=r(KCt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),KCt.forEach(t),fmr=i(m6),Xd=n(m6,"P",{});var Yoe=s(Xd);mmr=r(Yoe,`Note:
Loading a model from its configuration file does `),ebe=n(Yoe,"STRONG",{});var ZCt=s(ebe);gmr=r(ZCt,"not"),ZCt.forEach(t),hmr=r(Yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),yQ=n(Yoe,"A",{href:!0});var e5t=s(yQ);pmr=r(e5t,"from_pretrained()"),e5t.forEach(t),umr=r(Yoe," to load the model weights."),Yoe.forEach(t),_mr=i(m6),T(_7.$$.fragment,m6),m6.forEach(t),bmr=i(vl),_o=n(vl,"DIV",{class:!0});var Ca=s(_o);T(Q8.$$.fragment,Ca),vmr=i(Ca),obe=n(Ca,"P",{});var o5t=s(obe);Fmr=r(o5t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),o5t.forEach(t),Tmr=i(Ca),Ka=n(Ca,"P",{});var g6=s(Ka);Mmr=r(g6,"The model class to instantiate is selected based on the "),rbe=n(g6,"CODE",{});var r5t=s(rbe);Emr=r(r5t,"model_type"),r5t.forEach(t),Cmr=r(g6,` property of the config object (either
passed as an argument or loaded from `),tbe=n(g6,"CODE",{});var t5t=s(tbe);wmr=r(t5t,"pretrained_model_name_or_path"),t5t.forEach(t),Amr=r(g6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),abe=n(g6,"CODE",{});var a5t=s(abe);Lmr=r(a5t,"pretrained_model_name_or_path"),a5t.forEach(t),ymr=r(g6,":"),g6.forEach(t),xmr=i(Ca),H8=n(Ca,"UL",{});var LXe=s(H8);b7=n(LXe,"LI",{});var _Be=s(b7);nbe=n(_Be,"STRONG",{});var n5t=s(nbe);$mr=r(n5t,"detr"),n5t.forEach(t),kmr=r(_Be," \u2014 "),xQ=n(_Be,"A",{href:!0});var s5t=s(xQ);Smr=r(s5t,"DetrForObjectDetection"),s5t.forEach(t),Rmr=r(_Be," (DETR model)"),_Be.forEach(t),Pmr=i(LXe),v7=n(LXe,"LI",{});var bBe=s(v7);sbe=n(bBe,"STRONG",{});var l5t=s(sbe);Bmr=r(l5t,"yolos"),l5t.forEach(t),Imr=r(bBe," \u2014 "),$Q=n(bBe,"A",{href:!0});var i5t=s($Q);Nmr=r(i5t,"YolosForObjectDetection"),i5t.forEach(t),qmr=r(bBe," (YOLOS model)"),bBe.forEach(t),LXe.forEach(t),jmr=i(Ca),F7=n(Ca,"P",{});var vBe=s(F7);Dmr=r(vBe,"The model is set in evaluation mode by default using "),lbe=n(vBe,"CODE",{});var d5t=s(lbe);Gmr=r(d5t,"model.eval()"),d5t.forEach(t),Omr=r(vBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ibe=n(vBe,"CODE",{});var c5t=s(ibe);Vmr=r(c5t,"model.train()"),c5t.forEach(t),vBe.forEach(t),Xmr=i(Ca),T(T7.$$.fragment,Ca),Ca.forEach(t),vl.forEach(t),FOe=i(f),zd=n(f,"H2",{class:!0});var yXe=s(zd);M7=n(yXe,"A",{id:!0,class:!0,href:!0});var f5t=s(M7);dbe=n(f5t,"SPAN",{});var m5t=s(dbe);T(U8.$$.fragment,m5t),m5t.forEach(t),f5t.forEach(t),zmr=i(yXe),cbe=n(yXe,"SPAN",{});var g5t=s(cbe);Wmr=r(g5t,"AutoModelForImageSegmentation"),g5t.forEach(t),yXe.forEach(t),TOe=i(f),Jo=n(f,"DIV",{class:!0});var Fl=s(Jo);T(J8.$$.fragment,Fl),Qmr=i(Fl),Wd=n(Fl,"P",{});var Koe=s(Wd);Hmr=r(Koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),kQ=n(Koe,"A",{href:!0});var h5t=s(kQ);Umr=r(h5t,"from_pretrained()"),h5t.forEach(t),Jmr=r(Koe," class method or the "),SQ=n(Koe,"A",{href:!0});var p5t=s(SQ);Ymr=r(p5t,"from_config()"),p5t.forEach(t),Kmr=r(Koe,` class
method.`),Koe.forEach(t),Zmr=i(Fl),Y8=n(Fl,"P",{});var xXe=s(Y8);egr=r(xXe,"This class cannot be instantiated directly using "),fbe=n(xXe,"CODE",{});var u5t=s(fbe);ogr=r(u5t,"__init__()"),u5t.forEach(t),rgr=r(xXe," (throws an error)."),xXe.forEach(t),tgr=i(Fl),Lt=n(Fl,"DIV",{class:!0});var h6=s(Lt);T(K8.$$.fragment,h6),agr=i(h6),mbe=n(h6,"P",{});var _5t=s(mbe);ngr=r(_5t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),_5t.forEach(t),sgr=i(h6),Qd=n(h6,"P",{});var Zoe=s(Qd);lgr=r(Zoe,`Note:
Loading a model from its configuration file does `),gbe=n(Zoe,"STRONG",{});var b5t=s(gbe);igr=r(b5t,"not"),b5t.forEach(t),dgr=r(Zoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),RQ=n(Zoe,"A",{href:!0});var v5t=s(RQ);cgr=r(v5t,"from_pretrained()"),v5t.forEach(t),fgr=r(Zoe," to load the model weights."),Zoe.forEach(t),mgr=i(h6),T(E7.$$.fragment,h6),h6.forEach(t),ggr=i(Fl),bo=n(Fl,"DIV",{class:!0});var wa=s(bo);T(Z8.$$.fragment,wa),hgr=i(wa),hbe=n(wa,"P",{});var F5t=s(hbe);pgr=r(F5t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),F5t.forEach(t),ugr=i(wa),Za=n(wa,"P",{});var p6=s(Za);_gr=r(p6,"The model class to instantiate is selected based on the "),pbe=n(p6,"CODE",{});var T5t=s(pbe);bgr=r(T5t,"model_type"),T5t.forEach(t),vgr=r(p6,` property of the config object (either
passed as an argument or loaded from `),ube=n(p6,"CODE",{});var M5t=s(ube);Fgr=r(M5t,"pretrained_model_name_or_path"),M5t.forEach(t),Tgr=r(p6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_be=n(p6,"CODE",{});var E5t=s(_be);Mgr=r(E5t,"pretrained_model_name_or_path"),E5t.forEach(t),Egr=r(p6,":"),p6.forEach(t),Cgr=i(wa),bbe=n(wa,"UL",{});var C5t=s(bbe);C7=n(C5t,"LI",{});var FBe=s(C7);vbe=n(FBe,"STRONG",{});var w5t=s(vbe);wgr=r(w5t,"detr"),w5t.forEach(t),Agr=r(FBe," \u2014 "),PQ=n(FBe,"A",{href:!0});var A5t=s(PQ);Lgr=r(A5t,"DetrForSegmentation"),A5t.forEach(t),ygr=r(FBe," (DETR model)"),FBe.forEach(t),C5t.forEach(t),xgr=i(wa),w7=n(wa,"P",{});var TBe=s(w7);$gr=r(TBe,"The model is set in evaluation mode by default using "),Fbe=n(TBe,"CODE",{});var L5t=s(Fbe);kgr=r(L5t,"model.eval()"),L5t.forEach(t),Sgr=r(TBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tbe=n(TBe,"CODE",{});var y5t=s(Tbe);Rgr=r(y5t,"model.train()"),y5t.forEach(t),TBe.forEach(t),Pgr=i(wa),T(A7.$$.fragment,wa),wa.forEach(t),Fl.forEach(t),MOe=i(f),Hd=n(f,"H2",{class:!0});var $Xe=s(Hd);L7=n($Xe,"A",{id:!0,class:!0,href:!0});var x5t=s(L7);Mbe=n(x5t,"SPAN",{});var $5t=s(Mbe);T(e9.$$.fragment,$5t),$5t.forEach(t),x5t.forEach(t),Bgr=i($Xe),Ebe=n($Xe,"SPAN",{});var k5t=s(Ebe);Igr=r(k5t,"AutoModelForSemanticSegmentation"),k5t.forEach(t),$Xe.forEach(t),EOe=i(f),Yo=n(f,"DIV",{class:!0});var Tl=s(Yo);T(o9.$$.fragment,Tl),Ngr=i(Tl),Ud=n(Tl,"P",{});var ere=s(Ud);qgr=r(ere,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),BQ=n(ere,"A",{href:!0});var S5t=s(BQ);jgr=r(S5t,"from_pretrained()"),S5t.forEach(t),Dgr=r(ere," class method or the "),IQ=n(ere,"A",{href:!0});var R5t=s(IQ);Ggr=r(R5t,"from_config()"),R5t.forEach(t),Ogr=r(ere,` class
method.`),ere.forEach(t),Vgr=i(Tl),r9=n(Tl,"P",{});var kXe=s(r9);Xgr=r(kXe,"This class cannot be instantiated directly using "),Cbe=n(kXe,"CODE",{});var P5t=s(Cbe);zgr=r(P5t,"__init__()"),P5t.forEach(t),Wgr=r(kXe," (throws an error)."),kXe.forEach(t),Qgr=i(Tl),yt=n(Tl,"DIV",{class:!0});var u6=s(yt);T(t9.$$.fragment,u6),Hgr=i(u6),wbe=n(u6,"P",{});var B5t=s(wbe);Ugr=r(B5t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),B5t.forEach(t),Jgr=i(u6),Jd=n(u6,"P",{});var ore=s(Jd);Ygr=r(ore,`Note:
Loading a model from its configuration file does `),Abe=n(ore,"STRONG",{});var I5t=s(Abe);Kgr=r(I5t,"not"),I5t.forEach(t),Zgr=r(ore,` load the model weights. It only affects the
model\u2019s configuration. Use `),NQ=n(ore,"A",{href:!0});var N5t=s(NQ);ehr=r(N5t,"from_pretrained()"),N5t.forEach(t),ohr=r(ore," to load the model weights."),ore.forEach(t),rhr=i(u6),T(y7.$$.fragment,u6),u6.forEach(t),thr=i(Tl),vo=n(Tl,"DIV",{class:!0});var Aa=s(vo);T(a9.$$.fragment,Aa),ahr=i(Aa),Lbe=n(Aa,"P",{});var q5t=s(Lbe);nhr=r(q5t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),q5t.forEach(t),shr=i(Aa),en=n(Aa,"P",{});var _6=s(en);lhr=r(_6,"The model class to instantiate is selected based on the "),ybe=n(_6,"CODE",{});var j5t=s(ybe);ihr=r(j5t,"model_type"),j5t.forEach(t),dhr=r(_6,` property of the config object (either
passed as an argument or loaded from `),xbe=n(_6,"CODE",{});var D5t=s(xbe);chr=r(D5t,"pretrained_model_name_or_path"),D5t.forEach(t),fhr=r(_6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$be=n(_6,"CODE",{});var G5t=s($be);mhr=r(G5t,"pretrained_model_name_or_path"),G5t.forEach(t),ghr=r(_6,":"),_6.forEach(t),hhr=i(Aa),on=n(Aa,"UL",{});var b6=s(on);x7=n(b6,"LI",{});var MBe=s(x7);kbe=n(MBe,"STRONG",{});var O5t=s(kbe);phr=r(O5t,"beit"),O5t.forEach(t),uhr=r(MBe," \u2014 "),qQ=n(MBe,"A",{href:!0});var V5t=s(qQ);_hr=r(V5t,"BeitForSemanticSegmentation"),V5t.forEach(t),bhr=r(MBe," (BEiT model)"),MBe.forEach(t),vhr=i(b6),$7=n(b6,"LI",{});var EBe=s($7);Sbe=n(EBe,"STRONG",{});var X5t=s(Sbe);Fhr=r(X5t,"data2vec-vision"),X5t.forEach(t),Thr=r(EBe," \u2014 "),jQ=n(EBe,"A",{href:!0});var z5t=s(jQ);Mhr=r(z5t,"Data2VecVisionForSemanticSegmentation"),z5t.forEach(t),Ehr=r(EBe," (Data2VecVision model)"),EBe.forEach(t),Chr=i(b6),k7=n(b6,"LI",{});var CBe=s(k7);Rbe=n(CBe,"STRONG",{});var W5t=s(Rbe);whr=r(W5t,"dpt"),W5t.forEach(t),Ahr=r(CBe," \u2014 "),DQ=n(CBe,"A",{href:!0});var Q5t=s(DQ);Lhr=r(Q5t,"DPTForSemanticSegmentation"),Q5t.forEach(t),yhr=r(CBe," (DPT model)"),CBe.forEach(t),xhr=i(b6),S7=n(b6,"LI",{});var wBe=s(S7);Pbe=n(wBe,"STRONG",{});var H5t=s(Pbe);$hr=r(H5t,"segformer"),H5t.forEach(t),khr=r(wBe," \u2014 "),GQ=n(wBe,"A",{href:!0});var U5t=s(GQ);Shr=r(U5t,"SegformerForSemanticSegmentation"),U5t.forEach(t),Rhr=r(wBe," (SegFormer model)"),wBe.forEach(t),b6.forEach(t),Phr=i(Aa),R7=n(Aa,"P",{});var ABe=s(R7);Bhr=r(ABe,"The model is set in evaluation mode by default using "),Bbe=n(ABe,"CODE",{});var J5t=s(Bbe);Ihr=r(J5t,"model.eval()"),J5t.forEach(t),Nhr=r(ABe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=n(ABe,"CODE",{});var Y5t=s(Ibe);qhr=r(Y5t,"model.train()"),Y5t.forEach(t),ABe.forEach(t),jhr=i(Aa),T(P7.$$.fragment,Aa),Aa.forEach(t),Tl.forEach(t),COe=i(f),Yd=n(f,"H2",{class:!0});var SXe=s(Yd);B7=n(SXe,"A",{id:!0,class:!0,href:!0});var K5t=s(B7);Nbe=n(K5t,"SPAN",{});var Z5t=s(Nbe);T(n9.$$.fragment,Z5t),Z5t.forEach(t),K5t.forEach(t),Dhr=i(SXe),qbe=n(SXe,"SPAN",{});var e0t=s(qbe);Ghr=r(e0t,"AutoModelForInstanceSegmentation"),e0t.forEach(t),SXe.forEach(t),wOe=i(f),Ko=n(f,"DIV",{class:!0});var Ml=s(Ko);T(s9.$$.fragment,Ml),Ohr=i(Ml),Kd=n(Ml,"P",{});var rre=s(Kd);Vhr=r(rre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),OQ=n(rre,"A",{href:!0});var o0t=s(OQ);Xhr=r(o0t,"from_pretrained()"),o0t.forEach(t),zhr=r(rre," class method or the "),VQ=n(rre,"A",{href:!0});var r0t=s(VQ);Whr=r(r0t,"from_config()"),r0t.forEach(t),Qhr=r(rre,` class
method.`),rre.forEach(t),Hhr=i(Ml),l9=n(Ml,"P",{});var RXe=s(l9);Uhr=r(RXe,"This class cannot be instantiated directly using "),jbe=n(RXe,"CODE",{});var t0t=s(jbe);Jhr=r(t0t,"__init__()"),t0t.forEach(t),Yhr=r(RXe," (throws an error)."),RXe.forEach(t),Khr=i(Ml),xt=n(Ml,"DIV",{class:!0});var v6=s(xt);T(i9.$$.fragment,v6),Zhr=i(v6),Dbe=n(v6,"P",{});var a0t=s(Dbe);epr=r(a0t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),a0t.forEach(t),opr=i(v6),Zd=n(v6,"P",{});var tre=s(Zd);rpr=r(tre,`Note:
Loading a model from its configuration file does `),Gbe=n(tre,"STRONG",{});var n0t=s(Gbe);tpr=r(n0t,"not"),n0t.forEach(t),apr=r(tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),XQ=n(tre,"A",{href:!0});var s0t=s(XQ);npr=r(s0t,"from_pretrained()"),s0t.forEach(t),spr=r(tre," to load the model weights."),tre.forEach(t),lpr=i(v6),T(I7.$$.fragment,v6),v6.forEach(t),ipr=i(Ml),Fo=n(Ml,"DIV",{class:!0});var La=s(Fo);T(d9.$$.fragment,La),dpr=i(La),Obe=n(La,"P",{});var l0t=s(Obe);cpr=r(l0t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),l0t.forEach(t),fpr=i(La),rn=n(La,"P",{});var F6=s(rn);mpr=r(F6,"The model class to instantiate is selected based on the "),Vbe=n(F6,"CODE",{});var i0t=s(Vbe);gpr=r(i0t,"model_type"),i0t.forEach(t),hpr=r(F6,` property of the config object (either
passed as an argument or loaded from `),Xbe=n(F6,"CODE",{});var d0t=s(Xbe);ppr=r(d0t,"pretrained_model_name_or_path"),d0t.forEach(t),upr=r(F6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=n(F6,"CODE",{});var c0t=s(zbe);_pr=r(c0t,"pretrained_model_name_or_path"),c0t.forEach(t),bpr=r(F6,":"),F6.forEach(t),vpr=i(La),Wbe=n(La,"UL",{});var f0t=s(Wbe);N7=n(f0t,"LI",{});var LBe=s(N7);Qbe=n(LBe,"STRONG",{});var m0t=s(Qbe);Fpr=r(m0t,"maskformer"),m0t.forEach(t),Tpr=r(LBe," \u2014 "),zQ=n(LBe,"A",{href:!0});var g0t=s(zQ);Mpr=r(g0t,"MaskFormerForInstanceSegmentation"),g0t.forEach(t),Epr=r(LBe," (MaskFormer model)"),LBe.forEach(t),f0t.forEach(t),Cpr=i(La),q7=n(La,"P",{});var yBe=s(q7);wpr=r(yBe,"The model is set in evaluation mode by default using "),Hbe=n(yBe,"CODE",{});var h0t=s(Hbe);Apr=r(h0t,"model.eval()"),h0t.forEach(t),Lpr=r(yBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ube=n(yBe,"CODE",{});var p0t=s(Ube);ypr=r(p0t,"model.train()"),p0t.forEach(t),yBe.forEach(t),xpr=i(La),T(j7.$$.fragment,La),La.forEach(t),Ml.forEach(t),AOe=i(f),ec=n(f,"H2",{class:!0});var PXe=s(ec);D7=n(PXe,"A",{id:!0,class:!0,href:!0});var u0t=s(D7);Jbe=n(u0t,"SPAN",{});var _0t=s(Jbe);T(c9.$$.fragment,_0t),_0t.forEach(t),u0t.forEach(t),$pr=i(PXe),Ybe=n(PXe,"SPAN",{});var b0t=s(Ybe);kpr=r(b0t,"TFAutoModel"),b0t.forEach(t),PXe.forEach(t),LOe=i(f),Zo=n(f,"DIV",{class:!0});var El=s(Zo);T(f9.$$.fragment,El),Spr=i(El),oc=n(El,"P",{});var are=s(oc);Rpr=r(are,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),WQ=n(are,"A",{href:!0});var v0t=s(WQ);Ppr=r(v0t,"from_pretrained()"),v0t.forEach(t),Bpr=r(are," class method or the "),QQ=n(are,"A",{href:!0});var F0t=s(QQ);Ipr=r(F0t,"from_config()"),F0t.forEach(t),Npr=r(are,` class
method.`),are.forEach(t),qpr=i(El),m9=n(El,"P",{});var BXe=s(m9);jpr=r(BXe,"This class cannot be instantiated directly using "),Kbe=n(BXe,"CODE",{});var T0t=s(Kbe);Dpr=r(T0t,"__init__()"),T0t.forEach(t),Gpr=r(BXe," (throws an error)."),BXe.forEach(t),Opr=i(El),$t=n(El,"DIV",{class:!0});var T6=s($t);T(g9.$$.fragment,T6),Vpr=i(T6),Zbe=n(T6,"P",{});var M0t=s(Zbe);Xpr=r(M0t,"Instantiates one of the base model classes of the library from a configuration."),M0t.forEach(t),zpr=i(T6),rc=n(T6,"P",{});var nre=s(rc);Wpr=r(nre,`Note:
Loading a model from its configuration file does `),eve=n(nre,"STRONG",{});var E0t=s(eve);Qpr=r(E0t,"not"),E0t.forEach(t),Hpr=r(nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),HQ=n(nre,"A",{href:!0});var C0t=s(HQ);Upr=r(C0t,"from_pretrained()"),C0t.forEach(t),Jpr=r(nre," to load the model weights."),nre.forEach(t),Ypr=i(T6),T(G7.$$.fragment,T6),T6.forEach(t),Kpr=i(El),Lr=n(El,"DIV",{class:!0});var Cl=s(Lr);T(h9.$$.fragment,Cl),Zpr=i(Cl),ove=n(Cl,"P",{});var w0t=s(ove);eur=r(w0t,"Instantiate one of the base model classes of the library from a pretrained model."),w0t.forEach(t),our=i(Cl),tn=n(Cl,"P",{});var M6=s(tn);rur=r(M6,"The model class to instantiate is selected based on the "),rve=n(M6,"CODE",{});var A0t=s(rve);tur=r(A0t,"model_type"),A0t.forEach(t),aur=r(M6,` property of the config object (either
passed as an argument or loaded from `),tve=n(M6,"CODE",{});var L0t=s(tve);nur=r(L0t,"pretrained_model_name_or_path"),L0t.forEach(t),sur=r(M6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ave=n(M6,"CODE",{});var y0t=s(ave);lur=r(y0t,"pretrained_model_name_or_path"),y0t.forEach(t),iur=r(M6,":"),M6.forEach(t),dur=i(Cl),q=n(Cl,"UL",{});var D=s(q);O7=n(D,"LI",{});var xBe=s(O7);nve=n(xBe,"STRONG",{});var x0t=s(nve);cur=r(x0t,"albert"),x0t.forEach(t),fur=r(xBe," \u2014 "),UQ=n(xBe,"A",{href:!0});var $0t=s(UQ);mur=r($0t,"TFAlbertModel"),$0t.forEach(t),gur=r(xBe," (ALBERT model)"),xBe.forEach(t),hur=i(D),V7=n(D,"LI",{});var $Be=s(V7);sve=n($Be,"STRONG",{});var k0t=s(sve);pur=r(k0t,"bart"),k0t.forEach(t),uur=r($Be," \u2014 "),JQ=n($Be,"A",{href:!0});var S0t=s(JQ);_ur=r(S0t,"TFBartModel"),S0t.forEach(t),bur=r($Be," (BART model)"),$Be.forEach(t),vur=i(D),X7=n(D,"LI",{});var kBe=s(X7);lve=n(kBe,"STRONG",{});var R0t=s(lve);Fur=r(R0t,"bert"),R0t.forEach(t),Tur=r(kBe," \u2014 "),YQ=n(kBe,"A",{href:!0});var P0t=s(YQ);Mur=r(P0t,"TFBertModel"),P0t.forEach(t),Eur=r(kBe," (BERT model)"),kBe.forEach(t),Cur=i(D),z7=n(D,"LI",{});var SBe=s(z7);ive=n(SBe,"STRONG",{});var B0t=s(ive);wur=r(B0t,"blenderbot"),B0t.forEach(t),Aur=r(SBe," \u2014 "),KQ=n(SBe,"A",{href:!0});var I0t=s(KQ);Lur=r(I0t,"TFBlenderbotModel"),I0t.forEach(t),yur=r(SBe," (Blenderbot model)"),SBe.forEach(t),xur=i(D),W7=n(D,"LI",{});var RBe=s(W7);dve=n(RBe,"STRONG",{});var N0t=s(dve);$ur=r(N0t,"blenderbot-small"),N0t.forEach(t),kur=r(RBe," \u2014 "),ZQ=n(RBe,"A",{href:!0});var q0t=s(ZQ);Sur=r(q0t,"TFBlenderbotSmallModel"),q0t.forEach(t),Rur=r(RBe," (BlenderbotSmall model)"),RBe.forEach(t),Pur=i(D),Q7=n(D,"LI",{});var PBe=s(Q7);cve=n(PBe,"STRONG",{});var j0t=s(cve);Bur=r(j0t,"camembert"),j0t.forEach(t),Iur=r(PBe," \u2014 "),eH=n(PBe,"A",{href:!0});var D0t=s(eH);Nur=r(D0t,"TFCamembertModel"),D0t.forEach(t),qur=r(PBe," (CamemBERT model)"),PBe.forEach(t),jur=i(D),H7=n(D,"LI",{});var BBe=s(H7);fve=n(BBe,"STRONG",{});var G0t=s(fve);Dur=r(G0t,"clip"),G0t.forEach(t),Gur=r(BBe," \u2014 "),oH=n(BBe,"A",{href:!0});var O0t=s(oH);Our=r(O0t,"TFCLIPModel"),O0t.forEach(t),Vur=r(BBe," (CLIP model)"),BBe.forEach(t),Xur=i(D),U7=n(D,"LI",{});var IBe=s(U7);mve=n(IBe,"STRONG",{});var V0t=s(mve);zur=r(V0t,"convbert"),V0t.forEach(t),Wur=r(IBe," \u2014 "),rH=n(IBe,"A",{href:!0});var X0t=s(rH);Qur=r(X0t,"TFConvBertModel"),X0t.forEach(t),Hur=r(IBe," (ConvBERT model)"),IBe.forEach(t),Uur=i(D),J7=n(D,"LI",{});var NBe=s(J7);gve=n(NBe,"STRONG",{});var z0t=s(gve);Jur=r(z0t,"convnext"),z0t.forEach(t),Yur=r(NBe," \u2014 "),tH=n(NBe,"A",{href:!0});var W0t=s(tH);Kur=r(W0t,"TFConvNextModel"),W0t.forEach(t),Zur=r(NBe," (ConvNeXT model)"),NBe.forEach(t),e_r=i(D),Y7=n(D,"LI",{});var qBe=s(Y7);hve=n(qBe,"STRONG",{});var Q0t=s(hve);o_r=r(Q0t,"ctrl"),Q0t.forEach(t),r_r=r(qBe," \u2014 "),aH=n(qBe,"A",{href:!0});var H0t=s(aH);t_r=r(H0t,"TFCTRLModel"),H0t.forEach(t),a_r=r(qBe," (CTRL model)"),qBe.forEach(t),n_r=i(D),K7=n(D,"LI",{});var jBe=s(K7);pve=n(jBe,"STRONG",{});var U0t=s(pve);s_r=r(U0t,"data2vec-vision"),U0t.forEach(t),l_r=r(jBe," \u2014 "),nH=n(jBe,"A",{href:!0});var J0t=s(nH);i_r=r(J0t,"TFData2VecVisionModel"),J0t.forEach(t),d_r=r(jBe," (Data2VecVision model)"),jBe.forEach(t),c_r=i(D),Z7=n(D,"LI",{});var DBe=s(Z7);uve=n(DBe,"STRONG",{});var Y0t=s(uve);f_r=r(Y0t,"deberta"),Y0t.forEach(t),m_r=r(DBe," \u2014 "),sH=n(DBe,"A",{href:!0});var K0t=s(sH);g_r=r(K0t,"TFDebertaModel"),K0t.forEach(t),h_r=r(DBe," (DeBERTa model)"),DBe.forEach(t),p_r=i(D),eM=n(D,"LI",{});var GBe=s(eM);_ve=n(GBe,"STRONG",{});var Z0t=s(_ve);u_r=r(Z0t,"deberta-v2"),Z0t.forEach(t),__r=r(GBe," \u2014 "),lH=n(GBe,"A",{href:!0});var ewt=s(lH);b_r=r(ewt,"TFDebertaV2Model"),ewt.forEach(t),v_r=r(GBe," (DeBERTa-v2 model)"),GBe.forEach(t),F_r=i(D),oM=n(D,"LI",{});var OBe=s(oM);bve=n(OBe,"STRONG",{});var owt=s(bve);T_r=r(owt,"distilbert"),owt.forEach(t),M_r=r(OBe," \u2014 "),iH=n(OBe,"A",{href:!0});var rwt=s(iH);E_r=r(rwt,"TFDistilBertModel"),rwt.forEach(t),C_r=r(OBe," (DistilBERT model)"),OBe.forEach(t),w_r=i(D),rM=n(D,"LI",{});var VBe=s(rM);vve=n(VBe,"STRONG",{});var twt=s(vve);A_r=r(twt,"dpr"),twt.forEach(t),L_r=r(VBe," \u2014 "),dH=n(VBe,"A",{href:!0});var awt=s(dH);y_r=r(awt,"TFDPRQuestionEncoder"),awt.forEach(t),x_r=r(VBe," (DPR model)"),VBe.forEach(t),$_r=i(D),tM=n(D,"LI",{});var XBe=s(tM);Fve=n(XBe,"STRONG",{});var nwt=s(Fve);k_r=r(nwt,"electra"),nwt.forEach(t),S_r=r(XBe," \u2014 "),cH=n(XBe,"A",{href:!0});var swt=s(cH);R_r=r(swt,"TFElectraModel"),swt.forEach(t),P_r=r(XBe," (ELECTRA model)"),XBe.forEach(t),B_r=i(D),aM=n(D,"LI",{});var zBe=s(aM);Tve=n(zBe,"STRONG",{});var lwt=s(Tve);I_r=r(lwt,"flaubert"),lwt.forEach(t),N_r=r(zBe," \u2014 "),fH=n(zBe,"A",{href:!0});var iwt=s(fH);q_r=r(iwt,"TFFlaubertModel"),iwt.forEach(t),j_r=r(zBe," (FlauBERT model)"),zBe.forEach(t),D_r=i(D),zs=n(D,"LI",{});var Jk=s(zs);Mve=n(Jk,"STRONG",{});var dwt=s(Mve);G_r=r(dwt,"funnel"),dwt.forEach(t),O_r=r(Jk," \u2014 "),mH=n(Jk,"A",{href:!0});var cwt=s(mH);V_r=r(cwt,"TFFunnelModel"),cwt.forEach(t),X_r=r(Jk," or "),gH=n(Jk,"A",{href:!0});var fwt=s(gH);z_r=r(fwt,"TFFunnelBaseModel"),fwt.forEach(t),W_r=r(Jk," (Funnel Transformer model)"),Jk.forEach(t),Q_r=i(D),nM=n(D,"LI",{});var WBe=s(nM);Eve=n(WBe,"STRONG",{});var mwt=s(Eve);H_r=r(mwt,"gpt2"),mwt.forEach(t),U_r=r(WBe," \u2014 "),hH=n(WBe,"A",{href:!0});var gwt=s(hH);J_r=r(gwt,"TFGPT2Model"),gwt.forEach(t),Y_r=r(WBe," (OpenAI GPT-2 model)"),WBe.forEach(t),K_r=i(D),sM=n(D,"LI",{});var QBe=s(sM);Cve=n(QBe,"STRONG",{});var hwt=s(Cve);Z_r=r(hwt,"gptj"),hwt.forEach(t),e1r=r(QBe," \u2014 "),pH=n(QBe,"A",{href:!0});var pwt=s(pH);o1r=r(pwt,"TFGPTJModel"),pwt.forEach(t),r1r=r(QBe," (GPT-J model)"),QBe.forEach(t),t1r=i(D),lM=n(D,"LI",{});var HBe=s(lM);wve=n(HBe,"STRONG",{});var uwt=s(wve);a1r=r(uwt,"hubert"),uwt.forEach(t),n1r=r(HBe," \u2014 "),uH=n(HBe,"A",{href:!0});var _wt=s(uH);s1r=r(_wt,"TFHubertModel"),_wt.forEach(t),l1r=r(HBe," (Hubert model)"),HBe.forEach(t),i1r=i(D),iM=n(D,"LI",{});var UBe=s(iM);Ave=n(UBe,"STRONG",{});var bwt=s(Ave);d1r=r(bwt,"layoutlm"),bwt.forEach(t),c1r=r(UBe," \u2014 "),_H=n(UBe,"A",{href:!0});var vwt=s(_H);f1r=r(vwt,"TFLayoutLMModel"),vwt.forEach(t),m1r=r(UBe," (LayoutLM model)"),UBe.forEach(t),g1r=i(D),dM=n(D,"LI",{});var JBe=s(dM);Lve=n(JBe,"STRONG",{});var Fwt=s(Lve);h1r=r(Fwt,"led"),Fwt.forEach(t),p1r=r(JBe," \u2014 "),bH=n(JBe,"A",{href:!0});var Twt=s(bH);u1r=r(Twt,"TFLEDModel"),Twt.forEach(t),_1r=r(JBe," (LED model)"),JBe.forEach(t),b1r=i(D),cM=n(D,"LI",{});var YBe=s(cM);yve=n(YBe,"STRONG",{});var Mwt=s(yve);v1r=r(Mwt,"longformer"),Mwt.forEach(t),F1r=r(YBe," \u2014 "),vH=n(YBe,"A",{href:!0});var Ewt=s(vH);T1r=r(Ewt,"TFLongformerModel"),Ewt.forEach(t),M1r=r(YBe," (Longformer model)"),YBe.forEach(t),E1r=i(D),fM=n(D,"LI",{});var KBe=s(fM);xve=n(KBe,"STRONG",{});var Cwt=s(xve);C1r=r(Cwt,"lxmert"),Cwt.forEach(t),w1r=r(KBe," \u2014 "),FH=n(KBe,"A",{href:!0});var wwt=s(FH);A1r=r(wwt,"TFLxmertModel"),wwt.forEach(t),L1r=r(KBe," (LXMERT model)"),KBe.forEach(t),y1r=i(D),mM=n(D,"LI",{});var ZBe=s(mM);$ve=n(ZBe,"STRONG",{});var Awt=s($ve);x1r=r(Awt,"marian"),Awt.forEach(t),$1r=r(ZBe," \u2014 "),TH=n(ZBe,"A",{href:!0});var Lwt=s(TH);k1r=r(Lwt,"TFMarianModel"),Lwt.forEach(t),S1r=r(ZBe," (Marian model)"),ZBe.forEach(t),R1r=i(D),gM=n(D,"LI",{});var eIe=s(gM);kve=n(eIe,"STRONG",{});var ywt=s(kve);P1r=r(ywt,"mbart"),ywt.forEach(t),B1r=r(eIe," \u2014 "),MH=n(eIe,"A",{href:!0});var xwt=s(MH);I1r=r(xwt,"TFMBartModel"),xwt.forEach(t),N1r=r(eIe," (mBART model)"),eIe.forEach(t),q1r=i(D),hM=n(D,"LI",{});var oIe=s(hM);Sve=n(oIe,"STRONG",{});var $wt=s(Sve);j1r=r($wt,"mobilebert"),$wt.forEach(t),D1r=r(oIe," \u2014 "),EH=n(oIe,"A",{href:!0});var kwt=s(EH);G1r=r(kwt,"TFMobileBertModel"),kwt.forEach(t),O1r=r(oIe," (MobileBERT model)"),oIe.forEach(t),V1r=i(D),pM=n(D,"LI",{});var rIe=s(pM);Rve=n(rIe,"STRONG",{});var Swt=s(Rve);X1r=r(Swt,"mpnet"),Swt.forEach(t),z1r=r(rIe," \u2014 "),CH=n(rIe,"A",{href:!0});var Rwt=s(CH);W1r=r(Rwt,"TFMPNetModel"),Rwt.forEach(t),Q1r=r(rIe," (MPNet model)"),rIe.forEach(t),H1r=i(D),uM=n(D,"LI",{});var tIe=s(uM);Pve=n(tIe,"STRONG",{});var Pwt=s(Pve);U1r=r(Pwt,"mt5"),Pwt.forEach(t),J1r=r(tIe," \u2014 "),wH=n(tIe,"A",{href:!0});var Bwt=s(wH);Y1r=r(Bwt,"TFMT5Model"),Bwt.forEach(t),K1r=r(tIe," (MT5 model)"),tIe.forEach(t),Z1r=i(D),_M=n(D,"LI",{});var aIe=s(_M);Bve=n(aIe,"STRONG",{});var Iwt=s(Bve);e3r=r(Iwt,"openai-gpt"),Iwt.forEach(t),o3r=r(aIe," \u2014 "),AH=n(aIe,"A",{href:!0});var Nwt=s(AH);r3r=r(Nwt,"TFOpenAIGPTModel"),Nwt.forEach(t),t3r=r(aIe," (OpenAI GPT model)"),aIe.forEach(t),a3r=i(D),bM=n(D,"LI",{});var nIe=s(bM);Ive=n(nIe,"STRONG",{});var qwt=s(Ive);n3r=r(qwt,"opt"),qwt.forEach(t),s3r=r(nIe," \u2014 "),LH=n(nIe,"A",{href:!0});var jwt=s(LH);l3r=r(jwt,"TFOPTModel"),jwt.forEach(t),i3r=r(nIe," (OPT model)"),nIe.forEach(t),d3r=i(D),vM=n(D,"LI",{});var sIe=s(vM);Nve=n(sIe,"STRONG",{});var Dwt=s(Nve);c3r=r(Dwt,"pegasus"),Dwt.forEach(t),f3r=r(sIe," \u2014 "),yH=n(sIe,"A",{href:!0});var Gwt=s(yH);m3r=r(Gwt,"TFPegasusModel"),Gwt.forEach(t),g3r=r(sIe," (Pegasus model)"),sIe.forEach(t),h3r=i(D),FM=n(D,"LI",{});var lIe=s(FM);qve=n(lIe,"STRONG",{});var Owt=s(qve);p3r=r(Owt,"rembert"),Owt.forEach(t),u3r=r(lIe," \u2014 "),xH=n(lIe,"A",{href:!0});var Vwt=s(xH);_3r=r(Vwt,"TFRemBertModel"),Vwt.forEach(t),b3r=r(lIe," (RemBERT model)"),lIe.forEach(t),v3r=i(D),TM=n(D,"LI",{});var iIe=s(TM);jve=n(iIe,"STRONG",{});var Xwt=s(jve);F3r=r(Xwt,"roberta"),Xwt.forEach(t),T3r=r(iIe," \u2014 "),$H=n(iIe,"A",{href:!0});var zwt=s($H);M3r=r(zwt,"TFRobertaModel"),zwt.forEach(t),E3r=r(iIe," (RoBERTa model)"),iIe.forEach(t),C3r=i(D),MM=n(D,"LI",{});var dIe=s(MM);Dve=n(dIe,"STRONG",{});var Wwt=s(Dve);w3r=r(Wwt,"roformer"),Wwt.forEach(t),A3r=r(dIe," \u2014 "),kH=n(dIe,"A",{href:!0});var Qwt=s(kH);L3r=r(Qwt,"TFRoFormerModel"),Qwt.forEach(t),y3r=r(dIe," (RoFormer model)"),dIe.forEach(t),x3r=i(D),EM=n(D,"LI",{});var cIe=s(EM);Gve=n(cIe,"STRONG",{});var Hwt=s(Gve);$3r=r(Hwt,"speech_to_text"),Hwt.forEach(t),k3r=r(cIe," \u2014 "),SH=n(cIe,"A",{href:!0});var Uwt=s(SH);S3r=r(Uwt,"TFSpeech2TextModel"),Uwt.forEach(t),R3r=r(cIe," (Speech2Text model)"),cIe.forEach(t),P3r=i(D),CM=n(D,"LI",{});var fIe=s(CM);Ove=n(fIe,"STRONG",{});var Jwt=s(Ove);B3r=r(Jwt,"swin"),Jwt.forEach(t),I3r=r(fIe," \u2014 "),RH=n(fIe,"A",{href:!0});var Ywt=s(RH);N3r=r(Ywt,"TFSwinModel"),Ywt.forEach(t),q3r=r(fIe," (Swin Transformer model)"),fIe.forEach(t),j3r=i(D),wM=n(D,"LI",{});var mIe=s(wM);Vve=n(mIe,"STRONG",{});var Kwt=s(Vve);D3r=r(Kwt,"t5"),Kwt.forEach(t),G3r=r(mIe," \u2014 "),PH=n(mIe,"A",{href:!0});var Zwt=s(PH);O3r=r(Zwt,"TFT5Model"),Zwt.forEach(t),V3r=r(mIe," (T5 model)"),mIe.forEach(t),X3r=i(D),AM=n(D,"LI",{});var gIe=s(AM);Xve=n(gIe,"STRONG",{});var eAt=s(Xve);z3r=r(eAt,"tapas"),eAt.forEach(t),W3r=r(gIe," \u2014 "),BH=n(gIe,"A",{href:!0});var oAt=s(BH);Q3r=r(oAt,"TFTapasModel"),oAt.forEach(t),H3r=r(gIe," (TAPAS model)"),gIe.forEach(t),U3r=i(D),LM=n(D,"LI",{});var hIe=s(LM);zve=n(hIe,"STRONG",{});var rAt=s(zve);J3r=r(rAt,"transfo-xl"),rAt.forEach(t),Y3r=r(hIe," \u2014 "),IH=n(hIe,"A",{href:!0});var tAt=s(IH);K3r=r(tAt,"TFTransfoXLModel"),tAt.forEach(t),Z3r=r(hIe," (Transformer-XL model)"),hIe.forEach(t),e2r=i(D),yM=n(D,"LI",{});var pIe=s(yM);Wve=n(pIe,"STRONG",{});var aAt=s(Wve);o2r=r(aAt,"vit"),aAt.forEach(t),r2r=r(pIe," \u2014 "),NH=n(pIe,"A",{href:!0});var nAt=s(NH);t2r=r(nAt,"TFViTModel"),nAt.forEach(t),a2r=r(pIe," (ViT model)"),pIe.forEach(t),n2r=i(D),xM=n(D,"LI",{});var uIe=s(xM);Qve=n(uIe,"STRONG",{});var sAt=s(Qve);s2r=r(sAt,"vit_mae"),sAt.forEach(t),l2r=r(uIe," \u2014 "),qH=n(uIe,"A",{href:!0});var lAt=s(qH);i2r=r(lAt,"TFViTMAEModel"),lAt.forEach(t),d2r=r(uIe," (ViTMAE model)"),uIe.forEach(t),c2r=i(D),$M=n(D,"LI",{});var _Ie=s($M);Hve=n(_Ie,"STRONG",{});var iAt=s(Hve);f2r=r(iAt,"wav2vec2"),iAt.forEach(t),m2r=r(_Ie," \u2014 "),jH=n(_Ie,"A",{href:!0});var dAt=s(jH);g2r=r(dAt,"TFWav2Vec2Model"),dAt.forEach(t),h2r=r(_Ie," (Wav2Vec2 model)"),_Ie.forEach(t),p2r=i(D),kM=n(D,"LI",{});var bIe=s(kM);Uve=n(bIe,"STRONG",{});var cAt=s(Uve);u2r=r(cAt,"xlm"),cAt.forEach(t),_2r=r(bIe," \u2014 "),DH=n(bIe,"A",{href:!0});var fAt=s(DH);b2r=r(fAt,"TFXLMModel"),fAt.forEach(t),v2r=r(bIe," (XLM model)"),bIe.forEach(t),F2r=i(D),SM=n(D,"LI",{});var vIe=s(SM);Jve=n(vIe,"STRONG",{});var mAt=s(Jve);T2r=r(mAt,"xlm-roberta"),mAt.forEach(t),M2r=r(vIe," \u2014 "),GH=n(vIe,"A",{href:!0});var gAt=s(GH);E2r=r(gAt,"TFXLMRobertaModel"),gAt.forEach(t),C2r=r(vIe," (XLM-RoBERTa model)"),vIe.forEach(t),w2r=i(D),RM=n(D,"LI",{});var FIe=s(RM);Yve=n(FIe,"STRONG",{});var hAt=s(Yve);A2r=r(hAt,"xlnet"),hAt.forEach(t),L2r=r(FIe," \u2014 "),OH=n(FIe,"A",{href:!0});var pAt=s(OH);y2r=r(pAt,"TFXLNetModel"),pAt.forEach(t),x2r=r(FIe," (XLNet model)"),FIe.forEach(t),D.forEach(t),$2r=i(Cl),T(PM.$$.fragment,Cl),Cl.forEach(t),El.forEach(t),yOe=i(f),tc=n(f,"H2",{class:!0});var IXe=s(tc);BM=n(IXe,"A",{id:!0,class:!0,href:!0});var uAt=s(BM);Kve=n(uAt,"SPAN",{});var _At=s(Kve);T(p9.$$.fragment,_At),_At.forEach(t),uAt.forEach(t),k2r=i(IXe),Zve=n(IXe,"SPAN",{});var bAt=s(Zve);S2r=r(bAt,"TFAutoModelForPreTraining"),bAt.forEach(t),IXe.forEach(t),xOe=i(f),er=n(f,"DIV",{class:!0});var wl=s(er);T(u9.$$.fragment,wl),R2r=i(wl),ac=n(wl,"P",{});var sre=s(ac);P2r=r(sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),VH=n(sre,"A",{href:!0});var vAt=s(VH);B2r=r(vAt,"from_pretrained()"),vAt.forEach(t),I2r=r(sre," class method or the "),XH=n(sre,"A",{href:!0});var FAt=s(XH);N2r=r(FAt,"from_config()"),FAt.forEach(t),q2r=r(sre,` class
method.`),sre.forEach(t),j2r=i(wl),_9=n(wl,"P",{});var NXe=s(_9);D2r=r(NXe,"This class cannot be instantiated directly using "),eFe=n(NXe,"CODE",{});var TAt=s(eFe);G2r=r(TAt,"__init__()"),TAt.forEach(t),O2r=r(NXe," (throws an error)."),NXe.forEach(t),V2r=i(wl),kt=n(wl,"DIV",{class:!0});var E6=s(kt);T(b9.$$.fragment,E6),X2r=i(E6),oFe=n(E6,"P",{});var MAt=s(oFe);z2r=r(MAt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),MAt.forEach(t),W2r=i(E6),nc=n(E6,"P",{});var lre=s(nc);Q2r=r(lre,`Note:
Loading a model from its configuration file does `),rFe=n(lre,"STRONG",{});var EAt=s(rFe);H2r=r(EAt,"not"),EAt.forEach(t),U2r=r(lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),zH=n(lre,"A",{href:!0});var CAt=s(zH);J2r=r(CAt,"from_pretrained()"),CAt.forEach(t),Y2r=r(lre," to load the model weights."),lre.forEach(t),K2r=i(E6),T(IM.$$.fragment,E6),E6.forEach(t),Z2r=i(wl),yr=n(wl,"DIV",{class:!0});var Al=s(yr);T(v9.$$.fragment,Al),ebr=i(Al),tFe=n(Al,"P",{});var wAt=s(tFe);obr=r(wAt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),wAt.forEach(t),rbr=i(Al),an=n(Al,"P",{});var C6=s(an);tbr=r(C6,"The model class to instantiate is selected based on the "),aFe=n(C6,"CODE",{});var AAt=s(aFe);abr=r(AAt,"model_type"),AAt.forEach(t),nbr=r(C6,` property of the config object (either
passed as an argument or loaded from `),nFe=n(C6,"CODE",{});var LAt=s(nFe);sbr=r(LAt,"pretrained_model_name_or_path"),LAt.forEach(t),lbr=r(C6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=n(C6,"CODE",{});var yAt=s(sFe);ibr=r(yAt,"pretrained_model_name_or_path"),yAt.forEach(t),dbr=r(C6,":"),C6.forEach(t),cbr=i(Al),se=n(Al,"UL",{});var le=s(se);NM=n(le,"LI",{});var TIe=s(NM);lFe=n(TIe,"STRONG",{});var xAt=s(lFe);fbr=r(xAt,"albert"),xAt.forEach(t),mbr=r(TIe," \u2014 "),WH=n(TIe,"A",{href:!0});var $At=s(WH);gbr=r($At,"TFAlbertForPreTraining"),$At.forEach(t),hbr=r(TIe," (ALBERT model)"),TIe.forEach(t),pbr=i(le),qM=n(le,"LI",{});var MIe=s(qM);iFe=n(MIe,"STRONG",{});var kAt=s(iFe);ubr=r(kAt,"bart"),kAt.forEach(t),_br=r(MIe," \u2014 "),QH=n(MIe,"A",{href:!0});var SAt=s(QH);bbr=r(SAt,"TFBartForConditionalGeneration"),SAt.forEach(t),vbr=r(MIe," (BART model)"),MIe.forEach(t),Fbr=i(le),jM=n(le,"LI",{});var EIe=s(jM);dFe=n(EIe,"STRONG",{});var RAt=s(dFe);Tbr=r(RAt,"bert"),RAt.forEach(t),Mbr=r(EIe," \u2014 "),HH=n(EIe,"A",{href:!0});var PAt=s(HH);Ebr=r(PAt,"TFBertForPreTraining"),PAt.forEach(t),Cbr=r(EIe," (BERT model)"),EIe.forEach(t),wbr=i(le),DM=n(le,"LI",{});var CIe=s(DM);cFe=n(CIe,"STRONG",{});var BAt=s(cFe);Abr=r(BAt,"camembert"),BAt.forEach(t),Lbr=r(CIe," \u2014 "),UH=n(CIe,"A",{href:!0});var IAt=s(UH);ybr=r(IAt,"TFCamembertForMaskedLM"),IAt.forEach(t),xbr=r(CIe," (CamemBERT model)"),CIe.forEach(t),$br=i(le),GM=n(le,"LI",{});var wIe=s(GM);fFe=n(wIe,"STRONG",{});var NAt=s(fFe);kbr=r(NAt,"ctrl"),NAt.forEach(t),Sbr=r(wIe," \u2014 "),JH=n(wIe,"A",{href:!0});var qAt=s(JH);Rbr=r(qAt,"TFCTRLLMHeadModel"),qAt.forEach(t),Pbr=r(wIe," (CTRL model)"),wIe.forEach(t),Bbr=i(le),OM=n(le,"LI",{});var AIe=s(OM);mFe=n(AIe,"STRONG",{});var jAt=s(mFe);Ibr=r(jAt,"distilbert"),jAt.forEach(t),Nbr=r(AIe," \u2014 "),YH=n(AIe,"A",{href:!0});var DAt=s(YH);qbr=r(DAt,"TFDistilBertForMaskedLM"),DAt.forEach(t),jbr=r(AIe," (DistilBERT model)"),AIe.forEach(t),Dbr=i(le),VM=n(le,"LI",{});var LIe=s(VM);gFe=n(LIe,"STRONG",{});var GAt=s(gFe);Gbr=r(GAt,"electra"),GAt.forEach(t),Obr=r(LIe," \u2014 "),KH=n(LIe,"A",{href:!0});var OAt=s(KH);Vbr=r(OAt,"TFElectraForPreTraining"),OAt.forEach(t),Xbr=r(LIe," (ELECTRA model)"),LIe.forEach(t),zbr=i(le),XM=n(le,"LI",{});var yIe=s(XM);hFe=n(yIe,"STRONG",{});var VAt=s(hFe);Wbr=r(VAt,"flaubert"),VAt.forEach(t),Qbr=r(yIe," \u2014 "),ZH=n(yIe,"A",{href:!0});var XAt=s(ZH);Hbr=r(XAt,"TFFlaubertWithLMHeadModel"),XAt.forEach(t),Ubr=r(yIe," (FlauBERT model)"),yIe.forEach(t),Jbr=i(le),zM=n(le,"LI",{});var xIe=s(zM);pFe=n(xIe,"STRONG",{});var zAt=s(pFe);Ybr=r(zAt,"funnel"),zAt.forEach(t),Kbr=r(xIe," \u2014 "),eU=n(xIe,"A",{href:!0});var WAt=s(eU);Zbr=r(WAt,"TFFunnelForPreTraining"),WAt.forEach(t),evr=r(xIe," (Funnel Transformer model)"),xIe.forEach(t),ovr=i(le),WM=n(le,"LI",{});var $Ie=s(WM);uFe=n($Ie,"STRONG",{});var QAt=s(uFe);rvr=r(QAt,"gpt2"),QAt.forEach(t),tvr=r($Ie," \u2014 "),oU=n($Ie,"A",{href:!0});var HAt=s(oU);avr=r(HAt,"TFGPT2LMHeadModel"),HAt.forEach(t),nvr=r($Ie," (OpenAI GPT-2 model)"),$Ie.forEach(t),svr=i(le),QM=n(le,"LI",{});var kIe=s(QM);_Fe=n(kIe,"STRONG",{});var UAt=s(_Fe);lvr=r(UAt,"layoutlm"),UAt.forEach(t),ivr=r(kIe," \u2014 "),rU=n(kIe,"A",{href:!0});var JAt=s(rU);dvr=r(JAt,"TFLayoutLMForMaskedLM"),JAt.forEach(t),cvr=r(kIe," (LayoutLM model)"),kIe.forEach(t),fvr=i(le),HM=n(le,"LI",{});var SIe=s(HM);bFe=n(SIe,"STRONG",{});var YAt=s(bFe);mvr=r(YAt,"lxmert"),YAt.forEach(t),gvr=r(SIe," \u2014 "),tU=n(SIe,"A",{href:!0});var KAt=s(tU);hvr=r(KAt,"TFLxmertForPreTraining"),KAt.forEach(t),pvr=r(SIe," (LXMERT model)"),SIe.forEach(t),uvr=i(le),UM=n(le,"LI",{});var RIe=s(UM);vFe=n(RIe,"STRONG",{});var ZAt=s(vFe);_vr=r(ZAt,"mobilebert"),ZAt.forEach(t),bvr=r(RIe," \u2014 "),aU=n(RIe,"A",{href:!0});var e6t=s(aU);vvr=r(e6t,"TFMobileBertForPreTraining"),e6t.forEach(t),Fvr=r(RIe," (MobileBERT model)"),RIe.forEach(t),Tvr=i(le),JM=n(le,"LI",{});var PIe=s(JM);FFe=n(PIe,"STRONG",{});var o6t=s(FFe);Mvr=r(o6t,"mpnet"),o6t.forEach(t),Evr=r(PIe," \u2014 "),nU=n(PIe,"A",{href:!0});var r6t=s(nU);Cvr=r(r6t,"TFMPNetForMaskedLM"),r6t.forEach(t),wvr=r(PIe," (MPNet model)"),PIe.forEach(t),Avr=i(le),YM=n(le,"LI",{});var BIe=s(YM);TFe=n(BIe,"STRONG",{});var t6t=s(TFe);Lvr=r(t6t,"openai-gpt"),t6t.forEach(t),yvr=r(BIe," \u2014 "),sU=n(BIe,"A",{href:!0});var a6t=s(sU);xvr=r(a6t,"TFOpenAIGPTLMHeadModel"),a6t.forEach(t),$vr=r(BIe," (OpenAI GPT model)"),BIe.forEach(t),kvr=i(le),KM=n(le,"LI",{});var IIe=s(KM);MFe=n(IIe,"STRONG",{});var n6t=s(MFe);Svr=r(n6t,"roberta"),n6t.forEach(t),Rvr=r(IIe," \u2014 "),lU=n(IIe,"A",{href:!0});var s6t=s(lU);Pvr=r(s6t,"TFRobertaForMaskedLM"),s6t.forEach(t),Bvr=r(IIe," (RoBERTa model)"),IIe.forEach(t),Ivr=i(le),ZM=n(le,"LI",{});var NIe=s(ZM);EFe=n(NIe,"STRONG",{});var l6t=s(EFe);Nvr=r(l6t,"t5"),l6t.forEach(t),qvr=r(NIe," \u2014 "),iU=n(NIe,"A",{href:!0});var i6t=s(iU);jvr=r(i6t,"TFT5ForConditionalGeneration"),i6t.forEach(t),Dvr=r(NIe," (T5 model)"),NIe.forEach(t),Gvr=i(le),eE=n(le,"LI",{});var qIe=s(eE);CFe=n(qIe,"STRONG",{});var d6t=s(CFe);Ovr=r(d6t,"tapas"),d6t.forEach(t),Vvr=r(qIe," \u2014 "),dU=n(qIe,"A",{href:!0});var c6t=s(dU);Xvr=r(c6t,"TFTapasForMaskedLM"),c6t.forEach(t),zvr=r(qIe," (TAPAS model)"),qIe.forEach(t),Wvr=i(le),oE=n(le,"LI",{});var jIe=s(oE);wFe=n(jIe,"STRONG",{});var f6t=s(wFe);Qvr=r(f6t,"transfo-xl"),f6t.forEach(t),Hvr=r(jIe," \u2014 "),cU=n(jIe,"A",{href:!0});var m6t=s(cU);Uvr=r(m6t,"TFTransfoXLLMHeadModel"),m6t.forEach(t),Jvr=r(jIe," (Transformer-XL model)"),jIe.forEach(t),Yvr=i(le),rE=n(le,"LI",{});var DIe=s(rE);AFe=n(DIe,"STRONG",{});var g6t=s(AFe);Kvr=r(g6t,"vit_mae"),g6t.forEach(t),Zvr=r(DIe," \u2014 "),fU=n(DIe,"A",{href:!0});var h6t=s(fU);eFr=r(h6t,"TFViTMAEForPreTraining"),h6t.forEach(t),oFr=r(DIe," (ViTMAE model)"),DIe.forEach(t),rFr=i(le),tE=n(le,"LI",{});var GIe=s(tE);LFe=n(GIe,"STRONG",{});var p6t=s(LFe);tFr=r(p6t,"xlm"),p6t.forEach(t),aFr=r(GIe," \u2014 "),mU=n(GIe,"A",{href:!0});var u6t=s(mU);nFr=r(u6t,"TFXLMWithLMHeadModel"),u6t.forEach(t),sFr=r(GIe," (XLM model)"),GIe.forEach(t),lFr=i(le),aE=n(le,"LI",{});var OIe=s(aE);yFe=n(OIe,"STRONG",{});var _6t=s(yFe);iFr=r(_6t,"xlm-roberta"),_6t.forEach(t),dFr=r(OIe," \u2014 "),gU=n(OIe,"A",{href:!0});var b6t=s(gU);cFr=r(b6t,"TFXLMRobertaForMaskedLM"),b6t.forEach(t),fFr=r(OIe," (XLM-RoBERTa model)"),OIe.forEach(t),mFr=i(le),nE=n(le,"LI",{});var VIe=s(nE);xFe=n(VIe,"STRONG",{});var v6t=s(xFe);gFr=r(v6t,"xlnet"),v6t.forEach(t),hFr=r(VIe," \u2014 "),hU=n(VIe,"A",{href:!0});var F6t=s(hU);pFr=r(F6t,"TFXLNetLMHeadModel"),F6t.forEach(t),uFr=r(VIe," (XLNet model)"),VIe.forEach(t),le.forEach(t),_Fr=i(Al),T(sE.$$.fragment,Al),Al.forEach(t),wl.forEach(t),$Oe=i(f),sc=n(f,"H2",{class:!0});var qXe=s(sc);lE=n(qXe,"A",{id:!0,class:!0,href:!0});var T6t=s(lE);$Fe=n(T6t,"SPAN",{});var M6t=s($Fe);T(F9.$$.fragment,M6t),M6t.forEach(t),T6t.forEach(t),bFr=i(qXe),kFe=n(qXe,"SPAN",{});var E6t=s(kFe);vFr=r(E6t,"TFAutoModelForCausalLM"),E6t.forEach(t),qXe.forEach(t),kOe=i(f),or=n(f,"DIV",{class:!0});var Ll=s(or);T(T9.$$.fragment,Ll),FFr=i(Ll),lc=n(Ll,"P",{});var ire=s(lc);TFr=r(ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),pU=n(ire,"A",{href:!0});var C6t=s(pU);MFr=r(C6t,"from_pretrained()"),C6t.forEach(t),EFr=r(ire," class method or the "),uU=n(ire,"A",{href:!0});var w6t=s(uU);CFr=r(w6t,"from_config()"),w6t.forEach(t),wFr=r(ire,` class
method.`),ire.forEach(t),AFr=i(Ll),M9=n(Ll,"P",{});var jXe=s(M9);LFr=r(jXe,"This class cannot be instantiated directly using "),SFe=n(jXe,"CODE",{});var A6t=s(SFe);yFr=r(A6t,"__init__()"),A6t.forEach(t),xFr=r(jXe," (throws an error)."),jXe.forEach(t),$Fr=i(Ll),St=n(Ll,"DIV",{class:!0});var w6=s(St);T(E9.$$.fragment,w6),kFr=i(w6),RFe=n(w6,"P",{});var L6t=s(RFe);SFr=r(L6t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),L6t.forEach(t),RFr=i(w6),ic=n(w6,"P",{});var dre=s(ic);PFr=r(dre,`Note:
Loading a model from its configuration file does `),PFe=n(dre,"STRONG",{});var y6t=s(PFe);BFr=r(y6t,"not"),y6t.forEach(t),IFr=r(dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),_U=n(dre,"A",{href:!0});var x6t=s(_U);NFr=r(x6t,"from_pretrained()"),x6t.forEach(t),qFr=r(dre," to load the model weights."),dre.forEach(t),jFr=i(w6),T(iE.$$.fragment,w6),w6.forEach(t),DFr=i(Ll),xr=n(Ll,"DIV",{class:!0});var yl=s(xr);T(C9.$$.fragment,yl),GFr=i(yl),BFe=n(yl,"P",{});var $6t=s(BFe);OFr=r($6t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),$6t.forEach(t),VFr=i(yl),nn=n(yl,"P",{});var A6=s(nn);XFr=r(A6,"The model class to instantiate is selected based on the "),IFe=n(A6,"CODE",{});var k6t=s(IFe);zFr=r(k6t,"model_type"),k6t.forEach(t),WFr=r(A6,` property of the config object (either
passed as an argument or loaded from `),NFe=n(A6,"CODE",{});var S6t=s(NFe);QFr=r(S6t,"pretrained_model_name_or_path"),S6t.forEach(t),HFr=r(A6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qFe=n(A6,"CODE",{});var R6t=s(qFe);UFr=r(R6t,"pretrained_model_name_or_path"),R6t.forEach(t),JFr=r(A6,":"),A6.forEach(t),YFr=i(yl),Me=n(yl,"UL",{});var Ce=s(Me);dE=n(Ce,"LI",{});var XIe=s(dE);jFe=n(XIe,"STRONG",{});var P6t=s(jFe);KFr=r(P6t,"bert"),P6t.forEach(t),ZFr=r(XIe," \u2014 "),bU=n(XIe,"A",{href:!0});var B6t=s(bU);eTr=r(B6t,"TFBertLMHeadModel"),B6t.forEach(t),oTr=r(XIe," (BERT model)"),XIe.forEach(t),rTr=i(Ce),cE=n(Ce,"LI",{});var zIe=s(cE);DFe=n(zIe,"STRONG",{});var I6t=s(DFe);tTr=r(I6t,"camembert"),I6t.forEach(t),aTr=r(zIe," \u2014 "),vU=n(zIe,"A",{href:!0});var N6t=s(vU);nTr=r(N6t,"TFCamembertForCausalLM"),N6t.forEach(t),sTr=r(zIe," (CamemBERT model)"),zIe.forEach(t),lTr=i(Ce),fE=n(Ce,"LI",{});var WIe=s(fE);GFe=n(WIe,"STRONG",{});var q6t=s(GFe);iTr=r(q6t,"ctrl"),q6t.forEach(t),dTr=r(WIe," \u2014 "),FU=n(WIe,"A",{href:!0});var j6t=s(FU);cTr=r(j6t,"TFCTRLLMHeadModel"),j6t.forEach(t),fTr=r(WIe," (CTRL model)"),WIe.forEach(t),mTr=i(Ce),mE=n(Ce,"LI",{});var QIe=s(mE);OFe=n(QIe,"STRONG",{});var D6t=s(OFe);gTr=r(D6t,"gpt2"),D6t.forEach(t),hTr=r(QIe," \u2014 "),TU=n(QIe,"A",{href:!0});var G6t=s(TU);pTr=r(G6t,"TFGPT2LMHeadModel"),G6t.forEach(t),uTr=r(QIe," (OpenAI GPT-2 model)"),QIe.forEach(t),_Tr=i(Ce),gE=n(Ce,"LI",{});var HIe=s(gE);VFe=n(HIe,"STRONG",{});var O6t=s(VFe);bTr=r(O6t,"gptj"),O6t.forEach(t),vTr=r(HIe," \u2014 "),MU=n(HIe,"A",{href:!0});var V6t=s(MU);FTr=r(V6t,"TFGPTJForCausalLM"),V6t.forEach(t),TTr=r(HIe," (GPT-J model)"),HIe.forEach(t),MTr=i(Ce),hE=n(Ce,"LI",{});var UIe=s(hE);XFe=n(UIe,"STRONG",{});var X6t=s(XFe);ETr=r(X6t,"openai-gpt"),X6t.forEach(t),CTr=r(UIe," \u2014 "),EU=n(UIe,"A",{href:!0});var z6t=s(EU);wTr=r(z6t,"TFOpenAIGPTLMHeadModel"),z6t.forEach(t),ATr=r(UIe," (OpenAI GPT model)"),UIe.forEach(t),LTr=i(Ce),pE=n(Ce,"LI",{});var JIe=s(pE);zFe=n(JIe,"STRONG",{});var W6t=s(zFe);yTr=r(W6t,"opt"),W6t.forEach(t),xTr=r(JIe," \u2014 "),CU=n(JIe,"A",{href:!0});var Q6t=s(CU);$Tr=r(Q6t,"TFOPTForCausalLM"),Q6t.forEach(t),kTr=r(JIe," (OPT model)"),JIe.forEach(t),STr=i(Ce),uE=n(Ce,"LI",{});var YIe=s(uE);WFe=n(YIe,"STRONG",{});var H6t=s(WFe);RTr=r(H6t,"rembert"),H6t.forEach(t),PTr=r(YIe," \u2014 "),wU=n(YIe,"A",{href:!0});var U6t=s(wU);BTr=r(U6t,"TFRemBertForCausalLM"),U6t.forEach(t),ITr=r(YIe," (RemBERT model)"),YIe.forEach(t),NTr=i(Ce),_E=n(Ce,"LI",{});var KIe=s(_E);QFe=n(KIe,"STRONG",{});var J6t=s(QFe);qTr=r(J6t,"roberta"),J6t.forEach(t),jTr=r(KIe," \u2014 "),AU=n(KIe,"A",{href:!0});var Y6t=s(AU);DTr=r(Y6t,"TFRobertaForCausalLM"),Y6t.forEach(t),GTr=r(KIe," (RoBERTa model)"),KIe.forEach(t),OTr=i(Ce),bE=n(Ce,"LI",{});var ZIe=s(bE);HFe=n(ZIe,"STRONG",{});var K6t=s(HFe);VTr=r(K6t,"roformer"),K6t.forEach(t),XTr=r(ZIe," \u2014 "),LU=n(ZIe,"A",{href:!0});var Z6t=s(LU);zTr=r(Z6t,"TFRoFormerForCausalLM"),Z6t.forEach(t),WTr=r(ZIe," (RoFormer model)"),ZIe.forEach(t),QTr=i(Ce),vE=n(Ce,"LI",{});var eNe=s(vE);UFe=n(eNe,"STRONG",{});var eLt=s(UFe);HTr=r(eLt,"transfo-xl"),eLt.forEach(t),UTr=r(eNe," \u2014 "),yU=n(eNe,"A",{href:!0});var oLt=s(yU);JTr=r(oLt,"TFTransfoXLLMHeadModel"),oLt.forEach(t),YTr=r(eNe," (Transformer-XL model)"),eNe.forEach(t),KTr=i(Ce),FE=n(Ce,"LI",{});var oNe=s(FE);JFe=n(oNe,"STRONG",{});var rLt=s(JFe);ZTr=r(rLt,"xlm"),rLt.forEach(t),e7r=r(oNe," \u2014 "),xU=n(oNe,"A",{href:!0});var tLt=s(xU);o7r=r(tLt,"TFXLMWithLMHeadModel"),tLt.forEach(t),r7r=r(oNe," (XLM model)"),oNe.forEach(t),t7r=i(Ce),TE=n(Ce,"LI",{});var rNe=s(TE);YFe=n(rNe,"STRONG",{});var aLt=s(YFe);a7r=r(aLt,"xlnet"),aLt.forEach(t),n7r=r(rNe," \u2014 "),$U=n(rNe,"A",{href:!0});var nLt=s($U);s7r=r(nLt,"TFXLNetLMHeadModel"),nLt.forEach(t),l7r=r(rNe," (XLNet model)"),rNe.forEach(t),Ce.forEach(t),i7r=i(yl),T(ME.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),SOe=i(f),dc=n(f,"H2",{class:!0});var DXe=s(dc);EE=n(DXe,"A",{id:!0,class:!0,href:!0});var sLt=s(EE);KFe=n(sLt,"SPAN",{});var lLt=s(KFe);T(w9.$$.fragment,lLt),lLt.forEach(t),sLt.forEach(t),d7r=i(DXe),ZFe=n(DXe,"SPAN",{});var iLt=s(ZFe);c7r=r(iLt,"TFAutoModelForImageClassification"),iLt.forEach(t),DXe.forEach(t),ROe=i(f),rr=n(f,"DIV",{class:!0});var xl=s(rr);T(A9.$$.fragment,xl),f7r=i(xl),cc=n(xl,"P",{});var cre=s(cc);m7r=r(cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),kU=n(cre,"A",{href:!0});var dLt=s(kU);g7r=r(dLt,"from_pretrained()"),dLt.forEach(t),h7r=r(cre," class method or the "),SU=n(cre,"A",{href:!0});var cLt=s(SU);p7r=r(cLt,"from_config()"),cLt.forEach(t),u7r=r(cre,` class
method.`),cre.forEach(t),_7r=i(xl),L9=n(xl,"P",{});var GXe=s(L9);b7r=r(GXe,"This class cannot be instantiated directly using "),eTe=n(GXe,"CODE",{});var fLt=s(eTe);v7r=r(fLt,"__init__()"),fLt.forEach(t),F7r=r(GXe," (throws an error)."),GXe.forEach(t),T7r=i(xl),Rt=n(xl,"DIV",{class:!0});var L6=s(Rt);T(y9.$$.fragment,L6),M7r=i(L6),oTe=n(L6,"P",{});var mLt=s(oTe);E7r=r(mLt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),mLt.forEach(t),C7r=i(L6),fc=n(L6,"P",{});var fre=s(fc);w7r=r(fre,`Note:
Loading a model from its configuration file does `),rTe=n(fre,"STRONG",{});var gLt=s(rTe);A7r=r(gLt,"not"),gLt.forEach(t),L7r=r(fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=n(fre,"A",{href:!0});var hLt=s(RU);y7r=r(hLt,"from_pretrained()"),hLt.forEach(t),x7r=r(fre," to load the model weights."),fre.forEach(t),$7r=i(L6),T(CE.$$.fragment,L6),L6.forEach(t),k7r=i(xl),$r=n(xl,"DIV",{class:!0});var $l=s($r);T(x9.$$.fragment,$l),S7r=i($l),tTe=n($l,"P",{});var pLt=s(tTe);R7r=r(pLt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),pLt.forEach(t),P7r=i($l),sn=n($l,"P",{});var y6=s(sn);B7r=r(y6,"The model class to instantiate is selected based on the "),aTe=n(y6,"CODE",{});var uLt=s(aTe);I7r=r(uLt,"model_type"),uLt.forEach(t),N7r=r(y6,` property of the config object (either
passed as an argument or loaded from `),nTe=n(y6,"CODE",{});var _Lt=s(nTe);q7r=r(_Lt,"pretrained_model_name_or_path"),_Lt.forEach(t),j7r=r(y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sTe=n(y6,"CODE",{});var bLt=s(sTe);D7r=r(bLt,"pretrained_model_name_or_path"),bLt.forEach(t),G7r=r(y6,":"),y6.forEach(t),O7r=i($l),ln=n($l,"UL",{});var x6=s(ln);wE=n(x6,"LI",{});var tNe=s(wE);lTe=n(tNe,"STRONG",{});var vLt=s(lTe);V7r=r(vLt,"convnext"),vLt.forEach(t),X7r=r(tNe," \u2014 "),PU=n(tNe,"A",{href:!0});var FLt=s(PU);z7r=r(FLt,"TFConvNextForImageClassification"),FLt.forEach(t),W7r=r(tNe," (ConvNeXT model)"),tNe.forEach(t),Q7r=i(x6),AE=n(x6,"LI",{});var aNe=s(AE);iTe=n(aNe,"STRONG",{});var TLt=s(iTe);H7r=r(TLt,"data2vec-vision"),TLt.forEach(t),U7r=r(aNe," \u2014 "),BU=n(aNe,"A",{href:!0});var MLt=s(BU);J7r=r(MLt,"TFData2VecVisionForImageClassification"),MLt.forEach(t),Y7r=r(aNe," (Data2VecVision model)"),aNe.forEach(t),K7r=i(x6),LE=n(x6,"LI",{});var nNe=s(LE);dTe=n(nNe,"STRONG",{});var ELt=s(dTe);Z7r=r(ELt,"swin"),ELt.forEach(t),eMr=r(nNe," \u2014 "),IU=n(nNe,"A",{href:!0});var CLt=s(IU);oMr=r(CLt,"TFSwinForImageClassification"),CLt.forEach(t),rMr=r(nNe," (Swin Transformer model)"),nNe.forEach(t),tMr=i(x6),yE=n(x6,"LI",{});var sNe=s(yE);cTe=n(sNe,"STRONG",{});var wLt=s(cTe);aMr=r(wLt,"vit"),wLt.forEach(t),nMr=r(sNe," \u2014 "),NU=n(sNe,"A",{href:!0});var ALt=s(NU);sMr=r(ALt,"TFViTForImageClassification"),ALt.forEach(t),lMr=r(sNe," (ViT model)"),sNe.forEach(t),x6.forEach(t),iMr=i($l),T(xE.$$.fragment,$l),$l.forEach(t),xl.forEach(t),POe=i(f),mc=n(f,"H2",{class:!0});var OXe=s(mc);$E=n(OXe,"A",{id:!0,class:!0,href:!0});var LLt=s($E);fTe=n(LLt,"SPAN",{});var yLt=s(fTe);T($9.$$.fragment,yLt),yLt.forEach(t),LLt.forEach(t),dMr=i(OXe),mTe=n(OXe,"SPAN",{});var xLt=s(mTe);cMr=r(xLt,"TFAutoModelForMaskedLM"),xLt.forEach(t),OXe.forEach(t),BOe=i(f),tr=n(f,"DIV",{class:!0});var kl=s(tr);T(k9.$$.fragment,kl),fMr=i(kl),gc=n(kl,"P",{});var mre=s(gc);mMr=r(mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qU=n(mre,"A",{href:!0});var $Lt=s(qU);gMr=r($Lt,"from_pretrained()"),$Lt.forEach(t),hMr=r(mre," class method or the "),jU=n(mre,"A",{href:!0});var kLt=s(jU);pMr=r(kLt,"from_config()"),kLt.forEach(t),uMr=r(mre,` class
method.`),mre.forEach(t),_Mr=i(kl),S9=n(kl,"P",{});var VXe=s(S9);bMr=r(VXe,"This class cannot be instantiated directly using "),gTe=n(VXe,"CODE",{});var SLt=s(gTe);vMr=r(SLt,"__init__()"),SLt.forEach(t),FMr=r(VXe," (throws an error)."),VXe.forEach(t),TMr=i(kl),Pt=n(kl,"DIV",{class:!0});var $6=s(Pt);T(R9.$$.fragment,$6),MMr=i($6),hTe=n($6,"P",{});var RLt=s(hTe);EMr=r(RLt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),RLt.forEach(t),CMr=i($6),hc=n($6,"P",{});var gre=s(hc);wMr=r(gre,`Note:
Loading a model from its configuration file does `),pTe=n(gre,"STRONG",{});var PLt=s(pTe);AMr=r(PLt,"not"),PLt.forEach(t),LMr=r(gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),DU=n(gre,"A",{href:!0});var BLt=s(DU);yMr=r(BLt,"from_pretrained()"),BLt.forEach(t),xMr=r(gre," to load the model weights."),gre.forEach(t),$Mr=i($6),T(kE.$$.fragment,$6),$6.forEach(t),kMr=i(kl),kr=n(kl,"DIV",{class:!0});var Sl=s(kr);T(P9.$$.fragment,Sl),SMr=i(Sl),uTe=n(Sl,"P",{});var ILt=s(uTe);RMr=r(ILt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ILt.forEach(t),PMr=i(Sl),dn=n(Sl,"P",{});var k6=s(dn);BMr=r(k6,"The model class to instantiate is selected based on the "),_Te=n(k6,"CODE",{});var NLt=s(_Te);IMr=r(NLt,"model_type"),NLt.forEach(t),NMr=r(k6,` property of the config object (either
passed as an argument or loaded from `),bTe=n(k6,"CODE",{});var qLt=s(bTe);qMr=r(qLt,"pretrained_model_name_or_path"),qLt.forEach(t),jMr=r(k6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vTe=n(k6,"CODE",{});var jLt=s(vTe);DMr=r(jLt,"pretrained_model_name_or_path"),jLt.forEach(t),GMr=r(k6,":"),k6.forEach(t),OMr=i(Sl),ie=n(Sl,"UL",{});var fe=s(ie);SE=n(fe,"LI",{});var lNe=s(SE);FTe=n(lNe,"STRONG",{});var DLt=s(FTe);VMr=r(DLt,"albert"),DLt.forEach(t),XMr=r(lNe," \u2014 "),GU=n(lNe,"A",{href:!0});var GLt=s(GU);zMr=r(GLt,"TFAlbertForMaskedLM"),GLt.forEach(t),WMr=r(lNe," (ALBERT model)"),lNe.forEach(t),QMr=i(fe),RE=n(fe,"LI",{});var iNe=s(RE);TTe=n(iNe,"STRONG",{});var OLt=s(TTe);HMr=r(OLt,"bert"),OLt.forEach(t),UMr=r(iNe," \u2014 "),OU=n(iNe,"A",{href:!0});var VLt=s(OU);JMr=r(VLt,"TFBertForMaskedLM"),VLt.forEach(t),YMr=r(iNe," (BERT model)"),iNe.forEach(t),KMr=i(fe),PE=n(fe,"LI",{});var dNe=s(PE);MTe=n(dNe,"STRONG",{});var XLt=s(MTe);ZMr=r(XLt,"camembert"),XLt.forEach(t),eEr=r(dNe," \u2014 "),VU=n(dNe,"A",{href:!0});var zLt=s(VU);oEr=r(zLt,"TFCamembertForMaskedLM"),zLt.forEach(t),rEr=r(dNe," (CamemBERT model)"),dNe.forEach(t),tEr=i(fe),BE=n(fe,"LI",{});var cNe=s(BE);ETe=n(cNe,"STRONG",{});var WLt=s(ETe);aEr=r(WLt,"convbert"),WLt.forEach(t),nEr=r(cNe," \u2014 "),XU=n(cNe,"A",{href:!0});var QLt=s(XU);sEr=r(QLt,"TFConvBertForMaskedLM"),QLt.forEach(t),lEr=r(cNe," (ConvBERT model)"),cNe.forEach(t),iEr=i(fe),IE=n(fe,"LI",{});var fNe=s(IE);CTe=n(fNe,"STRONG",{});var HLt=s(CTe);dEr=r(HLt,"deberta"),HLt.forEach(t),cEr=r(fNe," \u2014 "),zU=n(fNe,"A",{href:!0});var ULt=s(zU);fEr=r(ULt,"TFDebertaForMaskedLM"),ULt.forEach(t),mEr=r(fNe," (DeBERTa model)"),fNe.forEach(t),gEr=i(fe),NE=n(fe,"LI",{});var mNe=s(NE);wTe=n(mNe,"STRONG",{});var JLt=s(wTe);hEr=r(JLt,"deberta-v2"),JLt.forEach(t),pEr=r(mNe," \u2014 "),WU=n(mNe,"A",{href:!0});var YLt=s(WU);uEr=r(YLt,"TFDebertaV2ForMaskedLM"),YLt.forEach(t),_Er=r(mNe," (DeBERTa-v2 model)"),mNe.forEach(t),bEr=i(fe),qE=n(fe,"LI",{});var gNe=s(qE);ATe=n(gNe,"STRONG",{});var KLt=s(ATe);vEr=r(KLt,"distilbert"),KLt.forEach(t),FEr=r(gNe," \u2014 "),QU=n(gNe,"A",{href:!0});var ZLt=s(QU);TEr=r(ZLt,"TFDistilBertForMaskedLM"),ZLt.forEach(t),MEr=r(gNe," (DistilBERT model)"),gNe.forEach(t),EEr=i(fe),jE=n(fe,"LI",{});var hNe=s(jE);LTe=n(hNe,"STRONG",{});var eyt=s(LTe);CEr=r(eyt,"electra"),eyt.forEach(t),wEr=r(hNe," \u2014 "),HU=n(hNe,"A",{href:!0});var oyt=s(HU);AEr=r(oyt,"TFElectraForMaskedLM"),oyt.forEach(t),LEr=r(hNe," (ELECTRA model)"),hNe.forEach(t),yEr=i(fe),DE=n(fe,"LI",{});var pNe=s(DE);yTe=n(pNe,"STRONG",{});var ryt=s(yTe);xEr=r(ryt,"flaubert"),ryt.forEach(t),$Er=r(pNe," \u2014 "),UU=n(pNe,"A",{href:!0});var tyt=s(UU);kEr=r(tyt,"TFFlaubertWithLMHeadModel"),tyt.forEach(t),SEr=r(pNe," (FlauBERT model)"),pNe.forEach(t),REr=i(fe),GE=n(fe,"LI",{});var uNe=s(GE);xTe=n(uNe,"STRONG",{});var ayt=s(xTe);PEr=r(ayt,"funnel"),ayt.forEach(t),BEr=r(uNe," \u2014 "),JU=n(uNe,"A",{href:!0});var nyt=s(JU);IEr=r(nyt,"TFFunnelForMaskedLM"),nyt.forEach(t),NEr=r(uNe," (Funnel Transformer model)"),uNe.forEach(t),qEr=i(fe),OE=n(fe,"LI",{});var _Ne=s(OE);$Te=n(_Ne,"STRONG",{});var syt=s($Te);jEr=r(syt,"layoutlm"),syt.forEach(t),DEr=r(_Ne," \u2014 "),YU=n(_Ne,"A",{href:!0});var lyt=s(YU);GEr=r(lyt,"TFLayoutLMForMaskedLM"),lyt.forEach(t),OEr=r(_Ne," (LayoutLM model)"),_Ne.forEach(t),VEr=i(fe),VE=n(fe,"LI",{});var bNe=s(VE);kTe=n(bNe,"STRONG",{});var iyt=s(kTe);XEr=r(iyt,"longformer"),iyt.forEach(t),zEr=r(bNe," \u2014 "),KU=n(bNe,"A",{href:!0});var dyt=s(KU);WEr=r(dyt,"TFLongformerForMaskedLM"),dyt.forEach(t),QEr=r(bNe," (Longformer model)"),bNe.forEach(t),HEr=i(fe),XE=n(fe,"LI",{});var vNe=s(XE);STe=n(vNe,"STRONG",{});var cyt=s(STe);UEr=r(cyt,"mobilebert"),cyt.forEach(t),JEr=r(vNe," \u2014 "),ZU=n(vNe,"A",{href:!0});var fyt=s(ZU);YEr=r(fyt,"TFMobileBertForMaskedLM"),fyt.forEach(t),KEr=r(vNe," (MobileBERT model)"),vNe.forEach(t),ZEr=i(fe),zE=n(fe,"LI",{});var FNe=s(zE);RTe=n(FNe,"STRONG",{});var myt=s(RTe);e4r=r(myt,"mpnet"),myt.forEach(t),o4r=r(FNe," \u2014 "),eJ=n(FNe,"A",{href:!0});var gyt=s(eJ);r4r=r(gyt,"TFMPNetForMaskedLM"),gyt.forEach(t),t4r=r(FNe," (MPNet model)"),FNe.forEach(t),a4r=i(fe),WE=n(fe,"LI",{});var TNe=s(WE);PTe=n(TNe,"STRONG",{});var hyt=s(PTe);n4r=r(hyt,"rembert"),hyt.forEach(t),s4r=r(TNe," \u2014 "),oJ=n(TNe,"A",{href:!0});var pyt=s(oJ);l4r=r(pyt,"TFRemBertForMaskedLM"),pyt.forEach(t),i4r=r(TNe," (RemBERT model)"),TNe.forEach(t),d4r=i(fe),QE=n(fe,"LI",{});var MNe=s(QE);BTe=n(MNe,"STRONG",{});var uyt=s(BTe);c4r=r(uyt,"roberta"),uyt.forEach(t),f4r=r(MNe," \u2014 "),rJ=n(MNe,"A",{href:!0});var _yt=s(rJ);m4r=r(_yt,"TFRobertaForMaskedLM"),_yt.forEach(t),g4r=r(MNe," (RoBERTa model)"),MNe.forEach(t),h4r=i(fe),HE=n(fe,"LI",{});var ENe=s(HE);ITe=n(ENe,"STRONG",{});var byt=s(ITe);p4r=r(byt,"roformer"),byt.forEach(t),u4r=r(ENe," \u2014 "),tJ=n(ENe,"A",{href:!0});var vyt=s(tJ);_4r=r(vyt,"TFRoFormerForMaskedLM"),vyt.forEach(t),b4r=r(ENe," (RoFormer model)"),ENe.forEach(t),v4r=i(fe),UE=n(fe,"LI",{});var CNe=s(UE);NTe=n(CNe,"STRONG",{});var Fyt=s(NTe);F4r=r(Fyt,"tapas"),Fyt.forEach(t),T4r=r(CNe," \u2014 "),aJ=n(CNe,"A",{href:!0});var Tyt=s(aJ);M4r=r(Tyt,"TFTapasForMaskedLM"),Tyt.forEach(t),E4r=r(CNe," (TAPAS model)"),CNe.forEach(t),C4r=i(fe),JE=n(fe,"LI",{});var wNe=s(JE);qTe=n(wNe,"STRONG",{});var Myt=s(qTe);w4r=r(Myt,"xlm"),Myt.forEach(t),A4r=r(wNe," \u2014 "),nJ=n(wNe,"A",{href:!0});var Eyt=s(nJ);L4r=r(Eyt,"TFXLMWithLMHeadModel"),Eyt.forEach(t),y4r=r(wNe," (XLM model)"),wNe.forEach(t),x4r=i(fe),YE=n(fe,"LI",{});var ANe=s(YE);jTe=n(ANe,"STRONG",{});var Cyt=s(jTe);$4r=r(Cyt,"xlm-roberta"),Cyt.forEach(t),k4r=r(ANe," \u2014 "),sJ=n(ANe,"A",{href:!0});var wyt=s(sJ);S4r=r(wyt,"TFXLMRobertaForMaskedLM"),wyt.forEach(t),R4r=r(ANe," (XLM-RoBERTa model)"),ANe.forEach(t),fe.forEach(t),P4r=i(Sl),T(KE.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),IOe=i(f),pc=n(f,"H2",{class:!0});var XXe=s(pc);ZE=n(XXe,"A",{id:!0,class:!0,href:!0});var Ayt=s(ZE);DTe=n(Ayt,"SPAN",{});var Lyt=s(DTe);T(B9.$$.fragment,Lyt),Lyt.forEach(t),Ayt.forEach(t),B4r=i(XXe),GTe=n(XXe,"SPAN",{});var yyt=s(GTe);I4r=r(yyt,"TFAutoModelForSeq2SeqLM"),yyt.forEach(t),XXe.forEach(t),NOe=i(f),ar=n(f,"DIV",{class:!0});var Rl=s(ar);T(I9.$$.fragment,Rl),N4r=i(Rl),uc=n(Rl,"P",{});var hre=s(uc);q4r=r(hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),lJ=n(hre,"A",{href:!0});var xyt=s(lJ);j4r=r(xyt,"from_pretrained()"),xyt.forEach(t),D4r=r(hre," class method or the "),iJ=n(hre,"A",{href:!0});var $yt=s(iJ);G4r=r($yt,"from_config()"),$yt.forEach(t),O4r=r(hre,` class
method.`),hre.forEach(t),V4r=i(Rl),N9=n(Rl,"P",{});var zXe=s(N9);X4r=r(zXe,"This class cannot be instantiated directly using "),OTe=n(zXe,"CODE",{});var kyt=s(OTe);z4r=r(kyt,"__init__()"),kyt.forEach(t),W4r=r(zXe," (throws an error)."),zXe.forEach(t),Q4r=i(Rl),Bt=n(Rl,"DIV",{class:!0});var S6=s(Bt);T(q9.$$.fragment,S6),H4r=i(S6),VTe=n(S6,"P",{});var Syt=s(VTe);U4r=r(Syt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Syt.forEach(t),J4r=i(S6),_c=n(S6,"P",{});var pre=s(_c);Y4r=r(pre,`Note:
Loading a model from its configuration file does `),XTe=n(pre,"STRONG",{});var Ryt=s(XTe);K4r=r(Ryt,"not"),Ryt.forEach(t),Z4r=r(pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),dJ=n(pre,"A",{href:!0});var Pyt=s(dJ);eCr=r(Pyt,"from_pretrained()"),Pyt.forEach(t),oCr=r(pre," to load the model weights."),pre.forEach(t),rCr=i(S6),T(e4.$$.fragment,S6),S6.forEach(t),tCr=i(Rl),Sr=n(Rl,"DIV",{class:!0});var Pl=s(Sr);T(j9.$$.fragment,Pl),aCr=i(Pl),zTe=n(Pl,"P",{});var Byt=s(zTe);nCr=r(Byt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Byt.forEach(t),sCr=i(Pl),cn=n(Pl,"P",{});var R6=s(cn);lCr=r(R6,"The model class to instantiate is selected based on the "),WTe=n(R6,"CODE",{});var Iyt=s(WTe);iCr=r(Iyt,"model_type"),Iyt.forEach(t),dCr=r(R6,` property of the config object (either
passed as an argument or loaded from `),QTe=n(R6,"CODE",{});var Nyt=s(QTe);cCr=r(Nyt,"pretrained_model_name_or_path"),Nyt.forEach(t),fCr=r(R6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HTe=n(R6,"CODE",{});var qyt=s(HTe);mCr=r(qyt,"pretrained_model_name_or_path"),qyt.forEach(t),gCr=r(R6,":"),R6.forEach(t),hCr=i(Pl),ye=n(Pl,"UL",{});var Ie=s(ye);o4=n(Ie,"LI",{});var LNe=s(o4);UTe=n(LNe,"STRONG",{});var jyt=s(UTe);pCr=r(jyt,"bart"),jyt.forEach(t),uCr=r(LNe," \u2014 "),cJ=n(LNe,"A",{href:!0});var Dyt=s(cJ);_Cr=r(Dyt,"TFBartForConditionalGeneration"),Dyt.forEach(t),bCr=r(LNe," (BART model)"),LNe.forEach(t),vCr=i(Ie),r4=n(Ie,"LI",{});var yNe=s(r4);JTe=n(yNe,"STRONG",{});var Gyt=s(JTe);FCr=r(Gyt,"blenderbot"),Gyt.forEach(t),TCr=r(yNe," \u2014 "),fJ=n(yNe,"A",{href:!0});var Oyt=s(fJ);MCr=r(Oyt,"TFBlenderbotForConditionalGeneration"),Oyt.forEach(t),ECr=r(yNe," (Blenderbot model)"),yNe.forEach(t),CCr=i(Ie),t4=n(Ie,"LI",{});var xNe=s(t4);YTe=n(xNe,"STRONG",{});var Vyt=s(YTe);wCr=r(Vyt,"blenderbot-small"),Vyt.forEach(t),ACr=r(xNe," \u2014 "),mJ=n(xNe,"A",{href:!0});var Xyt=s(mJ);LCr=r(Xyt,"TFBlenderbotSmallForConditionalGeneration"),Xyt.forEach(t),yCr=r(xNe," (BlenderbotSmall model)"),xNe.forEach(t),xCr=i(Ie),a4=n(Ie,"LI",{});var $Ne=s(a4);KTe=n($Ne,"STRONG",{});var zyt=s(KTe);$Cr=r(zyt,"encoder-decoder"),zyt.forEach(t),kCr=r($Ne," \u2014 "),gJ=n($Ne,"A",{href:!0});var Wyt=s(gJ);SCr=r(Wyt,"TFEncoderDecoderModel"),Wyt.forEach(t),RCr=r($Ne," (Encoder decoder model)"),$Ne.forEach(t),PCr=i(Ie),n4=n(Ie,"LI",{});var kNe=s(n4);ZTe=n(kNe,"STRONG",{});var Qyt=s(ZTe);BCr=r(Qyt,"led"),Qyt.forEach(t),ICr=r(kNe," \u2014 "),hJ=n(kNe,"A",{href:!0});var Hyt=s(hJ);NCr=r(Hyt,"TFLEDForConditionalGeneration"),Hyt.forEach(t),qCr=r(kNe," (LED model)"),kNe.forEach(t),jCr=i(Ie),s4=n(Ie,"LI",{});var SNe=s(s4);e7e=n(SNe,"STRONG",{});var Uyt=s(e7e);DCr=r(Uyt,"marian"),Uyt.forEach(t),GCr=r(SNe," \u2014 "),pJ=n(SNe,"A",{href:!0});var Jyt=s(pJ);OCr=r(Jyt,"TFMarianMTModel"),Jyt.forEach(t),VCr=r(SNe," (Marian model)"),SNe.forEach(t),XCr=i(Ie),l4=n(Ie,"LI",{});var RNe=s(l4);o7e=n(RNe,"STRONG",{});var Yyt=s(o7e);zCr=r(Yyt,"mbart"),Yyt.forEach(t),WCr=r(RNe," \u2014 "),uJ=n(RNe,"A",{href:!0});var Kyt=s(uJ);QCr=r(Kyt,"TFMBartForConditionalGeneration"),Kyt.forEach(t),HCr=r(RNe," (mBART model)"),RNe.forEach(t),UCr=i(Ie),i4=n(Ie,"LI",{});var PNe=s(i4);r7e=n(PNe,"STRONG",{});var Zyt=s(r7e);JCr=r(Zyt,"mt5"),Zyt.forEach(t),YCr=r(PNe," \u2014 "),_J=n(PNe,"A",{href:!0});var e8t=s(_J);KCr=r(e8t,"TFMT5ForConditionalGeneration"),e8t.forEach(t),ZCr=r(PNe," (MT5 model)"),PNe.forEach(t),e5r=i(Ie),d4=n(Ie,"LI",{});var BNe=s(d4);t7e=n(BNe,"STRONG",{});var o8t=s(t7e);o5r=r(o8t,"pegasus"),o8t.forEach(t),r5r=r(BNe," \u2014 "),bJ=n(BNe,"A",{href:!0});var r8t=s(bJ);t5r=r(r8t,"TFPegasusForConditionalGeneration"),r8t.forEach(t),a5r=r(BNe," (Pegasus model)"),BNe.forEach(t),n5r=i(Ie),c4=n(Ie,"LI",{});var INe=s(c4);a7e=n(INe,"STRONG",{});var t8t=s(a7e);s5r=r(t8t,"t5"),t8t.forEach(t),l5r=r(INe," \u2014 "),vJ=n(INe,"A",{href:!0});var a8t=s(vJ);i5r=r(a8t,"TFT5ForConditionalGeneration"),a8t.forEach(t),d5r=r(INe," (T5 model)"),INe.forEach(t),Ie.forEach(t),c5r=i(Pl),T(f4.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),qOe=i(f),bc=n(f,"H2",{class:!0});var WXe=s(bc);m4=n(WXe,"A",{id:!0,class:!0,href:!0});var n8t=s(m4);n7e=n(n8t,"SPAN",{});var s8t=s(n7e);T(D9.$$.fragment,s8t),s8t.forEach(t),n8t.forEach(t),f5r=i(WXe),s7e=n(WXe,"SPAN",{});var l8t=s(s7e);m5r=r(l8t,"TFAutoModelForSequenceClassification"),l8t.forEach(t),WXe.forEach(t),jOe=i(f),nr=n(f,"DIV",{class:!0});var Bl=s(nr);T(G9.$$.fragment,Bl),g5r=i(Bl),vc=n(Bl,"P",{});var ure=s(vc);h5r=r(ure,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),FJ=n(ure,"A",{href:!0});var i8t=s(FJ);p5r=r(i8t,"from_pretrained()"),i8t.forEach(t),u5r=r(ure," class method or the "),TJ=n(ure,"A",{href:!0});var d8t=s(TJ);_5r=r(d8t,"from_config()"),d8t.forEach(t),b5r=r(ure,` class
method.`),ure.forEach(t),v5r=i(Bl),O9=n(Bl,"P",{});var QXe=s(O9);F5r=r(QXe,"This class cannot be instantiated directly using "),l7e=n(QXe,"CODE",{});var c8t=s(l7e);T5r=r(c8t,"__init__()"),c8t.forEach(t),M5r=r(QXe," (throws an error)."),QXe.forEach(t),E5r=i(Bl),It=n(Bl,"DIV",{class:!0});var P6=s(It);T(V9.$$.fragment,P6),C5r=i(P6),i7e=n(P6,"P",{});var f8t=s(i7e);w5r=r(f8t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),f8t.forEach(t),A5r=i(P6),Fc=n(P6,"P",{});var _re=s(Fc);L5r=r(_re,`Note:
Loading a model from its configuration file does `),d7e=n(_re,"STRONG",{});var m8t=s(d7e);y5r=r(m8t,"not"),m8t.forEach(t),x5r=r(_re,` load the model weights. It only affects the
model\u2019s configuration. Use `),MJ=n(_re,"A",{href:!0});var g8t=s(MJ);$5r=r(g8t,"from_pretrained()"),g8t.forEach(t),k5r=r(_re," to load the model weights."),_re.forEach(t),S5r=i(P6),T(g4.$$.fragment,P6),P6.forEach(t),R5r=i(Bl),Rr=n(Bl,"DIV",{class:!0});var Il=s(Rr);T(X9.$$.fragment,Il),P5r=i(Il),c7e=n(Il,"P",{});var h8t=s(c7e);B5r=r(h8t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),h8t.forEach(t),I5r=i(Il),fn=n(Il,"P",{});var B6=s(fn);N5r=r(B6,"The model class to instantiate is selected based on the "),f7e=n(B6,"CODE",{});var p8t=s(f7e);q5r=r(p8t,"model_type"),p8t.forEach(t),j5r=r(B6,` property of the config object (either
passed as an argument or loaded from `),m7e=n(B6,"CODE",{});var u8t=s(m7e);D5r=r(u8t,"pretrained_model_name_or_path"),u8t.forEach(t),G5r=r(B6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g7e=n(B6,"CODE",{});var _8t=s(g7e);O5r=r(_8t,"pretrained_model_name_or_path"),_8t.forEach(t),V5r=r(B6,":"),B6.forEach(t),X5r=i(Il),te=n(Il,"UL",{});var ne=s(te);h4=n(ne,"LI",{});var NNe=s(h4);h7e=n(NNe,"STRONG",{});var b8t=s(h7e);z5r=r(b8t,"albert"),b8t.forEach(t),W5r=r(NNe," \u2014 "),EJ=n(NNe,"A",{href:!0});var v8t=s(EJ);Q5r=r(v8t,"TFAlbertForSequenceClassification"),v8t.forEach(t),H5r=r(NNe," (ALBERT model)"),NNe.forEach(t),U5r=i(ne),p4=n(ne,"LI",{});var qNe=s(p4);p7e=n(qNe,"STRONG",{});var F8t=s(p7e);J5r=r(F8t,"bert"),F8t.forEach(t),Y5r=r(qNe," \u2014 "),CJ=n(qNe,"A",{href:!0});var T8t=s(CJ);K5r=r(T8t,"TFBertForSequenceClassification"),T8t.forEach(t),Z5r=r(qNe," (BERT model)"),qNe.forEach(t),e0r=i(ne),u4=n(ne,"LI",{});var jNe=s(u4);u7e=n(jNe,"STRONG",{});var M8t=s(u7e);o0r=r(M8t,"camembert"),M8t.forEach(t),r0r=r(jNe," \u2014 "),wJ=n(jNe,"A",{href:!0});var E8t=s(wJ);t0r=r(E8t,"TFCamembertForSequenceClassification"),E8t.forEach(t),a0r=r(jNe," (CamemBERT model)"),jNe.forEach(t),n0r=i(ne),_4=n(ne,"LI",{});var DNe=s(_4);_7e=n(DNe,"STRONG",{});var C8t=s(_7e);s0r=r(C8t,"convbert"),C8t.forEach(t),l0r=r(DNe," \u2014 "),AJ=n(DNe,"A",{href:!0});var w8t=s(AJ);i0r=r(w8t,"TFConvBertForSequenceClassification"),w8t.forEach(t),d0r=r(DNe," (ConvBERT model)"),DNe.forEach(t),c0r=i(ne),b4=n(ne,"LI",{});var GNe=s(b4);b7e=n(GNe,"STRONG",{});var A8t=s(b7e);f0r=r(A8t,"ctrl"),A8t.forEach(t),m0r=r(GNe," \u2014 "),LJ=n(GNe,"A",{href:!0});var L8t=s(LJ);g0r=r(L8t,"TFCTRLForSequenceClassification"),L8t.forEach(t),h0r=r(GNe," (CTRL model)"),GNe.forEach(t),p0r=i(ne),v4=n(ne,"LI",{});var ONe=s(v4);v7e=n(ONe,"STRONG",{});var y8t=s(v7e);u0r=r(y8t,"deberta"),y8t.forEach(t),_0r=r(ONe," \u2014 "),yJ=n(ONe,"A",{href:!0});var x8t=s(yJ);b0r=r(x8t,"TFDebertaForSequenceClassification"),x8t.forEach(t),v0r=r(ONe," (DeBERTa model)"),ONe.forEach(t),F0r=i(ne),F4=n(ne,"LI",{});var VNe=s(F4);F7e=n(VNe,"STRONG",{});var $8t=s(F7e);T0r=r($8t,"deberta-v2"),$8t.forEach(t),M0r=r(VNe," \u2014 "),xJ=n(VNe,"A",{href:!0});var k8t=s(xJ);E0r=r(k8t,"TFDebertaV2ForSequenceClassification"),k8t.forEach(t),C0r=r(VNe," (DeBERTa-v2 model)"),VNe.forEach(t),w0r=i(ne),T4=n(ne,"LI",{});var XNe=s(T4);T7e=n(XNe,"STRONG",{});var S8t=s(T7e);A0r=r(S8t,"distilbert"),S8t.forEach(t),L0r=r(XNe," \u2014 "),$J=n(XNe,"A",{href:!0});var R8t=s($J);y0r=r(R8t,"TFDistilBertForSequenceClassification"),R8t.forEach(t),x0r=r(XNe," (DistilBERT model)"),XNe.forEach(t),$0r=i(ne),M4=n(ne,"LI",{});var zNe=s(M4);M7e=n(zNe,"STRONG",{});var P8t=s(M7e);k0r=r(P8t,"electra"),P8t.forEach(t),S0r=r(zNe," \u2014 "),kJ=n(zNe,"A",{href:!0});var B8t=s(kJ);R0r=r(B8t,"TFElectraForSequenceClassification"),B8t.forEach(t),P0r=r(zNe," (ELECTRA model)"),zNe.forEach(t),B0r=i(ne),E4=n(ne,"LI",{});var WNe=s(E4);E7e=n(WNe,"STRONG",{});var I8t=s(E7e);I0r=r(I8t,"flaubert"),I8t.forEach(t),N0r=r(WNe," \u2014 "),SJ=n(WNe,"A",{href:!0});var N8t=s(SJ);q0r=r(N8t,"TFFlaubertForSequenceClassification"),N8t.forEach(t),j0r=r(WNe," (FlauBERT model)"),WNe.forEach(t),D0r=i(ne),C4=n(ne,"LI",{});var QNe=s(C4);C7e=n(QNe,"STRONG",{});var q8t=s(C7e);G0r=r(q8t,"funnel"),q8t.forEach(t),O0r=r(QNe," \u2014 "),RJ=n(QNe,"A",{href:!0});var j8t=s(RJ);V0r=r(j8t,"TFFunnelForSequenceClassification"),j8t.forEach(t),X0r=r(QNe," (Funnel Transformer model)"),QNe.forEach(t),z0r=i(ne),w4=n(ne,"LI",{});var HNe=s(w4);w7e=n(HNe,"STRONG",{});var D8t=s(w7e);W0r=r(D8t,"gpt2"),D8t.forEach(t),Q0r=r(HNe," \u2014 "),PJ=n(HNe,"A",{href:!0});var G8t=s(PJ);H0r=r(G8t,"TFGPT2ForSequenceClassification"),G8t.forEach(t),U0r=r(HNe," (OpenAI GPT-2 model)"),HNe.forEach(t),J0r=i(ne),A4=n(ne,"LI",{});var UNe=s(A4);A7e=n(UNe,"STRONG",{});var O8t=s(A7e);Y0r=r(O8t,"gptj"),O8t.forEach(t),K0r=r(UNe," \u2014 "),BJ=n(UNe,"A",{href:!0});var V8t=s(BJ);Z0r=r(V8t,"TFGPTJForSequenceClassification"),V8t.forEach(t),ewr=r(UNe," (GPT-J model)"),UNe.forEach(t),owr=i(ne),L4=n(ne,"LI",{});var JNe=s(L4);L7e=n(JNe,"STRONG",{});var X8t=s(L7e);rwr=r(X8t,"layoutlm"),X8t.forEach(t),twr=r(JNe," \u2014 "),IJ=n(JNe,"A",{href:!0});var z8t=s(IJ);awr=r(z8t,"TFLayoutLMForSequenceClassification"),z8t.forEach(t),nwr=r(JNe," (LayoutLM model)"),JNe.forEach(t),swr=i(ne),y4=n(ne,"LI",{});var YNe=s(y4);y7e=n(YNe,"STRONG",{});var W8t=s(y7e);lwr=r(W8t,"longformer"),W8t.forEach(t),iwr=r(YNe," \u2014 "),NJ=n(YNe,"A",{href:!0});var Q8t=s(NJ);dwr=r(Q8t,"TFLongformerForSequenceClassification"),Q8t.forEach(t),cwr=r(YNe," (Longformer model)"),YNe.forEach(t),fwr=i(ne),x4=n(ne,"LI",{});var KNe=s(x4);x7e=n(KNe,"STRONG",{});var H8t=s(x7e);mwr=r(H8t,"mobilebert"),H8t.forEach(t),gwr=r(KNe," \u2014 "),qJ=n(KNe,"A",{href:!0});var U8t=s(qJ);hwr=r(U8t,"TFMobileBertForSequenceClassification"),U8t.forEach(t),pwr=r(KNe," (MobileBERT model)"),KNe.forEach(t),uwr=i(ne),$4=n(ne,"LI",{});var ZNe=s($4);$7e=n(ZNe,"STRONG",{});var J8t=s($7e);_wr=r(J8t,"mpnet"),J8t.forEach(t),bwr=r(ZNe," \u2014 "),jJ=n(ZNe,"A",{href:!0});var Y8t=s(jJ);vwr=r(Y8t,"TFMPNetForSequenceClassification"),Y8t.forEach(t),Fwr=r(ZNe," (MPNet model)"),ZNe.forEach(t),Twr=i(ne),k4=n(ne,"LI",{});var eqe=s(k4);k7e=n(eqe,"STRONG",{});var K8t=s(k7e);Mwr=r(K8t,"openai-gpt"),K8t.forEach(t),Ewr=r(eqe," \u2014 "),DJ=n(eqe,"A",{href:!0});var Z8t=s(DJ);Cwr=r(Z8t,"TFOpenAIGPTForSequenceClassification"),Z8t.forEach(t),wwr=r(eqe," (OpenAI GPT model)"),eqe.forEach(t),Awr=i(ne),S4=n(ne,"LI",{});var oqe=s(S4);S7e=n(oqe,"STRONG",{});var e9t=s(S7e);Lwr=r(e9t,"rembert"),e9t.forEach(t),ywr=r(oqe," \u2014 "),GJ=n(oqe,"A",{href:!0});var o9t=s(GJ);xwr=r(o9t,"TFRemBertForSequenceClassification"),o9t.forEach(t),$wr=r(oqe," (RemBERT model)"),oqe.forEach(t),kwr=i(ne),R4=n(ne,"LI",{});var rqe=s(R4);R7e=n(rqe,"STRONG",{});var r9t=s(R7e);Swr=r(r9t,"roberta"),r9t.forEach(t),Rwr=r(rqe," \u2014 "),OJ=n(rqe,"A",{href:!0});var t9t=s(OJ);Pwr=r(t9t,"TFRobertaForSequenceClassification"),t9t.forEach(t),Bwr=r(rqe," (RoBERTa model)"),rqe.forEach(t),Iwr=i(ne),P4=n(ne,"LI",{});var tqe=s(P4);P7e=n(tqe,"STRONG",{});var a9t=s(P7e);Nwr=r(a9t,"roformer"),a9t.forEach(t),qwr=r(tqe," \u2014 "),VJ=n(tqe,"A",{href:!0});var n9t=s(VJ);jwr=r(n9t,"TFRoFormerForSequenceClassification"),n9t.forEach(t),Dwr=r(tqe," (RoFormer model)"),tqe.forEach(t),Gwr=i(ne),B4=n(ne,"LI",{});var aqe=s(B4);B7e=n(aqe,"STRONG",{});var s9t=s(B7e);Owr=r(s9t,"tapas"),s9t.forEach(t),Vwr=r(aqe," \u2014 "),XJ=n(aqe,"A",{href:!0});var l9t=s(XJ);Xwr=r(l9t,"TFTapasForSequenceClassification"),l9t.forEach(t),zwr=r(aqe," (TAPAS model)"),aqe.forEach(t),Wwr=i(ne),I4=n(ne,"LI",{});var nqe=s(I4);I7e=n(nqe,"STRONG",{});var i9t=s(I7e);Qwr=r(i9t,"transfo-xl"),i9t.forEach(t),Hwr=r(nqe," \u2014 "),zJ=n(nqe,"A",{href:!0});var d9t=s(zJ);Uwr=r(d9t,"TFTransfoXLForSequenceClassification"),d9t.forEach(t),Jwr=r(nqe," (Transformer-XL model)"),nqe.forEach(t),Ywr=i(ne),N4=n(ne,"LI",{});var sqe=s(N4);N7e=n(sqe,"STRONG",{});var c9t=s(N7e);Kwr=r(c9t,"xlm"),c9t.forEach(t),Zwr=r(sqe," \u2014 "),WJ=n(sqe,"A",{href:!0});var f9t=s(WJ);eAr=r(f9t,"TFXLMForSequenceClassification"),f9t.forEach(t),oAr=r(sqe," (XLM model)"),sqe.forEach(t),rAr=i(ne),q4=n(ne,"LI",{});var lqe=s(q4);q7e=n(lqe,"STRONG",{});var m9t=s(q7e);tAr=r(m9t,"xlm-roberta"),m9t.forEach(t),aAr=r(lqe," \u2014 "),QJ=n(lqe,"A",{href:!0});var g9t=s(QJ);nAr=r(g9t,"TFXLMRobertaForSequenceClassification"),g9t.forEach(t),sAr=r(lqe," (XLM-RoBERTa model)"),lqe.forEach(t),lAr=i(ne),j4=n(ne,"LI",{});var iqe=s(j4);j7e=n(iqe,"STRONG",{});var h9t=s(j7e);iAr=r(h9t,"xlnet"),h9t.forEach(t),dAr=r(iqe," \u2014 "),HJ=n(iqe,"A",{href:!0});var p9t=s(HJ);cAr=r(p9t,"TFXLNetForSequenceClassification"),p9t.forEach(t),fAr=r(iqe," (XLNet model)"),iqe.forEach(t),ne.forEach(t),mAr=i(Il),T(D4.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),DOe=i(f),Tc=n(f,"H2",{class:!0});var HXe=s(Tc);G4=n(HXe,"A",{id:!0,class:!0,href:!0});var u9t=s(G4);D7e=n(u9t,"SPAN",{});var _9t=s(D7e);T(z9.$$.fragment,_9t),_9t.forEach(t),u9t.forEach(t),gAr=i(HXe),G7e=n(HXe,"SPAN",{});var b9t=s(G7e);hAr=r(b9t,"TFAutoModelForMultipleChoice"),b9t.forEach(t),HXe.forEach(t),GOe=i(f),sr=n(f,"DIV",{class:!0});var Nl=s(sr);T(W9.$$.fragment,Nl),pAr=i(Nl),Mc=n(Nl,"P",{});var bre=s(Mc);uAr=r(bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),UJ=n(bre,"A",{href:!0});var v9t=s(UJ);_Ar=r(v9t,"from_pretrained()"),v9t.forEach(t),bAr=r(bre," class method or the "),JJ=n(bre,"A",{href:!0});var F9t=s(JJ);vAr=r(F9t,"from_config()"),F9t.forEach(t),FAr=r(bre,` class
method.`),bre.forEach(t),TAr=i(Nl),Q9=n(Nl,"P",{});var UXe=s(Q9);MAr=r(UXe,"This class cannot be instantiated directly using "),O7e=n(UXe,"CODE",{});var T9t=s(O7e);EAr=r(T9t,"__init__()"),T9t.forEach(t),CAr=r(UXe," (throws an error)."),UXe.forEach(t),wAr=i(Nl),Nt=n(Nl,"DIV",{class:!0});var I6=s(Nt);T(H9.$$.fragment,I6),AAr=i(I6),V7e=n(I6,"P",{});var M9t=s(V7e);LAr=r(M9t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),M9t.forEach(t),yAr=i(I6),Ec=n(I6,"P",{});var vre=s(Ec);xAr=r(vre,`Note:
Loading a model from its configuration file does `),X7e=n(vre,"STRONG",{});var E9t=s(X7e);$Ar=r(E9t,"not"),E9t.forEach(t),kAr=r(vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=n(vre,"A",{href:!0});var C9t=s(YJ);SAr=r(C9t,"from_pretrained()"),C9t.forEach(t),RAr=r(vre," to load the model weights."),vre.forEach(t),PAr=i(I6),T(O4.$$.fragment,I6),I6.forEach(t),BAr=i(Nl),Pr=n(Nl,"DIV",{class:!0});var ql=s(Pr);T(U9.$$.fragment,ql),IAr=i(ql),z7e=n(ql,"P",{});var w9t=s(z7e);NAr=r(w9t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),w9t.forEach(t),qAr=i(ql),mn=n(ql,"P",{});var N6=s(mn);jAr=r(N6,"The model class to instantiate is selected based on the "),W7e=n(N6,"CODE",{});var A9t=s(W7e);DAr=r(A9t,"model_type"),A9t.forEach(t),GAr=r(N6,` property of the config object (either
passed as an argument or loaded from `),Q7e=n(N6,"CODE",{});var L9t=s(Q7e);OAr=r(L9t,"pretrained_model_name_or_path"),L9t.forEach(t),VAr=r(N6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H7e=n(N6,"CODE",{});var y9t=s(H7e);XAr=r(y9t,"pretrained_model_name_or_path"),y9t.forEach(t),zAr=r(N6,":"),N6.forEach(t),WAr=i(ql),ue=n(ql,"UL",{});var ve=s(ue);V4=n(ve,"LI",{});var dqe=s(V4);U7e=n(dqe,"STRONG",{});var x9t=s(U7e);QAr=r(x9t,"albert"),x9t.forEach(t),HAr=r(dqe," \u2014 "),KJ=n(dqe,"A",{href:!0});var $9t=s(KJ);UAr=r($9t,"TFAlbertForMultipleChoice"),$9t.forEach(t),JAr=r(dqe," (ALBERT model)"),dqe.forEach(t),YAr=i(ve),X4=n(ve,"LI",{});var cqe=s(X4);J7e=n(cqe,"STRONG",{});var k9t=s(J7e);KAr=r(k9t,"bert"),k9t.forEach(t),ZAr=r(cqe," \u2014 "),ZJ=n(cqe,"A",{href:!0});var S9t=s(ZJ);e6r=r(S9t,"TFBertForMultipleChoice"),S9t.forEach(t),o6r=r(cqe," (BERT model)"),cqe.forEach(t),r6r=i(ve),z4=n(ve,"LI",{});var fqe=s(z4);Y7e=n(fqe,"STRONG",{});var R9t=s(Y7e);t6r=r(R9t,"camembert"),R9t.forEach(t),a6r=r(fqe," \u2014 "),eY=n(fqe,"A",{href:!0});var P9t=s(eY);n6r=r(P9t,"TFCamembertForMultipleChoice"),P9t.forEach(t),s6r=r(fqe," (CamemBERT model)"),fqe.forEach(t),l6r=i(ve),W4=n(ve,"LI",{});var mqe=s(W4);K7e=n(mqe,"STRONG",{});var B9t=s(K7e);i6r=r(B9t,"convbert"),B9t.forEach(t),d6r=r(mqe," \u2014 "),oY=n(mqe,"A",{href:!0});var I9t=s(oY);c6r=r(I9t,"TFConvBertForMultipleChoice"),I9t.forEach(t),f6r=r(mqe," (ConvBERT model)"),mqe.forEach(t),m6r=i(ve),Q4=n(ve,"LI",{});var gqe=s(Q4);Z7e=n(gqe,"STRONG",{});var N9t=s(Z7e);g6r=r(N9t,"distilbert"),N9t.forEach(t),h6r=r(gqe," \u2014 "),rY=n(gqe,"A",{href:!0});var q9t=s(rY);p6r=r(q9t,"TFDistilBertForMultipleChoice"),q9t.forEach(t),u6r=r(gqe," (DistilBERT model)"),gqe.forEach(t),_6r=i(ve),H4=n(ve,"LI",{});var hqe=s(H4);eMe=n(hqe,"STRONG",{});var j9t=s(eMe);b6r=r(j9t,"electra"),j9t.forEach(t),v6r=r(hqe," \u2014 "),tY=n(hqe,"A",{href:!0});var D9t=s(tY);F6r=r(D9t,"TFElectraForMultipleChoice"),D9t.forEach(t),T6r=r(hqe," (ELECTRA model)"),hqe.forEach(t),M6r=i(ve),U4=n(ve,"LI",{});var pqe=s(U4);oMe=n(pqe,"STRONG",{});var G9t=s(oMe);E6r=r(G9t,"flaubert"),G9t.forEach(t),C6r=r(pqe," \u2014 "),aY=n(pqe,"A",{href:!0});var O9t=s(aY);w6r=r(O9t,"TFFlaubertForMultipleChoice"),O9t.forEach(t),A6r=r(pqe," (FlauBERT model)"),pqe.forEach(t),L6r=i(ve),J4=n(ve,"LI",{});var uqe=s(J4);rMe=n(uqe,"STRONG",{});var V9t=s(rMe);y6r=r(V9t,"funnel"),V9t.forEach(t),x6r=r(uqe," \u2014 "),nY=n(uqe,"A",{href:!0});var X9t=s(nY);$6r=r(X9t,"TFFunnelForMultipleChoice"),X9t.forEach(t),k6r=r(uqe," (Funnel Transformer model)"),uqe.forEach(t),S6r=i(ve),Y4=n(ve,"LI",{});var _qe=s(Y4);tMe=n(_qe,"STRONG",{});var z9t=s(tMe);R6r=r(z9t,"longformer"),z9t.forEach(t),P6r=r(_qe," \u2014 "),sY=n(_qe,"A",{href:!0});var W9t=s(sY);B6r=r(W9t,"TFLongformerForMultipleChoice"),W9t.forEach(t),I6r=r(_qe," (Longformer model)"),_qe.forEach(t),N6r=i(ve),K4=n(ve,"LI",{});var bqe=s(K4);aMe=n(bqe,"STRONG",{});var Q9t=s(aMe);q6r=r(Q9t,"mobilebert"),Q9t.forEach(t),j6r=r(bqe," \u2014 "),lY=n(bqe,"A",{href:!0});var H9t=s(lY);D6r=r(H9t,"TFMobileBertForMultipleChoice"),H9t.forEach(t),G6r=r(bqe," (MobileBERT model)"),bqe.forEach(t),O6r=i(ve),Z4=n(ve,"LI",{});var vqe=s(Z4);nMe=n(vqe,"STRONG",{});var U9t=s(nMe);V6r=r(U9t,"mpnet"),U9t.forEach(t),X6r=r(vqe," \u2014 "),iY=n(vqe,"A",{href:!0});var J9t=s(iY);z6r=r(J9t,"TFMPNetForMultipleChoice"),J9t.forEach(t),W6r=r(vqe," (MPNet model)"),vqe.forEach(t),Q6r=i(ve),eC=n(ve,"LI",{});var Fqe=s(eC);sMe=n(Fqe,"STRONG",{});var Y9t=s(sMe);H6r=r(Y9t,"rembert"),Y9t.forEach(t),U6r=r(Fqe," \u2014 "),dY=n(Fqe,"A",{href:!0});var K9t=s(dY);J6r=r(K9t,"TFRemBertForMultipleChoice"),K9t.forEach(t),Y6r=r(Fqe," (RemBERT model)"),Fqe.forEach(t),K6r=i(ve),oC=n(ve,"LI",{});var Tqe=s(oC);lMe=n(Tqe,"STRONG",{});var Z9t=s(lMe);Z6r=r(Z9t,"roberta"),Z9t.forEach(t),eLr=r(Tqe," \u2014 "),cY=n(Tqe,"A",{href:!0});var ext=s(cY);oLr=r(ext,"TFRobertaForMultipleChoice"),ext.forEach(t),rLr=r(Tqe," (RoBERTa model)"),Tqe.forEach(t),tLr=i(ve),rC=n(ve,"LI",{});var Mqe=s(rC);iMe=n(Mqe,"STRONG",{});var oxt=s(iMe);aLr=r(oxt,"roformer"),oxt.forEach(t),nLr=r(Mqe," \u2014 "),fY=n(Mqe,"A",{href:!0});var rxt=s(fY);sLr=r(rxt,"TFRoFormerForMultipleChoice"),rxt.forEach(t),lLr=r(Mqe," (RoFormer model)"),Mqe.forEach(t),iLr=i(ve),tC=n(ve,"LI",{});var Eqe=s(tC);dMe=n(Eqe,"STRONG",{});var txt=s(dMe);dLr=r(txt,"xlm"),txt.forEach(t),cLr=r(Eqe," \u2014 "),mY=n(Eqe,"A",{href:!0});var axt=s(mY);fLr=r(axt,"TFXLMForMultipleChoice"),axt.forEach(t),mLr=r(Eqe," (XLM model)"),Eqe.forEach(t),gLr=i(ve),aC=n(ve,"LI",{});var Cqe=s(aC);cMe=n(Cqe,"STRONG",{});var nxt=s(cMe);hLr=r(nxt,"xlm-roberta"),nxt.forEach(t),pLr=r(Cqe," \u2014 "),gY=n(Cqe,"A",{href:!0});var sxt=s(gY);uLr=r(sxt,"TFXLMRobertaForMultipleChoice"),sxt.forEach(t),_Lr=r(Cqe," (XLM-RoBERTa model)"),Cqe.forEach(t),bLr=i(ve),nC=n(ve,"LI",{});var wqe=s(nC);fMe=n(wqe,"STRONG",{});var lxt=s(fMe);vLr=r(lxt,"xlnet"),lxt.forEach(t),FLr=r(wqe," \u2014 "),hY=n(wqe,"A",{href:!0});var ixt=s(hY);TLr=r(ixt,"TFXLNetForMultipleChoice"),ixt.forEach(t),MLr=r(wqe," (XLNet model)"),wqe.forEach(t),ve.forEach(t),ELr=i(ql),T(sC.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),OOe=i(f),Cc=n(f,"H2",{class:!0});var JXe=s(Cc);lC=n(JXe,"A",{id:!0,class:!0,href:!0});var dxt=s(lC);mMe=n(dxt,"SPAN",{});var cxt=s(mMe);T(J9.$$.fragment,cxt),cxt.forEach(t),dxt.forEach(t),CLr=i(JXe),gMe=n(JXe,"SPAN",{});var fxt=s(gMe);wLr=r(fxt,"TFAutoModelForNextSentencePrediction"),fxt.forEach(t),JXe.forEach(t),VOe=i(f),lr=n(f,"DIV",{class:!0});var jl=s(lr);T(Y9.$$.fragment,jl),ALr=i(jl),wc=n(jl,"P",{});var Fre=s(wc);LLr=r(Fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),pY=n(Fre,"A",{href:!0});var mxt=s(pY);yLr=r(mxt,"from_pretrained()"),mxt.forEach(t),xLr=r(Fre," class method or the "),uY=n(Fre,"A",{href:!0});var gxt=s(uY);$Lr=r(gxt,"from_config()"),gxt.forEach(t),kLr=r(Fre,` class
method.`),Fre.forEach(t),SLr=i(jl),K9=n(jl,"P",{});var YXe=s(K9);RLr=r(YXe,"This class cannot be instantiated directly using "),hMe=n(YXe,"CODE",{});var hxt=s(hMe);PLr=r(hxt,"__init__()"),hxt.forEach(t),BLr=r(YXe," (throws an error)."),YXe.forEach(t),ILr=i(jl),qt=n(jl,"DIV",{class:!0});var q6=s(qt);T(Z9.$$.fragment,q6),NLr=i(q6),pMe=n(q6,"P",{});var pxt=s(pMe);qLr=r(pxt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),pxt.forEach(t),jLr=i(q6),Ac=n(q6,"P",{});var Tre=s(Ac);DLr=r(Tre,`Note:
Loading a model from its configuration file does `),uMe=n(Tre,"STRONG",{});var uxt=s(uMe);GLr=r(uxt,"not"),uxt.forEach(t),OLr=r(Tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),_Y=n(Tre,"A",{href:!0});var _xt=s(_Y);VLr=r(_xt,"from_pretrained()"),_xt.forEach(t),XLr=r(Tre," to load the model weights."),Tre.forEach(t),zLr=i(q6),T(iC.$$.fragment,q6),q6.forEach(t),WLr=i(jl),Br=n(jl,"DIV",{class:!0});var Dl=s(Br);T(ex.$$.fragment,Dl),QLr=i(Dl),_Me=n(Dl,"P",{});var bxt=s(_Me);HLr=r(bxt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),bxt.forEach(t),ULr=i(Dl),gn=n(Dl,"P",{});var j6=s(gn);JLr=r(j6,"The model class to instantiate is selected based on the "),bMe=n(j6,"CODE",{});var vxt=s(bMe);YLr=r(vxt,"model_type"),vxt.forEach(t),KLr=r(j6,` property of the config object (either
passed as an argument or loaded from `),vMe=n(j6,"CODE",{});var Fxt=s(vMe);ZLr=r(Fxt,"pretrained_model_name_or_path"),Fxt.forEach(t),eyr=r(j6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FMe=n(j6,"CODE",{});var Txt=s(FMe);oyr=r(Txt,"pretrained_model_name_or_path"),Txt.forEach(t),ryr=r(j6,":"),j6.forEach(t),tyr=i(Dl),ox=n(Dl,"UL",{});var KXe=s(ox);dC=n(KXe,"LI",{});var Aqe=s(dC);TMe=n(Aqe,"STRONG",{});var Mxt=s(TMe);ayr=r(Mxt,"bert"),Mxt.forEach(t),nyr=r(Aqe," \u2014 "),bY=n(Aqe,"A",{href:!0});var Ext=s(bY);syr=r(Ext,"TFBertForNextSentencePrediction"),Ext.forEach(t),lyr=r(Aqe," (BERT model)"),Aqe.forEach(t),iyr=i(KXe),cC=n(KXe,"LI",{});var Lqe=s(cC);MMe=n(Lqe,"STRONG",{});var Cxt=s(MMe);dyr=r(Cxt,"mobilebert"),Cxt.forEach(t),cyr=r(Lqe," \u2014 "),vY=n(Lqe,"A",{href:!0});var wxt=s(vY);fyr=r(wxt,"TFMobileBertForNextSentencePrediction"),wxt.forEach(t),myr=r(Lqe," (MobileBERT model)"),Lqe.forEach(t),KXe.forEach(t),gyr=i(Dl),T(fC.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),XOe=i(f),Lc=n(f,"H2",{class:!0});var ZXe=s(Lc);mC=n(ZXe,"A",{id:!0,class:!0,href:!0});var Axt=s(mC);EMe=n(Axt,"SPAN",{});var Lxt=s(EMe);T(rx.$$.fragment,Lxt),Lxt.forEach(t),Axt.forEach(t),hyr=i(ZXe),CMe=n(ZXe,"SPAN",{});var yxt=s(CMe);pyr=r(yxt,"TFAutoModelForTableQuestionAnswering"),yxt.forEach(t),ZXe.forEach(t),zOe=i(f),ir=n(f,"DIV",{class:!0});var Gl=s(ir);T(tx.$$.fragment,Gl),uyr=i(Gl),yc=n(Gl,"P",{});var Mre=s(yc);_yr=r(Mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),FY=n(Mre,"A",{href:!0});var xxt=s(FY);byr=r(xxt,"from_pretrained()"),xxt.forEach(t),vyr=r(Mre," class method or the "),TY=n(Mre,"A",{href:!0});var $xt=s(TY);Fyr=r($xt,"from_config()"),$xt.forEach(t),Tyr=r(Mre,` class
method.`),Mre.forEach(t),Myr=i(Gl),ax=n(Gl,"P",{});var eze=s(ax);Eyr=r(eze,"This class cannot be instantiated directly using "),wMe=n(eze,"CODE",{});var kxt=s(wMe);Cyr=r(kxt,"__init__()"),kxt.forEach(t),wyr=r(eze," (throws an error)."),eze.forEach(t),Ayr=i(Gl),jt=n(Gl,"DIV",{class:!0});var D6=s(jt);T(nx.$$.fragment,D6),Lyr=i(D6),AMe=n(D6,"P",{});var Sxt=s(AMe);yyr=r(Sxt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Sxt.forEach(t),xyr=i(D6),xc=n(D6,"P",{});var Ere=s(xc);$yr=r(Ere,`Note:
Loading a model from its configuration file does `),LMe=n(Ere,"STRONG",{});var Rxt=s(LMe);kyr=r(Rxt,"not"),Rxt.forEach(t),Syr=r(Ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),MY=n(Ere,"A",{href:!0});var Pxt=s(MY);Ryr=r(Pxt,"from_pretrained()"),Pxt.forEach(t),Pyr=r(Ere," to load the model weights."),Ere.forEach(t),Byr=i(D6),T(gC.$$.fragment,D6),D6.forEach(t),Iyr=i(Gl),Ir=n(Gl,"DIV",{class:!0});var Ol=s(Ir);T(sx.$$.fragment,Ol),Nyr=i(Ol),yMe=n(Ol,"P",{});var Bxt=s(yMe);qyr=r(Bxt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Bxt.forEach(t),jyr=i(Ol),hn=n(Ol,"P",{});var G6=s(hn);Dyr=r(G6,"The model class to instantiate is selected based on the "),xMe=n(G6,"CODE",{});var Ixt=s(xMe);Gyr=r(Ixt,"model_type"),Ixt.forEach(t),Oyr=r(G6,` property of the config object (either
passed as an argument or loaded from `),$Me=n(G6,"CODE",{});var Nxt=s($Me);Vyr=r(Nxt,"pretrained_model_name_or_path"),Nxt.forEach(t),Xyr=r(G6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kMe=n(G6,"CODE",{});var qxt=s(kMe);zyr=r(qxt,"pretrained_model_name_or_path"),qxt.forEach(t),Wyr=r(G6,":"),G6.forEach(t),Qyr=i(Ol),SMe=n(Ol,"UL",{});var jxt=s(SMe);hC=n(jxt,"LI",{});var yqe=s(hC);RMe=n(yqe,"STRONG",{});var Dxt=s(RMe);Hyr=r(Dxt,"tapas"),Dxt.forEach(t),Uyr=r(yqe," \u2014 "),EY=n(yqe,"A",{href:!0});var Gxt=s(EY);Jyr=r(Gxt,"TFTapasForQuestionAnswering"),Gxt.forEach(t),Yyr=r(yqe," (TAPAS model)"),yqe.forEach(t),jxt.forEach(t),Kyr=i(Ol),T(pC.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),WOe=i(f),$c=n(f,"H2",{class:!0});var oze=s($c);uC=n(oze,"A",{id:!0,class:!0,href:!0});var Oxt=s(uC);PMe=n(Oxt,"SPAN",{});var Vxt=s(PMe);T(lx.$$.fragment,Vxt),Vxt.forEach(t),Oxt.forEach(t),Zyr=i(oze),BMe=n(oze,"SPAN",{});var Xxt=s(BMe);e8r=r(Xxt,"TFAutoModelForTokenClassification"),Xxt.forEach(t),oze.forEach(t),QOe=i(f),dr=n(f,"DIV",{class:!0});var Vl=s(dr);T(ix.$$.fragment,Vl),o8r=i(Vl),kc=n(Vl,"P",{});var Cre=s(kc);r8r=r(Cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),CY=n(Cre,"A",{href:!0});var zxt=s(CY);t8r=r(zxt,"from_pretrained()"),zxt.forEach(t),a8r=r(Cre," class method or the "),wY=n(Cre,"A",{href:!0});var Wxt=s(wY);n8r=r(Wxt,"from_config()"),Wxt.forEach(t),s8r=r(Cre,` class
method.`),Cre.forEach(t),l8r=i(Vl),dx=n(Vl,"P",{});var rze=s(dx);i8r=r(rze,"This class cannot be instantiated directly using "),IMe=n(rze,"CODE",{});var Qxt=s(IMe);d8r=r(Qxt,"__init__()"),Qxt.forEach(t),c8r=r(rze," (throws an error)."),rze.forEach(t),f8r=i(Vl),Dt=n(Vl,"DIV",{class:!0});var O6=s(Dt);T(cx.$$.fragment,O6),m8r=i(O6),NMe=n(O6,"P",{});var Hxt=s(NMe);g8r=r(Hxt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Hxt.forEach(t),h8r=i(O6),Sc=n(O6,"P",{});var wre=s(Sc);p8r=r(wre,`Note:
Loading a model from its configuration file does `),qMe=n(wre,"STRONG",{});var Uxt=s(qMe);u8r=r(Uxt,"not"),Uxt.forEach(t),_8r=r(wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),AY=n(wre,"A",{href:!0});var Jxt=s(AY);b8r=r(Jxt,"from_pretrained()"),Jxt.forEach(t),v8r=r(wre," to load the model weights."),wre.forEach(t),F8r=i(O6),T(_C.$$.fragment,O6),O6.forEach(t),T8r=i(Vl),Nr=n(Vl,"DIV",{class:!0});var Xl=s(Nr);T(fx.$$.fragment,Xl),M8r=i(Xl),jMe=n(Xl,"P",{});var Yxt=s(jMe);E8r=r(Yxt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Yxt.forEach(t),C8r=i(Xl),pn=n(Xl,"P",{});var V6=s(pn);w8r=r(V6,"The model class to instantiate is selected based on the "),DMe=n(V6,"CODE",{});var Kxt=s(DMe);A8r=r(Kxt,"model_type"),Kxt.forEach(t),L8r=r(V6,` property of the config object (either
passed as an argument or loaded from `),GMe=n(V6,"CODE",{});var Zxt=s(GMe);y8r=r(Zxt,"pretrained_model_name_or_path"),Zxt.forEach(t),x8r=r(V6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OMe=n(V6,"CODE",{});var e$t=s(OMe);$8r=r(e$t,"pretrained_model_name_or_path"),e$t.forEach(t),k8r=r(V6,":"),V6.forEach(t),S8r=i(Xl),de=n(Xl,"UL",{});var me=s(de);bC=n(me,"LI",{});var xqe=s(bC);VMe=n(xqe,"STRONG",{});var o$t=s(VMe);R8r=r(o$t,"albert"),o$t.forEach(t),P8r=r(xqe," \u2014 "),LY=n(xqe,"A",{href:!0});var r$t=s(LY);B8r=r(r$t,"TFAlbertForTokenClassification"),r$t.forEach(t),I8r=r(xqe," (ALBERT model)"),xqe.forEach(t),N8r=i(me),vC=n(me,"LI",{});var $qe=s(vC);XMe=n($qe,"STRONG",{});var t$t=s(XMe);q8r=r(t$t,"bert"),t$t.forEach(t),j8r=r($qe," \u2014 "),yY=n($qe,"A",{href:!0});var a$t=s(yY);D8r=r(a$t,"TFBertForTokenClassification"),a$t.forEach(t),G8r=r($qe," (BERT model)"),$qe.forEach(t),O8r=i(me),FC=n(me,"LI",{});var kqe=s(FC);zMe=n(kqe,"STRONG",{});var n$t=s(zMe);V8r=r(n$t,"camembert"),n$t.forEach(t),X8r=r(kqe," \u2014 "),xY=n(kqe,"A",{href:!0});var s$t=s(xY);z8r=r(s$t,"TFCamembertForTokenClassification"),s$t.forEach(t),W8r=r(kqe," (CamemBERT model)"),kqe.forEach(t),Q8r=i(me),TC=n(me,"LI",{});var Sqe=s(TC);WMe=n(Sqe,"STRONG",{});var l$t=s(WMe);H8r=r(l$t,"convbert"),l$t.forEach(t),U8r=r(Sqe," \u2014 "),$Y=n(Sqe,"A",{href:!0});var i$t=s($Y);J8r=r(i$t,"TFConvBertForTokenClassification"),i$t.forEach(t),Y8r=r(Sqe," (ConvBERT model)"),Sqe.forEach(t),K8r=i(me),MC=n(me,"LI",{});var Rqe=s(MC);QMe=n(Rqe,"STRONG",{});var d$t=s(QMe);Z8r=r(d$t,"deberta"),d$t.forEach(t),e9r=r(Rqe," \u2014 "),kY=n(Rqe,"A",{href:!0});var c$t=s(kY);o9r=r(c$t,"TFDebertaForTokenClassification"),c$t.forEach(t),r9r=r(Rqe," (DeBERTa model)"),Rqe.forEach(t),t9r=i(me),EC=n(me,"LI",{});var Pqe=s(EC);HMe=n(Pqe,"STRONG",{});var f$t=s(HMe);a9r=r(f$t,"deberta-v2"),f$t.forEach(t),n9r=r(Pqe," \u2014 "),SY=n(Pqe,"A",{href:!0});var m$t=s(SY);s9r=r(m$t,"TFDebertaV2ForTokenClassification"),m$t.forEach(t),l9r=r(Pqe," (DeBERTa-v2 model)"),Pqe.forEach(t),i9r=i(me),CC=n(me,"LI",{});var Bqe=s(CC);UMe=n(Bqe,"STRONG",{});var g$t=s(UMe);d9r=r(g$t,"distilbert"),g$t.forEach(t),c9r=r(Bqe," \u2014 "),RY=n(Bqe,"A",{href:!0});var h$t=s(RY);f9r=r(h$t,"TFDistilBertForTokenClassification"),h$t.forEach(t),m9r=r(Bqe," (DistilBERT model)"),Bqe.forEach(t),g9r=i(me),wC=n(me,"LI",{});var Iqe=s(wC);JMe=n(Iqe,"STRONG",{});var p$t=s(JMe);h9r=r(p$t,"electra"),p$t.forEach(t),p9r=r(Iqe," \u2014 "),PY=n(Iqe,"A",{href:!0});var u$t=s(PY);u9r=r(u$t,"TFElectraForTokenClassification"),u$t.forEach(t),_9r=r(Iqe," (ELECTRA model)"),Iqe.forEach(t),b9r=i(me),AC=n(me,"LI",{});var Nqe=s(AC);YMe=n(Nqe,"STRONG",{});var _$t=s(YMe);v9r=r(_$t,"flaubert"),_$t.forEach(t),F9r=r(Nqe," \u2014 "),BY=n(Nqe,"A",{href:!0});var b$t=s(BY);T9r=r(b$t,"TFFlaubertForTokenClassification"),b$t.forEach(t),M9r=r(Nqe," (FlauBERT model)"),Nqe.forEach(t),E9r=i(me),LC=n(me,"LI",{});var qqe=s(LC);KMe=n(qqe,"STRONG",{});var v$t=s(KMe);C9r=r(v$t,"funnel"),v$t.forEach(t),w9r=r(qqe," \u2014 "),IY=n(qqe,"A",{href:!0});var F$t=s(IY);A9r=r(F$t,"TFFunnelForTokenClassification"),F$t.forEach(t),L9r=r(qqe," (Funnel Transformer model)"),qqe.forEach(t),y9r=i(me),yC=n(me,"LI",{});var jqe=s(yC);ZMe=n(jqe,"STRONG",{});var T$t=s(ZMe);x9r=r(T$t,"layoutlm"),T$t.forEach(t),$9r=r(jqe," \u2014 "),NY=n(jqe,"A",{href:!0});var M$t=s(NY);k9r=r(M$t,"TFLayoutLMForTokenClassification"),M$t.forEach(t),S9r=r(jqe," (LayoutLM model)"),jqe.forEach(t),R9r=i(me),xC=n(me,"LI",{});var Dqe=s(xC);eEe=n(Dqe,"STRONG",{});var E$t=s(eEe);P9r=r(E$t,"longformer"),E$t.forEach(t),B9r=r(Dqe," \u2014 "),qY=n(Dqe,"A",{href:!0});var C$t=s(qY);I9r=r(C$t,"TFLongformerForTokenClassification"),C$t.forEach(t),N9r=r(Dqe," (Longformer model)"),Dqe.forEach(t),q9r=i(me),$C=n(me,"LI",{});var Gqe=s($C);oEe=n(Gqe,"STRONG",{});var w$t=s(oEe);j9r=r(w$t,"mobilebert"),w$t.forEach(t),D9r=r(Gqe," \u2014 "),jY=n(Gqe,"A",{href:!0});var A$t=s(jY);G9r=r(A$t,"TFMobileBertForTokenClassification"),A$t.forEach(t),O9r=r(Gqe," (MobileBERT model)"),Gqe.forEach(t),V9r=i(me),kC=n(me,"LI",{});var Oqe=s(kC);rEe=n(Oqe,"STRONG",{});var L$t=s(rEe);X9r=r(L$t,"mpnet"),L$t.forEach(t),z9r=r(Oqe," \u2014 "),DY=n(Oqe,"A",{href:!0});var y$t=s(DY);W9r=r(y$t,"TFMPNetForTokenClassification"),y$t.forEach(t),Q9r=r(Oqe," (MPNet model)"),Oqe.forEach(t),H9r=i(me),SC=n(me,"LI",{});var Vqe=s(SC);tEe=n(Vqe,"STRONG",{});var x$t=s(tEe);U9r=r(x$t,"rembert"),x$t.forEach(t),J9r=r(Vqe," \u2014 "),GY=n(Vqe,"A",{href:!0});var $$t=s(GY);Y9r=r($$t,"TFRemBertForTokenClassification"),$$t.forEach(t),K9r=r(Vqe," (RemBERT model)"),Vqe.forEach(t),Z9r=i(me),RC=n(me,"LI",{});var Xqe=s(RC);aEe=n(Xqe,"STRONG",{});var k$t=s(aEe);exr=r(k$t,"roberta"),k$t.forEach(t),oxr=r(Xqe," \u2014 "),OY=n(Xqe,"A",{href:!0});var S$t=s(OY);rxr=r(S$t,"TFRobertaForTokenClassification"),S$t.forEach(t),txr=r(Xqe," (RoBERTa model)"),Xqe.forEach(t),axr=i(me),PC=n(me,"LI",{});var zqe=s(PC);nEe=n(zqe,"STRONG",{});var R$t=s(nEe);nxr=r(R$t,"roformer"),R$t.forEach(t),sxr=r(zqe," \u2014 "),VY=n(zqe,"A",{href:!0});var P$t=s(VY);lxr=r(P$t,"TFRoFormerForTokenClassification"),P$t.forEach(t),ixr=r(zqe," (RoFormer model)"),zqe.forEach(t),dxr=i(me),BC=n(me,"LI",{});var Wqe=s(BC);sEe=n(Wqe,"STRONG",{});var B$t=s(sEe);cxr=r(B$t,"xlm"),B$t.forEach(t),fxr=r(Wqe," \u2014 "),XY=n(Wqe,"A",{href:!0});var I$t=s(XY);mxr=r(I$t,"TFXLMForTokenClassification"),I$t.forEach(t),gxr=r(Wqe," (XLM model)"),Wqe.forEach(t),hxr=i(me),IC=n(me,"LI",{});var Qqe=s(IC);lEe=n(Qqe,"STRONG",{});var N$t=s(lEe);pxr=r(N$t,"xlm-roberta"),N$t.forEach(t),uxr=r(Qqe," \u2014 "),zY=n(Qqe,"A",{href:!0});var q$t=s(zY);_xr=r(q$t,"TFXLMRobertaForTokenClassification"),q$t.forEach(t),bxr=r(Qqe," (XLM-RoBERTa model)"),Qqe.forEach(t),vxr=i(me),NC=n(me,"LI",{});var Hqe=s(NC);iEe=n(Hqe,"STRONG",{});var j$t=s(iEe);Fxr=r(j$t,"xlnet"),j$t.forEach(t),Txr=r(Hqe," \u2014 "),WY=n(Hqe,"A",{href:!0});var D$t=s(WY);Mxr=r(D$t,"TFXLNetForTokenClassification"),D$t.forEach(t),Exr=r(Hqe," (XLNet model)"),Hqe.forEach(t),me.forEach(t),Cxr=i(Xl),T(qC.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),HOe=i(f),Rc=n(f,"H2",{class:!0});var tze=s(Rc);jC=n(tze,"A",{id:!0,class:!0,href:!0});var G$t=s(jC);dEe=n(G$t,"SPAN",{});var O$t=s(dEe);T(mx.$$.fragment,O$t),O$t.forEach(t),G$t.forEach(t),wxr=i(tze),cEe=n(tze,"SPAN",{});var V$t=s(cEe);Axr=r(V$t,"TFAutoModelForQuestionAnswering"),V$t.forEach(t),tze.forEach(t),UOe=i(f),cr=n(f,"DIV",{class:!0});var zl=s(cr);T(gx.$$.fragment,zl),Lxr=i(zl),Pc=n(zl,"P",{});var Are=s(Pc);yxr=r(Are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),QY=n(Are,"A",{href:!0});var X$t=s(QY);xxr=r(X$t,"from_pretrained()"),X$t.forEach(t),$xr=r(Are," class method or the "),HY=n(Are,"A",{href:!0});var z$t=s(HY);kxr=r(z$t,"from_config()"),z$t.forEach(t),Sxr=r(Are,` class
method.`),Are.forEach(t),Rxr=i(zl),hx=n(zl,"P",{});var aze=s(hx);Pxr=r(aze,"This class cannot be instantiated directly using "),fEe=n(aze,"CODE",{});var W$t=s(fEe);Bxr=r(W$t,"__init__()"),W$t.forEach(t),Ixr=r(aze," (throws an error)."),aze.forEach(t),Nxr=i(zl),Gt=n(zl,"DIV",{class:!0});var X6=s(Gt);T(px.$$.fragment,X6),qxr=i(X6),mEe=n(X6,"P",{});var Q$t=s(mEe);jxr=r(Q$t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Q$t.forEach(t),Dxr=i(X6),Bc=n(X6,"P",{});var Lre=s(Bc);Gxr=r(Lre,`Note:
Loading a model from its configuration file does `),gEe=n(Lre,"STRONG",{});var H$t=s(gEe);Oxr=r(H$t,"not"),H$t.forEach(t),Vxr=r(Lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),UY=n(Lre,"A",{href:!0});var U$t=s(UY);Xxr=r(U$t,"from_pretrained()"),U$t.forEach(t),zxr=r(Lre," to load the model weights."),Lre.forEach(t),Wxr=i(X6),T(DC.$$.fragment,X6),X6.forEach(t),Qxr=i(zl),qr=n(zl,"DIV",{class:!0});var Wl=s(qr);T(ux.$$.fragment,Wl),Hxr=i(Wl),hEe=n(Wl,"P",{});var J$t=s(hEe);Uxr=r(J$t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),J$t.forEach(t),Jxr=i(Wl),un=n(Wl,"P",{});var z6=s(un);Yxr=r(z6,"The model class to instantiate is selected based on the "),pEe=n(z6,"CODE",{});var Y$t=s(pEe);Kxr=r(Y$t,"model_type"),Y$t.forEach(t),Zxr=r(z6,` property of the config object (either
passed as an argument or loaded from `),uEe=n(z6,"CODE",{});var K$t=s(uEe);e$r=r(K$t,"pretrained_model_name_or_path"),K$t.forEach(t),o$r=r(z6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ee=n(z6,"CODE",{});var Z$t=s(_Ee);r$r=r(Z$t,"pretrained_model_name_or_path"),Z$t.forEach(t),t$r=r(z6,":"),z6.forEach(t),a$r=i(Wl),ce=n(Wl,"UL",{});var ge=s(ce);GC=n(ge,"LI",{});var Uqe=s(GC);bEe=n(Uqe,"STRONG",{});var ekt=s(bEe);n$r=r(ekt,"albert"),ekt.forEach(t),s$r=r(Uqe," \u2014 "),JY=n(Uqe,"A",{href:!0});var okt=s(JY);l$r=r(okt,"TFAlbertForQuestionAnswering"),okt.forEach(t),i$r=r(Uqe," (ALBERT model)"),Uqe.forEach(t),d$r=i(ge),OC=n(ge,"LI",{});var Jqe=s(OC);vEe=n(Jqe,"STRONG",{});var rkt=s(vEe);c$r=r(rkt,"bert"),rkt.forEach(t),f$r=r(Jqe," \u2014 "),YY=n(Jqe,"A",{href:!0});var tkt=s(YY);m$r=r(tkt,"TFBertForQuestionAnswering"),tkt.forEach(t),g$r=r(Jqe," (BERT model)"),Jqe.forEach(t),h$r=i(ge),VC=n(ge,"LI",{});var Yqe=s(VC);FEe=n(Yqe,"STRONG",{});var akt=s(FEe);p$r=r(akt,"camembert"),akt.forEach(t),u$r=r(Yqe," \u2014 "),KY=n(Yqe,"A",{href:!0});var nkt=s(KY);_$r=r(nkt,"TFCamembertForQuestionAnswering"),nkt.forEach(t),b$r=r(Yqe," (CamemBERT model)"),Yqe.forEach(t),v$r=i(ge),XC=n(ge,"LI",{});var Kqe=s(XC);TEe=n(Kqe,"STRONG",{});var skt=s(TEe);F$r=r(skt,"convbert"),skt.forEach(t),T$r=r(Kqe," \u2014 "),ZY=n(Kqe,"A",{href:!0});var lkt=s(ZY);M$r=r(lkt,"TFConvBertForQuestionAnswering"),lkt.forEach(t),E$r=r(Kqe," (ConvBERT model)"),Kqe.forEach(t),C$r=i(ge),zC=n(ge,"LI",{});var Zqe=s(zC);MEe=n(Zqe,"STRONG",{});var ikt=s(MEe);w$r=r(ikt,"deberta"),ikt.forEach(t),A$r=r(Zqe," \u2014 "),eK=n(Zqe,"A",{href:!0});var dkt=s(eK);L$r=r(dkt,"TFDebertaForQuestionAnswering"),dkt.forEach(t),y$r=r(Zqe," (DeBERTa model)"),Zqe.forEach(t),x$r=i(ge),WC=n(ge,"LI",{});var eje=s(WC);EEe=n(eje,"STRONG",{});var ckt=s(EEe);$$r=r(ckt,"deberta-v2"),ckt.forEach(t),k$r=r(eje," \u2014 "),oK=n(eje,"A",{href:!0});var fkt=s(oK);S$r=r(fkt,"TFDebertaV2ForQuestionAnswering"),fkt.forEach(t),R$r=r(eje," (DeBERTa-v2 model)"),eje.forEach(t),P$r=i(ge),QC=n(ge,"LI",{});var oje=s(QC);CEe=n(oje,"STRONG",{});var mkt=s(CEe);B$r=r(mkt,"distilbert"),mkt.forEach(t),I$r=r(oje," \u2014 "),rK=n(oje,"A",{href:!0});var gkt=s(rK);N$r=r(gkt,"TFDistilBertForQuestionAnswering"),gkt.forEach(t),q$r=r(oje," (DistilBERT model)"),oje.forEach(t),j$r=i(ge),HC=n(ge,"LI",{});var rje=s(HC);wEe=n(rje,"STRONG",{});var hkt=s(wEe);D$r=r(hkt,"electra"),hkt.forEach(t),G$r=r(rje," \u2014 "),tK=n(rje,"A",{href:!0});var pkt=s(tK);O$r=r(pkt,"TFElectraForQuestionAnswering"),pkt.forEach(t),V$r=r(rje," (ELECTRA model)"),rje.forEach(t),X$r=i(ge),UC=n(ge,"LI",{});var tje=s(UC);AEe=n(tje,"STRONG",{});var ukt=s(AEe);z$r=r(ukt,"flaubert"),ukt.forEach(t),W$r=r(tje," \u2014 "),aK=n(tje,"A",{href:!0});var _kt=s(aK);Q$r=r(_kt,"TFFlaubertForQuestionAnsweringSimple"),_kt.forEach(t),H$r=r(tje," (FlauBERT model)"),tje.forEach(t),U$r=i(ge),JC=n(ge,"LI",{});var aje=s(JC);LEe=n(aje,"STRONG",{});var bkt=s(LEe);J$r=r(bkt,"funnel"),bkt.forEach(t),Y$r=r(aje," \u2014 "),nK=n(aje,"A",{href:!0});var vkt=s(nK);K$r=r(vkt,"TFFunnelForQuestionAnswering"),vkt.forEach(t),Z$r=r(aje," (Funnel Transformer model)"),aje.forEach(t),ekr=i(ge),YC=n(ge,"LI",{});var nje=s(YC);yEe=n(nje,"STRONG",{});var Fkt=s(yEe);okr=r(Fkt,"gptj"),Fkt.forEach(t),rkr=r(nje," \u2014 "),sK=n(nje,"A",{href:!0});var Tkt=s(sK);tkr=r(Tkt,"TFGPTJForQuestionAnswering"),Tkt.forEach(t),akr=r(nje," (GPT-J model)"),nje.forEach(t),nkr=i(ge),KC=n(ge,"LI",{});var sje=s(KC);xEe=n(sje,"STRONG",{});var Mkt=s(xEe);skr=r(Mkt,"longformer"),Mkt.forEach(t),lkr=r(sje," \u2014 "),lK=n(sje,"A",{href:!0});var Ekt=s(lK);ikr=r(Ekt,"TFLongformerForQuestionAnswering"),Ekt.forEach(t),dkr=r(sje," (Longformer model)"),sje.forEach(t),ckr=i(ge),ZC=n(ge,"LI",{});var lje=s(ZC);$Ee=n(lje,"STRONG",{});var Ckt=s($Ee);fkr=r(Ckt,"mobilebert"),Ckt.forEach(t),mkr=r(lje," \u2014 "),iK=n(lje,"A",{href:!0});var wkt=s(iK);gkr=r(wkt,"TFMobileBertForQuestionAnswering"),wkt.forEach(t),hkr=r(lje," (MobileBERT model)"),lje.forEach(t),pkr=i(ge),e5=n(ge,"LI",{});var ije=s(e5);kEe=n(ije,"STRONG",{});var Akt=s(kEe);ukr=r(Akt,"mpnet"),Akt.forEach(t),_kr=r(ije," \u2014 "),dK=n(ije,"A",{href:!0});var Lkt=s(dK);bkr=r(Lkt,"TFMPNetForQuestionAnswering"),Lkt.forEach(t),vkr=r(ije," (MPNet model)"),ije.forEach(t),Fkr=i(ge),o5=n(ge,"LI",{});var dje=s(o5);SEe=n(dje,"STRONG",{});var ykt=s(SEe);Tkr=r(ykt,"rembert"),ykt.forEach(t),Mkr=r(dje," \u2014 "),cK=n(dje,"A",{href:!0});var xkt=s(cK);Ekr=r(xkt,"TFRemBertForQuestionAnswering"),xkt.forEach(t),Ckr=r(dje," (RemBERT model)"),dje.forEach(t),wkr=i(ge),r5=n(ge,"LI",{});var cje=s(r5);REe=n(cje,"STRONG",{});var $kt=s(REe);Akr=r($kt,"roberta"),$kt.forEach(t),Lkr=r(cje," \u2014 "),fK=n(cje,"A",{href:!0});var kkt=s(fK);ykr=r(kkt,"TFRobertaForQuestionAnswering"),kkt.forEach(t),xkr=r(cje," (RoBERTa model)"),cje.forEach(t),$kr=i(ge),t5=n(ge,"LI",{});var fje=s(t5);PEe=n(fje,"STRONG",{});var Skt=s(PEe);kkr=r(Skt,"roformer"),Skt.forEach(t),Skr=r(fje," \u2014 "),mK=n(fje,"A",{href:!0});var Rkt=s(mK);Rkr=r(Rkt,"TFRoFormerForQuestionAnswering"),Rkt.forEach(t),Pkr=r(fje," (RoFormer model)"),fje.forEach(t),Bkr=i(ge),a5=n(ge,"LI",{});var mje=s(a5);BEe=n(mje,"STRONG",{});var Pkt=s(BEe);Ikr=r(Pkt,"xlm"),Pkt.forEach(t),Nkr=r(mje," \u2014 "),gK=n(mje,"A",{href:!0});var Bkt=s(gK);qkr=r(Bkt,"TFXLMForQuestionAnsweringSimple"),Bkt.forEach(t),jkr=r(mje," (XLM model)"),mje.forEach(t),Dkr=i(ge),n5=n(ge,"LI",{});var gje=s(n5);IEe=n(gje,"STRONG",{});var Ikt=s(IEe);Gkr=r(Ikt,"xlm-roberta"),Ikt.forEach(t),Okr=r(gje," \u2014 "),hK=n(gje,"A",{href:!0});var Nkt=s(hK);Vkr=r(Nkt,"TFXLMRobertaForQuestionAnswering"),Nkt.forEach(t),Xkr=r(gje," (XLM-RoBERTa model)"),gje.forEach(t),zkr=i(ge),s5=n(ge,"LI",{});var hje=s(s5);NEe=n(hje,"STRONG",{});var qkt=s(NEe);Wkr=r(qkt,"xlnet"),qkt.forEach(t),Qkr=r(hje," \u2014 "),pK=n(hje,"A",{href:!0});var jkt=s(pK);Hkr=r(jkt,"TFXLNetForQuestionAnsweringSimple"),jkt.forEach(t),Ukr=r(hje," (XLNet model)"),hje.forEach(t),ge.forEach(t),Jkr=i(Wl),T(l5.$$.fragment,Wl),Wl.forEach(t),zl.forEach(t),JOe=i(f),Ic=n(f,"H2",{class:!0});var nze=s(Ic);i5=n(nze,"A",{id:!0,class:!0,href:!0});var Dkt=s(i5);qEe=n(Dkt,"SPAN",{});var Gkt=s(qEe);T(_x.$$.fragment,Gkt),Gkt.forEach(t),Dkt.forEach(t),Ykr=i(nze),jEe=n(nze,"SPAN",{});var Okt=s(jEe);Kkr=r(Okt,"TFAutoModelForVision2Seq"),Okt.forEach(t),nze.forEach(t),YOe=i(f),fr=n(f,"DIV",{class:!0});var Ql=s(fr);T(bx.$$.fragment,Ql),Zkr=i(Ql),Nc=n(Ql,"P",{});var yre=s(Nc);eSr=r(yre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),uK=n(yre,"A",{href:!0});var Vkt=s(uK);oSr=r(Vkt,"from_pretrained()"),Vkt.forEach(t),rSr=r(yre," class method or the "),_K=n(yre,"A",{href:!0});var Xkt=s(_K);tSr=r(Xkt,"from_config()"),Xkt.forEach(t),aSr=r(yre,` class
method.`),yre.forEach(t),nSr=i(Ql),vx=n(Ql,"P",{});var sze=s(vx);sSr=r(sze,"This class cannot be instantiated directly using "),DEe=n(sze,"CODE",{});var zkt=s(DEe);lSr=r(zkt,"__init__()"),zkt.forEach(t),iSr=r(sze," (throws an error)."),sze.forEach(t),dSr=i(Ql),Ot=n(Ql,"DIV",{class:!0});var W6=s(Ot);T(Fx.$$.fragment,W6),cSr=i(W6),GEe=n(W6,"P",{});var Wkt=s(GEe);fSr=r(Wkt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Wkt.forEach(t),mSr=i(W6),qc=n(W6,"P",{});var xre=s(qc);gSr=r(xre,`Note:
Loading a model from its configuration file does `),OEe=n(xre,"STRONG",{});var Qkt=s(OEe);hSr=r(Qkt,"not"),Qkt.forEach(t),pSr=r(xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=n(xre,"A",{href:!0});var Hkt=s(bK);uSr=r(Hkt,"from_pretrained()"),Hkt.forEach(t),_Sr=r(xre," to load the model weights."),xre.forEach(t),bSr=i(W6),T(d5.$$.fragment,W6),W6.forEach(t),vSr=i(Ql),jr=n(Ql,"DIV",{class:!0});var Hl=s(jr);T(Tx.$$.fragment,Hl),FSr=i(Hl),VEe=n(Hl,"P",{});var Ukt=s(VEe);TSr=r(Ukt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Ukt.forEach(t),MSr=i(Hl),_n=n(Hl,"P",{});var Q6=s(_n);ESr=r(Q6,"The model class to instantiate is selected based on the "),XEe=n(Q6,"CODE",{});var Jkt=s(XEe);CSr=r(Jkt,"model_type"),Jkt.forEach(t),wSr=r(Q6,` property of the config object (either
passed as an argument or loaded from `),zEe=n(Q6,"CODE",{});var Ykt=s(zEe);ASr=r(Ykt,"pretrained_model_name_or_path"),Ykt.forEach(t),LSr=r(Q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WEe=n(Q6,"CODE",{});var Kkt=s(WEe);ySr=r(Kkt,"pretrained_model_name_or_path"),Kkt.forEach(t),xSr=r(Q6,":"),Q6.forEach(t),$Sr=i(Hl),QEe=n(Hl,"UL",{});var Zkt=s(QEe);c5=n(Zkt,"LI",{});var pje=s(c5);HEe=n(pje,"STRONG",{});var eSt=s(HEe);kSr=r(eSt,"vision-encoder-decoder"),eSt.forEach(t),SSr=r(pje," \u2014 "),vK=n(pje,"A",{href:!0});var oSt=s(vK);RSr=r(oSt,"TFVisionEncoderDecoderModel"),oSt.forEach(t),PSr=r(pje," (Vision Encoder decoder model)"),pje.forEach(t),Zkt.forEach(t),BSr=i(Hl),T(f5.$$.fragment,Hl),Hl.forEach(t),Ql.forEach(t),KOe=i(f),jc=n(f,"H2",{class:!0});var lze=s(jc);m5=n(lze,"A",{id:!0,class:!0,href:!0});var rSt=s(m5);UEe=n(rSt,"SPAN",{});var tSt=s(UEe);T(Mx.$$.fragment,tSt),tSt.forEach(t),rSt.forEach(t),ISr=i(lze),JEe=n(lze,"SPAN",{});var aSt=s(JEe);NSr=r(aSt,"TFAutoModelForSpeechSeq2Seq"),aSt.forEach(t),lze.forEach(t),ZOe=i(f),mr=n(f,"DIV",{class:!0});var Ul=s(mr);T(Ex.$$.fragment,Ul),qSr=i(Ul),Dc=n(Ul,"P",{});var $re=s(Dc);jSr=r($re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),FK=n($re,"A",{href:!0});var nSt=s(FK);DSr=r(nSt,"from_pretrained()"),nSt.forEach(t),GSr=r($re," class method or the "),TK=n($re,"A",{href:!0});var sSt=s(TK);OSr=r(sSt,"from_config()"),sSt.forEach(t),VSr=r($re,` class
method.`),$re.forEach(t),XSr=i(Ul),Cx=n(Ul,"P",{});var ize=s(Cx);zSr=r(ize,"This class cannot be instantiated directly using "),YEe=n(ize,"CODE",{});var lSt=s(YEe);WSr=r(lSt,"__init__()"),lSt.forEach(t),QSr=r(ize," (throws an error)."),ize.forEach(t),HSr=i(Ul),Vt=n(Ul,"DIV",{class:!0});var H6=s(Vt);T(wx.$$.fragment,H6),USr=i(H6),KEe=n(H6,"P",{});var iSt=s(KEe);JSr=r(iSt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),iSt.forEach(t),YSr=i(H6),Gc=n(H6,"P",{});var kre=s(Gc);KSr=r(kre,`Note:
Loading a model from its configuration file does `),ZEe=n(kre,"STRONG",{});var dSt=s(ZEe);ZSr=r(dSt,"not"),dSt.forEach(t),eRr=r(kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),MK=n(kre,"A",{href:!0});var cSt=s(MK);oRr=r(cSt,"from_pretrained()"),cSt.forEach(t),rRr=r(kre," to load the model weights."),kre.forEach(t),tRr=i(H6),T(g5.$$.fragment,H6),H6.forEach(t),aRr=i(Ul),Dr=n(Ul,"DIV",{class:!0});var Jl=s(Dr);T(Ax.$$.fragment,Jl),nRr=i(Jl),e4e=n(Jl,"P",{});var fSt=s(e4e);sRr=r(fSt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),fSt.forEach(t),lRr=i(Jl),bn=n(Jl,"P",{});var U6=s(bn);iRr=r(U6,"The model class to instantiate is selected based on the "),o4e=n(U6,"CODE",{});var mSt=s(o4e);dRr=r(mSt,"model_type"),mSt.forEach(t),cRr=r(U6,` property of the config object (either
passed as an argument or loaded from `),r4e=n(U6,"CODE",{});var gSt=s(r4e);fRr=r(gSt,"pretrained_model_name_or_path"),gSt.forEach(t),mRr=r(U6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t4e=n(U6,"CODE",{});var hSt=s(t4e);gRr=r(hSt,"pretrained_model_name_or_path"),hSt.forEach(t),hRr=r(U6,":"),U6.forEach(t),pRr=i(Jl),a4e=n(Jl,"UL",{});var pSt=s(a4e);h5=n(pSt,"LI",{});var uje=s(h5);n4e=n(uje,"STRONG",{});var uSt=s(n4e);uRr=r(uSt,"speech_to_text"),uSt.forEach(t),_Rr=r(uje," \u2014 "),EK=n(uje,"A",{href:!0});var _St=s(EK);bRr=r(_St,"TFSpeech2TextForConditionalGeneration"),_St.forEach(t),vRr=r(uje," (Speech2Text model)"),uje.forEach(t),pSt.forEach(t),FRr=i(Jl),T(p5.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),eVe=i(f),Oc=n(f,"H2",{class:!0});var dze=s(Oc);u5=n(dze,"A",{id:!0,class:!0,href:!0});var bSt=s(u5);s4e=n(bSt,"SPAN",{});var vSt=s(s4e);T(Lx.$$.fragment,vSt),vSt.forEach(t),bSt.forEach(t),TRr=i(dze),l4e=n(dze,"SPAN",{});var FSt=s(l4e);MRr=r(FSt,"FlaxAutoModel"),FSt.forEach(t),dze.forEach(t),oVe=i(f),gr=n(f,"DIV",{class:!0});var Yl=s(gr);T(yx.$$.fragment,Yl),ERr=i(Yl),Vc=n(Yl,"P",{});var Sre=s(Vc);CRr=r(Sre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),CK=n(Sre,"A",{href:!0});var TSt=s(CK);wRr=r(TSt,"from_pretrained()"),TSt.forEach(t),ARr=r(Sre," class method or the "),wK=n(Sre,"A",{href:!0});var MSt=s(wK);LRr=r(MSt,"from_config()"),MSt.forEach(t),yRr=r(Sre,` class
method.`),Sre.forEach(t),xRr=i(Yl),xx=n(Yl,"P",{});var cze=s(xx);$Rr=r(cze,"This class cannot be instantiated directly using "),i4e=n(cze,"CODE",{});var ESt=s(i4e);kRr=r(ESt,"__init__()"),ESt.forEach(t),SRr=r(cze," (throws an error)."),cze.forEach(t),RRr=i(Yl),Xt=n(Yl,"DIV",{class:!0});var J6=s(Xt);T($x.$$.fragment,J6),PRr=i(J6),d4e=n(J6,"P",{});var CSt=s(d4e);BRr=r(CSt,"Instantiates one of the base model classes of the library from a configuration."),CSt.forEach(t),IRr=i(J6),Xc=n(J6,"P",{});var Rre=s(Xc);NRr=r(Rre,`Note:
Loading a model from its configuration file does `),c4e=n(Rre,"STRONG",{});var wSt=s(c4e);qRr=r(wSt,"not"),wSt.forEach(t),jRr=r(Rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),AK=n(Rre,"A",{href:!0});var ASt=s(AK);DRr=r(ASt,"from_pretrained()"),ASt.forEach(t),GRr=r(Rre," to load the model weights."),Rre.forEach(t),ORr=i(J6),T(_5.$$.fragment,J6),J6.forEach(t),VRr=i(Yl),Gr=n(Yl,"DIV",{class:!0});var Kl=s(Gr);T(kx.$$.fragment,Kl),XRr=i(Kl),f4e=n(Kl,"P",{});var LSt=s(f4e);zRr=r(LSt,"Instantiate one of the base model classes of the library from a pretrained model."),LSt.forEach(t),WRr=i(Kl),vn=n(Kl,"P",{});var Y6=s(vn);QRr=r(Y6,"The model class to instantiate is selected based on the "),m4e=n(Y6,"CODE",{});var ySt=s(m4e);HRr=r(ySt,"model_type"),ySt.forEach(t),URr=r(Y6,` property of the config object (either
passed as an argument or loaded from `),g4e=n(Y6,"CODE",{});var xSt=s(g4e);JRr=r(xSt,"pretrained_model_name_or_path"),xSt.forEach(t),YRr=r(Y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h4e=n(Y6,"CODE",{});var $St=s(h4e);KRr=r($St,"pretrained_model_name_or_path"),$St.forEach(t),ZRr=r(Y6,":"),Y6.forEach(t),ePr=i(Kl),oe=n(Kl,"UL",{});var ae=s(oe);b5=n(ae,"LI",{});var _je=s(b5);p4e=n(_je,"STRONG",{});var kSt=s(p4e);oPr=r(kSt,"albert"),kSt.forEach(t),rPr=r(_je," \u2014 "),LK=n(_je,"A",{href:!0});var SSt=s(LK);tPr=r(SSt,"FlaxAlbertModel"),SSt.forEach(t),aPr=r(_je," (ALBERT model)"),_je.forEach(t),nPr=i(ae),v5=n(ae,"LI",{});var bje=s(v5);u4e=n(bje,"STRONG",{});var RSt=s(u4e);sPr=r(RSt,"bart"),RSt.forEach(t),lPr=r(bje," \u2014 "),yK=n(bje,"A",{href:!0});var PSt=s(yK);iPr=r(PSt,"FlaxBartModel"),PSt.forEach(t),dPr=r(bje," (BART model)"),bje.forEach(t),cPr=i(ae),F5=n(ae,"LI",{});var vje=s(F5);_4e=n(vje,"STRONG",{});var BSt=s(_4e);fPr=r(BSt,"beit"),BSt.forEach(t),mPr=r(vje," \u2014 "),xK=n(vje,"A",{href:!0});var ISt=s(xK);gPr=r(ISt,"FlaxBeitModel"),ISt.forEach(t),hPr=r(vje," (BEiT model)"),vje.forEach(t),pPr=i(ae),T5=n(ae,"LI",{});var Fje=s(T5);b4e=n(Fje,"STRONG",{});var NSt=s(b4e);uPr=r(NSt,"bert"),NSt.forEach(t),_Pr=r(Fje," \u2014 "),$K=n(Fje,"A",{href:!0});var qSt=s($K);bPr=r(qSt,"FlaxBertModel"),qSt.forEach(t),vPr=r(Fje," (BERT model)"),Fje.forEach(t),FPr=i(ae),M5=n(ae,"LI",{});var Tje=s(M5);v4e=n(Tje,"STRONG",{});var jSt=s(v4e);TPr=r(jSt,"big_bird"),jSt.forEach(t),MPr=r(Tje," \u2014 "),kK=n(Tje,"A",{href:!0});var DSt=s(kK);EPr=r(DSt,"FlaxBigBirdModel"),DSt.forEach(t),CPr=r(Tje," (BigBird model)"),Tje.forEach(t),wPr=i(ae),E5=n(ae,"LI",{});var Mje=s(E5);F4e=n(Mje,"STRONG",{});var GSt=s(F4e);APr=r(GSt,"blenderbot"),GSt.forEach(t),LPr=r(Mje," \u2014 "),SK=n(Mje,"A",{href:!0});var OSt=s(SK);yPr=r(OSt,"FlaxBlenderbotModel"),OSt.forEach(t),xPr=r(Mje," (Blenderbot model)"),Mje.forEach(t),$Pr=i(ae),C5=n(ae,"LI",{});var Eje=s(C5);T4e=n(Eje,"STRONG",{});var VSt=s(T4e);kPr=r(VSt,"blenderbot-small"),VSt.forEach(t),SPr=r(Eje," \u2014 "),RK=n(Eje,"A",{href:!0});var XSt=s(RK);RPr=r(XSt,"FlaxBlenderbotSmallModel"),XSt.forEach(t),PPr=r(Eje," (BlenderbotSmall model)"),Eje.forEach(t),BPr=i(ae),w5=n(ae,"LI",{});var Cje=s(w5);M4e=n(Cje,"STRONG",{});var zSt=s(M4e);IPr=r(zSt,"clip"),zSt.forEach(t),NPr=r(Cje," \u2014 "),PK=n(Cje,"A",{href:!0});var WSt=s(PK);qPr=r(WSt,"FlaxCLIPModel"),WSt.forEach(t),jPr=r(Cje," (CLIP model)"),Cje.forEach(t),DPr=i(ae),A5=n(ae,"LI",{});var wje=s(A5);E4e=n(wje,"STRONG",{});var QSt=s(E4e);GPr=r(QSt,"distilbert"),QSt.forEach(t),OPr=r(wje," \u2014 "),BK=n(wje,"A",{href:!0});var HSt=s(BK);VPr=r(HSt,"FlaxDistilBertModel"),HSt.forEach(t),XPr=r(wje," (DistilBERT model)"),wje.forEach(t),zPr=i(ae),L5=n(ae,"LI",{});var Aje=s(L5);C4e=n(Aje,"STRONG",{});var USt=s(C4e);WPr=r(USt,"electra"),USt.forEach(t),QPr=r(Aje," \u2014 "),IK=n(Aje,"A",{href:!0});var JSt=s(IK);HPr=r(JSt,"FlaxElectraModel"),JSt.forEach(t),UPr=r(Aje," (ELECTRA model)"),Aje.forEach(t),JPr=i(ae),y5=n(ae,"LI",{});var Lje=s(y5);w4e=n(Lje,"STRONG",{});var YSt=s(w4e);YPr=r(YSt,"gpt2"),YSt.forEach(t),KPr=r(Lje," \u2014 "),NK=n(Lje,"A",{href:!0});var KSt=s(NK);ZPr=r(KSt,"FlaxGPT2Model"),KSt.forEach(t),eBr=r(Lje," (OpenAI GPT-2 model)"),Lje.forEach(t),oBr=i(ae),x5=n(ae,"LI",{});var yje=s(x5);A4e=n(yje,"STRONG",{});var ZSt=s(A4e);rBr=r(ZSt,"gpt_neo"),ZSt.forEach(t),tBr=r(yje," \u2014 "),qK=n(yje,"A",{href:!0});var eRt=s(qK);aBr=r(eRt,"FlaxGPTNeoModel"),eRt.forEach(t),nBr=r(yje," (GPT Neo model)"),yje.forEach(t),sBr=i(ae),$5=n(ae,"LI",{});var xje=s($5);L4e=n(xje,"STRONG",{});var oRt=s(L4e);lBr=r(oRt,"gptj"),oRt.forEach(t),iBr=r(xje," \u2014 "),jK=n(xje,"A",{href:!0});var rRt=s(jK);dBr=r(rRt,"FlaxGPTJModel"),rRt.forEach(t),cBr=r(xje," (GPT-J model)"),xje.forEach(t),fBr=i(ae),k5=n(ae,"LI",{});var $je=s(k5);y4e=n($je,"STRONG",{});var tRt=s(y4e);mBr=r(tRt,"longt5"),tRt.forEach(t),gBr=r($je," \u2014 "),DK=n($je,"A",{href:!0});var aRt=s(DK);hBr=r(aRt,"FlaxLongT5Model"),aRt.forEach(t),pBr=r($je," (LongT5 model)"),$je.forEach(t),uBr=i(ae),S5=n(ae,"LI",{});var kje=s(S5);x4e=n(kje,"STRONG",{});var nRt=s(x4e);_Br=r(nRt,"marian"),nRt.forEach(t),bBr=r(kje," \u2014 "),GK=n(kje,"A",{href:!0});var sRt=s(GK);vBr=r(sRt,"FlaxMarianModel"),sRt.forEach(t),FBr=r(kje," (Marian model)"),kje.forEach(t),TBr=i(ae),R5=n(ae,"LI",{});var Sje=s(R5);$4e=n(Sje,"STRONG",{});var lRt=s($4e);MBr=r(lRt,"mbart"),lRt.forEach(t),EBr=r(Sje," \u2014 "),OK=n(Sje,"A",{href:!0});var iRt=s(OK);CBr=r(iRt,"FlaxMBartModel"),iRt.forEach(t),wBr=r(Sje," (mBART model)"),Sje.forEach(t),ABr=i(ae),P5=n(ae,"LI",{});var Rje=s(P5);k4e=n(Rje,"STRONG",{});var dRt=s(k4e);LBr=r(dRt,"mt5"),dRt.forEach(t),yBr=r(Rje," \u2014 "),VK=n(Rje,"A",{href:!0});var cRt=s(VK);xBr=r(cRt,"FlaxMT5Model"),cRt.forEach(t),$Br=r(Rje," (MT5 model)"),Rje.forEach(t),kBr=i(ae),B5=n(ae,"LI",{});var Pje=s(B5);S4e=n(Pje,"STRONG",{});var fRt=s(S4e);SBr=r(fRt,"opt"),fRt.forEach(t),RBr=r(Pje," \u2014 "),XK=n(Pje,"A",{href:!0});var mRt=s(XK);PBr=r(mRt,"FlaxOPTModel"),mRt.forEach(t),BBr=r(Pje," (OPT model)"),Pje.forEach(t),IBr=i(ae),I5=n(ae,"LI",{});var Bje=s(I5);R4e=n(Bje,"STRONG",{});var gRt=s(R4e);NBr=r(gRt,"pegasus"),gRt.forEach(t),qBr=r(Bje," \u2014 "),zK=n(Bje,"A",{href:!0});var hRt=s(zK);jBr=r(hRt,"FlaxPegasusModel"),hRt.forEach(t),DBr=r(Bje," (Pegasus model)"),Bje.forEach(t),GBr=i(ae),N5=n(ae,"LI",{});var Ije=s(N5);P4e=n(Ije,"STRONG",{});var pRt=s(P4e);OBr=r(pRt,"roberta"),pRt.forEach(t),VBr=r(Ije," \u2014 "),WK=n(Ije,"A",{href:!0});var uRt=s(WK);XBr=r(uRt,"FlaxRobertaModel"),uRt.forEach(t),zBr=r(Ije," (RoBERTa model)"),Ije.forEach(t),WBr=i(ae),q5=n(ae,"LI",{});var Nje=s(q5);B4e=n(Nje,"STRONG",{});var _Rt=s(B4e);QBr=r(_Rt,"roformer"),_Rt.forEach(t),HBr=r(Nje," \u2014 "),QK=n(Nje,"A",{href:!0});var bRt=s(QK);UBr=r(bRt,"FlaxRoFormerModel"),bRt.forEach(t),JBr=r(Nje," (RoFormer model)"),Nje.forEach(t),YBr=i(ae),j5=n(ae,"LI",{});var qje=s(j5);I4e=n(qje,"STRONG",{});var vRt=s(I4e);KBr=r(vRt,"t5"),vRt.forEach(t),ZBr=r(qje," \u2014 "),HK=n(qje,"A",{href:!0});var FRt=s(HK);eIr=r(FRt,"FlaxT5Model"),FRt.forEach(t),oIr=r(qje," (T5 model)"),qje.forEach(t),rIr=i(ae),D5=n(ae,"LI",{});var jje=s(D5);N4e=n(jje,"STRONG",{});var TRt=s(N4e);tIr=r(TRt,"vision-text-dual-encoder"),TRt.forEach(t),aIr=r(jje," \u2014 "),UK=n(jje,"A",{href:!0});var MRt=s(UK);nIr=r(MRt,"FlaxVisionTextDualEncoderModel"),MRt.forEach(t),sIr=r(jje," (VisionTextDualEncoder model)"),jje.forEach(t),lIr=i(ae),G5=n(ae,"LI",{});var Dje=s(G5);q4e=n(Dje,"STRONG",{});var ERt=s(q4e);iIr=r(ERt,"vit"),ERt.forEach(t),dIr=r(Dje," \u2014 "),JK=n(Dje,"A",{href:!0});var CRt=s(JK);cIr=r(CRt,"FlaxViTModel"),CRt.forEach(t),fIr=r(Dje," (ViT model)"),Dje.forEach(t),mIr=i(ae),O5=n(ae,"LI",{});var Gje=s(O5);j4e=n(Gje,"STRONG",{});var wRt=s(j4e);gIr=r(wRt,"wav2vec2"),wRt.forEach(t),hIr=r(Gje," \u2014 "),YK=n(Gje,"A",{href:!0});var ARt=s(YK);pIr=r(ARt,"FlaxWav2Vec2Model"),ARt.forEach(t),uIr=r(Gje," (Wav2Vec2 model)"),Gje.forEach(t),_Ir=i(ae),V5=n(ae,"LI",{});var Oje=s(V5);D4e=n(Oje,"STRONG",{});var LRt=s(D4e);bIr=r(LRt,"xglm"),LRt.forEach(t),vIr=r(Oje," \u2014 "),KK=n(Oje,"A",{href:!0});var yRt=s(KK);FIr=r(yRt,"FlaxXGLMModel"),yRt.forEach(t),TIr=r(Oje," (XGLM model)"),Oje.forEach(t),MIr=i(ae),X5=n(ae,"LI",{});var Vje=s(X5);G4e=n(Vje,"STRONG",{});var xRt=s(G4e);EIr=r(xRt,"xlm-roberta"),xRt.forEach(t),CIr=r(Vje," \u2014 "),ZK=n(Vje,"A",{href:!0});var $Rt=s(ZK);wIr=r($Rt,"FlaxXLMRobertaModel"),$Rt.forEach(t),AIr=r(Vje," (XLM-RoBERTa model)"),Vje.forEach(t),ae.forEach(t),LIr=i(Kl),T(z5.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),rVe=i(f),zc=n(f,"H2",{class:!0});var fze=s(zc);W5=n(fze,"A",{id:!0,class:!0,href:!0});var kRt=s(W5);O4e=n(kRt,"SPAN",{});var SRt=s(O4e);T(Sx.$$.fragment,SRt),SRt.forEach(t),kRt.forEach(t),yIr=i(fze),V4e=n(fze,"SPAN",{});var RRt=s(V4e);xIr=r(RRt,"FlaxAutoModelForCausalLM"),RRt.forEach(t),fze.forEach(t),tVe=i(f),hr=n(f,"DIV",{class:!0});var Zl=s(hr);T(Rx.$$.fragment,Zl),$Ir=i(Zl),Wc=n(Zl,"P",{});var Pre=s(Wc);kIr=r(Pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),eZ=n(Pre,"A",{href:!0});var PRt=s(eZ);SIr=r(PRt,"from_pretrained()"),PRt.forEach(t),RIr=r(Pre," class method or the "),oZ=n(Pre,"A",{href:!0});var BRt=s(oZ);PIr=r(BRt,"from_config()"),BRt.forEach(t),BIr=r(Pre,` class
method.`),Pre.forEach(t),IIr=i(Zl),Px=n(Zl,"P",{});var mze=s(Px);NIr=r(mze,"This class cannot be instantiated directly using "),X4e=n(mze,"CODE",{});var IRt=s(X4e);qIr=r(IRt,"__init__()"),IRt.forEach(t),jIr=r(mze," (throws an error)."),mze.forEach(t),DIr=i(Zl),zt=n(Zl,"DIV",{class:!0});var K6=s(zt);T(Bx.$$.fragment,K6),GIr=i(K6),z4e=n(K6,"P",{});var NRt=s(z4e);OIr=r(NRt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),NRt.forEach(t),VIr=i(K6),Qc=n(K6,"P",{});var Bre=s(Qc);XIr=r(Bre,`Note:
Loading a model from its configuration file does `),W4e=n(Bre,"STRONG",{});var qRt=s(W4e);zIr=r(qRt,"not"),qRt.forEach(t),WIr=r(Bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),rZ=n(Bre,"A",{href:!0});var jRt=s(rZ);QIr=r(jRt,"from_pretrained()"),jRt.forEach(t),HIr=r(Bre," to load the model weights."),Bre.forEach(t),UIr=i(K6),T(Q5.$$.fragment,K6),K6.forEach(t),JIr=i(Zl),Or=n(Zl,"DIV",{class:!0});var ei=s(Or);T(Ix.$$.fragment,ei),YIr=i(ei),Q4e=n(ei,"P",{});var DRt=s(Q4e);KIr=r(DRt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),DRt.forEach(t),ZIr=i(ei),Fn=n(ei,"P",{});var Z6=s(Fn);eNr=r(Z6,"The model class to instantiate is selected based on the "),H4e=n(Z6,"CODE",{});var GRt=s(H4e);oNr=r(GRt,"model_type"),GRt.forEach(t),rNr=r(Z6,` property of the config object (either
passed as an argument or loaded from `),U4e=n(Z6,"CODE",{});var ORt=s(U4e);tNr=r(ORt,"pretrained_model_name_or_path"),ORt.forEach(t),aNr=r(Z6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J4e=n(Z6,"CODE",{});var VRt=s(J4e);nNr=r(VRt,"pretrained_model_name_or_path"),VRt.forEach(t),sNr=r(Z6,":"),Z6.forEach(t),lNr=i(ei),xe=n(ei,"UL",{});var Ne=s(xe);H5=n(Ne,"LI",{});var Xje=s(H5);Y4e=n(Xje,"STRONG",{});var XRt=s(Y4e);iNr=r(XRt,"bart"),XRt.forEach(t),dNr=r(Xje," \u2014 "),tZ=n(Xje,"A",{href:!0});var zRt=s(tZ);cNr=r(zRt,"FlaxBartForCausalLM"),zRt.forEach(t),fNr=r(Xje," (BART model)"),Xje.forEach(t),mNr=i(Ne),U5=n(Ne,"LI",{});var zje=s(U5);K4e=n(zje,"STRONG",{});var WRt=s(K4e);gNr=r(WRt,"bert"),WRt.forEach(t),hNr=r(zje," \u2014 "),aZ=n(zje,"A",{href:!0});var QRt=s(aZ);pNr=r(QRt,"FlaxBertForCausalLM"),QRt.forEach(t),uNr=r(zje," (BERT model)"),zje.forEach(t),_Nr=i(Ne),J5=n(Ne,"LI",{});var Wje=s(J5);Z4e=n(Wje,"STRONG",{});var HRt=s(Z4e);bNr=r(HRt,"big_bird"),HRt.forEach(t),vNr=r(Wje," \u2014 "),nZ=n(Wje,"A",{href:!0});var URt=s(nZ);FNr=r(URt,"FlaxBigBirdForCausalLM"),URt.forEach(t),TNr=r(Wje," (BigBird model)"),Wje.forEach(t),MNr=i(Ne),Y5=n(Ne,"LI",{});var Qje=s(Y5);eCe=n(Qje,"STRONG",{});var JRt=s(eCe);ENr=r(JRt,"electra"),JRt.forEach(t),CNr=r(Qje," \u2014 "),sZ=n(Qje,"A",{href:!0});var YRt=s(sZ);wNr=r(YRt,"FlaxElectraForCausalLM"),YRt.forEach(t),ANr=r(Qje," (ELECTRA model)"),Qje.forEach(t),LNr=i(Ne),K5=n(Ne,"LI",{});var Hje=s(K5);oCe=n(Hje,"STRONG",{});var KRt=s(oCe);yNr=r(KRt,"gpt2"),KRt.forEach(t),xNr=r(Hje," \u2014 "),lZ=n(Hje,"A",{href:!0});var ZRt=s(lZ);$Nr=r(ZRt,"FlaxGPT2LMHeadModel"),ZRt.forEach(t),kNr=r(Hje," (OpenAI GPT-2 model)"),Hje.forEach(t),SNr=i(Ne),Z5=n(Ne,"LI",{});var Uje=s(Z5);rCe=n(Uje,"STRONG",{});var ePt=s(rCe);RNr=r(ePt,"gpt_neo"),ePt.forEach(t),PNr=r(Uje," \u2014 "),iZ=n(Uje,"A",{href:!0});var oPt=s(iZ);BNr=r(oPt,"FlaxGPTNeoForCausalLM"),oPt.forEach(t),INr=r(Uje," (GPT Neo model)"),Uje.forEach(t),NNr=i(Ne),e0=n(Ne,"LI",{});var Jje=s(e0);tCe=n(Jje,"STRONG",{});var rPt=s(tCe);qNr=r(rPt,"gptj"),rPt.forEach(t),jNr=r(Jje," \u2014 "),dZ=n(Jje,"A",{href:!0});var tPt=s(dZ);DNr=r(tPt,"FlaxGPTJForCausalLM"),tPt.forEach(t),GNr=r(Jje," (GPT-J model)"),Jje.forEach(t),ONr=i(Ne),o0=n(Ne,"LI",{});var Yje=s(o0);aCe=n(Yje,"STRONG",{});var aPt=s(aCe);VNr=r(aPt,"opt"),aPt.forEach(t),XNr=r(Yje," \u2014 "),cZ=n(Yje,"A",{href:!0});var nPt=s(cZ);zNr=r(nPt,"FlaxOPTForCausalLM"),nPt.forEach(t),WNr=r(Yje," (OPT model)"),Yje.forEach(t),QNr=i(Ne),r0=n(Ne,"LI",{});var Kje=s(r0);nCe=n(Kje,"STRONG",{});var sPt=s(nCe);HNr=r(sPt,"roberta"),sPt.forEach(t),UNr=r(Kje," \u2014 "),fZ=n(Kje,"A",{href:!0});var lPt=s(fZ);JNr=r(lPt,"FlaxRobertaForCausalLM"),lPt.forEach(t),YNr=r(Kje," (RoBERTa model)"),Kje.forEach(t),KNr=i(Ne),t0=n(Ne,"LI",{});var Zje=s(t0);sCe=n(Zje,"STRONG",{});var iPt=s(sCe);ZNr=r(iPt,"xglm"),iPt.forEach(t),eqr=r(Zje," \u2014 "),mZ=n(Zje,"A",{href:!0});var dPt=s(mZ);oqr=r(dPt,"FlaxXGLMForCausalLM"),dPt.forEach(t),rqr=r(Zje," (XGLM model)"),Zje.forEach(t),Ne.forEach(t),tqr=i(ei),T(a0.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),aVe=i(f),Hc=n(f,"H2",{class:!0});var gze=s(Hc);n0=n(gze,"A",{id:!0,class:!0,href:!0});var cPt=s(n0);lCe=n(cPt,"SPAN",{});var fPt=s(lCe);T(Nx.$$.fragment,fPt),fPt.forEach(t),cPt.forEach(t),aqr=i(gze),iCe=n(gze,"SPAN",{});var mPt=s(iCe);nqr=r(mPt,"FlaxAutoModelForPreTraining"),mPt.forEach(t),gze.forEach(t),nVe=i(f),pr=n(f,"DIV",{class:!0});var oi=s(pr);T(qx.$$.fragment,oi),sqr=i(oi),Uc=n(oi,"P",{});var Ire=s(Uc);lqr=r(Ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gZ=n(Ire,"A",{href:!0});var gPt=s(gZ);iqr=r(gPt,"from_pretrained()"),gPt.forEach(t),dqr=r(Ire," class method or the "),hZ=n(Ire,"A",{href:!0});var hPt=s(hZ);cqr=r(hPt,"from_config()"),hPt.forEach(t),fqr=r(Ire,` class
method.`),Ire.forEach(t),mqr=i(oi),jx=n(oi,"P",{});var hze=s(jx);gqr=r(hze,"This class cannot be instantiated directly using "),dCe=n(hze,"CODE",{});var pPt=s(dCe);hqr=r(pPt,"__init__()"),pPt.forEach(t),pqr=r(hze," (throws an error)."),hze.forEach(t),uqr=i(oi),Wt=n(oi,"DIV",{class:!0});var eL=s(Wt);T(Dx.$$.fragment,eL),_qr=i(eL),cCe=n(eL,"P",{});var uPt=s(cCe);bqr=r(uPt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),uPt.forEach(t),vqr=i(eL),Jc=n(eL,"P",{});var Nre=s(Jc);Fqr=r(Nre,`Note:
Loading a model from its configuration file does `),fCe=n(Nre,"STRONG",{});var _Pt=s(fCe);Tqr=r(_Pt,"not"),_Pt.forEach(t),Mqr=r(Nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),pZ=n(Nre,"A",{href:!0});var bPt=s(pZ);Eqr=r(bPt,"from_pretrained()"),bPt.forEach(t),Cqr=r(Nre," to load the model weights."),Nre.forEach(t),wqr=i(eL),T(s0.$$.fragment,eL),eL.forEach(t),Aqr=i(oi),Vr=n(oi,"DIV",{class:!0});var ri=s(Vr);T(Gx.$$.fragment,ri),Lqr=i(ri),mCe=n(ri,"P",{});var vPt=s(mCe);yqr=r(vPt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),vPt.forEach(t),xqr=i(ri),Tn=n(ri,"P",{});var oL=s(Tn);$qr=r(oL,"The model class to instantiate is selected based on the "),gCe=n(oL,"CODE",{});var FPt=s(gCe);kqr=r(FPt,"model_type"),FPt.forEach(t),Sqr=r(oL,` property of the config object (either
passed as an argument or loaded from `),hCe=n(oL,"CODE",{});var TPt=s(hCe);Rqr=r(TPt,"pretrained_model_name_or_path"),TPt.forEach(t),Pqr=r(oL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pCe=n(oL,"CODE",{});var MPt=s(pCe);Bqr=r(MPt,"pretrained_model_name_or_path"),MPt.forEach(t),Iqr=r(oL,":"),oL.forEach(t),Nqr=i(ri),Ee=n(ri,"UL",{});var we=s(Ee);l0=n(we,"LI",{});var eDe=s(l0);uCe=n(eDe,"STRONG",{});var EPt=s(uCe);qqr=r(EPt,"albert"),EPt.forEach(t),jqr=r(eDe," \u2014 "),uZ=n(eDe,"A",{href:!0});var CPt=s(uZ);Dqr=r(CPt,"FlaxAlbertForPreTraining"),CPt.forEach(t),Gqr=r(eDe," (ALBERT model)"),eDe.forEach(t),Oqr=i(we),i0=n(we,"LI",{});var oDe=s(i0);_Ce=n(oDe,"STRONG",{});var wPt=s(_Ce);Vqr=r(wPt,"bart"),wPt.forEach(t),Xqr=r(oDe," \u2014 "),_Z=n(oDe,"A",{href:!0});var APt=s(_Z);zqr=r(APt,"FlaxBartForConditionalGeneration"),APt.forEach(t),Wqr=r(oDe," (BART model)"),oDe.forEach(t),Qqr=i(we),d0=n(we,"LI",{});var rDe=s(d0);bCe=n(rDe,"STRONG",{});var LPt=s(bCe);Hqr=r(LPt,"bert"),LPt.forEach(t),Uqr=r(rDe," \u2014 "),bZ=n(rDe,"A",{href:!0});var yPt=s(bZ);Jqr=r(yPt,"FlaxBertForPreTraining"),yPt.forEach(t),Yqr=r(rDe," (BERT model)"),rDe.forEach(t),Kqr=i(we),c0=n(we,"LI",{});var tDe=s(c0);vCe=n(tDe,"STRONG",{});var xPt=s(vCe);Zqr=r(xPt,"big_bird"),xPt.forEach(t),ejr=r(tDe," \u2014 "),vZ=n(tDe,"A",{href:!0});var $Pt=s(vZ);ojr=r($Pt,"FlaxBigBirdForPreTraining"),$Pt.forEach(t),rjr=r(tDe," (BigBird model)"),tDe.forEach(t),tjr=i(we),f0=n(we,"LI",{});var aDe=s(f0);FCe=n(aDe,"STRONG",{});var kPt=s(FCe);ajr=r(kPt,"electra"),kPt.forEach(t),njr=r(aDe," \u2014 "),FZ=n(aDe,"A",{href:!0});var SPt=s(FZ);sjr=r(SPt,"FlaxElectraForPreTraining"),SPt.forEach(t),ljr=r(aDe," (ELECTRA model)"),aDe.forEach(t),ijr=i(we),m0=n(we,"LI",{});var nDe=s(m0);TCe=n(nDe,"STRONG",{});var RPt=s(TCe);djr=r(RPt,"longt5"),RPt.forEach(t),cjr=r(nDe," \u2014 "),TZ=n(nDe,"A",{href:!0});var PPt=s(TZ);fjr=r(PPt,"FlaxLongT5ForConditionalGeneration"),PPt.forEach(t),mjr=r(nDe," (LongT5 model)"),nDe.forEach(t),gjr=i(we),g0=n(we,"LI",{});var sDe=s(g0);MCe=n(sDe,"STRONG",{});var BPt=s(MCe);hjr=r(BPt,"mbart"),BPt.forEach(t),pjr=r(sDe," \u2014 "),MZ=n(sDe,"A",{href:!0});var IPt=s(MZ);ujr=r(IPt,"FlaxMBartForConditionalGeneration"),IPt.forEach(t),_jr=r(sDe," (mBART model)"),sDe.forEach(t),bjr=i(we),h0=n(we,"LI",{});var lDe=s(h0);ECe=n(lDe,"STRONG",{});var NPt=s(ECe);vjr=r(NPt,"mt5"),NPt.forEach(t),Fjr=r(lDe," \u2014 "),EZ=n(lDe,"A",{href:!0});var qPt=s(EZ);Tjr=r(qPt,"FlaxMT5ForConditionalGeneration"),qPt.forEach(t),Mjr=r(lDe," (MT5 model)"),lDe.forEach(t),Ejr=i(we),p0=n(we,"LI",{});var iDe=s(p0);CCe=n(iDe,"STRONG",{});var jPt=s(CCe);Cjr=r(jPt,"roberta"),jPt.forEach(t),wjr=r(iDe," \u2014 "),CZ=n(iDe,"A",{href:!0});var DPt=s(CZ);Ajr=r(DPt,"FlaxRobertaForMaskedLM"),DPt.forEach(t),Ljr=r(iDe," (RoBERTa model)"),iDe.forEach(t),yjr=i(we),u0=n(we,"LI",{});var dDe=s(u0);wCe=n(dDe,"STRONG",{});var GPt=s(wCe);xjr=r(GPt,"roformer"),GPt.forEach(t),$jr=r(dDe," \u2014 "),wZ=n(dDe,"A",{href:!0});var OPt=s(wZ);kjr=r(OPt,"FlaxRoFormerForMaskedLM"),OPt.forEach(t),Sjr=r(dDe," (RoFormer model)"),dDe.forEach(t),Rjr=i(we),_0=n(we,"LI",{});var cDe=s(_0);ACe=n(cDe,"STRONG",{});var VPt=s(ACe);Pjr=r(VPt,"t5"),VPt.forEach(t),Bjr=r(cDe," \u2014 "),AZ=n(cDe,"A",{href:!0});var XPt=s(AZ);Ijr=r(XPt,"FlaxT5ForConditionalGeneration"),XPt.forEach(t),Njr=r(cDe," (T5 model)"),cDe.forEach(t),qjr=i(we),b0=n(we,"LI",{});var fDe=s(b0);LCe=n(fDe,"STRONG",{});var zPt=s(LCe);jjr=r(zPt,"wav2vec2"),zPt.forEach(t),Djr=r(fDe," \u2014 "),LZ=n(fDe,"A",{href:!0});var WPt=s(LZ);Gjr=r(WPt,"FlaxWav2Vec2ForPreTraining"),WPt.forEach(t),Ojr=r(fDe," (Wav2Vec2 model)"),fDe.forEach(t),Vjr=i(we),v0=n(we,"LI",{});var mDe=s(v0);yCe=n(mDe,"STRONG",{});var QPt=s(yCe);Xjr=r(QPt,"xlm-roberta"),QPt.forEach(t),zjr=r(mDe," \u2014 "),yZ=n(mDe,"A",{href:!0});var HPt=s(yZ);Wjr=r(HPt,"FlaxXLMRobertaForMaskedLM"),HPt.forEach(t),Qjr=r(mDe," (XLM-RoBERTa model)"),mDe.forEach(t),we.forEach(t),Hjr=i(ri),T(F0.$$.fragment,ri),ri.forEach(t),oi.forEach(t),sVe=i(f),Yc=n(f,"H2",{class:!0});var pze=s(Yc);T0=n(pze,"A",{id:!0,class:!0,href:!0});var UPt=s(T0);xCe=n(UPt,"SPAN",{});var JPt=s(xCe);T(Ox.$$.fragment,JPt),JPt.forEach(t),UPt.forEach(t),Ujr=i(pze),$Ce=n(pze,"SPAN",{});var YPt=s($Ce);Jjr=r(YPt,"FlaxAutoModelForMaskedLM"),YPt.forEach(t),pze.forEach(t),lVe=i(f),ur=n(f,"DIV",{class:!0});var ti=s(ur);T(Vx.$$.fragment,ti),Yjr=i(ti),Kc=n(ti,"P",{});var qre=s(Kc);Kjr=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),xZ=n(qre,"A",{href:!0});var KPt=s(xZ);Zjr=r(KPt,"from_pretrained()"),KPt.forEach(t),eDr=r(qre," class method or the "),$Z=n(qre,"A",{href:!0});var ZPt=s($Z);oDr=r(ZPt,"from_config()"),ZPt.forEach(t),rDr=r(qre,` class
method.`),qre.forEach(t),tDr=i(ti),Xx=n(ti,"P",{});var uze=s(Xx);aDr=r(uze,"This class cannot be instantiated directly using "),kCe=n(uze,"CODE",{});var eBt=s(kCe);nDr=r(eBt,"__init__()"),eBt.forEach(t),sDr=r(uze," (throws an error)."),uze.forEach(t),lDr=i(ti),Qt=n(ti,"DIV",{class:!0});var rL=s(Qt);T(zx.$$.fragment,rL),iDr=i(rL),SCe=n(rL,"P",{});var oBt=s(SCe);dDr=r(oBt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),oBt.forEach(t),cDr=i(rL),Zc=n(rL,"P",{});var jre=s(Zc);fDr=r(jre,`Note:
Loading a model from its configuration file does `),RCe=n(jre,"STRONG",{});var rBt=s(RCe);mDr=r(rBt,"not"),rBt.forEach(t),gDr=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),kZ=n(jre,"A",{href:!0});var tBt=s(kZ);hDr=r(tBt,"from_pretrained()"),tBt.forEach(t),pDr=r(jre," to load the model weights."),jre.forEach(t),uDr=i(rL),T(M0.$$.fragment,rL),rL.forEach(t),_Dr=i(ti),Xr=n(ti,"DIV",{class:!0});var ai=s(Xr);T(Wx.$$.fragment,ai),bDr=i(ai),PCe=n(ai,"P",{});var aBt=s(PCe);vDr=r(aBt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),aBt.forEach(t),FDr=i(ai),Mn=n(ai,"P",{});var tL=s(Mn);TDr=r(tL,"The model class to instantiate is selected based on the "),BCe=n(tL,"CODE",{});var nBt=s(BCe);MDr=r(nBt,"model_type"),nBt.forEach(t),EDr=r(tL,` property of the config object (either
passed as an argument or loaded from `),ICe=n(tL,"CODE",{});var sBt=s(ICe);CDr=r(sBt,"pretrained_model_name_or_path"),sBt.forEach(t),wDr=r(tL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NCe=n(tL,"CODE",{});var lBt=s(NCe);ADr=r(lBt,"pretrained_model_name_or_path"),lBt.forEach(t),LDr=r(tL,":"),tL.forEach(t),yDr=i(ai),$e=n(ai,"UL",{});var qe=s($e);E0=n(qe,"LI",{});var gDe=s(E0);qCe=n(gDe,"STRONG",{});var iBt=s(qCe);xDr=r(iBt,"albert"),iBt.forEach(t),$Dr=r(gDe," \u2014 "),SZ=n(gDe,"A",{href:!0});var dBt=s(SZ);kDr=r(dBt,"FlaxAlbertForMaskedLM"),dBt.forEach(t),SDr=r(gDe," (ALBERT model)"),gDe.forEach(t),RDr=i(qe),C0=n(qe,"LI",{});var hDe=s(C0);jCe=n(hDe,"STRONG",{});var cBt=s(jCe);PDr=r(cBt,"bart"),cBt.forEach(t),BDr=r(hDe," \u2014 "),RZ=n(hDe,"A",{href:!0});var fBt=s(RZ);IDr=r(fBt,"FlaxBartForConditionalGeneration"),fBt.forEach(t),NDr=r(hDe," (BART model)"),hDe.forEach(t),qDr=i(qe),w0=n(qe,"LI",{});var pDe=s(w0);DCe=n(pDe,"STRONG",{});var mBt=s(DCe);jDr=r(mBt,"bert"),mBt.forEach(t),DDr=r(pDe," \u2014 "),PZ=n(pDe,"A",{href:!0});var gBt=s(PZ);GDr=r(gBt,"FlaxBertForMaskedLM"),gBt.forEach(t),ODr=r(pDe," (BERT model)"),pDe.forEach(t),VDr=i(qe),A0=n(qe,"LI",{});var uDe=s(A0);GCe=n(uDe,"STRONG",{});var hBt=s(GCe);XDr=r(hBt,"big_bird"),hBt.forEach(t),zDr=r(uDe," \u2014 "),BZ=n(uDe,"A",{href:!0});var pBt=s(BZ);WDr=r(pBt,"FlaxBigBirdForMaskedLM"),pBt.forEach(t),QDr=r(uDe," (BigBird model)"),uDe.forEach(t),HDr=i(qe),L0=n(qe,"LI",{});var _De=s(L0);OCe=n(_De,"STRONG",{});var uBt=s(OCe);UDr=r(uBt,"distilbert"),uBt.forEach(t),JDr=r(_De," \u2014 "),IZ=n(_De,"A",{href:!0});var _Bt=s(IZ);YDr=r(_Bt,"FlaxDistilBertForMaskedLM"),_Bt.forEach(t),KDr=r(_De," (DistilBERT model)"),_De.forEach(t),ZDr=i(qe),y0=n(qe,"LI",{});var bDe=s(y0);VCe=n(bDe,"STRONG",{});var bBt=s(VCe);eGr=r(bBt,"electra"),bBt.forEach(t),oGr=r(bDe," \u2014 "),NZ=n(bDe,"A",{href:!0});var vBt=s(NZ);rGr=r(vBt,"FlaxElectraForMaskedLM"),vBt.forEach(t),tGr=r(bDe," (ELECTRA model)"),bDe.forEach(t),aGr=i(qe),x0=n(qe,"LI",{});var vDe=s(x0);XCe=n(vDe,"STRONG",{});var FBt=s(XCe);nGr=r(FBt,"mbart"),FBt.forEach(t),sGr=r(vDe," \u2014 "),qZ=n(vDe,"A",{href:!0});var TBt=s(qZ);lGr=r(TBt,"FlaxMBartForConditionalGeneration"),TBt.forEach(t),iGr=r(vDe," (mBART model)"),vDe.forEach(t),dGr=i(qe),$0=n(qe,"LI",{});var FDe=s($0);zCe=n(FDe,"STRONG",{});var MBt=s(zCe);cGr=r(MBt,"roberta"),MBt.forEach(t),fGr=r(FDe," \u2014 "),jZ=n(FDe,"A",{href:!0});var EBt=s(jZ);mGr=r(EBt,"FlaxRobertaForMaskedLM"),EBt.forEach(t),gGr=r(FDe," (RoBERTa model)"),FDe.forEach(t),hGr=i(qe),k0=n(qe,"LI",{});var TDe=s(k0);WCe=n(TDe,"STRONG",{});var CBt=s(WCe);pGr=r(CBt,"roformer"),CBt.forEach(t),uGr=r(TDe," \u2014 "),DZ=n(TDe,"A",{href:!0});var wBt=s(DZ);_Gr=r(wBt,"FlaxRoFormerForMaskedLM"),wBt.forEach(t),bGr=r(TDe," (RoFormer model)"),TDe.forEach(t),vGr=i(qe),S0=n(qe,"LI",{});var MDe=s(S0);QCe=n(MDe,"STRONG",{});var ABt=s(QCe);FGr=r(ABt,"xlm-roberta"),ABt.forEach(t),TGr=r(MDe," \u2014 "),GZ=n(MDe,"A",{href:!0});var LBt=s(GZ);MGr=r(LBt,"FlaxXLMRobertaForMaskedLM"),LBt.forEach(t),EGr=r(MDe," (XLM-RoBERTa model)"),MDe.forEach(t),qe.forEach(t),CGr=i(ai),T(R0.$$.fragment,ai),ai.forEach(t),ti.forEach(t),iVe=i(f),ef=n(f,"H2",{class:!0});var _ze=s(ef);P0=n(_ze,"A",{id:!0,class:!0,href:!0});var yBt=s(P0);HCe=n(yBt,"SPAN",{});var xBt=s(HCe);T(Qx.$$.fragment,xBt),xBt.forEach(t),yBt.forEach(t),wGr=i(_ze),UCe=n(_ze,"SPAN",{});var $Bt=s(UCe);AGr=r($Bt,"FlaxAutoModelForSeq2SeqLM"),$Bt.forEach(t),_ze.forEach(t),dVe=i(f),_r=n(f,"DIV",{class:!0});var ni=s(_r);T(Hx.$$.fragment,ni),LGr=i(ni),of=n(ni,"P",{});var Dre=s(of);yGr=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),OZ=n(Dre,"A",{href:!0});var kBt=s(OZ);xGr=r(kBt,"from_pretrained()"),kBt.forEach(t),$Gr=r(Dre," class method or the "),VZ=n(Dre,"A",{href:!0});var SBt=s(VZ);kGr=r(SBt,"from_config()"),SBt.forEach(t),SGr=r(Dre,` class
method.`),Dre.forEach(t),RGr=i(ni),Ux=n(ni,"P",{});var bze=s(Ux);PGr=r(bze,"This class cannot be instantiated directly using "),JCe=n(bze,"CODE",{});var RBt=s(JCe);BGr=r(RBt,"__init__()"),RBt.forEach(t),IGr=r(bze," (throws an error)."),bze.forEach(t),NGr=i(ni),Ht=n(ni,"DIV",{class:!0});var aL=s(Ht);T(Jx.$$.fragment,aL),qGr=i(aL),YCe=n(aL,"P",{});var PBt=s(YCe);jGr=r(PBt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),PBt.forEach(t),DGr=i(aL),rf=n(aL,"P",{});var Gre=s(rf);GGr=r(Gre,`Note:
Loading a model from its configuration file does `),KCe=n(Gre,"STRONG",{});var BBt=s(KCe);OGr=r(BBt,"not"),BBt.forEach(t),VGr=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),XZ=n(Gre,"A",{href:!0});var IBt=s(XZ);XGr=r(IBt,"from_pretrained()"),IBt.forEach(t),zGr=r(Gre," to load the model weights."),Gre.forEach(t),WGr=i(aL),T(B0.$$.fragment,aL),aL.forEach(t),QGr=i(ni),zr=n(ni,"DIV",{class:!0});var si=s(zr);T(Yx.$$.fragment,si),HGr=i(si),ZCe=n(si,"P",{});var NBt=s(ZCe);UGr=r(NBt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),NBt.forEach(t),JGr=i(si),En=n(si,"P",{});var nL=s(En);YGr=r(nL,"The model class to instantiate is selected based on the "),e5e=n(nL,"CODE",{});var qBt=s(e5e);KGr=r(qBt,"model_type"),qBt.forEach(t),ZGr=r(nL,` property of the config object (either
passed as an argument or loaded from `),o5e=n(nL,"CODE",{});var jBt=s(o5e);eOr=r(jBt,"pretrained_model_name_or_path"),jBt.forEach(t),oOr=r(nL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r5e=n(nL,"CODE",{});var DBt=s(r5e);rOr=r(DBt,"pretrained_model_name_or_path"),DBt.forEach(t),tOr=r(nL,":"),nL.forEach(t),aOr=i(si),ke=n(si,"UL",{});var je=s(ke);I0=n(je,"LI",{});var EDe=s(I0);t5e=n(EDe,"STRONG",{});var GBt=s(t5e);nOr=r(GBt,"bart"),GBt.forEach(t),sOr=r(EDe," \u2014 "),zZ=n(EDe,"A",{href:!0});var OBt=s(zZ);lOr=r(OBt,"FlaxBartForConditionalGeneration"),OBt.forEach(t),iOr=r(EDe," (BART model)"),EDe.forEach(t),dOr=i(je),N0=n(je,"LI",{});var CDe=s(N0);a5e=n(CDe,"STRONG",{});var VBt=s(a5e);cOr=r(VBt,"blenderbot"),VBt.forEach(t),fOr=r(CDe," \u2014 "),WZ=n(CDe,"A",{href:!0});var XBt=s(WZ);mOr=r(XBt,"FlaxBlenderbotForConditionalGeneration"),XBt.forEach(t),gOr=r(CDe," (Blenderbot model)"),CDe.forEach(t),hOr=i(je),q0=n(je,"LI",{});var wDe=s(q0);n5e=n(wDe,"STRONG",{});var zBt=s(n5e);pOr=r(zBt,"blenderbot-small"),zBt.forEach(t),uOr=r(wDe," \u2014 "),QZ=n(wDe,"A",{href:!0});var WBt=s(QZ);_Or=r(WBt,"FlaxBlenderbotSmallForConditionalGeneration"),WBt.forEach(t),bOr=r(wDe," (BlenderbotSmall model)"),wDe.forEach(t),vOr=i(je),j0=n(je,"LI",{});var ADe=s(j0);s5e=n(ADe,"STRONG",{});var QBt=s(s5e);FOr=r(QBt,"encoder-decoder"),QBt.forEach(t),TOr=r(ADe," \u2014 "),HZ=n(ADe,"A",{href:!0});var HBt=s(HZ);MOr=r(HBt,"FlaxEncoderDecoderModel"),HBt.forEach(t),EOr=r(ADe," (Encoder decoder model)"),ADe.forEach(t),COr=i(je),D0=n(je,"LI",{});var LDe=s(D0);l5e=n(LDe,"STRONG",{});var UBt=s(l5e);wOr=r(UBt,"longt5"),UBt.forEach(t),AOr=r(LDe," \u2014 "),UZ=n(LDe,"A",{href:!0});var JBt=s(UZ);LOr=r(JBt,"FlaxLongT5ForConditionalGeneration"),JBt.forEach(t),yOr=r(LDe," (LongT5 model)"),LDe.forEach(t),xOr=i(je),G0=n(je,"LI",{});var yDe=s(G0);i5e=n(yDe,"STRONG",{});var YBt=s(i5e);$Or=r(YBt,"marian"),YBt.forEach(t),kOr=r(yDe," \u2014 "),JZ=n(yDe,"A",{href:!0});var KBt=s(JZ);SOr=r(KBt,"FlaxMarianMTModel"),KBt.forEach(t),ROr=r(yDe," (Marian model)"),yDe.forEach(t),POr=i(je),O0=n(je,"LI",{});var xDe=s(O0);d5e=n(xDe,"STRONG",{});var ZBt=s(d5e);BOr=r(ZBt,"mbart"),ZBt.forEach(t),IOr=r(xDe," \u2014 "),YZ=n(xDe,"A",{href:!0});var eIt=s(YZ);NOr=r(eIt,"FlaxMBartForConditionalGeneration"),eIt.forEach(t),qOr=r(xDe," (mBART model)"),xDe.forEach(t),jOr=i(je),V0=n(je,"LI",{});var $De=s(V0);c5e=n($De,"STRONG",{});var oIt=s(c5e);DOr=r(oIt,"mt5"),oIt.forEach(t),GOr=r($De," \u2014 "),KZ=n($De,"A",{href:!0});var rIt=s(KZ);OOr=r(rIt,"FlaxMT5ForConditionalGeneration"),rIt.forEach(t),VOr=r($De," (MT5 model)"),$De.forEach(t),XOr=i(je),X0=n(je,"LI",{});var kDe=s(X0);f5e=n(kDe,"STRONG",{});var tIt=s(f5e);zOr=r(tIt,"pegasus"),tIt.forEach(t),WOr=r(kDe," \u2014 "),ZZ=n(kDe,"A",{href:!0});var aIt=s(ZZ);QOr=r(aIt,"FlaxPegasusForConditionalGeneration"),aIt.forEach(t),HOr=r(kDe," (Pegasus model)"),kDe.forEach(t),UOr=i(je),z0=n(je,"LI",{});var SDe=s(z0);m5e=n(SDe,"STRONG",{});var nIt=s(m5e);JOr=r(nIt,"t5"),nIt.forEach(t),YOr=r(SDe," \u2014 "),eee=n(SDe,"A",{href:!0});var sIt=s(eee);KOr=r(sIt,"FlaxT5ForConditionalGeneration"),sIt.forEach(t),ZOr=r(SDe," (T5 model)"),SDe.forEach(t),je.forEach(t),eVr=i(si),T(W0.$$.fragment,si),si.forEach(t),ni.forEach(t),cVe=i(f),tf=n(f,"H2",{class:!0});var vze=s(tf);Q0=n(vze,"A",{id:!0,class:!0,href:!0});var lIt=s(Q0);g5e=n(lIt,"SPAN",{});var iIt=s(g5e);T(Kx.$$.fragment,iIt),iIt.forEach(t),lIt.forEach(t),oVr=i(vze),h5e=n(vze,"SPAN",{});var dIt=s(h5e);rVr=r(dIt,"FlaxAutoModelForSequenceClassification"),dIt.forEach(t),vze.forEach(t),fVe=i(f),br=n(f,"DIV",{class:!0});var li=s(br);T(Zx.$$.fragment,li),tVr=i(li),af=n(li,"P",{});var Ore=s(af);aVr=r(Ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),oee=n(Ore,"A",{href:!0});var cIt=s(oee);nVr=r(cIt,"from_pretrained()"),cIt.forEach(t),sVr=r(Ore," class method or the "),ree=n(Ore,"A",{href:!0});var fIt=s(ree);lVr=r(fIt,"from_config()"),fIt.forEach(t),iVr=r(Ore,` class
method.`),Ore.forEach(t),dVr=i(li),e$=n(li,"P",{});var Fze=s(e$);cVr=r(Fze,"This class cannot be instantiated directly using "),p5e=n(Fze,"CODE",{});var mIt=s(p5e);fVr=r(mIt,"__init__()"),mIt.forEach(t),mVr=r(Fze," (throws an error)."),Fze.forEach(t),gVr=i(li),Ut=n(li,"DIV",{class:!0});var sL=s(Ut);T(o$.$$.fragment,sL),hVr=i(sL),u5e=n(sL,"P",{});var gIt=s(u5e);pVr=r(gIt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),gIt.forEach(t),uVr=i(sL),nf=n(sL,"P",{});var Vre=s(nf);_Vr=r(Vre,`Note:
Loading a model from its configuration file does `),_5e=n(Vre,"STRONG",{});var hIt=s(_5e);bVr=r(hIt,"not"),hIt.forEach(t),vVr=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),tee=n(Vre,"A",{href:!0});var pIt=s(tee);FVr=r(pIt,"from_pretrained()"),pIt.forEach(t),TVr=r(Vre," to load the model weights."),Vre.forEach(t),MVr=i(sL),T(H0.$$.fragment,sL),sL.forEach(t),EVr=i(li),Wr=n(li,"DIV",{class:!0});var ii=s(Wr);T(r$.$$.fragment,ii),CVr=i(ii),b5e=n(ii,"P",{});var uIt=s(b5e);wVr=r(uIt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uIt.forEach(t),AVr=i(ii),Cn=n(ii,"P",{});var lL=s(Cn);LVr=r(lL,"The model class to instantiate is selected based on the "),v5e=n(lL,"CODE",{});var _It=s(v5e);yVr=r(_It,"model_type"),_It.forEach(t),xVr=r(lL,` property of the config object (either
passed as an argument or loaded from `),F5e=n(lL,"CODE",{});var bIt=s(F5e);$Vr=r(bIt,"pretrained_model_name_or_path"),bIt.forEach(t),kVr=r(lL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T5e=n(lL,"CODE",{});var vIt=s(T5e);SVr=r(vIt,"pretrained_model_name_or_path"),vIt.forEach(t),RVr=r(lL,":"),lL.forEach(t),PVr=i(ii),Se=n(ii,"UL",{});var De=s(Se);U0=n(De,"LI",{});var RDe=s(U0);M5e=n(RDe,"STRONG",{});var FIt=s(M5e);BVr=r(FIt,"albert"),FIt.forEach(t),IVr=r(RDe," \u2014 "),aee=n(RDe,"A",{href:!0});var TIt=s(aee);NVr=r(TIt,"FlaxAlbertForSequenceClassification"),TIt.forEach(t),qVr=r(RDe," (ALBERT model)"),RDe.forEach(t),jVr=i(De),J0=n(De,"LI",{});var PDe=s(J0);E5e=n(PDe,"STRONG",{});var MIt=s(E5e);DVr=r(MIt,"bart"),MIt.forEach(t),GVr=r(PDe," \u2014 "),nee=n(PDe,"A",{href:!0});var EIt=s(nee);OVr=r(EIt,"FlaxBartForSequenceClassification"),EIt.forEach(t),VVr=r(PDe," (BART model)"),PDe.forEach(t),XVr=i(De),Y0=n(De,"LI",{});var BDe=s(Y0);C5e=n(BDe,"STRONG",{});var CIt=s(C5e);zVr=r(CIt,"bert"),CIt.forEach(t),WVr=r(BDe," \u2014 "),see=n(BDe,"A",{href:!0});var wIt=s(see);QVr=r(wIt,"FlaxBertForSequenceClassification"),wIt.forEach(t),HVr=r(BDe," (BERT model)"),BDe.forEach(t),UVr=i(De),K0=n(De,"LI",{});var IDe=s(K0);w5e=n(IDe,"STRONG",{});var AIt=s(w5e);JVr=r(AIt,"big_bird"),AIt.forEach(t),YVr=r(IDe," \u2014 "),lee=n(IDe,"A",{href:!0});var LIt=s(lee);KVr=r(LIt,"FlaxBigBirdForSequenceClassification"),LIt.forEach(t),ZVr=r(IDe," (BigBird model)"),IDe.forEach(t),eXr=i(De),Z0=n(De,"LI",{});var NDe=s(Z0);A5e=n(NDe,"STRONG",{});var yIt=s(A5e);oXr=r(yIt,"distilbert"),yIt.forEach(t),rXr=r(NDe," \u2014 "),iee=n(NDe,"A",{href:!0});var xIt=s(iee);tXr=r(xIt,"FlaxDistilBertForSequenceClassification"),xIt.forEach(t),aXr=r(NDe," (DistilBERT model)"),NDe.forEach(t),nXr=i(De),ew=n(De,"LI",{});var qDe=s(ew);L5e=n(qDe,"STRONG",{});var $It=s(L5e);sXr=r($It,"electra"),$It.forEach(t),lXr=r(qDe," \u2014 "),dee=n(qDe,"A",{href:!0});var kIt=s(dee);iXr=r(kIt,"FlaxElectraForSequenceClassification"),kIt.forEach(t),dXr=r(qDe," (ELECTRA model)"),qDe.forEach(t),cXr=i(De),ow=n(De,"LI",{});var jDe=s(ow);y5e=n(jDe,"STRONG",{});var SIt=s(y5e);fXr=r(SIt,"mbart"),SIt.forEach(t),mXr=r(jDe," \u2014 "),cee=n(jDe,"A",{href:!0});var RIt=s(cee);gXr=r(RIt,"FlaxMBartForSequenceClassification"),RIt.forEach(t),hXr=r(jDe," (mBART model)"),jDe.forEach(t),pXr=i(De),rw=n(De,"LI",{});var DDe=s(rw);x5e=n(DDe,"STRONG",{});var PIt=s(x5e);uXr=r(PIt,"roberta"),PIt.forEach(t),_Xr=r(DDe," \u2014 "),fee=n(DDe,"A",{href:!0});var BIt=s(fee);bXr=r(BIt,"FlaxRobertaForSequenceClassification"),BIt.forEach(t),vXr=r(DDe," (RoBERTa model)"),DDe.forEach(t),FXr=i(De),tw=n(De,"LI",{});var GDe=s(tw);$5e=n(GDe,"STRONG",{});var IIt=s($5e);TXr=r(IIt,"roformer"),IIt.forEach(t),MXr=r(GDe," \u2014 "),mee=n(GDe,"A",{href:!0});var NIt=s(mee);EXr=r(NIt,"FlaxRoFormerForSequenceClassification"),NIt.forEach(t),CXr=r(GDe," (RoFormer model)"),GDe.forEach(t),wXr=i(De),aw=n(De,"LI",{});var ODe=s(aw);k5e=n(ODe,"STRONG",{});var qIt=s(k5e);AXr=r(qIt,"xlm-roberta"),qIt.forEach(t),LXr=r(ODe," \u2014 "),gee=n(ODe,"A",{href:!0});var jIt=s(gee);yXr=r(jIt,"FlaxXLMRobertaForSequenceClassification"),jIt.forEach(t),xXr=r(ODe," (XLM-RoBERTa model)"),ODe.forEach(t),De.forEach(t),$Xr=i(ii),T(nw.$$.fragment,ii),ii.forEach(t),li.forEach(t),mVe=i(f),sf=n(f,"H2",{class:!0});var Tze=s(sf);sw=n(Tze,"A",{id:!0,class:!0,href:!0});var DIt=s(sw);S5e=n(DIt,"SPAN",{});var GIt=s(S5e);T(t$.$$.fragment,GIt),GIt.forEach(t),DIt.forEach(t),kXr=i(Tze),R5e=n(Tze,"SPAN",{});var OIt=s(R5e);SXr=r(OIt,"FlaxAutoModelForQuestionAnswering"),OIt.forEach(t),Tze.forEach(t),gVe=i(f),vr=n(f,"DIV",{class:!0});var di=s(vr);T(a$.$$.fragment,di),RXr=i(di),lf=n(di,"P",{});var Xre=s(lf);PXr=r(Xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hee=n(Xre,"A",{href:!0});var VIt=s(hee);BXr=r(VIt,"from_pretrained()"),VIt.forEach(t),IXr=r(Xre," class method or the "),pee=n(Xre,"A",{href:!0});var XIt=s(pee);NXr=r(XIt,"from_config()"),XIt.forEach(t),qXr=r(Xre,` class
method.`),Xre.forEach(t),jXr=i(di),n$=n(di,"P",{});var Mze=s(n$);DXr=r(Mze,"This class cannot be instantiated directly using "),P5e=n(Mze,"CODE",{});var zIt=s(P5e);GXr=r(zIt,"__init__()"),zIt.forEach(t),OXr=r(Mze," (throws an error)."),Mze.forEach(t),VXr=i(di),Jt=n(di,"DIV",{class:!0});var iL=s(Jt);T(s$.$$.fragment,iL),XXr=i(iL),B5e=n(iL,"P",{});var WIt=s(B5e);zXr=r(WIt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),WIt.forEach(t),WXr=i(iL),df=n(iL,"P",{});var zre=s(df);QXr=r(zre,`Note:
Loading a model from its configuration file does `),I5e=n(zre,"STRONG",{});var QIt=s(I5e);HXr=r(QIt,"not"),QIt.forEach(t),UXr=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=n(zre,"A",{href:!0});var HIt=s(uee);JXr=r(HIt,"from_pretrained()"),HIt.forEach(t),YXr=r(zre," to load the model weights."),zre.forEach(t),KXr=i(iL),T(lw.$$.fragment,iL),iL.forEach(t),ZXr=i(di),Qr=n(di,"DIV",{class:!0});var ci=s(Qr);T(l$.$$.fragment,ci),ezr=i(ci),N5e=n(ci,"P",{});var UIt=s(N5e);ozr=r(UIt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),UIt.forEach(t),rzr=i(ci),wn=n(ci,"P",{});var dL=s(wn);tzr=r(dL,"The model class to instantiate is selected based on the "),q5e=n(dL,"CODE",{});var JIt=s(q5e);azr=r(JIt,"model_type"),JIt.forEach(t),nzr=r(dL,` property of the config object (either
passed as an argument or loaded from `),j5e=n(dL,"CODE",{});var YIt=s(j5e);szr=r(YIt,"pretrained_model_name_or_path"),YIt.forEach(t),lzr=r(dL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D5e=n(dL,"CODE",{});var KIt=s(D5e);izr=r(KIt,"pretrained_model_name_or_path"),KIt.forEach(t),dzr=r(dL,":"),dL.forEach(t),czr=i(ci),Re=n(ci,"UL",{});var Ge=s(Re);iw=n(Ge,"LI",{});var VDe=s(iw);G5e=n(VDe,"STRONG",{});var ZIt=s(G5e);fzr=r(ZIt,"albert"),ZIt.forEach(t),mzr=r(VDe," \u2014 "),_ee=n(VDe,"A",{href:!0});var eNt=s(_ee);gzr=r(eNt,"FlaxAlbertForQuestionAnswering"),eNt.forEach(t),hzr=r(VDe," (ALBERT model)"),VDe.forEach(t),pzr=i(Ge),dw=n(Ge,"LI",{});var XDe=s(dw);O5e=n(XDe,"STRONG",{});var oNt=s(O5e);uzr=r(oNt,"bart"),oNt.forEach(t),_zr=r(XDe," \u2014 "),bee=n(XDe,"A",{href:!0});var rNt=s(bee);bzr=r(rNt,"FlaxBartForQuestionAnswering"),rNt.forEach(t),vzr=r(XDe," (BART model)"),XDe.forEach(t),Fzr=i(Ge),cw=n(Ge,"LI",{});var zDe=s(cw);V5e=n(zDe,"STRONG",{});var tNt=s(V5e);Tzr=r(tNt,"bert"),tNt.forEach(t),Mzr=r(zDe," \u2014 "),vee=n(zDe,"A",{href:!0});var aNt=s(vee);Ezr=r(aNt,"FlaxBertForQuestionAnswering"),aNt.forEach(t),Czr=r(zDe," (BERT model)"),zDe.forEach(t),wzr=i(Ge),fw=n(Ge,"LI",{});var WDe=s(fw);X5e=n(WDe,"STRONG",{});var nNt=s(X5e);Azr=r(nNt,"big_bird"),nNt.forEach(t),Lzr=r(WDe," \u2014 "),Fee=n(WDe,"A",{href:!0});var sNt=s(Fee);yzr=r(sNt,"FlaxBigBirdForQuestionAnswering"),sNt.forEach(t),xzr=r(WDe," (BigBird model)"),WDe.forEach(t),$zr=i(Ge),mw=n(Ge,"LI",{});var QDe=s(mw);z5e=n(QDe,"STRONG",{});var lNt=s(z5e);kzr=r(lNt,"distilbert"),lNt.forEach(t),Szr=r(QDe," \u2014 "),Tee=n(QDe,"A",{href:!0});var iNt=s(Tee);Rzr=r(iNt,"FlaxDistilBertForQuestionAnswering"),iNt.forEach(t),Pzr=r(QDe," (DistilBERT model)"),QDe.forEach(t),Bzr=i(Ge),gw=n(Ge,"LI",{});var HDe=s(gw);W5e=n(HDe,"STRONG",{});var dNt=s(W5e);Izr=r(dNt,"electra"),dNt.forEach(t),Nzr=r(HDe," \u2014 "),Mee=n(HDe,"A",{href:!0});var cNt=s(Mee);qzr=r(cNt,"FlaxElectraForQuestionAnswering"),cNt.forEach(t),jzr=r(HDe," (ELECTRA model)"),HDe.forEach(t),Dzr=i(Ge),hw=n(Ge,"LI",{});var UDe=s(hw);Q5e=n(UDe,"STRONG",{});var fNt=s(Q5e);Gzr=r(fNt,"mbart"),fNt.forEach(t),Ozr=r(UDe," \u2014 "),Eee=n(UDe,"A",{href:!0});var mNt=s(Eee);Vzr=r(mNt,"FlaxMBartForQuestionAnswering"),mNt.forEach(t),Xzr=r(UDe," (mBART model)"),UDe.forEach(t),zzr=i(Ge),pw=n(Ge,"LI",{});var JDe=s(pw);H5e=n(JDe,"STRONG",{});var gNt=s(H5e);Wzr=r(gNt,"roberta"),gNt.forEach(t),Qzr=r(JDe," \u2014 "),Cee=n(JDe,"A",{href:!0});var hNt=s(Cee);Hzr=r(hNt,"FlaxRobertaForQuestionAnswering"),hNt.forEach(t),Uzr=r(JDe," (RoBERTa model)"),JDe.forEach(t),Jzr=i(Ge),uw=n(Ge,"LI",{});var YDe=s(uw);U5e=n(YDe,"STRONG",{});var pNt=s(U5e);Yzr=r(pNt,"roformer"),pNt.forEach(t),Kzr=r(YDe," \u2014 "),wee=n(YDe,"A",{href:!0});var uNt=s(wee);Zzr=r(uNt,"FlaxRoFormerForQuestionAnswering"),uNt.forEach(t),eWr=r(YDe," (RoFormer model)"),YDe.forEach(t),oWr=i(Ge),_w=n(Ge,"LI",{});var KDe=s(_w);J5e=n(KDe,"STRONG",{});var _Nt=s(J5e);rWr=r(_Nt,"xlm-roberta"),_Nt.forEach(t),tWr=r(KDe," \u2014 "),Aee=n(KDe,"A",{href:!0});var bNt=s(Aee);aWr=r(bNt,"FlaxXLMRobertaForQuestionAnswering"),bNt.forEach(t),nWr=r(KDe," (XLM-RoBERTa model)"),KDe.forEach(t),Ge.forEach(t),sWr=i(ci),T(bw.$$.fragment,ci),ci.forEach(t),di.forEach(t),hVe=i(f),cf=n(f,"H2",{class:!0});var Eze=s(cf);vw=n(Eze,"A",{id:!0,class:!0,href:!0});var vNt=s(vw);Y5e=n(vNt,"SPAN",{});var FNt=s(Y5e);T(i$.$$.fragment,FNt),FNt.forEach(t),vNt.forEach(t),lWr=i(Eze),K5e=n(Eze,"SPAN",{});var TNt=s(K5e);iWr=r(TNt,"FlaxAutoModelForTokenClassification"),TNt.forEach(t),Eze.forEach(t),pVe=i(f),Fr=n(f,"DIV",{class:!0});var fi=s(Fr);T(d$.$$.fragment,fi),dWr=i(fi),ff=n(fi,"P",{});var Wre=s(ff);cWr=r(Wre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Lee=n(Wre,"A",{href:!0});var MNt=s(Lee);fWr=r(MNt,"from_pretrained()"),MNt.forEach(t),mWr=r(Wre," class method or the "),yee=n(Wre,"A",{href:!0});var ENt=s(yee);gWr=r(ENt,"from_config()"),ENt.forEach(t),hWr=r(Wre,` class
method.`),Wre.forEach(t),pWr=i(fi),c$=n(fi,"P",{});var Cze=s(c$);uWr=r(Cze,"This class cannot be instantiated directly using "),Z5e=n(Cze,"CODE",{});var CNt=s(Z5e);_Wr=r(CNt,"__init__()"),CNt.forEach(t),bWr=r(Cze," (throws an error)."),Cze.forEach(t),vWr=i(fi),Yt=n(fi,"DIV",{class:!0});var cL=s(Yt);T(f$.$$.fragment,cL),FWr=i(cL),e0e=n(cL,"P",{});var wNt=s(e0e);TWr=r(wNt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),wNt.forEach(t),MWr=i(cL),mf=n(cL,"P",{});var Qre=s(mf);EWr=r(Qre,`Note:
Loading a model from its configuration file does `),o0e=n(Qre,"STRONG",{});var ANt=s(o0e);CWr=r(ANt,"not"),ANt.forEach(t),wWr=r(Qre,` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=n(Qre,"A",{href:!0});var LNt=s(xee);AWr=r(LNt,"from_pretrained()"),LNt.forEach(t),LWr=r(Qre," to load the model weights."),Qre.forEach(t),yWr=i(cL),T(Fw.$$.fragment,cL),cL.forEach(t),xWr=i(fi),Hr=n(fi,"DIV",{class:!0});var mi=s(Hr);T(m$.$$.fragment,mi),$Wr=i(mi),r0e=n(mi,"P",{});var yNt=s(r0e);kWr=r(yNt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),yNt.forEach(t),SWr=i(mi),An=n(mi,"P",{});var fL=s(An);RWr=r(fL,"The model class to instantiate is selected based on the "),t0e=n(fL,"CODE",{});var xNt=s(t0e);PWr=r(xNt,"model_type"),xNt.forEach(t),BWr=r(fL,` property of the config object (either
passed as an argument or loaded from `),a0e=n(fL,"CODE",{});var $Nt=s(a0e);IWr=r($Nt,"pretrained_model_name_or_path"),$Nt.forEach(t),NWr=r(fL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n0e=n(fL,"CODE",{});var kNt=s(n0e);qWr=r(kNt,"pretrained_model_name_or_path"),kNt.forEach(t),jWr=r(fL,":"),fL.forEach(t),DWr=i(mi),Ve=n(mi,"UL",{});var To=s(Ve);Tw=n(To,"LI",{});var ZDe=s(Tw);s0e=n(ZDe,"STRONG",{});var SNt=s(s0e);GWr=r(SNt,"albert"),SNt.forEach(t),OWr=r(ZDe," \u2014 "),$ee=n(ZDe,"A",{href:!0});var RNt=s($ee);VWr=r(RNt,"FlaxAlbertForTokenClassification"),RNt.forEach(t),XWr=r(ZDe," (ALBERT model)"),ZDe.forEach(t),zWr=i(To),Mw=n(To,"LI",{});var eGe=s(Mw);l0e=n(eGe,"STRONG",{});var PNt=s(l0e);WWr=r(PNt,"bert"),PNt.forEach(t),QWr=r(eGe," \u2014 "),kee=n(eGe,"A",{href:!0});var BNt=s(kee);HWr=r(BNt,"FlaxBertForTokenClassification"),BNt.forEach(t),UWr=r(eGe," (BERT model)"),eGe.forEach(t),JWr=i(To),Ew=n(To,"LI",{});var oGe=s(Ew);i0e=n(oGe,"STRONG",{});var INt=s(i0e);YWr=r(INt,"big_bird"),INt.forEach(t),KWr=r(oGe," \u2014 "),See=n(oGe,"A",{href:!0});var NNt=s(See);ZWr=r(NNt,"FlaxBigBirdForTokenClassification"),NNt.forEach(t),eQr=r(oGe," (BigBird model)"),oGe.forEach(t),oQr=i(To),Cw=n(To,"LI",{});var rGe=s(Cw);d0e=n(rGe,"STRONG",{});var qNt=s(d0e);rQr=r(qNt,"distilbert"),qNt.forEach(t),tQr=r(rGe," \u2014 "),Ree=n(rGe,"A",{href:!0});var jNt=s(Ree);aQr=r(jNt,"FlaxDistilBertForTokenClassification"),jNt.forEach(t),nQr=r(rGe," (DistilBERT model)"),rGe.forEach(t),sQr=i(To),ww=n(To,"LI",{});var tGe=s(ww);c0e=n(tGe,"STRONG",{});var DNt=s(c0e);lQr=r(DNt,"electra"),DNt.forEach(t),iQr=r(tGe," \u2014 "),Pee=n(tGe,"A",{href:!0});var GNt=s(Pee);dQr=r(GNt,"FlaxElectraForTokenClassification"),GNt.forEach(t),cQr=r(tGe," (ELECTRA model)"),tGe.forEach(t),fQr=i(To),Aw=n(To,"LI",{});var aGe=s(Aw);f0e=n(aGe,"STRONG",{});var ONt=s(f0e);mQr=r(ONt,"roberta"),ONt.forEach(t),gQr=r(aGe," \u2014 "),Bee=n(aGe,"A",{href:!0});var VNt=s(Bee);hQr=r(VNt,"FlaxRobertaForTokenClassification"),VNt.forEach(t),pQr=r(aGe," (RoBERTa model)"),aGe.forEach(t),uQr=i(To),Lw=n(To,"LI",{});var nGe=s(Lw);m0e=n(nGe,"STRONG",{});var XNt=s(m0e);_Qr=r(XNt,"roformer"),XNt.forEach(t),bQr=r(nGe," \u2014 "),Iee=n(nGe,"A",{href:!0});var zNt=s(Iee);vQr=r(zNt,"FlaxRoFormerForTokenClassification"),zNt.forEach(t),FQr=r(nGe," (RoFormer model)"),nGe.forEach(t),TQr=i(To),yw=n(To,"LI",{});var sGe=s(yw);g0e=n(sGe,"STRONG",{});var WNt=s(g0e);MQr=r(WNt,"xlm-roberta"),WNt.forEach(t),EQr=r(sGe," \u2014 "),Nee=n(sGe,"A",{href:!0});var QNt=s(Nee);CQr=r(QNt,"FlaxXLMRobertaForTokenClassification"),QNt.forEach(t),wQr=r(sGe," (XLM-RoBERTa model)"),sGe.forEach(t),To.forEach(t),AQr=i(mi),T(xw.$$.fragment,mi),mi.forEach(t),fi.forEach(t),uVe=i(f),gf=n(f,"H2",{class:!0});var wze=s(gf);$w=n(wze,"A",{id:!0,class:!0,href:!0});var HNt=s($w);h0e=n(HNt,"SPAN",{});var UNt=s(h0e);T(g$.$$.fragment,UNt),UNt.forEach(t),HNt.forEach(t),LQr=i(wze),p0e=n(wze,"SPAN",{});var JNt=s(p0e);yQr=r(JNt,"FlaxAutoModelForMultipleChoice"),JNt.forEach(t),wze.forEach(t),_Ve=i(f),Tr=n(f,"DIV",{class:!0});var gi=s(Tr);T(h$.$$.fragment,gi),xQr=i(gi),hf=n(gi,"P",{});var Hre=s(hf);$Qr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),qee=n(Hre,"A",{href:!0});var YNt=s(qee);kQr=r(YNt,"from_pretrained()"),YNt.forEach(t),SQr=r(Hre," class method or the "),jee=n(Hre,"A",{href:!0});var KNt=s(jee);RQr=r(KNt,"from_config()"),KNt.forEach(t),PQr=r(Hre,` class
method.`),Hre.forEach(t),BQr=i(gi),p$=n(gi,"P",{});var Aze=s(p$);IQr=r(Aze,"This class cannot be instantiated directly using "),u0e=n(Aze,"CODE",{});var ZNt=s(u0e);NQr=r(ZNt,"__init__()"),ZNt.forEach(t),qQr=r(Aze," (throws an error)."),Aze.forEach(t),jQr=i(gi),Kt=n(gi,"DIV",{class:!0});var mL=s(Kt);T(u$.$$.fragment,mL),DQr=i(mL),_0e=n(mL,"P",{});var eqt=s(_0e);GQr=r(eqt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),eqt.forEach(t),OQr=i(mL),pf=n(mL,"P",{});var Ure=s(pf);VQr=r(Ure,`Note:
Loading a model from its configuration file does `),b0e=n(Ure,"STRONG",{});var oqt=s(b0e);XQr=r(oqt,"not"),oqt.forEach(t),zQr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dee=n(Ure,"A",{href:!0});var rqt=s(Dee);WQr=r(rqt,"from_pretrained()"),rqt.forEach(t),QQr=r(Ure," to load the model weights."),Ure.forEach(t),HQr=i(mL),T(kw.$$.fragment,mL),mL.forEach(t),UQr=i(gi),Ur=n(gi,"DIV",{class:!0});var hi=s(Ur);T(_$.$$.fragment,hi),JQr=i(hi),v0e=n(hi,"P",{});var tqt=s(v0e);YQr=r(tqt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),tqt.forEach(t),KQr=i(hi),Ln=n(hi,"P",{});var gL=s(Ln);ZQr=r(gL,"The model class to instantiate is selected based on the "),F0e=n(gL,"CODE",{});var aqt=s(F0e);eHr=r(aqt,"model_type"),aqt.forEach(t),oHr=r(gL,` property of the config object (either
passed as an argument or loaded from `),T0e=n(gL,"CODE",{});var nqt=s(T0e);rHr=r(nqt,"pretrained_model_name_or_path"),nqt.forEach(t),tHr=r(gL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M0e=n(gL,"CODE",{});var sqt=s(M0e);aHr=r(sqt,"pretrained_model_name_or_path"),sqt.forEach(t),nHr=r(gL,":"),gL.forEach(t),sHr=i(hi),Xe=n(hi,"UL",{});var Mo=s(Xe);Sw=n(Mo,"LI",{});var lGe=s(Sw);E0e=n(lGe,"STRONG",{});var lqt=s(E0e);lHr=r(lqt,"albert"),lqt.forEach(t),iHr=r(lGe," \u2014 "),Gee=n(lGe,"A",{href:!0});var iqt=s(Gee);dHr=r(iqt,"FlaxAlbertForMultipleChoice"),iqt.forEach(t),cHr=r(lGe," (ALBERT model)"),lGe.forEach(t),fHr=i(Mo),Rw=n(Mo,"LI",{});var iGe=s(Rw);C0e=n(iGe,"STRONG",{});var dqt=s(C0e);mHr=r(dqt,"bert"),dqt.forEach(t),gHr=r(iGe," \u2014 "),Oee=n(iGe,"A",{href:!0});var cqt=s(Oee);hHr=r(cqt,"FlaxBertForMultipleChoice"),cqt.forEach(t),pHr=r(iGe," (BERT model)"),iGe.forEach(t),uHr=i(Mo),Pw=n(Mo,"LI",{});var dGe=s(Pw);w0e=n(dGe,"STRONG",{});var fqt=s(w0e);_Hr=r(fqt,"big_bird"),fqt.forEach(t),bHr=r(dGe," \u2014 "),Vee=n(dGe,"A",{href:!0});var mqt=s(Vee);vHr=r(mqt,"FlaxBigBirdForMultipleChoice"),mqt.forEach(t),FHr=r(dGe," (BigBird model)"),dGe.forEach(t),THr=i(Mo),Bw=n(Mo,"LI",{});var cGe=s(Bw);A0e=n(cGe,"STRONG",{});var gqt=s(A0e);MHr=r(gqt,"distilbert"),gqt.forEach(t),EHr=r(cGe," \u2014 "),Xee=n(cGe,"A",{href:!0});var hqt=s(Xee);CHr=r(hqt,"FlaxDistilBertForMultipleChoice"),hqt.forEach(t),wHr=r(cGe," (DistilBERT model)"),cGe.forEach(t),AHr=i(Mo),Iw=n(Mo,"LI",{});var fGe=s(Iw);L0e=n(fGe,"STRONG",{});var pqt=s(L0e);LHr=r(pqt,"electra"),pqt.forEach(t),yHr=r(fGe," \u2014 "),zee=n(fGe,"A",{href:!0});var uqt=s(zee);xHr=r(uqt,"FlaxElectraForMultipleChoice"),uqt.forEach(t),$Hr=r(fGe," (ELECTRA model)"),fGe.forEach(t),kHr=i(Mo),Nw=n(Mo,"LI",{});var mGe=s(Nw);y0e=n(mGe,"STRONG",{});var _qt=s(y0e);SHr=r(_qt,"roberta"),_qt.forEach(t),RHr=r(mGe," \u2014 "),Wee=n(mGe,"A",{href:!0});var bqt=s(Wee);PHr=r(bqt,"FlaxRobertaForMultipleChoice"),bqt.forEach(t),BHr=r(mGe," (RoBERTa model)"),mGe.forEach(t),IHr=i(Mo),qw=n(Mo,"LI",{});var gGe=s(qw);x0e=n(gGe,"STRONG",{});var vqt=s(x0e);NHr=r(vqt,"roformer"),vqt.forEach(t),qHr=r(gGe," \u2014 "),Qee=n(gGe,"A",{href:!0});var Fqt=s(Qee);jHr=r(Fqt,"FlaxRoFormerForMultipleChoice"),Fqt.forEach(t),DHr=r(gGe," (RoFormer model)"),gGe.forEach(t),GHr=i(Mo),jw=n(Mo,"LI",{});var hGe=s(jw);$0e=n(hGe,"STRONG",{});var Tqt=s($0e);OHr=r(Tqt,"xlm-roberta"),Tqt.forEach(t),VHr=r(hGe," \u2014 "),Hee=n(hGe,"A",{href:!0});var Mqt=s(Hee);XHr=r(Mqt,"FlaxXLMRobertaForMultipleChoice"),Mqt.forEach(t),zHr=r(hGe," (XLM-RoBERTa model)"),hGe.forEach(t),Mo.forEach(t),WHr=i(hi),T(Dw.$$.fragment,hi),hi.forEach(t),gi.forEach(t),bVe=i(f),uf=n(f,"H2",{class:!0});var Lze=s(uf);Gw=n(Lze,"A",{id:!0,class:!0,href:!0});var Eqt=s(Gw);k0e=n(Eqt,"SPAN",{});var Cqt=s(k0e);T(b$.$$.fragment,Cqt),Cqt.forEach(t),Eqt.forEach(t),QHr=i(Lze),S0e=n(Lze,"SPAN",{});var wqt=s(S0e);HHr=r(wqt,"FlaxAutoModelForNextSentencePrediction"),wqt.forEach(t),Lze.forEach(t),vVe=i(f),Mr=n(f,"DIV",{class:!0});var pi=s(Mr);T(v$.$$.fragment,pi),UHr=i(pi),_f=n(pi,"P",{});var Jre=s(_f);JHr=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Uee=n(Jre,"A",{href:!0});var Aqt=s(Uee);YHr=r(Aqt,"from_pretrained()"),Aqt.forEach(t),KHr=r(Jre," class method or the "),Jee=n(Jre,"A",{href:!0});var Lqt=s(Jee);ZHr=r(Lqt,"from_config()"),Lqt.forEach(t),eUr=r(Jre,` class
method.`),Jre.forEach(t),oUr=i(pi),F$=n(pi,"P",{});var yze=s(F$);rUr=r(yze,"This class cannot be instantiated directly using "),R0e=n(yze,"CODE",{});var yqt=s(R0e);tUr=r(yqt,"__init__()"),yqt.forEach(t),aUr=r(yze," (throws an error)."),yze.forEach(t),nUr=i(pi),Zt=n(pi,"DIV",{class:!0});var hL=s(Zt);T(T$.$$.fragment,hL),sUr=i(hL),P0e=n(hL,"P",{});var xqt=s(P0e);lUr=r(xqt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),xqt.forEach(t),iUr=i(hL),bf=n(hL,"P",{});var Yre=s(bf);dUr=r(Yre,`Note:
Loading a model from its configuration file does `),B0e=n(Yre,"STRONG",{});var $qt=s(B0e);cUr=r($qt,"not"),$qt.forEach(t),fUr=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=n(Yre,"A",{href:!0});var kqt=s(Yee);mUr=r(kqt,"from_pretrained()"),kqt.forEach(t),gUr=r(Yre," to load the model weights."),Yre.forEach(t),hUr=i(hL),T(Ow.$$.fragment,hL),hL.forEach(t),pUr=i(pi),Jr=n(pi,"DIV",{class:!0});var ui=s(Jr);T(M$.$$.fragment,ui),uUr=i(ui),I0e=n(ui,"P",{});var Sqt=s(I0e);_Ur=r(Sqt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Sqt.forEach(t),bUr=i(ui),yn=n(ui,"P",{});var pL=s(yn);vUr=r(pL,"The model class to instantiate is selected based on the "),N0e=n(pL,"CODE",{});var Rqt=s(N0e);FUr=r(Rqt,"model_type"),Rqt.forEach(t),TUr=r(pL,` property of the config object (either
passed as an argument or loaded from `),q0e=n(pL,"CODE",{});var Pqt=s(q0e);MUr=r(Pqt,"pretrained_model_name_or_path"),Pqt.forEach(t),EUr=r(pL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j0e=n(pL,"CODE",{});var Bqt=s(j0e);CUr=r(Bqt,"pretrained_model_name_or_path"),Bqt.forEach(t),wUr=r(pL,":"),pL.forEach(t),AUr=i(ui),D0e=n(ui,"UL",{});var Iqt=s(D0e);Vw=n(Iqt,"LI",{});var pGe=s(Vw);G0e=n(pGe,"STRONG",{});var Nqt=s(G0e);LUr=r(Nqt,"bert"),Nqt.forEach(t),yUr=r(pGe," \u2014 "),Kee=n(pGe,"A",{href:!0});var qqt=s(Kee);xUr=r(qqt,"FlaxBertForNextSentencePrediction"),qqt.forEach(t),$Ur=r(pGe," (BERT model)"),pGe.forEach(t),Iqt.forEach(t),kUr=i(ui),T(Xw.$$.fragment,ui),ui.forEach(t),pi.forEach(t),FVe=i(f),vf=n(f,"H2",{class:!0});var xze=s(vf);zw=n(xze,"A",{id:!0,class:!0,href:!0});var jqt=s(zw);O0e=n(jqt,"SPAN",{});var Dqt=s(O0e);T(E$.$$.fragment,Dqt),Dqt.forEach(t),jqt.forEach(t),SUr=i(xze),V0e=n(xze,"SPAN",{});var Gqt=s(V0e);RUr=r(Gqt,"FlaxAutoModelForImageClassification"),Gqt.forEach(t),xze.forEach(t),TVe=i(f),Er=n(f,"DIV",{class:!0});var _i=s(Er);T(C$.$$.fragment,_i),PUr=i(_i),Ff=n(_i,"P",{});var Kre=s(Ff);BUr=r(Kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Zee=n(Kre,"A",{href:!0});var Oqt=s(Zee);IUr=r(Oqt,"from_pretrained()"),Oqt.forEach(t),NUr=r(Kre," class method or the "),eoe=n(Kre,"A",{href:!0});var Vqt=s(eoe);qUr=r(Vqt,"from_config()"),Vqt.forEach(t),jUr=r(Kre,` class
method.`),Kre.forEach(t),DUr=i(_i),w$=n(_i,"P",{});var $ze=s(w$);GUr=r($ze,"This class cannot be instantiated directly using "),X0e=n($ze,"CODE",{});var Xqt=s(X0e);OUr=r(Xqt,"__init__()"),Xqt.forEach(t),VUr=r($ze," (throws an error)."),$ze.forEach(t),XUr=i(_i),ea=n(_i,"DIV",{class:!0});var uL=s(ea);T(A$.$$.fragment,uL),zUr=i(uL),z0e=n(uL,"P",{});var zqt=s(z0e);WUr=r(zqt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),zqt.forEach(t),QUr=i(uL),Tf=n(uL,"P",{});var Zre=s(Tf);HUr=r(Zre,`Note:
Loading a model from its configuration file does `),W0e=n(Zre,"STRONG",{});var Wqt=s(W0e);UUr=r(Wqt,"not"),Wqt.forEach(t),JUr=r(Zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),ooe=n(Zre,"A",{href:!0});var Qqt=s(ooe);YUr=r(Qqt,"from_pretrained()"),Qqt.forEach(t),KUr=r(Zre," to load the model weights."),Zre.forEach(t),ZUr=i(uL),T(Ww.$$.fragment,uL),uL.forEach(t),eJr=i(_i),Yr=n(_i,"DIV",{class:!0});var bi=s(Yr);T(L$.$$.fragment,bi),oJr=i(bi),Q0e=n(bi,"P",{});var Hqt=s(Q0e);rJr=r(Hqt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Hqt.forEach(t),tJr=i(bi),xn=n(bi,"P",{});var _L=s(xn);aJr=r(_L,"The model class to instantiate is selected based on the "),H0e=n(_L,"CODE",{});var Uqt=s(H0e);nJr=r(Uqt,"model_type"),Uqt.forEach(t),sJr=r(_L,` property of the config object (either
passed as an argument or loaded from `),U0e=n(_L,"CODE",{});var Jqt=s(U0e);lJr=r(Jqt,"pretrained_model_name_or_path"),Jqt.forEach(t),iJr=r(_L,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J0e=n(_L,"CODE",{});var Yqt=s(J0e);dJr=r(Yqt,"pretrained_model_name_or_path"),Yqt.forEach(t),cJr=r(_L,":"),_L.forEach(t),fJr=i(bi),y$=n(bi,"UL",{});var kze=s(y$);Qw=n(kze,"LI",{});var uGe=s(Qw);Y0e=n(uGe,"STRONG",{});var Kqt=s(Y0e);mJr=r(Kqt,"beit"),Kqt.forEach(t),gJr=r(uGe," \u2014 "),roe=n(uGe,"A",{href:!0});var Zqt=s(roe);hJr=r(Zqt,"FlaxBeitForImageClassification"),Zqt.forEach(t),pJr=r(uGe," (BEiT model)"),uGe.forEach(t),uJr=i(kze),Hw=n(kze,"LI",{});var _Ge=s(Hw);K0e=n(_Ge,"STRONG",{});var ejt=s(K0e);_Jr=r(ejt,"vit"),ejt.forEach(t),bJr=r(_Ge," \u2014 "),toe=n(_Ge,"A",{href:!0});var ojt=s(toe);vJr=r(ojt,"FlaxViTForImageClassification"),ojt.forEach(t),FJr=r(_Ge," (ViT model)"),_Ge.forEach(t),kze.forEach(t),TJr=i(bi),T(Uw.$$.fragment,bi),bi.forEach(t),_i.forEach(t),MVe=i(f),Mf=n(f,"H2",{class:!0});var Sze=s(Mf);Jw=n(Sze,"A",{id:!0,class:!0,href:!0});var rjt=s(Jw);Z0e=n(rjt,"SPAN",{});var tjt=s(Z0e);T(x$.$$.fragment,tjt),tjt.forEach(t),rjt.forEach(t),MJr=i(Sze),ewe=n(Sze,"SPAN",{});var ajt=s(ewe);EJr=r(ajt,"FlaxAutoModelForVision2Seq"),ajt.forEach(t),Sze.forEach(t),EVe=i(f),Cr=n(f,"DIV",{class:!0});var vi=s(Cr);T($$.$$.fragment,vi),CJr=i(vi),Ef=n(vi,"P",{});var ete=s(Ef);wJr=r(ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),aoe=n(ete,"A",{href:!0});var njt=s(aoe);AJr=r(njt,"from_pretrained()"),njt.forEach(t),LJr=r(ete," class method or the "),noe=n(ete,"A",{href:!0});var sjt=s(noe);yJr=r(sjt,"from_config()"),sjt.forEach(t),xJr=r(ete,` class
method.`),ete.forEach(t),$Jr=i(vi),k$=n(vi,"P",{});var Rze=s(k$);kJr=r(Rze,"This class cannot be instantiated directly using "),owe=n(Rze,"CODE",{});var ljt=s(owe);SJr=r(ljt,"__init__()"),ljt.forEach(t),RJr=r(Rze," (throws an error)."),Rze.forEach(t),PJr=i(vi),oa=n(vi,"DIV",{class:!0});var bL=s(oa);T(S$.$$.fragment,bL),BJr=i(bL),rwe=n(bL,"P",{});var ijt=s(rwe);IJr=r(ijt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),ijt.forEach(t),NJr=i(bL),Cf=n(bL,"P",{});var ote=s(Cf);qJr=r(ote,`Note:
Loading a model from its configuration file does `),twe=n(ote,"STRONG",{});var djt=s(twe);jJr=r(djt,"not"),djt.forEach(t),DJr=r(ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),soe=n(ote,"A",{href:!0});var cjt=s(soe);GJr=r(cjt,"from_pretrained()"),cjt.forEach(t),OJr=r(ote," to load the model weights."),ote.forEach(t),VJr=i(bL),T(Yw.$$.fragment,bL),bL.forEach(t),XJr=i(vi),Kr=n(vi,"DIV",{class:!0});var Fi=s(Kr);T(R$.$$.fragment,Fi),zJr=i(Fi),awe=n(Fi,"P",{});var fjt=s(awe);WJr=r(fjt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),fjt.forEach(t),QJr=i(Fi),$n=n(Fi,"P",{});var vL=s($n);HJr=r(vL,"The model class to instantiate is selected based on the "),nwe=n(vL,"CODE",{});var mjt=s(nwe);UJr=r(mjt,"model_type"),mjt.forEach(t),JJr=r(vL,` property of the config object (either
passed as an argument or loaded from `),swe=n(vL,"CODE",{});var gjt=s(swe);YJr=r(gjt,"pretrained_model_name_or_path"),gjt.forEach(t),KJr=r(vL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lwe=n(vL,"CODE",{});var hjt=s(lwe);ZJr=r(hjt,"pretrained_model_name_or_path"),hjt.forEach(t),eYr=r(vL,":"),vL.forEach(t),oYr=i(Fi),iwe=n(Fi,"UL",{});var pjt=s(iwe);Kw=n(pjt,"LI",{});var bGe=s(Kw);dwe=n(bGe,"STRONG",{});var ujt=s(dwe);rYr=r(ujt,"vision-encoder-decoder"),ujt.forEach(t),tYr=r(bGe," \u2014 "),loe=n(bGe,"A",{href:!0});var _jt=s(loe);aYr=r(_jt,"FlaxVisionEncoderDecoderModel"),_jt.forEach(t),nYr=r(bGe," (Vision Encoder decoder model)"),bGe.forEach(t),pjt.forEach(t),sYr=i(Fi),T(Zw.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(EGt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Sn,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.AutoConfig"),c(Pn,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.AutoModel"),c(Bn,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.AutoTokenizer"),c(Li,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertModel"),c(Sf,"id","extending-the-auto-classes"),c(Sf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Sf,"href","#extending-the-auto-classes"),c(yi,"class","relative group"),c(Pf,"id","transformers.AutoConfig"),c(Pf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pf,"href","#transformers.AutoConfig"),c(xi,"class","relative group"),c(tS,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(aS,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertConfig"),c(nS,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartConfig"),c(sS,"href","/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitConfig"),c(lS,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertConfig"),c(iS,"href","/docs/transformers/pr_17313/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(dS,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdConfig"),c(cS,"href","/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(fS,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(mS,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(gS,"href","/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomConfig"),c(hS,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertConfig"),c(pS,"href","/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineConfig"),c(uS,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPConfig"),c(_S,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertConfig"),c(bS,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextConfig"),c(vS,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLConfig"),c(FS,"href","/docs/transformers/pr_17313/en/model_doc/cvt#transformers.CvtConfig"),c(TS,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(MS,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(ES,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(CS,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaConfig"),c(wS,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(AS,"href","/docs/transformers/pr_17313/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(LS,"href","/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTConfig"),c(yS,"href","/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrConfig"),c(xS,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertConfig"),c($S,"href","/docs/transformers/pr_17313/en/model_doc/dpr#transformers.DPRConfig"),c(kS,"href","/docs/transformers/pr_17313/en/model_doc/dpt#transformers.DPTConfig"),c(SS,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraConfig"),c(RS,"href","/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(PS,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertConfig"),c(BS,"href","/docs/transformers/pr_17313/en/model_doc/flava#transformers.FlavaConfig"),c(IS,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetConfig"),c(NS,"href","/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTConfig"),c(qS,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelConfig"),c(jS,"href","/docs/transformers/pr_17313/en/model_doc/glpn#transformers.GLPNConfig"),c(DS,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Config"),c(GS,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(OS,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(VS,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJConfig"),c(XS,"href","/docs/transformers/pr_17313/en/model_doc/groupvit#transformers.GroupViTConfig"),c(zS,"href","/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertConfig"),c(WS,"href","/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertConfig"),c(QS,"href","/docs/transformers/pr_17313/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(HS,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(US,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(JS,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(YS,"href","/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDConfig"),c(KS,"href","/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitConfig"),c(ZS,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerConfig"),c(eR,"href","/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5Config"),c(oR,"href","/docs/transformers/pr_17313/en/model_doc/luke#transformers.LukeConfig"),c(rR,"href","/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertConfig"),c(tR,"href","/docs/transformers/pr_17313/en/model_doc/m2m_100#transformers.M2M100Config"),c(aR,"href","/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianConfig"),c(nR,"href","/docs/transformers/pr_17313/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(sR,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartConfig"),c(lR,"href","/docs/transformers/pr_17313/en/model_doc/mctct#transformers.MCTCTConfig"),c(iR,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(dR,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(cR,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetConfig"),c(fR,"href","/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Config"),c(mR,"href","/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(gR,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(hR,"href","/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTConfig"),c(pR,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusConfig"),c(uR,"href","/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverConfig"),c(_R,"href","/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartConfig"),c(bR,"href","/docs/transformers/pr_17313/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(vR,"href","/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(FR,"href","/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(TR,"href","/docs/transformers/pr_17313/en/model_doc/rag#transformers.RagConfig"),c(MR,"href","/docs/transformers/pr_17313/en/model_doc/realm#transformers.RealmConfig"),c(ER,"href","/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerConfig"),c(CR,"href","/docs/transformers/pr_17313/en/model_doc/regnet#transformers.RegNetConfig"),c(wR,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertConfig"),c(AR,"href","/docs/transformers/pr_17313/en/model_doc/resnet#transformers.ResNetConfig"),c(LR,"href","/docs/transformers/pr_17313/en/model_doc/retribert#transformers.RetriBertConfig"),c(yR,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaConfig"),c(xR,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerConfig"),c($R,"href","/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerConfig"),c(kR,"href","/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWConfig"),c(SR,"href","/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDConfig"),c(RR,"href","/docs/transformers/pr_17313/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(PR,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(BR,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(IR,"href","/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterConfig"),c(NR,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(qR,"href","/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinConfig"),c(jR,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Config"),c(DR,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasConfig"),c(GR,"href","/docs/transformers/pr_17313/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(OR,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(VR,"href","/docs/transformers/pr_17313/en/model_doc/trocr#transformers.TrOCRConfig"),c(XR,"href","/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(zR,"href","/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(WR,"href","/docs/transformers/pr_17313/en/model_doc/van#transformers.VanConfig"),c(QR,"href","/docs/transformers/pr_17313/en/model_doc/vilt#transformers.ViltConfig"),c(HR,"href","/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(UR,"href","/docs/transformers/pr_17313/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(JR,"href","/docs/transformers/pr_17313/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(YR,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTConfig"),c(KR,"href","/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(ZR,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(eP,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(oP,"href","/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMConfig"),c(rP,"href","/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMConfig"),c(tP,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMConfig"),c(aP,"href","/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(nP,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(sP,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(lP,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetConfig"),c(iP,"href","/docs/transformers/pr_17313/en/model_doc/yolos#transformers.YolosConfig"),c(dP,"href","/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoConfig"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Og,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vg,"id","transformers.AutoTokenizer"),c(Vg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vg,"href","#transformers.AutoTokenizer"),c(ki,"class","relative group"),c(cP,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(fP,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertTokenizer"),c(mP,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(gP,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartTokenizer"),c(hP,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartTokenizerFast"),c(pP,"href","/docs/transformers/pr_17313/en/model_doc/barthez#transformers.BarthezTokenizer"),c(uP,"href","/docs/transformers/pr_17313/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(_P,"href","/docs/transformers/pr_17313/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(bP,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizer"),c(vP,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizerFast"),c(FP,"href","/docs/transformers/pr_17313/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(TP,"href","/docs/transformers/pr_17313/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(MP,"href","/docs/transformers/pr_17313/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(EP,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(CP,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(wP,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(AP,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(LP,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(yP,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(xP,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c($P,"href","/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(kP,"href","/docs/transformers/pr_17313/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(SP,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertTokenizer"),c(RP,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(PP,"href","/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineTokenizer"),c(BP,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPTokenizer"),c(IP,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(NP,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(qP,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(jP,"href","/docs/transformers/pr_17313/en/model_doc/cpm#transformers.CpmTokenizer"),c(DP,"href","/docs/transformers/pr_17313/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(GP,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(OP,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaTokenizer"),c(VP,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(XP,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaTokenizer"),c(zP,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(WP,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(QP,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(HP,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(UP,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(JP,"href","/docs/transformers/pr_17313/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(YP,"href","/docs/transformers/pr_17313/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(KP,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraTokenizer"),c(ZP,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(eB,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(oB,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetTokenizer"),c(rB,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(tB,"href","/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(aB,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelTokenizer"),c(nB,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(sB,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(lB,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(iB,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(dB,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(cB,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(fB,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(mB,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(gB,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPTokenizer"),c(hB,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(pB,"href","/docs/transformers/pr_17313/en/model_doc/herbert#transformers.HerbertTokenizer"),c(uB,"href","/docs/transformers/pr_17313/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(_B,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(bB,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaTokenizer"),c(vB,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(FB,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(TB,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(MB,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(EB,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(CB,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(wB,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(AB,"href","/docs/transformers/pr_17313/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(LB,"href","/docs/transformers/pr_17313/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(yB,"href","/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDTokenizer"),c(xB,"href","/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDTokenizerFast"),c($B,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerTokenizer"),c(kB,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(SB,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Tokenizer"),c(RB,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5TokenizerFast"),c(PB,"href","/docs/transformers/pr_17313/en/model_doc/luke#transformers.LukeTokenizer"),c(BB,"href","/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(IB,"href","/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(NB,"href","/docs/transformers/pr_17313/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(qB,"href","/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianTokenizer"),c(jB,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartTokenizer"),c(DB,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(GB,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(OB,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(VB,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizer"),c(XB,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizerFast"),c(zB,"href","/docs/transformers/pr_17313/en/model_doc/mluke#transformers.MLukeTokenizer"),c(WB,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(QB,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(HB,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(UB,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(JB,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Tokenizer"),c(YB,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5TokenizerFast"),c(KB,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertTokenizer"),c(ZB,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(eI,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(oI,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(rI,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(tI,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(aI,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(nI,"href","/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(sI,"href","/docs/transformers/pr_17313/en/model_doc/phobert#transformers.PhobertTokenizer"),c(lI,"href","/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartTokenizer"),c(iI,"href","/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(dI,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizer"),c(cI,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizerFast"),c(fI,"href","/docs/transformers/pr_17313/en/model_doc/rag#transformers.RagTokenizer"),c(mI,"href","/docs/transformers/pr_17313/en/model_doc/realm#transformers.RealmTokenizer"),c(gI,"href","/docs/transformers/pr_17313/en/model_doc/realm#transformers.RealmTokenizerFast"),c(hI,"href","/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerTokenizer"),c(pI,"href","/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(uI,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertTokenizer"),c(_I,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(bI,"href","/docs/transformers/pr_17313/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(vI,"href","/docs/transformers/pr_17313/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(FI,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaTokenizer"),c(TI,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(MI,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(EI,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(CI,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(wI,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(AI,"href","/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterTokenizer"),c(LI,"href","/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(yI,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(xI,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c($I,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Tokenizer"),c(kI,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5TokenizerFast"),c(SI,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasTokenizer"),c(RI,"href","/docs/transformers/pr_17313/en/model_doc/tapex#transformers.TapexTokenizer"),c(PI,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(BI,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizer"),c(II,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizerFast"),c(NI,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizer"),c(qI,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertTokenizerFast"),c(jI,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(DI,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(GI,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(OI,"href","/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMTokenizer"),c(VI,"href","/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(XI,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMTokenizer"),c(zI,"href","/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(WI,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(QI,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(HI,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaTokenizer"),c(UI,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(JI,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(YI,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(KI,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertTokenizer"),c(ZI,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ch,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wh,"id","transformers.AutoFeatureExtractor"),c(wh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wh,"href","#transformers.AutoFeatureExtractor"),c(Si,"class","relative group"),c(eN,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(oN,"href","/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(rN,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(tN,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(aN,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(nN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(sN,"href","/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(lN,"href","/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(iN,"href","/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(dN,"href","/docs/transformers/pr_17313/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(cN,"href","/docs/transformers/pr_17313/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(fN,"href","/docs/transformers/pr_17313/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(mN,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(gN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(hN,"href","/docs/transformers/pr_17313/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(pN,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(uN,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(_N,"href","/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(bN,"href","/docs/transformers/pr_17313/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(vN,"href","/docs/transformers/pr_17313/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(FN,"href","/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(TN,"href","/docs/transformers/pr_17313/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(MN,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(EN,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(CN,"href","/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(wN,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(AN,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(LN,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yN,"href","/docs/transformers/pr_17313/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(xN,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTFeatureExtractor"),c($N,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(SN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(RN,"href","/docs/transformers/pr_17313/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ip,"id","transformers.AutoProcessor"),c(ip,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ip,"href","#transformers.AutoProcessor"),c(Ri,"class","relative group"),c(PN,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(BN,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPProcessor"),c(IN,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPProcessor"),c(NN,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(qN,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(jN,"href","/docs/transformers/pr_17313/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(DN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(GN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ON,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(VN,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(XN,"href","/docs/transformers/pr_17313/en/model_doc/trocr#transformers.TrOCRProcessor"),c(zN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(WN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(QN,"href","/docs/transformers/pr_17313/en/model_doc/vilt#transformers.ViltProcessor"),c(HN,"href","/docs/transformers/pr_17313/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(UN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(JN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(YN,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($p,"id","transformers.AutoModel"),c($p,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($p,"href","#transformers.AutoModel"),c(Bi,"class","relative group"),c(KN,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZN,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eq,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oq,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertModel"),c(rq,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartModel"),c(tq,"href","/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitModel"),c(aq,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertModel"),c(nq,"href","/docs/transformers/pr_17313/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(sq,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdModel"),c(lq,"href","/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(iq,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(dq,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(cq,"href","/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomModel"),c(fq,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertModel"),c(mq,"href","/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineModel"),c(gq,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.CLIPModel"),c(hq,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertModel"),c(pq,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextModel"),c(uq,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLModel"),c(_q,"href","/docs/transformers/pr_17313/en/model_doc/cvt#transformers.CvtModel"),c(bq,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(vq,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(Fq,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(Tq,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaModel"),c(Mq,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(Eq,"href","/docs/transformers/pr_17313/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(Cq,"href","/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTModel"),c(wq,"href","/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrModel"),c(Aq,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertModel"),c(Lq,"href","/docs/transformers/pr_17313/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(yq,"href","/docs/transformers/pr_17313/en/model_doc/dpt#transformers.DPTModel"),c(xq,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraModel"),c($q,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertModel"),c(kq,"href","/docs/transformers/pr_17313/en/model_doc/flava#transformers.FlavaModel"),c(Sq,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetModel"),c(Rq,"href","/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTModel"),c(Pq,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelModel"),c(Bq,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelBaseModel"),c(Iq,"href","/docs/transformers/pr_17313/en/model_doc/glpn#transformers.GLPNModel"),c(Nq,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2Model"),c(qq,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(jq,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Dq,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJModel"),c(Gq,"href","/docs/transformers/pr_17313/en/model_doc/groupvit#transformers.GroupViTModel"),c(Oq,"href","/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertModel"),c(Vq,"href","/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertModel"),c(Xq,"href","/docs/transformers/pr_17313/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(zq,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Wq,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Qq,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Hq,"href","/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDModel"),c(Uq,"href","/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitModel"),c(Jq,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerModel"),c(Yq,"href","/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5Model"),c(Kq,"href","/docs/transformers/pr_17313/en/model_doc/luke#transformers.LukeModel"),c(Zq,"href","/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertModel"),c(ej,"href","/docs/transformers/pr_17313/en/model_doc/m2m_100#transformers.M2M100Model"),c(oj,"href","/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianModel"),c(rj,"href","/docs/transformers/pr_17313/en/model_doc/maskformer#transformers.MaskFormerModel"),c(tj,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartModel"),c(aj,"href","/docs/transformers/pr_17313/en/model_doc/mctct#transformers.MCTCTModel"),c(nj,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(sj,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertModel"),c(lj,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetModel"),c(ij,"href","/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5Model"),c(dj,"href","/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerModel"),c(cj,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(fj,"href","/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTModel"),c(mj,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusModel"),c(gj,"href","/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverModel"),c(hj,"href","/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartModel"),c(pj,"href","/docs/transformers/pr_17313/en/model_doc/poolformer#transformers.PoolFormerModel"),c(uj,"href","/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(_j,"href","/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertModel"),c(bj,"href","/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerModel"),c(vj,"href","/docs/transformers/pr_17313/en/model_doc/regnet#transformers.RegNetModel"),c(Fj,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertModel"),c(Tj,"href","/docs/transformers/pr_17313/en/model_doc/resnet#transformers.ResNetModel"),c(Mj,"href","/docs/transformers/pr_17313/en/model_doc/retribert#transformers.RetriBertModel"),c(Ej,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaModel"),c(Cj,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerModel"),c(wj,"href","/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerModel"),c(Aj,"href","/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWModel"),c(Lj,"href","/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDModel"),c(yj,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(xj,"href","/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterModel"),c($j,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(kj,"href","/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinModel"),c(Sj,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5Model"),c(Rj,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasModel"),c(Pj,"href","/docs/transformers/pr_17313/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(Bj,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(Ij,"href","/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Nj,"href","/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(qj,"href","/docs/transformers/pr_17313/en/model_doc/van#transformers.VanModel"),c(jj,"href","/docs/transformers/pr_17313/en/model_doc/vilt#transformers.ViltModel"),c(Dj,"href","/docs/transformers/pr_17313/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Gj,"href","/docs/transformers/pr_17313/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Oj,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTModel"),c(Vj,"href","/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Xj,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(zj,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Wj,"href","/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMModel"),c(Qj,"href","/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMModel"),c(Hj,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMModel"),c(Uj,"href","/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Jj,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(Yj,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(Kj,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetModel"),c(Zj,"href","/docs/transformers/pr_17313/en/model_doc/yolos#transformers.YolosModel"),c(eD,"href","/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S_,"id","transformers.AutoModelForPreTraining"),c(S_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S_,"href","#transformers.AutoModelForPreTraining"),c(qi,"class","relative group"),c(oD,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rD,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tD,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aD,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForPreTraining"),c(nD,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(sD,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForPreTraining"),c(lD,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(iD,"href","/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomForCausalLM"),c(dD,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(cD,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(fD,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(mD,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(gD,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(hD,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(pD,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForPreTraining"),c(uD,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(_D,"href","/docs/transformers/pr_17313/en/model_doc/flava#transformers.FlavaForPreTraining"),c(bD,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForPreTraining"),c(vD,"href","/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(FD,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(TD,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(MD,"href","/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(ED,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(CD,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(wD,"href","/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(AD,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(LD,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(yD,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(xD,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c($D,"href","/docs/transformers/pr_17313/en/model_doc/retribert#transformers.RetriBertModel"),c(kD,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(SD,"href","/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(RD,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(PD,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(BD,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(ID,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(ND,"href","/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(qD,"href","/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(jD,"href","/docs/transformers/pr_17313/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(DD,"href","/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(GD,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(OD,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(VD,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(XD,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(zD,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(WD,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w1,"id","transformers.AutoModelForCausalLM"),c(w1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w1,"href","#transformers.AutoModelForCausalLM"),c(Gi,"class","relative group"),c(QD,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HD,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UD,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JD,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForCausalLM"),c(YD,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertLMHeadModel"),c(KD,"href","/docs/transformers/pr_17313/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(ZD,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(eG,"href","/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(oG,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(rG,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(tG,"href","/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomForCausalLM"),c(aG,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(nG,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(sG,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(lG,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForCausalLM"),c(iG,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(dG,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(cG,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(fG,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(mG,"href","/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianForCausalLM"),c(gG,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForCausalLM"),c(hG,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(pG,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(uG,"href","/docs/transformers/pr_17313/en/model_doc/opt#transformers.OPTForCausalLM"),c(_G,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(bG,"href","/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(vG,"href","/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(FG,"href","/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(TG,"href","/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(MG,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(EG,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(CG,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(wG,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(AG,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(LG,"href","/docs/transformers/pr_17313/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(yG,"href","/docs/transformers/pr_17313/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(xG,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c($G,"href","/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(kG,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(SG,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(RG,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g3,"id","transformers.AutoModelForMaskedLM"),c(g3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g3,"href","#transformers.AutoModelForMaskedLM"),c(Xi,"class","relative group"),c(PG,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BG,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IG,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NG,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(qG,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(jG,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForMaskedLM"),c(DG,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(GG,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(OG,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(VG,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(XG,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(zG,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(WG,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(QG,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(HG,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(UG,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(JG,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(YG,"href","/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(KG,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(ZG,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(eO,"href","/docs/transformers/pr_17313/en/model_doc/luke#transformers.LukeForMaskedLM"),c(oO,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(rO,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(tO,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(aO,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(nO,"href","/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(sO,"href","/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(lO,"href","/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(iO,"href","/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(dO,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(cO,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(fO,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(mO,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(gO,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(hO,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(pO,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(uO,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(_O,"href","/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z3,"id","transformers.AutoModelForSeq2SeqLM"),c(Z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z3,"href","#transformers.AutoModelForSeq2SeqLM"),c(Qi,"class","relative group"),c(bO,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vO,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FO,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TO,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(MO,"href","/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(EO,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(CO,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(wO,"href","/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(AO,"href","/docs/transformers/pr_17313/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(LO,"href","/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(yO,"href","/docs/transformers/pr_17313/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(xO,"href","/docs/transformers/pr_17313/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c($O,"href","/docs/transformers/pr_17313/en/model_doc/marian#transformers.MarianMTModel"),c(kO,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(SO,"href","/docs/transformers/pr_17313/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(RO,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(PO,"href","/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(BO,"href","/docs/transformers/pr_17313/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(IO,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(NO,"href","/docs/transformers/pr_17313/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F2,"id","transformers.AutoModelForSequenceClassification"),c(F2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F2,"href","#transformers.AutoModelForSequenceClassification"),c(Ji,"class","relative group"),c(qO,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jO,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DO,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GO,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(OO,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForSequenceClassification"),c(VO,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForSequenceClassification"),c(XO,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(zO,"href","/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(WO,"href","/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(QO,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(HO,"href","/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(UO,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(JO,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(YO,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(KO,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(ZO,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(eV,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(oV,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(rV,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(tV,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(aV,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(nV,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(sV,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(lV,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(iV,"href","/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(dV,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(cV,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(fV,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(mV,"href","/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDForSequenceClassification"),c(gV,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(hV,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(pV,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(uV,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(_V,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(bV,"href","/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(vV,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(FV,"href","/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(TV,"href","/docs/transformers/pr_17313/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(MV,"href","/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(EV,"href","/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(CV,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(wV,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(AV,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(LV,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(yV,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(xV,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c($V,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(kV,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(SV,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(RV,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(PV,"href","/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bb,"id","transformers.AutoModelForMultipleChoice"),c(bb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bb,"href","#transformers.AutoModelForMultipleChoice"),c(Zi,"class","relative group"),c(BV,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IV,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NV,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qV,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(jV,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForMultipleChoice"),c(DV,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(GV,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(OV,"href","/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(VV,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(XV,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(zV,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(WV,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(QV,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(HV,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(UV,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(JV,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(YV,"href","/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(KV,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(ZV,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(eX,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(oX,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(rX,"href","/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(tX,"href","/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(aX,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(nX,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(sX,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(lX,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(iX,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(dX,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(cX,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(fX,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(mX,"href","/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yb,"id","transformers.AutoModelForNextSentencePrediction"),c(Yb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yb,"href","#transformers.AutoModelForNextSentencePrediction"),c(rd,"class","relative group"),c(gX,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hX,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pX,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uX,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(_X,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(bX,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(vX,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(FX,"href","/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sv,"id","transformers.AutoModelForTokenClassification"),c(sv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sv,"href","#transformers.AutoModelForTokenClassification"),c(nd,"class","relative group"),c(TX,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MX,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EX,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CX,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(wX,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForTokenClassification"),c(AX,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(LX,"href","/docs/transformers/pr_17313/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(yX,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(xX,"href","/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineForTokenClassification"),c($X,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(kX,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(SX,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(RX,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(PX,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(BX,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(IX,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(NX,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(qX,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(jX,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(DX,"href","/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(GX,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(OX,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(VX,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(XX,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(zX,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(WX,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(QX,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(HX,"href","/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(UX,"href","/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(JX,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(YX,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(KX,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(ZX,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(ez,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(oz,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(rz,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(tz,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(az,"href","/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zv,"id","transformers.AutoModelForQuestionAnswering"),c(zv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zv,"href","#transformers.AutoModelForQuestionAnswering"),c(id,"class","relative group"),c(nz,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sz,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lz,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iz,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(dz,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(cz,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(fz,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(mz,"href","/docs/transformers/pr_17313/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(gz,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(hz,"href","/docs/transformers/pr_17313/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(pz,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(uz,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(_z,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(bz,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(vz,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(Fz,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(Tz,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(Mz,"href","/docs/transformers/pr_17313/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(Ez,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(Cz,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(wz,"href","/docs/transformers/pr_17313/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(Az,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(Lz,"href","/docs/transformers/pr_17313/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(yz,"href","/docs/transformers/pr_17313/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(xz,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c($z,"href","/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(kz,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(Sz,"href","/docs/transformers/pr_17313/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(Rz,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(Pz,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(Bz,"href","/docs/transformers/pr_17313/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(Iz,"href","/docs/transformers/pr_17313/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(Nz,"href","/docs/transformers/pr_17313/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(qz,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(jz,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(Dz,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(Gz,"href","/docs/transformers/pr_17313/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(Oz,"href","/docs/transformers/pr_17313/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(Vz,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(Xz,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(zz,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(Wz,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(Qz,"href","/docs/transformers/pr_17313/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BF,"id","transformers.AutoModelForTableQuestionAnswering"),c(BF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BF,"href","#transformers.AutoModelForTableQuestionAnswering"),c(fd,"class","relative group"),c(Hz,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uz,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jz,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yz,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DF,"id","transformers.AutoModelForImageClassification"),c(DF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DF,"href","#transformers.AutoModelForImageClassification"),c(hd,"class","relative group"),c(Kz,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zz,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oW,"href","/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitForImageClassification"),c(rW,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(tW,"href","/docs/transformers/pr_17313/en/model_doc/cvt#transformers.CvtForImageClassification"),c(aW,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(nW,"href","/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTForImageClassification"),c(sW,"href","/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(lW,"href","/docs/transformers/pr_17313/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(iW,"href","/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitForImageClassification"),c(dW,"href","/docs/transformers/pr_17313/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(cW,"href","/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(fW,"href","/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(mW,"href","/docs/transformers/pr_17313/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(gW,"href","/docs/transformers/pr_17313/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(hW,"href","/docs/transformers/pr_17313/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(pW,"href","/docs/transformers/pr_17313/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(uW,"href","/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(_W,"href","/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinForImageClassification"),c(bW,"href","/docs/transformers/pr_17313/en/model_doc/van#transformers.VanForImageClassification"),c(vW,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rT,"id","transformers.AutoModelForVision2Seq"),c(rT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rT,"href","#transformers.AutoModelForVision2Seq"),c(_d,"class","relative group"),c(FW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EW,"href","/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lT,"id","transformers.AutoModelForVisualQuestionAnswering"),c(lT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lT,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Fd,"class","relative group"),c(CW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LW,"href","/docs/transformers/pr_17313/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mT,"id","transformers.AutoModelForAudioClassification"),c(mT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mT,"href","#transformers.AutoModelForAudioClassification"),c(Ed,"class","relative group"),c(yW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($W,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kW,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(SW,"href","/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(RW,"href","/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(PW,"href","/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(BW,"href","/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(IW,"href","/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(NW,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(qW,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(jW,"href","/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wT,"id","transformers.AutoModelForAudioFrameClassification"),c(wT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wT,"href","#transformers.AutoModelForAudioFrameClassification"),c(Ad,"class","relative group"),c(DW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VW,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(XW,"href","/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(zW,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(WW,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(QW,"href","/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PT,"id","transformers.AutoModelForCTC"),c(PT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PT,"href","#transformers.AutoModelForCTC"),c(xd,"class","relative group"),c(HW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JW,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YW,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(KW,"href","/docs/transformers/pr_17313/en/model_doc/hubert#transformers.HubertForCTC"),c(ZW,"href","/docs/transformers/pr_17313/en/model_doc/mctct#transformers.MCTCTForCTC"),c(eQ,"href","/docs/transformers/pr_17313/en/model_doc/sew#transformers.SEWForCTC"),c(oQ,"href","/docs/transformers/pr_17313/en/model_doc/sew-d#transformers.SEWDForCTC"),c(rQ,"href","/docs/transformers/pr_17313/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(tQ,"href","/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(aQ,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(nQ,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(sQ,"href","/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HT,"id","transformers.AutoModelForSpeechSeq2Seq"),c(HT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(HT,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Sd,"class","relative group"),c(lQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cQ,"href","/docs/transformers/pr_17313/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(fQ,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e7,"id","transformers.AutoModelForAudioXVector"),c(e7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e7,"href","#transformers.AutoModelForAudioXVector"),c(Bd,"class","relative group"),c(mQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pQ,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(uQ,"href","/docs/transformers/pr_17313/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(_Q,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(bQ,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(vQ,"href","/docs/transformers/pr_17313/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d7,"id","transformers.AutoModelForMaskedImageModeling"),c(d7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d7,"href","#transformers.AutoModelForMaskedImageModeling"),c(qd,"class","relative group"),c(FQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EQ,"href","/docs/transformers/pr_17313/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(CQ,"href","/docs/transformers/pr_17313/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(wQ,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u7,"id","transformers.AutoModelForObjectDetection"),c(u7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u7,"href","#transformers.AutoModelForObjectDetection"),c(Od,"class","relative group"),c(AQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xQ,"href","/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrForObjectDetection"),c($Q,"href","/docs/transformers/pr_17313/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(M7,"id","transformers.AutoModelForImageSegmentation"),c(M7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M7,"href","#transformers.AutoModelForImageSegmentation"),c(zd,"class","relative group"),c(kQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PQ,"href","/docs/transformers/pr_17313/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L7,"id","transformers.AutoModelForSemanticSegmentation"),c(L7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L7,"href","#transformers.AutoModelForSemanticSegmentation"),c(Hd,"class","relative group"),c(BQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qQ,"href","/docs/transformers/pr_17313/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(jQ,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(DQ,"href","/docs/transformers/pr_17313/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(GQ,"href","/docs/transformers/pr_17313/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B7,"id","transformers.AutoModelForInstanceSegmentation"),c(B7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B7,"href","#transformers.AutoModelForInstanceSegmentation"),c(Yd,"class","relative group"),c(OQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zQ,"href","/docs/transformers/pr_17313/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D7,"id","transformers.TFAutoModel"),c(D7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D7,"href","#transformers.TFAutoModel"),c(ec,"class","relative group"),c(WQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HQ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UQ,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertModel"),c(JQ,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.TFBartModel"),c(YQ,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertModel"),c(KQ,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(ZQ,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(eH,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertModel"),c(oH,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.TFCLIPModel"),c(rH,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertModel"),c(tH,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.TFConvNextModel"),c(aH,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.TFCTRLModel"),c(nH,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(sH,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaModel"),c(lH,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(iH,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(dH,"href","/docs/transformers/pr_17313/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(cH,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraModel"),c(fH,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(mH,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelModel"),c(gH,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(hH,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.TFGPT2Model"),c(pH,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.TFGPTJModel"),c(uH,"href","/docs/transformers/pr_17313/en/model_doc/hubert#transformers.TFHubertModel"),c(_H,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(bH,"href","/docs/transformers/pr_17313/en/model_doc/led#transformers.TFLEDModel"),c(vH,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerModel"),c(FH,"href","/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.TFLxmertModel"),c(TH,"href","/docs/transformers/pr_17313/en/model_doc/marian#transformers.TFMarianModel"),c(MH,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.TFMBartModel"),c(EH,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(CH,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetModel"),c(wH,"href","/docs/transformers/pr_17313/en/model_doc/mt5#transformers.TFMT5Model"),c(AH,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(LH,"href","/docs/transformers/pr_17313/en/model_doc/opt#transformers.TFOPTModel"),c(yH,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.TFPegasusModel"),c(xH,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertModel"),c($H,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaModel"),c(kH,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerModel"),c(SH,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(RH,"href","/docs/transformers/pr_17313/en/model_doc/swin#transformers.TFSwinModel"),c(PH,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.TFT5Model"),c(BH,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasModel"),c(IH,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(NH,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.TFViTModel"),c(qH,"href","/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(jH,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(DH,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMModel"),c(GH,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(OH,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BM,"id","transformers.TFAutoModelForPreTraining"),c(BM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BM,"href","#transformers.TFAutoModelForPreTraining"),c(tc,"class","relative group"),c(VH,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XH,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zH,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WH,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(QH,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(HH,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForPreTraining"),c(UH,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(JH,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(YH,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(KH,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(ZH,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(eU,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(oU,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(rU,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(tU,"href","/docs/transformers/pr_17313/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(aU,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(nU,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(sU,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(lU,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(iU,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(dU,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(cU,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(fU,"href","/docs/transformers/pr_17313/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(mU,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(gU,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(hU,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lE,"id","transformers.TFAutoModelForCausalLM"),c(lE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lE,"href","#transformers.TFAutoModelForCausalLM"),c(sc,"class","relative group"),c(pU,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uU,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_U,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bU,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(vU,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(FU,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(TU,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(MU,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(EU,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(CU,"href","/docs/transformers/pr_17313/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(wU,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(AU,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(LU,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(yU,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(xU,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c($U,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EE,"id","transformers.TFAutoModelForImageClassification"),c(EE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EE,"href","#transformers.TFAutoModelForImageClassification"),c(dc,"class","relative group"),c(kU,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SU,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RU,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PU,"href","/docs/transformers/pr_17313/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(BU,"href","/docs/transformers/pr_17313/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(IU,"href","/docs/transformers/pr_17313/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(NU,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.TFViTForImageClassification"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($E,"id","transformers.TFAutoModelForMaskedLM"),c($E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($E,"href","#transformers.TFAutoModelForMaskedLM"),c(mc,"class","relative group"),c(qU,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jU,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DU,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GU,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(OU,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(VU,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(XU,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(zU,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(WU,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(QU,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(HU,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(UU,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(JU,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(YU,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(KU,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(ZU,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(eJ,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(oJ,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(rJ,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(tJ,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(aJ,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(nJ,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(sJ,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZE,"id","transformers.TFAutoModelForSeq2SeqLM"),c(ZE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZE,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(pc,"class","relative group"),c(lJ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iJ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dJ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cJ,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(fJ,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(mJ,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(gJ,"href","/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(hJ,"href","/docs/transformers/pr_17313/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(pJ,"href","/docs/transformers/pr_17313/en/model_doc/marian#transformers.TFMarianMTModel"),c(uJ,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(_J,"href","/docs/transformers/pr_17313/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(bJ,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(vJ,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m4,"id","transformers.TFAutoModelForSequenceClassification"),c(m4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m4,"href","#transformers.TFAutoModelForSequenceClassification"),c(bc,"class","relative group"),c(FJ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TJ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MJ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EJ,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(CJ,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(wJ,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(AJ,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(LJ,"href","/docs/transformers/pr_17313/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(yJ,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(xJ,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c($J,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(kJ,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(SJ,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(RJ,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(PJ,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(BJ,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(IJ,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(NJ,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(qJ,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(jJ,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(DJ,"href","/docs/transformers/pr_17313/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(GJ,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(OJ,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(VJ,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(XJ,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(zJ,"href","/docs/transformers/pr_17313/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(WJ,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(QJ,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(HJ,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G4,"id","transformers.TFAutoModelForMultipleChoice"),c(G4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G4,"href","#transformers.TFAutoModelForMultipleChoice"),c(Tc,"class","relative group"),c(UJ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JJ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YJ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KJ,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(ZJ,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(eY,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(oY,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(rY,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(tY,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(aY,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(nY,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(sY,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(lY,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(iY,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(dY,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(cY,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(fY,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(mY,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(gY,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(hY,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lC,"id","transformers.TFAutoModelForNextSentencePrediction"),c(lC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lC,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Cc,"class","relative group"),c(pY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_Y,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bY,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(vY,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mC,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(mC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mC,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Lc,"class","relative group"),c(FY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EY,"href","/docs/transformers/pr_17313/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uC,"id","transformers.TFAutoModelForTokenClassification"),c(uC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uC,"href","#transformers.TFAutoModelForTokenClassification"),c($c,"class","relative group"),c(CY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LY,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(yY,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(xY,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c($Y,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(kY,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(SY,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(RY,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(PY,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(BY,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(IY,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(NY,"href","/docs/transformers/pr_17313/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(qY,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(jY,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(DY,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(GY,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(OY,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(VY,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(XY,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(zY,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(WY,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jC,"id","transformers.TFAutoModelForQuestionAnswering"),c(jC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jC,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Rc,"class","relative group"),c(QY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UY,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JY,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(YY,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(KY,"href","/docs/transformers/pr_17313/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(ZY,"href","/docs/transformers/pr_17313/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(eK,"href","/docs/transformers/pr_17313/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(oK,"href","/docs/transformers/pr_17313/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(rK,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(tK,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(aK,"href","/docs/transformers/pr_17313/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(nK,"href","/docs/transformers/pr_17313/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(sK,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(lK,"href","/docs/transformers/pr_17313/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(iK,"href","/docs/transformers/pr_17313/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(dK,"href","/docs/transformers/pr_17313/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(cK,"href","/docs/transformers/pr_17313/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(fK,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(mK,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(gK,"href","/docs/transformers/pr_17313/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(hK,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(pK,"href","/docs/transformers/pr_17313/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i5,"id","transformers.TFAutoModelForVision2Seq"),c(i5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i5,"href","#transformers.TFAutoModelForVision2Seq"),c(Ic,"class","relative group"),c(uK,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_K,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bK,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vK,"href","/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m5,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(m5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m5,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(jc,"class","relative group"),c(FK,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TK,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MK,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EK,"href","/docs/transformers/pr_17313/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u5,"id","transformers.FlaxAutoModel"),c(u5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u5,"href","#transformers.FlaxAutoModel"),c(Oc,"class","relative group"),c(CK,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wK,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AK,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LK,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertModel"),c(yK,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartModel"),c(xK,"href","/docs/transformers/pr_17313/en/model_doc/beit#transformers.FlaxBeitModel"),c($K,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertModel"),c(kK,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(SK,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(RK,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(PK,"href","/docs/transformers/pr_17313/en/model_doc/clip#transformers.FlaxCLIPModel"),c(BK,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(IK,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraModel"),c(NK,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(qK,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(jK,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(DK,"href","/docs/transformers/pr_17313/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(GK,"href","/docs/transformers/pr_17313/en/model_doc/marian#transformers.FlaxMarianModel"),c(OK,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartModel"),c(VK,"href","/docs/transformers/pr_17313/en/model_doc/mt5#transformers.FlaxMT5Model"),c(XK,"href","/docs/transformers/pr_17313/en/model_doc/opt#transformers.FlaxOPTModel"),c(zK,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(WK,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(QK,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(HK,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.FlaxT5Model"),c(UK,"href","/docs/transformers/pr_17313/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(JK,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.FlaxViTModel"),c(YK,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(KK,"href","/docs/transformers/pr_17313/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(ZK,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W5,"id","transformers.FlaxAutoModelForCausalLM"),c(W5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W5,"href","#transformers.FlaxAutoModelForCausalLM"),c(zc,"class","relative group"),c(eZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tZ,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(aZ,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(nZ,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(sZ,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(lZ,"href","/docs/transformers/pr_17313/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(iZ,"href","/docs/transformers/pr_17313/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(dZ,"href","/docs/transformers/pr_17313/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(cZ,"href","/docs/transformers/pr_17313/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(fZ,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(mZ,"href","/docs/transformers/pr_17313/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n0,"id","transformers.FlaxAutoModelForPreTraining"),c(n0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n0,"href","#transformers.FlaxAutoModelForPreTraining"),c(Hc,"class","relative group"),c(gZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uZ,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(_Z,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(bZ,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(vZ,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(FZ,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(TZ,"href","/docs/transformers/pr_17313/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(MZ,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(EZ,"href","/docs/transformers/pr_17313/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(CZ,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(wZ,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(AZ,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(LZ,"href","/docs/transformers/pr_17313/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(yZ,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T0,"id","transformers.FlaxAutoModelForMaskedLM"),c(T0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T0,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Yc,"class","relative group"),c(xZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($Z,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SZ,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(RZ,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(PZ,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(BZ,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(IZ,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(NZ,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(qZ,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(jZ,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(DZ,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(GZ,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P0,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(P0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P0,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(ef,"class","relative group"),c(OZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XZ,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zZ,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(WZ,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(QZ,"href","/docs/transformers/pr_17313/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(HZ,"href","/docs/transformers/pr_17313/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(UZ,"href","/docs/transformers/pr_17313/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(JZ,"href","/docs/transformers/pr_17313/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(YZ,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(KZ,"href","/docs/transformers/pr_17313/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(ZZ,"href","/docs/transformers/pr_17313/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(eee,"href","/docs/transformers/pr_17313/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q0,"id","transformers.FlaxAutoModelForSequenceClassification"),c(Q0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q0,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(tf,"class","relative group"),c(oee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ree,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aee,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(nee,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(see,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(lee,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(iee,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(dee,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(cee,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(fee,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(mee,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(gee,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sw,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(sw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sw,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(sf,"class","relative group"),c(hee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_ee,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(bee,"href","/docs/transformers/pr_17313/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(vee,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(Fee,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(Tee,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(Mee,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Eee,"href","/docs/transformers/pr_17313/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Cee,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(wee,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Aee,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vw,"id","transformers.FlaxAutoModelForTokenClassification"),c(vw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vw,"href","#transformers.FlaxAutoModelForTokenClassification"),c(cf,"class","relative group"),c(Lee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($ee,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(kee,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(See,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Ree,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Pee,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Bee,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Iee,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Nee,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($w,"id","transformers.FlaxAutoModelForMultipleChoice"),c($w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($w,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(gf,"class","relative group"),c(qee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Dee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gee,"href","/docs/transformers/pr_17313/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Oee,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Vee,"href","/docs/transformers/pr_17313/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Xee,"href","/docs/transformers/pr_17313/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(zee,"href","/docs/transformers/pr_17313/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Wee,"href","/docs/transformers/pr_17313/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Qee,"href","/docs/transformers/pr_17313/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Hee,"href","/docs/transformers/pr_17313/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gw,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Gw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Gw,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(uf,"class","relative group"),c(Uee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kee,"href","/docs/transformers/pr_17313/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zw,"id","transformers.FlaxAutoModelForImageClassification"),c(zw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zw,"href","#transformers.FlaxAutoModelForImageClassification"),c(vf,"class","relative group"),c(Zee,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eoe,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ooe,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(roe,"href","/docs/transformers/pr_17313/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(toe,"href","/docs/transformers/pr_17313/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jw,"id","transformers.FlaxAutoModelForVision2Seq"),c(Jw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jw,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Mf,"class","relative group"),c(aoe,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(noe,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(soe,"href","/docs/transformers/pr_17313/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(loe,"href","/docs/transformers/pr_17313/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),b(f,v,_),b(f,p,_),e(p,m),e(m,u),M(d,u,null),e(p,h),e(p,Eo),e(Eo,Ti),b(f,yf,_),b(f,at,_),e(at,Mi),e(at,Ei),e(Ei,FL),e(at,xf),b(f,Oe,_),b(f,We,_),e(We,Ci),e(We,Sn),e(Sn,TL),e(We,Rn),e(We,Pn),e(Pn,ML),e(We,wi),e(We,Bn),e(Bn,EL),e(We,Ai),b(f,$f,_),M(ya,f,_),b(f,Qe,_),b(f,Ae,_),e(Ae,Yk),e(Ae,Li),e(Li,Kk),e(Ae,Zk),b(f,Co,_),b(f,xa,_),e(xa,eS),e(xa,kf),e(kf,oS),e(xa,Pze),b(f,vGe,_),b(f,yi,_),e(yi,Sf),e(Sf,rte),M(CL,rte,null),e(yi,Bze),e(yi,tte),e(tte,Ize),b(f,FGe,_),b(f,In,_),e(In,Nze),e(In,ate),e(ate,qze),e(In,jze),e(In,nte),e(nte,Dze),e(In,Gze),b(f,TGe,_),M(wL,f,_),b(f,MGe,_),b(f,rS,_),e(rS,Oze),b(f,EGe,_),M(Rf,f,_),b(f,CGe,_),b(f,xi,_),e(xi,Pf),e(Pf,ste),M(AL,ste,null),e(xi,Vze),e(xi,lte),e(lte,Xze),b(f,wGe,_),b(f,wo,_),M(LL,wo,null),e(wo,zze),e(wo,yL),e(yL,Wze),e(yL,tS),e(tS,Qze),e(yL,Hze),e(wo,Uze),e(wo,xL),e(xL,Jze),e(xL,ite),e(ite,Yze),e(xL,Kze),e(wo,Zze),e(wo,wr),M($L,wr,null),e(wr,eWe),e(wr,dte),e(dte,oWe),e(wr,rWe),e(wr,$i),e($i,tWe),e($i,cte),e(cte,aWe),e($i,nWe),e($i,fte),e(fte,sWe),e($i,lWe),e(wr,iWe),e(wr,A),e(A,Bf),e(Bf,mte),e(mte,dWe),e(Bf,cWe),e(Bf,aS),e(aS,fWe),e(Bf,mWe),e(A,gWe),e(A,If),e(If,gte),e(gte,hWe),e(If,pWe),e(If,nS),e(nS,uWe),e(If,_We),e(A,bWe),e(A,Nf),e(Nf,hte),e(hte,vWe),e(Nf,FWe),e(Nf,sS),e(sS,TWe),e(Nf,MWe),e(A,EWe),e(A,qf),e(qf,pte),e(pte,CWe),e(qf,wWe),e(qf,lS),e(lS,AWe),e(qf,LWe),e(A,yWe),e(A,jf),e(jf,ute),e(ute,xWe),e(jf,$We),e(jf,iS),e(iS,kWe),e(jf,SWe),e(A,RWe),e(A,Df),e(Df,_te),e(_te,PWe),e(Df,BWe),e(Df,dS),e(dS,IWe),e(Df,NWe),e(A,qWe),e(A,Gf),e(Gf,bte),e(bte,jWe),e(Gf,DWe),e(Gf,cS),e(cS,GWe),e(Gf,OWe),e(A,VWe),e(A,Of),e(Of,vte),e(vte,XWe),e(Of,zWe),e(Of,fS),e(fS,WWe),e(Of,QWe),e(A,HWe),e(A,Vf),e(Vf,Fte),e(Fte,UWe),e(Vf,JWe),e(Vf,mS),e(mS,YWe),e(Vf,KWe),e(A,ZWe),e(A,Xf),e(Xf,Tte),e(Tte,eQe),e(Xf,oQe),e(Xf,gS),e(gS,rQe),e(Xf,tQe),e(A,aQe),e(A,zf),e(zf,Mte),e(Mte,nQe),e(zf,sQe),e(zf,hS),e(hS,lQe),e(zf,iQe),e(A,dQe),e(A,Wf),e(Wf,Ete),e(Ete,cQe),e(Wf,fQe),e(Wf,pS),e(pS,mQe),e(Wf,gQe),e(A,hQe),e(A,Qf),e(Qf,Cte),e(Cte,pQe),e(Qf,uQe),e(Qf,uS),e(uS,_Qe),e(Qf,bQe),e(A,vQe),e(A,Hf),e(Hf,wte),e(wte,FQe),e(Hf,TQe),e(Hf,_S),e(_S,MQe),e(Hf,EQe),e(A,CQe),e(A,Uf),e(Uf,Ate),e(Ate,wQe),e(Uf,AQe),e(Uf,bS),e(bS,LQe),e(Uf,yQe),e(A,xQe),e(A,Jf),e(Jf,Lte),e(Lte,$Qe),e(Jf,kQe),e(Jf,vS),e(vS,SQe),e(Jf,RQe),e(A,PQe),e(A,Yf),e(Yf,yte),e(yte,BQe),e(Yf,IQe),e(Yf,FS),e(FS,NQe),e(Yf,qQe),e(A,jQe),e(A,Kf),e(Kf,xte),e(xte,DQe),e(Kf,GQe),e(Kf,TS),e(TS,OQe),e(Kf,VQe),e(A,XQe),e(A,Zf),e(Zf,$te),e($te,zQe),e(Zf,WQe),e(Zf,MS),e(MS,QQe),e(Zf,HQe),e(A,UQe),e(A,em),e(em,kte),e(kte,JQe),e(em,YQe),e(em,ES),e(ES,KQe),e(em,ZQe),e(A,eHe),e(A,om),e(om,Ste),e(Ste,oHe),e(om,rHe),e(om,CS),e(CS,tHe),e(om,aHe),e(A,nHe),e(A,rm),e(rm,Rte),e(Rte,sHe),e(rm,lHe),e(rm,wS),e(wS,iHe),e(rm,dHe),e(A,cHe),e(A,tm),e(tm,Pte),e(Pte,fHe),e(tm,mHe),e(tm,AS),e(AS,gHe),e(tm,hHe),e(A,pHe),e(A,am),e(am,Bte),e(Bte,uHe),e(am,_He),e(am,LS),e(LS,bHe),e(am,vHe),e(A,FHe),e(A,nm),e(nm,Ite),e(Ite,THe),e(nm,MHe),e(nm,yS),e(yS,EHe),e(nm,CHe),e(A,wHe),e(A,sm),e(sm,Nte),e(Nte,AHe),e(sm,LHe),e(sm,xS),e(xS,yHe),e(sm,xHe),e(A,$He),e(A,lm),e(lm,qte),e(qte,kHe),e(lm,SHe),e(lm,$S),e($S,RHe),e(lm,PHe),e(A,BHe),e(A,im),e(im,jte),e(jte,IHe),e(im,NHe),e(im,kS),e(kS,qHe),e(im,jHe),e(A,DHe),e(A,dm),e(dm,Dte),e(Dte,GHe),e(dm,OHe),e(dm,SS),e(SS,VHe),e(dm,XHe),e(A,zHe),e(A,cm),e(cm,Gte),e(Gte,WHe),e(cm,QHe),e(cm,RS),e(RS,HHe),e(cm,UHe),e(A,JHe),e(A,fm),e(fm,Ote),e(Ote,YHe),e(fm,KHe),e(fm,PS),e(PS,ZHe),e(fm,eUe),e(A,oUe),e(A,mm),e(mm,Vte),e(Vte,rUe),e(mm,tUe),e(mm,BS),e(BS,aUe),e(mm,nUe),e(A,sUe),e(A,gm),e(gm,Xte),e(Xte,lUe),e(gm,iUe),e(gm,IS),e(IS,dUe),e(gm,cUe),e(A,fUe),e(A,hm),e(hm,zte),e(zte,mUe),e(hm,gUe),e(hm,NS),e(NS,hUe),e(hm,pUe),e(A,uUe),e(A,pm),e(pm,Wte),e(Wte,_Ue),e(pm,bUe),e(pm,qS),e(qS,vUe),e(pm,FUe),e(A,TUe),e(A,um),e(um,Qte),e(Qte,MUe),e(um,EUe),e(um,jS),e(jS,CUe),e(um,wUe),e(A,AUe),e(A,_m),e(_m,Hte),e(Hte,LUe),e(_m,yUe),e(_m,DS),e(DS,xUe),e(_m,$Ue),e(A,kUe),e(A,bm),e(bm,Ute),e(Ute,SUe),e(bm,RUe),e(bm,GS),e(GS,PUe),e(bm,BUe),e(A,IUe),e(A,vm),e(vm,Jte),e(Jte,NUe),e(vm,qUe),e(vm,OS),e(OS,jUe),e(vm,DUe),e(A,GUe),e(A,Fm),e(Fm,Yte),e(Yte,OUe),e(Fm,VUe),e(Fm,VS),e(VS,XUe),e(Fm,zUe),e(A,WUe),e(A,Tm),e(Tm,Kte),e(Kte,QUe),e(Tm,HUe),e(Tm,XS),e(XS,UUe),e(Tm,JUe),e(A,YUe),e(A,Mm),e(Mm,Zte),e(Zte,KUe),e(Mm,ZUe),e(Mm,zS),e(zS,eJe),e(Mm,oJe),e(A,rJe),e(A,Em),e(Em,eae),e(eae,tJe),e(Em,aJe),e(Em,WS),e(WS,nJe),e(Em,sJe),e(A,lJe),e(A,Cm),e(Cm,oae),e(oae,iJe),e(Cm,dJe),e(Cm,QS),e(QS,cJe),e(Cm,fJe),e(A,mJe),e(A,wm),e(wm,rae),e(rae,gJe),e(wm,hJe),e(wm,HS),e(HS,pJe),e(wm,uJe),e(A,_Je),e(A,Am),e(Am,tae),e(tae,bJe),e(Am,vJe),e(Am,US),e(US,FJe),e(Am,TJe),e(A,MJe),e(A,Lm),e(Lm,aae),e(aae,EJe),e(Lm,CJe),e(Lm,JS),e(JS,wJe),e(Lm,AJe),e(A,LJe),e(A,ym),e(ym,nae),e(nae,yJe),e(ym,xJe),e(ym,YS),e(YS,$Je),e(ym,kJe),e(A,SJe),e(A,xm),e(xm,sae),e(sae,RJe),e(xm,PJe),e(xm,KS),e(KS,BJe),e(xm,IJe),e(A,NJe),e(A,$m),e($m,lae),e(lae,qJe),e($m,jJe),e($m,ZS),e(ZS,DJe),e($m,GJe),e(A,OJe),e(A,km),e(km,iae),e(iae,VJe),e(km,XJe),e(km,eR),e(eR,zJe),e(km,WJe),e(A,QJe),e(A,Sm),e(Sm,dae),e(dae,HJe),e(Sm,UJe),e(Sm,oR),e(oR,JJe),e(Sm,YJe),e(A,KJe),e(A,Rm),e(Rm,cae),e(cae,ZJe),e(Rm,eYe),e(Rm,rR),e(rR,oYe),e(Rm,rYe),e(A,tYe),e(A,Pm),e(Pm,fae),e(fae,aYe),e(Pm,nYe),e(Pm,tR),e(tR,sYe),e(Pm,lYe),e(A,iYe),e(A,Bm),e(Bm,mae),e(mae,dYe),e(Bm,cYe),e(Bm,aR),e(aR,fYe),e(Bm,mYe),e(A,gYe),e(A,Im),e(Im,gae),e(gae,hYe),e(Im,pYe),e(Im,nR),e(nR,uYe),e(Im,_Ye),e(A,bYe),e(A,Nm),e(Nm,hae),e(hae,vYe),e(Nm,FYe),e(Nm,sR),e(sR,TYe),e(Nm,MYe),e(A,EYe),e(A,qm),e(qm,pae),e(pae,CYe),e(qm,wYe),e(qm,lR),e(lR,AYe),e(qm,LYe),e(A,yYe),e(A,jm),e(jm,uae),e(uae,xYe),e(jm,$Ye),e(jm,iR),e(iR,kYe),e(jm,SYe),e(A,RYe),e(A,Dm),e(Dm,_ae),e(_ae,PYe),e(Dm,BYe),e(Dm,dR),e(dR,IYe),e(Dm,NYe),e(A,qYe),e(A,Gm),e(Gm,bae),e(bae,jYe),e(Gm,DYe),e(Gm,cR),e(cR,GYe),e(Gm,OYe),e(A,VYe),e(A,Om),e(Om,vae),e(vae,XYe),e(Om,zYe),e(Om,fR),e(fR,WYe),e(Om,QYe),e(A,HYe),e(A,Vm),e(Vm,Fae),e(Fae,UYe),e(Vm,JYe),e(Vm,mR),e(mR,YYe),e(Vm,KYe),e(A,ZYe),e(A,Xm),e(Xm,Tae),e(Tae,eKe),e(Xm,oKe),e(Xm,gR),e(gR,rKe),e(Xm,tKe),e(A,aKe),e(A,zm),e(zm,Mae),e(Mae,nKe),e(zm,sKe),e(zm,hR),e(hR,lKe),e(zm,iKe),e(A,dKe),e(A,Wm),e(Wm,Eae),e(Eae,cKe),e(Wm,fKe),e(Wm,pR),e(pR,mKe),e(Wm,gKe),e(A,hKe),e(A,Qm),e(Qm,Cae),e(Cae,pKe),e(Qm,uKe),e(Qm,uR),e(uR,_Ke),e(Qm,bKe),e(A,vKe),e(A,Hm),e(Hm,wae),e(wae,FKe),e(Hm,TKe),e(Hm,_R),e(_R,MKe),e(Hm,EKe),e(A,CKe),e(A,Um),e(Um,Aae),e(Aae,wKe),e(Um,AKe),e(Um,bR),e(bR,LKe),e(Um,yKe),e(A,xKe),e(A,Jm),e(Jm,Lae),e(Lae,$Ke),e(Jm,kKe),e(Jm,vR),e(vR,SKe),e(Jm,RKe),e(A,PKe),e(A,Ym),e(Ym,yae),e(yae,BKe),e(Ym,IKe),e(Ym,FR),e(FR,NKe),e(Ym,qKe),e(A,jKe),e(A,Km),e(Km,xae),e(xae,DKe),e(Km,GKe),e(Km,TR),e(TR,OKe),e(Km,VKe),e(A,XKe),e(A,Zm),e(Zm,$ae),e($ae,zKe),e(Zm,WKe),e(Zm,MR),e(MR,QKe),e(Zm,HKe),e(A,UKe),e(A,eg),e(eg,kae),e(kae,JKe),e(eg,YKe),e(eg,ER),e(ER,KKe),e(eg,ZKe),e(A,eZe),e(A,og),e(og,Sae),e(Sae,oZe),e(og,rZe),e(og,CR),e(CR,tZe),e(og,aZe),e(A,nZe),e(A,rg),e(rg,Rae),e(Rae,sZe),e(rg,lZe),e(rg,wR),e(wR,iZe),e(rg,dZe),e(A,cZe),e(A,tg),e(tg,Pae),e(Pae,fZe),e(tg,mZe),e(tg,AR),e(AR,gZe),e(tg,hZe),e(A,pZe),e(A,ag),e(ag,Bae),e(Bae,uZe),e(ag,_Ze),e(ag,LR),e(LR,bZe),e(ag,vZe),e(A,FZe),e(A,ng),e(ng,Iae),e(Iae,TZe),e(ng,MZe),e(ng,yR),e(yR,EZe),e(ng,CZe),e(A,wZe),e(A,sg),e(sg,Nae),e(Nae,AZe),e(sg,LZe),e(sg,xR),e(xR,yZe),e(sg,xZe),e(A,$Ze),e(A,lg),e(lg,qae),e(qae,kZe),e(lg,SZe),e(lg,$R),e($R,RZe),e(lg,PZe),e(A,BZe),e(A,ig),e(ig,jae),e(jae,IZe),e(ig,NZe),e(ig,kR),e(kR,qZe),e(ig,jZe),e(A,DZe),e(A,dg),e(dg,Dae),e(Dae,GZe),e(dg,OZe),e(dg,SR),e(SR,VZe),e(dg,XZe),e(A,zZe),e(A,cg),e(cg,Gae),e(Gae,WZe),e(cg,QZe),e(cg,RR),e(RR,HZe),e(cg,UZe),e(A,JZe),e(A,fg),e(fg,Oae),e(Oae,YZe),e(fg,KZe),e(fg,PR),e(PR,ZZe),e(fg,eeo),e(A,oeo),e(A,mg),e(mg,Vae),e(Vae,reo),e(mg,teo),e(mg,BR),e(BR,aeo),e(mg,neo),e(A,seo),e(A,gg),e(gg,Xae),e(Xae,leo),e(gg,ieo),e(gg,IR),e(IR,deo),e(gg,ceo),e(A,feo),e(A,hg),e(hg,zae),e(zae,meo),e(hg,geo),e(hg,NR),e(NR,heo),e(hg,peo),e(A,ueo),e(A,pg),e(pg,Wae),e(Wae,_eo),e(pg,beo),e(pg,qR),e(qR,veo),e(pg,Feo),e(A,Teo),e(A,ug),e(ug,Qae),e(Qae,Meo),e(ug,Eeo),e(ug,jR),e(jR,Ceo),e(ug,weo),e(A,Aeo),e(A,_g),e(_g,Hae),e(Hae,Leo),e(_g,yeo),e(_g,DR),e(DR,xeo),e(_g,$eo),e(A,keo),e(A,bg),e(bg,Uae),e(Uae,Seo),e(bg,Reo),e(bg,GR),e(GR,Peo),e(bg,Beo),e(A,Ieo),e(A,vg),e(vg,Jae),e(Jae,Neo),e(vg,qeo),e(vg,OR),e(OR,jeo),e(vg,Deo),e(A,Geo),e(A,Fg),e(Fg,Yae),e(Yae,Oeo),e(Fg,Veo),e(Fg,VR),e(VR,Xeo),e(Fg,zeo),e(A,Weo),e(A,Tg),e(Tg,Kae),e(Kae,Qeo),e(Tg,Heo),e(Tg,XR),e(XR,Ueo),e(Tg,Jeo),e(A,Yeo),e(A,Mg),e(Mg,Zae),e(Zae,Keo),e(Mg,Zeo),e(Mg,zR),e(zR,eoo),e(Mg,ooo),e(A,roo),e(A,Eg),e(Eg,ene),e(ene,too),e(Eg,aoo),e(Eg,WR),e(WR,noo),e(Eg,soo),e(A,loo),e(A,Cg),e(Cg,one),e(one,ioo),e(Cg,doo),e(Cg,QR),e(QR,coo),e(Cg,foo),e(A,moo),e(A,wg),e(wg,rne),e(rne,goo),e(wg,hoo),e(wg,HR),e(HR,poo),e(wg,uoo),e(A,_oo),e(A,Ag),e(Ag,tne),e(tne,boo),e(Ag,voo),e(Ag,UR),e(UR,Foo),e(Ag,Too),e(A,Moo),e(A,Lg),e(Lg,ane),e(ane,Eoo),e(Lg,Coo),e(Lg,JR),e(JR,woo),e(Lg,Aoo),e(A,Loo),e(A,yg),e(yg,nne),e(nne,yoo),e(yg,xoo),e(yg,YR),e(YR,$oo),e(yg,koo),e(A,Soo),e(A,xg),e(xg,sne),e(sne,Roo),e(xg,Poo),e(xg,KR),e(KR,Boo),e(xg,Ioo),e(A,Noo),e(A,$g),e($g,lne),e(lne,qoo),e($g,joo),e($g,ZR),e(ZR,Doo),e($g,Goo),e(A,Ooo),e(A,kg),e(kg,ine),e(ine,Voo),e(kg,Xoo),e(kg,eP),e(eP,zoo),e(kg,Woo),e(A,Qoo),e(A,Sg),e(Sg,dne),e(dne,Hoo),e(Sg,Uoo),e(Sg,oP),e(oP,Joo),e(Sg,Yoo),e(A,Koo),e(A,Rg),e(Rg,cne),e(cne,Zoo),e(Rg,ero),e(Rg,rP),e(rP,oro),e(Rg,rro),e(A,tro),e(A,Pg),e(Pg,fne),e(fne,aro),e(Pg,nro),e(Pg,tP),e(tP,sro),e(Pg,lro),e(A,iro),e(A,Bg),e(Bg,mne),e(mne,dro),e(Bg,cro),e(Bg,aP),e(aP,fro),e(Bg,mro),e(A,gro),e(A,Ig),e(Ig,gne),e(gne,hro),e(Ig,pro),e(Ig,nP),e(nP,uro),e(Ig,_ro),e(A,bro),e(A,Ng),e(Ng,hne),e(hne,vro),e(Ng,Fro),e(Ng,sP),e(sP,Tro),e(Ng,Mro),e(A,Ero),e(A,qg),e(qg,pne),e(pne,Cro),e(qg,wro),e(qg,lP),e(lP,Aro),e(qg,Lro),e(A,yro),e(A,jg),e(jg,une),e(une,xro),e(jg,$ro),e(jg,iP),e(iP,kro),e(jg,Sro),e(A,Rro),e(A,Dg),e(Dg,_ne),e(_ne,Pro),e(Dg,Bro),e(Dg,dP),e(dP,Iro),e(Dg,Nro),e(wr,qro),M(Gg,wr,null),e(wo,jro),e(wo,Og),M(kL,Og,null),e(Og,Dro),e(Og,bne),e(bne,Gro),b(f,AGe,_),b(f,ki,_),e(ki,Vg),e(Vg,vne),M(SL,vne,null),e(ki,Oro),e(ki,Fne),e(Fne,Vro),b(f,LGe,_),b(f,Ao,_),M(RL,Ao,null),e(Ao,Xro),e(Ao,PL),e(PL,zro),e(PL,cP),e(cP,Wro),e(PL,Qro),e(Ao,Hro),e(Ao,BL),e(BL,Uro),e(BL,Tne),e(Tne,Jro),e(BL,Yro),e(Ao,Kro),e(Ao,Ar),M(IL,Ar,null),e(Ar,Zro),e(Ar,Mne),e(Mne,eto),e(Ar,oto),e(Ar,$a),e($a,rto),e($a,Ene),e(Ene,tto),e($a,ato),e($a,Cne),e(Cne,nto),e($a,sto),e($a,wne),e(wne,lto),e($a,ito),e(Ar,dto),e(Ar,k),e(k,Nn),e(Nn,Ane),e(Ane,cto),e(Nn,fto),e(Nn,fP),e(fP,mto),e(Nn,gto),e(Nn,mP),e(mP,hto),e(Nn,pto),e(k,uto),e(k,qn),e(qn,Lne),e(Lne,_to),e(qn,bto),e(qn,gP),e(gP,vto),e(qn,Fto),e(qn,hP),e(hP,Tto),e(qn,Mto),e(k,Eto),e(k,jn),e(jn,yne),e(yne,Cto),e(jn,wto),e(jn,pP),e(pP,Ato),e(jn,Lto),e(jn,uP),e(uP,yto),e(jn,xto),e(k,$to),e(k,Xg),e(Xg,xne),e(xne,kto),e(Xg,Sto),e(Xg,_P),e(_P,Rto),e(Xg,Pto),e(k,Bto),e(k,Dn),e(Dn,$ne),e($ne,Ito),e(Dn,Nto),e(Dn,bP),e(bP,qto),e(Dn,jto),e(Dn,vP),e(vP,Dto),e(Dn,Gto),e(k,Oto),e(k,zg),e(zg,kne),e(kne,Vto),e(zg,Xto),e(zg,FP),e(FP,zto),e(zg,Wto),e(k,Qto),e(k,Wg),e(Wg,Sne),e(Sne,Hto),e(Wg,Uto),e(Wg,TP),e(TP,Jto),e(Wg,Yto),e(k,Kto),e(k,Qg),e(Qg,Rne),e(Rne,Zto),e(Qg,eao),e(Qg,MP),e(MP,oao),e(Qg,rao),e(k,tao),e(k,Gn),e(Gn,Pne),e(Pne,aao),e(Gn,nao),e(Gn,EP),e(EP,sao),e(Gn,lao),e(Gn,CP),e(CP,iao),e(Gn,dao),e(k,cao),e(k,On),e(On,Bne),e(Bne,fao),e(On,mao),e(On,wP),e(wP,gao),e(On,hao),e(On,AP),e(AP,pao),e(On,uao),e(k,_ao),e(k,Vn),e(Vn,Ine),e(Ine,bao),e(Vn,vao),e(Vn,LP),e(LP,Fao),e(Vn,Tao),e(Vn,yP),e(yP,Mao),e(Vn,Eao),e(k,Cao),e(k,Hg),e(Hg,Nne),e(Nne,wao),e(Hg,Aao),e(Hg,xP),e(xP,Lao),e(Hg,yao),e(k,xao),e(k,Ug),e(Ug,qne),e(qne,$ao),e(Ug,kao),e(Ug,$P),e($P,Sao),e(Ug,Rao),e(k,Pao),e(k,Jg),e(Jg,jne),e(jne,Bao),e(Jg,Iao),e(Jg,kP),e(kP,Nao),e(Jg,qao),e(k,jao),e(k,Xn),e(Xn,Dne),e(Dne,Dao),e(Xn,Gao),e(Xn,SP),e(SP,Oao),e(Xn,Vao),e(Xn,RP),e(RP,Xao),e(Xn,zao),e(k,Wao),e(k,Yg),e(Yg,Gne),e(Gne,Qao),e(Yg,Hao),e(Yg,PP),e(PP,Uao),e(Yg,Jao),e(k,Yao),e(k,zn),e(zn,One),e(One,Kao),e(zn,Zao),e(zn,BP),e(BP,eno),e(zn,ono),e(zn,IP),e(IP,rno),e(zn,tno),e(k,ano),e(k,Wn),e(Wn,Vne),e(Vne,nno),e(Wn,sno),e(Wn,NP),e(NP,lno),e(Wn,ino),e(Wn,qP),e(qP,dno),e(Wn,cno),e(k,fno),e(k,Qn),e(Qn,Xne),e(Xne,mno),e(Qn,gno),e(Qn,jP),e(jP,hno),e(Qn,pno),e(Qn,DP),e(DP,uno),e(Qn,_no),e(k,bno),e(k,Kg),e(Kg,zne),e(zne,vno),e(Kg,Fno),e(Kg,GP),e(GP,Tno),e(Kg,Mno),e(k,Eno),e(k,Hn),e(Hn,Wne),e(Wne,Cno),e(Hn,wno),e(Hn,OP),e(OP,Ano),e(Hn,Lno),e(Hn,VP),e(VP,yno),e(Hn,xno),e(k,$no),e(k,Un),e(Un,Qne),e(Qne,kno),e(Un,Sno),e(Un,XP),e(XP,Rno),e(Un,Pno),e(Un,zP),e(zP,Bno),e(Un,Ino),e(k,Nno),e(k,Jn),e(Jn,Hne),e(Hne,qno),e(Jn,jno),e(Jn,WP),e(WP,Dno),e(Jn,Gno),e(Jn,QP),e(QP,Ono),e(Jn,Vno),e(k,Xno),e(k,Yn),e(Yn,Une),e(Une,zno),e(Yn,Wno),e(Yn,HP),e(HP,Qno),e(Yn,Hno),e(Yn,UP),e(UP,Uno),e(Yn,Jno),e(k,Yno),e(k,Kn),e(Kn,Jne),e(Jne,Kno),e(Kn,Zno),e(Kn,JP),e(JP,eso),e(Kn,oso),e(Kn,YP),e(YP,rso),e(Kn,tso),e(k,aso),e(k,Zn),e(Zn,Yne),e(Yne,nso),e(Zn,sso),e(Zn,KP),e(KP,lso),e(Zn,iso),e(Zn,ZP),e(ZP,dso),e(Zn,cso),e(k,fso),e(k,Zg),e(Zg,Kne),e(Kne,mso),e(Zg,gso),e(Zg,eB),e(eB,hso),e(Zg,pso),e(k,uso),e(k,es),e(es,Zne),e(Zne,_so),e(es,bso),e(es,oB),e(oB,vso),e(es,Fso),e(es,rB),e(rB,Tso),e(es,Mso),e(k,Eso),e(k,eh),e(eh,ese),e(ese,Cso),e(eh,wso),e(eh,tB),e(tB,Aso),e(eh,Lso),e(k,yso),e(k,os),e(os,ose),e(ose,xso),e(os,$so),e(os,aB),e(aB,kso),e(os,Sso),e(os,nB),e(nB,Rso),e(os,Pso),e(k,Bso),e(k,rs),e(rs,rse),e(rse,Iso),e(rs,Nso),e(rs,sB),e(sB,qso),e(rs,jso),e(rs,lB),e(lB,Dso),e(rs,Gso),e(k,Oso),e(k,ts),e(ts,tse),e(tse,Vso),e(ts,Xso),e(ts,iB),e(iB,zso),e(ts,Wso),e(ts,dB),e(dB,Qso),e(ts,Hso),e(k,Uso),e(k,oh),e(oh,ase),e(ase,Jso),e(oh,Yso),e(oh,cB),e(cB,Kso),e(oh,Zso),e(k,elo),e(k,as),e(as,nse),e(nse,olo),e(as,rlo),e(as,fB),e(fB,tlo),e(as,alo),e(as,mB),e(mB,nlo),e(as,slo),e(k,llo),e(k,ns),e(ns,sse),e(sse,ilo),e(ns,dlo),e(ns,gB),e(gB,clo),e(ns,flo),e(ns,hB),e(hB,mlo),e(ns,glo),e(k,hlo),e(k,ss),e(ss,lse),e(lse,plo),e(ss,ulo),e(ss,pB),e(pB,_lo),e(ss,blo),e(ss,uB),e(uB,vlo),e(ss,Flo),e(k,Tlo),e(k,rh),e(rh,ise),e(ise,Mlo),e(rh,Elo),e(rh,_B),e(_B,Clo),e(rh,wlo),e(k,Alo),e(k,ls),e(ls,dse),e(dse,Llo),e(ls,ylo),e(ls,bB),e(bB,xlo),e(ls,$lo),e(ls,vB),e(vB,klo),e(ls,Slo),e(k,Rlo),e(k,is),e(is,cse),e(cse,Plo),e(is,Blo),e(is,FB),e(FB,Ilo),e(is,Nlo),e(is,TB),e(TB,qlo),e(is,jlo),e(k,Dlo),e(k,ds),e(ds,fse),e(fse,Glo),e(ds,Olo),e(ds,MB),e(MB,Vlo),e(ds,Xlo),e(ds,EB),e(EB,zlo),e(ds,Wlo),e(k,Qlo),e(k,cs),e(cs,mse),e(mse,Hlo),e(cs,Ulo),e(cs,CB),e(CB,Jlo),e(cs,Ylo),e(cs,wB),e(wB,Klo),e(cs,Zlo),e(k,eio),e(k,fs),e(fs,gse),e(gse,oio),e(fs,rio),e(fs,AB),e(AB,tio),e(fs,aio),e(fs,LB),e(LB,nio),e(fs,sio),e(k,lio),e(k,ms),e(ms,hse),e(hse,iio),e(ms,dio),e(ms,yB),e(yB,cio),e(ms,fio),e(ms,xB),e(xB,mio),e(ms,gio),e(k,hio),e(k,gs),e(gs,pse),e(pse,pio),e(gs,uio),e(gs,$B),e($B,_io),e(gs,bio),e(gs,kB),e(kB,vio),e(gs,Fio),e(k,Tio),e(k,hs),e(hs,use),e(use,Mio),e(hs,Eio),e(hs,SB),e(SB,Cio),e(hs,wio),e(hs,RB),e(RB,Aio),e(hs,Lio),e(k,yio),e(k,th),e(th,_se),e(_se,xio),e(th,$io),e(th,PB),e(PB,kio),e(th,Sio),e(k,Rio),e(k,ps),e(ps,bse),e(bse,Pio),e(ps,Bio),e(ps,BB),e(BB,Iio),e(ps,Nio),e(ps,IB),e(IB,qio),e(ps,jio),e(k,Dio),e(k,ah),e(ah,vse),e(vse,Gio),e(ah,Oio),e(ah,NB),e(NB,Vio),e(ah,Xio),e(k,zio),e(k,nh),e(nh,Fse),e(Fse,Wio),e(nh,Qio),e(nh,qB),e(qB,Hio),e(nh,Uio),e(k,Jio),e(k,us),e(us,Tse),e(Tse,Yio),e(us,Kio),e(us,jB),e(jB,Zio),e(us,edo),e(us,DB),e(DB,odo),e(us,rdo),e(k,tdo),e(k,_s),e(_s,Mse),e(Mse,ado),e(_s,ndo),e(_s,GB),e(GB,sdo),e(_s,ldo),e(_s,OB),e(OB,ido),e(_s,ddo),e(k,cdo),e(k,bs),e(bs,Ese),e(Ese,fdo),e(bs,mdo),e(bs,VB),e(VB,gdo),e(bs,hdo),e(bs,XB),e(XB,pdo),e(bs,udo),e(k,_do),e(k,sh),e(sh,Cse),e(Cse,bdo),e(sh,vdo),e(sh,zB),e(zB,Fdo),e(sh,Tdo),e(k,Mdo),e(k,vs),e(vs,wse),e(wse,Edo),e(vs,Cdo),e(vs,WB),e(WB,wdo),e(vs,Ado),e(vs,QB),e(QB,Ldo),e(vs,ydo),e(k,xdo),e(k,Fs),e(Fs,Ase),e(Ase,$do),e(Fs,kdo),e(Fs,HB),e(HB,Sdo),e(Fs,Rdo),e(Fs,UB),e(UB,Pdo),e(Fs,Bdo),e(k,Ido),e(k,Ts),e(Ts,Lse),e(Lse,Ndo),e(Ts,qdo),e(Ts,JB),e(JB,jdo),e(Ts,Ddo),e(Ts,YB),e(YB,Gdo),e(Ts,Odo),e(k,Vdo),e(k,Ms),e(Ms,yse),e(yse,Xdo),e(Ms,zdo),e(Ms,KB),e(KB,Wdo),e(Ms,Qdo),e(Ms,ZB),e(ZB,Hdo),e(Ms,Udo),e(k,Jdo),e(k,Es),e(Es,xse),e(xse,Ydo),e(Es,Kdo),e(Es,eI),e(eI,Zdo),e(Es,eco),e(Es,oI),e(oI,oco),e(Es,rco),e(k,tco),e(k,lh),e(lh,$se),e($se,aco),e(lh,nco),e(lh,rI),e(rI,sco),e(lh,lco),e(k,ico),e(k,Cs),e(Cs,kse),e(kse,dco),e(Cs,cco),e(Cs,tI),e(tI,fco),e(Cs,mco),e(Cs,aI),e(aI,gco),e(Cs,hco),e(k,pco),e(k,ih),e(ih,Sse),e(Sse,uco),e(ih,_co),e(ih,nI),e(nI,bco),e(ih,vco),e(k,Fco),e(k,dh),e(dh,Rse),e(Rse,Tco),e(dh,Mco),e(dh,sI),e(sI,Eco),e(dh,Cco),e(k,wco),e(k,ch),e(ch,Pse),e(Pse,Aco),e(ch,Lco),e(ch,lI),e(lI,yco),e(ch,xco),e(k,$co),e(k,fh),e(fh,Bse),e(Bse,kco),e(fh,Sco),e(fh,iI),e(iI,Rco),e(fh,Pco),e(k,Bco),e(k,ws),e(ws,Ise),e(Ise,Ico),e(ws,Nco),e(ws,dI),e(dI,qco),e(ws,jco),e(ws,cI),e(cI,Dco),e(ws,Gco),e(k,Oco),e(k,mh),e(mh,Nse),e(Nse,Vco),e(mh,Xco),e(mh,fI),e(fI,zco),e(mh,Wco),e(k,Qco),e(k,As),e(As,qse),e(qse,Hco),e(As,Uco),e(As,mI),e(mI,Jco),e(As,Yco),e(As,gI),e(gI,Kco),e(As,Zco),e(k,efo),e(k,Ls),e(Ls,jse),e(jse,ofo),e(Ls,rfo),e(Ls,hI),e(hI,tfo),e(Ls,afo),e(Ls,pI),e(pI,nfo),e(Ls,sfo),e(k,lfo),e(k,ys),e(ys,Dse),e(Dse,ifo),e(ys,dfo),e(ys,uI),e(uI,cfo),e(ys,ffo),e(ys,_I),e(_I,mfo),e(ys,gfo),e(k,hfo),e(k,xs),e(xs,Gse),e(Gse,pfo),e(xs,ufo),e(xs,bI),e(bI,_fo),e(xs,bfo),e(xs,vI),e(vI,vfo),e(xs,Ffo),e(k,Tfo),e(k,$s),e($s,Ose),e(Ose,Mfo),e($s,Efo),e($s,FI),e(FI,Cfo),e($s,wfo),e($s,TI),e(TI,Afo),e($s,Lfo),e(k,yfo),e(k,ks),e(ks,Vse),e(Vse,xfo),e(ks,$fo),e(ks,MI),e(MI,kfo),e(ks,Sfo),e(ks,EI),e(EI,Rfo),e(ks,Pfo),e(k,Bfo),e(k,gh),e(gh,Xse),e(Xse,Ifo),e(gh,Nfo),e(gh,CI),e(CI,qfo),e(gh,jfo),e(k,Dfo),e(k,hh),e(hh,zse),e(zse,Gfo),e(hh,Ofo),e(hh,wI),e(wI,Vfo),e(hh,Xfo),e(k,zfo),e(k,Ss),e(Ss,Wse),e(Wse,Wfo),e(Ss,Qfo),e(Ss,AI),e(AI,Hfo),e(Ss,Ufo),e(Ss,LI),e(LI,Jfo),e(Ss,Yfo),e(k,Kfo),e(k,Rs),e(Rs,Qse),e(Qse,Zfo),e(Rs,emo),e(Rs,yI),e(yI,omo),e(Rs,rmo),e(Rs,xI),e(xI,tmo),e(Rs,amo),e(k,nmo),e(k,Ps),e(Ps,Hse),e(Hse,smo),e(Ps,lmo),e(Ps,$I),e($I,imo),e(Ps,dmo),e(Ps,kI),e(kI,cmo),e(Ps,fmo),e(k,mmo),e(k,ph),e(ph,Use),e(Use,gmo),e(ph,hmo),e(ph,SI),e(SI,pmo),e(ph,umo),e(k,_mo),e(k,uh),e(uh,Jse),e(Jse,bmo),e(uh,vmo),e(uh,RI),e(RI,Fmo),e(uh,Tmo),e(k,Mmo),e(k,_h),e(_h,Yse),e(Yse,Emo),e(_h,Cmo),e(_h,PI),e(PI,wmo),e(_h,Amo),e(k,Lmo),e(k,Bs),e(Bs,Kse),e(Kse,ymo),e(Bs,xmo),e(Bs,BI),e(BI,$mo),e(Bs,kmo),e(Bs,II),e(II,Smo),e(Bs,Rmo),e(k,Pmo),e(k,Is),e(Is,Zse),e(Zse,Bmo),e(Is,Imo),e(Is,NI),e(NI,Nmo),e(Is,qmo),e(Is,qI),e(qI,jmo),e(Is,Dmo),e(k,Gmo),e(k,bh),e(bh,ele),e(ele,Omo),e(bh,Vmo),e(bh,jI),e(jI,Xmo),e(bh,zmo),e(k,Wmo),e(k,vh),e(vh,ole),e(ole,Qmo),e(vh,Hmo),e(vh,DI),e(DI,Umo),e(vh,Jmo),e(k,Ymo),e(k,Fh),e(Fh,rle),e(rle,Kmo),e(Fh,Zmo),e(Fh,GI),e(GI,ego),e(Fh,ogo),e(k,rgo),e(k,Ns),e(Ns,tle),e(tle,tgo),e(Ns,ago),e(Ns,OI),e(OI,ngo),e(Ns,sgo),e(Ns,VI),e(VI,lgo),e(Ns,igo),e(k,dgo),e(k,Th),e(Th,ale),e(ale,cgo),e(Th,fgo),e(Th,XI),e(XI,mgo),e(Th,ggo),e(k,hgo),e(k,Mh),e(Mh,nle),e(nle,pgo),e(Mh,ugo),e(Mh,zI),e(zI,_go),e(Mh,bgo),e(k,vgo),e(k,qs),e(qs,sle),e(sle,Fgo),e(qs,Tgo),e(qs,WI),e(WI,Mgo),e(qs,Ego),e(qs,QI),e(QI,Cgo),e(qs,wgo),e(k,Ago),e(k,js),e(js,lle),e(lle,Lgo),e(js,ygo),e(js,HI),e(HI,xgo),e(js,$go),e(js,UI),e(UI,kgo),e(js,Sgo),e(k,Rgo),e(k,Ds),e(Ds,ile),e(ile,Pgo),e(Ds,Bgo),e(Ds,JI),e(JI,Igo),e(Ds,Ngo),e(Ds,YI),e(YI,qgo),e(Ds,jgo),e(k,Dgo),e(k,Gs),e(Gs,dle),e(dle,Ggo),e(Gs,Ogo),e(Gs,KI),e(KI,Vgo),e(Gs,Xgo),e(Gs,ZI),e(ZI,zgo),e(Gs,Wgo),e(Ar,Qgo),M(Eh,Ar,null),e(Ao,Hgo),e(Ao,Ch),M(NL,Ch,null),e(Ch,Ugo),e(Ch,cle),e(cle,Jgo),b(f,yGe,_),b(f,Si,_),e(Si,wh),e(wh,fle),M(qL,fle,null),e(Si,Ygo),e(Si,mle),e(mle,Kgo),b(f,xGe,_),b(f,Lo,_),M(jL,Lo,null),e(Lo,Zgo),e(Lo,DL),e(DL,eho),e(DL,eN),e(eN,oho),e(DL,rho),e(Lo,tho),e(Lo,GL),e(GL,aho),e(GL,gle),e(gle,nho),e(GL,sho),e(Lo,lho),e(Lo,He),M(OL,He,null),e(He,iho),e(He,hle),e(hle,dho),e(He,cho),e(He,ka),e(ka,fho),e(ka,ple),e(ple,mho),e(ka,gho),e(ka,ule),e(ule,hho),e(ka,pho),e(ka,_le),e(_le,uho),e(ka,_ho),e(He,bho),e(He,Y),e(Y,Ah),e(Ah,ble),e(ble,vho),e(Ah,Fho),e(Ah,oN),e(oN,Tho),e(Ah,Mho),e(Y,Eho),e(Y,Lh),e(Lh,vle),e(vle,Cho),e(Lh,who),e(Lh,rN),e(rN,Aho),e(Lh,Lho),e(Y,yho),e(Y,yh),e(yh,Fle),e(Fle,xho),e(yh,$ho),e(yh,tN),e(tN,kho),e(yh,Sho),e(Y,Rho),e(Y,xh),e(xh,Tle),e(Tle,Pho),e(xh,Bho),e(xh,aN),e(aN,Iho),e(xh,Nho),e(Y,qho),e(Y,$h),e($h,Mle),e(Mle,jho),e($h,Dho),e($h,nN),e(nN,Gho),e($h,Oho),e(Y,Vho),e(Y,kh),e(kh,Ele),e(Ele,Xho),e(kh,zho),e(kh,sN),e(sN,Who),e(kh,Qho),e(Y,Hho),e(Y,Sh),e(Sh,Cle),e(Cle,Uho),e(Sh,Jho),e(Sh,lN),e(lN,Yho),e(Sh,Kho),e(Y,Zho),e(Y,Rh),e(Rh,wle),e(wle,epo),e(Rh,opo),e(Rh,iN),e(iN,rpo),e(Rh,tpo),e(Y,apo),e(Y,Ph),e(Ph,Ale),e(Ale,npo),e(Ph,spo),e(Ph,dN),e(dN,lpo),e(Ph,ipo),e(Y,dpo),e(Y,Bh),e(Bh,Lle),e(Lle,cpo),e(Bh,fpo),e(Bh,cN),e(cN,mpo),e(Bh,gpo),e(Y,hpo),e(Y,Ih),e(Ih,yle),e(yle,ppo),e(Ih,upo),e(Ih,fN),e(fN,_po),e(Ih,bpo),e(Y,vpo),e(Y,Nh),e(Nh,xle),e(xle,Fpo),e(Nh,Tpo),e(Nh,mN),e(mN,Mpo),e(Nh,Epo),e(Y,Cpo),e(Y,qh),e(qh,$le),e($le,wpo),e(qh,Apo),e(qh,gN),e(gN,Lpo),e(qh,ypo),e(Y,xpo),e(Y,jh),e(jh,kle),e(kle,$po),e(jh,kpo),e(jh,hN),e(hN,Spo),e(jh,Rpo),e(Y,Ppo),e(Y,Dh),e(Dh,Sle),e(Sle,Bpo),e(Dh,Ipo),e(Dh,pN),e(pN,Npo),e(Dh,qpo),e(Y,jpo),e(Y,Gh),e(Gh,Rle),e(Rle,Dpo),e(Gh,Gpo),e(Gh,uN),e(uN,Opo),e(Gh,Vpo),e(Y,Xpo),e(Y,Oh),e(Oh,Ple),e(Ple,zpo),e(Oh,Wpo),e(Oh,_N),e(_N,Qpo),e(Oh,Hpo),e(Y,Upo),e(Y,Vh),e(Vh,Ble),e(Ble,Jpo),e(Vh,Ypo),e(Vh,bN),e(bN,Kpo),e(Vh,Zpo),e(Y,euo),e(Y,Xh),e(Xh,Ile),e(Ile,ouo),e(Xh,ruo),e(Xh,vN),e(vN,tuo),e(Xh,auo),e(Y,nuo),e(Y,zh),e(zh,Nle),e(Nle,suo),e(zh,luo),e(zh,FN),e(FN,iuo),e(zh,duo),e(Y,cuo),e(Y,Wh),e(Wh,qle),e(qle,fuo),e(Wh,muo),e(Wh,TN),e(TN,guo),e(Wh,huo),e(Y,puo),e(Y,Qh),e(Qh,jle),e(jle,uuo),e(Qh,_uo),e(Qh,MN),e(MN,buo),e(Qh,vuo),e(Y,Fuo),e(Y,Hh),e(Hh,Dle),e(Dle,Tuo),e(Hh,Muo),e(Hh,EN),e(EN,Euo),e(Hh,Cuo),e(Y,wuo),e(Y,Uh),e(Uh,Gle),e(Gle,Auo),e(Uh,Luo),e(Uh,CN),e(CN,yuo),e(Uh,xuo),e(Y,$uo),e(Y,Jh),e(Jh,Ole),e(Ole,kuo),e(Jh,Suo),e(Jh,wN),e(wN,Ruo),e(Jh,Puo),e(Y,Buo),e(Y,Yh),e(Yh,Vle),e(Vle,Iuo),e(Yh,Nuo),e(Yh,AN),e(AN,quo),e(Yh,juo),e(Y,Duo),e(Y,Kh),e(Kh,Xle),e(Xle,Guo),e(Kh,Ouo),e(Kh,LN),e(LN,Vuo),e(Kh,Xuo),e(Y,zuo),e(Y,Zh),e(Zh,zle),e(zle,Wuo),e(Zh,Quo),e(Zh,yN),e(yN,Huo),e(Zh,Uuo),e(Y,Juo),e(Y,ep),e(ep,Wle),e(Wle,Yuo),e(ep,Kuo),e(ep,xN),e(xN,Zuo),e(ep,e_o),e(Y,o_o),e(Y,op),e(op,Qle),e(Qle,r_o),e(op,t_o),e(op,$N),e($N,a_o),e(op,n_o),e(Y,s_o),e(Y,rp),e(rp,Hle),e(Hle,l_o),e(rp,i_o),e(rp,kN),e(kN,d_o),e(rp,c_o),e(Y,f_o),e(Y,tp),e(tp,Ule),e(Ule,m_o),e(tp,g_o),e(tp,SN),e(SN,h_o),e(tp,p_o),e(Y,u_o),e(Y,ap),e(ap,Jle),e(Jle,__o),e(ap,b_o),e(ap,RN),e(RN,v_o),e(ap,F_o),e(He,T_o),M(np,He,null),e(He,M_o),M(sp,He,null),e(Lo,E_o),e(Lo,lp),M(VL,lp,null),e(lp,C_o),e(lp,Yle),e(Yle,w_o),b(f,$Ge,_),b(f,Ri,_),e(Ri,ip),e(ip,Kle),M(XL,Kle,null),e(Ri,A_o),e(Ri,Zle),e(Zle,L_o),b(f,kGe,_),b(f,yo,_),M(zL,yo,null),e(yo,y_o),e(yo,WL),e(WL,x_o),e(WL,PN),e(PN,$_o),e(WL,k_o),e(yo,S_o),e(yo,QL),e(QL,R_o),e(QL,eie),e(eie,P_o),e(QL,B_o),e(yo,I_o),e(yo,Ue),M(HL,Ue,null),e(Ue,N_o),e(Ue,oie),e(oie,q_o),e(Ue,j_o),e(Ue,Pi),e(Pi,D_o),e(Pi,rie),e(rie,G_o),e(Pi,O_o),e(Pi,tie),e(tie,V_o),e(Pi,X_o),e(Ue,z_o),e(Ue,he),e(he,dp),e(dp,aie),e(aie,W_o),e(dp,Q_o),e(dp,BN),e(BN,H_o),e(dp,U_o),e(he,J_o),e(he,cp),e(cp,nie),e(nie,Y_o),e(cp,K_o),e(cp,sie),e(sie,Z_o),e(cp,e1o),e(he,o1o),e(he,fp),e(fp,lie),e(lie,r1o),e(fp,t1o),e(fp,IN),e(IN,a1o),e(fp,n1o),e(he,s1o),e(he,mp),e(mp,iie),e(iie,l1o),e(mp,i1o),e(mp,NN),e(NN,d1o),e(mp,c1o),e(he,f1o),e(he,gp),e(gp,die),e(die,m1o),e(gp,g1o),e(gp,qN),e(qN,h1o),e(gp,p1o),e(he,u1o),e(he,hp),e(hp,cie),e(cie,_1o),e(hp,b1o),e(hp,jN),e(jN,v1o),e(hp,F1o),e(he,T1o),e(he,pp),e(pp,fie),e(fie,M1o),e(pp,E1o),e(pp,DN),e(DN,C1o),e(pp,w1o),e(he,A1o),e(he,up),e(up,mie),e(mie,L1o),e(up,y1o),e(up,GN),e(GN,x1o),e(up,$1o),e(he,k1o),e(he,_p),e(_p,gie),e(gie,S1o),e(_p,R1o),e(_p,ON),e(ON,P1o),e(_p,B1o),e(he,I1o),e(he,bp),e(bp,hie),e(hie,N1o),e(bp,q1o),e(bp,VN),e(VN,j1o),e(bp,D1o),e(he,G1o),e(he,vp),e(vp,pie),e(pie,O1o),e(vp,V1o),e(vp,XN),e(XN,X1o),e(vp,z1o),e(he,W1o),e(he,Fp),e(Fp,uie),e(uie,Q1o),e(Fp,H1o),e(Fp,zN),e(zN,U1o),e(Fp,J1o),e(he,Y1o),e(he,Tp),e(Tp,_ie),e(_ie,K1o),e(Tp,Z1o),e(Tp,WN),e(WN,e3o),e(Tp,o3o),e(he,r3o),e(he,Mp),e(Mp,bie),e(bie,t3o),e(Mp,a3o),e(Mp,QN),e(QN,n3o),e(Mp,s3o),e(he,l3o),e(he,Ep),e(Ep,vie),e(vie,i3o),e(Ep,d3o),e(Ep,HN),e(HN,c3o),e(Ep,f3o),e(he,m3o),e(he,Cp),e(Cp,Fie),e(Fie,g3o),e(Cp,h3o),e(Cp,UN),e(UN,p3o),e(Cp,u3o),e(he,_3o),e(he,wp),e(wp,Tie),e(Tie,b3o),e(wp,v3o),e(wp,JN),e(JN,F3o),e(wp,T3o),e(he,M3o),e(he,Ap),e(Ap,Mie),e(Mie,E3o),e(Ap,C3o),e(Ap,YN),e(YN,w3o),e(Ap,A3o),e(Ue,L3o),M(Lp,Ue,null),e(Ue,y3o),M(yp,Ue,null),e(yo,x3o),e(yo,xp),M(UL,xp,null),e(xp,$3o),e(xp,Eie),e(Eie,k3o),b(f,SGe,_),b(f,Bi,_),e(Bi,$p),e($p,Cie),M(JL,Cie,null),e(Bi,S3o),e(Bi,wie),e(wie,R3o),b(f,RGe,_),b(f,xo,_),M(YL,xo,null),e(xo,P3o),e(xo,Ii),e(Ii,B3o),e(Ii,KN),e(KN,I3o),e(Ii,N3o),e(Ii,ZN),e(ZN,q3o),e(Ii,j3o),e(xo,D3o),e(xo,KL),e(KL,G3o),e(KL,Aie),e(Aie,O3o),e(KL,V3o),e(xo,X3o),e(xo,nt),M(ZL,nt,null),e(nt,z3o),e(nt,Lie),e(Lie,W3o),e(nt,Q3o),e(nt,Ni),e(Ni,H3o),e(Ni,yie),e(yie,U3o),e(Ni,J3o),e(Ni,eq),e(eq,Y3o),e(Ni,K3o),e(nt,Z3o),M(kp,nt,null),e(xo,e2o),e(xo,Je),M(ey,Je,null),e(Je,o2o),e(Je,xie),e(xie,r2o),e(Je,t2o),e(Je,Sa),e(Sa,a2o),e(Sa,$ie),e($ie,n2o),e(Sa,s2o),e(Sa,kie),e(kie,l2o),e(Sa,i2o),e(Sa,Sie),e(Sie,d2o),e(Sa,c2o),e(Je,f2o),e(Je,y),e(y,Sp),e(Sp,Rie),e(Rie,m2o),e(Sp,g2o),e(Sp,oq),e(oq,h2o),e(Sp,p2o),e(y,u2o),e(y,Rp),e(Rp,Pie),e(Pie,_2o),e(Rp,b2o),e(Rp,rq),e(rq,v2o),e(Rp,F2o),e(y,T2o),e(y,Pp),e(Pp,Bie),e(Bie,M2o),e(Pp,E2o),e(Pp,tq),e(tq,C2o),e(Pp,w2o),e(y,A2o),e(y,Bp),e(Bp,Iie),e(Iie,L2o),e(Bp,y2o),e(Bp,aq),e(aq,x2o),e(Bp,$2o),e(y,k2o),e(y,Ip),e(Ip,Nie),e(Nie,S2o),e(Ip,R2o),e(Ip,nq),e(nq,P2o),e(Ip,B2o),e(y,I2o),e(y,Np),e(Np,qie),e(qie,N2o),e(Np,q2o),e(Np,sq),e(sq,j2o),e(Np,D2o),e(y,G2o),e(y,qp),e(qp,jie),e(jie,O2o),e(qp,V2o),e(qp,lq),e(lq,X2o),e(qp,z2o),e(y,W2o),e(y,jp),e(jp,Die),e(Die,Q2o),e(jp,H2o),e(jp,iq),e(iq,U2o),e(jp,J2o),e(y,Y2o),e(y,Dp),e(Dp,Gie),e(Gie,K2o),e(Dp,Z2o),e(Dp,dq),e(dq,ebo),e(Dp,obo),e(y,rbo),e(y,Gp),e(Gp,Oie),e(Oie,tbo),e(Gp,abo),e(Gp,cq),e(cq,nbo),e(Gp,sbo),e(y,lbo),e(y,Op),e(Op,Vie),e(Vie,ibo),e(Op,dbo),e(Op,fq),e(fq,cbo),e(Op,fbo),e(y,mbo),e(y,Vp),e(Vp,Xie),e(Xie,gbo),e(Vp,hbo),e(Vp,mq),e(mq,pbo),e(Vp,ubo),e(y,_bo),e(y,Xp),e(Xp,zie),e(zie,bbo),e(Xp,vbo),e(Xp,gq),e(gq,Fbo),e(Xp,Tbo),e(y,Mbo),e(y,zp),e(zp,Wie),e(Wie,Ebo),e(zp,Cbo),e(zp,hq),e(hq,wbo),e(zp,Abo),e(y,Lbo),e(y,Wp),e(Wp,Qie),e(Qie,ybo),e(Wp,xbo),e(Wp,pq),e(pq,$bo),e(Wp,kbo),e(y,Sbo),e(y,Qp),e(Qp,Hie),e(Hie,Rbo),e(Qp,Pbo),e(Qp,uq),e(uq,Bbo),e(Qp,Ibo),e(y,Nbo),e(y,Hp),e(Hp,Uie),e(Uie,qbo),e(Hp,jbo),e(Hp,_q),e(_q,Dbo),e(Hp,Gbo),e(y,Obo),e(y,Up),e(Up,Jie),e(Jie,Vbo),e(Up,Xbo),e(Up,bq),e(bq,zbo),e(Up,Wbo),e(y,Qbo),e(y,Jp),e(Jp,Yie),e(Yie,Hbo),e(Jp,Ubo),e(Jp,vq),e(vq,Jbo),e(Jp,Ybo),e(y,Kbo),e(y,Yp),e(Yp,Kie),e(Kie,Zbo),e(Yp,evo),e(Yp,Fq),e(Fq,ovo),e(Yp,rvo),e(y,tvo),e(y,Kp),e(Kp,Zie),e(Zie,avo),e(Kp,nvo),e(Kp,Tq),e(Tq,svo),e(Kp,lvo),e(y,ivo),e(y,Zp),e(Zp,ede),e(ede,dvo),e(Zp,cvo),e(Zp,Mq),e(Mq,fvo),e(Zp,mvo),e(y,gvo),e(y,eu),e(eu,ode),e(ode,hvo),e(eu,pvo),e(eu,Eq),e(Eq,uvo),e(eu,_vo),e(y,bvo),e(y,ou),e(ou,rde),e(rde,vvo),e(ou,Fvo),e(ou,Cq),e(Cq,Tvo),e(ou,Mvo),e(y,Evo),e(y,ru),e(ru,tde),e(tde,Cvo),e(ru,wvo),e(ru,wq),e(wq,Avo),e(ru,Lvo),e(y,yvo),e(y,tu),e(tu,ade),e(ade,xvo),e(tu,$vo),e(tu,Aq),e(Aq,kvo),e(tu,Svo),e(y,Rvo),e(y,au),e(au,nde),e(nde,Pvo),e(au,Bvo),e(au,Lq),e(Lq,Ivo),e(au,Nvo),e(y,qvo),e(y,nu),e(nu,sde),e(sde,jvo),e(nu,Dvo),e(nu,yq),e(yq,Gvo),e(nu,Ovo),e(y,Vvo),e(y,su),e(su,lde),e(lde,Xvo),e(su,zvo),e(su,xq),e(xq,Wvo),e(su,Qvo),e(y,Hvo),e(y,lu),e(lu,ide),e(ide,Uvo),e(lu,Jvo),e(lu,$q),e($q,Yvo),e(lu,Kvo),e(y,Zvo),e(y,iu),e(iu,dde),e(dde,eFo),e(iu,oFo),e(iu,kq),e(kq,rFo),e(iu,tFo),e(y,aFo),e(y,du),e(du,cde),e(cde,nFo),e(du,sFo),e(du,Sq),e(Sq,lFo),e(du,iFo),e(y,dFo),e(y,cu),e(cu,fde),e(fde,cFo),e(cu,fFo),e(cu,Rq),e(Rq,mFo),e(cu,gFo),e(y,hFo),e(y,Os),e(Os,mde),e(mde,pFo),e(Os,uFo),e(Os,Pq),e(Pq,_Fo),e(Os,bFo),e(Os,Bq),e(Bq,vFo),e(Os,FFo),e(y,TFo),e(y,fu),e(fu,gde),e(gde,MFo),e(fu,EFo),e(fu,Iq),e(Iq,CFo),e(fu,wFo),e(y,AFo),e(y,mu),e(mu,hde),e(hde,LFo),e(mu,yFo),e(mu,Nq),e(Nq,xFo),e(mu,$Fo),e(y,kFo),e(y,gu),e(gu,pde),e(pde,SFo),e(gu,RFo),e(gu,qq),e(qq,PFo),e(gu,BFo),e(y,IFo),e(y,hu),e(hu,ude),e(ude,NFo),e(hu,qFo),e(hu,jq),e(jq,jFo),e(hu,DFo),e(y,GFo),e(y,pu),e(pu,_de),e(_de,OFo),e(pu,VFo),e(pu,Dq),e(Dq,XFo),e(pu,zFo),e(y,WFo),e(y,uu),e(uu,bde),e(bde,QFo),e(uu,HFo),e(uu,Gq),e(Gq,UFo),e(uu,JFo),e(y,YFo),e(y,_u),e(_u,vde),e(vde,KFo),e(_u,ZFo),e(_u,Oq),e(Oq,eTo),e(_u,oTo),e(y,rTo),e(y,bu),e(bu,Fde),e(Fde,tTo),e(bu,aTo),e(bu,Vq),e(Vq,nTo),e(bu,sTo),e(y,lTo),e(y,vu),e(vu,Tde),e(Tde,iTo),e(vu,dTo),e(vu,Xq),e(Xq,cTo),e(vu,fTo),e(y,mTo),e(y,Fu),e(Fu,Mde),e(Mde,gTo),e(Fu,hTo),e(Fu,zq),e(zq,pTo),e(Fu,uTo),e(y,_To),e(y,Tu),e(Tu,Ede),e(Ede,bTo),e(Tu,vTo),e(Tu,Wq),e(Wq,FTo),e(Tu,TTo),e(y,MTo),e(y,Mu),e(Mu,Cde),e(Cde,ETo),e(Mu,CTo),e(Mu,Qq),e(Qq,wTo),e(Mu,ATo),e(y,LTo),e(y,Eu),e(Eu,wde),e(wde,yTo),e(Eu,xTo),e(Eu,Hq),e(Hq,$To),e(Eu,kTo),e(y,STo),e(y,Cu),e(Cu,Ade),e(Ade,RTo),e(Cu,PTo),e(Cu,Uq),e(Uq,BTo),e(Cu,ITo),e(y,NTo),e(y,wu),e(wu,Lde),e(Lde,qTo),e(wu,jTo),e(wu,Jq),e(Jq,DTo),e(wu,GTo),e(y,OTo),e(y,Au),e(Au,yde),e(yde,VTo),e(Au,XTo),e(Au,Yq),e(Yq,zTo),e(Au,WTo),e(y,QTo),e(y,Lu),e(Lu,xde),e(xde,HTo),e(Lu,UTo),e(Lu,Kq),e(Kq,JTo),e(Lu,YTo),e(y,KTo),e(y,yu),e(yu,$de),e($de,ZTo),e(yu,e7o),e(yu,Zq),e(Zq,o7o),e(yu,r7o),e(y,t7o),e(y,xu),e(xu,kde),e(kde,a7o),e(xu,n7o),e(xu,ej),e(ej,s7o),e(xu,l7o),e(y,i7o),e(y,$u),e($u,Sde),e(Sde,d7o),e($u,c7o),e($u,oj),e(oj,f7o),e($u,m7o),e(y,g7o),e(y,ku),e(ku,Rde),e(Rde,h7o),e(ku,p7o),e(ku,rj),e(rj,u7o),e(ku,_7o),e(y,b7o),e(y,Su),e(Su,Pde),e(Pde,v7o),e(Su,F7o),e(Su,tj),e(tj,T7o),e(Su,M7o),e(y,E7o),e(y,Ru),e(Ru,Bde),e(Bde,C7o),e(Ru,w7o),e(Ru,aj),e(aj,A7o),e(Ru,L7o),e(y,y7o),e(y,Pu),e(Pu,Ide),e(Ide,x7o),e(Pu,$7o),e(Pu,nj),e(nj,k7o),e(Pu,S7o),e(y,R7o),e(y,Bu),e(Bu,Nde),e(Nde,P7o),e(Bu,B7o),e(Bu,sj),e(sj,I7o),e(Bu,N7o),e(y,q7o),e(y,Iu),e(Iu,qde),e(qde,j7o),e(Iu,D7o),e(Iu,lj),e(lj,G7o),e(Iu,O7o),e(y,V7o),e(y,Nu),e(Nu,jde),e(jde,X7o),e(Nu,z7o),e(Nu,ij),e(ij,W7o),e(Nu,Q7o),e(y,H7o),e(y,qu),e(qu,Dde),e(Dde,U7o),e(qu,J7o),e(qu,dj),e(dj,Y7o),e(qu,K7o),e(y,Z7o),e(y,ju),e(ju,Gde),e(Gde,eMo),e(ju,oMo),e(ju,cj),e(cj,rMo),e(ju,tMo),e(y,aMo),e(y,Du),e(Du,Ode),e(Ode,nMo),e(Du,sMo),e(Du,fj),e(fj,lMo),e(Du,iMo),e(y,dMo),e(y,Gu),e(Gu,Vde),e(Vde,cMo),e(Gu,fMo),e(Gu,mj),e(mj,mMo),e(Gu,gMo),e(y,hMo),e(y,Ou),e(Ou,Xde),e(Xde,pMo),e(Ou,uMo),e(Ou,gj),e(gj,_Mo),e(Ou,bMo),e(y,vMo),e(y,Vu),e(Vu,zde),e(zde,FMo),e(Vu,TMo),e(Vu,hj),e(hj,MMo),e(Vu,EMo),e(y,CMo),e(y,Xu),e(Xu,Wde),e(Wde,wMo),e(Xu,AMo),e(Xu,pj),e(pj,LMo),e(Xu,yMo),e(y,xMo),e(y,zu),e(zu,Qde),e(Qde,$Mo),e(zu,kMo),e(zu,uj),e(uj,SMo),e(zu,RMo),e(y,PMo),e(y,Wu),e(Wu,Hde),e(Hde,BMo),e(Wu,IMo),e(Wu,_j),e(_j,NMo),e(Wu,qMo),e(y,jMo),e(y,Qu),e(Qu,Ude),e(Ude,DMo),e(Qu,GMo),e(Qu,bj),e(bj,OMo),e(Qu,VMo),e(y,XMo),e(y,Hu),e(Hu,Jde),e(Jde,zMo),e(Hu,WMo),e(Hu,vj),e(vj,QMo),e(Hu,HMo),e(y,UMo),e(y,Uu),e(Uu,Yde),e(Yde,JMo),e(Uu,YMo),e(Uu,Fj),e(Fj,KMo),e(Uu,ZMo),e(y,eEo),e(y,Ju),e(Ju,Kde),e(Kde,oEo),e(Ju,rEo),e(Ju,Tj),e(Tj,tEo),e(Ju,aEo),e(y,nEo),e(y,Yu),e(Yu,Zde),e(Zde,sEo),e(Yu,lEo),e(Yu,Mj),e(Mj,iEo),e(Yu,dEo),e(y,cEo),e(y,Ku),e(Ku,ece),e(ece,fEo),e(Ku,mEo),e(Ku,Ej),e(Ej,gEo),e(Ku,hEo),e(y,pEo),e(y,Zu),e(Zu,oce),e(oce,uEo),e(Zu,_Eo),e(Zu,Cj),e(Cj,bEo),e(Zu,vEo),e(y,FEo),e(y,e_),e(e_,rce),e(rce,TEo),e(e_,MEo),e(e_,wj),e(wj,EEo),e(e_,CEo),e(y,wEo),e(y,o_),e(o_,tce),e(tce,AEo),e(o_,LEo),e(o_,Aj),e(Aj,yEo),e(o_,xEo),e(y,$Eo),e(y,r_),e(r_,ace),e(ace,kEo),e(r_,SEo),e(r_,Lj),e(Lj,REo),e(r_,PEo),e(y,BEo),e(y,t_),e(t_,nce),e(nce,IEo),e(t_,NEo),e(t_,yj),e(yj,qEo),e(t_,jEo),e(y,DEo),e(y,a_),e(a_,sce),e(sce,GEo),e(a_,OEo),e(a_,xj),e(xj,VEo),e(a_,XEo),e(y,zEo),e(y,n_),e(n_,lce),e(lce,WEo),e(n_,QEo),e(n_,$j),e($j,HEo),e(n_,UEo),e(y,JEo),e(y,s_),e(s_,ice),e(ice,YEo),e(s_,KEo),e(s_,kj),e(kj,ZEo),e(s_,e4o),e(y,o4o),e(y,l_),e(l_,dce),e(dce,r4o),e(l_,t4o),e(l_,Sj),e(Sj,a4o),e(l_,n4o),e(y,s4o),e(y,i_),e(i_,cce),e(cce,l4o),e(i_,i4o),e(i_,Rj),e(Rj,d4o),e(i_,c4o),e(y,f4o),e(y,d_),e(d_,fce),e(fce,m4o),e(d_,g4o),e(d_,Pj),e(Pj,h4o),e(d_,p4o),e(y,u4o),e(y,c_),e(c_,mce),e(mce,_4o),e(c_,b4o),e(c_,Bj),e(Bj,v4o),e(c_,F4o),e(y,T4o),e(y,f_),e(f_,gce),e(gce,M4o),e(f_,E4o),e(f_,Ij),e(Ij,C4o),e(f_,w4o),e(y,A4o),e(y,m_),e(m_,hce),e(hce,L4o),e(m_,y4o),e(m_,Nj),e(Nj,x4o),e(m_,$4o),e(y,k4o),e(y,g_),e(g_,pce),e(pce,S4o),e(g_,R4o),e(g_,qj),e(qj,P4o),e(g_,B4o),e(y,I4o),e(y,h_),e(h_,uce),e(uce,N4o),e(h_,q4o),e(h_,jj),e(jj,j4o),e(h_,D4o),e(y,G4o),e(y,p_),e(p_,_ce),e(_ce,O4o),e(p_,V4o),e(p_,Dj),e(Dj,X4o),e(p_,z4o),e(y,W4o),e(y,u_),e(u_,bce),e(bce,Q4o),e(u_,H4o),e(u_,Gj),e(Gj,U4o),e(u_,J4o),e(y,Y4o),e(y,__),e(__,vce),e(vce,K4o),e(__,Z4o),e(__,Oj),e(Oj,eCo),e(__,oCo),e(y,rCo),e(y,b_),e(b_,Fce),e(Fce,tCo),e(b_,aCo),e(b_,Vj),e(Vj,nCo),e(b_,sCo),e(y,lCo),e(y,v_),e(v_,Tce),e(Tce,iCo),e(v_,dCo),e(v_,Xj),e(Xj,cCo),e(v_,fCo),e(y,mCo),e(y,F_),e(F_,Mce),e(Mce,gCo),e(F_,hCo),e(F_,zj),e(zj,pCo),e(F_,uCo),e(y,_Co),e(y,T_),e(T_,Ece),e(Ece,bCo),e(T_,vCo),e(T_,Wj),e(Wj,FCo),e(T_,TCo),e(y,MCo),e(y,M_),e(M_,Cce),e(Cce,ECo),e(M_,CCo),e(M_,Qj),e(Qj,wCo),e(M_,ACo),e(y,LCo),e(y,E_),e(E_,wce),e(wce,yCo),e(E_,xCo),e(E_,Hj),e(Hj,$Co),e(E_,kCo),e(y,SCo),e(y,C_),e(C_,Ace),e(Ace,RCo),e(C_,PCo),e(C_,Uj),e(Uj,BCo),e(C_,ICo),e(y,NCo),e(y,w_),e(w_,Lce),e(Lce,qCo),e(w_,jCo),e(w_,Jj),e(Jj,DCo),e(w_,GCo),e(y,OCo),e(y,A_),e(A_,yce),e(yce,VCo),e(A_,XCo),e(A_,Yj),e(Yj,zCo),e(A_,WCo),e(y,QCo),e(y,L_),e(L_,xce),e(xce,HCo),e(L_,UCo),e(L_,Kj),e(Kj,JCo),e(L_,YCo),e(y,KCo),e(y,y_),e(y_,$ce),e($ce,ZCo),e(y_,e5o),e(y_,Zj),e(Zj,o5o),e(y_,r5o),e(y,t5o),e(y,x_),e(x_,kce),e(kce,a5o),e(x_,n5o),e(x_,eD),e(eD,s5o),e(x_,l5o),e(Je,i5o),e(Je,$_),e($_,d5o),e($_,Sce),e(Sce,c5o),e($_,f5o),e($_,Rce),e(Rce,m5o),e(Je,g5o),M(k_,Je,null),b(f,PGe,_),b(f,qi,_),e(qi,S_),e(S_,Pce),M(oy,Pce,null),e(qi,h5o),e(qi,Bce),e(Bce,p5o),b(f,BGe,_),b(f,$o,_),M(ry,$o,null),e($o,u5o),e($o,ji),e(ji,_5o),e(ji,oD),e(oD,b5o),e(ji,v5o),e(ji,rD),e(rD,F5o),e(ji,T5o),e($o,M5o),e($o,ty),e(ty,E5o),e(ty,Ice),e(Ice,C5o),e(ty,w5o),e($o,A5o),e($o,st),M(ay,st,null),e(st,L5o),e(st,Nce),e(Nce,y5o),e(st,x5o),e(st,Di),e(Di,$5o),e(Di,qce),e(qce,k5o),e(Di,S5o),e(Di,tD),e(tD,R5o),e(Di,P5o),e(st,B5o),M(R_,st,null),e($o,I5o),e($o,Ye),M(ny,Ye,null),e(Ye,N5o),e(Ye,jce),e(jce,q5o),e(Ye,j5o),e(Ye,Ra),e(Ra,D5o),e(Ra,Dce),e(Dce,G5o),e(Ra,O5o),e(Ra,Gce),e(Gce,V5o),e(Ra,X5o),e(Ra,Oce),e(Oce,z5o),e(Ra,W5o),e(Ye,Q5o),e(Ye,G),e(G,P_),e(P_,Vce),e(Vce,H5o),e(P_,U5o),e(P_,aD),e(aD,J5o),e(P_,Y5o),e(G,K5o),e(G,B_),e(B_,Xce),e(Xce,Z5o),e(B_,e0o),e(B_,nD),e(nD,o0o),e(B_,r0o),e(G,t0o),e(G,I_),e(I_,zce),e(zce,a0o),e(I_,n0o),e(I_,sD),e(sD,s0o),e(I_,l0o),e(G,i0o),e(G,N_),e(N_,Wce),e(Wce,d0o),e(N_,c0o),e(N_,lD),e(lD,f0o),e(N_,m0o),e(G,g0o),e(G,q_),e(q_,Qce),e(Qce,h0o),e(q_,p0o),e(q_,iD),e(iD,u0o),e(q_,_0o),e(G,b0o),e(G,j_),e(j_,Hce),e(Hce,v0o),e(j_,F0o),e(j_,dD),e(dD,T0o),e(j_,M0o),e(G,E0o),e(G,D_),e(D_,Uce),e(Uce,C0o),e(D_,w0o),e(D_,cD),e(cD,A0o),e(D_,L0o),e(G,y0o),e(G,G_),e(G_,Jce),e(Jce,x0o),e(G_,$0o),e(G_,fD),e(fD,k0o),e(G_,S0o),e(G,R0o),e(G,O_),e(O_,Yce),e(Yce,P0o),e(O_,B0o),e(O_,mD),e(mD,I0o),e(O_,N0o),e(G,q0o),e(G,V_),e(V_,Kce),e(Kce,j0o),e(V_,D0o),e(V_,gD),e(gD,G0o),e(V_,O0o),e(G,V0o),e(G,X_),e(X_,Zce),e(Zce,X0o),e(X_,z0o),e(X_,hD),e(hD,W0o),e(X_,Q0o),e(G,H0o),e(G,z_),e(z_,efe),e(efe,U0o),e(z_,J0o),e(z_,pD),e(pD,Y0o),e(z_,K0o),e(G,Z0o),e(G,W_),e(W_,ofe),e(ofe,ewo),e(W_,owo),e(W_,uD),e(uD,rwo),e(W_,two),e(G,awo),e(G,Q_),e(Q_,rfe),e(rfe,nwo),e(Q_,swo),e(Q_,_D),e(_D,lwo),e(Q_,iwo),e(G,dwo),e(G,H_),e(H_,tfe),e(tfe,cwo),e(H_,fwo),e(H_,bD),e(bD,mwo),e(H_,gwo),e(G,hwo),e(G,U_),e(U_,afe),e(afe,pwo),e(U_,uwo),e(U_,vD),e(vD,_wo),e(U_,bwo),e(G,vwo),e(G,J_),e(J_,nfe),e(nfe,Fwo),e(J_,Two),e(J_,FD),e(FD,Mwo),e(J_,Ewo),e(G,Cwo),e(G,Y_),e(Y_,sfe),e(sfe,wwo),e(Y_,Awo),e(Y_,TD),e(TD,Lwo),e(Y_,ywo),e(G,xwo),e(G,K_),e(K_,lfe),e(lfe,$wo),e(K_,kwo),e(K_,MD),e(MD,Swo),e(K_,Rwo),e(G,Pwo),e(G,Z_),e(Z_,ife),e(ife,Bwo),e(Z_,Iwo),e(Z_,ED),e(ED,Nwo),e(Z_,qwo),e(G,jwo),e(G,e1),e(e1,dfe),e(dfe,Dwo),e(e1,Gwo),e(e1,CD),e(CD,Owo),e(e1,Vwo),e(G,Xwo),e(G,o1),e(o1,cfe),e(cfe,zwo),e(o1,Wwo),e(o1,wD),e(wD,Qwo),e(o1,Hwo),e(G,Uwo),e(G,r1),e(r1,ffe),e(ffe,Jwo),e(r1,Ywo),e(r1,AD),e(AD,Kwo),e(r1,Zwo),e(G,eAo),e(G,t1),e(t1,mfe),e(mfe,oAo),e(t1,rAo),e(t1,LD),e(LD,tAo),e(t1,aAo),e(G,nAo),e(G,a1),e(a1,gfe),e(gfe,sAo),e(a1,lAo),e(a1,yD),e(yD,iAo),e(a1,dAo),e(G,cAo),e(G,n1),e(n1,hfe),e(hfe,fAo),e(n1,mAo),e(n1,xD),e(xD,gAo),e(n1,hAo),e(G,pAo),e(G,s1),e(s1,pfe),e(pfe,uAo),e(s1,_Ao),e(s1,$D),e($D,bAo),e(s1,vAo),e(G,FAo),e(G,l1),e(l1,ufe),e(ufe,TAo),e(l1,MAo),e(l1,kD),e(kD,EAo),e(l1,CAo),e(G,wAo),e(G,i1),e(i1,_fe),e(_fe,AAo),e(i1,LAo),e(i1,SD),e(SD,yAo),e(i1,xAo),e(G,$Ao),e(G,d1),e(d1,bfe),e(bfe,kAo),e(d1,SAo),e(d1,RD),e(RD,RAo),e(d1,PAo),e(G,BAo),e(G,c1),e(c1,vfe),e(vfe,IAo),e(c1,NAo),e(c1,PD),e(PD,qAo),e(c1,jAo),e(G,DAo),e(G,f1),e(f1,Ffe),e(Ffe,GAo),e(f1,OAo),e(f1,BD),e(BD,VAo),e(f1,XAo),e(G,zAo),e(G,m1),e(m1,Tfe),e(Tfe,WAo),e(m1,QAo),e(m1,ID),e(ID,HAo),e(m1,UAo),e(G,JAo),e(G,g1),e(g1,Mfe),e(Mfe,YAo),e(g1,KAo),e(g1,ND),e(ND,ZAo),e(g1,e6o),e(G,o6o),e(G,h1),e(h1,Efe),e(Efe,r6o),e(h1,t6o),e(h1,qD),e(qD,a6o),e(h1,n6o),e(G,s6o),e(G,p1),e(p1,Cfe),e(Cfe,l6o),e(p1,i6o),e(p1,jD),e(jD,d6o),e(p1,c6o),e(G,f6o),e(G,u1),e(u1,wfe),e(wfe,m6o),e(u1,g6o),e(u1,DD),e(DD,h6o),e(u1,p6o),e(G,u6o),e(G,_1),e(_1,Afe),e(Afe,_6o),e(_1,b6o),e(_1,GD),e(GD,v6o),e(_1,F6o),e(G,T6o),e(G,b1),e(b1,Lfe),e(Lfe,M6o),e(b1,E6o),e(b1,OD),e(OD,C6o),e(b1,w6o),e(G,A6o),e(G,v1),e(v1,yfe),e(yfe,L6o),e(v1,y6o),e(v1,VD),e(VD,x6o),e(v1,$6o),e(G,k6o),e(G,F1),e(F1,xfe),e(xfe,S6o),e(F1,R6o),e(F1,XD),e(XD,P6o),e(F1,B6o),e(G,I6o),e(G,T1),e(T1,$fe),e($fe,N6o),e(T1,q6o),e(T1,zD),e(zD,j6o),e(T1,D6o),e(G,G6o),e(G,M1),e(M1,kfe),e(kfe,O6o),e(M1,V6o),e(M1,WD),e(WD,X6o),e(M1,z6o),e(Ye,W6o),e(Ye,E1),e(E1,Q6o),e(E1,Sfe),e(Sfe,H6o),e(E1,U6o),e(E1,Rfe),e(Rfe,J6o),e(Ye,Y6o),M(C1,Ye,null),b(f,IGe,_),b(f,Gi,_),e(Gi,w1),e(w1,Pfe),M(sy,Pfe,null),e(Gi,K6o),e(Gi,Bfe),e(Bfe,Z6o),b(f,NGe,_),b(f,ko,_),M(ly,ko,null),e(ko,eLo),e(ko,Oi),e(Oi,oLo),e(Oi,QD),e(QD,rLo),e(Oi,tLo),e(Oi,HD),e(HD,aLo),e(Oi,nLo),e(ko,sLo),e(ko,iy),e(iy,lLo),e(iy,Ife),e(Ife,iLo),e(iy,dLo),e(ko,cLo),e(ko,lt),M(dy,lt,null),e(lt,fLo),e(lt,Nfe),e(Nfe,mLo),e(lt,gLo),e(lt,Vi),e(Vi,hLo),e(Vi,qfe),e(qfe,pLo),e(Vi,uLo),e(Vi,UD),e(UD,_Lo),e(Vi,bLo),e(lt,vLo),M(A1,lt,null),e(ko,FLo),e(ko,Ke),M(cy,Ke,null),e(Ke,TLo),e(Ke,jfe),e(jfe,MLo),e(Ke,ELo),e(Ke,Pa),e(Pa,CLo),e(Pa,Dfe),e(Dfe,wLo),e(Pa,ALo),e(Pa,Gfe),e(Gfe,LLo),e(Pa,yLo),e(Pa,Ofe),e(Ofe,xLo),e(Pa,$Lo),e(Ke,kLo),e(Ke,z),e(z,L1),e(L1,Vfe),e(Vfe,SLo),e(L1,RLo),e(L1,JD),e(JD,PLo),e(L1,BLo),e(z,ILo),e(z,y1),e(y1,Xfe),e(Xfe,NLo),e(y1,qLo),e(y1,YD),e(YD,jLo),e(y1,DLo),e(z,GLo),e(z,x1),e(x1,zfe),e(zfe,OLo),e(x1,VLo),e(x1,KD),e(KD,XLo),e(x1,zLo),e(z,WLo),e(z,$1),e($1,Wfe),e(Wfe,QLo),e($1,HLo),e($1,ZD),e(ZD,ULo),e($1,JLo),e(z,YLo),e(z,k1),e(k1,Qfe),e(Qfe,KLo),e(k1,ZLo),e(k1,eG),e(eG,eyo),e(k1,oyo),e(z,ryo),e(z,S1),e(S1,Hfe),e(Hfe,tyo),e(S1,ayo),e(S1,oG),e(oG,nyo),e(S1,syo),e(z,lyo),e(z,R1),e(R1,Ufe),e(Ufe,iyo),e(R1,dyo),e(R1,rG),e(rG,cyo),e(R1,fyo),e(z,myo),e(z,P1),e(P1,Jfe),e(Jfe,gyo),e(P1,hyo),e(P1,tG),e(tG,pyo),e(P1,uyo),e(z,_yo),e(z,B1),e(B1,Yfe),e(Yfe,byo),e(B1,vyo),e(B1,aG),e(aG,Fyo),e(B1,Tyo),e(z,Myo),e(z,I1),e(I1,Kfe),e(Kfe,Eyo),e(I1,Cyo),e(I1,nG),e(nG,wyo),e(I1,Ayo),e(z,Lyo),e(z,N1),e(N1,Zfe),e(Zfe,yyo),e(N1,xyo),e(N1,sG),e(sG,$yo),e(N1,kyo),e(z,Syo),e(z,q1),e(q1,eme),e(eme,Ryo),e(q1,Pyo),e(q1,lG),e(lG,Byo),e(q1,Iyo),e(z,Nyo),e(z,j1),e(j1,ome),e(ome,qyo),e(j1,jyo),e(j1,iG),e(iG,Dyo),e(j1,Gyo),e(z,Oyo),e(z,D1),e(D1,rme),e(rme,Vyo),e(D1,Xyo),e(D1,dG),e(dG,zyo),e(D1,Wyo),e(z,Qyo),e(z,G1),e(G1,tme),e(tme,Hyo),e(G1,Uyo),e(G1,cG),e(cG,Jyo),e(G1,Yyo),e(z,Kyo),e(z,O1),e(O1,ame),e(ame,Zyo),e(O1,e8o),e(O1,fG),e(fG,o8o),e(O1,r8o),e(z,t8o),e(z,V1),e(V1,nme),e(nme,a8o),e(V1,n8o),e(V1,mG),e(mG,s8o),e(V1,l8o),e(z,i8o),e(z,X1),e(X1,sme),e(sme,d8o),e(X1,c8o),e(X1,gG),e(gG,f8o),e(X1,m8o),e(z,g8o),e(z,z1),e(z1,lme),e(lme,h8o),e(z1,p8o),e(z1,hG),e(hG,u8o),e(z1,_8o),e(z,b8o),e(z,W1),e(W1,ime),e(ime,v8o),e(W1,F8o),e(W1,pG),e(pG,T8o),e(W1,M8o),e(z,E8o),e(z,Q1),e(Q1,dme),e(dme,C8o),e(Q1,w8o),e(Q1,uG),e(uG,A8o),e(Q1,L8o),e(z,y8o),e(z,H1),e(H1,cme),e(cme,x8o),e(H1,$8o),e(H1,_G),e(_G,k8o),e(H1,S8o),e(z,R8o),e(z,U1),e(U1,fme),e(fme,P8o),e(U1,B8o),e(U1,bG),e(bG,I8o),e(U1,N8o),e(z,q8o),e(z,J1),e(J1,mme),e(mme,j8o),e(J1,D8o),e(J1,vG),e(vG,G8o),e(J1,O8o),e(z,V8o),e(z,Y1),e(Y1,gme),e(gme,X8o),e(Y1,z8o),e(Y1,FG),e(FG,W8o),e(Y1,Q8o),e(z,H8o),e(z,K1),e(K1,hme),e(hme,U8o),e(K1,J8o),e(K1,TG),e(TG,Y8o),e(K1,K8o),e(z,Z8o),e(z,Z1),e(Z1,pme),e(pme,e9o),e(Z1,o9o),e(Z1,MG),e(MG,r9o),e(Z1,t9o),e(z,a9o),e(z,e3),e(e3,ume),e(ume,n9o),e(e3,s9o),e(e3,EG),e(EG,l9o),e(e3,i9o),e(z,d9o),e(z,o3),e(o3,_me),e(_me,c9o),e(o3,f9o),e(o3,CG),e(CG,m9o),e(o3,g9o),e(z,h9o),e(z,r3),e(r3,bme),e(bme,p9o),e(r3,u9o),e(r3,wG),e(wG,_9o),e(r3,b9o),e(z,v9o),e(z,t3),e(t3,vme),e(vme,F9o),e(t3,T9o),e(t3,AG),e(AG,M9o),e(t3,E9o),e(z,C9o),e(z,a3),e(a3,Fme),e(Fme,w9o),e(a3,A9o),e(a3,LG),e(LG,L9o),e(a3,y9o),e(z,x9o),e(z,n3),e(n3,Tme),e(Tme,$9o),e(n3,k9o),e(n3,yG),e(yG,S9o),e(n3,R9o),e(z,P9o),e(z,s3),e(s3,Mme),e(Mme,B9o),e(s3,I9o),e(s3,xG),e(xG,N9o),e(s3,q9o),e(z,j9o),e(z,l3),e(l3,Eme),e(Eme,D9o),e(l3,G9o),e(l3,$G),e($G,O9o),e(l3,V9o),e(z,X9o),e(z,i3),e(i3,Cme),e(Cme,z9o),e(i3,W9o),e(i3,kG),e(kG,Q9o),e(i3,H9o),e(z,U9o),e(z,d3),e(d3,wme),e(wme,J9o),e(d3,Y9o),e(d3,SG),e(SG,K9o),e(d3,Z9o),e(z,exo),e(z,c3),e(c3,Ame),e(Ame,oxo),e(c3,rxo),e(c3,RG),e(RG,txo),e(c3,axo),e(Ke,nxo),e(Ke,f3),e(f3,sxo),e(f3,Lme),e(Lme,lxo),e(f3,ixo),e(f3,yme),e(yme,dxo),e(Ke,cxo),M(m3,Ke,null),b(f,qGe,_),b(f,Xi,_),e(Xi,g3),e(g3,xme),M(fy,xme,null),e(Xi,fxo),e(Xi,$me),e($me,mxo),b(f,jGe,_),b(f,So,_),M(my,So,null),e(So,gxo),e(So,zi),e(zi,hxo),e(zi,PG),e(PG,pxo),e(zi,uxo),e(zi,BG),e(BG,_xo),e(zi,bxo),e(So,vxo),e(So,gy),e(gy,Fxo),e(gy,kme),e(kme,Txo),e(gy,Mxo),e(So,Exo),e(So,it),M(hy,it,null),e(it,Cxo),e(it,Sme),e(Sme,wxo),e(it,Axo),e(it,Wi),e(Wi,Lxo),e(Wi,Rme),e(Rme,yxo),e(Wi,xxo),e(Wi,IG),e(IG,$xo),e(Wi,kxo),e(it,Sxo),M(h3,it,null),e(So,Rxo),e(So,Ze),M(py,Ze,null),e(Ze,Pxo),e(Ze,Pme),e(Pme,Bxo),e(Ze,Ixo),e(Ze,Ba),e(Ba,Nxo),e(Ba,Bme),e(Bme,qxo),e(Ba,jxo),e(Ba,Ime),e(Ime,Dxo),e(Ba,Gxo),e(Ba,Nme),e(Nme,Oxo),e(Ba,Vxo),e(Ze,Xxo),e(Ze,Q),e(Q,p3),e(p3,qme),e(qme,zxo),e(p3,Wxo),e(p3,NG),e(NG,Qxo),e(p3,Hxo),e(Q,Uxo),e(Q,u3),e(u3,jme),e(jme,Jxo),e(u3,Yxo),e(u3,qG),e(qG,Kxo),e(u3,Zxo),e(Q,e$o),e(Q,_3),e(_3,Dme),e(Dme,o$o),e(_3,r$o),e(_3,jG),e(jG,t$o),e(_3,a$o),e(Q,n$o),e(Q,b3),e(b3,Gme),e(Gme,s$o),e(b3,l$o),e(b3,DG),e(DG,i$o),e(b3,d$o),e(Q,c$o),e(Q,v3),e(v3,Ome),e(Ome,f$o),e(v3,m$o),e(v3,GG),e(GG,g$o),e(v3,h$o),e(Q,p$o),e(Q,F3),e(F3,Vme),e(Vme,u$o),e(F3,_$o),e(F3,OG),e(OG,b$o),e(F3,v$o),e(Q,F$o),e(Q,T3),e(T3,Xme),e(Xme,T$o),e(T3,M$o),e(T3,VG),e(VG,E$o),e(T3,C$o),e(Q,w$o),e(Q,M3),e(M3,zme),e(zme,A$o),e(M3,L$o),e(M3,XG),e(XG,y$o),e(M3,x$o),e(Q,$$o),e(Q,E3),e(E3,Wme),e(Wme,k$o),e(E3,S$o),e(E3,zG),e(zG,R$o),e(E3,P$o),e(Q,B$o),e(Q,C3),e(C3,Qme),e(Qme,I$o),e(C3,N$o),e(C3,WG),e(WG,q$o),e(C3,j$o),e(Q,D$o),e(Q,w3),e(w3,Hme),e(Hme,G$o),e(w3,O$o),e(w3,QG),e(QG,V$o),e(w3,X$o),e(Q,z$o),e(Q,A3),e(A3,Ume),e(Ume,W$o),e(A3,Q$o),e(A3,HG),e(HG,H$o),e(A3,U$o),e(Q,J$o),e(Q,L3),e(L3,Jme),e(Jme,Y$o),e(L3,K$o),e(L3,UG),e(UG,Z$o),e(L3,eko),e(Q,oko),e(Q,y3),e(y3,Yme),e(Yme,rko),e(y3,tko),e(y3,JG),e(JG,ako),e(y3,nko),e(Q,sko),e(Q,x3),e(x3,Kme),e(Kme,lko),e(x3,iko),e(x3,YG),e(YG,dko),e(x3,cko),e(Q,fko),e(Q,$3),e($3,Zme),e(Zme,mko),e($3,gko),e($3,KG),e(KG,hko),e($3,pko),e(Q,uko),e(Q,k3),e(k3,ege),e(ege,_ko),e(k3,bko),e(k3,ZG),e(ZG,vko),e(k3,Fko),e(Q,Tko),e(Q,S3),e(S3,oge),e(oge,Mko),e(S3,Eko),e(S3,eO),e(eO,Cko),e(S3,wko),e(Q,Ako),e(Q,R3),e(R3,rge),e(rge,Lko),e(R3,yko),e(R3,oO),e(oO,xko),e(R3,$ko),e(Q,kko),e(Q,P3),e(P3,tge),e(tge,Sko),e(P3,Rko),e(P3,rO),e(rO,Pko),e(P3,Bko),e(Q,Iko),e(Q,B3),e(B3,age),e(age,Nko),e(B3,qko),e(B3,tO),e(tO,jko),e(B3,Dko),e(Q,Gko),e(Q,I3),e(I3,nge),e(nge,Oko),e(I3,Vko),e(I3,aO),e(aO,Xko),e(I3,zko),e(Q,Wko),e(Q,N3),e(N3,sge),e(sge,Qko),e(N3,Hko),e(N3,nO),e(nO,Uko),e(N3,Jko),e(Q,Yko),e(Q,q3),e(q3,lge),e(lge,Kko),e(q3,Zko),e(q3,sO),e(sO,eSo),e(q3,oSo),e(Q,rSo),e(Q,j3),e(j3,ige),e(ige,tSo),e(j3,aSo),e(j3,lO),e(lO,nSo),e(j3,sSo),e(Q,lSo),e(Q,D3),e(D3,dge),e(dge,iSo),e(D3,dSo),e(D3,iO),e(iO,cSo),e(D3,fSo),e(Q,mSo),e(Q,G3),e(G3,cge),e(cge,gSo),e(G3,hSo),e(G3,dO),e(dO,pSo),e(G3,uSo),e(Q,_So),e(Q,O3),e(O3,fge),e(fge,bSo),e(O3,vSo),e(O3,cO),e(cO,FSo),e(O3,TSo),e(Q,MSo),e(Q,V3),e(V3,mge),e(mge,ESo),e(V3,CSo),e(V3,fO),e(fO,wSo),e(V3,ASo),e(Q,LSo),e(Q,X3),e(X3,gge),e(gge,ySo),e(X3,xSo),e(X3,mO),e(mO,$So),e(X3,kSo),e(Q,SSo),e(Q,z3),e(z3,hge),e(hge,RSo),e(z3,PSo),e(z3,gO),e(gO,BSo),e(z3,ISo),e(Q,NSo),e(Q,W3),e(W3,pge),e(pge,qSo),e(W3,jSo),e(W3,uge),e(uge,DSo),e(W3,GSo),e(Q,OSo),e(Q,Q3),e(Q3,_ge),e(_ge,VSo),e(Q3,XSo),e(Q3,hO),e(hO,zSo),e(Q3,WSo),e(Q,QSo),e(Q,H3),e(H3,bge),e(bge,HSo),e(H3,USo),e(H3,pO),e(pO,JSo),e(H3,YSo),e(Q,KSo),e(Q,U3),e(U3,vge),e(vge,ZSo),e(U3,eRo),e(U3,uO),e(uO,oRo),e(U3,rRo),e(Q,tRo),e(Q,J3),e(J3,Fge),e(Fge,aRo),e(J3,nRo),e(J3,_O),e(_O,sRo),e(J3,lRo),e(Ze,iRo),e(Ze,Y3),e(Y3,dRo),e(Y3,Tge),e(Tge,cRo),e(Y3,fRo),e(Y3,Mge),e(Mge,mRo),e(Ze,gRo),M(K3,Ze,null),b(f,DGe,_),b(f,Qi,_),e(Qi,Z3),e(Z3,Ege),M(uy,Ege,null),e(Qi,hRo),e(Qi,Cge),e(Cge,pRo),b(f,GGe,_),b(f,Ro,_),M(_y,Ro,null),e(Ro,uRo),e(Ro,Hi),e(Hi,_Ro),e(Hi,bO),e(bO,bRo),e(Hi,vRo),e(Hi,vO),e(vO,FRo),e(Hi,TRo),e(Ro,MRo),e(Ro,by),e(by,ERo),e(by,wge),e(wge,CRo),e(by,wRo),e(Ro,ARo),e(Ro,dt),M(vy,dt,null),e(dt,LRo),e(dt,Age),e(Age,yRo),e(dt,xRo),e(dt,Ui),e(Ui,$Ro),e(Ui,Lge),e(Lge,kRo),e(Ui,SRo),e(Ui,FO),e(FO,RRo),e(Ui,PRo),e(dt,BRo),M(e2,dt,null),e(Ro,IRo),e(Ro,eo),M(Fy,eo,null),e(eo,NRo),e(eo,yge),e(yge,qRo),e(eo,jRo),e(eo,Ia),e(Ia,DRo),e(Ia,xge),e(xge,GRo),e(Ia,ORo),e(Ia,$ge),e($ge,VRo),e(Ia,XRo),e(Ia,kge),e(kge,zRo),e(Ia,WRo),e(eo,QRo),e(eo,pe),e(pe,o2),e(o2,Sge),e(Sge,HRo),e(o2,URo),e(o2,TO),e(TO,JRo),e(o2,YRo),e(pe,KRo),e(pe,r2),e(r2,Rge),e(Rge,ZRo),e(r2,ePo),e(r2,MO),e(MO,oPo),e(r2,rPo),e(pe,tPo),e(pe,t2),e(t2,Pge),e(Pge,aPo),e(t2,nPo),e(t2,EO),e(EO,sPo),e(t2,lPo),e(pe,iPo),e(pe,a2),e(a2,Bge),e(Bge,dPo),e(a2,cPo),e(a2,CO),e(CO,fPo),e(a2,mPo),e(pe,gPo),e(pe,n2),e(n2,Ige),e(Ige,hPo),e(n2,pPo),e(n2,wO),e(wO,uPo),e(n2,_Po),e(pe,bPo),e(pe,s2),e(s2,Nge),e(Nge,vPo),e(s2,FPo),e(s2,AO),e(AO,TPo),e(s2,MPo),e(pe,EPo),e(pe,l2),e(l2,qge),e(qge,CPo),e(l2,wPo),e(l2,LO),e(LO,APo),e(l2,LPo),e(pe,yPo),e(pe,i2),e(i2,jge),e(jge,xPo),e(i2,$Po),e(i2,yO),e(yO,kPo),e(i2,SPo),e(pe,RPo),e(pe,d2),e(d2,Dge),e(Dge,PPo),e(d2,BPo),e(d2,xO),e(xO,IPo),e(d2,NPo),e(pe,qPo),e(pe,c2),e(c2,Gge),e(Gge,jPo),e(c2,DPo),e(c2,$O),e($O,GPo),e(c2,OPo),e(pe,VPo),e(pe,f2),e(f2,Oge),e(Oge,XPo),e(f2,zPo),e(f2,kO),e(kO,WPo),e(f2,QPo),e(pe,HPo),e(pe,m2),e(m2,Vge),e(Vge,UPo),e(m2,JPo),e(m2,SO),e(SO,YPo),e(m2,KPo),e(pe,ZPo),e(pe,g2),e(g2,Xge),e(Xge,eBo),e(g2,oBo),e(g2,RO),e(RO,rBo),e(g2,tBo),e(pe,aBo),e(pe,h2),e(h2,zge),e(zge,nBo),e(h2,sBo),e(h2,PO),e(PO,lBo),e(h2,iBo),e(pe,dBo),e(pe,p2),e(p2,Wge),e(Wge,cBo),e(p2,fBo),e(p2,BO),e(BO,mBo),e(p2,gBo),e(pe,hBo),e(pe,u2),e(u2,Qge),e(Qge,pBo),e(u2,uBo),e(u2,IO),e(IO,_Bo),e(u2,bBo),e(pe,vBo),e(pe,_2),e(_2,Hge),e(Hge,FBo),e(_2,TBo),e(_2,NO),e(NO,MBo),e(_2,EBo),e(eo,CBo),e(eo,b2),e(b2,wBo),e(b2,Uge),e(Uge,ABo),e(b2,LBo),e(b2,Jge),e(Jge,yBo),e(eo,xBo),M(v2,eo,null),b(f,OGe,_),b(f,Ji,_),e(Ji,F2),e(F2,Yge),M(Ty,Yge,null),e(Ji,$Bo),e(Ji,Kge),e(Kge,kBo),b(f,VGe,_),b(f,Po,_),M(My,Po,null),e(Po,SBo),e(Po,Yi),e(Yi,RBo),e(Yi,qO),e(qO,PBo),e(Yi,BBo),e(Yi,jO),e(jO,IBo),e(Yi,NBo),e(Po,qBo),e(Po,Ey),e(Ey,jBo),e(Ey,Zge),e(Zge,DBo),e(Ey,GBo),e(Po,OBo),e(Po,ct),M(Cy,ct,null),e(ct,VBo),e(ct,ehe),e(ehe,XBo),e(ct,zBo),e(ct,Ki),e(Ki,WBo),e(Ki,ohe),e(ohe,QBo),e(Ki,HBo),e(Ki,DO),e(DO,UBo),e(Ki,JBo),e(ct,YBo),M(T2,ct,null),e(Po,KBo),e(Po,oo),M(wy,oo,null),e(oo,ZBo),e(oo,rhe),e(rhe,eIo),e(oo,oIo),e(oo,Na),e(Na,rIo),e(Na,the),e(the,tIo),e(Na,aIo),e(Na,ahe),e(ahe,nIo),e(Na,sIo),e(Na,nhe),e(nhe,lIo),e(Na,iIo),e(oo,dIo),e(oo,N),e(N,M2),e(M2,she),e(she,cIo),e(M2,fIo),e(M2,GO),e(GO,mIo),e(M2,gIo),e(N,hIo),e(N,E2),e(E2,lhe),e(lhe,pIo),e(E2,uIo),e(E2,OO),e(OO,_Io),e(E2,bIo),e(N,vIo),e(N,C2),e(C2,ihe),e(ihe,FIo),e(C2,TIo),e(C2,VO),e(VO,MIo),e(C2,EIo),e(N,CIo),e(N,w2),e(w2,dhe),e(dhe,wIo),e(w2,AIo),e(w2,XO),e(XO,LIo),e(w2,yIo),e(N,xIo),e(N,A2),e(A2,che),e(che,$Io),e(A2,kIo),e(A2,zO),e(zO,SIo),e(A2,RIo),e(N,PIo),e(N,L2),e(L2,fhe),e(fhe,BIo),e(L2,IIo),e(L2,WO),e(WO,NIo),e(L2,qIo),e(N,jIo),e(N,y2),e(y2,mhe),e(mhe,DIo),e(y2,GIo),e(y2,QO),e(QO,OIo),e(y2,VIo),e(N,XIo),e(N,x2),e(x2,ghe),e(ghe,zIo),e(x2,WIo),e(x2,HO),e(HO,QIo),e(x2,HIo),e(N,UIo),e(N,$2),e($2,hhe),e(hhe,JIo),e($2,YIo),e($2,UO),e(UO,KIo),e($2,ZIo),e(N,eNo),e(N,k2),e(k2,phe),e(phe,oNo),e(k2,rNo),e(k2,JO),e(JO,tNo),e(k2,aNo),e(N,nNo),e(N,S2),e(S2,uhe),e(uhe,sNo),e(S2,lNo),e(S2,YO),e(YO,iNo),e(S2,dNo),e(N,cNo),e(N,R2),e(R2,_he),e(_he,fNo),e(R2,mNo),e(R2,KO),e(KO,gNo),e(R2,hNo),e(N,pNo),e(N,P2),e(P2,bhe),e(bhe,uNo),e(P2,_No),e(P2,ZO),e(ZO,bNo),e(P2,vNo),e(N,FNo),e(N,B2),e(B2,vhe),e(vhe,TNo),e(B2,MNo),e(B2,eV),e(eV,ENo),e(B2,CNo),e(N,wNo),e(N,I2),e(I2,Fhe),e(Fhe,ANo),e(I2,LNo),e(I2,oV),e(oV,yNo),e(I2,xNo),e(N,$No),e(N,N2),e(N2,The),e(The,kNo),e(N2,SNo),e(N2,rV),e(rV,RNo),e(N2,PNo),e(N,BNo),e(N,q2),e(q2,Mhe),e(Mhe,INo),e(q2,NNo),e(q2,tV),e(tV,qNo),e(q2,jNo),e(N,DNo),e(N,j2),e(j2,Ehe),e(Ehe,GNo),e(j2,ONo),e(j2,aV),e(aV,VNo),e(j2,XNo),e(N,zNo),e(N,D2),e(D2,Che),e(Che,WNo),e(D2,QNo),e(D2,nV),e(nV,HNo),e(D2,UNo),e(N,JNo),e(N,G2),e(G2,whe),e(whe,YNo),e(G2,KNo),e(G2,sV),e(sV,ZNo),e(G2,eqo),e(N,oqo),e(N,O2),e(O2,Ahe),e(Ahe,rqo),e(O2,tqo),e(O2,lV),e(lV,aqo),e(O2,nqo),e(N,sqo),e(N,V2),e(V2,Lhe),e(Lhe,lqo),e(V2,iqo),e(V2,iV),e(iV,dqo),e(V2,cqo),e(N,fqo),e(N,X2),e(X2,yhe),e(yhe,mqo),e(X2,gqo),e(X2,dV),e(dV,hqo),e(X2,pqo),e(N,uqo),e(N,z2),e(z2,xhe),e(xhe,_qo),e(z2,bqo),e(z2,cV),e(cV,vqo),e(z2,Fqo),e(N,Tqo),e(N,W2),e(W2,$he),e($he,Mqo),e(W2,Eqo),e(W2,fV),e(fV,Cqo),e(W2,wqo),e(N,Aqo),e(N,Q2),e(Q2,khe),e(khe,Lqo),e(Q2,yqo),e(Q2,mV),e(mV,xqo),e(Q2,$qo),e(N,kqo),e(N,H2),e(H2,She),e(She,Sqo),e(H2,Rqo),e(H2,gV),e(gV,Pqo),e(H2,Bqo),e(N,Iqo),e(N,U2),e(U2,Rhe),e(Rhe,Nqo),e(U2,qqo),e(U2,hV),e(hV,jqo),e(U2,Dqo),e(N,Gqo),e(N,J2),e(J2,Phe),e(Phe,Oqo),e(J2,Vqo),e(J2,pV),e(pV,Xqo),e(J2,zqo),e(N,Wqo),e(N,Y2),e(Y2,Bhe),e(Bhe,Qqo),e(Y2,Hqo),e(Y2,uV),e(uV,Uqo),e(Y2,Jqo),e(N,Yqo),e(N,K2),e(K2,Ihe),e(Ihe,Kqo),e(K2,Zqo),e(K2,_V),e(_V,ejo),e(K2,ojo),e(N,rjo),e(N,Z2),e(Z2,Nhe),e(Nhe,tjo),e(Z2,ajo),e(Z2,bV),e(bV,njo),e(Z2,sjo),e(N,ljo),e(N,eb),e(eb,qhe),e(qhe,ijo),e(eb,djo),e(eb,vV),e(vV,cjo),e(eb,fjo),e(N,mjo),e(N,ob),e(ob,jhe),e(jhe,gjo),e(ob,hjo),e(ob,FV),e(FV,pjo),e(ob,ujo),e(N,_jo),e(N,rb),e(rb,Dhe),e(Dhe,bjo),e(rb,vjo),e(rb,TV),e(TV,Fjo),e(rb,Tjo),e(N,Mjo),e(N,tb),e(tb,Ghe),e(Ghe,Ejo),e(tb,Cjo),e(tb,MV),e(MV,wjo),e(tb,Ajo),e(N,Ljo),e(N,ab),e(ab,Ohe),e(Ohe,yjo),e(ab,xjo),e(ab,EV),e(EV,$jo),e(ab,kjo),e(N,Sjo),e(N,nb),e(nb,Vhe),e(Vhe,Rjo),e(nb,Pjo),e(nb,CV),e(CV,Bjo),e(nb,Ijo),e(N,Njo),e(N,sb),e(sb,Xhe),e(Xhe,qjo),e(sb,jjo),e(sb,wV),e(wV,Djo),e(sb,Gjo),e(N,Ojo),e(N,lb),e(lb,zhe),e(zhe,Vjo),e(lb,Xjo),e(lb,AV),e(AV,zjo),e(lb,Wjo),e(N,Qjo),e(N,ib),e(ib,Whe),e(Whe,Hjo),e(ib,Ujo),e(ib,LV),e(LV,Jjo),e(ib,Yjo),e(N,Kjo),e(N,db),e(db,Qhe),e(Qhe,Zjo),e(db,eDo),e(db,yV),e(yV,oDo),e(db,rDo),e(N,tDo),e(N,cb),e(cb,Hhe),e(Hhe,aDo),e(cb,nDo),e(cb,xV),e(xV,sDo),e(cb,lDo),e(N,iDo),e(N,fb),e(fb,Uhe),e(Uhe,dDo),e(fb,cDo),e(fb,$V),e($V,fDo),e(fb,mDo),e(N,gDo),e(N,mb),e(mb,Jhe),e(Jhe,hDo),e(mb,pDo),e(mb,kV),e(kV,uDo),e(mb,_Do),e(N,bDo),e(N,gb),e(gb,Yhe),e(Yhe,vDo),e(gb,FDo),e(gb,SV),e(SV,TDo),e(gb,MDo),e(N,EDo),e(N,hb),e(hb,Khe),e(Khe,CDo),e(hb,wDo),e(hb,RV),e(RV,ADo),e(hb,LDo),e(N,yDo),e(N,pb),e(pb,Zhe),e(Zhe,xDo),e(pb,$Do),e(pb,PV),e(PV,kDo),e(pb,SDo),e(oo,RDo),e(oo,ub),e(ub,PDo),e(ub,epe),e(epe,BDo),e(ub,IDo),e(ub,ope),e(ope,NDo),e(oo,qDo),M(_b,oo,null),b(f,XGe,_),b(f,Zi,_),e(Zi,bb),e(bb,rpe),M(Ay,rpe,null),e(Zi,jDo),e(Zi,tpe),e(tpe,DDo),b(f,zGe,_),b(f,Bo,_),M(Ly,Bo,null),e(Bo,GDo),e(Bo,ed),e(ed,ODo),e(ed,BV),e(BV,VDo),e(ed,XDo),e(ed,IV),e(IV,zDo),e(ed,WDo),e(Bo,QDo),e(Bo,yy),e(yy,HDo),e(yy,ape),e(ape,UDo),e(yy,JDo),e(Bo,YDo),e(Bo,ft),M(xy,ft,null),e(ft,KDo),e(ft,npe),e(npe,ZDo),e(ft,eGo),e(ft,od),e(od,oGo),e(od,spe),e(spe,rGo),e(od,tGo),e(od,NV),e(NV,aGo),e(od,nGo),e(ft,sGo),M(vb,ft,null),e(Bo,lGo),e(Bo,ro),M($y,ro,null),e(ro,iGo),e(ro,lpe),e(lpe,dGo),e(ro,cGo),e(ro,qa),e(qa,fGo),e(qa,ipe),e(ipe,mGo),e(qa,gGo),e(qa,dpe),e(dpe,hGo),e(qa,pGo),e(qa,cpe),e(cpe,uGo),e(qa,_Go),e(ro,bGo),e(ro,Z),e(Z,Fb),e(Fb,fpe),e(fpe,vGo),e(Fb,FGo),e(Fb,qV),e(qV,TGo),e(Fb,MGo),e(Z,EGo),e(Z,Tb),e(Tb,mpe),e(mpe,CGo),e(Tb,wGo),e(Tb,jV),e(jV,AGo),e(Tb,LGo),e(Z,yGo),e(Z,Mb),e(Mb,gpe),e(gpe,xGo),e(Mb,$Go),e(Mb,DV),e(DV,kGo),e(Mb,SGo),e(Z,RGo),e(Z,Eb),e(Eb,hpe),e(hpe,PGo),e(Eb,BGo),e(Eb,GV),e(GV,IGo),e(Eb,NGo),e(Z,qGo),e(Z,Cb),e(Cb,ppe),e(ppe,jGo),e(Cb,DGo),e(Cb,OV),e(OV,GGo),e(Cb,OGo),e(Z,VGo),e(Z,wb),e(wb,upe),e(upe,XGo),e(wb,zGo),e(wb,VV),e(VV,WGo),e(wb,QGo),e(Z,HGo),e(Z,Ab),e(Ab,_pe),e(_pe,UGo),e(Ab,JGo),e(Ab,XV),e(XV,YGo),e(Ab,KGo),e(Z,ZGo),e(Z,Lb),e(Lb,bpe),e(bpe,eOo),e(Lb,oOo),e(Lb,zV),e(zV,rOo),e(Lb,tOo),e(Z,aOo),e(Z,yb),e(yb,vpe),e(vpe,nOo),e(yb,sOo),e(yb,WV),e(WV,lOo),e(yb,iOo),e(Z,dOo),e(Z,xb),e(xb,Fpe),e(Fpe,cOo),e(xb,fOo),e(xb,QV),e(QV,mOo),e(xb,gOo),e(Z,hOo),e(Z,$b),e($b,Tpe),e(Tpe,pOo),e($b,uOo),e($b,HV),e(HV,_Oo),e($b,bOo),e(Z,vOo),e(Z,kb),e(kb,Mpe),e(Mpe,FOo),e(kb,TOo),e(kb,UV),e(UV,MOo),e(kb,EOo),e(Z,COo),e(Z,Sb),e(Sb,Epe),e(Epe,wOo),e(Sb,AOo),e(Sb,JV),e(JV,LOo),e(Sb,yOo),e(Z,xOo),e(Z,Rb),e(Rb,Cpe),e(Cpe,$Oo),e(Rb,kOo),e(Rb,YV),e(YV,SOo),e(Rb,ROo),e(Z,POo),e(Z,Pb),e(Pb,wpe),e(wpe,BOo),e(Pb,IOo),e(Pb,KV),e(KV,NOo),e(Pb,qOo),e(Z,jOo),e(Z,Bb),e(Bb,Ape),e(Ape,DOo),e(Bb,GOo),e(Bb,ZV),e(ZV,OOo),e(Bb,VOo),e(Z,XOo),e(Z,Ib),e(Ib,Lpe),e(Lpe,zOo),e(Ib,WOo),e(Ib,eX),e(eX,QOo),e(Ib,HOo),e(Z,UOo),e(Z,Nb),e(Nb,ype),e(ype,JOo),e(Nb,YOo),e(Nb,oX),e(oX,KOo),e(Nb,ZOo),e(Z,eVo),e(Z,qb),e(qb,xpe),e(xpe,oVo),e(qb,rVo),e(qb,rX),e(rX,tVo),e(qb,aVo),e(Z,nVo),e(Z,jb),e(jb,$pe),e($pe,sVo),e(jb,lVo),e(jb,tX),e(tX,iVo),e(jb,dVo),e(Z,cVo),e(Z,Db),e(Db,kpe),e(kpe,fVo),e(Db,mVo),e(Db,aX),e(aX,gVo),e(Db,hVo),e(Z,pVo),e(Z,Gb),e(Gb,Spe),e(Spe,uVo),e(Gb,_Vo),e(Gb,nX),e(nX,bVo),e(Gb,vVo),e(Z,FVo),e(Z,Ob),e(Ob,Rpe),e(Rpe,TVo),e(Ob,MVo),e(Ob,sX),e(sX,EVo),e(Ob,CVo),e(Z,wVo),e(Z,Vb),e(Vb,Ppe),e(Ppe,AVo),e(Vb,LVo),e(Vb,lX),e(lX,yVo),e(Vb,xVo),e(Z,$Vo),e(Z,Xb),e(Xb,Bpe),e(Bpe,kVo),e(Xb,SVo),e(Xb,iX),e(iX,RVo),e(Xb,PVo),e(Z,BVo),e(Z,zb),e(zb,Ipe),e(Ipe,IVo),e(zb,NVo),e(zb,dX),e(dX,qVo),e(zb,jVo),e(Z,DVo),e(Z,Wb),e(Wb,Npe),e(Npe,GVo),e(Wb,OVo),e(Wb,cX),e(cX,VVo),e(Wb,XVo),e(Z,zVo),e(Z,Qb),e(Qb,qpe),e(qpe,WVo),e(Qb,QVo),e(Qb,fX),e(fX,HVo),e(Qb,UVo),e(Z,JVo),e(Z,Hb),e(Hb,jpe),e(jpe,YVo),e(Hb,KVo),e(Hb,mX),e(mX,ZVo),e(Hb,eXo),e(ro,oXo),e(ro,Ub),e(Ub,rXo),e(Ub,Dpe),e(Dpe,tXo),e(Ub,aXo),e(Ub,Gpe),e(Gpe,nXo),e(ro,sXo),M(Jb,ro,null),b(f,WGe,_),b(f,rd,_),e(rd,Yb),e(Yb,Ope),M(ky,Ope,null),e(rd,lXo),e(rd,Vpe),e(Vpe,iXo),b(f,QGe,_),b(f,Io,_),M(Sy,Io,null),e(Io,dXo),e(Io,td),e(td,cXo),e(td,gX),e(gX,fXo),e(td,mXo),e(td,hX),e(hX,gXo),e(td,hXo),e(Io,pXo),e(Io,Ry),e(Ry,uXo),e(Ry,Xpe),e(Xpe,_Xo),e(Ry,bXo),e(Io,vXo),e(Io,mt),M(Py,mt,null),e(mt,FXo),e(mt,zpe),e(zpe,TXo),e(mt,MXo),e(mt,ad),e(ad,EXo),e(ad,Wpe),e(Wpe,CXo),e(ad,wXo),e(ad,pX),e(pX,AXo),e(ad,LXo),e(mt,yXo),M(Kb,mt,null),e(Io,xXo),e(Io,to),M(By,to,null),e(to,$Xo),e(to,Qpe),e(Qpe,kXo),e(to,SXo),e(to,ja),e(ja,RXo),e(ja,Hpe),e(Hpe,PXo),e(ja,BXo),e(ja,Upe),e(Upe,IXo),e(ja,NXo),e(ja,Jpe),e(Jpe,qXo),e(ja,jXo),e(to,DXo),e(to,Zr),e(Zr,Zb),e(Zb,Ype),e(Ype,GXo),e(Zb,OXo),e(Zb,uX),e(uX,VXo),e(Zb,XXo),e(Zr,zXo),e(Zr,ev),e(ev,Kpe),e(Kpe,WXo),e(ev,QXo),e(ev,_X),e(_X,HXo),e(ev,UXo),e(Zr,JXo),e(Zr,ov),e(ov,Zpe),e(Zpe,YXo),e(ov,KXo),e(ov,bX),e(bX,ZXo),e(ov,ezo),e(Zr,ozo),e(Zr,rv),e(rv,eue),e(eue,rzo),e(rv,tzo),e(rv,vX),e(vX,azo),e(rv,nzo),e(Zr,szo),e(Zr,tv),e(tv,oue),e(oue,lzo),e(tv,izo),e(tv,FX),e(FX,dzo),e(tv,czo),e(to,fzo),e(to,av),e(av,mzo),e(av,rue),e(rue,gzo),e(av,hzo),e(av,tue),e(tue,pzo),e(to,uzo),M(nv,to,null),b(f,HGe,_),b(f,nd,_),e(nd,sv),e(sv,aue),M(Iy,aue,null),e(nd,_zo),e(nd,nue),e(nue,bzo),b(f,UGe,_),b(f,No,_),M(Ny,No,null),e(No,vzo),e(No,sd),e(sd,Fzo),e(sd,TX),e(TX,Tzo),e(sd,Mzo),e(sd,MX),e(MX,Ezo),e(sd,Czo),e(No,wzo),e(No,qy),e(qy,Azo),e(qy,sue),e(sue,Lzo),e(qy,yzo),e(No,xzo),e(No,gt),M(jy,gt,null),e(gt,$zo),e(gt,lue),e(lue,kzo),e(gt,Szo),e(gt,ld),e(ld,Rzo),e(ld,iue),e(iue,Pzo),e(ld,Bzo),e(ld,EX),e(EX,Izo),e(ld,Nzo),e(gt,qzo),M(lv,gt,null),e(No,jzo),e(No,ao),M(Dy,ao,null),e(ao,Dzo),e(ao,due),e(due,Gzo),e(ao,Ozo),e(ao,Da),e(Da,Vzo),e(Da,cue),e(cue,Xzo),e(Da,zzo),e(Da,fue),e(fue,Wzo),e(Da,Qzo),e(Da,mue),e(mue,Hzo),e(Da,Uzo),e(ao,Jzo),e(ao,H),e(H,iv),e(iv,gue),e(gue,Yzo),e(iv,Kzo),e(iv,CX),e(CX,Zzo),e(iv,eWo),e(H,oWo),e(H,dv),e(dv,hue),e(hue,rWo),e(dv,tWo),e(dv,wX),e(wX,aWo),e(dv,nWo),e(H,sWo),e(H,cv),e(cv,pue),e(pue,lWo),e(cv,iWo),e(cv,AX),e(AX,dWo),e(cv,cWo),e(H,fWo),e(H,fv),e(fv,uue),e(uue,mWo),e(fv,gWo),e(fv,LX),e(LX,hWo),e(fv,pWo),e(H,uWo),e(H,mv),e(mv,_ue),e(_ue,_Wo),e(mv,bWo),e(mv,yX),e(yX,vWo),e(mv,FWo),e(H,TWo),e(H,gv),e(gv,bue),e(bue,MWo),e(gv,EWo),e(gv,xX),e(xX,CWo),e(gv,wWo),e(H,AWo),e(H,hv),e(hv,vue),e(vue,LWo),e(hv,yWo),e(hv,$X),e($X,xWo),e(hv,$Wo),e(H,kWo),e(H,pv),e(pv,Fue),e(Fue,SWo),e(pv,RWo),e(pv,kX),e(kX,PWo),e(pv,BWo),e(H,IWo),e(H,uv),e(uv,Tue),e(Tue,NWo),e(uv,qWo),e(uv,SX),e(SX,jWo),e(uv,DWo),e(H,GWo),e(H,_v),e(_v,Mue),e(Mue,OWo),e(_v,VWo),e(_v,RX),e(RX,XWo),e(_v,zWo),e(H,WWo),e(H,bv),e(bv,Eue),e(Eue,QWo),e(bv,HWo),e(bv,PX),e(PX,UWo),e(bv,JWo),e(H,YWo),e(H,vv),e(vv,Cue),e(Cue,KWo),e(vv,ZWo),e(vv,BX),e(BX,eQo),e(vv,oQo),e(H,rQo),e(H,Fv),e(Fv,wue),e(wue,tQo),e(Fv,aQo),e(Fv,IX),e(IX,nQo),e(Fv,sQo),e(H,lQo),e(H,Tv),e(Tv,Aue),e(Aue,iQo),e(Tv,dQo),e(Tv,NX),e(NX,cQo),e(Tv,fQo),e(H,mQo),e(H,Mv),e(Mv,Lue),e(Lue,gQo),e(Mv,hQo),e(Mv,qX),e(qX,pQo),e(Mv,uQo),e(H,_Qo),e(H,Ev),e(Ev,yue),e(yue,bQo),e(Ev,vQo),e(Ev,jX),e(jX,FQo),e(Ev,TQo),e(H,MQo),e(H,Cv),e(Cv,xue),e(xue,EQo),e(Cv,CQo),e(Cv,DX),e(DX,wQo),e(Cv,AQo),e(H,LQo),e(H,wv),e(wv,$ue),e($ue,yQo),e(wv,xQo),e(wv,GX),e(GX,$Qo),e(wv,kQo),e(H,SQo),e(H,Av),e(Av,kue),e(kue,RQo),e(Av,PQo),e(Av,OX),e(OX,BQo),e(Av,IQo),e(H,NQo),e(H,Lv),e(Lv,Sue),e(Sue,qQo),e(Lv,jQo),e(Lv,VX),e(VX,DQo),e(Lv,GQo),e(H,OQo),e(H,yv),e(yv,Rue),e(Rue,VQo),e(yv,XQo),e(yv,XX),e(XX,zQo),e(yv,WQo),e(H,QQo),e(H,xv),e(xv,Pue),e(Pue,HQo),e(xv,UQo),e(xv,zX),e(zX,JQo),e(xv,YQo),e(H,KQo),e(H,$v),e($v,Bue),e(Bue,ZQo),e($v,eHo),e($v,WX),e(WX,oHo),e($v,rHo),e(H,tHo),e(H,kv),e(kv,Iue),e(Iue,aHo),e(kv,nHo),e(kv,QX),e(QX,sHo),e(kv,lHo),e(H,iHo),e(H,Sv),e(Sv,Nue),e(Nue,dHo),e(Sv,cHo),e(Sv,HX),e(HX,fHo),e(Sv,mHo),e(H,gHo),e(H,Rv),e(Rv,que),e(que,hHo),e(Rv,pHo),e(Rv,UX),e(UX,uHo),e(Rv,_Ho),e(H,bHo),e(H,Pv),e(Pv,jue),e(jue,vHo),e(Pv,FHo),e(Pv,JX),e(JX,THo),e(Pv,MHo),e(H,EHo),e(H,Bv),e(Bv,Due),e(Due,CHo),e(Bv,wHo),e(Bv,YX),e(YX,AHo),e(Bv,LHo),e(H,yHo),e(H,Iv),e(Iv,Gue),e(Gue,xHo),e(Iv,$Ho),e(Iv,KX),e(KX,kHo),e(Iv,SHo),e(H,RHo),e(H,Nv),e(Nv,Oue),e(Oue,PHo),e(Nv,BHo),e(Nv,ZX),e(ZX,IHo),e(Nv,NHo),e(H,qHo),e(H,qv),e(qv,Vue),e(Vue,jHo),e(qv,DHo),e(qv,ez),e(ez,GHo),e(qv,OHo),e(H,VHo),e(H,jv),e(jv,Xue),e(Xue,XHo),e(jv,zHo),e(jv,oz),e(oz,WHo),e(jv,QHo),e(H,HHo),e(H,Dv),e(Dv,zue),e(zue,UHo),e(Dv,JHo),e(Dv,rz),e(rz,YHo),e(Dv,KHo),e(H,ZHo),e(H,Gv),e(Gv,Wue),e(Wue,eUo),e(Gv,oUo),e(Gv,tz),e(tz,rUo),e(Gv,tUo),e(H,aUo),e(H,Ov),e(Ov,Que),e(Que,nUo),e(Ov,sUo),e(Ov,az),e(az,lUo),e(Ov,iUo),e(ao,dUo),e(ao,Vv),e(Vv,cUo),e(Vv,Hue),e(Hue,fUo),e(Vv,mUo),e(Vv,Uue),e(Uue,gUo),e(ao,hUo),M(Xv,ao,null),b(f,JGe,_),b(f,id,_),e(id,zv),e(zv,Jue),M(Gy,Jue,null),e(id,pUo),e(id,Yue),e(Yue,uUo),b(f,YGe,_),b(f,qo,_),M(Oy,qo,null),e(qo,_Uo),e(qo,dd),e(dd,bUo),e(dd,nz),e(nz,vUo),e(dd,FUo),e(dd,sz),e(sz,TUo),e(dd,MUo),e(qo,EUo),e(qo,Vy),e(Vy,CUo),e(Vy,Kue),e(Kue,wUo),e(Vy,AUo),e(qo,LUo),e(qo,ht),M(Xy,ht,null),e(ht,yUo),e(ht,Zue),e(Zue,xUo),e(ht,$Uo),e(ht,cd),e(cd,kUo),e(cd,e_e),e(e_e,SUo),e(cd,RUo),e(cd,lz),e(lz,PUo),e(cd,BUo),e(ht,IUo),M(Wv,ht,null),e(qo,NUo),e(qo,no),M(zy,no,null),e(no,qUo),e(no,o_e),e(o_e,jUo),e(no,DUo),e(no,Ga),e(Ga,GUo),e(Ga,r_e),e(r_e,OUo),e(Ga,VUo),e(Ga,t_e),e(t_e,XUo),e(Ga,zUo),e(Ga,a_e),e(a_e,WUo),e(Ga,QUo),e(no,HUo),e(no,V),e(V,Qv),e(Qv,n_e),e(n_e,UUo),e(Qv,JUo),e(Qv,iz),e(iz,YUo),e(Qv,KUo),e(V,ZUo),e(V,Hv),e(Hv,s_e),e(s_e,eJo),e(Hv,oJo),e(Hv,dz),e(dz,rJo),e(Hv,tJo),e(V,aJo),e(V,Uv),e(Uv,l_e),e(l_e,nJo),e(Uv,sJo),e(Uv,cz),e(cz,lJo),e(Uv,iJo),e(V,dJo),e(V,Jv),e(Jv,i_e),e(i_e,cJo),e(Jv,fJo),e(Jv,fz),e(fz,mJo),e(Jv,gJo),e(V,hJo),e(V,Yv),e(Yv,d_e),e(d_e,pJo),e(Yv,uJo),e(Yv,mz),e(mz,_Jo),e(Yv,bJo),e(V,vJo),e(V,Kv),e(Kv,c_e),e(c_e,FJo),e(Kv,TJo),e(Kv,gz),e(gz,MJo),e(Kv,EJo),e(V,CJo),e(V,Zv),e(Zv,f_e),e(f_e,wJo),e(Zv,AJo),e(Zv,hz),e(hz,LJo),e(Zv,yJo),e(V,xJo),e(V,eF),e(eF,m_e),e(m_e,$Jo),e(eF,kJo),e(eF,pz),e(pz,SJo),e(eF,RJo),e(V,PJo),e(V,oF),e(oF,g_e),e(g_e,BJo),e(oF,IJo),e(oF,uz),e(uz,NJo),e(oF,qJo),e(V,jJo),e(V,rF),e(rF,h_e),e(h_e,DJo),e(rF,GJo),e(rF,_z),e(_z,OJo),e(rF,VJo),e(V,XJo),e(V,tF),e(tF,p_e),e(p_e,zJo),e(tF,WJo),e(tF,bz),e(bz,QJo),e(tF,HJo),e(V,UJo),e(V,aF),e(aF,u_e),e(u_e,JJo),e(aF,YJo),e(aF,vz),e(vz,KJo),e(aF,ZJo),e(V,eYo),e(V,nF),e(nF,__e),e(__e,oYo),e(nF,rYo),e(nF,Fz),e(Fz,tYo),e(nF,aYo),e(V,nYo),e(V,sF),e(sF,b_e),e(b_e,sYo),e(sF,lYo),e(sF,Tz),e(Tz,iYo),e(sF,dYo),e(V,cYo),e(V,lF),e(lF,v_e),e(v_e,fYo),e(lF,mYo),e(lF,Mz),e(Mz,gYo),e(lF,hYo),e(V,pYo),e(V,iF),e(iF,F_e),e(F_e,uYo),e(iF,_Yo),e(iF,Ez),e(Ez,bYo),e(iF,vYo),e(V,FYo),e(V,dF),e(dF,T_e),e(T_e,TYo),e(dF,MYo),e(dF,Cz),e(Cz,EYo),e(dF,CYo),e(V,wYo),e(V,cF),e(cF,M_e),e(M_e,AYo),e(cF,LYo),e(cF,wz),e(wz,yYo),e(cF,xYo),e(V,$Yo),e(V,fF),e(fF,E_e),e(E_e,kYo),e(fF,SYo),e(fF,Az),e(Az,RYo),e(fF,PYo),e(V,BYo),e(V,mF),e(mF,C_e),e(C_e,IYo),e(mF,NYo),e(mF,Lz),e(Lz,qYo),e(mF,jYo),e(V,DYo),e(V,gF),e(gF,w_e),e(w_e,GYo),e(gF,OYo),e(gF,yz),e(yz,VYo),e(gF,XYo),e(V,zYo),e(V,hF),e(hF,A_e),e(A_e,WYo),e(hF,QYo),e(hF,xz),e(xz,HYo),e(hF,UYo),e(V,JYo),e(V,pF),e(pF,L_e),e(L_e,YYo),e(pF,KYo),e(pF,$z),e($z,ZYo),e(pF,eKo),e(V,oKo),e(V,uF),e(uF,y_e),e(y_e,rKo),e(uF,tKo),e(uF,kz),e(kz,aKo),e(uF,nKo),e(V,sKo),e(V,_F),e(_F,x_e),e(x_e,lKo),e(_F,iKo),e(_F,Sz),e(Sz,dKo),e(_F,cKo),e(V,fKo),e(V,bF),e(bF,$_e),e($_e,mKo),e(bF,gKo),e(bF,Rz),e(Rz,hKo),e(bF,pKo),e(V,uKo),e(V,vF),e(vF,k_e),e(k_e,_Ko),e(vF,bKo),e(vF,Pz),e(Pz,vKo),e(vF,FKo),e(V,TKo),e(V,FF),e(FF,S_e),e(S_e,MKo),e(FF,EKo),e(FF,Bz),e(Bz,CKo),e(FF,wKo),e(V,AKo),e(V,TF),e(TF,R_e),e(R_e,LKo),e(TF,yKo),e(TF,Iz),e(Iz,xKo),e(TF,$Ko),e(V,kKo),e(V,MF),e(MF,P_e),e(P_e,SKo),e(MF,RKo),e(MF,Nz),e(Nz,PKo),e(MF,BKo),e(V,IKo),e(V,EF),e(EF,B_e),e(B_e,NKo),e(EF,qKo),e(EF,qz),e(qz,jKo),e(EF,DKo),e(V,GKo),e(V,CF),e(CF,I_e),e(I_e,OKo),e(CF,VKo),e(CF,jz),e(jz,XKo),e(CF,zKo),e(V,WKo),e(V,wF),e(wF,N_e),e(N_e,QKo),e(wF,HKo),e(wF,Dz),e(Dz,UKo),e(wF,JKo),e(V,YKo),e(V,AF),e(AF,q_e),e(q_e,KKo),e(AF,ZKo),e(AF,Gz),e(Gz,eZo),e(AF,oZo),e(V,rZo),e(V,LF),e(LF,j_e),e(j_e,tZo),e(LF,aZo),e(LF,Oz),e(Oz,nZo),e(LF,sZo),e(V,lZo),e(V,yF),e(yF,D_e),e(D_e,iZo),e(yF,dZo),e(yF,Vz),e(Vz,cZo),e(yF,fZo),e(V,mZo),e(V,xF),e(xF,G_e),e(G_e,gZo),e(xF,hZo),e(xF,Xz),e(Xz,pZo),e(xF,uZo),e(V,_Zo),e(V,$F),e($F,O_e),e(O_e,bZo),e($F,vZo),e($F,zz),e(zz,FZo),e($F,TZo),e(V,MZo),e(V,kF),e(kF,V_e),e(V_e,EZo),e(kF,CZo),e(kF,Wz),e(Wz,wZo),e(kF,AZo),e(V,LZo),e(V,SF),e(SF,X_e),e(X_e,yZo),e(SF,xZo),e(SF,Qz),e(Qz,$Zo),e(SF,kZo),e(no,SZo),e(no,RF),e(RF,RZo),e(RF,z_e),e(z_e,PZo),e(RF,BZo),e(RF,W_e),e(W_e,IZo),e(no,NZo),M(PF,no,null),b(f,KGe,_),b(f,fd,_),e(fd,BF),e(BF,Q_e),M(Wy,Q_e,null),e(fd,qZo),e(fd,H_e),e(H_e,jZo),b(f,ZGe,_),b(f,jo,_),M(Qy,jo,null),e(jo,DZo),e(jo,md),e(md,GZo),e(md,Hz),e(Hz,OZo),e(md,VZo),e(md,Uz),e(Uz,XZo),e(md,zZo),e(jo,WZo),e(jo,Hy),e(Hy,QZo),e(Hy,U_e),e(U_e,HZo),e(Hy,UZo),e(jo,JZo),e(jo,pt),M(Uy,pt,null),e(pt,YZo),e(pt,J_e),e(J_e,KZo),e(pt,ZZo),e(pt,gd),e(gd,eer),e(gd,Y_e),e(Y_e,oer),e(gd,rer),e(gd,Jz),e(Jz,ter),e(gd,aer),e(pt,ner),M(IF,pt,null),e(jo,ser),e(jo,so),M(Jy,so,null),e(so,ler),e(so,K_e),e(K_e,ier),e(so,der),e(so,Oa),e(Oa,cer),e(Oa,Z_e),e(Z_e,fer),e(Oa,mer),e(Oa,e1e),e(e1e,ger),e(Oa,her),e(Oa,o1e),e(o1e,per),e(Oa,uer),e(so,_er),e(so,r1e),e(r1e,NF),e(NF,t1e),e(t1e,ber),e(NF,ver),e(NF,Yz),e(Yz,Fer),e(NF,Ter),e(so,Mer),e(so,qF),e(qF,Eer),e(qF,a1e),e(a1e,Cer),e(qF,wer),e(qF,n1e),e(n1e,Aer),e(so,Ler),M(jF,so,null),b(f,eOe,_),b(f,hd,_),e(hd,DF),e(DF,s1e),M(Yy,s1e,null),e(hd,yer),e(hd,l1e),e(l1e,xer),b(f,oOe,_),b(f,Do,_),M(Ky,Do,null),e(Do,$er),e(Do,pd),e(pd,ker),e(pd,Kz),e(Kz,Ser),e(pd,Rer),e(pd,Zz),e(Zz,Per),e(pd,Ber),e(Do,Ier),e(Do,Zy),e(Zy,Ner),e(Zy,i1e),e(i1e,qer),e(Zy,jer),e(Do,Der),e(Do,ut),M(e8,ut,null),e(ut,Ger),e(ut,d1e),e(d1e,Oer),e(ut,Ver),e(ut,ud),e(ud,Xer),e(ud,c1e),e(c1e,zer),e(ud,Wer),e(ud,eW),e(eW,Qer),e(ud,Her),e(ut,Uer),M(GF,ut,null),e(Do,Jer),e(Do,lo),M(o8,lo,null),e(lo,Yer),e(lo,f1e),e(f1e,Ker),e(lo,Zer),e(lo,Va),e(Va,eor),e(Va,m1e),e(m1e,oor),e(Va,ror),e(Va,g1e),e(g1e,tor),e(Va,aor),e(Va,h1e),e(h1e,nor),e(Va,sor),e(lo,lor),e(lo,Fe),e(Fe,OF),e(OF,p1e),e(p1e,ior),e(OF,dor),e(OF,oW),e(oW,cor),e(OF,mor),e(Fe,gor),e(Fe,VF),e(VF,u1e),e(u1e,hor),e(VF,por),e(VF,rW),e(rW,uor),e(VF,_or),e(Fe,bor),e(Fe,XF),e(XF,_1e),e(_1e,vor),e(XF,For),e(XF,tW),e(tW,Tor),e(XF,Mor),e(Fe,Eor),e(Fe,zF),e(zF,b1e),e(b1e,Cor),e(zF,wor),e(zF,aW),e(aW,Aor),e(zF,Lor),e(Fe,yor),e(Fe,Vs),e(Vs,v1e),e(v1e,xor),e(Vs,$or),e(Vs,nW),e(nW,kor),e(Vs,Sor),e(Vs,sW),e(sW,Ror),e(Vs,Por),e(Fe,Bor),e(Fe,WF),e(WF,F1e),e(F1e,Ior),e(WF,Nor),e(WF,lW),e(lW,qor),e(WF,jor),e(Fe,Dor),e(Fe,Xs),e(Xs,T1e),e(T1e,Gor),e(Xs,Oor),e(Xs,iW),e(iW,Vor),e(Xs,Xor),e(Xs,dW),e(dW,zor),e(Xs,Wor),e(Fe,Qor),e(Fe,_t),e(_t,M1e),e(M1e,Hor),e(_t,Uor),e(_t,cW),e(cW,Jor),e(_t,Yor),e(_t,fW),e(fW,Kor),e(_t,Zor),e(_t,mW),e(mW,err),e(_t,orr),e(Fe,rrr),e(Fe,QF),e(QF,E1e),e(E1e,trr),e(QF,arr),e(QF,gW),e(gW,nrr),e(QF,srr),e(Fe,lrr),e(Fe,HF),e(HF,C1e),e(C1e,irr),e(HF,drr),e(HF,hW),e(hW,crr),e(HF,frr),e(Fe,mrr),e(Fe,UF),e(UF,w1e),e(w1e,grr),e(UF,hrr),e(UF,pW),e(pW,prr),e(UF,urr),e(Fe,_rr),e(Fe,JF),e(JF,A1e),e(A1e,brr),e(JF,vrr),e(JF,uW),e(uW,Frr),e(JF,Trr),e(Fe,Mrr),e(Fe,YF),e(YF,L1e),e(L1e,Err),e(YF,Crr),e(YF,_W),e(_W,wrr),e(YF,Arr),e(Fe,Lrr),e(Fe,KF),e(KF,y1e),e(y1e,yrr),e(KF,xrr),e(KF,bW),e(bW,$rr),e(KF,krr),e(Fe,Srr),e(Fe,ZF),e(ZF,x1e),e(x1e,Rrr),e(ZF,Prr),e(ZF,vW),e(vW,Brr),e(ZF,Irr),e(lo,Nrr),e(lo,eT),e(eT,qrr),e(eT,$1e),e($1e,jrr),e(eT,Drr),e(eT,k1e),e(k1e,Grr),e(lo,Orr),M(oT,lo,null),b(f,rOe,_),b(f,_d,_),e(_d,rT),e(rT,S1e),M(r8,S1e,null),e(_d,Vrr),e(_d,R1e),e(R1e,Xrr),b(f,tOe,_),b(f,Go,_),M(t8,Go,null),e(Go,zrr),e(Go,bd),e(bd,Wrr),e(bd,FW),e(FW,Qrr),e(bd,Hrr),e(bd,TW),e(TW,Urr),e(bd,Jrr),e(Go,Yrr),e(Go,a8),e(a8,Krr),e(a8,P1e),e(P1e,Zrr),e(a8,etr),e(Go,otr),e(Go,bt),M(n8,bt,null),e(bt,rtr),e(bt,B1e),e(B1e,ttr),e(bt,atr),e(bt,vd),e(vd,ntr),e(vd,I1e),e(I1e,str),e(vd,ltr),e(vd,MW),e(MW,itr),e(vd,dtr),e(bt,ctr),M(tT,bt,null),e(Go,ftr),e(Go,io),M(s8,io,null),e(io,mtr),e(io,N1e),e(N1e,gtr),e(io,htr),e(io,Xa),e(Xa,ptr),e(Xa,q1e),e(q1e,utr),e(Xa,_tr),e(Xa,j1e),e(j1e,btr),e(Xa,vtr),e(Xa,D1e),e(D1e,Ftr),e(Xa,Ttr),e(io,Mtr),e(io,G1e),e(G1e,aT),e(aT,O1e),e(O1e,Etr),e(aT,Ctr),e(aT,EW),e(EW,wtr),e(aT,Atr),e(io,Ltr),e(io,nT),e(nT,ytr),e(nT,V1e),e(V1e,xtr),e(nT,$tr),e(nT,X1e),e(X1e,ktr),e(io,Str),M(sT,io,null),b(f,aOe,_),b(f,Fd,_),e(Fd,lT),e(lT,z1e),M(l8,z1e,null),e(Fd,Rtr),e(Fd,W1e),e(W1e,Ptr),b(f,nOe,_),b(f,Oo,_),M(i8,Oo,null),e(Oo,Btr),e(Oo,Td),e(Td,Itr),e(Td,CW),e(CW,Ntr),e(Td,qtr),e(Td,wW),e(wW,jtr),e(Td,Dtr),e(Oo,Gtr),e(Oo,d8),e(d8,Otr),e(d8,Q1e),e(Q1e,Vtr),e(d8,Xtr),e(Oo,ztr),e(Oo,vt),M(c8,vt,null),e(vt,Wtr),e(vt,H1e),e(H1e,Qtr),e(vt,Htr),e(vt,Md),e(Md,Utr),e(Md,U1e),e(U1e,Jtr),e(Md,Ytr),e(Md,AW),e(AW,Ktr),e(Md,Ztr),e(vt,ear),M(iT,vt,null),e(Oo,oar),e(Oo,co),M(f8,co,null),e(co,rar),e(co,J1e),e(J1e,tar),e(co,aar),e(co,za),e(za,nar),e(za,Y1e),e(Y1e,sar),e(za,lar),e(za,K1e),e(K1e,iar),e(za,dar),e(za,Z1e),e(Z1e,car),e(za,far),e(co,mar),e(co,e3e),e(e3e,dT),e(dT,o3e),e(o3e,gar),e(dT,har),e(dT,LW),e(LW,par),e(dT,uar),e(co,_ar),e(co,cT),e(cT,bar),e(cT,r3e),e(r3e,Far),e(cT,Tar),e(cT,t3e),e(t3e,Mar),e(co,Ear),M(fT,co,null),b(f,sOe,_),b(f,Ed,_),e(Ed,mT),e(mT,a3e),M(m8,a3e,null),e(Ed,Car),e(Ed,n3e),e(n3e,war),b(f,lOe,_),b(f,Vo,_),M(g8,Vo,null),e(Vo,Aar),e(Vo,Cd),e(Cd,Lar),e(Cd,yW),e(yW,yar),e(Cd,xar),e(Cd,xW),e(xW,$ar),e(Cd,kar),e(Vo,Sar),e(Vo,h8),e(h8,Rar),e(h8,s3e),e(s3e,Par),e(h8,Bar),e(Vo,Iar),e(Vo,Ft),M(p8,Ft,null),e(Ft,Nar),e(Ft,l3e),e(l3e,qar),e(Ft,jar),e(Ft,wd),e(wd,Dar),e(wd,i3e),e(i3e,Gar),e(wd,Oar),e(wd,$W),e($W,Var),e(wd,Xar),e(Ft,zar),M(gT,Ft,null),e(Vo,War),e(Vo,fo),M(u8,fo,null),e(fo,Qar),e(fo,d3e),e(d3e,Har),e(fo,Uar),e(fo,Wa),e(Wa,Jar),e(Wa,c3e),e(c3e,Yar),e(Wa,Kar),e(Wa,f3e),e(f3e,Zar),e(Wa,enr),e(Wa,m3e),e(m3e,onr),e(Wa,rnr),e(fo,tnr),e(fo,Pe),e(Pe,hT),e(hT,g3e),e(g3e,anr),e(hT,nnr),e(hT,kW),e(kW,snr),e(hT,lnr),e(Pe,inr),e(Pe,pT),e(pT,h3e),e(h3e,dnr),e(pT,cnr),e(pT,SW),e(SW,fnr),e(pT,mnr),e(Pe,gnr),e(Pe,uT),e(uT,p3e),e(p3e,hnr),e(uT,pnr),e(uT,RW),e(RW,unr),e(uT,_nr),e(Pe,bnr),e(Pe,_T),e(_T,u3e),e(u3e,vnr),e(_T,Fnr),e(_T,PW),e(PW,Tnr),e(_T,Mnr),e(Pe,Enr),e(Pe,bT),e(bT,_3e),e(_3e,Cnr),e(bT,wnr),e(bT,BW),e(BW,Anr),e(bT,Lnr),e(Pe,ynr),e(Pe,vT),e(vT,b3e),e(b3e,xnr),e(vT,$nr),e(vT,IW),e(IW,knr),e(vT,Snr),e(Pe,Rnr),e(Pe,FT),e(FT,v3e),e(v3e,Pnr),e(FT,Bnr),e(FT,NW),e(NW,Inr),e(FT,Nnr),e(Pe,qnr),e(Pe,TT),e(TT,F3e),e(F3e,jnr),e(TT,Dnr),e(TT,qW),e(qW,Gnr),e(TT,Onr),e(Pe,Vnr),e(Pe,MT),e(MT,T3e),e(T3e,Xnr),e(MT,znr),e(MT,jW),e(jW,Wnr),e(MT,Qnr),e(fo,Hnr),e(fo,ET),e(ET,Unr),e(ET,M3e),e(M3e,Jnr),e(ET,Ynr),e(ET,E3e),e(E3e,Knr),e(fo,Znr),M(CT,fo,null),b(f,iOe,_),b(f,Ad,_),e(Ad,wT),e(wT,C3e),M(_8,C3e,null),e(Ad,esr),e(Ad,w3e),e(w3e,osr),b(f,dOe,_),b(f,Xo,_),M(b8,Xo,null),e(Xo,rsr),e(Xo,Ld),e(Ld,tsr),e(Ld,DW),e(DW,asr),e(Ld,nsr),e(Ld,GW),e(GW,ssr),e(Ld,lsr),e(Xo,isr),e(Xo,v8),e(v8,dsr),e(v8,A3e),e(A3e,csr),e(v8,fsr),e(Xo,msr),e(Xo,Tt),M(F8,Tt,null),e(Tt,gsr),e(Tt,L3e),e(L3e,hsr),e(Tt,psr),e(Tt,yd),e(yd,usr),e(yd,y3e),e(y3e,_sr),e(yd,bsr),e(yd,OW),e(OW,vsr),e(yd,Fsr),e(Tt,Tsr),M(AT,Tt,null),e(Xo,Msr),e(Xo,mo),M(T8,mo,null),e(mo,Esr),e(mo,x3e),e(x3e,Csr),e(mo,wsr),e(mo,Qa),e(Qa,Asr),e(Qa,$3e),e($3e,Lsr),e(Qa,ysr),e(Qa,k3e),e(k3e,xsr),e(Qa,$sr),e(Qa,S3e),e(S3e,ksr),e(Qa,Ssr),e(mo,Rsr),e(mo,et),e(et,LT),e(LT,R3e),e(R3e,Psr),e(LT,Bsr),e(LT,VW),e(VW,Isr),e(LT,Nsr),e(et,qsr),e(et,yT),e(yT,P3e),e(P3e,jsr),e(yT,Dsr),e(yT,XW),e(XW,Gsr),e(yT,Osr),e(et,Vsr),e(et,xT),e(xT,B3e),e(B3e,Xsr),e(xT,zsr),e(xT,zW),e(zW,Wsr),e(xT,Qsr),e(et,Hsr),e(et,$T),e($T,I3e),e(I3e,Usr),e($T,Jsr),e($T,WW),e(WW,Ysr),e($T,Ksr),e(et,Zsr),e(et,kT),e(kT,N3e),e(N3e,elr),e(kT,olr),e(kT,QW),e(QW,rlr),e(kT,tlr),e(mo,alr),e(mo,ST),e(ST,nlr),e(ST,q3e),e(q3e,slr),e(ST,llr),e(ST,j3e),e(j3e,ilr),e(mo,dlr),M(RT,mo,null),b(f,cOe,_),b(f,xd,_),e(xd,PT),e(PT,D3e),M(M8,D3e,null),e(xd,clr),e(xd,G3e),e(G3e,flr),b(f,fOe,_),b(f,zo,_),M(E8,zo,null),e(zo,mlr),e(zo,$d),e($d,glr),e($d,HW),e(HW,hlr),e($d,plr),e($d,UW),e(UW,ulr),e($d,_lr),e(zo,blr),e(zo,C8),e(C8,vlr),e(C8,O3e),e(O3e,Flr),e(C8,Tlr),e(zo,Mlr),e(zo,Mt),M(w8,Mt,null),e(Mt,Elr),e(Mt,V3e),e(V3e,Clr),e(Mt,wlr),e(Mt,kd),e(kd,Alr),e(kd,X3e),e(X3e,Llr),e(kd,ylr),e(kd,JW),e(JW,xlr),e(kd,$lr),e(Mt,klr),M(BT,Mt,null),e(zo,Slr),e(zo,go),M(A8,go,null),e(go,Rlr),e(go,z3e),e(z3e,Plr),e(go,Blr),e(go,Ha),e(Ha,Ilr),e(Ha,W3e),e(W3e,Nlr),e(Ha,qlr),e(Ha,Q3e),e(Q3e,jlr),e(Ha,Dlr),e(Ha,H3e),e(H3e,Glr),e(Ha,Olr),e(go,Vlr),e(go,Le),e(Le,IT),e(IT,U3e),e(U3e,Xlr),e(IT,zlr),e(IT,YW),e(YW,Wlr),e(IT,Qlr),e(Le,Hlr),e(Le,NT),e(NT,J3e),e(J3e,Ulr),e(NT,Jlr),e(NT,KW),e(KW,Ylr),e(NT,Klr),e(Le,Zlr),e(Le,qT),e(qT,Y3e),e(Y3e,eir),e(qT,oir),e(qT,ZW),e(ZW,rir),e(qT,tir),e(Le,air),e(Le,jT),e(jT,K3e),e(K3e,nir),e(jT,sir),e(jT,eQ),e(eQ,lir),e(jT,iir),e(Le,dir),e(Le,DT),e(DT,Z3e),e(Z3e,cir),e(DT,fir),e(DT,oQ),e(oQ,mir),e(DT,gir),e(Le,hir),e(Le,GT),e(GT,e2e),e(e2e,pir),e(GT,uir),e(GT,rQ),e(rQ,_ir),e(GT,bir),e(Le,vir),e(Le,OT),e(OT,o2e),e(o2e,Fir),e(OT,Tir),e(OT,tQ),e(tQ,Mir),e(OT,Eir),e(Le,Cir),e(Le,VT),e(VT,r2e),e(r2e,wir),e(VT,Air),e(VT,aQ),e(aQ,Lir),e(VT,yir),e(Le,xir),e(Le,XT),e(XT,t2e),e(t2e,$ir),e(XT,kir),e(XT,nQ),e(nQ,Sir),e(XT,Rir),e(Le,Pir),e(Le,zT),e(zT,a2e),e(a2e,Bir),e(zT,Iir),e(zT,sQ),e(sQ,Nir),e(zT,qir),e(go,jir),e(go,WT),e(WT,Dir),e(WT,n2e),e(n2e,Gir),e(WT,Oir),e(WT,s2e),e(s2e,Vir),e(go,Xir),M(QT,go,null),b(f,mOe,_),b(f,Sd,_),e(Sd,HT),e(HT,l2e),M(L8,l2e,null),e(Sd,zir),e(Sd,i2e),e(i2e,Wir),b(f,gOe,_),b(f,Wo,_),M(y8,Wo,null),e(Wo,Qir),e(Wo,Rd),e(Rd,Hir),e(Rd,lQ),e(lQ,Uir),e(Rd,Jir),e(Rd,iQ),e(iQ,Yir),e(Rd,Kir),e(Wo,Zir),e(Wo,x8),e(x8,edr),e(x8,d2e),e(d2e,odr),e(x8,rdr),e(Wo,tdr),e(Wo,Et),M($8,Et,null),e(Et,adr),e(Et,c2e),e(c2e,ndr),e(Et,sdr),e(Et,Pd),e(Pd,ldr),e(Pd,f2e),e(f2e,idr),e(Pd,ddr),e(Pd,dQ),e(dQ,cdr),e(Pd,fdr),e(Et,mdr),M(UT,Et,null),e(Wo,gdr),e(Wo,ho),M(k8,ho,null),e(ho,hdr),e(ho,m2e),e(m2e,pdr),e(ho,udr),e(ho,Ua),e(Ua,_dr),e(Ua,g2e),e(g2e,bdr),e(Ua,vdr),e(Ua,h2e),e(h2e,Fdr),e(Ua,Tdr),e(Ua,p2e),e(p2e,Mdr),e(Ua,Edr),e(ho,Cdr),e(ho,S8),e(S8,JT),e(JT,u2e),e(u2e,wdr),e(JT,Adr),e(JT,cQ),e(cQ,Ldr),e(JT,ydr),e(S8,xdr),e(S8,YT),e(YT,_2e),e(_2e,$dr),e(YT,kdr),e(YT,fQ),e(fQ,Sdr),e(YT,Rdr),e(ho,Pdr),e(ho,KT),e(KT,Bdr),e(KT,b2e),e(b2e,Idr),e(KT,Ndr),e(KT,v2e),e(v2e,qdr),e(ho,jdr),M(ZT,ho,null),b(f,hOe,_),b(f,Bd,_),e(Bd,e7),e(e7,F2e),M(R8,F2e,null),e(Bd,Ddr),e(Bd,T2e),e(T2e,Gdr),b(f,pOe,_),b(f,Qo,_),M(P8,Qo,null),e(Qo,Odr),e(Qo,Id),e(Id,Vdr),e(Id,mQ),e(mQ,Xdr),e(Id,zdr),e(Id,gQ),e(gQ,Wdr),e(Id,Qdr),e(Qo,Hdr),e(Qo,B8),e(B8,Udr),e(B8,M2e),e(M2e,Jdr),e(B8,Ydr),e(Qo,Kdr),e(Qo,Ct),M(I8,Ct,null),e(Ct,Zdr),e(Ct,E2e),e(E2e,ecr),e(Ct,ocr),e(Ct,Nd),e(Nd,rcr),e(Nd,C2e),e(C2e,tcr),e(Nd,acr),e(Nd,hQ),e(hQ,ncr),e(Nd,scr),e(Ct,lcr),M(o7,Ct,null),e(Qo,icr),e(Qo,po),M(N8,po,null),e(po,dcr),e(po,w2e),e(w2e,ccr),e(po,fcr),e(po,Ja),e(Ja,mcr),e(Ja,A2e),e(A2e,gcr),e(Ja,hcr),e(Ja,L2e),e(L2e,pcr),e(Ja,ucr),e(Ja,y2e),e(y2e,_cr),e(Ja,bcr),e(po,vcr),e(po,ot),e(ot,r7),e(r7,x2e),e(x2e,Fcr),e(r7,Tcr),e(r7,pQ),e(pQ,Mcr),e(r7,Ecr),e(ot,Ccr),e(ot,t7),e(t7,$2e),e($2e,wcr),e(t7,Acr),e(t7,uQ),e(uQ,Lcr),e(t7,ycr),e(ot,xcr),e(ot,a7),e(a7,k2e),e(k2e,$cr),e(a7,kcr),e(a7,_Q),e(_Q,Scr),e(a7,Rcr),e(ot,Pcr),e(ot,n7),e(n7,S2e),e(S2e,Bcr),e(n7,Icr),e(n7,bQ),e(bQ,Ncr),e(n7,qcr),e(ot,jcr),e(ot,s7),e(s7,R2e),e(R2e,Dcr),e(s7,Gcr),e(s7,vQ),e(vQ,Ocr),e(s7,Vcr),e(po,Xcr),e(po,l7),e(l7,zcr),e(l7,P2e),e(P2e,Wcr),e(l7,Qcr),e(l7,B2e),e(B2e,Hcr),e(po,Ucr),M(i7,po,null),b(f,uOe,_),b(f,qd,_),e(qd,d7),e(d7,I2e),M(q8,I2e,null),e(qd,Jcr),e(qd,N2e),e(N2e,Ycr),b(f,_Oe,_),b(f,Ho,_),M(j8,Ho,null),e(Ho,Kcr),e(Ho,jd),e(jd,Zcr),e(jd,FQ),e(FQ,efr),e(jd,ofr),e(jd,TQ),e(TQ,rfr),e(jd,tfr),e(Ho,afr),e(Ho,D8),e(D8,nfr),e(D8,q2e),e(q2e,sfr),e(D8,lfr),e(Ho,ifr),e(Ho,wt),M(G8,wt,null),e(wt,dfr),e(wt,j2e),e(j2e,cfr),e(wt,ffr),e(wt,Dd),e(Dd,mfr),e(Dd,D2e),e(D2e,gfr),e(Dd,hfr),e(Dd,MQ),e(MQ,pfr),e(Dd,ufr),e(wt,_fr),M(c7,wt,null),e(Ho,bfr),e(Ho,uo),M(O8,uo,null),e(uo,vfr),e(uo,G2e),e(G2e,Ffr),e(uo,Tfr),e(uo,Ya),e(Ya,Mfr),e(Ya,O2e),e(O2e,Efr),e(Ya,Cfr),e(Ya,V2e),e(V2e,wfr),e(Ya,Afr),e(Ya,X2e),e(X2e,Lfr),e(Ya,yfr),e(uo,xfr),e(uo,Gd),e(Gd,f7),e(f7,z2e),e(z2e,$fr),e(f7,kfr),e(f7,EQ),e(EQ,Sfr),e(f7,Rfr),e(Gd,Pfr),e(Gd,m7),e(m7,W2e),e(W2e,Bfr),e(m7,Ifr),e(m7,CQ),e(CQ,Nfr),e(m7,qfr),e(Gd,jfr),e(Gd,g7),e(g7,Q2e),e(Q2e,Dfr),e(g7,Gfr),e(g7,wQ),e(wQ,Ofr),e(g7,Vfr),e(uo,Xfr),e(uo,h7),e(h7,zfr),e(h7,H2e),e(H2e,Wfr),e(h7,Qfr),e(h7,U2e),e(U2e,Hfr),e(uo,Ufr),M(p7,uo,null),b(f,bOe,_),b(f,Od,_),e(Od,u7),e(u7,J2e),M(V8,J2e,null),e(Od,Jfr),e(Od,Y2e),e(Y2e,Yfr),b(f,vOe,_),b(f,Uo,_),M(X8,Uo,null),e(Uo,Kfr),e(Uo,Vd),e(Vd,Zfr),e(Vd,AQ),e(AQ,emr),e(Vd,omr),e(Vd,LQ),e(LQ,rmr),e(Vd,tmr),e(Uo,amr),e(Uo,z8),e(z8,nmr),e(z8,K2e),e(K2e,smr),e(z8,lmr),e(Uo,imr),e(Uo,At),M(W8,At,null),e(At,dmr),e(At,Z2e),e(Z2e,cmr),e(At,fmr),e(At,Xd),e(Xd,mmr),e(Xd,ebe),e(ebe,gmr),e(Xd,hmr),e(Xd,yQ),e(yQ,pmr),e(Xd,umr),e(At,_mr),M(_7,At,null),e(Uo,bmr),e(Uo,_o),M(Q8,_o,null),e(_o,vmr),e(_o,obe),e(obe,Fmr),e(_o,Tmr),e(_o,Ka),e(Ka,Mmr),e(Ka,rbe),e(rbe,Emr),e(Ka,Cmr),e(Ka,tbe),e(tbe,wmr),e(Ka,Amr),e(Ka,abe),e(abe,Lmr),e(Ka,ymr),e(_o,xmr),e(_o,H8),e(H8,b7),e(b7,nbe),e(nbe,$mr),e(b7,kmr),e(b7,xQ),e(xQ,Smr),e(b7,Rmr),e(H8,Pmr),e(H8,v7),e(v7,sbe),e(sbe,Bmr),e(v7,Imr),e(v7,$Q),e($Q,Nmr),e(v7,qmr),e(_o,jmr),e(_o,F7),e(F7,Dmr),e(F7,lbe),e(lbe,Gmr),e(F7,Omr),e(F7,ibe),e(ibe,Vmr),e(_o,Xmr),M(T7,_o,null),b(f,FOe,_),b(f,zd,_),e(zd,M7),e(M7,dbe),M(U8,dbe,null),e(zd,zmr),e(zd,cbe),e(cbe,Wmr),b(f,TOe,_),b(f,Jo,_),M(J8,Jo,null),e(Jo,Qmr),e(Jo,Wd),e(Wd,Hmr),e(Wd,kQ),e(kQ,Umr),e(Wd,Jmr),e(Wd,SQ),e(SQ,Ymr),e(Wd,Kmr),e(Jo,Zmr),e(Jo,Y8),e(Y8,egr),e(Y8,fbe),e(fbe,ogr),e(Y8,rgr),e(Jo,tgr),e(Jo,Lt),M(K8,Lt,null),e(Lt,agr),e(Lt,mbe),e(mbe,ngr),e(Lt,sgr),e(Lt,Qd),e(Qd,lgr),e(Qd,gbe),e(gbe,igr),e(Qd,dgr),e(Qd,RQ),e(RQ,cgr),e(Qd,fgr),e(Lt,mgr),M(E7,Lt,null),e(Jo,ggr),e(Jo,bo),M(Z8,bo,null),e(bo,hgr),e(bo,hbe),e(hbe,pgr),e(bo,ugr),e(bo,Za),e(Za,_gr),e(Za,pbe),e(pbe,bgr),e(Za,vgr),e(Za,ube),e(ube,Fgr),e(Za,Tgr),e(Za,_be),e(_be,Mgr),e(Za,Egr),e(bo,Cgr),e(bo,bbe),e(bbe,C7),e(C7,vbe),e(vbe,wgr),e(C7,Agr),e(C7,PQ),e(PQ,Lgr),e(C7,ygr),e(bo,xgr),e(bo,w7),e(w7,$gr),e(w7,Fbe),e(Fbe,kgr),e(w7,Sgr),e(w7,Tbe),e(Tbe,Rgr),e(bo,Pgr),M(A7,bo,null),b(f,MOe,_),b(f,Hd,_),e(Hd,L7),e(L7,Mbe),M(e9,Mbe,null),e(Hd,Bgr),e(Hd,Ebe),e(Ebe,Igr),b(f,EOe,_),b(f,Yo,_),M(o9,Yo,null),e(Yo,Ngr),e(Yo,Ud),e(Ud,qgr),e(Ud,BQ),e(BQ,jgr),e(Ud,Dgr),e(Ud,IQ),e(IQ,Ggr),e(Ud,Ogr),e(Yo,Vgr),e(Yo,r9),e(r9,Xgr),e(r9,Cbe),e(Cbe,zgr),e(r9,Wgr),e(Yo,Qgr),e(Yo,yt),M(t9,yt,null),e(yt,Hgr),e(yt,wbe),e(wbe,Ugr),e(yt,Jgr),e(yt,Jd),e(Jd,Ygr),e(Jd,Abe),e(Abe,Kgr),e(Jd,Zgr),e(Jd,NQ),e(NQ,ehr),e(Jd,ohr),e(yt,rhr),M(y7,yt,null),e(Yo,thr),e(Yo,vo),M(a9,vo,null),e(vo,ahr),e(vo,Lbe),e(Lbe,nhr),e(vo,shr),e(vo,en),e(en,lhr),e(en,ybe),e(ybe,ihr),e(en,dhr),e(en,xbe),e(xbe,chr),e(en,fhr),e(en,$be),e($be,mhr),e(en,ghr),e(vo,hhr),e(vo,on),e(on,x7),e(x7,kbe),e(kbe,phr),e(x7,uhr),e(x7,qQ),e(qQ,_hr),e(x7,bhr),e(on,vhr),e(on,$7),e($7,Sbe),e(Sbe,Fhr),e($7,Thr),e($7,jQ),e(jQ,Mhr),e($7,Ehr),e(on,Chr),e(on,k7),e(k7,Rbe),e(Rbe,whr),e(k7,Ahr),e(k7,DQ),e(DQ,Lhr),e(k7,yhr),e(on,xhr),e(on,S7),e(S7,Pbe),e(Pbe,$hr),e(S7,khr),e(S7,GQ),e(GQ,Shr),e(S7,Rhr),e(vo,Phr),e(vo,R7),e(R7,Bhr),e(R7,Bbe),e(Bbe,Ihr),e(R7,Nhr),e(R7,Ibe),e(Ibe,qhr),e(vo,jhr),M(P7,vo,null),b(f,COe,_),b(f,Yd,_),e(Yd,B7),e(B7,Nbe),M(n9,Nbe,null),e(Yd,Dhr),e(Yd,qbe),e(qbe,Ghr),b(f,wOe,_),b(f,Ko,_),M(s9,Ko,null),e(Ko,Ohr),e(Ko,Kd),e(Kd,Vhr),e(Kd,OQ),e(OQ,Xhr),e(Kd,zhr),e(Kd,VQ),e(VQ,Whr),e(Kd,Qhr),e(Ko,Hhr),e(Ko,l9),e(l9,Uhr),e(l9,jbe),e(jbe,Jhr),e(l9,Yhr),e(Ko,Khr),e(Ko,xt),M(i9,xt,null),e(xt,Zhr),e(xt,Dbe),e(Dbe,epr),e(xt,opr),e(xt,Zd),e(Zd,rpr),e(Zd,Gbe),e(Gbe,tpr),e(Zd,apr),e(Zd,XQ),e(XQ,npr),e(Zd,spr),e(xt,lpr),M(I7,xt,null),e(Ko,ipr),e(Ko,Fo),M(d9,Fo,null),e(Fo,dpr),e(Fo,Obe),e(Obe,cpr),e(Fo,fpr),e(Fo,rn),e(rn,mpr),e(rn,Vbe),e(Vbe,gpr),e(rn,hpr),e(rn,Xbe),e(Xbe,ppr),e(rn,upr),e(rn,zbe),e(zbe,_pr),e(rn,bpr),e(Fo,vpr),e(Fo,Wbe),e(Wbe,N7),e(N7,Qbe),e(Qbe,Fpr),e(N7,Tpr),e(N7,zQ),e(zQ,Mpr),e(N7,Epr),e(Fo,Cpr),e(Fo,q7),e(q7,wpr),e(q7,Hbe),e(Hbe,Apr),e(q7,Lpr),e(q7,Ube),e(Ube,ypr),e(Fo,xpr),M(j7,Fo,null),b(f,AOe,_),b(f,ec,_),e(ec,D7),e(D7,Jbe),M(c9,Jbe,null),e(ec,$pr),e(ec,Ybe),e(Ybe,kpr),b(f,LOe,_),b(f,Zo,_),M(f9,Zo,null),e(Zo,Spr),e(Zo,oc),e(oc,Rpr),e(oc,WQ),e(WQ,Ppr),e(oc,Bpr),e(oc,QQ),e(QQ,Ipr),e(oc,Npr),e(Zo,qpr),e(Zo,m9),e(m9,jpr),e(m9,Kbe),e(Kbe,Dpr),e(m9,Gpr),e(Zo,Opr),e(Zo,$t),M(g9,$t,null),e($t,Vpr),e($t,Zbe),e(Zbe,Xpr),e($t,zpr),e($t,rc),e(rc,Wpr),e(rc,eve),e(eve,Qpr),e(rc,Hpr),e(rc,HQ),e(HQ,Upr),e(rc,Jpr),e($t,Ypr),M(G7,$t,null),e(Zo,Kpr),e(Zo,Lr),M(h9,Lr,null),e(Lr,Zpr),e(Lr,ove),e(ove,eur),e(Lr,our),e(Lr,tn),e(tn,rur),e(tn,rve),e(rve,tur),e(tn,aur),e(tn,tve),e(tve,nur),e(tn,sur),e(tn,ave),e(ave,lur),e(tn,iur),e(Lr,dur),e(Lr,q),e(q,O7),e(O7,nve),e(nve,cur),e(O7,fur),e(O7,UQ),e(UQ,mur),e(O7,gur),e(q,hur),e(q,V7),e(V7,sve),e(sve,pur),e(V7,uur),e(V7,JQ),e(JQ,_ur),e(V7,bur),e(q,vur),e(q,X7),e(X7,lve),e(lve,Fur),e(X7,Tur),e(X7,YQ),e(YQ,Mur),e(X7,Eur),e(q,Cur),e(q,z7),e(z7,ive),e(ive,wur),e(z7,Aur),e(z7,KQ),e(KQ,Lur),e(z7,yur),e(q,xur),e(q,W7),e(W7,dve),e(dve,$ur),e(W7,kur),e(W7,ZQ),e(ZQ,Sur),e(W7,Rur),e(q,Pur),e(q,Q7),e(Q7,cve),e(cve,Bur),e(Q7,Iur),e(Q7,eH),e(eH,Nur),e(Q7,qur),e(q,jur),e(q,H7),e(H7,fve),e(fve,Dur),e(H7,Gur),e(H7,oH),e(oH,Our),e(H7,Vur),e(q,Xur),e(q,U7),e(U7,mve),e(mve,zur),e(U7,Wur),e(U7,rH),e(rH,Qur),e(U7,Hur),e(q,Uur),e(q,J7),e(J7,gve),e(gve,Jur),e(J7,Yur),e(J7,tH),e(tH,Kur),e(J7,Zur),e(q,e_r),e(q,Y7),e(Y7,hve),e(hve,o_r),e(Y7,r_r),e(Y7,aH),e(aH,t_r),e(Y7,a_r),e(q,n_r),e(q,K7),e(K7,pve),e(pve,s_r),e(K7,l_r),e(K7,nH),e(nH,i_r),e(K7,d_r),e(q,c_r),e(q,Z7),e(Z7,uve),e(uve,f_r),e(Z7,m_r),e(Z7,sH),e(sH,g_r),e(Z7,h_r),e(q,p_r),e(q,eM),e(eM,_ve),e(_ve,u_r),e(eM,__r),e(eM,lH),e(lH,b_r),e(eM,v_r),e(q,F_r),e(q,oM),e(oM,bve),e(bve,T_r),e(oM,M_r),e(oM,iH),e(iH,E_r),e(oM,C_r),e(q,w_r),e(q,rM),e(rM,vve),e(vve,A_r),e(rM,L_r),e(rM,dH),e(dH,y_r),e(rM,x_r),e(q,$_r),e(q,tM),e(tM,Fve),e(Fve,k_r),e(tM,S_r),e(tM,cH),e(cH,R_r),e(tM,P_r),e(q,B_r),e(q,aM),e(aM,Tve),e(Tve,I_r),e(aM,N_r),e(aM,fH),e(fH,q_r),e(aM,j_r),e(q,D_r),e(q,zs),e(zs,Mve),e(Mve,G_r),e(zs,O_r),e(zs,mH),e(mH,V_r),e(zs,X_r),e(zs,gH),e(gH,z_r),e(zs,W_r),e(q,Q_r),e(q,nM),e(nM,Eve),e(Eve,H_r),e(nM,U_r),e(nM,hH),e(hH,J_r),e(nM,Y_r),e(q,K_r),e(q,sM),e(sM,Cve),e(Cve,Z_r),e(sM,e1r),e(sM,pH),e(pH,o1r),e(sM,r1r),e(q,t1r),e(q,lM),e(lM,wve),e(wve,a1r),e(lM,n1r),e(lM,uH),e(uH,s1r),e(lM,l1r),e(q,i1r),e(q,iM),e(iM,Ave),e(Ave,d1r),e(iM,c1r),e(iM,_H),e(_H,f1r),e(iM,m1r),e(q,g1r),e(q,dM),e(dM,Lve),e(Lve,h1r),e(dM,p1r),e(dM,bH),e(bH,u1r),e(dM,_1r),e(q,b1r),e(q,cM),e(cM,yve),e(yve,v1r),e(cM,F1r),e(cM,vH),e(vH,T1r),e(cM,M1r),e(q,E1r),e(q,fM),e(fM,xve),e(xve,C1r),e(fM,w1r),e(fM,FH),e(FH,A1r),e(fM,L1r),e(q,y1r),e(q,mM),e(mM,$ve),e($ve,x1r),e(mM,$1r),e(mM,TH),e(TH,k1r),e(mM,S1r),e(q,R1r),e(q,gM),e(gM,kve),e(kve,P1r),e(gM,B1r),e(gM,MH),e(MH,I1r),e(gM,N1r),e(q,q1r),e(q,hM),e(hM,Sve),e(Sve,j1r),e(hM,D1r),e(hM,EH),e(EH,G1r),e(hM,O1r),e(q,V1r),e(q,pM),e(pM,Rve),e(Rve,X1r),e(pM,z1r),e(pM,CH),e(CH,W1r),e(pM,Q1r),e(q,H1r),e(q,uM),e(uM,Pve),e(Pve,U1r),e(uM,J1r),e(uM,wH),e(wH,Y1r),e(uM,K1r),e(q,Z1r),e(q,_M),e(_M,Bve),e(Bve,e3r),e(_M,o3r),e(_M,AH),e(AH,r3r),e(_M,t3r),e(q,a3r),e(q,bM),e(bM,Ive),e(Ive,n3r),e(bM,s3r),e(bM,LH),e(LH,l3r),e(bM,i3r),e(q,d3r),e(q,vM),e(vM,Nve),e(Nve,c3r),e(vM,f3r),e(vM,yH),e(yH,m3r),e(vM,g3r),e(q,h3r),e(q,FM),e(FM,qve),e(qve,p3r),e(FM,u3r),e(FM,xH),e(xH,_3r),e(FM,b3r),e(q,v3r),e(q,TM),e(TM,jve),e(jve,F3r),e(TM,T3r),e(TM,$H),e($H,M3r),e(TM,E3r),e(q,C3r),e(q,MM),e(MM,Dve),e(Dve,w3r),e(MM,A3r),e(MM,kH),e(kH,L3r),e(MM,y3r),e(q,x3r),e(q,EM),e(EM,Gve),e(Gve,$3r),e(EM,k3r),e(EM,SH),e(SH,S3r),e(EM,R3r),e(q,P3r),e(q,CM),e(CM,Ove),e(Ove,B3r),e(CM,I3r),e(CM,RH),e(RH,N3r),e(CM,q3r),e(q,j3r),e(q,wM),e(wM,Vve),e(Vve,D3r),e(wM,G3r),e(wM,PH),e(PH,O3r),e(wM,V3r),e(q,X3r),e(q,AM),e(AM,Xve),e(Xve,z3r),e(AM,W3r),e(AM,BH),e(BH,Q3r),e(AM,H3r),e(q,U3r),e(q,LM),e(LM,zve),e(zve,J3r),e(LM,Y3r),e(LM,IH),e(IH,K3r),e(LM,Z3r),e(q,e2r),e(q,yM),e(yM,Wve),e(Wve,o2r),e(yM,r2r),e(yM,NH),e(NH,t2r),e(yM,a2r),e(q,n2r),e(q,xM),e(xM,Qve),e(Qve,s2r),e(xM,l2r),e(xM,qH),e(qH,i2r),e(xM,d2r),e(q,c2r),e(q,$M),e($M,Hve),e(Hve,f2r),e($M,m2r),e($M,jH),e(jH,g2r),e($M,h2r),e(q,p2r),e(q,kM),e(kM,Uve),e(Uve,u2r),e(kM,_2r),e(kM,DH),e(DH,b2r),e(kM,v2r),e(q,F2r),e(q,SM),e(SM,Jve),e(Jve,T2r),e(SM,M2r),e(SM,GH),e(GH,E2r),e(SM,C2r),e(q,w2r),e(q,RM),e(RM,Yve),e(Yve,A2r),e(RM,L2r),e(RM,OH),e(OH,y2r),e(RM,x2r),e(Lr,$2r),M(PM,Lr,null),b(f,yOe,_),b(f,tc,_),e(tc,BM),e(BM,Kve),M(p9,Kve,null),e(tc,k2r),e(tc,Zve),e(Zve,S2r),b(f,xOe,_),b(f,er,_),M(u9,er,null),e(er,R2r),e(er,ac),e(ac,P2r),e(ac,VH),e(VH,B2r),e(ac,I2r),e(ac,XH),e(XH,N2r),e(ac,q2r),e(er,j2r),e(er,_9),e(_9,D2r),e(_9,eFe),e(eFe,G2r),e(_9,O2r),e(er,V2r),e(er,kt),M(b9,kt,null),e(kt,X2r),e(kt,oFe),e(oFe,z2r),e(kt,W2r),e(kt,nc),e(nc,Q2r),e(nc,rFe),e(rFe,H2r),e(nc,U2r),e(nc,zH),e(zH,J2r),e(nc,Y2r),e(kt,K2r),M(IM,kt,null),e(er,Z2r),e(er,yr),M(v9,yr,null),e(yr,ebr),e(yr,tFe),e(tFe,obr),e(yr,rbr),e(yr,an),e(an,tbr),e(an,aFe),e(aFe,abr),e(an,nbr),e(an,nFe),e(nFe,sbr),e(an,lbr),e(an,sFe),e(sFe,ibr),e(an,dbr),e(yr,cbr),e(yr,se),e(se,NM),e(NM,lFe),e(lFe,fbr),e(NM,mbr),e(NM,WH),e(WH,gbr),e(NM,hbr),e(se,pbr),e(se,qM),e(qM,iFe),e(iFe,ubr),e(qM,_br),e(qM,QH),e(QH,bbr),e(qM,vbr),e(se,Fbr),e(se,jM),e(jM,dFe),e(dFe,Tbr),e(jM,Mbr),e(jM,HH),e(HH,Ebr),e(jM,Cbr),e(se,wbr),e(se,DM),e(DM,cFe),e(cFe,Abr),e(DM,Lbr),e(DM,UH),e(UH,ybr),e(DM,xbr),e(se,$br),e(se,GM),e(GM,fFe),e(fFe,kbr),e(GM,Sbr),e(GM,JH),e(JH,Rbr),e(GM,Pbr),e(se,Bbr),e(se,OM),e(OM,mFe),e(mFe,Ibr),e(OM,Nbr),e(OM,YH),e(YH,qbr),e(OM,jbr),e(se,Dbr),e(se,VM),e(VM,gFe),e(gFe,Gbr),e(VM,Obr),e(VM,KH),e(KH,Vbr),e(VM,Xbr),e(se,zbr),e(se,XM),e(XM,hFe),e(hFe,Wbr),e(XM,Qbr),e(XM,ZH),e(ZH,Hbr),e(XM,Ubr),e(se,Jbr),e(se,zM),e(zM,pFe),e(pFe,Ybr),e(zM,Kbr),e(zM,eU),e(eU,Zbr),e(zM,evr),e(se,ovr),e(se,WM),e(WM,uFe),e(uFe,rvr),e(WM,tvr),e(WM,oU),e(oU,avr),e(WM,nvr),e(se,svr),e(se,QM),e(QM,_Fe),e(_Fe,lvr),e(QM,ivr),e(QM,rU),e(rU,dvr),e(QM,cvr),e(se,fvr),e(se,HM),e(HM,bFe),e(bFe,mvr),e(HM,gvr),e(HM,tU),e(tU,hvr),e(HM,pvr),e(se,uvr),e(se,UM),e(UM,vFe),e(vFe,_vr),e(UM,bvr),e(UM,aU),e(aU,vvr),e(UM,Fvr),e(se,Tvr),e(se,JM),e(JM,FFe),e(FFe,Mvr),e(JM,Evr),e(JM,nU),e(nU,Cvr),e(JM,wvr),e(se,Avr),e(se,YM),e(YM,TFe),e(TFe,Lvr),e(YM,yvr),e(YM,sU),e(sU,xvr),e(YM,$vr),e(se,kvr),e(se,KM),e(KM,MFe),e(MFe,Svr),e(KM,Rvr),e(KM,lU),e(lU,Pvr),e(KM,Bvr),e(se,Ivr),e(se,ZM),e(ZM,EFe),e(EFe,Nvr),e(ZM,qvr),e(ZM,iU),e(iU,jvr),e(ZM,Dvr),e(se,Gvr),e(se,eE),e(eE,CFe),e(CFe,Ovr),e(eE,Vvr),e(eE,dU),e(dU,Xvr),e(eE,zvr),e(se,Wvr),e(se,oE),e(oE,wFe),e(wFe,Qvr),e(oE,Hvr),e(oE,cU),e(cU,Uvr),e(oE,Jvr),e(se,Yvr),e(se,rE),e(rE,AFe),e(AFe,Kvr),e(rE,Zvr),e(rE,fU),e(fU,eFr),e(rE,oFr),e(se,rFr),e(se,tE),e(tE,LFe),e(LFe,tFr),e(tE,aFr),e(tE,mU),e(mU,nFr),e(tE,sFr),e(se,lFr),e(se,aE),e(aE,yFe),e(yFe,iFr),e(aE,dFr),e(aE,gU),e(gU,cFr),e(aE,fFr),e(se,mFr),e(se,nE),e(nE,xFe),e(xFe,gFr),e(nE,hFr),e(nE,hU),e(hU,pFr),e(nE,uFr),e(yr,_Fr),M(sE,yr,null),b(f,$Oe,_),b(f,sc,_),e(sc,lE),e(lE,$Fe),M(F9,$Fe,null),e(sc,bFr),e(sc,kFe),e(kFe,vFr),b(f,kOe,_),b(f,or,_),M(T9,or,null),e(or,FFr),e(or,lc),e(lc,TFr),e(lc,pU),e(pU,MFr),e(lc,EFr),e(lc,uU),e(uU,CFr),e(lc,wFr),e(or,AFr),e(or,M9),e(M9,LFr),e(M9,SFe),e(SFe,yFr),e(M9,xFr),e(or,$Fr),e(or,St),M(E9,St,null),e(St,kFr),e(St,RFe),e(RFe,SFr),e(St,RFr),e(St,ic),e(ic,PFr),e(ic,PFe),e(PFe,BFr),e(ic,IFr),e(ic,_U),e(_U,NFr),e(ic,qFr),e(St,jFr),M(iE,St,null),e(or,DFr),e(or,xr),M(C9,xr,null),e(xr,GFr),e(xr,BFe),e(BFe,OFr),e(xr,VFr),e(xr,nn),e(nn,XFr),e(nn,IFe),e(IFe,zFr),e(nn,WFr),e(nn,NFe),e(NFe,QFr),e(nn,HFr),e(nn,qFe),e(qFe,UFr),e(nn,JFr),e(xr,YFr),e(xr,Me),e(Me,dE),e(dE,jFe),e(jFe,KFr),e(dE,ZFr),e(dE,bU),e(bU,eTr),e(dE,oTr),e(Me,rTr),e(Me,cE),e(cE,DFe),e(DFe,tTr),e(cE,aTr),e(cE,vU),e(vU,nTr),e(cE,sTr),e(Me,lTr),e(Me,fE),e(fE,GFe),e(GFe,iTr),e(fE,dTr),e(fE,FU),e(FU,cTr),e(fE,fTr),e(Me,mTr),e(Me,mE),e(mE,OFe),e(OFe,gTr),e(mE,hTr),e(mE,TU),e(TU,pTr),e(mE,uTr),e(Me,_Tr),e(Me,gE),e(gE,VFe),e(VFe,bTr),e(gE,vTr),e(gE,MU),e(MU,FTr),e(gE,TTr),e(Me,MTr),e(Me,hE),e(hE,XFe),e(XFe,ETr),e(hE,CTr),e(hE,EU),e(EU,wTr),e(hE,ATr),e(Me,LTr),e(Me,pE),e(pE,zFe),e(zFe,yTr),e(pE,xTr),e(pE,CU),e(CU,$Tr),e(pE,kTr),e(Me,STr),e(Me,uE),e(uE,WFe),e(WFe,RTr),e(uE,PTr),e(uE,wU),e(wU,BTr),e(uE,ITr),e(Me,NTr),e(Me,_E),e(_E,QFe),e(QFe,qTr),e(_E,jTr),e(_E,AU),e(AU,DTr),e(_E,GTr),e(Me,OTr),e(Me,bE),e(bE,HFe),e(HFe,VTr),e(bE,XTr),e(bE,LU),e(LU,zTr),e(bE,WTr),e(Me,QTr),e(Me,vE),e(vE,UFe),e(UFe,HTr),e(vE,UTr),e(vE,yU),e(yU,JTr),e(vE,YTr),e(Me,KTr),e(Me,FE),e(FE,JFe),e(JFe,ZTr),e(FE,e7r),e(FE,xU),e(xU,o7r),e(FE,r7r),e(Me,t7r),e(Me,TE),e(TE,YFe),e(YFe,a7r),e(TE,n7r),e(TE,$U),e($U,s7r),e(TE,l7r),e(xr,i7r),M(ME,xr,null),b(f,SOe,_),b(f,dc,_),e(dc,EE),e(EE,KFe),M(w9,KFe,null),e(dc,d7r),e(dc,ZFe),e(ZFe,c7r),b(f,ROe,_),b(f,rr,_),M(A9,rr,null),e(rr,f7r),e(rr,cc),e(cc,m7r),e(cc,kU),e(kU,g7r),e(cc,h7r),e(cc,SU),e(SU,p7r),e(cc,u7r),e(rr,_7r),e(rr,L9),e(L9,b7r),e(L9,eTe),e(eTe,v7r),e(L9,F7r),e(rr,T7r),e(rr,Rt),M(y9,Rt,null),e(Rt,M7r),e(Rt,oTe),e(oTe,E7r),e(Rt,C7r),e(Rt,fc),e(fc,w7r),e(fc,rTe),e(rTe,A7r),e(fc,L7r),e(fc,RU),e(RU,y7r),e(fc,x7r),e(Rt,$7r),M(CE,Rt,null),e(rr,k7r),e(rr,$r),M(x9,$r,null),e($r,S7r),e($r,tTe),e(tTe,R7r),e($r,P7r),e($r,sn),e(sn,B7r),e(sn,aTe),e(aTe,I7r),e(sn,N7r),e(sn,nTe),e(nTe,q7r),e(sn,j7r),e(sn,sTe),e(sTe,D7r),e(sn,G7r),e($r,O7r),e($r,ln),e(ln,wE),e(wE,lTe),e(lTe,V7r),e(wE,X7r),e(wE,PU),e(PU,z7r),e(wE,W7r),e(ln,Q7r),e(ln,AE),e(AE,iTe),e(iTe,H7r),e(AE,U7r),e(AE,BU),e(BU,J7r),e(AE,Y7r),e(ln,K7r),e(ln,LE),e(LE,dTe),e(dTe,Z7r),e(LE,eMr),e(LE,IU),e(IU,oMr),e(LE,rMr),e(ln,tMr),e(ln,yE),e(yE,cTe),e(cTe,aMr),e(yE,nMr),e(yE,NU),e(NU,sMr),e(yE,lMr),e($r,iMr),M(xE,$r,null),b(f,POe,_),b(f,mc,_),e(mc,$E),e($E,fTe),M($9,fTe,null),e(mc,dMr),e(mc,mTe),e(mTe,cMr),b(f,BOe,_),b(f,tr,_),M(k9,tr,null),e(tr,fMr),e(tr,gc),e(gc,mMr),e(gc,qU),e(qU,gMr),e(gc,hMr),e(gc,jU),e(jU,pMr),e(gc,uMr),e(tr,_Mr),e(tr,S9),e(S9,bMr),e(S9,gTe),e(gTe,vMr),e(S9,FMr),e(tr,TMr),e(tr,Pt),M(R9,Pt,null),e(Pt,MMr),e(Pt,hTe),e(hTe,EMr),e(Pt,CMr),e(Pt,hc),e(hc,wMr),e(hc,pTe),e(pTe,AMr),e(hc,LMr),e(hc,DU),e(DU,yMr),e(hc,xMr),e(Pt,$Mr),M(kE,Pt,null),e(tr,kMr),e(tr,kr),M(P9,kr,null),e(kr,SMr),e(kr,uTe),e(uTe,RMr),e(kr,PMr),e(kr,dn),e(dn,BMr),e(dn,_Te),e(_Te,IMr),e(dn,NMr),e(dn,bTe),e(bTe,qMr),e(dn,jMr),e(dn,vTe),e(vTe,DMr),e(dn,GMr),e(kr,OMr),e(kr,ie),e(ie,SE),e(SE,FTe),e(FTe,VMr),e(SE,XMr),e(SE,GU),e(GU,zMr),e(SE,WMr),e(ie,QMr),e(ie,RE),e(RE,TTe),e(TTe,HMr),e(RE,UMr),e(RE,OU),e(OU,JMr),e(RE,YMr),e(ie,KMr),e(ie,PE),e(PE,MTe),e(MTe,ZMr),e(PE,eEr),e(PE,VU),e(VU,oEr),e(PE,rEr),e(ie,tEr),e(ie,BE),e(BE,ETe),e(ETe,aEr),e(BE,nEr),e(BE,XU),e(XU,sEr),e(BE,lEr),e(ie,iEr),e(ie,IE),e(IE,CTe),e(CTe,dEr),e(IE,cEr),e(IE,zU),e(zU,fEr),e(IE,mEr),e(ie,gEr),e(ie,NE),e(NE,wTe),e(wTe,hEr),e(NE,pEr),e(NE,WU),e(WU,uEr),e(NE,_Er),e(ie,bEr),e(ie,qE),e(qE,ATe),e(ATe,vEr),e(qE,FEr),e(qE,QU),e(QU,TEr),e(qE,MEr),e(ie,EEr),e(ie,jE),e(jE,LTe),e(LTe,CEr),e(jE,wEr),e(jE,HU),e(HU,AEr),e(jE,LEr),e(ie,yEr),e(ie,DE),e(DE,yTe),e(yTe,xEr),e(DE,$Er),e(DE,UU),e(UU,kEr),e(DE,SEr),e(ie,REr),e(ie,GE),e(GE,xTe),e(xTe,PEr),e(GE,BEr),e(GE,JU),e(JU,IEr),e(GE,NEr),e(ie,qEr),e(ie,OE),e(OE,$Te),e($Te,jEr),e(OE,DEr),e(OE,YU),e(YU,GEr),e(OE,OEr),e(ie,VEr),e(ie,VE),e(VE,kTe),e(kTe,XEr),e(VE,zEr),e(VE,KU),e(KU,WEr),e(VE,QEr),e(ie,HEr),e(ie,XE),e(XE,STe),e(STe,UEr),e(XE,JEr),e(XE,ZU),e(ZU,YEr),e(XE,KEr),e(ie,ZEr),e(ie,zE),e(zE,RTe),e(RTe,e4r),e(zE,o4r),e(zE,eJ),e(eJ,r4r),e(zE,t4r),e(ie,a4r),e(ie,WE),e(WE,PTe),e(PTe,n4r),e(WE,s4r),e(WE,oJ),e(oJ,l4r),e(WE,i4r),e(ie,d4r),e(ie,QE),e(QE,BTe),e(BTe,c4r),e(QE,f4r),e(QE,rJ),e(rJ,m4r),e(QE,g4r),e(ie,h4r),e(ie,HE),e(HE,ITe),e(ITe,p4r),e(HE,u4r),e(HE,tJ),e(tJ,_4r),e(HE,b4r),e(ie,v4r),e(ie,UE),e(UE,NTe),e(NTe,F4r),e(UE,T4r),e(UE,aJ),e(aJ,M4r),e(UE,E4r),e(ie,C4r),e(ie,JE),e(JE,qTe),e(qTe,w4r),e(JE,A4r),e(JE,nJ),e(nJ,L4r),e(JE,y4r),e(ie,x4r),e(ie,YE),e(YE,jTe),e(jTe,$4r),e(YE,k4r),e(YE,sJ),e(sJ,S4r),e(YE,R4r),e(kr,P4r),M(KE,kr,null),b(f,IOe,_),b(f,pc,_),e(pc,ZE),e(ZE,DTe),M(B9,DTe,null),e(pc,B4r),e(pc,GTe),e(GTe,I4r),b(f,NOe,_),b(f,ar,_),M(I9,ar,null),e(ar,N4r),e(ar,uc),e(uc,q4r),e(uc,lJ),e(lJ,j4r),e(uc,D4r),e(uc,iJ),e(iJ,G4r),e(uc,O4r),e(ar,V4r),e(ar,N9),e(N9,X4r),e(N9,OTe),e(OTe,z4r),e(N9,W4r),e(ar,Q4r),e(ar,Bt),M(q9,Bt,null),e(Bt,H4r),e(Bt,VTe),e(VTe,U4r),e(Bt,J4r),e(Bt,_c),e(_c,Y4r),e(_c,XTe),e(XTe,K4r),e(_c,Z4r),e(_c,dJ),e(dJ,eCr),e(_c,oCr),e(Bt,rCr),M(e4,Bt,null),e(ar,tCr),e(ar,Sr),M(j9,Sr,null),e(Sr,aCr),e(Sr,zTe),e(zTe,nCr),e(Sr,sCr),e(Sr,cn),e(cn,lCr),e(cn,WTe),e(WTe,iCr),e(cn,dCr),e(cn,QTe),e(QTe,cCr),e(cn,fCr),e(cn,HTe),e(HTe,mCr),e(cn,gCr),e(Sr,hCr),e(Sr,ye),e(ye,o4),e(o4,UTe),e(UTe,pCr),e(o4,uCr),e(o4,cJ),e(cJ,_Cr),e(o4,bCr),e(ye,vCr),e(ye,r4),e(r4,JTe),e(JTe,FCr),e(r4,TCr),e(r4,fJ),e(fJ,MCr),e(r4,ECr),e(ye,CCr),e(ye,t4),e(t4,YTe),e(YTe,wCr),e(t4,ACr),e(t4,mJ),e(mJ,LCr),e(t4,yCr),e(ye,xCr),e(ye,a4),e(a4,KTe),e(KTe,$Cr),e(a4,kCr),e(a4,gJ),e(gJ,SCr),e(a4,RCr),e(ye,PCr),e(ye,n4),e(n4,ZTe),e(ZTe,BCr),e(n4,ICr),e(n4,hJ),e(hJ,NCr),e(n4,qCr),e(ye,jCr),e(ye,s4),e(s4,e7e),e(e7e,DCr),e(s4,GCr),e(s4,pJ),e(pJ,OCr),e(s4,VCr),e(ye,XCr),e(ye,l4),e(l4,o7e),e(o7e,zCr),e(l4,WCr),e(l4,uJ),e(uJ,QCr),e(l4,HCr),e(ye,UCr),e(ye,i4),e(i4,r7e),e(r7e,JCr),e(i4,YCr),e(i4,_J),e(_J,KCr),e(i4,ZCr),e(ye,e5r),e(ye,d4),e(d4,t7e),e(t7e,o5r),e(d4,r5r),e(d4,bJ),e(bJ,t5r),e(d4,a5r),e(ye,n5r),e(ye,c4),e(c4,a7e),e(a7e,s5r),e(c4,l5r),e(c4,vJ),e(vJ,i5r),e(c4,d5r),e(Sr,c5r),M(f4,Sr,null),b(f,qOe,_),b(f,bc,_),e(bc,m4),e(m4,n7e),M(D9,n7e,null),e(bc,f5r),e(bc,s7e),e(s7e,m5r),b(f,jOe,_),b(f,nr,_),M(G9,nr,null),e(nr,g5r),e(nr,vc),e(vc,h5r),e(vc,FJ),e(FJ,p5r),e(vc,u5r),e(vc,TJ),e(TJ,_5r),e(vc,b5r),e(nr,v5r),e(nr,O9),e(O9,F5r),e(O9,l7e),e(l7e,T5r),e(O9,M5r),e(nr,E5r),e(nr,It),M(V9,It,null),e(It,C5r),e(It,i7e),e(i7e,w5r),e(It,A5r),e(It,Fc),e(Fc,L5r),e(Fc,d7e),e(d7e,y5r),e(Fc,x5r),e(Fc,MJ),e(MJ,$5r),e(Fc,k5r),e(It,S5r),M(g4,It,null),e(nr,R5r),e(nr,Rr),M(X9,Rr,null),e(Rr,P5r),e(Rr,c7e),e(c7e,B5r),e(Rr,I5r),e(Rr,fn),e(fn,N5r),e(fn,f7e),e(f7e,q5r),e(fn,j5r),e(fn,m7e),e(m7e,D5r),e(fn,G5r),e(fn,g7e),e(g7e,O5r),e(fn,V5r),e(Rr,X5r),e(Rr,te),e(te,h4),e(h4,h7e),e(h7e,z5r),e(h4,W5r),e(h4,EJ),e(EJ,Q5r),e(h4,H5r),e(te,U5r),e(te,p4),e(p4,p7e),e(p7e,J5r),e(p4,Y5r),e(p4,CJ),e(CJ,K5r),e(p4,Z5r),e(te,e0r),e(te,u4),e(u4,u7e),e(u7e,o0r),e(u4,r0r),e(u4,wJ),e(wJ,t0r),e(u4,a0r),e(te,n0r),e(te,_4),e(_4,_7e),e(_7e,s0r),e(_4,l0r),e(_4,AJ),e(AJ,i0r),e(_4,d0r),e(te,c0r),e(te,b4),e(b4,b7e),e(b7e,f0r),e(b4,m0r),e(b4,LJ),e(LJ,g0r),e(b4,h0r),e(te,p0r),e(te,v4),e(v4,v7e),e(v7e,u0r),e(v4,_0r),e(v4,yJ),e(yJ,b0r),e(v4,v0r),e(te,F0r),e(te,F4),e(F4,F7e),e(F7e,T0r),e(F4,M0r),e(F4,xJ),e(xJ,E0r),e(F4,C0r),e(te,w0r),e(te,T4),e(T4,T7e),e(T7e,A0r),e(T4,L0r),e(T4,$J),e($J,y0r),e(T4,x0r),e(te,$0r),e(te,M4),e(M4,M7e),e(M7e,k0r),e(M4,S0r),e(M4,kJ),e(kJ,R0r),e(M4,P0r),e(te,B0r),e(te,E4),e(E4,E7e),e(E7e,I0r),e(E4,N0r),e(E4,SJ),e(SJ,q0r),e(E4,j0r),e(te,D0r),e(te,C4),e(C4,C7e),e(C7e,G0r),e(C4,O0r),e(C4,RJ),e(RJ,V0r),e(C4,X0r),e(te,z0r),e(te,w4),e(w4,w7e),e(w7e,W0r),e(w4,Q0r),e(w4,PJ),e(PJ,H0r),e(w4,U0r),e(te,J0r),e(te,A4),e(A4,A7e),e(A7e,Y0r),e(A4,K0r),e(A4,BJ),e(BJ,Z0r),e(A4,ewr),e(te,owr),e(te,L4),e(L4,L7e),e(L7e,rwr),e(L4,twr),e(L4,IJ),e(IJ,awr),e(L4,nwr),e(te,swr),e(te,y4),e(y4,y7e),e(y7e,lwr),e(y4,iwr),e(y4,NJ),e(NJ,dwr),e(y4,cwr),e(te,fwr),e(te,x4),e(x4,x7e),e(x7e,mwr),e(x4,gwr),e(x4,qJ),e(qJ,hwr),e(x4,pwr),e(te,uwr),e(te,$4),e($4,$7e),e($7e,_wr),e($4,bwr),e($4,jJ),e(jJ,vwr),e($4,Fwr),e(te,Twr),e(te,k4),e(k4,k7e),e(k7e,Mwr),e(k4,Ewr),e(k4,DJ),e(DJ,Cwr),e(k4,wwr),e(te,Awr),e(te,S4),e(S4,S7e),e(S7e,Lwr),e(S4,ywr),e(S4,GJ),e(GJ,xwr),e(S4,$wr),e(te,kwr),e(te,R4),e(R4,R7e),e(R7e,Swr),e(R4,Rwr),e(R4,OJ),e(OJ,Pwr),e(R4,Bwr),e(te,Iwr),e(te,P4),e(P4,P7e),e(P7e,Nwr),e(P4,qwr),e(P4,VJ),e(VJ,jwr),e(P4,Dwr),e(te,Gwr),e(te,B4),e(B4,B7e),e(B7e,Owr),e(B4,Vwr),e(B4,XJ),e(XJ,Xwr),e(B4,zwr),e(te,Wwr),e(te,I4),e(I4,I7e),e(I7e,Qwr),e(I4,Hwr),e(I4,zJ),e(zJ,Uwr),e(I4,Jwr),e(te,Ywr),e(te,N4),e(N4,N7e),e(N7e,Kwr),e(N4,Zwr),e(N4,WJ),e(WJ,eAr),e(N4,oAr),e(te,rAr),e(te,q4),e(q4,q7e),e(q7e,tAr),e(q4,aAr),e(q4,QJ),e(QJ,nAr),e(q4,sAr),e(te,lAr),e(te,j4),e(j4,j7e),e(j7e,iAr),e(j4,dAr),e(j4,HJ),e(HJ,cAr),e(j4,fAr),e(Rr,mAr),M(D4,Rr,null),b(f,DOe,_),b(f,Tc,_),e(Tc,G4),e(G4,D7e),M(z9,D7e,null),e(Tc,gAr),e(Tc,G7e),e(G7e,hAr),b(f,GOe,_),b(f,sr,_),M(W9,sr,null),e(sr,pAr),e(sr,Mc),e(Mc,uAr),e(Mc,UJ),e(UJ,_Ar),e(Mc,bAr),e(Mc,JJ),e(JJ,vAr),e(Mc,FAr),e(sr,TAr),e(sr,Q9),e(Q9,MAr),e(Q9,O7e),e(O7e,EAr),e(Q9,CAr),e(sr,wAr),e(sr,Nt),M(H9,Nt,null),e(Nt,AAr),e(Nt,V7e),e(V7e,LAr),e(Nt,yAr),e(Nt,Ec),e(Ec,xAr),e(Ec,X7e),e(X7e,$Ar),e(Ec,kAr),e(Ec,YJ),e(YJ,SAr),e(Ec,RAr),e(Nt,PAr),M(O4,Nt,null),e(sr,BAr),e(sr,Pr),M(U9,Pr,null),e(Pr,IAr),e(Pr,z7e),e(z7e,NAr),e(Pr,qAr),e(Pr,mn),e(mn,jAr),e(mn,W7e),e(W7e,DAr),e(mn,GAr),e(mn,Q7e),e(Q7e,OAr),e(mn,VAr),e(mn,H7e),e(H7e,XAr),e(mn,zAr),e(Pr,WAr),e(Pr,ue),e(ue,V4),e(V4,U7e),e(U7e,QAr),e(V4,HAr),e(V4,KJ),e(KJ,UAr),e(V4,JAr),e(ue,YAr),e(ue,X4),e(X4,J7e),e(J7e,KAr),e(X4,ZAr),e(X4,ZJ),e(ZJ,e6r),e(X4,o6r),e(ue,r6r),e(ue,z4),e(z4,Y7e),e(Y7e,t6r),e(z4,a6r),e(z4,eY),e(eY,n6r),e(z4,s6r),e(ue,l6r),e(ue,W4),e(W4,K7e),e(K7e,i6r),e(W4,d6r),e(W4,oY),e(oY,c6r),e(W4,f6r),e(ue,m6r),e(ue,Q4),e(Q4,Z7e),e(Z7e,g6r),e(Q4,h6r),e(Q4,rY),e(rY,p6r),e(Q4,u6r),e(ue,_6r),e(ue,H4),e(H4,eMe),e(eMe,b6r),e(H4,v6r),e(H4,tY),e(tY,F6r),e(H4,T6r),e(ue,M6r),e(ue,U4),e(U4,oMe),e(oMe,E6r),e(U4,C6r),e(U4,aY),e(aY,w6r),e(U4,A6r),e(ue,L6r),e(ue,J4),e(J4,rMe),e(rMe,y6r),e(J4,x6r),e(J4,nY),e(nY,$6r),e(J4,k6r),e(ue,S6r),e(ue,Y4),e(Y4,tMe),e(tMe,R6r),e(Y4,P6r),e(Y4,sY),e(sY,B6r),e(Y4,I6r),e(ue,N6r),e(ue,K4),e(K4,aMe),e(aMe,q6r),e(K4,j6r),e(K4,lY),e(lY,D6r),e(K4,G6r),e(ue,O6r),e(ue,Z4),e(Z4,nMe),e(nMe,V6r),e(Z4,X6r),e(Z4,iY),e(iY,z6r),e(Z4,W6r),e(ue,Q6r),e(ue,eC),e(eC,sMe),e(sMe,H6r),e(eC,U6r),e(eC,dY),e(dY,J6r),e(eC,Y6r),e(ue,K6r),e(ue,oC),e(oC,lMe),e(lMe,Z6r),e(oC,eLr),e(oC,cY),e(cY,oLr),e(oC,rLr),e(ue,tLr),e(ue,rC),e(rC,iMe),e(iMe,aLr),e(rC,nLr),e(rC,fY),e(fY,sLr),e(rC,lLr),e(ue,iLr),e(ue,tC),e(tC,dMe),e(dMe,dLr),e(tC,cLr),e(tC,mY),e(mY,fLr),e(tC,mLr),e(ue,gLr),e(ue,aC),e(aC,cMe),e(cMe,hLr),e(aC,pLr),e(aC,gY),e(gY,uLr),e(aC,_Lr),e(ue,bLr),e(ue,nC),e(nC,fMe),e(fMe,vLr),e(nC,FLr),e(nC,hY),e(hY,TLr),e(nC,MLr),e(Pr,ELr),M(sC,Pr,null),b(f,OOe,_),b(f,Cc,_),e(Cc,lC),e(lC,mMe),M(J9,mMe,null),e(Cc,CLr),e(Cc,gMe),e(gMe,wLr),b(f,VOe,_),b(f,lr,_),M(Y9,lr,null),e(lr,ALr),e(lr,wc),e(wc,LLr),e(wc,pY),e(pY,yLr),e(wc,xLr),e(wc,uY),e(uY,$Lr),e(wc,kLr),e(lr,SLr),e(lr,K9),e(K9,RLr),e(K9,hMe),e(hMe,PLr),e(K9,BLr),e(lr,ILr),e(lr,qt),M(Z9,qt,null),e(qt,NLr),e(qt,pMe),e(pMe,qLr),e(qt,jLr),e(qt,Ac),e(Ac,DLr),e(Ac,uMe),e(uMe,GLr),e(Ac,OLr),e(Ac,_Y),e(_Y,VLr),e(Ac,XLr),e(qt,zLr),M(iC,qt,null),e(lr,WLr),e(lr,Br),M(ex,Br,null),e(Br,QLr),e(Br,_Me),e(_Me,HLr),e(Br,ULr),e(Br,gn),e(gn,JLr),e(gn,bMe),e(bMe,YLr),e(gn,KLr),e(gn,vMe),e(vMe,ZLr),e(gn,eyr),e(gn,FMe),e(FMe,oyr),e(gn,ryr),e(Br,tyr),e(Br,ox),e(ox,dC),e(dC,TMe),e(TMe,ayr),e(dC,nyr),e(dC,bY),e(bY,syr),e(dC,lyr),e(ox,iyr),e(ox,cC),e(cC,MMe),e(MMe,dyr),e(cC,cyr),e(cC,vY),e(vY,fyr),e(cC,myr),e(Br,gyr),M(fC,Br,null),b(f,XOe,_),b(f,Lc,_),e(Lc,mC),e(mC,EMe),M(rx,EMe,null),e(Lc,hyr),e(Lc,CMe),e(CMe,pyr),b(f,zOe,_),b(f,ir,_),M(tx,ir,null),e(ir,uyr),e(ir,yc),e(yc,_yr),e(yc,FY),e(FY,byr),e(yc,vyr),e(yc,TY),e(TY,Fyr),e(yc,Tyr),e(ir,Myr),e(ir,ax),e(ax,Eyr),e(ax,wMe),e(wMe,Cyr),e(ax,wyr),e(ir,Ayr),e(ir,jt),M(nx,jt,null),e(jt,Lyr),e(jt,AMe),e(AMe,yyr),e(jt,xyr),e(jt,xc),e(xc,$yr),e(xc,LMe),e(LMe,kyr),e(xc,Syr),e(xc,MY),e(MY,Ryr),e(xc,Pyr),e(jt,Byr),M(gC,jt,null),e(ir,Iyr),e(ir,Ir),M(sx,Ir,null),e(Ir,Nyr),e(Ir,yMe),e(yMe,qyr),e(Ir,jyr),e(Ir,hn),e(hn,Dyr),e(hn,xMe),e(xMe,Gyr),e(hn,Oyr),e(hn,$Me),e($Me,Vyr),e(hn,Xyr),e(hn,kMe),e(kMe,zyr),e(hn,Wyr),e(Ir,Qyr),e(Ir,SMe),e(SMe,hC),e(hC,RMe),e(RMe,Hyr),e(hC,Uyr),e(hC,EY),e(EY,Jyr),e(hC,Yyr),e(Ir,Kyr),M(pC,Ir,null),b(f,WOe,_),b(f,$c,_),e($c,uC),e(uC,PMe),M(lx,PMe,null),e($c,Zyr),e($c,BMe),e(BMe,e8r),b(f,QOe,_),b(f,dr,_),M(ix,dr,null),e(dr,o8r),e(dr,kc),e(kc,r8r),e(kc,CY),e(CY,t8r),e(kc,a8r),e(kc,wY),e(wY,n8r),e(kc,s8r),e(dr,l8r),e(dr,dx),e(dx,i8r),e(dx,IMe),e(IMe,d8r),e(dx,c8r),e(dr,f8r),e(dr,Dt),M(cx,Dt,null),e(Dt,m8r),e(Dt,NMe),e(NMe,g8r),e(Dt,h8r),e(Dt,Sc),e(Sc,p8r),e(Sc,qMe),e(qMe,u8r),e(Sc,_8r),e(Sc,AY),e(AY,b8r),e(Sc,v8r),e(Dt,F8r),M(_C,Dt,null),e(dr,T8r),e(dr,Nr),M(fx,Nr,null),e(Nr,M8r),e(Nr,jMe),e(jMe,E8r),e(Nr,C8r),e(Nr,pn),e(pn,w8r),e(pn,DMe),e(DMe,A8r),e(pn,L8r),e(pn,GMe),e(GMe,y8r),e(pn,x8r),e(pn,OMe),e(OMe,$8r),e(pn,k8r),e(Nr,S8r),e(Nr,de),e(de,bC),e(bC,VMe),e(VMe,R8r),e(bC,P8r),e(bC,LY),e(LY,B8r),e(bC,I8r),e(de,N8r),e(de,vC),e(vC,XMe),e(XMe,q8r),e(vC,j8r),e(vC,yY),e(yY,D8r),e(vC,G8r),e(de,O8r),e(de,FC),e(FC,zMe),e(zMe,V8r),e(FC,X8r),e(FC,xY),e(xY,z8r),e(FC,W8r),e(de,Q8r),e(de,TC),e(TC,WMe),e(WMe,H8r),e(TC,U8r),e(TC,$Y),e($Y,J8r),e(TC,Y8r),e(de,K8r),e(de,MC),e(MC,QMe),e(QMe,Z8r),e(MC,e9r),e(MC,kY),e(kY,o9r),e(MC,r9r),e(de,t9r),e(de,EC),e(EC,HMe),e(HMe,a9r),e(EC,n9r),e(EC,SY),e(SY,s9r),e(EC,l9r),e(de,i9r),e(de,CC),e(CC,UMe),e(UMe,d9r),e(CC,c9r),e(CC,RY),e(RY,f9r),e(CC,m9r),e(de,g9r),e(de,wC),e(wC,JMe),e(JMe,h9r),e(wC,p9r),e(wC,PY),e(PY,u9r),e(wC,_9r),e(de,b9r),e(de,AC),e(AC,YMe),e(YMe,v9r),e(AC,F9r),e(AC,BY),e(BY,T9r),e(AC,M9r),e(de,E9r),e(de,LC),e(LC,KMe),e(KMe,C9r),e(LC,w9r),e(LC,IY),e(IY,A9r),e(LC,L9r),e(de,y9r),e(de,yC),e(yC,ZMe),e(ZMe,x9r),e(yC,$9r),e(yC,NY),e(NY,k9r),e(yC,S9r),e(de,R9r),e(de,xC),e(xC,eEe),e(eEe,P9r),e(xC,B9r),e(xC,qY),e(qY,I9r),e(xC,N9r),e(de,q9r),e(de,$C),e($C,oEe),e(oEe,j9r),e($C,D9r),e($C,jY),e(jY,G9r),e($C,O9r),e(de,V9r),e(de,kC),e(kC,rEe),e(rEe,X9r),e(kC,z9r),e(kC,DY),e(DY,W9r),e(kC,Q9r),e(de,H9r),e(de,SC),e(SC,tEe),e(tEe,U9r),e(SC,J9r),e(SC,GY),e(GY,Y9r),e(SC,K9r),e(de,Z9r),e(de,RC),e(RC,aEe),e(aEe,exr),e(RC,oxr),e(RC,OY),e(OY,rxr),e(RC,txr),e(de,axr),e(de,PC),e(PC,nEe),e(nEe,nxr),e(PC,sxr),e(PC,VY),e(VY,lxr),e(PC,ixr),e(de,dxr),e(de,BC),e(BC,sEe),e(sEe,cxr),e(BC,fxr),e(BC,XY),e(XY,mxr),e(BC,gxr),e(de,hxr),e(de,IC),e(IC,lEe),e(lEe,pxr),e(IC,uxr),e(IC,zY),e(zY,_xr),e(IC,bxr),e(de,vxr),e(de,NC),e(NC,iEe),e(iEe,Fxr),e(NC,Txr),e(NC,WY),e(WY,Mxr),e(NC,Exr),e(Nr,Cxr),M(qC,Nr,null),b(f,HOe,_),b(f,Rc,_),e(Rc,jC),e(jC,dEe),M(mx,dEe,null),e(Rc,wxr),e(Rc,cEe),e(cEe,Axr),b(f,UOe,_),b(f,cr,_),M(gx,cr,null),e(cr,Lxr),e(cr,Pc),e(Pc,yxr),e(Pc,QY),e(QY,xxr),e(Pc,$xr),e(Pc,HY),e(HY,kxr),e(Pc,Sxr),e(cr,Rxr),e(cr,hx),e(hx,Pxr),e(hx,fEe),e(fEe,Bxr),e(hx,Ixr),e(cr,Nxr),e(cr,Gt),M(px,Gt,null),e(Gt,qxr),e(Gt,mEe),e(mEe,jxr),e(Gt,Dxr),e(Gt,Bc),e(Bc,Gxr),e(Bc,gEe),e(gEe,Oxr),e(Bc,Vxr),e(Bc,UY),e(UY,Xxr),e(Bc,zxr),e(Gt,Wxr),M(DC,Gt,null),e(cr,Qxr),e(cr,qr),M(ux,qr,null),e(qr,Hxr),e(qr,hEe),e(hEe,Uxr),e(qr,Jxr),e(qr,un),e(un,Yxr),e(un,pEe),e(pEe,Kxr),e(un,Zxr),e(un,uEe),e(uEe,e$r),e(un,o$r),e(un,_Ee),e(_Ee,r$r),e(un,t$r),e(qr,a$r),e(qr,ce),e(ce,GC),e(GC,bEe),e(bEe,n$r),e(GC,s$r),e(GC,JY),e(JY,l$r),e(GC,i$r),e(ce,d$r),e(ce,OC),e(OC,vEe),e(vEe,c$r),e(OC,f$r),e(OC,YY),e(YY,m$r),e(OC,g$r),e(ce,h$r),e(ce,VC),e(VC,FEe),e(FEe,p$r),e(VC,u$r),e(VC,KY),e(KY,_$r),e(VC,b$r),e(ce,v$r),e(ce,XC),e(XC,TEe),e(TEe,F$r),e(XC,T$r),e(XC,ZY),e(ZY,M$r),e(XC,E$r),e(ce,C$r),e(ce,zC),e(zC,MEe),e(MEe,w$r),e(zC,A$r),e(zC,eK),e(eK,L$r),e(zC,y$r),e(ce,x$r),e(ce,WC),e(WC,EEe),e(EEe,$$r),e(WC,k$r),e(WC,oK),e(oK,S$r),e(WC,R$r),e(ce,P$r),e(ce,QC),e(QC,CEe),e(CEe,B$r),e(QC,I$r),e(QC,rK),e(rK,N$r),e(QC,q$r),e(ce,j$r),e(ce,HC),e(HC,wEe),e(wEe,D$r),e(HC,G$r),e(HC,tK),e(tK,O$r),e(HC,V$r),e(ce,X$r),e(ce,UC),e(UC,AEe),e(AEe,z$r),e(UC,W$r),e(UC,aK),e(aK,Q$r),e(UC,H$r),e(ce,U$r),e(ce,JC),e(JC,LEe),e(LEe,J$r),e(JC,Y$r),e(JC,nK),e(nK,K$r),e(JC,Z$r),e(ce,ekr),e(ce,YC),e(YC,yEe),e(yEe,okr),e(YC,rkr),e(YC,sK),e(sK,tkr),e(YC,akr),e(ce,nkr),e(ce,KC),e(KC,xEe),e(xEe,skr),e(KC,lkr),e(KC,lK),e(lK,ikr),e(KC,dkr),e(ce,ckr),e(ce,ZC),e(ZC,$Ee),e($Ee,fkr),e(ZC,mkr),e(ZC,iK),e(iK,gkr),e(ZC,hkr),e(ce,pkr),e(ce,e5),e(e5,kEe),e(kEe,ukr),e(e5,_kr),e(e5,dK),e(dK,bkr),e(e5,vkr),e(ce,Fkr),e(ce,o5),e(o5,SEe),e(SEe,Tkr),e(o5,Mkr),e(o5,cK),e(cK,Ekr),e(o5,Ckr),e(ce,wkr),e(ce,r5),e(r5,REe),e(REe,Akr),e(r5,Lkr),e(r5,fK),e(fK,ykr),e(r5,xkr),e(ce,$kr),e(ce,t5),e(t5,PEe),e(PEe,kkr),e(t5,Skr),e(t5,mK),e(mK,Rkr),e(t5,Pkr),e(ce,Bkr),e(ce,a5),e(a5,BEe),e(BEe,Ikr),e(a5,Nkr),e(a5,gK),e(gK,qkr),e(a5,jkr),e(ce,Dkr),e(ce,n5),e(n5,IEe),e(IEe,Gkr),e(n5,Okr),e(n5,hK),e(hK,Vkr),e(n5,Xkr),e(ce,zkr),e(ce,s5),e(s5,NEe),e(NEe,Wkr),e(s5,Qkr),e(s5,pK),e(pK,Hkr),e(s5,Ukr),e(qr,Jkr),M(l5,qr,null),b(f,JOe,_),b(f,Ic,_),e(Ic,i5),e(i5,qEe),M(_x,qEe,null),e(Ic,Ykr),e(Ic,jEe),e(jEe,Kkr),b(f,YOe,_),b(f,fr,_),M(bx,fr,null),e(fr,Zkr),e(fr,Nc),e(Nc,eSr),e(Nc,uK),e(uK,oSr),e(Nc,rSr),e(Nc,_K),e(_K,tSr),e(Nc,aSr),e(fr,nSr),e(fr,vx),e(vx,sSr),e(vx,DEe),e(DEe,lSr),e(vx,iSr),e(fr,dSr),e(fr,Ot),M(Fx,Ot,null),e(Ot,cSr),e(Ot,GEe),e(GEe,fSr),e(Ot,mSr),e(Ot,qc),e(qc,gSr),e(qc,OEe),e(OEe,hSr),e(qc,pSr),e(qc,bK),e(bK,uSr),e(qc,_Sr),e(Ot,bSr),M(d5,Ot,null),e(fr,vSr),e(fr,jr),M(Tx,jr,null),e(jr,FSr),e(jr,VEe),e(VEe,TSr),e(jr,MSr),e(jr,_n),e(_n,ESr),e(_n,XEe),e(XEe,CSr),e(_n,wSr),e(_n,zEe),e(zEe,ASr),e(_n,LSr),e(_n,WEe),e(WEe,ySr),e(_n,xSr),e(jr,$Sr),e(jr,QEe),e(QEe,c5),e(c5,HEe),e(HEe,kSr),e(c5,SSr),e(c5,vK),e(vK,RSr),e(c5,PSr),e(jr,BSr),M(f5,jr,null),b(f,KOe,_),b(f,jc,_),e(jc,m5),e(m5,UEe),M(Mx,UEe,null),e(jc,ISr),e(jc,JEe),e(JEe,NSr),b(f,ZOe,_),b(f,mr,_),M(Ex,mr,null),e(mr,qSr),e(mr,Dc),e(Dc,jSr),e(Dc,FK),e(FK,DSr),e(Dc,GSr),e(Dc,TK),e(TK,OSr),e(Dc,VSr),e(mr,XSr),e(mr,Cx),e(Cx,zSr),e(Cx,YEe),e(YEe,WSr),e(Cx,QSr),e(mr,HSr),e(mr,Vt),M(wx,Vt,null),e(Vt,USr),e(Vt,KEe),e(KEe,JSr),e(Vt,YSr),e(Vt,Gc),e(Gc,KSr),e(Gc,ZEe),e(ZEe,ZSr),e(Gc,eRr),e(Gc,MK),e(MK,oRr),e(Gc,rRr),e(Vt,tRr),M(g5,Vt,null),e(mr,aRr),e(mr,Dr),M(Ax,Dr,null),e(Dr,nRr),e(Dr,e4e),e(e4e,sRr),e(Dr,lRr),e(Dr,bn),e(bn,iRr),e(bn,o4e),e(o4e,dRr),e(bn,cRr),e(bn,r4e),e(r4e,fRr),e(bn,mRr),e(bn,t4e),e(t4e,gRr),e(bn,hRr),e(Dr,pRr),e(Dr,a4e),e(a4e,h5),e(h5,n4e),e(n4e,uRr),e(h5,_Rr),e(h5,EK),e(EK,bRr),e(h5,vRr),e(Dr,FRr),M(p5,Dr,null),b(f,eVe,_),b(f,Oc,_),e(Oc,u5),e(u5,s4e),M(Lx,s4e,null),e(Oc,TRr),e(Oc,l4e),e(l4e,MRr),b(f,oVe,_),b(f,gr,_),M(yx,gr,null),e(gr,ERr),e(gr,Vc),e(Vc,CRr),e(Vc,CK),e(CK,wRr),e(Vc,ARr),e(Vc,wK),e(wK,LRr),e(Vc,yRr),e(gr,xRr),e(gr,xx),e(xx,$Rr),e(xx,i4e),e(i4e,kRr),e(xx,SRr),e(gr,RRr),e(gr,Xt),M($x,Xt,null),e(Xt,PRr),e(Xt,d4e),e(d4e,BRr),e(Xt,IRr),e(Xt,Xc),e(Xc,NRr),e(Xc,c4e),e(c4e,qRr),e(Xc,jRr),e(Xc,AK),e(AK,DRr),e(Xc,GRr),e(Xt,ORr),M(_5,Xt,null),e(gr,VRr),e(gr,Gr),M(kx,Gr,null),e(Gr,XRr),e(Gr,f4e),e(f4e,zRr),e(Gr,WRr),e(Gr,vn),e(vn,QRr),e(vn,m4e),e(m4e,HRr),e(vn,URr),e(vn,g4e),e(g4e,JRr),e(vn,YRr),e(vn,h4e),e(h4e,KRr),e(vn,ZRr),e(Gr,ePr),e(Gr,oe),e(oe,b5),e(b5,p4e),e(p4e,oPr),e(b5,rPr),e(b5,LK),e(LK,tPr),e(b5,aPr),e(oe,nPr),e(oe,v5),e(v5,u4e),e(u4e,sPr),e(v5,lPr),e(v5,yK),e(yK,iPr),e(v5,dPr),e(oe,cPr),e(oe,F5),e(F5,_4e),e(_4e,fPr),e(F5,mPr),e(F5,xK),e(xK,gPr),e(F5,hPr),e(oe,pPr),e(oe,T5),e(T5,b4e),e(b4e,uPr),e(T5,_Pr),e(T5,$K),e($K,bPr),e(T5,vPr),e(oe,FPr),e(oe,M5),e(M5,v4e),e(v4e,TPr),e(M5,MPr),e(M5,kK),e(kK,EPr),e(M5,CPr),e(oe,wPr),e(oe,E5),e(E5,F4e),e(F4e,APr),e(E5,LPr),e(E5,SK),e(SK,yPr),e(E5,xPr),e(oe,$Pr),e(oe,C5),e(C5,T4e),e(T4e,kPr),e(C5,SPr),e(C5,RK),e(RK,RPr),e(C5,PPr),e(oe,BPr),e(oe,w5),e(w5,M4e),e(M4e,IPr),e(w5,NPr),e(w5,PK),e(PK,qPr),e(w5,jPr),e(oe,DPr),e(oe,A5),e(A5,E4e),e(E4e,GPr),e(A5,OPr),e(A5,BK),e(BK,VPr),e(A5,XPr),e(oe,zPr),e(oe,L5),e(L5,C4e),e(C4e,WPr),e(L5,QPr),e(L5,IK),e(IK,HPr),e(L5,UPr),e(oe,JPr),e(oe,y5),e(y5,w4e),e(w4e,YPr),e(y5,KPr),e(y5,NK),e(NK,ZPr),e(y5,eBr),e(oe,oBr),e(oe,x5),e(x5,A4e),e(A4e,rBr),e(x5,tBr),e(x5,qK),e(qK,aBr),e(x5,nBr),e(oe,sBr),e(oe,$5),e($5,L4e),e(L4e,lBr),e($5,iBr),e($5,jK),e(jK,dBr),e($5,cBr),e(oe,fBr),e(oe,k5),e(k5,y4e),e(y4e,mBr),e(k5,gBr),e(k5,DK),e(DK,hBr),e(k5,pBr),e(oe,uBr),e(oe,S5),e(S5,x4e),e(x4e,_Br),e(S5,bBr),e(S5,GK),e(GK,vBr),e(S5,FBr),e(oe,TBr),e(oe,R5),e(R5,$4e),e($4e,MBr),e(R5,EBr),e(R5,OK),e(OK,CBr),e(R5,wBr),e(oe,ABr),e(oe,P5),e(P5,k4e),e(k4e,LBr),e(P5,yBr),e(P5,VK),e(VK,xBr),e(P5,$Br),e(oe,kBr),e(oe,B5),e(B5,S4e),e(S4e,SBr),e(B5,RBr),e(B5,XK),e(XK,PBr),e(B5,BBr),e(oe,IBr),e(oe,I5),e(I5,R4e),e(R4e,NBr),e(I5,qBr),e(I5,zK),e(zK,jBr),e(I5,DBr),e(oe,GBr),e(oe,N5),e(N5,P4e),e(P4e,OBr),e(N5,VBr),e(N5,WK),e(WK,XBr),e(N5,zBr),e(oe,WBr),e(oe,q5),e(q5,B4e),e(B4e,QBr),e(q5,HBr),e(q5,QK),e(QK,UBr),e(q5,JBr),e(oe,YBr),e(oe,j5),e(j5,I4e),e(I4e,KBr),e(j5,ZBr),e(j5,HK),e(HK,eIr),e(j5,oIr),e(oe,rIr),e(oe,D5),e(D5,N4e),e(N4e,tIr),e(D5,aIr),e(D5,UK),e(UK,nIr),e(D5,sIr),e(oe,lIr),e(oe,G5),e(G5,q4e),e(q4e,iIr),e(G5,dIr),e(G5,JK),e(JK,cIr),e(G5,fIr),e(oe,mIr),e(oe,O5),e(O5,j4e),e(j4e,gIr),e(O5,hIr),e(O5,YK),e(YK,pIr),e(O5,uIr),e(oe,_Ir),e(oe,V5),e(V5,D4e),e(D4e,bIr),e(V5,vIr),e(V5,KK),e(KK,FIr),e(V5,TIr),e(oe,MIr),e(oe,X5),e(X5,G4e),e(G4e,EIr),e(X5,CIr),e(X5,ZK),e(ZK,wIr),e(X5,AIr),e(Gr,LIr),M(z5,Gr,null),b(f,rVe,_),b(f,zc,_),e(zc,W5),e(W5,O4e),M(Sx,O4e,null),e(zc,yIr),e(zc,V4e),e(V4e,xIr),b(f,tVe,_),b(f,hr,_),M(Rx,hr,null),e(hr,$Ir),e(hr,Wc),e(Wc,kIr),e(Wc,eZ),e(eZ,SIr),e(Wc,RIr),e(Wc,oZ),e(oZ,PIr),e(Wc,BIr),e(hr,IIr),e(hr,Px),e(Px,NIr),e(Px,X4e),e(X4e,qIr),e(Px,jIr),e(hr,DIr),e(hr,zt),M(Bx,zt,null),e(zt,GIr),e(zt,z4e),e(z4e,OIr),e(zt,VIr),e(zt,Qc),e(Qc,XIr),e(Qc,W4e),e(W4e,zIr),e(Qc,WIr),e(Qc,rZ),e(rZ,QIr),e(Qc,HIr),e(zt,UIr),M(Q5,zt,null),e(hr,JIr),e(hr,Or),M(Ix,Or,null),e(Or,YIr),e(Or,Q4e),e(Q4e,KIr),e(Or,ZIr),e(Or,Fn),e(Fn,eNr),e(Fn,H4e),e(H4e,oNr),e(Fn,rNr),e(Fn,U4e),e(U4e,tNr),e(Fn,aNr),e(Fn,J4e),e(J4e,nNr),e(Fn,sNr),e(Or,lNr),e(Or,xe),e(xe,H5),e(H5,Y4e),e(Y4e,iNr),e(H5,dNr),e(H5,tZ),e(tZ,cNr),e(H5,fNr),e(xe,mNr),e(xe,U5),e(U5,K4e),e(K4e,gNr),e(U5,hNr),e(U5,aZ),e(aZ,pNr),e(U5,uNr),e(xe,_Nr),e(xe,J5),e(J5,Z4e),e(Z4e,bNr),e(J5,vNr),e(J5,nZ),e(nZ,FNr),e(J5,TNr),e(xe,MNr),e(xe,Y5),e(Y5,eCe),e(eCe,ENr),e(Y5,CNr),e(Y5,sZ),e(sZ,wNr),e(Y5,ANr),e(xe,LNr),e(xe,K5),e(K5,oCe),e(oCe,yNr),e(K5,xNr),e(K5,lZ),e(lZ,$Nr),e(K5,kNr),e(xe,SNr),e(xe,Z5),e(Z5,rCe),e(rCe,RNr),e(Z5,PNr),e(Z5,iZ),e(iZ,BNr),e(Z5,INr),e(xe,NNr),e(xe,e0),e(e0,tCe),e(tCe,qNr),e(e0,jNr),e(e0,dZ),e(dZ,DNr),e(e0,GNr),e(xe,ONr),e(xe,o0),e(o0,aCe),e(aCe,VNr),e(o0,XNr),e(o0,cZ),e(cZ,zNr),e(o0,WNr),e(xe,QNr),e(xe,r0),e(r0,nCe),e(nCe,HNr),e(r0,UNr),e(r0,fZ),e(fZ,JNr),e(r0,YNr),e(xe,KNr),e(xe,t0),e(t0,sCe),e(sCe,ZNr),e(t0,eqr),e(t0,mZ),e(mZ,oqr),e(t0,rqr),e(Or,tqr),M(a0,Or,null),b(f,aVe,_),b(f,Hc,_),e(Hc,n0),e(n0,lCe),M(Nx,lCe,null),e(Hc,aqr),e(Hc,iCe),e(iCe,nqr),b(f,nVe,_),b(f,pr,_),M(qx,pr,null),e(pr,sqr),e(pr,Uc),e(Uc,lqr),e(Uc,gZ),e(gZ,iqr),e(Uc,dqr),e(Uc,hZ),e(hZ,cqr),e(Uc,fqr),e(pr,mqr),e(pr,jx),e(jx,gqr),e(jx,dCe),e(dCe,hqr),e(jx,pqr),e(pr,uqr),e(pr,Wt),M(Dx,Wt,null),e(Wt,_qr),e(Wt,cCe),e(cCe,bqr),e(Wt,vqr),e(Wt,Jc),e(Jc,Fqr),e(Jc,fCe),e(fCe,Tqr),e(Jc,Mqr),e(Jc,pZ),e(pZ,Eqr),e(Jc,Cqr),e(Wt,wqr),M(s0,Wt,null),e(pr,Aqr),e(pr,Vr),M(Gx,Vr,null),e(Vr,Lqr),e(Vr,mCe),e(mCe,yqr),e(Vr,xqr),e(Vr,Tn),e(Tn,$qr),e(Tn,gCe),e(gCe,kqr),e(Tn,Sqr),e(Tn,hCe),e(hCe,Rqr),e(Tn,Pqr),e(Tn,pCe),e(pCe,Bqr),e(Tn,Iqr),e(Vr,Nqr),e(Vr,Ee),e(Ee,l0),e(l0,uCe),e(uCe,qqr),e(l0,jqr),e(l0,uZ),e(uZ,Dqr),e(l0,Gqr),e(Ee,Oqr),e(Ee,i0),e(i0,_Ce),e(_Ce,Vqr),e(i0,Xqr),e(i0,_Z),e(_Z,zqr),e(i0,Wqr),e(Ee,Qqr),e(Ee,d0),e(d0,bCe),e(bCe,Hqr),e(d0,Uqr),e(d0,bZ),e(bZ,Jqr),e(d0,Yqr),e(Ee,Kqr),e(Ee,c0),e(c0,vCe),e(vCe,Zqr),e(c0,ejr),e(c0,vZ),e(vZ,ojr),e(c0,rjr),e(Ee,tjr),e(Ee,f0),e(f0,FCe),e(FCe,ajr),e(f0,njr),e(f0,FZ),e(FZ,sjr),e(f0,ljr),e(Ee,ijr),e(Ee,m0),e(m0,TCe),e(TCe,djr),e(m0,cjr),e(m0,TZ),e(TZ,fjr),e(m0,mjr),e(Ee,gjr),e(Ee,g0),e(g0,MCe),e(MCe,hjr),e(g0,pjr),e(g0,MZ),e(MZ,ujr),e(g0,_jr),e(Ee,bjr),e(Ee,h0),e(h0,ECe),e(ECe,vjr),e(h0,Fjr),e(h0,EZ),e(EZ,Tjr),e(h0,Mjr),e(Ee,Ejr),e(Ee,p0),e(p0,CCe),e(CCe,Cjr),e(p0,wjr),e(p0,CZ),e(CZ,Ajr),e(p0,Ljr),e(Ee,yjr),e(Ee,u0),e(u0,wCe),e(wCe,xjr),e(u0,$jr),e(u0,wZ),e(wZ,kjr),e(u0,Sjr),e(Ee,Rjr),e(Ee,_0),e(_0,ACe),e(ACe,Pjr),e(_0,Bjr),e(_0,AZ),e(AZ,Ijr),e(_0,Njr),e(Ee,qjr),e(Ee,b0),e(b0,LCe),e(LCe,jjr),e(b0,Djr),e(b0,LZ),e(LZ,Gjr),e(b0,Ojr),e(Ee,Vjr),e(Ee,v0),e(v0,yCe),e(yCe,Xjr),e(v0,zjr),e(v0,yZ),e(yZ,Wjr),e(v0,Qjr),e(Vr,Hjr),M(F0,Vr,null),b(f,sVe,_),b(f,Yc,_),e(Yc,T0),e(T0,xCe),M(Ox,xCe,null),e(Yc,Ujr),e(Yc,$Ce),e($Ce,Jjr),b(f,lVe,_),b(f,ur,_),M(Vx,ur,null),e(ur,Yjr),e(ur,Kc),e(Kc,Kjr),e(Kc,xZ),e(xZ,Zjr),e(Kc,eDr),e(Kc,$Z),e($Z,oDr),e(Kc,rDr),e(ur,tDr),e(ur,Xx),e(Xx,aDr),e(Xx,kCe),e(kCe,nDr),e(Xx,sDr),e(ur,lDr),e(ur,Qt),M(zx,Qt,null),e(Qt,iDr),e(Qt,SCe),e(SCe,dDr),e(Qt,cDr),e(Qt,Zc),e(Zc,fDr),e(Zc,RCe),e(RCe,mDr),e(Zc,gDr),e(Zc,kZ),e(kZ,hDr),e(Zc,pDr),e(Qt,uDr),M(M0,Qt,null),e(ur,_Dr),e(ur,Xr),M(Wx,Xr,null),e(Xr,bDr),e(Xr,PCe),e(PCe,vDr),e(Xr,FDr),e(Xr,Mn),e(Mn,TDr),e(Mn,BCe),e(BCe,MDr),e(Mn,EDr),e(Mn,ICe),e(ICe,CDr),e(Mn,wDr),e(Mn,NCe),e(NCe,ADr),e(Mn,LDr),e(Xr,yDr),e(Xr,$e),e($e,E0),e(E0,qCe),e(qCe,xDr),e(E0,$Dr),e(E0,SZ),e(SZ,kDr),e(E0,SDr),e($e,RDr),e($e,C0),e(C0,jCe),e(jCe,PDr),e(C0,BDr),e(C0,RZ),e(RZ,IDr),e(C0,NDr),e($e,qDr),e($e,w0),e(w0,DCe),e(DCe,jDr),e(w0,DDr),e(w0,PZ),e(PZ,GDr),e(w0,ODr),e($e,VDr),e($e,A0),e(A0,GCe),e(GCe,XDr),e(A0,zDr),e(A0,BZ),e(BZ,WDr),e(A0,QDr),e($e,HDr),e($e,L0),e(L0,OCe),e(OCe,UDr),e(L0,JDr),e(L0,IZ),e(IZ,YDr),e(L0,KDr),e($e,ZDr),e($e,y0),e(y0,VCe),e(VCe,eGr),e(y0,oGr),e(y0,NZ),e(NZ,rGr),e(y0,tGr),e($e,aGr),e($e,x0),e(x0,XCe),e(XCe,nGr),e(x0,sGr),e(x0,qZ),e(qZ,lGr),e(x0,iGr),e($e,dGr),e($e,$0),e($0,zCe),e(zCe,cGr),e($0,fGr),e($0,jZ),e(jZ,mGr),e($0,gGr),e($e,hGr),e($e,k0),e(k0,WCe),e(WCe,pGr),e(k0,uGr),e(k0,DZ),e(DZ,_Gr),e(k0,bGr),e($e,vGr),e($e,S0),e(S0,QCe),e(QCe,FGr),e(S0,TGr),e(S0,GZ),e(GZ,MGr),e(S0,EGr),e(Xr,CGr),M(R0,Xr,null),b(f,iVe,_),b(f,ef,_),e(ef,P0),e(P0,HCe),M(Qx,HCe,null),e(ef,wGr),e(ef,UCe),e(UCe,AGr),b(f,dVe,_),b(f,_r,_),M(Hx,_r,null),e(_r,LGr),e(_r,of),e(of,yGr),e(of,OZ),e(OZ,xGr),e(of,$Gr),e(of,VZ),e(VZ,kGr),e(of,SGr),e(_r,RGr),e(_r,Ux),e(Ux,PGr),e(Ux,JCe),e(JCe,BGr),e(Ux,IGr),e(_r,NGr),e(_r,Ht),M(Jx,Ht,null),e(Ht,qGr),e(Ht,YCe),e(YCe,jGr),e(Ht,DGr),e(Ht,rf),e(rf,GGr),e(rf,KCe),e(KCe,OGr),e(rf,VGr),e(rf,XZ),e(XZ,XGr),e(rf,zGr),e(Ht,WGr),M(B0,Ht,null),e(_r,QGr),e(_r,zr),M(Yx,zr,null),e(zr,HGr),e(zr,ZCe),e(ZCe,UGr),e(zr,JGr),e(zr,En),e(En,YGr),e(En,e5e),e(e5e,KGr),e(En,ZGr),e(En,o5e),e(o5e,eOr),e(En,oOr),e(En,r5e),e(r5e,rOr),e(En,tOr),e(zr,aOr),e(zr,ke),e(ke,I0),e(I0,t5e),e(t5e,nOr),e(I0,sOr),e(I0,zZ),e(zZ,lOr),e(I0,iOr),e(ke,dOr),e(ke,N0),e(N0,a5e),e(a5e,cOr),e(N0,fOr),e(N0,WZ),e(WZ,mOr),e(N0,gOr),e(ke,hOr),e(ke,q0),e(q0,n5e),e(n5e,pOr),e(q0,uOr),e(q0,QZ),e(QZ,_Or),e(q0,bOr),e(ke,vOr),e(ke,j0),e(j0,s5e),e(s5e,FOr),e(j0,TOr),e(j0,HZ),e(HZ,MOr),e(j0,EOr),e(ke,COr),e(ke,D0),e(D0,l5e),e(l5e,wOr),e(D0,AOr),e(D0,UZ),e(UZ,LOr),e(D0,yOr),e(ke,xOr),e(ke,G0),e(G0,i5e),e(i5e,$Or),e(G0,kOr),e(G0,JZ),e(JZ,SOr),e(G0,ROr),e(ke,POr),e(ke,O0),e(O0,d5e),e(d5e,BOr),e(O0,IOr),e(O0,YZ),e(YZ,NOr),e(O0,qOr),e(ke,jOr),e(ke,V0),e(V0,c5e),e(c5e,DOr),e(V0,GOr),e(V0,KZ),e(KZ,OOr),e(V0,VOr),e(ke,XOr),e(ke,X0),e(X0,f5e),e(f5e,zOr),e(X0,WOr),e(X0,ZZ),e(ZZ,QOr),e(X0,HOr),e(ke,UOr),e(ke,z0),e(z0,m5e),e(m5e,JOr),e(z0,YOr),e(z0,eee),e(eee,KOr),e(z0,ZOr),e(zr,eVr),M(W0,zr,null),b(f,cVe,_),b(f,tf,_),e(tf,Q0),e(Q0,g5e),M(Kx,g5e,null),e(tf,oVr),e(tf,h5e),e(h5e,rVr),b(f,fVe,_),b(f,br,_),M(Zx,br,null),e(br,tVr),e(br,af),e(af,aVr),e(af,oee),e(oee,nVr),e(af,sVr),e(af,ree),e(ree,lVr),e(af,iVr),e(br,dVr),e(br,e$),e(e$,cVr),e(e$,p5e),e(p5e,fVr),e(e$,mVr),e(br,gVr),e(br,Ut),M(o$,Ut,null),e(Ut,hVr),e(Ut,u5e),e(u5e,pVr),e(Ut,uVr),e(Ut,nf),e(nf,_Vr),e(nf,_5e),e(_5e,bVr),e(nf,vVr),e(nf,tee),e(tee,FVr),e(nf,TVr),e(Ut,MVr),M(H0,Ut,null),e(br,EVr),e(br,Wr),M(r$,Wr,null),e(Wr,CVr),e(Wr,b5e),e(b5e,wVr),e(Wr,AVr),e(Wr,Cn),e(Cn,LVr),e(Cn,v5e),e(v5e,yVr),e(Cn,xVr),e(Cn,F5e),e(F5e,$Vr),e(Cn,kVr),e(Cn,T5e),e(T5e,SVr),e(Cn,RVr),e(Wr,PVr),e(Wr,Se),e(Se,U0),e(U0,M5e),e(M5e,BVr),e(U0,IVr),e(U0,aee),e(aee,NVr),e(U0,qVr),e(Se,jVr),e(Se,J0),e(J0,E5e),e(E5e,DVr),e(J0,GVr),e(J0,nee),e(nee,OVr),e(J0,VVr),e(Se,XVr),e(Se,Y0),e(Y0,C5e),e(C5e,zVr),e(Y0,WVr),e(Y0,see),e(see,QVr),e(Y0,HVr),e(Se,UVr),e(Se,K0),e(K0,w5e),e(w5e,JVr),e(K0,YVr),e(K0,lee),e(lee,KVr),e(K0,ZVr),e(Se,eXr),e(Se,Z0),e(Z0,A5e),e(A5e,oXr),e(Z0,rXr),e(Z0,iee),e(iee,tXr),e(Z0,aXr),e(Se,nXr),e(Se,ew),e(ew,L5e),e(L5e,sXr),e(ew,lXr),e(ew,dee),e(dee,iXr),e(ew,dXr),e(Se,cXr),e(Se,ow),e(ow,y5e),e(y5e,fXr),e(ow,mXr),e(ow,cee),e(cee,gXr),e(ow,hXr),e(Se,pXr),e(Se,rw),e(rw,x5e),e(x5e,uXr),e(rw,_Xr),e(rw,fee),e(fee,bXr),e(rw,vXr),e(Se,FXr),e(Se,tw),e(tw,$5e),e($5e,TXr),e(tw,MXr),e(tw,mee),e(mee,EXr),e(tw,CXr),e(Se,wXr),e(Se,aw),e(aw,k5e),e(k5e,AXr),e(aw,LXr),e(aw,gee),e(gee,yXr),e(aw,xXr),e(Wr,$Xr),M(nw,Wr,null),b(f,mVe,_),b(f,sf,_),e(sf,sw),e(sw,S5e),M(t$,S5e,null),e(sf,kXr),e(sf,R5e),e(R5e,SXr),b(f,gVe,_),b(f,vr,_),M(a$,vr,null),e(vr,RXr),e(vr,lf),e(lf,PXr),e(lf,hee),e(hee,BXr),e(lf,IXr),e(lf,pee),e(pee,NXr),e(lf,qXr),e(vr,jXr),e(vr,n$),e(n$,DXr),e(n$,P5e),e(P5e,GXr),e(n$,OXr),e(vr,VXr),e(vr,Jt),M(s$,Jt,null),e(Jt,XXr),e(Jt,B5e),e(B5e,zXr),e(Jt,WXr),e(Jt,df),e(df,QXr),e(df,I5e),e(I5e,HXr),e(df,UXr),e(df,uee),e(uee,JXr),e(df,YXr),e(Jt,KXr),M(lw,Jt,null),e(vr,ZXr),e(vr,Qr),M(l$,Qr,null),e(Qr,ezr),e(Qr,N5e),e(N5e,ozr),e(Qr,rzr),e(Qr,wn),e(wn,tzr),e(wn,q5e),e(q5e,azr),e(wn,nzr),e(wn,j5e),e(j5e,szr),e(wn,lzr),e(wn,D5e),e(D5e,izr),e(wn,dzr),e(Qr,czr),e(Qr,Re),e(Re,iw),e(iw,G5e),e(G5e,fzr),e(iw,mzr),e(iw,_ee),e(_ee,gzr),e(iw,hzr),e(Re,pzr),e(Re,dw),e(dw,O5e),e(O5e,uzr),e(dw,_zr),e(dw,bee),e(bee,bzr),e(dw,vzr),e(Re,Fzr),e(Re,cw),e(cw,V5e),e(V5e,Tzr),e(cw,Mzr),e(cw,vee),e(vee,Ezr),e(cw,Czr),e(Re,wzr),e(Re,fw),e(fw,X5e),e(X5e,Azr),e(fw,Lzr),e(fw,Fee),e(Fee,yzr),e(fw,xzr),e(Re,$zr),e(Re,mw),e(mw,z5e),e(z5e,kzr),e(mw,Szr),e(mw,Tee),e(Tee,Rzr),e(mw,Pzr),e(Re,Bzr),e(Re,gw),e(gw,W5e),e(W5e,Izr),e(gw,Nzr),e(gw,Mee),e(Mee,qzr),e(gw,jzr),e(Re,Dzr),e(Re,hw),e(hw,Q5e),e(Q5e,Gzr),e(hw,Ozr),e(hw,Eee),e(Eee,Vzr),e(hw,Xzr),e(Re,zzr),e(Re,pw),e(pw,H5e),e(H5e,Wzr),e(pw,Qzr),e(pw,Cee),e(Cee,Hzr),e(pw,Uzr),e(Re,Jzr),e(Re,uw),e(uw,U5e),e(U5e,Yzr),e(uw,Kzr),e(uw,wee),e(wee,Zzr),e(uw,eWr),e(Re,oWr),e(Re,_w),e(_w,J5e),e(J5e,rWr),e(_w,tWr),e(_w,Aee),e(Aee,aWr),e(_w,nWr),e(Qr,sWr),M(bw,Qr,null),b(f,hVe,_),b(f,cf,_),e(cf,vw),e(vw,Y5e),M(i$,Y5e,null),e(cf,lWr),e(cf,K5e),e(K5e,iWr),b(f,pVe,_),b(f,Fr,_),M(d$,Fr,null),e(Fr,dWr),e(Fr,ff),e(ff,cWr),e(ff,Lee),e(Lee,fWr),e(ff,mWr),e(ff,yee),e(yee,gWr),e(ff,hWr),e(Fr,pWr),e(Fr,c$),e(c$,uWr),e(c$,Z5e),e(Z5e,_Wr),e(c$,bWr),e(Fr,vWr),e(Fr,Yt),M(f$,Yt,null),e(Yt,FWr),e(Yt,e0e),e(e0e,TWr),e(Yt,MWr),e(Yt,mf),e(mf,EWr),e(mf,o0e),e(o0e,CWr),e(mf,wWr),e(mf,xee),e(xee,AWr),e(mf,LWr),e(Yt,yWr),M(Fw,Yt,null),e(Fr,xWr),e(Fr,Hr),M(m$,Hr,null),e(Hr,$Wr),e(Hr,r0e),e(r0e,kWr),e(Hr,SWr),e(Hr,An),e(An,RWr),e(An,t0e),e(t0e,PWr),e(An,BWr),e(An,a0e),e(a0e,IWr),e(An,NWr),e(An,n0e),e(n0e,qWr),e(An,jWr),e(Hr,DWr),e(Hr,Ve),e(Ve,Tw),e(Tw,s0e),e(s0e,GWr),e(Tw,OWr),e(Tw,$ee),e($ee,VWr),e(Tw,XWr),e(Ve,zWr),e(Ve,Mw),e(Mw,l0e),e(l0e,WWr),e(Mw,QWr),e(Mw,kee),e(kee,HWr),e(Mw,UWr),e(Ve,JWr),e(Ve,Ew),e(Ew,i0e),e(i0e,YWr),e(Ew,KWr),e(Ew,See),e(See,ZWr),e(Ew,eQr),e(Ve,oQr),e(Ve,Cw),e(Cw,d0e),e(d0e,rQr),e(Cw,tQr),e(Cw,Ree),e(Ree,aQr),e(Cw,nQr),e(Ve,sQr),e(Ve,ww),e(ww,c0e),e(c0e,lQr),e(ww,iQr),e(ww,Pee),e(Pee,dQr),e(ww,cQr),e(Ve,fQr),e(Ve,Aw),e(Aw,f0e),e(f0e,mQr),e(Aw,gQr),e(Aw,Bee),e(Bee,hQr),e(Aw,pQr),e(Ve,uQr),e(Ve,Lw),e(Lw,m0e),e(m0e,_Qr),e(Lw,bQr),e(Lw,Iee),e(Iee,vQr),e(Lw,FQr),e(Ve,TQr),e(Ve,yw),e(yw,g0e),e(g0e,MQr),e(yw,EQr),e(yw,Nee),e(Nee,CQr),e(yw,wQr),e(Hr,AQr),M(xw,Hr,null),b(f,uVe,_),b(f,gf,_),e(gf,$w),e($w,h0e),M(g$,h0e,null),e(gf,LQr),e(gf,p0e),e(p0e,yQr),b(f,_Ve,_),b(f,Tr,_),M(h$,Tr,null),e(Tr,xQr),e(Tr,hf),e(hf,$Qr),e(hf,qee),e(qee,kQr),e(hf,SQr),e(hf,jee),e(jee,RQr),e(hf,PQr),e(Tr,BQr),e(Tr,p$),e(p$,IQr),e(p$,u0e),e(u0e,NQr),e(p$,qQr),e(Tr,jQr),e(Tr,Kt),M(u$,Kt,null),e(Kt,DQr),e(Kt,_0e),e(_0e,GQr),e(Kt,OQr),e(Kt,pf),e(pf,VQr),e(pf,b0e),e(b0e,XQr),e(pf,zQr),e(pf,Dee),e(Dee,WQr),e(pf,QQr),e(Kt,HQr),M(kw,Kt,null),e(Tr,UQr),e(Tr,Ur),M(_$,Ur,null),e(Ur,JQr),e(Ur,v0e),e(v0e,YQr),e(Ur,KQr),e(Ur,Ln),e(Ln,ZQr),e(Ln,F0e),e(F0e,eHr),e(Ln,oHr),e(Ln,T0e),e(T0e,rHr),e(Ln,tHr),e(Ln,M0e),e(M0e,aHr),e(Ln,nHr),e(Ur,sHr),e(Ur,Xe),e(Xe,Sw),e(Sw,E0e),e(E0e,lHr),e(Sw,iHr),e(Sw,Gee),e(Gee,dHr),e(Sw,cHr),e(Xe,fHr),e(Xe,Rw),e(Rw,C0e),e(C0e,mHr),e(Rw,gHr),e(Rw,Oee),e(Oee,hHr),e(Rw,pHr),e(Xe,uHr),e(Xe,Pw),e(Pw,w0e),e(w0e,_Hr),e(Pw,bHr),e(Pw,Vee),e(Vee,vHr),e(Pw,FHr),e(Xe,THr),e(Xe,Bw),e(Bw,A0e),e(A0e,MHr),e(Bw,EHr),e(Bw,Xee),e(Xee,CHr),e(Bw,wHr),e(Xe,AHr),e(Xe,Iw),e(Iw,L0e),e(L0e,LHr),e(Iw,yHr),e(Iw,zee),e(zee,xHr),e(Iw,$Hr),e(Xe,kHr),e(Xe,Nw),e(Nw,y0e),e(y0e,SHr),e(Nw,RHr),e(Nw,Wee),e(Wee,PHr),e(Nw,BHr),e(Xe,IHr),e(Xe,qw),e(qw,x0e),e(x0e,NHr),e(qw,qHr),e(qw,Qee),e(Qee,jHr),e(qw,DHr),e(Xe,GHr),e(Xe,jw),e(jw,$0e),e($0e,OHr),e(jw,VHr),e(jw,Hee),e(Hee,XHr),e(jw,zHr),e(Ur,WHr),M(Dw,Ur,null),b(f,bVe,_),b(f,uf,_),e(uf,Gw),e(Gw,k0e),M(b$,k0e,null),e(uf,QHr),e(uf,S0e),e(S0e,HHr),b(f,vVe,_),b(f,Mr,_),M(v$,Mr,null),e(Mr,UHr),e(Mr,_f),e(_f,JHr),e(_f,Uee),e(Uee,YHr),e(_f,KHr),e(_f,Jee),e(Jee,ZHr),e(_f,eUr),e(Mr,oUr),e(Mr,F$),e(F$,rUr),e(F$,R0e),e(R0e,tUr),e(F$,aUr),e(Mr,nUr),e(Mr,Zt),M(T$,Zt,null),e(Zt,sUr),e(Zt,P0e),e(P0e,lUr),e(Zt,iUr),e(Zt,bf),e(bf,dUr),e(bf,B0e),e(B0e,cUr),e(bf,fUr),e(bf,Yee),e(Yee,mUr),e(bf,gUr),e(Zt,hUr),M(Ow,Zt,null),e(Mr,pUr),e(Mr,Jr),M(M$,Jr,null),e(Jr,uUr),e(Jr,I0e),e(I0e,_Ur),e(Jr,bUr),e(Jr,yn),e(yn,vUr),e(yn,N0e),e(N0e,FUr),e(yn,TUr),e(yn,q0e),e(q0e,MUr),e(yn,EUr),e(yn,j0e),e(j0e,CUr),e(yn,wUr),e(Jr,AUr),e(Jr,D0e),e(D0e,Vw),e(Vw,G0e),e(G0e,LUr),e(Vw,yUr),e(Vw,Kee),e(Kee,xUr),e(Vw,$Ur),e(Jr,kUr),M(Xw,Jr,null),b(f,FVe,_),b(f,vf,_),e(vf,zw),e(zw,O0e),M(E$,O0e,null),e(vf,SUr),e(vf,V0e),e(V0e,RUr),b(f,TVe,_),b(f,Er,_),M(C$,Er,null),e(Er,PUr),e(Er,Ff),e(Ff,BUr),e(Ff,Zee),e(Zee,IUr),e(Ff,NUr),e(Ff,eoe),e(eoe,qUr),e(Ff,jUr),e(Er,DUr),e(Er,w$),e(w$,GUr),e(w$,X0e),e(X0e,OUr),e(w$,VUr),e(Er,XUr),e(Er,ea),M(A$,ea,null),e(ea,zUr),e(ea,z0e),e(z0e,WUr),e(ea,QUr),e(ea,Tf),e(Tf,HUr),e(Tf,W0e),e(W0e,UUr),e(Tf,JUr),e(Tf,ooe),e(ooe,YUr),e(Tf,KUr),e(ea,ZUr),M(Ww,ea,null),e(Er,eJr),e(Er,Yr),M(L$,Yr,null),e(Yr,oJr),e(Yr,Q0e),e(Q0e,rJr),e(Yr,tJr),e(Yr,xn),e(xn,aJr),e(xn,H0e),e(H0e,nJr),e(xn,sJr),e(xn,U0e),e(U0e,lJr),e(xn,iJr),e(xn,J0e),e(J0e,dJr),e(xn,cJr),e(Yr,fJr),e(Yr,y$),e(y$,Qw),e(Qw,Y0e),e(Y0e,mJr),e(Qw,gJr),e(Qw,roe),e(roe,hJr),e(Qw,pJr),e(y$,uJr),e(y$,Hw),e(Hw,K0e),e(K0e,_Jr),e(Hw,bJr),e(Hw,toe),e(toe,vJr),e(Hw,FJr),e(Yr,TJr),M(Uw,Yr,null),b(f,MVe,_),b(f,Mf,_),e(Mf,Jw),e(Jw,Z0e),M(x$,Z0e,null),e(Mf,MJr),e(Mf,ewe),e(ewe,EJr),b(f,EVe,_),b(f,Cr,_),M($$,Cr,null),e(Cr,CJr),e(Cr,Ef),e(Ef,wJr),e(Ef,aoe),e(aoe,AJr),e(Ef,LJr),e(Ef,noe),e(noe,yJr),e(Ef,xJr),e(Cr,$Jr),e(Cr,k$),e(k$,kJr),e(k$,owe),e(owe,SJr),e(k$,RJr),e(Cr,PJr),e(Cr,oa),M(S$,oa,null),e(oa,BJr),e(oa,rwe),e(rwe,IJr),e(oa,NJr),e(oa,Cf),e(Cf,qJr),e(Cf,twe),e(twe,jJr),e(Cf,DJr),e(Cf,soe),e(soe,GJr),e(Cf,OJr),e(oa,VJr),M(Yw,oa,null),e(Cr,XJr),e(Cr,Kr),M(R$,Kr,null),e(Kr,zJr),e(Kr,awe),e(awe,WJr),e(Kr,QJr),e(Kr,$n),e($n,HJr),e($n,nwe),e(nwe,UJr),e($n,JJr),e($n,swe),e(swe,YJr),e($n,KJr),e($n,lwe),e(lwe,ZJr),e($n,eYr),e(Kr,oYr),e(Kr,iwe),e(iwe,Kw),e(Kw,dwe),e(dwe,rYr),e(Kw,tYr),e(Kw,loe),e(loe,aYr),e(Kw,nYr),e(Kr,sYr),M(Zw,Kr,null),CVe=!0},p(f,[_]){const P$={};_&2&&(P$.$$scope={dirty:_,ctx:f}),Rf.$set(P$);const cwe={};_&2&&(cwe.$$scope={dirty:_,ctx:f}),Gg.$set(cwe);const fwe={};_&2&&(fwe.$$scope={dirty:_,ctx:f}),Eh.$set(fwe);const mwe={};_&2&&(mwe.$$scope={dirty:_,ctx:f}),np.$set(mwe);const B$={};_&2&&(B$.$$scope={dirty:_,ctx:f}),sp.$set(B$);const gwe={};_&2&&(gwe.$$scope={dirty:_,ctx:f}),Lp.$set(gwe);const kn={};_&2&&(kn.$$scope={dirty:_,ctx:f}),yp.$set(kn);const hwe={};_&2&&(hwe.$$scope={dirty:_,ctx:f}),kp.$set(hwe);const pwe={};_&2&&(pwe.$$scope={dirty:_,ctx:f}),k_.$set(pwe);const uwe={};_&2&&(uwe.$$scope={dirty:_,ctx:f}),R_.$set(uwe);const I$={};_&2&&(I$.$$scope={dirty:_,ctx:f}),C1.$set(I$);const _we={};_&2&&(_we.$$scope={dirty:_,ctx:f}),A1.$set(_we);const N$={};_&2&&(N$.$$scope={dirty:_,ctx:f}),m3.$set(N$);const bwe={};_&2&&(bwe.$$scope={dirty:_,ctx:f}),h3.$set(bwe);const q$={};_&2&&(q$.$$scope={dirty:_,ctx:f}),K3.$set(q$);const vwe={};_&2&&(vwe.$$scope={dirty:_,ctx:f}),e2.$set(vwe);const Fwe={};_&2&&(Fwe.$$scope={dirty:_,ctx:f}),v2.$set(Fwe);const Twe={};_&2&&(Twe.$$scope={dirty:_,ctx:f}),T2.$set(Twe);const wf={};_&2&&(wf.$$scope={dirty:_,ctx:f}),_b.$set(wf);const Mwe={};_&2&&(Mwe.$$scope={dirty:_,ctx:f}),vb.$set(Mwe);const Ewe={};_&2&&(Ewe.$$scope={dirty:_,ctx:f}),Jb.$set(Ewe);const Cwe={};_&2&&(Cwe.$$scope={dirty:_,ctx:f}),Kb.$set(Cwe);const j$={};_&2&&(j$.$$scope={dirty:_,ctx:f}),nv.$set(j$);const wwe={};_&2&&(wwe.$$scope={dirty:_,ctx:f}),lv.$set(wwe);const Awe={};_&2&&(Awe.$$scope={dirty:_,ctx:f}),Xv.$set(Awe);const Lwe={};_&2&&(Lwe.$$scope={dirty:_,ctx:f}),Wv.$set(Lwe);const rt={};_&2&&(rt.$$scope={dirty:_,ctx:f}),PF.$set(rt);const D$={};_&2&&(D$.$$scope={dirty:_,ctx:f}),IF.$set(D$);const ywe={};_&2&&(ywe.$$scope={dirty:_,ctx:f}),jF.$set(ywe);const G$={};_&2&&(G$.$$scope={dirty:_,ctx:f}),GF.$set(G$);const xwe={};_&2&&(xwe.$$scope={dirty:_,ctx:f}),oT.$set(xwe);const tt={};_&2&&(tt.$$scope={dirty:_,ctx:f}),tT.$set(tt);const $we={};_&2&&($we.$$scope={dirty:_,ctx:f}),sT.$set($we);const Af={};_&2&&(Af.$$scope={dirty:_,ctx:f}),iT.$set(Af);const kwe={};_&2&&(kwe.$$scope={dirty:_,ctx:f}),fT.$set(kwe);const Swe={};_&2&&(Swe.$$scope={dirty:_,ctx:f}),gT.$set(Swe);const L={};_&2&&(L.$$scope={dirty:_,ctx:f}),CT.$set(L);const eA={};_&2&&(eA.$$scope={dirty:_,ctx:f}),AT.$set(eA);const Rwe={};_&2&&(Rwe.$$scope={dirty:_,ctx:f}),RT.$set(Rwe);const Pwe={};_&2&&(Pwe.$$scope={dirty:_,ctx:f}),BT.$set(Pwe);const oA={};_&2&&(oA.$$scope={dirty:_,ctx:f}),QT.$set(oA);const Bwe={};_&2&&(Bwe.$$scope={dirty:_,ctx:f}),UT.$set(Bwe);const Iwe={};_&2&&(Iwe.$$scope={dirty:_,ctx:f}),ZT.$set(Iwe);const rA={};_&2&&(rA.$$scope={dirty:_,ctx:f}),o7.$set(rA);const Nwe={};_&2&&(Nwe.$$scope={dirty:_,ctx:f}),i7.$set(Nwe);const qwe={};_&2&&(qwe.$$scope={dirty:_,ctx:f}),c7.$set(qwe);const tA={};_&2&&(tA.$$scope={dirty:_,ctx:f}),p7.$set(tA);const jwe={};_&2&&(jwe.$$scope={dirty:_,ctx:f}),_7.$set(jwe);const Dwe={};_&2&&(Dwe.$$scope={dirty:_,ctx:f}),T7.$set(Dwe);const aA={};_&2&&(aA.$$scope={dirty:_,ctx:f}),E7.$set(aA);const Gwe={};_&2&&(Gwe.$$scope={dirty:_,ctx:f}),A7.$set(Gwe);const Owe={};_&2&&(Owe.$$scope={dirty:_,ctx:f}),y7.$set(Owe);const nA={};_&2&&(nA.$$scope={dirty:_,ctx:f}),P7.$set(nA);const Vwe={};_&2&&(Vwe.$$scope={dirty:_,ctx:f}),I7.$set(Vwe);const Xwe={};_&2&&(Xwe.$$scope={dirty:_,ctx:f}),j7.$set(Xwe);const sA={};_&2&&(sA.$$scope={dirty:_,ctx:f}),G7.$set(sA);const zwe={};_&2&&(zwe.$$scope={dirty:_,ctx:f}),PM.$set(zwe);const Wwe={};_&2&&(Wwe.$$scope={dirty:_,ctx:f}),IM.$set(Wwe);const lA={};_&2&&(lA.$$scope={dirty:_,ctx:f}),sE.$set(lA);const Qwe={};_&2&&(Qwe.$$scope={dirty:_,ctx:f}),iE.$set(Qwe);const Hwe={};_&2&&(Hwe.$$scope={dirty:_,ctx:f}),ME.$set(Hwe);const iA={};_&2&&(iA.$$scope={dirty:_,ctx:f}),CE.$set(iA);const Uwe={};_&2&&(Uwe.$$scope={dirty:_,ctx:f}),xE.$set(Uwe);const Jwe={};_&2&&(Jwe.$$scope={dirty:_,ctx:f}),kE.$set(Jwe);const dA={};_&2&&(dA.$$scope={dirty:_,ctx:f}),KE.$set(dA);const Ywe={};_&2&&(Ywe.$$scope={dirty:_,ctx:f}),e4.$set(Ywe);const Kwe={};_&2&&(Kwe.$$scope={dirty:_,ctx:f}),f4.$set(Kwe);const cA={};_&2&&(cA.$$scope={dirty:_,ctx:f}),g4.$set(cA);const Zwe={};_&2&&(Zwe.$$scope={dirty:_,ctx:f}),D4.$set(Zwe);const eAe={};_&2&&(eAe.$$scope={dirty:_,ctx:f}),O4.$set(eAe);const fA={};_&2&&(fA.$$scope={dirty:_,ctx:f}),sC.$set(fA);const oAe={};_&2&&(oAe.$$scope={dirty:_,ctx:f}),iC.$set(oAe);const rAe={};_&2&&(rAe.$$scope={dirty:_,ctx:f}),fC.$set(rAe);const mA={};_&2&&(mA.$$scope={dirty:_,ctx:f}),gC.$set(mA);const tAe={};_&2&&(tAe.$$scope={dirty:_,ctx:f}),pC.$set(tAe);const aAe={};_&2&&(aAe.$$scope={dirty:_,ctx:f}),_C.$set(aAe);const gA={};_&2&&(gA.$$scope={dirty:_,ctx:f}),qC.$set(gA);const nAe={};_&2&&(nAe.$$scope={dirty:_,ctx:f}),DC.$set(nAe);const sAe={};_&2&&(sAe.$$scope={dirty:_,ctx:f}),l5.$set(sAe);const hA={};_&2&&(hA.$$scope={dirty:_,ctx:f}),d5.$set(hA);const lAe={};_&2&&(lAe.$$scope={dirty:_,ctx:f}),f5.$set(lAe);const iAe={};_&2&&(iAe.$$scope={dirty:_,ctx:f}),g5.$set(iAe);const pA={};_&2&&(pA.$$scope={dirty:_,ctx:f}),p5.$set(pA);const dAe={};_&2&&(dAe.$$scope={dirty:_,ctx:f}),_5.$set(dAe);const cAe={};_&2&&(cAe.$$scope={dirty:_,ctx:f}),z5.$set(cAe);const uA={};_&2&&(uA.$$scope={dirty:_,ctx:f}),Q5.$set(uA);const fAe={};_&2&&(fAe.$$scope={dirty:_,ctx:f}),a0.$set(fAe);const mAe={};_&2&&(mAe.$$scope={dirty:_,ctx:f}),s0.$set(mAe);const _A={};_&2&&(_A.$$scope={dirty:_,ctx:f}),F0.$set(_A);const gAe={};_&2&&(gAe.$$scope={dirty:_,ctx:f}),M0.$set(gAe);const hAe={};_&2&&(hAe.$$scope={dirty:_,ctx:f}),R0.$set(hAe);const bA={};_&2&&(bA.$$scope={dirty:_,ctx:f}),B0.$set(bA);const pAe={};_&2&&(pAe.$$scope={dirty:_,ctx:f}),W0.$set(pAe);const uAe={};_&2&&(uAe.$$scope={dirty:_,ctx:f}),H0.$set(uAe);const vA={};_&2&&(vA.$$scope={dirty:_,ctx:f}),nw.$set(vA);const _Ae={};_&2&&(_Ae.$$scope={dirty:_,ctx:f}),lw.$set(_Ae);const bAe={};_&2&&(bAe.$$scope={dirty:_,ctx:f}),bw.$set(bAe);const FA={};_&2&&(FA.$$scope={dirty:_,ctx:f}),Fw.$set(FA);const vAe={};_&2&&(vAe.$$scope={dirty:_,ctx:f}),xw.$set(vAe);const FAe={};_&2&&(FAe.$$scope={dirty:_,ctx:f}),kw.$set(FAe);const TA={};_&2&&(TA.$$scope={dirty:_,ctx:f}),Dw.$set(TA);const TAe={};_&2&&(TAe.$$scope={dirty:_,ctx:f}),Ow.$set(TAe);const MAe={};_&2&&(MAe.$$scope={dirty:_,ctx:f}),Xw.$set(MAe);const MA={};_&2&&(MA.$$scope={dirty:_,ctx:f}),Ww.$set(MA);const EAe={};_&2&&(EAe.$$scope={dirty:_,ctx:f}),Uw.$set(EAe);const CAe={};_&2&&(CAe.$$scope={dirty:_,ctx:f}),Yw.$set(CAe);const EA={};_&2&&(EA.$$scope={dirty:_,ctx:f}),Zw.$set(EA)},i(f){CVe||(E(d.$$.fragment,f),E(ya.$$.fragment,f),E(CL.$$.fragment,f),E(wL.$$.fragment,f),E(Rf.$$.fragment,f),E(AL.$$.fragment,f),E(LL.$$.fragment,f),E($L.$$.fragment,f),E(Gg.$$.fragment,f),E(kL.$$.fragment,f),E(SL.$$.fragment,f),E(RL.$$.fragment,f),E(IL.$$.fragment,f),E(Eh.$$.fragment,f),E(NL.$$.fragment,f),E(qL.$$.fragment,f),E(jL.$$.fragment,f),E(OL.$$.fragment,f),E(np.$$.fragment,f),E(sp.$$.fragment,f),E(VL.$$.fragment,f),E(XL.$$.fragment,f),E(zL.$$.fragment,f),E(HL.$$.fragment,f),E(Lp.$$.fragment,f),E(yp.$$.fragment,f),E(UL.$$.fragment,f),E(JL.$$.fragment,f),E(YL.$$.fragment,f),E(ZL.$$.fragment,f),E(kp.$$.fragment,f),E(ey.$$.fragment,f),E(k_.$$.fragment,f),E(oy.$$.fragment,f),E(ry.$$.fragment,f),E(ay.$$.fragment,f),E(R_.$$.fragment,f),E(ny.$$.fragment,f),E(C1.$$.fragment,f),E(sy.$$.fragment,f),E(ly.$$.fragment,f),E(dy.$$.fragment,f),E(A1.$$.fragment,f),E(cy.$$.fragment,f),E(m3.$$.fragment,f),E(fy.$$.fragment,f),E(my.$$.fragment,f),E(hy.$$.fragment,f),E(h3.$$.fragment,f),E(py.$$.fragment,f),E(K3.$$.fragment,f),E(uy.$$.fragment,f),E(_y.$$.fragment,f),E(vy.$$.fragment,f),E(e2.$$.fragment,f),E(Fy.$$.fragment,f),E(v2.$$.fragment,f),E(Ty.$$.fragment,f),E(My.$$.fragment,f),E(Cy.$$.fragment,f),E(T2.$$.fragment,f),E(wy.$$.fragment,f),E(_b.$$.fragment,f),E(Ay.$$.fragment,f),E(Ly.$$.fragment,f),E(xy.$$.fragment,f),E(vb.$$.fragment,f),E($y.$$.fragment,f),E(Jb.$$.fragment,f),E(ky.$$.fragment,f),E(Sy.$$.fragment,f),E(Py.$$.fragment,f),E(Kb.$$.fragment,f),E(By.$$.fragment,f),E(nv.$$.fragment,f),E(Iy.$$.fragment,f),E(Ny.$$.fragment,f),E(jy.$$.fragment,f),E(lv.$$.fragment,f),E(Dy.$$.fragment,f),E(Xv.$$.fragment,f),E(Gy.$$.fragment,f),E(Oy.$$.fragment,f),E(Xy.$$.fragment,f),E(Wv.$$.fragment,f),E(zy.$$.fragment,f),E(PF.$$.fragment,f),E(Wy.$$.fragment,f),E(Qy.$$.fragment,f),E(Uy.$$.fragment,f),E(IF.$$.fragment,f),E(Jy.$$.fragment,f),E(jF.$$.fragment,f),E(Yy.$$.fragment,f),E(Ky.$$.fragment,f),E(e8.$$.fragment,f),E(GF.$$.fragment,f),E(o8.$$.fragment,f),E(oT.$$.fragment,f),E(r8.$$.fragment,f),E(t8.$$.fragment,f),E(n8.$$.fragment,f),E(tT.$$.fragment,f),E(s8.$$.fragment,f),E(sT.$$.fragment,f),E(l8.$$.fragment,f),E(i8.$$.fragment,f),E(c8.$$.fragment,f),E(iT.$$.fragment,f),E(f8.$$.fragment,f),E(fT.$$.fragment,f),E(m8.$$.fragment,f),E(g8.$$.fragment,f),E(p8.$$.fragment,f),E(gT.$$.fragment,f),E(u8.$$.fragment,f),E(CT.$$.fragment,f),E(_8.$$.fragment,f),E(b8.$$.fragment,f),E(F8.$$.fragment,f),E(AT.$$.fragment,f),E(T8.$$.fragment,f),E(RT.$$.fragment,f),E(M8.$$.fragment,f),E(E8.$$.fragment,f),E(w8.$$.fragment,f),E(BT.$$.fragment,f),E(A8.$$.fragment,f),E(QT.$$.fragment,f),E(L8.$$.fragment,f),E(y8.$$.fragment,f),E($8.$$.fragment,f),E(UT.$$.fragment,f),E(k8.$$.fragment,f),E(ZT.$$.fragment,f),E(R8.$$.fragment,f),E(P8.$$.fragment,f),E(I8.$$.fragment,f),E(o7.$$.fragment,f),E(N8.$$.fragment,f),E(i7.$$.fragment,f),E(q8.$$.fragment,f),E(j8.$$.fragment,f),E(G8.$$.fragment,f),E(c7.$$.fragment,f),E(O8.$$.fragment,f),E(p7.$$.fragment,f),E(V8.$$.fragment,f),E(X8.$$.fragment,f),E(W8.$$.fragment,f),E(_7.$$.fragment,f),E(Q8.$$.fragment,f),E(T7.$$.fragment,f),E(U8.$$.fragment,f),E(J8.$$.fragment,f),E(K8.$$.fragment,f),E(E7.$$.fragment,f),E(Z8.$$.fragment,f),E(A7.$$.fragment,f),E(e9.$$.fragment,f),E(o9.$$.fragment,f),E(t9.$$.fragment,f),E(y7.$$.fragment,f),E(a9.$$.fragment,f),E(P7.$$.fragment,f),E(n9.$$.fragment,f),E(s9.$$.fragment,f),E(i9.$$.fragment,f),E(I7.$$.fragment,f),E(d9.$$.fragment,f),E(j7.$$.fragment,f),E(c9.$$.fragment,f),E(f9.$$.fragment,f),E(g9.$$.fragment,f),E(G7.$$.fragment,f),E(h9.$$.fragment,f),E(PM.$$.fragment,f),E(p9.$$.fragment,f),E(u9.$$.fragment,f),E(b9.$$.fragment,f),E(IM.$$.fragment,f),E(v9.$$.fragment,f),E(sE.$$.fragment,f),E(F9.$$.fragment,f),E(T9.$$.fragment,f),E(E9.$$.fragment,f),E(iE.$$.fragment,f),E(C9.$$.fragment,f),E(ME.$$.fragment,f),E(w9.$$.fragment,f),E(A9.$$.fragment,f),E(y9.$$.fragment,f),E(CE.$$.fragment,f),E(x9.$$.fragment,f),E(xE.$$.fragment,f),E($9.$$.fragment,f),E(k9.$$.fragment,f),E(R9.$$.fragment,f),E(kE.$$.fragment,f),E(P9.$$.fragment,f),E(KE.$$.fragment,f),E(B9.$$.fragment,f),E(I9.$$.fragment,f),E(q9.$$.fragment,f),E(e4.$$.fragment,f),E(j9.$$.fragment,f),E(f4.$$.fragment,f),E(D9.$$.fragment,f),E(G9.$$.fragment,f),E(V9.$$.fragment,f),E(g4.$$.fragment,f),E(X9.$$.fragment,f),E(D4.$$.fragment,f),E(z9.$$.fragment,f),E(W9.$$.fragment,f),E(H9.$$.fragment,f),E(O4.$$.fragment,f),E(U9.$$.fragment,f),E(sC.$$.fragment,f),E(J9.$$.fragment,f),E(Y9.$$.fragment,f),E(Z9.$$.fragment,f),E(iC.$$.fragment,f),E(ex.$$.fragment,f),E(fC.$$.fragment,f),E(rx.$$.fragment,f),E(tx.$$.fragment,f),E(nx.$$.fragment,f),E(gC.$$.fragment,f),E(sx.$$.fragment,f),E(pC.$$.fragment,f),E(lx.$$.fragment,f),E(ix.$$.fragment,f),E(cx.$$.fragment,f),E(_C.$$.fragment,f),E(fx.$$.fragment,f),E(qC.$$.fragment,f),E(mx.$$.fragment,f),E(gx.$$.fragment,f),E(px.$$.fragment,f),E(DC.$$.fragment,f),E(ux.$$.fragment,f),E(l5.$$.fragment,f),E(_x.$$.fragment,f),E(bx.$$.fragment,f),E(Fx.$$.fragment,f),E(d5.$$.fragment,f),E(Tx.$$.fragment,f),E(f5.$$.fragment,f),E(Mx.$$.fragment,f),E(Ex.$$.fragment,f),E(wx.$$.fragment,f),E(g5.$$.fragment,f),E(Ax.$$.fragment,f),E(p5.$$.fragment,f),E(Lx.$$.fragment,f),E(yx.$$.fragment,f),E($x.$$.fragment,f),E(_5.$$.fragment,f),E(kx.$$.fragment,f),E(z5.$$.fragment,f),E(Sx.$$.fragment,f),E(Rx.$$.fragment,f),E(Bx.$$.fragment,f),E(Q5.$$.fragment,f),E(Ix.$$.fragment,f),E(a0.$$.fragment,f),E(Nx.$$.fragment,f),E(qx.$$.fragment,f),E(Dx.$$.fragment,f),E(s0.$$.fragment,f),E(Gx.$$.fragment,f),E(F0.$$.fragment,f),E(Ox.$$.fragment,f),E(Vx.$$.fragment,f),E(zx.$$.fragment,f),E(M0.$$.fragment,f),E(Wx.$$.fragment,f),E(R0.$$.fragment,f),E(Qx.$$.fragment,f),E(Hx.$$.fragment,f),E(Jx.$$.fragment,f),E(B0.$$.fragment,f),E(Yx.$$.fragment,f),E(W0.$$.fragment,f),E(Kx.$$.fragment,f),E(Zx.$$.fragment,f),E(o$.$$.fragment,f),E(H0.$$.fragment,f),E(r$.$$.fragment,f),E(nw.$$.fragment,f),E(t$.$$.fragment,f),E(a$.$$.fragment,f),E(s$.$$.fragment,f),E(lw.$$.fragment,f),E(l$.$$.fragment,f),E(bw.$$.fragment,f),E(i$.$$.fragment,f),E(d$.$$.fragment,f),E(f$.$$.fragment,f),E(Fw.$$.fragment,f),E(m$.$$.fragment,f),E(xw.$$.fragment,f),E(g$.$$.fragment,f),E(h$.$$.fragment,f),E(u$.$$.fragment,f),E(kw.$$.fragment,f),E(_$.$$.fragment,f),E(Dw.$$.fragment,f),E(b$.$$.fragment,f),E(v$.$$.fragment,f),E(T$.$$.fragment,f),E(Ow.$$.fragment,f),E(M$.$$.fragment,f),E(Xw.$$.fragment,f),E(E$.$$.fragment,f),E(C$.$$.fragment,f),E(A$.$$.fragment,f),E(Ww.$$.fragment,f),E(L$.$$.fragment,f),E(Uw.$$.fragment,f),E(x$.$$.fragment,f),E($$.$$.fragment,f),E(S$.$$.fragment,f),E(Yw.$$.fragment,f),E(R$.$$.fragment,f),E(Zw.$$.fragment,f),CVe=!0)},o(f){C(d.$$.fragment,f),C(ya.$$.fragment,f),C(CL.$$.fragment,f),C(wL.$$.fragment,f),C(Rf.$$.fragment,f),C(AL.$$.fragment,f),C(LL.$$.fragment,f),C($L.$$.fragment,f),C(Gg.$$.fragment,f),C(kL.$$.fragment,f),C(SL.$$.fragment,f),C(RL.$$.fragment,f),C(IL.$$.fragment,f),C(Eh.$$.fragment,f),C(NL.$$.fragment,f),C(qL.$$.fragment,f),C(jL.$$.fragment,f),C(OL.$$.fragment,f),C(np.$$.fragment,f),C(sp.$$.fragment,f),C(VL.$$.fragment,f),C(XL.$$.fragment,f),C(zL.$$.fragment,f),C(HL.$$.fragment,f),C(Lp.$$.fragment,f),C(yp.$$.fragment,f),C(UL.$$.fragment,f),C(JL.$$.fragment,f),C(YL.$$.fragment,f),C(ZL.$$.fragment,f),C(kp.$$.fragment,f),C(ey.$$.fragment,f),C(k_.$$.fragment,f),C(oy.$$.fragment,f),C(ry.$$.fragment,f),C(ay.$$.fragment,f),C(R_.$$.fragment,f),C(ny.$$.fragment,f),C(C1.$$.fragment,f),C(sy.$$.fragment,f),C(ly.$$.fragment,f),C(dy.$$.fragment,f),C(A1.$$.fragment,f),C(cy.$$.fragment,f),C(m3.$$.fragment,f),C(fy.$$.fragment,f),C(my.$$.fragment,f),C(hy.$$.fragment,f),C(h3.$$.fragment,f),C(py.$$.fragment,f),C(K3.$$.fragment,f),C(uy.$$.fragment,f),C(_y.$$.fragment,f),C(vy.$$.fragment,f),C(e2.$$.fragment,f),C(Fy.$$.fragment,f),C(v2.$$.fragment,f),C(Ty.$$.fragment,f),C(My.$$.fragment,f),C(Cy.$$.fragment,f),C(T2.$$.fragment,f),C(wy.$$.fragment,f),C(_b.$$.fragment,f),C(Ay.$$.fragment,f),C(Ly.$$.fragment,f),C(xy.$$.fragment,f),C(vb.$$.fragment,f),C($y.$$.fragment,f),C(Jb.$$.fragment,f),C(ky.$$.fragment,f),C(Sy.$$.fragment,f),C(Py.$$.fragment,f),C(Kb.$$.fragment,f),C(By.$$.fragment,f),C(nv.$$.fragment,f),C(Iy.$$.fragment,f),C(Ny.$$.fragment,f),C(jy.$$.fragment,f),C(lv.$$.fragment,f),C(Dy.$$.fragment,f),C(Xv.$$.fragment,f),C(Gy.$$.fragment,f),C(Oy.$$.fragment,f),C(Xy.$$.fragment,f),C(Wv.$$.fragment,f),C(zy.$$.fragment,f),C(PF.$$.fragment,f),C(Wy.$$.fragment,f),C(Qy.$$.fragment,f),C(Uy.$$.fragment,f),C(IF.$$.fragment,f),C(Jy.$$.fragment,f),C(jF.$$.fragment,f),C(Yy.$$.fragment,f),C(Ky.$$.fragment,f),C(e8.$$.fragment,f),C(GF.$$.fragment,f),C(o8.$$.fragment,f),C(oT.$$.fragment,f),C(r8.$$.fragment,f),C(t8.$$.fragment,f),C(n8.$$.fragment,f),C(tT.$$.fragment,f),C(s8.$$.fragment,f),C(sT.$$.fragment,f),C(l8.$$.fragment,f),C(i8.$$.fragment,f),C(c8.$$.fragment,f),C(iT.$$.fragment,f),C(f8.$$.fragment,f),C(fT.$$.fragment,f),C(m8.$$.fragment,f),C(g8.$$.fragment,f),C(p8.$$.fragment,f),C(gT.$$.fragment,f),C(u8.$$.fragment,f),C(CT.$$.fragment,f),C(_8.$$.fragment,f),C(b8.$$.fragment,f),C(F8.$$.fragment,f),C(AT.$$.fragment,f),C(T8.$$.fragment,f),C(RT.$$.fragment,f),C(M8.$$.fragment,f),C(E8.$$.fragment,f),C(w8.$$.fragment,f),C(BT.$$.fragment,f),C(A8.$$.fragment,f),C(QT.$$.fragment,f),C(L8.$$.fragment,f),C(y8.$$.fragment,f),C($8.$$.fragment,f),C(UT.$$.fragment,f),C(k8.$$.fragment,f),C(ZT.$$.fragment,f),C(R8.$$.fragment,f),C(P8.$$.fragment,f),C(I8.$$.fragment,f),C(o7.$$.fragment,f),C(N8.$$.fragment,f),C(i7.$$.fragment,f),C(q8.$$.fragment,f),C(j8.$$.fragment,f),C(G8.$$.fragment,f),C(c7.$$.fragment,f),C(O8.$$.fragment,f),C(p7.$$.fragment,f),C(V8.$$.fragment,f),C(X8.$$.fragment,f),C(W8.$$.fragment,f),C(_7.$$.fragment,f),C(Q8.$$.fragment,f),C(T7.$$.fragment,f),C(U8.$$.fragment,f),C(J8.$$.fragment,f),C(K8.$$.fragment,f),C(E7.$$.fragment,f),C(Z8.$$.fragment,f),C(A7.$$.fragment,f),C(e9.$$.fragment,f),C(o9.$$.fragment,f),C(t9.$$.fragment,f),C(y7.$$.fragment,f),C(a9.$$.fragment,f),C(P7.$$.fragment,f),C(n9.$$.fragment,f),C(s9.$$.fragment,f),C(i9.$$.fragment,f),C(I7.$$.fragment,f),C(d9.$$.fragment,f),C(j7.$$.fragment,f),C(c9.$$.fragment,f),C(f9.$$.fragment,f),C(g9.$$.fragment,f),C(G7.$$.fragment,f),C(h9.$$.fragment,f),C(PM.$$.fragment,f),C(p9.$$.fragment,f),C(u9.$$.fragment,f),C(b9.$$.fragment,f),C(IM.$$.fragment,f),C(v9.$$.fragment,f),C(sE.$$.fragment,f),C(F9.$$.fragment,f),C(T9.$$.fragment,f),C(E9.$$.fragment,f),C(iE.$$.fragment,f),C(C9.$$.fragment,f),C(ME.$$.fragment,f),C(w9.$$.fragment,f),C(A9.$$.fragment,f),C(y9.$$.fragment,f),C(CE.$$.fragment,f),C(x9.$$.fragment,f),C(xE.$$.fragment,f),C($9.$$.fragment,f),C(k9.$$.fragment,f),C(R9.$$.fragment,f),C(kE.$$.fragment,f),C(P9.$$.fragment,f),C(KE.$$.fragment,f),C(B9.$$.fragment,f),C(I9.$$.fragment,f),C(q9.$$.fragment,f),C(e4.$$.fragment,f),C(j9.$$.fragment,f),C(f4.$$.fragment,f),C(D9.$$.fragment,f),C(G9.$$.fragment,f),C(V9.$$.fragment,f),C(g4.$$.fragment,f),C(X9.$$.fragment,f),C(D4.$$.fragment,f),C(z9.$$.fragment,f),C(W9.$$.fragment,f),C(H9.$$.fragment,f),C(O4.$$.fragment,f),C(U9.$$.fragment,f),C(sC.$$.fragment,f),C(J9.$$.fragment,f),C(Y9.$$.fragment,f),C(Z9.$$.fragment,f),C(iC.$$.fragment,f),C(ex.$$.fragment,f),C(fC.$$.fragment,f),C(rx.$$.fragment,f),C(tx.$$.fragment,f),C(nx.$$.fragment,f),C(gC.$$.fragment,f),C(sx.$$.fragment,f),C(pC.$$.fragment,f),C(lx.$$.fragment,f),C(ix.$$.fragment,f),C(cx.$$.fragment,f),C(_C.$$.fragment,f),C(fx.$$.fragment,f),C(qC.$$.fragment,f),C(mx.$$.fragment,f),C(gx.$$.fragment,f),C(px.$$.fragment,f),C(DC.$$.fragment,f),C(ux.$$.fragment,f),C(l5.$$.fragment,f),C(_x.$$.fragment,f),C(bx.$$.fragment,f),C(Fx.$$.fragment,f),C(d5.$$.fragment,f),C(Tx.$$.fragment,f),C(f5.$$.fragment,f),C(Mx.$$.fragment,f),C(Ex.$$.fragment,f),C(wx.$$.fragment,f),C(g5.$$.fragment,f),C(Ax.$$.fragment,f),C(p5.$$.fragment,f),C(Lx.$$.fragment,f),C(yx.$$.fragment,f),C($x.$$.fragment,f),C(_5.$$.fragment,f),C(kx.$$.fragment,f),C(z5.$$.fragment,f),C(Sx.$$.fragment,f),C(Rx.$$.fragment,f),C(Bx.$$.fragment,f),C(Q5.$$.fragment,f),C(Ix.$$.fragment,f),C(a0.$$.fragment,f),C(Nx.$$.fragment,f),C(qx.$$.fragment,f),C(Dx.$$.fragment,f),C(s0.$$.fragment,f),C(Gx.$$.fragment,f),C(F0.$$.fragment,f),C(Ox.$$.fragment,f),C(Vx.$$.fragment,f),C(zx.$$.fragment,f),C(M0.$$.fragment,f),C(Wx.$$.fragment,f),C(R0.$$.fragment,f),C(Qx.$$.fragment,f),C(Hx.$$.fragment,f),C(Jx.$$.fragment,f),C(B0.$$.fragment,f),C(Yx.$$.fragment,f),C(W0.$$.fragment,f),C(Kx.$$.fragment,f),C(Zx.$$.fragment,f),C(o$.$$.fragment,f),C(H0.$$.fragment,f),C(r$.$$.fragment,f),C(nw.$$.fragment,f),C(t$.$$.fragment,f),C(a$.$$.fragment,f),C(s$.$$.fragment,f),C(lw.$$.fragment,f),C(l$.$$.fragment,f),C(bw.$$.fragment,f),C(i$.$$.fragment,f),C(d$.$$.fragment,f),C(f$.$$.fragment,f),C(Fw.$$.fragment,f),C(m$.$$.fragment,f),C(xw.$$.fragment,f),C(g$.$$.fragment,f),C(h$.$$.fragment,f),C(u$.$$.fragment,f),C(kw.$$.fragment,f),C(_$.$$.fragment,f),C(Dw.$$.fragment,f),C(b$.$$.fragment,f),C(v$.$$.fragment,f),C(T$.$$.fragment,f),C(Ow.$$.fragment,f),C(M$.$$.fragment,f),C(Xw.$$.fragment,f),C(E$.$$.fragment,f),C(C$.$$.fragment,f),C(A$.$$.fragment,f),C(Ww.$$.fragment,f),C(L$.$$.fragment,f),C(Uw.$$.fragment,f),C(x$.$$.fragment,f),C($$.$$.fragment,f),C(S$.$$.fragment,f),C(Yw.$$.fragment,f),C(R$.$$.fragment,f),C(Zw.$$.fragment,f),CVe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(yf),f&&t(at),f&&t(Oe),f&&t(We),f&&t($f),w(ya,f),f&&t(Qe),f&&t(Ae),f&&t(Co),f&&t(xa),f&&t(vGe),f&&t(yi),w(CL),f&&t(FGe),f&&t(In),f&&t(TGe),w(wL,f),f&&t(MGe),f&&t(rS),f&&t(EGe),w(Rf,f),f&&t(CGe),f&&t(xi),w(AL),f&&t(wGe),f&&t(wo),w(LL),w($L),w(Gg),w(kL),f&&t(AGe),f&&t(ki),w(SL),f&&t(LGe),f&&t(Ao),w(RL),w(IL),w(Eh),w(NL),f&&t(yGe),f&&t(Si),w(qL),f&&t(xGe),f&&t(Lo),w(jL),w(OL),w(np),w(sp),w(VL),f&&t($Ge),f&&t(Ri),w(XL),f&&t(kGe),f&&t(yo),w(zL),w(HL),w(Lp),w(yp),w(UL),f&&t(SGe),f&&t(Bi),w(JL),f&&t(RGe),f&&t(xo),w(YL),w(ZL),w(kp),w(ey),w(k_),f&&t(PGe),f&&t(qi),w(oy),f&&t(BGe),f&&t($o),w(ry),w(ay),w(R_),w(ny),w(C1),f&&t(IGe),f&&t(Gi),w(sy),f&&t(NGe),f&&t(ko),w(ly),w(dy),w(A1),w(cy),w(m3),f&&t(qGe),f&&t(Xi),w(fy),f&&t(jGe),f&&t(So),w(my),w(hy),w(h3),w(py),w(K3),f&&t(DGe),f&&t(Qi),w(uy),f&&t(GGe),f&&t(Ro),w(_y),w(vy),w(e2),w(Fy),w(v2),f&&t(OGe),f&&t(Ji),w(Ty),f&&t(VGe),f&&t(Po),w(My),w(Cy),w(T2),w(wy),w(_b),f&&t(XGe),f&&t(Zi),w(Ay),f&&t(zGe),f&&t(Bo),w(Ly),w(xy),w(vb),w($y),w(Jb),f&&t(WGe),f&&t(rd),w(ky),f&&t(QGe),f&&t(Io),w(Sy),w(Py),w(Kb),w(By),w(nv),f&&t(HGe),f&&t(nd),w(Iy),f&&t(UGe),f&&t(No),w(Ny),w(jy),w(lv),w(Dy),w(Xv),f&&t(JGe),f&&t(id),w(Gy),f&&t(YGe),f&&t(qo),w(Oy),w(Xy),w(Wv),w(zy),w(PF),f&&t(KGe),f&&t(fd),w(Wy),f&&t(ZGe),f&&t(jo),w(Qy),w(Uy),w(IF),w(Jy),w(jF),f&&t(eOe),f&&t(hd),w(Yy),f&&t(oOe),f&&t(Do),w(Ky),w(e8),w(GF),w(o8),w(oT),f&&t(rOe),f&&t(_d),w(r8),f&&t(tOe),f&&t(Go),w(t8),w(n8),w(tT),w(s8),w(sT),f&&t(aOe),f&&t(Fd),w(l8),f&&t(nOe),f&&t(Oo),w(i8),w(c8),w(iT),w(f8),w(fT),f&&t(sOe),f&&t(Ed),w(m8),f&&t(lOe),f&&t(Vo),w(g8),w(p8),w(gT),w(u8),w(CT),f&&t(iOe),f&&t(Ad),w(_8),f&&t(dOe),f&&t(Xo),w(b8),w(F8),w(AT),w(T8),w(RT),f&&t(cOe),f&&t(xd),w(M8),f&&t(fOe),f&&t(zo),w(E8),w(w8),w(BT),w(A8),w(QT),f&&t(mOe),f&&t(Sd),w(L8),f&&t(gOe),f&&t(Wo),w(y8),w($8),w(UT),w(k8),w(ZT),f&&t(hOe),f&&t(Bd),w(R8),f&&t(pOe),f&&t(Qo),w(P8),w(I8),w(o7),w(N8),w(i7),f&&t(uOe),f&&t(qd),w(q8),f&&t(_Oe),f&&t(Ho),w(j8),w(G8),w(c7),w(O8),w(p7),f&&t(bOe),f&&t(Od),w(V8),f&&t(vOe),f&&t(Uo),w(X8),w(W8),w(_7),w(Q8),w(T7),f&&t(FOe),f&&t(zd),w(U8),f&&t(TOe),f&&t(Jo),w(J8),w(K8),w(E7),w(Z8),w(A7),f&&t(MOe),f&&t(Hd),w(e9),f&&t(EOe),f&&t(Yo),w(o9),w(t9),w(y7),w(a9),w(P7),f&&t(COe),f&&t(Yd),w(n9),f&&t(wOe),f&&t(Ko),w(s9),w(i9),w(I7),w(d9),w(j7),f&&t(AOe),f&&t(ec),w(c9),f&&t(LOe),f&&t(Zo),w(f9),w(g9),w(G7),w(h9),w(PM),f&&t(yOe),f&&t(tc),w(p9),f&&t(xOe),f&&t(er),w(u9),w(b9),w(IM),w(v9),w(sE),f&&t($Oe),f&&t(sc),w(F9),f&&t(kOe),f&&t(or),w(T9),w(E9),w(iE),w(C9),w(ME),f&&t(SOe),f&&t(dc),w(w9),f&&t(ROe),f&&t(rr),w(A9),w(y9),w(CE),w(x9),w(xE),f&&t(POe),f&&t(mc),w($9),f&&t(BOe),f&&t(tr),w(k9),w(R9),w(kE),w(P9),w(KE),f&&t(IOe),f&&t(pc),w(B9),f&&t(NOe),f&&t(ar),w(I9),w(q9),w(e4),w(j9),w(f4),f&&t(qOe),f&&t(bc),w(D9),f&&t(jOe),f&&t(nr),w(G9),w(V9),w(g4),w(X9),w(D4),f&&t(DOe),f&&t(Tc),w(z9),f&&t(GOe),f&&t(sr),w(W9),w(H9),w(O4),w(U9),w(sC),f&&t(OOe),f&&t(Cc),w(J9),f&&t(VOe),f&&t(lr),w(Y9),w(Z9),w(iC),w(ex),w(fC),f&&t(XOe),f&&t(Lc),w(rx),f&&t(zOe),f&&t(ir),w(tx),w(nx),w(gC),w(sx),w(pC),f&&t(WOe),f&&t($c),w(lx),f&&t(QOe),f&&t(dr),w(ix),w(cx),w(_C),w(fx),w(qC),f&&t(HOe),f&&t(Rc),w(mx),f&&t(UOe),f&&t(cr),w(gx),w(px),w(DC),w(ux),w(l5),f&&t(JOe),f&&t(Ic),w(_x),f&&t(YOe),f&&t(fr),w(bx),w(Fx),w(d5),w(Tx),w(f5),f&&t(KOe),f&&t(jc),w(Mx),f&&t(ZOe),f&&t(mr),w(Ex),w(wx),w(g5),w(Ax),w(p5),f&&t(eVe),f&&t(Oc),w(Lx),f&&t(oVe),f&&t(gr),w(yx),w($x),w(_5),w(kx),w(z5),f&&t(rVe),f&&t(zc),w(Sx),f&&t(tVe),f&&t(hr),w(Rx),w(Bx),w(Q5),w(Ix),w(a0),f&&t(aVe),f&&t(Hc),w(Nx),f&&t(nVe),f&&t(pr),w(qx),w(Dx),w(s0),w(Gx),w(F0),f&&t(sVe),f&&t(Yc),w(Ox),f&&t(lVe),f&&t(ur),w(Vx),w(zx),w(M0),w(Wx),w(R0),f&&t(iVe),f&&t(ef),w(Qx),f&&t(dVe),f&&t(_r),w(Hx),w(Jx),w(B0),w(Yx),w(W0),f&&t(cVe),f&&t(tf),w(Kx),f&&t(fVe),f&&t(br),w(Zx),w(o$),w(H0),w(r$),w(nw),f&&t(mVe),f&&t(sf),w(t$),f&&t(gVe),f&&t(vr),w(a$),w(s$),w(lw),w(l$),w(bw),f&&t(hVe),f&&t(cf),w(i$),f&&t(pVe),f&&t(Fr),w(d$),w(f$),w(Fw),w(m$),w(xw),f&&t(uVe),f&&t(gf),w(g$),f&&t(_Ve),f&&t(Tr),w(h$),w(u$),w(kw),w(_$),w(Dw),f&&t(bVe),f&&t(uf),w(b$),f&&t(vVe),f&&t(Mr),w(v$),w(T$),w(Ow),w(M$),w(Xw),f&&t(FVe),f&&t(vf),w(E$),f&&t(TVe),f&&t(Er),w(C$),w(A$),w(Ww),w(L$),w(Uw),f&&t(MVe),f&&t(Mf),w(x$),f&&t(EVe),f&&t(Cr),w($$),w(S$),w(Yw),w(R$),w(Zw)}}}const EGt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function CGt(x){return Mjt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class kGt extends bjt{constructor(g){super();vjt(this,g,CGt,MGt,Fjt,{})}}export{kGt as default,EGt as metadata};
