import{S as iVt,i as dVt,s as cVt,e as a,k as l,w as F,t as o,M as fVt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as mVt,L as N}from"../../chunks/vendor-hf-doc-builder.js";import{T as het}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function gVt($){let g,v,p,m,_,d,h,Eo,Ci,kf,nt,wi,Ai,qL,Sf,Oe,Qe,Li,Pn,jL,Bn,Nn,DL,yi,In,GL,xi,Rf,ka;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Ci=a("code"),kf=o("model_type"),nt=o(" attribute is set to the same key you use when registering the config (here "),wi=a("code"),Ai=o('"new-model"'),qL=o(")."),Sf=l(),Oe=a("p"),Qe=o("Likewise, if your "),Li=a("code"),Pn=o("NewModel"),jL=o(" is a subclass of "),Bn=a("a"),Nn=o("PreTrainedModel"),DL=o(`, make sure its
`),yi=a("code"),In=o("config_class"),GL=o(` attribute is set to the same class you use when registering the model (here
`),xi=a("code"),Rf=o("NewModelConfig"),ka=o(")."),this.h()},l(We){g=n(We,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var uS=s(p);m=r(uS,"NewModelConfig"),uS.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var $i=s(d);h=r($i,"PretrainedConfig"),$i.forEach(t),Eo=r(Ae,`, make sure its
`),Ci=n(Ae,"CODE",{});var bS=s(Ci);kf=r(bS,"model_type"),bS.forEach(t),nt=r(Ae," attribute is set to the same key you use when registering the config (here "),wi=n(Ae,"CODE",{});var vS=s(wi);Ai=r(vS,'"new-model"'),vS.forEach(t),qL=r(Ae,")."),Ae.forEach(t),Sf=i(We),Oe=n(We,"P",{});var Co=s(Oe);Qe=r(Co,"Likewise, if your "),Li=n(Co,"CODE",{});var Sa=s(Li);Pn=r(Sa,"NewModel"),Sa.forEach(t),jL=r(Co," is a subclass of "),Bn=n(Co,"A",{href:!0});var FS=s(Bn);Nn=r(FS,"PreTrainedModel"),FS.forEach(t),DL=r(Co,`, make sure its
`),yi=n(Co,"CODE",{});var Pf=s(yi);In=r(Pf,"config_class"),Pf.forEach(t),GL=r(Co,` attribute is set to the same class you use when registering the model (here
`),xi=n(Co,"CODE",{});var TS=s(xi);Rf=r(TS,"NewModelConfig"),TS.forEach(t),ka=r(Co,")."),Co.forEach(t),this.h()},h(){c(Bn,"href","/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel")},m(We,Ae){b(We,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Eo),e(g,Ci),e(Ci,kf),e(g,nt),e(g,wi),e(wi,Ai),e(g,qL),b(We,Sf,Ae),b(We,Oe,Ae),e(Oe,Qe),e(Oe,Li),e(Li,Pn),e(Oe,jL),e(Oe,Bn),e(Bn,Nn),e(Oe,DL),e(Oe,yi),e(yi,In),e(Oe,GL),e(Oe,xi),e(xi,Rf),e(Oe,ka)},d(We){We&&t(g),We&&t(Sf),We&&t(Oe)}}}function hVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Vt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function uVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bVt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function vVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Vt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Xt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Xt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ezt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ozt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function azt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function szt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function izt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function czt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mzt($){let g,v,p,m,_,d,h,Eo,Ci,kf,nt,wi,Ai,qL,Sf,Oe,Qe,Li,Pn,jL,Bn,Nn,DL,yi,In,GL,xi,Rf,ka,We,Ae,uS,$i,bS,vS,Co,Sa,FS,Pf,TS,eWe,jOe,ki,Bf,Ote,OL,oWe,Vte,rWe,DOe,qn,tWe,Xte,aWe,nWe,zte,sWe,lWe,GOe,VL,OOe,MS,iWe,VOe,Nf,XOe,Si,If,Qte,XL,dWe,Wte,cWe,zOe,wo,zL,fWe,QL,mWe,ES,gWe,hWe,pWe,WL,_We,Hte,uWe,bWe,vWe,Lr,HL,FWe,Ute,TWe,MWe,Ri,EWe,Jte,CWe,wWe,Yte,AWe,LWe,yWe,A,qf,Kte,xWe,$We,CS,kWe,SWe,RWe,jf,Zte,PWe,BWe,wS,NWe,IWe,qWe,Df,eae,jWe,DWe,AS,GWe,OWe,VWe,Gf,oae,XWe,zWe,LS,QWe,WWe,HWe,Of,rae,UWe,JWe,yS,YWe,KWe,ZWe,Vf,tae,eHe,oHe,xS,rHe,tHe,aHe,Xf,aae,nHe,sHe,$S,lHe,iHe,dHe,zf,nae,cHe,fHe,kS,mHe,gHe,hHe,Qf,sae,pHe,_He,SS,uHe,bHe,vHe,Wf,lae,FHe,THe,RS,MHe,EHe,CHe,Hf,iae,wHe,AHe,PS,LHe,yHe,xHe,Uf,dae,$He,kHe,BS,SHe,RHe,PHe,Jf,cae,BHe,NHe,NS,IHe,qHe,jHe,Yf,fae,DHe,GHe,IS,OHe,VHe,XHe,Kf,mae,zHe,QHe,qS,WHe,HHe,UHe,Zf,gae,JHe,YHe,jS,KHe,ZHe,eUe,em,hae,oUe,rUe,DS,tUe,aUe,nUe,om,pae,sUe,lUe,GS,iUe,dUe,cUe,rm,_ae,fUe,mUe,OS,gUe,hUe,pUe,tm,uae,_Ue,uUe,VS,bUe,vUe,FUe,am,bae,TUe,MUe,XS,EUe,CUe,wUe,nm,vae,AUe,LUe,zS,yUe,xUe,$Ue,sm,Fae,kUe,SUe,QS,RUe,PUe,BUe,lm,Tae,NUe,IUe,WS,qUe,jUe,DUe,im,Mae,GUe,OUe,HS,VUe,XUe,zUe,dm,Eae,QUe,WUe,US,HUe,UUe,JUe,cm,Cae,YUe,KUe,JS,ZUe,eJe,oJe,fm,wae,rJe,tJe,YS,aJe,nJe,sJe,mm,Aae,lJe,iJe,KS,dJe,cJe,fJe,gm,Lae,mJe,gJe,ZS,hJe,pJe,_Je,hm,yae,uJe,bJe,eR,vJe,FJe,TJe,pm,xae,MJe,EJe,oR,CJe,wJe,AJe,_m,$ae,LJe,yJe,rR,xJe,$Je,kJe,um,kae,SJe,RJe,tR,PJe,BJe,NJe,bm,Sae,IJe,qJe,aR,jJe,DJe,GJe,vm,Rae,OJe,VJe,nR,XJe,zJe,QJe,Fm,Pae,WJe,HJe,sR,UJe,JJe,YJe,Tm,Bae,KJe,ZJe,lR,eYe,oYe,rYe,Mm,Nae,tYe,aYe,iR,nYe,sYe,lYe,Em,Iae,iYe,dYe,dR,cYe,fYe,mYe,Cm,qae,gYe,hYe,cR,pYe,_Ye,uYe,wm,jae,bYe,vYe,fR,FYe,TYe,MYe,Am,Dae,EYe,CYe,mR,wYe,AYe,LYe,Lm,Gae,yYe,xYe,gR,$Ye,kYe,SYe,ym,Oae,RYe,PYe,hR,BYe,NYe,IYe,xm,Vae,qYe,jYe,pR,DYe,GYe,OYe,$m,Xae,VYe,XYe,_R,zYe,QYe,WYe,km,zae,HYe,UYe,uR,JYe,YYe,KYe,Sm,Qae,ZYe,eKe,bR,oKe,rKe,tKe,Rm,Wae,aKe,nKe,vR,sKe,lKe,iKe,Pm,Hae,dKe,cKe,FR,fKe,mKe,gKe,Bm,Uae,hKe,pKe,TR,_Ke,uKe,bKe,Nm,Jae,vKe,FKe,MR,TKe,MKe,EKe,Im,Yae,CKe,wKe,ER,AKe,LKe,yKe,qm,Kae,xKe,$Ke,CR,kKe,SKe,RKe,jm,Zae,PKe,BKe,wR,NKe,IKe,qKe,Dm,ene,jKe,DKe,AR,GKe,OKe,VKe,Gm,one,XKe,zKe,LR,QKe,WKe,HKe,Om,rne,UKe,JKe,yR,YKe,KKe,ZKe,Vm,tne,eZe,oZe,xR,rZe,tZe,aZe,Xm,ane,nZe,sZe,$R,lZe,iZe,dZe,zm,nne,cZe,fZe,kR,mZe,gZe,hZe,Qm,sne,pZe,_Ze,SR,uZe,bZe,vZe,Wm,lne,FZe,TZe,RR,MZe,EZe,CZe,Hm,ine,wZe,AZe,PR,LZe,yZe,xZe,Um,dne,$Ze,kZe,BR,SZe,RZe,PZe,Jm,cne,BZe,NZe,NR,IZe,qZe,jZe,Ym,fne,DZe,GZe,IR,OZe,VZe,XZe,Km,mne,zZe,QZe,qR,WZe,HZe,UZe,Zm,gne,JZe,YZe,jR,KZe,ZZe,eeo,eg,hne,oeo,reo,DR,teo,aeo,neo,og,pne,seo,leo,GR,ieo,deo,ceo,rg,_ne,feo,meo,OR,geo,heo,peo,tg,une,_eo,ueo,VR,beo,veo,Feo,ag,bne,Teo,Meo,XR,Eeo,Ceo,weo,ng,vne,Aeo,Leo,zR,yeo,xeo,$eo,sg,Fne,keo,Seo,QR,Reo,Peo,Beo,lg,Tne,Neo,Ieo,WR,qeo,jeo,Deo,ig,Mne,Geo,Oeo,HR,Veo,Xeo,zeo,dg,Ene,Qeo,Weo,UR,Heo,Ueo,Jeo,cg,Cne,Yeo,Keo,JR,Zeo,eoo,ooo,fg,wne,roo,too,YR,aoo,noo,soo,mg,Ane,loo,ioo,KR,doo,coo,foo,gg,Lne,moo,goo,ZR,hoo,poo,_oo,hg,yne,uoo,boo,eP,voo,Foo,Too,pg,xne,Moo,Eoo,oP,Coo,woo,Aoo,_g,$ne,Loo,yoo,rP,xoo,$oo,koo,ug,kne,Soo,Roo,tP,Poo,Boo,Noo,bg,Sne,Ioo,qoo,aP,joo,Doo,Goo,vg,Rne,Ooo,Voo,nP,Xoo,zoo,Qoo,Fg,Pne,Woo,Hoo,sP,Uoo,Joo,Yoo,Tg,Bne,Koo,Zoo,lP,ero,oro,rro,Mg,Nne,tro,aro,iP,nro,sro,lro,Eg,Ine,iro,dro,dP,cro,fro,mro,Cg,qne,gro,hro,cP,pro,_ro,uro,wg,jne,bro,vro,fP,Fro,Tro,Mro,Ag,Dne,Ero,Cro,mP,wro,Aro,Lro,Lg,Gne,yro,xro,gP,$ro,kro,Sro,yg,One,Rro,Pro,hP,Bro,Nro,Iro,xg,Vne,qro,jro,pP,Dro,Gro,Oro,$g,Xne,Vro,Xro,_P,zro,Qro,Wro,kg,zne,Hro,Uro,uP,Jro,Yro,Kro,Sg,Qne,Zro,eto,bP,oto,rto,tto,Rg,Wne,ato,nto,vP,sto,lto,ito,Pg,Hne,dto,cto,FP,fto,mto,gto,Bg,Une,hto,pto,TP,_to,uto,bto,Ng,Jne,vto,Fto,MP,Tto,Mto,Eto,Ig,Yne,Cto,wto,EP,Ato,Lto,yto,qg,Kne,xto,$to,CP,kto,Sto,Rto,jg,Zne,Pto,Bto,wP,Nto,Ito,qto,Dg,ese,jto,Dto,AP,Gto,Oto,Vto,Gg,ose,Xto,zto,LP,Qto,Wto,Hto,Og,rse,Uto,Jto,yP,Yto,Kto,Zto,Vg,tse,eao,oao,xP,rao,tao,aao,Xg,ase,nao,sao,$P,lao,iao,dao,zg,nse,cao,fao,kP,mao,gao,hao,Qg,pao,Wg,UL,_ao,sse,uao,QOe,Pi,Hg,lse,JL,bao,ise,vao,WOe,Ao,YL,Fao,KL,Tao,SP,Mao,Eao,Cao,ZL,wao,dse,Aao,Lao,yao,yr,ey,xao,cse,$ao,kao,Ra,Sao,fse,Rao,Pao,mse,Bao,Nao,gse,Iao,qao,jao,k,jn,hse,Dao,Gao,RP,Oao,Vao,PP,Xao,zao,Qao,Dn,pse,Wao,Hao,BP,Uao,Jao,NP,Yao,Kao,Zao,Gn,_se,eno,ono,IP,rno,tno,qP,ano,nno,sno,Ug,use,lno,ino,jP,dno,cno,fno,On,bse,mno,gno,DP,hno,pno,GP,_no,uno,bno,Jg,vse,vno,Fno,OP,Tno,Mno,Eno,Yg,Fse,Cno,wno,VP,Ano,Lno,yno,Kg,Tse,xno,$no,XP,kno,Sno,Rno,Vn,Mse,Pno,Bno,zP,Nno,Ino,QP,qno,jno,Dno,Xn,Ese,Gno,Ono,WP,Vno,Xno,HP,zno,Qno,Wno,zn,Cse,Hno,Uno,UP,Jno,Yno,JP,Kno,Zno,eso,Zg,wse,oso,rso,YP,tso,aso,nso,eh,Ase,sso,lso,KP,iso,dso,cso,oh,Lse,fso,mso,ZP,gso,hso,pso,Qn,yse,_so,uso,eB,bso,vso,oB,Fso,Tso,Mso,rh,xse,Eso,Cso,rB,wso,Aso,Lso,Wn,$se,yso,xso,tB,$so,kso,aB,Sso,Rso,Pso,Hn,kse,Bso,Nso,nB,Iso,qso,sB,jso,Dso,Gso,Un,Sse,Oso,Vso,lB,Xso,zso,iB,Qso,Wso,Hso,Jn,Rse,Uso,Jso,dB,Yso,Kso,cB,Zso,elo,olo,th,Pse,rlo,tlo,fB,alo,nlo,slo,Yn,Bse,llo,ilo,mB,dlo,clo,gB,flo,mlo,glo,Kn,Nse,hlo,plo,hB,_lo,ulo,pB,blo,vlo,Flo,Zn,Ise,Tlo,Mlo,_B,Elo,Clo,uB,wlo,Alo,Llo,es,qse,ylo,xlo,bB,$lo,klo,vB,Slo,Rlo,Plo,os,jse,Blo,Nlo,FB,Ilo,qlo,TB,jlo,Dlo,Glo,rs,Dse,Olo,Vlo,MB,Xlo,zlo,EB,Qlo,Wlo,Hlo,ah,Gse,Ulo,Jlo,CB,Ylo,Klo,Zlo,ts,Ose,eio,oio,wB,rio,tio,AB,aio,nio,sio,nh,Vse,lio,iio,LB,dio,cio,fio,as,Xse,mio,gio,yB,hio,pio,xB,_io,uio,bio,ns,zse,vio,Fio,$B,Tio,Mio,kB,Eio,Cio,wio,ss,Qse,Aio,Lio,SB,yio,xio,RB,$io,kio,Sio,sh,Wse,Rio,Pio,PB,Bio,Nio,Iio,ls,Hse,qio,jio,BB,Dio,Gio,NB,Oio,Vio,Xio,is,Use,zio,Qio,IB,Wio,Hio,qB,Uio,Jio,Yio,ds,Jse,Kio,Zio,jB,edo,odo,DB,rdo,tdo,ado,lh,Yse,ndo,sdo,GB,ldo,ido,ddo,cs,Kse,cdo,fdo,OB,mdo,gdo,VB,hdo,pdo,_do,fs,Zse,udo,bdo,XB,vdo,Fdo,zB,Tdo,Mdo,Edo,ms,ele,Cdo,wdo,QB,Ado,Ldo,WB,ydo,xdo,$do,gs,ole,kdo,Sdo,HB,Rdo,Pdo,UB,Bdo,Ndo,Ido,hs,rle,qdo,jdo,JB,Ddo,Gdo,YB,Odo,Vdo,Xdo,ps,tle,zdo,Qdo,KB,Wdo,Hdo,ZB,Udo,Jdo,Ydo,_s,ale,Kdo,Zdo,eN,eco,oco,oN,rco,tco,aco,us,nle,nco,sco,rN,lco,ico,tN,dco,cco,fco,ih,sle,mco,gco,aN,hco,pco,_co,bs,lle,uco,bco,nN,vco,Fco,sN,Tco,Mco,Eco,dh,ile,Cco,wco,lN,Aco,Lco,yco,ch,dle,xco,$co,iN,kco,Sco,Rco,vs,cle,Pco,Bco,dN,Nco,Ico,cN,qco,jco,Dco,Fs,fle,Gco,Oco,fN,Vco,Xco,mN,zco,Qco,Wco,Ts,mle,Hco,Uco,gN,Jco,Yco,hN,Kco,Zco,efo,fh,gle,ofo,rfo,pN,tfo,afo,nfo,Ms,hle,sfo,lfo,_N,ifo,dfo,uN,cfo,ffo,mfo,Es,ple,gfo,hfo,bN,pfo,_fo,vN,ufo,bfo,vfo,Cs,_le,Ffo,Tfo,FN,Mfo,Efo,TN,Cfo,wfo,Afo,ws,ule,Lfo,yfo,MN,xfo,$fo,EN,kfo,Sfo,Rfo,As,ble,Pfo,Bfo,CN,Nfo,Ifo,wN,qfo,jfo,Dfo,Ls,vle,Gfo,Ofo,AN,Vfo,Xfo,LN,zfo,Qfo,Wfo,mh,Fle,Hfo,Ufo,yN,Jfo,Yfo,Kfo,ys,Tle,Zfo,emo,xN,omo,rmo,$N,tmo,amo,nmo,gh,Mle,smo,lmo,kN,imo,dmo,cmo,hh,Ele,fmo,mmo,SN,gmo,hmo,pmo,ph,Cle,_mo,umo,RN,bmo,vmo,Fmo,_h,wle,Tmo,Mmo,PN,Emo,Cmo,wmo,xs,Ale,Amo,Lmo,BN,ymo,xmo,NN,$mo,kmo,Smo,uh,Lle,Rmo,Pmo,IN,Bmo,Nmo,Imo,$s,yle,qmo,jmo,qN,Dmo,Gmo,jN,Omo,Vmo,Xmo,ks,xle,zmo,Qmo,DN,Wmo,Hmo,GN,Umo,Jmo,Ymo,Ss,$le,Kmo,Zmo,ON,ego,ogo,VN,rgo,tgo,ago,Rs,kle,ngo,sgo,XN,lgo,igo,zN,dgo,cgo,fgo,Ps,Sle,mgo,ggo,QN,hgo,pgo,WN,_go,ugo,bgo,Bs,Rle,vgo,Fgo,HN,Tgo,Mgo,UN,Ego,Cgo,wgo,bh,Ple,Ago,Lgo,JN,ygo,xgo,$go,vh,Ble,kgo,Sgo,YN,Rgo,Pgo,Bgo,Ns,Nle,Ngo,Igo,KN,qgo,jgo,ZN,Dgo,Ggo,Ogo,Is,Ile,Vgo,Xgo,eI,zgo,Qgo,oI,Wgo,Hgo,Ugo,qs,qle,Jgo,Ygo,rI,Kgo,Zgo,tI,eho,oho,rho,Fh,jle,tho,aho,aI,nho,sho,lho,Th,Dle,iho,dho,nI,cho,fho,mho,Mh,Gle,gho,hho,sI,pho,_ho,uho,js,Ole,bho,vho,lI,Fho,Tho,iI,Mho,Eho,Cho,Ds,Vle,who,Aho,dI,Lho,yho,cI,xho,$ho,kho,Eh,Xle,Sho,Rho,fI,Pho,Bho,Nho,Ch,zle,Iho,qho,mI,jho,Dho,Gho,wh,Qle,Oho,Vho,gI,Xho,zho,Qho,Gs,Wle,Who,Hho,hI,Uho,Jho,pI,Yho,Kho,Zho,Ah,Hle,epo,opo,_I,rpo,tpo,apo,Lh,Ule,npo,spo,uI,lpo,ipo,dpo,Os,Jle,cpo,fpo,bI,mpo,gpo,vI,hpo,ppo,_po,Vs,Yle,upo,bpo,FI,vpo,Fpo,TI,Tpo,Mpo,Epo,Xs,Kle,Cpo,wpo,MI,Apo,Lpo,EI,ypo,xpo,$po,zs,Zle,kpo,Spo,CI,Rpo,Ppo,wI,Bpo,Npo,Ipo,yh,qpo,xh,oy,jpo,eie,Dpo,HOe,Bi,$h,oie,ry,Gpo,rie,Opo,UOe,Lo,ty,Vpo,ay,Xpo,AI,zpo,Qpo,Wpo,ny,Hpo,tie,Upo,Jpo,Ypo,He,sy,Kpo,aie,Zpo,e_o,Pa,o_o,nie,r_o,t_o,sie,a_o,n_o,lie,s_o,l_o,i_o,Y,kh,iie,d_o,c_o,LI,f_o,m_o,g_o,Sh,die,h_o,p_o,yI,__o,u_o,b_o,Rh,cie,v_o,F_o,xI,T_o,M_o,E_o,Ph,fie,C_o,w_o,$I,A_o,L_o,y_o,Bh,mie,x_o,$_o,kI,k_o,S_o,R_o,Nh,gie,P_o,B_o,SI,N_o,I_o,q_o,Ih,hie,j_o,D_o,RI,G_o,O_o,V_o,qh,pie,X_o,z_o,PI,Q_o,W_o,H_o,jh,_ie,U_o,J_o,BI,Y_o,K_o,Z_o,Dh,uie,euo,ouo,NI,ruo,tuo,auo,Gh,bie,nuo,suo,II,luo,iuo,duo,Oh,vie,cuo,fuo,qI,muo,guo,huo,Vh,Fie,puo,_uo,jI,uuo,buo,vuo,Xh,Tie,Fuo,Tuo,DI,Muo,Euo,Cuo,zh,Mie,wuo,Auo,GI,Luo,yuo,xuo,Qh,Eie,$uo,kuo,OI,Suo,Ruo,Puo,Wh,Cie,Buo,Nuo,VI,Iuo,quo,juo,Hh,wie,Duo,Guo,XI,Ouo,Vuo,Xuo,Uh,Aie,zuo,Quo,zI,Wuo,Huo,Uuo,Jh,Lie,Juo,Yuo,QI,Kuo,Zuo,e2o,Yh,yie,o2o,r2o,WI,t2o,a2o,n2o,Kh,xie,s2o,l2o,HI,i2o,d2o,c2o,Zh,$ie,f2o,m2o,UI,g2o,h2o,p2o,ep,kie,_2o,u2o,JI,b2o,v2o,F2o,op,Sie,T2o,M2o,YI,E2o,C2o,w2o,rp,Rie,A2o,L2o,KI,y2o,x2o,$2o,tp,Pie,k2o,S2o,ZI,R2o,P2o,B2o,ap,Bie,N2o,I2o,eq,q2o,j2o,D2o,np,Nie,G2o,O2o,oq,V2o,X2o,z2o,sp,Iie,Q2o,W2o,rq,H2o,U2o,J2o,lp,qie,Y2o,K2o,tq,Z2o,e1o,o1o,ip,jie,r1o,t1o,aq,a1o,n1o,s1o,dp,Die,l1o,i1o,nq,d1o,c1o,f1o,cp,m1o,fp,g1o,mp,ly,h1o,Gie,p1o,JOe,Ni,gp,Oie,iy,_1o,Vie,u1o,YOe,yo,dy,b1o,cy,v1o,sq,F1o,T1o,M1o,fy,E1o,Xie,C1o,w1o,A1o,Ue,my,L1o,zie,y1o,x1o,Ii,$1o,Qie,k1o,S1o,Wie,R1o,P1o,B1o,he,hp,Hie,N1o,I1o,lq,q1o,j1o,D1o,pp,Uie,G1o,O1o,Jie,V1o,X1o,z1o,_p,Yie,Q1o,W1o,iq,H1o,U1o,J1o,up,Kie,Y1o,K1o,dq,Z1o,e7o,o7o,bp,Zie,r7o,t7o,cq,a7o,n7o,s7o,vp,ede,l7o,i7o,fq,d7o,c7o,f7o,Fp,ode,m7o,g7o,mq,h7o,p7o,_7o,Tp,rde,u7o,b7o,gq,v7o,F7o,T7o,Mp,tde,M7o,E7o,hq,C7o,w7o,A7o,Ep,ade,L7o,y7o,pq,x7o,$7o,k7o,Cp,nde,S7o,R7o,_q,P7o,B7o,N7o,wp,sde,I7o,q7o,uq,j7o,D7o,G7o,Ap,lde,O7o,V7o,bq,X7o,z7o,Q7o,Lp,ide,W7o,H7o,vq,U7o,J7o,Y7o,yp,dde,K7o,Z7o,Fq,e4o,o4o,r4o,xp,cde,t4o,a4o,Tq,n4o,s4o,l4o,$p,fde,i4o,d4o,Mq,c4o,f4o,m4o,kp,mde,g4o,h4o,Eq,p4o,_4o,u4o,Sp,b4o,Rp,v4o,Pp,gy,F4o,gde,T4o,KOe,qi,Bp,hde,hy,M4o,pde,E4o,ZOe,xo,py,C4o,ji,w4o,Cq,A4o,L4o,wq,y4o,x4o,$4o,_y,k4o,_de,S4o,R4o,P4o,st,uy,B4o,ude,N4o,I4o,Di,q4o,bde,j4o,D4o,Aq,G4o,O4o,V4o,Np,X4o,Je,by,z4o,vde,Q4o,W4o,Ba,H4o,Fde,U4o,J4o,Tde,Y4o,K4o,Mde,Z4o,ebo,obo,y,Ip,Ede,rbo,tbo,Lq,abo,nbo,sbo,qp,Cde,lbo,ibo,yq,dbo,cbo,fbo,jp,wde,mbo,gbo,xq,hbo,pbo,_bo,Dp,Ade,ubo,bbo,$q,vbo,Fbo,Tbo,Gp,Lde,Mbo,Ebo,kq,Cbo,wbo,Abo,Op,yde,Lbo,ybo,Sq,xbo,$bo,kbo,Vp,xde,Sbo,Rbo,Rq,Pbo,Bbo,Nbo,Xp,$de,Ibo,qbo,Pq,jbo,Dbo,Gbo,zp,kde,Obo,Vbo,Bq,Xbo,zbo,Qbo,Qp,Sde,Wbo,Hbo,Nq,Ubo,Jbo,Ybo,Wp,Rde,Kbo,Zbo,Iq,evo,ovo,rvo,Hp,Pde,tvo,avo,qq,nvo,svo,lvo,Up,Bde,ivo,dvo,jq,cvo,fvo,mvo,Jp,Nde,gvo,hvo,Dq,pvo,_vo,uvo,Yp,Ide,bvo,vvo,Gq,Fvo,Tvo,Mvo,Kp,qde,Evo,Cvo,Oq,wvo,Avo,Lvo,Zp,jde,yvo,xvo,Vq,$vo,kvo,Svo,e_,Dde,Rvo,Pvo,Xq,Bvo,Nvo,Ivo,o_,Gde,qvo,jvo,zq,Dvo,Gvo,Ovo,r_,Ode,Vvo,Xvo,Qq,zvo,Qvo,Wvo,t_,Vde,Hvo,Uvo,Wq,Jvo,Yvo,Kvo,a_,Xde,Zvo,eFo,Hq,oFo,rFo,tFo,n_,zde,aFo,nFo,Uq,sFo,lFo,iFo,s_,Qde,dFo,cFo,Jq,fFo,mFo,gFo,l_,Wde,hFo,pFo,Yq,_Fo,uFo,bFo,i_,Hde,vFo,FFo,Kq,TFo,MFo,EFo,d_,Ude,CFo,wFo,Zq,AFo,LFo,yFo,c_,Jde,xFo,$Fo,ej,kFo,SFo,RFo,f_,Yde,PFo,BFo,oj,NFo,IFo,qFo,m_,Kde,jFo,DFo,rj,GFo,OFo,VFo,g_,Zde,XFo,zFo,tj,QFo,WFo,HFo,h_,ece,UFo,JFo,aj,YFo,KFo,ZFo,p_,oce,eTo,oTo,nj,rTo,tTo,aTo,__,rce,nTo,sTo,sj,lTo,iTo,dTo,Qs,tce,cTo,fTo,lj,mTo,gTo,ij,hTo,pTo,_To,u_,ace,uTo,bTo,dj,vTo,FTo,TTo,b_,nce,MTo,ETo,cj,CTo,wTo,ATo,v_,sce,LTo,yTo,fj,xTo,$To,kTo,F_,lce,STo,RTo,mj,PTo,BTo,NTo,T_,ice,ITo,qTo,gj,jTo,DTo,GTo,M_,dce,OTo,VTo,hj,XTo,zTo,QTo,E_,cce,WTo,HTo,pj,UTo,JTo,YTo,C_,fce,KTo,ZTo,_j,eMo,oMo,rMo,w_,mce,tMo,aMo,uj,nMo,sMo,lMo,A_,gce,iMo,dMo,bj,cMo,fMo,mMo,L_,hce,gMo,hMo,vj,pMo,_Mo,uMo,y_,pce,bMo,vMo,Fj,FMo,TMo,MMo,x_,_ce,EMo,CMo,Tj,wMo,AMo,LMo,$_,uce,yMo,xMo,Mj,$Mo,kMo,SMo,k_,bce,RMo,PMo,Ej,BMo,NMo,IMo,S_,vce,qMo,jMo,Cj,DMo,GMo,OMo,R_,Fce,VMo,XMo,wj,zMo,QMo,WMo,P_,Tce,HMo,UMo,Aj,JMo,YMo,KMo,B_,Mce,ZMo,eEo,Lj,oEo,rEo,tEo,N_,Ece,aEo,nEo,yj,sEo,lEo,iEo,I_,Cce,dEo,cEo,xj,fEo,mEo,gEo,q_,wce,hEo,pEo,$j,_Eo,uEo,bEo,j_,Ace,vEo,FEo,kj,TEo,MEo,EEo,D_,Lce,CEo,wEo,Sj,AEo,LEo,yEo,G_,yce,xEo,$Eo,Rj,kEo,SEo,REo,O_,xce,PEo,BEo,Pj,NEo,IEo,qEo,V_,$ce,jEo,DEo,Bj,GEo,OEo,VEo,X_,kce,XEo,zEo,Nj,QEo,WEo,HEo,z_,Sce,UEo,JEo,Ij,YEo,KEo,ZEo,Q_,Rce,eCo,oCo,qj,rCo,tCo,aCo,W_,Pce,nCo,sCo,jj,lCo,iCo,dCo,H_,Bce,cCo,fCo,Dj,mCo,gCo,hCo,U_,Nce,pCo,_Co,Gj,uCo,bCo,vCo,J_,Ice,FCo,TCo,Oj,MCo,ECo,CCo,Y_,qce,wCo,ACo,Vj,LCo,yCo,xCo,K_,jce,$Co,kCo,Xj,SCo,RCo,PCo,Z_,Dce,BCo,NCo,zj,ICo,qCo,jCo,eu,Gce,DCo,GCo,Qj,OCo,VCo,XCo,ou,Oce,zCo,QCo,Wj,WCo,HCo,UCo,ru,Vce,JCo,YCo,Hj,KCo,ZCo,e3o,tu,Xce,o3o,r3o,Uj,t3o,a3o,n3o,au,zce,s3o,l3o,Jj,i3o,d3o,c3o,nu,Qce,f3o,m3o,Yj,g3o,h3o,p3o,su,Wce,_3o,u3o,Kj,b3o,v3o,F3o,lu,Hce,T3o,M3o,Zj,E3o,C3o,w3o,iu,Uce,A3o,L3o,eD,y3o,x3o,$3o,du,Jce,k3o,S3o,oD,R3o,P3o,B3o,cu,Yce,N3o,I3o,rD,q3o,j3o,D3o,fu,Kce,G3o,O3o,tD,V3o,X3o,z3o,mu,Zce,Q3o,W3o,aD,H3o,U3o,J3o,gu,efe,Y3o,K3o,nD,Z3o,e5o,o5o,hu,ofe,r5o,t5o,sD,a5o,n5o,s5o,pu,rfe,l5o,i5o,lD,d5o,c5o,f5o,_u,tfe,m5o,g5o,iD,h5o,p5o,_5o,uu,afe,u5o,b5o,dD,v5o,F5o,T5o,bu,nfe,M5o,E5o,cD,C5o,w5o,A5o,vu,sfe,L5o,y5o,fD,x5o,$5o,k5o,Fu,lfe,S5o,R5o,mD,P5o,B5o,N5o,Tu,ife,I5o,q5o,gD,j5o,D5o,G5o,Mu,dfe,O5o,V5o,hD,X5o,z5o,Q5o,Eu,cfe,W5o,H5o,pD,U5o,J5o,Y5o,Cu,ffe,K5o,Z5o,_D,e0o,o0o,r0o,wu,mfe,t0o,a0o,uD,n0o,s0o,l0o,Au,gfe,i0o,d0o,bD,c0o,f0o,m0o,Lu,hfe,g0o,h0o,vD,p0o,_0o,u0o,yu,pfe,b0o,v0o,FD,F0o,T0o,M0o,xu,_fe,E0o,C0o,TD,w0o,A0o,L0o,$u,ufe,y0o,x0o,MD,$0o,k0o,S0o,ku,bfe,R0o,P0o,ED,B0o,N0o,I0o,Su,vfe,q0o,j0o,CD,D0o,G0o,O0o,Ru,Ffe,V0o,X0o,wD,z0o,Q0o,W0o,Pu,Tfe,H0o,U0o,AD,J0o,Y0o,K0o,Bu,Mfe,Z0o,ewo,LD,owo,rwo,two,Nu,Efe,awo,nwo,yD,swo,lwo,iwo,Iu,dwo,Cfe,cwo,fwo,wfe,mwo,gwo,qu,eVe,Gi,ju,Afe,vy,hwo,Lfe,pwo,oVe,$o,Fy,_wo,Oi,uwo,xD,bwo,vwo,$D,Fwo,Two,Mwo,Ty,Ewo,yfe,Cwo,wwo,Awo,lt,My,Lwo,xfe,ywo,xwo,Vi,$wo,$fe,kwo,Swo,kD,Rwo,Pwo,Bwo,Du,Nwo,Ye,Ey,Iwo,kfe,qwo,jwo,Na,Dwo,Sfe,Gwo,Owo,Rfe,Vwo,Xwo,Pfe,zwo,Qwo,Wwo,G,Gu,Bfe,Hwo,Uwo,SD,Jwo,Ywo,Kwo,Ou,Nfe,Zwo,eAo,RD,oAo,rAo,tAo,Vu,Ife,aAo,nAo,PD,sAo,lAo,iAo,Xu,qfe,dAo,cAo,BD,fAo,mAo,gAo,zu,jfe,hAo,pAo,ND,_Ao,uAo,bAo,Qu,Dfe,vAo,FAo,ID,TAo,MAo,EAo,Wu,Gfe,CAo,wAo,qD,AAo,LAo,yAo,Hu,Ofe,xAo,$Ao,jD,kAo,SAo,RAo,Uu,Vfe,PAo,BAo,DD,NAo,IAo,qAo,Ju,Xfe,jAo,DAo,GD,GAo,OAo,VAo,Yu,zfe,XAo,zAo,OD,QAo,WAo,HAo,Ku,Qfe,UAo,JAo,VD,YAo,KAo,ZAo,Zu,Wfe,e6o,o6o,XD,r6o,t6o,a6o,e2,Hfe,n6o,s6o,zD,l6o,i6o,d6o,o2,Ufe,c6o,f6o,QD,m6o,g6o,h6o,r2,Jfe,p6o,_6o,WD,u6o,b6o,v6o,t2,Yfe,F6o,T6o,HD,M6o,E6o,C6o,a2,Kfe,w6o,A6o,UD,L6o,y6o,x6o,n2,Zfe,$6o,k6o,JD,S6o,R6o,P6o,s2,eme,B6o,N6o,YD,I6o,q6o,j6o,l2,ome,D6o,G6o,KD,O6o,V6o,X6o,i2,rme,z6o,Q6o,ZD,W6o,H6o,U6o,d2,tme,J6o,Y6o,eG,K6o,Z6o,eLo,c2,ame,oLo,rLo,oG,tLo,aLo,nLo,f2,nme,sLo,lLo,rG,iLo,dLo,cLo,m2,sme,fLo,mLo,tG,gLo,hLo,pLo,g2,lme,_Lo,uLo,aG,bLo,vLo,FLo,h2,ime,TLo,MLo,nG,ELo,CLo,wLo,p2,dme,ALo,LLo,sG,yLo,xLo,$Lo,_2,cme,kLo,SLo,lG,RLo,PLo,BLo,u2,fme,NLo,ILo,iG,qLo,jLo,DLo,b2,mme,GLo,OLo,dG,VLo,XLo,zLo,v2,gme,QLo,WLo,cG,HLo,ULo,JLo,F2,hme,YLo,KLo,fG,ZLo,eyo,oyo,T2,pme,ryo,tyo,mG,ayo,nyo,syo,M2,_me,lyo,iyo,gG,dyo,cyo,fyo,E2,ume,myo,gyo,hG,hyo,pyo,_yo,C2,bme,uyo,byo,pG,vyo,Fyo,Tyo,w2,vme,Myo,Eyo,_G,Cyo,wyo,Ayo,A2,Fme,Lyo,yyo,uG,xyo,$yo,kyo,L2,Tme,Syo,Ryo,bG,Pyo,Byo,Nyo,y2,Mme,Iyo,qyo,vG,jyo,Dyo,Gyo,x2,Eme,Oyo,Vyo,FG,Xyo,zyo,Qyo,$2,Cme,Wyo,Hyo,TG,Uyo,Jyo,Yyo,k2,Kyo,wme,Zyo,e8o,Ame,o8o,r8o,S2,rVe,Xi,R2,Lme,Cy,t8o,yme,a8o,tVe,ko,wy,n8o,zi,s8o,MG,l8o,i8o,EG,d8o,c8o,f8o,Ay,m8o,xme,g8o,h8o,p8o,it,Ly,_8o,$me,u8o,b8o,Qi,v8o,kme,F8o,T8o,CG,M8o,E8o,C8o,P2,w8o,Ke,yy,A8o,Sme,L8o,y8o,Ia,x8o,Rme,$8o,k8o,Pme,S8o,R8o,Bme,P8o,B8o,N8o,z,B2,Nme,I8o,q8o,wG,j8o,D8o,G8o,N2,Ime,O8o,V8o,AG,X8o,z8o,Q8o,I2,qme,W8o,H8o,LG,U8o,J8o,Y8o,q2,jme,K8o,Z8o,yG,e9o,o9o,r9o,j2,Dme,t9o,a9o,xG,n9o,s9o,l9o,D2,Gme,i9o,d9o,$G,c9o,f9o,m9o,G2,Ome,g9o,h9o,kG,p9o,_9o,u9o,O2,Vme,b9o,v9o,SG,F9o,T9o,M9o,V2,Xme,E9o,C9o,RG,w9o,A9o,L9o,X2,zme,y9o,x9o,PG,$9o,k9o,S9o,z2,Qme,R9o,P9o,BG,B9o,N9o,I9o,Q2,Wme,q9o,j9o,NG,D9o,G9o,O9o,W2,Hme,V9o,X9o,IG,z9o,Q9o,W9o,H2,Ume,H9o,U9o,qG,J9o,Y9o,K9o,U2,Jme,Z9o,exo,jG,oxo,rxo,txo,J2,Yme,axo,nxo,DG,sxo,lxo,ixo,Y2,Kme,dxo,cxo,GG,fxo,mxo,gxo,K2,Zme,hxo,pxo,OG,_xo,uxo,bxo,Z2,ege,vxo,Fxo,VG,Txo,Mxo,Exo,e1,oge,Cxo,wxo,XG,Axo,Lxo,yxo,o1,rge,xxo,$xo,zG,kxo,Sxo,Rxo,r1,tge,Pxo,Bxo,QG,Nxo,Ixo,qxo,t1,age,jxo,Dxo,WG,Gxo,Oxo,Vxo,a1,nge,Xxo,zxo,HG,Qxo,Wxo,Hxo,n1,sge,Uxo,Jxo,UG,Yxo,Kxo,Zxo,s1,lge,e$o,o$o,JG,r$o,t$o,a$o,l1,ige,n$o,s$o,YG,l$o,i$o,d$o,i1,dge,c$o,f$o,KG,m$o,g$o,h$o,d1,cge,p$o,_$o,ZG,u$o,b$o,v$o,c1,fge,F$o,T$o,eO,M$o,E$o,C$o,f1,mge,w$o,A$o,oO,L$o,y$o,x$o,m1,gge,$$o,k$o,rO,S$o,R$o,P$o,g1,hge,B$o,N$o,tO,I$o,q$o,j$o,h1,pge,D$o,G$o,aO,O$o,V$o,X$o,p1,_ge,z$o,Q$o,nO,W$o,H$o,U$o,_1,uge,J$o,Y$o,sO,K$o,Z$o,eko,u1,bge,oko,rko,lO,tko,ako,nko,b1,vge,sko,lko,iO,iko,dko,cko,v1,Fge,fko,mko,dO,gko,hko,pko,F1,_ko,Tge,uko,bko,Mge,vko,Fko,T1,aVe,Wi,M1,Ege,xy,Tko,Cge,Mko,nVe,So,$y,Eko,Hi,Cko,cO,wko,Ako,fO,Lko,yko,xko,ky,$ko,wge,kko,Sko,Rko,dt,Sy,Pko,Age,Bko,Nko,Ui,Iko,Lge,qko,jko,mO,Dko,Gko,Oko,E1,Vko,Ze,Ry,Xko,yge,zko,Qko,qa,Wko,xge,Hko,Uko,$ge,Jko,Yko,kge,Kko,Zko,eSo,W,C1,Sge,oSo,rSo,gO,tSo,aSo,nSo,w1,Rge,sSo,lSo,hO,iSo,dSo,cSo,A1,Pge,fSo,mSo,pO,gSo,hSo,pSo,L1,Bge,_So,uSo,_O,bSo,vSo,FSo,y1,Nge,TSo,MSo,uO,ESo,CSo,wSo,x1,Ige,ASo,LSo,bO,ySo,xSo,$So,$1,qge,kSo,SSo,vO,RSo,PSo,BSo,k1,jge,NSo,ISo,FO,qSo,jSo,DSo,S1,Dge,GSo,OSo,TO,VSo,XSo,zSo,R1,Gge,QSo,WSo,MO,HSo,USo,JSo,P1,Oge,YSo,KSo,EO,ZSo,eRo,oRo,B1,Vge,rRo,tRo,CO,aRo,nRo,sRo,N1,Xge,lRo,iRo,wO,dRo,cRo,fRo,I1,zge,mRo,gRo,AO,hRo,pRo,_Ro,q1,Qge,uRo,bRo,LO,vRo,FRo,TRo,j1,Wge,MRo,ERo,yO,CRo,wRo,ARo,D1,Hge,LRo,yRo,xO,xRo,$Ro,kRo,G1,Uge,SRo,RRo,$O,PRo,BRo,NRo,O1,Jge,IRo,qRo,kO,jRo,DRo,GRo,V1,Yge,ORo,VRo,SO,XRo,zRo,QRo,X1,Kge,WRo,HRo,RO,URo,JRo,YRo,z1,Zge,KRo,ZRo,PO,ePo,oPo,rPo,Q1,ehe,tPo,aPo,BO,nPo,sPo,lPo,W1,ohe,iPo,dPo,NO,cPo,fPo,mPo,H1,rhe,gPo,hPo,IO,pPo,_Po,uPo,U1,the,bPo,vPo,qO,FPo,TPo,MPo,J1,ahe,EPo,CPo,jO,wPo,APo,LPo,Y1,nhe,yPo,xPo,DO,$Po,kPo,SPo,K1,she,RPo,PPo,GO,BPo,NPo,IPo,Z1,lhe,qPo,jPo,OO,DPo,GPo,OPo,e7,ihe,VPo,XPo,VO,zPo,QPo,WPo,o7,dhe,HPo,UPo,XO,JPo,YPo,KPo,r7,che,ZPo,eBo,fhe,oBo,rBo,tBo,t7,mhe,aBo,nBo,zO,sBo,lBo,iBo,a7,ghe,dBo,cBo,QO,fBo,mBo,gBo,n7,hhe,hBo,pBo,WO,_Bo,uBo,bBo,s7,phe,vBo,FBo,HO,TBo,MBo,EBo,l7,CBo,_he,wBo,ABo,uhe,LBo,yBo,i7,sVe,Ji,d7,bhe,Py,xBo,vhe,$Bo,lVe,Ro,By,kBo,Yi,SBo,UO,RBo,PBo,JO,BBo,NBo,IBo,Ny,qBo,Fhe,jBo,DBo,GBo,ct,Iy,OBo,The,VBo,XBo,Ki,zBo,Mhe,QBo,WBo,YO,HBo,UBo,JBo,c7,YBo,eo,qy,KBo,Ehe,ZBo,eNo,ja,oNo,Che,rNo,tNo,whe,aNo,nNo,Ahe,sNo,lNo,iNo,pe,f7,Lhe,dNo,cNo,KO,fNo,mNo,gNo,m7,yhe,hNo,pNo,ZO,_No,uNo,bNo,g7,xhe,vNo,FNo,eV,TNo,MNo,ENo,h7,$he,CNo,wNo,oV,ANo,LNo,yNo,p7,khe,xNo,$No,rV,kNo,SNo,RNo,_7,She,PNo,BNo,tV,NNo,INo,qNo,u7,Rhe,jNo,DNo,aV,GNo,ONo,VNo,b7,Phe,XNo,zNo,nV,QNo,WNo,HNo,v7,Bhe,UNo,JNo,sV,YNo,KNo,ZNo,F7,Nhe,eIo,oIo,lV,rIo,tIo,aIo,T7,Ihe,nIo,sIo,iV,lIo,iIo,dIo,M7,qhe,cIo,fIo,dV,mIo,gIo,hIo,E7,jhe,pIo,_Io,cV,uIo,bIo,vIo,C7,Dhe,FIo,TIo,fV,MIo,EIo,CIo,w7,Ghe,wIo,AIo,mV,LIo,yIo,xIo,A7,Ohe,$Io,kIo,gV,SIo,RIo,PIo,L7,Vhe,BIo,NIo,hV,IIo,qIo,jIo,y7,DIo,Xhe,GIo,OIo,zhe,VIo,XIo,x7,iVe,Zi,$7,Qhe,jy,zIo,Whe,QIo,dVe,Po,Dy,WIo,ed,HIo,pV,UIo,JIo,_V,YIo,KIo,ZIo,Gy,eqo,Hhe,oqo,rqo,tqo,ft,Oy,aqo,Uhe,nqo,sqo,od,lqo,Jhe,iqo,dqo,uV,cqo,fqo,mqo,k7,gqo,oo,Vy,hqo,Yhe,pqo,_qo,Da,uqo,Khe,bqo,vqo,Zhe,Fqo,Tqo,epe,Mqo,Eqo,Cqo,I,S7,ope,wqo,Aqo,bV,Lqo,yqo,xqo,R7,rpe,$qo,kqo,vV,Sqo,Rqo,Pqo,P7,tpe,Bqo,Nqo,FV,Iqo,qqo,jqo,B7,ape,Dqo,Gqo,TV,Oqo,Vqo,Xqo,N7,npe,zqo,Qqo,MV,Wqo,Hqo,Uqo,I7,spe,Jqo,Yqo,EV,Kqo,Zqo,ejo,q7,lpe,ojo,rjo,CV,tjo,ajo,njo,j7,ipe,sjo,ljo,wV,ijo,djo,cjo,D7,dpe,fjo,mjo,AV,gjo,hjo,pjo,G7,cpe,_jo,ujo,LV,bjo,vjo,Fjo,O7,fpe,Tjo,Mjo,yV,Ejo,Cjo,wjo,V7,mpe,Ajo,Ljo,xV,yjo,xjo,$jo,X7,gpe,kjo,Sjo,$V,Rjo,Pjo,Bjo,z7,hpe,Njo,Ijo,kV,qjo,jjo,Djo,Q7,ppe,Gjo,Ojo,SV,Vjo,Xjo,zjo,W7,_pe,Qjo,Wjo,RV,Hjo,Ujo,Jjo,H7,upe,Yjo,Kjo,PV,Zjo,eDo,oDo,U7,bpe,rDo,tDo,BV,aDo,nDo,sDo,J7,vpe,lDo,iDo,NV,dDo,cDo,fDo,Y7,Fpe,mDo,gDo,IV,hDo,pDo,_Do,K7,Tpe,uDo,bDo,qV,vDo,FDo,TDo,Z7,Mpe,MDo,EDo,jV,CDo,wDo,ADo,e4,Epe,LDo,yDo,DV,xDo,$Do,kDo,o4,Cpe,SDo,RDo,GV,PDo,BDo,NDo,r4,wpe,IDo,qDo,OV,jDo,DDo,GDo,t4,Ape,ODo,VDo,VV,XDo,zDo,QDo,a4,Lpe,WDo,HDo,XV,UDo,JDo,YDo,n4,ype,KDo,ZDo,zV,eGo,oGo,rGo,s4,xpe,tGo,aGo,QV,nGo,sGo,lGo,l4,$pe,iGo,dGo,WV,cGo,fGo,mGo,i4,kpe,gGo,hGo,HV,pGo,_Go,uGo,d4,Spe,bGo,vGo,UV,FGo,TGo,MGo,c4,Rpe,EGo,CGo,JV,wGo,AGo,LGo,f4,Ppe,yGo,xGo,YV,$Go,kGo,SGo,m4,Bpe,RGo,PGo,KV,BGo,NGo,IGo,g4,Npe,qGo,jGo,ZV,DGo,GGo,OGo,h4,Ipe,VGo,XGo,eX,zGo,QGo,WGo,p4,qpe,HGo,UGo,oX,JGo,YGo,KGo,_4,jpe,ZGo,eOo,rX,oOo,rOo,tOo,u4,Dpe,aOo,nOo,tX,sOo,lOo,iOo,b4,Gpe,dOo,cOo,aX,fOo,mOo,gOo,v4,Ope,hOo,pOo,nX,_Oo,uOo,bOo,F4,Vpe,vOo,FOo,sX,TOo,MOo,EOo,T4,Xpe,COo,wOo,lX,AOo,LOo,yOo,M4,zpe,xOo,$Oo,iX,kOo,SOo,ROo,E4,Qpe,POo,BOo,dX,NOo,IOo,qOo,C4,Wpe,jOo,DOo,cX,GOo,OOo,VOo,w4,Hpe,XOo,zOo,fX,QOo,WOo,HOo,A4,Upe,UOo,JOo,mX,YOo,KOo,ZOo,L4,eVo,Jpe,oVo,rVo,Ype,tVo,aVo,y4,cVe,rd,x4,Kpe,Xy,nVo,Zpe,sVo,fVe,Bo,zy,lVo,td,iVo,gX,dVo,cVo,hX,fVo,mVo,gVo,Qy,hVo,e_e,pVo,_Vo,uVo,mt,Wy,bVo,o_e,vVo,FVo,ad,TVo,r_e,MVo,EVo,pX,CVo,wVo,AVo,$4,LVo,ro,Hy,yVo,t_e,xVo,$Vo,Ga,kVo,a_e,SVo,RVo,n_e,PVo,BVo,s_e,NVo,IVo,qVo,Z,k4,l_e,jVo,DVo,_X,GVo,OVo,VVo,S4,i_e,XVo,zVo,uX,QVo,WVo,HVo,R4,d_e,UVo,JVo,bX,YVo,KVo,ZVo,P4,c_e,eXo,oXo,vX,rXo,tXo,aXo,B4,f_e,nXo,sXo,FX,lXo,iXo,dXo,N4,m_e,cXo,fXo,TX,mXo,gXo,hXo,I4,g_e,pXo,_Xo,MX,uXo,bXo,vXo,q4,h_e,FXo,TXo,EX,MXo,EXo,CXo,j4,p_e,wXo,AXo,CX,LXo,yXo,xXo,D4,__e,$Xo,kXo,wX,SXo,RXo,PXo,G4,u_e,BXo,NXo,AX,IXo,qXo,jXo,O4,b_e,DXo,GXo,LX,OXo,VXo,XXo,V4,v_e,zXo,QXo,yX,WXo,HXo,UXo,X4,F_e,JXo,YXo,xX,KXo,ZXo,ezo,z4,T_e,ozo,rzo,$X,tzo,azo,nzo,Q4,M_e,szo,lzo,kX,izo,dzo,czo,W4,E_e,fzo,mzo,SX,gzo,hzo,pzo,H4,C_e,_zo,uzo,RX,bzo,vzo,Fzo,U4,w_e,Tzo,Mzo,PX,Ezo,Czo,wzo,J4,A_e,Azo,Lzo,BX,yzo,xzo,$zo,Y4,L_e,kzo,Szo,NX,Rzo,Pzo,Bzo,K4,y_e,Nzo,Izo,IX,qzo,jzo,Dzo,Z4,x_e,Gzo,Ozo,qX,Vzo,Xzo,zzo,eb,$_e,Qzo,Wzo,jX,Hzo,Uzo,Jzo,ob,k_e,Yzo,Kzo,DX,Zzo,eQo,oQo,rb,S_e,rQo,tQo,GX,aQo,nQo,sQo,tb,R_e,lQo,iQo,OX,dQo,cQo,fQo,ab,P_e,mQo,gQo,VX,hQo,pQo,_Qo,nb,B_e,uQo,bQo,XX,vQo,FQo,TQo,sb,N_e,MQo,EQo,zX,CQo,wQo,AQo,lb,LQo,I_e,yQo,xQo,q_e,$Qo,kQo,ib,mVe,nd,db,j_e,Uy,SQo,D_e,RQo,gVe,No,Jy,PQo,sd,BQo,QX,NQo,IQo,WX,qQo,jQo,DQo,Yy,GQo,G_e,OQo,VQo,XQo,gt,Ky,zQo,O_e,QQo,WQo,ld,HQo,V_e,UQo,JQo,HX,YQo,KQo,ZQo,cb,eWo,to,Zy,oWo,X_e,rWo,tWo,Oa,aWo,z_e,nWo,sWo,Q_e,lWo,iWo,W_e,dWo,cWo,fWo,Io,fb,H_e,mWo,gWo,UX,hWo,pWo,_Wo,mb,U_e,uWo,bWo,JX,vWo,FWo,TWo,gb,J_e,MWo,EWo,YX,CWo,wWo,AWo,hb,Y_e,LWo,yWo,KX,xWo,$Wo,kWo,pb,K_e,SWo,RWo,ZX,PWo,BWo,NWo,_b,Z_e,IWo,qWo,ez,jWo,DWo,GWo,ub,OWo,eue,VWo,XWo,oue,zWo,QWo,bb,hVe,id,vb,rue,e8,WWo,tue,HWo,pVe,qo,o8,UWo,dd,JWo,oz,YWo,KWo,rz,ZWo,eHo,oHo,r8,rHo,aue,tHo,aHo,nHo,ht,t8,sHo,nue,lHo,iHo,cd,dHo,sue,cHo,fHo,tz,mHo,gHo,hHo,Fb,pHo,ao,a8,_Ho,lue,uHo,bHo,Va,vHo,iue,FHo,THo,due,MHo,EHo,cue,CHo,wHo,AHo,H,Tb,fue,LHo,yHo,az,xHo,$Ho,kHo,Mb,mue,SHo,RHo,nz,PHo,BHo,NHo,Eb,gue,IHo,qHo,sz,jHo,DHo,GHo,Cb,hue,OHo,VHo,lz,XHo,zHo,QHo,wb,pue,WHo,HHo,iz,UHo,JHo,YHo,Ab,_ue,KHo,ZHo,dz,eUo,oUo,rUo,Lb,uue,tUo,aUo,cz,nUo,sUo,lUo,yb,bue,iUo,dUo,fz,cUo,fUo,mUo,xb,vue,gUo,hUo,mz,pUo,_Uo,uUo,$b,Fue,bUo,vUo,gz,FUo,TUo,MUo,kb,Tue,EUo,CUo,hz,wUo,AUo,LUo,Sb,Mue,yUo,xUo,pz,$Uo,kUo,SUo,Rb,Eue,RUo,PUo,_z,BUo,NUo,IUo,Pb,Cue,qUo,jUo,uz,DUo,GUo,OUo,Bb,wue,VUo,XUo,bz,zUo,QUo,WUo,Nb,Aue,HUo,UUo,vz,JUo,YUo,KUo,Ib,Lue,ZUo,eJo,Fz,oJo,rJo,tJo,qb,yue,aJo,nJo,Tz,sJo,lJo,iJo,jb,xue,dJo,cJo,Mz,fJo,mJo,gJo,Db,$ue,hJo,pJo,Ez,_Jo,uJo,bJo,Gb,kue,vJo,FJo,Cz,TJo,MJo,EJo,Ob,Sue,CJo,wJo,wz,AJo,LJo,yJo,Vb,Rue,xJo,$Jo,Az,kJo,SJo,RJo,Xb,Pue,PJo,BJo,Lz,NJo,IJo,qJo,zb,Bue,jJo,DJo,yz,GJo,OJo,VJo,Qb,Nue,XJo,zJo,xz,QJo,WJo,HJo,Wb,Iue,UJo,JJo,$z,YJo,KJo,ZJo,Hb,que,eYo,oYo,kz,rYo,tYo,aYo,Ub,jue,nYo,sYo,Sz,lYo,iYo,dYo,Jb,Due,cYo,fYo,Rz,mYo,gYo,hYo,Yb,Gue,pYo,_Yo,Pz,uYo,bYo,vYo,Kb,Oue,FYo,TYo,Bz,MYo,EYo,CYo,Zb,Vue,wYo,AYo,Nz,LYo,yYo,xYo,ev,Xue,$Yo,kYo,Iz,SYo,RYo,PYo,ov,zue,BYo,NYo,qz,IYo,qYo,jYo,rv,Que,DYo,GYo,jz,OYo,VYo,XYo,tv,zYo,Wue,QYo,WYo,Hue,HYo,UYo,av,_Ve,fd,nv,Uue,n8,JYo,Jue,YYo,uVe,jo,s8,KYo,md,ZYo,Dz,eKo,oKo,Gz,rKo,tKo,aKo,l8,nKo,Yue,sKo,lKo,iKo,pt,i8,dKo,Kue,cKo,fKo,gd,mKo,Zue,gKo,hKo,Oz,pKo,_Ko,uKo,sv,bKo,no,d8,vKo,e2e,FKo,TKo,Xa,MKo,o2e,EKo,CKo,r2e,wKo,AKo,t2e,LKo,yKo,xKo,V,lv,a2e,$Ko,kKo,Vz,SKo,RKo,PKo,iv,n2e,BKo,NKo,Xz,IKo,qKo,jKo,dv,s2e,DKo,GKo,zz,OKo,VKo,XKo,cv,l2e,zKo,QKo,Qz,WKo,HKo,UKo,fv,i2e,JKo,YKo,Wz,KKo,ZKo,eZo,mv,d2e,oZo,rZo,Hz,tZo,aZo,nZo,gv,c2e,sZo,lZo,Uz,iZo,dZo,cZo,hv,f2e,fZo,mZo,Jz,gZo,hZo,pZo,pv,m2e,_Zo,uZo,Yz,bZo,vZo,FZo,_v,g2e,TZo,MZo,Kz,EZo,CZo,wZo,uv,h2e,AZo,LZo,Zz,yZo,xZo,$Zo,bv,p2e,kZo,SZo,eQ,RZo,PZo,BZo,vv,_2e,NZo,IZo,oQ,qZo,jZo,DZo,Fv,u2e,GZo,OZo,rQ,VZo,XZo,zZo,Tv,b2e,QZo,WZo,tQ,HZo,UZo,JZo,Mv,v2e,YZo,KZo,aQ,ZZo,eer,oer,Ev,F2e,rer,ter,nQ,aer,ner,ser,Cv,T2e,ler,ier,sQ,der,cer,fer,wv,M2e,mer,ger,lQ,her,per,_er,Av,E2e,uer,ber,iQ,ver,Fer,Ter,Lv,C2e,Mer,Eer,dQ,Cer,wer,Aer,yv,w2e,Ler,yer,cQ,xer,$er,ker,xv,A2e,Ser,Rer,fQ,Per,Ber,Ner,$v,L2e,Ier,qer,mQ,jer,Der,Ger,kv,y2e,Oer,Ver,gQ,Xer,zer,Qer,Sv,x2e,Wer,Her,hQ,Uer,Jer,Yer,Rv,$2e,Ker,Zer,pQ,eor,oor,ror,Pv,k2e,tor,aor,_Q,nor,sor,lor,Bv,S2e,ior,dor,uQ,cor,mor,gor,Nv,R2e,hor,por,bQ,_or,uor,bor,Iv,P2e,vor,For,vQ,Tor,Mor,Eor,qv,B2e,Cor,wor,FQ,Aor,Lor,yor,jv,N2e,xor,$or,TQ,kor,Sor,Ror,Dv,I2e,Por,Bor,MQ,Nor,Ior,qor,Gv,q2e,jor,Dor,EQ,Gor,Oor,Vor,Ov,j2e,Xor,zor,CQ,Qor,Wor,Hor,Vv,D2e,Uor,Jor,wQ,Yor,Kor,Zor,Xv,G2e,err,orr,AQ,rrr,trr,arr,zv,O2e,nrr,srr,LQ,lrr,irr,drr,Qv,V2e,crr,frr,yQ,mrr,grr,hrr,Wv,X2e,prr,_rr,xQ,urr,brr,vrr,Hv,Frr,z2e,Trr,Mrr,Q2e,Err,Crr,Uv,bVe,hd,Jv,W2e,c8,wrr,H2e,Arr,vVe,Do,f8,Lrr,pd,yrr,$Q,xrr,$rr,kQ,krr,Srr,Rrr,m8,Prr,U2e,Brr,Nrr,Irr,_t,g8,qrr,J2e,jrr,Drr,_d,Grr,Y2e,Orr,Vrr,SQ,Xrr,zrr,Qrr,Yv,Wrr,so,h8,Hrr,K2e,Urr,Jrr,za,Yrr,Z2e,Krr,Zrr,e1e,etr,otr,o1e,rtr,ttr,atr,r1e,Kv,t1e,ntr,str,RQ,ltr,itr,dtr,Zv,ctr,a1e,ftr,mtr,n1e,gtr,htr,eF,FVe,ud,oF,s1e,p8,ptr,l1e,_tr,TVe,Go,_8,utr,bd,btr,PQ,vtr,Ftr,BQ,Ttr,Mtr,Etr,u8,Ctr,i1e,wtr,Atr,Ltr,ut,b8,ytr,d1e,xtr,$tr,vd,ktr,c1e,Str,Rtr,NQ,Ptr,Btr,Ntr,rF,Itr,lo,v8,qtr,f1e,jtr,Dtr,Qa,Gtr,m1e,Otr,Vtr,g1e,Xtr,ztr,h1e,Qtr,Wtr,Htr,Fe,tF,p1e,Utr,Jtr,IQ,Ytr,Ktr,Ztr,aF,_1e,ear,oar,qQ,rar,tar,aar,nF,u1e,nar,sar,jQ,lar,iar,dar,sF,b1e,car,far,DQ,mar,gar,har,Ws,v1e,par,_ar,GQ,uar,bar,OQ,Far,Tar,Mar,lF,F1e,Ear,Car,VQ,war,Aar,Lar,Hs,T1e,yar,xar,XQ,$ar,kar,zQ,Sar,Rar,Par,bt,M1e,Bar,Nar,QQ,Iar,qar,WQ,jar,Dar,HQ,Gar,Oar,Var,iF,E1e,Xar,zar,UQ,Qar,War,Har,dF,C1e,Uar,Jar,JQ,Yar,Kar,Zar,cF,w1e,enr,onr,YQ,rnr,tnr,anr,fF,A1e,nnr,snr,KQ,lnr,inr,dnr,mF,L1e,cnr,fnr,ZQ,mnr,gnr,hnr,gF,y1e,pnr,_nr,eW,unr,bnr,vnr,hF,x1e,Fnr,Tnr,oW,Mnr,Enr,Cnr,pF,wnr,$1e,Anr,Lnr,k1e,ynr,xnr,_F,MVe,Fd,uF,S1e,F8,$nr,R1e,knr,EVe,Oo,T8,Snr,Td,Rnr,rW,Pnr,Bnr,tW,Nnr,Inr,qnr,M8,jnr,P1e,Dnr,Gnr,Onr,vt,E8,Vnr,B1e,Xnr,znr,Md,Qnr,N1e,Wnr,Hnr,aW,Unr,Jnr,Ynr,bF,Knr,io,C8,Znr,I1e,esr,osr,Wa,rsr,q1e,tsr,asr,j1e,nsr,ssr,D1e,lsr,isr,dsr,G1e,vF,O1e,csr,fsr,nW,msr,gsr,hsr,FF,psr,V1e,_sr,usr,X1e,bsr,vsr,TF,CVe,Ed,MF,z1e,w8,Fsr,Q1e,Tsr,wVe,Vo,A8,Msr,Cd,Esr,sW,Csr,wsr,lW,Asr,Lsr,ysr,L8,xsr,W1e,$sr,ksr,Ssr,Ft,y8,Rsr,H1e,Psr,Bsr,wd,Nsr,U1e,Isr,qsr,iW,jsr,Dsr,Gsr,EF,Osr,co,x8,Vsr,J1e,Xsr,zsr,Ha,Qsr,Y1e,Wsr,Hsr,K1e,Usr,Jsr,Z1e,Ysr,Ksr,Zsr,e7e,CF,o7e,elr,olr,dW,rlr,tlr,alr,wF,nlr,r7e,slr,llr,t7e,ilr,dlr,AF,AVe,Ad,LF,a7e,$8,clr,n7e,flr,LVe,Xo,k8,mlr,Ld,glr,cW,hlr,plr,fW,_lr,ulr,blr,S8,vlr,s7e,Flr,Tlr,Mlr,Tt,R8,Elr,l7e,Clr,wlr,yd,Alr,i7e,Llr,ylr,mW,xlr,$lr,klr,yF,Slr,fo,P8,Rlr,d7e,Plr,Blr,Ua,Nlr,c7e,Ilr,qlr,f7e,jlr,Dlr,m7e,Glr,Olr,Vlr,Pe,xF,g7e,Xlr,zlr,gW,Qlr,Wlr,Hlr,$F,h7e,Ulr,Jlr,hW,Ylr,Klr,Zlr,kF,p7e,eir,oir,pW,rir,tir,air,SF,_7e,nir,sir,_W,lir,iir,dir,RF,u7e,cir,fir,uW,mir,gir,hir,PF,b7e,pir,_ir,bW,uir,bir,vir,BF,v7e,Fir,Tir,vW,Mir,Eir,Cir,NF,F7e,wir,Air,FW,Lir,yir,xir,IF,T7e,$ir,kir,TW,Sir,Rir,Pir,qF,Bir,M7e,Nir,Iir,E7e,qir,jir,jF,yVe,xd,DF,C7e,B8,Dir,w7e,Gir,xVe,zo,N8,Oir,$d,Vir,MW,Xir,zir,EW,Qir,Wir,Hir,I8,Uir,A7e,Jir,Yir,Kir,Mt,q8,Zir,L7e,edr,odr,kd,rdr,y7e,tdr,adr,CW,ndr,sdr,ldr,GF,idr,mo,j8,ddr,x7e,cdr,fdr,Ja,mdr,$7e,gdr,hdr,k7e,pdr,_dr,S7e,udr,bdr,vdr,ot,OF,R7e,Fdr,Tdr,wW,Mdr,Edr,Cdr,VF,P7e,wdr,Adr,AW,Ldr,ydr,xdr,XF,B7e,$dr,kdr,LW,Sdr,Rdr,Pdr,zF,N7e,Bdr,Ndr,yW,Idr,qdr,jdr,QF,I7e,Ddr,Gdr,xW,Odr,Vdr,Xdr,WF,zdr,q7e,Qdr,Wdr,j7e,Hdr,Udr,HF,$Ve,Sd,UF,D7e,D8,Jdr,G7e,Ydr,kVe,Qo,G8,Kdr,Rd,Zdr,$W,ecr,ocr,kW,rcr,tcr,acr,O8,ncr,O7e,scr,lcr,icr,Et,V8,dcr,V7e,ccr,fcr,Pd,mcr,X7e,gcr,hcr,SW,pcr,_cr,ucr,JF,bcr,go,X8,vcr,z7e,Fcr,Tcr,Ya,Mcr,Q7e,Ecr,Ccr,W7e,wcr,Acr,H7e,Lcr,ycr,xcr,Le,YF,U7e,$cr,kcr,RW,Scr,Rcr,Pcr,KF,J7e,Bcr,Ncr,PW,Icr,qcr,jcr,ZF,Y7e,Dcr,Gcr,BW,Ocr,Vcr,Xcr,eT,K7e,zcr,Qcr,NW,Wcr,Hcr,Ucr,oT,Z7e,Jcr,Ycr,IW,Kcr,Zcr,efr,rT,e4e,ofr,rfr,qW,tfr,afr,nfr,tT,o4e,sfr,lfr,jW,ifr,dfr,cfr,aT,r4e,ffr,mfr,DW,gfr,hfr,pfr,nT,t4e,_fr,ufr,GW,bfr,vfr,Ffr,sT,a4e,Tfr,Mfr,OW,Efr,Cfr,wfr,lT,Afr,n4e,Lfr,yfr,s4e,xfr,$fr,iT,SVe,Bd,dT,l4e,z8,kfr,i4e,Sfr,RVe,Wo,Q8,Rfr,Nd,Pfr,VW,Bfr,Nfr,XW,Ifr,qfr,jfr,W8,Dfr,d4e,Gfr,Ofr,Vfr,Ct,H8,Xfr,c4e,zfr,Qfr,Id,Wfr,f4e,Hfr,Ufr,zW,Jfr,Yfr,Kfr,cT,Zfr,ho,U8,emr,m4e,omr,rmr,Ka,tmr,g4e,amr,nmr,h4e,smr,lmr,p4e,imr,dmr,cmr,J8,fT,_4e,fmr,mmr,QW,gmr,hmr,pmr,mT,u4e,_mr,umr,WW,bmr,vmr,Fmr,gT,Tmr,b4e,Mmr,Emr,v4e,Cmr,wmr,hT,PVe,qd,pT,F4e,Y8,Amr,T4e,Lmr,BVe,Ho,K8,ymr,jd,xmr,HW,$mr,kmr,UW,Smr,Rmr,Pmr,Z8,Bmr,M4e,Nmr,Imr,qmr,wt,e9,jmr,E4e,Dmr,Gmr,Dd,Omr,C4e,Vmr,Xmr,JW,zmr,Qmr,Wmr,_T,Hmr,po,o9,Umr,w4e,Jmr,Ymr,Za,Kmr,A4e,Zmr,egr,L4e,ogr,rgr,y4e,tgr,agr,ngr,rt,uT,x4e,sgr,lgr,YW,igr,dgr,cgr,bT,$4e,fgr,mgr,KW,ggr,hgr,pgr,vT,k4e,_gr,ugr,ZW,bgr,vgr,Fgr,FT,S4e,Tgr,Mgr,eH,Egr,Cgr,wgr,TT,R4e,Agr,Lgr,oH,ygr,xgr,$gr,MT,kgr,P4e,Sgr,Rgr,B4e,Pgr,Bgr,ET,NVe,Gd,CT,N4e,r9,Ngr,I4e,Igr,IVe,Uo,t9,qgr,Od,jgr,rH,Dgr,Ggr,tH,Ogr,Vgr,Xgr,a9,zgr,q4e,Qgr,Wgr,Hgr,At,n9,Ugr,j4e,Jgr,Ygr,Vd,Kgr,D4e,Zgr,ehr,aH,ohr,rhr,thr,wT,ahr,_o,s9,nhr,G4e,shr,lhr,en,ihr,O4e,dhr,chr,V4e,fhr,mhr,X4e,ghr,hhr,phr,Xd,AT,z4e,_hr,uhr,nH,bhr,vhr,Fhr,LT,Q4e,Thr,Mhr,sH,Ehr,Chr,whr,yT,W4e,Ahr,Lhr,lH,yhr,xhr,$hr,xT,khr,H4e,Shr,Rhr,U4e,Phr,Bhr,$T,qVe,zd,kT,J4e,l9,Nhr,Y4e,Ihr,jVe,Jo,i9,qhr,Qd,jhr,iH,Dhr,Ghr,dH,Ohr,Vhr,Xhr,d9,zhr,K4e,Qhr,Whr,Hhr,Lt,c9,Uhr,Z4e,Jhr,Yhr,Wd,Khr,ebe,Zhr,epr,cH,opr,rpr,tpr,ST,apr,uo,f9,npr,obe,spr,lpr,on,ipr,rbe,dpr,cpr,tbe,fpr,mpr,abe,gpr,hpr,ppr,m9,RT,nbe,_pr,upr,fH,bpr,vpr,Fpr,PT,sbe,Tpr,Mpr,mH,Epr,Cpr,wpr,BT,Apr,lbe,Lpr,ypr,ibe,xpr,$pr,NT,DVe,Hd,IT,dbe,g9,kpr,cbe,Spr,GVe,Yo,h9,Rpr,Ud,Ppr,gH,Bpr,Npr,hH,Ipr,qpr,jpr,p9,Dpr,fbe,Gpr,Opr,Vpr,yt,_9,Xpr,mbe,zpr,Qpr,Jd,Wpr,gbe,Hpr,Upr,pH,Jpr,Ypr,Kpr,qT,Zpr,bo,u9,e_r,hbe,o_r,r_r,rn,t_r,pbe,a_r,n_r,_be,s_r,l_r,ube,i_r,d_r,c_r,bbe,jT,vbe,f_r,m_r,_H,g_r,h_r,p_r,DT,__r,Fbe,u_r,b_r,Tbe,v_r,F_r,GT,OVe,Yd,OT,Mbe,b9,T_r,Ebe,M_r,VVe,Ko,v9,E_r,Kd,C_r,uH,w_r,A_r,bH,L_r,y_r,x_r,F9,$_r,Cbe,k_r,S_r,R_r,xt,T9,P_r,wbe,B_r,N_r,Zd,I_r,Abe,q_r,j_r,vH,D_r,G_r,O_r,VT,V_r,vo,M9,X_r,Lbe,z_r,Q_r,tn,W_r,ybe,H_r,U_r,xbe,J_r,Y_r,$be,K_r,Z_r,eur,an,XT,kbe,our,rur,FH,tur,aur,nur,zT,Sbe,sur,lur,TH,iur,dur,cur,QT,Rbe,fur,mur,MH,gur,hur,pur,WT,Pbe,_ur,uur,EH,bur,vur,Fur,HT,Tur,Bbe,Mur,Eur,Nbe,Cur,wur,UT,XVe,ec,JT,Ibe,E9,Aur,qbe,Lur,zVe,Zo,C9,yur,oc,xur,CH,$ur,kur,wH,Sur,Rur,Pur,w9,Bur,jbe,Nur,Iur,qur,$t,A9,jur,Dbe,Dur,Gur,rc,Our,Gbe,Vur,Xur,AH,zur,Qur,Wur,YT,Hur,Fo,L9,Uur,Obe,Jur,Yur,nn,Kur,Vbe,Zur,e2r,Xbe,o2r,r2r,zbe,t2r,a2r,n2r,Qbe,KT,Wbe,s2r,l2r,LH,i2r,d2r,c2r,ZT,f2r,Hbe,m2r,g2r,Ube,h2r,p2r,eM,QVe,tc,oM,Jbe,y9,_2r,Ybe,u2r,WVe,er,x9,b2r,ac,v2r,yH,F2r,T2r,xH,M2r,E2r,C2r,$9,w2r,Kbe,A2r,L2r,y2r,kt,k9,x2r,Zbe,$2r,k2r,nc,S2r,eve,R2r,P2r,$H,B2r,N2r,I2r,rM,q2r,xr,S9,j2r,ove,D2r,G2r,sn,O2r,rve,V2r,X2r,tve,z2r,Q2r,ave,W2r,H2r,U2r,q,tM,nve,J2r,Y2r,kH,K2r,Z2r,e1r,aM,sve,o1r,r1r,SH,t1r,a1r,n1r,nM,lve,s1r,l1r,RH,i1r,d1r,c1r,sM,ive,f1r,m1r,PH,g1r,h1r,p1r,lM,dve,_1r,u1r,BH,b1r,v1r,F1r,iM,cve,T1r,M1r,NH,E1r,C1r,w1r,dM,fve,A1r,L1r,IH,y1r,x1r,$1r,cM,mve,k1r,S1r,qH,R1r,P1r,B1r,fM,gve,N1r,I1r,jH,q1r,j1r,D1r,mM,hve,G1r,O1r,DH,V1r,X1r,z1r,gM,pve,Q1r,W1r,GH,H1r,U1r,J1r,hM,_ve,Y1r,K1r,OH,Z1r,e7r,o7r,pM,uve,r7r,t7r,VH,a7r,n7r,s7r,_M,bve,l7r,i7r,XH,d7r,c7r,f7r,uM,vve,m7r,g7r,zH,h7r,p7r,_7r,bM,Fve,u7r,b7r,QH,v7r,F7r,T7r,vM,Tve,M7r,E7r,WH,C7r,w7r,A7r,Us,Mve,L7r,y7r,HH,x7r,$7r,UH,k7r,S7r,R7r,FM,Eve,P7r,B7r,JH,N7r,I7r,q7r,TM,Cve,j7r,D7r,YH,G7r,O7r,V7r,MM,wve,X7r,z7r,KH,Q7r,W7r,H7r,EM,Ave,U7r,J7r,ZH,Y7r,K7r,Z7r,CM,Lve,e4r,o4r,eU,r4r,t4r,a4r,wM,yve,n4r,s4r,oU,l4r,i4r,d4r,AM,xve,c4r,f4r,rU,m4r,g4r,h4r,LM,$ve,p4r,_4r,tU,u4r,b4r,v4r,yM,kve,F4r,T4r,aU,M4r,E4r,C4r,xM,Sve,w4r,A4r,nU,L4r,y4r,x4r,$M,Rve,$4r,k4r,sU,S4r,R4r,P4r,kM,Pve,B4r,N4r,lU,I4r,q4r,j4r,SM,Bve,D4r,G4r,iU,O4r,V4r,X4r,RM,Nve,z4r,Q4r,dU,W4r,H4r,U4r,PM,Ive,J4r,Y4r,cU,K4r,Z4r,ebr,BM,qve,obr,rbr,fU,tbr,abr,nbr,NM,jve,sbr,lbr,mU,ibr,dbr,cbr,IM,Dve,fbr,mbr,gU,gbr,hbr,pbr,qM,Gve,_br,ubr,hU,bbr,vbr,Fbr,jM,Ove,Tbr,Mbr,pU,Ebr,Cbr,wbr,DM,Vve,Abr,Lbr,_U,ybr,xbr,$br,GM,Xve,kbr,Sbr,uU,Rbr,Pbr,Bbr,OM,zve,Nbr,Ibr,bU,qbr,jbr,Dbr,VM,Qve,Gbr,Obr,vU,Vbr,Xbr,zbr,XM,Wve,Qbr,Wbr,FU,Hbr,Ubr,Jbr,zM,Hve,Ybr,Kbr,TU,Zbr,evr,ovr,QM,Uve,rvr,tvr,MU,avr,nvr,svr,WM,Jve,lvr,ivr,EU,dvr,cvr,fvr,HM,Yve,mvr,gvr,CU,hvr,pvr,_vr,UM,Kve,uvr,bvr,wU,vvr,Fvr,Tvr,JM,Zve,Mvr,Evr,AU,Cvr,wvr,Avr,YM,HVe,sc,KM,eFe,R9,Lvr,oFe,yvr,UVe,or,P9,xvr,lc,$vr,LU,kvr,Svr,yU,Rvr,Pvr,Bvr,B9,Nvr,rFe,Ivr,qvr,jvr,St,N9,Dvr,tFe,Gvr,Ovr,ic,Vvr,aFe,Xvr,zvr,xU,Qvr,Wvr,Hvr,ZM,Uvr,$r,I9,Jvr,nFe,Yvr,Kvr,ln,Zvr,sFe,eFr,oFr,lFe,rFr,tFr,iFe,aFr,nFr,sFr,se,eE,dFe,lFr,iFr,$U,dFr,cFr,fFr,oE,cFe,mFr,gFr,kU,hFr,pFr,_Fr,rE,fFe,uFr,bFr,SU,vFr,FFr,TFr,tE,mFe,MFr,EFr,RU,CFr,wFr,AFr,aE,gFe,LFr,yFr,PU,xFr,$Fr,kFr,nE,hFe,SFr,RFr,BU,PFr,BFr,NFr,sE,pFe,IFr,qFr,NU,jFr,DFr,GFr,lE,_Fe,OFr,VFr,IU,XFr,zFr,QFr,iE,uFe,WFr,HFr,qU,UFr,JFr,YFr,dE,bFe,KFr,ZFr,jU,eTr,oTr,rTr,cE,vFe,tTr,aTr,DU,nTr,sTr,lTr,fE,FFe,iTr,dTr,GU,cTr,fTr,mTr,mE,TFe,gTr,hTr,OU,pTr,_Tr,uTr,gE,MFe,bTr,vTr,VU,FTr,TTr,MTr,hE,EFe,ETr,CTr,XU,wTr,ATr,LTr,pE,CFe,yTr,xTr,zU,$Tr,kTr,STr,_E,wFe,RTr,PTr,QU,BTr,NTr,ITr,uE,AFe,qTr,jTr,WU,DTr,GTr,OTr,bE,LFe,VTr,XTr,HU,zTr,QTr,WTr,vE,yFe,HTr,UTr,UU,JTr,YTr,KTr,FE,xFe,ZTr,eMr,JU,oMr,rMr,tMr,TE,$Fe,aMr,nMr,YU,sMr,lMr,iMr,ME,kFe,dMr,cMr,KU,fMr,mMr,gMr,EE,JVe,dc,CE,SFe,q9,hMr,RFe,pMr,YVe,rr,j9,_Mr,cc,uMr,ZU,bMr,vMr,eJ,FMr,TMr,MMr,D9,EMr,PFe,CMr,wMr,AMr,Rt,G9,LMr,BFe,yMr,xMr,fc,$Mr,NFe,kMr,SMr,oJ,RMr,PMr,BMr,wE,NMr,kr,O9,IMr,IFe,qMr,jMr,dn,DMr,qFe,GMr,OMr,jFe,VMr,XMr,DFe,zMr,QMr,WMr,Me,AE,GFe,HMr,UMr,rJ,JMr,YMr,KMr,LE,OFe,ZMr,eEr,tJ,oEr,rEr,tEr,yE,VFe,aEr,nEr,aJ,sEr,lEr,iEr,xE,XFe,dEr,cEr,nJ,fEr,mEr,gEr,$E,zFe,hEr,pEr,sJ,_Er,uEr,bEr,kE,QFe,vEr,FEr,lJ,TEr,MEr,EEr,SE,WFe,CEr,wEr,iJ,AEr,LEr,yEr,RE,HFe,xEr,$Er,dJ,kEr,SEr,REr,PE,UFe,PEr,BEr,cJ,NEr,IEr,qEr,BE,JFe,jEr,DEr,fJ,GEr,OEr,VEr,NE,YFe,XEr,zEr,mJ,QEr,WEr,HEr,IE,KFe,UEr,JEr,gJ,YEr,KEr,ZEr,qE,ZFe,eCr,oCr,hJ,rCr,tCr,aCr,jE,KVe,mc,DE,eTe,V9,nCr,oTe,sCr,ZVe,tr,X9,lCr,gc,iCr,pJ,dCr,cCr,_J,fCr,mCr,gCr,z9,hCr,rTe,pCr,_Cr,uCr,Pt,Q9,bCr,tTe,vCr,FCr,hc,TCr,aTe,MCr,ECr,uJ,CCr,wCr,ACr,GE,LCr,Sr,W9,yCr,nTe,xCr,$Cr,cn,kCr,sTe,SCr,RCr,lTe,PCr,BCr,iTe,NCr,ICr,qCr,ar,OE,dTe,jCr,DCr,bJ,GCr,OCr,VCr,VE,cTe,XCr,zCr,vJ,QCr,WCr,HCr,XE,fTe,UCr,JCr,FJ,YCr,KCr,ZCr,zE,mTe,e3r,o3r,TJ,r3r,t3r,a3r,QE,gTe,n3r,s3r,MJ,l3r,i3r,d3r,WE,hTe,c3r,f3r,EJ,m3r,g3r,h3r,HE,eXe,pc,UE,pTe,H9,p3r,_Te,_3r,oXe,nr,U9,u3r,_c,b3r,CJ,v3r,F3r,wJ,T3r,M3r,E3r,J9,C3r,uTe,w3r,A3r,L3r,Bt,Y9,y3r,bTe,x3r,$3r,uc,k3r,vTe,S3r,R3r,AJ,P3r,B3r,N3r,JE,I3r,Rr,K9,q3r,FTe,j3r,D3r,fn,G3r,TTe,O3r,V3r,MTe,X3r,z3r,ETe,Q3r,W3r,H3r,ie,YE,CTe,U3r,J3r,LJ,Y3r,K3r,Z3r,KE,wTe,e5r,o5r,yJ,r5r,t5r,a5r,ZE,ATe,n5r,s5r,xJ,l5r,i5r,d5r,eC,LTe,c5r,f5r,$J,m5r,g5r,h5r,oC,yTe,p5r,_5r,kJ,u5r,b5r,v5r,rC,xTe,F5r,T5r,SJ,M5r,E5r,C5r,tC,$Te,w5r,A5r,RJ,L5r,y5r,x5r,aC,kTe,$5r,k5r,PJ,S5r,R5r,P5r,nC,STe,B5r,N5r,BJ,I5r,q5r,j5r,sC,RTe,D5r,G5r,NJ,O5r,V5r,X5r,lC,PTe,z5r,Q5r,IJ,W5r,H5r,U5r,iC,BTe,J5r,Y5r,qJ,K5r,Z5r,e0r,dC,NTe,o0r,r0r,jJ,t0r,a0r,n0r,cC,ITe,s0r,l0r,DJ,i0r,d0r,c0r,fC,qTe,f0r,m0r,GJ,g0r,h0r,p0r,mC,jTe,_0r,u0r,OJ,b0r,v0r,F0r,gC,DTe,T0r,M0r,VJ,E0r,C0r,w0r,hC,GTe,A0r,L0r,XJ,y0r,x0r,$0r,pC,OTe,k0r,S0r,zJ,R0r,P0r,B0r,_C,VTe,N0r,I0r,QJ,q0r,j0r,D0r,uC,rXe,bc,bC,XTe,Z9,G0r,zTe,O0r,tXe,sr,ex,V0r,vc,X0r,WJ,z0r,Q0r,HJ,W0r,H0r,U0r,ox,J0r,QTe,Y0r,K0r,Z0r,Nt,rx,ewr,WTe,owr,rwr,Fc,twr,HTe,awr,nwr,UJ,swr,lwr,iwr,vC,dwr,Pr,tx,cwr,UTe,fwr,mwr,mn,gwr,JTe,hwr,pwr,YTe,_wr,uwr,KTe,bwr,vwr,Fwr,ye,FC,ZTe,Twr,Mwr,JJ,Ewr,Cwr,wwr,TC,eMe,Awr,Lwr,YJ,ywr,xwr,$wr,MC,oMe,kwr,Swr,KJ,Rwr,Pwr,Bwr,EC,rMe,Nwr,Iwr,ZJ,qwr,jwr,Dwr,CC,tMe,Gwr,Owr,eY,Vwr,Xwr,zwr,wC,aMe,Qwr,Wwr,oY,Hwr,Uwr,Jwr,AC,nMe,Ywr,Kwr,rY,Zwr,eAr,oAr,LC,sMe,rAr,tAr,tY,aAr,nAr,sAr,yC,lMe,lAr,iAr,aY,dAr,cAr,fAr,xC,iMe,mAr,gAr,nY,hAr,pAr,_Ar,$C,aXe,Tc,kC,dMe,ax,uAr,cMe,bAr,nXe,lr,nx,vAr,Mc,FAr,sY,TAr,MAr,lY,EAr,CAr,wAr,sx,AAr,fMe,LAr,yAr,xAr,It,lx,$Ar,mMe,kAr,SAr,Ec,RAr,gMe,PAr,BAr,iY,NAr,IAr,qAr,SC,jAr,Br,ix,DAr,hMe,GAr,OAr,gn,VAr,pMe,XAr,zAr,_Me,QAr,WAr,uMe,HAr,UAr,JAr,te,RC,bMe,YAr,KAr,dY,ZAr,e6r,o6r,PC,vMe,r6r,t6r,cY,a6r,n6r,s6r,BC,FMe,l6r,i6r,fY,d6r,c6r,f6r,NC,TMe,m6r,g6r,mY,h6r,p6r,_6r,IC,MMe,u6r,b6r,gY,v6r,F6r,T6r,qC,EMe,M6r,E6r,hY,C6r,w6r,A6r,jC,CMe,L6r,y6r,pY,x6r,$6r,k6r,DC,wMe,S6r,R6r,_Y,P6r,B6r,N6r,GC,AMe,I6r,q6r,uY,j6r,D6r,G6r,OC,LMe,O6r,V6r,bY,X6r,z6r,Q6r,VC,yMe,W6r,H6r,vY,U6r,J6r,Y6r,XC,xMe,K6r,Z6r,FY,eLr,oLr,rLr,zC,$Me,tLr,aLr,TY,nLr,sLr,lLr,QC,kMe,iLr,dLr,MY,cLr,fLr,mLr,WC,SMe,gLr,hLr,EY,pLr,_Lr,uLr,HC,RMe,bLr,vLr,CY,FLr,TLr,MLr,UC,PMe,ELr,CLr,wY,wLr,ALr,LLr,JC,BMe,yLr,xLr,AY,$Lr,kLr,SLr,YC,NMe,RLr,PLr,LY,BLr,NLr,ILr,KC,IMe,qLr,jLr,yY,DLr,GLr,OLr,ZC,qMe,VLr,XLr,xY,zLr,QLr,WLr,e3,jMe,HLr,ULr,$Y,JLr,YLr,KLr,o3,DMe,ZLr,eyr,kY,oyr,ryr,tyr,r3,GMe,ayr,nyr,SY,syr,lyr,iyr,t3,OMe,dyr,cyr,RY,fyr,myr,gyr,a3,VMe,hyr,pyr,PY,_yr,uyr,byr,n3,sXe,Cc,s3,XMe,dx,vyr,zMe,Fyr,lXe,ir,cx,Tyr,wc,Myr,BY,Eyr,Cyr,NY,wyr,Ayr,Lyr,fx,yyr,QMe,xyr,$yr,kyr,qt,mx,Syr,WMe,Ryr,Pyr,Ac,Byr,HMe,Nyr,Iyr,IY,qyr,jyr,Dyr,l3,Gyr,Nr,gx,Oyr,UMe,Vyr,Xyr,hn,zyr,JMe,Qyr,Wyr,YMe,Hyr,Uyr,KMe,Jyr,Yyr,Kyr,_e,i3,ZMe,Zyr,e8r,qY,o8r,r8r,t8r,d3,eEe,a8r,n8r,jY,s8r,l8r,i8r,c3,oEe,d8r,c8r,DY,f8r,m8r,g8r,f3,rEe,h8r,p8r,GY,_8r,u8r,b8r,m3,tEe,v8r,F8r,OY,T8r,M8r,E8r,g3,aEe,C8r,w8r,VY,A8r,L8r,y8r,h3,nEe,x8r,$8r,XY,k8r,S8r,R8r,p3,sEe,P8r,B8r,zY,N8r,I8r,q8r,_3,lEe,j8r,D8r,QY,G8r,O8r,V8r,u3,iEe,X8r,z8r,WY,Q8r,W8r,H8r,b3,dEe,U8r,J8r,HY,Y8r,K8r,Z8r,v3,cEe,e9r,o9r,UY,r9r,t9r,a9r,F3,fEe,n9r,s9r,JY,l9r,i9r,d9r,T3,mEe,c9r,f9r,YY,m9r,g9r,h9r,M3,gEe,p9r,_9r,KY,u9r,b9r,v9r,E3,hEe,F9r,T9r,ZY,M9r,E9r,C9r,C3,pEe,w9r,A9r,eK,L9r,y9r,x9r,w3,iXe,Lc,A3,_Ee,hx,$9r,uEe,k9r,dXe,dr,px,S9r,yc,R9r,oK,P9r,B9r,rK,N9r,I9r,q9r,_x,j9r,bEe,D9r,G9r,O9r,jt,ux,V9r,vEe,X9r,z9r,xc,Q9r,FEe,W9r,H9r,tK,U9r,J9r,Y9r,L3,K9r,Ir,bx,Z9r,TEe,exr,oxr,pn,rxr,MEe,txr,axr,EEe,nxr,sxr,CEe,lxr,ixr,dxr,vx,y3,wEe,cxr,fxr,aK,mxr,gxr,hxr,x3,AEe,pxr,_xr,nK,uxr,bxr,vxr,$3,cXe,$c,k3,LEe,Fx,Fxr,yEe,Txr,fXe,cr,Tx,Mxr,kc,Exr,sK,Cxr,wxr,lK,Axr,Lxr,yxr,Mx,xxr,xEe,$xr,kxr,Sxr,Dt,Ex,Rxr,$Ee,Pxr,Bxr,Sc,Nxr,kEe,Ixr,qxr,iK,jxr,Dxr,Gxr,S3,Oxr,qr,Cx,Vxr,SEe,Xxr,zxr,_n,Qxr,REe,Wxr,Hxr,PEe,Uxr,Jxr,BEe,Yxr,Kxr,Zxr,NEe,R3,IEe,e$r,o$r,dK,r$r,t$r,a$r,P3,mXe,Rc,B3,qEe,wx,n$r,jEe,s$r,gXe,fr,Ax,l$r,Pc,i$r,cK,d$r,c$r,fK,f$r,m$r,g$r,Lx,h$r,DEe,p$r,_$r,u$r,Gt,yx,b$r,GEe,v$r,F$r,Bc,T$r,OEe,M$r,E$r,mK,C$r,w$r,A$r,N3,L$r,jr,xx,y$r,VEe,x$r,$$r,un,k$r,XEe,S$r,R$r,zEe,P$r,B$r,QEe,N$r,I$r,q$r,de,I3,WEe,j$r,D$r,gK,G$r,O$r,V$r,q3,HEe,X$r,z$r,hK,Q$r,W$r,H$r,j3,UEe,U$r,J$r,pK,Y$r,K$r,Z$r,D3,JEe,ekr,okr,_K,rkr,tkr,akr,G3,YEe,nkr,skr,uK,lkr,ikr,dkr,O3,KEe,ckr,fkr,bK,mkr,gkr,hkr,V3,ZEe,pkr,_kr,vK,ukr,bkr,vkr,X3,eCe,Fkr,Tkr,FK,Mkr,Ekr,Ckr,z3,oCe,wkr,Akr,TK,Lkr,ykr,xkr,Q3,rCe,$kr,kkr,MK,Skr,Rkr,Pkr,W3,tCe,Bkr,Nkr,EK,Ikr,qkr,jkr,H3,aCe,Dkr,Gkr,CK,Okr,Vkr,Xkr,U3,nCe,zkr,Qkr,wK,Wkr,Hkr,Ukr,J3,sCe,Jkr,Ykr,AK,Kkr,Zkr,eSr,Y3,lCe,oSr,rSr,LK,tSr,aSr,nSr,K3,iCe,sSr,lSr,yK,iSr,dSr,cSr,Z3,dCe,fSr,mSr,xK,gSr,hSr,pSr,e5,cCe,_Sr,uSr,$K,bSr,vSr,FSr,o5,fCe,TSr,MSr,kK,ESr,CSr,wSr,r5,mCe,ASr,LSr,SK,ySr,xSr,$Sr,t5,hXe,Nc,a5,gCe,$x,kSr,hCe,SSr,pXe,mr,kx,RSr,Ic,PSr,RK,BSr,NSr,PK,ISr,qSr,jSr,Sx,DSr,pCe,GSr,OSr,VSr,Ot,Rx,XSr,_Ce,zSr,QSr,qc,WSr,uCe,HSr,USr,BK,JSr,YSr,KSr,n5,ZSr,Dr,Px,eRr,bCe,oRr,rRr,bn,tRr,vCe,aRr,nRr,FCe,sRr,lRr,TCe,iRr,dRr,cRr,ce,s5,MCe,fRr,mRr,NK,gRr,hRr,pRr,l5,ECe,_Rr,uRr,IK,bRr,vRr,FRr,i5,CCe,TRr,MRr,qK,ERr,CRr,wRr,d5,wCe,ARr,LRr,jK,yRr,xRr,$Rr,c5,ACe,kRr,SRr,DK,RRr,PRr,BRr,f5,LCe,NRr,IRr,GK,qRr,jRr,DRr,m5,yCe,GRr,ORr,OK,VRr,XRr,zRr,g5,xCe,QRr,WRr,VK,HRr,URr,JRr,h5,$Ce,YRr,KRr,XK,ZRr,ePr,oPr,p5,kCe,rPr,tPr,zK,aPr,nPr,sPr,_5,SCe,lPr,iPr,QK,dPr,cPr,fPr,u5,RCe,mPr,gPr,WK,hPr,pPr,_Pr,b5,PCe,uPr,bPr,HK,vPr,FPr,TPr,v5,BCe,MPr,EPr,UK,CPr,wPr,APr,F5,NCe,LPr,yPr,JK,xPr,$Pr,kPr,T5,ICe,SPr,RPr,YK,PPr,BPr,NPr,M5,qCe,IPr,qPr,KK,jPr,DPr,GPr,E5,jCe,OPr,VPr,ZK,XPr,zPr,QPr,C5,DCe,WPr,HPr,eZ,UPr,JPr,YPr,w5,GCe,KPr,ZPr,oZ,eBr,oBr,rBr,A5,_Xe,jc,L5,OCe,Bx,tBr,VCe,aBr,uXe,gr,Nx,nBr,Dc,sBr,rZ,lBr,iBr,tZ,dBr,cBr,fBr,Ix,mBr,XCe,gBr,hBr,pBr,Vt,qx,_Br,zCe,uBr,bBr,Gc,vBr,QCe,FBr,TBr,aZ,MBr,EBr,CBr,y5,wBr,Gr,jx,ABr,WCe,LBr,yBr,vn,xBr,HCe,$Br,kBr,UCe,SBr,RBr,JCe,PBr,BBr,NBr,YCe,x5,KCe,IBr,qBr,nZ,jBr,DBr,GBr,$5,bXe,Oc,k5,ZCe,Dx,OBr,e3e,VBr,vXe,hr,Gx,XBr,Vc,zBr,sZ,QBr,WBr,lZ,HBr,UBr,JBr,Ox,YBr,o3e,KBr,ZBr,eNr,Xt,Vx,oNr,r3e,rNr,tNr,Xc,aNr,t3e,nNr,sNr,iZ,lNr,iNr,dNr,S5,cNr,Or,Xx,fNr,a3e,mNr,gNr,Fn,hNr,n3e,pNr,_Nr,s3e,uNr,bNr,l3e,vNr,FNr,TNr,i3e,R5,d3e,MNr,ENr,dZ,CNr,wNr,ANr,P5,FXe,zc,B5,c3e,zx,LNr,f3e,yNr,TXe,pr,Qx,xNr,Qc,$Nr,cZ,kNr,SNr,fZ,RNr,PNr,BNr,Wx,NNr,m3e,INr,qNr,jNr,zt,Hx,DNr,g3e,GNr,ONr,Wc,VNr,h3e,XNr,zNr,mZ,QNr,WNr,HNr,N5,UNr,Vr,Ux,JNr,p3e,YNr,KNr,Tn,ZNr,_3e,eIr,oIr,u3e,rIr,tIr,b3e,aIr,nIr,sIr,oe,I5,v3e,lIr,iIr,gZ,dIr,cIr,fIr,q5,F3e,mIr,gIr,hZ,hIr,pIr,_Ir,j5,T3e,uIr,bIr,pZ,vIr,FIr,TIr,D5,M3e,MIr,EIr,_Z,CIr,wIr,AIr,G5,E3e,LIr,yIr,uZ,xIr,$Ir,kIr,O5,C3e,SIr,RIr,bZ,PIr,BIr,NIr,V5,w3e,IIr,qIr,vZ,jIr,DIr,GIr,X5,A3e,OIr,VIr,FZ,XIr,zIr,QIr,z5,L3e,WIr,HIr,TZ,UIr,JIr,YIr,Q5,y3e,KIr,ZIr,MZ,eqr,oqr,rqr,W5,x3e,tqr,aqr,EZ,nqr,sqr,lqr,H5,$3e,iqr,dqr,CZ,cqr,fqr,mqr,U5,k3e,gqr,hqr,wZ,pqr,_qr,uqr,J5,S3e,bqr,vqr,AZ,Fqr,Tqr,Mqr,Y5,R3e,Eqr,Cqr,LZ,wqr,Aqr,Lqr,K5,P3e,yqr,xqr,yZ,$qr,kqr,Sqr,Z5,B3e,Rqr,Pqr,xZ,Bqr,Nqr,Iqr,e0,N3e,qqr,jqr,$Z,Dqr,Gqr,Oqr,o0,I3e,Vqr,Xqr,kZ,zqr,Qqr,Wqr,r0,q3e,Hqr,Uqr,SZ,Jqr,Yqr,Kqr,t0,j3e,Zqr,ejr,RZ,ojr,rjr,tjr,a0,D3e,ajr,njr,PZ,sjr,ljr,ijr,n0,G3e,djr,cjr,BZ,fjr,mjr,gjr,s0,O3e,hjr,pjr,NZ,_jr,ujr,bjr,l0,V3e,vjr,Fjr,IZ,Tjr,Mjr,Ejr,i0,X3e,Cjr,wjr,qZ,Ajr,Ljr,yjr,d0,z3e,xjr,$jr,jZ,kjr,Sjr,Rjr,c0,MXe,Hc,f0,Q3e,Jx,Pjr,W3e,Bjr,EXe,_r,Yx,Njr,Uc,Ijr,DZ,qjr,jjr,GZ,Djr,Gjr,Ojr,Kx,Vjr,H3e,Xjr,zjr,Qjr,Qt,Zx,Wjr,U3e,Hjr,Ujr,Jc,Jjr,J3e,Yjr,Kjr,OZ,Zjr,eDr,oDr,m0,rDr,Xr,e$,tDr,Y3e,aDr,nDr,Mn,sDr,K3e,lDr,iDr,Z3e,dDr,cDr,e5e,fDr,mDr,gDr,xe,g0,o5e,hDr,pDr,VZ,_Dr,uDr,bDr,h0,r5e,vDr,FDr,XZ,TDr,MDr,EDr,p0,t5e,CDr,wDr,zZ,ADr,LDr,yDr,_0,a5e,xDr,$Dr,QZ,kDr,SDr,RDr,u0,n5e,PDr,BDr,WZ,NDr,IDr,qDr,b0,s5e,jDr,DDr,HZ,GDr,ODr,VDr,v0,l5e,XDr,zDr,UZ,QDr,WDr,HDr,F0,i5e,UDr,JDr,JZ,YDr,KDr,ZDr,T0,d5e,eGr,oGr,YZ,rGr,tGr,aGr,M0,c5e,nGr,sGr,KZ,lGr,iGr,dGr,E0,CXe,Yc,C0,f5e,o$,cGr,m5e,fGr,wXe,ur,r$,mGr,Kc,gGr,ZZ,hGr,pGr,eee,_Gr,uGr,bGr,t$,vGr,g5e,FGr,TGr,MGr,Wt,a$,EGr,h5e,CGr,wGr,Zc,AGr,p5e,LGr,yGr,oee,xGr,$Gr,kGr,w0,SGr,zr,n$,RGr,_5e,PGr,BGr,En,NGr,u5e,IGr,qGr,b5e,jGr,DGr,v5e,GGr,OGr,VGr,Ee,A0,F5e,XGr,zGr,ree,QGr,WGr,HGr,L0,T5e,UGr,JGr,tee,YGr,KGr,ZGr,y0,M5e,eOr,oOr,aee,rOr,tOr,aOr,x0,E5e,nOr,sOr,nee,lOr,iOr,dOr,$0,C5e,cOr,fOr,see,mOr,gOr,hOr,k0,w5e,pOr,_Or,lee,uOr,bOr,vOr,S0,A5e,FOr,TOr,iee,MOr,EOr,COr,R0,L5e,wOr,AOr,dee,LOr,yOr,xOr,P0,y5e,$Or,kOr,cee,SOr,ROr,POr,B0,x5e,BOr,NOr,fee,IOr,qOr,jOr,N0,$5e,DOr,GOr,mee,OOr,VOr,XOr,I0,k5e,zOr,QOr,gee,WOr,HOr,UOr,q0,S5e,JOr,YOr,hee,KOr,ZOr,eVr,j0,AXe,ef,D0,R5e,s$,oVr,P5e,rVr,LXe,br,l$,tVr,of,aVr,pee,nVr,sVr,_ee,lVr,iVr,dVr,i$,cVr,B5e,fVr,mVr,gVr,Ht,d$,hVr,N5e,pVr,_Vr,rf,uVr,I5e,bVr,vVr,uee,FVr,TVr,MVr,G0,EVr,Qr,c$,CVr,q5e,wVr,AVr,Cn,LVr,j5e,yVr,xVr,D5e,$Vr,kVr,G5e,SVr,RVr,PVr,$e,O0,O5e,BVr,NVr,bee,IVr,qVr,jVr,V0,V5e,DVr,GVr,vee,OVr,VVr,XVr,X0,X5e,zVr,QVr,Fee,WVr,HVr,UVr,z0,z5e,JVr,YVr,Tee,KVr,ZVr,eXr,Q0,Q5e,oXr,rXr,Mee,tXr,aXr,nXr,W0,W5e,sXr,lXr,Eee,iXr,dXr,cXr,H0,H5e,fXr,mXr,Cee,gXr,hXr,pXr,U0,U5e,_Xr,uXr,wee,bXr,vXr,FXr,J0,J5e,TXr,MXr,Aee,EXr,CXr,wXr,Y0,Y5e,AXr,LXr,Lee,yXr,xXr,$Xr,K0,yXe,tf,Z0,K5e,f$,kXr,Z5e,SXr,xXe,vr,m$,RXr,af,PXr,yee,BXr,NXr,xee,IXr,qXr,jXr,g$,DXr,e0e,GXr,OXr,VXr,Ut,h$,XXr,o0e,zXr,QXr,nf,WXr,r0e,HXr,UXr,$ee,JXr,YXr,KXr,ew,ZXr,Wr,p$,ezr,t0e,ozr,rzr,wn,tzr,a0e,azr,nzr,n0e,szr,lzr,s0e,izr,dzr,czr,ke,ow,l0e,fzr,mzr,kee,gzr,hzr,pzr,rw,i0e,_zr,uzr,See,bzr,vzr,Fzr,tw,d0e,Tzr,Mzr,Ree,Ezr,Czr,wzr,aw,c0e,Azr,Lzr,Pee,yzr,xzr,$zr,nw,f0e,kzr,Szr,Bee,Rzr,Pzr,Bzr,sw,m0e,Nzr,Izr,Nee,qzr,jzr,Dzr,lw,g0e,Gzr,Ozr,Iee,Vzr,Xzr,zzr,iw,h0e,Qzr,Wzr,qee,Hzr,Uzr,Jzr,dw,p0e,Yzr,Kzr,jee,Zzr,eQr,oQr,cw,_0e,rQr,tQr,Dee,aQr,nQr,sQr,fw,$Xe,sf,mw,u0e,_$,lQr,b0e,iQr,kXe,Fr,u$,dQr,lf,cQr,Gee,fQr,mQr,Oee,gQr,hQr,pQr,b$,_Qr,v0e,uQr,bQr,vQr,Jt,v$,FQr,F0e,TQr,MQr,df,EQr,T0e,CQr,wQr,Vee,AQr,LQr,yQr,gw,xQr,Hr,F$,$Qr,M0e,kQr,SQr,An,RQr,E0e,PQr,BQr,C0e,NQr,IQr,w0e,qQr,jQr,DQr,Se,hw,A0e,GQr,OQr,Xee,VQr,XQr,zQr,pw,L0e,QQr,WQr,zee,HQr,UQr,JQr,_w,y0e,YQr,KQr,Qee,ZQr,eWr,oWr,uw,x0e,rWr,tWr,Wee,aWr,nWr,sWr,bw,$0e,lWr,iWr,Hee,dWr,cWr,fWr,vw,k0e,mWr,gWr,Uee,hWr,pWr,_Wr,Fw,S0e,uWr,bWr,Jee,vWr,FWr,TWr,Tw,R0e,MWr,EWr,Yee,CWr,wWr,AWr,Mw,P0e,LWr,yWr,Kee,xWr,$Wr,kWr,Ew,B0e,SWr,RWr,Zee,PWr,BWr,NWr,Cw,SXe,cf,ww,N0e,T$,IWr,I0e,qWr,RXe,Tr,M$,jWr,ff,DWr,eoe,GWr,OWr,ooe,VWr,XWr,zWr,E$,QWr,q0e,WWr,HWr,UWr,Yt,C$,JWr,j0e,YWr,KWr,mf,ZWr,D0e,eHr,oHr,roe,rHr,tHr,aHr,Aw,nHr,Ur,w$,sHr,G0e,lHr,iHr,Ln,dHr,O0e,cHr,fHr,V0e,mHr,gHr,X0e,hHr,pHr,_Hr,Re,Lw,z0e,uHr,bHr,toe,vHr,FHr,THr,yw,Q0e,MHr,EHr,aoe,CHr,wHr,AHr,xw,W0e,LHr,yHr,noe,xHr,$Hr,kHr,$w,H0e,SHr,RHr,soe,PHr,BHr,NHr,kw,U0e,IHr,qHr,loe,jHr,DHr,GHr,Sw,J0e,OHr,VHr,ioe,XHr,zHr,QHr,Rw,Y0e,WHr,HHr,doe,UHr,JHr,YHr,Pw,K0e,KHr,ZHr,coe,eUr,oUr,rUr,Bw,Z0e,tUr,aUr,foe,nUr,sUr,lUr,Nw,ewe,iUr,dUr,moe,cUr,fUr,mUr,Iw,PXe,gf,qw,owe,A$,gUr,rwe,hUr,BXe,Mr,L$,pUr,hf,_Ur,goe,uUr,bUr,hoe,vUr,FUr,TUr,y$,MUr,twe,EUr,CUr,wUr,Kt,x$,AUr,awe,LUr,yUr,pf,xUr,nwe,$Ur,kUr,poe,SUr,RUr,PUr,jw,BUr,Jr,$$,NUr,swe,IUr,qUr,yn,jUr,lwe,DUr,GUr,iwe,OUr,VUr,dwe,XUr,zUr,QUr,Ve,Dw,cwe,WUr,HUr,_oe,UUr,JUr,YUr,Gw,fwe,KUr,ZUr,uoe,eJr,oJr,rJr,Ow,mwe,tJr,aJr,boe,nJr,sJr,lJr,Vw,gwe,iJr,dJr,voe,cJr,fJr,mJr,Xw,hwe,gJr,hJr,Foe,pJr,_Jr,uJr,zw,pwe,bJr,vJr,Toe,FJr,TJr,MJr,Qw,_we,EJr,CJr,Moe,wJr,AJr,LJr,Ww,uwe,yJr,xJr,Eoe,$Jr,kJr,SJr,Hw,NXe,_f,Uw,bwe,k$,RJr,vwe,PJr,IXe,Er,S$,BJr,uf,NJr,Coe,IJr,qJr,woe,jJr,DJr,GJr,R$,OJr,Fwe,VJr,XJr,zJr,Zt,P$,QJr,Twe,WJr,HJr,bf,UJr,Mwe,JJr,YJr,Aoe,KJr,ZJr,eYr,Jw,oYr,Yr,B$,rYr,Ewe,tYr,aYr,xn,nYr,Cwe,sYr,lYr,wwe,iYr,dYr,Awe,cYr,fYr,mYr,Xe,Yw,Lwe,gYr,hYr,Loe,pYr,_Yr,uYr,Kw,ywe,bYr,vYr,yoe,FYr,TYr,MYr,Zw,xwe,EYr,CYr,xoe,wYr,AYr,LYr,eA,$we,yYr,xYr,$oe,$Yr,kYr,SYr,oA,kwe,RYr,PYr,koe,BYr,NYr,IYr,rA,Swe,qYr,jYr,Soe,DYr,GYr,OYr,tA,Rwe,VYr,XYr,Roe,zYr,QYr,WYr,aA,Pwe,HYr,UYr,Poe,JYr,YYr,KYr,nA,qXe,vf,sA,Bwe,N$,ZYr,Nwe,eKr,jXe,Cr,I$,oKr,Ff,rKr,Boe,tKr,aKr,Noe,nKr,sKr,lKr,q$,iKr,Iwe,dKr,cKr,fKr,ea,j$,mKr,qwe,gKr,hKr,Tf,pKr,jwe,_Kr,uKr,Ioe,bKr,vKr,FKr,lA,TKr,Kr,D$,MKr,Dwe,EKr,CKr,$n,wKr,Gwe,AKr,LKr,Owe,yKr,xKr,Vwe,$Kr,kKr,SKr,Xwe,iA,zwe,RKr,PKr,qoe,BKr,NKr,IKr,dA,DXe,Mf,cA,Qwe,G$,qKr,Wwe,jKr,GXe,wr,O$,DKr,Ef,GKr,joe,OKr,VKr,Doe,XKr,zKr,QKr,V$,WKr,Hwe,HKr,UKr,JKr,oa,X$,YKr,Uwe,KKr,ZKr,Cf,eZr,Jwe,oZr,rZr,Goe,tZr,aZr,nZr,fA,sZr,Zr,z$,lZr,Ywe,iZr,dZr,kn,cZr,Kwe,fZr,mZr,Zwe,gZr,hZr,eAe,pZr,_Zr,uZr,Q$,mA,oAe,bZr,vZr,Ooe,FZr,TZr,MZr,gA,rAe,EZr,CZr,Voe,wZr,AZr,LZr,hA,OXe,wf,pA,tAe,W$,yZr,aAe,xZr,VXe,Ar,H$,$Zr,Af,kZr,Xoe,SZr,RZr,zoe,PZr,BZr,NZr,U$,IZr,nAe,qZr,jZr,DZr,ra,J$,GZr,sAe,OZr,VZr,Lf,XZr,lAe,zZr,QZr,Qoe,WZr,HZr,UZr,_A,JZr,et,Y$,YZr,iAe,KZr,ZZr,Sn,eet,dAe,oet,ret,cAe,tet,aet,fAe,net,set,iet,mAe,uA,gAe,det,cet,Woe,fet,met,get,bA,XXe;return d=new re({}),ka=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),OL=new re({}),VL=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Nf=new het({props:{warning:!0,$$slots:{default:[gVt]},$$scope:{ctx:$}}}),XL=new re({}),zL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/configuration_auto.py#L604"}}),HL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/configuration_auto.py#L627"}}),Qg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[hVt]},$$scope:{ctx:$}}}),UL=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/configuration_auto.py#L750"}}),JL=new re({}),YL=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/tokenization_auto.py#L402"}}),ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17427/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/tokenization_auto.py#L416"}}),yh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[pVt]},$$scope:{ctx:$}}}),oy=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/tokenization_auto.py#L615"}}),ry=new re({}),ty=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/feature_extraction_auto.py#L194"}}),sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17427/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/feature_extraction_auto.py#L208"}}),cp=new het({props:{$$slots:{default:[_Vt]},$$scope:{ctx:$}}}),fp=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[uVt]},$$scope:{ctx:$}}}),ly=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/feature_extraction_auto.py#L335"}}),iy=new re({}),dy=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/processing_auto.py#L89"}}),my=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/processing_auto.py#L103"}}),Sp=new het({props:{$$slots:{default:[bVt]},$$scope:{ctx:$}}}),Rp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[vVt]},$$scope:{ctx:$}}}),gy=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/processing_auto.py#L256"}}),hy=new re({}),py=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L771"}}),uy=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Np=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[FVt]},$$scope:{ctx:$}}}),by=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),qu=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[TVt]},$$scope:{ctx:$}}}),vy=new re({}),Fy=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L778"}}),My=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Du=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[MVt]},$$scope:{ctx:$}}}),Ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),S2=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[EVt]},$$scope:{ctx:$}}}),Cy=new re({}),wy=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L793"}}),Ly=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),P2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[CVt]},$$scope:{ctx:$}}}),yy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),T1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[wVt]},$$scope:{ctx:$}}}),xy=new re({}),$y=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L800"}}),Sy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),E1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[AVt]},$$scope:{ctx:$}}}),Ry=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),i7=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[LVt]},$$scope:{ctx:$}}}),Py=new re({}),By=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L807"}}),Iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),c7=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[yVt]},$$scope:{ctx:$}}}),qy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),x7=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[xVt]},$$scope:{ctx:$}}}),jy=new re({}),Dy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L816"}}),Oy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),k7=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[$Vt]},$$scope:{ctx:$}}}),Vy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),y4=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[kVt]},$$scope:{ctx:$}}}),Xy=new re({}),zy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L861"}}),Wy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),$4=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[SVt]},$$scope:{ctx:$}}}),Hy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),ib=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[RVt]},$$scope:{ctx:$}}}),Uy=new re({}),Jy=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L868"}}),Ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),cb=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[PVt]},$$scope:{ctx:$}}}),Zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),bb=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[BVt]},$$scope:{ctx:$}}}),e8=new re({}),o8=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L854"}}),t8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Fb=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[NVt]},$$scope:{ctx:$}}}),a8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),av=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[IVt]},$$scope:{ctx:$}}}),n8=new re({}),s8=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L825"}}),i8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),sv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[qVt]},$$scope:{ctx:$}}}),d8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),Uv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[jVt]},$$scope:{ctx:$}}}),c8=new re({}),f8=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L832"}}),g8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Yv=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[DVt]},$$scope:{ctx:$}}}),h8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),eF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[GVt]},$$scope:{ctx:$}}}),p8=new re({}),_8=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L877"}}),b8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),rF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[OVt]},$$scope:{ctx:$}}}),v8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),_F=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[VVt]},$$scope:{ctx:$}}}),F8=new re({}),T8=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L916"}}),E8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),bF=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[XVt]},$$scope:{ctx:$}}}),C8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),TF=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[zVt]},$$scope:{ctx:$}}}),w8=new re({}),A8=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L843"}}),y8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),EF=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[QVt]},$$scope:{ctx:$}}}),x8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),AF=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[WVt]},$$scope:{ctx:$}}}),$8=new re({}),k8=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L923"}}),R8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),yF=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[HVt]},$$scope:{ctx:$}}}),P8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),jF=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[UVt]},$$scope:{ctx:$}}}),B8=new re({}),N8=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L946"}}),q8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),GF=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[JVt]},$$scope:{ctx:$}}}),j8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),HF=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[YVt]},$$scope:{ctx:$}}}),D8=new re({}),G8=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L930"}}),V8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),JF=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[KVt]},$$scope:{ctx:$}}}),X8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),iT=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[ZVt]},$$scope:{ctx:$}}}),z8=new re({}),Q8=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L937"}}),H8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),cT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[eXt]},$$scope:{ctx:$}}}),U8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),hT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[oXt]},$$scope:{ctx:$}}}),Y8=new re({}),K8=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L955"}}),e9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),_T=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[rXt]},$$scope:{ctx:$}}}),o9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),ET=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[tXt]},$$scope:{ctx:$}}}),r9=new re({}),t9=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L962"}}),n9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),wT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[aXt]},$$scope:{ctx:$}}}),s9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),$T=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[nXt]},$$scope:{ctx:$}}}),l9=new re({}),i9=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L909"}}),c9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),ST=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[sXt]},$$scope:{ctx:$}}}),f9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),NT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[lXt]},$$scope:{ctx:$}}}),g9=new re({}),h9=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L884"}}),_9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),qT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[iXt]},$$scope:{ctx:$}}}),u9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),GT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[dXt]},$$scope:{ctx:$}}}),b9=new re({}),v9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L891"}}),T9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),VT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[cXt]},$$scope:{ctx:$}}}),M9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),UT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[fXt]},$$scope:{ctx:$}}}),E9=new re({}),C9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L900"}}),A9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),YT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[mXt]},$$scope:{ctx:$}}}),L9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),eM=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[gXt]},$$scope:{ctx:$}}}),y9=new re({}),x9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L410"}}),k9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),rM=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[hXt]},$$scope:{ctx:$}}}),S9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),YM=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[pXt]},$$scope:{ctx:$}}}),R9=new re({}),P9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L417"}}),N9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),ZM=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[_Xt]},$$scope:{ctx:$}}}),I9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),EE=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[uXt]},$$scope:{ctx:$}}}),q9=new re({}),j9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L432"}}),G9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),wE=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[bXt]},$$scope:{ctx:$}}}),O9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),jE=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[vXt]},$$scope:{ctx:$}}}),V9=new re({}),X9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L448"}}),Q9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),GE=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[FXt]},$$scope:{ctx:$}}}),W9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),HE=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[TXt]},$$scope:{ctx:$}}}),H9=new re({}),U9=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L473"}}),Y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),JE=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[MXt]},$$scope:{ctx:$}}}),K9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),uC=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[EXt]},$$scope:{ctx:$}}}),Z9=new re({}),ex=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),rx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),vC=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[CXt]},$$scope:{ctx:$}}}),tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),$C=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[wXt]},$$scope:{ctx:$}}}),ax=new re({}),nx=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L489"}}),lx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),SC=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[AXt]},$$scope:{ctx:$}}}),ix=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),n3=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[LXt]},$$scope:{ctx:$}}}),dx=new re({}),cx=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L525"}}),mx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),l3=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[yXt]},$$scope:{ctx:$}}}),gx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),w3=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[xXt]},$$scope:{ctx:$}}}),hx=new re({}),px=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),ux=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),L3=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[$Xt]},$$scope:{ctx:$}}}),bx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),$3=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[kXt]},$$scope:{ctx:$}}}),Fx=new re({}),Tx=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L505"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),S3=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[SXt]},$$scope:{ctx:$}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),P3=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[RXt]},$$scope:{ctx:$}}}),wx=new re({}),Ax=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L516"}}),yx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),N3=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[PXt]},$$scope:{ctx:$}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),t5=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[BXt]},$$scope:{ctx:$}}}),$x=new re({}),kx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L498"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),n5=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[NXt]},$$scope:{ctx:$}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),A5=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[IXt]},$$scope:{ctx:$}}}),Bx=new re({}),Nx=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),qx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),y5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[qXt]},$$scope:{ctx:$}}}),jx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),$5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[jXt]},$$scope:{ctx:$}}}),Dx=new re({}),Gx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L541"}}),Vx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),S5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[DXt]},$$scope:{ctx:$}}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),P5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[GXt]},$$scope:{ctx:$}}}),zx=new re({}),Qx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),Hx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),N5=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[OXt]},$$scope:{ctx:$}}}),Ux=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),c0=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[VXt]},$$scope:{ctx:$}}}),Jx=new re({}),Yx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),m0=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[XXt]},$$scope:{ctx:$}}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),E0=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[zXt]},$$scope:{ctx:$}}}),o$=new re({}),r$=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),a$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),w0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[QXt]},$$scope:{ctx:$}}}),n$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),j0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[WXt]},$$scope:{ctx:$}}}),s$=new re({}),l$=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),d$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),G0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[HXt]},$$scope:{ctx:$}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),K0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[UXt]},$$scope:{ctx:$}}}),f$=new re({}),m$=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),h$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),ew=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[JXt]},$$scope:{ctx:$}}}),p$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),fw=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[YXt]},$$scope:{ctx:$}}}),_$=new re({}),u$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),v$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),gw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[KXt]},$$scope:{ctx:$}}}),F$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),Cw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[ZXt]},$$scope:{ctx:$}}}),T$=new re({}),M$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),C$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Aw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[ezt]},$$scope:{ctx:$}}}),w$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),Iw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[ozt]},$$scope:{ctx:$}}}),A$=new re({}),L$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),x$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),jw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[rzt]},$$scope:{ctx:$}}}),$$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),Hw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[tzt]},$$scope:{ctx:$}}}),k$=new re({}),S$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),P$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Jw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[azt]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),nA=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[nzt]},$$scope:{ctx:$}}}),N$=new re({}),I$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),j$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),lA=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[szt]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),dA=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[lzt]},$$scope:{ctx:$}}}),G$=new re({}),O$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),X$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),fA=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[izt]},$$scope:{ctx:$}}}),z$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),hA=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[dzt]},$$scope:{ctx:$}}}),W$=new re({}),H$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),J$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),_A=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[czt]},$$scope:{ctx:$}}}),Y$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),bA=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[fzt]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Ci=o("Auto Classes"),kf=l(),nt=a("p"),wi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ai=a("code"),qL=o("from_pretrained()"),Sf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),Li=o("Instantiating one of "),Pn=a("a"),jL=o("AutoConfig"),Bn=o(", "),Nn=a("a"),DL=o("AutoModel"),yi=o(`, and
`),In=a("a"),GL=o("AutoTokenizer"),xi=o(" will directly create a class of the relevant architecture. For instance"),Rf=l(),F(ka.$$.fragment),We=l(),Ae=a("p"),uS=o("will create a model that is an instance of "),$i=a("a"),bS=o("BertModel"),vS=o("."),Co=l(),Sa=a("p"),FS=o("There is one class of "),Pf=a("code"),TS=o("AutoModel"),eWe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jOe=l(),ki=a("h2"),Bf=a("a"),Ote=a("span"),F(OL.$$.fragment),oWe=l(),Vte=a("span"),rWe=o("Extending the Auto Classes"),DOe=l(),qn=a("p"),tWe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Xte=a("code"),aWe=o("NewModel"),nWe=o(", make sure you have a "),zte=a("code"),sWe=o("NewModelConfig"),lWe=o(` then you can add those to the auto
classes like this:`),GOe=l(),F(VL.$$.fragment),OOe=l(),MS=a("p"),iWe=o("You will then be able to use the auto classes like you would usually do!"),VOe=l(),F(Nf.$$.fragment),XOe=l(),Si=a("h2"),If=a("a"),Qte=a("span"),F(XL.$$.fragment),dWe=l(),Wte=a("span"),cWe=o("AutoConfig"),zOe=l(),wo=a("div"),F(zL.$$.fragment),fWe=l(),QL=a("p"),mWe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),ES=a("a"),gWe=o("from_pretrained()"),hWe=o(" class method."),pWe=l(),WL=a("p"),_We=o("This class cannot be instantiated directly using "),Hte=a("code"),uWe=o("__init__()"),bWe=o(" (throws an error)."),vWe=l(),Lr=a("div"),F(HL.$$.fragment),FWe=l(),Ute=a("p"),TWe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),MWe=l(),Ri=a("p"),EWe=o("The configuration class to instantiate is selected based on the "),Jte=a("code"),CWe=o("model_type"),wWe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Yte=a("code"),AWe=o("pretrained_model_name_or_path"),LWe=o(":"),yWe=l(),A=a("ul"),qf=a("li"),Kte=a("strong"),xWe=o("albert"),$We=o(" \u2014 "),CS=a("a"),kWe=o("AlbertConfig"),SWe=o(" (ALBERT model)"),RWe=l(),jf=a("li"),Zte=a("strong"),PWe=o("bart"),BWe=o(" \u2014 "),wS=a("a"),NWe=o("BartConfig"),IWe=o(" (BART model)"),qWe=l(),Df=a("li"),eae=a("strong"),jWe=o("beit"),DWe=o(" \u2014 "),AS=a("a"),GWe=o("BeitConfig"),OWe=o(" (BEiT model)"),VWe=l(),Gf=a("li"),oae=a("strong"),XWe=o("bert"),zWe=o(" \u2014 "),LS=a("a"),QWe=o("BertConfig"),WWe=o(" (BERT model)"),HWe=l(),Of=a("li"),rae=a("strong"),UWe=o("bert-generation"),JWe=o(" \u2014 "),yS=a("a"),YWe=o("BertGenerationConfig"),KWe=o(" (Bert Generation model)"),ZWe=l(),Vf=a("li"),tae=a("strong"),eHe=o("big_bird"),oHe=o(" \u2014 "),xS=a("a"),rHe=o("BigBirdConfig"),tHe=o(" (BigBird model)"),aHe=l(),Xf=a("li"),aae=a("strong"),nHe=o("bigbird_pegasus"),sHe=o(" \u2014 "),$S=a("a"),lHe=o("BigBirdPegasusConfig"),iHe=o(" (BigBird-Pegasus model)"),dHe=l(),zf=a("li"),nae=a("strong"),cHe=o("blenderbot"),fHe=o(" \u2014 "),kS=a("a"),mHe=o("BlenderbotConfig"),gHe=o(" (Blenderbot model)"),hHe=l(),Qf=a("li"),sae=a("strong"),pHe=o("blenderbot-small"),_He=o(" \u2014 "),SS=a("a"),uHe=o("BlenderbotSmallConfig"),bHe=o(" (BlenderbotSmall model)"),vHe=l(),Wf=a("li"),lae=a("strong"),FHe=o("bloom"),THe=o(" \u2014 "),RS=a("a"),MHe=o("BloomConfig"),EHe=o(" (BLOOM model)"),CHe=l(),Hf=a("li"),iae=a("strong"),wHe=o("camembert"),AHe=o(" \u2014 "),PS=a("a"),LHe=o("CamembertConfig"),yHe=o(" (CamemBERT model)"),xHe=l(),Uf=a("li"),dae=a("strong"),$He=o("canine"),kHe=o(" \u2014 "),BS=a("a"),SHe=o("CanineConfig"),RHe=o(" (CANINE model)"),PHe=l(),Jf=a("li"),cae=a("strong"),BHe=o("clip"),NHe=o(" \u2014 "),NS=a("a"),IHe=o("CLIPConfig"),qHe=o(" (CLIP model)"),jHe=l(),Yf=a("li"),fae=a("strong"),DHe=o("codegen"),GHe=o(" \u2014 "),IS=a("a"),OHe=o("CodeGenConfig"),VHe=o(" (CodeGen model)"),XHe=l(),Kf=a("li"),mae=a("strong"),zHe=o("convbert"),QHe=o(" \u2014 "),qS=a("a"),WHe=o("ConvBertConfig"),HHe=o(" (ConvBERT model)"),UHe=l(),Zf=a("li"),gae=a("strong"),JHe=o("convnext"),YHe=o(" \u2014 "),jS=a("a"),KHe=o("ConvNextConfig"),ZHe=o(" (ConvNeXT model)"),eUe=l(),em=a("li"),hae=a("strong"),oUe=o("ctrl"),rUe=o(" \u2014 "),DS=a("a"),tUe=o("CTRLConfig"),aUe=o(" (CTRL model)"),nUe=l(),om=a("li"),pae=a("strong"),sUe=o("cvt"),lUe=o(" \u2014 "),GS=a("a"),iUe=o("CvtConfig"),dUe=o(" (CvT model)"),cUe=l(),rm=a("li"),_ae=a("strong"),fUe=o("data2vec-audio"),mUe=o(" \u2014 "),OS=a("a"),gUe=o("Data2VecAudioConfig"),hUe=o(" (Data2VecAudio model)"),pUe=l(),tm=a("li"),uae=a("strong"),_Ue=o("data2vec-text"),uUe=o(" \u2014 "),VS=a("a"),bUe=o("Data2VecTextConfig"),vUe=o(" (Data2VecText model)"),FUe=l(),am=a("li"),bae=a("strong"),TUe=o("data2vec-vision"),MUe=o(" \u2014 "),XS=a("a"),EUe=o("Data2VecVisionConfig"),CUe=o(" (Data2VecVision model)"),wUe=l(),nm=a("li"),vae=a("strong"),AUe=o("deberta"),LUe=o(" \u2014 "),zS=a("a"),yUe=o("DebertaConfig"),xUe=o(" (DeBERTa model)"),$Ue=l(),sm=a("li"),Fae=a("strong"),kUe=o("deberta-v2"),SUe=o(" \u2014 "),QS=a("a"),RUe=o("DebertaV2Config"),PUe=o(" (DeBERTa-v2 model)"),BUe=l(),lm=a("li"),Tae=a("strong"),NUe=o("decision_transformer"),IUe=o(" \u2014 "),WS=a("a"),qUe=o("DecisionTransformerConfig"),jUe=o(" (Decision Transformer model)"),DUe=l(),im=a("li"),Mae=a("strong"),GUe=o("deit"),OUe=o(" \u2014 "),HS=a("a"),VUe=o("DeiTConfig"),XUe=o(" (DeiT model)"),zUe=l(),dm=a("li"),Eae=a("strong"),QUe=o("detr"),WUe=o(" \u2014 "),US=a("a"),HUe=o("DetrConfig"),UUe=o(" (DETR model)"),JUe=l(),cm=a("li"),Cae=a("strong"),YUe=o("distilbert"),KUe=o(" \u2014 "),JS=a("a"),ZUe=o("DistilBertConfig"),eJe=o(" (DistilBERT model)"),oJe=l(),fm=a("li"),wae=a("strong"),rJe=o("dpr"),tJe=o(" \u2014 "),YS=a("a"),aJe=o("DPRConfig"),nJe=o(" (DPR model)"),sJe=l(),mm=a("li"),Aae=a("strong"),lJe=o("dpt"),iJe=o(" \u2014 "),KS=a("a"),dJe=o("DPTConfig"),cJe=o(" (DPT model)"),fJe=l(),gm=a("li"),Lae=a("strong"),mJe=o("electra"),gJe=o(" \u2014 "),ZS=a("a"),hJe=o("ElectraConfig"),pJe=o(" (ELECTRA model)"),_Je=l(),hm=a("li"),yae=a("strong"),uJe=o("encoder-decoder"),bJe=o(" \u2014 "),eR=a("a"),vJe=o("EncoderDecoderConfig"),FJe=o(" (Encoder decoder model)"),TJe=l(),pm=a("li"),xae=a("strong"),MJe=o("flaubert"),EJe=o(" \u2014 "),oR=a("a"),CJe=o("FlaubertConfig"),wJe=o(" (FlauBERT model)"),AJe=l(),_m=a("li"),$ae=a("strong"),LJe=o("flava"),yJe=o(" \u2014 "),rR=a("a"),xJe=o("FlavaConfig"),$Je=o(" (FLAVA model)"),kJe=l(),um=a("li"),kae=a("strong"),SJe=o("fnet"),RJe=o(" \u2014 "),tR=a("a"),PJe=o("FNetConfig"),BJe=o(" (FNet model)"),NJe=l(),bm=a("li"),Sae=a("strong"),IJe=o("fsmt"),qJe=o(" \u2014 "),aR=a("a"),jJe=o("FSMTConfig"),DJe=o(" (FairSeq Machine-Translation model)"),GJe=l(),vm=a("li"),Rae=a("strong"),OJe=o("funnel"),VJe=o(" \u2014 "),nR=a("a"),XJe=o("FunnelConfig"),zJe=o(" (Funnel Transformer model)"),QJe=l(),Fm=a("li"),Pae=a("strong"),WJe=o("glpn"),HJe=o(" \u2014 "),sR=a("a"),UJe=o("GLPNConfig"),JJe=o(" (GLPN model)"),YJe=l(),Tm=a("li"),Bae=a("strong"),KJe=o("gpt2"),ZJe=o(" \u2014 "),lR=a("a"),eYe=o("GPT2Config"),oYe=o(" (OpenAI GPT-2 model)"),rYe=l(),Mm=a("li"),Nae=a("strong"),tYe=o("gpt_neo"),aYe=o(" \u2014 "),iR=a("a"),nYe=o("GPTNeoConfig"),sYe=o(" (GPT Neo model)"),lYe=l(),Em=a("li"),Iae=a("strong"),iYe=o("gpt_neox"),dYe=o(" \u2014 "),dR=a("a"),cYe=o("GPTNeoXConfig"),fYe=o(" (GPT NeoX model)"),mYe=l(),Cm=a("li"),qae=a("strong"),gYe=o("gptj"),hYe=o(" \u2014 "),cR=a("a"),pYe=o("GPTJConfig"),_Ye=o(" (GPT-J model)"),uYe=l(),wm=a("li"),jae=a("strong"),bYe=o("groupvit"),vYe=o(" \u2014 "),fR=a("a"),FYe=o("GroupViTConfig"),TYe=o(" (GroupViT model)"),MYe=l(),Am=a("li"),Dae=a("strong"),EYe=o("hubert"),CYe=o(" \u2014 "),mR=a("a"),wYe=o("HubertConfig"),AYe=o(" (Hubert model)"),LYe=l(),Lm=a("li"),Gae=a("strong"),yYe=o("ibert"),xYe=o(" \u2014 "),gR=a("a"),$Ye=o("IBertConfig"),kYe=o(" (I-BERT model)"),SYe=l(),ym=a("li"),Oae=a("strong"),RYe=o("imagegpt"),PYe=o(" \u2014 "),hR=a("a"),BYe=o("ImageGPTConfig"),NYe=o(" (ImageGPT model)"),IYe=l(),xm=a("li"),Vae=a("strong"),qYe=o("layoutlm"),jYe=o(" \u2014 "),pR=a("a"),DYe=o("LayoutLMConfig"),GYe=o(" (LayoutLM model)"),OYe=l(),$m=a("li"),Xae=a("strong"),VYe=o("layoutlmv2"),XYe=o(" \u2014 "),_R=a("a"),zYe=o("LayoutLMv2Config"),QYe=o(" (LayoutLMv2 model)"),WYe=l(),km=a("li"),zae=a("strong"),HYe=o("layoutlmv3"),UYe=o(" \u2014 "),uR=a("a"),JYe=o("LayoutLMv3Config"),YYe=o(" (LayoutLMv3 model)"),KYe=l(),Sm=a("li"),Qae=a("strong"),ZYe=o("led"),eKe=o(" \u2014 "),bR=a("a"),oKe=o("LEDConfig"),rKe=o(" (LED model)"),tKe=l(),Rm=a("li"),Wae=a("strong"),aKe=o("levit"),nKe=o(" \u2014 "),vR=a("a"),sKe=o("LevitConfig"),lKe=o(" (LeViT model)"),iKe=l(),Pm=a("li"),Hae=a("strong"),dKe=o("longformer"),cKe=o(" \u2014 "),FR=a("a"),fKe=o("LongformerConfig"),mKe=o(" (Longformer model)"),gKe=l(),Bm=a("li"),Uae=a("strong"),hKe=o("longt5"),pKe=o(" \u2014 "),TR=a("a"),_Ke=o("LongT5Config"),uKe=o(" (LongT5 model)"),bKe=l(),Nm=a("li"),Jae=a("strong"),vKe=o("luke"),FKe=o(" \u2014 "),MR=a("a"),TKe=o("LukeConfig"),MKe=o(" (LUKE model)"),EKe=l(),Im=a("li"),Yae=a("strong"),CKe=o("lxmert"),wKe=o(" \u2014 "),ER=a("a"),AKe=o("LxmertConfig"),LKe=o(" (LXMERT model)"),yKe=l(),qm=a("li"),Kae=a("strong"),xKe=o("m2m_100"),$Ke=o(" \u2014 "),CR=a("a"),kKe=o("M2M100Config"),SKe=o(" (M2M100 model)"),RKe=l(),jm=a("li"),Zae=a("strong"),PKe=o("marian"),BKe=o(" \u2014 "),wR=a("a"),NKe=o("MarianConfig"),IKe=o(" (Marian model)"),qKe=l(),Dm=a("li"),ene=a("strong"),jKe=o("maskformer"),DKe=o(" \u2014 "),AR=a("a"),GKe=o("MaskFormerConfig"),OKe=o(" (MaskFormer model)"),VKe=l(),Gm=a("li"),one=a("strong"),XKe=o("mbart"),zKe=o(" \u2014 "),LR=a("a"),QKe=o("MBartConfig"),WKe=o(" (mBART model)"),HKe=l(),Om=a("li"),rne=a("strong"),UKe=o("mctct"),JKe=o(" \u2014 "),yR=a("a"),YKe=o("MCTCTConfig"),KKe=o(" (M-CTC-T model)"),ZKe=l(),Vm=a("li"),tne=a("strong"),eZe=o("megatron-bert"),oZe=o(" \u2014 "),xR=a("a"),rZe=o("MegatronBertConfig"),tZe=o(" (Megatron-BERT model)"),aZe=l(),Xm=a("li"),ane=a("strong"),nZe=o("mobilebert"),sZe=o(" \u2014 "),$R=a("a"),lZe=o("MobileBertConfig"),iZe=o(" (MobileBERT model)"),dZe=l(),zm=a("li"),nne=a("strong"),cZe=o("mpnet"),fZe=o(" \u2014 "),kR=a("a"),mZe=o("MPNetConfig"),gZe=o(" (MPNet model)"),hZe=l(),Qm=a("li"),sne=a("strong"),pZe=o("mt5"),_Ze=o(" \u2014 "),SR=a("a"),uZe=o("MT5Config"),bZe=o(" (MT5 model)"),vZe=l(),Wm=a("li"),lne=a("strong"),FZe=o("nezha"),TZe=o(" \u2014 "),RR=a("a"),MZe=o("NezhaConfig"),EZe=o(" (Nezha model)"),CZe=l(),Hm=a("li"),ine=a("strong"),wZe=o("nystromformer"),AZe=o(" \u2014 "),PR=a("a"),LZe=o("NystromformerConfig"),yZe=o(" (Nystr\xF6mformer model)"),xZe=l(),Um=a("li"),dne=a("strong"),$Ze=o("openai-gpt"),kZe=o(" \u2014 "),BR=a("a"),SZe=o("OpenAIGPTConfig"),RZe=o(" (OpenAI GPT model)"),PZe=l(),Jm=a("li"),cne=a("strong"),BZe=o("opt"),NZe=o(" \u2014 "),NR=a("a"),IZe=o("OPTConfig"),qZe=o(" (OPT model)"),jZe=l(),Ym=a("li"),fne=a("strong"),DZe=o("pegasus"),GZe=o(" \u2014 "),IR=a("a"),OZe=o("PegasusConfig"),VZe=o(" (Pegasus model)"),XZe=l(),Km=a("li"),mne=a("strong"),zZe=o("perceiver"),QZe=o(" \u2014 "),qR=a("a"),WZe=o("PerceiverConfig"),HZe=o(" (Perceiver model)"),UZe=l(),Zm=a("li"),gne=a("strong"),JZe=o("plbart"),YZe=o(" \u2014 "),jR=a("a"),KZe=o("PLBartConfig"),ZZe=o(" (PLBart model)"),eeo=l(),eg=a("li"),hne=a("strong"),oeo=o("poolformer"),reo=o(" \u2014 "),DR=a("a"),teo=o("PoolFormerConfig"),aeo=o(" (PoolFormer model)"),neo=l(),og=a("li"),pne=a("strong"),seo=o("prophetnet"),leo=o(" \u2014 "),GR=a("a"),ieo=o("ProphetNetConfig"),deo=o(" (ProphetNet model)"),ceo=l(),rg=a("li"),_ne=a("strong"),feo=o("qdqbert"),meo=o(" \u2014 "),OR=a("a"),geo=o("QDQBertConfig"),heo=o(" (QDQBert model)"),peo=l(),tg=a("li"),une=a("strong"),_eo=o("rag"),ueo=o(" \u2014 "),VR=a("a"),beo=o("RagConfig"),veo=o(" (RAG model)"),Feo=l(),ag=a("li"),bne=a("strong"),Teo=o("realm"),Meo=o(" \u2014 "),XR=a("a"),Eeo=o("RealmConfig"),Ceo=o(" (REALM model)"),weo=l(),ng=a("li"),vne=a("strong"),Aeo=o("reformer"),Leo=o(" \u2014 "),zR=a("a"),yeo=o("ReformerConfig"),xeo=o(" (Reformer model)"),$eo=l(),sg=a("li"),Fne=a("strong"),keo=o("regnet"),Seo=o(" \u2014 "),QR=a("a"),Reo=o("RegNetConfig"),Peo=o(" (RegNet model)"),Beo=l(),lg=a("li"),Tne=a("strong"),Neo=o("rembert"),Ieo=o(" \u2014 "),WR=a("a"),qeo=o("RemBertConfig"),jeo=o(" (RemBERT model)"),Deo=l(),ig=a("li"),Mne=a("strong"),Geo=o("resnet"),Oeo=o(" \u2014 "),HR=a("a"),Veo=o("ResNetConfig"),Xeo=o(" (ResNet model)"),zeo=l(),dg=a("li"),Ene=a("strong"),Qeo=o("retribert"),Weo=o(" \u2014 "),UR=a("a"),Heo=o("RetriBertConfig"),Ueo=o(" (RetriBERT model)"),Jeo=l(),cg=a("li"),Cne=a("strong"),Yeo=o("roberta"),Keo=o(" \u2014 "),JR=a("a"),Zeo=o("RobertaConfig"),eoo=o(" (RoBERTa model)"),ooo=l(),fg=a("li"),wne=a("strong"),roo=o("roformer"),too=o(" \u2014 "),YR=a("a"),aoo=o("RoFormerConfig"),noo=o(" (RoFormer model)"),soo=l(),mg=a("li"),Ane=a("strong"),loo=o("segformer"),ioo=o(" \u2014 "),KR=a("a"),doo=o("SegformerConfig"),coo=o(" (SegFormer model)"),foo=l(),gg=a("li"),Lne=a("strong"),moo=o("sew"),goo=o(" \u2014 "),ZR=a("a"),hoo=o("SEWConfig"),poo=o(" (SEW model)"),_oo=l(),hg=a("li"),yne=a("strong"),uoo=o("sew-d"),boo=o(" \u2014 "),eP=a("a"),voo=o("SEWDConfig"),Foo=o(" (SEW-D model)"),Too=l(),pg=a("li"),xne=a("strong"),Moo=o("speech-encoder-decoder"),Eoo=o(" \u2014 "),oP=a("a"),Coo=o("SpeechEncoderDecoderConfig"),woo=o(" (Speech Encoder decoder model)"),Aoo=l(),_g=a("li"),$ne=a("strong"),Loo=o("speech_to_text"),yoo=o(" \u2014 "),rP=a("a"),xoo=o("Speech2TextConfig"),$oo=o(" (Speech2Text model)"),koo=l(),ug=a("li"),kne=a("strong"),Soo=o("speech_to_text_2"),Roo=o(" \u2014 "),tP=a("a"),Poo=o("Speech2Text2Config"),Boo=o(" (Speech2Text2 model)"),Noo=l(),bg=a("li"),Sne=a("strong"),Ioo=o("splinter"),qoo=o(" \u2014 "),aP=a("a"),joo=o("SplinterConfig"),Doo=o(" (Splinter model)"),Goo=l(),vg=a("li"),Rne=a("strong"),Ooo=o("squeezebert"),Voo=o(" \u2014 "),nP=a("a"),Xoo=o("SqueezeBertConfig"),zoo=o(" (SqueezeBERT model)"),Qoo=l(),Fg=a("li"),Pne=a("strong"),Woo=o("swin"),Hoo=o(" \u2014 "),sP=a("a"),Uoo=o("SwinConfig"),Joo=o(" (Swin Transformer model)"),Yoo=l(),Tg=a("li"),Bne=a("strong"),Koo=o("t5"),Zoo=o(" \u2014 "),lP=a("a"),ero=o("T5Config"),oro=o(" (T5 model)"),rro=l(),Mg=a("li"),Nne=a("strong"),tro=o("tapas"),aro=o(" \u2014 "),iP=a("a"),nro=o("TapasConfig"),sro=o(" (TAPAS model)"),lro=l(),Eg=a("li"),Ine=a("strong"),iro=o("trajectory_transformer"),dro=o(" \u2014 "),dP=a("a"),cro=o("TrajectoryTransformerConfig"),fro=o(" (Trajectory Transformer model)"),mro=l(),Cg=a("li"),qne=a("strong"),gro=o("transfo-xl"),hro=o(" \u2014 "),cP=a("a"),pro=o("TransfoXLConfig"),_ro=o(" (Transformer-XL model)"),uro=l(),wg=a("li"),jne=a("strong"),bro=o("trocr"),vro=o(" \u2014 "),fP=a("a"),Fro=o("TrOCRConfig"),Tro=o(" (TrOCR model)"),Mro=l(),Ag=a("li"),Dne=a("strong"),Ero=o("unispeech"),Cro=o(" \u2014 "),mP=a("a"),wro=o("UniSpeechConfig"),Aro=o(" (UniSpeech model)"),Lro=l(),Lg=a("li"),Gne=a("strong"),yro=o("unispeech-sat"),xro=o(" \u2014 "),gP=a("a"),$ro=o("UniSpeechSatConfig"),kro=o(" (UniSpeechSat model)"),Sro=l(),yg=a("li"),One=a("strong"),Rro=o("van"),Pro=o(" \u2014 "),hP=a("a"),Bro=o("VanConfig"),Nro=o(" (VAN model)"),Iro=l(),xg=a("li"),Vne=a("strong"),qro=o("vilt"),jro=o(" \u2014 "),pP=a("a"),Dro=o("ViltConfig"),Gro=o(" (ViLT model)"),Oro=l(),$g=a("li"),Xne=a("strong"),Vro=o("vision-encoder-decoder"),Xro=o(" \u2014 "),_P=a("a"),zro=o("VisionEncoderDecoderConfig"),Qro=o(" (Vision Encoder decoder model)"),Wro=l(),kg=a("li"),zne=a("strong"),Hro=o("vision-text-dual-encoder"),Uro=o(" \u2014 "),uP=a("a"),Jro=o("VisionTextDualEncoderConfig"),Yro=o(" (VisionTextDualEncoder model)"),Kro=l(),Sg=a("li"),Qne=a("strong"),Zro=o("visual_bert"),eto=o(" \u2014 "),bP=a("a"),oto=o("VisualBertConfig"),rto=o(" (VisualBERT model)"),tto=l(),Rg=a("li"),Wne=a("strong"),ato=o("vit"),nto=o(" \u2014 "),vP=a("a"),sto=o("ViTConfig"),lto=o(" (ViT model)"),ito=l(),Pg=a("li"),Hne=a("strong"),dto=o("vit_mae"),cto=o(" \u2014 "),FP=a("a"),fto=o("ViTMAEConfig"),mto=o(" (ViTMAE model)"),gto=l(),Bg=a("li"),Une=a("strong"),hto=o("wav2vec2"),pto=o(" \u2014 "),TP=a("a"),_to=o("Wav2Vec2Config"),uto=o(" (Wav2Vec2 model)"),bto=l(),Ng=a("li"),Jne=a("strong"),vto=o("wav2vec2-conformer"),Fto=o(" \u2014 "),MP=a("a"),Tto=o("Wav2Vec2ConformerConfig"),Mto=o(" (Wav2Vec2-Conformer model)"),Eto=l(),Ig=a("li"),Yne=a("strong"),Cto=o("wavlm"),wto=o(" \u2014 "),EP=a("a"),Ato=o("WavLMConfig"),Lto=o(" (WavLM model)"),yto=l(),qg=a("li"),Kne=a("strong"),xto=o("xglm"),$to=o(" \u2014 "),CP=a("a"),kto=o("XGLMConfig"),Sto=o(" (XGLM model)"),Rto=l(),jg=a("li"),Zne=a("strong"),Pto=o("xlm"),Bto=o(" \u2014 "),wP=a("a"),Nto=o("XLMConfig"),Ito=o(" (XLM model)"),qto=l(),Dg=a("li"),ese=a("strong"),jto=o("xlm-prophetnet"),Dto=o(" \u2014 "),AP=a("a"),Gto=o("XLMProphetNetConfig"),Oto=o(" (XLM-ProphetNet model)"),Vto=l(),Gg=a("li"),ose=a("strong"),Xto=o("xlm-roberta"),zto=o(" \u2014 "),LP=a("a"),Qto=o("XLMRobertaConfig"),Wto=o(" (XLM-RoBERTa model)"),Hto=l(),Og=a("li"),rse=a("strong"),Uto=o("xlm-roberta-xl"),Jto=o(" \u2014 "),yP=a("a"),Yto=o("XLMRobertaXLConfig"),Kto=o(" (XLM-RoBERTa-XL model)"),Zto=l(),Vg=a("li"),tse=a("strong"),eao=o("xlnet"),oao=o(" \u2014 "),xP=a("a"),rao=o("XLNetConfig"),tao=o(" (XLNet model)"),aao=l(),Xg=a("li"),ase=a("strong"),nao=o("yolos"),sao=o(" \u2014 "),$P=a("a"),lao=o("YolosConfig"),iao=o(" (YOLOS model)"),dao=l(),zg=a("li"),nse=a("strong"),cao=o("yoso"),fao=o(" \u2014 "),kP=a("a"),mao=o("YosoConfig"),gao=o(" (YOSO model)"),hao=l(),F(Qg.$$.fragment),pao=l(),Wg=a("div"),F(UL.$$.fragment),_ao=l(),sse=a("p"),uao=o("Register a new configuration for this class."),QOe=l(),Pi=a("h2"),Hg=a("a"),lse=a("span"),F(JL.$$.fragment),bao=l(),ise=a("span"),vao=o("AutoTokenizer"),WOe=l(),Ao=a("div"),F(YL.$$.fragment),Fao=l(),KL=a("p"),Tao=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),SP=a("a"),Mao=o("AutoTokenizer.from_pretrained()"),Eao=o(" class method."),Cao=l(),ZL=a("p"),wao=o("This class cannot be instantiated directly using "),dse=a("code"),Aao=o("__init__()"),Lao=o(" (throws an error)."),yao=l(),yr=a("div"),F(ey.$$.fragment),xao=l(),cse=a("p"),$ao=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),kao=l(),Ra=a("p"),Sao=o("The tokenizer class to instantiate is selected based on the "),fse=a("code"),Rao=o("model_type"),Pao=o(` property of the config object (either
passed as an argument or loaded from `),mse=a("code"),Bao=o("pretrained_model_name_or_path"),Nao=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gse=a("code"),Iao=o("pretrained_model_name_or_path"),qao=o(":"),jao=l(),k=a("ul"),jn=a("li"),hse=a("strong"),Dao=o("albert"),Gao=o(" \u2014 "),RP=a("a"),Oao=o("AlbertTokenizer"),Vao=o(" or "),PP=a("a"),Xao=o("AlbertTokenizerFast"),zao=o(" (ALBERT model)"),Qao=l(),Dn=a("li"),pse=a("strong"),Wao=o("bart"),Hao=o(" \u2014 "),BP=a("a"),Uao=o("BartTokenizer"),Jao=o(" or "),NP=a("a"),Yao=o("BartTokenizerFast"),Kao=o(" (BART model)"),Zao=l(),Gn=a("li"),_se=a("strong"),eno=o("barthez"),ono=o(" \u2014 "),IP=a("a"),rno=o("BarthezTokenizer"),tno=o(" or "),qP=a("a"),ano=o("BarthezTokenizerFast"),nno=o(" (BARThez model)"),sno=l(),Ug=a("li"),use=a("strong"),lno=o("bartpho"),ino=o(" \u2014 "),jP=a("a"),dno=o("BartphoTokenizer"),cno=o(" (BARTpho model)"),fno=l(),On=a("li"),bse=a("strong"),mno=o("bert"),gno=o(" \u2014 "),DP=a("a"),hno=o("BertTokenizer"),pno=o(" or "),GP=a("a"),_no=o("BertTokenizerFast"),uno=o(" (BERT model)"),bno=l(),Jg=a("li"),vse=a("strong"),vno=o("bert-generation"),Fno=o(" \u2014 "),OP=a("a"),Tno=o("BertGenerationTokenizer"),Mno=o(" (Bert Generation model)"),Eno=l(),Yg=a("li"),Fse=a("strong"),Cno=o("bert-japanese"),wno=o(" \u2014 "),VP=a("a"),Ano=o("BertJapaneseTokenizer"),Lno=o(" (BertJapanese model)"),yno=l(),Kg=a("li"),Tse=a("strong"),xno=o("bertweet"),$no=o(" \u2014 "),XP=a("a"),kno=o("BertweetTokenizer"),Sno=o(" (BERTweet model)"),Rno=l(),Vn=a("li"),Mse=a("strong"),Pno=o("big_bird"),Bno=o(" \u2014 "),zP=a("a"),Nno=o("BigBirdTokenizer"),Ino=o(" or "),QP=a("a"),qno=o("BigBirdTokenizerFast"),jno=o(" (BigBird model)"),Dno=l(),Xn=a("li"),Ese=a("strong"),Gno=o("bigbird_pegasus"),Ono=o(" \u2014 "),WP=a("a"),Vno=o("PegasusTokenizer"),Xno=o(" or "),HP=a("a"),zno=o("PegasusTokenizerFast"),Qno=o(" (BigBird-Pegasus model)"),Wno=l(),zn=a("li"),Cse=a("strong"),Hno=o("blenderbot"),Uno=o(" \u2014 "),UP=a("a"),Jno=o("BlenderbotTokenizer"),Yno=o(" or "),JP=a("a"),Kno=o("BlenderbotTokenizerFast"),Zno=o(" (Blenderbot model)"),eso=l(),Zg=a("li"),wse=a("strong"),oso=o("blenderbot-small"),rso=o(" \u2014 "),YP=a("a"),tso=o("BlenderbotSmallTokenizer"),aso=o(" (BlenderbotSmall model)"),nso=l(),eh=a("li"),Ase=a("strong"),sso=o("bloom"),lso=o(" \u2014 "),KP=a("a"),iso=o("BloomTokenizerFast"),dso=o(" (BLOOM model)"),cso=l(),oh=a("li"),Lse=a("strong"),fso=o("byt5"),mso=o(" \u2014 "),ZP=a("a"),gso=o("ByT5Tokenizer"),hso=o(" (ByT5 model)"),pso=l(),Qn=a("li"),yse=a("strong"),_so=o("camembert"),uso=o(" \u2014 "),eB=a("a"),bso=o("CamembertTokenizer"),vso=o(" or "),oB=a("a"),Fso=o("CamembertTokenizerFast"),Tso=o(" (CamemBERT model)"),Mso=l(),rh=a("li"),xse=a("strong"),Eso=o("canine"),Cso=o(" \u2014 "),rB=a("a"),wso=o("CanineTokenizer"),Aso=o(" (CANINE model)"),Lso=l(),Wn=a("li"),$se=a("strong"),yso=o("clip"),xso=o(" \u2014 "),tB=a("a"),$so=o("CLIPTokenizer"),kso=o(" or "),aB=a("a"),Sso=o("CLIPTokenizerFast"),Rso=o(" (CLIP model)"),Pso=l(),Hn=a("li"),kse=a("strong"),Bso=o("codegen"),Nso=o(" \u2014 "),nB=a("a"),Iso=o("CodeGenTokenizer"),qso=o(" or "),sB=a("a"),jso=o("CodeGenTokenizerFast"),Dso=o(" (CodeGen model)"),Gso=l(),Un=a("li"),Sse=a("strong"),Oso=o("convbert"),Vso=o(" \u2014 "),lB=a("a"),Xso=o("ConvBertTokenizer"),zso=o(" or "),iB=a("a"),Qso=o("ConvBertTokenizerFast"),Wso=o(" (ConvBERT model)"),Hso=l(),Jn=a("li"),Rse=a("strong"),Uso=o("cpm"),Jso=o(" \u2014 "),dB=a("a"),Yso=o("CpmTokenizer"),Kso=o(" or "),cB=a("a"),Zso=o("CpmTokenizerFast"),elo=o(" (CPM model)"),olo=l(),th=a("li"),Pse=a("strong"),rlo=o("ctrl"),tlo=o(" \u2014 "),fB=a("a"),alo=o("CTRLTokenizer"),nlo=o(" (CTRL model)"),slo=l(),Yn=a("li"),Bse=a("strong"),llo=o("data2vec-text"),ilo=o(" \u2014 "),mB=a("a"),dlo=o("RobertaTokenizer"),clo=o(" or "),gB=a("a"),flo=o("RobertaTokenizerFast"),mlo=o(" (Data2VecText model)"),glo=l(),Kn=a("li"),Nse=a("strong"),hlo=o("deberta"),plo=o(" \u2014 "),hB=a("a"),_lo=o("DebertaTokenizer"),ulo=o(" or "),pB=a("a"),blo=o("DebertaTokenizerFast"),vlo=o(" (DeBERTa model)"),Flo=l(),Zn=a("li"),Ise=a("strong"),Tlo=o("deberta-v2"),Mlo=o(" \u2014 "),_B=a("a"),Elo=o("DebertaV2Tokenizer"),Clo=o(" or "),uB=a("a"),wlo=o("DebertaV2TokenizerFast"),Alo=o(" (DeBERTa-v2 model)"),Llo=l(),es=a("li"),qse=a("strong"),ylo=o("distilbert"),xlo=o(" \u2014 "),bB=a("a"),$lo=o("DistilBertTokenizer"),klo=o(" or "),vB=a("a"),Slo=o("DistilBertTokenizerFast"),Rlo=o(" (DistilBERT model)"),Plo=l(),os=a("li"),jse=a("strong"),Blo=o("dpr"),Nlo=o(" \u2014 "),FB=a("a"),Ilo=o("DPRQuestionEncoderTokenizer"),qlo=o(" or "),TB=a("a"),jlo=o("DPRQuestionEncoderTokenizerFast"),Dlo=o(" (DPR model)"),Glo=l(),rs=a("li"),Dse=a("strong"),Olo=o("electra"),Vlo=o(" \u2014 "),MB=a("a"),Xlo=o("ElectraTokenizer"),zlo=o(" or "),EB=a("a"),Qlo=o("ElectraTokenizerFast"),Wlo=o(" (ELECTRA model)"),Hlo=l(),ah=a("li"),Gse=a("strong"),Ulo=o("flaubert"),Jlo=o(" \u2014 "),CB=a("a"),Ylo=o("FlaubertTokenizer"),Klo=o(" (FlauBERT model)"),Zlo=l(),ts=a("li"),Ose=a("strong"),eio=o("fnet"),oio=o(" \u2014 "),wB=a("a"),rio=o("FNetTokenizer"),tio=o(" or "),AB=a("a"),aio=o("FNetTokenizerFast"),nio=o(" (FNet model)"),sio=l(),nh=a("li"),Vse=a("strong"),lio=o("fsmt"),iio=o(" \u2014 "),LB=a("a"),dio=o("FSMTTokenizer"),cio=o(" (FairSeq Machine-Translation model)"),fio=l(),as=a("li"),Xse=a("strong"),mio=o("funnel"),gio=o(" \u2014 "),yB=a("a"),hio=o("FunnelTokenizer"),pio=o(" or "),xB=a("a"),_io=o("FunnelTokenizerFast"),uio=o(" (Funnel Transformer model)"),bio=l(),ns=a("li"),zse=a("strong"),vio=o("gpt2"),Fio=o(" \u2014 "),$B=a("a"),Tio=o("GPT2Tokenizer"),Mio=o(" or "),kB=a("a"),Eio=o("GPT2TokenizerFast"),Cio=o(" (OpenAI GPT-2 model)"),wio=l(),ss=a("li"),Qse=a("strong"),Aio=o("gpt_neo"),Lio=o(" \u2014 "),SB=a("a"),yio=o("GPT2Tokenizer"),xio=o(" or "),RB=a("a"),$io=o("GPT2TokenizerFast"),kio=o(" (GPT Neo model)"),Sio=l(),sh=a("li"),Wse=a("strong"),Rio=o("gpt_neox"),Pio=o(" \u2014 "),PB=a("a"),Bio=o("GPTNeoXTokenizerFast"),Nio=o(" (GPT NeoX model)"),Iio=l(),ls=a("li"),Hse=a("strong"),qio=o("gptj"),jio=o(" \u2014 "),BB=a("a"),Dio=o("GPT2Tokenizer"),Gio=o(" or "),NB=a("a"),Oio=o("GPT2TokenizerFast"),Vio=o(" (GPT-J model)"),Xio=l(),is=a("li"),Use=a("strong"),zio=o("groupvit"),Qio=o(" \u2014 "),IB=a("a"),Wio=o("CLIPTokenizer"),Hio=o(" or "),qB=a("a"),Uio=o("CLIPTokenizerFast"),Jio=o(" (GroupViT model)"),Yio=l(),ds=a("li"),Jse=a("strong"),Kio=o("herbert"),Zio=o(" \u2014 "),jB=a("a"),edo=o("HerbertTokenizer"),odo=o(" or "),DB=a("a"),rdo=o("HerbertTokenizerFast"),tdo=o(" (HerBERT model)"),ado=l(),lh=a("li"),Yse=a("strong"),ndo=o("hubert"),sdo=o(" \u2014 "),GB=a("a"),ldo=o("Wav2Vec2CTCTokenizer"),ido=o(" (Hubert model)"),ddo=l(),cs=a("li"),Kse=a("strong"),cdo=o("ibert"),fdo=o(" \u2014 "),OB=a("a"),mdo=o("RobertaTokenizer"),gdo=o(" or "),VB=a("a"),hdo=o("RobertaTokenizerFast"),pdo=o(" (I-BERT model)"),_do=l(),fs=a("li"),Zse=a("strong"),udo=o("layoutlm"),bdo=o(" \u2014 "),XB=a("a"),vdo=o("LayoutLMTokenizer"),Fdo=o(" or "),zB=a("a"),Tdo=o("LayoutLMTokenizerFast"),Mdo=o(" (LayoutLM model)"),Edo=l(),ms=a("li"),ele=a("strong"),Cdo=o("layoutlmv2"),wdo=o(" \u2014 "),QB=a("a"),Ado=o("LayoutLMv2Tokenizer"),Ldo=o(" or "),WB=a("a"),ydo=o("LayoutLMv2TokenizerFast"),xdo=o(" (LayoutLMv2 model)"),$do=l(),gs=a("li"),ole=a("strong"),kdo=o("layoutlmv3"),Sdo=o(" \u2014 "),HB=a("a"),Rdo=o("LayoutLMv3Tokenizer"),Pdo=o(" or "),UB=a("a"),Bdo=o("LayoutLMv3TokenizerFast"),Ndo=o(" (LayoutLMv3 model)"),Ido=l(),hs=a("li"),rle=a("strong"),qdo=o("layoutxlm"),jdo=o(" \u2014 "),JB=a("a"),Ddo=o("LayoutXLMTokenizer"),Gdo=o(" or "),YB=a("a"),Odo=o("LayoutXLMTokenizerFast"),Vdo=o(" (LayoutXLM model)"),Xdo=l(),ps=a("li"),tle=a("strong"),zdo=o("led"),Qdo=o(" \u2014 "),KB=a("a"),Wdo=o("LEDTokenizer"),Hdo=o(" or "),ZB=a("a"),Udo=o("LEDTokenizerFast"),Jdo=o(" (LED model)"),Ydo=l(),_s=a("li"),ale=a("strong"),Kdo=o("longformer"),Zdo=o(" \u2014 "),eN=a("a"),eco=o("LongformerTokenizer"),oco=o(" or "),oN=a("a"),rco=o("LongformerTokenizerFast"),tco=o(" (Longformer model)"),aco=l(),us=a("li"),nle=a("strong"),nco=o("longt5"),sco=o(" \u2014 "),rN=a("a"),lco=o("T5Tokenizer"),ico=o(" or "),tN=a("a"),dco=o("T5TokenizerFast"),cco=o(" (LongT5 model)"),fco=l(),ih=a("li"),sle=a("strong"),mco=o("luke"),gco=o(" \u2014 "),aN=a("a"),hco=o("LukeTokenizer"),pco=o(" (LUKE model)"),_co=l(),bs=a("li"),lle=a("strong"),uco=o("lxmert"),bco=o(" \u2014 "),nN=a("a"),vco=o("LxmertTokenizer"),Fco=o(" or "),sN=a("a"),Tco=o("LxmertTokenizerFast"),Mco=o(" (LXMERT model)"),Eco=l(),dh=a("li"),ile=a("strong"),Cco=o("m2m_100"),wco=o(" \u2014 "),lN=a("a"),Aco=o("M2M100Tokenizer"),Lco=o(" (M2M100 model)"),yco=l(),ch=a("li"),dle=a("strong"),xco=o("marian"),$co=o(" \u2014 "),iN=a("a"),kco=o("MarianTokenizer"),Sco=o(" (Marian model)"),Rco=l(),vs=a("li"),cle=a("strong"),Pco=o("mbart"),Bco=o(" \u2014 "),dN=a("a"),Nco=o("MBartTokenizer"),Ico=o(" or "),cN=a("a"),qco=o("MBartTokenizerFast"),jco=o(" (mBART model)"),Dco=l(),Fs=a("li"),fle=a("strong"),Gco=o("mbart50"),Oco=o(" \u2014 "),fN=a("a"),Vco=o("MBart50Tokenizer"),Xco=o(" or "),mN=a("a"),zco=o("MBart50TokenizerFast"),Qco=o(" (mBART-50 model)"),Wco=l(),Ts=a("li"),mle=a("strong"),Hco=o("megatron-bert"),Uco=o(" \u2014 "),gN=a("a"),Jco=o("BertTokenizer"),Yco=o(" or "),hN=a("a"),Kco=o("BertTokenizerFast"),Zco=o(" (Megatron-BERT model)"),efo=l(),fh=a("li"),gle=a("strong"),ofo=o("mluke"),rfo=o(" \u2014 "),pN=a("a"),tfo=o("MLukeTokenizer"),afo=o(" (mLUKE model)"),nfo=l(),Ms=a("li"),hle=a("strong"),sfo=o("mobilebert"),lfo=o(" \u2014 "),_N=a("a"),ifo=o("MobileBertTokenizer"),dfo=o(" or "),uN=a("a"),cfo=o("MobileBertTokenizerFast"),ffo=o(" (MobileBERT model)"),mfo=l(),Es=a("li"),ple=a("strong"),gfo=o("mpnet"),hfo=o(" \u2014 "),bN=a("a"),pfo=o("MPNetTokenizer"),_fo=o(" or "),vN=a("a"),ufo=o("MPNetTokenizerFast"),bfo=o(" (MPNet model)"),vfo=l(),Cs=a("li"),_le=a("strong"),Ffo=o("mt5"),Tfo=o(" \u2014 "),FN=a("a"),Mfo=o("MT5Tokenizer"),Efo=o(" or "),TN=a("a"),Cfo=o("MT5TokenizerFast"),wfo=o(" (MT5 model)"),Afo=l(),ws=a("li"),ule=a("strong"),Lfo=o("nezha"),yfo=o(" \u2014 "),MN=a("a"),xfo=o("BertTokenizer"),$fo=o(" or "),EN=a("a"),kfo=o("BertTokenizerFast"),Sfo=o(" (Nezha model)"),Rfo=l(),As=a("li"),ble=a("strong"),Pfo=o("nystromformer"),Bfo=o(" \u2014 "),CN=a("a"),Nfo=o("AlbertTokenizer"),Ifo=o(" or "),wN=a("a"),qfo=o("AlbertTokenizerFast"),jfo=o(" (Nystr\xF6mformer model)"),Dfo=l(),Ls=a("li"),vle=a("strong"),Gfo=o("openai-gpt"),Ofo=o(" \u2014 "),AN=a("a"),Vfo=o("OpenAIGPTTokenizer"),Xfo=o(" or "),LN=a("a"),zfo=o("OpenAIGPTTokenizerFast"),Qfo=o(" (OpenAI GPT model)"),Wfo=l(),mh=a("li"),Fle=a("strong"),Hfo=o("opt"),Ufo=o(" \u2014 "),yN=a("a"),Jfo=o("GPT2Tokenizer"),Yfo=o(" (OPT model)"),Kfo=l(),ys=a("li"),Tle=a("strong"),Zfo=o("pegasus"),emo=o(" \u2014 "),xN=a("a"),omo=o("PegasusTokenizer"),rmo=o(" or "),$N=a("a"),tmo=o("PegasusTokenizerFast"),amo=o(" (Pegasus model)"),nmo=l(),gh=a("li"),Mle=a("strong"),smo=o("perceiver"),lmo=o(" \u2014 "),kN=a("a"),imo=o("PerceiverTokenizer"),dmo=o(" (Perceiver model)"),cmo=l(),hh=a("li"),Ele=a("strong"),fmo=o("phobert"),mmo=o(" \u2014 "),SN=a("a"),gmo=o("PhobertTokenizer"),hmo=o(" (PhoBERT model)"),pmo=l(),ph=a("li"),Cle=a("strong"),_mo=o("plbart"),umo=o(" \u2014 "),RN=a("a"),bmo=o("PLBartTokenizer"),vmo=o(" (PLBart model)"),Fmo=l(),_h=a("li"),wle=a("strong"),Tmo=o("prophetnet"),Mmo=o(" \u2014 "),PN=a("a"),Emo=o("ProphetNetTokenizer"),Cmo=o(" (ProphetNet model)"),wmo=l(),xs=a("li"),Ale=a("strong"),Amo=o("qdqbert"),Lmo=o(" \u2014 "),BN=a("a"),ymo=o("BertTokenizer"),xmo=o(" or "),NN=a("a"),$mo=o("BertTokenizerFast"),kmo=o(" (QDQBert model)"),Smo=l(),uh=a("li"),Lle=a("strong"),Rmo=o("rag"),Pmo=o(" \u2014 "),IN=a("a"),Bmo=o("RagTokenizer"),Nmo=o(" (RAG model)"),Imo=l(),$s=a("li"),yle=a("strong"),qmo=o("realm"),jmo=o(" \u2014 "),qN=a("a"),Dmo=o("RealmTokenizer"),Gmo=o(" or "),jN=a("a"),Omo=o("RealmTokenizerFast"),Vmo=o(" (REALM model)"),Xmo=l(),ks=a("li"),xle=a("strong"),zmo=o("reformer"),Qmo=o(" \u2014 "),DN=a("a"),Wmo=o("ReformerTokenizer"),Hmo=o(" or "),GN=a("a"),Umo=o("ReformerTokenizerFast"),Jmo=o(" (Reformer model)"),Ymo=l(),Ss=a("li"),$le=a("strong"),Kmo=o("rembert"),Zmo=o(" \u2014 "),ON=a("a"),ego=o("RemBertTokenizer"),ogo=o(" or "),VN=a("a"),rgo=o("RemBertTokenizerFast"),tgo=o(" (RemBERT model)"),ago=l(),Rs=a("li"),kle=a("strong"),ngo=o("retribert"),sgo=o(" \u2014 "),XN=a("a"),lgo=o("RetriBertTokenizer"),igo=o(" or "),zN=a("a"),dgo=o("RetriBertTokenizerFast"),cgo=o(" (RetriBERT model)"),fgo=l(),Ps=a("li"),Sle=a("strong"),mgo=o("roberta"),ggo=o(" \u2014 "),QN=a("a"),hgo=o("RobertaTokenizer"),pgo=o(" or "),WN=a("a"),_go=o("RobertaTokenizerFast"),ugo=o(" (RoBERTa model)"),bgo=l(),Bs=a("li"),Rle=a("strong"),vgo=o("roformer"),Fgo=o(" \u2014 "),HN=a("a"),Tgo=o("RoFormerTokenizer"),Mgo=o(" or "),UN=a("a"),Ego=o("RoFormerTokenizerFast"),Cgo=o(" (RoFormer model)"),wgo=l(),bh=a("li"),Ple=a("strong"),Ago=o("speech_to_text"),Lgo=o(" \u2014 "),JN=a("a"),ygo=o("Speech2TextTokenizer"),xgo=o(" (Speech2Text model)"),$go=l(),vh=a("li"),Ble=a("strong"),kgo=o("speech_to_text_2"),Sgo=o(" \u2014 "),YN=a("a"),Rgo=o("Speech2Text2Tokenizer"),Pgo=o(" (Speech2Text2 model)"),Bgo=l(),Ns=a("li"),Nle=a("strong"),Ngo=o("splinter"),Igo=o(" \u2014 "),KN=a("a"),qgo=o("SplinterTokenizer"),jgo=o(" or "),ZN=a("a"),Dgo=o("SplinterTokenizerFast"),Ggo=o(" (Splinter model)"),Ogo=l(),Is=a("li"),Ile=a("strong"),Vgo=o("squeezebert"),Xgo=o(" \u2014 "),eI=a("a"),zgo=o("SqueezeBertTokenizer"),Qgo=o(" or "),oI=a("a"),Wgo=o("SqueezeBertTokenizerFast"),Hgo=o(" (SqueezeBERT model)"),Ugo=l(),qs=a("li"),qle=a("strong"),Jgo=o("t5"),Ygo=o(" \u2014 "),rI=a("a"),Kgo=o("T5Tokenizer"),Zgo=o(" or "),tI=a("a"),eho=o("T5TokenizerFast"),oho=o(" (T5 model)"),rho=l(),Fh=a("li"),jle=a("strong"),tho=o("tapas"),aho=o(" \u2014 "),aI=a("a"),nho=o("TapasTokenizer"),sho=o(" (TAPAS model)"),lho=l(),Th=a("li"),Dle=a("strong"),iho=o("tapex"),dho=o(" \u2014 "),nI=a("a"),cho=o("TapexTokenizer"),fho=o(" (TAPEX model)"),mho=l(),Mh=a("li"),Gle=a("strong"),gho=o("transfo-xl"),hho=o(" \u2014 "),sI=a("a"),pho=o("TransfoXLTokenizer"),_ho=o(" (Transformer-XL model)"),uho=l(),js=a("li"),Ole=a("strong"),bho=o("vilt"),vho=o(" \u2014 "),lI=a("a"),Fho=o("BertTokenizer"),Tho=o(" or "),iI=a("a"),Mho=o("BertTokenizerFast"),Eho=o(" (ViLT model)"),Cho=l(),Ds=a("li"),Vle=a("strong"),who=o("visual_bert"),Aho=o(" \u2014 "),dI=a("a"),Lho=o("BertTokenizer"),yho=o(" or "),cI=a("a"),xho=o("BertTokenizerFast"),$ho=o(" (VisualBERT model)"),kho=l(),Eh=a("li"),Xle=a("strong"),Sho=o("wav2vec2"),Rho=o(" \u2014 "),fI=a("a"),Pho=o("Wav2Vec2CTCTokenizer"),Bho=o(" (Wav2Vec2 model)"),Nho=l(),Ch=a("li"),zle=a("strong"),Iho=o("wav2vec2-conformer"),qho=o(" \u2014 "),mI=a("a"),jho=o("Wav2Vec2CTCTokenizer"),Dho=o(" (Wav2Vec2-Conformer model)"),Gho=l(),wh=a("li"),Qle=a("strong"),Oho=o("wav2vec2_phoneme"),Vho=o(" \u2014 "),gI=a("a"),Xho=o("Wav2Vec2PhonemeCTCTokenizer"),zho=o(" (Wav2Vec2Phoneme model)"),Qho=l(),Gs=a("li"),Wle=a("strong"),Who=o("xglm"),Hho=o(" \u2014 "),hI=a("a"),Uho=o("XGLMTokenizer"),Jho=o(" or "),pI=a("a"),Yho=o("XGLMTokenizerFast"),Kho=o(" (XGLM model)"),Zho=l(),Ah=a("li"),Hle=a("strong"),epo=o("xlm"),opo=o(" \u2014 "),_I=a("a"),rpo=o("XLMTokenizer"),tpo=o(" (XLM model)"),apo=l(),Lh=a("li"),Ule=a("strong"),npo=o("xlm-prophetnet"),spo=o(" \u2014 "),uI=a("a"),lpo=o("XLMProphetNetTokenizer"),ipo=o(" (XLM-ProphetNet model)"),dpo=l(),Os=a("li"),Jle=a("strong"),cpo=o("xlm-roberta"),fpo=o(" \u2014 "),bI=a("a"),mpo=o("XLMRobertaTokenizer"),gpo=o(" or "),vI=a("a"),hpo=o("XLMRobertaTokenizerFast"),ppo=o(" (XLM-RoBERTa model)"),_po=l(),Vs=a("li"),Yle=a("strong"),upo=o("xlm-roberta-xl"),bpo=o(" \u2014 "),FI=a("a"),vpo=o("RobertaTokenizer"),Fpo=o(" or "),TI=a("a"),Tpo=o("RobertaTokenizerFast"),Mpo=o(" (XLM-RoBERTa-XL model)"),Epo=l(),Xs=a("li"),Kle=a("strong"),Cpo=o("xlnet"),wpo=o(" \u2014 "),MI=a("a"),Apo=o("XLNetTokenizer"),Lpo=o(" or "),EI=a("a"),ypo=o("XLNetTokenizerFast"),xpo=o(" (XLNet model)"),$po=l(),zs=a("li"),Zle=a("strong"),kpo=o("yoso"),Spo=o(" \u2014 "),CI=a("a"),Rpo=o("AlbertTokenizer"),Ppo=o(" or "),wI=a("a"),Bpo=o("AlbertTokenizerFast"),Npo=o(" (YOSO model)"),Ipo=l(),F(yh.$$.fragment),qpo=l(),xh=a("div"),F(oy.$$.fragment),jpo=l(),eie=a("p"),Dpo=o("Register a new tokenizer in this mapping."),HOe=l(),Bi=a("h2"),$h=a("a"),oie=a("span"),F(ry.$$.fragment),Gpo=l(),rie=a("span"),Opo=o("AutoFeatureExtractor"),UOe=l(),Lo=a("div"),F(ty.$$.fragment),Vpo=l(),ay=a("p"),Xpo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),AI=a("a"),zpo=o("AutoFeatureExtractor.from_pretrained()"),Qpo=o(" class method."),Wpo=l(),ny=a("p"),Hpo=o("This class cannot be instantiated directly using "),tie=a("code"),Upo=o("__init__()"),Jpo=o(" (throws an error)."),Ypo=l(),He=a("div"),F(sy.$$.fragment),Kpo=l(),aie=a("p"),Zpo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),e_o=l(),Pa=a("p"),o_o=o("The feature extractor class to instantiate is selected based on the "),nie=a("code"),r_o=o("model_type"),t_o=o(` property of the config object
(either passed as an argument or loaded from `),sie=a("code"),a_o=o("pretrained_model_name_or_path"),n_o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),lie=a("code"),s_o=o("pretrained_model_name_or_path"),l_o=o(":"),i_o=l(),Y=a("ul"),kh=a("li"),iie=a("strong"),d_o=o("beit"),c_o=o(" \u2014 "),LI=a("a"),f_o=o("BeitFeatureExtractor"),m_o=o(" (BEiT model)"),g_o=l(),Sh=a("li"),die=a("strong"),h_o=o("clip"),p_o=o(" \u2014 "),yI=a("a"),__o=o("CLIPFeatureExtractor"),u_o=o(" (CLIP model)"),b_o=l(),Rh=a("li"),cie=a("strong"),v_o=o("convnext"),F_o=o(" \u2014 "),xI=a("a"),T_o=o("ConvNextFeatureExtractor"),M_o=o(" (ConvNeXT model)"),E_o=l(),Ph=a("li"),fie=a("strong"),C_o=o("cvt"),w_o=o(" \u2014 "),$I=a("a"),A_o=o("ConvNextFeatureExtractor"),L_o=o(" (CvT model)"),y_o=l(),Bh=a("li"),mie=a("strong"),x_o=o("data2vec-audio"),$_o=o(" \u2014 "),kI=a("a"),k_o=o("Wav2Vec2FeatureExtractor"),S_o=o(" (Data2VecAudio model)"),R_o=l(),Nh=a("li"),gie=a("strong"),P_o=o("data2vec-vision"),B_o=o(" \u2014 "),SI=a("a"),N_o=o("BeitFeatureExtractor"),I_o=o(" (Data2VecVision model)"),q_o=l(),Ih=a("li"),hie=a("strong"),j_o=o("deit"),D_o=o(" \u2014 "),RI=a("a"),G_o=o("DeiTFeatureExtractor"),O_o=o(" (DeiT model)"),V_o=l(),qh=a("li"),pie=a("strong"),X_o=o("detr"),z_o=o(" \u2014 "),PI=a("a"),Q_o=o("DetrFeatureExtractor"),W_o=o(" (DETR model)"),H_o=l(),jh=a("li"),_ie=a("strong"),U_o=o("dpt"),J_o=o(" \u2014 "),BI=a("a"),Y_o=o("DPTFeatureExtractor"),K_o=o(" (DPT model)"),Z_o=l(),Dh=a("li"),uie=a("strong"),euo=o("flava"),ouo=o(" \u2014 "),NI=a("a"),ruo=o("FlavaFeatureExtractor"),tuo=o(" (FLAVA model)"),auo=l(),Gh=a("li"),bie=a("strong"),nuo=o("glpn"),suo=o(" \u2014 "),II=a("a"),luo=o("GLPNFeatureExtractor"),iuo=o(" (GLPN model)"),duo=l(),Oh=a("li"),vie=a("strong"),cuo=o("groupvit"),fuo=o(" \u2014 "),qI=a("a"),muo=o("CLIPFeatureExtractor"),guo=o(" (GroupViT model)"),huo=l(),Vh=a("li"),Fie=a("strong"),puo=o("hubert"),_uo=o(" \u2014 "),jI=a("a"),uuo=o("Wav2Vec2FeatureExtractor"),buo=o(" (Hubert model)"),vuo=l(),Xh=a("li"),Tie=a("strong"),Fuo=o("imagegpt"),Tuo=o(" \u2014 "),DI=a("a"),Muo=o("ImageGPTFeatureExtractor"),Euo=o(" (ImageGPT model)"),Cuo=l(),zh=a("li"),Mie=a("strong"),wuo=o("layoutlmv2"),Auo=o(" \u2014 "),GI=a("a"),Luo=o("LayoutLMv2FeatureExtractor"),yuo=o(" (LayoutLMv2 model)"),xuo=l(),Qh=a("li"),Eie=a("strong"),$uo=o("layoutlmv3"),kuo=o(" \u2014 "),OI=a("a"),Suo=o("LayoutLMv3FeatureExtractor"),Ruo=o(" (LayoutLMv3 model)"),Puo=l(),Wh=a("li"),Cie=a("strong"),Buo=o("levit"),Nuo=o(" \u2014 "),VI=a("a"),Iuo=o("LevitFeatureExtractor"),quo=o(" (LeViT model)"),juo=l(),Hh=a("li"),wie=a("strong"),Duo=o("maskformer"),Guo=o(" \u2014 "),XI=a("a"),Ouo=o("MaskFormerFeatureExtractor"),Vuo=o(" (MaskFormer model)"),Xuo=l(),Uh=a("li"),Aie=a("strong"),zuo=o("mctct"),Quo=o(" \u2014 "),zI=a("a"),Wuo=o("MCTCTFeatureExtractor"),Huo=o(" (M-CTC-T model)"),Uuo=l(),Jh=a("li"),Lie=a("strong"),Juo=o("perceiver"),Yuo=o(" \u2014 "),QI=a("a"),Kuo=o("PerceiverFeatureExtractor"),Zuo=o(" (Perceiver model)"),e2o=l(),Yh=a("li"),yie=a("strong"),o2o=o("poolformer"),r2o=o(" \u2014 "),WI=a("a"),t2o=o("PoolFormerFeatureExtractor"),a2o=o(" (PoolFormer model)"),n2o=l(),Kh=a("li"),xie=a("strong"),s2o=o("regnet"),l2o=o(" \u2014 "),HI=a("a"),i2o=o("ConvNextFeatureExtractor"),d2o=o(" (RegNet model)"),c2o=l(),Zh=a("li"),$ie=a("strong"),f2o=o("resnet"),m2o=o(" \u2014 "),UI=a("a"),g2o=o("ConvNextFeatureExtractor"),h2o=o(" (ResNet model)"),p2o=l(),ep=a("li"),kie=a("strong"),_2o=o("segformer"),u2o=o(" \u2014 "),JI=a("a"),b2o=o("SegformerFeatureExtractor"),v2o=o(" (SegFormer model)"),F2o=l(),op=a("li"),Sie=a("strong"),T2o=o("speech_to_text"),M2o=o(" \u2014 "),YI=a("a"),E2o=o("Speech2TextFeatureExtractor"),C2o=o(" (Speech2Text model)"),w2o=l(),rp=a("li"),Rie=a("strong"),A2o=o("swin"),L2o=o(" \u2014 "),KI=a("a"),y2o=o("ViTFeatureExtractor"),x2o=o(" (Swin Transformer model)"),$2o=l(),tp=a("li"),Pie=a("strong"),k2o=o("van"),S2o=o(" \u2014 "),ZI=a("a"),R2o=o("ConvNextFeatureExtractor"),P2o=o(" (VAN model)"),B2o=l(),ap=a("li"),Bie=a("strong"),N2o=o("vilt"),I2o=o(" \u2014 "),eq=a("a"),q2o=o("ViltFeatureExtractor"),j2o=o(" (ViLT model)"),D2o=l(),np=a("li"),Nie=a("strong"),G2o=o("vit"),O2o=o(" \u2014 "),oq=a("a"),V2o=o("ViTFeatureExtractor"),X2o=o(" (ViT model)"),z2o=l(),sp=a("li"),Iie=a("strong"),Q2o=o("vit_mae"),W2o=o(" \u2014 "),rq=a("a"),H2o=o("ViTFeatureExtractor"),U2o=o(" (ViTMAE model)"),J2o=l(),lp=a("li"),qie=a("strong"),Y2o=o("wav2vec2"),K2o=o(" \u2014 "),tq=a("a"),Z2o=o("Wav2Vec2FeatureExtractor"),e1o=o(" (Wav2Vec2 model)"),o1o=l(),ip=a("li"),jie=a("strong"),r1o=o("wav2vec2-conformer"),t1o=o(" \u2014 "),aq=a("a"),a1o=o("Wav2Vec2FeatureExtractor"),n1o=o(" (Wav2Vec2-Conformer model)"),s1o=l(),dp=a("li"),Die=a("strong"),l1o=o("yolos"),i1o=o(" \u2014 "),nq=a("a"),d1o=o("YolosFeatureExtractor"),c1o=o(" (YOLOS model)"),f1o=l(),F(cp.$$.fragment),m1o=l(),F(fp.$$.fragment),g1o=l(),mp=a("div"),F(ly.$$.fragment),h1o=l(),Gie=a("p"),p1o=o("Register a new feature extractor for this class."),JOe=l(),Ni=a("h2"),gp=a("a"),Oie=a("span"),F(iy.$$.fragment),_1o=l(),Vie=a("span"),u1o=o("AutoProcessor"),YOe=l(),yo=a("div"),F(dy.$$.fragment),b1o=l(),cy=a("p"),v1o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),sq=a("a"),F1o=o("AutoProcessor.from_pretrained()"),T1o=o(" class method."),M1o=l(),fy=a("p"),E1o=o("This class cannot be instantiated directly using "),Xie=a("code"),C1o=o("__init__()"),w1o=o(" (throws an error)."),A1o=l(),Ue=a("div"),F(my.$$.fragment),L1o=l(),zie=a("p"),y1o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),x1o=l(),Ii=a("p"),$1o=o("The processor class to instantiate is selected based on the "),Qie=a("code"),k1o=o("model_type"),S1o=o(` property of the config object (either
passed as an argument or loaded from `),Wie=a("code"),R1o=o("pretrained_model_name_or_path"),P1o=o(" if possible):"),B1o=l(),he=a("ul"),hp=a("li"),Hie=a("strong"),N1o=o("clip"),I1o=o(" \u2014 "),lq=a("a"),q1o=o("CLIPProcessor"),j1o=o(" (CLIP model)"),D1o=l(),pp=a("li"),Uie=a("strong"),G1o=o("flava"),O1o=o(" \u2014 "),Jie=a("code"),V1o=o("FLAVAProcessor"),X1o=o(" (FLAVA model)"),z1o=l(),_p=a("li"),Yie=a("strong"),Q1o=o("groupvit"),W1o=o(" \u2014 "),iq=a("a"),H1o=o("CLIPProcessor"),U1o=o(" (GroupViT model)"),J1o=l(),up=a("li"),Kie=a("strong"),Y1o=o("layoutlmv2"),K1o=o(" \u2014 "),dq=a("a"),Z1o=o("LayoutLMv2Processor"),e7o=o(" (LayoutLMv2 model)"),o7o=l(),bp=a("li"),Zie=a("strong"),r7o=o("layoutlmv3"),t7o=o(" \u2014 "),cq=a("a"),a7o=o("LayoutLMv3Processor"),n7o=o(" (LayoutLMv3 model)"),s7o=l(),vp=a("li"),ede=a("strong"),l7o=o("layoutxlm"),i7o=o(" \u2014 "),fq=a("a"),d7o=o("LayoutXLMProcessor"),c7o=o(" (LayoutXLM model)"),f7o=l(),Fp=a("li"),ode=a("strong"),m7o=o("sew"),g7o=o(" \u2014 "),mq=a("a"),h7o=o("Wav2Vec2Processor"),p7o=o(" (SEW model)"),_7o=l(),Tp=a("li"),rde=a("strong"),u7o=o("sew-d"),b7o=o(" \u2014 "),gq=a("a"),v7o=o("Wav2Vec2Processor"),F7o=o(" (SEW-D model)"),T7o=l(),Mp=a("li"),tde=a("strong"),M7o=o("speech_to_text"),E7o=o(" \u2014 "),hq=a("a"),C7o=o("Speech2TextProcessor"),w7o=o(" (Speech2Text model)"),A7o=l(),Ep=a("li"),ade=a("strong"),L7o=o("speech_to_text_2"),y7o=o(" \u2014 "),pq=a("a"),x7o=o("Speech2Text2Processor"),$7o=o(" (Speech2Text2 model)"),k7o=l(),Cp=a("li"),nde=a("strong"),S7o=o("trocr"),R7o=o(" \u2014 "),_q=a("a"),P7o=o("TrOCRProcessor"),B7o=o(" (TrOCR model)"),N7o=l(),wp=a("li"),sde=a("strong"),I7o=o("unispeech"),q7o=o(" \u2014 "),uq=a("a"),j7o=o("Wav2Vec2Processor"),D7o=o(" (UniSpeech model)"),G7o=l(),Ap=a("li"),lde=a("strong"),O7o=o("unispeech-sat"),V7o=o(" \u2014 "),bq=a("a"),X7o=o("Wav2Vec2Processor"),z7o=o(" (UniSpeechSat model)"),Q7o=l(),Lp=a("li"),ide=a("strong"),W7o=o("vilt"),H7o=o(" \u2014 "),vq=a("a"),U7o=o("ViltProcessor"),J7o=o(" (ViLT model)"),Y7o=l(),yp=a("li"),dde=a("strong"),K7o=o("vision-text-dual-encoder"),Z7o=o(" \u2014 "),Fq=a("a"),e4o=o("VisionTextDualEncoderProcessor"),o4o=o(" (VisionTextDualEncoder model)"),r4o=l(),xp=a("li"),cde=a("strong"),t4o=o("wav2vec2"),a4o=o(" \u2014 "),Tq=a("a"),n4o=o("Wav2Vec2Processor"),s4o=o(" (Wav2Vec2 model)"),l4o=l(),$p=a("li"),fde=a("strong"),i4o=o("wav2vec2-conformer"),d4o=o(" \u2014 "),Mq=a("a"),c4o=o("Wav2Vec2Processor"),f4o=o(" (Wav2Vec2-Conformer model)"),m4o=l(),kp=a("li"),mde=a("strong"),g4o=o("wavlm"),h4o=o(" \u2014 "),Eq=a("a"),p4o=o("Wav2Vec2Processor"),_4o=o(" (WavLM model)"),u4o=l(),F(Sp.$$.fragment),b4o=l(),F(Rp.$$.fragment),v4o=l(),Pp=a("div"),F(gy.$$.fragment),F4o=l(),gde=a("p"),T4o=o("Register a new processor for this class."),KOe=l(),qi=a("h2"),Bp=a("a"),hde=a("span"),F(hy.$$.fragment),M4o=l(),pde=a("span"),E4o=o("AutoModel"),ZOe=l(),xo=a("div"),F(py.$$.fragment),C4o=l(),ji=a("p"),w4o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Cq=a("a"),A4o=o("from_pretrained()"),L4o=o(" class method or the "),wq=a("a"),y4o=o("from_config()"),x4o=o(` class
method.`),$4o=l(),_y=a("p"),k4o=o("This class cannot be instantiated directly using "),_de=a("code"),S4o=o("__init__()"),R4o=o(" (throws an error)."),P4o=l(),st=a("div"),F(uy.$$.fragment),B4o=l(),ude=a("p"),N4o=o("Instantiates one of the base model classes of the library from a configuration."),I4o=l(),Di=a("p"),q4o=o(`Note:
Loading a model from its configuration file does `),bde=a("strong"),j4o=o("not"),D4o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aq=a("a"),G4o=o("from_pretrained()"),O4o=o(" to load the model weights."),V4o=l(),F(Np.$$.fragment),X4o=l(),Je=a("div"),F(by.$$.fragment),z4o=l(),vde=a("p"),Q4o=o("Instantiate one of the base model classes of the library from a pretrained model."),W4o=l(),Ba=a("p"),H4o=o("The model class to instantiate is selected based on the "),Fde=a("code"),U4o=o("model_type"),J4o=o(` property of the config object (either
passed as an argument or loaded from `),Tde=a("code"),Y4o=o("pretrained_model_name_or_path"),K4o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mde=a("code"),Z4o=o("pretrained_model_name_or_path"),ebo=o(":"),obo=l(),y=a("ul"),Ip=a("li"),Ede=a("strong"),rbo=o("albert"),tbo=o(" \u2014 "),Lq=a("a"),abo=o("AlbertModel"),nbo=o(" (ALBERT model)"),sbo=l(),qp=a("li"),Cde=a("strong"),lbo=o("bart"),ibo=o(" \u2014 "),yq=a("a"),dbo=o("BartModel"),cbo=o(" (BART model)"),fbo=l(),jp=a("li"),wde=a("strong"),mbo=o("beit"),gbo=o(" \u2014 "),xq=a("a"),hbo=o("BeitModel"),pbo=o(" (BEiT model)"),_bo=l(),Dp=a("li"),Ade=a("strong"),ubo=o("bert"),bbo=o(" \u2014 "),$q=a("a"),vbo=o("BertModel"),Fbo=o(" (BERT model)"),Tbo=l(),Gp=a("li"),Lde=a("strong"),Mbo=o("bert-generation"),Ebo=o(" \u2014 "),kq=a("a"),Cbo=o("BertGenerationEncoder"),wbo=o(" (Bert Generation model)"),Abo=l(),Op=a("li"),yde=a("strong"),Lbo=o("big_bird"),ybo=o(" \u2014 "),Sq=a("a"),xbo=o("BigBirdModel"),$bo=o(" (BigBird model)"),kbo=l(),Vp=a("li"),xde=a("strong"),Sbo=o("bigbird_pegasus"),Rbo=o(" \u2014 "),Rq=a("a"),Pbo=o("BigBirdPegasusModel"),Bbo=o(" (BigBird-Pegasus model)"),Nbo=l(),Xp=a("li"),$de=a("strong"),Ibo=o("blenderbot"),qbo=o(" \u2014 "),Pq=a("a"),jbo=o("BlenderbotModel"),Dbo=o(" (Blenderbot model)"),Gbo=l(),zp=a("li"),kde=a("strong"),Obo=o("blenderbot-small"),Vbo=o(" \u2014 "),Bq=a("a"),Xbo=o("BlenderbotSmallModel"),zbo=o(" (BlenderbotSmall model)"),Qbo=l(),Qp=a("li"),Sde=a("strong"),Wbo=o("bloom"),Hbo=o(" \u2014 "),Nq=a("a"),Ubo=o("BloomModel"),Jbo=o(" (BLOOM model)"),Ybo=l(),Wp=a("li"),Rde=a("strong"),Kbo=o("camembert"),Zbo=o(" \u2014 "),Iq=a("a"),evo=o("CamembertModel"),ovo=o(" (CamemBERT model)"),rvo=l(),Hp=a("li"),Pde=a("strong"),tvo=o("canine"),avo=o(" \u2014 "),qq=a("a"),nvo=o("CanineModel"),svo=o(" (CANINE model)"),lvo=l(),Up=a("li"),Bde=a("strong"),ivo=o("clip"),dvo=o(" \u2014 "),jq=a("a"),cvo=o("CLIPModel"),fvo=o(" (CLIP model)"),mvo=l(),Jp=a("li"),Nde=a("strong"),gvo=o("codegen"),hvo=o(" \u2014 "),Dq=a("a"),pvo=o("CodeGenModel"),_vo=o(" (CodeGen model)"),uvo=l(),Yp=a("li"),Ide=a("strong"),bvo=o("convbert"),vvo=o(" \u2014 "),Gq=a("a"),Fvo=o("ConvBertModel"),Tvo=o(" (ConvBERT model)"),Mvo=l(),Kp=a("li"),qde=a("strong"),Evo=o("convnext"),Cvo=o(" \u2014 "),Oq=a("a"),wvo=o("ConvNextModel"),Avo=o(" (ConvNeXT model)"),Lvo=l(),Zp=a("li"),jde=a("strong"),yvo=o("ctrl"),xvo=o(" \u2014 "),Vq=a("a"),$vo=o("CTRLModel"),kvo=o(" (CTRL model)"),Svo=l(),e_=a("li"),Dde=a("strong"),Rvo=o("cvt"),Pvo=o(" \u2014 "),Xq=a("a"),Bvo=o("CvtModel"),Nvo=o(" (CvT model)"),Ivo=l(),o_=a("li"),Gde=a("strong"),qvo=o("data2vec-audio"),jvo=o(" \u2014 "),zq=a("a"),Dvo=o("Data2VecAudioModel"),Gvo=o(" (Data2VecAudio model)"),Ovo=l(),r_=a("li"),Ode=a("strong"),Vvo=o("data2vec-text"),Xvo=o(" \u2014 "),Qq=a("a"),zvo=o("Data2VecTextModel"),Qvo=o(" (Data2VecText model)"),Wvo=l(),t_=a("li"),Vde=a("strong"),Hvo=o("data2vec-vision"),Uvo=o(" \u2014 "),Wq=a("a"),Jvo=o("Data2VecVisionModel"),Yvo=o(" (Data2VecVision model)"),Kvo=l(),a_=a("li"),Xde=a("strong"),Zvo=o("deberta"),eFo=o(" \u2014 "),Hq=a("a"),oFo=o("DebertaModel"),rFo=o(" (DeBERTa model)"),tFo=l(),n_=a("li"),zde=a("strong"),aFo=o("deberta-v2"),nFo=o(" \u2014 "),Uq=a("a"),sFo=o("DebertaV2Model"),lFo=o(" (DeBERTa-v2 model)"),iFo=l(),s_=a("li"),Qde=a("strong"),dFo=o("decision_transformer"),cFo=o(" \u2014 "),Jq=a("a"),fFo=o("DecisionTransformerModel"),mFo=o(" (Decision Transformer model)"),gFo=l(),l_=a("li"),Wde=a("strong"),hFo=o("deit"),pFo=o(" \u2014 "),Yq=a("a"),_Fo=o("DeiTModel"),uFo=o(" (DeiT model)"),bFo=l(),i_=a("li"),Hde=a("strong"),vFo=o("detr"),FFo=o(" \u2014 "),Kq=a("a"),TFo=o("DetrModel"),MFo=o(" (DETR model)"),EFo=l(),d_=a("li"),Ude=a("strong"),CFo=o("distilbert"),wFo=o(" \u2014 "),Zq=a("a"),AFo=o("DistilBertModel"),LFo=o(" (DistilBERT model)"),yFo=l(),c_=a("li"),Jde=a("strong"),xFo=o("dpr"),$Fo=o(" \u2014 "),ej=a("a"),kFo=o("DPRQuestionEncoder"),SFo=o(" (DPR model)"),RFo=l(),f_=a("li"),Yde=a("strong"),PFo=o("dpt"),BFo=o(" \u2014 "),oj=a("a"),NFo=o("DPTModel"),IFo=o(" (DPT model)"),qFo=l(),m_=a("li"),Kde=a("strong"),jFo=o("electra"),DFo=o(" \u2014 "),rj=a("a"),GFo=o("ElectraModel"),OFo=o(" (ELECTRA model)"),VFo=l(),g_=a("li"),Zde=a("strong"),XFo=o("flaubert"),zFo=o(" \u2014 "),tj=a("a"),QFo=o("FlaubertModel"),WFo=o(" (FlauBERT model)"),HFo=l(),h_=a("li"),ece=a("strong"),UFo=o("flava"),JFo=o(" \u2014 "),aj=a("a"),YFo=o("FlavaModel"),KFo=o(" (FLAVA model)"),ZFo=l(),p_=a("li"),oce=a("strong"),eTo=o("fnet"),oTo=o(" \u2014 "),nj=a("a"),rTo=o("FNetModel"),tTo=o(" (FNet model)"),aTo=l(),__=a("li"),rce=a("strong"),nTo=o("fsmt"),sTo=o(" \u2014 "),sj=a("a"),lTo=o("FSMTModel"),iTo=o(" (FairSeq Machine-Translation model)"),dTo=l(),Qs=a("li"),tce=a("strong"),cTo=o("funnel"),fTo=o(" \u2014 "),lj=a("a"),mTo=o("FunnelModel"),gTo=o(" or "),ij=a("a"),hTo=o("FunnelBaseModel"),pTo=o(" (Funnel Transformer model)"),_To=l(),u_=a("li"),ace=a("strong"),uTo=o("glpn"),bTo=o(" \u2014 "),dj=a("a"),vTo=o("GLPNModel"),FTo=o(" (GLPN model)"),TTo=l(),b_=a("li"),nce=a("strong"),MTo=o("gpt2"),ETo=o(" \u2014 "),cj=a("a"),CTo=o("GPT2Model"),wTo=o(" (OpenAI GPT-2 model)"),ATo=l(),v_=a("li"),sce=a("strong"),LTo=o("gpt_neo"),yTo=o(" \u2014 "),fj=a("a"),xTo=o("GPTNeoModel"),$To=o(" (GPT Neo model)"),kTo=l(),F_=a("li"),lce=a("strong"),STo=o("gpt_neox"),RTo=o(" \u2014 "),mj=a("a"),PTo=o("GPTNeoXModel"),BTo=o(" (GPT NeoX model)"),NTo=l(),T_=a("li"),ice=a("strong"),ITo=o("gptj"),qTo=o(" \u2014 "),gj=a("a"),jTo=o("GPTJModel"),DTo=o(" (GPT-J model)"),GTo=l(),M_=a("li"),dce=a("strong"),OTo=o("groupvit"),VTo=o(" \u2014 "),hj=a("a"),XTo=o("GroupViTModel"),zTo=o(" (GroupViT model)"),QTo=l(),E_=a("li"),cce=a("strong"),WTo=o("hubert"),HTo=o(" \u2014 "),pj=a("a"),UTo=o("HubertModel"),JTo=o(" (Hubert model)"),YTo=l(),C_=a("li"),fce=a("strong"),KTo=o("ibert"),ZTo=o(" \u2014 "),_j=a("a"),eMo=o("IBertModel"),oMo=o(" (I-BERT model)"),rMo=l(),w_=a("li"),mce=a("strong"),tMo=o("imagegpt"),aMo=o(" \u2014 "),uj=a("a"),nMo=o("ImageGPTModel"),sMo=o(" (ImageGPT model)"),lMo=l(),A_=a("li"),gce=a("strong"),iMo=o("layoutlm"),dMo=o(" \u2014 "),bj=a("a"),cMo=o("LayoutLMModel"),fMo=o(" (LayoutLM model)"),mMo=l(),L_=a("li"),hce=a("strong"),gMo=o("layoutlmv2"),hMo=o(" \u2014 "),vj=a("a"),pMo=o("LayoutLMv2Model"),_Mo=o(" (LayoutLMv2 model)"),uMo=l(),y_=a("li"),pce=a("strong"),bMo=o("layoutlmv3"),vMo=o(" \u2014 "),Fj=a("a"),FMo=o("LayoutLMv3Model"),TMo=o(" (LayoutLMv3 model)"),MMo=l(),x_=a("li"),_ce=a("strong"),EMo=o("led"),CMo=o(" \u2014 "),Tj=a("a"),wMo=o("LEDModel"),AMo=o(" (LED model)"),LMo=l(),$_=a("li"),uce=a("strong"),yMo=o("levit"),xMo=o(" \u2014 "),Mj=a("a"),$Mo=o("LevitModel"),kMo=o(" (LeViT model)"),SMo=l(),k_=a("li"),bce=a("strong"),RMo=o("longformer"),PMo=o(" \u2014 "),Ej=a("a"),BMo=o("LongformerModel"),NMo=o(" (Longformer model)"),IMo=l(),S_=a("li"),vce=a("strong"),qMo=o("longt5"),jMo=o(" \u2014 "),Cj=a("a"),DMo=o("LongT5Model"),GMo=o(" (LongT5 model)"),OMo=l(),R_=a("li"),Fce=a("strong"),VMo=o("luke"),XMo=o(" \u2014 "),wj=a("a"),zMo=o("LukeModel"),QMo=o(" (LUKE model)"),WMo=l(),P_=a("li"),Tce=a("strong"),HMo=o("lxmert"),UMo=o(" \u2014 "),Aj=a("a"),JMo=o("LxmertModel"),YMo=o(" (LXMERT model)"),KMo=l(),B_=a("li"),Mce=a("strong"),ZMo=o("m2m_100"),eEo=o(" \u2014 "),Lj=a("a"),oEo=o("M2M100Model"),rEo=o(" (M2M100 model)"),tEo=l(),N_=a("li"),Ece=a("strong"),aEo=o("marian"),nEo=o(" \u2014 "),yj=a("a"),sEo=o("MarianModel"),lEo=o(" (Marian model)"),iEo=l(),I_=a("li"),Cce=a("strong"),dEo=o("maskformer"),cEo=o(" \u2014 "),xj=a("a"),fEo=o("MaskFormerModel"),mEo=o(" (MaskFormer model)"),gEo=l(),q_=a("li"),wce=a("strong"),hEo=o("mbart"),pEo=o(" \u2014 "),$j=a("a"),_Eo=o("MBartModel"),uEo=o(" (mBART model)"),bEo=l(),j_=a("li"),Ace=a("strong"),vEo=o("mctct"),FEo=o(" \u2014 "),kj=a("a"),TEo=o("MCTCTModel"),MEo=o(" (M-CTC-T model)"),EEo=l(),D_=a("li"),Lce=a("strong"),CEo=o("megatron-bert"),wEo=o(" \u2014 "),Sj=a("a"),AEo=o("MegatronBertModel"),LEo=o(" (Megatron-BERT model)"),yEo=l(),G_=a("li"),yce=a("strong"),xEo=o("mobilebert"),$Eo=o(" \u2014 "),Rj=a("a"),kEo=o("MobileBertModel"),SEo=o(" (MobileBERT model)"),REo=l(),O_=a("li"),xce=a("strong"),PEo=o("mpnet"),BEo=o(" \u2014 "),Pj=a("a"),NEo=o("MPNetModel"),IEo=o(" (MPNet model)"),qEo=l(),V_=a("li"),$ce=a("strong"),jEo=o("mt5"),DEo=o(" \u2014 "),Bj=a("a"),GEo=o("MT5Model"),OEo=o(" (MT5 model)"),VEo=l(),X_=a("li"),kce=a("strong"),XEo=o("nezha"),zEo=o(" \u2014 "),Nj=a("a"),QEo=o("NezhaModel"),WEo=o(" (Nezha model)"),HEo=l(),z_=a("li"),Sce=a("strong"),UEo=o("nystromformer"),JEo=o(" \u2014 "),Ij=a("a"),YEo=o("NystromformerModel"),KEo=o(" (Nystr\xF6mformer model)"),ZEo=l(),Q_=a("li"),Rce=a("strong"),eCo=o("openai-gpt"),oCo=o(" \u2014 "),qj=a("a"),rCo=o("OpenAIGPTModel"),tCo=o(" (OpenAI GPT model)"),aCo=l(),W_=a("li"),Pce=a("strong"),nCo=o("opt"),sCo=o(" \u2014 "),jj=a("a"),lCo=o("OPTModel"),iCo=o(" (OPT model)"),dCo=l(),H_=a("li"),Bce=a("strong"),cCo=o("pegasus"),fCo=o(" \u2014 "),Dj=a("a"),mCo=o("PegasusModel"),gCo=o(" (Pegasus model)"),hCo=l(),U_=a("li"),Nce=a("strong"),pCo=o("perceiver"),_Co=o(" \u2014 "),Gj=a("a"),uCo=o("PerceiverModel"),bCo=o(" (Perceiver model)"),vCo=l(),J_=a("li"),Ice=a("strong"),FCo=o("plbart"),TCo=o(" \u2014 "),Oj=a("a"),MCo=o("PLBartModel"),ECo=o(" (PLBart model)"),CCo=l(),Y_=a("li"),qce=a("strong"),wCo=o("poolformer"),ACo=o(" \u2014 "),Vj=a("a"),LCo=o("PoolFormerModel"),yCo=o(" (PoolFormer model)"),xCo=l(),K_=a("li"),jce=a("strong"),$Co=o("prophetnet"),kCo=o(" \u2014 "),Xj=a("a"),SCo=o("ProphetNetModel"),RCo=o(" (ProphetNet model)"),PCo=l(),Z_=a("li"),Dce=a("strong"),BCo=o("qdqbert"),NCo=o(" \u2014 "),zj=a("a"),ICo=o("QDQBertModel"),qCo=o(" (QDQBert model)"),jCo=l(),eu=a("li"),Gce=a("strong"),DCo=o("reformer"),GCo=o(" \u2014 "),Qj=a("a"),OCo=o("ReformerModel"),VCo=o(" (Reformer model)"),XCo=l(),ou=a("li"),Oce=a("strong"),zCo=o("regnet"),QCo=o(" \u2014 "),Wj=a("a"),WCo=o("RegNetModel"),HCo=o(" (RegNet model)"),UCo=l(),ru=a("li"),Vce=a("strong"),JCo=o("rembert"),YCo=o(" \u2014 "),Hj=a("a"),KCo=o("RemBertModel"),ZCo=o(" (RemBERT model)"),e3o=l(),tu=a("li"),Xce=a("strong"),o3o=o("resnet"),r3o=o(" \u2014 "),Uj=a("a"),t3o=o("ResNetModel"),a3o=o(" (ResNet model)"),n3o=l(),au=a("li"),zce=a("strong"),s3o=o("retribert"),l3o=o(" \u2014 "),Jj=a("a"),i3o=o("RetriBertModel"),d3o=o(" (RetriBERT model)"),c3o=l(),nu=a("li"),Qce=a("strong"),f3o=o("roberta"),m3o=o(" \u2014 "),Yj=a("a"),g3o=o("RobertaModel"),h3o=o(" (RoBERTa model)"),p3o=l(),su=a("li"),Wce=a("strong"),_3o=o("roformer"),u3o=o(" \u2014 "),Kj=a("a"),b3o=o("RoFormerModel"),v3o=o(" (RoFormer model)"),F3o=l(),lu=a("li"),Hce=a("strong"),T3o=o("segformer"),M3o=o(" \u2014 "),Zj=a("a"),E3o=o("SegformerModel"),C3o=o(" (SegFormer model)"),w3o=l(),iu=a("li"),Uce=a("strong"),A3o=o("sew"),L3o=o(" \u2014 "),eD=a("a"),y3o=o("SEWModel"),x3o=o(" (SEW model)"),$3o=l(),du=a("li"),Jce=a("strong"),k3o=o("sew-d"),S3o=o(" \u2014 "),oD=a("a"),R3o=o("SEWDModel"),P3o=o(" (SEW-D model)"),B3o=l(),cu=a("li"),Yce=a("strong"),N3o=o("speech_to_text"),I3o=o(" \u2014 "),rD=a("a"),q3o=o("Speech2TextModel"),j3o=o(" (Speech2Text model)"),D3o=l(),fu=a("li"),Kce=a("strong"),G3o=o("splinter"),O3o=o(" \u2014 "),tD=a("a"),V3o=o("SplinterModel"),X3o=o(" (Splinter model)"),z3o=l(),mu=a("li"),Zce=a("strong"),Q3o=o("squeezebert"),W3o=o(" \u2014 "),aD=a("a"),H3o=o("SqueezeBertModel"),U3o=o(" (SqueezeBERT model)"),J3o=l(),gu=a("li"),efe=a("strong"),Y3o=o("swin"),K3o=o(" \u2014 "),nD=a("a"),Z3o=o("SwinModel"),e5o=o(" (Swin Transformer model)"),o5o=l(),hu=a("li"),ofe=a("strong"),r5o=o("t5"),t5o=o(" \u2014 "),sD=a("a"),a5o=o("T5Model"),n5o=o(" (T5 model)"),s5o=l(),pu=a("li"),rfe=a("strong"),l5o=o("tapas"),i5o=o(" \u2014 "),lD=a("a"),d5o=o("TapasModel"),c5o=o(" (TAPAS model)"),f5o=l(),_u=a("li"),tfe=a("strong"),m5o=o("trajectory_transformer"),g5o=o(" \u2014 "),iD=a("a"),h5o=o("TrajectoryTransformerModel"),p5o=o(" (Trajectory Transformer model)"),_5o=l(),uu=a("li"),afe=a("strong"),u5o=o("transfo-xl"),b5o=o(" \u2014 "),dD=a("a"),v5o=o("TransfoXLModel"),F5o=o(" (Transformer-XL model)"),T5o=l(),bu=a("li"),nfe=a("strong"),M5o=o("unispeech"),E5o=o(" \u2014 "),cD=a("a"),C5o=o("UniSpeechModel"),w5o=o(" (UniSpeech model)"),A5o=l(),vu=a("li"),sfe=a("strong"),L5o=o("unispeech-sat"),y5o=o(" \u2014 "),fD=a("a"),x5o=o("UniSpeechSatModel"),$5o=o(" (UniSpeechSat model)"),k5o=l(),Fu=a("li"),lfe=a("strong"),S5o=o("van"),R5o=o(" \u2014 "),mD=a("a"),P5o=o("VanModel"),B5o=o(" (VAN model)"),N5o=l(),Tu=a("li"),ife=a("strong"),I5o=o("vilt"),q5o=o(" \u2014 "),gD=a("a"),j5o=o("ViltModel"),D5o=o(" (ViLT model)"),G5o=l(),Mu=a("li"),dfe=a("strong"),O5o=o("vision-text-dual-encoder"),V5o=o(" \u2014 "),hD=a("a"),X5o=o("VisionTextDualEncoderModel"),z5o=o(" (VisionTextDualEncoder model)"),Q5o=l(),Eu=a("li"),cfe=a("strong"),W5o=o("visual_bert"),H5o=o(" \u2014 "),pD=a("a"),U5o=o("VisualBertModel"),J5o=o(" (VisualBERT model)"),Y5o=l(),Cu=a("li"),ffe=a("strong"),K5o=o("vit"),Z5o=o(" \u2014 "),_D=a("a"),e0o=o("ViTModel"),o0o=o(" (ViT model)"),r0o=l(),wu=a("li"),mfe=a("strong"),t0o=o("vit_mae"),a0o=o(" \u2014 "),uD=a("a"),n0o=o("ViTMAEModel"),s0o=o(" (ViTMAE model)"),l0o=l(),Au=a("li"),gfe=a("strong"),i0o=o("wav2vec2"),d0o=o(" \u2014 "),bD=a("a"),c0o=o("Wav2Vec2Model"),f0o=o(" (Wav2Vec2 model)"),m0o=l(),Lu=a("li"),hfe=a("strong"),g0o=o("wav2vec2-conformer"),h0o=o(" \u2014 "),vD=a("a"),p0o=o("Wav2Vec2ConformerModel"),_0o=o(" (Wav2Vec2-Conformer model)"),u0o=l(),yu=a("li"),pfe=a("strong"),b0o=o("wavlm"),v0o=o(" \u2014 "),FD=a("a"),F0o=o("WavLMModel"),T0o=o(" (WavLM model)"),M0o=l(),xu=a("li"),_fe=a("strong"),E0o=o("xglm"),C0o=o(" \u2014 "),TD=a("a"),w0o=o("XGLMModel"),A0o=o(" (XGLM model)"),L0o=l(),$u=a("li"),ufe=a("strong"),y0o=o("xlm"),x0o=o(" \u2014 "),MD=a("a"),$0o=o("XLMModel"),k0o=o(" (XLM model)"),S0o=l(),ku=a("li"),bfe=a("strong"),R0o=o("xlm-prophetnet"),P0o=o(" \u2014 "),ED=a("a"),B0o=o("XLMProphetNetModel"),N0o=o(" (XLM-ProphetNet model)"),I0o=l(),Su=a("li"),vfe=a("strong"),q0o=o("xlm-roberta"),j0o=o(" \u2014 "),CD=a("a"),D0o=o("XLMRobertaModel"),G0o=o(" (XLM-RoBERTa model)"),O0o=l(),Ru=a("li"),Ffe=a("strong"),V0o=o("xlm-roberta-xl"),X0o=o(" \u2014 "),wD=a("a"),z0o=o("XLMRobertaXLModel"),Q0o=o(" (XLM-RoBERTa-XL model)"),W0o=l(),Pu=a("li"),Tfe=a("strong"),H0o=o("xlnet"),U0o=o(" \u2014 "),AD=a("a"),J0o=o("XLNetModel"),Y0o=o(" (XLNet model)"),K0o=l(),Bu=a("li"),Mfe=a("strong"),Z0o=o("yolos"),ewo=o(" \u2014 "),LD=a("a"),owo=o("YolosModel"),rwo=o(" (YOLOS model)"),two=l(),Nu=a("li"),Efe=a("strong"),awo=o("yoso"),nwo=o(" \u2014 "),yD=a("a"),swo=o("YosoModel"),lwo=o(" (YOSO model)"),iwo=l(),Iu=a("p"),dwo=o("The model is set in evaluation mode by default using "),Cfe=a("code"),cwo=o("model.eval()"),fwo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wfe=a("code"),mwo=o("model.train()"),gwo=l(),F(qu.$$.fragment),eVe=l(),Gi=a("h2"),ju=a("a"),Afe=a("span"),F(vy.$$.fragment),hwo=l(),Lfe=a("span"),pwo=o("AutoModelForPreTraining"),oVe=l(),$o=a("div"),F(Fy.$$.fragment),_wo=l(),Oi=a("p"),uwo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),xD=a("a"),bwo=o("from_pretrained()"),vwo=o(" class method or the "),$D=a("a"),Fwo=o("from_config()"),Two=o(` class
method.`),Mwo=l(),Ty=a("p"),Ewo=o("This class cannot be instantiated directly using "),yfe=a("code"),Cwo=o("__init__()"),wwo=o(" (throws an error)."),Awo=l(),lt=a("div"),F(My.$$.fragment),Lwo=l(),xfe=a("p"),ywo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),xwo=l(),Vi=a("p"),$wo=o(`Note:
Loading a model from its configuration file does `),$fe=a("strong"),kwo=o("not"),Swo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kD=a("a"),Rwo=o("from_pretrained()"),Pwo=o(" to load the model weights."),Bwo=l(),F(Du.$$.fragment),Nwo=l(),Ye=a("div"),F(Ey.$$.fragment),Iwo=l(),kfe=a("p"),qwo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),jwo=l(),Na=a("p"),Dwo=o("The model class to instantiate is selected based on the "),Sfe=a("code"),Gwo=o("model_type"),Owo=o(` property of the config object (either
passed as an argument or loaded from `),Rfe=a("code"),Vwo=o("pretrained_model_name_or_path"),Xwo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pfe=a("code"),zwo=o("pretrained_model_name_or_path"),Qwo=o(":"),Wwo=l(),G=a("ul"),Gu=a("li"),Bfe=a("strong"),Hwo=o("albert"),Uwo=o(" \u2014 "),SD=a("a"),Jwo=o("AlbertForPreTraining"),Ywo=o(" (ALBERT model)"),Kwo=l(),Ou=a("li"),Nfe=a("strong"),Zwo=o("bart"),eAo=o(" \u2014 "),RD=a("a"),oAo=o("BartForConditionalGeneration"),rAo=o(" (BART model)"),tAo=l(),Vu=a("li"),Ife=a("strong"),aAo=o("bert"),nAo=o(" \u2014 "),PD=a("a"),sAo=o("BertForPreTraining"),lAo=o(" (BERT model)"),iAo=l(),Xu=a("li"),qfe=a("strong"),dAo=o("big_bird"),cAo=o(" \u2014 "),BD=a("a"),fAo=o("BigBirdForPreTraining"),mAo=o(" (BigBird model)"),gAo=l(),zu=a("li"),jfe=a("strong"),hAo=o("bloom"),pAo=o(" \u2014 "),ND=a("a"),_Ao=o("BloomForCausalLM"),uAo=o(" (BLOOM model)"),bAo=l(),Qu=a("li"),Dfe=a("strong"),vAo=o("camembert"),FAo=o(" \u2014 "),ID=a("a"),TAo=o("CamembertForMaskedLM"),MAo=o(" (CamemBERT model)"),EAo=l(),Wu=a("li"),Gfe=a("strong"),CAo=o("ctrl"),wAo=o(" \u2014 "),qD=a("a"),AAo=o("CTRLLMHeadModel"),LAo=o(" (CTRL model)"),yAo=l(),Hu=a("li"),Ofe=a("strong"),xAo=o("data2vec-text"),$Ao=o(" \u2014 "),jD=a("a"),kAo=o("Data2VecTextForMaskedLM"),SAo=o(" (Data2VecText model)"),RAo=l(),Uu=a("li"),Vfe=a("strong"),PAo=o("deberta"),BAo=o(" \u2014 "),DD=a("a"),NAo=o("DebertaForMaskedLM"),IAo=o(" (DeBERTa model)"),qAo=l(),Ju=a("li"),Xfe=a("strong"),jAo=o("deberta-v2"),DAo=o(" \u2014 "),GD=a("a"),GAo=o("DebertaV2ForMaskedLM"),OAo=o(" (DeBERTa-v2 model)"),VAo=l(),Yu=a("li"),zfe=a("strong"),XAo=o("distilbert"),zAo=o(" \u2014 "),OD=a("a"),QAo=o("DistilBertForMaskedLM"),WAo=o(" (DistilBERT model)"),HAo=l(),Ku=a("li"),Qfe=a("strong"),UAo=o("electra"),JAo=o(" \u2014 "),VD=a("a"),YAo=o("ElectraForPreTraining"),KAo=o(" (ELECTRA model)"),ZAo=l(),Zu=a("li"),Wfe=a("strong"),e6o=o("flaubert"),o6o=o(" \u2014 "),XD=a("a"),r6o=o("FlaubertWithLMHeadModel"),t6o=o(" (FlauBERT model)"),a6o=l(),e2=a("li"),Hfe=a("strong"),n6o=o("flava"),s6o=o(" \u2014 "),zD=a("a"),l6o=o("FlavaForPreTraining"),i6o=o(" (FLAVA model)"),d6o=l(),o2=a("li"),Ufe=a("strong"),c6o=o("fnet"),f6o=o(" \u2014 "),QD=a("a"),m6o=o("FNetForPreTraining"),g6o=o(" (FNet model)"),h6o=l(),r2=a("li"),Jfe=a("strong"),p6o=o("fsmt"),_6o=o(" \u2014 "),WD=a("a"),u6o=o("FSMTForConditionalGeneration"),b6o=o(" (FairSeq Machine-Translation model)"),v6o=l(),t2=a("li"),Yfe=a("strong"),F6o=o("funnel"),T6o=o(" \u2014 "),HD=a("a"),M6o=o("FunnelForPreTraining"),E6o=o(" (Funnel Transformer model)"),C6o=l(),a2=a("li"),Kfe=a("strong"),w6o=o("gpt2"),A6o=o(" \u2014 "),UD=a("a"),L6o=o("GPT2LMHeadModel"),y6o=o(" (OpenAI GPT-2 model)"),x6o=l(),n2=a("li"),Zfe=a("strong"),$6o=o("ibert"),k6o=o(" \u2014 "),JD=a("a"),S6o=o("IBertForMaskedLM"),R6o=o(" (I-BERT model)"),P6o=l(),s2=a("li"),eme=a("strong"),B6o=o("layoutlm"),N6o=o(" \u2014 "),YD=a("a"),I6o=o("LayoutLMForMaskedLM"),q6o=o(" (LayoutLM model)"),j6o=l(),l2=a("li"),ome=a("strong"),D6o=o("longformer"),G6o=o(" \u2014 "),KD=a("a"),O6o=o("LongformerForMaskedLM"),V6o=o(" (Longformer model)"),X6o=l(),i2=a("li"),rme=a("strong"),z6o=o("lxmert"),Q6o=o(" \u2014 "),ZD=a("a"),W6o=o("LxmertForPreTraining"),H6o=o(" (LXMERT model)"),U6o=l(),d2=a("li"),tme=a("strong"),J6o=o("megatron-bert"),Y6o=o(" \u2014 "),eG=a("a"),K6o=o("MegatronBertForPreTraining"),Z6o=o(" (Megatron-BERT model)"),eLo=l(),c2=a("li"),ame=a("strong"),oLo=o("mobilebert"),rLo=o(" \u2014 "),oG=a("a"),tLo=o("MobileBertForPreTraining"),aLo=o(" (MobileBERT model)"),nLo=l(),f2=a("li"),nme=a("strong"),sLo=o("mpnet"),lLo=o(" \u2014 "),rG=a("a"),iLo=o("MPNetForMaskedLM"),dLo=o(" (MPNet model)"),cLo=l(),m2=a("li"),sme=a("strong"),fLo=o("nezha"),mLo=o(" \u2014 "),tG=a("a"),gLo=o("NezhaForPreTraining"),hLo=o(" (Nezha model)"),pLo=l(),g2=a("li"),lme=a("strong"),_Lo=o("openai-gpt"),uLo=o(" \u2014 "),aG=a("a"),bLo=o("OpenAIGPTLMHeadModel"),vLo=o(" (OpenAI GPT model)"),FLo=l(),h2=a("li"),ime=a("strong"),TLo=o("retribert"),MLo=o(" \u2014 "),nG=a("a"),ELo=o("RetriBertModel"),CLo=o(" (RetriBERT model)"),wLo=l(),p2=a("li"),dme=a("strong"),ALo=o("roberta"),LLo=o(" \u2014 "),sG=a("a"),yLo=o("RobertaForMaskedLM"),xLo=o(" (RoBERTa model)"),$Lo=l(),_2=a("li"),cme=a("strong"),kLo=o("splinter"),SLo=o(" \u2014 "),lG=a("a"),RLo=o("SplinterForPreTraining"),PLo=o(" (Splinter model)"),BLo=l(),u2=a("li"),fme=a("strong"),NLo=o("squeezebert"),ILo=o(" \u2014 "),iG=a("a"),qLo=o("SqueezeBertForMaskedLM"),jLo=o(" (SqueezeBERT model)"),DLo=l(),b2=a("li"),mme=a("strong"),GLo=o("t5"),OLo=o(" \u2014 "),dG=a("a"),VLo=o("T5ForConditionalGeneration"),XLo=o(" (T5 model)"),zLo=l(),v2=a("li"),gme=a("strong"),QLo=o("tapas"),WLo=o(" \u2014 "),cG=a("a"),HLo=o("TapasForMaskedLM"),ULo=o(" (TAPAS model)"),JLo=l(),F2=a("li"),hme=a("strong"),YLo=o("transfo-xl"),KLo=o(" \u2014 "),fG=a("a"),ZLo=o("TransfoXLLMHeadModel"),eyo=o(" (Transformer-XL model)"),oyo=l(),T2=a("li"),pme=a("strong"),ryo=o("unispeech"),tyo=o(" \u2014 "),mG=a("a"),ayo=o("UniSpeechForPreTraining"),nyo=o(" (UniSpeech model)"),syo=l(),M2=a("li"),_me=a("strong"),lyo=o("unispeech-sat"),iyo=o(" \u2014 "),gG=a("a"),dyo=o("UniSpeechSatForPreTraining"),cyo=o(" (UniSpeechSat model)"),fyo=l(),E2=a("li"),ume=a("strong"),myo=o("visual_bert"),gyo=o(" \u2014 "),hG=a("a"),hyo=o("VisualBertForPreTraining"),pyo=o(" (VisualBERT model)"),_yo=l(),C2=a("li"),bme=a("strong"),uyo=o("vit_mae"),byo=o(" \u2014 "),pG=a("a"),vyo=o("ViTMAEForPreTraining"),Fyo=o(" (ViTMAE model)"),Tyo=l(),w2=a("li"),vme=a("strong"),Myo=o("wav2vec2"),Eyo=o(" \u2014 "),_G=a("a"),Cyo=o("Wav2Vec2ForPreTraining"),wyo=o(" (Wav2Vec2 model)"),Ayo=l(),A2=a("li"),Fme=a("strong"),Lyo=o("wav2vec2-conformer"),yyo=o(" \u2014 "),uG=a("a"),xyo=o("Wav2Vec2ConformerForPreTraining"),$yo=o(" (Wav2Vec2-Conformer model)"),kyo=l(),L2=a("li"),Tme=a("strong"),Syo=o("xlm"),Ryo=o(" \u2014 "),bG=a("a"),Pyo=o("XLMWithLMHeadModel"),Byo=o(" (XLM model)"),Nyo=l(),y2=a("li"),Mme=a("strong"),Iyo=o("xlm-roberta"),qyo=o(" \u2014 "),vG=a("a"),jyo=o("XLMRobertaForMaskedLM"),Dyo=o(" (XLM-RoBERTa model)"),Gyo=l(),x2=a("li"),Eme=a("strong"),Oyo=o("xlm-roberta-xl"),Vyo=o(" \u2014 "),FG=a("a"),Xyo=o("XLMRobertaXLForMaskedLM"),zyo=o(" (XLM-RoBERTa-XL model)"),Qyo=l(),$2=a("li"),Cme=a("strong"),Wyo=o("xlnet"),Hyo=o(" \u2014 "),TG=a("a"),Uyo=o("XLNetLMHeadModel"),Jyo=o(" (XLNet model)"),Yyo=l(),k2=a("p"),Kyo=o("The model is set in evaluation mode by default using "),wme=a("code"),Zyo=o("model.eval()"),e8o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ame=a("code"),o8o=o("model.train()"),r8o=l(),F(S2.$$.fragment),rVe=l(),Xi=a("h2"),R2=a("a"),Lme=a("span"),F(Cy.$$.fragment),t8o=l(),yme=a("span"),a8o=o("AutoModelForCausalLM"),tVe=l(),ko=a("div"),F(wy.$$.fragment),n8o=l(),zi=a("p"),s8o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),MG=a("a"),l8o=o("from_pretrained()"),i8o=o(" class method or the "),EG=a("a"),d8o=o("from_config()"),c8o=o(` class
method.`),f8o=l(),Ay=a("p"),m8o=o("This class cannot be instantiated directly using "),xme=a("code"),g8o=o("__init__()"),h8o=o(" (throws an error)."),p8o=l(),it=a("div"),F(Ly.$$.fragment),_8o=l(),$me=a("p"),u8o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),b8o=l(),Qi=a("p"),v8o=o(`Note:
Loading a model from its configuration file does `),kme=a("strong"),F8o=o("not"),T8o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CG=a("a"),M8o=o("from_pretrained()"),E8o=o(" to load the model weights."),C8o=l(),F(P2.$$.fragment),w8o=l(),Ke=a("div"),F(yy.$$.fragment),A8o=l(),Sme=a("p"),L8o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),y8o=l(),Ia=a("p"),x8o=o("The model class to instantiate is selected based on the "),Rme=a("code"),$8o=o("model_type"),k8o=o(` property of the config object (either
passed as an argument or loaded from `),Pme=a("code"),S8o=o("pretrained_model_name_or_path"),R8o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bme=a("code"),P8o=o("pretrained_model_name_or_path"),B8o=o(":"),N8o=l(),z=a("ul"),B2=a("li"),Nme=a("strong"),I8o=o("bart"),q8o=o(" \u2014 "),wG=a("a"),j8o=o("BartForCausalLM"),D8o=o(" (BART model)"),G8o=l(),N2=a("li"),Ime=a("strong"),O8o=o("bert"),V8o=o(" \u2014 "),AG=a("a"),X8o=o("BertLMHeadModel"),z8o=o(" (BERT model)"),Q8o=l(),I2=a("li"),qme=a("strong"),W8o=o("bert-generation"),H8o=o(" \u2014 "),LG=a("a"),U8o=o("BertGenerationDecoder"),J8o=o(" (Bert Generation model)"),Y8o=l(),q2=a("li"),jme=a("strong"),K8o=o("big_bird"),Z8o=o(" \u2014 "),yG=a("a"),e9o=o("BigBirdForCausalLM"),o9o=o(" (BigBird model)"),r9o=l(),j2=a("li"),Dme=a("strong"),t9o=o("bigbird_pegasus"),a9o=o(" \u2014 "),xG=a("a"),n9o=o("BigBirdPegasusForCausalLM"),s9o=o(" (BigBird-Pegasus model)"),l9o=l(),D2=a("li"),Gme=a("strong"),i9o=o("blenderbot"),d9o=o(" \u2014 "),$G=a("a"),c9o=o("BlenderbotForCausalLM"),f9o=o(" (Blenderbot model)"),m9o=l(),G2=a("li"),Ome=a("strong"),g9o=o("blenderbot-small"),h9o=o(" \u2014 "),kG=a("a"),p9o=o("BlenderbotSmallForCausalLM"),_9o=o(" (BlenderbotSmall model)"),u9o=l(),O2=a("li"),Vme=a("strong"),b9o=o("bloom"),v9o=o(" \u2014 "),SG=a("a"),F9o=o("BloomForCausalLM"),T9o=o(" (BLOOM model)"),M9o=l(),V2=a("li"),Xme=a("strong"),E9o=o("camembert"),C9o=o(" \u2014 "),RG=a("a"),w9o=o("CamembertForCausalLM"),A9o=o(" (CamemBERT model)"),L9o=l(),X2=a("li"),zme=a("strong"),y9o=o("codegen"),x9o=o(" \u2014 "),PG=a("a"),$9o=o("CodeGenForCausalLM"),k9o=o(" (CodeGen model)"),S9o=l(),z2=a("li"),Qme=a("strong"),R9o=o("ctrl"),P9o=o(" \u2014 "),BG=a("a"),B9o=o("CTRLLMHeadModel"),N9o=o(" (CTRL model)"),I9o=l(),Q2=a("li"),Wme=a("strong"),q9o=o("data2vec-text"),j9o=o(" \u2014 "),NG=a("a"),D9o=o("Data2VecTextForCausalLM"),G9o=o(" (Data2VecText model)"),O9o=l(),W2=a("li"),Hme=a("strong"),V9o=o("electra"),X9o=o(" \u2014 "),IG=a("a"),z9o=o("ElectraForCausalLM"),Q9o=o(" (ELECTRA model)"),W9o=l(),H2=a("li"),Ume=a("strong"),H9o=o("gpt2"),U9o=o(" \u2014 "),qG=a("a"),J9o=o("GPT2LMHeadModel"),Y9o=o(" (OpenAI GPT-2 model)"),K9o=l(),U2=a("li"),Jme=a("strong"),Z9o=o("gpt_neo"),exo=o(" \u2014 "),jG=a("a"),oxo=o("GPTNeoForCausalLM"),rxo=o(" (GPT Neo model)"),txo=l(),J2=a("li"),Yme=a("strong"),axo=o("gpt_neox"),nxo=o(" \u2014 "),DG=a("a"),sxo=o("GPTNeoXForCausalLM"),lxo=o(" (GPT NeoX model)"),ixo=l(),Y2=a("li"),Kme=a("strong"),dxo=o("gptj"),cxo=o(" \u2014 "),GG=a("a"),fxo=o("GPTJForCausalLM"),mxo=o(" (GPT-J model)"),gxo=l(),K2=a("li"),Zme=a("strong"),hxo=o("marian"),pxo=o(" \u2014 "),OG=a("a"),_xo=o("MarianForCausalLM"),uxo=o(" (Marian model)"),bxo=l(),Z2=a("li"),ege=a("strong"),vxo=o("mbart"),Fxo=o(" \u2014 "),VG=a("a"),Txo=o("MBartForCausalLM"),Mxo=o(" (mBART model)"),Exo=l(),e1=a("li"),oge=a("strong"),Cxo=o("megatron-bert"),wxo=o(" \u2014 "),XG=a("a"),Axo=o("MegatronBertForCausalLM"),Lxo=o(" (Megatron-BERT model)"),yxo=l(),o1=a("li"),rge=a("strong"),xxo=o("openai-gpt"),$xo=o(" \u2014 "),zG=a("a"),kxo=o("OpenAIGPTLMHeadModel"),Sxo=o(" (OpenAI GPT model)"),Rxo=l(),r1=a("li"),tge=a("strong"),Pxo=o("opt"),Bxo=o(" \u2014 "),QG=a("a"),Nxo=o("OPTForCausalLM"),Ixo=o(" (OPT model)"),qxo=l(),t1=a("li"),age=a("strong"),jxo=o("pegasus"),Dxo=o(" \u2014 "),WG=a("a"),Gxo=o("PegasusForCausalLM"),Oxo=o(" (Pegasus model)"),Vxo=l(),a1=a("li"),nge=a("strong"),Xxo=o("plbart"),zxo=o(" \u2014 "),HG=a("a"),Qxo=o("PLBartForCausalLM"),Wxo=o(" (PLBart model)"),Hxo=l(),n1=a("li"),sge=a("strong"),Uxo=o("prophetnet"),Jxo=o(" \u2014 "),UG=a("a"),Yxo=o("ProphetNetForCausalLM"),Kxo=o(" (ProphetNet model)"),Zxo=l(),s1=a("li"),lge=a("strong"),e$o=o("qdqbert"),o$o=o(" \u2014 "),JG=a("a"),r$o=o("QDQBertLMHeadModel"),t$o=o(" (QDQBert model)"),a$o=l(),l1=a("li"),ige=a("strong"),n$o=o("reformer"),s$o=o(" \u2014 "),YG=a("a"),l$o=o("ReformerModelWithLMHead"),i$o=o(" (Reformer model)"),d$o=l(),i1=a("li"),dge=a("strong"),c$o=o("rembert"),f$o=o(" \u2014 "),KG=a("a"),m$o=o("RemBertForCausalLM"),g$o=o(" (RemBERT model)"),h$o=l(),d1=a("li"),cge=a("strong"),p$o=o("roberta"),_$o=o(" \u2014 "),ZG=a("a"),u$o=o("RobertaForCausalLM"),b$o=o(" (RoBERTa model)"),v$o=l(),c1=a("li"),fge=a("strong"),F$o=o("roformer"),T$o=o(" \u2014 "),eO=a("a"),M$o=o("RoFormerForCausalLM"),E$o=o(" (RoFormer model)"),C$o=l(),f1=a("li"),mge=a("strong"),w$o=o("speech_to_text_2"),A$o=o(" \u2014 "),oO=a("a"),L$o=o("Speech2Text2ForCausalLM"),y$o=o(" (Speech2Text2 model)"),x$o=l(),m1=a("li"),gge=a("strong"),$$o=o("transfo-xl"),k$o=o(" \u2014 "),rO=a("a"),S$o=o("TransfoXLLMHeadModel"),R$o=o(" (Transformer-XL model)"),P$o=l(),g1=a("li"),hge=a("strong"),B$o=o("trocr"),N$o=o(" \u2014 "),tO=a("a"),I$o=o("TrOCRForCausalLM"),q$o=o(" (TrOCR model)"),j$o=l(),h1=a("li"),pge=a("strong"),D$o=o("xglm"),G$o=o(" \u2014 "),aO=a("a"),O$o=o("XGLMForCausalLM"),V$o=o(" (XGLM model)"),X$o=l(),p1=a("li"),_ge=a("strong"),z$o=o("xlm"),Q$o=o(" \u2014 "),nO=a("a"),W$o=o("XLMWithLMHeadModel"),H$o=o(" (XLM model)"),U$o=l(),_1=a("li"),uge=a("strong"),J$o=o("xlm-prophetnet"),Y$o=o(" \u2014 "),sO=a("a"),K$o=o("XLMProphetNetForCausalLM"),Z$o=o(" (XLM-ProphetNet model)"),eko=l(),u1=a("li"),bge=a("strong"),oko=o("xlm-roberta"),rko=o(" \u2014 "),lO=a("a"),tko=o("XLMRobertaForCausalLM"),ako=o(" (XLM-RoBERTa model)"),nko=l(),b1=a("li"),vge=a("strong"),sko=o("xlm-roberta-xl"),lko=o(" \u2014 "),iO=a("a"),iko=o("XLMRobertaXLForCausalLM"),dko=o(" (XLM-RoBERTa-XL model)"),cko=l(),v1=a("li"),Fge=a("strong"),fko=o("xlnet"),mko=o(" \u2014 "),dO=a("a"),gko=o("XLNetLMHeadModel"),hko=o(" (XLNet model)"),pko=l(),F1=a("p"),_ko=o("The model is set in evaluation mode by default using "),Tge=a("code"),uko=o("model.eval()"),bko=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mge=a("code"),vko=o("model.train()"),Fko=l(),F(T1.$$.fragment),aVe=l(),Wi=a("h2"),M1=a("a"),Ege=a("span"),F(xy.$$.fragment),Tko=l(),Cge=a("span"),Mko=o("AutoModelForMaskedLM"),nVe=l(),So=a("div"),F($y.$$.fragment),Eko=l(),Hi=a("p"),Cko=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),cO=a("a"),wko=o("from_pretrained()"),Ako=o(" class method or the "),fO=a("a"),Lko=o("from_config()"),yko=o(` class
method.`),xko=l(),ky=a("p"),$ko=o("This class cannot be instantiated directly using "),wge=a("code"),kko=o("__init__()"),Sko=o(" (throws an error)."),Rko=l(),dt=a("div"),F(Sy.$$.fragment),Pko=l(),Age=a("p"),Bko=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Nko=l(),Ui=a("p"),Iko=o(`Note:
Loading a model from its configuration file does `),Lge=a("strong"),qko=o("not"),jko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mO=a("a"),Dko=o("from_pretrained()"),Gko=o(" to load the model weights."),Oko=l(),F(E1.$$.fragment),Vko=l(),Ze=a("div"),F(Ry.$$.fragment),Xko=l(),yge=a("p"),zko=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Qko=l(),qa=a("p"),Wko=o("The model class to instantiate is selected based on the "),xge=a("code"),Hko=o("model_type"),Uko=o(` property of the config object (either
passed as an argument or loaded from `),$ge=a("code"),Jko=o("pretrained_model_name_or_path"),Yko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kge=a("code"),Kko=o("pretrained_model_name_or_path"),Zko=o(":"),eSo=l(),W=a("ul"),C1=a("li"),Sge=a("strong"),oSo=o("albert"),rSo=o(" \u2014 "),gO=a("a"),tSo=o("AlbertForMaskedLM"),aSo=o(" (ALBERT model)"),nSo=l(),w1=a("li"),Rge=a("strong"),sSo=o("bart"),lSo=o(" \u2014 "),hO=a("a"),iSo=o("BartForConditionalGeneration"),dSo=o(" (BART model)"),cSo=l(),A1=a("li"),Pge=a("strong"),fSo=o("bert"),mSo=o(" \u2014 "),pO=a("a"),gSo=o("BertForMaskedLM"),hSo=o(" (BERT model)"),pSo=l(),L1=a("li"),Bge=a("strong"),_So=o("big_bird"),uSo=o(" \u2014 "),_O=a("a"),bSo=o("BigBirdForMaskedLM"),vSo=o(" (BigBird model)"),FSo=l(),y1=a("li"),Nge=a("strong"),TSo=o("camembert"),MSo=o(" \u2014 "),uO=a("a"),ESo=o("CamembertForMaskedLM"),CSo=o(" (CamemBERT model)"),wSo=l(),x1=a("li"),Ige=a("strong"),ASo=o("convbert"),LSo=o(" \u2014 "),bO=a("a"),ySo=o("ConvBertForMaskedLM"),xSo=o(" (ConvBERT model)"),$So=l(),$1=a("li"),qge=a("strong"),kSo=o("data2vec-text"),SSo=o(" \u2014 "),vO=a("a"),RSo=o("Data2VecTextForMaskedLM"),PSo=o(" (Data2VecText model)"),BSo=l(),k1=a("li"),jge=a("strong"),NSo=o("deberta"),ISo=o(" \u2014 "),FO=a("a"),qSo=o("DebertaForMaskedLM"),jSo=o(" (DeBERTa model)"),DSo=l(),S1=a("li"),Dge=a("strong"),GSo=o("deberta-v2"),OSo=o(" \u2014 "),TO=a("a"),VSo=o("DebertaV2ForMaskedLM"),XSo=o(" (DeBERTa-v2 model)"),zSo=l(),R1=a("li"),Gge=a("strong"),QSo=o("distilbert"),WSo=o(" \u2014 "),MO=a("a"),HSo=o("DistilBertForMaskedLM"),USo=o(" (DistilBERT model)"),JSo=l(),P1=a("li"),Oge=a("strong"),YSo=o("electra"),KSo=o(" \u2014 "),EO=a("a"),ZSo=o("ElectraForMaskedLM"),eRo=o(" (ELECTRA model)"),oRo=l(),B1=a("li"),Vge=a("strong"),rRo=o("flaubert"),tRo=o(" \u2014 "),CO=a("a"),aRo=o("FlaubertWithLMHeadModel"),nRo=o(" (FlauBERT model)"),sRo=l(),N1=a("li"),Xge=a("strong"),lRo=o("fnet"),iRo=o(" \u2014 "),wO=a("a"),dRo=o("FNetForMaskedLM"),cRo=o(" (FNet model)"),fRo=l(),I1=a("li"),zge=a("strong"),mRo=o("funnel"),gRo=o(" \u2014 "),AO=a("a"),hRo=o("FunnelForMaskedLM"),pRo=o(" (Funnel Transformer model)"),_Ro=l(),q1=a("li"),Qge=a("strong"),uRo=o("ibert"),bRo=o(" \u2014 "),LO=a("a"),vRo=o("IBertForMaskedLM"),FRo=o(" (I-BERT model)"),TRo=l(),j1=a("li"),Wge=a("strong"),MRo=o("layoutlm"),ERo=o(" \u2014 "),yO=a("a"),CRo=o("LayoutLMForMaskedLM"),wRo=o(" (LayoutLM model)"),ARo=l(),D1=a("li"),Hge=a("strong"),LRo=o("longformer"),yRo=o(" \u2014 "),xO=a("a"),xRo=o("LongformerForMaskedLM"),$Ro=o(" (Longformer model)"),kRo=l(),G1=a("li"),Uge=a("strong"),SRo=o("luke"),RRo=o(" \u2014 "),$O=a("a"),PRo=o("LukeForMaskedLM"),BRo=o(" (LUKE model)"),NRo=l(),O1=a("li"),Jge=a("strong"),IRo=o("mbart"),qRo=o(" \u2014 "),kO=a("a"),jRo=o("MBartForConditionalGeneration"),DRo=o(" (mBART model)"),GRo=l(),V1=a("li"),Yge=a("strong"),ORo=o("megatron-bert"),VRo=o(" \u2014 "),SO=a("a"),XRo=o("MegatronBertForMaskedLM"),zRo=o(" (Megatron-BERT model)"),QRo=l(),X1=a("li"),Kge=a("strong"),WRo=o("mobilebert"),HRo=o(" \u2014 "),RO=a("a"),URo=o("MobileBertForMaskedLM"),JRo=o(" (MobileBERT model)"),YRo=l(),z1=a("li"),Zge=a("strong"),KRo=o("mpnet"),ZRo=o(" \u2014 "),PO=a("a"),ePo=o("MPNetForMaskedLM"),oPo=o(" (MPNet model)"),rPo=l(),Q1=a("li"),ehe=a("strong"),tPo=o("nezha"),aPo=o(" \u2014 "),BO=a("a"),nPo=o("NezhaForMaskedLM"),sPo=o(" (Nezha model)"),lPo=l(),W1=a("li"),ohe=a("strong"),iPo=o("nystromformer"),dPo=o(" \u2014 "),NO=a("a"),cPo=o("NystromformerForMaskedLM"),fPo=o(" (Nystr\xF6mformer model)"),mPo=l(),H1=a("li"),rhe=a("strong"),gPo=o("perceiver"),hPo=o(" \u2014 "),IO=a("a"),pPo=o("PerceiverForMaskedLM"),_Po=o(" (Perceiver model)"),uPo=l(),U1=a("li"),the=a("strong"),bPo=o("qdqbert"),vPo=o(" \u2014 "),qO=a("a"),FPo=o("QDQBertForMaskedLM"),TPo=o(" (QDQBert model)"),MPo=l(),J1=a("li"),ahe=a("strong"),EPo=o("reformer"),CPo=o(" \u2014 "),jO=a("a"),wPo=o("ReformerForMaskedLM"),APo=o(" (Reformer model)"),LPo=l(),Y1=a("li"),nhe=a("strong"),yPo=o("rembert"),xPo=o(" \u2014 "),DO=a("a"),$Po=o("RemBertForMaskedLM"),kPo=o(" (RemBERT model)"),SPo=l(),K1=a("li"),she=a("strong"),RPo=o("roberta"),PPo=o(" \u2014 "),GO=a("a"),BPo=o("RobertaForMaskedLM"),NPo=o(" (RoBERTa model)"),IPo=l(),Z1=a("li"),lhe=a("strong"),qPo=o("roformer"),jPo=o(" \u2014 "),OO=a("a"),DPo=o("RoFormerForMaskedLM"),GPo=o(" (RoFormer model)"),OPo=l(),e7=a("li"),ihe=a("strong"),VPo=o("squeezebert"),XPo=o(" \u2014 "),VO=a("a"),zPo=o("SqueezeBertForMaskedLM"),QPo=o(" (SqueezeBERT model)"),WPo=l(),o7=a("li"),dhe=a("strong"),HPo=o("tapas"),UPo=o(" \u2014 "),XO=a("a"),JPo=o("TapasForMaskedLM"),YPo=o(" (TAPAS model)"),KPo=l(),r7=a("li"),che=a("strong"),ZPo=o("wav2vec2"),eBo=o(" \u2014 "),fhe=a("code"),oBo=o("Wav2Vec2ForMaskedLM"),rBo=o(" (Wav2Vec2 model)"),tBo=l(),t7=a("li"),mhe=a("strong"),aBo=o("xlm"),nBo=o(" \u2014 "),zO=a("a"),sBo=o("XLMWithLMHeadModel"),lBo=o(" (XLM model)"),iBo=l(),a7=a("li"),ghe=a("strong"),dBo=o("xlm-roberta"),cBo=o(" \u2014 "),QO=a("a"),fBo=o("XLMRobertaForMaskedLM"),mBo=o(" (XLM-RoBERTa model)"),gBo=l(),n7=a("li"),hhe=a("strong"),hBo=o("xlm-roberta-xl"),pBo=o(" \u2014 "),WO=a("a"),_Bo=o("XLMRobertaXLForMaskedLM"),uBo=o(" (XLM-RoBERTa-XL model)"),bBo=l(),s7=a("li"),phe=a("strong"),vBo=o("yoso"),FBo=o(" \u2014 "),HO=a("a"),TBo=o("YosoForMaskedLM"),MBo=o(" (YOSO model)"),EBo=l(),l7=a("p"),CBo=o("The model is set in evaluation mode by default using "),_he=a("code"),wBo=o("model.eval()"),ABo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),uhe=a("code"),LBo=o("model.train()"),yBo=l(),F(i7.$$.fragment),sVe=l(),Ji=a("h2"),d7=a("a"),bhe=a("span"),F(Py.$$.fragment),xBo=l(),vhe=a("span"),$Bo=o("AutoModelForSeq2SeqLM"),lVe=l(),Ro=a("div"),F(By.$$.fragment),kBo=l(),Yi=a("p"),SBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),UO=a("a"),RBo=o("from_pretrained()"),PBo=o(" class method or the "),JO=a("a"),BBo=o("from_config()"),NBo=o(` class
method.`),IBo=l(),Ny=a("p"),qBo=o("This class cannot be instantiated directly using "),Fhe=a("code"),jBo=o("__init__()"),DBo=o(" (throws an error)."),GBo=l(),ct=a("div"),F(Iy.$$.fragment),OBo=l(),The=a("p"),VBo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),XBo=l(),Ki=a("p"),zBo=o(`Note:
Loading a model from its configuration file does `),Mhe=a("strong"),QBo=o("not"),WBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YO=a("a"),HBo=o("from_pretrained()"),UBo=o(" to load the model weights."),JBo=l(),F(c7.$$.fragment),YBo=l(),eo=a("div"),F(qy.$$.fragment),KBo=l(),Ehe=a("p"),ZBo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),eNo=l(),ja=a("p"),oNo=o("The model class to instantiate is selected based on the "),Che=a("code"),rNo=o("model_type"),tNo=o(` property of the config object (either
passed as an argument or loaded from `),whe=a("code"),aNo=o("pretrained_model_name_or_path"),nNo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ahe=a("code"),sNo=o("pretrained_model_name_or_path"),lNo=o(":"),iNo=l(),pe=a("ul"),f7=a("li"),Lhe=a("strong"),dNo=o("bart"),cNo=o(" \u2014 "),KO=a("a"),fNo=o("BartForConditionalGeneration"),mNo=o(" (BART model)"),gNo=l(),m7=a("li"),yhe=a("strong"),hNo=o("bigbird_pegasus"),pNo=o(" \u2014 "),ZO=a("a"),_No=o("BigBirdPegasusForConditionalGeneration"),uNo=o(" (BigBird-Pegasus model)"),bNo=l(),g7=a("li"),xhe=a("strong"),vNo=o("blenderbot"),FNo=o(" \u2014 "),eV=a("a"),TNo=o("BlenderbotForConditionalGeneration"),MNo=o(" (Blenderbot model)"),ENo=l(),h7=a("li"),$he=a("strong"),CNo=o("blenderbot-small"),wNo=o(" \u2014 "),oV=a("a"),ANo=o("BlenderbotSmallForConditionalGeneration"),LNo=o(" (BlenderbotSmall model)"),yNo=l(),p7=a("li"),khe=a("strong"),xNo=o("encoder-decoder"),$No=o(" \u2014 "),rV=a("a"),kNo=o("EncoderDecoderModel"),SNo=o(" (Encoder decoder model)"),RNo=l(),_7=a("li"),She=a("strong"),PNo=o("fsmt"),BNo=o(" \u2014 "),tV=a("a"),NNo=o("FSMTForConditionalGeneration"),INo=o(" (FairSeq Machine-Translation model)"),qNo=l(),u7=a("li"),Rhe=a("strong"),jNo=o("led"),DNo=o(" \u2014 "),aV=a("a"),GNo=o("LEDForConditionalGeneration"),ONo=o(" (LED model)"),VNo=l(),b7=a("li"),Phe=a("strong"),XNo=o("longt5"),zNo=o(" \u2014 "),nV=a("a"),QNo=o("LongT5ForConditionalGeneration"),WNo=o(" (LongT5 model)"),HNo=l(),v7=a("li"),Bhe=a("strong"),UNo=o("m2m_100"),JNo=o(" \u2014 "),sV=a("a"),YNo=o("M2M100ForConditionalGeneration"),KNo=o(" (M2M100 model)"),ZNo=l(),F7=a("li"),Nhe=a("strong"),eIo=o("marian"),oIo=o(" \u2014 "),lV=a("a"),rIo=o("MarianMTModel"),tIo=o(" (Marian model)"),aIo=l(),T7=a("li"),Ihe=a("strong"),nIo=o("mbart"),sIo=o(" \u2014 "),iV=a("a"),lIo=o("MBartForConditionalGeneration"),iIo=o(" (mBART model)"),dIo=l(),M7=a("li"),qhe=a("strong"),cIo=o("mt5"),fIo=o(" \u2014 "),dV=a("a"),mIo=o("MT5ForConditionalGeneration"),gIo=o(" (MT5 model)"),hIo=l(),E7=a("li"),jhe=a("strong"),pIo=o("pegasus"),_Io=o(" \u2014 "),cV=a("a"),uIo=o("PegasusForConditionalGeneration"),bIo=o(" (Pegasus model)"),vIo=l(),C7=a("li"),Dhe=a("strong"),FIo=o("plbart"),TIo=o(" \u2014 "),fV=a("a"),MIo=o("PLBartForConditionalGeneration"),EIo=o(" (PLBart model)"),CIo=l(),w7=a("li"),Ghe=a("strong"),wIo=o("prophetnet"),AIo=o(" \u2014 "),mV=a("a"),LIo=o("ProphetNetForConditionalGeneration"),yIo=o(" (ProphetNet model)"),xIo=l(),A7=a("li"),Ohe=a("strong"),$Io=o("t5"),kIo=o(" \u2014 "),gV=a("a"),SIo=o("T5ForConditionalGeneration"),RIo=o(" (T5 model)"),PIo=l(),L7=a("li"),Vhe=a("strong"),BIo=o("xlm-prophetnet"),NIo=o(" \u2014 "),hV=a("a"),IIo=o("XLMProphetNetForConditionalGeneration"),qIo=o(" (XLM-ProphetNet model)"),jIo=l(),y7=a("p"),DIo=o("The model is set in evaluation mode by default using "),Xhe=a("code"),GIo=o("model.eval()"),OIo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zhe=a("code"),VIo=o("model.train()"),XIo=l(),F(x7.$$.fragment),iVe=l(),Zi=a("h2"),$7=a("a"),Qhe=a("span"),F(jy.$$.fragment),zIo=l(),Whe=a("span"),QIo=o("AutoModelForSequenceClassification"),dVe=l(),Po=a("div"),F(Dy.$$.fragment),WIo=l(),ed=a("p"),HIo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pV=a("a"),UIo=o("from_pretrained()"),JIo=o(" class method or the "),_V=a("a"),YIo=o("from_config()"),KIo=o(` class
method.`),ZIo=l(),Gy=a("p"),eqo=o("This class cannot be instantiated directly using "),Hhe=a("code"),oqo=o("__init__()"),rqo=o(" (throws an error)."),tqo=l(),ft=a("div"),F(Oy.$$.fragment),aqo=l(),Uhe=a("p"),nqo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),sqo=l(),od=a("p"),lqo=o(`Note:
Loading a model from its configuration file does `),Jhe=a("strong"),iqo=o("not"),dqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uV=a("a"),cqo=o("from_pretrained()"),fqo=o(" to load the model weights."),mqo=l(),F(k7.$$.fragment),gqo=l(),oo=a("div"),F(Vy.$$.fragment),hqo=l(),Yhe=a("p"),pqo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_qo=l(),Da=a("p"),uqo=o("The model class to instantiate is selected based on the "),Khe=a("code"),bqo=o("model_type"),vqo=o(` property of the config object (either
passed as an argument or loaded from `),Zhe=a("code"),Fqo=o("pretrained_model_name_or_path"),Tqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),epe=a("code"),Mqo=o("pretrained_model_name_or_path"),Eqo=o(":"),Cqo=l(),I=a("ul"),S7=a("li"),ope=a("strong"),wqo=o("albert"),Aqo=o(" \u2014 "),bV=a("a"),Lqo=o("AlbertForSequenceClassification"),yqo=o(" (ALBERT model)"),xqo=l(),R7=a("li"),rpe=a("strong"),$qo=o("bart"),kqo=o(" \u2014 "),vV=a("a"),Sqo=o("BartForSequenceClassification"),Rqo=o(" (BART model)"),Pqo=l(),P7=a("li"),tpe=a("strong"),Bqo=o("bert"),Nqo=o(" \u2014 "),FV=a("a"),Iqo=o("BertForSequenceClassification"),qqo=o(" (BERT model)"),jqo=l(),B7=a("li"),ape=a("strong"),Dqo=o("big_bird"),Gqo=o(" \u2014 "),TV=a("a"),Oqo=o("BigBirdForSequenceClassification"),Vqo=o(" (BigBird model)"),Xqo=l(),N7=a("li"),npe=a("strong"),zqo=o("bigbird_pegasus"),Qqo=o(" \u2014 "),MV=a("a"),Wqo=o("BigBirdPegasusForSequenceClassification"),Hqo=o(" (BigBird-Pegasus model)"),Uqo=l(),I7=a("li"),spe=a("strong"),Jqo=o("bloom"),Yqo=o(" \u2014 "),EV=a("a"),Kqo=o("BloomForSequenceClassification"),Zqo=o(" (BLOOM model)"),ejo=l(),q7=a("li"),lpe=a("strong"),ojo=o("camembert"),rjo=o(" \u2014 "),CV=a("a"),tjo=o("CamembertForSequenceClassification"),ajo=o(" (CamemBERT model)"),njo=l(),j7=a("li"),ipe=a("strong"),sjo=o("canine"),ljo=o(" \u2014 "),wV=a("a"),ijo=o("CanineForSequenceClassification"),djo=o(" (CANINE model)"),cjo=l(),D7=a("li"),dpe=a("strong"),fjo=o("convbert"),mjo=o(" \u2014 "),AV=a("a"),gjo=o("ConvBertForSequenceClassification"),hjo=o(" (ConvBERT model)"),pjo=l(),G7=a("li"),cpe=a("strong"),_jo=o("ctrl"),ujo=o(" \u2014 "),LV=a("a"),bjo=o("CTRLForSequenceClassification"),vjo=o(" (CTRL model)"),Fjo=l(),O7=a("li"),fpe=a("strong"),Tjo=o("data2vec-text"),Mjo=o(" \u2014 "),yV=a("a"),Ejo=o("Data2VecTextForSequenceClassification"),Cjo=o(" (Data2VecText model)"),wjo=l(),V7=a("li"),mpe=a("strong"),Ajo=o("deberta"),Ljo=o(" \u2014 "),xV=a("a"),yjo=o("DebertaForSequenceClassification"),xjo=o(" (DeBERTa model)"),$jo=l(),X7=a("li"),gpe=a("strong"),kjo=o("deberta-v2"),Sjo=o(" \u2014 "),$V=a("a"),Rjo=o("DebertaV2ForSequenceClassification"),Pjo=o(" (DeBERTa-v2 model)"),Bjo=l(),z7=a("li"),hpe=a("strong"),Njo=o("distilbert"),Ijo=o(" \u2014 "),kV=a("a"),qjo=o("DistilBertForSequenceClassification"),jjo=o(" (DistilBERT model)"),Djo=l(),Q7=a("li"),ppe=a("strong"),Gjo=o("electra"),Ojo=o(" \u2014 "),SV=a("a"),Vjo=o("ElectraForSequenceClassification"),Xjo=o(" (ELECTRA model)"),zjo=l(),W7=a("li"),_pe=a("strong"),Qjo=o("flaubert"),Wjo=o(" \u2014 "),RV=a("a"),Hjo=o("FlaubertForSequenceClassification"),Ujo=o(" (FlauBERT model)"),Jjo=l(),H7=a("li"),upe=a("strong"),Yjo=o("fnet"),Kjo=o(" \u2014 "),PV=a("a"),Zjo=o("FNetForSequenceClassification"),eDo=o(" (FNet model)"),oDo=l(),U7=a("li"),bpe=a("strong"),rDo=o("funnel"),tDo=o(" \u2014 "),BV=a("a"),aDo=o("FunnelForSequenceClassification"),nDo=o(" (Funnel Transformer model)"),sDo=l(),J7=a("li"),vpe=a("strong"),lDo=o("gpt2"),iDo=o(" \u2014 "),NV=a("a"),dDo=o("GPT2ForSequenceClassification"),cDo=o(" (OpenAI GPT-2 model)"),fDo=l(),Y7=a("li"),Fpe=a("strong"),mDo=o("gpt_neo"),gDo=o(" \u2014 "),IV=a("a"),hDo=o("GPTNeoForSequenceClassification"),pDo=o(" (GPT Neo model)"),_Do=l(),K7=a("li"),Tpe=a("strong"),uDo=o("gptj"),bDo=o(" \u2014 "),qV=a("a"),vDo=o("GPTJForSequenceClassification"),FDo=o(" (GPT-J model)"),TDo=l(),Z7=a("li"),Mpe=a("strong"),MDo=o("ibert"),EDo=o(" \u2014 "),jV=a("a"),CDo=o("IBertForSequenceClassification"),wDo=o(" (I-BERT model)"),ADo=l(),e4=a("li"),Epe=a("strong"),LDo=o("layoutlm"),yDo=o(" \u2014 "),DV=a("a"),xDo=o("LayoutLMForSequenceClassification"),$Do=o(" (LayoutLM model)"),kDo=l(),o4=a("li"),Cpe=a("strong"),SDo=o("layoutlmv2"),RDo=o(" \u2014 "),GV=a("a"),PDo=o("LayoutLMv2ForSequenceClassification"),BDo=o(" (LayoutLMv2 model)"),NDo=l(),r4=a("li"),wpe=a("strong"),IDo=o("layoutlmv3"),qDo=o(" \u2014 "),OV=a("a"),jDo=o("LayoutLMv3ForSequenceClassification"),DDo=o(" (LayoutLMv3 model)"),GDo=l(),t4=a("li"),Ape=a("strong"),ODo=o("led"),VDo=o(" \u2014 "),VV=a("a"),XDo=o("LEDForSequenceClassification"),zDo=o(" (LED model)"),QDo=l(),a4=a("li"),Lpe=a("strong"),WDo=o("longformer"),HDo=o(" \u2014 "),XV=a("a"),UDo=o("LongformerForSequenceClassification"),JDo=o(" (Longformer model)"),YDo=l(),n4=a("li"),ype=a("strong"),KDo=o("mbart"),ZDo=o(" \u2014 "),zV=a("a"),eGo=o("MBartForSequenceClassification"),oGo=o(" (mBART model)"),rGo=l(),s4=a("li"),xpe=a("strong"),tGo=o("megatron-bert"),aGo=o(" \u2014 "),QV=a("a"),nGo=o("MegatronBertForSequenceClassification"),sGo=o(" (Megatron-BERT model)"),lGo=l(),l4=a("li"),$pe=a("strong"),iGo=o("mobilebert"),dGo=o(" \u2014 "),WV=a("a"),cGo=o("MobileBertForSequenceClassification"),fGo=o(" (MobileBERT model)"),mGo=l(),i4=a("li"),kpe=a("strong"),gGo=o("mpnet"),hGo=o(" \u2014 "),HV=a("a"),pGo=o("MPNetForSequenceClassification"),_Go=o(" (MPNet model)"),uGo=l(),d4=a("li"),Spe=a("strong"),bGo=o("nezha"),vGo=o(" \u2014 "),UV=a("a"),FGo=o("NezhaForSequenceClassification"),TGo=o(" (Nezha model)"),MGo=l(),c4=a("li"),Rpe=a("strong"),EGo=o("nystromformer"),CGo=o(" \u2014 "),JV=a("a"),wGo=o("NystromformerForSequenceClassification"),AGo=o(" (Nystr\xF6mformer model)"),LGo=l(),f4=a("li"),Ppe=a("strong"),yGo=o("openai-gpt"),xGo=o(" \u2014 "),YV=a("a"),$Go=o("OpenAIGPTForSequenceClassification"),kGo=o(" (OpenAI GPT model)"),SGo=l(),m4=a("li"),Bpe=a("strong"),RGo=o("perceiver"),PGo=o(" \u2014 "),KV=a("a"),BGo=o("PerceiverForSequenceClassification"),NGo=o(" (Perceiver model)"),IGo=l(),g4=a("li"),Npe=a("strong"),qGo=o("plbart"),jGo=o(" \u2014 "),ZV=a("a"),DGo=o("PLBartForSequenceClassification"),GGo=o(" (PLBart model)"),OGo=l(),h4=a("li"),Ipe=a("strong"),VGo=o("qdqbert"),XGo=o(" \u2014 "),eX=a("a"),zGo=o("QDQBertForSequenceClassification"),QGo=o(" (QDQBert model)"),WGo=l(),p4=a("li"),qpe=a("strong"),HGo=o("reformer"),UGo=o(" \u2014 "),oX=a("a"),JGo=o("ReformerForSequenceClassification"),YGo=o(" (Reformer model)"),KGo=l(),_4=a("li"),jpe=a("strong"),ZGo=o("rembert"),eOo=o(" \u2014 "),rX=a("a"),oOo=o("RemBertForSequenceClassification"),rOo=o(" (RemBERT model)"),tOo=l(),u4=a("li"),Dpe=a("strong"),aOo=o("roberta"),nOo=o(" \u2014 "),tX=a("a"),sOo=o("RobertaForSequenceClassification"),lOo=o(" (RoBERTa model)"),iOo=l(),b4=a("li"),Gpe=a("strong"),dOo=o("roformer"),cOo=o(" \u2014 "),aX=a("a"),fOo=o("RoFormerForSequenceClassification"),mOo=o(" (RoFormer model)"),gOo=l(),v4=a("li"),Ope=a("strong"),hOo=o("squeezebert"),pOo=o(" \u2014 "),nX=a("a"),_Oo=o("SqueezeBertForSequenceClassification"),uOo=o(" (SqueezeBERT model)"),bOo=l(),F4=a("li"),Vpe=a("strong"),vOo=o("tapas"),FOo=o(" \u2014 "),sX=a("a"),TOo=o("TapasForSequenceClassification"),MOo=o(" (TAPAS model)"),EOo=l(),T4=a("li"),Xpe=a("strong"),COo=o("transfo-xl"),wOo=o(" \u2014 "),lX=a("a"),AOo=o("TransfoXLForSequenceClassification"),LOo=o(" (Transformer-XL model)"),yOo=l(),M4=a("li"),zpe=a("strong"),xOo=o("xlm"),$Oo=o(" \u2014 "),iX=a("a"),kOo=o("XLMForSequenceClassification"),SOo=o(" (XLM model)"),ROo=l(),E4=a("li"),Qpe=a("strong"),POo=o("xlm-roberta"),BOo=o(" \u2014 "),dX=a("a"),NOo=o("XLMRobertaForSequenceClassification"),IOo=o(" (XLM-RoBERTa model)"),qOo=l(),C4=a("li"),Wpe=a("strong"),jOo=o("xlm-roberta-xl"),DOo=o(" \u2014 "),cX=a("a"),GOo=o("XLMRobertaXLForSequenceClassification"),OOo=o(" (XLM-RoBERTa-XL model)"),VOo=l(),w4=a("li"),Hpe=a("strong"),XOo=o("xlnet"),zOo=o(" \u2014 "),fX=a("a"),QOo=o("XLNetForSequenceClassification"),WOo=o(" (XLNet model)"),HOo=l(),A4=a("li"),Upe=a("strong"),UOo=o("yoso"),JOo=o(" \u2014 "),mX=a("a"),YOo=o("YosoForSequenceClassification"),KOo=o(" (YOSO model)"),ZOo=l(),L4=a("p"),eVo=o("The model is set in evaluation mode by default using "),Jpe=a("code"),oVo=o("model.eval()"),rVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=a("code"),tVo=o("model.train()"),aVo=l(),F(y4.$$.fragment),cVe=l(),rd=a("h2"),x4=a("a"),Kpe=a("span"),F(Xy.$$.fragment),nVo=l(),Zpe=a("span"),sVo=o("AutoModelForMultipleChoice"),fVe=l(),Bo=a("div"),F(zy.$$.fragment),lVo=l(),td=a("p"),iVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),gX=a("a"),dVo=o("from_pretrained()"),cVo=o(" class method or the "),hX=a("a"),fVo=o("from_config()"),mVo=o(` class
method.`),gVo=l(),Qy=a("p"),hVo=o("This class cannot be instantiated directly using "),e_e=a("code"),pVo=o("__init__()"),_Vo=o(" (throws an error)."),uVo=l(),mt=a("div"),F(Wy.$$.fragment),bVo=l(),o_e=a("p"),vVo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),FVo=l(),ad=a("p"),TVo=o(`Note:
Loading a model from its configuration file does `),r_e=a("strong"),MVo=o("not"),EVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pX=a("a"),CVo=o("from_pretrained()"),wVo=o(" to load the model weights."),AVo=l(),F($4.$$.fragment),LVo=l(),ro=a("div"),F(Hy.$$.fragment),yVo=l(),t_e=a("p"),xVo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),$Vo=l(),Ga=a("p"),kVo=o("The model class to instantiate is selected based on the "),a_e=a("code"),SVo=o("model_type"),RVo=o(` property of the config object (either
passed as an argument or loaded from `),n_e=a("code"),PVo=o("pretrained_model_name_or_path"),BVo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s_e=a("code"),NVo=o("pretrained_model_name_or_path"),IVo=o(":"),qVo=l(),Z=a("ul"),k4=a("li"),l_e=a("strong"),jVo=o("albert"),DVo=o(" \u2014 "),_X=a("a"),GVo=o("AlbertForMultipleChoice"),OVo=o(" (ALBERT model)"),VVo=l(),S4=a("li"),i_e=a("strong"),XVo=o("bert"),zVo=o(" \u2014 "),uX=a("a"),QVo=o("BertForMultipleChoice"),WVo=o(" (BERT model)"),HVo=l(),R4=a("li"),d_e=a("strong"),UVo=o("big_bird"),JVo=o(" \u2014 "),bX=a("a"),YVo=o("BigBirdForMultipleChoice"),KVo=o(" (BigBird model)"),ZVo=l(),P4=a("li"),c_e=a("strong"),eXo=o("camembert"),oXo=o(" \u2014 "),vX=a("a"),rXo=o("CamembertForMultipleChoice"),tXo=o(" (CamemBERT model)"),aXo=l(),B4=a("li"),f_e=a("strong"),nXo=o("canine"),sXo=o(" \u2014 "),FX=a("a"),lXo=o("CanineForMultipleChoice"),iXo=o(" (CANINE model)"),dXo=l(),N4=a("li"),m_e=a("strong"),cXo=o("convbert"),fXo=o(" \u2014 "),TX=a("a"),mXo=o("ConvBertForMultipleChoice"),gXo=o(" (ConvBERT model)"),hXo=l(),I4=a("li"),g_e=a("strong"),pXo=o("data2vec-text"),_Xo=o(" \u2014 "),MX=a("a"),uXo=o("Data2VecTextForMultipleChoice"),bXo=o(" (Data2VecText model)"),vXo=l(),q4=a("li"),h_e=a("strong"),FXo=o("deberta-v2"),TXo=o(" \u2014 "),EX=a("a"),MXo=o("DebertaV2ForMultipleChoice"),EXo=o(" (DeBERTa-v2 model)"),CXo=l(),j4=a("li"),p_e=a("strong"),wXo=o("distilbert"),AXo=o(" \u2014 "),CX=a("a"),LXo=o("DistilBertForMultipleChoice"),yXo=o(" (DistilBERT model)"),xXo=l(),D4=a("li"),__e=a("strong"),$Xo=o("electra"),kXo=o(" \u2014 "),wX=a("a"),SXo=o("ElectraForMultipleChoice"),RXo=o(" (ELECTRA model)"),PXo=l(),G4=a("li"),u_e=a("strong"),BXo=o("flaubert"),NXo=o(" \u2014 "),AX=a("a"),IXo=o("FlaubertForMultipleChoice"),qXo=o(" (FlauBERT model)"),jXo=l(),O4=a("li"),b_e=a("strong"),DXo=o("fnet"),GXo=o(" \u2014 "),LX=a("a"),OXo=o("FNetForMultipleChoice"),VXo=o(" (FNet model)"),XXo=l(),V4=a("li"),v_e=a("strong"),zXo=o("funnel"),QXo=o(" \u2014 "),yX=a("a"),WXo=o("FunnelForMultipleChoice"),HXo=o(" (Funnel Transformer model)"),UXo=l(),X4=a("li"),F_e=a("strong"),JXo=o("ibert"),YXo=o(" \u2014 "),xX=a("a"),KXo=o("IBertForMultipleChoice"),ZXo=o(" (I-BERT model)"),ezo=l(),z4=a("li"),T_e=a("strong"),ozo=o("longformer"),rzo=o(" \u2014 "),$X=a("a"),tzo=o("LongformerForMultipleChoice"),azo=o(" (Longformer model)"),nzo=l(),Q4=a("li"),M_e=a("strong"),szo=o("megatron-bert"),lzo=o(" \u2014 "),kX=a("a"),izo=o("MegatronBertForMultipleChoice"),dzo=o(" (Megatron-BERT model)"),czo=l(),W4=a("li"),E_e=a("strong"),fzo=o("mobilebert"),mzo=o(" \u2014 "),SX=a("a"),gzo=o("MobileBertForMultipleChoice"),hzo=o(" (MobileBERT model)"),pzo=l(),H4=a("li"),C_e=a("strong"),_zo=o("mpnet"),uzo=o(" \u2014 "),RX=a("a"),bzo=o("MPNetForMultipleChoice"),vzo=o(" (MPNet model)"),Fzo=l(),U4=a("li"),w_e=a("strong"),Tzo=o("nezha"),Mzo=o(" \u2014 "),PX=a("a"),Ezo=o("NezhaForMultipleChoice"),Czo=o(" (Nezha model)"),wzo=l(),J4=a("li"),A_e=a("strong"),Azo=o("nystromformer"),Lzo=o(" \u2014 "),BX=a("a"),yzo=o("NystromformerForMultipleChoice"),xzo=o(" (Nystr\xF6mformer model)"),$zo=l(),Y4=a("li"),L_e=a("strong"),kzo=o("qdqbert"),Szo=o(" \u2014 "),NX=a("a"),Rzo=o("QDQBertForMultipleChoice"),Pzo=o(" (QDQBert model)"),Bzo=l(),K4=a("li"),y_e=a("strong"),Nzo=o("rembert"),Izo=o(" \u2014 "),IX=a("a"),qzo=o("RemBertForMultipleChoice"),jzo=o(" (RemBERT model)"),Dzo=l(),Z4=a("li"),x_e=a("strong"),Gzo=o("roberta"),Ozo=o(" \u2014 "),qX=a("a"),Vzo=o("RobertaForMultipleChoice"),Xzo=o(" (RoBERTa model)"),zzo=l(),eb=a("li"),$_e=a("strong"),Qzo=o("roformer"),Wzo=o(" \u2014 "),jX=a("a"),Hzo=o("RoFormerForMultipleChoice"),Uzo=o(" (RoFormer model)"),Jzo=l(),ob=a("li"),k_e=a("strong"),Yzo=o("squeezebert"),Kzo=o(" \u2014 "),DX=a("a"),Zzo=o("SqueezeBertForMultipleChoice"),eQo=o(" (SqueezeBERT model)"),oQo=l(),rb=a("li"),S_e=a("strong"),rQo=o("xlm"),tQo=o(" \u2014 "),GX=a("a"),aQo=o("XLMForMultipleChoice"),nQo=o(" (XLM model)"),sQo=l(),tb=a("li"),R_e=a("strong"),lQo=o("xlm-roberta"),iQo=o(" \u2014 "),OX=a("a"),dQo=o("XLMRobertaForMultipleChoice"),cQo=o(" (XLM-RoBERTa model)"),fQo=l(),ab=a("li"),P_e=a("strong"),mQo=o("xlm-roberta-xl"),gQo=o(" \u2014 "),VX=a("a"),hQo=o("XLMRobertaXLForMultipleChoice"),pQo=o(" (XLM-RoBERTa-XL model)"),_Qo=l(),nb=a("li"),B_e=a("strong"),uQo=o("xlnet"),bQo=o(" \u2014 "),XX=a("a"),vQo=o("XLNetForMultipleChoice"),FQo=o(" (XLNet model)"),TQo=l(),sb=a("li"),N_e=a("strong"),MQo=o("yoso"),EQo=o(" \u2014 "),zX=a("a"),CQo=o("YosoForMultipleChoice"),wQo=o(" (YOSO model)"),AQo=l(),lb=a("p"),LQo=o("The model is set in evaluation mode by default using "),I_e=a("code"),yQo=o("model.eval()"),xQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q_e=a("code"),$Qo=o("model.train()"),kQo=l(),F(ib.$$.fragment),mVe=l(),nd=a("h2"),db=a("a"),j_e=a("span"),F(Uy.$$.fragment),SQo=l(),D_e=a("span"),RQo=o("AutoModelForNextSentencePrediction"),gVe=l(),No=a("div"),F(Jy.$$.fragment),PQo=l(),sd=a("p"),BQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),QX=a("a"),NQo=o("from_pretrained()"),IQo=o(" class method or the "),WX=a("a"),qQo=o("from_config()"),jQo=o(` class
method.`),DQo=l(),Yy=a("p"),GQo=o("This class cannot be instantiated directly using "),G_e=a("code"),OQo=o("__init__()"),VQo=o(" (throws an error)."),XQo=l(),gt=a("div"),F(Ky.$$.fragment),zQo=l(),O_e=a("p"),QQo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),WQo=l(),ld=a("p"),HQo=o(`Note:
Loading a model from its configuration file does `),V_e=a("strong"),UQo=o("not"),JQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HX=a("a"),YQo=o("from_pretrained()"),KQo=o(" to load the model weights."),ZQo=l(),F(cb.$$.fragment),eWo=l(),to=a("div"),F(Zy.$$.fragment),oWo=l(),X_e=a("p"),rWo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),tWo=l(),Oa=a("p"),aWo=o("The model class to instantiate is selected based on the "),z_e=a("code"),nWo=o("model_type"),sWo=o(` property of the config object (either
passed as an argument or loaded from `),Q_e=a("code"),lWo=o("pretrained_model_name_or_path"),iWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W_e=a("code"),dWo=o("pretrained_model_name_or_path"),cWo=o(":"),fWo=l(),Io=a("ul"),fb=a("li"),H_e=a("strong"),mWo=o("bert"),gWo=o(" \u2014 "),UX=a("a"),hWo=o("BertForNextSentencePrediction"),pWo=o(" (BERT model)"),_Wo=l(),mb=a("li"),U_e=a("strong"),uWo=o("fnet"),bWo=o(" \u2014 "),JX=a("a"),vWo=o("FNetForNextSentencePrediction"),FWo=o(" (FNet model)"),TWo=l(),gb=a("li"),J_e=a("strong"),MWo=o("megatron-bert"),EWo=o(" \u2014 "),YX=a("a"),CWo=o("MegatronBertForNextSentencePrediction"),wWo=o(" (Megatron-BERT model)"),AWo=l(),hb=a("li"),Y_e=a("strong"),LWo=o("mobilebert"),yWo=o(" \u2014 "),KX=a("a"),xWo=o("MobileBertForNextSentencePrediction"),$Wo=o(" (MobileBERT model)"),kWo=l(),pb=a("li"),K_e=a("strong"),SWo=o("nezha"),RWo=o(" \u2014 "),ZX=a("a"),PWo=o("NezhaForNextSentencePrediction"),BWo=o(" (Nezha model)"),NWo=l(),_b=a("li"),Z_e=a("strong"),IWo=o("qdqbert"),qWo=o(" \u2014 "),ez=a("a"),jWo=o("QDQBertForNextSentencePrediction"),DWo=o(" (QDQBert model)"),GWo=l(),ub=a("p"),OWo=o("The model is set in evaluation mode by default using "),eue=a("code"),VWo=o("model.eval()"),XWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oue=a("code"),zWo=o("model.train()"),QWo=l(),F(bb.$$.fragment),hVe=l(),id=a("h2"),vb=a("a"),rue=a("span"),F(e8.$$.fragment),WWo=l(),tue=a("span"),HWo=o("AutoModelForTokenClassification"),pVe=l(),qo=a("div"),F(o8.$$.fragment),UWo=l(),dd=a("p"),JWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),oz=a("a"),YWo=o("from_pretrained()"),KWo=o(" class method or the "),rz=a("a"),ZWo=o("from_config()"),eHo=o(` class
method.`),oHo=l(),r8=a("p"),rHo=o("This class cannot be instantiated directly using "),aue=a("code"),tHo=o("__init__()"),aHo=o(" (throws an error)."),nHo=l(),ht=a("div"),F(t8.$$.fragment),sHo=l(),nue=a("p"),lHo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),iHo=l(),cd=a("p"),dHo=o(`Note:
Loading a model from its configuration file does `),sue=a("strong"),cHo=o("not"),fHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tz=a("a"),mHo=o("from_pretrained()"),gHo=o(" to load the model weights."),hHo=l(),F(Fb.$$.fragment),pHo=l(),ao=a("div"),F(a8.$$.fragment),_Ho=l(),lue=a("p"),uHo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),bHo=l(),Va=a("p"),vHo=o("The model class to instantiate is selected based on the "),iue=a("code"),FHo=o("model_type"),THo=o(` property of the config object (either
passed as an argument or loaded from `),due=a("code"),MHo=o("pretrained_model_name_or_path"),EHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cue=a("code"),CHo=o("pretrained_model_name_or_path"),wHo=o(":"),AHo=l(),H=a("ul"),Tb=a("li"),fue=a("strong"),LHo=o("albert"),yHo=o(" \u2014 "),az=a("a"),xHo=o("AlbertForTokenClassification"),$Ho=o(" (ALBERT model)"),kHo=l(),Mb=a("li"),mue=a("strong"),SHo=o("bert"),RHo=o(" \u2014 "),nz=a("a"),PHo=o("BertForTokenClassification"),BHo=o(" (BERT model)"),NHo=l(),Eb=a("li"),gue=a("strong"),IHo=o("big_bird"),qHo=o(" \u2014 "),sz=a("a"),jHo=o("BigBirdForTokenClassification"),DHo=o(" (BigBird model)"),GHo=l(),Cb=a("li"),hue=a("strong"),OHo=o("bloom"),VHo=o(" \u2014 "),lz=a("a"),XHo=o("BloomForTokenClassification"),zHo=o(" (BLOOM model)"),QHo=l(),wb=a("li"),pue=a("strong"),WHo=o("camembert"),HHo=o(" \u2014 "),iz=a("a"),UHo=o("CamembertForTokenClassification"),JHo=o(" (CamemBERT model)"),YHo=l(),Ab=a("li"),_ue=a("strong"),KHo=o("canine"),ZHo=o(" \u2014 "),dz=a("a"),eUo=o("CanineForTokenClassification"),oUo=o(" (CANINE model)"),rUo=l(),Lb=a("li"),uue=a("strong"),tUo=o("convbert"),aUo=o(" \u2014 "),cz=a("a"),nUo=o("ConvBertForTokenClassification"),sUo=o(" (ConvBERT model)"),lUo=l(),yb=a("li"),bue=a("strong"),iUo=o("data2vec-text"),dUo=o(" \u2014 "),fz=a("a"),cUo=o("Data2VecTextForTokenClassification"),fUo=o(" (Data2VecText model)"),mUo=l(),xb=a("li"),vue=a("strong"),gUo=o("deberta"),hUo=o(" \u2014 "),mz=a("a"),pUo=o("DebertaForTokenClassification"),_Uo=o(" (DeBERTa model)"),uUo=l(),$b=a("li"),Fue=a("strong"),bUo=o("deberta-v2"),vUo=o(" \u2014 "),gz=a("a"),FUo=o("DebertaV2ForTokenClassification"),TUo=o(" (DeBERTa-v2 model)"),MUo=l(),kb=a("li"),Tue=a("strong"),EUo=o("distilbert"),CUo=o(" \u2014 "),hz=a("a"),wUo=o("DistilBertForTokenClassification"),AUo=o(" (DistilBERT model)"),LUo=l(),Sb=a("li"),Mue=a("strong"),yUo=o("electra"),xUo=o(" \u2014 "),pz=a("a"),$Uo=o("ElectraForTokenClassification"),kUo=o(" (ELECTRA model)"),SUo=l(),Rb=a("li"),Eue=a("strong"),RUo=o("flaubert"),PUo=o(" \u2014 "),_z=a("a"),BUo=o("FlaubertForTokenClassification"),NUo=o(" (FlauBERT model)"),IUo=l(),Pb=a("li"),Cue=a("strong"),qUo=o("fnet"),jUo=o(" \u2014 "),uz=a("a"),DUo=o("FNetForTokenClassification"),GUo=o(" (FNet model)"),OUo=l(),Bb=a("li"),wue=a("strong"),VUo=o("funnel"),XUo=o(" \u2014 "),bz=a("a"),zUo=o("FunnelForTokenClassification"),QUo=o(" (Funnel Transformer model)"),WUo=l(),Nb=a("li"),Aue=a("strong"),HUo=o("gpt2"),UUo=o(" \u2014 "),vz=a("a"),JUo=o("GPT2ForTokenClassification"),YUo=o(" (OpenAI GPT-2 model)"),KUo=l(),Ib=a("li"),Lue=a("strong"),ZUo=o("ibert"),eJo=o(" \u2014 "),Fz=a("a"),oJo=o("IBertForTokenClassification"),rJo=o(" (I-BERT model)"),tJo=l(),qb=a("li"),yue=a("strong"),aJo=o("layoutlm"),nJo=o(" \u2014 "),Tz=a("a"),sJo=o("LayoutLMForTokenClassification"),lJo=o(" (LayoutLM model)"),iJo=l(),jb=a("li"),xue=a("strong"),dJo=o("layoutlmv2"),cJo=o(" \u2014 "),Mz=a("a"),fJo=o("LayoutLMv2ForTokenClassification"),mJo=o(" (LayoutLMv2 model)"),gJo=l(),Db=a("li"),$ue=a("strong"),hJo=o("layoutlmv3"),pJo=o(" \u2014 "),Ez=a("a"),_Jo=o("LayoutLMv3ForTokenClassification"),uJo=o(" (LayoutLMv3 model)"),bJo=l(),Gb=a("li"),kue=a("strong"),vJo=o("longformer"),FJo=o(" \u2014 "),Cz=a("a"),TJo=o("LongformerForTokenClassification"),MJo=o(" (Longformer model)"),EJo=l(),Ob=a("li"),Sue=a("strong"),CJo=o("megatron-bert"),wJo=o(" \u2014 "),wz=a("a"),AJo=o("MegatronBertForTokenClassification"),LJo=o(" (Megatron-BERT model)"),yJo=l(),Vb=a("li"),Rue=a("strong"),xJo=o("mobilebert"),$Jo=o(" \u2014 "),Az=a("a"),kJo=o("MobileBertForTokenClassification"),SJo=o(" (MobileBERT model)"),RJo=l(),Xb=a("li"),Pue=a("strong"),PJo=o("mpnet"),BJo=o(" \u2014 "),Lz=a("a"),NJo=o("MPNetForTokenClassification"),IJo=o(" (MPNet model)"),qJo=l(),zb=a("li"),Bue=a("strong"),jJo=o("nezha"),DJo=o(" \u2014 "),yz=a("a"),GJo=o("NezhaForTokenClassification"),OJo=o(" (Nezha model)"),VJo=l(),Qb=a("li"),Nue=a("strong"),XJo=o("nystromformer"),zJo=o(" \u2014 "),xz=a("a"),QJo=o("NystromformerForTokenClassification"),WJo=o(" (Nystr\xF6mformer model)"),HJo=l(),Wb=a("li"),Iue=a("strong"),UJo=o("qdqbert"),JJo=o(" \u2014 "),$z=a("a"),YJo=o("QDQBertForTokenClassification"),KJo=o(" (QDQBert model)"),ZJo=l(),Hb=a("li"),que=a("strong"),eYo=o("rembert"),oYo=o(" \u2014 "),kz=a("a"),rYo=o("RemBertForTokenClassification"),tYo=o(" (RemBERT model)"),aYo=l(),Ub=a("li"),jue=a("strong"),nYo=o("roberta"),sYo=o(" \u2014 "),Sz=a("a"),lYo=o("RobertaForTokenClassification"),iYo=o(" (RoBERTa model)"),dYo=l(),Jb=a("li"),Due=a("strong"),cYo=o("roformer"),fYo=o(" \u2014 "),Rz=a("a"),mYo=o("RoFormerForTokenClassification"),gYo=o(" (RoFormer model)"),hYo=l(),Yb=a("li"),Gue=a("strong"),pYo=o("squeezebert"),_Yo=o(" \u2014 "),Pz=a("a"),uYo=o("SqueezeBertForTokenClassification"),bYo=o(" (SqueezeBERT model)"),vYo=l(),Kb=a("li"),Oue=a("strong"),FYo=o("xlm"),TYo=o(" \u2014 "),Bz=a("a"),MYo=o("XLMForTokenClassification"),EYo=o(" (XLM model)"),CYo=l(),Zb=a("li"),Vue=a("strong"),wYo=o("xlm-roberta"),AYo=o(" \u2014 "),Nz=a("a"),LYo=o("XLMRobertaForTokenClassification"),yYo=o(" (XLM-RoBERTa model)"),xYo=l(),ev=a("li"),Xue=a("strong"),$Yo=o("xlm-roberta-xl"),kYo=o(" \u2014 "),Iz=a("a"),SYo=o("XLMRobertaXLForTokenClassification"),RYo=o(" (XLM-RoBERTa-XL model)"),PYo=l(),ov=a("li"),zue=a("strong"),BYo=o("xlnet"),NYo=o(" \u2014 "),qz=a("a"),IYo=o("XLNetForTokenClassification"),qYo=o(" (XLNet model)"),jYo=l(),rv=a("li"),Que=a("strong"),DYo=o("yoso"),GYo=o(" \u2014 "),jz=a("a"),OYo=o("YosoForTokenClassification"),VYo=o(" (YOSO model)"),XYo=l(),tv=a("p"),zYo=o("The model is set in evaluation mode by default using "),Wue=a("code"),QYo=o("model.eval()"),WYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hue=a("code"),HYo=o("model.train()"),UYo=l(),F(av.$$.fragment),_Ve=l(),fd=a("h2"),nv=a("a"),Uue=a("span"),F(n8.$$.fragment),JYo=l(),Jue=a("span"),YYo=o("AutoModelForQuestionAnswering"),uVe=l(),jo=a("div"),F(s8.$$.fragment),KYo=l(),md=a("p"),ZYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Dz=a("a"),eKo=o("from_pretrained()"),oKo=o(" class method or the "),Gz=a("a"),rKo=o("from_config()"),tKo=o(` class
method.`),aKo=l(),l8=a("p"),nKo=o("This class cannot be instantiated directly using "),Yue=a("code"),sKo=o("__init__()"),lKo=o(" (throws an error)."),iKo=l(),pt=a("div"),F(i8.$$.fragment),dKo=l(),Kue=a("p"),cKo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),fKo=l(),gd=a("p"),mKo=o(`Note:
Loading a model from its configuration file does `),Zue=a("strong"),gKo=o("not"),hKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Oz=a("a"),pKo=o("from_pretrained()"),_Ko=o(" to load the model weights."),uKo=l(),F(sv.$$.fragment),bKo=l(),no=a("div"),F(d8.$$.fragment),vKo=l(),e2e=a("p"),FKo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),TKo=l(),Xa=a("p"),MKo=o("The model class to instantiate is selected based on the "),o2e=a("code"),EKo=o("model_type"),CKo=o(` property of the config object (either
passed as an argument or loaded from `),r2e=a("code"),wKo=o("pretrained_model_name_or_path"),AKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t2e=a("code"),LKo=o("pretrained_model_name_or_path"),yKo=o(":"),xKo=l(),V=a("ul"),lv=a("li"),a2e=a("strong"),$Ko=o("albert"),kKo=o(" \u2014 "),Vz=a("a"),SKo=o("AlbertForQuestionAnswering"),RKo=o(" (ALBERT model)"),PKo=l(),iv=a("li"),n2e=a("strong"),BKo=o("bart"),NKo=o(" \u2014 "),Xz=a("a"),IKo=o("BartForQuestionAnswering"),qKo=o(" (BART model)"),jKo=l(),dv=a("li"),s2e=a("strong"),DKo=o("bert"),GKo=o(" \u2014 "),zz=a("a"),OKo=o("BertForQuestionAnswering"),VKo=o(" (BERT model)"),XKo=l(),cv=a("li"),l2e=a("strong"),zKo=o("big_bird"),QKo=o(" \u2014 "),Qz=a("a"),WKo=o("BigBirdForQuestionAnswering"),HKo=o(" (BigBird model)"),UKo=l(),fv=a("li"),i2e=a("strong"),JKo=o("bigbird_pegasus"),YKo=o(" \u2014 "),Wz=a("a"),KKo=o("BigBirdPegasusForQuestionAnswering"),ZKo=o(" (BigBird-Pegasus model)"),eZo=l(),mv=a("li"),d2e=a("strong"),oZo=o("camembert"),rZo=o(" \u2014 "),Hz=a("a"),tZo=o("CamembertForQuestionAnswering"),aZo=o(" (CamemBERT model)"),nZo=l(),gv=a("li"),c2e=a("strong"),sZo=o("canine"),lZo=o(" \u2014 "),Uz=a("a"),iZo=o("CanineForQuestionAnswering"),dZo=o(" (CANINE model)"),cZo=l(),hv=a("li"),f2e=a("strong"),fZo=o("convbert"),mZo=o(" \u2014 "),Jz=a("a"),gZo=o("ConvBertForQuestionAnswering"),hZo=o(" (ConvBERT model)"),pZo=l(),pv=a("li"),m2e=a("strong"),_Zo=o("data2vec-text"),uZo=o(" \u2014 "),Yz=a("a"),bZo=o("Data2VecTextForQuestionAnswering"),vZo=o(" (Data2VecText model)"),FZo=l(),_v=a("li"),g2e=a("strong"),TZo=o("deberta"),MZo=o(" \u2014 "),Kz=a("a"),EZo=o("DebertaForQuestionAnswering"),CZo=o(" (DeBERTa model)"),wZo=l(),uv=a("li"),h2e=a("strong"),AZo=o("deberta-v2"),LZo=o(" \u2014 "),Zz=a("a"),yZo=o("DebertaV2ForQuestionAnswering"),xZo=o(" (DeBERTa-v2 model)"),$Zo=l(),bv=a("li"),p2e=a("strong"),kZo=o("distilbert"),SZo=o(" \u2014 "),eQ=a("a"),RZo=o("DistilBertForQuestionAnswering"),PZo=o(" (DistilBERT model)"),BZo=l(),vv=a("li"),_2e=a("strong"),NZo=o("electra"),IZo=o(" \u2014 "),oQ=a("a"),qZo=o("ElectraForQuestionAnswering"),jZo=o(" (ELECTRA model)"),DZo=l(),Fv=a("li"),u2e=a("strong"),GZo=o("flaubert"),OZo=o(" \u2014 "),rQ=a("a"),VZo=o("FlaubertForQuestionAnsweringSimple"),XZo=o(" (FlauBERT model)"),zZo=l(),Tv=a("li"),b2e=a("strong"),QZo=o("fnet"),WZo=o(" \u2014 "),tQ=a("a"),HZo=o("FNetForQuestionAnswering"),UZo=o(" (FNet model)"),JZo=l(),Mv=a("li"),v2e=a("strong"),YZo=o("funnel"),KZo=o(" \u2014 "),aQ=a("a"),ZZo=o("FunnelForQuestionAnswering"),eer=o(" (Funnel Transformer model)"),oer=l(),Ev=a("li"),F2e=a("strong"),rer=o("gptj"),ter=o(" \u2014 "),nQ=a("a"),aer=o("GPTJForQuestionAnswering"),ner=o(" (GPT-J model)"),ser=l(),Cv=a("li"),T2e=a("strong"),ler=o("ibert"),ier=o(" \u2014 "),sQ=a("a"),der=o("IBertForQuestionAnswering"),cer=o(" (I-BERT model)"),fer=l(),wv=a("li"),M2e=a("strong"),mer=o("layoutlmv2"),ger=o(" \u2014 "),lQ=a("a"),her=o("LayoutLMv2ForQuestionAnswering"),per=o(" (LayoutLMv2 model)"),_er=l(),Av=a("li"),E2e=a("strong"),uer=o("layoutlmv3"),ber=o(" \u2014 "),iQ=a("a"),ver=o("LayoutLMv3ForQuestionAnswering"),Fer=o(" (LayoutLMv3 model)"),Ter=l(),Lv=a("li"),C2e=a("strong"),Mer=o("led"),Eer=o(" \u2014 "),dQ=a("a"),Cer=o("LEDForQuestionAnswering"),wer=o(" (LED model)"),Aer=l(),yv=a("li"),w2e=a("strong"),Ler=o("longformer"),yer=o(" \u2014 "),cQ=a("a"),xer=o("LongformerForQuestionAnswering"),$er=o(" (Longformer model)"),ker=l(),xv=a("li"),A2e=a("strong"),Ser=o("lxmert"),Rer=o(" \u2014 "),fQ=a("a"),Per=o("LxmertForQuestionAnswering"),Ber=o(" (LXMERT model)"),Ner=l(),$v=a("li"),L2e=a("strong"),Ier=o("mbart"),qer=o(" \u2014 "),mQ=a("a"),jer=o("MBartForQuestionAnswering"),Der=o(" (mBART model)"),Ger=l(),kv=a("li"),y2e=a("strong"),Oer=o("megatron-bert"),Ver=o(" \u2014 "),gQ=a("a"),Xer=o("MegatronBertForQuestionAnswering"),zer=o(" (Megatron-BERT model)"),Qer=l(),Sv=a("li"),x2e=a("strong"),Wer=o("mobilebert"),Her=o(" \u2014 "),hQ=a("a"),Uer=o("MobileBertForQuestionAnswering"),Jer=o(" (MobileBERT model)"),Yer=l(),Rv=a("li"),$2e=a("strong"),Ker=o("mpnet"),Zer=o(" \u2014 "),pQ=a("a"),eor=o("MPNetForQuestionAnswering"),oor=o(" (MPNet model)"),ror=l(),Pv=a("li"),k2e=a("strong"),tor=o("nezha"),aor=o(" \u2014 "),_Q=a("a"),nor=o("NezhaForQuestionAnswering"),sor=o(" (Nezha model)"),lor=l(),Bv=a("li"),S2e=a("strong"),ior=o("nystromformer"),dor=o(" \u2014 "),uQ=a("a"),cor=o("NystromformerForQuestionAnswering"),mor=o(" (Nystr\xF6mformer model)"),gor=l(),Nv=a("li"),R2e=a("strong"),hor=o("qdqbert"),por=o(" \u2014 "),bQ=a("a"),_or=o("QDQBertForQuestionAnswering"),uor=o(" (QDQBert model)"),bor=l(),Iv=a("li"),P2e=a("strong"),vor=o("reformer"),For=o(" \u2014 "),vQ=a("a"),Tor=o("ReformerForQuestionAnswering"),Mor=o(" (Reformer model)"),Eor=l(),qv=a("li"),B2e=a("strong"),Cor=o("rembert"),wor=o(" \u2014 "),FQ=a("a"),Aor=o("RemBertForQuestionAnswering"),Lor=o(" (RemBERT model)"),yor=l(),jv=a("li"),N2e=a("strong"),xor=o("roberta"),$or=o(" \u2014 "),TQ=a("a"),kor=o("RobertaForQuestionAnswering"),Sor=o(" (RoBERTa model)"),Ror=l(),Dv=a("li"),I2e=a("strong"),Por=o("roformer"),Bor=o(" \u2014 "),MQ=a("a"),Nor=o("RoFormerForQuestionAnswering"),Ior=o(" (RoFormer model)"),qor=l(),Gv=a("li"),q2e=a("strong"),jor=o("splinter"),Dor=o(" \u2014 "),EQ=a("a"),Gor=o("SplinterForQuestionAnswering"),Oor=o(" (Splinter model)"),Vor=l(),Ov=a("li"),j2e=a("strong"),Xor=o("squeezebert"),zor=o(" \u2014 "),CQ=a("a"),Qor=o("SqueezeBertForQuestionAnswering"),Wor=o(" (SqueezeBERT model)"),Hor=l(),Vv=a("li"),D2e=a("strong"),Uor=o("xlm"),Jor=o(" \u2014 "),wQ=a("a"),Yor=o("XLMForQuestionAnsweringSimple"),Kor=o(" (XLM model)"),Zor=l(),Xv=a("li"),G2e=a("strong"),err=o("xlm-roberta"),orr=o(" \u2014 "),AQ=a("a"),rrr=o("XLMRobertaForQuestionAnswering"),trr=o(" (XLM-RoBERTa model)"),arr=l(),zv=a("li"),O2e=a("strong"),nrr=o("xlm-roberta-xl"),srr=o(" \u2014 "),LQ=a("a"),lrr=o("XLMRobertaXLForQuestionAnswering"),irr=o(" (XLM-RoBERTa-XL model)"),drr=l(),Qv=a("li"),V2e=a("strong"),crr=o("xlnet"),frr=o(" \u2014 "),yQ=a("a"),mrr=o("XLNetForQuestionAnsweringSimple"),grr=o(" (XLNet model)"),hrr=l(),Wv=a("li"),X2e=a("strong"),prr=o("yoso"),_rr=o(" \u2014 "),xQ=a("a"),urr=o("YosoForQuestionAnswering"),brr=o(" (YOSO model)"),vrr=l(),Hv=a("p"),Frr=o("The model is set in evaluation mode by default using "),z2e=a("code"),Trr=o("model.eval()"),Mrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q2e=a("code"),Err=o("model.train()"),Crr=l(),F(Uv.$$.fragment),bVe=l(),hd=a("h2"),Jv=a("a"),W2e=a("span"),F(c8.$$.fragment),wrr=l(),H2e=a("span"),Arr=o("AutoModelForTableQuestionAnswering"),vVe=l(),Do=a("div"),F(f8.$$.fragment),Lrr=l(),pd=a("p"),yrr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Q=a("a"),xrr=o("from_pretrained()"),$rr=o(" class method or the "),kQ=a("a"),krr=o("from_config()"),Srr=o(` class
method.`),Rrr=l(),m8=a("p"),Prr=o("This class cannot be instantiated directly using "),U2e=a("code"),Brr=o("__init__()"),Nrr=o(" (throws an error)."),Irr=l(),_t=a("div"),F(g8.$$.fragment),qrr=l(),J2e=a("p"),jrr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Drr=l(),_d=a("p"),Grr=o(`Note:
Loading a model from its configuration file does `),Y2e=a("strong"),Orr=o("not"),Vrr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=a("a"),Xrr=o("from_pretrained()"),zrr=o(" to load the model weights."),Qrr=l(),F(Yv.$$.fragment),Wrr=l(),so=a("div"),F(h8.$$.fragment),Hrr=l(),K2e=a("p"),Urr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Jrr=l(),za=a("p"),Yrr=o("The model class to instantiate is selected based on the "),Z2e=a("code"),Krr=o("model_type"),Zrr=o(` property of the config object (either
passed as an argument or loaded from `),e1e=a("code"),etr=o("pretrained_model_name_or_path"),otr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o1e=a("code"),rtr=o("pretrained_model_name_or_path"),ttr=o(":"),atr=l(),r1e=a("ul"),Kv=a("li"),t1e=a("strong"),ntr=o("tapas"),str=o(" \u2014 "),RQ=a("a"),ltr=o("TapasForQuestionAnswering"),itr=o(" (TAPAS model)"),dtr=l(),Zv=a("p"),ctr=o("The model is set in evaluation mode by default using "),a1e=a("code"),ftr=o("model.eval()"),mtr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n1e=a("code"),gtr=o("model.train()"),htr=l(),F(eF.$$.fragment),FVe=l(),ud=a("h2"),oF=a("a"),s1e=a("span"),F(p8.$$.fragment),ptr=l(),l1e=a("span"),_tr=o("AutoModelForImageClassification"),TVe=l(),Go=a("div"),F(_8.$$.fragment),utr=l(),bd=a("p"),btr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),PQ=a("a"),vtr=o("from_pretrained()"),Ftr=o(" class method or the "),BQ=a("a"),Ttr=o("from_config()"),Mtr=o(` class
method.`),Etr=l(),u8=a("p"),Ctr=o("This class cannot be instantiated directly using "),i1e=a("code"),wtr=o("__init__()"),Atr=o(" (throws an error)."),Ltr=l(),ut=a("div"),F(b8.$$.fragment),ytr=l(),d1e=a("p"),xtr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),$tr=l(),vd=a("p"),ktr=o(`Note:
Loading a model from its configuration file does `),c1e=a("strong"),Str=o("not"),Rtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NQ=a("a"),Ptr=o("from_pretrained()"),Btr=o(" to load the model weights."),Ntr=l(),F(rF.$$.fragment),Itr=l(),lo=a("div"),F(v8.$$.fragment),qtr=l(),f1e=a("p"),jtr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Dtr=l(),Qa=a("p"),Gtr=o("The model class to instantiate is selected based on the "),m1e=a("code"),Otr=o("model_type"),Vtr=o(` property of the config object (either
passed as an argument or loaded from `),g1e=a("code"),Xtr=o("pretrained_model_name_or_path"),ztr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h1e=a("code"),Qtr=o("pretrained_model_name_or_path"),Wtr=o(":"),Htr=l(),Fe=a("ul"),tF=a("li"),p1e=a("strong"),Utr=o("beit"),Jtr=o(" \u2014 "),IQ=a("a"),Ytr=o("BeitForImageClassification"),Ktr=o(" (BEiT model)"),Ztr=l(),aF=a("li"),_1e=a("strong"),ear=o("convnext"),oar=o(" \u2014 "),qQ=a("a"),rar=o("ConvNextForImageClassification"),tar=o(" (ConvNeXT model)"),aar=l(),nF=a("li"),u1e=a("strong"),nar=o("cvt"),sar=o(" \u2014 "),jQ=a("a"),lar=o("CvtForImageClassification"),iar=o(" (CvT model)"),dar=l(),sF=a("li"),b1e=a("strong"),car=o("data2vec-vision"),far=o(" \u2014 "),DQ=a("a"),mar=o("Data2VecVisionForImageClassification"),gar=o(" (Data2VecVision model)"),har=l(),Ws=a("li"),v1e=a("strong"),par=o("deit"),_ar=o(" \u2014 "),GQ=a("a"),uar=o("DeiTForImageClassification"),bar=o(" or "),OQ=a("a"),Far=o("DeiTForImageClassificationWithTeacher"),Tar=o(" (DeiT model)"),Mar=l(),lF=a("li"),F1e=a("strong"),Ear=o("imagegpt"),Car=o(" \u2014 "),VQ=a("a"),war=o("ImageGPTForImageClassification"),Aar=o(" (ImageGPT model)"),Lar=l(),Hs=a("li"),T1e=a("strong"),yar=o("levit"),xar=o(" \u2014 "),XQ=a("a"),$ar=o("LevitForImageClassification"),kar=o(" or "),zQ=a("a"),Sar=o("LevitForImageClassificationWithTeacher"),Rar=o(" (LeViT model)"),Par=l(),bt=a("li"),M1e=a("strong"),Bar=o("perceiver"),Nar=o(" \u2014 "),QQ=a("a"),Iar=o("PerceiverForImageClassificationLearned"),qar=o(" or "),WQ=a("a"),jar=o("PerceiverForImageClassificationFourier"),Dar=o(" or "),HQ=a("a"),Gar=o("PerceiverForImageClassificationConvProcessing"),Oar=o(" (Perceiver model)"),Var=l(),iF=a("li"),E1e=a("strong"),Xar=o("poolformer"),zar=o(" \u2014 "),UQ=a("a"),Qar=o("PoolFormerForImageClassification"),War=o(" (PoolFormer model)"),Har=l(),dF=a("li"),C1e=a("strong"),Uar=o("regnet"),Jar=o(" \u2014 "),JQ=a("a"),Yar=o("RegNetForImageClassification"),Kar=o(" (RegNet model)"),Zar=l(),cF=a("li"),w1e=a("strong"),enr=o("resnet"),onr=o(" \u2014 "),YQ=a("a"),rnr=o("ResNetForImageClassification"),tnr=o(" (ResNet model)"),anr=l(),fF=a("li"),A1e=a("strong"),nnr=o("segformer"),snr=o(" \u2014 "),KQ=a("a"),lnr=o("SegformerForImageClassification"),inr=o(" (SegFormer model)"),dnr=l(),mF=a("li"),L1e=a("strong"),cnr=o("swin"),fnr=o(" \u2014 "),ZQ=a("a"),mnr=o("SwinForImageClassification"),gnr=o(" (Swin Transformer model)"),hnr=l(),gF=a("li"),y1e=a("strong"),pnr=o("van"),_nr=o(" \u2014 "),eW=a("a"),unr=o("VanForImageClassification"),bnr=o(" (VAN model)"),vnr=l(),hF=a("li"),x1e=a("strong"),Fnr=o("vit"),Tnr=o(" \u2014 "),oW=a("a"),Mnr=o("ViTForImageClassification"),Enr=o(" (ViT model)"),Cnr=l(),pF=a("p"),wnr=o("The model is set in evaluation mode by default using "),$1e=a("code"),Anr=o("model.eval()"),Lnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k1e=a("code"),ynr=o("model.train()"),xnr=l(),F(_F.$$.fragment),MVe=l(),Fd=a("h2"),uF=a("a"),S1e=a("span"),F(F8.$$.fragment),$nr=l(),R1e=a("span"),knr=o("AutoModelForVision2Seq"),EVe=l(),Oo=a("div"),F(T8.$$.fragment),Snr=l(),Td=a("p"),Rnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),rW=a("a"),Pnr=o("from_pretrained()"),Bnr=o(" class method or the "),tW=a("a"),Nnr=o("from_config()"),Inr=o(` class
method.`),qnr=l(),M8=a("p"),jnr=o("This class cannot be instantiated directly using "),P1e=a("code"),Dnr=o("__init__()"),Gnr=o(" (throws an error)."),Onr=l(),vt=a("div"),F(E8.$$.fragment),Vnr=l(),B1e=a("p"),Xnr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),znr=l(),Md=a("p"),Qnr=o(`Note:
Loading a model from its configuration file does `),N1e=a("strong"),Wnr=o("not"),Hnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aW=a("a"),Unr=o("from_pretrained()"),Jnr=o(" to load the model weights."),Ynr=l(),F(bF.$$.fragment),Knr=l(),io=a("div"),F(C8.$$.fragment),Znr=l(),I1e=a("p"),esr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),osr=l(),Wa=a("p"),rsr=o("The model class to instantiate is selected based on the "),q1e=a("code"),tsr=o("model_type"),asr=o(` property of the config object (either
passed as an argument or loaded from `),j1e=a("code"),nsr=o("pretrained_model_name_or_path"),ssr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D1e=a("code"),lsr=o("pretrained_model_name_or_path"),isr=o(":"),dsr=l(),G1e=a("ul"),vF=a("li"),O1e=a("strong"),csr=o("vision-encoder-decoder"),fsr=o(" \u2014 "),nW=a("a"),msr=o("VisionEncoderDecoderModel"),gsr=o(" (Vision Encoder decoder model)"),hsr=l(),FF=a("p"),psr=o("The model is set in evaluation mode by default using "),V1e=a("code"),_sr=o("model.eval()"),usr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X1e=a("code"),bsr=o("model.train()"),vsr=l(),F(TF.$$.fragment),CVe=l(),Ed=a("h2"),MF=a("a"),z1e=a("span"),F(w8.$$.fragment),Fsr=l(),Q1e=a("span"),Tsr=o("AutoModelForVisualQuestionAnswering"),wVe=l(),Vo=a("div"),F(A8.$$.fragment),Msr=l(),Cd=a("p"),Esr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),sW=a("a"),Csr=o("from_pretrained()"),wsr=o(" class method or the "),lW=a("a"),Asr=o("from_config()"),Lsr=o(` class
method.`),ysr=l(),L8=a("p"),xsr=o("This class cannot be instantiated directly using "),W1e=a("code"),$sr=o("__init__()"),ksr=o(" (throws an error)."),Ssr=l(),Ft=a("div"),F(y8.$$.fragment),Rsr=l(),H1e=a("p"),Psr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Bsr=l(),wd=a("p"),Nsr=o(`Note:
Loading a model from its configuration file does `),U1e=a("strong"),Isr=o("not"),qsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iW=a("a"),jsr=o("from_pretrained()"),Dsr=o(" to load the model weights."),Gsr=l(),F(EF.$$.fragment),Osr=l(),co=a("div"),F(x8.$$.fragment),Vsr=l(),J1e=a("p"),Xsr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),zsr=l(),Ha=a("p"),Qsr=o("The model class to instantiate is selected based on the "),Y1e=a("code"),Wsr=o("model_type"),Hsr=o(` property of the config object (either
passed as an argument or loaded from `),K1e=a("code"),Usr=o("pretrained_model_name_or_path"),Jsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=a("code"),Ysr=o("pretrained_model_name_or_path"),Ksr=o(":"),Zsr=l(),e7e=a("ul"),CF=a("li"),o7e=a("strong"),elr=o("vilt"),olr=o(" \u2014 "),dW=a("a"),rlr=o("ViltForQuestionAnswering"),tlr=o(" (ViLT model)"),alr=l(),wF=a("p"),nlr=o("The model is set in evaluation mode by default using "),r7e=a("code"),slr=o("model.eval()"),llr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t7e=a("code"),ilr=o("model.train()"),dlr=l(),F(AF.$$.fragment),AVe=l(),Ad=a("h2"),LF=a("a"),a7e=a("span"),F($8.$$.fragment),clr=l(),n7e=a("span"),flr=o("AutoModelForAudioClassification"),LVe=l(),Xo=a("div"),F(k8.$$.fragment),mlr=l(),Ld=a("p"),glr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),cW=a("a"),hlr=o("from_pretrained()"),plr=o(" class method or the "),fW=a("a"),_lr=o("from_config()"),ulr=o(` class
method.`),blr=l(),S8=a("p"),vlr=o("This class cannot be instantiated directly using "),s7e=a("code"),Flr=o("__init__()"),Tlr=o(" (throws an error)."),Mlr=l(),Tt=a("div"),F(R8.$$.fragment),Elr=l(),l7e=a("p"),Clr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),wlr=l(),yd=a("p"),Alr=o(`Note:
Loading a model from its configuration file does `),i7e=a("strong"),Llr=o("not"),ylr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mW=a("a"),xlr=o("from_pretrained()"),$lr=o(" to load the model weights."),klr=l(),F(yF.$$.fragment),Slr=l(),fo=a("div"),F(P8.$$.fragment),Rlr=l(),d7e=a("p"),Plr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Blr=l(),Ua=a("p"),Nlr=o("The model class to instantiate is selected based on the "),c7e=a("code"),Ilr=o("model_type"),qlr=o(` property of the config object (either
passed as an argument or loaded from `),f7e=a("code"),jlr=o("pretrained_model_name_or_path"),Dlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m7e=a("code"),Glr=o("pretrained_model_name_or_path"),Olr=o(":"),Vlr=l(),Pe=a("ul"),xF=a("li"),g7e=a("strong"),Xlr=o("data2vec-audio"),zlr=o(" \u2014 "),gW=a("a"),Qlr=o("Data2VecAudioForSequenceClassification"),Wlr=o(" (Data2VecAudio model)"),Hlr=l(),$F=a("li"),h7e=a("strong"),Ulr=o("hubert"),Jlr=o(" \u2014 "),hW=a("a"),Ylr=o("HubertForSequenceClassification"),Klr=o(" (Hubert model)"),Zlr=l(),kF=a("li"),p7e=a("strong"),eir=o("sew"),oir=o(" \u2014 "),pW=a("a"),rir=o("SEWForSequenceClassification"),tir=o(" (SEW model)"),air=l(),SF=a("li"),_7e=a("strong"),nir=o("sew-d"),sir=o(" \u2014 "),_W=a("a"),lir=o("SEWDForSequenceClassification"),iir=o(" (SEW-D model)"),dir=l(),RF=a("li"),u7e=a("strong"),cir=o("unispeech"),fir=o(" \u2014 "),uW=a("a"),mir=o("UniSpeechForSequenceClassification"),gir=o(" (UniSpeech model)"),hir=l(),PF=a("li"),b7e=a("strong"),pir=o("unispeech-sat"),_ir=o(" \u2014 "),bW=a("a"),uir=o("UniSpeechSatForSequenceClassification"),bir=o(" (UniSpeechSat model)"),vir=l(),BF=a("li"),v7e=a("strong"),Fir=o("wav2vec2"),Tir=o(" \u2014 "),vW=a("a"),Mir=o("Wav2Vec2ForSequenceClassification"),Eir=o(" (Wav2Vec2 model)"),Cir=l(),NF=a("li"),F7e=a("strong"),wir=o("wav2vec2-conformer"),Air=o(" \u2014 "),FW=a("a"),Lir=o("Wav2Vec2ConformerForSequenceClassification"),yir=o(" (Wav2Vec2-Conformer model)"),xir=l(),IF=a("li"),T7e=a("strong"),$ir=o("wavlm"),kir=o(" \u2014 "),TW=a("a"),Sir=o("WavLMForSequenceClassification"),Rir=o(" (WavLM model)"),Pir=l(),qF=a("p"),Bir=o("The model is set in evaluation mode by default using "),M7e=a("code"),Nir=o("model.eval()"),Iir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E7e=a("code"),qir=o("model.train()"),jir=l(),F(jF.$$.fragment),yVe=l(),xd=a("h2"),DF=a("a"),C7e=a("span"),F(B8.$$.fragment),Dir=l(),w7e=a("span"),Gir=o("AutoModelForAudioFrameClassification"),xVe=l(),zo=a("div"),F(N8.$$.fragment),Oir=l(),$d=a("p"),Vir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),MW=a("a"),Xir=o("from_pretrained()"),zir=o(" class method or the "),EW=a("a"),Qir=o("from_config()"),Wir=o(` class
method.`),Hir=l(),I8=a("p"),Uir=o("This class cannot be instantiated directly using "),A7e=a("code"),Jir=o("__init__()"),Yir=o(" (throws an error)."),Kir=l(),Mt=a("div"),F(q8.$$.fragment),Zir=l(),L7e=a("p"),edr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),odr=l(),kd=a("p"),rdr=o(`Note:
Loading a model from its configuration file does `),y7e=a("strong"),tdr=o("not"),adr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=a("a"),ndr=o("from_pretrained()"),sdr=o(" to load the model weights."),ldr=l(),F(GF.$$.fragment),idr=l(),mo=a("div"),F(j8.$$.fragment),ddr=l(),x7e=a("p"),cdr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),fdr=l(),Ja=a("p"),mdr=o("The model class to instantiate is selected based on the "),$7e=a("code"),gdr=o("model_type"),hdr=o(` property of the config object (either
passed as an argument or loaded from `),k7e=a("code"),pdr=o("pretrained_model_name_or_path"),_dr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S7e=a("code"),udr=o("pretrained_model_name_or_path"),bdr=o(":"),vdr=l(),ot=a("ul"),OF=a("li"),R7e=a("strong"),Fdr=o("data2vec-audio"),Tdr=o(" \u2014 "),wW=a("a"),Mdr=o("Data2VecAudioForAudioFrameClassification"),Edr=o(" (Data2VecAudio model)"),Cdr=l(),VF=a("li"),P7e=a("strong"),wdr=o("unispeech-sat"),Adr=o(" \u2014 "),AW=a("a"),Ldr=o("UniSpeechSatForAudioFrameClassification"),ydr=o(" (UniSpeechSat model)"),xdr=l(),XF=a("li"),B7e=a("strong"),$dr=o("wav2vec2"),kdr=o(" \u2014 "),LW=a("a"),Sdr=o("Wav2Vec2ForAudioFrameClassification"),Rdr=o(" (Wav2Vec2 model)"),Pdr=l(),zF=a("li"),N7e=a("strong"),Bdr=o("wav2vec2-conformer"),Ndr=o(" \u2014 "),yW=a("a"),Idr=o("Wav2Vec2ConformerForAudioFrameClassification"),qdr=o(" (Wav2Vec2-Conformer model)"),jdr=l(),QF=a("li"),I7e=a("strong"),Ddr=o("wavlm"),Gdr=o(" \u2014 "),xW=a("a"),Odr=o("WavLMForAudioFrameClassification"),Vdr=o(" (WavLM model)"),Xdr=l(),WF=a("p"),zdr=o("The model is set in evaluation mode by default using "),q7e=a("code"),Qdr=o("model.eval()"),Wdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j7e=a("code"),Hdr=o("model.train()"),Udr=l(),F(HF.$$.fragment),$Ve=l(),Sd=a("h2"),UF=a("a"),D7e=a("span"),F(D8.$$.fragment),Jdr=l(),G7e=a("span"),Ydr=o("AutoModelForCTC"),kVe=l(),Qo=a("div"),F(G8.$$.fragment),Kdr=l(),Rd=a("p"),Zdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),$W=a("a"),ecr=o("from_pretrained()"),ocr=o(" class method or the "),kW=a("a"),rcr=o("from_config()"),tcr=o(` class
method.`),acr=l(),O8=a("p"),ncr=o("This class cannot be instantiated directly using "),O7e=a("code"),scr=o("__init__()"),lcr=o(" (throws an error)."),icr=l(),Et=a("div"),F(V8.$$.fragment),dcr=l(),V7e=a("p"),ccr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),fcr=l(),Pd=a("p"),mcr=o(`Note:
Loading a model from its configuration file does `),X7e=a("strong"),gcr=o("not"),hcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=a("a"),pcr=o("from_pretrained()"),_cr=o(" to load the model weights."),ucr=l(),F(JF.$$.fragment),bcr=l(),go=a("div"),F(X8.$$.fragment),vcr=l(),z7e=a("p"),Fcr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Tcr=l(),Ya=a("p"),Mcr=o("The model class to instantiate is selected based on the "),Q7e=a("code"),Ecr=o("model_type"),Ccr=o(` property of the config object (either
passed as an argument or loaded from `),W7e=a("code"),wcr=o("pretrained_model_name_or_path"),Acr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H7e=a("code"),Lcr=o("pretrained_model_name_or_path"),ycr=o(":"),xcr=l(),Le=a("ul"),YF=a("li"),U7e=a("strong"),$cr=o("data2vec-audio"),kcr=o(" \u2014 "),RW=a("a"),Scr=o("Data2VecAudioForCTC"),Rcr=o(" (Data2VecAudio model)"),Pcr=l(),KF=a("li"),J7e=a("strong"),Bcr=o("hubert"),Ncr=o(" \u2014 "),PW=a("a"),Icr=o("HubertForCTC"),qcr=o(" (Hubert model)"),jcr=l(),ZF=a("li"),Y7e=a("strong"),Dcr=o("mctct"),Gcr=o(" \u2014 "),BW=a("a"),Ocr=o("MCTCTForCTC"),Vcr=o(" (M-CTC-T model)"),Xcr=l(),eT=a("li"),K7e=a("strong"),zcr=o("sew"),Qcr=o(" \u2014 "),NW=a("a"),Wcr=o("SEWForCTC"),Hcr=o(" (SEW model)"),Ucr=l(),oT=a("li"),Z7e=a("strong"),Jcr=o("sew-d"),Ycr=o(" \u2014 "),IW=a("a"),Kcr=o("SEWDForCTC"),Zcr=o(" (SEW-D model)"),efr=l(),rT=a("li"),e4e=a("strong"),ofr=o("unispeech"),rfr=o(" \u2014 "),qW=a("a"),tfr=o("UniSpeechForCTC"),afr=o(" (UniSpeech model)"),nfr=l(),tT=a("li"),o4e=a("strong"),sfr=o("unispeech-sat"),lfr=o(" \u2014 "),jW=a("a"),ifr=o("UniSpeechSatForCTC"),dfr=o(" (UniSpeechSat model)"),cfr=l(),aT=a("li"),r4e=a("strong"),ffr=o("wav2vec2"),mfr=o(" \u2014 "),DW=a("a"),gfr=o("Wav2Vec2ForCTC"),hfr=o(" (Wav2Vec2 model)"),pfr=l(),nT=a("li"),t4e=a("strong"),_fr=o("wav2vec2-conformer"),ufr=o(" \u2014 "),GW=a("a"),bfr=o("Wav2Vec2ConformerForCTC"),vfr=o(" (Wav2Vec2-Conformer model)"),Ffr=l(),sT=a("li"),a4e=a("strong"),Tfr=o("wavlm"),Mfr=o(" \u2014 "),OW=a("a"),Efr=o("WavLMForCTC"),Cfr=o(" (WavLM model)"),wfr=l(),lT=a("p"),Afr=o("The model is set in evaluation mode by default using "),n4e=a("code"),Lfr=o("model.eval()"),yfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s4e=a("code"),xfr=o("model.train()"),$fr=l(),F(iT.$$.fragment),SVe=l(),Bd=a("h2"),dT=a("a"),l4e=a("span"),F(z8.$$.fragment),kfr=l(),i4e=a("span"),Sfr=o("AutoModelForSpeechSeq2Seq"),RVe=l(),Wo=a("div"),F(Q8.$$.fragment),Rfr=l(),Nd=a("p"),Pfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),VW=a("a"),Bfr=o("from_pretrained()"),Nfr=o(" class method or the "),XW=a("a"),Ifr=o("from_config()"),qfr=o(` class
method.`),jfr=l(),W8=a("p"),Dfr=o("This class cannot be instantiated directly using "),d4e=a("code"),Gfr=o("__init__()"),Ofr=o(" (throws an error)."),Vfr=l(),Ct=a("div"),F(H8.$$.fragment),Xfr=l(),c4e=a("p"),zfr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Qfr=l(),Id=a("p"),Wfr=o(`Note:
Loading a model from its configuration file does `),f4e=a("strong"),Hfr=o("not"),Ufr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zW=a("a"),Jfr=o("from_pretrained()"),Yfr=o(" to load the model weights."),Kfr=l(),F(cT.$$.fragment),Zfr=l(),ho=a("div"),F(U8.$$.fragment),emr=l(),m4e=a("p"),omr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),rmr=l(),Ka=a("p"),tmr=o("The model class to instantiate is selected based on the "),g4e=a("code"),amr=o("model_type"),nmr=o(` property of the config object (either
passed as an argument or loaded from `),h4e=a("code"),smr=o("pretrained_model_name_or_path"),lmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p4e=a("code"),imr=o("pretrained_model_name_or_path"),dmr=o(":"),cmr=l(),J8=a("ul"),fT=a("li"),_4e=a("strong"),fmr=o("speech-encoder-decoder"),mmr=o(" \u2014 "),QW=a("a"),gmr=o("SpeechEncoderDecoderModel"),hmr=o(" (Speech Encoder decoder model)"),pmr=l(),mT=a("li"),u4e=a("strong"),_mr=o("speech_to_text"),umr=o(" \u2014 "),WW=a("a"),bmr=o("Speech2TextForConditionalGeneration"),vmr=o(" (Speech2Text model)"),Fmr=l(),gT=a("p"),Tmr=o("The model is set in evaluation mode by default using "),b4e=a("code"),Mmr=o("model.eval()"),Emr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v4e=a("code"),Cmr=o("model.train()"),wmr=l(),F(hT.$$.fragment),PVe=l(),qd=a("h2"),pT=a("a"),F4e=a("span"),F(Y8.$$.fragment),Amr=l(),T4e=a("span"),Lmr=o("AutoModelForAudioXVector"),BVe=l(),Ho=a("div"),F(K8.$$.fragment),ymr=l(),jd=a("p"),xmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),HW=a("a"),$mr=o("from_pretrained()"),kmr=o(" class method or the "),UW=a("a"),Smr=o("from_config()"),Rmr=o(` class
method.`),Pmr=l(),Z8=a("p"),Bmr=o("This class cannot be instantiated directly using "),M4e=a("code"),Nmr=o("__init__()"),Imr=o(" (throws an error)."),qmr=l(),wt=a("div"),F(e9.$$.fragment),jmr=l(),E4e=a("p"),Dmr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Gmr=l(),Dd=a("p"),Omr=o(`Note:
Loading a model from its configuration file does `),C4e=a("strong"),Vmr=o("not"),Xmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JW=a("a"),zmr=o("from_pretrained()"),Qmr=o(" to load the model weights."),Wmr=l(),F(_T.$$.fragment),Hmr=l(),po=a("div"),F(o9.$$.fragment),Umr=l(),w4e=a("p"),Jmr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Ymr=l(),Za=a("p"),Kmr=o("The model class to instantiate is selected based on the "),A4e=a("code"),Zmr=o("model_type"),egr=o(` property of the config object (either
passed as an argument or loaded from `),L4e=a("code"),ogr=o("pretrained_model_name_or_path"),rgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y4e=a("code"),tgr=o("pretrained_model_name_or_path"),agr=o(":"),ngr=l(),rt=a("ul"),uT=a("li"),x4e=a("strong"),sgr=o("data2vec-audio"),lgr=o(" \u2014 "),YW=a("a"),igr=o("Data2VecAudioForXVector"),dgr=o(" (Data2VecAudio model)"),cgr=l(),bT=a("li"),$4e=a("strong"),fgr=o("unispeech-sat"),mgr=o(" \u2014 "),KW=a("a"),ggr=o("UniSpeechSatForXVector"),hgr=o(" (UniSpeechSat model)"),pgr=l(),vT=a("li"),k4e=a("strong"),_gr=o("wav2vec2"),ugr=o(" \u2014 "),ZW=a("a"),bgr=o("Wav2Vec2ForXVector"),vgr=o(" (Wav2Vec2 model)"),Fgr=l(),FT=a("li"),S4e=a("strong"),Tgr=o("wav2vec2-conformer"),Mgr=o(" \u2014 "),eH=a("a"),Egr=o("Wav2Vec2ConformerForXVector"),Cgr=o(" (Wav2Vec2-Conformer model)"),wgr=l(),TT=a("li"),R4e=a("strong"),Agr=o("wavlm"),Lgr=o(" \u2014 "),oH=a("a"),ygr=o("WavLMForXVector"),xgr=o(" (WavLM model)"),$gr=l(),MT=a("p"),kgr=o("The model is set in evaluation mode by default using "),P4e=a("code"),Sgr=o("model.eval()"),Rgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B4e=a("code"),Pgr=o("model.train()"),Bgr=l(),F(ET.$$.fragment),NVe=l(),Gd=a("h2"),CT=a("a"),N4e=a("span"),F(r9.$$.fragment),Ngr=l(),I4e=a("span"),Igr=o("AutoModelForMaskedImageModeling"),IVe=l(),Uo=a("div"),F(t9.$$.fragment),qgr=l(),Od=a("p"),jgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),rH=a("a"),Dgr=o("from_pretrained()"),Ggr=o(" class method or the "),tH=a("a"),Ogr=o("from_config()"),Vgr=o(` class
method.`),Xgr=l(),a9=a("p"),zgr=o("This class cannot be instantiated directly using "),q4e=a("code"),Qgr=o("__init__()"),Wgr=o(" (throws an error)."),Hgr=l(),At=a("div"),F(n9.$$.fragment),Ugr=l(),j4e=a("p"),Jgr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Ygr=l(),Vd=a("p"),Kgr=o(`Note:
Loading a model from its configuration file does `),D4e=a("strong"),Zgr=o("not"),ehr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=a("a"),ohr=o("from_pretrained()"),rhr=o(" to load the model weights."),thr=l(),F(wT.$$.fragment),ahr=l(),_o=a("div"),F(s9.$$.fragment),nhr=l(),G4e=a("p"),shr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),lhr=l(),en=a("p"),ihr=o("The model class to instantiate is selected based on the "),O4e=a("code"),dhr=o("model_type"),chr=o(` property of the config object (either
passed as an argument or loaded from `),V4e=a("code"),fhr=o("pretrained_model_name_or_path"),mhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X4e=a("code"),ghr=o("pretrained_model_name_or_path"),hhr=o(":"),phr=l(),Xd=a("ul"),AT=a("li"),z4e=a("strong"),_hr=o("deit"),uhr=o(" \u2014 "),nH=a("a"),bhr=o("DeiTForMaskedImageModeling"),vhr=o(" (DeiT model)"),Fhr=l(),LT=a("li"),Q4e=a("strong"),Thr=o("swin"),Mhr=o(" \u2014 "),sH=a("a"),Ehr=o("SwinForMaskedImageModeling"),Chr=o(" (Swin Transformer model)"),whr=l(),yT=a("li"),W4e=a("strong"),Ahr=o("vit"),Lhr=o(" \u2014 "),lH=a("a"),yhr=o("ViTForMaskedImageModeling"),xhr=o(" (ViT model)"),$hr=l(),xT=a("p"),khr=o("The model is set in evaluation mode by default using "),H4e=a("code"),Shr=o("model.eval()"),Rhr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U4e=a("code"),Phr=o("model.train()"),Bhr=l(),F($T.$$.fragment),qVe=l(),zd=a("h2"),kT=a("a"),J4e=a("span"),F(l9.$$.fragment),Nhr=l(),Y4e=a("span"),Ihr=o("AutoModelForObjectDetection"),jVe=l(),Jo=a("div"),F(i9.$$.fragment),qhr=l(),Qd=a("p"),jhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),iH=a("a"),Dhr=o("from_pretrained()"),Ghr=o(" class method or the "),dH=a("a"),Ohr=o("from_config()"),Vhr=o(` class
method.`),Xhr=l(),d9=a("p"),zhr=o("This class cannot be instantiated directly using "),K4e=a("code"),Qhr=o("__init__()"),Whr=o(" (throws an error)."),Hhr=l(),Lt=a("div"),F(c9.$$.fragment),Uhr=l(),Z4e=a("p"),Jhr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Yhr=l(),Wd=a("p"),Khr=o(`Note:
Loading a model from its configuration file does `),ebe=a("strong"),Zhr=o("not"),epr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cH=a("a"),opr=o("from_pretrained()"),rpr=o(" to load the model weights."),tpr=l(),F(ST.$$.fragment),apr=l(),uo=a("div"),F(f9.$$.fragment),npr=l(),obe=a("p"),spr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),lpr=l(),on=a("p"),ipr=o("The model class to instantiate is selected based on the "),rbe=a("code"),dpr=o("model_type"),cpr=o(` property of the config object (either
passed as an argument or loaded from `),tbe=a("code"),fpr=o("pretrained_model_name_or_path"),mpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),abe=a("code"),gpr=o("pretrained_model_name_or_path"),hpr=o(":"),ppr=l(),m9=a("ul"),RT=a("li"),nbe=a("strong"),_pr=o("detr"),upr=o(" \u2014 "),fH=a("a"),bpr=o("DetrForObjectDetection"),vpr=o(" (DETR model)"),Fpr=l(),PT=a("li"),sbe=a("strong"),Tpr=o("yolos"),Mpr=o(" \u2014 "),mH=a("a"),Epr=o("YolosForObjectDetection"),Cpr=o(" (YOLOS model)"),wpr=l(),BT=a("p"),Apr=o("The model is set in evaluation mode by default using "),lbe=a("code"),Lpr=o("model.eval()"),ypr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ibe=a("code"),xpr=o("model.train()"),$pr=l(),F(NT.$$.fragment),DVe=l(),Hd=a("h2"),IT=a("a"),dbe=a("span"),F(g9.$$.fragment),kpr=l(),cbe=a("span"),Spr=o("AutoModelForImageSegmentation"),GVe=l(),Yo=a("div"),F(h9.$$.fragment),Rpr=l(),Ud=a("p"),Ppr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),gH=a("a"),Bpr=o("from_pretrained()"),Npr=o(" class method or the "),hH=a("a"),Ipr=o("from_config()"),qpr=o(` class
method.`),jpr=l(),p9=a("p"),Dpr=o("This class cannot be instantiated directly using "),fbe=a("code"),Gpr=o("__init__()"),Opr=o(" (throws an error)."),Vpr=l(),yt=a("div"),F(_9.$$.fragment),Xpr=l(),mbe=a("p"),zpr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Qpr=l(),Jd=a("p"),Wpr=o(`Note:
Loading a model from its configuration file does `),gbe=a("strong"),Hpr=o("not"),Upr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pH=a("a"),Jpr=o("from_pretrained()"),Ypr=o(" to load the model weights."),Kpr=l(),F(qT.$$.fragment),Zpr=l(),bo=a("div"),F(u9.$$.fragment),e_r=l(),hbe=a("p"),o_r=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),r_r=l(),rn=a("p"),t_r=o("The model class to instantiate is selected based on the "),pbe=a("code"),a_r=o("model_type"),n_r=o(` property of the config object (either
passed as an argument or loaded from `),_be=a("code"),s_r=o("pretrained_model_name_or_path"),l_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ube=a("code"),i_r=o("pretrained_model_name_or_path"),d_r=o(":"),c_r=l(),bbe=a("ul"),jT=a("li"),vbe=a("strong"),f_r=o("detr"),m_r=o(" \u2014 "),_H=a("a"),g_r=o("DetrForSegmentation"),h_r=o(" (DETR model)"),p_r=l(),DT=a("p"),__r=o("The model is set in evaluation mode by default using "),Fbe=a("code"),u_r=o("model.eval()"),b_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tbe=a("code"),v_r=o("model.train()"),F_r=l(),F(GT.$$.fragment),OVe=l(),Yd=a("h2"),OT=a("a"),Mbe=a("span"),F(b9.$$.fragment),T_r=l(),Ebe=a("span"),M_r=o("AutoModelForSemanticSegmentation"),VVe=l(),Ko=a("div"),F(v9.$$.fragment),E_r=l(),Kd=a("p"),C_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),uH=a("a"),w_r=o("from_pretrained()"),A_r=o(" class method or the "),bH=a("a"),L_r=o("from_config()"),y_r=o(` class
method.`),x_r=l(),F9=a("p"),$_r=o("This class cannot be instantiated directly using "),Cbe=a("code"),k_r=o("__init__()"),S_r=o(" (throws an error)."),R_r=l(),xt=a("div"),F(T9.$$.fragment),P_r=l(),wbe=a("p"),B_r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),N_r=l(),Zd=a("p"),I_r=o(`Note:
Loading a model from its configuration file does `),Abe=a("strong"),q_r=o("not"),j_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vH=a("a"),D_r=o("from_pretrained()"),G_r=o(" to load the model weights."),O_r=l(),F(VT.$$.fragment),V_r=l(),vo=a("div"),F(M9.$$.fragment),X_r=l(),Lbe=a("p"),z_r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Q_r=l(),tn=a("p"),W_r=o("The model class to instantiate is selected based on the "),ybe=a("code"),H_r=o("model_type"),U_r=o(` property of the config object (either
passed as an argument or loaded from `),xbe=a("code"),J_r=o("pretrained_model_name_or_path"),Y_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$be=a("code"),K_r=o("pretrained_model_name_or_path"),Z_r=o(":"),eur=l(),an=a("ul"),XT=a("li"),kbe=a("strong"),our=o("beit"),rur=o(" \u2014 "),FH=a("a"),tur=o("BeitForSemanticSegmentation"),aur=o(" (BEiT model)"),nur=l(),zT=a("li"),Sbe=a("strong"),sur=o("data2vec-vision"),lur=o(" \u2014 "),TH=a("a"),iur=o("Data2VecVisionForSemanticSegmentation"),dur=o(" (Data2VecVision model)"),cur=l(),QT=a("li"),Rbe=a("strong"),fur=o("dpt"),mur=o(" \u2014 "),MH=a("a"),gur=o("DPTForSemanticSegmentation"),hur=o(" (DPT model)"),pur=l(),WT=a("li"),Pbe=a("strong"),_ur=o("segformer"),uur=o(" \u2014 "),EH=a("a"),bur=o("SegformerForSemanticSegmentation"),vur=o(" (SegFormer model)"),Fur=l(),HT=a("p"),Tur=o("The model is set in evaluation mode by default using "),Bbe=a("code"),Mur=o("model.eval()"),Eur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nbe=a("code"),Cur=o("model.train()"),wur=l(),F(UT.$$.fragment),XVe=l(),ec=a("h2"),JT=a("a"),Ibe=a("span"),F(E9.$$.fragment),Aur=l(),qbe=a("span"),Lur=o("AutoModelForInstanceSegmentation"),zVe=l(),Zo=a("div"),F(C9.$$.fragment),yur=l(),oc=a("p"),xur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),CH=a("a"),$ur=o("from_pretrained()"),kur=o(" class method or the "),wH=a("a"),Sur=o("from_config()"),Rur=o(` class
method.`),Pur=l(),w9=a("p"),Bur=o("This class cannot be instantiated directly using "),jbe=a("code"),Nur=o("__init__()"),Iur=o(" (throws an error)."),qur=l(),$t=a("div"),F(A9.$$.fragment),jur=l(),Dbe=a("p"),Dur=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Gur=l(),rc=a("p"),Our=o(`Note:
Loading a model from its configuration file does `),Gbe=a("strong"),Vur=o("not"),Xur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AH=a("a"),zur=o("from_pretrained()"),Qur=o(" to load the model weights."),Wur=l(),F(YT.$$.fragment),Hur=l(),Fo=a("div"),F(L9.$$.fragment),Uur=l(),Obe=a("p"),Jur=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Yur=l(),nn=a("p"),Kur=o("The model class to instantiate is selected based on the "),Vbe=a("code"),Zur=o("model_type"),e2r=o(` property of the config object (either
passed as an argument or loaded from `),Xbe=a("code"),o2r=o("pretrained_model_name_or_path"),r2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=a("code"),t2r=o("pretrained_model_name_or_path"),a2r=o(":"),n2r=l(),Qbe=a("ul"),KT=a("li"),Wbe=a("strong"),s2r=o("maskformer"),l2r=o(" \u2014 "),LH=a("a"),i2r=o("MaskFormerForInstanceSegmentation"),d2r=o(" (MaskFormer model)"),c2r=l(),ZT=a("p"),f2r=o("The model is set in evaluation mode by default using "),Hbe=a("code"),m2r=o("model.eval()"),g2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ube=a("code"),h2r=o("model.train()"),p2r=l(),F(eM.$$.fragment),QVe=l(),tc=a("h2"),oM=a("a"),Jbe=a("span"),F(y9.$$.fragment),_2r=l(),Ybe=a("span"),u2r=o("TFAutoModel"),WVe=l(),er=a("div"),F(x9.$$.fragment),b2r=l(),ac=a("p"),v2r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),yH=a("a"),F2r=o("from_pretrained()"),T2r=o(" class method or the "),xH=a("a"),M2r=o("from_config()"),E2r=o(` class
method.`),C2r=l(),$9=a("p"),w2r=o("This class cannot be instantiated directly using "),Kbe=a("code"),A2r=o("__init__()"),L2r=o(" (throws an error)."),y2r=l(),kt=a("div"),F(k9.$$.fragment),x2r=l(),Zbe=a("p"),$2r=o("Instantiates one of the base model classes of the library from a configuration."),k2r=l(),nc=a("p"),S2r=o(`Note:
Loading a model from its configuration file does `),eve=a("strong"),R2r=o("not"),P2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=a("a"),B2r=o("from_pretrained()"),N2r=o(" to load the model weights."),I2r=l(),F(rM.$$.fragment),q2r=l(),xr=a("div"),F(S9.$$.fragment),j2r=l(),ove=a("p"),D2r=o("Instantiate one of the base model classes of the library from a pretrained model."),G2r=l(),sn=a("p"),O2r=o("The model class to instantiate is selected based on the "),rve=a("code"),V2r=o("model_type"),X2r=o(` property of the config object (either
passed as an argument or loaded from `),tve=a("code"),z2r=o("pretrained_model_name_or_path"),Q2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ave=a("code"),W2r=o("pretrained_model_name_or_path"),H2r=o(":"),U2r=l(),q=a("ul"),tM=a("li"),nve=a("strong"),J2r=o("albert"),Y2r=o(" \u2014 "),kH=a("a"),K2r=o("TFAlbertModel"),Z2r=o(" (ALBERT model)"),e1r=l(),aM=a("li"),sve=a("strong"),o1r=o("bart"),r1r=o(" \u2014 "),SH=a("a"),t1r=o("TFBartModel"),a1r=o(" (BART model)"),n1r=l(),nM=a("li"),lve=a("strong"),s1r=o("bert"),l1r=o(" \u2014 "),RH=a("a"),i1r=o("TFBertModel"),d1r=o(" (BERT model)"),c1r=l(),sM=a("li"),ive=a("strong"),f1r=o("blenderbot"),m1r=o(" \u2014 "),PH=a("a"),g1r=o("TFBlenderbotModel"),h1r=o(" (Blenderbot model)"),p1r=l(),lM=a("li"),dve=a("strong"),_1r=o("blenderbot-small"),u1r=o(" \u2014 "),BH=a("a"),b1r=o("TFBlenderbotSmallModel"),v1r=o(" (BlenderbotSmall model)"),F1r=l(),iM=a("li"),cve=a("strong"),T1r=o("camembert"),M1r=o(" \u2014 "),NH=a("a"),E1r=o("TFCamembertModel"),C1r=o(" (CamemBERT model)"),w1r=l(),dM=a("li"),fve=a("strong"),A1r=o("clip"),L1r=o(" \u2014 "),IH=a("a"),y1r=o("TFCLIPModel"),x1r=o(" (CLIP model)"),$1r=l(),cM=a("li"),mve=a("strong"),k1r=o("convbert"),S1r=o(" \u2014 "),qH=a("a"),R1r=o("TFConvBertModel"),P1r=o(" (ConvBERT model)"),B1r=l(),fM=a("li"),gve=a("strong"),N1r=o("convnext"),I1r=o(" \u2014 "),jH=a("a"),q1r=o("TFConvNextModel"),j1r=o(" (ConvNeXT model)"),D1r=l(),mM=a("li"),hve=a("strong"),G1r=o("ctrl"),O1r=o(" \u2014 "),DH=a("a"),V1r=o("TFCTRLModel"),X1r=o(" (CTRL model)"),z1r=l(),gM=a("li"),pve=a("strong"),Q1r=o("data2vec-vision"),W1r=o(" \u2014 "),GH=a("a"),H1r=o("TFData2VecVisionModel"),U1r=o(" (Data2VecVision model)"),J1r=l(),hM=a("li"),_ve=a("strong"),Y1r=o("deberta"),K1r=o(" \u2014 "),OH=a("a"),Z1r=o("TFDebertaModel"),e7r=o(" (DeBERTa model)"),o7r=l(),pM=a("li"),uve=a("strong"),r7r=o("deberta-v2"),t7r=o(" \u2014 "),VH=a("a"),a7r=o("TFDebertaV2Model"),n7r=o(" (DeBERTa-v2 model)"),s7r=l(),_M=a("li"),bve=a("strong"),l7r=o("distilbert"),i7r=o(" \u2014 "),XH=a("a"),d7r=o("TFDistilBertModel"),c7r=o(" (DistilBERT model)"),f7r=l(),uM=a("li"),vve=a("strong"),m7r=o("dpr"),g7r=o(" \u2014 "),zH=a("a"),h7r=o("TFDPRQuestionEncoder"),p7r=o(" (DPR model)"),_7r=l(),bM=a("li"),Fve=a("strong"),u7r=o("electra"),b7r=o(" \u2014 "),QH=a("a"),v7r=o("TFElectraModel"),F7r=o(" (ELECTRA model)"),T7r=l(),vM=a("li"),Tve=a("strong"),M7r=o("flaubert"),E7r=o(" \u2014 "),WH=a("a"),C7r=o("TFFlaubertModel"),w7r=o(" (FlauBERT model)"),A7r=l(),Us=a("li"),Mve=a("strong"),L7r=o("funnel"),y7r=o(" \u2014 "),HH=a("a"),x7r=o("TFFunnelModel"),$7r=o(" or "),UH=a("a"),k7r=o("TFFunnelBaseModel"),S7r=o(" (Funnel Transformer model)"),R7r=l(),FM=a("li"),Eve=a("strong"),P7r=o("gpt2"),B7r=o(" \u2014 "),JH=a("a"),N7r=o("TFGPT2Model"),I7r=o(" (OpenAI GPT-2 model)"),q7r=l(),TM=a("li"),Cve=a("strong"),j7r=o("gptj"),D7r=o(" \u2014 "),YH=a("a"),G7r=o("TFGPTJModel"),O7r=o(" (GPT-J model)"),V7r=l(),MM=a("li"),wve=a("strong"),X7r=o("hubert"),z7r=o(" \u2014 "),KH=a("a"),Q7r=o("TFHubertModel"),W7r=o(" (Hubert model)"),H7r=l(),EM=a("li"),Ave=a("strong"),U7r=o("layoutlm"),J7r=o(" \u2014 "),ZH=a("a"),Y7r=o("TFLayoutLMModel"),K7r=o(" (LayoutLM model)"),Z7r=l(),CM=a("li"),Lve=a("strong"),e4r=o("led"),o4r=o(" \u2014 "),eU=a("a"),r4r=o("TFLEDModel"),t4r=o(" (LED model)"),a4r=l(),wM=a("li"),yve=a("strong"),n4r=o("longformer"),s4r=o(" \u2014 "),oU=a("a"),l4r=o("TFLongformerModel"),i4r=o(" (Longformer model)"),d4r=l(),AM=a("li"),xve=a("strong"),c4r=o("lxmert"),f4r=o(" \u2014 "),rU=a("a"),m4r=o("TFLxmertModel"),g4r=o(" (LXMERT model)"),h4r=l(),LM=a("li"),$ve=a("strong"),p4r=o("marian"),_4r=o(" \u2014 "),tU=a("a"),u4r=o("TFMarianModel"),b4r=o(" (Marian model)"),v4r=l(),yM=a("li"),kve=a("strong"),F4r=o("mbart"),T4r=o(" \u2014 "),aU=a("a"),M4r=o("TFMBartModel"),E4r=o(" (mBART model)"),C4r=l(),xM=a("li"),Sve=a("strong"),w4r=o("mobilebert"),A4r=o(" \u2014 "),nU=a("a"),L4r=o("TFMobileBertModel"),y4r=o(" (MobileBERT model)"),x4r=l(),$M=a("li"),Rve=a("strong"),$4r=o("mpnet"),k4r=o(" \u2014 "),sU=a("a"),S4r=o("TFMPNetModel"),R4r=o(" (MPNet model)"),P4r=l(),kM=a("li"),Pve=a("strong"),B4r=o("mt5"),N4r=o(" \u2014 "),lU=a("a"),I4r=o("TFMT5Model"),q4r=o(" (MT5 model)"),j4r=l(),SM=a("li"),Bve=a("strong"),D4r=o("openai-gpt"),G4r=o(" \u2014 "),iU=a("a"),O4r=o("TFOpenAIGPTModel"),V4r=o(" (OpenAI GPT model)"),X4r=l(),RM=a("li"),Nve=a("strong"),z4r=o("opt"),Q4r=o(" \u2014 "),dU=a("a"),W4r=o("TFOPTModel"),H4r=o(" (OPT model)"),U4r=l(),PM=a("li"),Ive=a("strong"),J4r=o("pegasus"),Y4r=o(" \u2014 "),cU=a("a"),K4r=o("TFPegasusModel"),Z4r=o(" (Pegasus model)"),ebr=l(),BM=a("li"),qve=a("strong"),obr=o("regnet"),rbr=o(" \u2014 "),fU=a("a"),tbr=o("TFRegNetModel"),abr=o(" (RegNet model)"),nbr=l(),NM=a("li"),jve=a("strong"),sbr=o("rembert"),lbr=o(" \u2014 "),mU=a("a"),ibr=o("TFRemBertModel"),dbr=o(" (RemBERT model)"),cbr=l(),IM=a("li"),Dve=a("strong"),fbr=o("resnet"),mbr=o(" \u2014 "),gU=a("a"),gbr=o("TFResNetModel"),hbr=o(" (ResNet model)"),pbr=l(),qM=a("li"),Gve=a("strong"),_br=o("roberta"),ubr=o(" \u2014 "),hU=a("a"),bbr=o("TFRobertaModel"),vbr=o(" (RoBERTa model)"),Fbr=l(),jM=a("li"),Ove=a("strong"),Tbr=o("roformer"),Mbr=o(" \u2014 "),pU=a("a"),Ebr=o("TFRoFormerModel"),Cbr=o(" (RoFormer model)"),wbr=l(),DM=a("li"),Vve=a("strong"),Abr=o("speech_to_text"),Lbr=o(" \u2014 "),_U=a("a"),ybr=o("TFSpeech2TextModel"),xbr=o(" (Speech2Text model)"),$br=l(),GM=a("li"),Xve=a("strong"),kbr=o("swin"),Sbr=o(" \u2014 "),uU=a("a"),Rbr=o("TFSwinModel"),Pbr=o(" (Swin Transformer model)"),Bbr=l(),OM=a("li"),zve=a("strong"),Nbr=o("t5"),Ibr=o(" \u2014 "),bU=a("a"),qbr=o("TFT5Model"),jbr=o(" (T5 model)"),Dbr=l(),VM=a("li"),Qve=a("strong"),Gbr=o("tapas"),Obr=o(" \u2014 "),vU=a("a"),Vbr=o("TFTapasModel"),Xbr=o(" (TAPAS model)"),zbr=l(),XM=a("li"),Wve=a("strong"),Qbr=o("transfo-xl"),Wbr=o(" \u2014 "),FU=a("a"),Hbr=o("TFTransfoXLModel"),Ubr=o(" (Transformer-XL model)"),Jbr=l(),zM=a("li"),Hve=a("strong"),Ybr=o("vit"),Kbr=o(" \u2014 "),TU=a("a"),Zbr=o("TFViTModel"),evr=o(" (ViT model)"),ovr=l(),QM=a("li"),Uve=a("strong"),rvr=o("vit_mae"),tvr=o(" \u2014 "),MU=a("a"),avr=o("TFViTMAEModel"),nvr=o(" (ViTMAE model)"),svr=l(),WM=a("li"),Jve=a("strong"),lvr=o("wav2vec2"),ivr=o(" \u2014 "),EU=a("a"),dvr=o("TFWav2Vec2Model"),cvr=o(" (Wav2Vec2 model)"),fvr=l(),HM=a("li"),Yve=a("strong"),mvr=o("xlm"),gvr=o(" \u2014 "),CU=a("a"),hvr=o("TFXLMModel"),pvr=o(" (XLM model)"),_vr=l(),UM=a("li"),Kve=a("strong"),uvr=o("xlm-roberta"),bvr=o(" \u2014 "),wU=a("a"),vvr=o("TFXLMRobertaModel"),Fvr=o(" (XLM-RoBERTa model)"),Tvr=l(),JM=a("li"),Zve=a("strong"),Mvr=o("xlnet"),Evr=o(" \u2014 "),AU=a("a"),Cvr=o("TFXLNetModel"),wvr=o(" (XLNet model)"),Avr=l(),F(YM.$$.fragment),HVe=l(),sc=a("h2"),KM=a("a"),eFe=a("span"),F(R9.$$.fragment),Lvr=l(),oFe=a("span"),yvr=o("TFAutoModelForPreTraining"),UVe=l(),or=a("div"),F(P9.$$.fragment),xvr=l(),lc=a("p"),$vr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),LU=a("a"),kvr=o("from_pretrained()"),Svr=o(" class method or the "),yU=a("a"),Rvr=o("from_config()"),Pvr=o(` class
method.`),Bvr=l(),B9=a("p"),Nvr=o("This class cannot be instantiated directly using "),rFe=a("code"),Ivr=o("__init__()"),qvr=o(" (throws an error)."),jvr=l(),St=a("div"),F(N9.$$.fragment),Dvr=l(),tFe=a("p"),Gvr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Ovr=l(),ic=a("p"),Vvr=o(`Note:
Loading a model from its configuration file does `),aFe=a("strong"),Xvr=o("not"),zvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=a("a"),Qvr=o("from_pretrained()"),Wvr=o(" to load the model weights."),Hvr=l(),F(ZM.$$.fragment),Uvr=l(),$r=a("div"),F(I9.$$.fragment),Jvr=l(),nFe=a("p"),Yvr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Kvr=l(),ln=a("p"),Zvr=o("The model class to instantiate is selected based on the "),sFe=a("code"),eFr=o("model_type"),oFr=o(` property of the config object (either
passed as an argument or loaded from `),lFe=a("code"),rFr=o("pretrained_model_name_or_path"),tFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iFe=a("code"),aFr=o("pretrained_model_name_or_path"),nFr=o(":"),sFr=l(),se=a("ul"),eE=a("li"),dFe=a("strong"),lFr=o("albert"),iFr=o(" \u2014 "),$U=a("a"),dFr=o("TFAlbertForPreTraining"),cFr=o(" (ALBERT model)"),fFr=l(),oE=a("li"),cFe=a("strong"),mFr=o("bart"),gFr=o(" \u2014 "),kU=a("a"),hFr=o("TFBartForConditionalGeneration"),pFr=o(" (BART model)"),_Fr=l(),rE=a("li"),fFe=a("strong"),uFr=o("bert"),bFr=o(" \u2014 "),SU=a("a"),vFr=o("TFBertForPreTraining"),FFr=o(" (BERT model)"),TFr=l(),tE=a("li"),mFe=a("strong"),MFr=o("camembert"),EFr=o(" \u2014 "),RU=a("a"),CFr=o("TFCamembertForMaskedLM"),wFr=o(" (CamemBERT model)"),AFr=l(),aE=a("li"),gFe=a("strong"),LFr=o("ctrl"),yFr=o(" \u2014 "),PU=a("a"),xFr=o("TFCTRLLMHeadModel"),$Fr=o(" (CTRL model)"),kFr=l(),nE=a("li"),hFe=a("strong"),SFr=o("distilbert"),RFr=o(" \u2014 "),BU=a("a"),PFr=o("TFDistilBertForMaskedLM"),BFr=o(" (DistilBERT model)"),NFr=l(),sE=a("li"),pFe=a("strong"),IFr=o("electra"),qFr=o(" \u2014 "),NU=a("a"),jFr=o("TFElectraForPreTraining"),DFr=o(" (ELECTRA model)"),GFr=l(),lE=a("li"),_Fe=a("strong"),OFr=o("flaubert"),VFr=o(" \u2014 "),IU=a("a"),XFr=o("TFFlaubertWithLMHeadModel"),zFr=o(" (FlauBERT model)"),QFr=l(),iE=a("li"),uFe=a("strong"),WFr=o("funnel"),HFr=o(" \u2014 "),qU=a("a"),UFr=o("TFFunnelForPreTraining"),JFr=o(" (Funnel Transformer model)"),YFr=l(),dE=a("li"),bFe=a("strong"),KFr=o("gpt2"),ZFr=o(" \u2014 "),jU=a("a"),eTr=o("TFGPT2LMHeadModel"),oTr=o(" (OpenAI GPT-2 model)"),rTr=l(),cE=a("li"),vFe=a("strong"),tTr=o("layoutlm"),aTr=o(" \u2014 "),DU=a("a"),nTr=o("TFLayoutLMForMaskedLM"),sTr=o(" (LayoutLM model)"),lTr=l(),fE=a("li"),FFe=a("strong"),iTr=o("lxmert"),dTr=o(" \u2014 "),GU=a("a"),cTr=o("TFLxmertForPreTraining"),fTr=o(" (LXMERT model)"),mTr=l(),mE=a("li"),TFe=a("strong"),gTr=o("mobilebert"),hTr=o(" \u2014 "),OU=a("a"),pTr=o("TFMobileBertForPreTraining"),_Tr=o(" (MobileBERT model)"),uTr=l(),gE=a("li"),MFe=a("strong"),bTr=o("mpnet"),vTr=o(" \u2014 "),VU=a("a"),FTr=o("TFMPNetForMaskedLM"),TTr=o(" (MPNet model)"),MTr=l(),hE=a("li"),EFe=a("strong"),ETr=o("openai-gpt"),CTr=o(" \u2014 "),XU=a("a"),wTr=o("TFOpenAIGPTLMHeadModel"),ATr=o(" (OpenAI GPT model)"),LTr=l(),pE=a("li"),CFe=a("strong"),yTr=o("roberta"),xTr=o(" \u2014 "),zU=a("a"),$Tr=o("TFRobertaForMaskedLM"),kTr=o(" (RoBERTa model)"),STr=l(),_E=a("li"),wFe=a("strong"),RTr=o("t5"),PTr=o(" \u2014 "),QU=a("a"),BTr=o("TFT5ForConditionalGeneration"),NTr=o(" (T5 model)"),ITr=l(),uE=a("li"),AFe=a("strong"),qTr=o("tapas"),jTr=o(" \u2014 "),WU=a("a"),DTr=o("TFTapasForMaskedLM"),GTr=o(" (TAPAS model)"),OTr=l(),bE=a("li"),LFe=a("strong"),VTr=o("transfo-xl"),XTr=o(" \u2014 "),HU=a("a"),zTr=o("TFTransfoXLLMHeadModel"),QTr=o(" (Transformer-XL model)"),WTr=l(),vE=a("li"),yFe=a("strong"),HTr=o("vit_mae"),UTr=o(" \u2014 "),UU=a("a"),JTr=o("TFViTMAEForPreTraining"),YTr=o(" (ViTMAE model)"),KTr=l(),FE=a("li"),xFe=a("strong"),ZTr=o("xlm"),eMr=o(" \u2014 "),JU=a("a"),oMr=o("TFXLMWithLMHeadModel"),rMr=o(" (XLM model)"),tMr=l(),TE=a("li"),$Fe=a("strong"),aMr=o("xlm-roberta"),nMr=o(" \u2014 "),YU=a("a"),sMr=o("TFXLMRobertaForMaskedLM"),lMr=o(" (XLM-RoBERTa model)"),iMr=l(),ME=a("li"),kFe=a("strong"),dMr=o("xlnet"),cMr=o(" \u2014 "),KU=a("a"),fMr=o("TFXLNetLMHeadModel"),mMr=o(" (XLNet model)"),gMr=l(),F(EE.$$.fragment),JVe=l(),dc=a("h2"),CE=a("a"),SFe=a("span"),F(q9.$$.fragment),hMr=l(),RFe=a("span"),pMr=o("TFAutoModelForCausalLM"),YVe=l(),rr=a("div"),F(j9.$$.fragment),_Mr=l(),cc=a("p"),uMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),ZU=a("a"),bMr=o("from_pretrained()"),vMr=o(" class method or the "),eJ=a("a"),FMr=o("from_config()"),TMr=o(` class
method.`),MMr=l(),D9=a("p"),EMr=o("This class cannot be instantiated directly using "),PFe=a("code"),CMr=o("__init__()"),wMr=o(" (throws an error)."),AMr=l(),Rt=a("div"),F(G9.$$.fragment),LMr=l(),BFe=a("p"),yMr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),xMr=l(),fc=a("p"),$Mr=o(`Note:
Loading a model from its configuration file does `),NFe=a("strong"),kMr=o("not"),SMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=a("a"),RMr=o("from_pretrained()"),PMr=o(" to load the model weights."),BMr=l(),F(wE.$$.fragment),NMr=l(),kr=a("div"),F(O9.$$.fragment),IMr=l(),IFe=a("p"),qMr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),jMr=l(),dn=a("p"),DMr=o("The model class to instantiate is selected based on the "),qFe=a("code"),GMr=o("model_type"),OMr=o(` property of the config object (either
passed as an argument or loaded from `),jFe=a("code"),VMr=o("pretrained_model_name_or_path"),XMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DFe=a("code"),zMr=o("pretrained_model_name_or_path"),QMr=o(":"),WMr=l(),Me=a("ul"),AE=a("li"),GFe=a("strong"),HMr=o("bert"),UMr=o(" \u2014 "),rJ=a("a"),JMr=o("TFBertLMHeadModel"),YMr=o(" (BERT model)"),KMr=l(),LE=a("li"),OFe=a("strong"),ZMr=o("camembert"),eEr=o(" \u2014 "),tJ=a("a"),oEr=o("TFCamembertForCausalLM"),rEr=o(" (CamemBERT model)"),tEr=l(),yE=a("li"),VFe=a("strong"),aEr=o("ctrl"),nEr=o(" \u2014 "),aJ=a("a"),sEr=o("TFCTRLLMHeadModel"),lEr=o(" (CTRL model)"),iEr=l(),xE=a("li"),XFe=a("strong"),dEr=o("gpt2"),cEr=o(" \u2014 "),nJ=a("a"),fEr=o("TFGPT2LMHeadModel"),mEr=o(" (OpenAI GPT-2 model)"),gEr=l(),$E=a("li"),zFe=a("strong"),hEr=o("gptj"),pEr=o(" \u2014 "),sJ=a("a"),_Er=o("TFGPTJForCausalLM"),uEr=o(" (GPT-J model)"),bEr=l(),kE=a("li"),QFe=a("strong"),vEr=o("openai-gpt"),FEr=o(" \u2014 "),lJ=a("a"),TEr=o("TFOpenAIGPTLMHeadModel"),MEr=o(" (OpenAI GPT model)"),EEr=l(),SE=a("li"),WFe=a("strong"),CEr=o("opt"),wEr=o(" \u2014 "),iJ=a("a"),AEr=o("TFOPTForCausalLM"),LEr=o(" (OPT model)"),yEr=l(),RE=a("li"),HFe=a("strong"),xEr=o("rembert"),$Er=o(" \u2014 "),dJ=a("a"),kEr=o("TFRemBertForCausalLM"),SEr=o(" (RemBERT model)"),REr=l(),PE=a("li"),UFe=a("strong"),PEr=o("roberta"),BEr=o(" \u2014 "),cJ=a("a"),NEr=o("TFRobertaForCausalLM"),IEr=o(" (RoBERTa model)"),qEr=l(),BE=a("li"),JFe=a("strong"),jEr=o("roformer"),DEr=o(" \u2014 "),fJ=a("a"),GEr=o("TFRoFormerForCausalLM"),OEr=o(" (RoFormer model)"),VEr=l(),NE=a("li"),YFe=a("strong"),XEr=o("transfo-xl"),zEr=o(" \u2014 "),mJ=a("a"),QEr=o("TFTransfoXLLMHeadModel"),WEr=o(" (Transformer-XL model)"),HEr=l(),IE=a("li"),KFe=a("strong"),UEr=o("xlm"),JEr=o(" \u2014 "),gJ=a("a"),YEr=o("TFXLMWithLMHeadModel"),KEr=o(" (XLM model)"),ZEr=l(),qE=a("li"),ZFe=a("strong"),eCr=o("xlnet"),oCr=o(" \u2014 "),hJ=a("a"),rCr=o("TFXLNetLMHeadModel"),tCr=o(" (XLNet model)"),aCr=l(),F(jE.$$.fragment),KVe=l(),mc=a("h2"),DE=a("a"),eTe=a("span"),F(V9.$$.fragment),nCr=l(),oTe=a("span"),sCr=o("TFAutoModelForImageClassification"),ZVe=l(),tr=a("div"),F(X9.$$.fragment),lCr=l(),gc=a("p"),iCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),pJ=a("a"),dCr=o("from_pretrained()"),cCr=o(" class method or the "),_J=a("a"),fCr=o("from_config()"),mCr=o(` class
method.`),gCr=l(),z9=a("p"),hCr=o("This class cannot be instantiated directly using "),rTe=a("code"),pCr=o("__init__()"),_Cr=o(" (throws an error)."),uCr=l(),Pt=a("div"),F(Q9.$$.fragment),bCr=l(),tTe=a("p"),vCr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),FCr=l(),hc=a("p"),TCr=o(`Note:
Loading a model from its configuration file does `),aTe=a("strong"),MCr=o("not"),ECr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uJ=a("a"),CCr=o("from_pretrained()"),wCr=o(" to load the model weights."),ACr=l(),F(GE.$$.fragment),LCr=l(),Sr=a("div"),F(W9.$$.fragment),yCr=l(),nTe=a("p"),xCr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),$Cr=l(),cn=a("p"),kCr=o("The model class to instantiate is selected based on the "),sTe=a("code"),SCr=o("model_type"),RCr=o(` property of the config object (either
passed as an argument or loaded from `),lTe=a("code"),PCr=o("pretrained_model_name_or_path"),BCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=a("code"),NCr=o("pretrained_model_name_or_path"),ICr=o(":"),qCr=l(),ar=a("ul"),OE=a("li"),dTe=a("strong"),jCr=o("convnext"),DCr=o(" \u2014 "),bJ=a("a"),GCr=o("TFConvNextForImageClassification"),OCr=o(" (ConvNeXT model)"),VCr=l(),VE=a("li"),cTe=a("strong"),XCr=o("data2vec-vision"),zCr=o(" \u2014 "),vJ=a("a"),QCr=o("TFData2VecVisionForImageClassification"),WCr=o(" (Data2VecVision model)"),HCr=l(),XE=a("li"),fTe=a("strong"),UCr=o("regnet"),JCr=o(" \u2014 "),FJ=a("a"),YCr=o("TFRegNetForImageClassification"),KCr=o(" (RegNet model)"),ZCr=l(),zE=a("li"),mTe=a("strong"),e3r=o("resnet"),o3r=o(" \u2014 "),TJ=a("a"),r3r=o("TFResNetForImageClassification"),t3r=o(" (ResNet model)"),a3r=l(),QE=a("li"),gTe=a("strong"),n3r=o("swin"),s3r=o(" \u2014 "),MJ=a("a"),l3r=o("TFSwinForImageClassification"),i3r=o(" (Swin Transformer model)"),d3r=l(),WE=a("li"),hTe=a("strong"),c3r=o("vit"),f3r=o(" \u2014 "),EJ=a("a"),m3r=o("TFViTForImageClassification"),g3r=o(" (ViT model)"),h3r=l(),F(HE.$$.fragment),eXe=l(),pc=a("h2"),UE=a("a"),pTe=a("span"),F(H9.$$.fragment),p3r=l(),_Te=a("span"),_3r=o("TFAutoModelForMaskedLM"),oXe=l(),nr=a("div"),F(U9.$$.fragment),u3r=l(),_c=a("p"),b3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),CJ=a("a"),v3r=o("from_pretrained()"),F3r=o(" class method or the "),wJ=a("a"),T3r=o("from_config()"),M3r=o(` class
method.`),E3r=l(),J9=a("p"),C3r=o("This class cannot be instantiated directly using "),uTe=a("code"),w3r=o("__init__()"),A3r=o(" (throws an error)."),L3r=l(),Bt=a("div"),F(Y9.$$.fragment),y3r=l(),bTe=a("p"),x3r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),$3r=l(),uc=a("p"),k3r=o(`Note:
Loading a model from its configuration file does `),vTe=a("strong"),S3r=o("not"),R3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AJ=a("a"),P3r=o("from_pretrained()"),B3r=o(" to load the model weights."),N3r=l(),F(JE.$$.fragment),I3r=l(),Rr=a("div"),F(K9.$$.fragment),q3r=l(),FTe=a("p"),j3r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),D3r=l(),fn=a("p"),G3r=o("The model class to instantiate is selected based on the "),TTe=a("code"),O3r=o("model_type"),V3r=o(` property of the config object (either
passed as an argument or loaded from `),MTe=a("code"),X3r=o("pretrained_model_name_or_path"),z3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ETe=a("code"),Q3r=o("pretrained_model_name_or_path"),W3r=o(":"),H3r=l(),ie=a("ul"),YE=a("li"),CTe=a("strong"),U3r=o("albert"),J3r=o(" \u2014 "),LJ=a("a"),Y3r=o("TFAlbertForMaskedLM"),K3r=o(" (ALBERT model)"),Z3r=l(),KE=a("li"),wTe=a("strong"),e5r=o("bert"),o5r=o(" \u2014 "),yJ=a("a"),r5r=o("TFBertForMaskedLM"),t5r=o(" (BERT model)"),a5r=l(),ZE=a("li"),ATe=a("strong"),n5r=o("camembert"),s5r=o(" \u2014 "),xJ=a("a"),l5r=o("TFCamembertForMaskedLM"),i5r=o(" (CamemBERT model)"),d5r=l(),eC=a("li"),LTe=a("strong"),c5r=o("convbert"),f5r=o(" \u2014 "),$J=a("a"),m5r=o("TFConvBertForMaskedLM"),g5r=o(" (ConvBERT model)"),h5r=l(),oC=a("li"),yTe=a("strong"),p5r=o("deberta"),_5r=o(" \u2014 "),kJ=a("a"),u5r=o("TFDebertaForMaskedLM"),b5r=o(" (DeBERTa model)"),v5r=l(),rC=a("li"),xTe=a("strong"),F5r=o("deberta-v2"),T5r=o(" \u2014 "),SJ=a("a"),M5r=o("TFDebertaV2ForMaskedLM"),E5r=o(" (DeBERTa-v2 model)"),C5r=l(),tC=a("li"),$Te=a("strong"),w5r=o("distilbert"),A5r=o(" \u2014 "),RJ=a("a"),L5r=o("TFDistilBertForMaskedLM"),y5r=o(" (DistilBERT model)"),x5r=l(),aC=a("li"),kTe=a("strong"),$5r=o("electra"),k5r=o(" \u2014 "),PJ=a("a"),S5r=o("TFElectraForMaskedLM"),R5r=o(" (ELECTRA model)"),P5r=l(),nC=a("li"),STe=a("strong"),B5r=o("flaubert"),N5r=o(" \u2014 "),BJ=a("a"),I5r=o("TFFlaubertWithLMHeadModel"),q5r=o(" (FlauBERT model)"),j5r=l(),sC=a("li"),RTe=a("strong"),D5r=o("funnel"),G5r=o(" \u2014 "),NJ=a("a"),O5r=o("TFFunnelForMaskedLM"),V5r=o(" (Funnel Transformer model)"),X5r=l(),lC=a("li"),PTe=a("strong"),z5r=o("layoutlm"),Q5r=o(" \u2014 "),IJ=a("a"),W5r=o("TFLayoutLMForMaskedLM"),H5r=o(" (LayoutLM model)"),U5r=l(),iC=a("li"),BTe=a("strong"),J5r=o("longformer"),Y5r=o(" \u2014 "),qJ=a("a"),K5r=o("TFLongformerForMaskedLM"),Z5r=o(" (Longformer model)"),e0r=l(),dC=a("li"),NTe=a("strong"),o0r=o("mobilebert"),r0r=o(" \u2014 "),jJ=a("a"),t0r=o("TFMobileBertForMaskedLM"),a0r=o(" (MobileBERT model)"),n0r=l(),cC=a("li"),ITe=a("strong"),s0r=o("mpnet"),l0r=o(" \u2014 "),DJ=a("a"),i0r=o("TFMPNetForMaskedLM"),d0r=o(" (MPNet model)"),c0r=l(),fC=a("li"),qTe=a("strong"),f0r=o("rembert"),m0r=o(" \u2014 "),GJ=a("a"),g0r=o("TFRemBertForMaskedLM"),h0r=o(" (RemBERT model)"),p0r=l(),mC=a("li"),jTe=a("strong"),_0r=o("roberta"),u0r=o(" \u2014 "),OJ=a("a"),b0r=o("TFRobertaForMaskedLM"),v0r=o(" (RoBERTa model)"),F0r=l(),gC=a("li"),DTe=a("strong"),T0r=o("roformer"),M0r=o(" \u2014 "),VJ=a("a"),E0r=o("TFRoFormerForMaskedLM"),C0r=o(" (RoFormer model)"),w0r=l(),hC=a("li"),GTe=a("strong"),A0r=o("tapas"),L0r=o(" \u2014 "),XJ=a("a"),y0r=o("TFTapasForMaskedLM"),x0r=o(" (TAPAS model)"),$0r=l(),pC=a("li"),OTe=a("strong"),k0r=o("xlm"),S0r=o(" \u2014 "),zJ=a("a"),R0r=o("TFXLMWithLMHeadModel"),P0r=o(" (XLM model)"),B0r=l(),_C=a("li"),VTe=a("strong"),N0r=o("xlm-roberta"),I0r=o(" \u2014 "),QJ=a("a"),q0r=o("TFXLMRobertaForMaskedLM"),j0r=o(" (XLM-RoBERTa model)"),D0r=l(),F(uC.$$.fragment),rXe=l(),bc=a("h2"),bC=a("a"),XTe=a("span"),F(Z9.$$.fragment),G0r=l(),zTe=a("span"),O0r=o("TFAutoModelForSeq2SeqLM"),tXe=l(),sr=a("div"),F(ex.$$.fragment),V0r=l(),vc=a("p"),X0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),WJ=a("a"),z0r=o("from_pretrained()"),Q0r=o(" class method or the "),HJ=a("a"),W0r=o("from_config()"),H0r=o(` class
method.`),U0r=l(),ox=a("p"),J0r=o("This class cannot be instantiated directly using "),QTe=a("code"),Y0r=o("__init__()"),K0r=o(" (throws an error)."),Z0r=l(),Nt=a("div"),F(rx.$$.fragment),ewr=l(),WTe=a("p"),owr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),rwr=l(),Fc=a("p"),twr=o(`Note:
Loading a model from its configuration file does `),HTe=a("strong"),awr=o("not"),nwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UJ=a("a"),swr=o("from_pretrained()"),lwr=o(" to load the model weights."),iwr=l(),F(vC.$$.fragment),dwr=l(),Pr=a("div"),F(tx.$$.fragment),cwr=l(),UTe=a("p"),fwr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),mwr=l(),mn=a("p"),gwr=o("The model class to instantiate is selected based on the "),JTe=a("code"),hwr=o("model_type"),pwr=o(` property of the config object (either
passed as an argument or loaded from `),YTe=a("code"),_wr=o("pretrained_model_name_or_path"),uwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KTe=a("code"),bwr=o("pretrained_model_name_or_path"),vwr=o(":"),Fwr=l(),ye=a("ul"),FC=a("li"),ZTe=a("strong"),Twr=o("bart"),Mwr=o(" \u2014 "),JJ=a("a"),Ewr=o("TFBartForConditionalGeneration"),Cwr=o(" (BART model)"),wwr=l(),TC=a("li"),eMe=a("strong"),Awr=o("blenderbot"),Lwr=o(" \u2014 "),YJ=a("a"),ywr=o("TFBlenderbotForConditionalGeneration"),xwr=o(" (Blenderbot model)"),$wr=l(),MC=a("li"),oMe=a("strong"),kwr=o("blenderbot-small"),Swr=o(" \u2014 "),KJ=a("a"),Rwr=o("TFBlenderbotSmallForConditionalGeneration"),Pwr=o(" (BlenderbotSmall model)"),Bwr=l(),EC=a("li"),rMe=a("strong"),Nwr=o("encoder-decoder"),Iwr=o(" \u2014 "),ZJ=a("a"),qwr=o("TFEncoderDecoderModel"),jwr=o(" (Encoder decoder model)"),Dwr=l(),CC=a("li"),tMe=a("strong"),Gwr=o("led"),Owr=o(" \u2014 "),eY=a("a"),Vwr=o("TFLEDForConditionalGeneration"),Xwr=o(" (LED model)"),zwr=l(),wC=a("li"),aMe=a("strong"),Qwr=o("marian"),Wwr=o(" \u2014 "),oY=a("a"),Hwr=o("TFMarianMTModel"),Uwr=o(" (Marian model)"),Jwr=l(),AC=a("li"),nMe=a("strong"),Ywr=o("mbart"),Kwr=o(" \u2014 "),rY=a("a"),Zwr=o("TFMBartForConditionalGeneration"),eAr=o(" (mBART model)"),oAr=l(),LC=a("li"),sMe=a("strong"),rAr=o("mt5"),tAr=o(" \u2014 "),tY=a("a"),aAr=o("TFMT5ForConditionalGeneration"),nAr=o(" (MT5 model)"),sAr=l(),yC=a("li"),lMe=a("strong"),lAr=o("pegasus"),iAr=o(" \u2014 "),aY=a("a"),dAr=o("TFPegasusForConditionalGeneration"),cAr=o(" (Pegasus model)"),fAr=l(),xC=a("li"),iMe=a("strong"),mAr=o("t5"),gAr=o(" \u2014 "),nY=a("a"),hAr=o("TFT5ForConditionalGeneration"),pAr=o(" (T5 model)"),_Ar=l(),F($C.$$.fragment),aXe=l(),Tc=a("h2"),kC=a("a"),dMe=a("span"),F(ax.$$.fragment),uAr=l(),cMe=a("span"),bAr=o("TFAutoModelForSequenceClassification"),nXe=l(),lr=a("div"),F(nx.$$.fragment),vAr=l(),Mc=a("p"),FAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),sY=a("a"),TAr=o("from_pretrained()"),MAr=o(" class method or the "),lY=a("a"),EAr=o("from_config()"),CAr=o(` class
method.`),wAr=l(),sx=a("p"),AAr=o("This class cannot be instantiated directly using "),fMe=a("code"),LAr=o("__init__()"),yAr=o(" (throws an error)."),xAr=l(),It=a("div"),F(lx.$$.fragment),$Ar=l(),mMe=a("p"),kAr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),SAr=l(),Ec=a("p"),RAr=o(`Note:
Loading a model from its configuration file does `),gMe=a("strong"),PAr=o("not"),BAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=a("a"),NAr=o("from_pretrained()"),IAr=o(" to load the model weights."),qAr=l(),F(SC.$$.fragment),jAr=l(),Br=a("div"),F(ix.$$.fragment),DAr=l(),hMe=a("p"),GAr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),OAr=l(),gn=a("p"),VAr=o("The model class to instantiate is selected based on the "),pMe=a("code"),XAr=o("model_type"),zAr=o(` property of the config object (either
passed as an argument or loaded from `),_Me=a("code"),QAr=o("pretrained_model_name_or_path"),WAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uMe=a("code"),HAr=o("pretrained_model_name_or_path"),UAr=o(":"),JAr=l(),te=a("ul"),RC=a("li"),bMe=a("strong"),YAr=o("albert"),KAr=o(" \u2014 "),dY=a("a"),ZAr=o("TFAlbertForSequenceClassification"),e6r=o(" (ALBERT model)"),o6r=l(),PC=a("li"),vMe=a("strong"),r6r=o("bert"),t6r=o(" \u2014 "),cY=a("a"),a6r=o("TFBertForSequenceClassification"),n6r=o(" (BERT model)"),s6r=l(),BC=a("li"),FMe=a("strong"),l6r=o("camembert"),i6r=o(" \u2014 "),fY=a("a"),d6r=o("TFCamembertForSequenceClassification"),c6r=o(" (CamemBERT model)"),f6r=l(),NC=a("li"),TMe=a("strong"),m6r=o("convbert"),g6r=o(" \u2014 "),mY=a("a"),h6r=o("TFConvBertForSequenceClassification"),p6r=o(" (ConvBERT model)"),_6r=l(),IC=a("li"),MMe=a("strong"),u6r=o("ctrl"),b6r=o(" \u2014 "),gY=a("a"),v6r=o("TFCTRLForSequenceClassification"),F6r=o(" (CTRL model)"),T6r=l(),qC=a("li"),EMe=a("strong"),M6r=o("deberta"),E6r=o(" \u2014 "),hY=a("a"),C6r=o("TFDebertaForSequenceClassification"),w6r=o(" (DeBERTa model)"),A6r=l(),jC=a("li"),CMe=a("strong"),L6r=o("deberta-v2"),y6r=o(" \u2014 "),pY=a("a"),x6r=o("TFDebertaV2ForSequenceClassification"),$6r=o(" (DeBERTa-v2 model)"),k6r=l(),DC=a("li"),wMe=a("strong"),S6r=o("distilbert"),R6r=o(" \u2014 "),_Y=a("a"),P6r=o("TFDistilBertForSequenceClassification"),B6r=o(" (DistilBERT model)"),N6r=l(),GC=a("li"),AMe=a("strong"),I6r=o("electra"),q6r=o(" \u2014 "),uY=a("a"),j6r=o("TFElectraForSequenceClassification"),D6r=o(" (ELECTRA model)"),G6r=l(),OC=a("li"),LMe=a("strong"),O6r=o("flaubert"),V6r=o(" \u2014 "),bY=a("a"),X6r=o("TFFlaubertForSequenceClassification"),z6r=o(" (FlauBERT model)"),Q6r=l(),VC=a("li"),yMe=a("strong"),W6r=o("funnel"),H6r=o(" \u2014 "),vY=a("a"),U6r=o("TFFunnelForSequenceClassification"),J6r=o(" (Funnel Transformer model)"),Y6r=l(),XC=a("li"),xMe=a("strong"),K6r=o("gpt2"),Z6r=o(" \u2014 "),FY=a("a"),eLr=o("TFGPT2ForSequenceClassification"),oLr=o(" (OpenAI GPT-2 model)"),rLr=l(),zC=a("li"),$Me=a("strong"),tLr=o("gptj"),aLr=o(" \u2014 "),TY=a("a"),nLr=o("TFGPTJForSequenceClassification"),sLr=o(" (GPT-J model)"),lLr=l(),QC=a("li"),kMe=a("strong"),iLr=o("layoutlm"),dLr=o(" \u2014 "),MY=a("a"),cLr=o("TFLayoutLMForSequenceClassification"),fLr=o(" (LayoutLM model)"),mLr=l(),WC=a("li"),SMe=a("strong"),gLr=o("longformer"),hLr=o(" \u2014 "),EY=a("a"),pLr=o("TFLongformerForSequenceClassification"),_Lr=o(" (Longformer model)"),uLr=l(),HC=a("li"),RMe=a("strong"),bLr=o("mobilebert"),vLr=o(" \u2014 "),CY=a("a"),FLr=o("TFMobileBertForSequenceClassification"),TLr=o(" (MobileBERT model)"),MLr=l(),UC=a("li"),PMe=a("strong"),ELr=o("mpnet"),CLr=o(" \u2014 "),wY=a("a"),wLr=o("TFMPNetForSequenceClassification"),ALr=o(" (MPNet model)"),LLr=l(),JC=a("li"),BMe=a("strong"),yLr=o("openai-gpt"),xLr=o(" \u2014 "),AY=a("a"),$Lr=o("TFOpenAIGPTForSequenceClassification"),kLr=o(" (OpenAI GPT model)"),SLr=l(),YC=a("li"),NMe=a("strong"),RLr=o("rembert"),PLr=o(" \u2014 "),LY=a("a"),BLr=o("TFRemBertForSequenceClassification"),NLr=o(" (RemBERT model)"),ILr=l(),KC=a("li"),IMe=a("strong"),qLr=o("roberta"),jLr=o(" \u2014 "),yY=a("a"),DLr=o("TFRobertaForSequenceClassification"),GLr=o(" (RoBERTa model)"),OLr=l(),ZC=a("li"),qMe=a("strong"),VLr=o("roformer"),XLr=o(" \u2014 "),xY=a("a"),zLr=o("TFRoFormerForSequenceClassification"),QLr=o(" (RoFormer model)"),WLr=l(),e3=a("li"),jMe=a("strong"),HLr=o("tapas"),ULr=o(" \u2014 "),$Y=a("a"),JLr=o("TFTapasForSequenceClassification"),YLr=o(" (TAPAS model)"),KLr=l(),o3=a("li"),DMe=a("strong"),ZLr=o("transfo-xl"),eyr=o(" \u2014 "),kY=a("a"),oyr=o("TFTransfoXLForSequenceClassification"),ryr=o(" (Transformer-XL model)"),tyr=l(),r3=a("li"),GMe=a("strong"),ayr=o("xlm"),nyr=o(" \u2014 "),SY=a("a"),syr=o("TFXLMForSequenceClassification"),lyr=o(" (XLM model)"),iyr=l(),t3=a("li"),OMe=a("strong"),dyr=o("xlm-roberta"),cyr=o(" \u2014 "),RY=a("a"),fyr=o("TFXLMRobertaForSequenceClassification"),myr=o(" (XLM-RoBERTa model)"),gyr=l(),a3=a("li"),VMe=a("strong"),hyr=o("xlnet"),pyr=o(" \u2014 "),PY=a("a"),_yr=o("TFXLNetForSequenceClassification"),uyr=o(" (XLNet model)"),byr=l(),F(n3.$$.fragment),sXe=l(),Cc=a("h2"),s3=a("a"),XMe=a("span"),F(dx.$$.fragment),vyr=l(),zMe=a("span"),Fyr=o("TFAutoModelForMultipleChoice"),lXe=l(),ir=a("div"),F(cx.$$.fragment),Tyr=l(),wc=a("p"),Myr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),BY=a("a"),Eyr=o("from_pretrained()"),Cyr=o(" class method or the "),NY=a("a"),wyr=o("from_config()"),Ayr=o(` class
method.`),Lyr=l(),fx=a("p"),yyr=o("This class cannot be instantiated directly using "),QMe=a("code"),xyr=o("__init__()"),$yr=o(" (throws an error)."),kyr=l(),qt=a("div"),F(mx.$$.fragment),Syr=l(),WMe=a("p"),Ryr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Pyr=l(),Ac=a("p"),Byr=o(`Note:
Loading a model from its configuration file does `),HMe=a("strong"),Nyr=o("not"),Iyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),qyr=o("from_pretrained()"),jyr=o(" to load the model weights."),Dyr=l(),F(l3.$$.fragment),Gyr=l(),Nr=a("div"),F(gx.$$.fragment),Oyr=l(),UMe=a("p"),Vyr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Xyr=l(),hn=a("p"),zyr=o("The model class to instantiate is selected based on the "),JMe=a("code"),Qyr=o("model_type"),Wyr=o(` property of the config object (either
passed as an argument or loaded from `),YMe=a("code"),Hyr=o("pretrained_model_name_or_path"),Uyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KMe=a("code"),Jyr=o("pretrained_model_name_or_path"),Yyr=o(":"),Kyr=l(),_e=a("ul"),i3=a("li"),ZMe=a("strong"),Zyr=o("albert"),e8r=o(" \u2014 "),qY=a("a"),o8r=o("TFAlbertForMultipleChoice"),r8r=o(" (ALBERT model)"),t8r=l(),d3=a("li"),eEe=a("strong"),a8r=o("bert"),n8r=o(" \u2014 "),jY=a("a"),s8r=o("TFBertForMultipleChoice"),l8r=o(" (BERT model)"),i8r=l(),c3=a("li"),oEe=a("strong"),d8r=o("camembert"),c8r=o(" \u2014 "),DY=a("a"),f8r=o("TFCamembertForMultipleChoice"),m8r=o(" (CamemBERT model)"),g8r=l(),f3=a("li"),rEe=a("strong"),h8r=o("convbert"),p8r=o(" \u2014 "),GY=a("a"),_8r=o("TFConvBertForMultipleChoice"),u8r=o(" (ConvBERT model)"),b8r=l(),m3=a("li"),tEe=a("strong"),v8r=o("distilbert"),F8r=o(" \u2014 "),OY=a("a"),T8r=o("TFDistilBertForMultipleChoice"),M8r=o(" (DistilBERT model)"),E8r=l(),g3=a("li"),aEe=a("strong"),C8r=o("electra"),w8r=o(" \u2014 "),VY=a("a"),A8r=o("TFElectraForMultipleChoice"),L8r=o(" (ELECTRA model)"),y8r=l(),h3=a("li"),nEe=a("strong"),x8r=o("flaubert"),$8r=o(" \u2014 "),XY=a("a"),k8r=o("TFFlaubertForMultipleChoice"),S8r=o(" (FlauBERT model)"),R8r=l(),p3=a("li"),sEe=a("strong"),P8r=o("funnel"),B8r=o(" \u2014 "),zY=a("a"),N8r=o("TFFunnelForMultipleChoice"),I8r=o(" (Funnel Transformer model)"),q8r=l(),_3=a("li"),lEe=a("strong"),j8r=o("longformer"),D8r=o(" \u2014 "),QY=a("a"),G8r=o("TFLongformerForMultipleChoice"),O8r=o(" (Longformer model)"),V8r=l(),u3=a("li"),iEe=a("strong"),X8r=o("mobilebert"),z8r=o(" \u2014 "),WY=a("a"),Q8r=o("TFMobileBertForMultipleChoice"),W8r=o(" (MobileBERT model)"),H8r=l(),b3=a("li"),dEe=a("strong"),U8r=o("mpnet"),J8r=o(" \u2014 "),HY=a("a"),Y8r=o("TFMPNetForMultipleChoice"),K8r=o(" (MPNet model)"),Z8r=l(),v3=a("li"),cEe=a("strong"),e9r=o("rembert"),o9r=o(" \u2014 "),UY=a("a"),r9r=o("TFRemBertForMultipleChoice"),t9r=o(" (RemBERT model)"),a9r=l(),F3=a("li"),fEe=a("strong"),n9r=o("roberta"),s9r=o(" \u2014 "),JY=a("a"),l9r=o("TFRobertaForMultipleChoice"),i9r=o(" (RoBERTa model)"),d9r=l(),T3=a("li"),mEe=a("strong"),c9r=o("roformer"),f9r=o(" \u2014 "),YY=a("a"),m9r=o("TFRoFormerForMultipleChoice"),g9r=o(" (RoFormer model)"),h9r=l(),M3=a("li"),gEe=a("strong"),p9r=o("xlm"),_9r=o(" \u2014 "),KY=a("a"),u9r=o("TFXLMForMultipleChoice"),b9r=o(" (XLM model)"),v9r=l(),E3=a("li"),hEe=a("strong"),F9r=o("xlm-roberta"),T9r=o(" \u2014 "),ZY=a("a"),M9r=o("TFXLMRobertaForMultipleChoice"),E9r=o(" (XLM-RoBERTa model)"),C9r=l(),C3=a("li"),pEe=a("strong"),w9r=o("xlnet"),A9r=o(" \u2014 "),eK=a("a"),L9r=o("TFXLNetForMultipleChoice"),y9r=o(" (XLNet model)"),x9r=l(),F(w3.$$.fragment),iXe=l(),Lc=a("h2"),A3=a("a"),_Ee=a("span"),F(hx.$$.fragment),$9r=l(),uEe=a("span"),k9r=o("TFAutoModelForNextSentencePrediction"),dXe=l(),dr=a("div"),F(px.$$.fragment),S9r=l(),yc=a("p"),R9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),oK=a("a"),P9r=o("from_pretrained()"),B9r=o(" class method or the "),rK=a("a"),N9r=o("from_config()"),I9r=o(` class
method.`),q9r=l(),_x=a("p"),j9r=o("This class cannot be instantiated directly using "),bEe=a("code"),D9r=o("__init__()"),G9r=o(" (throws an error)."),O9r=l(),jt=a("div"),F(ux.$$.fragment),V9r=l(),vEe=a("p"),X9r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),z9r=l(),xc=a("p"),Q9r=o(`Note:
Loading a model from its configuration file does `),FEe=a("strong"),W9r=o("not"),H9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=a("a"),U9r=o("from_pretrained()"),J9r=o(" to load the model weights."),Y9r=l(),F(L3.$$.fragment),K9r=l(),Ir=a("div"),F(bx.$$.fragment),Z9r=l(),TEe=a("p"),exr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),oxr=l(),pn=a("p"),rxr=o("The model class to instantiate is selected based on the "),MEe=a("code"),txr=o("model_type"),axr=o(` property of the config object (either
passed as an argument or loaded from `),EEe=a("code"),nxr=o("pretrained_model_name_or_path"),sxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CEe=a("code"),lxr=o("pretrained_model_name_or_path"),ixr=o(":"),dxr=l(),vx=a("ul"),y3=a("li"),wEe=a("strong"),cxr=o("bert"),fxr=o(" \u2014 "),aK=a("a"),mxr=o("TFBertForNextSentencePrediction"),gxr=o(" (BERT model)"),hxr=l(),x3=a("li"),AEe=a("strong"),pxr=o("mobilebert"),_xr=o(" \u2014 "),nK=a("a"),uxr=o("TFMobileBertForNextSentencePrediction"),bxr=o(" (MobileBERT model)"),vxr=l(),F($3.$$.fragment),cXe=l(),$c=a("h2"),k3=a("a"),LEe=a("span"),F(Fx.$$.fragment),Fxr=l(),yEe=a("span"),Txr=o("TFAutoModelForTableQuestionAnswering"),fXe=l(),cr=a("div"),F(Tx.$$.fragment),Mxr=l(),kc=a("p"),Exr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),sK=a("a"),Cxr=o("from_pretrained()"),wxr=o(" class method or the "),lK=a("a"),Axr=o("from_config()"),Lxr=o(` class
method.`),yxr=l(),Mx=a("p"),xxr=o("This class cannot be instantiated directly using "),xEe=a("code"),$xr=o("__init__()"),kxr=o(" (throws an error)."),Sxr=l(),Dt=a("div"),F(Ex.$$.fragment),Rxr=l(),$Ee=a("p"),Pxr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Bxr=l(),Sc=a("p"),Nxr=o(`Note:
Loading a model from its configuration file does `),kEe=a("strong"),Ixr=o("not"),qxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iK=a("a"),jxr=o("from_pretrained()"),Dxr=o(" to load the model weights."),Gxr=l(),F(S3.$$.fragment),Oxr=l(),qr=a("div"),F(Cx.$$.fragment),Vxr=l(),SEe=a("p"),Xxr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),zxr=l(),_n=a("p"),Qxr=o("The model class to instantiate is selected based on the "),REe=a("code"),Wxr=o("model_type"),Hxr=o(` property of the config object (either
passed as an argument or loaded from `),PEe=a("code"),Uxr=o("pretrained_model_name_or_path"),Jxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BEe=a("code"),Yxr=o("pretrained_model_name_or_path"),Kxr=o(":"),Zxr=l(),NEe=a("ul"),R3=a("li"),IEe=a("strong"),e$r=o("tapas"),o$r=o(" \u2014 "),dK=a("a"),r$r=o("TFTapasForQuestionAnswering"),t$r=o(" (TAPAS model)"),a$r=l(),F(P3.$$.fragment),mXe=l(),Rc=a("h2"),B3=a("a"),qEe=a("span"),F(wx.$$.fragment),n$r=l(),jEe=a("span"),s$r=o("TFAutoModelForTokenClassification"),gXe=l(),fr=a("div"),F(Ax.$$.fragment),l$r=l(),Pc=a("p"),i$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),cK=a("a"),d$r=o("from_pretrained()"),c$r=o(" class method or the "),fK=a("a"),f$r=o("from_config()"),m$r=o(` class
method.`),g$r=l(),Lx=a("p"),h$r=o("This class cannot be instantiated directly using "),DEe=a("code"),p$r=o("__init__()"),_$r=o(" (throws an error)."),u$r=l(),Gt=a("div"),F(yx.$$.fragment),b$r=l(),GEe=a("p"),v$r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),F$r=l(),Bc=a("p"),T$r=o(`Note:
Loading a model from its configuration file does `),OEe=a("strong"),M$r=o("not"),E$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mK=a("a"),C$r=o("from_pretrained()"),w$r=o(" to load the model weights."),A$r=l(),F(N3.$$.fragment),L$r=l(),jr=a("div"),F(xx.$$.fragment),y$r=l(),VEe=a("p"),x$r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),$$r=l(),un=a("p"),k$r=o("The model class to instantiate is selected based on the "),XEe=a("code"),S$r=o("model_type"),R$r=o(` property of the config object (either
passed as an argument or loaded from `),zEe=a("code"),P$r=o("pretrained_model_name_or_path"),B$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=a("code"),N$r=o("pretrained_model_name_or_path"),I$r=o(":"),q$r=l(),de=a("ul"),I3=a("li"),WEe=a("strong"),j$r=o("albert"),D$r=o(" \u2014 "),gK=a("a"),G$r=o("TFAlbertForTokenClassification"),O$r=o(" (ALBERT model)"),V$r=l(),q3=a("li"),HEe=a("strong"),X$r=o("bert"),z$r=o(" \u2014 "),hK=a("a"),Q$r=o("TFBertForTokenClassification"),W$r=o(" (BERT model)"),H$r=l(),j3=a("li"),UEe=a("strong"),U$r=o("camembert"),J$r=o(" \u2014 "),pK=a("a"),Y$r=o("TFCamembertForTokenClassification"),K$r=o(" (CamemBERT model)"),Z$r=l(),D3=a("li"),JEe=a("strong"),ekr=o("convbert"),okr=o(" \u2014 "),_K=a("a"),rkr=o("TFConvBertForTokenClassification"),tkr=o(" (ConvBERT model)"),akr=l(),G3=a("li"),YEe=a("strong"),nkr=o("deberta"),skr=o(" \u2014 "),uK=a("a"),lkr=o("TFDebertaForTokenClassification"),ikr=o(" (DeBERTa model)"),dkr=l(),O3=a("li"),KEe=a("strong"),ckr=o("deberta-v2"),fkr=o(" \u2014 "),bK=a("a"),mkr=o("TFDebertaV2ForTokenClassification"),gkr=o(" (DeBERTa-v2 model)"),hkr=l(),V3=a("li"),ZEe=a("strong"),pkr=o("distilbert"),_kr=o(" \u2014 "),vK=a("a"),ukr=o("TFDistilBertForTokenClassification"),bkr=o(" (DistilBERT model)"),vkr=l(),X3=a("li"),eCe=a("strong"),Fkr=o("electra"),Tkr=o(" \u2014 "),FK=a("a"),Mkr=o("TFElectraForTokenClassification"),Ekr=o(" (ELECTRA model)"),Ckr=l(),z3=a("li"),oCe=a("strong"),wkr=o("flaubert"),Akr=o(" \u2014 "),TK=a("a"),Lkr=o("TFFlaubertForTokenClassification"),ykr=o(" (FlauBERT model)"),xkr=l(),Q3=a("li"),rCe=a("strong"),$kr=o("funnel"),kkr=o(" \u2014 "),MK=a("a"),Skr=o("TFFunnelForTokenClassification"),Rkr=o(" (Funnel Transformer model)"),Pkr=l(),W3=a("li"),tCe=a("strong"),Bkr=o("layoutlm"),Nkr=o(" \u2014 "),EK=a("a"),Ikr=o("TFLayoutLMForTokenClassification"),qkr=o(" (LayoutLM model)"),jkr=l(),H3=a("li"),aCe=a("strong"),Dkr=o("longformer"),Gkr=o(" \u2014 "),CK=a("a"),Okr=o("TFLongformerForTokenClassification"),Vkr=o(" (Longformer model)"),Xkr=l(),U3=a("li"),nCe=a("strong"),zkr=o("mobilebert"),Qkr=o(" \u2014 "),wK=a("a"),Wkr=o("TFMobileBertForTokenClassification"),Hkr=o(" (MobileBERT model)"),Ukr=l(),J3=a("li"),sCe=a("strong"),Jkr=o("mpnet"),Ykr=o(" \u2014 "),AK=a("a"),Kkr=o("TFMPNetForTokenClassification"),Zkr=o(" (MPNet model)"),eSr=l(),Y3=a("li"),lCe=a("strong"),oSr=o("rembert"),rSr=o(" \u2014 "),LK=a("a"),tSr=o("TFRemBertForTokenClassification"),aSr=o(" (RemBERT model)"),nSr=l(),K3=a("li"),iCe=a("strong"),sSr=o("roberta"),lSr=o(" \u2014 "),yK=a("a"),iSr=o("TFRobertaForTokenClassification"),dSr=o(" (RoBERTa model)"),cSr=l(),Z3=a("li"),dCe=a("strong"),fSr=o("roformer"),mSr=o(" \u2014 "),xK=a("a"),gSr=o("TFRoFormerForTokenClassification"),hSr=o(" (RoFormer model)"),pSr=l(),e5=a("li"),cCe=a("strong"),_Sr=o("xlm"),uSr=o(" \u2014 "),$K=a("a"),bSr=o("TFXLMForTokenClassification"),vSr=o(" (XLM model)"),FSr=l(),o5=a("li"),fCe=a("strong"),TSr=o("xlm-roberta"),MSr=o(" \u2014 "),kK=a("a"),ESr=o("TFXLMRobertaForTokenClassification"),CSr=o(" (XLM-RoBERTa model)"),wSr=l(),r5=a("li"),mCe=a("strong"),ASr=o("xlnet"),LSr=o(" \u2014 "),SK=a("a"),ySr=o("TFXLNetForTokenClassification"),xSr=o(" (XLNet model)"),$Sr=l(),F(t5.$$.fragment),hXe=l(),Nc=a("h2"),a5=a("a"),gCe=a("span"),F($x.$$.fragment),kSr=l(),hCe=a("span"),SSr=o("TFAutoModelForQuestionAnswering"),pXe=l(),mr=a("div"),F(kx.$$.fragment),RSr=l(),Ic=a("p"),PSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),RK=a("a"),BSr=o("from_pretrained()"),NSr=o(" class method or the "),PK=a("a"),ISr=o("from_config()"),qSr=o(` class
method.`),jSr=l(),Sx=a("p"),DSr=o("This class cannot be instantiated directly using "),pCe=a("code"),GSr=o("__init__()"),OSr=o(" (throws an error)."),VSr=l(),Ot=a("div"),F(Rx.$$.fragment),XSr=l(),_Ce=a("p"),zSr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),QSr=l(),qc=a("p"),WSr=o(`Note:
Loading a model from its configuration file does `),uCe=a("strong"),HSr=o("not"),USr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BK=a("a"),JSr=o("from_pretrained()"),YSr=o(" to load the model weights."),KSr=l(),F(n5.$$.fragment),ZSr=l(),Dr=a("div"),F(Px.$$.fragment),eRr=l(),bCe=a("p"),oRr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),rRr=l(),bn=a("p"),tRr=o("The model class to instantiate is selected based on the "),vCe=a("code"),aRr=o("model_type"),nRr=o(` property of the config object (either
passed as an argument or loaded from `),FCe=a("code"),sRr=o("pretrained_model_name_or_path"),lRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=a("code"),iRr=o("pretrained_model_name_or_path"),dRr=o(":"),cRr=l(),ce=a("ul"),s5=a("li"),MCe=a("strong"),fRr=o("albert"),mRr=o(" \u2014 "),NK=a("a"),gRr=o("TFAlbertForQuestionAnswering"),hRr=o(" (ALBERT model)"),pRr=l(),l5=a("li"),ECe=a("strong"),_Rr=o("bert"),uRr=o(" \u2014 "),IK=a("a"),bRr=o("TFBertForQuestionAnswering"),vRr=o(" (BERT model)"),FRr=l(),i5=a("li"),CCe=a("strong"),TRr=o("camembert"),MRr=o(" \u2014 "),qK=a("a"),ERr=o("TFCamembertForQuestionAnswering"),CRr=o(" (CamemBERT model)"),wRr=l(),d5=a("li"),wCe=a("strong"),ARr=o("convbert"),LRr=o(" \u2014 "),jK=a("a"),yRr=o("TFConvBertForQuestionAnswering"),xRr=o(" (ConvBERT model)"),$Rr=l(),c5=a("li"),ACe=a("strong"),kRr=o("deberta"),SRr=o(" \u2014 "),DK=a("a"),RRr=o("TFDebertaForQuestionAnswering"),PRr=o(" (DeBERTa model)"),BRr=l(),f5=a("li"),LCe=a("strong"),NRr=o("deberta-v2"),IRr=o(" \u2014 "),GK=a("a"),qRr=o("TFDebertaV2ForQuestionAnswering"),jRr=o(" (DeBERTa-v2 model)"),DRr=l(),m5=a("li"),yCe=a("strong"),GRr=o("distilbert"),ORr=o(" \u2014 "),OK=a("a"),VRr=o("TFDistilBertForQuestionAnswering"),XRr=o(" (DistilBERT model)"),zRr=l(),g5=a("li"),xCe=a("strong"),QRr=o("electra"),WRr=o(" \u2014 "),VK=a("a"),HRr=o("TFElectraForQuestionAnswering"),URr=o(" (ELECTRA model)"),JRr=l(),h5=a("li"),$Ce=a("strong"),YRr=o("flaubert"),KRr=o(" \u2014 "),XK=a("a"),ZRr=o("TFFlaubertForQuestionAnsweringSimple"),ePr=o(" (FlauBERT model)"),oPr=l(),p5=a("li"),kCe=a("strong"),rPr=o("funnel"),tPr=o(" \u2014 "),zK=a("a"),aPr=o("TFFunnelForQuestionAnswering"),nPr=o(" (Funnel Transformer model)"),sPr=l(),_5=a("li"),SCe=a("strong"),lPr=o("gptj"),iPr=o(" \u2014 "),QK=a("a"),dPr=o("TFGPTJForQuestionAnswering"),cPr=o(" (GPT-J model)"),fPr=l(),u5=a("li"),RCe=a("strong"),mPr=o("longformer"),gPr=o(" \u2014 "),WK=a("a"),hPr=o("TFLongformerForQuestionAnswering"),pPr=o(" (Longformer model)"),_Pr=l(),b5=a("li"),PCe=a("strong"),uPr=o("mobilebert"),bPr=o(" \u2014 "),HK=a("a"),vPr=o("TFMobileBertForQuestionAnswering"),FPr=o(" (MobileBERT model)"),TPr=l(),v5=a("li"),BCe=a("strong"),MPr=o("mpnet"),EPr=o(" \u2014 "),UK=a("a"),CPr=o("TFMPNetForQuestionAnswering"),wPr=o(" (MPNet model)"),APr=l(),F5=a("li"),NCe=a("strong"),LPr=o("rembert"),yPr=o(" \u2014 "),JK=a("a"),xPr=o("TFRemBertForQuestionAnswering"),$Pr=o(" (RemBERT model)"),kPr=l(),T5=a("li"),ICe=a("strong"),SPr=o("roberta"),RPr=o(" \u2014 "),YK=a("a"),PPr=o("TFRobertaForQuestionAnswering"),BPr=o(" (RoBERTa model)"),NPr=l(),M5=a("li"),qCe=a("strong"),IPr=o("roformer"),qPr=o(" \u2014 "),KK=a("a"),jPr=o("TFRoFormerForQuestionAnswering"),DPr=o(" (RoFormer model)"),GPr=l(),E5=a("li"),jCe=a("strong"),OPr=o("xlm"),VPr=o(" \u2014 "),ZK=a("a"),XPr=o("TFXLMForQuestionAnsweringSimple"),zPr=o(" (XLM model)"),QPr=l(),C5=a("li"),DCe=a("strong"),WPr=o("xlm-roberta"),HPr=o(" \u2014 "),eZ=a("a"),UPr=o("TFXLMRobertaForQuestionAnswering"),JPr=o(" (XLM-RoBERTa model)"),YPr=l(),w5=a("li"),GCe=a("strong"),KPr=o("xlnet"),ZPr=o(" \u2014 "),oZ=a("a"),eBr=o("TFXLNetForQuestionAnsweringSimple"),oBr=o(" (XLNet model)"),rBr=l(),F(A5.$$.fragment),_Xe=l(),jc=a("h2"),L5=a("a"),OCe=a("span"),F(Bx.$$.fragment),tBr=l(),VCe=a("span"),aBr=o("TFAutoModelForVision2Seq"),uXe=l(),gr=a("div"),F(Nx.$$.fragment),nBr=l(),Dc=a("p"),sBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),rZ=a("a"),lBr=o("from_pretrained()"),iBr=o(" class method or the "),tZ=a("a"),dBr=o("from_config()"),cBr=o(` class
method.`),fBr=l(),Ix=a("p"),mBr=o("This class cannot be instantiated directly using "),XCe=a("code"),gBr=o("__init__()"),hBr=o(" (throws an error)."),pBr=l(),Vt=a("div"),F(qx.$$.fragment),_Br=l(),zCe=a("p"),uBr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),bBr=l(),Gc=a("p"),vBr=o(`Note:
Loading a model from its configuration file does `),QCe=a("strong"),FBr=o("not"),TBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aZ=a("a"),MBr=o("from_pretrained()"),EBr=o(" to load the model weights."),CBr=l(),F(y5.$$.fragment),wBr=l(),Gr=a("div"),F(jx.$$.fragment),ABr=l(),WCe=a("p"),LBr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),yBr=l(),vn=a("p"),xBr=o("The model class to instantiate is selected based on the "),HCe=a("code"),$Br=o("model_type"),kBr=o(` property of the config object (either
passed as an argument or loaded from `),UCe=a("code"),SBr=o("pretrained_model_name_or_path"),RBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JCe=a("code"),PBr=o("pretrained_model_name_or_path"),BBr=o(":"),NBr=l(),YCe=a("ul"),x5=a("li"),KCe=a("strong"),IBr=o("vision-encoder-decoder"),qBr=o(" \u2014 "),nZ=a("a"),jBr=o("TFVisionEncoderDecoderModel"),DBr=o(" (Vision Encoder decoder model)"),GBr=l(),F($5.$$.fragment),bXe=l(),Oc=a("h2"),k5=a("a"),ZCe=a("span"),F(Dx.$$.fragment),OBr=l(),e3e=a("span"),VBr=o("TFAutoModelForSpeechSeq2Seq"),vXe=l(),hr=a("div"),F(Gx.$$.fragment),XBr=l(),Vc=a("p"),zBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),sZ=a("a"),QBr=o("from_pretrained()"),WBr=o(" class method or the "),lZ=a("a"),HBr=o("from_config()"),UBr=o(` class
method.`),JBr=l(),Ox=a("p"),YBr=o("This class cannot be instantiated directly using "),o3e=a("code"),KBr=o("__init__()"),ZBr=o(" (throws an error)."),eNr=l(),Xt=a("div"),F(Vx.$$.fragment),oNr=l(),r3e=a("p"),rNr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),tNr=l(),Xc=a("p"),aNr=o(`Note:
Loading a model from its configuration file does `),t3e=a("strong"),nNr=o("not"),sNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iZ=a("a"),lNr=o("from_pretrained()"),iNr=o(" to load the model weights."),dNr=l(),F(S5.$$.fragment),cNr=l(),Or=a("div"),F(Xx.$$.fragment),fNr=l(),a3e=a("p"),mNr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),gNr=l(),Fn=a("p"),hNr=o("The model class to instantiate is selected based on the "),n3e=a("code"),pNr=o("model_type"),_Nr=o(` property of the config object (either
passed as an argument or loaded from `),s3e=a("code"),uNr=o("pretrained_model_name_or_path"),bNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l3e=a("code"),vNr=o("pretrained_model_name_or_path"),FNr=o(":"),TNr=l(),i3e=a("ul"),R5=a("li"),d3e=a("strong"),MNr=o("speech_to_text"),ENr=o(" \u2014 "),dZ=a("a"),CNr=o("TFSpeech2TextForConditionalGeneration"),wNr=o(" (Speech2Text model)"),ANr=l(),F(P5.$$.fragment),FXe=l(),zc=a("h2"),B5=a("a"),c3e=a("span"),F(zx.$$.fragment),LNr=l(),f3e=a("span"),yNr=o("FlaxAutoModel"),TXe=l(),pr=a("div"),F(Qx.$$.fragment),xNr=l(),Qc=a("p"),$Nr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),cZ=a("a"),kNr=o("from_pretrained()"),SNr=o(" class method or the "),fZ=a("a"),RNr=o("from_config()"),PNr=o(` class
method.`),BNr=l(),Wx=a("p"),NNr=o("This class cannot be instantiated directly using "),m3e=a("code"),INr=o("__init__()"),qNr=o(" (throws an error)."),jNr=l(),zt=a("div"),F(Hx.$$.fragment),DNr=l(),g3e=a("p"),GNr=o("Instantiates one of the base model classes of the library from a configuration."),ONr=l(),Wc=a("p"),VNr=o(`Note:
Loading a model from its configuration file does `),h3e=a("strong"),XNr=o("not"),zNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=a("a"),QNr=o("from_pretrained()"),WNr=o(" to load the model weights."),HNr=l(),F(N5.$$.fragment),UNr=l(),Vr=a("div"),F(Ux.$$.fragment),JNr=l(),p3e=a("p"),YNr=o("Instantiate one of the base model classes of the library from a pretrained model."),KNr=l(),Tn=a("p"),ZNr=o("The model class to instantiate is selected based on the "),_3e=a("code"),eIr=o("model_type"),oIr=o(` property of the config object (either
passed as an argument or loaded from `),u3e=a("code"),rIr=o("pretrained_model_name_or_path"),tIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b3e=a("code"),aIr=o("pretrained_model_name_or_path"),nIr=o(":"),sIr=l(),oe=a("ul"),I5=a("li"),v3e=a("strong"),lIr=o("albert"),iIr=o(" \u2014 "),gZ=a("a"),dIr=o("FlaxAlbertModel"),cIr=o(" (ALBERT model)"),fIr=l(),q5=a("li"),F3e=a("strong"),mIr=o("bart"),gIr=o(" \u2014 "),hZ=a("a"),hIr=o("FlaxBartModel"),pIr=o(" (BART model)"),_Ir=l(),j5=a("li"),T3e=a("strong"),uIr=o("beit"),bIr=o(" \u2014 "),pZ=a("a"),vIr=o("FlaxBeitModel"),FIr=o(" (BEiT model)"),TIr=l(),D5=a("li"),M3e=a("strong"),MIr=o("bert"),EIr=o(" \u2014 "),_Z=a("a"),CIr=o("FlaxBertModel"),wIr=o(" (BERT model)"),AIr=l(),G5=a("li"),E3e=a("strong"),LIr=o("big_bird"),yIr=o(" \u2014 "),uZ=a("a"),xIr=o("FlaxBigBirdModel"),$Ir=o(" (BigBird model)"),kIr=l(),O5=a("li"),C3e=a("strong"),SIr=o("blenderbot"),RIr=o(" \u2014 "),bZ=a("a"),PIr=o("FlaxBlenderbotModel"),BIr=o(" (Blenderbot model)"),NIr=l(),V5=a("li"),w3e=a("strong"),IIr=o("blenderbot-small"),qIr=o(" \u2014 "),vZ=a("a"),jIr=o("FlaxBlenderbotSmallModel"),DIr=o(" (BlenderbotSmall model)"),GIr=l(),X5=a("li"),A3e=a("strong"),OIr=o("clip"),VIr=o(" \u2014 "),FZ=a("a"),XIr=o("FlaxCLIPModel"),zIr=o(" (CLIP model)"),QIr=l(),z5=a("li"),L3e=a("strong"),WIr=o("distilbert"),HIr=o(" \u2014 "),TZ=a("a"),UIr=o("FlaxDistilBertModel"),JIr=o(" (DistilBERT model)"),YIr=l(),Q5=a("li"),y3e=a("strong"),KIr=o("electra"),ZIr=o(" \u2014 "),MZ=a("a"),eqr=o("FlaxElectraModel"),oqr=o(" (ELECTRA model)"),rqr=l(),W5=a("li"),x3e=a("strong"),tqr=o("gpt2"),aqr=o(" \u2014 "),EZ=a("a"),nqr=o("FlaxGPT2Model"),sqr=o(" (OpenAI GPT-2 model)"),lqr=l(),H5=a("li"),$3e=a("strong"),iqr=o("gpt_neo"),dqr=o(" \u2014 "),CZ=a("a"),cqr=o("FlaxGPTNeoModel"),fqr=o(" (GPT Neo model)"),mqr=l(),U5=a("li"),k3e=a("strong"),gqr=o("gptj"),hqr=o(" \u2014 "),wZ=a("a"),pqr=o("FlaxGPTJModel"),_qr=o(" (GPT-J model)"),uqr=l(),J5=a("li"),S3e=a("strong"),bqr=o("longt5"),vqr=o(" \u2014 "),AZ=a("a"),Fqr=o("FlaxLongT5Model"),Tqr=o(" (LongT5 model)"),Mqr=l(),Y5=a("li"),R3e=a("strong"),Eqr=o("marian"),Cqr=o(" \u2014 "),LZ=a("a"),wqr=o("FlaxMarianModel"),Aqr=o(" (Marian model)"),Lqr=l(),K5=a("li"),P3e=a("strong"),yqr=o("mbart"),xqr=o(" \u2014 "),yZ=a("a"),$qr=o("FlaxMBartModel"),kqr=o(" (mBART model)"),Sqr=l(),Z5=a("li"),B3e=a("strong"),Rqr=o("mt5"),Pqr=o(" \u2014 "),xZ=a("a"),Bqr=o("FlaxMT5Model"),Nqr=o(" (MT5 model)"),Iqr=l(),e0=a("li"),N3e=a("strong"),qqr=o("opt"),jqr=o(" \u2014 "),$Z=a("a"),Dqr=o("FlaxOPTModel"),Gqr=o(" (OPT model)"),Oqr=l(),o0=a("li"),I3e=a("strong"),Vqr=o("pegasus"),Xqr=o(" \u2014 "),kZ=a("a"),zqr=o("FlaxPegasusModel"),Qqr=o(" (Pegasus model)"),Wqr=l(),r0=a("li"),q3e=a("strong"),Hqr=o("roberta"),Uqr=o(" \u2014 "),SZ=a("a"),Jqr=o("FlaxRobertaModel"),Yqr=o(" (RoBERTa model)"),Kqr=l(),t0=a("li"),j3e=a("strong"),Zqr=o("roformer"),ejr=o(" \u2014 "),RZ=a("a"),ojr=o("FlaxRoFormerModel"),rjr=o(" (RoFormer model)"),tjr=l(),a0=a("li"),D3e=a("strong"),ajr=o("t5"),njr=o(" \u2014 "),PZ=a("a"),sjr=o("FlaxT5Model"),ljr=o(" (T5 model)"),ijr=l(),n0=a("li"),G3e=a("strong"),djr=o("vision-text-dual-encoder"),cjr=o(" \u2014 "),BZ=a("a"),fjr=o("FlaxVisionTextDualEncoderModel"),mjr=o(" (VisionTextDualEncoder model)"),gjr=l(),s0=a("li"),O3e=a("strong"),hjr=o("vit"),pjr=o(" \u2014 "),NZ=a("a"),_jr=o("FlaxViTModel"),ujr=o(" (ViT model)"),bjr=l(),l0=a("li"),V3e=a("strong"),vjr=o("wav2vec2"),Fjr=o(" \u2014 "),IZ=a("a"),Tjr=o("FlaxWav2Vec2Model"),Mjr=o(" (Wav2Vec2 model)"),Ejr=l(),i0=a("li"),X3e=a("strong"),Cjr=o("xglm"),wjr=o(" \u2014 "),qZ=a("a"),Ajr=o("FlaxXGLMModel"),Ljr=o(" (XGLM model)"),yjr=l(),d0=a("li"),z3e=a("strong"),xjr=o("xlm-roberta"),$jr=o(" \u2014 "),jZ=a("a"),kjr=o("FlaxXLMRobertaModel"),Sjr=o(" (XLM-RoBERTa model)"),Rjr=l(),F(c0.$$.fragment),MXe=l(),Hc=a("h2"),f0=a("a"),Q3e=a("span"),F(Jx.$$.fragment),Pjr=l(),W3e=a("span"),Bjr=o("FlaxAutoModelForCausalLM"),EXe=l(),_r=a("div"),F(Yx.$$.fragment),Njr=l(),Uc=a("p"),Ijr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),DZ=a("a"),qjr=o("from_pretrained()"),jjr=o(" class method or the "),GZ=a("a"),Djr=o("from_config()"),Gjr=o(` class
method.`),Ojr=l(),Kx=a("p"),Vjr=o("This class cannot be instantiated directly using "),H3e=a("code"),Xjr=o("__init__()"),zjr=o(" (throws an error)."),Qjr=l(),Qt=a("div"),F(Zx.$$.fragment),Wjr=l(),U3e=a("p"),Hjr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Ujr=l(),Jc=a("p"),Jjr=o(`Note:
Loading a model from its configuration file does `),J3e=a("strong"),Yjr=o("not"),Kjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OZ=a("a"),Zjr=o("from_pretrained()"),eDr=o(" to load the model weights."),oDr=l(),F(m0.$$.fragment),rDr=l(),Xr=a("div"),F(e$.$$.fragment),tDr=l(),Y3e=a("p"),aDr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),nDr=l(),Mn=a("p"),sDr=o("The model class to instantiate is selected based on the "),K3e=a("code"),lDr=o("model_type"),iDr=o(` property of the config object (either
passed as an argument or loaded from `),Z3e=a("code"),dDr=o("pretrained_model_name_or_path"),cDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e5e=a("code"),fDr=o("pretrained_model_name_or_path"),mDr=o(":"),gDr=l(),xe=a("ul"),g0=a("li"),o5e=a("strong"),hDr=o("bart"),pDr=o(" \u2014 "),VZ=a("a"),_Dr=o("FlaxBartForCausalLM"),uDr=o(" (BART model)"),bDr=l(),h0=a("li"),r5e=a("strong"),vDr=o("bert"),FDr=o(" \u2014 "),XZ=a("a"),TDr=o("FlaxBertForCausalLM"),MDr=o(" (BERT model)"),EDr=l(),p0=a("li"),t5e=a("strong"),CDr=o("big_bird"),wDr=o(" \u2014 "),zZ=a("a"),ADr=o("FlaxBigBirdForCausalLM"),LDr=o(" (BigBird model)"),yDr=l(),_0=a("li"),a5e=a("strong"),xDr=o("electra"),$Dr=o(" \u2014 "),QZ=a("a"),kDr=o("FlaxElectraForCausalLM"),SDr=o(" (ELECTRA model)"),RDr=l(),u0=a("li"),n5e=a("strong"),PDr=o("gpt2"),BDr=o(" \u2014 "),WZ=a("a"),NDr=o("FlaxGPT2LMHeadModel"),IDr=o(" (OpenAI GPT-2 model)"),qDr=l(),b0=a("li"),s5e=a("strong"),jDr=o("gpt_neo"),DDr=o(" \u2014 "),HZ=a("a"),GDr=o("FlaxGPTNeoForCausalLM"),ODr=o(" (GPT Neo model)"),VDr=l(),v0=a("li"),l5e=a("strong"),XDr=o("gptj"),zDr=o(" \u2014 "),UZ=a("a"),QDr=o("FlaxGPTJForCausalLM"),WDr=o(" (GPT-J model)"),HDr=l(),F0=a("li"),i5e=a("strong"),UDr=o("opt"),JDr=o(" \u2014 "),JZ=a("a"),YDr=o("FlaxOPTForCausalLM"),KDr=o(" (OPT model)"),ZDr=l(),T0=a("li"),d5e=a("strong"),eGr=o("roberta"),oGr=o(" \u2014 "),YZ=a("a"),rGr=o("FlaxRobertaForCausalLM"),tGr=o(" (RoBERTa model)"),aGr=l(),M0=a("li"),c5e=a("strong"),nGr=o("xglm"),sGr=o(" \u2014 "),KZ=a("a"),lGr=o("FlaxXGLMForCausalLM"),iGr=o(" (XGLM model)"),dGr=l(),F(E0.$$.fragment),CXe=l(),Yc=a("h2"),C0=a("a"),f5e=a("span"),F(o$.$$.fragment),cGr=l(),m5e=a("span"),fGr=o("FlaxAutoModelForPreTraining"),wXe=l(),ur=a("div"),F(r$.$$.fragment),mGr=l(),Kc=a("p"),gGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZZ=a("a"),hGr=o("from_pretrained()"),pGr=o(" class method or the "),eee=a("a"),_Gr=o("from_config()"),uGr=o(` class
method.`),bGr=l(),t$=a("p"),vGr=o("This class cannot be instantiated directly using "),g5e=a("code"),FGr=o("__init__()"),TGr=o(" (throws an error)."),MGr=l(),Wt=a("div"),F(a$.$$.fragment),EGr=l(),h5e=a("p"),CGr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),wGr=l(),Zc=a("p"),AGr=o(`Note:
Loading a model from its configuration file does `),p5e=a("strong"),LGr=o("not"),yGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oee=a("a"),xGr=o("from_pretrained()"),$Gr=o(" to load the model weights."),kGr=l(),F(w0.$$.fragment),SGr=l(),zr=a("div"),F(n$.$$.fragment),RGr=l(),_5e=a("p"),PGr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),BGr=l(),En=a("p"),NGr=o("The model class to instantiate is selected based on the "),u5e=a("code"),IGr=o("model_type"),qGr=o(` property of the config object (either
passed as an argument or loaded from `),b5e=a("code"),jGr=o("pretrained_model_name_or_path"),DGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v5e=a("code"),GGr=o("pretrained_model_name_or_path"),OGr=o(":"),VGr=l(),Ee=a("ul"),A0=a("li"),F5e=a("strong"),XGr=o("albert"),zGr=o(" \u2014 "),ree=a("a"),QGr=o("FlaxAlbertForPreTraining"),WGr=o(" (ALBERT model)"),HGr=l(),L0=a("li"),T5e=a("strong"),UGr=o("bart"),JGr=o(" \u2014 "),tee=a("a"),YGr=o("FlaxBartForConditionalGeneration"),KGr=o(" (BART model)"),ZGr=l(),y0=a("li"),M5e=a("strong"),eOr=o("bert"),oOr=o(" \u2014 "),aee=a("a"),rOr=o("FlaxBertForPreTraining"),tOr=o(" (BERT model)"),aOr=l(),x0=a("li"),E5e=a("strong"),nOr=o("big_bird"),sOr=o(" \u2014 "),nee=a("a"),lOr=o("FlaxBigBirdForPreTraining"),iOr=o(" (BigBird model)"),dOr=l(),$0=a("li"),C5e=a("strong"),cOr=o("electra"),fOr=o(" \u2014 "),see=a("a"),mOr=o("FlaxElectraForPreTraining"),gOr=o(" (ELECTRA model)"),hOr=l(),k0=a("li"),w5e=a("strong"),pOr=o("longt5"),_Or=o(" \u2014 "),lee=a("a"),uOr=o("FlaxLongT5ForConditionalGeneration"),bOr=o(" (LongT5 model)"),vOr=l(),S0=a("li"),A5e=a("strong"),FOr=o("mbart"),TOr=o(" \u2014 "),iee=a("a"),MOr=o("FlaxMBartForConditionalGeneration"),EOr=o(" (mBART model)"),COr=l(),R0=a("li"),L5e=a("strong"),wOr=o("mt5"),AOr=o(" \u2014 "),dee=a("a"),LOr=o("FlaxMT5ForConditionalGeneration"),yOr=o(" (MT5 model)"),xOr=l(),P0=a("li"),y5e=a("strong"),$Or=o("roberta"),kOr=o(" \u2014 "),cee=a("a"),SOr=o("FlaxRobertaForMaskedLM"),ROr=o(" (RoBERTa model)"),POr=l(),B0=a("li"),x5e=a("strong"),BOr=o("roformer"),NOr=o(" \u2014 "),fee=a("a"),IOr=o("FlaxRoFormerForMaskedLM"),qOr=o(" (RoFormer model)"),jOr=l(),N0=a("li"),$5e=a("strong"),DOr=o("t5"),GOr=o(" \u2014 "),mee=a("a"),OOr=o("FlaxT5ForConditionalGeneration"),VOr=o(" (T5 model)"),XOr=l(),I0=a("li"),k5e=a("strong"),zOr=o("wav2vec2"),QOr=o(" \u2014 "),gee=a("a"),WOr=o("FlaxWav2Vec2ForPreTraining"),HOr=o(" (Wav2Vec2 model)"),UOr=l(),q0=a("li"),S5e=a("strong"),JOr=o("xlm-roberta"),YOr=o(" \u2014 "),hee=a("a"),KOr=o("FlaxXLMRobertaForMaskedLM"),ZOr=o(" (XLM-RoBERTa model)"),eVr=l(),F(j0.$$.fragment),AXe=l(),ef=a("h2"),D0=a("a"),R5e=a("span"),F(s$.$$.fragment),oVr=l(),P5e=a("span"),rVr=o("FlaxAutoModelForMaskedLM"),LXe=l(),br=a("div"),F(l$.$$.fragment),tVr=l(),of=a("p"),aVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pee=a("a"),nVr=o("from_pretrained()"),sVr=o(" class method or the "),_ee=a("a"),lVr=o("from_config()"),iVr=o(` class
method.`),dVr=l(),i$=a("p"),cVr=o("This class cannot be instantiated directly using "),B5e=a("code"),fVr=o("__init__()"),mVr=o(" (throws an error)."),gVr=l(),Ht=a("div"),F(d$.$$.fragment),hVr=l(),N5e=a("p"),pVr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),_Vr=l(),rf=a("p"),uVr=o(`Note:
Loading a model from its configuration file does `),I5e=a("strong"),bVr=o("not"),vVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=a("a"),FVr=o("from_pretrained()"),TVr=o(" to load the model weights."),MVr=l(),F(G0.$$.fragment),EVr=l(),Qr=a("div"),F(c$.$$.fragment),CVr=l(),q5e=a("p"),wVr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),AVr=l(),Cn=a("p"),LVr=o("The model class to instantiate is selected based on the "),j5e=a("code"),yVr=o("model_type"),xVr=o(` property of the config object (either
passed as an argument or loaded from `),D5e=a("code"),$Vr=o("pretrained_model_name_or_path"),kVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G5e=a("code"),SVr=o("pretrained_model_name_or_path"),RVr=o(":"),PVr=l(),$e=a("ul"),O0=a("li"),O5e=a("strong"),BVr=o("albert"),NVr=o(" \u2014 "),bee=a("a"),IVr=o("FlaxAlbertForMaskedLM"),qVr=o(" (ALBERT model)"),jVr=l(),V0=a("li"),V5e=a("strong"),DVr=o("bart"),GVr=o(" \u2014 "),vee=a("a"),OVr=o("FlaxBartForConditionalGeneration"),VVr=o(" (BART model)"),XVr=l(),X0=a("li"),X5e=a("strong"),zVr=o("bert"),QVr=o(" \u2014 "),Fee=a("a"),WVr=o("FlaxBertForMaskedLM"),HVr=o(" (BERT model)"),UVr=l(),z0=a("li"),z5e=a("strong"),JVr=o("big_bird"),YVr=o(" \u2014 "),Tee=a("a"),KVr=o("FlaxBigBirdForMaskedLM"),ZVr=o(" (BigBird model)"),eXr=l(),Q0=a("li"),Q5e=a("strong"),oXr=o("distilbert"),rXr=o(" \u2014 "),Mee=a("a"),tXr=o("FlaxDistilBertForMaskedLM"),aXr=o(" (DistilBERT model)"),nXr=l(),W0=a("li"),W5e=a("strong"),sXr=o("electra"),lXr=o(" \u2014 "),Eee=a("a"),iXr=o("FlaxElectraForMaskedLM"),dXr=o(" (ELECTRA model)"),cXr=l(),H0=a("li"),H5e=a("strong"),fXr=o("mbart"),mXr=o(" \u2014 "),Cee=a("a"),gXr=o("FlaxMBartForConditionalGeneration"),hXr=o(" (mBART model)"),pXr=l(),U0=a("li"),U5e=a("strong"),_Xr=o("roberta"),uXr=o(" \u2014 "),wee=a("a"),bXr=o("FlaxRobertaForMaskedLM"),vXr=o(" (RoBERTa model)"),FXr=l(),J0=a("li"),J5e=a("strong"),TXr=o("roformer"),MXr=o(" \u2014 "),Aee=a("a"),EXr=o("FlaxRoFormerForMaskedLM"),CXr=o(" (RoFormer model)"),wXr=l(),Y0=a("li"),Y5e=a("strong"),AXr=o("xlm-roberta"),LXr=o(" \u2014 "),Lee=a("a"),yXr=o("FlaxXLMRobertaForMaskedLM"),xXr=o(" (XLM-RoBERTa model)"),$Xr=l(),F(K0.$$.fragment),yXe=l(),tf=a("h2"),Z0=a("a"),K5e=a("span"),F(f$.$$.fragment),kXr=l(),Z5e=a("span"),SXr=o("FlaxAutoModelForSeq2SeqLM"),xXe=l(),vr=a("div"),F(m$.$$.fragment),RXr=l(),af=a("p"),PXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),yee=a("a"),BXr=o("from_pretrained()"),NXr=o(" class method or the "),xee=a("a"),IXr=o("from_config()"),qXr=o(` class
method.`),jXr=l(),g$=a("p"),DXr=o("This class cannot be instantiated directly using "),e0e=a("code"),GXr=o("__init__()"),OXr=o(" (throws an error)."),VXr=l(),Ut=a("div"),F(h$.$$.fragment),XXr=l(),o0e=a("p"),zXr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),QXr=l(),nf=a("p"),WXr=o(`Note:
Loading a model from its configuration file does `),r0e=a("strong"),HXr=o("not"),UXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$ee=a("a"),JXr=o("from_pretrained()"),YXr=o(" to load the model weights."),KXr=l(),F(ew.$$.fragment),ZXr=l(),Wr=a("div"),F(p$.$$.fragment),ezr=l(),t0e=a("p"),ozr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),rzr=l(),wn=a("p"),tzr=o("The model class to instantiate is selected based on the "),a0e=a("code"),azr=o("model_type"),nzr=o(` property of the config object (either
passed as an argument or loaded from `),n0e=a("code"),szr=o("pretrained_model_name_or_path"),lzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s0e=a("code"),izr=o("pretrained_model_name_or_path"),dzr=o(":"),czr=l(),ke=a("ul"),ow=a("li"),l0e=a("strong"),fzr=o("bart"),mzr=o(" \u2014 "),kee=a("a"),gzr=o("FlaxBartForConditionalGeneration"),hzr=o(" (BART model)"),pzr=l(),rw=a("li"),i0e=a("strong"),_zr=o("blenderbot"),uzr=o(" \u2014 "),See=a("a"),bzr=o("FlaxBlenderbotForConditionalGeneration"),vzr=o(" (Blenderbot model)"),Fzr=l(),tw=a("li"),d0e=a("strong"),Tzr=o("blenderbot-small"),Mzr=o(" \u2014 "),Ree=a("a"),Ezr=o("FlaxBlenderbotSmallForConditionalGeneration"),Czr=o(" (BlenderbotSmall model)"),wzr=l(),aw=a("li"),c0e=a("strong"),Azr=o("encoder-decoder"),Lzr=o(" \u2014 "),Pee=a("a"),yzr=o("FlaxEncoderDecoderModel"),xzr=o(" (Encoder decoder model)"),$zr=l(),nw=a("li"),f0e=a("strong"),kzr=o("longt5"),Szr=o(" \u2014 "),Bee=a("a"),Rzr=o("FlaxLongT5ForConditionalGeneration"),Pzr=o(" (LongT5 model)"),Bzr=l(),sw=a("li"),m0e=a("strong"),Nzr=o("marian"),Izr=o(" \u2014 "),Nee=a("a"),qzr=o("FlaxMarianMTModel"),jzr=o(" (Marian model)"),Dzr=l(),lw=a("li"),g0e=a("strong"),Gzr=o("mbart"),Ozr=o(" \u2014 "),Iee=a("a"),Vzr=o("FlaxMBartForConditionalGeneration"),Xzr=o(" (mBART model)"),zzr=l(),iw=a("li"),h0e=a("strong"),Qzr=o("mt5"),Wzr=o(" \u2014 "),qee=a("a"),Hzr=o("FlaxMT5ForConditionalGeneration"),Uzr=o(" (MT5 model)"),Jzr=l(),dw=a("li"),p0e=a("strong"),Yzr=o("pegasus"),Kzr=o(" \u2014 "),jee=a("a"),Zzr=o("FlaxPegasusForConditionalGeneration"),eQr=o(" (Pegasus model)"),oQr=l(),cw=a("li"),_0e=a("strong"),rQr=o("t5"),tQr=o(" \u2014 "),Dee=a("a"),aQr=o("FlaxT5ForConditionalGeneration"),nQr=o(" (T5 model)"),sQr=l(),F(fw.$$.fragment),$Xe=l(),sf=a("h2"),mw=a("a"),u0e=a("span"),F(_$.$$.fragment),lQr=l(),b0e=a("span"),iQr=o("FlaxAutoModelForSequenceClassification"),kXe=l(),Fr=a("div"),F(u$.$$.fragment),dQr=l(),lf=a("p"),cQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Gee=a("a"),fQr=o("from_pretrained()"),mQr=o(" class method or the "),Oee=a("a"),gQr=o("from_config()"),hQr=o(` class
method.`),pQr=l(),b$=a("p"),_Qr=o("This class cannot be instantiated directly using "),v0e=a("code"),uQr=o("__init__()"),bQr=o(" (throws an error)."),vQr=l(),Jt=a("div"),F(v$.$$.fragment),FQr=l(),F0e=a("p"),TQr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),MQr=l(),df=a("p"),EQr=o(`Note:
Loading a model from its configuration file does `),T0e=a("strong"),CQr=o("not"),wQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=a("a"),AQr=o("from_pretrained()"),LQr=o(" to load the model weights."),yQr=l(),F(gw.$$.fragment),xQr=l(),Hr=a("div"),F(F$.$$.fragment),$Qr=l(),M0e=a("p"),kQr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),SQr=l(),An=a("p"),RQr=o("The model class to instantiate is selected based on the "),E0e=a("code"),PQr=o("model_type"),BQr=o(` property of the config object (either
passed as an argument or loaded from `),C0e=a("code"),NQr=o("pretrained_model_name_or_path"),IQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w0e=a("code"),qQr=o("pretrained_model_name_or_path"),jQr=o(":"),DQr=l(),Se=a("ul"),hw=a("li"),A0e=a("strong"),GQr=o("albert"),OQr=o(" \u2014 "),Xee=a("a"),VQr=o("FlaxAlbertForSequenceClassification"),XQr=o(" (ALBERT model)"),zQr=l(),pw=a("li"),L0e=a("strong"),QQr=o("bart"),WQr=o(" \u2014 "),zee=a("a"),HQr=o("FlaxBartForSequenceClassification"),UQr=o(" (BART model)"),JQr=l(),_w=a("li"),y0e=a("strong"),YQr=o("bert"),KQr=o(" \u2014 "),Qee=a("a"),ZQr=o("FlaxBertForSequenceClassification"),eWr=o(" (BERT model)"),oWr=l(),uw=a("li"),x0e=a("strong"),rWr=o("big_bird"),tWr=o(" \u2014 "),Wee=a("a"),aWr=o("FlaxBigBirdForSequenceClassification"),nWr=o(" (BigBird model)"),sWr=l(),bw=a("li"),$0e=a("strong"),lWr=o("distilbert"),iWr=o(" \u2014 "),Hee=a("a"),dWr=o("FlaxDistilBertForSequenceClassification"),cWr=o(" (DistilBERT model)"),fWr=l(),vw=a("li"),k0e=a("strong"),mWr=o("electra"),gWr=o(" \u2014 "),Uee=a("a"),hWr=o("FlaxElectraForSequenceClassification"),pWr=o(" (ELECTRA model)"),_Wr=l(),Fw=a("li"),S0e=a("strong"),uWr=o("mbart"),bWr=o(" \u2014 "),Jee=a("a"),vWr=o("FlaxMBartForSequenceClassification"),FWr=o(" (mBART model)"),TWr=l(),Tw=a("li"),R0e=a("strong"),MWr=o("roberta"),EWr=o(" \u2014 "),Yee=a("a"),CWr=o("FlaxRobertaForSequenceClassification"),wWr=o(" (RoBERTa model)"),AWr=l(),Mw=a("li"),P0e=a("strong"),LWr=o("roformer"),yWr=o(" \u2014 "),Kee=a("a"),xWr=o("FlaxRoFormerForSequenceClassification"),$Wr=o(" (RoFormer model)"),kWr=l(),Ew=a("li"),B0e=a("strong"),SWr=o("xlm-roberta"),RWr=o(" \u2014 "),Zee=a("a"),PWr=o("FlaxXLMRobertaForSequenceClassification"),BWr=o(" (XLM-RoBERTa model)"),NWr=l(),F(Cw.$$.fragment),SXe=l(),cf=a("h2"),ww=a("a"),N0e=a("span"),F(T$.$$.fragment),IWr=l(),I0e=a("span"),qWr=o("FlaxAutoModelForQuestionAnswering"),RXe=l(),Tr=a("div"),F(M$.$$.fragment),jWr=l(),ff=a("p"),DWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),eoe=a("a"),GWr=o("from_pretrained()"),OWr=o(" class method or the "),ooe=a("a"),VWr=o("from_config()"),XWr=o(` class
method.`),zWr=l(),E$=a("p"),QWr=o("This class cannot be instantiated directly using "),q0e=a("code"),WWr=o("__init__()"),HWr=o(" (throws an error)."),UWr=l(),Yt=a("div"),F(C$.$$.fragment),JWr=l(),j0e=a("p"),YWr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),KWr=l(),mf=a("p"),ZWr=o(`Note:
Loading a model from its configuration file does `),D0e=a("strong"),eHr=o("not"),oHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),roe=a("a"),rHr=o("from_pretrained()"),tHr=o(" to load the model weights."),aHr=l(),F(Aw.$$.fragment),nHr=l(),Ur=a("div"),F(w$.$$.fragment),sHr=l(),G0e=a("p"),lHr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),iHr=l(),Ln=a("p"),dHr=o("The model class to instantiate is selected based on the "),O0e=a("code"),cHr=o("model_type"),fHr=o(` property of the config object (either
passed as an argument or loaded from `),V0e=a("code"),mHr=o("pretrained_model_name_or_path"),gHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X0e=a("code"),hHr=o("pretrained_model_name_or_path"),pHr=o(":"),_Hr=l(),Re=a("ul"),Lw=a("li"),z0e=a("strong"),uHr=o("albert"),bHr=o(" \u2014 "),toe=a("a"),vHr=o("FlaxAlbertForQuestionAnswering"),FHr=o(" (ALBERT model)"),THr=l(),yw=a("li"),Q0e=a("strong"),MHr=o("bart"),EHr=o(" \u2014 "),aoe=a("a"),CHr=o("FlaxBartForQuestionAnswering"),wHr=o(" (BART model)"),AHr=l(),xw=a("li"),W0e=a("strong"),LHr=o("bert"),yHr=o(" \u2014 "),noe=a("a"),xHr=o("FlaxBertForQuestionAnswering"),$Hr=o(" (BERT model)"),kHr=l(),$w=a("li"),H0e=a("strong"),SHr=o("big_bird"),RHr=o(" \u2014 "),soe=a("a"),PHr=o("FlaxBigBirdForQuestionAnswering"),BHr=o(" (BigBird model)"),NHr=l(),kw=a("li"),U0e=a("strong"),IHr=o("distilbert"),qHr=o(" \u2014 "),loe=a("a"),jHr=o("FlaxDistilBertForQuestionAnswering"),DHr=o(" (DistilBERT model)"),GHr=l(),Sw=a("li"),J0e=a("strong"),OHr=o("electra"),VHr=o(" \u2014 "),ioe=a("a"),XHr=o("FlaxElectraForQuestionAnswering"),zHr=o(" (ELECTRA model)"),QHr=l(),Rw=a("li"),Y0e=a("strong"),WHr=o("mbart"),HHr=o(" \u2014 "),doe=a("a"),UHr=o("FlaxMBartForQuestionAnswering"),JHr=o(" (mBART model)"),YHr=l(),Pw=a("li"),K0e=a("strong"),KHr=o("roberta"),ZHr=o(" \u2014 "),coe=a("a"),eUr=o("FlaxRobertaForQuestionAnswering"),oUr=o(" (RoBERTa model)"),rUr=l(),Bw=a("li"),Z0e=a("strong"),tUr=o("roformer"),aUr=o(" \u2014 "),foe=a("a"),nUr=o("FlaxRoFormerForQuestionAnswering"),sUr=o(" (RoFormer model)"),lUr=l(),Nw=a("li"),ewe=a("strong"),iUr=o("xlm-roberta"),dUr=o(" \u2014 "),moe=a("a"),cUr=o("FlaxXLMRobertaForQuestionAnswering"),fUr=o(" (XLM-RoBERTa model)"),mUr=l(),F(Iw.$$.fragment),PXe=l(),gf=a("h2"),qw=a("a"),owe=a("span"),F(A$.$$.fragment),gUr=l(),rwe=a("span"),hUr=o("FlaxAutoModelForTokenClassification"),BXe=l(),Mr=a("div"),F(L$.$$.fragment),pUr=l(),hf=a("p"),_Ur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),goe=a("a"),uUr=o("from_pretrained()"),bUr=o(" class method or the "),hoe=a("a"),vUr=o("from_config()"),FUr=o(` class
method.`),TUr=l(),y$=a("p"),MUr=o("This class cannot be instantiated directly using "),twe=a("code"),EUr=o("__init__()"),CUr=o(" (throws an error)."),wUr=l(),Kt=a("div"),F(x$.$$.fragment),AUr=l(),awe=a("p"),LUr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),yUr=l(),pf=a("p"),xUr=o(`Note:
Loading a model from its configuration file does `),nwe=a("strong"),$Ur=o("not"),kUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=a("a"),SUr=o("from_pretrained()"),RUr=o(" to load the model weights."),PUr=l(),F(jw.$$.fragment),BUr=l(),Jr=a("div"),F($$.$$.fragment),NUr=l(),swe=a("p"),IUr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),qUr=l(),yn=a("p"),jUr=o("The model class to instantiate is selected based on the "),lwe=a("code"),DUr=o("model_type"),GUr=o(` property of the config object (either
passed as an argument or loaded from `),iwe=a("code"),OUr=o("pretrained_model_name_or_path"),VUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dwe=a("code"),XUr=o("pretrained_model_name_or_path"),zUr=o(":"),QUr=l(),Ve=a("ul"),Dw=a("li"),cwe=a("strong"),WUr=o("albert"),HUr=o(" \u2014 "),_oe=a("a"),UUr=o("FlaxAlbertForTokenClassification"),JUr=o(" (ALBERT model)"),YUr=l(),Gw=a("li"),fwe=a("strong"),KUr=o("bert"),ZUr=o(" \u2014 "),uoe=a("a"),eJr=o("FlaxBertForTokenClassification"),oJr=o(" (BERT model)"),rJr=l(),Ow=a("li"),mwe=a("strong"),tJr=o("big_bird"),aJr=o(" \u2014 "),boe=a("a"),nJr=o("FlaxBigBirdForTokenClassification"),sJr=o(" (BigBird model)"),lJr=l(),Vw=a("li"),gwe=a("strong"),iJr=o("distilbert"),dJr=o(" \u2014 "),voe=a("a"),cJr=o("FlaxDistilBertForTokenClassification"),fJr=o(" (DistilBERT model)"),mJr=l(),Xw=a("li"),hwe=a("strong"),gJr=o("electra"),hJr=o(" \u2014 "),Foe=a("a"),pJr=o("FlaxElectraForTokenClassification"),_Jr=o(" (ELECTRA model)"),uJr=l(),zw=a("li"),pwe=a("strong"),bJr=o("roberta"),vJr=o(" \u2014 "),Toe=a("a"),FJr=o("FlaxRobertaForTokenClassification"),TJr=o(" (RoBERTa model)"),MJr=l(),Qw=a("li"),_we=a("strong"),EJr=o("roformer"),CJr=o(" \u2014 "),Moe=a("a"),wJr=o("FlaxRoFormerForTokenClassification"),AJr=o(" (RoFormer model)"),LJr=l(),Ww=a("li"),uwe=a("strong"),yJr=o("xlm-roberta"),xJr=o(" \u2014 "),Eoe=a("a"),$Jr=o("FlaxXLMRobertaForTokenClassification"),kJr=o(" (XLM-RoBERTa model)"),SJr=l(),F(Hw.$$.fragment),NXe=l(),_f=a("h2"),Uw=a("a"),bwe=a("span"),F(k$.$$.fragment),RJr=l(),vwe=a("span"),PJr=o("FlaxAutoModelForMultipleChoice"),IXe=l(),Er=a("div"),F(S$.$$.fragment),BJr=l(),uf=a("p"),NJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Coe=a("a"),IJr=o("from_pretrained()"),qJr=o(" class method or the "),woe=a("a"),jJr=o("from_config()"),DJr=o(` class
method.`),GJr=l(),R$=a("p"),OJr=o("This class cannot be instantiated directly using "),Fwe=a("code"),VJr=o("__init__()"),XJr=o(" (throws an error)."),zJr=l(),Zt=a("div"),F(P$.$$.fragment),QJr=l(),Twe=a("p"),WJr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),HJr=l(),bf=a("p"),UJr=o(`Note:
Loading a model from its configuration file does `),Mwe=a("strong"),JJr=o("not"),YJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aoe=a("a"),KJr=o("from_pretrained()"),ZJr=o(" to load the model weights."),eYr=l(),F(Jw.$$.fragment),oYr=l(),Yr=a("div"),F(B$.$$.fragment),rYr=l(),Ewe=a("p"),tYr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),aYr=l(),xn=a("p"),nYr=o("The model class to instantiate is selected based on the "),Cwe=a("code"),sYr=o("model_type"),lYr=o(` property of the config object (either
passed as an argument or loaded from `),wwe=a("code"),iYr=o("pretrained_model_name_or_path"),dYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Awe=a("code"),cYr=o("pretrained_model_name_or_path"),fYr=o(":"),mYr=l(),Xe=a("ul"),Yw=a("li"),Lwe=a("strong"),gYr=o("albert"),hYr=o(" \u2014 "),Loe=a("a"),pYr=o("FlaxAlbertForMultipleChoice"),_Yr=o(" (ALBERT model)"),uYr=l(),Kw=a("li"),ywe=a("strong"),bYr=o("bert"),vYr=o(" \u2014 "),yoe=a("a"),FYr=o("FlaxBertForMultipleChoice"),TYr=o(" (BERT model)"),MYr=l(),Zw=a("li"),xwe=a("strong"),EYr=o("big_bird"),CYr=o(" \u2014 "),xoe=a("a"),wYr=o("FlaxBigBirdForMultipleChoice"),AYr=o(" (BigBird model)"),LYr=l(),eA=a("li"),$we=a("strong"),yYr=o("distilbert"),xYr=o(" \u2014 "),$oe=a("a"),$Yr=o("FlaxDistilBertForMultipleChoice"),kYr=o(" (DistilBERT model)"),SYr=l(),oA=a("li"),kwe=a("strong"),RYr=o("electra"),PYr=o(" \u2014 "),koe=a("a"),BYr=o("FlaxElectraForMultipleChoice"),NYr=o(" (ELECTRA model)"),IYr=l(),rA=a("li"),Swe=a("strong"),qYr=o("roberta"),jYr=o(" \u2014 "),Soe=a("a"),DYr=o("FlaxRobertaForMultipleChoice"),GYr=o(" (RoBERTa model)"),OYr=l(),tA=a("li"),Rwe=a("strong"),VYr=o("roformer"),XYr=o(" \u2014 "),Roe=a("a"),zYr=o("FlaxRoFormerForMultipleChoice"),QYr=o(" (RoFormer model)"),WYr=l(),aA=a("li"),Pwe=a("strong"),HYr=o("xlm-roberta"),UYr=o(" \u2014 "),Poe=a("a"),JYr=o("FlaxXLMRobertaForMultipleChoice"),YYr=o(" (XLM-RoBERTa model)"),KYr=l(),F(nA.$$.fragment),qXe=l(),vf=a("h2"),sA=a("a"),Bwe=a("span"),F(N$.$$.fragment),ZYr=l(),Nwe=a("span"),eKr=o("FlaxAutoModelForNextSentencePrediction"),jXe=l(),Cr=a("div"),F(I$.$$.fragment),oKr=l(),Ff=a("p"),rKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Boe=a("a"),tKr=o("from_pretrained()"),aKr=o(" class method or the "),Noe=a("a"),nKr=o("from_config()"),sKr=o(` class
method.`),lKr=l(),q$=a("p"),iKr=o("This class cannot be instantiated directly using "),Iwe=a("code"),dKr=o("__init__()"),cKr=o(" (throws an error)."),fKr=l(),ea=a("div"),F(j$.$$.fragment),mKr=l(),qwe=a("p"),gKr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),hKr=l(),Tf=a("p"),pKr=o(`Note:
Loading a model from its configuration file does `),jwe=a("strong"),_Kr=o("not"),uKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ioe=a("a"),bKr=o("from_pretrained()"),vKr=o(" to load the model weights."),FKr=l(),F(lA.$$.fragment),TKr=l(),Kr=a("div"),F(D$.$$.fragment),MKr=l(),Dwe=a("p"),EKr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),CKr=l(),$n=a("p"),wKr=o("The model class to instantiate is selected based on the "),Gwe=a("code"),AKr=o("model_type"),LKr=o(` property of the config object (either
passed as an argument or loaded from `),Owe=a("code"),yKr=o("pretrained_model_name_or_path"),xKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vwe=a("code"),$Kr=o("pretrained_model_name_or_path"),kKr=o(":"),SKr=l(),Xwe=a("ul"),iA=a("li"),zwe=a("strong"),RKr=o("bert"),PKr=o(" \u2014 "),qoe=a("a"),BKr=o("FlaxBertForNextSentencePrediction"),NKr=o(" (BERT model)"),IKr=l(),F(dA.$$.fragment),DXe=l(),Mf=a("h2"),cA=a("a"),Qwe=a("span"),F(G$.$$.fragment),qKr=l(),Wwe=a("span"),jKr=o("FlaxAutoModelForImageClassification"),GXe=l(),wr=a("div"),F(O$.$$.fragment),DKr=l(),Ef=a("p"),GKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),joe=a("a"),OKr=o("from_pretrained()"),VKr=o(" class method or the "),Doe=a("a"),XKr=o("from_config()"),zKr=o(` class
method.`),QKr=l(),V$=a("p"),WKr=o("This class cannot be instantiated directly using "),Hwe=a("code"),HKr=o("__init__()"),UKr=o(" (throws an error)."),JKr=l(),oa=a("div"),F(X$.$$.fragment),YKr=l(),Uwe=a("p"),KKr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),ZKr=l(),Cf=a("p"),eZr=o(`Note:
Loading a model from its configuration file does `),Jwe=a("strong"),oZr=o("not"),rZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Goe=a("a"),tZr=o("from_pretrained()"),aZr=o(" to load the model weights."),nZr=l(),F(fA.$$.fragment),sZr=l(),Zr=a("div"),F(z$.$$.fragment),lZr=l(),Ywe=a("p"),iZr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),dZr=l(),kn=a("p"),cZr=o("The model class to instantiate is selected based on the "),Kwe=a("code"),fZr=o("model_type"),mZr=o(` property of the config object (either
passed as an argument or loaded from `),Zwe=a("code"),gZr=o("pretrained_model_name_or_path"),hZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eAe=a("code"),pZr=o("pretrained_model_name_or_path"),_Zr=o(":"),uZr=l(),Q$=a("ul"),mA=a("li"),oAe=a("strong"),bZr=o("beit"),vZr=o(" \u2014 "),Ooe=a("a"),FZr=o("FlaxBeitForImageClassification"),TZr=o(" (BEiT model)"),MZr=l(),gA=a("li"),rAe=a("strong"),EZr=o("vit"),CZr=o(" \u2014 "),Voe=a("a"),wZr=o("FlaxViTForImageClassification"),AZr=o(" (ViT model)"),LZr=l(),F(hA.$$.fragment),OXe=l(),wf=a("h2"),pA=a("a"),tAe=a("span"),F(W$.$$.fragment),yZr=l(),aAe=a("span"),xZr=o("FlaxAutoModelForVision2Seq"),VXe=l(),Ar=a("div"),F(H$.$$.fragment),$Zr=l(),Af=a("p"),kZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Xoe=a("a"),SZr=o("from_pretrained()"),RZr=o(" class method or the "),zoe=a("a"),PZr=o("from_config()"),BZr=o(` class
method.`),NZr=l(),U$=a("p"),IZr=o("This class cannot be instantiated directly using "),nAe=a("code"),qZr=o("__init__()"),jZr=o(" (throws an error)."),DZr=l(),ra=a("div"),F(J$.$$.fragment),GZr=l(),sAe=a("p"),OZr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),VZr=l(),Lf=a("p"),XZr=o(`Note:
Loading a model from its configuration file does `),lAe=a("strong"),zZr=o("not"),QZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qoe=a("a"),WZr=o("from_pretrained()"),HZr=o(" to load the model weights."),UZr=l(),F(_A.$$.fragment),JZr=l(),et=a("div"),F(Y$.$$.fragment),YZr=l(),iAe=a("p"),KZr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),ZZr=l(),Sn=a("p"),eet=o("The model class to instantiate is selected based on the "),dAe=a("code"),oet=o("model_type"),ret=o(` property of the config object (either
passed as an argument or loaded from `),cAe=a("code"),tet=o("pretrained_model_name_or_path"),aet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fAe=a("code"),net=o("pretrained_model_name_or_path"),set=o(":"),iet=l(),mAe=a("ul"),uA=a("li"),gAe=a("strong"),det=o("vision-encoder-decoder"),cet=o(" \u2014 "),Woe=a("a"),fet=o("FlaxVisionEncoderDecoderModel"),met=o(" (Vision Encoder decoder model)"),get=l(),F(bA.$$.fragment),this.h()},l(f){const u=fVt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var K$=s(p);m=n(K$,"A",{id:!0,class:!0,href:!0});var hAe=s(m);_=n(hAe,"SPAN",{});var pAe=s(_);T(d.$$.fragment,pAe),pAe.forEach(t),hAe.forEach(t),h=i(K$),Eo=n(K$,"SPAN",{});var _Ae=s(Eo);Ci=r(_Ae,"Auto Classes"),_Ae.forEach(t),K$.forEach(t),kf=i(f),nt=n(f,"P",{});var Z$=s(nt);wi=r(Z$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ai=n(Z$,"CODE",{});var uAe=s(Ai);qL=r(uAe,"from_pretrained()"),uAe.forEach(t),Sf=r(Z$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Z$.forEach(t),Oe=i(f),Qe=n(f,"P",{});var Rn=s(Qe);Li=r(Rn,"Instantiating one of "),Pn=n(Rn,"A",{href:!0});var bAe=s(Pn);jL=r(bAe,"AutoConfig"),bAe.forEach(t),Bn=r(Rn,", "),Nn=n(Rn,"A",{href:!0});var vAe=s(Nn);DL=r(vAe,"AutoModel"),vAe.forEach(t),yi=r(Rn,`, and
`),In=n(Rn,"A",{href:!0});var FAe=s(In);GL=r(FAe,"AutoTokenizer"),FAe.forEach(t),xi=r(Rn," will directly create a class of the relevant architecture. For instance"),Rn.forEach(t),Rf=i(f),T(ka.$$.fragment,f),We=i(f),Ae=n(f,"P",{});var ek=s(Ae);uS=r(ek,"will create a model that is an instance of "),$i=n(ek,"A",{href:!0});var TAe=s($i);bS=r(TAe,"BertModel"),TAe.forEach(t),vS=r(ek,"."),ek.forEach(t),Co=i(f),Sa=n(f,"P",{});var ok=s(Sa);FS=r(ok,"There is one class of "),Pf=n(ok,"CODE",{});var MAe=s(Pf);TS=r(MAe,"AutoModel"),MAe.forEach(t),eWe=r(ok," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ok.forEach(t),jOe=i(f),ki=n(f,"H2",{class:!0});var rk=s(ki);Bf=n(rk,"A",{id:!0,class:!0,href:!0});var EAe=s(Bf);Ote=n(EAe,"SPAN",{});var CAe=s(Ote);T(OL.$$.fragment,CAe),CAe.forEach(t),EAe.forEach(t),oWe=i(rk),Vte=n(rk,"SPAN",{});var wAe=s(Vte);rWe=r(wAe,"Extending the Auto Classes"),wAe.forEach(t),rk.forEach(t),DOe=i(f),qn=n(f,"P",{});var yf=s(qn);tWe=r(yf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Xte=n(yf,"CODE",{});var AAe=s(Xte);aWe=r(AAe,"NewModel"),AAe.forEach(t),nWe=r(yf,", make sure you have a "),zte=n(yf,"CODE",{});var LAe=s(zte);sWe=r(LAe,"NewModelConfig"),LAe.forEach(t),lWe=r(yf,` then you can add those to the auto
classes like this:`),yf.forEach(t),GOe=i(f),T(VL.$$.fragment,f),OOe=i(f),MS=n(f,"P",{});var yAe=s(MS);iWe=r(yAe,"You will then be able to use the auto classes like you would usually do!"),yAe.forEach(t),VOe=i(f),T(Nf.$$.fragment,f),XOe=i(f),Si=n(f,"H2",{class:!0});var tk=s(Si);If=n(tk,"A",{id:!0,class:!0,href:!0});var xAe=s(If);Qte=n(xAe,"SPAN",{});var $Ae=s(Qte);T(XL.$$.fragment,$Ae),$Ae.forEach(t),xAe.forEach(t),dWe=i(tk),Wte=n(tk,"SPAN",{});var kAe=s(Wte);cWe=r(kAe,"AutoConfig"),kAe.forEach(t),tk.forEach(t),zOe=i(f),wo=n(f,"DIV",{class:!0});var tt=s(wo);T(zL.$$.fragment,tt),fWe=i(tt),QL=n(tt,"P",{});var ak=s(QL);mWe=r(ak,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),ES=n(ak,"A",{href:!0});var SAe=s(ES);gWe=r(SAe,"from_pretrained()"),SAe.forEach(t),hWe=r(ak," class method."),ak.forEach(t),pWe=i(tt),WL=n(tt,"P",{});var nk=s(WL);_We=r(nk,"This class cannot be instantiated directly using "),Hte=n(nk,"CODE",{});var RAe=s(Hte);uWe=r(RAe,"__init__()"),RAe.forEach(t),bWe=r(nk," (throws an error)."),nk.forEach(t),vWe=i(tt),Lr=n(tt,"DIV",{class:!0});var at=s(Lr);T(HL.$$.fragment,at),FWe=i(at),Ute=n(at,"P",{});var PAe=s(Ute);TWe=r(PAe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),PAe.forEach(t),MWe=i(at),Ri=n(at,"P",{});var xf=s(Ri);EWe=r(xf,"The configuration class to instantiate is selected based on the "),Jte=n(xf,"CODE",{});var BAe=s(Jte);CWe=r(BAe,"model_type"),BAe.forEach(t),wWe=r(xf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Yte=n(xf,"CODE",{});var NAe=s(Yte);AWe=r(NAe,"pretrained_model_name_or_path"),NAe.forEach(t),LWe=r(xf,":"),xf.forEach(t),yWe=i(at),A=n(at,"UL",{});var L=s(A);qf=n(L,"LI",{});var vA=s(qf);Kte=n(vA,"STRONG",{});var IAe=s(Kte);xWe=r(IAe,"albert"),IAe.forEach(t),$We=r(vA," \u2014 "),CS=n(vA,"A",{href:!0});var qAe=s(CS);kWe=r(qAe,"AlbertConfig"),qAe.forEach(t),SWe=r(vA," (ALBERT model)"),vA.forEach(t),RWe=i(L),jf=n(L,"LI",{});var FA=s(jf);Zte=n(FA,"STRONG",{});var jAe=s(Zte);PWe=r(jAe,"bart"),jAe.forEach(t),BWe=r(FA," \u2014 "),wS=n(FA,"A",{href:!0});var DAe=s(wS);NWe=r(DAe,"BartConfig"),DAe.forEach(t),IWe=r(FA," (BART model)"),FA.forEach(t),qWe=i(L),Df=n(L,"LI",{});var TA=s(Df);eae=n(TA,"STRONG",{});var GAe=s(eae);jWe=r(GAe,"beit"),GAe.forEach(t),DWe=r(TA," \u2014 "),AS=n(TA,"A",{href:!0});var OAe=s(AS);GWe=r(OAe,"BeitConfig"),OAe.forEach(t),OWe=r(TA," (BEiT model)"),TA.forEach(t),VWe=i(L),Gf=n(L,"LI",{});var MA=s(Gf);oae=n(MA,"STRONG",{});var VAe=s(oae);XWe=r(VAe,"bert"),VAe.forEach(t),zWe=r(MA," \u2014 "),LS=n(MA,"A",{href:!0});var XAe=s(LS);QWe=r(XAe,"BertConfig"),XAe.forEach(t),WWe=r(MA," (BERT model)"),MA.forEach(t),HWe=i(L),Of=n(L,"LI",{});var EA=s(Of);rae=n(EA,"STRONG",{});var zAe=s(rae);UWe=r(zAe,"bert-generation"),zAe.forEach(t),JWe=r(EA," \u2014 "),yS=n(EA,"A",{href:!0});var QAe=s(yS);YWe=r(QAe,"BertGenerationConfig"),QAe.forEach(t),KWe=r(EA," (Bert Generation model)"),EA.forEach(t),ZWe=i(L),Vf=n(L,"LI",{});var CA=s(Vf);tae=n(CA,"STRONG",{});var WAe=s(tae);eHe=r(WAe,"big_bird"),WAe.forEach(t),oHe=r(CA," \u2014 "),xS=n(CA,"A",{href:!0});var HAe=s(xS);rHe=r(HAe,"BigBirdConfig"),HAe.forEach(t),tHe=r(CA," (BigBird model)"),CA.forEach(t),aHe=i(L),Xf=n(L,"LI",{});var wA=s(Xf);aae=n(wA,"STRONG",{});var UAe=s(aae);nHe=r(UAe,"bigbird_pegasus"),UAe.forEach(t),sHe=r(wA," \u2014 "),$S=n(wA,"A",{href:!0});var JAe=s($S);lHe=r(JAe,"BigBirdPegasusConfig"),JAe.forEach(t),iHe=r(wA," (BigBird-Pegasus model)"),wA.forEach(t),dHe=i(L),zf=n(L,"LI",{});var AA=s(zf);nae=n(AA,"STRONG",{});var YAe=s(nae);cHe=r(YAe,"blenderbot"),YAe.forEach(t),fHe=r(AA," \u2014 "),kS=n(AA,"A",{href:!0});var KAe=s(kS);mHe=r(KAe,"BlenderbotConfig"),KAe.forEach(t),gHe=r(AA," (Blenderbot model)"),AA.forEach(t),hHe=i(L),Qf=n(L,"LI",{});var LA=s(Qf);sae=n(LA,"STRONG",{});var ZAe=s(sae);pHe=r(ZAe,"blenderbot-small"),ZAe.forEach(t),_He=r(LA," \u2014 "),SS=n(LA,"A",{href:!0});var e6e=s(SS);uHe=r(e6e,"BlenderbotSmallConfig"),e6e.forEach(t),bHe=r(LA," (BlenderbotSmall model)"),LA.forEach(t),vHe=i(L),Wf=n(L,"LI",{});var yA=s(Wf);lae=n(yA,"STRONG",{});var o6e=s(lae);FHe=r(o6e,"bloom"),o6e.forEach(t),THe=r(yA," \u2014 "),RS=n(yA,"A",{href:!0});var r6e=s(RS);MHe=r(r6e,"BloomConfig"),r6e.forEach(t),EHe=r(yA," (BLOOM model)"),yA.forEach(t),CHe=i(L),Hf=n(L,"LI",{});var xA=s(Hf);iae=n(xA,"STRONG",{});var t6e=s(iae);wHe=r(t6e,"camembert"),t6e.forEach(t),AHe=r(xA," \u2014 "),PS=n(xA,"A",{href:!0});var a6e=s(PS);LHe=r(a6e,"CamembertConfig"),a6e.forEach(t),yHe=r(xA," (CamemBERT model)"),xA.forEach(t),xHe=i(L),Uf=n(L,"LI",{});var $A=s(Uf);dae=n($A,"STRONG",{});var n6e=s(dae);$He=r(n6e,"canine"),n6e.forEach(t),kHe=r($A," \u2014 "),BS=n($A,"A",{href:!0});var s6e=s(BS);SHe=r(s6e,"CanineConfig"),s6e.forEach(t),RHe=r($A," (CANINE model)"),$A.forEach(t),PHe=i(L),Jf=n(L,"LI",{});var kA=s(Jf);cae=n(kA,"STRONG",{});var l6e=s(cae);BHe=r(l6e,"clip"),l6e.forEach(t),NHe=r(kA," \u2014 "),NS=n(kA,"A",{href:!0});var i6e=s(NS);IHe=r(i6e,"CLIPConfig"),i6e.forEach(t),qHe=r(kA," (CLIP model)"),kA.forEach(t),jHe=i(L),Yf=n(L,"LI",{});var SA=s(Yf);fae=n(SA,"STRONG",{});var d6e=s(fae);DHe=r(d6e,"codegen"),d6e.forEach(t),GHe=r(SA," \u2014 "),IS=n(SA,"A",{href:!0});var c6e=s(IS);OHe=r(c6e,"CodeGenConfig"),c6e.forEach(t),VHe=r(SA," (CodeGen model)"),SA.forEach(t),XHe=i(L),Kf=n(L,"LI",{});var RA=s(Kf);mae=n(RA,"STRONG",{});var f6e=s(mae);zHe=r(f6e,"convbert"),f6e.forEach(t),QHe=r(RA," \u2014 "),qS=n(RA,"A",{href:!0});var m6e=s(qS);WHe=r(m6e,"ConvBertConfig"),m6e.forEach(t),HHe=r(RA," (ConvBERT model)"),RA.forEach(t),UHe=i(L),Zf=n(L,"LI",{});var PA=s(Zf);gae=n(PA,"STRONG",{});var g6e=s(gae);JHe=r(g6e,"convnext"),g6e.forEach(t),YHe=r(PA," \u2014 "),jS=n(PA,"A",{href:!0});var h6e=s(jS);KHe=r(h6e,"ConvNextConfig"),h6e.forEach(t),ZHe=r(PA," (ConvNeXT model)"),PA.forEach(t),eUe=i(L),em=n(L,"LI",{});var BA=s(em);hae=n(BA,"STRONG",{});var p6e=s(hae);oUe=r(p6e,"ctrl"),p6e.forEach(t),rUe=r(BA," \u2014 "),DS=n(BA,"A",{href:!0});var _6e=s(DS);tUe=r(_6e,"CTRLConfig"),_6e.forEach(t),aUe=r(BA," (CTRL model)"),BA.forEach(t),nUe=i(L),om=n(L,"LI",{});var NA=s(om);pae=n(NA,"STRONG",{});var u6e=s(pae);sUe=r(u6e,"cvt"),u6e.forEach(t),lUe=r(NA," \u2014 "),GS=n(NA,"A",{href:!0});var b6e=s(GS);iUe=r(b6e,"CvtConfig"),b6e.forEach(t),dUe=r(NA," (CvT model)"),NA.forEach(t),cUe=i(L),rm=n(L,"LI",{});var IA=s(rm);_ae=n(IA,"STRONG",{});var v6e=s(_ae);fUe=r(v6e,"data2vec-audio"),v6e.forEach(t),mUe=r(IA," \u2014 "),OS=n(IA,"A",{href:!0});var F6e=s(OS);gUe=r(F6e,"Data2VecAudioConfig"),F6e.forEach(t),hUe=r(IA," (Data2VecAudio model)"),IA.forEach(t),pUe=i(L),tm=n(L,"LI",{});var qA=s(tm);uae=n(qA,"STRONG",{});var T6e=s(uae);_Ue=r(T6e,"data2vec-text"),T6e.forEach(t),uUe=r(qA," \u2014 "),VS=n(qA,"A",{href:!0});var M6e=s(VS);bUe=r(M6e,"Data2VecTextConfig"),M6e.forEach(t),vUe=r(qA," (Data2VecText model)"),qA.forEach(t),FUe=i(L),am=n(L,"LI",{});var jA=s(am);bae=n(jA,"STRONG",{});var E6e=s(bae);TUe=r(E6e,"data2vec-vision"),E6e.forEach(t),MUe=r(jA," \u2014 "),XS=n(jA,"A",{href:!0});var C6e=s(XS);EUe=r(C6e,"Data2VecVisionConfig"),C6e.forEach(t),CUe=r(jA," (Data2VecVision model)"),jA.forEach(t),wUe=i(L),nm=n(L,"LI",{});var DA=s(nm);vae=n(DA,"STRONG",{});var w6e=s(vae);AUe=r(w6e,"deberta"),w6e.forEach(t),LUe=r(DA," \u2014 "),zS=n(DA,"A",{href:!0});var A6e=s(zS);yUe=r(A6e,"DebertaConfig"),A6e.forEach(t),xUe=r(DA," (DeBERTa model)"),DA.forEach(t),$Ue=i(L),sm=n(L,"LI",{});var GA=s(sm);Fae=n(GA,"STRONG",{});var L6e=s(Fae);kUe=r(L6e,"deberta-v2"),L6e.forEach(t),SUe=r(GA," \u2014 "),QS=n(GA,"A",{href:!0});var y6e=s(QS);RUe=r(y6e,"DebertaV2Config"),y6e.forEach(t),PUe=r(GA," (DeBERTa-v2 model)"),GA.forEach(t),BUe=i(L),lm=n(L,"LI",{});var OA=s(lm);Tae=n(OA,"STRONG",{});var pet=s(Tae);NUe=r(pet,"decision_transformer"),pet.forEach(t),IUe=r(OA," \u2014 "),WS=n(OA,"A",{href:!0});var _et=s(WS);qUe=r(_et,"DecisionTransformerConfig"),_et.forEach(t),jUe=r(OA," (Decision Transformer model)"),OA.forEach(t),DUe=i(L),im=n(L,"LI",{});var x6e=s(im);Mae=n(x6e,"STRONG",{});var uet=s(Mae);GUe=r(uet,"deit"),uet.forEach(t),OUe=r(x6e," \u2014 "),HS=n(x6e,"A",{href:!0});var bet=s(HS);VUe=r(bet,"DeiTConfig"),bet.forEach(t),XUe=r(x6e," (DeiT model)"),x6e.forEach(t),zUe=i(L),dm=n(L,"LI",{});var $6e=s(dm);Eae=n($6e,"STRONG",{});var vet=s(Eae);QUe=r(vet,"detr"),vet.forEach(t),WUe=r($6e," \u2014 "),US=n($6e,"A",{href:!0});var Fet=s(US);HUe=r(Fet,"DetrConfig"),Fet.forEach(t),UUe=r($6e," (DETR model)"),$6e.forEach(t),JUe=i(L),cm=n(L,"LI",{});var k6e=s(cm);Cae=n(k6e,"STRONG",{});var Tet=s(Cae);YUe=r(Tet,"distilbert"),Tet.forEach(t),KUe=r(k6e," \u2014 "),JS=n(k6e,"A",{href:!0});var Met=s(JS);ZUe=r(Met,"DistilBertConfig"),Met.forEach(t),eJe=r(k6e," (DistilBERT model)"),k6e.forEach(t),oJe=i(L),fm=n(L,"LI",{});var S6e=s(fm);wae=n(S6e,"STRONG",{});var Eet=s(wae);rJe=r(Eet,"dpr"),Eet.forEach(t),tJe=r(S6e," \u2014 "),YS=n(S6e,"A",{href:!0});var Cet=s(YS);aJe=r(Cet,"DPRConfig"),Cet.forEach(t),nJe=r(S6e," (DPR model)"),S6e.forEach(t),sJe=i(L),mm=n(L,"LI",{});var R6e=s(mm);Aae=n(R6e,"STRONG",{});var wet=s(Aae);lJe=r(wet,"dpt"),wet.forEach(t),iJe=r(R6e," \u2014 "),KS=n(R6e,"A",{href:!0});var Aet=s(KS);dJe=r(Aet,"DPTConfig"),Aet.forEach(t),cJe=r(R6e," (DPT model)"),R6e.forEach(t),fJe=i(L),gm=n(L,"LI",{});var P6e=s(gm);Lae=n(P6e,"STRONG",{});var Let=s(Lae);mJe=r(Let,"electra"),Let.forEach(t),gJe=r(P6e," \u2014 "),ZS=n(P6e,"A",{href:!0});var yet=s(ZS);hJe=r(yet,"ElectraConfig"),yet.forEach(t),pJe=r(P6e," (ELECTRA model)"),P6e.forEach(t),_Je=i(L),hm=n(L,"LI",{});var B6e=s(hm);yae=n(B6e,"STRONG",{});var xet=s(yae);uJe=r(xet,"encoder-decoder"),xet.forEach(t),bJe=r(B6e," \u2014 "),eR=n(B6e,"A",{href:!0});var $et=s(eR);vJe=r($et,"EncoderDecoderConfig"),$et.forEach(t),FJe=r(B6e," (Encoder decoder model)"),B6e.forEach(t),TJe=i(L),pm=n(L,"LI",{});var N6e=s(pm);xae=n(N6e,"STRONG",{});var ket=s(xae);MJe=r(ket,"flaubert"),ket.forEach(t),EJe=r(N6e," \u2014 "),oR=n(N6e,"A",{href:!0});var Set=s(oR);CJe=r(Set,"FlaubertConfig"),Set.forEach(t),wJe=r(N6e," (FlauBERT model)"),N6e.forEach(t),AJe=i(L),_m=n(L,"LI",{});var I6e=s(_m);$ae=n(I6e,"STRONG",{});var Ret=s($ae);LJe=r(Ret,"flava"),Ret.forEach(t),yJe=r(I6e," \u2014 "),rR=n(I6e,"A",{href:!0});var Pet=s(rR);xJe=r(Pet,"FlavaConfig"),Pet.forEach(t),$Je=r(I6e," (FLAVA model)"),I6e.forEach(t),kJe=i(L),um=n(L,"LI",{});var q6e=s(um);kae=n(q6e,"STRONG",{});var Bet=s(kae);SJe=r(Bet,"fnet"),Bet.forEach(t),RJe=r(q6e," \u2014 "),tR=n(q6e,"A",{href:!0});var Net=s(tR);PJe=r(Net,"FNetConfig"),Net.forEach(t),BJe=r(q6e," (FNet model)"),q6e.forEach(t),NJe=i(L),bm=n(L,"LI",{});var j6e=s(bm);Sae=n(j6e,"STRONG",{});var Iet=s(Sae);IJe=r(Iet,"fsmt"),Iet.forEach(t),qJe=r(j6e," \u2014 "),aR=n(j6e,"A",{href:!0});var qet=s(aR);jJe=r(qet,"FSMTConfig"),qet.forEach(t),DJe=r(j6e," (FairSeq Machine-Translation model)"),j6e.forEach(t),GJe=i(L),vm=n(L,"LI",{});var D6e=s(vm);Rae=n(D6e,"STRONG",{});var jet=s(Rae);OJe=r(jet,"funnel"),jet.forEach(t),VJe=r(D6e," \u2014 "),nR=n(D6e,"A",{href:!0});var Det=s(nR);XJe=r(Det,"FunnelConfig"),Det.forEach(t),zJe=r(D6e," (Funnel Transformer model)"),D6e.forEach(t),QJe=i(L),Fm=n(L,"LI",{});var G6e=s(Fm);Pae=n(G6e,"STRONG",{});var Get=s(Pae);WJe=r(Get,"glpn"),Get.forEach(t),HJe=r(G6e," \u2014 "),sR=n(G6e,"A",{href:!0});var Oet=s(sR);UJe=r(Oet,"GLPNConfig"),Oet.forEach(t),JJe=r(G6e," (GLPN model)"),G6e.forEach(t),YJe=i(L),Tm=n(L,"LI",{});var O6e=s(Tm);Bae=n(O6e,"STRONG",{});var Vet=s(Bae);KJe=r(Vet,"gpt2"),Vet.forEach(t),ZJe=r(O6e," \u2014 "),lR=n(O6e,"A",{href:!0});var Xet=s(lR);eYe=r(Xet,"GPT2Config"),Xet.forEach(t),oYe=r(O6e," (OpenAI GPT-2 model)"),O6e.forEach(t),rYe=i(L),Mm=n(L,"LI",{});var V6e=s(Mm);Nae=n(V6e,"STRONG",{});var zet=s(Nae);tYe=r(zet,"gpt_neo"),zet.forEach(t),aYe=r(V6e," \u2014 "),iR=n(V6e,"A",{href:!0});var Qet=s(iR);nYe=r(Qet,"GPTNeoConfig"),Qet.forEach(t),sYe=r(V6e," (GPT Neo model)"),V6e.forEach(t),lYe=i(L),Em=n(L,"LI",{});var X6e=s(Em);Iae=n(X6e,"STRONG",{});var Wet=s(Iae);iYe=r(Wet,"gpt_neox"),Wet.forEach(t),dYe=r(X6e," \u2014 "),dR=n(X6e,"A",{href:!0});var Het=s(dR);cYe=r(Het,"GPTNeoXConfig"),Het.forEach(t),fYe=r(X6e," (GPT NeoX model)"),X6e.forEach(t),mYe=i(L),Cm=n(L,"LI",{});var z6e=s(Cm);qae=n(z6e,"STRONG",{});var Uet=s(qae);gYe=r(Uet,"gptj"),Uet.forEach(t),hYe=r(z6e," \u2014 "),cR=n(z6e,"A",{href:!0});var Jet=s(cR);pYe=r(Jet,"GPTJConfig"),Jet.forEach(t),_Ye=r(z6e," (GPT-J model)"),z6e.forEach(t),uYe=i(L),wm=n(L,"LI",{});var Q6e=s(wm);jae=n(Q6e,"STRONG",{});var Yet=s(jae);bYe=r(Yet,"groupvit"),Yet.forEach(t),vYe=r(Q6e," \u2014 "),fR=n(Q6e,"A",{href:!0});var Ket=s(fR);FYe=r(Ket,"GroupViTConfig"),Ket.forEach(t),TYe=r(Q6e," (GroupViT model)"),Q6e.forEach(t),MYe=i(L),Am=n(L,"LI",{});var W6e=s(Am);Dae=n(W6e,"STRONG",{});var Zet=s(Dae);EYe=r(Zet,"hubert"),Zet.forEach(t),CYe=r(W6e," \u2014 "),mR=n(W6e,"A",{href:!0});var eot=s(mR);wYe=r(eot,"HubertConfig"),eot.forEach(t),AYe=r(W6e," (Hubert model)"),W6e.forEach(t),LYe=i(L),Lm=n(L,"LI",{});var H6e=s(Lm);Gae=n(H6e,"STRONG",{});var oot=s(Gae);yYe=r(oot,"ibert"),oot.forEach(t),xYe=r(H6e," \u2014 "),gR=n(H6e,"A",{href:!0});var rot=s(gR);$Ye=r(rot,"IBertConfig"),rot.forEach(t),kYe=r(H6e," (I-BERT model)"),H6e.forEach(t),SYe=i(L),ym=n(L,"LI",{});var U6e=s(ym);Oae=n(U6e,"STRONG",{});var tot=s(Oae);RYe=r(tot,"imagegpt"),tot.forEach(t),PYe=r(U6e," \u2014 "),hR=n(U6e,"A",{href:!0});var aot=s(hR);BYe=r(aot,"ImageGPTConfig"),aot.forEach(t),NYe=r(U6e," (ImageGPT model)"),U6e.forEach(t),IYe=i(L),xm=n(L,"LI",{});var J6e=s(xm);Vae=n(J6e,"STRONG",{});var not=s(Vae);qYe=r(not,"layoutlm"),not.forEach(t),jYe=r(J6e," \u2014 "),pR=n(J6e,"A",{href:!0});var sot=s(pR);DYe=r(sot,"LayoutLMConfig"),sot.forEach(t),GYe=r(J6e," (LayoutLM model)"),J6e.forEach(t),OYe=i(L),$m=n(L,"LI",{});var Y6e=s($m);Xae=n(Y6e,"STRONG",{});var lot=s(Xae);VYe=r(lot,"layoutlmv2"),lot.forEach(t),XYe=r(Y6e," \u2014 "),_R=n(Y6e,"A",{href:!0});var iot=s(_R);zYe=r(iot,"LayoutLMv2Config"),iot.forEach(t),QYe=r(Y6e," (LayoutLMv2 model)"),Y6e.forEach(t),WYe=i(L),km=n(L,"LI",{});var K6e=s(km);zae=n(K6e,"STRONG",{});var dot=s(zae);HYe=r(dot,"layoutlmv3"),dot.forEach(t),UYe=r(K6e," \u2014 "),uR=n(K6e,"A",{href:!0});var cot=s(uR);JYe=r(cot,"LayoutLMv3Config"),cot.forEach(t),YYe=r(K6e," (LayoutLMv3 model)"),K6e.forEach(t),KYe=i(L),Sm=n(L,"LI",{});var Z6e=s(Sm);Qae=n(Z6e,"STRONG",{});var fot=s(Qae);ZYe=r(fot,"led"),fot.forEach(t),eKe=r(Z6e," \u2014 "),bR=n(Z6e,"A",{href:!0});var mot=s(bR);oKe=r(mot,"LEDConfig"),mot.forEach(t),rKe=r(Z6e," (LED model)"),Z6e.forEach(t),tKe=i(L),Rm=n(L,"LI",{});var eLe=s(Rm);Wae=n(eLe,"STRONG",{});var got=s(Wae);aKe=r(got,"levit"),got.forEach(t),nKe=r(eLe," \u2014 "),vR=n(eLe,"A",{href:!0});var hot=s(vR);sKe=r(hot,"LevitConfig"),hot.forEach(t),lKe=r(eLe," (LeViT model)"),eLe.forEach(t),iKe=i(L),Pm=n(L,"LI",{});var oLe=s(Pm);Hae=n(oLe,"STRONG",{});var pot=s(Hae);dKe=r(pot,"longformer"),pot.forEach(t),cKe=r(oLe," \u2014 "),FR=n(oLe,"A",{href:!0});var _ot=s(FR);fKe=r(_ot,"LongformerConfig"),_ot.forEach(t),mKe=r(oLe," (Longformer model)"),oLe.forEach(t),gKe=i(L),Bm=n(L,"LI",{});var rLe=s(Bm);Uae=n(rLe,"STRONG",{});var uot=s(Uae);hKe=r(uot,"longt5"),uot.forEach(t),pKe=r(rLe," \u2014 "),TR=n(rLe,"A",{href:!0});var bot=s(TR);_Ke=r(bot,"LongT5Config"),bot.forEach(t),uKe=r(rLe," (LongT5 model)"),rLe.forEach(t),bKe=i(L),Nm=n(L,"LI",{});var tLe=s(Nm);Jae=n(tLe,"STRONG",{});var vot=s(Jae);vKe=r(vot,"luke"),vot.forEach(t),FKe=r(tLe," \u2014 "),MR=n(tLe,"A",{href:!0});var Fot=s(MR);TKe=r(Fot,"LukeConfig"),Fot.forEach(t),MKe=r(tLe," (LUKE model)"),tLe.forEach(t),EKe=i(L),Im=n(L,"LI",{});var aLe=s(Im);Yae=n(aLe,"STRONG",{});var Tot=s(Yae);CKe=r(Tot,"lxmert"),Tot.forEach(t),wKe=r(aLe," \u2014 "),ER=n(aLe,"A",{href:!0});var Mot=s(ER);AKe=r(Mot,"LxmertConfig"),Mot.forEach(t),LKe=r(aLe," (LXMERT model)"),aLe.forEach(t),yKe=i(L),qm=n(L,"LI",{});var nLe=s(qm);Kae=n(nLe,"STRONG",{});var Eot=s(Kae);xKe=r(Eot,"m2m_100"),Eot.forEach(t),$Ke=r(nLe," \u2014 "),CR=n(nLe,"A",{href:!0});var Cot=s(CR);kKe=r(Cot,"M2M100Config"),Cot.forEach(t),SKe=r(nLe," (M2M100 model)"),nLe.forEach(t),RKe=i(L),jm=n(L,"LI",{});var sLe=s(jm);Zae=n(sLe,"STRONG",{});var wot=s(Zae);PKe=r(wot,"marian"),wot.forEach(t),BKe=r(sLe," \u2014 "),wR=n(sLe,"A",{href:!0});var Aot=s(wR);NKe=r(Aot,"MarianConfig"),Aot.forEach(t),IKe=r(sLe," (Marian model)"),sLe.forEach(t),qKe=i(L),Dm=n(L,"LI",{});var lLe=s(Dm);ene=n(lLe,"STRONG",{});var Lot=s(ene);jKe=r(Lot,"maskformer"),Lot.forEach(t),DKe=r(lLe," \u2014 "),AR=n(lLe,"A",{href:!0});var yot=s(AR);GKe=r(yot,"MaskFormerConfig"),yot.forEach(t),OKe=r(lLe," (MaskFormer model)"),lLe.forEach(t),VKe=i(L),Gm=n(L,"LI",{});var iLe=s(Gm);one=n(iLe,"STRONG",{});var xot=s(one);XKe=r(xot,"mbart"),xot.forEach(t),zKe=r(iLe," \u2014 "),LR=n(iLe,"A",{href:!0});var $ot=s(LR);QKe=r($ot,"MBartConfig"),$ot.forEach(t),WKe=r(iLe," (mBART model)"),iLe.forEach(t),HKe=i(L),Om=n(L,"LI",{});var dLe=s(Om);rne=n(dLe,"STRONG",{});var kot=s(rne);UKe=r(kot,"mctct"),kot.forEach(t),JKe=r(dLe," \u2014 "),yR=n(dLe,"A",{href:!0});var Sot=s(yR);YKe=r(Sot,"MCTCTConfig"),Sot.forEach(t),KKe=r(dLe," (M-CTC-T model)"),dLe.forEach(t),ZKe=i(L),Vm=n(L,"LI",{});var cLe=s(Vm);tne=n(cLe,"STRONG",{});var Rot=s(tne);eZe=r(Rot,"megatron-bert"),Rot.forEach(t),oZe=r(cLe," \u2014 "),xR=n(cLe,"A",{href:!0});var Pot=s(xR);rZe=r(Pot,"MegatronBertConfig"),Pot.forEach(t),tZe=r(cLe," (Megatron-BERT model)"),cLe.forEach(t),aZe=i(L),Xm=n(L,"LI",{});var fLe=s(Xm);ane=n(fLe,"STRONG",{});var Bot=s(ane);nZe=r(Bot,"mobilebert"),Bot.forEach(t),sZe=r(fLe," \u2014 "),$R=n(fLe,"A",{href:!0});var Not=s($R);lZe=r(Not,"MobileBertConfig"),Not.forEach(t),iZe=r(fLe," (MobileBERT model)"),fLe.forEach(t),dZe=i(L),zm=n(L,"LI",{});var mLe=s(zm);nne=n(mLe,"STRONG",{});var Iot=s(nne);cZe=r(Iot,"mpnet"),Iot.forEach(t),fZe=r(mLe," \u2014 "),kR=n(mLe,"A",{href:!0});var qot=s(kR);mZe=r(qot,"MPNetConfig"),qot.forEach(t),gZe=r(mLe," (MPNet model)"),mLe.forEach(t),hZe=i(L),Qm=n(L,"LI",{});var gLe=s(Qm);sne=n(gLe,"STRONG",{});var jot=s(sne);pZe=r(jot,"mt5"),jot.forEach(t),_Ze=r(gLe," \u2014 "),SR=n(gLe,"A",{href:!0});var Dot=s(SR);uZe=r(Dot,"MT5Config"),Dot.forEach(t),bZe=r(gLe," (MT5 model)"),gLe.forEach(t),vZe=i(L),Wm=n(L,"LI",{});var hLe=s(Wm);lne=n(hLe,"STRONG",{});var Got=s(lne);FZe=r(Got,"nezha"),Got.forEach(t),TZe=r(hLe," \u2014 "),RR=n(hLe,"A",{href:!0});var Oot=s(RR);MZe=r(Oot,"NezhaConfig"),Oot.forEach(t),EZe=r(hLe," (Nezha model)"),hLe.forEach(t),CZe=i(L),Hm=n(L,"LI",{});var pLe=s(Hm);ine=n(pLe,"STRONG",{});var Vot=s(ine);wZe=r(Vot,"nystromformer"),Vot.forEach(t),AZe=r(pLe," \u2014 "),PR=n(pLe,"A",{href:!0});var Xot=s(PR);LZe=r(Xot,"NystromformerConfig"),Xot.forEach(t),yZe=r(pLe," (Nystr\xF6mformer model)"),pLe.forEach(t),xZe=i(L),Um=n(L,"LI",{});var _Le=s(Um);dne=n(_Le,"STRONG",{});var zot=s(dne);$Ze=r(zot,"openai-gpt"),zot.forEach(t),kZe=r(_Le," \u2014 "),BR=n(_Le,"A",{href:!0});var Qot=s(BR);SZe=r(Qot,"OpenAIGPTConfig"),Qot.forEach(t),RZe=r(_Le," (OpenAI GPT model)"),_Le.forEach(t),PZe=i(L),Jm=n(L,"LI",{});var uLe=s(Jm);cne=n(uLe,"STRONG",{});var Wot=s(cne);BZe=r(Wot,"opt"),Wot.forEach(t),NZe=r(uLe," \u2014 "),NR=n(uLe,"A",{href:!0});var Hot=s(NR);IZe=r(Hot,"OPTConfig"),Hot.forEach(t),qZe=r(uLe," (OPT model)"),uLe.forEach(t),jZe=i(L),Ym=n(L,"LI",{});var bLe=s(Ym);fne=n(bLe,"STRONG",{});var Uot=s(fne);DZe=r(Uot,"pegasus"),Uot.forEach(t),GZe=r(bLe," \u2014 "),IR=n(bLe,"A",{href:!0});var Jot=s(IR);OZe=r(Jot,"PegasusConfig"),Jot.forEach(t),VZe=r(bLe," (Pegasus model)"),bLe.forEach(t),XZe=i(L),Km=n(L,"LI",{});var vLe=s(Km);mne=n(vLe,"STRONG",{});var Yot=s(mne);zZe=r(Yot,"perceiver"),Yot.forEach(t),QZe=r(vLe," \u2014 "),qR=n(vLe,"A",{href:!0});var Kot=s(qR);WZe=r(Kot,"PerceiverConfig"),Kot.forEach(t),HZe=r(vLe," (Perceiver model)"),vLe.forEach(t),UZe=i(L),Zm=n(L,"LI",{});var FLe=s(Zm);gne=n(FLe,"STRONG",{});var Zot=s(gne);JZe=r(Zot,"plbart"),Zot.forEach(t),YZe=r(FLe," \u2014 "),jR=n(FLe,"A",{href:!0});var ert=s(jR);KZe=r(ert,"PLBartConfig"),ert.forEach(t),ZZe=r(FLe," (PLBart model)"),FLe.forEach(t),eeo=i(L),eg=n(L,"LI",{});var TLe=s(eg);hne=n(TLe,"STRONG",{});var ort=s(hne);oeo=r(ort,"poolformer"),ort.forEach(t),reo=r(TLe," \u2014 "),DR=n(TLe,"A",{href:!0});var rrt=s(DR);teo=r(rrt,"PoolFormerConfig"),rrt.forEach(t),aeo=r(TLe," (PoolFormer model)"),TLe.forEach(t),neo=i(L),og=n(L,"LI",{});var MLe=s(og);pne=n(MLe,"STRONG",{});var trt=s(pne);seo=r(trt,"prophetnet"),trt.forEach(t),leo=r(MLe," \u2014 "),GR=n(MLe,"A",{href:!0});var art=s(GR);ieo=r(art,"ProphetNetConfig"),art.forEach(t),deo=r(MLe," (ProphetNet model)"),MLe.forEach(t),ceo=i(L),rg=n(L,"LI",{});var ELe=s(rg);_ne=n(ELe,"STRONG",{});var nrt=s(_ne);feo=r(nrt,"qdqbert"),nrt.forEach(t),meo=r(ELe," \u2014 "),OR=n(ELe,"A",{href:!0});var srt=s(OR);geo=r(srt,"QDQBertConfig"),srt.forEach(t),heo=r(ELe," (QDQBert model)"),ELe.forEach(t),peo=i(L),tg=n(L,"LI",{});var CLe=s(tg);une=n(CLe,"STRONG",{});var lrt=s(une);_eo=r(lrt,"rag"),lrt.forEach(t),ueo=r(CLe," \u2014 "),VR=n(CLe,"A",{href:!0});var irt=s(VR);beo=r(irt,"RagConfig"),irt.forEach(t),veo=r(CLe," (RAG model)"),CLe.forEach(t),Feo=i(L),ag=n(L,"LI",{});var wLe=s(ag);bne=n(wLe,"STRONG",{});var drt=s(bne);Teo=r(drt,"realm"),drt.forEach(t),Meo=r(wLe," \u2014 "),XR=n(wLe,"A",{href:!0});var crt=s(XR);Eeo=r(crt,"RealmConfig"),crt.forEach(t),Ceo=r(wLe," (REALM model)"),wLe.forEach(t),weo=i(L),ng=n(L,"LI",{});var ALe=s(ng);vne=n(ALe,"STRONG",{});var frt=s(vne);Aeo=r(frt,"reformer"),frt.forEach(t),Leo=r(ALe," \u2014 "),zR=n(ALe,"A",{href:!0});var mrt=s(zR);yeo=r(mrt,"ReformerConfig"),mrt.forEach(t),xeo=r(ALe," (Reformer model)"),ALe.forEach(t),$eo=i(L),sg=n(L,"LI",{});var LLe=s(sg);Fne=n(LLe,"STRONG",{});var grt=s(Fne);keo=r(grt,"regnet"),grt.forEach(t),Seo=r(LLe," \u2014 "),QR=n(LLe,"A",{href:!0});var hrt=s(QR);Reo=r(hrt,"RegNetConfig"),hrt.forEach(t),Peo=r(LLe," (RegNet model)"),LLe.forEach(t),Beo=i(L),lg=n(L,"LI",{});var yLe=s(lg);Tne=n(yLe,"STRONG",{});var prt=s(Tne);Neo=r(prt,"rembert"),prt.forEach(t),Ieo=r(yLe," \u2014 "),WR=n(yLe,"A",{href:!0});var _rt=s(WR);qeo=r(_rt,"RemBertConfig"),_rt.forEach(t),jeo=r(yLe," (RemBERT model)"),yLe.forEach(t),Deo=i(L),ig=n(L,"LI",{});var xLe=s(ig);Mne=n(xLe,"STRONG",{});var urt=s(Mne);Geo=r(urt,"resnet"),urt.forEach(t),Oeo=r(xLe," \u2014 "),HR=n(xLe,"A",{href:!0});var brt=s(HR);Veo=r(brt,"ResNetConfig"),brt.forEach(t),Xeo=r(xLe," (ResNet model)"),xLe.forEach(t),zeo=i(L),dg=n(L,"LI",{});var $Le=s(dg);Ene=n($Le,"STRONG",{});var vrt=s(Ene);Qeo=r(vrt,"retribert"),vrt.forEach(t),Weo=r($Le," \u2014 "),UR=n($Le,"A",{href:!0});var Frt=s(UR);Heo=r(Frt,"RetriBertConfig"),Frt.forEach(t),Ueo=r($Le," (RetriBERT model)"),$Le.forEach(t),Jeo=i(L),cg=n(L,"LI",{});var kLe=s(cg);Cne=n(kLe,"STRONG",{});var Trt=s(Cne);Yeo=r(Trt,"roberta"),Trt.forEach(t),Keo=r(kLe," \u2014 "),JR=n(kLe,"A",{href:!0});var Mrt=s(JR);Zeo=r(Mrt,"RobertaConfig"),Mrt.forEach(t),eoo=r(kLe," (RoBERTa model)"),kLe.forEach(t),ooo=i(L),fg=n(L,"LI",{});var SLe=s(fg);wne=n(SLe,"STRONG",{});var Ert=s(wne);roo=r(Ert,"roformer"),Ert.forEach(t),too=r(SLe," \u2014 "),YR=n(SLe,"A",{href:!0});var Crt=s(YR);aoo=r(Crt,"RoFormerConfig"),Crt.forEach(t),noo=r(SLe," (RoFormer model)"),SLe.forEach(t),soo=i(L),mg=n(L,"LI",{});var RLe=s(mg);Ane=n(RLe,"STRONG",{});var wrt=s(Ane);loo=r(wrt,"segformer"),wrt.forEach(t),ioo=r(RLe," \u2014 "),KR=n(RLe,"A",{href:!0});var Art=s(KR);doo=r(Art,"SegformerConfig"),Art.forEach(t),coo=r(RLe," (SegFormer model)"),RLe.forEach(t),foo=i(L),gg=n(L,"LI",{});var PLe=s(gg);Lne=n(PLe,"STRONG",{});var Lrt=s(Lne);moo=r(Lrt,"sew"),Lrt.forEach(t),goo=r(PLe," \u2014 "),ZR=n(PLe,"A",{href:!0});var yrt=s(ZR);hoo=r(yrt,"SEWConfig"),yrt.forEach(t),poo=r(PLe," (SEW model)"),PLe.forEach(t),_oo=i(L),hg=n(L,"LI",{});var BLe=s(hg);yne=n(BLe,"STRONG",{});var xrt=s(yne);uoo=r(xrt,"sew-d"),xrt.forEach(t),boo=r(BLe," \u2014 "),eP=n(BLe,"A",{href:!0});var $rt=s(eP);voo=r($rt,"SEWDConfig"),$rt.forEach(t),Foo=r(BLe," (SEW-D model)"),BLe.forEach(t),Too=i(L),pg=n(L,"LI",{});var NLe=s(pg);xne=n(NLe,"STRONG",{});var krt=s(xne);Moo=r(krt,"speech-encoder-decoder"),krt.forEach(t),Eoo=r(NLe," \u2014 "),oP=n(NLe,"A",{href:!0});var Srt=s(oP);Coo=r(Srt,"SpeechEncoderDecoderConfig"),Srt.forEach(t),woo=r(NLe," (Speech Encoder decoder model)"),NLe.forEach(t),Aoo=i(L),_g=n(L,"LI",{});var ILe=s(_g);$ne=n(ILe,"STRONG",{});var Rrt=s($ne);Loo=r(Rrt,"speech_to_text"),Rrt.forEach(t),yoo=r(ILe," \u2014 "),rP=n(ILe,"A",{href:!0});var Prt=s(rP);xoo=r(Prt,"Speech2TextConfig"),Prt.forEach(t),$oo=r(ILe," (Speech2Text model)"),ILe.forEach(t),koo=i(L),ug=n(L,"LI",{});var qLe=s(ug);kne=n(qLe,"STRONG",{});var Brt=s(kne);Soo=r(Brt,"speech_to_text_2"),Brt.forEach(t),Roo=r(qLe," \u2014 "),tP=n(qLe,"A",{href:!0});var Nrt=s(tP);Poo=r(Nrt,"Speech2Text2Config"),Nrt.forEach(t),Boo=r(qLe," (Speech2Text2 model)"),qLe.forEach(t),Noo=i(L),bg=n(L,"LI",{});var jLe=s(bg);Sne=n(jLe,"STRONG",{});var Irt=s(Sne);Ioo=r(Irt,"splinter"),Irt.forEach(t),qoo=r(jLe," \u2014 "),aP=n(jLe,"A",{href:!0});var qrt=s(aP);joo=r(qrt,"SplinterConfig"),qrt.forEach(t),Doo=r(jLe," (Splinter model)"),jLe.forEach(t),Goo=i(L),vg=n(L,"LI",{});var DLe=s(vg);Rne=n(DLe,"STRONG",{});var jrt=s(Rne);Ooo=r(jrt,"squeezebert"),jrt.forEach(t),Voo=r(DLe," \u2014 "),nP=n(DLe,"A",{href:!0});var Drt=s(nP);Xoo=r(Drt,"SqueezeBertConfig"),Drt.forEach(t),zoo=r(DLe," (SqueezeBERT model)"),DLe.forEach(t),Qoo=i(L),Fg=n(L,"LI",{});var GLe=s(Fg);Pne=n(GLe,"STRONG",{});var Grt=s(Pne);Woo=r(Grt,"swin"),Grt.forEach(t),Hoo=r(GLe," \u2014 "),sP=n(GLe,"A",{href:!0});var Ort=s(sP);Uoo=r(Ort,"SwinConfig"),Ort.forEach(t),Joo=r(GLe," (Swin Transformer model)"),GLe.forEach(t),Yoo=i(L),Tg=n(L,"LI",{});var OLe=s(Tg);Bne=n(OLe,"STRONG",{});var Vrt=s(Bne);Koo=r(Vrt,"t5"),Vrt.forEach(t),Zoo=r(OLe," \u2014 "),lP=n(OLe,"A",{href:!0});var Xrt=s(lP);ero=r(Xrt,"T5Config"),Xrt.forEach(t),oro=r(OLe," (T5 model)"),OLe.forEach(t),rro=i(L),Mg=n(L,"LI",{});var VLe=s(Mg);Nne=n(VLe,"STRONG",{});var zrt=s(Nne);tro=r(zrt,"tapas"),zrt.forEach(t),aro=r(VLe," \u2014 "),iP=n(VLe,"A",{href:!0});var Qrt=s(iP);nro=r(Qrt,"TapasConfig"),Qrt.forEach(t),sro=r(VLe," (TAPAS model)"),VLe.forEach(t),lro=i(L),Eg=n(L,"LI",{});var XLe=s(Eg);Ine=n(XLe,"STRONG",{});var Wrt=s(Ine);iro=r(Wrt,"trajectory_transformer"),Wrt.forEach(t),dro=r(XLe," \u2014 "),dP=n(XLe,"A",{href:!0});var Hrt=s(dP);cro=r(Hrt,"TrajectoryTransformerConfig"),Hrt.forEach(t),fro=r(XLe," (Trajectory Transformer model)"),XLe.forEach(t),mro=i(L),Cg=n(L,"LI",{});var zLe=s(Cg);qne=n(zLe,"STRONG",{});var Urt=s(qne);gro=r(Urt,"transfo-xl"),Urt.forEach(t),hro=r(zLe," \u2014 "),cP=n(zLe,"A",{href:!0});var Jrt=s(cP);pro=r(Jrt,"TransfoXLConfig"),Jrt.forEach(t),_ro=r(zLe," (Transformer-XL model)"),zLe.forEach(t),uro=i(L),wg=n(L,"LI",{});var QLe=s(wg);jne=n(QLe,"STRONG",{});var Yrt=s(jne);bro=r(Yrt,"trocr"),Yrt.forEach(t),vro=r(QLe," \u2014 "),fP=n(QLe,"A",{href:!0});var Krt=s(fP);Fro=r(Krt,"TrOCRConfig"),Krt.forEach(t),Tro=r(QLe," (TrOCR model)"),QLe.forEach(t),Mro=i(L),Ag=n(L,"LI",{});var WLe=s(Ag);Dne=n(WLe,"STRONG",{});var Zrt=s(Dne);Ero=r(Zrt,"unispeech"),Zrt.forEach(t),Cro=r(WLe," \u2014 "),mP=n(WLe,"A",{href:!0});var ett=s(mP);wro=r(ett,"UniSpeechConfig"),ett.forEach(t),Aro=r(WLe," (UniSpeech model)"),WLe.forEach(t),Lro=i(L),Lg=n(L,"LI",{});var HLe=s(Lg);Gne=n(HLe,"STRONG",{});var ott=s(Gne);yro=r(ott,"unispeech-sat"),ott.forEach(t),xro=r(HLe," \u2014 "),gP=n(HLe,"A",{href:!0});var rtt=s(gP);$ro=r(rtt,"UniSpeechSatConfig"),rtt.forEach(t),kro=r(HLe," (UniSpeechSat model)"),HLe.forEach(t),Sro=i(L),yg=n(L,"LI",{});var ULe=s(yg);One=n(ULe,"STRONG",{});var ttt=s(One);Rro=r(ttt,"van"),ttt.forEach(t),Pro=r(ULe," \u2014 "),hP=n(ULe,"A",{href:!0});var att=s(hP);Bro=r(att,"VanConfig"),att.forEach(t),Nro=r(ULe," (VAN model)"),ULe.forEach(t),Iro=i(L),xg=n(L,"LI",{});var JLe=s(xg);Vne=n(JLe,"STRONG",{});var ntt=s(Vne);qro=r(ntt,"vilt"),ntt.forEach(t),jro=r(JLe," \u2014 "),pP=n(JLe,"A",{href:!0});var stt=s(pP);Dro=r(stt,"ViltConfig"),stt.forEach(t),Gro=r(JLe," (ViLT model)"),JLe.forEach(t),Oro=i(L),$g=n(L,"LI",{});var YLe=s($g);Xne=n(YLe,"STRONG",{});var ltt=s(Xne);Vro=r(ltt,"vision-encoder-decoder"),ltt.forEach(t),Xro=r(YLe," \u2014 "),_P=n(YLe,"A",{href:!0});var itt=s(_P);zro=r(itt,"VisionEncoderDecoderConfig"),itt.forEach(t),Qro=r(YLe," (Vision Encoder decoder model)"),YLe.forEach(t),Wro=i(L),kg=n(L,"LI",{});var KLe=s(kg);zne=n(KLe,"STRONG",{});var dtt=s(zne);Hro=r(dtt,"vision-text-dual-encoder"),dtt.forEach(t),Uro=r(KLe," \u2014 "),uP=n(KLe,"A",{href:!0});var ctt=s(uP);Jro=r(ctt,"VisionTextDualEncoderConfig"),ctt.forEach(t),Yro=r(KLe," (VisionTextDualEncoder model)"),KLe.forEach(t),Kro=i(L),Sg=n(L,"LI",{});var ZLe=s(Sg);Qne=n(ZLe,"STRONG",{});var ftt=s(Qne);Zro=r(ftt,"visual_bert"),ftt.forEach(t),eto=r(ZLe," \u2014 "),bP=n(ZLe,"A",{href:!0});var mtt=s(bP);oto=r(mtt,"VisualBertConfig"),mtt.forEach(t),rto=r(ZLe," (VisualBERT model)"),ZLe.forEach(t),tto=i(L),Rg=n(L,"LI",{});var eye=s(Rg);Wne=n(eye,"STRONG",{});var gtt=s(Wne);ato=r(gtt,"vit"),gtt.forEach(t),nto=r(eye," \u2014 "),vP=n(eye,"A",{href:!0});var htt=s(vP);sto=r(htt,"ViTConfig"),htt.forEach(t),lto=r(eye," (ViT model)"),eye.forEach(t),ito=i(L),Pg=n(L,"LI",{});var oye=s(Pg);Hne=n(oye,"STRONG",{});var ptt=s(Hne);dto=r(ptt,"vit_mae"),ptt.forEach(t),cto=r(oye," \u2014 "),FP=n(oye,"A",{href:!0});var _tt=s(FP);fto=r(_tt,"ViTMAEConfig"),_tt.forEach(t),mto=r(oye," (ViTMAE model)"),oye.forEach(t),gto=i(L),Bg=n(L,"LI",{});var rye=s(Bg);Une=n(rye,"STRONG",{});var utt=s(Une);hto=r(utt,"wav2vec2"),utt.forEach(t),pto=r(rye," \u2014 "),TP=n(rye,"A",{href:!0});var btt=s(TP);_to=r(btt,"Wav2Vec2Config"),btt.forEach(t),uto=r(rye," (Wav2Vec2 model)"),rye.forEach(t),bto=i(L),Ng=n(L,"LI",{});var tye=s(Ng);Jne=n(tye,"STRONG",{});var vtt=s(Jne);vto=r(vtt,"wav2vec2-conformer"),vtt.forEach(t),Fto=r(tye," \u2014 "),MP=n(tye,"A",{href:!0});var Ftt=s(MP);Tto=r(Ftt,"Wav2Vec2ConformerConfig"),Ftt.forEach(t),Mto=r(tye," (Wav2Vec2-Conformer model)"),tye.forEach(t),Eto=i(L),Ig=n(L,"LI",{});var aye=s(Ig);Yne=n(aye,"STRONG",{});var Ttt=s(Yne);Cto=r(Ttt,"wavlm"),Ttt.forEach(t),wto=r(aye," \u2014 "),EP=n(aye,"A",{href:!0});var Mtt=s(EP);Ato=r(Mtt,"WavLMConfig"),Mtt.forEach(t),Lto=r(aye," (WavLM model)"),aye.forEach(t),yto=i(L),qg=n(L,"LI",{});var nye=s(qg);Kne=n(nye,"STRONG",{});var Ett=s(Kne);xto=r(Ett,"xglm"),Ett.forEach(t),$to=r(nye," \u2014 "),CP=n(nye,"A",{href:!0});var Ctt=s(CP);kto=r(Ctt,"XGLMConfig"),Ctt.forEach(t),Sto=r(nye," (XGLM model)"),nye.forEach(t),Rto=i(L),jg=n(L,"LI",{});var sye=s(jg);Zne=n(sye,"STRONG",{});var wtt=s(Zne);Pto=r(wtt,"xlm"),wtt.forEach(t),Bto=r(sye," \u2014 "),wP=n(sye,"A",{href:!0});var Att=s(wP);Nto=r(Att,"XLMConfig"),Att.forEach(t),Ito=r(sye," (XLM model)"),sye.forEach(t),qto=i(L),Dg=n(L,"LI",{});var lye=s(Dg);ese=n(lye,"STRONG",{});var Ltt=s(ese);jto=r(Ltt,"xlm-prophetnet"),Ltt.forEach(t),Dto=r(lye," \u2014 "),AP=n(lye,"A",{href:!0});var ytt=s(AP);Gto=r(ytt,"XLMProphetNetConfig"),ytt.forEach(t),Oto=r(lye," (XLM-ProphetNet model)"),lye.forEach(t),Vto=i(L),Gg=n(L,"LI",{});var iye=s(Gg);ose=n(iye,"STRONG",{});var xtt=s(ose);Xto=r(xtt,"xlm-roberta"),xtt.forEach(t),zto=r(iye," \u2014 "),LP=n(iye,"A",{href:!0});var $tt=s(LP);Qto=r($tt,"XLMRobertaConfig"),$tt.forEach(t),Wto=r(iye," (XLM-RoBERTa model)"),iye.forEach(t),Hto=i(L),Og=n(L,"LI",{});var dye=s(Og);rse=n(dye,"STRONG",{});var ktt=s(rse);Uto=r(ktt,"xlm-roberta-xl"),ktt.forEach(t),Jto=r(dye," \u2014 "),yP=n(dye,"A",{href:!0});var Stt=s(yP);Yto=r(Stt,"XLMRobertaXLConfig"),Stt.forEach(t),Kto=r(dye," (XLM-RoBERTa-XL model)"),dye.forEach(t),Zto=i(L),Vg=n(L,"LI",{});var cye=s(Vg);tse=n(cye,"STRONG",{});var Rtt=s(tse);eao=r(Rtt,"xlnet"),Rtt.forEach(t),oao=r(cye," \u2014 "),xP=n(cye,"A",{href:!0});var Ptt=s(xP);rao=r(Ptt,"XLNetConfig"),Ptt.forEach(t),tao=r(cye," (XLNet model)"),cye.forEach(t),aao=i(L),Xg=n(L,"LI",{});var fye=s(Xg);ase=n(fye,"STRONG",{});var Btt=s(ase);nao=r(Btt,"yolos"),Btt.forEach(t),sao=r(fye," \u2014 "),$P=n(fye,"A",{href:!0});var Ntt=s($P);lao=r(Ntt,"YolosConfig"),Ntt.forEach(t),iao=r(fye," (YOLOS model)"),fye.forEach(t),dao=i(L),zg=n(L,"LI",{});var mye=s(zg);nse=n(mye,"STRONG",{});var Itt=s(nse);cao=r(Itt,"yoso"),Itt.forEach(t),fao=r(mye," \u2014 "),kP=n(mye,"A",{href:!0});var qtt=s(kP);mao=r(qtt,"YosoConfig"),qtt.forEach(t),gao=r(mye," (YOSO model)"),mye.forEach(t),L.forEach(t),hao=i(at),T(Qg.$$.fragment,at),at.forEach(t),pao=i(tt),Wg=n(tt,"DIV",{class:!0});var zXe=s(Wg);T(UL.$$.fragment,zXe),_ao=i(zXe),sse=n(zXe,"P",{});var jtt=s(sse);uao=r(jtt,"Register a new configuration for this class."),jtt.forEach(t),zXe.forEach(t),tt.forEach(t),QOe=i(f),Pi=n(f,"H2",{class:!0});var QXe=s(Pi);Hg=n(QXe,"A",{id:!0,class:!0,href:!0});var Dtt=s(Hg);lse=n(Dtt,"SPAN",{});var Gtt=s(lse);T(JL.$$.fragment,Gtt),Gtt.forEach(t),Dtt.forEach(t),bao=i(QXe),ise=n(QXe,"SPAN",{});var Ott=s(ise);vao=r(Ott,"AutoTokenizer"),Ott.forEach(t),QXe.forEach(t),WOe=i(f),Ao=n(f,"DIV",{class:!0});var Js=s(Ao);T(YL.$$.fragment,Js),Fao=i(Js),KL=n(Js,"P",{});var WXe=s(KL);Tao=r(WXe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),SP=n(WXe,"A",{href:!0});var Vtt=s(SP);Mao=r(Vtt,"AutoTokenizer.from_pretrained()"),Vtt.forEach(t),Eao=r(WXe," class method."),WXe.forEach(t),Cao=i(Js),ZL=n(Js,"P",{});var HXe=s(ZL);wao=r(HXe,"This class cannot be instantiated directly using "),dse=n(HXe,"CODE",{});var Xtt=s(dse);Aao=r(Xtt,"__init__()"),Xtt.forEach(t),Lao=r(HXe," (throws an error)."),HXe.forEach(t),yao=i(Js),yr=n(Js,"DIV",{class:!0});var Ys=s(yr);T(ey.$$.fragment,Ys),xao=i(Ys),cse=n(Ys,"P",{});var ztt=s(cse);$ao=r(ztt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),ztt.forEach(t),kao=i(Ys),Ra=n(Ys,"P",{});var VA=s(Ra);Sao=r(VA,"The tokenizer class to instantiate is selected based on the "),fse=n(VA,"CODE",{});var Qtt=s(fse);Rao=r(Qtt,"model_type"),Qtt.forEach(t),Pao=r(VA,` property of the config object (either
passed as an argument or loaded from `),mse=n(VA,"CODE",{});var Wtt=s(mse);Bao=r(Wtt,"pretrained_model_name_or_path"),Wtt.forEach(t),Nao=r(VA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gse=n(VA,"CODE",{});var Htt=s(gse);Iao=r(Htt,"pretrained_model_name_or_path"),Htt.forEach(t),qao=r(VA,":"),VA.forEach(t),jao=i(Ys),k=n(Ys,"UL",{});var S=s(k);jn=n(S,"LI",{});var sk=s(jn);hse=n(sk,"STRONG",{});var Utt=s(hse);Dao=r(Utt,"albert"),Utt.forEach(t),Gao=r(sk," \u2014 "),RP=n(sk,"A",{href:!0});var Jtt=s(RP);Oao=r(Jtt,"AlbertTokenizer"),Jtt.forEach(t),Vao=r(sk," or "),PP=n(sk,"A",{href:!0});var Ytt=s(PP);Xao=r(Ytt,"AlbertTokenizerFast"),Ytt.forEach(t),zao=r(sk," (ALBERT model)"),sk.forEach(t),Qao=i(S),Dn=n(S,"LI",{});var lk=s(Dn);pse=n(lk,"STRONG",{});var Ktt=s(pse);Wao=r(Ktt,"bart"),Ktt.forEach(t),Hao=r(lk," \u2014 "),BP=n(lk,"A",{href:!0});var Ztt=s(BP);Uao=r(Ztt,"BartTokenizer"),Ztt.forEach(t),Jao=r(lk," or "),NP=n(lk,"A",{href:!0});var eat=s(NP);Yao=r(eat,"BartTokenizerFast"),eat.forEach(t),Kao=r(lk," (BART model)"),lk.forEach(t),Zao=i(S),Gn=n(S,"LI",{});var ik=s(Gn);_se=n(ik,"STRONG",{});var oat=s(_se);eno=r(oat,"barthez"),oat.forEach(t),ono=r(ik," \u2014 "),IP=n(ik,"A",{href:!0});var rat=s(IP);rno=r(rat,"BarthezTokenizer"),rat.forEach(t),tno=r(ik," or "),qP=n(ik,"A",{href:!0});var tat=s(qP);ano=r(tat,"BarthezTokenizerFast"),tat.forEach(t),nno=r(ik," (BARThez model)"),ik.forEach(t),sno=i(S),Ug=n(S,"LI",{});var gye=s(Ug);use=n(gye,"STRONG",{});var aat=s(use);lno=r(aat,"bartpho"),aat.forEach(t),ino=r(gye," \u2014 "),jP=n(gye,"A",{href:!0});var nat=s(jP);dno=r(nat,"BartphoTokenizer"),nat.forEach(t),cno=r(gye," (BARTpho model)"),gye.forEach(t),fno=i(S),On=n(S,"LI",{});var dk=s(On);bse=n(dk,"STRONG",{});var sat=s(bse);mno=r(sat,"bert"),sat.forEach(t),gno=r(dk," \u2014 "),DP=n(dk,"A",{href:!0});var lat=s(DP);hno=r(lat,"BertTokenizer"),lat.forEach(t),pno=r(dk," or "),GP=n(dk,"A",{href:!0});var iat=s(GP);_no=r(iat,"BertTokenizerFast"),iat.forEach(t),uno=r(dk," (BERT model)"),dk.forEach(t),bno=i(S),Jg=n(S,"LI",{});var hye=s(Jg);vse=n(hye,"STRONG",{});var dat=s(vse);vno=r(dat,"bert-generation"),dat.forEach(t),Fno=r(hye," \u2014 "),OP=n(hye,"A",{href:!0});var cat=s(OP);Tno=r(cat,"BertGenerationTokenizer"),cat.forEach(t),Mno=r(hye," (Bert Generation model)"),hye.forEach(t),Eno=i(S),Yg=n(S,"LI",{});var pye=s(Yg);Fse=n(pye,"STRONG",{});var fat=s(Fse);Cno=r(fat,"bert-japanese"),fat.forEach(t),wno=r(pye," \u2014 "),VP=n(pye,"A",{href:!0});var mat=s(VP);Ano=r(mat,"BertJapaneseTokenizer"),mat.forEach(t),Lno=r(pye," (BertJapanese model)"),pye.forEach(t),yno=i(S),Kg=n(S,"LI",{});var _ye=s(Kg);Tse=n(_ye,"STRONG",{});var gat=s(Tse);xno=r(gat,"bertweet"),gat.forEach(t),$no=r(_ye," \u2014 "),XP=n(_ye,"A",{href:!0});var hat=s(XP);kno=r(hat,"BertweetTokenizer"),hat.forEach(t),Sno=r(_ye," (BERTweet model)"),_ye.forEach(t),Rno=i(S),Vn=n(S,"LI",{});var ck=s(Vn);Mse=n(ck,"STRONG",{});var pat=s(Mse);Pno=r(pat,"big_bird"),pat.forEach(t),Bno=r(ck," \u2014 "),zP=n(ck,"A",{href:!0});var _at=s(zP);Nno=r(_at,"BigBirdTokenizer"),_at.forEach(t),Ino=r(ck," or "),QP=n(ck,"A",{href:!0});var uat=s(QP);qno=r(uat,"BigBirdTokenizerFast"),uat.forEach(t),jno=r(ck," (BigBird model)"),ck.forEach(t),Dno=i(S),Xn=n(S,"LI",{});var fk=s(Xn);Ese=n(fk,"STRONG",{});var bat=s(Ese);Gno=r(bat,"bigbird_pegasus"),bat.forEach(t),Ono=r(fk," \u2014 "),WP=n(fk,"A",{href:!0});var vat=s(WP);Vno=r(vat,"PegasusTokenizer"),vat.forEach(t),Xno=r(fk," or "),HP=n(fk,"A",{href:!0});var Fat=s(HP);zno=r(Fat,"PegasusTokenizerFast"),Fat.forEach(t),Qno=r(fk," (BigBird-Pegasus model)"),fk.forEach(t),Wno=i(S),zn=n(S,"LI",{});var mk=s(zn);Cse=n(mk,"STRONG",{});var Tat=s(Cse);Hno=r(Tat,"blenderbot"),Tat.forEach(t),Uno=r(mk," \u2014 "),UP=n(mk,"A",{href:!0});var Mat=s(UP);Jno=r(Mat,"BlenderbotTokenizer"),Mat.forEach(t),Yno=r(mk," or "),JP=n(mk,"A",{href:!0});var Eat=s(JP);Kno=r(Eat,"BlenderbotTokenizerFast"),Eat.forEach(t),Zno=r(mk," (Blenderbot model)"),mk.forEach(t),eso=i(S),Zg=n(S,"LI",{});var uye=s(Zg);wse=n(uye,"STRONG",{});var Cat=s(wse);oso=r(Cat,"blenderbot-small"),Cat.forEach(t),rso=r(uye," \u2014 "),YP=n(uye,"A",{href:!0});var wat=s(YP);tso=r(wat,"BlenderbotSmallTokenizer"),wat.forEach(t),aso=r(uye," (BlenderbotSmall model)"),uye.forEach(t),nso=i(S),eh=n(S,"LI",{});var bye=s(eh);Ase=n(bye,"STRONG",{});var Aat=s(Ase);sso=r(Aat,"bloom"),Aat.forEach(t),lso=r(bye," \u2014 "),KP=n(bye,"A",{href:!0});var Lat=s(KP);iso=r(Lat,"BloomTokenizerFast"),Lat.forEach(t),dso=r(bye," (BLOOM model)"),bye.forEach(t),cso=i(S),oh=n(S,"LI",{});var vye=s(oh);Lse=n(vye,"STRONG",{});var yat=s(Lse);fso=r(yat,"byt5"),yat.forEach(t),mso=r(vye," \u2014 "),ZP=n(vye,"A",{href:!0});var xat=s(ZP);gso=r(xat,"ByT5Tokenizer"),xat.forEach(t),hso=r(vye," (ByT5 model)"),vye.forEach(t),pso=i(S),Qn=n(S,"LI",{});var gk=s(Qn);yse=n(gk,"STRONG",{});var $at=s(yse);_so=r($at,"camembert"),$at.forEach(t),uso=r(gk," \u2014 "),eB=n(gk,"A",{href:!0});var kat=s(eB);bso=r(kat,"CamembertTokenizer"),kat.forEach(t),vso=r(gk," or "),oB=n(gk,"A",{href:!0});var Sat=s(oB);Fso=r(Sat,"CamembertTokenizerFast"),Sat.forEach(t),Tso=r(gk," (CamemBERT model)"),gk.forEach(t),Mso=i(S),rh=n(S,"LI",{});var Fye=s(rh);xse=n(Fye,"STRONG",{});var Rat=s(xse);Eso=r(Rat,"canine"),Rat.forEach(t),Cso=r(Fye," \u2014 "),rB=n(Fye,"A",{href:!0});var Pat=s(rB);wso=r(Pat,"CanineTokenizer"),Pat.forEach(t),Aso=r(Fye," (CANINE model)"),Fye.forEach(t),Lso=i(S),Wn=n(S,"LI",{});var hk=s(Wn);$se=n(hk,"STRONG",{});var Bat=s($se);yso=r(Bat,"clip"),Bat.forEach(t),xso=r(hk," \u2014 "),tB=n(hk,"A",{href:!0});var Nat=s(tB);$so=r(Nat,"CLIPTokenizer"),Nat.forEach(t),kso=r(hk," or "),aB=n(hk,"A",{href:!0});var Iat=s(aB);Sso=r(Iat,"CLIPTokenizerFast"),Iat.forEach(t),Rso=r(hk," (CLIP model)"),hk.forEach(t),Pso=i(S),Hn=n(S,"LI",{});var pk=s(Hn);kse=n(pk,"STRONG",{});var qat=s(kse);Bso=r(qat,"codegen"),qat.forEach(t),Nso=r(pk," \u2014 "),nB=n(pk,"A",{href:!0});var jat=s(nB);Iso=r(jat,"CodeGenTokenizer"),jat.forEach(t),qso=r(pk," or "),sB=n(pk,"A",{href:!0});var Dat=s(sB);jso=r(Dat,"CodeGenTokenizerFast"),Dat.forEach(t),Dso=r(pk," (CodeGen model)"),pk.forEach(t),Gso=i(S),Un=n(S,"LI",{});var _k=s(Un);Sse=n(_k,"STRONG",{});var Gat=s(Sse);Oso=r(Gat,"convbert"),Gat.forEach(t),Vso=r(_k," \u2014 "),lB=n(_k,"A",{href:!0});var Oat=s(lB);Xso=r(Oat,"ConvBertTokenizer"),Oat.forEach(t),zso=r(_k," or "),iB=n(_k,"A",{href:!0});var Vat=s(iB);Qso=r(Vat,"ConvBertTokenizerFast"),Vat.forEach(t),Wso=r(_k," (ConvBERT model)"),_k.forEach(t),Hso=i(S),Jn=n(S,"LI",{});var uk=s(Jn);Rse=n(uk,"STRONG",{});var Xat=s(Rse);Uso=r(Xat,"cpm"),Xat.forEach(t),Jso=r(uk," \u2014 "),dB=n(uk,"A",{href:!0});var zat=s(dB);Yso=r(zat,"CpmTokenizer"),zat.forEach(t),Kso=r(uk," or "),cB=n(uk,"A",{href:!0});var Qat=s(cB);Zso=r(Qat,"CpmTokenizerFast"),Qat.forEach(t),elo=r(uk," (CPM model)"),uk.forEach(t),olo=i(S),th=n(S,"LI",{});var Tye=s(th);Pse=n(Tye,"STRONG",{});var Wat=s(Pse);rlo=r(Wat,"ctrl"),Wat.forEach(t),tlo=r(Tye," \u2014 "),fB=n(Tye,"A",{href:!0});var Hat=s(fB);alo=r(Hat,"CTRLTokenizer"),Hat.forEach(t),nlo=r(Tye," (CTRL model)"),Tye.forEach(t),slo=i(S),Yn=n(S,"LI",{});var bk=s(Yn);Bse=n(bk,"STRONG",{});var Uat=s(Bse);llo=r(Uat,"data2vec-text"),Uat.forEach(t),ilo=r(bk," \u2014 "),mB=n(bk,"A",{href:!0});var Jat=s(mB);dlo=r(Jat,"RobertaTokenizer"),Jat.forEach(t),clo=r(bk," or "),gB=n(bk,"A",{href:!0});var Yat=s(gB);flo=r(Yat,"RobertaTokenizerFast"),Yat.forEach(t),mlo=r(bk," (Data2VecText model)"),bk.forEach(t),glo=i(S),Kn=n(S,"LI",{});var vk=s(Kn);Nse=n(vk,"STRONG",{});var Kat=s(Nse);hlo=r(Kat,"deberta"),Kat.forEach(t),plo=r(vk," \u2014 "),hB=n(vk,"A",{href:!0});var Zat=s(hB);_lo=r(Zat,"DebertaTokenizer"),Zat.forEach(t),ulo=r(vk," or "),pB=n(vk,"A",{href:!0});var ent=s(pB);blo=r(ent,"DebertaTokenizerFast"),ent.forEach(t),vlo=r(vk," (DeBERTa model)"),vk.forEach(t),Flo=i(S),Zn=n(S,"LI",{});var Fk=s(Zn);Ise=n(Fk,"STRONG",{});var ont=s(Ise);Tlo=r(ont,"deberta-v2"),ont.forEach(t),Mlo=r(Fk," \u2014 "),_B=n(Fk,"A",{href:!0});var rnt=s(_B);Elo=r(rnt,"DebertaV2Tokenizer"),rnt.forEach(t),Clo=r(Fk," or "),uB=n(Fk,"A",{href:!0});var tnt=s(uB);wlo=r(tnt,"DebertaV2TokenizerFast"),tnt.forEach(t),Alo=r(Fk," (DeBERTa-v2 model)"),Fk.forEach(t),Llo=i(S),es=n(S,"LI",{});var Tk=s(es);qse=n(Tk,"STRONG",{});var ant=s(qse);ylo=r(ant,"distilbert"),ant.forEach(t),xlo=r(Tk," \u2014 "),bB=n(Tk,"A",{href:!0});var nnt=s(bB);$lo=r(nnt,"DistilBertTokenizer"),nnt.forEach(t),klo=r(Tk," or "),vB=n(Tk,"A",{href:!0});var snt=s(vB);Slo=r(snt,"DistilBertTokenizerFast"),snt.forEach(t),Rlo=r(Tk," (DistilBERT model)"),Tk.forEach(t),Plo=i(S),os=n(S,"LI",{});var Mk=s(os);jse=n(Mk,"STRONG",{});var lnt=s(jse);Blo=r(lnt,"dpr"),lnt.forEach(t),Nlo=r(Mk," \u2014 "),FB=n(Mk,"A",{href:!0});var int=s(FB);Ilo=r(int,"DPRQuestionEncoderTokenizer"),int.forEach(t),qlo=r(Mk," or "),TB=n(Mk,"A",{href:!0});var dnt=s(TB);jlo=r(dnt,"DPRQuestionEncoderTokenizerFast"),dnt.forEach(t),Dlo=r(Mk," (DPR model)"),Mk.forEach(t),Glo=i(S),rs=n(S,"LI",{});var Ek=s(rs);Dse=n(Ek,"STRONG",{});var cnt=s(Dse);Olo=r(cnt,"electra"),cnt.forEach(t),Vlo=r(Ek," \u2014 "),MB=n(Ek,"A",{href:!0});var fnt=s(MB);Xlo=r(fnt,"ElectraTokenizer"),fnt.forEach(t),zlo=r(Ek," or "),EB=n(Ek,"A",{href:!0});var mnt=s(EB);Qlo=r(mnt,"ElectraTokenizerFast"),mnt.forEach(t),Wlo=r(Ek," (ELECTRA model)"),Ek.forEach(t),Hlo=i(S),ah=n(S,"LI",{});var Mye=s(ah);Gse=n(Mye,"STRONG",{});var gnt=s(Gse);Ulo=r(gnt,"flaubert"),gnt.forEach(t),Jlo=r(Mye," \u2014 "),CB=n(Mye,"A",{href:!0});var hnt=s(CB);Ylo=r(hnt,"FlaubertTokenizer"),hnt.forEach(t),Klo=r(Mye," (FlauBERT model)"),Mye.forEach(t),Zlo=i(S),ts=n(S,"LI",{});var Ck=s(ts);Ose=n(Ck,"STRONG",{});var pnt=s(Ose);eio=r(pnt,"fnet"),pnt.forEach(t),oio=r(Ck," \u2014 "),wB=n(Ck,"A",{href:!0});var _nt=s(wB);rio=r(_nt,"FNetTokenizer"),_nt.forEach(t),tio=r(Ck," or "),AB=n(Ck,"A",{href:!0});var unt=s(AB);aio=r(unt,"FNetTokenizerFast"),unt.forEach(t),nio=r(Ck," (FNet model)"),Ck.forEach(t),sio=i(S),nh=n(S,"LI",{});var Eye=s(nh);Vse=n(Eye,"STRONG",{});var bnt=s(Vse);lio=r(bnt,"fsmt"),bnt.forEach(t),iio=r(Eye," \u2014 "),LB=n(Eye,"A",{href:!0});var vnt=s(LB);dio=r(vnt,"FSMTTokenizer"),vnt.forEach(t),cio=r(Eye," (FairSeq Machine-Translation model)"),Eye.forEach(t),fio=i(S),as=n(S,"LI",{});var wk=s(as);Xse=n(wk,"STRONG",{});var Fnt=s(Xse);mio=r(Fnt,"funnel"),Fnt.forEach(t),gio=r(wk," \u2014 "),yB=n(wk,"A",{href:!0});var Tnt=s(yB);hio=r(Tnt,"FunnelTokenizer"),Tnt.forEach(t),pio=r(wk," or "),xB=n(wk,"A",{href:!0});var Mnt=s(xB);_io=r(Mnt,"FunnelTokenizerFast"),Mnt.forEach(t),uio=r(wk," (Funnel Transformer model)"),wk.forEach(t),bio=i(S),ns=n(S,"LI",{});var Ak=s(ns);zse=n(Ak,"STRONG",{});var Ent=s(zse);vio=r(Ent,"gpt2"),Ent.forEach(t),Fio=r(Ak," \u2014 "),$B=n(Ak,"A",{href:!0});var Cnt=s($B);Tio=r(Cnt,"GPT2Tokenizer"),Cnt.forEach(t),Mio=r(Ak," or "),kB=n(Ak,"A",{href:!0});var wnt=s(kB);Eio=r(wnt,"GPT2TokenizerFast"),wnt.forEach(t),Cio=r(Ak," (OpenAI GPT-2 model)"),Ak.forEach(t),wio=i(S),ss=n(S,"LI",{});var Lk=s(ss);Qse=n(Lk,"STRONG",{});var Ant=s(Qse);Aio=r(Ant,"gpt_neo"),Ant.forEach(t),Lio=r(Lk," \u2014 "),SB=n(Lk,"A",{href:!0});var Lnt=s(SB);yio=r(Lnt,"GPT2Tokenizer"),Lnt.forEach(t),xio=r(Lk," or "),RB=n(Lk,"A",{href:!0});var ynt=s(RB);$io=r(ynt,"GPT2TokenizerFast"),ynt.forEach(t),kio=r(Lk," (GPT Neo model)"),Lk.forEach(t),Sio=i(S),sh=n(S,"LI",{});var Cye=s(sh);Wse=n(Cye,"STRONG",{});var xnt=s(Wse);Rio=r(xnt,"gpt_neox"),xnt.forEach(t),Pio=r(Cye," \u2014 "),PB=n(Cye,"A",{href:!0});var $nt=s(PB);Bio=r($nt,"GPTNeoXTokenizerFast"),$nt.forEach(t),Nio=r(Cye," (GPT NeoX model)"),Cye.forEach(t),Iio=i(S),ls=n(S,"LI",{});var yk=s(ls);Hse=n(yk,"STRONG",{});var knt=s(Hse);qio=r(knt,"gptj"),knt.forEach(t),jio=r(yk," \u2014 "),BB=n(yk,"A",{href:!0});var Snt=s(BB);Dio=r(Snt,"GPT2Tokenizer"),Snt.forEach(t),Gio=r(yk," or "),NB=n(yk,"A",{href:!0});var Rnt=s(NB);Oio=r(Rnt,"GPT2TokenizerFast"),Rnt.forEach(t),Vio=r(yk," (GPT-J model)"),yk.forEach(t),Xio=i(S),is=n(S,"LI",{});var xk=s(is);Use=n(xk,"STRONG",{});var Pnt=s(Use);zio=r(Pnt,"groupvit"),Pnt.forEach(t),Qio=r(xk," \u2014 "),IB=n(xk,"A",{href:!0});var Bnt=s(IB);Wio=r(Bnt,"CLIPTokenizer"),Bnt.forEach(t),Hio=r(xk," or "),qB=n(xk,"A",{href:!0});var Nnt=s(qB);Uio=r(Nnt,"CLIPTokenizerFast"),Nnt.forEach(t),Jio=r(xk," (GroupViT model)"),xk.forEach(t),Yio=i(S),ds=n(S,"LI",{});var $k=s(ds);Jse=n($k,"STRONG",{});var Int=s(Jse);Kio=r(Int,"herbert"),Int.forEach(t),Zio=r($k," \u2014 "),jB=n($k,"A",{href:!0});var qnt=s(jB);edo=r(qnt,"HerbertTokenizer"),qnt.forEach(t),odo=r($k," or "),DB=n($k,"A",{href:!0});var jnt=s(DB);rdo=r(jnt,"HerbertTokenizerFast"),jnt.forEach(t),tdo=r($k," (HerBERT model)"),$k.forEach(t),ado=i(S),lh=n(S,"LI",{});var wye=s(lh);Yse=n(wye,"STRONG",{});var Dnt=s(Yse);ndo=r(Dnt,"hubert"),Dnt.forEach(t),sdo=r(wye," \u2014 "),GB=n(wye,"A",{href:!0});var Gnt=s(GB);ldo=r(Gnt,"Wav2Vec2CTCTokenizer"),Gnt.forEach(t),ido=r(wye," (Hubert model)"),wye.forEach(t),ddo=i(S),cs=n(S,"LI",{});var kk=s(cs);Kse=n(kk,"STRONG",{});var Ont=s(Kse);cdo=r(Ont,"ibert"),Ont.forEach(t),fdo=r(kk," \u2014 "),OB=n(kk,"A",{href:!0});var Vnt=s(OB);mdo=r(Vnt,"RobertaTokenizer"),Vnt.forEach(t),gdo=r(kk," or "),VB=n(kk,"A",{href:!0});var Xnt=s(VB);hdo=r(Xnt,"RobertaTokenizerFast"),Xnt.forEach(t),pdo=r(kk," (I-BERT model)"),kk.forEach(t),_do=i(S),fs=n(S,"LI",{});var Sk=s(fs);Zse=n(Sk,"STRONG",{});var znt=s(Zse);udo=r(znt,"layoutlm"),znt.forEach(t),bdo=r(Sk," \u2014 "),XB=n(Sk,"A",{href:!0});var Qnt=s(XB);vdo=r(Qnt,"LayoutLMTokenizer"),Qnt.forEach(t),Fdo=r(Sk," or "),zB=n(Sk,"A",{href:!0});var Wnt=s(zB);Tdo=r(Wnt,"LayoutLMTokenizerFast"),Wnt.forEach(t),Mdo=r(Sk," (LayoutLM model)"),Sk.forEach(t),Edo=i(S),ms=n(S,"LI",{});var Rk=s(ms);ele=n(Rk,"STRONG",{});var Hnt=s(ele);Cdo=r(Hnt,"layoutlmv2"),Hnt.forEach(t),wdo=r(Rk," \u2014 "),QB=n(Rk,"A",{href:!0});var Unt=s(QB);Ado=r(Unt,"LayoutLMv2Tokenizer"),Unt.forEach(t),Ldo=r(Rk," or "),WB=n(Rk,"A",{href:!0});var Jnt=s(WB);ydo=r(Jnt,"LayoutLMv2TokenizerFast"),Jnt.forEach(t),xdo=r(Rk," (LayoutLMv2 model)"),Rk.forEach(t),$do=i(S),gs=n(S,"LI",{});var Pk=s(gs);ole=n(Pk,"STRONG",{});var Ynt=s(ole);kdo=r(Ynt,"layoutlmv3"),Ynt.forEach(t),Sdo=r(Pk," \u2014 "),HB=n(Pk,"A",{href:!0});var Knt=s(HB);Rdo=r(Knt,"LayoutLMv3Tokenizer"),Knt.forEach(t),Pdo=r(Pk," or "),UB=n(Pk,"A",{href:!0});var Znt=s(UB);Bdo=r(Znt,"LayoutLMv3TokenizerFast"),Znt.forEach(t),Ndo=r(Pk," (LayoutLMv3 model)"),Pk.forEach(t),Ido=i(S),hs=n(S,"LI",{});var Bk=s(hs);rle=n(Bk,"STRONG",{});var est=s(rle);qdo=r(est,"layoutxlm"),est.forEach(t),jdo=r(Bk," \u2014 "),JB=n(Bk,"A",{href:!0});var ost=s(JB);Ddo=r(ost,"LayoutXLMTokenizer"),ost.forEach(t),Gdo=r(Bk," or "),YB=n(Bk,"A",{href:!0});var rst=s(YB);Odo=r(rst,"LayoutXLMTokenizerFast"),rst.forEach(t),Vdo=r(Bk," (LayoutXLM model)"),Bk.forEach(t),Xdo=i(S),ps=n(S,"LI",{});var Nk=s(ps);tle=n(Nk,"STRONG",{});var tst=s(tle);zdo=r(tst,"led"),tst.forEach(t),Qdo=r(Nk," \u2014 "),KB=n(Nk,"A",{href:!0});var ast=s(KB);Wdo=r(ast,"LEDTokenizer"),ast.forEach(t),Hdo=r(Nk," or "),ZB=n(Nk,"A",{href:!0});var nst=s(ZB);Udo=r(nst,"LEDTokenizerFast"),nst.forEach(t),Jdo=r(Nk," (LED model)"),Nk.forEach(t),Ydo=i(S),_s=n(S,"LI",{});var Ik=s(_s);ale=n(Ik,"STRONG",{});var sst=s(ale);Kdo=r(sst,"longformer"),sst.forEach(t),Zdo=r(Ik," \u2014 "),eN=n(Ik,"A",{href:!0});var lst=s(eN);eco=r(lst,"LongformerTokenizer"),lst.forEach(t),oco=r(Ik," or "),oN=n(Ik,"A",{href:!0});var ist=s(oN);rco=r(ist,"LongformerTokenizerFast"),ist.forEach(t),tco=r(Ik," (Longformer model)"),Ik.forEach(t),aco=i(S),us=n(S,"LI",{});var qk=s(us);nle=n(qk,"STRONG",{});var dst=s(nle);nco=r(dst,"longt5"),dst.forEach(t),sco=r(qk," \u2014 "),rN=n(qk,"A",{href:!0});var cst=s(rN);lco=r(cst,"T5Tokenizer"),cst.forEach(t),ico=r(qk," or "),tN=n(qk,"A",{href:!0});var fst=s(tN);dco=r(fst,"T5TokenizerFast"),fst.forEach(t),cco=r(qk," (LongT5 model)"),qk.forEach(t),fco=i(S),ih=n(S,"LI",{});var Aye=s(ih);sle=n(Aye,"STRONG",{});var mst=s(sle);mco=r(mst,"luke"),mst.forEach(t),gco=r(Aye," \u2014 "),aN=n(Aye,"A",{href:!0});var gst=s(aN);hco=r(gst,"LukeTokenizer"),gst.forEach(t),pco=r(Aye," (LUKE model)"),Aye.forEach(t),_co=i(S),bs=n(S,"LI",{});var jk=s(bs);lle=n(jk,"STRONG",{});var hst=s(lle);uco=r(hst,"lxmert"),hst.forEach(t),bco=r(jk," \u2014 "),nN=n(jk,"A",{href:!0});var pst=s(nN);vco=r(pst,"LxmertTokenizer"),pst.forEach(t),Fco=r(jk," or "),sN=n(jk,"A",{href:!0});var _st=s(sN);Tco=r(_st,"LxmertTokenizerFast"),_st.forEach(t),Mco=r(jk," (LXMERT model)"),jk.forEach(t),Eco=i(S),dh=n(S,"LI",{});var Lye=s(dh);ile=n(Lye,"STRONG",{});var ust=s(ile);Cco=r(ust,"m2m_100"),ust.forEach(t),wco=r(Lye," \u2014 "),lN=n(Lye,"A",{href:!0});var bst=s(lN);Aco=r(bst,"M2M100Tokenizer"),bst.forEach(t),Lco=r(Lye," (M2M100 model)"),Lye.forEach(t),yco=i(S),ch=n(S,"LI",{});var yye=s(ch);dle=n(yye,"STRONG",{});var vst=s(dle);xco=r(vst,"marian"),vst.forEach(t),$co=r(yye," \u2014 "),iN=n(yye,"A",{href:!0});var Fst=s(iN);kco=r(Fst,"MarianTokenizer"),Fst.forEach(t),Sco=r(yye," (Marian model)"),yye.forEach(t),Rco=i(S),vs=n(S,"LI",{});var Dk=s(vs);cle=n(Dk,"STRONG",{});var Tst=s(cle);Pco=r(Tst,"mbart"),Tst.forEach(t),Bco=r(Dk," \u2014 "),dN=n(Dk,"A",{href:!0});var Mst=s(dN);Nco=r(Mst,"MBartTokenizer"),Mst.forEach(t),Ico=r(Dk," or "),cN=n(Dk,"A",{href:!0});var Est=s(cN);qco=r(Est,"MBartTokenizerFast"),Est.forEach(t),jco=r(Dk," (mBART model)"),Dk.forEach(t),Dco=i(S),Fs=n(S,"LI",{});var Gk=s(Fs);fle=n(Gk,"STRONG",{});var Cst=s(fle);Gco=r(Cst,"mbart50"),Cst.forEach(t),Oco=r(Gk," \u2014 "),fN=n(Gk,"A",{href:!0});var wst=s(fN);Vco=r(wst,"MBart50Tokenizer"),wst.forEach(t),Xco=r(Gk," or "),mN=n(Gk,"A",{href:!0});var Ast=s(mN);zco=r(Ast,"MBart50TokenizerFast"),Ast.forEach(t),Qco=r(Gk," (mBART-50 model)"),Gk.forEach(t),Wco=i(S),Ts=n(S,"LI",{});var Ok=s(Ts);mle=n(Ok,"STRONG",{});var Lst=s(mle);Hco=r(Lst,"megatron-bert"),Lst.forEach(t),Uco=r(Ok," \u2014 "),gN=n(Ok,"A",{href:!0});var yst=s(gN);Jco=r(yst,"BertTokenizer"),yst.forEach(t),Yco=r(Ok," or "),hN=n(Ok,"A",{href:!0});var xst=s(hN);Kco=r(xst,"BertTokenizerFast"),xst.forEach(t),Zco=r(Ok," (Megatron-BERT model)"),Ok.forEach(t),efo=i(S),fh=n(S,"LI",{});var xye=s(fh);gle=n(xye,"STRONG",{});var $st=s(gle);ofo=r($st,"mluke"),$st.forEach(t),rfo=r(xye," \u2014 "),pN=n(xye,"A",{href:!0});var kst=s(pN);tfo=r(kst,"MLukeTokenizer"),kst.forEach(t),afo=r(xye," (mLUKE model)"),xye.forEach(t),nfo=i(S),Ms=n(S,"LI",{});var Vk=s(Ms);hle=n(Vk,"STRONG",{});var Sst=s(hle);sfo=r(Sst,"mobilebert"),Sst.forEach(t),lfo=r(Vk," \u2014 "),_N=n(Vk,"A",{href:!0});var Rst=s(_N);ifo=r(Rst,"MobileBertTokenizer"),Rst.forEach(t),dfo=r(Vk," or "),uN=n(Vk,"A",{href:!0});var Pst=s(uN);cfo=r(Pst,"MobileBertTokenizerFast"),Pst.forEach(t),ffo=r(Vk," (MobileBERT model)"),Vk.forEach(t),mfo=i(S),Es=n(S,"LI",{});var Xk=s(Es);ple=n(Xk,"STRONG",{});var Bst=s(ple);gfo=r(Bst,"mpnet"),Bst.forEach(t),hfo=r(Xk," \u2014 "),bN=n(Xk,"A",{href:!0});var Nst=s(bN);pfo=r(Nst,"MPNetTokenizer"),Nst.forEach(t),_fo=r(Xk," or "),vN=n(Xk,"A",{href:!0});var Ist=s(vN);ufo=r(Ist,"MPNetTokenizerFast"),Ist.forEach(t),bfo=r(Xk," (MPNet model)"),Xk.forEach(t),vfo=i(S),Cs=n(S,"LI",{});var zk=s(Cs);_le=n(zk,"STRONG",{});var qst=s(_le);Ffo=r(qst,"mt5"),qst.forEach(t),Tfo=r(zk," \u2014 "),FN=n(zk,"A",{href:!0});var jst=s(FN);Mfo=r(jst,"MT5Tokenizer"),jst.forEach(t),Efo=r(zk," or "),TN=n(zk,"A",{href:!0});var Dst=s(TN);Cfo=r(Dst,"MT5TokenizerFast"),Dst.forEach(t),wfo=r(zk," (MT5 model)"),zk.forEach(t),Afo=i(S),ws=n(S,"LI",{});var Qk=s(ws);ule=n(Qk,"STRONG",{});var Gst=s(ule);Lfo=r(Gst,"nezha"),Gst.forEach(t),yfo=r(Qk," \u2014 "),MN=n(Qk,"A",{href:!0});var Ost=s(MN);xfo=r(Ost,"BertTokenizer"),Ost.forEach(t),$fo=r(Qk," or "),EN=n(Qk,"A",{href:!0});var Vst=s(EN);kfo=r(Vst,"BertTokenizerFast"),Vst.forEach(t),Sfo=r(Qk," (Nezha model)"),Qk.forEach(t),Rfo=i(S),As=n(S,"LI",{});var Wk=s(As);ble=n(Wk,"STRONG",{});var Xst=s(ble);Pfo=r(Xst,"nystromformer"),Xst.forEach(t),Bfo=r(Wk," \u2014 "),CN=n(Wk,"A",{href:!0});var zst=s(CN);Nfo=r(zst,"AlbertTokenizer"),zst.forEach(t),Ifo=r(Wk," or "),wN=n(Wk,"A",{href:!0});var Qst=s(wN);qfo=r(Qst,"AlbertTokenizerFast"),Qst.forEach(t),jfo=r(Wk," (Nystr\xF6mformer model)"),Wk.forEach(t),Dfo=i(S),Ls=n(S,"LI",{});var Hk=s(Ls);vle=n(Hk,"STRONG",{});var Wst=s(vle);Gfo=r(Wst,"openai-gpt"),Wst.forEach(t),Ofo=r(Hk," \u2014 "),AN=n(Hk,"A",{href:!0});var Hst=s(AN);Vfo=r(Hst,"OpenAIGPTTokenizer"),Hst.forEach(t),Xfo=r(Hk," or "),LN=n(Hk,"A",{href:!0});var Ust=s(LN);zfo=r(Ust,"OpenAIGPTTokenizerFast"),Ust.forEach(t),Qfo=r(Hk," (OpenAI GPT model)"),Hk.forEach(t),Wfo=i(S),mh=n(S,"LI",{});var $ye=s(mh);Fle=n($ye,"STRONG",{});var Jst=s(Fle);Hfo=r(Jst,"opt"),Jst.forEach(t),Ufo=r($ye," \u2014 "),yN=n($ye,"A",{href:!0});var Yst=s(yN);Jfo=r(Yst,"GPT2Tokenizer"),Yst.forEach(t),Yfo=r($ye," (OPT model)"),$ye.forEach(t),Kfo=i(S),ys=n(S,"LI",{});var Uk=s(ys);Tle=n(Uk,"STRONG",{});var Kst=s(Tle);Zfo=r(Kst,"pegasus"),Kst.forEach(t),emo=r(Uk," \u2014 "),xN=n(Uk,"A",{href:!0});var Zst=s(xN);omo=r(Zst,"PegasusTokenizer"),Zst.forEach(t),rmo=r(Uk," or "),$N=n(Uk,"A",{href:!0});var elt=s($N);tmo=r(elt,"PegasusTokenizerFast"),elt.forEach(t),amo=r(Uk," (Pegasus model)"),Uk.forEach(t),nmo=i(S),gh=n(S,"LI",{});var kye=s(gh);Mle=n(kye,"STRONG",{});var olt=s(Mle);smo=r(olt,"perceiver"),olt.forEach(t),lmo=r(kye," \u2014 "),kN=n(kye,"A",{href:!0});var rlt=s(kN);imo=r(rlt,"PerceiverTokenizer"),rlt.forEach(t),dmo=r(kye," (Perceiver model)"),kye.forEach(t),cmo=i(S),hh=n(S,"LI",{});var Sye=s(hh);Ele=n(Sye,"STRONG",{});var tlt=s(Ele);fmo=r(tlt,"phobert"),tlt.forEach(t),mmo=r(Sye," \u2014 "),SN=n(Sye,"A",{href:!0});var alt=s(SN);gmo=r(alt,"PhobertTokenizer"),alt.forEach(t),hmo=r(Sye," (PhoBERT model)"),Sye.forEach(t),pmo=i(S),ph=n(S,"LI",{});var Rye=s(ph);Cle=n(Rye,"STRONG",{});var nlt=s(Cle);_mo=r(nlt,"plbart"),nlt.forEach(t),umo=r(Rye," \u2014 "),RN=n(Rye,"A",{href:!0});var slt=s(RN);bmo=r(slt,"PLBartTokenizer"),slt.forEach(t),vmo=r(Rye," (PLBart model)"),Rye.forEach(t),Fmo=i(S),_h=n(S,"LI",{});var Pye=s(_h);wle=n(Pye,"STRONG",{});var llt=s(wle);Tmo=r(llt,"prophetnet"),llt.forEach(t),Mmo=r(Pye," \u2014 "),PN=n(Pye,"A",{href:!0});var ilt=s(PN);Emo=r(ilt,"ProphetNetTokenizer"),ilt.forEach(t),Cmo=r(Pye," (ProphetNet model)"),Pye.forEach(t),wmo=i(S),xs=n(S,"LI",{});var Jk=s(xs);Ale=n(Jk,"STRONG",{});var dlt=s(Ale);Amo=r(dlt,"qdqbert"),dlt.forEach(t),Lmo=r(Jk," \u2014 "),BN=n(Jk,"A",{href:!0});var clt=s(BN);ymo=r(clt,"BertTokenizer"),clt.forEach(t),xmo=r(Jk," or "),NN=n(Jk,"A",{href:!0});var flt=s(NN);$mo=r(flt,"BertTokenizerFast"),flt.forEach(t),kmo=r(Jk," (QDQBert model)"),Jk.forEach(t),Smo=i(S),uh=n(S,"LI",{});var Bye=s(uh);Lle=n(Bye,"STRONG",{});var mlt=s(Lle);Rmo=r(mlt,"rag"),mlt.forEach(t),Pmo=r(Bye," \u2014 "),IN=n(Bye,"A",{href:!0});var glt=s(IN);Bmo=r(glt,"RagTokenizer"),glt.forEach(t),Nmo=r(Bye," (RAG model)"),Bye.forEach(t),Imo=i(S),$s=n(S,"LI",{});var Yk=s($s);yle=n(Yk,"STRONG",{});var hlt=s(yle);qmo=r(hlt,"realm"),hlt.forEach(t),jmo=r(Yk," \u2014 "),qN=n(Yk,"A",{href:!0});var plt=s(qN);Dmo=r(plt,"RealmTokenizer"),plt.forEach(t),Gmo=r(Yk," or "),jN=n(Yk,"A",{href:!0});var _lt=s(jN);Omo=r(_lt,"RealmTokenizerFast"),_lt.forEach(t),Vmo=r(Yk," (REALM model)"),Yk.forEach(t),Xmo=i(S),ks=n(S,"LI",{});var Kk=s(ks);xle=n(Kk,"STRONG",{});var ult=s(xle);zmo=r(ult,"reformer"),ult.forEach(t),Qmo=r(Kk," \u2014 "),DN=n(Kk,"A",{href:!0});var blt=s(DN);Wmo=r(blt,"ReformerTokenizer"),blt.forEach(t),Hmo=r(Kk," or "),GN=n(Kk,"A",{href:!0});var vlt=s(GN);Umo=r(vlt,"ReformerTokenizerFast"),vlt.forEach(t),Jmo=r(Kk," (Reformer model)"),Kk.forEach(t),Ymo=i(S),Ss=n(S,"LI",{});var Zk=s(Ss);$le=n(Zk,"STRONG",{});var Flt=s($le);Kmo=r(Flt,"rembert"),Flt.forEach(t),Zmo=r(Zk," \u2014 "),ON=n(Zk,"A",{href:!0});var Tlt=s(ON);ego=r(Tlt,"RemBertTokenizer"),Tlt.forEach(t),ogo=r(Zk," or "),VN=n(Zk,"A",{href:!0});var Mlt=s(VN);rgo=r(Mlt,"RemBertTokenizerFast"),Mlt.forEach(t),tgo=r(Zk," (RemBERT model)"),Zk.forEach(t),ago=i(S),Rs=n(S,"LI",{});var eS=s(Rs);kle=n(eS,"STRONG",{});var Elt=s(kle);ngo=r(Elt,"retribert"),Elt.forEach(t),sgo=r(eS," \u2014 "),XN=n(eS,"A",{href:!0});var Clt=s(XN);lgo=r(Clt,"RetriBertTokenizer"),Clt.forEach(t),igo=r(eS," or "),zN=n(eS,"A",{href:!0});var wlt=s(zN);dgo=r(wlt,"RetriBertTokenizerFast"),wlt.forEach(t),cgo=r(eS," (RetriBERT model)"),eS.forEach(t),fgo=i(S),Ps=n(S,"LI",{});var oS=s(Ps);Sle=n(oS,"STRONG",{});var Alt=s(Sle);mgo=r(Alt,"roberta"),Alt.forEach(t),ggo=r(oS," \u2014 "),QN=n(oS,"A",{href:!0});var Llt=s(QN);hgo=r(Llt,"RobertaTokenizer"),Llt.forEach(t),pgo=r(oS," or "),WN=n(oS,"A",{href:!0});var ylt=s(WN);_go=r(ylt,"RobertaTokenizerFast"),ylt.forEach(t),ugo=r(oS," (RoBERTa model)"),oS.forEach(t),bgo=i(S),Bs=n(S,"LI",{});var rS=s(Bs);Rle=n(rS,"STRONG",{});var xlt=s(Rle);vgo=r(xlt,"roformer"),xlt.forEach(t),Fgo=r(rS," \u2014 "),HN=n(rS,"A",{href:!0});var $lt=s(HN);Tgo=r($lt,"RoFormerTokenizer"),$lt.forEach(t),Mgo=r(rS," or "),UN=n(rS,"A",{href:!0});var klt=s(UN);Ego=r(klt,"RoFormerTokenizerFast"),klt.forEach(t),Cgo=r(rS," (RoFormer model)"),rS.forEach(t),wgo=i(S),bh=n(S,"LI",{});var Nye=s(bh);Ple=n(Nye,"STRONG",{});var Slt=s(Ple);Ago=r(Slt,"speech_to_text"),Slt.forEach(t),Lgo=r(Nye," \u2014 "),JN=n(Nye,"A",{href:!0});var Rlt=s(JN);ygo=r(Rlt,"Speech2TextTokenizer"),Rlt.forEach(t),xgo=r(Nye," (Speech2Text model)"),Nye.forEach(t),$go=i(S),vh=n(S,"LI",{});var Iye=s(vh);Ble=n(Iye,"STRONG",{});var Plt=s(Ble);kgo=r(Plt,"speech_to_text_2"),Plt.forEach(t),Sgo=r(Iye," \u2014 "),YN=n(Iye,"A",{href:!0});var Blt=s(YN);Rgo=r(Blt,"Speech2Text2Tokenizer"),Blt.forEach(t),Pgo=r(Iye," (Speech2Text2 model)"),Iye.forEach(t),Bgo=i(S),Ns=n(S,"LI",{});var tS=s(Ns);Nle=n(tS,"STRONG",{});var Nlt=s(Nle);Ngo=r(Nlt,"splinter"),Nlt.forEach(t),Igo=r(tS," \u2014 "),KN=n(tS,"A",{href:!0});var Ilt=s(KN);qgo=r(Ilt,"SplinterTokenizer"),Ilt.forEach(t),jgo=r(tS," or "),ZN=n(tS,"A",{href:!0});var qlt=s(ZN);Dgo=r(qlt,"SplinterTokenizerFast"),qlt.forEach(t),Ggo=r(tS," (Splinter model)"),tS.forEach(t),Ogo=i(S),Is=n(S,"LI",{});var aS=s(Is);Ile=n(aS,"STRONG",{});var jlt=s(Ile);Vgo=r(jlt,"squeezebert"),jlt.forEach(t),Xgo=r(aS," \u2014 "),eI=n(aS,"A",{href:!0});var Dlt=s(eI);zgo=r(Dlt,"SqueezeBertTokenizer"),Dlt.forEach(t),Qgo=r(aS," or "),oI=n(aS,"A",{href:!0});var Glt=s(oI);Wgo=r(Glt,"SqueezeBertTokenizerFast"),Glt.forEach(t),Hgo=r(aS," (SqueezeBERT model)"),aS.forEach(t),Ugo=i(S),qs=n(S,"LI",{});var nS=s(qs);qle=n(nS,"STRONG",{});var Olt=s(qle);Jgo=r(Olt,"t5"),Olt.forEach(t),Ygo=r(nS," \u2014 "),rI=n(nS,"A",{href:!0});var Vlt=s(rI);Kgo=r(Vlt,"T5Tokenizer"),Vlt.forEach(t),Zgo=r(nS," or "),tI=n(nS,"A",{href:!0});var Xlt=s(tI);eho=r(Xlt,"T5TokenizerFast"),Xlt.forEach(t),oho=r(nS," (T5 model)"),nS.forEach(t),rho=i(S),Fh=n(S,"LI",{});var qye=s(Fh);jle=n(qye,"STRONG",{});var zlt=s(jle);tho=r(zlt,"tapas"),zlt.forEach(t),aho=r(qye," \u2014 "),aI=n(qye,"A",{href:!0});var Qlt=s(aI);nho=r(Qlt,"TapasTokenizer"),Qlt.forEach(t),sho=r(qye," (TAPAS model)"),qye.forEach(t),lho=i(S),Th=n(S,"LI",{});var jye=s(Th);Dle=n(jye,"STRONG",{});var Wlt=s(Dle);iho=r(Wlt,"tapex"),Wlt.forEach(t),dho=r(jye," \u2014 "),nI=n(jye,"A",{href:!0});var Hlt=s(nI);cho=r(Hlt,"TapexTokenizer"),Hlt.forEach(t),fho=r(jye," (TAPEX model)"),jye.forEach(t),mho=i(S),Mh=n(S,"LI",{});var Dye=s(Mh);Gle=n(Dye,"STRONG",{});var Ult=s(Gle);gho=r(Ult,"transfo-xl"),Ult.forEach(t),hho=r(Dye," \u2014 "),sI=n(Dye,"A",{href:!0});var Jlt=s(sI);pho=r(Jlt,"TransfoXLTokenizer"),Jlt.forEach(t),_ho=r(Dye," (Transformer-XL model)"),Dye.forEach(t),uho=i(S),js=n(S,"LI",{});var sS=s(js);Ole=n(sS,"STRONG",{});var Ylt=s(Ole);bho=r(Ylt,"vilt"),Ylt.forEach(t),vho=r(sS," \u2014 "),lI=n(sS,"A",{href:!0});var Klt=s(lI);Fho=r(Klt,"BertTokenizer"),Klt.forEach(t),Tho=r(sS," or "),iI=n(sS,"A",{href:!0});var Zlt=s(iI);Mho=r(Zlt,"BertTokenizerFast"),Zlt.forEach(t),Eho=r(sS," (ViLT model)"),sS.forEach(t),Cho=i(S),Ds=n(S,"LI",{});var lS=s(Ds);Vle=n(lS,"STRONG",{});var eit=s(Vle);who=r(eit,"visual_bert"),eit.forEach(t),Aho=r(lS," \u2014 "),dI=n(lS,"A",{href:!0});var oit=s(dI);Lho=r(oit,"BertTokenizer"),oit.forEach(t),yho=r(lS," or "),cI=n(lS,"A",{href:!0});var rit=s(cI);xho=r(rit,"BertTokenizerFast"),rit.forEach(t),$ho=r(lS," (VisualBERT model)"),lS.forEach(t),kho=i(S),Eh=n(S,"LI",{});var Gye=s(Eh);Xle=n(Gye,"STRONG",{});var tit=s(Xle);Sho=r(tit,"wav2vec2"),tit.forEach(t),Rho=r(Gye," \u2014 "),fI=n(Gye,"A",{href:!0});var ait=s(fI);Pho=r(ait,"Wav2Vec2CTCTokenizer"),ait.forEach(t),Bho=r(Gye," (Wav2Vec2 model)"),Gye.forEach(t),Nho=i(S),Ch=n(S,"LI",{});var Oye=s(Ch);zle=n(Oye,"STRONG",{});var nit=s(zle);Iho=r(nit,"wav2vec2-conformer"),nit.forEach(t),qho=r(Oye," \u2014 "),mI=n(Oye,"A",{href:!0});var sit=s(mI);jho=r(sit,"Wav2Vec2CTCTokenizer"),sit.forEach(t),Dho=r(Oye," (Wav2Vec2-Conformer model)"),Oye.forEach(t),Gho=i(S),wh=n(S,"LI",{});var Vye=s(wh);Qle=n(Vye,"STRONG",{});var lit=s(Qle);Oho=r(lit,"wav2vec2_phoneme"),lit.forEach(t),Vho=r(Vye," \u2014 "),gI=n(Vye,"A",{href:!0});var iit=s(gI);Xho=r(iit,"Wav2Vec2PhonemeCTCTokenizer"),iit.forEach(t),zho=r(Vye," (Wav2Vec2Phoneme model)"),Vye.forEach(t),Qho=i(S),Gs=n(S,"LI",{});var iS=s(Gs);Wle=n(iS,"STRONG",{});var dit=s(Wle);Who=r(dit,"xglm"),dit.forEach(t),Hho=r(iS," \u2014 "),hI=n(iS,"A",{href:!0});var cit=s(hI);Uho=r(cit,"XGLMTokenizer"),cit.forEach(t),Jho=r(iS," or "),pI=n(iS,"A",{href:!0});var fit=s(pI);Yho=r(fit,"XGLMTokenizerFast"),fit.forEach(t),Kho=r(iS," (XGLM model)"),iS.forEach(t),Zho=i(S),Ah=n(S,"LI",{});var Xye=s(Ah);Hle=n(Xye,"STRONG",{});var mit=s(Hle);epo=r(mit,"xlm"),mit.forEach(t),opo=r(Xye," \u2014 "),_I=n(Xye,"A",{href:!0});var git=s(_I);rpo=r(git,"XLMTokenizer"),git.forEach(t),tpo=r(Xye," (XLM model)"),Xye.forEach(t),apo=i(S),Lh=n(S,"LI",{});var zye=s(Lh);Ule=n(zye,"STRONG",{});var hit=s(Ule);npo=r(hit,"xlm-prophetnet"),hit.forEach(t),spo=r(zye," \u2014 "),uI=n(zye,"A",{href:!0});var pit=s(uI);lpo=r(pit,"XLMProphetNetTokenizer"),pit.forEach(t),ipo=r(zye," (XLM-ProphetNet model)"),zye.forEach(t),dpo=i(S),Os=n(S,"LI",{});var dS=s(Os);Jle=n(dS,"STRONG",{});var _it=s(Jle);cpo=r(_it,"xlm-roberta"),_it.forEach(t),fpo=r(dS," \u2014 "),bI=n(dS,"A",{href:!0});var uit=s(bI);mpo=r(uit,"XLMRobertaTokenizer"),uit.forEach(t),gpo=r(dS," or "),vI=n(dS,"A",{href:!0});var bit=s(vI);hpo=r(bit,"XLMRobertaTokenizerFast"),bit.forEach(t),ppo=r(dS," (XLM-RoBERTa model)"),dS.forEach(t),_po=i(S),Vs=n(S,"LI",{});var cS=s(Vs);Yle=n(cS,"STRONG",{});var vit=s(Yle);upo=r(vit,"xlm-roberta-xl"),vit.forEach(t),bpo=r(cS," \u2014 "),FI=n(cS,"A",{href:!0});var Fit=s(FI);vpo=r(Fit,"RobertaTokenizer"),Fit.forEach(t),Fpo=r(cS," or "),TI=n(cS,"A",{href:!0});var Tit=s(TI);Tpo=r(Tit,"RobertaTokenizerFast"),Tit.forEach(t),Mpo=r(cS," (XLM-RoBERTa-XL model)"),cS.forEach(t),Epo=i(S),Xs=n(S,"LI",{});var fS=s(Xs);Kle=n(fS,"STRONG",{});var Mit=s(Kle);Cpo=r(Mit,"xlnet"),Mit.forEach(t),wpo=r(fS," \u2014 "),MI=n(fS,"A",{href:!0});var Eit=s(MI);Apo=r(Eit,"XLNetTokenizer"),Eit.forEach(t),Lpo=r(fS," or "),EI=n(fS,"A",{href:!0});var Cit=s(EI);ypo=r(Cit,"XLNetTokenizerFast"),Cit.forEach(t),xpo=r(fS," (XLNet model)"),fS.forEach(t),$po=i(S),zs=n(S,"LI",{});var mS=s(zs);Zle=n(mS,"STRONG",{});var wit=s(Zle);kpo=r(wit,"yoso"),wit.forEach(t),Spo=r(mS," \u2014 "),CI=n(mS,"A",{href:!0});var Ait=s(CI);Rpo=r(Ait,"AlbertTokenizer"),Ait.forEach(t),Ppo=r(mS," or "),wI=n(mS,"A",{href:!0});var Lit=s(wI);Bpo=r(Lit,"AlbertTokenizerFast"),Lit.forEach(t),Npo=r(mS," (YOSO model)"),mS.forEach(t),S.forEach(t),Ipo=i(Ys),T(yh.$$.fragment,Ys),Ys.forEach(t),qpo=i(Js),xh=n(Js,"DIV",{class:!0});var UXe=s(xh);T(oy.$$.fragment,UXe),jpo=i(UXe),eie=n(UXe,"P",{});var yit=s(eie);Dpo=r(yit,"Register a new tokenizer in this mapping."),yit.forEach(t),UXe.forEach(t),Js.forEach(t),HOe=i(f),Bi=n(f,"H2",{class:!0});var JXe=s(Bi);$h=n(JXe,"A",{id:!0,class:!0,href:!0});var xit=s($h);oie=n(xit,"SPAN",{});var $it=s(oie);T(ry.$$.fragment,$it),$it.forEach(t),xit.forEach(t),Gpo=i(JXe),rie=n(JXe,"SPAN",{});var kit=s(rie);Opo=r(kit,"AutoFeatureExtractor"),kit.forEach(t),JXe.forEach(t),UOe=i(f),Lo=n(f,"DIV",{class:!0});var Ks=s(Lo);T(ty.$$.fragment,Ks),Vpo=i(Ks),ay=n(Ks,"P",{});var YXe=s(ay);Xpo=r(YXe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),AI=n(YXe,"A",{href:!0});var Sit=s(AI);zpo=r(Sit,"AutoFeatureExtractor.from_pretrained()"),Sit.forEach(t),Qpo=r(YXe," class method."),YXe.forEach(t),Wpo=i(Ks),ny=n(Ks,"P",{});var KXe=s(ny);Hpo=r(KXe,"This class cannot be instantiated directly using "),tie=n(KXe,"CODE",{});var Rit=s(tie);Upo=r(Rit,"__init__()"),Rit.forEach(t),Jpo=r(KXe," (throws an error)."),KXe.forEach(t),Ypo=i(Ks),He=n(Ks,"DIV",{class:!0});var ta=s(He);T(sy.$$.fragment,ta),Kpo=i(ta),aie=n(ta,"P",{});var Pit=s(aie);Zpo=r(Pit,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Pit.forEach(t),e_o=i(ta),Pa=n(ta,"P",{});var XA=s(Pa);o_o=r(XA,"The feature extractor class to instantiate is selected based on the "),nie=n(XA,"CODE",{});var Bit=s(nie);r_o=r(Bit,"model_type"),Bit.forEach(t),t_o=r(XA,` property of the config object
(either passed as an argument or loaded from `),sie=n(XA,"CODE",{});var Nit=s(sie);a_o=r(Nit,"pretrained_model_name_or_path"),Nit.forEach(t),n_o=r(XA,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),lie=n(XA,"CODE",{});var Iit=s(lie);s_o=r(Iit,"pretrained_model_name_or_path"),Iit.forEach(t),l_o=r(XA,":"),XA.forEach(t),i_o=i(ta),Y=n(ta,"UL",{});var K=s(Y);kh=n(K,"LI",{});var Qye=s(kh);iie=n(Qye,"STRONG",{});var qit=s(iie);d_o=r(qit,"beit"),qit.forEach(t),c_o=r(Qye," \u2014 "),LI=n(Qye,"A",{href:!0});var jit=s(LI);f_o=r(jit,"BeitFeatureExtractor"),jit.forEach(t),m_o=r(Qye," (BEiT model)"),Qye.forEach(t),g_o=i(K),Sh=n(K,"LI",{});var Wye=s(Sh);die=n(Wye,"STRONG",{});var Dit=s(die);h_o=r(Dit,"clip"),Dit.forEach(t),p_o=r(Wye," \u2014 "),yI=n(Wye,"A",{href:!0});var Git=s(yI);__o=r(Git,"CLIPFeatureExtractor"),Git.forEach(t),u_o=r(Wye," (CLIP model)"),Wye.forEach(t),b_o=i(K),Rh=n(K,"LI",{});var Hye=s(Rh);cie=n(Hye,"STRONG",{});var Oit=s(cie);v_o=r(Oit,"convnext"),Oit.forEach(t),F_o=r(Hye," \u2014 "),xI=n(Hye,"A",{href:!0});var Vit=s(xI);T_o=r(Vit,"ConvNextFeatureExtractor"),Vit.forEach(t),M_o=r(Hye," (ConvNeXT model)"),Hye.forEach(t),E_o=i(K),Ph=n(K,"LI",{});var Uye=s(Ph);fie=n(Uye,"STRONG",{});var Xit=s(fie);C_o=r(Xit,"cvt"),Xit.forEach(t),w_o=r(Uye," \u2014 "),$I=n(Uye,"A",{href:!0});var zit=s($I);A_o=r(zit,"ConvNextFeatureExtractor"),zit.forEach(t),L_o=r(Uye," (CvT model)"),Uye.forEach(t),y_o=i(K),Bh=n(K,"LI",{});var Jye=s(Bh);mie=n(Jye,"STRONG",{});var Qit=s(mie);x_o=r(Qit,"data2vec-audio"),Qit.forEach(t),$_o=r(Jye," \u2014 "),kI=n(Jye,"A",{href:!0});var Wit=s(kI);k_o=r(Wit,"Wav2Vec2FeatureExtractor"),Wit.forEach(t),S_o=r(Jye," (Data2VecAudio model)"),Jye.forEach(t),R_o=i(K),Nh=n(K,"LI",{});var Yye=s(Nh);gie=n(Yye,"STRONG",{});var Hit=s(gie);P_o=r(Hit,"data2vec-vision"),Hit.forEach(t),B_o=r(Yye," \u2014 "),SI=n(Yye,"A",{href:!0});var Uit=s(SI);N_o=r(Uit,"BeitFeatureExtractor"),Uit.forEach(t),I_o=r(Yye," (Data2VecVision model)"),Yye.forEach(t),q_o=i(K),Ih=n(K,"LI",{});var Kye=s(Ih);hie=n(Kye,"STRONG",{});var Jit=s(hie);j_o=r(Jit,"deit"),Jit.forEach(t),D_o=r(Kye," \u2014 "),RI=n(Kye,"A",{href:!0});var Yit=s(RI);G_o=r(Yit,"DeiTFeatureExtractor"),Yit.forEach(t),O_o=r(Kye," (DeiT model)"),Kye.forEach(t),V_o=i(K),qh=n(K,"LI",{});var Zye=s(qh);pie=n(Zye,"STRONG",{});var Kit=s(pie);X_o=r(Kit,"detr"),Kit.forEach(t),z_o=r(Zye," \u2014 "),PI=n(Zye,"A",{href:!0});var Zit=s(PI);Q_o=r(Zit,"DetrFeatureExtractor"),Zit.forEach(t),W_o=r(Zye," (DETR model)"),Zye.forEach(t),H_o=i(K),jh=n(K,"LI",{});var e8e=s(jh);_ie=n(e8e,"STRONG",{});var edt=s(_ie);U_o=r(edt,"dpt"),edt.forEach(t),J_o=r(e8e," \u2014 "),BI=n(e8e,"A",{href:!0});var odt=s(BI);Y_o=r(odt,"DPTFeatureExtractor"),odt.forEach(t),K_o=r(e8e," (DPT model)"),e8e.forEach(t),Z_o=i(K),Dh=n(K,"LI",{});var o8e=s(Dh);uie=n(o8e,"STRONG",{});var rdt=s(uie);euo=r(rdt,"flava"),rdt.forEach(t),ouo=r(o8e," \u2014 "),NI=n(o8e,"A",{href:!0});var tdt=s(NI);ruo=r(tdt,"FlavaFeatureExtractor"),tdt.forEach(t),tuo=r(o8e," (FLAVA model)"),o8e.forEach(t),auo=i(K),Gh=n(K,"LI",{});var r8e=s(Gh);bie=n(r8e,"STRONG",{});var adt=s(bie);nuo=r(adt,"glpn"),adt.forEach(t),suo=r(r8e," \u2014 "),II=n(r8e,"A",{href:!0});var ndt=s(II);luo=r(ndt,"GLPNFeatureExtractor"),ndt.forEach(t),iuo=r(r8e," (GLPN model)"),r8e.forEach(t),duo=i(K),Oh=n(K,"LI",{});var t8e=s(Oh);vie=n(t8e,"STRONG",{});var sdt=s(vie);cuo=r(sdt,"groupvit"),sdt.forEach(t),fuo=r(t8e," \u2014 "),qI=n(t8e,"A",{href:!0});var ldt=s(qI);muo=r(ldt,"CLIPFeatureExtractor"),ldt.forEach(t),guo=r(t8e," (GroupViT model)"),t8e.forEach(t),huo=i(K),Vh=n(K,"LI",{});var a8e=s(Vh);Fie=n(a8e,"STRONG",{});var idt=s(Fie);puo=r(idt,"hubert"),idt.forEach(t),_uo=r(a8e," \u2014 "),jI=n(a8e,"A",{href:!0});var ddt=s(jI);uuo=r(ddt,"Wav2Vec2FeatureExtractor"),ddt.forEach(t),buo=r(a8e," (Hubert model)"),a8e.forEach(t),vuo=i(K),Xh=n(K,"LI",{});var n8e=s(Xh);Tie=n(n8e,"STRONG",{});var cdt=s(Tie);Fuo=r(cdt,"imagegpt"),cdt.forEach(t),Tuo=r(n8e," \u2014 "),DI=n(n8e,"A",{href:!0});var fdt=s(DI);Muo=r(fdt,"ImageGPTFeatureExtractor"),fdt.forEach(t),Euo=r(n8e," (ImageGPT model)"),n8e.forEach(t),Cuo=i(K),zh=n(K,"LI",{});var s8e=s(zh);Mie=n(s8e,"STRONG",{});var mdt=s(Mie);wuo=r(mdt,"layoutlmv2"),mdt.forEach(t),Auo=r(s8e," \u2014 "),GI=n(s8e,"A",{href:!0});var gdt=s(GI);Luo=r(gdt,"LayoutLMv2FeatureExtractor"),gdt.forEach(t),yuo=r(s8e," (LayoutLMv2 model)"),s8e.forEach(t),xuo=i(K),Qh=n(K,"LI",{});var l8e=s(Qh);Eie=n(l8e,"STRONG",{});var hdt=s(Eie);$uo=r(hdt,"layoutlmv3"),hdt.forEach(t),kuo=r(l8e," \u2014 "),OI=n(l8e,"A",{href:!0});var pdt=s(OI);Suo=r(pdt,"LayoutLMv3FeatureExtractor"),pdt.forEach(t),Ruo=r(l8e," (LayoutLMv3 model)"),l8e.forEach(t),Puo=i(K),Wh=n(K,"LI",{});var i8e=s(Wh);Cie=n(i8e,"STRONG",{});var _dt=s(Cie);Buo=r(_dt,"levit"),_dt.forEach(t),Nuo=r(i8e," \u2014 "),VI=n(i8e,"A",{href:!0});var udt=s(VI);Iuo=r(udt,"LevitFeatureExtractor"),udt.forEach(t),quo=r(i8e," (LeViT model)"),i8e.forEach(t),juo=i(K),Hh=n(K,"LI",{});var d8e=s(Hh);wie=n(d8e,"STRONG",{});var bdt=s(wie);Duo=r(bdt,"maskformer"),bdt.forEach(t),Guo=r(d8e," \u2014 "),XI=n(d8e,"A",{href:!0});var vdt=s(XI);Ouo=r(vdt,"MaskFormerFeatureExtractor"),vdt.forEach(t),Vuo=r(d8e," (MaskFormer model)"),d8e.forEach(t),Xuo=i(K),Uh=n(K,"LI",{});var c8e=s(Uh);Aie=n(c8e,"STRONG",{});var Fdt=s(Aie);zuo=r(Fdt,"mctct"),Fdt.forEach(t),Quo=r(c8e," \u2014 "),zI=n(c8e,"A",{href:!0});var Tdt=s(zI);Wuo=r(Tdt,"MCTCTFeatureExtractor"),Tdt.forEach(t),Huo=r(c8e," (M-CTC-T model)"),c8e.forEach(t),Uuo=i(K),Jh=n(K,"LI",{});var f8e=s(Jh);Lie=n(f8e,"STRONG",{});var Mdt=s(Lie);Juo=r(Mdt,"perceiver"),Mdt.forEach(t),Yuo=r(f8e," \u2014 "),QI=n(f8e,"A",{href:!0});var Edt=s(QI);Kuo=r(Edt,"PerceiverFeatureExtractor"),Edt.forEach(t),Zuo=r(f8e," (Perceiver model)"),f8e.forEach(t),e2o=i(K),Yh=n(K,"LI",{});var m8e=s(Yh);yie=n(m8e,"STRONG",{});var Cdt=s(yie);o2o=r(Cdt,"poolformer"),Cdt.forEach(t),r2o=r(m8e," \u2014 "),WI=n(m8e,"A",{href:!0});var wdt=s(WI);t2o=r(wdt,"PoolFormerFeatureExtractor"),wdt.forEach(t),a2o=r(m8e," (PoolFormer model)"),m8e.forEach(t),n2o=i(K),Kh=n(K,"LI",{});var g8e=s(Kh);xie=n(g8e,"STRONG",{});var Adt=s(xie);s2o=r(Adt,"regnet"),Adt.forEach(t),l2o=r(g8e," \u2014 "),HI=n(g8e,"A",{href:!0});var Ldt=s(HI);i2o=r(Ldt,"ConvNextFeatureExtractor"),Ldt.forEach(t),d2o=r(g8e," (RegNet model)"),g8e.forEach(t),c2o=i(K),Zh=n(K,"LI",{});var h8e=s(Zh);$ie=n(h8e,"STRONG",{});var ydt=s($ie);f2o=r(ydt,"resnet"),ydt.forEach(t),m2o=r(h8e," \u2014 "),UI=n(h8e,"A",{href:!0});var xdt=s(UI);g2o=r(xdt,"ConvNextFeatureExtractor"),xdt.forEach(t),h2o=r(h8e," (ResNet model)"),h8e.forEach(t),p2o=i(K),ep=n(K,"LI",{});var p8e=s(ep);kie=n(p8e,"STRONG",{});var $dt=s(kie);_2o=r($dt,"segformer"),$dt.forEach(t),u2o=r(p8e," \u2014 "),JI=n(p8e,"A",{href:!0});var kdt=s(JI);b2o=r(kdt,"SegformerFeatureExtractor"),kdt.forEach(t),v2o=r(p8e," (SegFormer model)"),p8e.forEach(t),F2o=i(K),op=n(K,"LI",{});var _8e=s(op);Sie=n(_8e,"STRONG",{});var Sdt=s(Sie);T2o=r(Sdt,"speech_to_text"),Sdt.forEach(t),M2o=r(_8e," \u2014 "),YI=n(_8e,"A",{href:!0});var Rdt=s(YI);E2o=r(Rdt,"Speech2TextFeatureExtractor"),Rdt.forEach(t),C2o=r(_8e," (Speech2Text model)"),_8e.forEach(t),w2o=i(K),rp=n(K,"LI",{});var u8e=s(rp);Rie=n(u8e,"STRONG",{});var Pdt=s(Rie);A2o=r(Pdt,"swin"),Pdt.forEach(t),L2o=r(u8e," \u2014 "),KI=n(u8e,"A",{href:!0});var Bdt=s(KI);y2o=r(Bdt,"ViTFeatureExtractor"),Bdt.forEach(t),x2o=r(u8e," (Swin Transformer model)"),u8e.forEach(t),$2o=i(K),tp=n(K,"LI",{});var b8e=s(tp);Pie=n(b8e,"STRONG",{});var Ndt=s(Pie);k2o=r(Ndt,"van"),Ndt.forEach(t),S2o=r(b8e," \u2014 "),ZI=n(b8e,"A",{href:!0});var Idt=s(ZI);R2o=r(Idt,"ConvNextFeatureExtractor"),Idt.forEach(t),P2o=r(b8e," (VAN model)"),b8e.forEach(t),B2o=i(K),ap=n(K,"LI",{});var v8e=s(ap);Bie=n(v8e,"STRONG",{});var qdt=s(Bie);N2o=r(qdt,"vilt"),qdt.forEach(t),I2o=r(v8e," \u2014 "),eq=n(v8e,"A",{href:!0});var jdt=s(eq);q2o=r(jdt,"ViltFeatureExtractor"),jdt.forEach(t),j2o=r(v8e," (ViLT model)"),v8e.forEach(t),D2o=i(K),np=n(K,"LI",{});var F8e=s(np);Nie=n(F8e,"STRONG",{});var Ddt=s(Nie);G2o=r(Ddt,"vit"),Ddt.forEach(t),O2o=r(F8e," \u2014 "),oq=n(F8e,"A",{href:!0});var Gdt=s(oq);V2o=r(Gdt,"ViTFeatureExtractor"),Gdt.forEach(t),X2o=r(F8e," (ViT model)"),F8e.forEach(t),z2o=i(K),sp=n(K,"LI",{});var T8e=s(sp);Iie=n(T8e,"STRONG",{});var Odt=s(Iie);Q2o=r(Odt,"vit_mae"),Odt.forEach(t),W2o=r(T8e," \u2014 "),rq=n(T8e,"A",{href:!0});var Vdt=s(rq);H2o=r(Vdt,"ViTFeatureExtractor"),Vdt.forEach(t),U2o=r(T8e," (ViTMAE model)"),T8e.forEach(t),J2o=i(K),lp=n(K,"LI",{});var M8e=s(lp);qie=n(M8e,"STRONG",{});var Xdt=s(qie);Y2o=r(Xdt,"wav2vec2"),Xdt.forEach(t),K2o=r(M8e," \u2014 "),tq=n(M8e,"A",{href:!0});var zdt=s(tq);Z2o=r(zdt,"Wav2Vec2FeatureExtractor"),zdt.forEach(t),e1o=r(M8e," (Wav2Vec2 model)"),M8e.forEach(t),o1o=i(K),ip=n(K,"LI",{});var E8e=s(ip);jie=n(E8e,"STRONG",{});var Qdt=s(jie);r1o=r(Qdt,"wav2vec2-conformer"),Qdt.forEach(t),t1o=r(E8e," \u2014 "),aq=n(E8e,"A",{href:!0});var Wdt=s(aq);a1o=r(Wdt,"Wav2Vec2FeatureExtractor"),Wdt.forEach(t),n1o=r(E8e," (Wav2Vec2-Conformer model)"),E8e.forEach(t),s1o=i(K),dp=n(K,"LI",{});var C8e=s(dp);Die=n(C8e,"STRONG",{});var Hdt=s(Die);l1o=r(Hdt,"yolos"),Hdt.forEach(t),i1o=r(C8e," \u2014 "),nq=n(C8e,"A",{href:!0});var Udt=s(nq);d1o=r(Udt,"YolosFeatureExtractor"),Udt.forEach(t),c1o=r(C8e," (YOLOS model)"),C8e.forEach(t),K.forEach(t),f1o=i(ta),T(cp.$$.fragment,ta),m1o=i(ta),T(fp.$$.fragment,ta),ta.forEach(t),g1o=i(Ks),mp=n(Ks,"DIV",{class:!0});var ZXe=s(mp);T(ly.$$.fragment,ZXe),h1o=i(ZXe),Gie=n(ZXe,"P",{});var Jdt=s(Gie);p1o=r(Jdt,"Register a new feature extractor for this class."),Jdt.forEach(t),ZXe.forEach(t),Ks.forEach(t),JOe=i(f),Ni=n(f,"H2",{class:!0});var eze=s(Ni);gp=n(eze,"A",{id:!0,class:!0,href:!0});var Ydt=s(gp);Oie=n(Ydt,"SPAN",{});var Kdt=s(Oie);T(iy.$$.fragment,Kdt),Kdt.forEach(t),Ydt.forEach(t),_1o=i(eze),Vie=n(eze,"SPAN",{});var Zdt=s(Vie);u1o=r(Zdt,"AutoProcessor"),Zdt.forEach(t),eze.forEach(t),YOe=i(f),yo=n(f,"DIV",{class:!0});var Zs=s(yo);T(dy.$$.fragment,Zs),b1o=i(Zs),cy=n(Zs,"P",{});var oze=s(cy);v1o=r(oze,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),sq=n(oze,"A",{href:!0});var ect=s(sq);F1o=r(ect,"AutoProcessor.from_pretrained()"),ect.forEach(t),T1o=r(oze," class method."),oze.forEach(t),M1o=i(Zs),fy=n(Zs,"P",{});var rze=s(fy);E1o=r(rze,"This class cannot be instantiated directly using "),Xie=n(rze,"CODE",{});var oct=s(Xie);C1o=r(oct,"__init__()"),oct.forEach(t),w1o=r(rze," (throws an error)."),rze.forEach(t),A1o=i(Zs),Ue=n(Zs,"DIV",{class:!0});var aa=s(Ue);T(my.$$.fragment,aa),L1o=i(aa),zie=n(aa,"P",{});var rct=s(zie);y1o=r(rct,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),rct.forEach(t),x1o=i(aa),Ii=n(aa,"P",{});var Hoe=s(Ii);$1o=r(Hoe,"The processor class to instantiate is selected based on the "),Qie=n(Hoe,"CODE",{});var tct=s(Qie);k1o=r(tct,"model_type"),tct.forEach(t),S1o=r(Hoe,` property of the config object (either
passed as an argument or loaded from `),Wie=n(Hoe,"CODE",{});var act=s(Wie);R1o=r(act,"pretrained_model_name_or_path"),act.forEach(t),P1o=r(Hoe," if possible):"),Hoe.forEach(t),B1o=i(aa),he=n(aa,"UL",{});var ue=s(he);hp=n(ue,"LI",{});var w8e=s(hp);Hie=n(w8e,"STRONG",{});var nct=s(Hie);N1o=r(nct,"clip"),nct.forEach(t),I1o=r(w8e," \u2014 "),lq=n(w8e,"A",{href:!0});var sct=s(lq);q1o=r(sct,"CLIPProcessor"),sct.forEach(t),j1o=r(w8e," (CLIP model)"),w8e.forEach(t),D1o=i(ue),pp=n(ue,"LI",{});var A8e=s(pp);Uie=n(A8e,"STRONG",{});var lct=s(Uie);G1o=r(lct,"flava"),lct.forEach(t),O1o=r(A8e," \u2014 "),Jie=n(A8e,"CODE",{});var ict=s(Jie);V1o=r(ict,"FLAVAProcessor"),ict.forEach(t),X1o=r(A8e," (FLAVA model)"),A8e.forEach(t),z1o=i(ue),_p=n(ue,"LI",{});var L8e=s(_p);Yie=n(L8e,"STRONG",{});var dct=s(Yie);Q1o=r(dct,"groupvit"),dct.forEach(t),W1o=r(L8e," \u2014 "),iq=n(L8e,"A",{href:!0});var cct=s(iq);H1o=r(cct,"CLIPProcessor"),cct.forEach(t),U1o=r(L8e," (GroupViT model)"),L8e.forEach(t),J1o=i(ue),up=n(ue,"LI",{});var y8e=s(up);Kie=n(y8e,"STRONG",{});var fct=s(Kie);Y1o=r(fct,"layoutlmv2"),fct.forEach(t),K1o=r(y8e," \u2014 "),dq=n(y8e,"A",{href:!0});var mct=s(dq);Z1o=r(mct,"LayoutLMv2Processor"),mct.forEach(t),e7o=r(y8e," (LayoutLMv2 model)"),y8e.forEach(t),o7o=i(ue),bp=n(ue,"LI",{});var x8e=s(bp);Zie=n(x8e,"STRONG",{});var gct=s(Zie);r7o=r(gct,"layoutlmv3"),gct.forEach(t),t7o=r(x8e," \u2014 "),cq=n(x8e,"A",{href:!0});var hct=s(cq);a7o=r(hct,"LayoutLMv3Processor"),hct.forEach(t),n7o=r(x8e," (LayoutLMv3 model)"),x8e.forEach(t),s7o=i(ue),vp=n(ue,"LI",{});var $8e=s(vp);ede=n($8e,"STRONG",{});var pct=s(ede);l7o=r(pct,"layoutxlm"),pct.forEach(t),i7o=r($8e," \u2014 "),fq=n($8e,"A",{href:!0});var _ct=s(fq);d7o=r(_ct,"LayoutXLMProcessor"),_ct.forEach(t),c7o=r($8e," (LayoutXLM model)"),$8e.forEach(t),f7o=i(ue),Fp=n(ue,"LI",{});var k8e=s(Fp);ode=n(k8e,"STRONG",{});var uct=s(ode);m7o=r(uct,"sew"),uct.forEach(t),g7o=r(k8e," \u2014 "),mq=n(k8e,"A",{href:!0});var bct=s(mq);h7o=r(bct,"Wav2Vec2Processor"),bct.forEach(t),p7o=r(k8e," (SEW model)"),k8e.forEach(t),_7o=i(ue),Tp=n(ue,"LI",{});var S8e=s(Tp);rde=n(S8e,"STRONG",{});var vct=s(rde);u7o=r(vct,"sew-d"),vct.forEach(t),b7o=r(S8e," \u2014 "),gq=n(S8e,"A",{href:!0});var Fct=s(gq);v7o=r(Fct,"Wav2Vec2Processor"),Fct.forEach(t),F7o=r(S8e," (SEW-D model)"),S8e.forEach(t),T7o=i(ue),Mp=n(ue,"LI",{});var R8e=s(Mp);tde=n(R8e,"STRONG",{});var Tct=s(tde);M7o=r(Tct,"speech_to_text"),Tct.forEach(t),E7o=r(R8e," \u2014 "),hq=n(R8e,"A",{href:!0});var Mct=s(hq);C7o=r(Mct,"Speech2TextProcessor"),Mct.forEach(t),w7o=r(R8e," (Speech2Text model)"),R8e.forEach(t),A7o=i(ue),Ep=n(ue,"LI",{});var P8e=s(Ep);ade=n(P8e,"STRONG",{});var Ect=s(ade);L7o=r(Ect,"speech_to_text_2"),Ect.forEach(t),y7o=r(P8e," \u2014 "),pq=n(P8e,"A",{href:!0});var Cct=s(pq);x7o=r(Cct,"Speech2Text2Processor"),Cct.forEach(t),$7o=r(P8e," (Speech2Text2 model)"),P8e.forEach(t),k7o=i(ue),Cp=n(ue,"LI",{});var B8e=s(Cp);nde=n(B8e,"STRONG",{});var wct=s(nde);S7o=r(wct,"trocr"),wct.forEach(t),R7o=r(B8e," \u2014 "),_q=n(B8e,"A",{href:!0});var Act=s(_q);P7o=r(Act,"TrOCRProcessor"),Act.forEach(t),B7o=r(B8e," (TrOCR model)"),B8e.forEach(t),N7o=i(ue),wp=n(ue,"LI",{});var N8e=s(wp);sde=n(N8e,"STRONG",{});var Lct=s(sde);I7o=r(Lct,"unispeech"),Lct.forEach(t),q7o=r(N8e," \u2014 "),uq=n(N8e,"A",{href:!0});var yct=s(uq);j7o=r(yct,"Wav2Vec2Processor"),yct.forEach(t),D7o=r(N8e," (UniSpeech model)"),N8e.forEach(t),G7o=i(ue),Ap=n(ue,"LI",{});var I8e=s(Ap);lde=n(I8e,"STRONG",{});var xct=s(lde);O7o=r(xct,"unispeech-sat"),xct.forEach(t),V7o=r(I8e," \u2014 "),bq=n(I8e,"A",{href:!0});var $ct=s(bq);X7o=r($ct,"Wav2Vec2Processor"),$ct.forEach(t),z7o=r(I8e," (UniSpeechSat model)"),I8e.forEach(t),Q7o=i(ue),Lp=n(ue,"LI",{});var q8e=s(Lp);ide=n(q8e,"STRONG",{});var kct=s(ide);W7o=r(kct,"vilt"),kct.forEach(t),H7o=r(q8e," \u2014 "),vq=n(q8e,"A",{href:!0});var Sct=s(vq);U7o=r(Sct,"ViltProcessor"),Sct.forEach(t),J7o=r(q8e," (ViLT model)"),q8e.forEach(t),Y7o=i(ue),yp=n(ue,"LI",{});var j8e=s(yp);dde=n(j8e,"STRONG",{});var Rct=s(dde);K7o=r(Rct,"vision-text-dual-encoder"),Rct.forEach(t),Z7o=r(j8e," \u2014 "),Fq=n(j8e,"A",{href:!0});var Pct=s(Fq);e4o=r(Pct,"VisionTextDualEncoderProcessor"),Pct.forEach(t),o4o=r(j8e," (VisionTextDualEncoder model)"),j8e.forEach(t),r4o=i(ue),xp=n(ue,"LI",{});var D8e=s(xp);cde=n(D8e,"STRONG",{});var Bct=s(cde);t4o=r(Bct,"wav2vec2"),Bct.forEach(t),a4o=r(D8e," \u2014 "),Tq=n(D8e,"A",{href:!0});var Nct=s(Tq);n4o=r(Nct,"Wav2Vec2Processor"),Nct.forEach(t),s4o=r(D8e," (Wav2Vec2 model)"),D8e.forEach(t),l4o=i(ue),$p=n(ue,"LI",{});var G8e=s($p);fde=n(G8e,"STRONG",{});var Ict=s(fde);i4o=r(Ict,"wav2vec2-conformer"),Ict.forEach(t),d4o=r(G8e," \u2014 "),Mq=n(G8e,"A",{href:!0});var qct=s(Mq);c4o=r(qct,"Wav2Vec2Processor"),qct.forEach(t),f4o=r(G8e," (Wav2Vec2-Conformer model)"),G8e.forEach(t),m4o=i(ue),kp=n(ue,"LI",{});var O8e=s(kp);mde=n(O8e,"STRONG",{});var jct=s(mde);g4o=r(jct,"wavlm"),jct.forEach(t),h4o=r(O8e," \u2014 "),Eq=n(O8e,"A",{href:!0});var Dct=s(Eq);p4o=r(Dct,"Wav2Vec2Processor"),Dct.forEach(t),_4o=r(O8e," (WavLM model)"),O8e.forEach(t),ue.forEach(t),u4o=i(aa),T(Sp.$$.fragment,aa),b4o=i(aa),T(Rp.$$.fragment,aa),aa.forEach(t),v4o=i(Zs),Pp=n(Zs,"DIV",{class:!0});var tze=s(Pp);T(gy.$$.fragment,tze),F4o=i(tze),gde=n(tze,"P",{});var Gct=s(gde);T4o=r(Gct,"Register a new processor for this class."),Gct.forEach(t),tze.forEach(t),Zs.forEach(t),KOe=i(f),qi=n(f,"H2",{class:!0});var aze=s(qi);Bp=n(aze,"A",{id:!0,class:!0,href:!0});var Oct=s(Bp);hde=n(Oct,"SPAN",{});var Vct=s(hde);T(hy.$$.fragment,Vct),Vct.forEach(t),Oct.forEach(t),M4o=i(aze),pde=n(aze,"SPAN",{});var Xct=s(pde);E4o=r(Xct,"AutoModel"),Xct.forEach(t),aze.forEach(t),ZOe=i(f),xo=n(f,"DIV",{class:!0});var el=s(xo);T(py.$$.fragment,el),C4o=i(el),ji=n(el,"P",{});var Uoe=s(ji);w4o=r(Uoe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Cq=n(Uoe,"A",{href:!0});var zct=s(Cq);A4o=r(zct,"from_pretrained()"),zct.forEach(t),L4o=r(Uoe," class method or the "),wq=n(Uoe,"A",{href:!0});var Qct=s(wq);y4o=r(Qct,"from_config()"),Qct.forEach(t),x4o=r(Uoe,` class
method.`),Uoe.forEach(t),$4o=i(el),_y=n(el,"P",{});var nze=s(_y);k4o=r(nze,"This class cannot be instantiated directly using "),_de=n(nze,"CODE",{});var Wct=s(_de);S4o=r(Wct,"__init__()"),Wct.forEach(t),R4o=r(nze," (throws an error)."),nze.forEach(t),P4o=i(el),st=n(el,"DIV",{class:!0});var zA=s(st);T(uy.$$.fragment,zA),B4o=i(zA),ude=n(zA,"P",{});var Hct=s(ude);N4o=r(Hct,"Instantiates one of the base model classes of the library from a configuration."),Hct.forEach(t),I4o=i(zA),Di=n(zA,"P",{});var Joe=s(Di);q4o=r(Joe,`Note:
Loading a model from its configuration file does `),bde=n(Joe,"STRONG",{});var Uct=s(bde);j4o=r(Uct,"not"),Uct.forEach(t),D4o=r(Joe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aq=n(Joe,"A",{href:!0});var Jct=s(Aq);G4o=r(Jct,"from_pretrained()"),Jct.forEach(t),O4o=r(Joe," to load the model weights."),Joe.forEach(t),V4o=i(zA),T(Np.$$.fragment,zA),zA.forEach(t),X4o=i(el),Je=n(el,"DIV",{class:!0});var na=s(Je);T(by.$$.fragment,na),z4o=i(na),vde=n(na,"P",{});var Yct=s(vde);Q4o=r(Yct,"Instantiate one of the base model classes of the library from a pretrained model."),Yct.forEach(t),W4o=i(na),Ba=n(na,"P",{});var QA=s(Ba);H4o=r(QA,"The model class to instantiate is selected based on the "),Fde=n(QA,"CODE",{});var Kct=s(Fde);U4o=r(Kct,"model_type"),Kct.forEach(t),J4o=r(QA,` property of the config object (either
passed as an argument or loaded from `),Tde=n(QA,"CODE",{});var Zct=s(Tde);Y4o=r(Zct,"pretrained_model_name_or_path"),Zct.forEach(t),K4o=r(QA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mde=n(QA,"CODE",{});var eft=s(Mde);Z4o=r(eft,"pretrained_model_name_or_path"),eft.forEach(t),ebo=r(QA,":"),QA.forEach(t),obo=i(na),y=n(na,"UL",{});var x=s(y);Ip=n(x,"LI",{});var V8e=s(Ip);Ede=n(V8e,"STRONG",{});var oft=s(Ede);rbo=r(oft,"albert"),oft.forEach(t),tbo=r(V8e," \u2014 "),Lq=n(V8e,"A",{href:!0});var rft=s(Lq);abo=r(rft,"AlbertModel"),rft.forEach(t),nbo=r(V8e," (ALBERT model)"),V8e.forEach(t),sbo=i(x),qp=n(x,"LI",{});var X8e=s(qp);Cde=n(X8e,"STRONG",{});var tft=s(Cde);lbo=r(tft,"bart"),tft.forEach(t),ibo=r(X8e," \u2014 "),yq=n(X8e,"A",{href:!0});var aft=s(yq);dbo=r(aft,"BartModel"),aft.forEach(t),cbo=r(X8e," (BART model)"),X8e.forEach(t),fbo=i(x),jp=n(x,"LI",{});var z8e=s(jp);wde=n(z8e,"STRONG",{});var nft=s(wde);mbo=r(nft,"beit"),nft.forEach(t),gbo=r(z8e," \u2014 "),xq=n(z8e,"A",{href:!0});var sft=s(xq);hbo=r(sft,"BeitModel"),sft.forEach(t),pbo=r(z8e," (BEiT model)"),z8e.forEach(t),_bo=i(x),Dp=n(x,"LI",{});var Q8e=s(Dp);Ade=n(Q8e,"STRONG",{});var lft=s(Ade);ubo=r(lft,"bert"),lft.forEach(t),bbo=r(Q8e," \u2014 "),$q=n(Q8e,"A",{href:!0});var ift=s($q);vbo=r(ift,"BertModel"),ift.forEach(t),Fbo=r(Q8e," (BERT model)"),Q8e.forEach(t),Tbo=i(x),Gp=n(x,"LI",{});var W8e=s(Gp);Lde=n(W8e,"STRONG",{});var dft=s(Lde);Mbo=r(dft,"bert-generation"),dft.forEach(t),Ebo=r(W8e," \u2014 "),kq=n(W8e,"A",{href:!0});var cft=s(kq);Cbo=r(cft,"BertGenerationEncoder"),cft.forEach(t),wbo=r(W8e," (Bert Generation model)"),W8e.forEach(t),Abo=i(x),Op=n(x,"LI",{});var H8e=s(Op);yde=n(H8e,"STRONG",{});var fft=s(yde);Lbo=r(fft,"big_bird"),fft.forEach(t),ybo=r(H8e," \u2014 "),Sq=n(H8e,"A",{href:!0});var mft=s(Sq);xbo=r(mft,"BigBirdModel"),mft.forEach(t),$bo=r(H8e," (BigBird model)"),H8e.forEach(t),kbo=i(x),Vp=n(x,"LI",{});var U8e=s(Vp);xde=n(U8e,"STRONG",{});var gft=s(xde);Sbo=r(gft,"bigbird_pegasus"),gft.forEach(t),Rbo=r(U8e," \u2014 "),Rq=n(U8e,"A",{href:!0});var hft=s(Rq);Pbo=r(hft,"BigBirdPegasusModel"),hft.forEach(t),Bbo=r(U8e," (BigBird-Pegasus model)"),U8e.forEach(t),Nbo=i(x),Xp=n(x,"LI",{});var J8e=s(Xp);$de=n(J8e,"STRONG",{});var pft=s($de);Ibo=r(pft,"blenderbot"),pft.forEach(t),qbo=r(J8e," \u2014 "),Pq=n(J8e,"A",{href:!0});var _ft=s(Pq);jbo=r(_ft,"BlenderbotModel"),_ft.forEach(t),Dbo=r(J8e," (Blenderbot model)"),J8e.forEach(t),Gbo=i(x),zp=n(x,"LI",{});var Y8e=s(zp);kde=n(Y8e,"STRONG",{});var uft=s(kde);Obo=r(uft,"blenderbot-small"),uft.forEach(t),Vbo=r(Y8e," \u2014 "),Bq=n(Y8e,"A",{href:!0});var bft=s(Bq);Xbo=r(bft,"BlenderbotSmallModel"),bft.forEach(t),zbo=r(Y8e," (BlenderbotSmall model)"),Y8e.forEach(t),Qbo=i(x),Qp=n(x,"LI",{});var K8e=s(Qp);Sde=n(K8e,"STRONG",{});var vft=s(Sde);Wbo=r(vft,"bloom"),vft.forEach(t),Hbo=r(K8e," \u2014 "),Nq=n(K8e,"A",{href:!0});var Fft=s(Nq);Ubo=r(Fft,"BloomModel"),Fft.forEach(t),Jbo=r(K8e," (BLOOM model)"),K8e.forEach(t),Ybo=i(x),Wp=n(x,"LI",{});var Z8e=s(Wp);Rde=n(Z8e,"STRONG",{});var Tft=s(Rde);Kbo=r(Tft,"camembert"),Tft.forEach(t),Zbo=r(Z8e," \u2014 "),Iq=n(Z8e,"A",{href:!0});var Mft=s(Iq);evo=r(Mft,"CamembertModel"),Mft.forEach(t),ovo=r(Z8e," (CamemBERT model)"),Z8e.forEach(t),rvo=i(x),Hp=n(x,"LI",{});var e9e=s(Hp);Pde=n(e9e,"STRONG",{});var Eft=s(Pde);tvo=r(Eft,"canine"),Eft.forEach(t),avo=r(e9e," \u2014 "),qq=n(e9e,"A",{href:!0});var Cft=s(qq);nvo=r(Cft,"CanineModel"),Cft.forEach(t),svo=r(e9e," (CANINE model)"),e9e.forEach(t),lvo=i(x),Up=n(x,"LI",{});var o9e=s(Up);Bde=n(o9e,"STRONG",{});var wft=s(Bde);ivo=r(wft,"clip"),wft.forEach(t),dvo=r(o9e," \u2014 "),jq=n(o9e,"A",{href:!0});var Aft=s(jq);cvo=r(Aft,"CLIPModel"),Aft.forEach(t),fvo=r(o9e," (CLIP model)"),o9e.forEach(t),mvo=i(x),Jp=n(x,"LI",{});var r9e=s(Jp);Nde=n(r9e,"STRONG",{});var Lft=s(Nde);gvo=r(Lft,"codegen"),Lft.forEach(t),hvo=r(r9e," \u2014 "),Dq=n(r9e,"A",{href:!0});var yft=s(Dq);pvo=r(yft,"CodeGenModel"),yft.forEach(t),_vo=r(r9e," (CodeGen model)"),r9e.forEach(t),uvo=i(x),Yp=n(x,"LI",{});var t9e=s(Yp);Ide=n(t9e,"STRONG",{});var xft=s(Ide);bvo=r(xft,"convbert"),xft.forEach(t),vvo=r(t9e," \u2014 "),Gq=n(t9e,"A",{href:!0});var $ft=s(Gq);Fvo=r($ft,"ConvBertModel"),$ft.forEach(t),Tvo=r(t9e," (ConvBERT model)"),t9e.forEach(t),Mvo=i(x),Kp=n(x,"LI",{});var a9e=s(Kp);qde=n(a9e,"STRONG",{});var kft=s(qde);Evo=r(kft,"convnext"),kft.forEach(t),Cvo=r(a9e," \u2014 "),Oq=n(a9e,"A",{href:!0});var Sft=s(Oq);wvo=r(Sft,"ConvNextModel"),Sft.forEach(t),Avo=r(a9e," (ConvNeXT model)"),a9e.forEach(t),Lvo=i(x),Zp=n(x,"LI",{});var n9e=s(Zp);jde=n(n9e,"STRONG",{});var Rft=s(jde);yvo=r(Rft,"ctrl"),Rft.forEach(t),xvo=r(n9e," \u2014 "),Vq=n(n9e,"A",{href:!0});var Pft=s(Vq);$vo=r(Pft,"CTRLModel"),Pft.forEach(t),kvo=r(n9e," (CTRL model)"),n9e.forEach(t),Svo=i(x),e_=n(x,"LI",{});var s9e=s(e_);Dde=n(s9e,"STRONG",{});var Bft=s(Dde);Rvo=r(Bft,"cvt"),Bft.forEach(t),Pvo=r(s9e," \u2014 "),Xq=n(s9e,"A",{href:!0});var Nft=s(Xq);Bvo=r(Nft,"CvtModel"),Nft.forEach(t),Nvo=r(s9e," (CvT model)"),s9e.forEach(t),Ivo=i(x),o_=n(x,"LI",{});var l9e=s(o_);Gde=n(l9e,"STRONG",{});var Ift=s(Gde);qvo=r(Ift,"data2vec-audio"),Ift.forEach(t),jvo=r(l9e," \u2014 "),zq=n(l9e,"A",{href:!0});var qft=s(zq);Dvo=r(qft,"Data2VecAudioModel"),qft.forEach(t),Gvo=r(l9e," (Data2VecAudio model)"),l9e.forEach(t),Ovo=i(x),r_=n(x,"LI",{});var i9e=s(r_);Ode=n(i9e,"STRONG",{});var jft=s(Ode);Vvo=r(jft,"data2vec-text"),jft.forEach(t),Xvo=r(i9e," \u2014 "),Qq=n(i9e,"A",{href:!0});var Dft=s(Qq);zvo=r(Dft,"Data2VecTextModel"),Dft.forEach(t),Qvo=r(i9e," (Data2VecText model)"),i9e.forEach(t),Wvo=i(x),t_=n(x,"LI",{});var d9e=s(t_);Vde=n(d9e,"STRONG",{});var Gft=s(Vde);Hvo=r(Gft,"data2vec-vision"),Gft.forEach(t),Uvo=r(d9e," \u2014 "),Wq=n(d9e,"A",{href:!0});var Oft=s(Wq);Jvo=r(Oft,"Data2VecVisionModel"),Oft.forEach(t),Yvo=r(d9e," (Data2VecVision model)"),d9e.forEach(t),Kvo=i(x),a_=n(x,"LI",{});var c9e=s(a_);Xde=n(c9e,"STRONG",{});var Vft=s(Xde);Zvo=r(Vft,"deberta"),Vft.forEach(t),eFo=r(c9e," \u2014 "),Hq=n(c9e,"A",{href:!0});var Xft=s(Hq);oFo=r(Xft,"DebertaModel"),Xft.forEach(t),rFo=r(c9e," (DeBERTa model)"),c9e.forEach(t),tFo=i(x),n_=n(x,"LI",{});var f9e=s(n_);zde=n(f9e,"STRONG",{});var zft=s(zde);aFo=r(zft,"deberta-v2"),zft.forEach(t),nFo=r(f9e," \u2014 "),Uq=n(f9e,"A",{href:!0});var Qft=s(Uq);sFo=r(Qft,"DebertaV2Model"),Qft.forEach(t),lFo=r(f9e," (DeBERTa-v2 model)"),f9e.forEach(t),iFo=i(x),s_=n(x,"LI",{});var m9e=s(s_);Qde=n(m9e,"STRONG",{});var Wft=s(Qde);dFo=r(Wft,"decision_transformer"),Wft.forEach(t),cFo=r(m9e," \u2014 "),Jq=n(m9e,"A",{href:!0});var Hft=s(Jq);fFo=r(Hft,"DecisionTransformerModel"),Hft.forEach(t),mFo=r(m9e," (Decision Transformer model)"),m9e.forEach(t),gFo=i(x),l_=n(x,"LI",{});var g9e=s(l_);Wde=n(g9e,"STRONG",{});var Uft=s(Wde);hFo=r(Uft,"deit"),Uft.forEach(t),pFo=r(g9e," \u2014 "),Yq=n(g9e,"A",{href:!0});var Jft=s(Yq);_Fo=r(Jft,"DeiTModel"),Jft.forEach(t),uFo=r(g9e," (DeiT model)"),g9e.forEach(t),bFo=i(x),i_=n(x,"LI",{});var h9e=s(i_);Hde=n(h9e,"STRONG",{});var Yft=s(Hde);vFo=r(Yft,"detr"),Yft.forEach(t),FFo=r(h9e," \u2014 "),Kq=n(h9e,"A",{href:!0});var Kft=s(Kq);TFo=r(Kft,"DetrModel"),Kft.forEach(t),MFo=r(h9e," (DETR model)"),h9e.forEach(t),EFo=i(x),d_=n(x,"LI",{});var p9e=s(d_);Ude=n(p9e,"STRONG",{});var Zft=s(Ude);CFo=r(Zft,"distilbert"),Zft.forEach(t),wFo=r(p9e," \u2014 "),Zq=n(p9e,"A",{href:!0});var emt=s(Zq);AFo=r(emt,"DistilBertModel"),emt.forEach(t),LFo=r(p9e," (DistilBERT model)"),p9e.forEach(t),yFo=i(x),c_=n(x,"LI",{});var _9e=s(c_);Jde=n(_9e,"STRONG",{});var omt=s(Jde);xFo=r(omt,"dpr"),omt.forEach(t),$Fo=r(_9e," \u2014 "),ej=n(_9e,"A",{href:!0});var rmt=s(ej);kFo=r(rmt,"DPRQuestionEncoder"),rmt.forEach(t),SFo=r(_9e," (DPR model)"),_9e.forEach(t),RFo=i(x),f_=n(x,"LI",{});var u9e=s(f_);Yde=n(u9e,"STRONG",{});var tmt=s(Yde);PFo=r(tmt,"dpt"),tmt.forEach(t),BFo=r(u9e," \u2014 "),oj=n(u9e,"A",{href:!0});var amt=s(oj);NFo=r(amt,"DPTModel"),amt.forEach(t),IFo=r(u9e," (DPT model)"),u9e.forEach(t),qFo=i(x),m_=n(x,"LI",{});var b9e=s(m_);Kde=n(b9e,"STRONG",{});var nmt=s(Kde);jFo=r(nmt,"electra"),nmt.forEach(t),DFo=r(b9e," \u2014 "),rj=n(b9e,"A",{href:!0});var smt=s(rj);GFo=r(smt,"ElectraModel"),smt.forEach(t),OFo=r(b9e," (ELECTRA model)"),b9e.forEach(t),VFo=i(x),g_=n(x,"LI",{});var v9e=s(g_);Zde=n(v9e,"STRONG",{});var lmt=s(Zde);XFo=r(lmt,"flaubert"),lmt.forEach(t),zFo=r(v9e," \u2014 "),tj=n(v9e,"A",{href:!0});var imt=s(tj);QFo=r(imt,"FlaubertModel"),imt.forEach(t),WFo=r(v9e," (FlauBERT model)"),v9e.forEach(t),HFo=i(x),h_=n(x,"LI",{});var F9e=s(h_);ece=n(F9e,"STRONG",{});var dmt=s(ece);UFo=r(dmt,"flava"),dmt.forEach(t),JFo=r(F9e," \u2014 "),aj=n(F9e,"A",{href:!0});var cmt=s(aj);YFo=r(cmt,"FlavaModel"),cmt.forEach(t),KFo=r(F9e," (FLAVA model)"),F9e.forEach(t),ZFo=i(x),p_=n(x,"LI",{});var T9e=s(p_);oce=n(T9e,"STRONG",{});var fmt=s(oce);eTo=r(fmt,"fnet"),fmt.forEach(t),oTo=r(T9e," \u2014 "),nj=n(T9e,"A",{href:!0});var mmt=s(nj);rTo=r(mmt,"FNetModel"),mmt.forEach(t),tTo=r(T9e," (FNet model)"),T9e.forEach(t),aTo=i(x),__=n(x,"LI",{});var M9e=s(__);rce=n(M9e,"STRONG",{});var gmt=s(rce);nTo=r(gmt,"fsmt"),gmt.forEach(t),sTo=r(M9e," \u2014 "),sj=n(M9e,"A",{href:!0});var hmt=s(sj);lTo=r(hmt,"FSMTModel"),hmt.forEach(t),iTo=r(M9e," (FairSeq Machine-Translation model)"),M9e.forEach(t),dTo=i(x),Qs=n(x,"LI",{});var gS=s(Qs);tce=n(gS,"STRONG",{});var pmt=s(tce);cTo=r(pmt,"funnel"),pmt.forEach(t),fTo=r(gS," \u2014 "),lj=n(gS,"A",{href:!0});var _mt=s(lj);mTo=r(_mt,"FunnelModel"),_mt.forEach(t),gTo=r(gS," or "),ij=n(gS,"A",{href:!0});var umt=s(ij);hTo=r(umt,"FunnelBaseModel"),umt.forEach(t),pTo=r(gS," (Funnel Transformer model)"),gS.forEach(t),_To=i(x),u_=n(x,"LI",{});var E9e=s(u_);ace=n(E9e,"STRONG",{});var bmt=s(ace);uTo=r(bmt,"glpn"),bmt.forEach(t),bTo=r(E9e," \u2014 "),dj=n(E9e,"A",{href:!0});var vmt=s(dj);vTo=r(vmt,"GLPNModel"),vmt.forEach(t),FTo=r(E9e," (GLPN model)"),E9e.forEach(t),TTo=i(x),b_=n(x,"LI",{});var C9e=s(b_);nce=n(C9e,"STRONG",{});var Fmt=s(nce);MTo=r(Fmt,"gpt2"),Fmt.forEach(t),ETo=r(C9e," \u2014 "),cj=n(C9e,"A",{href:!0});var Tmt=s(cj);CTo=r(Tmt,"GPT2Model"),Tmt.forEach(t),wTo=r(C9e," (OpenAI GPT-2 model)"),C9e.forEach(t),ATo=i(x),v_=n(x,"LI",{});var w9e=s(v_);sce=n(w9e,"STRONG",{});var Mmt=s(sce);LTo=r(Mmt,"gpt_neo"),Mmt.forEach(t),yTo=r(w9e," \u2014 "),fj=n(w9e,"A",{href:!0});var Emt=s(fj);xTo=r(Emt,"GPTNeoModel"),Emt.forEach(t),$To=r(w9e," (GPT Neo model)"),w9e.forEach(t),kTo=i(x),F_=n(x,"LI",{});var A9e=s(F_);lce=n(A9e,"STRONG",{});var Cmt=s(lce);STo=r(Cmt,"gpt_neox"),Cmt.forEach(t),RTo=r(A9e," \u2014 "),mj=n(A9e,"A",{href:!0});var wmt=s(mj);PTo=r(wmt,"GPTNeoXModel"),wmt.forEach(t),BTo=r(A9e," (GPT NeoX model)"),A9e.forEach(t),NTo=i(x),T_=n(x,"LI",{});var L9e=s(T_);ice=n(L9e,"STRONG",{});var Amt=s(ice);ITo=r(Amt,"gptj"),Amt.forEach(t),qTo=r(L9e," \u2014 "),gj=n(L9e,"A",{href:!0});var Lmt=s(gj);jTo=r(Lmt,"GPTJModel"),Lmt.forEach(t),DTo=r(L9e," (GPT-J model)"),L9e.forEach(t),GTo=i(x),M_=n(x,"LI",{});var y9e=s(M_);dce=n(y9e,"STRONG",{});var ymt=s(dce);OTo=r(ymt,"groupvit"),ymt.forEach(t),VTo=r(y9e," \u2014 "),hj=n(y9e,"A",{href:!0});var xmt=s(hj);XTo=r(xmt,"GroupViTModel"),xmt.forEach(t),zTo=r(y9e," (GroupViT model)"),y9e.forEach(t),QTo=i(x),E_=n(x,"LI",{});var x9e=s(E_);cce=n(x9e,"STRONG",{});var $mt=s(cce);WTo=r($mt,"hubert"),$mt.forEach(t),HTo=r(x9e," \u2014 "),pj=n(x9e,"A",{href:!0});var kmt=s(pj);UTo=r(kmt,"HubertModel"),kmt.forEach(t),JTo=r(x9e," (Hubert model)"),x9e.forEach(t),YTo=i(x),C_=n(x,"LI",{});var $9e=s(C_);fce=n($9e,"STRONG",{});var Smt=s(fce);KTo=r(Smt,"ibert"),Smt.forEach(t),ZTo=r($9e," \u2014 "),_j=n($9e,"A",{href:!0});var Rmt=s(_j);eMo=r(Rmt,"IBertModel"),Rmt.forEach(t),oMo=r($9e," (I-BERT model)"),$9e.forEach(t),rMo=i(x),w_=n(x,"LI",{});var k9e=s(w_);mce=n(k9e,"STRONG",{});var Pmt=s(mce);tMo=r(Pmt,"imagegpt"),Pmt.forEach(t),aMo=r(k9e," \u2014 "),uj=n(k9e,"A",{href:!0});var Bmt=s(uj);nMo=r(Bmt,"ImageGPTModel"),Bmt.forEach(t),sMo=r(k9e," (ImageGPT model)"),k9e.forEach(t),lMo=i(x),A_=n(x,"LI",{});var S9e=s(A_);gce=n(S9e,"STRONG",{});var Nmt=s(gce);iMo=r(Nmt,"layoutlm"),Nmt.forEach(t),dMo=r(S9e," \u2014 "),bj=n(S9e,"A",{href:!0});var Imt=s(bj);cMo=r(Imt,"LayoutLMModel"),Imt.forEach(t),fMo=r(S9e," (LayoutLM model)"),S9e.forEach(t),mMo=i(x),L_=n(x,"LI",{});var R9e=s(L_);hce=n(R9e,"STRONG",{});var qmt=s(hce);gMo=r(qmt,"layoutlmv2"),qmt.forEach(t),hMo=r(R9e," \u2014 "),vj=n(R9e,"A",{href:!0});var jmt=s(vj);pMo=r(jmt,"LayoutLMv2Model"),jmt.forEach(t),_Mo=r(R9e," (LayoutLMv2 model)"),R9e.forEach(t),uMo=i(x),y_=n(x,"LI",{});var P9e=s(y_);pce=n(P9e,"STRONG",{});var Dmt=s(pce);bMo=r(Dmt,"layoutlmv3"),Dmt.forEach(t),vMo=r(P9e," \u2014 "),Fj=n(P9e,"A",{href:!0});var Gmt=s(Fj);FMo=r(Gmt,"LayoutLMv3Model"),Gmt.forEach(t),TMo=r(P9e," (LayoutLMv3 model)"),P9e.forEach(t),MMo=i(x),x_=n(x,"LI",{});var B9e=s(x_);_ce=n(B9e,"STRONG",{});var Omt=s(_ce);EMo=r(Omt,"led"),Omt.forEach(t),CMo=r(B9e," \u2014 "),Tj=n(B9e,"A",{href:!0});var Vmt=s(Tj);wMo=r(Vmt,"LEDModel"),Vmt.forEach(t),AMo=r(B9e," (LED model)"),B9e.forEach(t),LMo=i(x),$_=n(x,"LI",{});var N9e=s($_);uce=n(N9e,"STRONG",{});var Xmt=s(uce);yMo=r(Xmt,"levit"),Xmt.forEach(t),xMo=r(N9e," \u2014 "),Mj=n(N9e,"A",{href:!0});var zmt=s(Mj);$Mo=r(zmt,"LevitModel"),zmt.forEach(t),kMo=r(N9e," (LeViT model)"),N9e.forEach(t),SMo=i(x),k_=n(x,"LI",{});var I9e=s(k_);bce=n(I9e,"STRONG",{});var Qmt=s(bce);RMo=r(Qmt,"longformer"),Qmt.forEach(t),PMo=r(I9e," \u2014 "),Ej=n(I9e,"A",{href:!0});var Wmt=s(Ej);BMo=r(Wmt,"LongformerModel"),Wmt.forEach(t),NMo=r(I9e," (Longformer model)"),I9e.forEach(t),IMo=i(x),S_=n(x,"LI",{});var q9e=s(S_);vce=n(q9e,"STRONG",{});var Hmt=s(vce);qMo=r(Hmt,"longt5"),Hmt.forEach(t),jMo=r(q9e," \u2014 "),Cj=n(q9e,"A",{href:!0});var Umt=s(Cj);DMo=r(Umt,"LongT5Model"),Umt.forEach(t),GMo=r(q9e," (LongT5 model)"),q9e.forEach(t),OMo=i(x),R_=n(x,"LI",{});var j9e=s(R_);Fce=n(j9e,"STRONG",{});var Jmt=s(Fce);VMo=r(Jmt,"luke"),Jmt.forEach(t),XMo=r(j9e," \u2014 "),wj=n(j9e,"A",{href:!0});var Ymt=s(wj);zMo=r(Ymt,"LukeModel"),Ymt.forEach(t),QMo=r(j9e," (LUKE model)"),j9e.forEach(t),WMo=i(x),P_=n(x,"LI",{});var D9e=s(P_);Tce=n(D9e,"STRONG",{});var Kmt=s(Tce);HMo=r(Kmt,"lxmert"),Kmt.forEach(t),UMo=r(D9e," \u2014 "),Aj=n(D9e,"A",{href:!0});var Zmt=s(Aj);JMo=r(Zmt,"LxmertModel"),Zmt.forEach(t),YMo=r(D9e," (LXMERT model)"),D9e.forEach(t),KMo=i(x),B_=n(x,"LI",{});var G9e=s(B_);Mce=n(G9e,"STRONG",{});var egt=s(Mce);ZMo=r(egt,"m2m_100"),egt.forEach(t),eEo=r(G9e," \u2014 "),Lj=n(G9e,"A",{href:!0});var ogt=s(Lj);oEo=r(ogt,"M2M100Model"),ogt.forEach(t),rEo=r(G9e," (M2M100 model)"),G9e.forEach(t),tEo=i(x),N_=n(x,"LI",{});var O9e=s(N_);Ece=n(O9e,"STRONG",{});var rgt=s(Ece);aEo=r(rgt,"marian"),rgt.forEach(t),nEo=r(O9e," \u2014 "),yj=n(O9e,"A",{href:!0});var tgt=s(yj);sEo=r(tgt,"MarianModel"),tgt.forEach(t),lEo=r(O9e," (Marian model)"),O9e.forEach(t),iEo=i(x),I_=n(x,"LI",{});var V9e=s(I_);Cce=n(V9e,"STRONG",{});var agt=s(Cce);dEo=r(agt,"maskformer"),agt.forEach(t),cEo=r(V9e," \u2014 "),xj=n(V9e,"A",{href:!0});var ngt=s(xj);fEo=r(ngt,"MaskFormerModel"),ngt.forEach(t),mEo=r(V9e," (MaskFormer model)"),V9e.forEach(t),gEo=i(x),q_=n(x,"LI",{});var X9e=s(q_);wce=n(X9e,"STRONG",{});var sgt=s(wce);hEo=r(sgt,"mbart"),sgt.forEach(t),pEo=r(X9e," \u2014 "),$j=n(X9e,"A",{href:!0});var lgt=s($j);_Eo=r(lgt,"MBartModel"),lgt.forEach(t),uEo=r(X9e," (mBART model)"),X9e.forEach(t),bEo=i(x),j_=n(x,"LI",{});var z9e=s(j_);Ace=n(z9e,"STRONG",{});var igt=s(Ace);vEo=r(igt,"mctct"),igt.forEach(t),FEo=r(z9e," \u2014 "),kj=n(z9e,"A",{href:!0});var dgt=s(kj);TEo=r(dgt,"MCTCTModel"),dgt.forEach(t),MEo=r(z9e," (M-CTC-T model)"),z9e.forEach(t),EEo=i(x),D_=n(x,"LI",{});var Q9e=s(D_);Lce=n(Q9e,"STRONG",{});var cgt=s(Lce);CEo=r(cgt,"megatron-bert"),cgt.forEach(t),wEo=r(Q9e," \u2014 "),Sj=n(Q9e,"A",{href:!0});var fgt=s(Sj);AEo=r(fgt,"MegatronBertModel"),fgt.forEach(t),LEo=r(Q9e," (Megatron-BERT model)"),Q9e.forEach(t),yEo=i(x),G_=n(x,"LI",{});var W9e=s(G_);yce=n(W9e,"STRONG",{});var mgt=s(yce);xEo=r(mgt,"mobilebert"),mgt.forEach(t),$Eo=r(W9e," \u2014 "),Rj=n(W9e,"A",{href:!0});var ggt=s(Rj);kEo=r(ggt,"MobileBertModel"),ggt.forEach(t),SEo=r(W9e," (MobileBERT model)"),W9e.forEach(t),REo=i(x),O_=n(x,"LI",{});var H9e=s(O_);xce=n(H9e,"STRONG",{});var hgt=s(xce);PEo=r(hgt,"mpnet"),hgt.forEach(t),BEo=r(H9e," \u2014 "),Pj=n(H9e,"A",{href:!0});var pgt=s(Pj);NEo=r(pgt,"MPNetModel"),pgt.forEach(t),IEo=r(H9e," (MPNet model)"),H9e.forEach(t),qEo=i(x),V_=n(x,"LI",{});var U9e=s(V_);$ce=n(U9e,"STRONG",{});var _gt=s($ce);jEo=r(_gt,"mt5"),_gt.forEach(t),DEo=r(U9e," \u2014 "),Bj=n(U9e,"A",{href:!0});var ugt=s(Bj);GEo=r(ugt,"MT5Model"),ugt.forEach(t),OEo=r(U9e," (MT5 model)"),U9e.forEach(t),VEo=i(x),X_=n(x,"LI",{});var J9e=s(X_);kce=n(J9e,"STRONG",{});var bgt=s(kce);XEo=r(bgt,"nezha"),bgt.forEach(t),zEo=r(J9e," \u2014 "),Nj=n(J9e,"A",{href:!0});var vgt=s(Nj);QEo=r(vgt,"NezhaModel"),vgt.forEach(t),WEo=r(J9e," (Nezha model)"),J9e.forEach(t),HEo=i(x),z_=n(x,"LI",{});var Y9e=s(z_);Sce=n(Y9e,"STRONG",{});var Fgt=s(Sce);UEo=r(Fgt,"nystromformer"),Fgt.forEach(t),JEo=r(Y9e," \u2014 "),Ij=n(Y9e,"A",{href:!0});var Tgt=s(Ij);YEo=r(Tgt,"NystromformerModel"),Tgt.forEach(t),KEo=r(Y9e," (Nystr\xF6mformer model)"),Y9e.forEach(t),ZEo=i(x),Q_=n(x,"LI",{});var K9e=s(Q_);Rce=n(K9e,"STRONG",{});var Mgt=s(Rce);eCo=r(Mgt,"openai-gpt"),Mgt.forEach(t),oCo=r(K9e," \u2014 "),qj=n(K9e,"A",{href:!0});var Egt=s(qj);rCo=r(Egt,"OpenAIGPTModel"),Egt.forEach(t),tCo=r(K9e," (OpenAI GPT model)"),K9e.forEach(t),aCo=i(x),W_=n(x,"LI",{});var Z9e=s(W_);Pce=n(Z9e,"STRONG",{});var Cgt=s(Pce);nCo=r(Cgt,"opt"),Cgt.forEach(t),sCo=r(Z9e," \u2014 "),jj=n(Z9e,"A",{href:!0});var wgt=s(jj);lCo=r(wgt,"OPTModel"),wgt.forEach(t),iCo=r(Z9e," (OPT model)"),Z9e.forEach(t),dCo=i(x),H_=n(x,"LI",{});var exe=s(H_);Bce=n(exe,"STRONG",{});var Agt=s(Bce);cCo=r(Agt,"pegasus"),Agt.forEach(t),fCo=r(exe," \u2014 "),Dj=n(exe,"A",{href:!0});var Lgt=s(Dj);mCo=r(Lgt,"PegasusModel"),Lgt.forEach(t),gCo=r(exe," (Pegasus model)"),exe.forEach(t),hCo=i(x),U_=n(x,"LI",{});var oxe=s(U_);Nce=n(oxe,"STRONG",{});var ygt=s(Nce);pCo=r(ygt,"perceiver"),ygt.forEach(t),_Co=r(oxe," \u2014 "),Gj=n(oxe,"A",{href:!0});var xgt=s(Gj);uCo=r(xgt,"PerceiverModel"),xgt.forEach(t),bCo=r(oxe," (Perceiver model)"),oxe.forEach(t),vCo=i(x),J_=n(x,"LI",{});var rxe=s(J_);Ice=n(rxe,"STRONG",{});var $gt=s(Ice);FCo=r($gt,"plbart"),$gt.forEach(t),TCo=r(rxe," \u2014 "),Oj=n(rxe,"A",{href:!0});var kgt=s(Oj);MCo=r(kgt,"PLBartModel"),kgt.forEach(t),ECo=r(rxe," (PLBart model)"),rxe.forEach(t),CCo=i(x),Y_=n(x,"LI",{});var txe=s(Y_);qce=n(txe,"STRONG",{});var Sgt=s(qce);wCo=r(Sgt,"poolformer"),Sgt.forEach(t),ACo=r(txe," \u2014 "),Vj=n(txe,"A",{href:!0});var Rgt=s(Vj);LCo=r(Rgt,"PoolFormerModel"),Rgt.forEach(t),yCo=r(txe," (PoolFormer model)"),txe.forEach(t),xCo=i(x),K_=n(x,"LI",{});var axe=s(K_);jce=n(axe,"STRONG",{});var Pgt=s(jce);$Co=r(Pgt,"prophetnet"),Pgt.forEach(t),kCo=r(axe," \u2014 "),Xj=n(axe,"A",{href:!0});var Bgt=s(Xj);SCo=r(Bgt,"ProphetNetModel"),Bgt.forEach(t),RCo=r(axe," (ProphetNet model)"),axe.forEach(t),PCo=i(x),Z_=n(x,"LI",{});var nxe=s(Z_);Dce=n(nxe,"STRONG",{});var Ngt=s(Dce);BCo=r(Ngt,"qdqbert"),Ngt.forEach(t),NCo=r(nxe," \u2014 "),zj=n(nxe,"A",{href:!0});var Igt=s(zj);ICo=r(Igt,"QDQBertModel"),Igt.forEach(t),qCo=r(nxe," (QDQBert model)"),nxe.forEach(t),jCo=i(x),eu=n(x,"LI",{});var sxe=s(eu);Gce=n(sxe,"STRONG",{});var qgt=s(Gce);DCo=r(qgt,"reformer"),qgt.forEach(t),GCo=r(sxe," \u2014 "),Qj=n(sxe,"A",{href:!0});var jgt=s(Qj);OCo=r(jgt,"ReformerModel"),jgt.forEach(t),VCo=r(sxe," (Reformer model)"),sxe.forEach(t),XCo=i(x),ou=n(x,"LI",{});var lxe=s(ou);Oce=n(lxe,"STRONG",{});var Dgt=s(Oce);zCo=r(Dgt,"regnet"),Dgt.forEach(t),QCo=r(lxe," \u2014 "),Wj=n(lxe,"A",{href:!0});var Ggt=s(Wj);WCo=r(Ggt,"RegNetModel"),Ggt.forEach(t),HCo=r(lxe," (RegNet model)"),lxe.forEach(t),UCo=i(x),ru=n(x,"LI",{});var ixe=s(ru);Vce=n(ixe,"STRONG",{});var Ogt=s(Vce);JCo=r(Ogt,"rembert"),Ogt.forEach(t),YCo=r(ixe," \u2014 "),Hj=n(ixe,"A",{href:!0});var Vgt=s(Hj);KCo=r(Vgt,"RemBertModel"),Vgt.forEach(t),ZCo=r(ixe," (RemBERT model)"),ixe.forEach(t),e3o=i(x),tu=n(x,"LI",{});var dxe=s(tu);Xce=n(dxe,"STRONG",{});var Xgt=s(Xce);o3o=r(Xgt,"resnet"),Xgt.forEach(t),r3o=r(dxe," \u2014 "),Uj=n(dxe,"A",{href:!0});var zgt=s(Uj);t3o=r(zgt,"ResNetModel"),zgt.forEach(t),a3o=r(dxe," (ResNet model)"),dxe.forEach(t),n3o=i(x),au=n(x,"LI",{});var cxe=s(au);zce=n(cxe,"STRONG",{});var Qgt=s(zce);s3o=r(Qgt,"retribert"),Qgt.forEach(t),l3o=r(cxe," \u2014 "),Jj=n(cxe,"A",{href:!0});var Wgt=s(Jj);i3o=r(Wgt,"RetriBertModel"),Wgt.forEach(t),d3o=r(cxe," (RetriBERT model)"),cxe.forEach(t),c3o=i(x),nu=n(x,"LI",{});var fxe=s(nu);Qce=n(fxe,"STRONG",{});var Hgt=s(Qce);f3o=r(Hgt,"roberta"),Hgt.forEach(t),m3o=r(fxe," \u2014 "),Yj=n(fxe,"A",{href:!0});var Ugt=s(Yj);g3o=r(Ugt,"RobertaModel"),Ugt.forEach(t),h3o=r(fxe," (RoBERTa model)"),fxe.forEach(t),p3o=i(x),su=n(x,"LI",{});var mxe=s(su);Wce=n(mxe,"STRONG",{});var Jgt=s(Wce);_3o=r(Jgt,"roformer"),Jgt.forEach(t),u3o=r(mxe," \u2014 "),Kj=n(mxe,"A",{href:!0});var Ygt=s(Kj);b3o=r(Ygt,"RoFormerModel"),Ygt.forEach(t),v3o=r(mxe," (RoFormer model)"),mxe.forEach(t),F3o=i(x),lu=n(x,"LI",{});var gxe=s(lu);Hce=n(gxe,"STRONG",{});var Kgt=s(Hce);T3o=r(Kgt,"segformer"),Kgt.forEach(t),M3o=r(gxe," \u2014 "),Zj=n(gxe,"A",{href:!0});var Zgt=s(Zj);E3o=r(Zgt,"SegformerModel"),Zgt.forEach(t),C3o=r(gxe," (SegFormer model)"),gxe.forEach(t),w3o=i(x),iu=n(x,"LI",{});var hxe=s(iu);Uce=n(hxe,"STRONG",{});var eht=s(Uce);A3o=r(eht,"sew"),eht.forEach(t),L3o=r(hxe," \u2014 "),eD=n(hxe,"A",{href:!0});var oht=s(eD);y3o=r(oht,"SEWModel"),oht.forEach(t),x3o=r(hxe," (SEW model)"),hxe.forEach(t),$3o=i(x),du=n(x,"LI",{});var pxe=s(du);Jce=n(pxe,"STRONG",{});var rht=s(Jce);k3o=r(rht,"sew-d"),rht.forEach(t),S3o=r(pxe," \u2014 "),oD=n(pxe,"A",{href:!0});var tht=s(oD);R3o=r(tht,"SEWDModel"),tht.forEach(t),P3o=r(pxe," (SEW-D model)"),pxe.forEach(t),B3o=i(x),cu=n(x,"LI",{});var _xe=s(cu);Yce=n(_xe,"STRONG",{});var aht=s(Yce);N3o=r(aht,"speech_to_text"),aht.forEach(t),I3o=r(_xe," \u2014 "),rD=n(_xe,"A",{href:!0});var nht=s(rD);q3o=r(nht,"Speech2TextModel"),nht.forEach(t),j3o=r(_xe," (Speech2Text model)"),_xe.forEach(t),D3o=i(x),fu=n(x,"LI",{});var uxe=s(fu);Kce=n(uxe,"STRONG",{});var sht=s(Kce);G3o=r(sht,"splinter"),sht.forEach(t),O3o=r(uxe," \u2014 "),tD=n(uxe,"A",{href:!0});var lht=s(tD);V3o=r(lht,"SplinterModel"),lht.forEach(t),X3o=r(uxe," (Splinter model)"),uxe.forEach(t),z3o=i(x),mu=n(x,"LI",{});var bxe=s(mu);Zce=n(bxe,"STRONG",{});var iht=s(Zce);Q3o=r(iht,"squeezebert"),iht.forEach(t),W3o=r(bxe," \u2014 "),aD=n(bxe,"A",{href:!0});var dht=s(aD);H3o=r(dht,"SqueezeBertModel"),dht.forEach(t),U3o=r(bxe," (SqueezeBERT model)"),bxe.forEach(t),J3o=i(x),gu=n(x,"LI",{});var vxe=s(gu);efe=n(vxe,"STRONG",{});var cht=s(efe);Y3o=r(cht,"swin"),cht.forEach(t),K3o=r(vxe," \u2014 "),nD=n(vxe,"A",{href:!0});var fht=s(nD);Z3o=r(fht,"SwinModel"),fht.forEach(t),e5o=r(vxe," (Swin Transformer model)"),vxe.forEach(t),o5o=i(x),hu=n(x,"LI",{});var Fxe=s(hu);ofe=n(Fxe,"STRONG",{});var mht=s(ofe);r5o=r(mht,"t5"),mht.forEach(t),t5o=r(Fxe," \u2014 "),sD=n(Fxe,"A",{href:!0});var ght=s(sD);a5o=r(ght,"T5Model"),ght.forEach(t),n5o=r(Fxe," (T5 model)"),Fxe.forEach(t),s5o=i(x),pu=n(x,"LI",{});var Txe=s(pu);rfe=n(Txe,"STRONG",{});var hht=s(rfe);l5o=r(hht,"tapas"),hht.forEach(t),i5o=r(Txe," \u2014 "),lD=n(Txe,"A",{href:!0});var pht=s(lD);d5o=r(pht,"TapasModel"),pht.forEach(t),c5o=r(Txe," (TAPAS model)"),Txe.forEach(t),f5o=i(x),_u=n(x,"LI",{});var Mxe=s(_u);tfe=n(Mxe,"STRONG",{});var _ht=s(tfe);m5o=r(_ht,"trajectory_transformer"),_ht.forEach(t),g5o=r(Mxe," \u2014 "),iD=n(Mxe,"A",{href:!0});var uht=s(iD);h5o=r(uht,"TrajectoryTransformerModel"),uht.forEach(t),p5o=r(Mxe," (Trajectory Transformer model)"),Mxe.forEach(t),_5o=i(x),uu=n(x,"LI",{});var Exe=s(uu);afe=n(Exe,"STRONG",{});var bht=s(afe);u5o=r(bht,"transfo-xl"),bht.forEach(t),b5o=r(Exe," \u2014 "),dD=n(Exe,"A",{href:!0});var vht=s(dD);v5o=r(vht,"TransfoXLModel"),vht.forEach(t),F5o=r(Exe," (Transformer-XL model)"),Exe.forEach(t),T5o=i(x),bu=n(x,"LI",{});var Cxe=s(bu);nfe=n(Cxe,"STRONG",{});var Fht=s(nfe);M5o=r(Fht,"unispeech"),Fht.forEach(t),E5o=r(Cxe," \u2014 "),cD=n(Cxe,"A",{href:!0});var Tht=s(cD);C5o=r(Tht,"UniSpeechModel"),Tht.forEach(t),w5o=r(Cxe," (UniSpeech model)"),Cxe.forEach(t),A5o=i(x),vu=n(x,"LI",{});var wxe=s(vu);sfe=n(wxe,"STRONG",{});var Mht=s(sfe);L5o=r(Mht,"unispeech-sat"),Mht.forEach(t),y5o=r(wxe," \u2014 "),fD=n(wxe,"A",{href:!0});var Eht=s(fD);x5o=r(Eht,"UniSpeechSatModel"),Eht.forEach(t),$5o=r(wxe," (UniSpeechSat model)"),wxe.forEach(t),k5o=i(x),Fu=n(x,"LI",{});var Axe=s(Fu);lfe=n(Axe,"STRONG",{});var Cht=s(lfe);S5o=r(Cht,"van"),Cht.forEach(t),R5o=r(Axe," \u2014 "),mD=n(Axe,"A",{href:!0});var wht=s(mD);P5o=r(wht,"VanModel"),wht.forEach(t),B5o=r(Axe," (VAN model)"),Axe.forEach(t),N5o=i(x),Tu=n(x,"LI",{});var Lxe=s(Tu);ife=n(Lxe,"STRONG",{});var Aht=s(ife);I5o=r(Aht,"vilt"),Aht.forEach(t),q5o=r(Lxe," \u2014 "),gD=n(Lxe,"A",{href:!0});var Lht=s(gD);j5o=r(Lht,"ViltModel"),Lht.forEach(t),D5o=r(Lxe," (ViLT model)"),Lxe.forEach(t),G5o=i(x),Mu=n(x,"LI",{});var yxe=s(Mu);dfe=n(yxe,"STRONG",{});var yht=s(dfe);O5o=r(yht,"vision-text-dual-encoder"),yht.forEach(t),V5o=r(yxe," \u2014 "),hD=n(yxe,"A",{href:!0});var xht=s(hD);X5o=r(xht,"VisionTextDualEncoderModel"),xht.forEach(t),z5o=r(yxe," (VisionTextDualEncoder model)"),yxe.forEach(t),Q5o=i(x),Eu=n(x,"LI",{});var xxe=s(Eu);cfe=n(xxe,"STRONG",{});var $ht=s(cfe);W5o=r($ht,"visual_bert"),$ht.forEach(t),H5o=r(xxe," \u2014 "),pD=n(xxe,"A",{href:!0});var kht=s(pD);U5o=r(kht,"VisualBertModel"),kht.forEach(t),J5o=r(xxe," (VisualBERT model)"),xxe.forEach(t),Y5o=i(x),Cu=n(x,"LI",{});var $xe=s(Cu);ffe=n($xe,"STRONG",{});var Sht=s(ffe);K5o=r(Sht,"vit"),Sht.forEach(t),Z5o=r($xe," \u2014 "),_D=n($xe,"A",{href:!0});var Rht=s(_D);e0o=r(Rht,"ViTModel"),Rht.forEach(t),o0o=r($xe," (ViT model)"),$xe.forEach(t),r0o=i(x),wu=n(x,"LI",{});var kxe=s(wu);mfe=n(kxe,"STRONG",{});var Pht=s(mfe);t0o=r(Pht,"vit_mae"),Pht.forEach(t),a0o=r(kxe," \u2014 "),uD=n(kxe,"A",{href:!0});var Bht=s(uD);n0o=r(Bht,"ViTMAEModel"),Bht.forEach(t),s0o=r(kxe," (ViTMAE model)"),kxe.forEach(t),l0o=i(x),Au=n(x,"LI",{});var Sxe=s(Au);gfe=n(Sxe,"STRONG",{});var Nht=s(gfe);i0o=r(Nht,"wav2vec2"),Nht.forEach(t),d0o=r(Sxe," \u2014 "),bD=n(Sxe,"A",{href:!0});var Iht=s(bD);c0o=r(Iht,"Wav2Vec2Model"),Iht.forEach(t),f0o=r(Sxe," (Wav2Vec2 model)"),Sxe.forEach(t),m0o=i(x),Lu=n(x,"LI",{});var Rxe=s(Lu);hfe=n(Rxe,"STRONG",{});var qht=s(hfe);g0o=r(qht,"wav2vec2-conformer"),qht.forEach(t),h0o=r(Rxe," \u2014 "),vD=n(Rxe,"A",{href:!0});var jht=s(vD);p0o=r(jht,"Wav2Vec2ConformerModel"),jht.forEach(t),_0o=r(Rxe," (Wav2Vec2-Conformer model)"),Rxe.forEach(t),u0o=i(x),yu=n(x,"LI",{});var Pxe=s(yu);pfe=n(Pxe,"STRONG",{});var Dht=s(pfe);b0o=r(Dht,"wavlm"),Dht.forEach(t),v0o=r(Pxe," \u2014 "),FD=n(Pxe,"A",{href:!0});var Ght=s(FD);F0o=r(Ght,"WavLMModel"),Ght.forEach(t),T0o=r(Pxe," (WavLM model)"),Pxe.forEach(t),M0o=i(x),xu=n(x,"LI",{});var Bxe=s(xu);_fe=n(Bxe,"STRONG",{});var Oht=s(_fe);E0o=r(Oht,"xglm"),Oht.forEach(t),C0o=r(Bxe," \u2014 "),TD=n(Bxe,"A",{href:!0});var Vht=s(TD);w0o=r(Vht,"XGLMModel"),Vht.forEach(t),A0o=r(Bxe," (XGLM model)"),Bxe.forEach(t),L0o=i(x),$u=n(x,"LI",{});var Nxe=s($u);ufe=n(Nxe,"STRONG",{});var Xht=s(ufe);y0o=r(Xht,"xlm"),Xht.forEach(t),x0o=r(Nxe," \u2014 "),MD=n(Nxe,"A",{href:!0});var zht=s(MD);$0o=r(zht,"XLMModel"),zht.forEach(t),k0o=r(Nxe," (XLM model)"),Nxe.forEach(t),S0o=i(x),ku=n(x,"LI",{});var Ixe=s(ku);bfe=n(Ixe,"STRONG",{});var Qht=s(bfe);R0o=r(Qht,"xlm-prophetnet"),Qht.forEach(t),P0o=r(Ixe," \u2014 "),ED=n(Ixe,"A",{href:!0});var Wht=s(ED);B0o=r(Wht,"XLMProphetNetModel"),Wht.forEach(t),N0o=r(Ixe," (XLM-ProphetNet model)"),Ixe.forEach(t),I0o=i(x),Su=n(x,"LI",{});var qxe=s(Su);vfe=n(qxe,"STRONG",{});var Hht=s(vfe);q0o=r(Hht,"xlm-roberta"),Hht.forEach(t),j0o=r(qxe," \u2014 "),CD=n(qxe,"A",{href:!0});var Uht=s(CD);D0o=r(Uht,"XLMRobertaModel"),Uht.forEach(t),G0o=r(qxe," (XLM-RoBERTa model)"),qxe.forEach(t),O0o=i(x),Ru=n(x,"LI",{});var jxe=s(Ru);Ffe=n(jxe,"STRONG",{});var Jht=s(Ffe);V0o=r(Jht,"xlm-roberta-xl"),Jht.forEach(t),X0o=r(jxe," \u2014 "),wD=n(jxe,"A",{href:!0});var Yht=s(wD);z0o=r(Yht,"XLMRobertaXLModel"),Yht.forEach(t),Q0o=r(jxe," (XLM-RoBERTa-XL model)"),jxe.forEach(t),W0o=i(x),Pu=n(x,"LI",{});var Dxe=s(Pu);Tfe=n(Dxe,"STRONG",{});var Kht=s(Tfe);H0o=r(Kht,"xlnet"),Kht.forEach(t),U0o=r(Dxe," \u2014 "),AD=n(Dxe,"A",{href:!0});var Zht=s(AD);J0o=r(Zht,"XLNetModel"),Zht.forEach(t),Y0o=r(Dxe," (XLNet model)"),Dxe.forEach(t),K0o=i(x),Bu=n(x,"LI",{});var Gxe=s(Bu);Mfe=n(Gxe,"STRONG",{});var ept=s(Mfe);Z0o=r(ept,"yolos"),ept.forEach(t),ewo=r(Gxe," \u2014 "),LD=n(Gxe,"A",{href:!0});var opt=s(LD);owo=r(opt,"YolosModel"),opt.forEach(t),rwo=r(Gxe," (YOLOS model)"),Gxe.forEach(t),two=i(x),Nu=n(x,"LI",{});var Oxe=s(Nu);Efe=n(Oxe,"STRONG",{});var rpt=s(Efe);awo=r(rpt,"yoso"),rpt.forEach(t),nwo=r(Oxe," \u2014 "),yD=n(Oxe,"A",{href:!0});var tpt=s(yD);swo=r(tpt,"YosoModel"),tpt.forEach(t),lwo=r(Oxe," (YOSO model)"),Oxe.forEach(t),x.forEach(t),iwo=i(na),Iu=n(na,"P",{});var Vxe=s(Iu);dwo=r(Vxe,"The model is set in evaluation mode by default using "),Cfe=n(Vxe,"CODE",{});var apt=s(Cfe);cwo=r(apt,"model.eval()"),apt.forEach(t),fwo=r(Vxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wfe=n(Vxe,"CODE",{});var npt=s(wfe);mwo=r(npt,"model.train()"),npt.forEach(t),Vxe.forEach(t),gwo=i(na),T(qu.$$.fragment,na),na.forEach(t),el.forEach(t),eVe=i(f),Gi=n(f,"H2",{class:!0});var sze=s(Gi);ju=n(sze,"A",{id:!0,class:!0,href:!0});var spt=s(ju);Afe=n(spt,"SPAN",{});var lpt=s(Afe);T(vy.$$.fragment,lpt),lpt.forEach(t),spt.forEach(t),hwo=i(sze),Lfe=n(sze,"SPAN",{});var ipt=s(Lfe);pwo=r(ipt,"AutoModelForPreTraining"),ipt.forEach(t),sze.forEach(t),oVe=i(f),$o=n(f,"DIV",{class:!0});var ol=s($o);T(Fy.$$.fragment,ol),_wo=i(ol),Oi=n(ol,"P",{});var Yoe=s(Oi);uwo=r(Yoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),xD=n(Yoe,"A",{href:!0});var dpt=s(xD);bwo=r(dpt,"from_pretrained()"),dpt.forEach(t),vwo=r(Yoe," class method or the "),$D=n(Yoe,"A",{href:!0});var cpt=s($D);Fwo=r(cpt,"from_config()"),cpt.forEach(t),Two=r(Yoe,` class
method.`),Yoe.forEach(t),Mwo=i(ol),Ty=n(ol,"P",{});var lze=s(Ty);Ewo=r(lze,"This class cannot be instantiated directly using "),yfe=n(lze,"CODE",{});var fpt=s(yfe);Cwo=r(fpt,"__init__()"),fpt.forEach(t),wwo=r(lze," (throws an error)."),lze.forEach(t),Awo=i(ol),lt=n(ol,"DIV",{class:!0});var WA=s(lt);T(My.$$.fragment,WA),Lwo=i(WA),xfe=n(WA,"P",{});var mpt=s(xfe);ywo=r(mpt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),mpt.forEach(t),xwo=i(WA),Vi=n(WA,"P",{});var Koe=s(Vi);$wo=r(Koe,`Note:
Loading a model from its configuration file does `),$fe=n(Koe,"STRONG",{});var gpt=s($fe);kwo=r(gpt,"not"),gpt.forEach(t),Swo=r(Koe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kD=n(Koe,"A",{href:!0});var hpt=s(kD);Rwo=r(hpt,"from_pretrained()"),hpt.forEach(t),Pwo=r(Koe," to load the model weights."),Koe.forEach(t),Bwo=i(WA),T(Du.$$.fragment,WA),WA.forEach(t),Nwo=i(ol),Ye=n(ol,"DIV",{class:!0});var sa=s(Ye);T(Ey.$$.fragment,sa),Iwo=i(sa),kfe=n(sa,"P",{});var ppt=s(kfe);qwo=r(ppt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ppt.forEach(t),jwo=i(sa),Na=n(sa,"P",{});var HA=s(Na);Dwo=r(HA,"The model class to instantiate is selected based on the "),Sfe=n(HA,"CODE",{});var _pt=s(Sfe);Gwo=r(_pt,"model_type"),_pt.forEach(t),Owo=r(HA,` property of the config object (either
passed as an argument or loaded from `),Rfe=n(HA,"CODE",{});var upt=s(Rfe);Vwo=r(upt,"pretrained_model_name_or_path"),upt.forEach(t),Xwo=r(HA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pfe=n(HA,"CODE",{});var bpt=s(Pfe);zwo=r(bpt,"pretrained_model_name_or_path"),bpt.forEach(t),Qwo=r(HA,":"),HA.forEach(t),Wwo=i(sa),G=n(sa,"UL",{});var O=s(G);Gu=n(O,"LI",{});var Xxe=s(Gu);Bfe=n(Xxe,"STRONG",{});var vpt=s(Bfe);Hwo=r(vpt,"albert"),vpt.forEach(t),Uwo=r(Xxe," \u2014 "),SD=n(Xxe,"A",{href:!0});var Fpt=s(SD);Jwo=r(Fpt,"AlbertForPreTraining"),Fpt.forEach(t),Ywo=r(Xxe," (ALBERT model)"),Xxe.forEach(t),Kwo=i(O),Ou=n(O,"LI",{});var zxe=s(Ou);Nfe=n(zxe,"STRONG",{});var Tpt=s(Nfe);Zwo=r(Tpt,"bart"),Tpt.forEach(t),eAo=r(zxe," \u2014 "),RD=n(zxe,"A",{href:!0});var Mpt=s(RD);oAo=r(Mpt,"BartForConditionalGeneration"),Mpt.forEach(t),rAo=r(zxe," (BART model)"),zxe.forEach(t),tAo=i(O),Vu=n(O,"LI",{});var Qxe=s(Vu);Ife=n(Qxe,"STRONG",{});var Ept=s(Ife);aAo=r(Ept,"bert"),Ept.forEach(t),nAo=r(Qxe," \u2014 "),PD=n(Qxe,"A",{href:!0});var Cpt=s(PD);sAo=r(Cpt,"BertForPreTraining"),Cpt.forEach(t),lAo=r(Qxe," (BERT model)"),Qxe.forEach(t),iAo=i(O),Xu=n(O,"LI",{});var Wxe=s(Xu);qfe=n(Wxe,"STRONG",{});var wpt=s(qfe);dAo=r(wpt,"big_bird"),wpt.forEach(t),cAo=r(Wxe," \u2014 "),BD=n(Wxe,"A",{href:!0});var Apt=s(BD);fAo=r(Apt,"BigBirdForPreTraining"),Apt.forEach(t),mAo=r(Wxe," (BigBird model)"),Wxe.forEach(t),gAo=i(O),zu=n(O,"LI",{});var Hxe=s(zu);jfe=n(Hxe,"STRONG",{});var Lpt=s(jfe);hAo=r(Lpt,"bloom"),Lpt.forEach(t),pAo=r(Hxe," \u2014 "),ND=n(Hxe,"A",{href:!0});var ypt=s(ND);_Ao=r(ypt,"BloomForCausalLM"),ypt.forEach(t),uAo=r(Hxe," (BLOOM model)"),Hxe.forEach(t),bAo=i(O),Qu=n(O,"LI",{});var Uxe=s(Qu);Dfe=n(Uxe,"STRONG",{});var xpt=s(Dfe);vAo=r(xpt,"camembert"),xpt.forEach(t),FAo=r(Uxe," \u2014 "),ID=n(Uxe,"A",{href:!0});var $pt=s(ID);TAo=r($pt,"CamembertForMaskedLM"),$pt.forEach(t),MAo=r(Uxe," (CamemBERT model)"),Uxe.forEach(t),EAo=i(O),Wu=n(O,"LI",{});var Jxe=s(Wu);Gfe=n(Jxe,"STRONG",{});var kpt=s(Gfe);CAo=r(kpt,"ctrl"),kpt.forEach(t),wAo=r(Jxe," \u2014 "),qD=n(Jxe,"A",{href:!0});var Spt=s(qD);AAo=r(Spt,"CTRLLMHeadModel"),Spt.forEach(t),LAo=r(Jxe," (CTRL model)"),Jxe.forEach(t),yAo=i(O),Hu=n(O,"LI",{});var Yxe=s(Hu);Ofe=n(Yxe,"STRONG",{});var Rpt=s(Ofe);xAo=r(Rpt,"data2vec-text"),Rpt.forEach(t),$Ao=r(Yxe," \u2014 "),jD=n(Yxe,"A",{href:!0});var Ppt=s(jD);kAo=r(Ppt,"Data2VecTextForMaskedLM"),Ppt.forEach(t),SAo=r(Yxe," (Data2VecText model)"),Yxe.forEach(t),RAo=i(O),Uu=n(O,"LI",{});var Kxe=s(Uu);Vfe=n(Kxe,"STRONG",{});var Bpt=s(Vfe);PAo=r(Bpt,"deberta"),Bpt.forEach(t),BAo=r(Kxe," \u2014 "),DD=n(Kxe,"A",{href:!0});var Npt=s(DD);NAo=r(Npt,"DebertaForMaskedLM"),Npt.forEach(t),IAo=r(Kxe," (DeBERTa model)"),Kxe.forEach(t),qAo=i(O),Ju=n(O,"LI",{});var Zxe=s(Ju);Xfe=n(Zxe,"STRONG",{});var Ipt=s(Xfe);jAo=r(Ipt,"deberta-v2"),Ipt.forEach(t),DAo=r(Zxe," \u2014 "),GD=n(Zxe,"A",{href:!0});var qpt=s(GD);GAo=r(qpt,"DebertaV2ForMaskedLM"),qpt.forEach(t),OAo=r(Zxe," (DeBERTa-v2 model)"),Zxe.forEach(t),VAo=i(O),Yu=n(O,"LI",{});var e$e=s(Yu);zfe=n(e$e,"STRONG",{});var jpt=s(zfe);XAo=r(jpt,"distilbert"),jpt.forEach(t),zAo=r(e$e," \u2014 "),OD=n(e$e,"A",{href:!0});var Dpt=s(OD);QAo=r(Dpt,"DistilBertForMaskedLM"),Dpt.forEach(t),WAo=r(e$e," (DistilBERT model)"),e$e.forEach(t),HAo=i(O),Ku=n(O,"LI",{});var o$e=s(Ku);Qfe=n(o$e,"STRONG",{});var Gpt=s(Qfe);UAo=r(Gpt,"electra"),Gpt.forEach(t),JAo=r(o$e," \u2014 "),VD=n(o$e,"A",{href:!0});var Opt=s(VD);YAo=r(Opt,"ElectraForPreTraining"),Opt.forEach(t),KAo=r(o$e," (ELECTRA model)"),o$e.forEach(t),ZAo=i(O),Zu=n(O,"LI",{});var r$e=s(Zu);Wfe=n(r$e,"STRONG",{});var Vpt=s(Wfe);e6o=r(Vpt,"flaubert"),Vpt.forEach(t),o6o=r(r$e," \u2014 "),XD=n(r$e,"A",{href:!0});var Xpt=s(XD);r6o=r(Xpt,"FlaubertWithLMHeadModel"),Xpt.forEach(t),t6o=r(r$e," (FlauBERT model)"),r$e.forEach(t),a6o=i(O),e2=n(O,"LI",{});var t$e=s(e2);Hfe=n(t$e,"STRONG",{});var zpt=s(Hfe);n6o=r(zpt,"flava"),zpt.forEach(t),s6o=r(t$e," \u2014 "),zD=n(t$e,"A",{href:!0});var Qpt=s(zD);l6o=r(Qpt,"FlavaForPreTraining"),Qpt.forEach(t),i6o=r(t$e," (FLAVA model)"),t$e.forEach(t),d6o=i(O),o2=n(O,"LI",{});var a$e=s(o2);Ufe=n(a$e,"STRONG",{});var Wpt=s(Ufe);c6o=r(Wpt,"fnet"),Wpt.forEach(t),f6o=r(a$e," \u2014 "),QD=n(a$e,"A",{href:!0});var Hpt=s(QD);m6o=r(Hpt,"FNetForPreTraining"),Hpt.forEach(t),g6o=r(a$e," (FNet model)"),a$e.forEach(t),h6o=i(O),r2=n(O,"LI",{});var n$e=s(r2);Jfe=n(n$e,"STRONG",{});var Upt=s(Jfe);p6o=r(Upt,"fsmt"),Upt.forEach(t),_6o=r(n$e," \u2014 "),WD=n(n$e,"A",{href:!0});var Jpt=s(WD);u6o=r(Jpt,"FSMTForConditionalGeneration"),Jpt.forEach(t),b6o=r(n$e," (FairSeq Machine-Translation model)"),n$e.forEach(t),v6o=i(O),t2=n(O,"LI",{});var s$e=s(t2);Yfe=n(s$e,"STRONG",{});var Ypt=s(Yfe);F6o=r(Ypt,"funnel"),Ypt.forEach(t),T6o=r(s$e," \u2014 "),HD=n(s$e,"A",{href:!0});var Kpt=s(HD);M6o=r(Kpt,"FunnelForPreTraining"),Kpt.forEach(t),E6o=r(s$e," (Funnel Transformer model)"),s$e.forEach(t),C6o=i(O),a2=n(O,"LI",{});var l$e=s(a2);Kfe=n(l$e,"STRONG",{});var Zpt=s(Kfe);w6o=r(Zpt,"gpt2"),Zpt.forEach(t),A6o=r(l$e," \u2014 "),UD=n(l$e,"A",{href:!0});var e_t=s(UD);L6o=r(e_t,"GPT2LMHeadModel"),e_t.forEach(t),y6o=r(l$e," (OpenAI GPT-2 model)"),l$e.forEach(t),x6o=i(O),n2=n(O,"LI",{});var i$e=s(n2);Zfe=n(i$e,"STRONG",{});var o_t=s(Zfe);$6o=r(o_t,"ibert"),o_t.forEach(t),k6o=r(i$e," \u2014 "),JD=n(i$e,"A",{href:!0});var r_t=s(JD);S6o=r(r_t,"IBertForMaskedLM"),r_t.forEach(t),R6o=r(i$e," (I-BERT model)"),i$e.forEach(t),P6o=i(O),s2=n(O,"LI",{});var d$e=s(s2);eme=n(d$e,"STRONG",{});var t_t=s(eme);B6o=r(t_t,"layoutlm"),t_t.forEach(t),N6o=r(d$e," \u2014 "),YD=n(d$e,"A",{href:!0});var a_t=s(YD);I6o=r(a_t,"LayoutLMForMaskedLM"),a_t.forEach(t),q6o=r(d$e," (LayoutLM model)"),d$e.forEach(t),j6o=i(O),l2=n(O,"LI",{});var c$e=s(l2);ome=n(c$e,"STRONG",{});var n_t=s(ome);D6o=r(n_t,"longformer"),n_t.forEach(t),G6o=r(c$e," \u2014 "),KD=n(c$e,"A",{href:!0});var s_t=s(KD);O6o=r(s_t,"LongformerForMaskedLM"),s_t.forEach(t),V6o=r(c$e," (Longformer model)"),c$e.forEach(t),X6o=i(O),i2=n(O,"LI",{});var f$e=s(i2);rme=n(f$e,"STRONG",{});var l_t=s(rme);z6o=r(l_t,"lxmert"),l_t.forEach(t),Q6o=r(f$e," \u2014 "),ZD=n(f$e,"A",{href:!0});var i_t=s(ZD);W6o=r(i_t,"LxmertForPreTraining"),i_t.forEach(t),H6o=r(f$e," (LXMERT model)"),f$e.forEach(t),U6o=i(O),d2=n(O,"LI",{});var m$e=s(d2);tme=n(m$e,"STRONG",{});var d_t=s(tme);J6o=r(d_t,"megatron-bert"),d_t.forEach(t),Y6o=r(m$e," \u2014 "),eG=n(m$e,"A",{href:!0});var c_t=s(eG);K6o=r(c_t,"MegatronBertForPreTraining"),c_t.forEach(t),Z6o=r(m$e," (Megatron-BERT model)"),m$e.forEach(t),eLo=i(O),c2=n(O,"LI",{});var g$e=s(c2);ame=n(g$e,"STRONG",{});var f_t=s(ame);oLo=r(f_t,"mobilebert"),f_t.forEach(t),rLo=r(g$e," \u2014 "),oG=n(g$e,"A",{href:!0});var m_t=s(oG);tLo=r(m_t,"MobileBertForPreTraining"),m_t.forEach(t),aLo=r(g$e," (MobileBERT model)"),g$e.forEach(t),nLo=i(O),f2=n(O,"LI",{});var h$e=s(f2);nme=n(h$e,"STRONG",{});var g_t=s(nme);sLo=r(g_t,"mpnet"),g_t.forEach(t),lLo=r(h$e," \u2014 "),rG=n(h$e,"A",{href:!0});var h_t=s(rG);iLo=r(h_t,"MPNetForMaskedLM"),h_t.forEach(t),dLo=r(h$e," (MPNet model)"),h$e.forEach(t),cLo=i(O),m2=n(O,"LI",{});var p$e=s(m2);sme=n(p$e,"STRONG",{});var p_t=s(sme);fLo=r(p_t,"nezha"),p_t.forEach(t),mLo=r(p$e," \u2014 "),tG=n(p$e,"A",{href:!0});var __t=s(tG);gLo=r(__t,"NezhaForPreTraining"),__t.forEach(t),hLo=r(p$e," (Nezha model)"),p$e.forEach(t),pLo=i(O),g2=n(O,"LI",{});var _$e=s(g2);lme=n(_$e,"STRONG",{});var u_t=s(lme);_Lo=r(u_t,"openai-gpt"),u_t.forEach(t),uLo=r(_$e," \u2014 "),aG=n(_$e,"A",{href:!0});var b_t=s(aG);bLo=r(b_t,"OpenAIGPTLMHeadModel"),b_t.forEach(t),vLo=r(_$e," (OpenAI GPT model)"),_$e.forEach(t),FLo=i(O),h2=n(O,"LI",{});var u$e=s(h2);ime=n(u$e,"STRONG",{});var v_t=s(ime);TLo=r(v_t,"retribert"),v_t.forEach(t),MLo=r(u$e," \u2014 "),nG=n(u$e,"A",{href:!0});var F_t=s(nG);ELo=r(F_t,"RetriBertModel"),F_t.forEach(t),CLo=r(u$e," (RetriBERT model)"),u$e.forEach(t),wLo=i(O),p2=n(O,"LI",{});var b$e=s(p2);dme=n(b$e,"STRONG",{});var T_t=s(dme);ALo=r(T_t,"roberta"),T_t.forEach(t),LLo=r(b$e," \u2014 "),sG=n(b$e,"A",{href:!0});var M_t=s(sG);yLo=r(M_t,"RobertaForMaskedLM"),M_t.forEach(t),xLo=r(b$e," (RoBERTa model)"),b$e.forEach(t),$Lo=i(O),_2=n(O,"LI",{});var v$e=s(_2);cme=n(v$e,"STRONG",{});var E_t=s(cme);kLo=r(E_t,"splinter"),E_t.forEach(t),SLo=r(v$e," \u2014 "),lG=n(v$e,"A",{href:!0});var C_t=s(lG);RLo=r(C_t,"SplinterForPreTraining"),C_t.forEach(t),PLo=r(v$e," (Splinter model)"),v$e.forEach(t),BLo=i(O),u2=n(O,"LI",{});var F$e=s(u2);fme=n(F$e,"STRONG",{});var w_t=s(fme);NLo=r(w_t,"squeezebert"),w_t.forEach(t),ILo=r(F$e," \u2014 "),iG=n(F$e,"A",{href:!0});var A_t=s(iG);qLo=r(A_t,"SqueezeBertForMaskedLM"),A_t.forEach(t),jLo=r(F$e," (SqueezeBERT model)"),F$e.forEach(t),DLo=i(O),b2=n(O,"LI",{});var T$e=s(b2);mme=n(T$e,"STRONG",{});var L_t=s(mme);GLo=r(L_t,"t5"),L_t.forEach(t),OLo=r(T$e," \u2014 "),dG=n(T$e,"A",{href:!0});var y_t=s(dG);VLo=r(y_t,"T5ForConditionalGeneration"),y_t.forEach(t),XLo=r(T$e," (T5 model)"),T$e.forEach(t),zLo=i(O),v2=n(O,"LI",{});var M$e=s(v2);gme=n(M$e,"STRONG",{});var x_t=s(gme);QLo=r(x_t,"tapas"),x_t.forEach(t),WLo=r(M$e," \u2014 "),cG=n(M$e,"A",{href:!0});var $_t=s(cG);HLo=r($_t,"TapasForMaskedLM"),$_t.forEach(t),ULo=r(M$e," (TAPAS model)"),M$e.forEach(t),JLo=i(O),F2=n(O,"LI",{});var E$e=s(F2);hme=n(E$e,"STRONG",{});var k_t=s(hme);YLo=r(k_t,"transfo-xl"),k_t.forEach(t),KLo=r(E$e," \u2014 "),fG=n(E$e,"A",{href:!0});var S_t=s(fG);ZLo=r(S_t,"TransfoXLLMHeadModel"),S_t.forEach(t),eyo=r(E$e," (Transformer-XL model)"),E$e.forEach(t),oyo=i(O),T2=n(O,"LI",{});var C$e=s(T2);pme=n(C$e,"STRONG",{});var R_t=s(pme);ryo=r(R_t,"unispeech"),R_t.forEach(t),tyo=r(C$e," \u2014 "),mG=n(C$e,"A",{href:!0});var P_t=s(mG);ayo=r(P_t,"UniSpeechForPreTraining"),P_t.forEach(t),nyo=r(C$e," (UniSpeech model)"),C$e.forEach(t),syo=i(O),M2=n(O,"LI",{});var w$e=s(M2);_me=n(w$e,"STRONG",{});var B_t=s(_me);lyo=r(B_t,"unispeech-sat"),B_t.forEach(t),iyo=r(w$e," \u2014 "),gG=n(w$e,"A",{href:!0});var N_t=s(gG);dyo=r(N_t,"UniSpeechSatForPreTraining"),N_t.forEach(t),cyo=r(w$e," (UniSpeechSat model)"),w$e.forEach(t),fyo=i(O),E2=n(O,"LI",{});var A$e=s(E2);ume=n(A$e,"STRONG",{});var I_t=s(ume);myo=r(I_t,"visual_bert"),I_t.forEach(t),gyo=r(A$e," \u2014 "),hG=n(A$e,"A",{href:!0});var q_t=s(hG);hyo=r(q_t,"VisualBertForPreTraining"),q_t.forEach(t),pyo=r(A$e," (VisualBERT model)"),A$e.forEach(t),_yo=i(O),C2=n(O,"LI",{});var L$e=s(C2);bme=n(L$e,"STRONG",{});var j_t=s(bme);uyo=r(j_t,"vit_mae"),j_t.forEach(t),byo=r(L$e," \u2014 "),pG=n(L$e,"A",{href:!0});var D_t=s(pG);vyo=r(D_t,"ViTMAEForPreTraining"),D_t.forEach(t),Fyo=r(L$e," (ViTMAE model)"),L$e.forEach(t),Tyo=i(O),w2=n(O,"LI",{});var y$e=s(w2);vme=n(y$e,"STRONG",{});var G_t=s(vme);Myo=r(G_t,"wav2vec2"),G_t.forEach(t),Eyo=r(y$e," \u2014 "),_G=n(y$e,"A",{href:!0});var O_t=s(_G);Cyo=r(O_t,"Wav2Vec2ForPreTraining"),O_t.forEach(t),wyo=r(y$e," (Wav2Vec2 model)"),y$e.forEach(t),Ayo=i(O),A2=n(O,"LI",{});var x$e=s(A2);Fme=n(x$e,"STRONG",{});var V_t=s(Fme);Lyo=r(V_t,"wav2vec2-conformer"),V_t.forEach(t),yyo=r(x$e," \u2014 "),uG=n(x$e,"A",{href:!0});var X_t=s(uG);xyo=r(X_t,"Wav2Vec2ConformerForPreTraining"),X_t.forEach(t),$yo=r(x$e," (Wav2Vec2-Conformer model)"),x$e.forEach(t),kyo=i(O),L2=n(O,"LI",{});var $$e=s(L2);Tme=n($$e,"STRONG",{});var z_t=s(Tme);Syo=r(z_t,"xlm"),z_t.forEach(t),Ryo=r($$e," \u2014 "),bG=n($$e,"A",{href:!0});var Q_t=s(bG);Pyo=r(Q_t,"XLMWithLMHeadModel"),Q_t.forEach(t),Byo=r($$e," (XLM model)"),$$e.forEach(t),Nyo=i(O),y2=n(O,"LI",{});var k$e=s(y2);Mme=n(k$e,"STRONG",{});var W_t=s(Mme);Iyo=r(W_t,"xlm-roberta"),W_t.forEach(t),qyo=r(k$e," \u2014 "),vG=n(k$e,"A",{href:!0});var H_t=s(vG);jyo=r(H_t,"XLMRobertaForMaskedLM"),H_t.forEach(t),Dyo=r(k$e," (XLM-RoBERTa model)"),k$e.forEach(t),Gyo=i(O),x2=n(O,"LI",{});var S$e=s(x2);Eme=n(S$e,"STRONG",{});var U_t=s(Eme);Oyo=r(U_t,"xlm-roberta-xl"),U_t.forEach(t),Vyo=r(S$e," \u2014 "),FG=n(S$e,"A",{href:!0});var J_t=s(FG);Xyo=r(J_t,"XLMRobertaXLForMaskedLM"),J_t.forEach(t),zyo=r(S$e," (XLM-RoBERTa-XL model)"),S$e.forEach(t),Qyo=i(O),$2=n(O,"LI",{});var R$e=s($2);Cme=n(R$e,"STRONG",{});var Y_t=s(Cme);Wyo=r(Y_t,"xlnet"),Y_t.forEach(t),Hyo=r(R$e," \u2014 "),TG=n(R$e,"A",{href:!0});var K_t=s(TG);Uyo=r(K_t,"XLNetLMHeadModel"),K_t.forEach(t),Jyo=r(R$e," (XLNet model)"),R$e.forEach(t),O.forEach(t),Yyo=i(sa),k2=n(sa,"P",{});var P$e=s(k2);Kyo=r(P$e,"The model is set in evaluation mode by default using "),wme=n(P$e,"CODE",{});var Z_t=s(wme);Zyo=r(Z_t,"model.eval()"),Z_t.forEach(t),e8o=r(P$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ame=n(P$e,"CODE",{});var eut=s(Ame);o8o=r(eut,"model.train()"),eut.forEach(t),P$e.forEach(t),r8o=i(sa),T(S2.$$.fragment,sa),sa.forEach(t),ol.forEach(t),rVe=i(f),Xi=n(f,"H2",{class:!0});var ize=s(Xi);R2=n(ize,"A",{id:!0,class:!0,href:!0});var out=s(R2);Lme=n(out,"SPAN",{});var rut=s(Lme);T(Cy.$$.fragment,rut),rut.forEach(t),out.forEach(t),t8o=i(ize),yme=n(ize,"SPAN",{});var tut=s(yme);a8o=r(tut,"AutoModelForCausalLM"),tut.forEach(t),ize.forEach(t),tVe=i(f),ko=n(f,"DIV",{class:!0});var rl=s(ko);T(wy.$$.fragment,rl),n8o=i(rl),zi=n(rl,"P",{});var Zoe=s(zi);s8o=r(Zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),MG=n(Zoe,"A",{href:!0});var aut=s(MG);l8o=r(aut,"from_pretrained()"),aut.forEach(t),i8o=r(Zoe," class method or the "),EG=n(Zoe,"A",{href:!0});var nut=s(EG);d8o=r(nut,"from_config()"),nut.forEach(t),c8o=r(Zoe,` class
method.`),Zoe.forEach(t),f8o=i(rl),Ay=n(rl,"P",{});var dze=s(Ay);m8o=r(dze,"This class cannot be instantiated directly using "),xme=n(dze,"CODE",{});var sut=s(xme);g8o=r(sut,"__init__()"),sut.forEach(t),h8o=r(dze," (throws an error)."),dze.forEach(t),p8o=i(rl),it=n(rl,"DIV",{class:!0});var UA=s(it);T(Ly.$$.fragment,UA),_8o=i(UA),$me=n(UA,"P",{});var lut=s($me);u8o=r(lut,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),lut.forEach(t),b8o=i(UA),Qi=n(UA,"P",{});var ere=s(Qi);v8o=r(ere,`Note:
Loading a model from its configuration file does `),kme=n(ere,"STRONG",{});var iut=s(kme);F8o=r(iut,"not"),iut.forEach(t),T8o=r(ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),CG=n(ere,"A",{href:!0});var dut=s(CG);M8o=r(dut,"from_pretrained()"),dut.forEach(t),E8o=r(ere," to load the model weights."),ere.forEach(t),C8o=i(UA),T(P2.$$.fragment,UA),UA.forEach(t),w8o=i(rl),Ke=n(rl,"DIV",{class:!0});var la=s(Ke);T(yy.$$.fragment,la),A8o=i(la),Sme=n(la,"P",{});var cut=s(Sme);L8o=r(cut,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cut.forEach(t),y8o=i(la),Ia=n(la,"P",{});var JA=s(Ia);x8o=r(JA,"The model class to instantiate is selected based on the "),Rme=n(JA,"CODE",{});var fut=s(Rme);$8o=r(fut,"model_type"),fut.forEach(t),k8o=r(JA,` property of the config object (either
passed as an argument or loaded from `),Pme=n(JA,"CODE",{});var mut=s(Pme);S8o=r(mut,"pretrained_model_name_or_path"),mut.forEach(t),R8o=r(JA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bme=n(JA,"CODE",{});var gut=s(Bme);P8o=r(gut,"pretrained_model_name_or_path"),gut.forEach(t),B8o=r(JA,":"),JA.forEach(t),N8o=i(la),z=n(la,"UL",{});var Q=s(z);B2=n(Q,"LI",{});var B$e=s(B2);Nme=n(B$e,"STRONG",{});var hut=s(Nme);I8o=r(hut,"bart"),hut.forEach(t),q8o=r(B$e," \u2014 "),wG=n(B$e,"A",{href:!0});var put=s(wG);j8o=r(put,"BartForCausalLM"),put.forEach(t),D8o=r(B$e," (BART model)"),B$e.forEach(t),G8o=i(Q),N2=n(Q,"LI",{});var N$e=s(N2);Ime=n(N$e,"STRONG",{});var _ut=s(Ime);O8o=r(_ut,"bert"),_ut.forEach(t),V8o=r(N$e," \u2014 "),AG=n(N$e,"A",{href:!0});var uut=s(AG);X8o=r(uut,"BertLMHeadModel"),uut.forEach(t),z8o=r(N$e," (BERT model)"),N$e.forEach(t),Q8o=i(Q),I2=n(Q,"LI",{});var I$e=s(I2);qme=n(I$e,"STRONG",{});var but=s(qme);W8o=r(but,"bert-generation"),but.forEach(t),H8o=r(I$e," \u2014 "),LG=n(I$e,"A",{href:!0});var vut=s(LG);U8o=r(vut,"BertGenerationDecoder"),vut.forEach(t),J8o=r(I$e," (Bert Generation model)"),I$e.forEach(t),Y8o=i(Q),q2=n(Q,"LI",{});var q$e=s(q2);jme=n(q$e,"STRONG",{});var Fut=s(jme);K8o=r(Fut,"big_bird"),Fut.forEach(t),Z8o=r(q$e," \u2014 "),yG=n(q$e,"A",{href:!0});var Tut=s(yG);e9o=r(Tut,"BigBirdForCausalLM"),Tut.forEach(t),o9o=r(q$e," (BigBird model)"),q$e.forEach(t),r9o=i(Q),j2=n(Q,"LI",{});var j$e=s(j2);Dme=n(j$e,"STRONG",{});var Mut=s(Dme);t9o=r(Mut,"bigbird_pegasus"),Mut.forEach(t),a9o=r(j$e," \u2014 "),xG=n(j$e,"A",{href:!0});var Eut=s(xG);n9o=r(Eut,"BigBirdPegasusForCausalLM"),Eut.forEach(t),s9o=r(j$e," (BigBird-Pegasus model)"),j$e.forEach(t),l9o=i(Q),D2=n(Q,"LI",{});var D$e=s(D2);Gme=n(D$e,"STRONG",{});var Cut=s(Gme);i9o=r(Cut,"blenderbot"),Cut.forEach(t),d9o=r(D$e," \u2014 "),$G=n(D$e,"A",{href:!0});var wut=s($G);c9o=r(wut,"BlenderbotForCausalLM"),wut.forEach(t),f9o=r(D$e," (Blenderbot model)"),D$e.forEach(t),m9o=i(Q),G2=n(Q,"LI",{});var G$e=s(G2);Ome=n(G$e,"STRONG",{});var Aut=s(Ome);g9o=r(Aut,"blenderbot-small"),Aut.forEach(t),h9o=r(G$e," \u2014 "),kG=n(G$e,"A",{href:!0});var Lut=s(kG);p9o=r(Lut,"BlenderbotSmallForCausalLM"),Lut.forEach(t),_9o=r(G$e," (BlenderbotSmall model)"),G$e.forEach(t),u9o=i(Q),O2=n(Q,"LI",{});var O$e=s(O2);Vme=n(O$e,"STRONG",{});var yut=s(Vme);b9o=r(yut,"bloom"),yut.forEach(t),v9o=r(O$e," \u2014 "),SG=n(O$e,"A",{href:!0});var xut=s(SG);F9o=r(xut,"BloomForCausalLM"),xut.forEach(t),T9o=r(O$e," (BLOOM model)"),O$e.forEach(t),M9o=i(Q),V2=n(Q,"LI",{});var V$e=s(V2);Xme=n(V$e,"STRONG",{});var $ut=s(Xme);E9o=r($ut,"camembert"),$ut.forEach(t),C9o=r(V$e," \u2014 "),RG=n(V$e,"A",{href:!0});var kut=s(RG);w9o=r(kut,"CamembertForCausalLM"),kut.forEach(t),A9o=r(V$e," (CamemBERT model)"),V$e.forEach(t),L9o=i(Q),X2=n(Q,"LI",{});var X$e=s(X2);zme=n(X$e,"STRONG",{});var Sut=s(zme);y9o=r(Sut,"codegen"),Sut.forEach(t),x9o=r(X$e," \u2014 "),PG=n(X$e,"A",{href:!0});var Rut=s(PG);$9o=r(Rut,"CodeGenForCausalLM"),Rut.forEach(t),k9o=r(X$e," (CodeGen model)"),X$e.forEach(t),S9o=i(Q),z2=n(Q,"LI",{});var z$e=s(z2);Qme=n(z$e,"STRONG",{});var Put=s(Qme);R9o=r(Put,"ctrl"),Put.forEach(t),P9o=r(z$e," \u2014 "),BG=n(z$e,"A",{href:!0});var But=s(BG);B9o=r(But,"CTRLLMHeadModel"),But.forEach(t),N9o=r(z$e," (CTRL model)"),z$e.forEach(t),I9o=i(Q),Q2=n(Q,"LI",{});var Q$e=s(Q2);Wme=n(Q$e,"STRONG",{});var Nut=s(Wme);q9o=r(Nut,"data2vec-text"),Nut.forEach(t),j9o=r(Q$e," \u2014 "),NG=n(Q$e,"A",{href:!0});var Iut=s(NG);D9o=r(Iut,"Data2VecTextForCausalLM"),Iut.forEach(t),G9o=r(Q$e," (Data2VecText model)"),Q$e.forEach(t),O9o=i(Q),W2=n(Q,"LI",{});var W$e=s(W2);Hme=n(W$e,"STRONG",{});var qut=s(Hme);V9o=r(qut,"electra"),qut.forEach(t),X9o=r(W$e," \u2014 "),IG=n(W$e,"A",{href:!0});var jut=s(IG);z9o=r(jut,"ElectraForCausalLM"),jut.forEach(t),Q9o=r(W$e," (ELECTRA model)"),W$e.forEach(t),W9o=i(Q),H2=n(Q,"LI",{});var H$e=s(H2);Ume=n(H$e,"STRONG",{});var Dut=s(Ume);H9o=r(Dut,"gpt2"),Dut.forEach(t),U9o=r(H$e," \u2014 "),qG=n(H$e,"A",{href:!0});var Gut=s(qG);J9o=r(Gut,"GPT2LMHeadModel"),Gut.forEach(t),Y9o=r(H$e," (OpenAI GPT-2 model)"),H$e.forEach(t),K9o=i(Q),U2=n(Q,"LI",{});var U$e=s(U2);Jme=n(U$e,"STRONG",{});var Out=s(Jme);Z9o=r(Out,"gpt_neo"),Out.forEach(t),exo=r(U$e," \u2014 "),jG=n(U$e,"A",{href:!0});var Vut=s(jG);oxo=r(Vut,"GPTNeoForCausalLM"),Vut.forEach(t),rxo=r(U$e," (GPT Neo model)"),U$e.forEach(t),txo=i(Q),J2=n(Q,"LI",{});var J$e=s(J2);Yme=n(J$e,"STRONG",{});var Xut=s(Yme);axo=r(Xut,"gpt_neox"),Xut.forEach(t),nxo=r(J$e," \u2014 "),DG=n(J$e,"A",{href:!0});var zut=s(DG);sxo=r(zut,"GPTNeoXForCausalLM"),zut.forEach(t),lxo=r(J$e," (GPT NeoX model)"),J$e.forEach(t),ixo=i(Q),Y2=n(Q,"LI",{});var Y$e=s(Y2);Kme=n(Y$e,"STRONG",{});var Qut=s(Kme);dxo=r(Qut,"gptj"),Qut.forEach(t),cxo=r(Y$e," \u2014 "),GG=n(Y$e,"A",{href:!0});var Wut=s(GG);fxo=r(Wut,"GPTJForCausalLM"),Wut.forEach(t),mxo=r(Y$e," (GPT-J model)"),Y$e.forEach(t),gxo=i(Q),K2=n(Q,"LI",{});var K$e=s(K2);Zme=n(K$e,"STRONG",{});var Hut=s(Zme);hxo=r(Hut,"marian"),Hut.forEach(t),pxo=r(K$e," \u2014 "),OG=n(K$e,"A",{href:!0});var Uut=s(OG);_xo=r(Uut,"MarianForCausalLM"),Uut.forEach(t),uxo=r(K$e," (Marian model)"),K$e.forEach(t),bxo=i(Q),Z2=n(Q,"LI",{});var Z$e=s(Z2);ege=n(Z$e,"STRONG",{});var Jut=s(ege);vxo=r(Jut,"mbart"),Jut.forEach(t),Fxo=r(Z$e," \u2014 "),VG=n(Z$e,"A",{href:!0});var Yut=s(VG);Txo=r(Yut,"MBartForCausalLM"),Yut.forEach(t),Mxo=r(Z$e," (mBART model)"),Z$e.forEach(t),Exo=i(Q),e1=n(Q,"LI",{});var eke=s(e1);oge=n(eke,"STRONG",{});var Kut=s(oge);Cxo=r(Kut,"megatron-bert"),Kut.forEach(t),wxo=r(eke," \u2014 "),XG=n(eke,"A",{href:!0});var Zut=s(XG);Axo=r(Zut,"MegatronBertForCausalLM"),Zut.forEach(t),Lxo=r(eke," (Megatron-BERT model)"),eke.forEach(t),yxo=i(Q),o1=n(Q,"LI",{});var oke=s(o1);rge=n(oke,"STRONG",{});var e2t=s(rge);xxo=r(e2t,"openai-gpt"),e2t.forEach(t),$xo=r(oke," \u2014 "),zG=n(oke,"A",{href:!0});var o2t=s(zG);kxo=r(o2t,"OpenAIGPTLMHeadModel"),o2t.forEach(t),Sxo=r(oke," (OpenAI GPT model)"),oke.forEach(t),Rxo=i(Q),r1=n(Q,"LI",{});var rke=s(r1);tge=n(rke,"STRONG",{});var r2t=s(tge);Pxo=r(r2t,"opt"),r2t.forEach(t),Bxo=r(rke," \u2014 "),QG=n(rke,"A",{href:!0});var t2t=s(QG);Nxo=r(t2t,"OPTForCausalLM"),t2t.forEach(t),Ixo=r(rke," (OPT model)"),rke.forEach(t),qxo=i(Q),t1=n(Q,"LI",{});var tke=s(t1);age=n(tke,"STRONG",{});var a2t=s(age);jxo=r(a2t,"pegasus"),a2t.forEach(t),Dxo=r(tke," \u2014 "),WG=n(tke,"A",{href:!0});var n2t=s(WG);Gxo=r(n2t,"PegasusForCausalLM"),n2t.forEach(t),Oxo=r(tke," (Pegasus model)"),tke.forEach(t),Vxo=i(Q),a1=n(Q,"LI",{});var ake=s(a1);nge=n(ake,"STRONG",{});var s2t=s(nge);Xxo=r(s2t,"plbart"),s2t.forEach(t),zxo=r(ake," \u2014 "),HG=n(ake,"A",{href:!0});var l2t=s(HG);Qxo=r(l2t,"PLBartForCausalLM"),l2t.forEach(t),Wxo=r(ake," (PLBart model)"),ake.forEach(t),Hxo=i(Q),n1=n(Q,"LI",{});var nke=s(n1);sge=n(nke,"STRONG",{});var i2t=s(sge);Uxo=r(i2t,"prophetnet"),i2t.forEach(t),Jxo=r(nke," \u2014 "),UG=n(nke,"A",{href:!0});var d2t=s(UG);Yxo=r(d2t,"ProphetNetForCausalLM"),d2t.forEach(t),Kxo=r(nke," (ProphetNet model)"),nke.forEach(t),Zxo=i(Q),s1=n(Q,"LI",{});var ske=s(s1);lge=n(ske,"STRONG",{});var c2t=s(lge);e$o=r(c2t,"qdqbert"),c2t.forEach(t),o$o=r(ske," \u2014 "),JG=n(ske,"A",{href:!0});var f2t=s(JG);r$o=r(f2t,"QDQBertLMHeadModel"),f2t.forEach(t),t$o=r(ske," (QDQBert model)"),ske.forEach(t),a$o=i(Q),l1=n(Q,"LI",{});var lke=s(l1);ige=n(lke,"STRONG",{});var m2t=s(ige);n$o=r(m2t,"reformer"),m2t.forEach(t),s$o=r(lke," \u2014 "),YG=n(lke,"A",{href:!0});var g2t=s(YG);l$o=r(g2t,"ReformerModelWithLMHead"),g2t.forEach(t),i$o=r(lke," (Reformer model)"),lke.forEach(t),d$o=i(Q),i1=n(Q,"LI",{});var ike=s(i1);dge=n(ike,"STRONG",{});var h2t=s(dge);c$o=r(h2t,"rembert"),h2t.forEach(t),f$o=r(ike," \u2014 "),KG=n(ike,"A",{href:!0});var p2t=s(KG);m$o=r(p2t,"RemBertForCausalLM"),p2t.forEach(t),g$o=r(ike," (RemBERT model)"),ike.forEach(t),h$o=i(Q),d1=n(Q,"LI",{});var dke=s(d1);cge=n(dke,"STRONG",{});var _2t=s(cge);p$o=r(_2t,"roberta"),_2t.forEach(t),_$o=r(dke," \u2014 "),ZG=n(dke,"A",{href:!0});var u2t=s(ZG);u$o=r(u2t,"RobertaForCausalLM"),u2t.forEach(t),b$o=r(dke," (RoBERTa model)"),dke.forEach(t),v$o=i(Q),c1=n(Q,"LI",{});var cke=s(c1);fge=n(cke,"STRONG",{});var b2t=s(fge);F$o=r(b2t,"roformer"),b2t.forEach(t),T$o=r(cke," \u2014 "),eO=n(cke,"A",{href:!0});var v2t=s(eO);M$o=r(v2t,"RoFormerForCausalLM"),v2t.forEach(t),E$o=r(cke," (RoFormer model)"),cke.forEach(t),C$o=i(Q),f1=n(Q,"LI",{});var fke=s(f1);mge=n(fke,"STRONG",{});var F2t=s(mge);w$o=r(F2t,"speech_to_text_2"),F2t.forEach(t),A$o=r(fke," \u2014 "),oO=n(fke,"A",{href:!0});var T2t=s(oO);L$o=r(T2t,"Speech2Text2ForCausalLM"),T2t.forEach(t),y$o=r(fke," (Speech2Text2 model)"),fke.forEach(t),x$o=i(Q),m1=n(Q,"LI",{});var mke=s(m1);gge=n(mke,"STRONG",{});var M2t=s(gge);$$o=r(M2t,"transfo-xl"),M2t.forEach(t),k$o=r(mke," \u2014 "),rO=n(mke,"A",{href:!0});var E2t=s(rO);S$o=r(E2t,"TransfoXLLMHeadModel"),E2t.forEach(t),R$o=r(mke," (Transformer-XL model)"),mke.forEach(t),P$o=i(Q),g1=n(Q,"LI",{});var gke=s(g1);hge=n(gke,"STRONG",{});var C2t=s(hge);B$o=r(C2t,"trocr"),C2t.forEach(t),N$o=r(gke," \u2014 "),tO=n(gke,"A",{href:!0});var w2t=s(tO);I$o=r(w2t,"TrOCRForCausalLM"),w2t.forEach(t),q$o=r(gke," (TrOCR model)"),gke.forEach(t),j$o=i(Q),h1=n(Q,"LI",{});var hke=s(h1);pge=n(hke,"STRONG",{});var A2t=s(pge);D$o=r(A2t,"xglm"),A2t.forEach(t),G$o=r(hke," \u2014 "),aO=n(hke,"A",{href:!0});var L2t=s(aO);O$o=r(L2t,"XGLMForCausalLM"),L2t.forEach(t),V$o=r(hke," (XGLM model)"),hke.forEach(t),X$o=i(Q),p1=n(Q,"LI",{});var pke=s(p1);_ge=n(pke,"STRONG",{});var y2t=s(_ge);z$o=r(y2t,"xlm"),y2t.forEach(t),Q$o=r(pke," \u2014 "),nO=n(pke,"A",{href:!0});var x2t=s(nO);W$o=r(x2t,"XLMWithLMHeadModel"),x2t.forEach(t),H$o=r(pke," (XLM model)"),pke.forEach(t),U$o=i(Q),_1=n(Q,"LI",{});var _ke=s(_1);uge=n(_ke,"STRONG",{});var $2t=s(uge);J$o=r($2t,"xlm-prophetnet"),$2t.forEach(t),Y$o=r(_ke," \u2014 "),sO=n(_ke,"A",{href:!0});var k2t=s(sO);K$o=r(k2t,"XLMProphetNetForCausalLM"),k2t.forEach(t),Z$o=r(_ke," (XLM-ProphetNet model)"),_ke.forEach(t),eko=i(Q),u1=n(Q,"LI",{});var uke=s(u1);bge=n(uke,"STRONG",{});var S2t=s(bge);oko=r(S2t,"xlm-roberta"),S2t.forEach(t),rko=r(uke," \u2014 "),lO=n(uke,"A",{href:!0});var R2t=s(lO);tko=r(R2t,"XLMRobertaForCausalLM"),R2t.forEach(t),ako=r(uke," (XLM-RoBERTa model)"),uke.forEach(t),nko=i(Q),b1=n(Q,"LI",{});var bke=s(b1);vge=n(bke,"STRONG",{});var P2t=s(vge);sko=r(P2t,"xlm-roberta-xl"),P2t.forEach(t),lko=r(bke," \u2014 "),iO=n(bke,"A",{href:!0});var B2t=s(iO);iko=r(B2t,"XLMRobertaXLForCausalLM"),B2t.forEach(t),dko=r(bke," (XLM-RoBERTa-XL model)"),bke.forEach(t),cko=i(Q),v1=n(Q,"LI",{});var vke=s(v1);Fge=n(vke,"STRONG",{});var N2t=s(Fge);fko=r(N2t,"xlnet"),N2t.forEach(t),mko=r(vke," \u2014 "),dO=n(vke,"A",{href:!0});var I2t=s(dO);gko=r(I2t,"XLNetLMHeadModel"),I2t.forEach(t),hko=r(vke," (XLNet model)"),vke.forEach(t),Q.forEach(t),pko=i(la),F1=n(la,"P",{});var Fke=s(F1);_ko=r(Fke,"The model is set in evaluation mode by default using "),Tge=n(Fke,"CODE",{});var q2t=s(Tge);uko=r(q2t,"model.eval()"),q2t.forEach(t),bko=r(Fke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mge=n(Fke,"CODE",{});var j2t=s(Mge);vko=r(j2t,"model.train()"),j2t.forEach(t),Fke.forEach(t),Fko=i(la),T(T1.$$.fragment,la),la.forEach(t),rl.forEach(t),aVe=i(f),Wi=n(f,"H2",{class:!0});var cze=s(Wi);M1=n(cze,"A",{id:!0,class:!0,href:!0});var D2t=s(M1);Ege=n(D2t,"SPAN",{});var G2t=s(Ege);T(xy.$$.fragment,G2t),G2t.forEach(t),D2t.forEach(t),Tko=i(cze),Cge=n(cze,"SPAN",{});var O2t=s(Cge);Mko=r(O2t,"AutoModelForMaskedLM"),O2t.forEach(t),cze.forEach(t),nVe=i(f),So=n(f,"DIV",{class:!0});var tl=s(So);T($y.$$.fragment,tl),Eko=i(tl),Hi=n(tl,"P",{});var ore=s(Hi);Cko=r(ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),cO=n(ore,"A",{href:!0});var V2t=s(cO);wko=r(V2t,"from_pretrained()"),V2t.forEach(t),Ako=r(ore," class method or the "),fO=n(ore,"A",{href:!0});var X2t=s(fO);Lko=r(X2t,"from_config()"),X2t.forEach(t),yko=r(ore,` class
method.`),ore.forEach(t),xko=i(tl),ky=n(tl,"P",{});var fze=s(ky);$ko=r(fze,"This class cannot be instantiated directly using "),wge=n(fze,"CODE",{});var z2t=s(wge);kko=r(z2t,"__init__()"),z2t.forEach(t),Sko=r(fze," (throws an error)."),fze.forEach(t),Rko=i(tl),dt=n(tl,"DIV",{class:!0});var YA=s(dt);T(Sy.$$.fragment,YA),Pko=i(YA),Age=n(YA,"P",{});var Q2t=s(Age);Bko=r(Q2t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Q2t.forEach(t),Nko=i(YA),Ui=n(YA,"P",{});var rre=s(Ui);Iko=r(rre,`Note:
Loading a model from its configuration file does `),Lge=n(rre,"STRONG",{});var W2t=s(Lge);qko=r(W2t,"not"),W2t.forEach(t),jko=r(rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),mO=n(rre,"A",{href:!0});var H2t=s(mO);Dko=r(H2t,"from_pretrained()"),H2t.forEach(t),Gko=r(rre," to load the model weights."),rre.forEach(t),Oko=i(YA),T(E1.$$.fragment,YA),YA.forEach(t),Vko=i(tl),Ze=n(tl,"DIV",{class:!0});var ia=s(Ze);T(Ry.$$.fragment,ia),Xko=i(ia),yge=n(ia,"P",{});var U2t=s(yge);zko=r(U2t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),U2t.forEach(t),Qko=i(ia),qa=n(ia,"P",{});var KA=s(qa);Wko=r(KA,"The model class to instantiate is selected based on the "),xge=n(KA,"CODE",{});var J2t=s(xge);Hko=r(J2t,"model_type"),J2t.forEach(t),Uko=r(KA,` property of the config object (either
passed as an argument or loaded from `),$ge=n(KA,"CODE",{});var Y2t=s($ge);Jko=r(Y2t,"pretrained_model_name_or_path"),Y2t.forEach(t),Yko=r(KA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kge=n(KA,"CODE",{});var K2t=s(kge);Kko=r(K2t,"pretrained_model_name_or_path"),K2t.forEach(t),Zko=r(KA,":"),KA.forEach(t),eSo=i(ia),W=n(ia,"UL",{});var U=s(W);C1=n(U,"LI",{});var Tke=s(C1);Sge=n(Tke,"STRONG",{});var Z2t=s(Sge);oSo=r(Z2t,"albert"),Z2t.forEach(t),rSo=r(Tke," \u2014 "),gO=n(Tke,"A",{href:!0});var e1t=s(gO);tSo=r(e1t,"AlbertForMaskedLM"),e1t.forEach(t),aSo=r(Tke," (ALBERT model)"),Tke.forEach(t),nSo=i(U),w1=n(U,"LI",{});var Mke=s(w1);Rge=n(Mke,"STRONG",{});var o1t=s(Rge);sSo=r(o1t,"bart"),o1t.forEach(t),lSo=r(Mke," \u2014 "),hO=n(Mke,"A",{href:!0});var r1t=s(hO);iSo=r(r1t,"BartForConditionalGeneration"),r1t.forEach(t),dSo=r(Mke," (BART model)"),Mke.forEach(t),cSo=i(U),A1=n(U,"LI",{});var Eke=s(A1);Pge=n(Eke,"STRONG",{});var t1t=s(Pge);fSo=r(t1t,"bert"),t1t.forEach(t),mSo=r(Eke," \u2014 "),pO=n(Eke,"A",{href:!0});var a1t=s(pO);gSo=r(a1t,"BertForMaskedLM"),a1t.forEach(t),hSo=r(Eke," (BERT model)"),Eke.forEach(t),pSo=i(U),L1=n(U,"LI",{});var Cke=s(L1);Bge=n(Cke,"STRONG",{});var n1t=s(Bge);_So=r(n1t,"big_bird"),n1t.forEach(t),uSo=r(Cke," \u2014 "),_O=n(Cke,"A",{href:!0});var s1t=s(_O);bSo=r(s1t,"BigBirdForMaskedLM"),s1t.forEach(t),vSo=r(Cke," (BigBird model)"),Cke.forEach(t),FSo=i(U),y1=n(U,"LI",{});var wke=s(y1);Nge=n(wke,"STRONG",{});var l1t=s(Nge);TSo=r(l1t,"camembert"),l1t.forEach(t),MSo=r(wke," \u2014 "),uO=n(wke,"A",{href:!0});var i1t=s(uO);ESo=r(i1t,"CamembertForMaskedLM"),i1t.forEach(t),CSo=r(wke," (CamemBERT model)"),wke.forEach(t),wSo=i(U),x1=n(U,"LI",{});var Ake=s(x1);Ige=n(Ake,"STRONG",{});var d1t=s(Ige);ASo=r(d1t,"convbert"),d1t.forEach(t),LSo=r(Ake," \u2014 "),bO=n(Ake,"A",{href:!0});var c1t=s(bO);ySo=r(c1t,"ConvBertForMaskedLM"),c1t.forEach(t),xSo=r(Ake," (ConvBERT model)"),Ake.forEach(t),$So=i(U),$1=n(U,"LI",{});var Lke=s($1);qge=n(Lke,"STRONG",{});var f1t=s(qge);kSo=r(f1t,"data2vec-text"),f1t.forEach(t),SSo=r(Lke," \u2014 "),vO=n(Lke,"A",{href:!0});var m1t=s(vO);RSo=r(m1t,"Data2VecTextForMaskedLM"),m1t.forEach(t),PSo=r(Lke," (Data2VecText model)"),Lke.forEach(t),BSo=i(U),k1=n(U,"LI",{});var yke=s(k1);jge=n(yke,"STRONG",{});var g1t=s(jge);NSo=r(g1t,"deberta"),g1t.forEach(t),ISo=r(yke," \u2014 "),FO=n(yke,"A",{href:!0});var h1t=s(FO);qSo=r(h1t,"DebertaForMaskedLM"),h1t.forEach(t),jSo=r(yke," (DeBERTa model)"),yke.forEach(t),DSo=i(U),S1=n(U,"LI",{});var xke=s(S1);Dge=n(xke,"STRONG",{});var p1t=s(Dge);GSo=r(p1t,"deberta-v2"),p1t.forEach(t),OSo=r(xke," \u2014 "),TO=n(xke,"A",{href:!0});var _1t=s(TO);VSo=r(_1t,"DebertaV2ForMaskedLM"),_1t.forEach(t),XSo=r(xke," (DeBERTa-v2 model)"),xke.forEach(t),zSo=i(U),R1=n(U,"LI",{});var $ke=s(R1);Gge=n($ke,"STRONG",{});var u1t=s(Gge);QSo=r(u1t,"distilbert"),u1t.forEach(t),WSo=r($ke," \u2014 "),MO=n($ke,"A",{href:!0});var b1t=s(MO);HSo=r(b1t,"DistilBertForMaskedLM"),b1t.forEach(t),USo=r($ke," (DistilBERT model)"),$ke.forEach(t),JSo=i(U),P1=n(U,"LI",{});var kke=s(P1);Oge=n(kke,"STRONG",{});var v1t=s(Oge);YSo=r(v1t,"electra"),v1t.forEach(t),KSo=r(kke," \u2014 "),EO=n(kke,"A",{href:!0});var F1t=s(EO);ZSo=r(F1t,"ElectraForMaskedLM"),F1t.forEach(t),eRo=r(kke," (ELECTRA model)"),kke.forEach(t),oRo=i(U),B1=n(U,"LI",{});var Ske=s(B1);Vge=n(Ske,"STRONG",{});var T1t=s(Vge);rRo=r(T1t,"flaubert"),T1t.forEach(t),tRo=r(Ske," \u2014 "),CO=n(Ske,"A",{href:!0});var M1t=s(CO);aRo=r(M1t,"FlaubertWithLMHeadModel"),M1t.forEach(t),nRo=r(Ske," (FlauBERT model)"),Ske.forEach(t),sRo=i(U),N1=n(U,"LI",{});var Rke=s(N1);Xge=n(Rke,"STRONG",{});var E1t=s(Xge);lRo=r(E1t,"fnet"),E1t.forEach(t),iRo=r(Rke," \u2014 "),wO=n(Rke,"A",{href:!0});var C1t=s(wO);dRo=r(C1t,"FNetForMaskedLM"),C1t.forEach(t),cRo=r(Rke," (FNet model)"),Rke.forEach(t),fRo=i(U),I1=n(U,"LI",{});var Pke=s(I1);zge=n(Pke,"STRONG",{});var w1t=s(zge);mRo=r(w1t,"funnel"),w1t.forEach(t),gRo=r(Pke," \u2014 "),AO=n(Pke,"A",{href:!0});var A1t=s(AO);hRo=r(A1t,"FunnelForMaskedLM"),A1t.forEach(t),pRo=r(Pke," (Funnel Transformer model)"),Pke.forEach(t),_Ro=i(U),q1=n(U,"LI",{});var Bke=s(q1);Qge=n(Bke,"STRONG",{});var L1t=s(Qge);uRo=r(L1t,"ibert"),L1t.forEach(t),bRo=r(Bke," \u2014 "),LO=n(Bke,"A",{href:!0});var y1t=s(LO);vRo=r(y1t,"IBertForMaskedLM"),y1t.forEach(t),FRo=r(Bke," (I-BERT model)"),Bke.forEach(t),TRo=i(U),j1=n(U,"LI",{});var Nke=s(j1);Wge=n(Nke,"STRONG",{});var x1t=s(Wge);MRo=r(x1t,"layoutlm"),x1t.forEach(t),ERo=r(Nke," \u2014 "),yO=n(Nke,"A",{href:!0});var $1t=s(yO);CRo=r($1t,"LayoutLMForMaskedLM"),$1t.forEach(t),wRo=r(Nke," (LayoutLM model)"),Nke.forEach(t),ARo=i(U),D1=n(U,"LI",{});var Ike=s(D1);Hge=n(Ike,"STRONG",{});var k1t=s(Hge);LRo=r(k1t,"longformer"),k1t.forEach(t),yRo=r(Ike," \u2014 "),xO=n(Ike,"A",{href:!0});var S1t=s(xO);xRo=r(S1t,"LongformerForMaskedLM"),S1t.forEach(t),$Ro=r(Ike," (Longformer model)"),Ike.forEach(t),kRo=i(U),G1=n(U,"LI",{});var qke=s(G1);Uge=n(qke,"STRONG",{});var R1t=s(Uge);SRo=r(R1t,"luke"),R1t.forEach(t),RRo=r(qke," \u2014 "),$O=n(qke,"A",{href:!0});var P1t=s($O);PRo=r(P1t,"LukeForMaskedLM"),P1t.forEach(t),BRo=r(qke," (LUKE model)"),qke.forEach(t),NRo=i(U),O1=n(U,"LI",{});var jke=s(O1);Jge=n(jke,"STRONG",{});var B1t=s(Jge);IRo=r(B1t,"mbart"),B1t.forEach(t),qRo=r(jke," \u2014 "),kO=n(jke,"A",{href:!0});var N1t=s(kO);jRo=r(N1t,"MBartForConditionalGeneration"),N1t.forEach(t),DRo=r(jke," (mBART model)"),jke.forEach(t),GRo=i(U),V1=n(U,"LI",{});var Dke=s(V1);Yge=n(Dke,"STRONG",{});var I1t=s(Yge);ORo=r(I1t,"megatron-bert"),I1t.forEach(t),VRo=r(Dke," \u2014 "),SO=n(Dke,"A",{href:!0});var q1t=s(SO);XRo=r(q1t,"MegatronBertForMaskedLM"),q1t.forEach(t),zRo=r(Dke," (Megatron-BERT model)"),Dke.forEach(t),QRo=i(U),X1=n(U,"LI",{});var Gke=s(X1);Kge=n(Gke,"STRONG",{});var j1t=s(Kge);WRo=r(j1t,"mobilebert"),j1t.forEach(t),HRo=r(Gke," \u2014 "),RO=n(Gke,"A",{href:!0});var D1t=s(RO);URo=r(D1t,"MobileBertForMaskedLM"),D1t.forEach(t),JRo=r(Gke," (MobileBERT model)"),Gke.forEach(t),YRo=i(U),z1=n(U,"LI",{});var Oke=s(z1);Zge=n(Oke,"STRONG",{});var G1t=s(Zge);KRo=r(G1t,"mpnet"),G1t.forEach(t),ZRo=r(Oke," \u2014 "),PO=n(Oke,"A",{href:!0});var O1t=s(PO);ePo=r(O1t,"MPNetForMaskedLM"),O1t.forEach(t),oPo=r(Oke," (MPNet model)"),Oke.forEach(t),rPo=i(U),Q1=n(U,"LI",{});var Vke=s(Q1);ehe=n(Vke,"STRONG",{});var V1t=s(ehe);tPo=r(V1t,"nezha"),V1t.forEach(t),aPo=r(Vke," \u2014 "),BO=n(Vke,"A",{href:!0});var X1t=s(BO);nPo=r(X1t,"NezhaForMaskedLM"),X1t.forEach(t),sPo=r(Vke," (Nezha model)"),Vke.forEach(t),lPo=i(U),W1=n(U,"LI",{});var Xke=s(W1);ohe=n(Xke,"STRONG",{});var z1t=s(ohe);iPo=r(z1t,"nystromformer"),z1t.forEach(t),dPo=r(Xke," \u2014 "),NO=n(Xke,"A",{href:!0});var Q1t=s(NO);cPo=r(Q1t,"NystromformerForMaskedLM"),Q1t.forEach(t),fPo=r(Xke," (Nystr\xF6mformer model)"),Xke.forEach(t),mPo=i(U),H1=n(U,"LI",{});var zke=s(H1);rhe=n(zke,"STRONG",{});var W1t=s(rhe);gPo=r(W1t,"perceiver"),W1t.forEach(t),hPo=r(zke," \u2014 "),IO=n(zke,"A",{href:!0});var H1t=s(IO);pPo=r(H1t,"PerceiverForMaskedLM"),H1t.forEach(t),_Po=r(zke," (Perceiver model)"),zke.forEach(t),uPo=i(U),U1=n(U,"LI",{});var Qke=s(U1);the=n(Qke,"STRONG",{});var U1t=s(the);bPo=r(U1t,"qdqbert"),U1t.forEach(t),vPo=r(Qke," \u2014 "),qO=n(Qke,"A",{href:!0});var J1t=s(qO);FPo=r(J1t,"QDQBertForMaskedLM"),J1t.forEach(t),TPo=r(Qke," (QDQBert model)"),Qke.forEach(t),MPo=i(U),J1=n(U,"LI",{});var Wke=s(J1);ahe=n(Wke,"STRONG",{});var Y1t=s(ahe);EPo=r(Y1t,"reformer"),Y1t.forEach(t),CPo=r(Wke," \u2014 "),jO=n(Wke,"A",{href:!0});var K1t=s(jO);wPo=r(K1t,"ReformerForMaskedLM"),K1t.forEach(t),APo=r(Wke," (Reformer model)"),Wke.forEach(t),LPo=i(U),Y1=n(U,"LI",{});var Hke=s(Y1);nhe=n(Hke,"STRONG",{});var Z1t=s(nhe);yPo=r(Z1t,"rembert"),Z1t.forEach(t),xPo=r(Hke," \u2014 "),DO=n(Hke,"A",{href:!0});var e7t=s(DO);$Po=r(e7t,"RemBertForMaskedLM"),e7t.forEach(t),kPo=r(Hke," (RemBERT model)"),Hke.forEach(t),SPo=i(U),K1=n(U,"LI",{});var Uke=s(K1);she=n(Uke,"STRONG",{});var o7t=s(she);RPo=r(o7t,"roberta"),o7t.forEach(t),PPo=r(Uke," \u2014 "),GO=n(Uke,"A",{href:!0});var r7t=s(GO);BPo=r(r7t,"RobertaForMaskedLM"),r7t.forEach(t),NPo=r(Uke," (RoBERTa model)"),Uke.forEach(t),IPo=i(U),Z1=n(U,"LI",{});var Jke=s(Z1);lhe=n(Jke,"STRONG",{});var t7t=s(lhe);qPo=r(t7t,"roformer"),t7t.forEach(t),jPo=r(Jke," \u2014 "),OO=n(Jke,"A",{href:!0});var a7t=s(OO);DPo=r(a7t,"RoFormerForMaskedLM"),a7t.forEach(t),GPo=r(Jke," (RoFormer model)"),Jke.forEach(t),OPo=i(U),e7=n(U,"LI",{});var Yke=s(e7);ihe=n(Yke,"STRONG",{});var n7t=s(ihe);VPo=r(n7t,"squeezebert"),n7t.forEach(t),XPo=r(Yke," \u2014 "),VO=n(Yke,"A",{href:!0});var s7t=s(VO);zPo=r(s7t,"SqueezeBertForMaskedLM"),s7t.forEach(t),QPo=r(Yke," (SqueezeBERT model)"),Yke.forEach(t),WPo=i(U),o7=n(U,"LI",{});var Kke=s(o7);dhe=n(Kke,"STRONG",{});var l7t=s(dhe);HPo=r(l7t,"tapas"),l7t.forEach(t),UPo=r(Kke," \u2014 "),XO=n(Kke,"A",{href:!0});var i7t=s(XO);JPo=r(i7t,"TapasForMaskedLM"),i7t.forEach(t),YPo=r(Kke," (TAPAS model)"),Kke.forEach(t),KPo=i(U),r7=n(U,"LI",{});var Zke=s(r7);che=n(Zke,"STRONG",{});var d7t=s(che);ZPo=r(d7t,"wav2vec2"),d7t.forEach(t),eBo=r(Zke," \u2014 "),fhe=n(Zke,"CODE",{});var c7t=s(fhe);oBo=r(c7t,"Wav2Vec2ForMaskedLM"),c7t.forEach(t),rBo=r(Zke," (Wav2Vec2 model)"),Zke.forEach(t),tBo=i(U),t7=n(U,"LI",{});var eSe=s(t7);mhe=n(eSe,"STRONG",{});var f7t=s(mhe);aBo=r(f7t,"xlm"),f7t.forEach(t),nBo=r(eSe," \u2014 "),zO=n(eSe,"A",{href:!0});var m7t=s(zO);sBo=r(m7t,"XLMWithLMHeadModel"),m7t.forEach(t),lBo=r(eSe," (XLM model)"),eSe.forEach(t),iBo=i(U),a7=n(U,"LI",{});var oSe=s(a7);ghe=n(oSe,"STRONG",{});var g7t=s(ghe);dBo=r(g7t,"xlm-roberta"),g7t.forEach(t),cBo=r(oSe," \u2014 "),QO=n(oSe,"A",{href:!0});var h7t=s(QO);fBo=r(h7t,"XLMRobertaForMaskedLM"),h7t.forEach(t),mBo=r(oSe," (XLM-RoBERTa model)"),oSe.forEach(t),gBo=i(U),n7=n(U,"LI",{});var rSe=s(n7);hhe=n(rSe,"STRONG",{});var p7t=s(hhe);hBo=r(p7t,"xlm-roberta-xl"),p7t.forEach(t),pBo=r(rSe," \u2014 "),WO=n(rSe,"A",{href:!0});var _7t=s(WO);_Bo=r(_7t,"XLMRobertaXLForMaskedLM"),_7t.forEach(t),uBo=r(rSe," (XLM-RoBERTa-XL model)"),rSe.forEach(t),bBo=i(U),s7=n(U,"LI",{});var tSe=s(s7);phe=n(tSe,"STRONG",{});var u7t=s(phe);vBo=r(u7t,"yoso"),u7t.forEach(t),FBo=r(tSe," \u2014 "),HO=n(tSe,"A",{href:!0});var b7t=s(HO);TBo=r(b7t,"YosoForMaskedLM"),b7t.forEach(t),MBo=r(tSe," (YOSO model)"),tSe.forEach(t),U.forEach(t),EBo=i(ia),l7=n(ia,"P",{});var aSe=s(l7);CBo=r(aSe,"The model is set in evaluation mode by default using "),_he=n(aSe,"CODE",{});var v7t=s(_he);wBo=r(v7t,"model.eval()"),v7t.forEach(t),ABo=r(aSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),uhe=n(aSe,"CODE",{});var F7t=s(uhe);LBo=r(F7t,"model.train()"),F7t.forEach(t),aSe.forEach(t),yBo=i(ia),T(i7.$$.fragment,ia),ia.forEach(t),tl.forEach(t),sVe=i(f),Ji=n(f,"H2",{class:!0});var mze=s(Ji);d7=n(mze,"A",{id:!0,class:!0,href:!0});var T7t=s(d7);bhe=n(T7t,"SPAN",{});var M7t=s(bhe);T(Py.$$.fragment,M7t),M7t.forEach(t),T7t.forEach(t),xBo=i(mze),vhe=n(mze,"SPAN",{});var E7t=s(vhe);$Bo=r(E7t,"AutoModelForSeq2SeqLM"),E7t.forEach(t),mze.forEach(t),lVe=i(f),Ro=n(f,"DIV",{class:!0});var al=s(Ro);T(By.$$.fragment,al),kBo=i(al),Yi=n(al,"P",{});var tre=s(Yi);SBo=r(tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),UO=n(tre,"A",{href:!0});var C7t=s(UO);RBo=r(C7t,"from_pretrained()"),C7t.forEach(t),PBo=r(tre," class method or the "),JO=n(tre,"A",{href:!0});var w7t=s(JO);BBo=r(w7t,"from_config()"),w7t.forEach(t),NBo=r(tre,` class
method.`),tre.forEach(t),IBo=i(al),Ny=n(al,"P",{});var gze=s(Ny);qBo=r(gze,"This class cannot be instantiated directly using "),Fhe=n(gze,"CODE",{});var A7t=s(Fhe);jBo=r(A7t,"__init__()"),A7t.forEach(t),DBo=r(gze," (throws an error)."),gze.forEach(t),GBo=i(al),ct=n(al,"DIV",{class:!0});var ZA=s(ct);T(Iy.$$.fragment,ZA),OBo=i(ZA),The=n(ZA,"P",{});var L7t=s(The);VBo=r(L7t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),L7t.forEach(t),XBo=i(ZA),Ki=n(ZA,"P",{});var are=s(Ki);zBo=r(are,`Note:
Loading a model from its configuration file does `),Mhe=n(are,"STRONG",{});var y7t=s(Mhe);QBo=r(y7t,"not"),y7t.forEach(t),WBo=r(are,` load the model weights. It only affects the
model\u2019s configuration. Use `),YO=n(are,"A",{href:!0});var x7t=s(YO);HBo=r(x7t,"from_pretrained()"),x7t.forEach(t),UBo=r(are," to load the model weights."),are.forEach(t),JBo=i(ZA),T(c7.$$.fragment,ZA),ZA.forEach(t),YBo=i(al),eo=n(al,"DIV",{class:!0});var da=s(eo);T(qy.$$.fragment,da),KBo=i(da),Ehe=n(da,"P",{});var $7t=s(Ehe);ZBo=r($7t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),$7t.forEach(t),eNo=i(da),ja=n(da,"P",{});var e6=s(ja);oNo=r(e6,"The model class to instantiate is selected based on the "),Che=n(e6,"CODE",{});var k7t=s(Che);rNo=r(k7t,"model_type"),k7t.forEach(t),tNo=r(e6,` property of the config object (either
passed as an argument or loaded from `),whe=n(e6,"CODE",{});var S7t=s(whe);aNo=r(S7t,"pretrained_model_name_or_path"),S7t.forEach(t),nNo=r(e6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ahe=n(e6,"CODE",{});var R7t=s(Ahe);sNo=r(R7t,"pretrained_model_name_or_path"),R7t.forEach(t),lNo=r(e6,":"),e6.forEach(t),iNo=i(da),pe=n(da,"UL",{});var be=s(pe);f7=n(be,"LI",{});var nSe=s(f7);Lhe=n(nSe,"STRONG",{});var P7t=s(Lhe);dNo=r(P7t,"bart"),P7t.forEach(t),cNo=r(nSe," \u2014 "),KO=n(nSe,"A",{href:!0});var B7t=s(KO);fNo=r(B7t,"BartForConditionalGeneration"),B7t.forEach(t),mNo=r(nSe," (BART model)"),nSe.forEach(t),gNo=i(be),m7=n(be,"LI",{});var sSe=s(m7);yhe=n(sSe,"STRONG",{});var N7t=s(yhe);hNo=r(N7t,"bigbird_pegasus"),N7t.forEach(t),pNo=r(sSe," \u2014 "),ZO=n(sSe,"A",{href:!0});var I7t=s(ZO);_No=r(I7t,"BigBirdPegasusForConditionalGeneration"),I7t.forEach(t),uNo=r(sSe," (BigBird-Pegasus model)"),sSe.forEach(t),bNo=i(be),g7=n(be,"LI",{});var lSe=s(g7);xhe=n(lSe,"STRONG",{});var q7t=s(xhe);vNo=r(q7t,"blenderbot"),q7t.forEach(t),FNo=r(lSe," \u2014 "),eV=n(lSe,"A",{href:!0});var j7t=s(eV);TNo=r(j7t,"BlenderbotForConditionalGeneration"),j7t.forEach(t),MNo=r(lSe," (Blenderbot model)"),lSe.forEach(t),ENo=i(be),h7=n(be,"LI",{});var iSe=s(h7);$he=n(iSe,"STRONG",{});var D7t=s($he);CNo=r(D7t,"blenderbot-small"),D7t.forEach(t),wNo=r(iSe," \u2014 "),oV=n(iSe,"A",{href:!0});var G7t=s(oV);ANo=r(G7t,"BlenderbotSmallForConditionalGeneration"),G7t.forEach(t),LNo=r(iSe," (BlenderbotSmall model)"),iSe.forEach(t),yNo=i(be),p7=n(be,"LI",{});var dSe=s(p7);khe=n(dSe,"STRONG",{});var O7t=s(khe);xNo=r(O7t,"encoder-decoder"),O7t.forEach(t),$No=r(dSe," \u2014 "),rV=n(dSe,"A",{href:!0});var V7t=s(rV);kNo=r(V7t,"EncoderDecoderModel"),V7t.forEach(t),SNo=r(dSe," (Encoder decoder model)"),dSe.forEach(t),RNo=i(be),_7=n(be,"LI",{});var cSe=s(_7);She=n(cSe,"STRONG",{});var X7t=s(She);PNo=r(X7t,"fsmt"),X7t.forEach(t),BNo=r(cSe," \u2014 "),tV=n(cSe,"A",{href:!0});var z7t=s(tV);NNo=r(z7t,"FSMTForConditionalGeneration"),z7t.forEach(t),INo=r(cSe," (FairSeq Machine-Translation model)"),cSe.forEach(t),qNo=i(be),u7=n(be,"LI",{});var fSe=s(u7);Rhe=n(fSe,"STRONG",{});var Q7t=s(Rhe);jNo=r(Q7t,"led"),Q7t.forEach(t),DNo=r(fSe," \u2014 "),aV=n(fSe,"A",{href:!0});var W7t=s(aV);GNo=r(W7t,"LEDForConditionalGeneration"),W7t.forEach(t),ONo=r(fSe," (LED model)"),fSe.forEach(t),VNo=i(be),b7=n(be,"LI",{});var mSe=s(b7);Phe=n(mSe,"STRONG",{});var H7t=s(Phe);XNo=r(H7t,"longt5"),H7t.forEach(t),zNo=r(mSe," \u2014 "),nV=n(mSe,"A",{href:!0});var U7t=s(nV);QNo=r(U7t,"LongT5ForConditionalGeneration"),U7t.forEach(t),WNo=r(mSe," (LongT5 model)"),mSe.forEach(t),HNo=i(be),v7=n(be,"LI",{});var gSe=s(v7);Bhe=n(gSe,"STRONG",{});var J7t=s(Bhe);UNo=r(J7t,"m2m_100"),J7t.forEach(t),JNo=r(gSe," \u2014 "),sV=n(gSe,"A",{href:!0});var Y7t=s(sV);YNo=r(Y7t,"M2M100ForConditionalGeneration"),Y7t.forEach(t),KNo=r(gSe," (M2M100 model)"),gSe.forEach(t),ZNo=i(be),F7=n(be,"LI",{});var hSe=s(F7);Nhe=n(hSe,"STRONG",{});var K7t=s(Nhe);eIo=r(K7t,"marian"),K7t.forEach(t),oIo=r(hSe," \u2014 "),lV=n(hSe,"A",{href:!0});var Z7t=s(lV);rIo=r(Z7t,"MarianMTModel"),Z7t.forEach(t),tIo=r(hSe," (Marian model)"),hSe.forEach(t),aIo=i(be),T7=n(be,"LI",{});var pSe=s(T7);Ihe=n(pSe,"STRONG",{});var e4t=s(Ihe);nIo=r(e4t,"mbart"),e4t.forEach(t),sIo=r(pSe," \u2014 "),iV=n(pSe,"A",{href:!0});var o4t=s(iV);lIo=r(o4t,"MBartForConditionalGeneration"),o4t.forEach(t),iIo=r(pSe," (mBART model)"),pSe.forEach(t),dIo=i(be),M7=n(be,"LI",{});var _Se=s(M7);qhe=n(_Se,"STRONG",{});var r4t=s(qhe);cIo=r(r4t,"mt5"),r4t.forEach(t),fIo=r(_Se," \u2014 "),dV=n(_Se,"A",{href:!0});var t4t=s(dV);mIo=r(t4t,"MT5ForConditionalGeneration"),t4t.forEach(t),gIo=r(_Se," (MT5 model)"),_Se.forEach(t),hIo=i(be),E7=n(be,"LI",{});var uSe=s(E7);jhe=n(uSe,"STRONG",{});var a4t=s(jhe);pIo=r(a4t,"pegasus"),a4t.forEach(t),_Io=r(uSe," \u2014 "),cV=n(uSe,"A",{href:!0});var n4t=s(cV);uIo=r(n4t,"PegasusForConditionalGeneration"),n4t.forEach(t),bIo=r(uSe," (Pegasus model)"),uSe.forEach(t),vIo=i(be),C7=n(be,"LI",{});var bSe=s(C7);Dhe=n(bSe,"STRONG",{});var s4t=s(Dhe);FIo=r(s4t,"plbart"),s4t.forEach(t),TIo=r(bSe," \u2014 "),fV=n(bSe,"A",{href:!0});var l4t=s(fV);MIo=r(l4t,"PLBartForConditionalGeneration"),l4t.forEach(t),EIo=r(bSe," (PLBart model)"),bSe.forEach(t),CIo=i(be),w7=n(be,"LI",{});var vSe=s(w7);Ghe=n(vSe,"STRONG",{});var i4t=s(Ghe);wIo=r(i4t,"prophetnet"),i4t.forEach(t),AIo=r(vSe," \u2014 "),mV=n(vSe,"A",{href:!0});var d4t=s(mV);LIo=r(d4t,"ProphetNetForConditionalGeneration"),d4t.forEach(t),yIo=r(vSe," (ProphetNet model)"),vSe.forEach(t),xIo=i(be),A7=n(be,"LI",{});var FSe=s(A7);Ohe=n(FSe,"STRONG",{});var c4t=s(Ohe);$Io=r(c4t,"t5"),c4t.forEach(t),kIo=r(FSe," \u2014 "),gV=n(FSe,"A",{href:!0});var f4t=s(gV);SIo=r(f4t,"T5ForConditionalGeneration"),f4t.forEach(t),RIo=r(FSe," (T5 model)"),FSe.forEach(t),PIo=i(be),L7=n(be,"LI",{});var TSe=s(L7);Vhe=n(TSe,"STRONG",{});var m4t=s(Vhe);BIo=r(m4t,"xlm-prophetnet"),m4t.forEach(t),NIo=r(TSe," \u2014 "),hV=n(TSe,"A",{href:!0});var g4t=s(hV);IIo=r(g4t,"XLMProphetNetForConditionalGeneration"),g4t.forEach(t),qIo=r(TSe," (XLM-ProphetNet model)"),TSe.forEach(t),be.forEach(t),jIo=i(da),y7=n(da,"P",{});var MSe=s(y7);DIo=r(MSe,"The model is set in evaluation mode by default using "),Xhe=n(MSe,"CODE",{});var h4t=s(Xhe);GIo=r(h4t,"model.eval()"),h4t.forEach(t),OIo=r(MSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zhe=n(MSe,"CODE",{});var p4t=s(zhe);VIo=r(p4t,"model.train()"),p4t.forEach(t),MSe.forEach(t),XIo=i(da),T(x7.$$.fragment,da),da.forEach(t),al.forEach(t),iVe=i(f),Zi=n(f,"H2",{class:!0});var hze=s(Zi);$7=n(hze,"A",{id:!0,class:!0,href:!0});var _4t=s($7);Qhe=n(_4t,"SPAN",{});var u4t=s(Qhe);T(jy.$$.fragment,u4t),u4t.forEach(t),_4t.forEach(t),zIo=i(hze),Whe=n(hze,"SPAN",{});var b4t=s(Whe);QIo=r(b4t,"AutoModelForSequenceClassification"),b4t.forEach(t),hze.forEach(t),dVe=i(f),Po=n(f,"DIV",{class:!0});var nl=s(Po);T(Dy.$$.fragment,nl),WIo=i(nl),ed=n(nl,"P",{});var nre=s(ed);HIo=r(nre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pV=n(nre,"A",{href:!0});var v4t=s(pV);UIo=r(v4t,"from_pretrained()"),v4t.forEach(t),JIo=r(nre," class method or the "),_V=n(nre,"A",{href:!0});var F4t=s(_V);YIo=r(F4t,"from_config()"),F4t.forEach(t),KIo=r(nre,` class
method.`),nre.forEach(t),ZIo=i(nl),Gy=n(nl,"P",{});var pze=s(Gy);eqo=r(pze,"This class cannot be instantiated directly using "),Hhe=n(pze,"CODE",{});var T4t=s(Hhe);oqo=r(T4t,"__init__()"),T4t.forEach(t),rqo=r(pze," (throws an error)."),pze.forEach(t),tqo=i(nl),ft=n(nl,"DIV",{class:!0});var o6=s(ft);T(Oy.$$.fragment,o6),aqo=i(o6),Uhe=n(o6,"P",{});var M4t=s(Uhe);nqo=r(M4t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),M4t.forEach(t),sqo=i(o6),od=n(o6,"P",{});var sre=s(od);lqo=r(sre,`Note:
Loading a model from its configuration file does `),Jhe=n(sre,"STRONG",{});var E4t=s(Jhe);iqo=r(E4t,"not"),E4t.forEach(t),dqo=r(sre,` load the model weights. It only affects the
model\u2019s configuration. Use `),uV=n(sre,"A",{href:!0});var C4t=s(uV);cqo=r(C4t,"from_pretrained()"),C4t.forEach(t),fqo=r(sre," to load the model weights."),sre.forEach(t),mqo=i(o6),T(k7.$$.fragment,o6),o6.forEach(t),gqo=i(nl),oo=n(nl,"DIV",{class:!0});var ca=s(oo);T(Vy.$$.fragment,ca),hqo=i(ca),Yhe=n(ca,"P",{});var w4t=s(Yhe);pqo=r(w4t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),w4t.forEach(t),_qo=i(ca),Da=n(ca,"P",{});var r6=s(Da);uqo=r(r6,"The model class to instantiate is selected based on the "),Khe=n(r6,"CODE",{});var A4t=s(Khe);bqo=r(A4t,"model_type"),A4t.forEach(t),vqo=r(r6,` property of the config object (either
passed as an argument or loaded from `),Zhe=n(r6,"CODE",{});var L4t=s(Zhe);Fqo=r(L4t,"pretrained_model_name_or_path"),L4t.forEach(t),Tqo=r(r6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),epe=n(r6,"CODE",{});var y4t=s(epe);Mqo=r(y4t,"pretrained_model_name_or_path"),y4t.forEach(t),Eqo=r(r6,":"),r6.forEach(t),Cqo=i(ca),I=n(ca,"UL",{});var j=s(I);S7=n(j,"LI",{});var ESe=s(S7);ope=n(ESe,"STRONG",{});var x4t=s(ope);wqo=r(x4t,"albert"),x4t.forEach(t),Aqo=r(ESe," \u2014 "),bV=n(ESe,"A",{href:!0});var $4t=s(bV);Lqo=r($4t,"AlbertForSequenceClassification"),$4t.forEach(t),yqo=r(ESe," (ALBERT model)"),ESe.forEach(t),xqo=i(j),R7=n(j,"LI",{});var CSe=s(R7);rpe=n(CSe,"STRONG",{});var k4t=s(rpe);$qo=r(k4t,"bart"),k4t.forEach(t),kqo=r(CSe," \u2014 "),vV=n(CSe,"A",{href:!0});var S4t=s(vV);Sqo=r(S4t,"BartForSequenceClassification"),S4t.forEach(t),Rqo=r(CSe," (BART model)"),CSe.forEach(t),Pqo=i(j),P7=n(j,"LI",{});var wSe=s(P7);tpe=n(wSe,"STRONG",{});var R4t=s(tpe);Bqo=r(R4t,"bert"),R4t.forEach(t),Nqo=r(wSe," \u2014 "),FV=n(wSe,"A",{href:!0});var P4t=s(FV);Iqo=r(P4t,"BertForSequenceClassification"),P4t.forEach(t),qqo=r(wSe," (BERT model)"),wSe.forEach(t),jqo=i(j),B7=n(j,"LI",{});var ASe=s(B7);ape=n(ASe,"STRONG",{});var B4t=s(ape);Dqo=r(B4t,"big_bird"),B4t.forEach(t),Gqo=r(ASe," \u2014 "),TV=n(ASe,"A",{href:!0});var N4t=s(TV);Oqo=r(N4t,"BigBirdForSequenceClassification"),N4t.forEach(t),Vqo=r(ASe," (BigBird model)"),ASe.forEach(t),Xqo=i(j),N7=n(j,"LI",{});var LSe=s(N7);npe=n(LSe,"STRONG",{});var I4t=s(npe);zqo=r(I4t,"bigbird_pegasus"),I4t.forEach(t),Qqo=r(LSe," \u2014 "),MV=n(LSe,"A",{href:!0});var q4t=s(MV);Wqo=r(q4t,"BigBirdPegasusForSequenceClassification"),q4t.forEach(t),Hqo=r(LSe," (BigBird-Pegasus model)"),LSe.forEach(t),Uqo=i(j),I7=n(j,"LI",{});var ySe=s(I7);spe=n(ySe,"STRONG",{});var j4t=s(spe);Jqo=r(j4t,"bloom"),j4t.forEach(t),Yqo=r(ySe," \u2014 "),EV=n(ySe,"A",{href:!0});var D4t=s(EV);Kqo=r(D4t,"BloomForSequenceClassification"),D4t.forEach(t),Zqo=r(ySe," (BLOOM model)"),ySe.forEach(t),ejo=i(j),q7=n(j,"LI",{});var xSe=s(q7);lpe=n(xSe,"STRONG",{});var G4t=s(lpe);ojo=r(G4t,"camembert"),G4t.forEach(t),rjo=r(xSe," \u2014 "),CV=n(xSe,"A",{href:!0});var O4t=s(CV);tjo=r(O4t,"CamembertForSequenceClassification"),O4t.forEach(t),ajo=r(xSe," (CamemBERT model)"),xSe.forEach(t),njo=i(j),j7=n(j,"LI",{});var $Se=s(j7);ipe=n($Se,"STRONG",{});var V4t=s(ipe);sjo=r(V4t,"canine"),V4t.forEach(t),ljo=r($Se," \u2014 "),wV=n($Se,"A",{href:!0});var X4t=s(wV);ijo=r(X4t,"CanineForSequenceClassification"),X4t.forEach(t),djo=r($Se," (CANINE model)"),$Se.forEach(t),cjo=i(j),D7=n(j,"LI",{});var kSe=s(D7);dpe=n(kSe,"STRONG",{});var z4t=s(dpe);fjo=r(z4t,"convbert"),z4t.forEach(t),mjo=r(kSe," \u2014 "),AV=n(kSe,"A",{href:!0});var Q4t=s(AV);gjo=r(Q4t,"ConvBertForSequenceClassification"),Q4t.forEach(t),hjo=r(kSe," (ConvBERT model)"),kSe.forEach(t),pjo=i(j),G7=n(j,"LI",{});var SSe=s(G7);cpe=n(SSe,"STRONG",{});var W4t=s(cpe);_jo=r(W4t,"ctrl"),W4t.forEach(t),ujo=r(SSe," \u2014 "),LV=n(SSe,"A",{href:!0});var H4t=s(LV);bjo=r(H4t,"CTRLForSequenceClassification"),H4t.forEach(t),vjo=r(SSe," (CTRL model)"),SSe.forEach(t),Fjo=i(j),O7=n(j,"LI",{});var RSe=s(O7);fpe=n(RSe,"STRONG",{});var U4t=s(fpe);Tjo=r(U4t,"data2vec-text"),U4t.forEach(t),Mjo=r(RSe," \u2014 "),yV=n(RSe,"A",{href:!0});var J4t=s(yV);Ejo=r(J4t,"Data2VecTextForSequenceClassification"),J4t.forEach(t),Cjo=r(RSe," (Data2VecText model)"),RSe.forEach(t),wjo=i(j),V7=n(j,"LI",{});var PSe=s(V7);mpe=n(PSe,"STRONG",{});var Y4t=s(mpe);Ajo=r(Y4t,"deberta"),Y4t.forEach(t),Ljo=r(PSe," \u2014 "),xV=n(PSe,"A",{href:!0});var K4t=s(xV);yjo=r(K4t,"DebertaForSequenceClassification"),K4t.forEach(t),xjo=r(PSe," (DeBERTa model)"),PSe.forEach(t),$jo=i(j),X7=n(j,"LI",{});var BSe=s(X7);gpe=n(BSe,"STRONG",{});var Z4t=s(gpe);kjo=r(Z4t,"deberta-v2"),Z4t.forEach(t),Sjo=r(BSe," \u2014 "),$V=n(BSe,"A",{href:!0});var ebt=s($V);Rjo=r(ebt,"DebertaV2ForSequenceClassification"),ebt.forEach(t),Pjo=r(BSe," (DeBERTa-v2 model)"),BSe.forEach(t),Bjo=i(j),z7=n(j,"LI",{});var NSe=s(z7);hpe=n(NSe,"STRONG",{});var obt=s(hpe);Njo=r(obt,"distilbert"),obt.forEach(t),Ijo=r(NSe," \u2014 "),kV=n(NSe,"A",{href:!0});var rbt=s(kV);qjo=r(rbt,"DistilBertForSequenceClassification"),rbt.forEach(t),jjo=r(NSe," (DistilBERT model)"),NSe.forEach(t),Djo=i(j),Q7=n(j,"LI",{});var ISe=s(Q7);ppe=n(ISe,"STRONG",{});var tbt=s(ppe);Gjo=r(tbt,"electra"),tbt.forEach(t),Ojo=r(ISe," \u2014 "),SV=n(ISe,"A",{href:!0});var abt=s(SV);Vjo=r(abt,"ElectraForSequenceClassification"),abt.forEach(t),Xjo=r(ISe," (ELECTRA model)"),ISe.forEach(t),zjo=i(j),W7=n(j,"LI",{});var qSe=s(W7);_pe=n(qSe,"STRONG",{});var nbt=s(_pe);Qjo=r(nbt,"flaubert"),nbt.forEach(t),Wjo=r(qSe," \u2014 "),RV=n(qSe,"A",{href:!0});var sbt=s(RV);Hjo=r(sbt,"FlaubertForSequenceClassification"),sbt.forEach(t),Ujo=r(qSe," (FlauBERT model)"),qSe.forEach(t),Jjo=i(j),H7=n(j,"LI",{});var jSe=s(H7);upe=n(jSe,"STRONG",{});var lbt=s(upe);Yjo=r(lbt,"fnet"),lbt.forEach(t),Kjo=r(jSe," \u2014 "),PV=n(jSe,"A",{href:!0});var ibt=s(PV);Zjo=r(ibt,"FNetForSequenceClassification"),ibt.forEach(t),eDo=r(jSe," (FNet model)"),jSe.forEach(t),oDo=i(j),U7=n(j,"LI",{});var DSe=s(U7);bpe=n(DSe,"STRONG",{});var dbt=s(bpe);rDo=r(dbt,"funnel"),dbt.forEach(t),tDo=r(DSe," \u2014 "),BV=n(DSe,"A",{href:!0});var cbt=s(BV);aDo=r(cbt,"FunnelForSequenceClassification"),cbt.forEach(t),nDo=r(DSe," (Funnel Transformer model)"),DSe.forEach(t),sDo=i(j),J7=n(j,"LI",{});var GSe=s(J7);vpe=n(GSe,"STRONG",{});var fbt=s(vpe);lDo=r(fbt,"gpt2"),fbt.forEach(t),iDo=r(GSe," \u2014 "),NV=n(GSe,"A",{href:!0});var mbt=s(NV);dDo=r(mbt,"GPT2ForSequenceClassification"),mbt.forEach(t),cDo=r(GSe," (OpenAI GPT-2 model)"),GSe.forEach(t),fDo=i(j),Y7=n(j,"LI",{});var OSe=s(Y7);Fpe=n(OSe,"STRONG",{});var gbt=s(Fpe);mDo=r(gbt,"gpt_neo"),gbt.forEach(t),gDo=r(OSe," \u2014 "),IV=n(OSe,"A",{href:!0});var hbt=s(IV);hDo=r(hbt,"GPTNeoForSequenceClassification"),hbt.forEach(t),pDo=r(OSe," (GPT Neo model)"),OSe.forEach(t),_Do=i(j),K7=n(j,"LI",{});var VSe=s(K7);Tpe=n(VSe,"STRONG",{});var pbt=s(Tpe);uDo=r(pbt,"gptj"),pbt.forEach(t),bDo=r(VSe," \u2014 "),qV=n(VSe,"A",{href:!0});var _bt=s(qV);vDo=r(_bt,"GPTJForSequenceClassification"),_bt.forEach(t),FDo=r(VSe," (GPT-J model)"),VSe.forEach(t),TDo=i(j),Z7=n(j,"LI",{});var XSe=s(Z7);Mpe=n(XSe,"STRONG",{});var ubt=s(Mpe);MDo=r(ubt,"ibert"),ubt.forEach(t),EDo=r(XSe," \u2014 "),jV=n(XSe,"A",{href:!0});var bbt=s(jV);CDo=r(bbt,"IBertForSequenceClassification"),bbt.forEach(t),wDo=r(XSe," (I-BERT model)"),XSe.forEach(t),ADo=i(j),e4=n(j,"LI",{});var zSe=s(e4);Epe=n(zSe,"STRONG",{});var vbt=s(Epe);LDo=r(vbt,"layoutlm"),vbt.forEach(t),yDo=r(zSe," \u2014 "),DV=n(zSe,"A",{href:!0});var Fbt=s(DV);xDo=r(Fbt,"LayoutLMForSequenceClassification"),Fbt.forEach(t),$Do=r(zSe," (LayoutLM model)"),zSe.forEach(t),kDo=i(j),o4=n(j,"LI",{});var QSe=s(o4);Cpe=n(QSe,"STRONG",{});var Tbt=s(Cpe);SDo=r(Tbt,"layoutlmv2"),Tbt.forEach(t),RDo=r(QSe," \u2014 "),GV=n(QSe,"A",{href:!0});var Mbt=s(GV);PDo=r(Mbt,"LayoutLMv2ForSequenceClassification"),Mbt.forEach(t),BDo=r(QSe," (LayoutLMv2 model)"),QSe.forEach(t),NDo=i(j),r4=n(j,"LI",{});var WSe=s(r4);wpe=n(WSe,"STRONG",{});var Ebt=s(wpe);IDo=r(Ebt,"layoutlmv3"),Ebt.forEach(t),qDo=r(WSe," \u2014 "),OV=n(WSe,"A",{href:!0});var Cbt=s(OV);jDo=r(Cbt,"LayoutLMv3ForSequenceClassification"),Cbt.forEach(t),DDo=r(WSe," (LayoutLMv3 model)"),WSe.forEach(t),GDo=i(j),t4=n(j,"LI",{});var HSe=s(t4);Ape=n(HSe,"STRONG",{});var wbt=s(Ape);ODo=r(wbt,"led"),wbt.forEach(t),VDo=r(HSe," \u2014 "),VV=n(HSe,"A",{href:!0});var Abt=s(VV);XDo=r(Abt,"LEDForSequenceClassification"),Abt.forEach(t),zDo=r(HSe," (LED model)"),HSe.forEach(t),QDo=i(j),a4=n(j,"LI",{});var USe=s(a4);Lpe=n(USe,"STRONG",{});var Lbt=s(Lpe);WDo=r(Lbt,"longformer"),Lbt.forEach(t),HDo=r(USe," \u2014 "),XV=n(USe,"A",{href:!0});var ybt=s(XV);UDo=r(ybt,"LongformerForSequenceClassification"),ybt.forEach(t),JDo=r(USe," (Longformer model)"),USe.forEach(t),YDo=i(j),n4=n(j,"LI",{});var JSe=s(n4);ype=n(JSe,"STRONG",{});var xbt=s(ype);KDo=r(xbt,"mbart"),xbt.forEach(t),ZDo=r(JSe," \u2014 "),zV=n(JSe,"A",{href:!0});var $bt=s(zV);eGo=r($bt,"MBartForSequenceClassification"),$bt.forEach(t),oGo=r(JSe," (mBART model)"),JSe.forEach(t),rGo=i(j),s4=n(j,"LI",{});var YSe=s(s4);xpe=n(YSe,"STRONG",{});var kbt=s(xpe);tGo=r(kbt,"megatron-bert"),kbt.forEach(t),aGo=r(YSe," \u2014 "),QV=n(YSe,"A",{href:!0});var Sbt=s(QV);nGo=r(Sbt,"MegatronBertForSequenceClassification"),Sbt.forEach(t),sGo=r(YSe," (Megatron-BERT model)"),YSe.forEach(t),lGo=i(j),l4=n(j,"LI",{});var KSe=s(l4);$pe=n(KSe,"STRONG",{});var Rbt=s($pe);iGo=r(Rbt,"mobilebert"),Rbt.forEach(t),dGo=r(KSe," \u2014 "),WV=n(KSe,"A",{href:!0});var Pbt=s(WV);cGo=r(Pbt,"MobileBertForSequenceClassification"),Pbt.forEach(t),fGo=r(KSe," (MobileBERT model)"),KSe.forEach(t),mGo=i(j),i4=n(j,"LI",{});var ZSe=s(i4);kpe=n(ZSe,"STRONG",{});var Bbt=s(kpe);gGo=r(Bbt,"mpnet"),Bbt.forEach(t),hGo=r(ZSe," \u2014 "),HV=n(ZSe,"A",{href:!0});var Nbt=s(HV);pGo=r(Nbt,"MPNetForSequenceClassification"),Nbt.forEach(t),_Go=r(ZSe," (MPNet model)"),ZSe.forEach(t),uGo=i(j),d4=n(j,"LI",{});var eRe=s(d4);Spe=n(eRe,"STRONG",{});var Ibt=s(Spe);bGo=r(Ibt,"nezha"),Ibt.forEach(t),vGo=r(eRe," \u2014 "),UV=n(eRe,"A",{href:!0});var qbt=s(UV);FGo=r(qbt,"NezhaForSequenceClassification"),qbt.forEach(t),TGo=r(eRe," (Nezha model)"),eRe.forEach(t),MGo=i(j),c4=n(j,"LI",{});var oRe=s(c4);Rpe=n(oRe,"STRONG",{});var jbt=s(Rpe);EGo=r(jbt,"nystromformer"),jbt.forEach(t),CGo=r(oRe," \u2014 "),JV=n(oRe,"A",{href:!0});var Dbt=s(JV);wGo=r(Dbt,"NystromformerForSequenceClassification"),Dbt.forEach(t),AGo=r(oRe," (Nystr\xF6mformer model)"),oRe.forEach(t),LGo=i(j),f4=n(j,"LI",{});var rRe=s(f4);Ppe=n(rRe,"STRONG",{});var Gbt=s(Ppe);yGo=r(Gbt,"openai-gpt"),Gbt.forEach(t),xGo=r(rRe," \u2014 "),YV=n(rRe,"A",{href:!0});var Obt=s(YV);$Go=r(Obt,"OpenAIGPTForSequenceClassification"),Obt.forEach(t),kGo=r(rRe," (OpenAI GPT model)"),rRe.forEach(t),SGo=i(j),m4=n(j,"LI",{});var tRe=s(m4);Bpe=n(tRe,"STRONG",{});var Vbt=s(Bpe);RGo=r(Vbt,"perceiver"),Vbt.forEach(t),PGo=r(tRe," \u2014 "),KV=n(tRe,"A",{href:!0});var Xbt=s(KV);BGo=r(Xbt,"PerceiverForSequenceClassification"),Xbt.forEach(t),NGo=r(tRe," (Perceiver model)"),tRe.forEach(t),IGo=i(j),g4=n(j,"LI",{});var aRe=s(g4);Npe=n(aRe,"STRONG",{});var zbt=s(Npe);qGo=r(zbt,"plbart"),zbt.forEach(t),jGo=r(aRe," \u2014 "),ZV=n(aRe,"A",{href:!0});var Qbt=s(ZV);DGo=r(Qbt,"PLBartForSequenceClassification"),Qbt.forEach(t),GGo=r(aRe," (PLBart model)"),aRe.forEach(t),OGo=i(j),h4=n(j,"LI",{});var nRe=s(h4);Ipe=n(nRe,"STRONG",{});var Wbt=s(Ipe);VGo=r(Wbt,"qdqbert"),Wbt.forEach(t),XGo=r(nRe," \u2014 "),eX=n(nRe,"A",{href:!0});var Hbt=s(eX);zGo=r(Hbt,"QDQBertForSequenceClassification"),Hbt.forEach(t),QGo=r(nRe," (QDQBert model)"),nRe.forEach(t),WGo=i(j),p4=n(j,"LI",{});var sRe=s(p4);qpe=n(sRe,"STRONG",{});var Ubt=s(qpe);HGo=r(Ubt,"reformer"),Ubt.forEach(t),UGo=r(sRe," \u2014 "),oX=n(sRe,"A",{href:!0});var Jbt=s(oX);JGo=r(Jbt,"ReformerForSequenceClassification"),Jbt.forEach(t),YGo=r(sRe," (Reformer model)"),sRe.forEach(t),KGo=i(j),_4=n(j,"LI",{});var lRe=s(_4);jpe=n(lRe,"STRONG",{});var Ybt=s(jpe);ZGo=r(Ybt,"rembert"),Ybt.forEach(t),eOo=r(lRe," \u2014 "),rX=n(lRe,"A",{href:!0});var Kbt=s(rX);oOo=r(Kbt,"RemBertForSequenceClassification"),Kbt.forEach(t),rOo=r(lRe," (RemBERT model)"),lRe.forEach(t),tOo=i(j),u4=n(j,"LI",{});var iRe=s(u4);Dpe=n(iRe,"STRONG",{});var Zbt=s(Dpe);aOo=r(Zbt,"roberta"),Zbt.forEach(t),nOo=r(iRe," \u2014 "),tX=n(iRe,"A",{href:!0});var evt=s(tX);sOo=r(evt,"RobertaForSequenceClassification"),evt.forEach(t),lOo=r(iRe," (RoBERTa model)"),iRe.forEach(t),iOo=i(j),b4=n(j,"LI",{});var dRe=s(b4);Gpe=n(dRe,"STRONG",{});var ovt=s(Gpe);dOo=r(ovt,"roformer"),ovt.forEach(t),cOo=r(dRe," \u2014 "),aX=n(dRe,"A",{href:!0});var rvt=s(aX);fOo=r(rvt,"RoFormerForSequenceClassification"),rvt.forEach(t),mOo=r(dRe," (RoFormer model)"),dRe.forEach(t),gOo=i(j),v4=n(j,"LI",{});var cRe=s(v4);Ope=n(cRe,"STRONG",{});var tvt=s(Ope);hOo=r(tvt,"squeezebert"),tvt.forEach(t),pOo=r(cRe," \u2014 "),nX=n(cRe,"A",{href:!0});var avt=s(nX);_Oo=r(avt,"SqueezeBertForSequenceClassification"),avt.forEach(t),uOo=r(cRe," (SqueezeBERT model)"),cRe.forEach(t),bOo=i(j),F4=n(j,"LI",{});var fRe=s(F4);Vpe=n(fRe,"STRONG",{});var nvt=s(Vpe);vOo=r(nvt,"tapas"),nvt.forEach(t),FOo=r(fRe," \u2014 "),sX=n(fRe,"A",{href:!0});var svt=s(sX);TOo=r(svt,"TapasForSequenceClassification"),svt.forEach(t),MOo=r(fRe," (TAPAS model)"),fRe.forEach(t),EOo=i(j),T4=n(j,"LI",{});var mRe=s(T4);Xpe=n(mRe,"STRONG",{});var lvt=s(Xpe);COo=r(lvt,"transfo-xl"),lvt.forEach(t),wOo=r(mRe," \u2014 "),lX=n(mRe,"A",{href:!0});var ivt=s(lX);AOo=r(ivt,"TransfoXLForSequenceClassification"),ivt.forEach(t),LOo=r(mRe," (Transformer-XL model)"),mRe.forEach(t),yOo=i(j),M4=n(j,"LI",{});var gRe=s(M4);zpe=n(gRe,"STRONG",{});var dvt=s(zpe);xOo=r(dvt,"xlm"),dvt.forEach(t),$Oo=r(gRe," \u2014 "),iX=n(gRe,"A",{href:!0});var cvt=s(iX);kOo=r(cvt,"XLMForSequenceClassification"),cvt.forEach(t),SOo=r(gRe," (XLM model)"),gRe.forEach(t),ROo=i(j),E4=n(j,"LI",{});var hRe=s(E4);Qpe=n(hRe,"STRONG",{});var fvt=s(Qpe);POo=r(fvt,"xlm-roberta"),fvt.forEach(t),BOo=r(hRe," \u2014 "),dX=n(hRe,"A",{href:!0});var mvt=s(dX);NOo=r(mvt,"XLMRobertaForSequenceClassification"),mvt.forEach(t),IOo=r(hRe," (XLM-RoBERTa model)"),hRe.forEach(t),qOo=i(j),C4=n(j,"LI",{});var pRe=s(C4);Wpe=n(pRe,"STRONG",{});var gvt=s(Wpe);jOo=r(gvt,"xlm-roberta-xl"),gvt.forEach(t),DOo=r(pRe," \u2014 "),cX=n(pRe,"A",{href:!0});var hvt=s(cX);GOo=r(hvt,"XLMRobertaXLForSequenceClassification"),hvt.forEach(t),OOo=r(pRe," (XLM-RoBERTa-XL model)"),pRe.forEach(t),VOo=i(j),w4=n(j,"LI",{});var _Re=s(w4);Hpe=n(_Re,"STRONG",{});var pvt=s(Hpe);XOo=r(pvt,"xlnet"),pvt.forEach(t),zOo=r(_Re," \u2014 "),fX=n(_Re,"A",{href:!0});var _vt=s(fX);QOo=r(_vt,"XLNetForSequenceClassification"),_vt.forEach(t),WOo=r(_Re," (XLNet model)"),_Re.forEach(t),HOo=i(j),A4=n(j,"LI",{});var uRe=s(A4);Upe=n(uRe,"STRONG",{});var uvt=s(Upe);UOo=r(uvt,"yoso"),uvt.forEach(t),JOo=r(uRe," \u2014 "),mX=n(uRe,"A",{href:!0});var bvt=s(mX);YOo=r(bvt,"YosoForSequenceClassification"),bvt.forEach(t),KOo=r(uRe," (YOSO model)"),uRe.forEach(t),j.forEach(t),ZOo=i(ca),L4=n(ca,"P",{});var bRe=s(L4);eVo=r(bRe,"The model is set in evaluation mode by default using "),Jpe=n(bRe,"CODE",{});var vvt=s(Jpe);oVo=r(vvt,"model.eval()"),vvt.forEach(t),rVo=r(bRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=n(bRe,"CODE",{});var Fvt=s(Ype);tVo=r(Fvt,"model.train()"),Fvt.forEach(t),bRe.forEach(t),aVo=i(ca),T(y4.$$.fragment,ca),ca.forEach(t),nl.forEach(t),cVe=i(f),rd=n(f,"H2",{class:!0});var _ze=s(rd);x4=n(_ze,"A",{id:!0,class:!0,href:!0});var Tvt=s(x4);Kpe=n(Tvt,"SPAN",{});var Mvt=s(Kpe);T(Xy.$$.fragment,Mvt),Mvt.forEach(t),Tvt.forEach(t),nVo=i(_ze),Zpe=n(_ze,"SPAN",{});var Evt=s(Zpe);sVo=r(Evt,"AutoModelForMultipleChoice"),Evt.forEach(t),_ze.forEach(t),fVe=i(f),Bo=n(f,"DIV",{class:!0});var sl=s(Bo);T(zy.$$.fragment,sl),lVo=i(sl),td=n(sl,"P",{});var lre=s(td);iVo=r(lre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),gX=n(lre,"A",{href:!0});var Cvt=s(gX);dVo=r(Cvt,"from_pretrained()"),Cvt.forEach(t),cVo=r(lre," class method or the "),hX=n(lre,"A",{href:!0});var wvt=s(hX);fVo=r(wvt,"from_config()"),wvt.forEach(t),mVo=r(lre,` class
method.`),lre.forEach(t),gVo=i(sl),Qy=n(sl,"P",{});var uze=s(Qy);hVo=r(uze,"This class cannot be instantiated directly using "),e_e=n(uze,"CODE",{});var Avt=s(e_e);pVo=r(Avt,"__init__()"),Avt.forEach(t),_Vo=r(uze," (throws an error)."),uze.forEach(t),uVo=i(sl),mt=n(sl,"DIV",{class:!0});var t6=s(mt);T(Wy.$$.fragment,t6),bVo=i(t6),o_e=n(t6,"P",{});var Lvt=s(o_e);vVo=r(Lvt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Lvt.forEach(t),FVo=i(t6),ad=n(t6,"P",{});var ire=s(ad);TVo=r(ire,`Note:
Loading a model from its configuration file does `),r_e=n(ire,"STRONG",{});var yvt=s(r_e);MVo=r(yvt,"not"),yvt.forEach(t),EVo=r(ire,` load the model weights. It only affects the
model\u2019s configuration. Use `),pX=n(ire,"A",{href:!0});var xvt=s(pX);CVo=r(xvt,"from_pretrained()"),xvt.forEach(t),wVo=r(ire," to load the model weights."),ire.forEach(t),AVo=i(t6),T($4.$$.fragment,t6),t6.forEach(t),LVo=i(sl),ro=n(sl,"DIV",{class:!0});var fa=s(ro);T(Hy.$$.fragment,fa),yVo=i(fa),t_e=n(fa,"P",{});var $vt=s(t_e);xVo=r($vt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),$vt.forEach(t),$Vo=i(fa),Ga=n(fa,"P",{});var a6=s(Ga);kVo=r(a6,"The model class to instantiate is selected based on the "),a_e=n(a6,"CODE",{});var kvt=s(a_e);SVo=r(kvt,"model_type"),kvt.forEach(t),RVo=r(a6,` property of the config object (either
passed as an argument or loaded from `),n_e=n(a6,"CODE",{});var Svt=s(n_e);PVo=r(Svt,"pretrained_model_name_or_path"),Svt.forEach(t),BVo=r(a6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s_e=n(a6,"CODE",{});var Rvt=s(s_e);NVo=r(Rvt,"pretrained_model_name_or_path"),Rvt.forEach(t),IVo=r(a6,":"),a6.forEach(t),qVo=i(fa),Z=n(fa,"UL",{});var ee=s(Z);k4=n(ee,"LI",{});var vRe=s(k4);l_e=n(vRe,"STRONG",{});var Pvt=s(l_e);jVo=r(Pvt,"albert"),Pvt.forEach(t),DVo=r(vRe," \u2014 "),_X=n(vRe,"A",{href:!0});var Bvt=s(_X);GVo=r(Bvt,"AlbertForMultipleChoice"),Bvt.forEach(t),OVo=r(vRe," (ALBERT model)"),vRe.forEach(t),VVo=i(ee),S4=n(ee,"LI",{});var FRe=s(S4);i_e=n(FRe,"STRONG",{});var Nvt=s(i_e);XVo=r(Nvt,"bert"),Nvt.forEach(t),zVo=r(FRe," \u2014 "),uX=n(FRe,"A",{href:!0});var Ivt=s(uX);QVo=r(Ivt,"BertForMultipleChoice"),Ivt.forEach(t),WVo=r(FRe," (BERT model)"),FRe.forEach(t),HVo=i(ee),R4=n(ee,"LI",{});var TRe=s(R4);d_e=n(TRe,"STRONG",{});var qvt=s(d_e);UVo=r(qvt,"big_bird"),qvt.forEach(t),JVo=r(TRe," \u2014 "),bX=n(TRe,"A",{href:!0});var jvt=s(bX);YVo=r(jvt,"BigBirdForMultipleChoice"),jvt.forEach(t),KVo=r(TRe," (BigBird model)"),TRe.forEach(t),ZVo=i(ee),P4=n(ee,"LI",{});var MRe=s(P4);c_e=n(MRe,"STRONG",{});var Dvt=s(c_e);eXo=r(Dvt,"camembert"),Dvt.forEach(t),oXo=r(MRe," \u2014 "),vX=n(MRe,"A",{href:!0});var Gvt=s(vX);rXo=r(Gvt,"CamembertForMultipleChoice"),Gvt.forEach(t),tXo=r(MRe," (CamemBERT model)"),MRe.forEach(t),aXo=i(ee),B4=n(ee,"LI",{});var ERe=s(B4);f_e=n(ERe,"STRONG",{});var Ovt=s(f_e);nXo=r(Ovt,"canine"),Ovt.forEach(t),sXo=r(ERe," \u2014 "),FX=n(ERe,"A",{href:!0});var Vvt=s(FX);lXo=r(Vvt,"CanineForMultipleChoice"),Vvt.forEach(t),iXo=r(ERe," (CANINE model)"),ERe.forEach(t),dXo=i(ee),N4=n(ee,"LI",{});var CRe=s(N4);m_e=n(CRe,"STRONG",{});var Xvt=s(m_e);cXo=r(Xvt,"convbert"),Xvt.forEach(t),fXo=r(CRe," \u2014 "),TX=n(CRe,"A",{href:!0});var zvt=s(TX);mXo=r(zvt,"ConvBertForMultipleChoice"),zvt.forEach(t),gXo=r(CRe," (ConvBERT model)"),CRe.forEach(t),hXo=i(ee),I4=n(ee,"LI",{});var wRe=s(I4);g_e=n(wRe,"STRONG",{});var Qvt=s(g_e);pXo=r(Qvt,"data2vec-text"),Qvt.forEach(t),_Xo=r(wRe," \u2014 "),MX=n(wRe,"A",{href:!0});var Wvt=s(MX);uXo=r(Wvt,"Data2VecTextForMultipleChoice"),Wvt.forEach(t),bXo=r(wRe," (Data2VecText model)"),wRe.forEach(t),vXo=i(ee),q4=n(ee,"LI",{});var ARe=s(q4);h_e=n(ARe,"STRONG",{});var Hvt=s(h_e);FXo=r(Hvt,"deberta-v2"),Hvt.forEach(t),TXo=r(ARe," \u2014 "),EX=n(ARe,"A",{href:!0});var Uvt=s(EX);MXo=r(Uvt,"DebertaV2ForMultipleChoice"),Uvt.forEach(t),EXo=r(ARe," (DeBERTa-v2 model)"),ARe.forEach(t),CXo=i(ee),j4=n(ee,"LI",{});var LRe=s(j4);p_e=n(LRe,"STRONG",{});var Jvt=s(p_e);wXo=r(Jvt,"distilbert"),Jvt.forEach(t),AXo=r(LRe," \u2014 "),CX=n(LRe,"A",{href:!0});var Yvt=s(CX);LXo=r(Yvt,"DistilBertForMultipleChoice"),Yvt.forEach(t),yXo=r(LRe," (DistilBERT model)"),LRe.forEach(t),xXo=i(ee),D4=n(ee,"LI",{});var yRe=s(D4);__e=n(yRe,"STRONG",{});var Kvt=s(__e);$Xo=r(Kvt,"electra"),Kvt.forEach(t),kXo=r(yRe," \u2014 "),wX=n(yRe,"A",{href:!0});var Zvt=s(wX);SXo=r(Zvt,"ElectraForMultipleChoice"),Zvt.forEach(t),RXo=r(yRe," (ELECTRA model)"),yRe.forEach(t),PXo=i(ee),G4=n(ee,"LI",{});var xRe=s(G4);u_e=n(xRe,"STRONG",{});var eFt=s(u_e);BXo=r(eFt,"flaubert"),eFt.forEach(t),NXo=r(xRe," \u2014 "),AX=n(xRe,"A",{href:!0});var oFt=s(AX);IXo=r(oFt,"FlaubertForMultipleChoice"),oFt.forEach(t),qXo=r(xRe," (FlauBERT model)"),xRe.forEach(t),jXo=i(ee),O4=n(ee,"LI",{});var $Re=s(O4);b_e=n($Re,"STRONG",{});var rFt=s(b_e);DXo=r(rFt,"fnet"),rFt.forEach(t),GXo=r($Re," \u2014 "),LX=n($Re,"A",{href:!0});var tFt=s(LX);OXo=r(tFt,"FNetForMultipleChoice"),tFt.forEach(t),VXo=r($Re," (FNet model)"),$Re.forEach(t),XXo=i(ee),V4=n(ee,"LI",{});var kRe=s(V4);v_e=n(kRe,"STRONG",{});var aFt=s(v_e);zXo=r(aFt,"funnel"),aFt.forEach(t),QXo=r(kRe," \u2014 "),yX=n(kRe,"A",{href:!0});var nFt=s(yX);WXo=r(nFt,"FunnelForMultipleChoice"),nFt.forEach(t),HXo=r(kRe," (Funnel Transformer model)"),kRe.forEach(t),UXo=i(ee),X4=n(ee,"LI",{});var SRe=s(X4);F_e=n(SRe,"STRONG",{});var sFt=s(F_e);JXo=r(sFt,"ibert"),sFt.forEach(t),YXo=r(SRe," \u2014 "),xX=n(SRe,"A",{href:!0});var lFt=s(xX);KXo=r(lFt,"IBertForMultipleChoice"),lFt.forEach(t),ZXo=r(SRe," (I-BERT model)"),SRe.forEach(t),ezo=i(ee),z4=n(ee,"LI",{});var RRe=s(z4);T_e=n(RRe,"STRONG",{});var iFt=s(T_e);ozo=r(iFt,"longformer"),iFt.forEach(t),rzo=r(RRe," \u2014 "),$X=n(RRe,"A",{href:!0});var dFt=s($X);tzo=r(dFt,"LongformerForMultipleChoice"),dFt.forEach(t),azo=r(RRe," (Longformer model)"),RRe.forEach(t),nzo=i(ee),Q4=n(ee,"LI",{});var PRe=s(Q4);M_e=n(PRe,"STRONG",{});var cFt=s(M_e);szo=r(cFt,"megatron-bert"),cFt.forEach(t),lzo=r(PRe," \u2014 "),kX=n(PRe,"A",{href:!0});var fFt=s(kX);izo=r(fFt,"MegatronBertForMultipleChoice"),fFt.forEach(t),dzo=r(PRe," (Megatron-BERT model)"),PRe.forEach(t),czo=i(ee),W4=n(ee,"LI",{});var BRe=s(W4);E_e=n(BRe,"STRONG",{});var mFt=s(E_e);fzo=r(mFt,"mobilebert"),mFt.forEach(t),mzo=r(BRe," \u2014 "),SX=n(BRe,"A",{href:!0});var gFt=s(SX);gzo=r(gFt,"MobileBertForMultipleChoice"),gFt.forEach(t),hzo=r(BRe," (MobileBERT model)"),BRe.forEach(t),pzo=i(ee),H4=n(ee,"LI",{});var NRe=s(H4);C_e=n(NRe,"STRONG",{});var hFt=s(C_e);_zo=r(hFt,"mpnet"),hFt.forEach(t),uzo=r(NRe," \u2014 "),RX=n(NRe,"A",{href:!0});var pFt=s(RX);bzo=r(pFt,"MPNetForMultipleChoice"),pFt.forEach(t),vzo=r(NRe," (MPNet model)"),NRe.forEach(t),Fzo=i(ee),U4=n(ee,"LI",{});var IRe=s(U4);w_e=n(IRe,"STRONG",{});var _Ft=s(w_e);Tzo=r(_Ft,"nezha"),_Ft.forEach(t),Mzo=r(IRe," \u2014 "),PX=n(IRe,"A",{href:!0});var uFt=s(PX);Ezo=r(uFt,"NezhaForMultipleChoice"),uFt.forEach(t),Czo=r(IRe," (Nezha model)"),IRe.forEach(t),wzo=i(ee),J4=n(ee,"LI",{});var qRe=s(J4);A_e=n(qRe,"STRONG",{});var bFt=s(A_e);Azo=r(bFt,"nystromformer"),bFt.forEach(t),Lzo=r(qRe," \u2014 "),BX=n(qRe,"A",{href:!0});var vFt=s(BX);yzo=r(vFt,"NystromformerForMultipleChoice"),vFt.forEach(t),xzo=r(qRe," (Nystr\xF6mformer model)"),qRe.forEach(t),$zo=i(ee),Y4=n(ee,"LI",{});var jRe=s(Y4);L_e=n(jRe,"STRONG",{});var FFt=s(L_e);kzo=r(FFt,"qdqbert"),FFt.forEach(t),Szo=r(jRe," \u2014 "),NX=n(jRe,"A",{href:!0});var TFt=s(NX);Rzo=r(TFt,"QDQBertForMultipleChoice"),TFt.forEach(t),Pzo=r(jRe," (QDQBert model)"),jRe.forEach(t),Bzo=i(ee),K4=n(ee,"LI",{});var DRe=s(K4);y_e=n(DRe,"STRONG",{});var MFt=s(y_e);Nzo=r(MFt,"rembert"),MFt.forEach(t),Izo=r(DRe," \u2014 "),IX=n(DRe,"A",{href:!0});var EFt=s(IX);qzo=r(EFt,"RemBertForMultipleChoice"),EFt.forEach(t),jzo=r(DRe," (RemBERT model)"),DRe.forEach(t),Dzo=i(ee),Z4=n(ee,"LI",{});var GRe=s(Z4);x_e=n(GRe,"STRONG",{});var CFt=s(x_e);Gzo=r(CFt,"roberta"),CFt.forEach(t),Ozo=r(GRe," \u2014 "),qX=n(GRe,"A",{href:!0});var wFt=s(qX);Vzo=r(wFt,"RobertaForMultipleChoice"),wFt.forEach(t),Xzo=r(GRe," (RoBERTa model)"),GRe.forEach(t),zzo=i(ee),eb=n(ee,"LI",{});var ORe=s(eb);$_e=n(ORe,"STRONG",{});var AFt=s($_e);Qzo=r(AFt,"roformer"),AFt.forEach(t),Wzo=r(ORe," \u2014 "),jX=n(ORe,"A",{href:!0});var LFt=s(jX);Hzo=r(LFt,"RoFormerForMultipleChoice"),LFt.forEach(t),Uzo=r(ORe," (RoFormer model)"),ORe.forEach(t),Jzo=i(ee),ob=n(ee,"LI",{});var VRe=s(ob);k_e=n(VRe,"STRONG",{});var yFt=s(k_e);Yzo=r(yFt,"squeezebert"),yFt.forEach(t),Kzo=r(VRe," \u2014 "),DX=n(VRe,"A",{href:!0});var xFt=s(DX);Zzo=r(xFt,"SqueezeBertForMultipleChoice"),xFt.forEach(t),eQo=r(VRe," (SqueezeBERT model)"),VRe.forEach(t),oQo=i(ee),rb=n(ee,"LI",{});var XRe=s(rb);S_e=n(XRe,"STRONG",{});var $Ft=s(S_e);rQo=r($Ft,"xlm"),$Ft.forEach(t),tQo=r(XRe," \u2014 "),GX=n(XRe,"A",{href:!0});var kFt=s(GX);aQo=r(kFt,"XLMForMultipleChoice"),kFt.forEach(t),nQo=r(XRe," (XLM model)"),XRe.forEach(t),sQo=i(ee),tb=n(ee,"LI",{});var zRe=s(tb);R_e=n(zRe,"STRONG",{});var SFt=s(R_e);lQo=r(SFt,"xlm-roberta"),SFt.forEach(t),iQo=r(zRe," \u2014 "),OX=n(zRe,"A",{href:!0});var RFt=s(OX);dQo=r(RFt,"XLMRobertaForMultipleChoice"),RFt.forEach(t),cQo=r(zRe," (XLM-RoBERTa model)"),zRe.forEach(t),fQo=i(ee),ab=n(ee,"LI",{});var QRe=s(ab);P_e=n(QRe,"STRONG",{});var PFt=s(P_e);mQo=r(PFt,"xlm-roberta-xl"),PFt.forEach(t),gQo=r(QRe," \u2014 "),VX=n(QRe,"A",{href:!0});var BFt=s(VX);hQo=r(BFt,"XLMRobertaXLForMultipleChoice"),BFt.forEach(t),pQo=r(QRe," (XLM-RoBERTa-XL model)"),QRe.forEach(t),_Qo=i(ee),nb=n(ee,"LI",{});var WRe=s(nb);B_e=n(WRe,"STRONG",{});var NFt=s(B_e);uQo=r(NFt,"xlnet"),NFt.forEach(t),bQo=r(WRe," \u2014 "),XX=n(WRe,"A",{href:!0});var IFt=s(XX);vQo=r(IFt,"XLNetForMultipleChoice"),IFt.forEach(t),FQo=r(WRe," (XLNet model)"),WRe.forEach(t),TQo=i(ee),sb=n(ee,"LI",{});var HRe=s(sb);N_e=n(HRe,"STRONG",{});var qFt=s(N_e);MQo=r(qFt,"yoso"),qFt.forEach(t),EQo=r(HRe," \u2014 "),zX=n(HRe,"A",{href:!0});var jFt=s(zX);CQo=r(jFt,"YosoForMultipleChoice"),jFt.forEach(t),wQo=r(HRe," (YOSO model)"),HRe.forEach(t),ee.forEach(t),AQo=i(fa),lb=n(fa,"P",{});var URe=s(lb);LQo=r(URe,"The model is set in evaluation mode by default using "),I_e=n(URe,"CODE",{});var DFt=s(I_e);yQo=r(DFt,"model.eval()"),DFt.forEach(t),xQo=r(URe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q_e=n(URe,"CODE",{});var GFt=s(q_e);$Qo=r(GFt,"model.train()"),GFt.forEach(t),URe.forEach(t),kQo=i(fa),T(ib.$$.fragment,fa),fa.forEach(t),sl.forEach(t),mVe=i(f),nd=n(f,"H2",{class:!0});var bze=s(nd);db=n(bze,"A",{id:!0,class:!0,href:!0});var OFt=s(db);j_e=n(OFt,"SPAN",{});var VFt=s(j_e);T(Uy.$$.fragment,VFt),VFt.forEach(t),OFt.forEach(t),SQo=i(bze),D_e=n(bze,"SPAN",{});var XFt=s(D_e);RQo=r(XFt,"AutoModelForNextSentencePrediction"),XFt.forEach(t),bze.forEach(t),gVe=i(f),No=n(f,"DIV",{class:!0});var ll=s(No);T(Jy.$$.fragment,ll),PQo=i(ll),sd=n(ll,"P",{});var dre=s(sd);BQo=r(dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),QX=n(dre,"A",{href:!0});var zFt=s(QX);NQo=r(zFt,"from_pretrained()"),zFt.forEach(t),IQo=r(dre," class method or the "),WX=n(dre,"A",{href:!0});var QFt=s(WX);qQo=r(QFt,"from_config()"),QFt.forEach(t),jQo=r(dre,` class
method.`),dre.forEach(t),DQo=i(ll),Yy=n(ll,"P",{});var vze=s(Yy);GQo=r(vze,"This class cannot be instantiated directly using "),G_e=n(vze,"CODE",{});var WFt=s(G_e);OQo=r(WFt,"__init__()"),WFt.forEach(t),VQo=r(vze," (throws an error)."),vze.forEach(t),XQo=i(ll),gt=n(ll,"DIV",{class:!0});var n6=s(gt);T(Ky.$$.fragment,n6),zQo=i(n6),O_e=n(n6,"P",{});var HFt=s(O_e);QQo=r(HFt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),HFt.forEach(t),WQo=i(n6),ld=n(n6,"P",{});var cre=s(ld);HQo=r(cre,`Note:
Loading a model from its configuration file does `),V_e=n(cre,"STRONG",{});var UFt=s(V_e);UQo=r(UFt,"not"),UFt.forEach(t),JQo=r(cre,` load the model weights. It only affects the
model\u2019s configuration. Use `),HX=n(cre,"A",{href:!0});var JFt=s(HX);YQo=r(JFt,"from_pretrained()"),JFt.forEach(t),KQo=r(cre," to load the model weights."),cre.forEach(t),ZQo=i(n6),T(cb.$$.fragment,n6),n6.forEach(t),eWo=i(ll),to=n(ll,"DIV",{class:!0});var ma=s(to);T(Zy.$$.fragment,ma),oWo=i(ma),X_e=n(ma,"P",{});var YFt=s(X_e);rWo=r(YFt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),YFt.forEach(t),tWo=i(ma),Oa=n(ma,"P",{});var s6=s(Oa);aWo=r(s6,"The model class to instantiate is selected based on the "),z_e=n(s6,"CODE",{});var KFt=s(z_e);nWo=r(KFt,"model_type"),KFt.forEach(t),sWo=r(s6,` property of the config object (either
passed as an argument or loaded from `),Q_e=n(s6,"CODE",{});var ZFt=s(Q_e);lWo=r(ZFt,"pretrained_model_name_or_path"),ZFt.forEach(t),iWo=r(s6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W_e=n(s6,"CODE",{});var eTt=s(W_e);dWo=r(eTt,"pretrained_model_name_or_path"),eTt.forEach(t),cWo=r(s6,":"),s6.forEach(t),fWo=i(ma),Io=n(ma,"UL",{});var ga=s(Io);fb=n(ga,"LI",{});var JRe=s(fb);H_e=n(JRe,"STRONG",{});var oTt=s(H_e);mWo=r(oTt,"bert"),oTt.forEach(t),gWo=r(JRe," \u2014 "),UX=n(JRe,"A",{href:!0});var rTt=s(UX);hWo=r(rTt,"BertForNextSentencePrediction"),rTt.forEach(t),pWo=r(JRe," (BERT model)"),JRe.forEach(t),_Wo=i(ga),mb=n(ga,"LI",{});var YRe=s(mb);U_e=n(YRe,"STRONG",{});var tTt=s(U_e);uWo=r(tTt,"fnet"),tTt.forEach(t),bWo=r(YRe," \u2014 "),JX=n(YRe,"A",{href:!0});var aTt=s(JX);vWo=r(aTt,"FNetForNextSentencePrediction"),aTt.forEach(t),FWo=r(YRe," (FNet model)"),YRe.forEach(t),TWo=i(ga),gb=n(ga,"LI",{});var KRe=s(gb);J_e=n(KRe,"STRONG",{});var nTt=s(J_e);MWo=r(nTt,"megatron-bert"),nTt.forEach(t),EWo=r(KRe," \u2014 "),YX=n(KRe,"A",{href:!0});var sTt=s(YX);CWo=r(sTt,"MegatronBertForNextSentencePrediction"),sTt.forEach(t),wWo=r(KRe," (Megatron-BERT model)"),KRe.forEach(t),AWo=i(ga),hb=n(ga,"LI",{});var ZRe=s(hb);Y_e=n(ZRe,"STRONG",{});var lTt=s(Y_e);LWo=r(lTt,"mobilebert"),lTt.forEach(t),yWo=r(ZRe," \u2014 "),KX=n(ZRe,"A",{href:!0});var iTt=s(KX);xWo=r(iTt,"MobileBertForNextSentencePrediction"),iTt.forEach(t),$Wo=r(ZRe," (MobileBERT model)"),ZRe.forEach(t),kWo=i(ga),pb=n(ga,"LI",{});var ePe=s(pb);K_e=n(ePe,"STRONG",{});var dTt=s(K_e);SWo=r(dTt,"nezha"),dTt.forEach(t),RWo=r(ePe," \u2014 "),ZX=n(ePe,"A",{href:!0});var cTt=s(ZX);PWo=r(cTt,"NezhaForNextSentencePrediction"),cTt.forEach(t),BWo=r(ePe," (Nezha model)"),ePe.forEach(t),NWo=i(ga),_b=n(ga,"LI",{});var oPe=s(_b);Z_e=n(oPe,"STRONG",{});var fTt=s(Z_e);IWo=r(fTt,"qdqbert"),fTt.forEach(t),qWo=r(oPe," \u2014 "),ez=n(oPe,"A",{href:!0});var mTt=s(ez);jWo=r(mTt,"QDQBertForNextSentencePrediction"),mTt.forEach(t),DWo=r(oPe," (QDQBert model)"),oPe.forEach(t),ga.forEach(t),GWo=i(ma),ub=n(ma,"P",{});var rPe=s(ub);OWo=r(rPe,"The model is set in evaluation mode by default using "),eue=n(rPe,"CODE",{});var gTt=s(eue);VWo=r(gTt,"model.eval()"),gTt.forEach(t),XWo=r(rPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oue=n(rPe,"CODE",{});var hTt=s(oue);zWo=r(hTt,"model.train()"),hTt.forEach(t),rPe.forEach(t),QWo=i(ma),T(bb.$$.fragment,ma),ma.forEach(t),ll.forEach(t),hVe=i(f),id=n(f,"H2",{class:!0});var Fze=s(id);vb=n(Fze,"A",{id:!0,class:!0,href:!0});var pTt=s(vb);rue=n(pTt,"SPAN",{});var _Tt=s(rue);T(e8.$$.fragment,_Tt),_Tt.forEach(t),pTt.forEach(t),WWo=i(Fze),tue=n(Fze,"SPAN",{});var uTt=s(tue);HWo=r(uTt,"AutoModelForTokenClassification"),uTt.forEach(t),Fze.forEach(t),pVe=i(f),qo=n(f,"DIV",{class:!0});var il=s(qo);T(o8.$$.fragment,il),UWo=i(il),dd=n(il,"P",{});var fre=s(dd);JWo=r(fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),oz=n(fre,"A",{href:!0});var bTt=s(oz);YWo=r(bTt,"from_pretrained()"),bTt.forEach(t),KWo=r(fre," class method or the "),rz=n(fre,"A",{href:!0});var vTt=s(rz);ZWo=r(vTt,"from_config()"),vTt.forEach(t),eHo=r(fre,` class
method.`),fre.forEach(t),oHo=i(il),r8=n(il,"P",{});var Tze=s(r8);rHo=r(Tze,"This class cannot be instantiated directly using "),aue=n(Tze,"CODE",{});var FTt=s(aue);tHo=r(FTt,"__init__()"),FTt.forEach(t),aHo=r(Tze," (throws an error)."),Tze.forEach(t),nHo=i(il),ht=n(il,"DIV",{class:!0});var l6=s(ht);T(t8.$$.fragment,l6),sHo=i(l6),nue=n(l6,"P",{});var TTt=s(nue);lHo=r(TTt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),TTt.forEach(t),iHo=i(l6),cd=n(l6,"P",{});var mre=s(cd);dHo=r(mre,`Note:
Loading a model from its configuration file does `),sue=n(mre,"STRONG",{});var MTt=s(sue);cHo=r(MTt,"not"),MTt.forEach(t),fHo=r(mre,` load the model weights. It only affects the
model\u2019s configuration. Use `),tz=n(mre,"A",{href:!0});var ETt=s(tz);mHo=r(ETt,"from_pretrained()"),ETt.forEach(t),gHo=r(mre," to load the model weights."),mre.forEach(t),hHo=i(l6),T(Fb.$$.fragment,l6),l6.forEach(t),pHo=i(il),ao=n(il,"DIV",{class:!0});var ha=s(ao);T(a8.$$.fragment,ha),_Ho=i(ha),lue=n(ha,"P",{});var CTt=s(lue);uHo=r(CTt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),CTt.forEach(t),bHo=i(ha),Va=n(ha,"P",{});var i6=s(Va);vHo=r(i6,"The model class to instantiate is selected based on the "),iue=n(i6,"CODE",{});var wTt=s(iue);FHo=r(wTt,"model_type"),wTt.forEach(t),THo=r(i6,` property of the config object (either
passed as an argument or loaded from `),due=n(i6,"CODE",{});var ATt=s(due);MHo=r(ATt,"pretrained_model_name_or_path"),ATt.forEach(t),EHo=r(i6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cue=n(i6,"CODE",{});var LTt=s(cue);CHo=r(LTt,"pretrained_model_name_or_path"),LTt.forEach(t),wHo=r(i6,":"),i6.forEach(t),AHo=i(ha),H=n(ha,"UL",{});var J=s(H);Tb=n(J,"LI",{});var tPe=s(Tb);fue=n(tPe,"STRONG",{});var yTt=s(fue);LHo=r(yTt,"albert"),yTt.forEach(t),yHo=r(tPe," \u2014 "),az=n(tPe,"A",{href:!0});var xTt=s(az);xHo=r(xTt,"AlbertForTokenClassification"),xTt.forEach(t),$Ho=r(tPe," (ALBERT model)"),tPe.forEach(t),kHo=i(J),Mb=n(J,"LI",{});var aPe=s(Mb);mue=n(aPe,"STRONG",{});var $Tt=s(mue);SHo=r($Tt,"bert"),$Tt.forEach(t),RHo=r(aPe," \u2014 "),nz=n(aPe,"A",{href:!0});var kTt=s(nz);PHo=r(kTt,"BertForTokenClassification"),kTt.forEach(t),BHo=r(aPe," (BERT model)"),aPe.forEach(t),NHo=i(J),Eb=n(J,"LI",{});var nPe=s(Eb);gue=n(nPe,"STRONG",{});var STt=s(gue);IHo=r(STt,"big_bird"),STt.forEach(t),qHo=r(nPe," \u2014 "),sz=n(nPe,"A",{href:!0});var RTt=s(sz);jHo=r(RTt,"BigBirdForTokenClassification"),RTt.forEach(t),DHo=r(nPe," (BigBird model)"),nPe.forEach(t),GHo=i(J),Cb=n(J,"LI",{});var sPe=s(Cb);hue=n(sPe,"STRONG",{});var PTt=s(hue);OHo=r(PTt,"bloom"),PTt.forEach(t),VHo=r(sPe," \u2014 "),lz=n(sPe,"A",{href:!0});var BTt=s(lz);XHo=r(BTt,"BloomForTokenClassification"),BTt.forEach(t),zHo=r(sPe," (BLOOM model)"),sPe.forEach(t),QHo=i(J),wb=n(J,"LI",{});var lPe=s(wb);pue=n(lPe,"STRONG",{});var NTt=s(pue);WHo=r(NTt,"camembert"),NTt.forEach(t),HHo=r(lPe," \u2014 "),iz=n(lPe,"A",{href:!0});var ITt=s(iz);UHo=r(ITt,"CamembertForTokenClassification"),ITt.forEach(t),JHo=r(lPe," (CamemBERT model)"),lPe.forEach(t),YHo=i(J),Ab=n(J,"LI",{});var iPe=s(Ab);_ue=n(iPe,"STRONG",{});var qTt=s(_ue);KHo=r(qTt,"canine"),qTt.forEach(t),ZHo=r(iPe," \u2014 "),dz=n(iPe,"A",{href:!0});var jTt=s(dz);eUo=r(jTt,"CanineForTokenClassification"),jTt.forEach(t),oUo=r(iPe," (CANINE model)"),iPe.forEach(t),rUo=i(J),Lb=n(J,"LI",{});var dPe=s(Lb);uue=n(dPe,"STRONG",{});var DTt=s(uue);tUo=r(DTt,"convbert"),DTt.forEach(t),aUo=r(dPe," \u2014 "),cz=n(dPe,"A",{href:!0});var GTt=s(cz);nUo=r(GTt,"ConvBertForTokenClassification"),GTt.forEach(t),sUo=r(dPe," (ConvBERT model)"),dPe.forEach(t),lUo=i(J),yb=n(J,"LI",{});var cPe=s(yb);bue=n(cPe,"STRONG",{});var OTt=s(bue);iUo=r(OTt,"data2vec-text"),OTt.forEach(t),dUo=r(cPe," \u2014 "),fz=n(cPe,"A",{href:!0});var VTt=s(fz);cUo=r(VTt,"Data2VecTextForTokenClassification"),VTt.forEach(t),fUo=r(cPe," (Data2VecText model)"),cPe.forEach(t),mUo=i(J),xb=n(J,"LI",{});var fPe=s(xb);vue=n(fPe,"STRONG",{});var XTt=s(vue);gUo=r(XTt,"deberta"),XTt.forEach(t),hUo=r(fPe," \u2014 "),mz=n(fPe,"A",{href:!0});var zTt=s(mz);pUo=r(zTt,"DebertaForTokenClassification"),zTt.forEach(t),_Uo=r(fPe," (DeBERTa model)"),fPe.forEach(t),uUo=i(J),$b=n(J,"LI",{});var mPe=s($b);Fue=n(mPe,"STRONG",{});var QTt=s(Fue);bUo=r(QTt,"deberta-v2"),QTt.forEach(t),vUo=r(mPe," \u2014 "),gz=n(mPe,"A",{href:!0});var WTt=s(gz);FUo=r(WTt,"DebertaV2ForTokenClassification"),WTt.forEach(t),TUo=r(mPe," (DeBERTa-v2 model)"),mPe.forEach(t),MUo=i(J),kb=n(J,"LI",{});var gPe=s(kb);Tue=n(gPe,"STRONG",{});var HTt=s(Tue);EUo=r(HTt,"distilbert"),HTt.forEach(t),CUo=r(gPe," \u2014 "),hz=n(gPe,"A",{href:!0});var UTt=s(hz);wUo=r(UTt,"DistilBertForTokenClassification"),UTt.forEach(t),AUo=r(gPe," (DistilBERT model)"),gPe.forEach(t),LUo=i(J),Sb=n(J,"LI",{});var hPe=s(Sb);Mue=n(hPe,"STRONG",{});var JTt=s(Mue);yUo=r(JTt,"electra"),JTt.forEach(t),xUo=r(hPe," \u2014 "),pz=n(hPe,"A",{href:!0});var YTt=s(pz);$Uo=r(YTt,"ElectraForTokenClassification"),YTt.forEach(t),kUo=r(hPe," (ELECTRA model)"),hPe.forEach(t),SUo=i(J),Rb=n(J,"LI",{});var pPe=s(Rb);Eue=n(pPe,"STRONG",{});var KTt=s(Eue);RUo=r(KTt,"flaubert"),KTt.forEach(t),PUo=r(pPe," \u2014 "),_z=n(pPe,"A",{href:!0});var ZTt=s(_z);BUo=r(ZTt,"FlaubertForTokenClassification"),ZTt.forEach(t),NUo=r(pPe," (FlauBERT model)"),pPe.forEach(t),IUo=i(J),Pb=n(J,"LI",{});var _Pe=s(Pb);Cue=n(_Pe,"STRONG",{});var eMt=s(Cue);qUo=r(eMt,"fnet"),eMt.forEach(t),jUo=r(_Pe," \u2014 "),uz=n(_Pe,"A",{href:!0});var oMt=s(uz);DUo=r(oMt,"FNetForTokenClassification"),oMt.forEach(t),GUo=r(_Pe," (FNet model)"),_Pe.forEach(t),OUo=i(J),Bb=n(J,"LI",{});var uPe=s(Bb);wue=n(uPe,"STRONG",{});var rMt=s(wue);VUo=r(rMt,"funnel"),rMt.forEach(t),XUo=r(uPe," \u2014 "),bz=n(uPe,"A",{href:!0});var tMt=s(bz);zUo=r(tMt,"FunnelForTokenClassification"),tMt.forEach(t),QUo=r(uPe," (Funnel Transformer model)"),uPe.forEach(t),WUo=i(J),Nb=n(J,"LI",{});var bPe=s(Nb);Aue=n(bPe,"STRONG",{});var aMt=s(Aue);HUo=r(aMt,"gpt2"),aMt.forEach(t),UUo=r(bPe," \u2014 "),vz=n(bPe,"A",{href:!0});var nMt=s(vz);JUo=r(nMt,"GPT2ForTokenClassification"),nMt.forEach(t),YUo=r(bPe," (OpenAI GPT-2 model)"),bPe.forEach(t),KUo=i(J),Ib=n(J,"LI",{});var vPe=s(Ib);Lue=n(vPe,"STRONG",{});var sMt=s(Lue);ZUo=r(sMt,"ibert"),sMt.forEach(t),eJo=r(vPe," \u2014 "),Fz=n(vPe,"A",{href:!0});var lMt=s(Fz);oJo=r(lMt,"IBertForTokenClassification"),lMt.forEach(t),rJo=r(vPe," (I-BERT model)"),vPe.forEach(t),tJo=i(J),qb=n(J,"LI",{});var FPe=s(qb);yue=n(FPe,"STRONG",{});var iMt=s(yue);aJo=r(iMt,"layoutlm"),iMt.forEach(t),nJo=r(FPe," \u2014 "),Tz=n(FPe,"A",{href:!0});var dMt=s(Tz);sJo=r(dMt,"LayoutLMForTokenClassification"),dMt.forEach(t),lJo=r(FPe," (LayoutLM model)"),FPe.forEach(t),iJo=i(J),jb=n(J,"LI",{});var TPe=s(jb);xue=n(TPe,"STRONG",{});var cMt=s(xue);dJo=r(cMt,"layoutlmv2"),cMt.forEach(t),cJo=r(TPe," \u2014 "),Mz=n(TPe,"A",{href:!0});var fMt=s(Mz);fJo=r(fMt,"LayoutLMv2ForTokenClassification"),fMt.forEach(t),mJo=r(TPe," (LayoutLMv2 model)"),TPe.forEach(t),gJo=i(J),Db=n(J,"LI",{});var MPe=s(Db);$ue=n(MPe,"STRONG",{});var mMt=s($ue);hJo=r(mMt,"layoutlmv3"),mMt.forEach(t),pJo=r(MPe," \u2014 "),Ez=n(MPe,"A",{href:!0});var gMt=s(Ez);_Jo=r(gMt,"LayoutLMv3ForTokenClassification"),gMt.forEach(t),uJo=r(MPe," (LayoutLMv3 model)"),MPe.forEach(t),bJo=i(J),Gb=n(J,"LI",{});var EPe=s(Gb);kue=n(EPe,"STRONG",{});var hMt=s(kue);vJo=r(hMt,"longformer"),hMt.forEach(t),FJo=r(EPe," \u2014 "),Cz=n(EPe,"A",{href:!0});var pMt=s(Cz);TJo=r(pMt,"LongformerForTokenClassification"),pMt.forEach(t),MJo=r(EPe," (Longformer model)"),EPe.forEach(t),EJo=i(J),Ob=n(J,"LI",{});var CPe=s(Ob);Sue=n(CPe,"STRONG",{});var _Mt=s(Sue);CJo=r(_Mt,"megatron-bert"),_Mt.forEach(t),wJo=r(CPe," \u2014 "),wz=n(CPe,"A",{href:!0});var uMt=s(wz);AJo=r(uMt,"MegatronBertForTokenClassification"),uMt.forEach(t),LJo=r(CPe," (Megatron-BERT model)"),CPe.forEach(t),yJo=i(J),Vb=n(J,"LI",{});var wPe=s(Vb);Rue=n(wPe,"STRONG",{});var bMt=s(Rue);xJo=r(bMt,"mobilebert"),bMt.forEach(t),$Jo=r(wPe," \u2014 "),Az=n(wPe,"A",{href:!0});var vMt=s(Az);kJo=r(vMt,"MobileBertForTokenClassification"),vMt.forEach(t),SJo=r(wPe," (MobileBERT model)"),wPe.forEach(t),RJo=i(J),Xb=n(J,"LI",{});var APe=s(Xb);Pue=n(APe,"STRONG",{});var FMt=s(Pue);PJo=r(FMt,"mpnet"),FMt.forEach(t),BJo=r(APe," \u2014 "),Lz=n(APe,"A",{href:!0});var TMt=s(Lz);NJo=r(TMt,"MPNetForTokenClassification"),TMt.forEach(t),IJo=r(APe," (MPNet model)"),APe.forEach(t),qJo=i(J),zb=n(J,"LI",{});var LPe=s(zb);Bue=n(LPe,"STRONG",{});var MMt=s(Bue);jJo=r(MMt,"nezha"),MMt.forEach(t),DJo=r(LPe," \u2014 "),yz=n(LPe,"A",{href:!0});var EMt=s(yz);GJo=r(EMt,"NezhaForTokenClassification"),EMt.forEach(t),OJo=r(LPe," (Nezha model)"),LPe.forEach(t),VJo=i(J),Qb=n(J,"LI",{});var yPe=s(Qb);Nue=n(yPe,"STRONG",{});var CMt=s(Nue);XJo=r(CMt,"nystromformer"),CMt.forEach(t),zJo=r(yPe," \u2014 "),xz=n(yPe,"A",{href:!0});var wMt=s(xz);QJo=r(wMt,"NystromformerForTokenClassification"),wMt.forEach(t),WJo=r(yPe," (Nystr\xF6mformer model)"),yPe.forEach(t),HJo=i(J),Wb=n(J,"LI",{});var xPe=s(Wb);Iue=n(xPe,"STRONG",{});var AMt=s(Iue);UJo=r(AMt,"qdqbert"),AMt.forEach(t),JJo=r(xPe," \u2014 "),$z=n(xPe,"A",{href:!0});var LMt=s($z);YJo=r(LMt,"QDQBertForTokenClassification"),LMt.forEach(t),KJo=r(xPe," (QDQBert model)"),xPe.forEach(t),ZJo=i(J),Hb=n(J,"LI",{});var $Pe=s(Hb);que=n($Pe,"STRONG",{});var yMt=s(que);eYo=r(yMt,"rembert"),yMt.forEach(t),oYo=r($Pe," \u2014 "),kz=n($Pe,"A",{href:!0});var xMt=s(kz);rYo=r(xMt,"RemBertForTokenClassification"),xMt.forEach(t),tYo=r($Pe," (RemBERT model)"),$Pe.forEach(t),aYo=i(J),Ub=n(J,"LI",{});var kPe=s(Ub);jue=n(kPe,"STRONG",{});var $Mt=s(jue);nYo=r($Mt,"roberta"),$Mt.forEach(t),sYo=r(kPe," \u2014 "),Sz=n(kPe,"A",{href:!0});var kMt=s(Sz);lYo=r(kMt,"RobertaForTokenClassification"),kMt.forEach(t),iYo=r(kPe," (RoBERTa model)"),kPe.forEach(t),dYo=i(J),Jb=n(J,"LI",{});var SPe=s(Jb);Due=n(SPe,"STRONG",{});var SMt=s(Due);cYo=r(SMt,"roformer"),SMt.forEach(t),fYo=r(SPe," \u2014 "),Rz=n(SPe,"A",{href:!0});var RMt=s(Rz);mYo=r(RMt,"RoFormerForTokenClassification"),RMt.forEach(t),gYo=r(SPe," (RoFormer model)"),SPe.forEach(t),hYo=i(J),Yb=n(J,"LI",{});var RPe=s(Yb);Gue=n(RPe,"STRONG",{});var PMt=s(Gue);pYo=r(PMt,"squeezebert"),PMt.forEach(t),_Yo=r(RPe," \u2014 "),Pz=n(RPe,"A",{href:!0});var BMt=s(Pz);uYo=r(BMt,"SqueezeBertForTokenClassification"),BMt.forEach(t),bYo=r(RPe," (SqueezeBERT model)"),RPe.forEach(t),vYo=i(J),Kb=n(J,"LI",{});var PPe=s(Kb);Oue=n(PPe,"STRONG",{});var NMt=s(Oue);FYo=r(NMt,"xlm"),NMt.forEach(t),TYo=r(PPe," \u2014 "),Bz=n(PPe,"A",{href:!0});var IMt=s(Bz);MYo=r(IMt,"XLMForTokenClassification"),IMt.forEach(t),EYo=r(PPe," (XLM model)"),PPe.forEach(t),CYo=i(J),Zb=n(J,"LI",{});var BPe=s(Zb);Vue=n(BPe,"STRONG",{});var qMt=s(Vue);wYo=r(qMt,"xlm-roberta"),qMt.forEach(t),AYo=r(BPe," \u2014 "),Nz=n(BPe,"A",{href:!0});var jMt=s(Nz);LYo=r(jMt,"XLMRobertaForTokenClassification"),jMt.forEach(t),yYo=r(BPe," (XLM-RoBERTa model)"),BPe.forEach(t),xYo=i(J),ev=n(J,"LI",{});var NPe=s(ev);Xue=n(NPe,"STRONG",{});var DMt=s(Xue);$Yo=r(DMt,"xlm-roberta-xl"),DMt.forEach(t),kYo=r(NPe," \u2014 "),Iz=n(NPe,"A",{href:!0});var GMt=s(Iz);SYo=r(GMt,"XLMRobertaXLForTokenClassification"),GMt.forEach(t),RYo=r(NPe," (XLM-RoBERTa-XL model)"),NPe.forEach(t),PYo=i(J),ov=n(J,"LI",{});var IPe=s(ov);zue=n(IPe,"STRONG",{});var OMt=s(zue);BYo=r(OMt,"xlnet"),OMt.forEach(t),NYo=r(IPe," \u2014 "),qz=n(IPe,"A",{href:!0});var VMt=s(qz);IYo=r(VMt,"XLNetForTokenClassification"),VMt.forEach(t),qYo=r(IPe," (XLNet model)"),IPe.forEach(t),jYo=i(J),rv=n(J,"LI",{});var qPe=s(rv);Que=n(qPe,"STRONG",{});var XMt=s(Que);DYo=r(XMt,"yoso"),XMt.forEach(t),GYo=r(qPe," \u2014 "),jz=n(qPe,"A",{href:!0});var zMt=s(jz);OYo=r(zMt,"YosoForTokenClassification"),zMt.forEach(t),VYo=r(qPe," (YOSO model)"),qPe.forEach(t),J.forEach(t),XYo=i(ha),tv=n(ha,"P",{});var jPe=s(tv);zYo=r(jPe,"The model is set in evaluation mode by default using "),Wue=n(jPe,"CODE",{});var QMt=s(Wue);QYo=r(QMt,"model.eval()"),QMt.forEach(t),WYo=r(jPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hue=n(jPe,"CODE",{});var WMt=s(Hue);HYo=r(WMt,"model.train()"),WMt.forEach(t),jPe.forEach(t),UYo=i(ha),T(av.$$.fragment,ha),ha.forEach(t),il.forEach(t),_Ve=i(f),fd=n(f,"H2",{class:!0});var Mze=s(fd);nv=n(Mze,"A",{id:!0,class:!0,href:!0});var HMt=s(nv);Uue=n(HMt,"SPAN",{});var UMt=s(Uue);T(n8.$$.fragment,UMt),UMt.forEach(t),HMt.forEach(t),JYo=i(Mze),Jue=n(Mze,"SPAN",{});var JMt=s(Jue);YYo=r(JMt,"AutoModelForQuestionAnswering"),JMt.forEach(t),Mze.forEach(t),uVe=i(f),jo=n(f,"DIV",{class:!0});var dl=s(jo);T(s8.$$.fragment,dl),KYo=i(dl),md=n(dl,"P",{});var gre=s(md);ZYo=r(gre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Dz=n(gre,"A",{href:!0});var YMt=s(Dz);eKo=r(YMt,"from_pretrained()"),YMt.forEach(t),oKo=r(gre," class method or the "),Gz=n(gre,"A",{href:!0});var KMt=s(Gz);rKo=r(KMt,"from_config()"),KMt.forEach(t),tKo=r(gre,` class
method.`),gre.forEach(t),aKo=i(dl),l8=n(dl,"P",{});var Eze=s(l8);nKo=r(Eze,"This class cannot be instantiated directly using "),Yue=n(Eze,"CODE",{});var ZMt=s(Yue);sKo=r(ZMt,"__init__()"),ZMt.forEach(t),lKo=r(Eze," (throws an error)."),Eze.forEach(t),iKo=i(dl),pt=n(dl,"DIV",{class:!0});var d6=s(pt);T(i8.$$.fragment,d6),dKo=i(d6),Kue=n(d6,"P",{});var eEt=s(Kue);cKo=r(eEt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),eEt.forEach(t),fKo=i(d6),gd=n(d6,"P",{});var hre=s(gd);mKo=r(hre,`Note:
Loading a model from its configuration file does `),Zue=n(hre,"STRONG",{});var oEt=s(Zue);gKo=r(oEt,"not"),oEt.forEach(t),hKo=r(hre,` load the model weights. It only affects the
model\u2019s configuration. Use `),Oz=n(hre,"A",{href:!0});var rEt=s(Oz);pKo=r(rEt,"from_pretrained()"),rEt.forEach(t),_Ko=r(hre," to load the model weights."),hre.forEach(t),uKo=i(d6),T(sv.$$.fragment,d6),d6.forEach(t),bKo=i(dl),no=n(dl,"DIV",{class:!0});var pa=s(no);T(d8.$$.fragment,pa),vKo=i(pa),e2e=n(pa,"P",{});var tEt=s(e2e);FKo=r(tEt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),tEt.forEach(t),TKo=i(pa),Xa=n(pa,"P",{});var c6=s(Xa);MKo=r(c6,"The model class to instantiate is selected based on the "),o2e=n(c6,"CODE",{});var aEt=s(o2e);EKo=r(aEt,"model_type"),aEt.forEach(t),CKo=r(c6,` property of the config object (either
passed as an argument or loaded from `),r2e=n(c6,"CODE",{});var nEt=s(r2e);wKo=r(nEt,"pretrained_model_name_or_path"),nEt.forEach(t),AKo=r(c6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t2e=n(c6,"CODE",{});var sEt=s(t2e);LKo=r(sEt,"pretrained_model_name_or_path"),sEt.forEach(t),yKo=r(c6,":"),c6.forEach(t),xKo=i(pa),V=n(pa,"UL",{});var X=s(V);lv=n(X,"LI",{});var DPe=s(lv);a2e=n(DPe,"STRONG",{});var lEt=s(a2e);$Ko=r(lEt,"albert"),lEt.forEach(t),kKo=r(DPe," \u2014 "),Vz=n(DPe,"A",{href:!0});var iEt=s(Vz);SKo=r(iEt,"AlbertForQuestionAnswering"),iEt.forEach(t),RKo=r(DPe," (ALBERT model)"),DPe.forEach(t),PKo=i(X),iv=n(X,"LI",{});var GPe=s(iv);n2e=n(GPe,"STRONG",{});var dEt=s(n2e);BKo=r(dEt,"bart"),dEt.forEach(t),NKo=r(GPe," \u2014 "),Xz=n(GPe,"A",{href:!0});var cEt=s(Xz);IKo=r(cEt,"BartForQuestionAnswering"),cEt.forEach(t),qKo=r(GPe," (BART model)"),GPe.forEach(t),jKo=i(X),dv=n(X,"LI",{});var OPe=s(dv);s2e=n(OPe,"STRONG",{});var fEt=s(s2e);DKo=r(fEt,"bert"),fEt.forEach(t),GKo=r(OPe," \u2014 "),zz=n(OPe,"A",{href:!0});var mEt=s(zz);OKo=r(mEt,"BertForQuestionAnswering"),mEt.forEach(t),VKo=r(OPe," (BERT model)"),OPe.forEach(t),XKo=i(X),cv=n(X,"LI",{});var VPe=s(cv);l2e=n(VPe,"STRONG",{});var gEt=s(l2e);zKo=r(gEt,"big_bird"),gEt.forEach(t),QKo=r(VPe," \u2014 "),Qz=n(VPe,"A",{href:!0});var hEt=s(Qz);WKo=r(hEt,"BigBirdForQuestionAnswering"),hEt.forEach(t),HKo=r(VPe," (BigBird model)"),VPe.forEach(t),UKo=i(X),fv=n(X,"LI",{});var XPe=s(fv);i2e=n(XPe,"STRONG",{});var pEt=s(i2e);JKo=r(pEt,"bigbird_pegasus"),pEt.forEach(t),YKo=r(XPe," \u2014 "),Wz=n(XPe,"A",{href:!0});var _Et=s(Wz);KKo=r(_Et,"BigBirdPegasusForQuestionAnswering"),_Et.forEach(t),ZKo=r(XPe," (BigBird-Pegasus model)"),XPe.forEach(t),eZo=i(X),mv=n(X,"LI",{});var zPe=s(mv);d2e=n(zPe,"STRONG",{});var uEt=s(d2e);oZo=r(uEt,"camembert"),uEt.forEach(t),rZo=r(zPe," \u2014 "),Hz=n(zPe,"A",{href:!0});var bEt=s(Hz);tZo=r(bEt,"CamembertForQuestionAnswering"),bEt.forEach(t),aZo=r(zPe," (CamemBERT model)"),zPe.forEach(t),nZo=i(X),gv=n(X,"LI",{});var QPe=s(gv);c2e=n(QPe,"STRONG",{});var vEt=s(c2e);sZo=r(vEt,"canine"),vEt.forEach(t),lZo=r(QPe," \u2014 "),Uz=n(QPe,"A",{href:!0});var FEt=s(Uz);iZo=r(FEt,"CanineForQuestionAnswering"),FEt.forEach(t),dZo=r(QPe," (CANINE model)"),QPe.forEach(t),cZo=i(X),hv=n(X,"LI",{});var WPe=s(hv);f2e=n(WPe,"STRONG",{});var TEt=s(f2e);fZo=r(TEt,"convbert"),TEt.forEach(t),mZo=r(WPe," \u2014 "),Jz=n(WPe,"A",{href:!0});var MEt=s(Jz);gZo=r(MEt,"ConvBertForQuestionAnswering"),MEt.forEach(t),hZo=r(WPe," (ConvBERT model)"),WPe.forEach(t),pZo=i(X),pv=n(X,"LI",{});var HPe=s(pv);m2e=n(HPe,"STRONG",{});var EEt=s(m2e);_Zo=r(EEt,"data2vec-text"),EEt.forEach(t),uZo=r(HPe," \u2014 "),Yz=n(HPe,"A",{href:!0});var CEt=s(Yz);bZo=r(CEt,"Data2VecTextForQuestionAnswering"),CEt.forEach(t),vZo=r(HPe," (Data2VecText model)"),HPe.forEach(t),FZo=i(X),_v=n(X,"LI",{});var UPe=s(_v);g2e=n(UPe,"STRONG",{});var wEt=s(g2e);TZo=r(wEt,"deberta"),wEt.forEach(t),MZo=r(UPe," \u2014 "),Kz=n(UPe,"A",{href:!0});var AEt=s(Kz);EZo=r(AEt,"DebertaForQuestionAnswering"),AEt.forEach(t),CZo=r(UPe," (DeBERTa model)"),UPe.forEach(t),wZo=i(X),uv=n(X,"LI",{});var JPe=s(uv);h2e=n(JPe,"STRONG",{});var LEt=s(h2e);AZo=r(LEt,"deberta-v2"),LEt.forEach(t),LZo=r(JPe," \u2014 "),Zz=n(JPe,"A",{href:!0});var yEt=s(Zz);yZo=r(yEt,"DebertaV2ForQuestionAnswering"),yEt.forEach(t),xZo=r(JPe," (DeBERTa-v2 model)"),JPe.forEach(t),$Zo=i(X),bv=n(X,"LI",{});var YPe=s(bv);p2e=n(YPe,"STRONG",{});var xEt=s(p2e);kZo=r(xEt,"distilbert"),xEt.forEach(t),SZo=r(YPe," \u2014 "),eQ=n(YPe,"A",{href:!0});var $Et=s(eQ);RZo=r($Et,"DistilBertForQuestionAnswering"),$Et.forEach(t),PZo=r(YPe," (DistilBERT model)"),YPe.forEach(t),BZo=i(X),vv=n(X,"LI",{});var KPe=s(vv);_2e=n(KPe,"STRONG",{});var kEt=s(_2e);NZo=r(kEt,"electra"),kEt.forEach(t),IZo=r(KPe," \u2014 "),oQ=n(KPe,"A",{href:!0});var SEt=s(oQ);qZo=r(SEt,"ElectraForQuestionAnswering"),SEt.forEach(t),jZo=r(KPe," (ELECTRA model)"),KPe.forEach(t),DZo=i(X),Fv=n(X,"LI",{});var ZPe=s(Fv);u2e=n(ZPe,"STRONG",{});var REt=s(u2e);GZo=r(REt,"flaubert"),REt.forEach(t),OZo=r(ZPe," \u2014 "),rQ=n(ZPe,"A",{href:!0});var PEt=s(rQ);VZo=r(PEt,"FlaubertForQuestionAnsweringSimple"),PEt.forEach(t),XZo=r(ZPe," (FlauBERT model)"),ZPe.forEach(t),zZo=i(X),Tv=n(X,"LI",{});var eBe=s(Tv);b2e=n(eBe,"STRONG",{});var BEt=s(b2e);QZo=r(BEt,"fnet"),BEt.forEach(t),WZo=r(eBe," \u2014 "),tQ=n(eBe,"A",{href:!0});var NEt=s(tQ);HZo=r(NEt,"FNetForQuestionAnswering"),NEt.forEach(t),UZo=r(eBe," (FNet model)"),eBe.forEach(t),JZo=i(X),Mv=n(X,"LI",{});var oBe=s(Mv);v2e=n(oBe,"STRONG",{});var IEt=s(v2e);YZo=r(IEt,"funnel"),IEt.forEach(t),KZo=r(oBe," \u2014 "),aQ=n(oBe,"A",{href:!0});var qEt=s(aQ);ZZo=r(qEt,"FunnelForQuestionAnswering"),qEt.forEach(t),eer=r(oBe," (Funnel Transformer model)"),oBe.forEach(t),oer=i(X),Ev=n(X,"LI",{});var rBe=s(Ev);F2e=n(rBe,"STRONG",{});var jEt=s(F2e);rer=r(jEt,"gptj"),jEt.forEach(t),ter=r(rBe," \u2014 "),nQ=n(rBe,"A",{href:!0});var DEt=s(nQ);aer=r(DEt,"GPTJForQuestionAnswering"),DEt.forEach(t),ner=r(rBe," (GPT-J model)"),rBe.forEach(t),ser=i(X),Cv=n(X,"LI",{});var tBe=s(Cv);T2e=n(tBe,"STRONG",{});var GEt=s(T2e);ler=r(GEt,"ibert"),GEt.forEach(t),ier=r(tBe," \u2014 "),sQ=n(tBe,"A",{href:!0});var OEt=s(sQ);der=r(OEt,"IBertForQuestionAnswering"),OEt.forEach(t),cer=r(tBe," (I-BERT model)"),tBe.forEach(t),fer=i(X),wv=n(X,"LI",{});var aBe=s(wv);M2e=n(aBe,"STRONG",{});var VEt=s(M2e);mer=r(VEt,"layoutlmv2"),VEt.forEach(t),ger=r(aBe," \u2014 "),lQ=n(aBe,"A",{href:!0});var XEt=s(lQ);her=r(XEt,"LayoutLMv2ForQuestionAnswering"),XEt.forEach(t),per=r(aBe," (LayoutLMv2 model)"),aBe.forEach(t),_er=i(X),Av=n(X,"LI",{});var nBe=s(Av);E2e=n(nBe,"STRONG",{});var zEt=s(E2e);uer=r(zEt,"layoutlmv3"),zEt.forEach(t),ber=r(nBe," \u2014 "),iQ=n(nBe,"A",{href:!0});var QEt=s(iQ);ver=r(QEt,"LayoutLMv3ForQuestionAnswering"),QEt.forEach(t),Fer=r(nBe," (LayoutLMv3 model)"),nBe.forEach(t),Ter=i(X),Lv=n(X,"LI",{});var sBe=s(Lv);C2e=n(sBe,"STRONG",{});var WEt=s(C2e);Mer=r(WEt,"led"),WEt.forEach(t),Eer=r(sBe," \u2014 "),dQ=n(sBe,"A",{href:!0});var HEt=s(dQ);Cer=r(HEt,"LEDForQuestionAnswering"),HEt.forEach(t),wer=r(sBe," (LED model)"),sBe.forEach(t),Aer=i(X),yv=n(X,"LI",{});var lBe=s(yv);w2e=n(lBe,"STRONG",{});var UEt=s(w2e);Ler=r(UEt,"longformer"),UEt.forEach(t),yer=r(lBe," \u2014 "),cQ=n(lBe,"A",{href:!0});var JEt=s(cQ);xer=r(JEt,"LongformerForQuestionAnswering"),JEt.forEach(t),$er=r(lBe," (Longformer model)"),lBe.forEach(t),ker=i(X),xv=n(X,"LI",{});var iBe=s(xv);A2e=n(iBe,"STRONG",{});var YEt=s(A2e);Ser=r(YEt,"lxmert"),YEt.forEach(t),Rer=r(iBe," \u2014 "),fQ=n(iBe,"A",{href:!0});var KEt=s(fQ);Per=r(KEt,"LxmertForQuestionAnswering"),KEt.forEach(t),Ber=r(iBe," (LXMERT model)"),iBe.forEach(t),Ner=i(X),$v=n(X,"LI",{});var dBe=s($v);L2e=n(dBe,"STRONG",{});var ZEt=s(L2e);Ier=r(ZEt,"mbart"),ZEt.forEach(t),qer=r(dBe," \u2014 "),mQ=n(dBe,"A",{href:!0});var eCt=s(mQ);jer=r(eCt,"MBartForQuestionAnswering"),eCt.forEach(t),Der=r(dBe," (mBART model)"),dBe.forEach(t),Ger=i(X),kv=n(X,"LI",{});var cBe=s(kv);y2e=n(cBe,"STRONG",{});var oCt=s(y2e);Oer=r(oCt,"megatron-bert"),oCt.forEach(t),Ver=r(cBe," \u2014 "),gQ=n(cBe,"A",{href:!0});var rCt=s(gQ);Xer=r(rCt,"MegatronBertForQuestionAnswering"),rCt.forEach(t),zer=r(cBe," (Megatron-BERT model)"),cBe.forEach(t),Qer=i(X),Sv=n(X,"LI",{});var fBe=s(Sv);x2e=n(fBe,"STRONG",{});var tCt=s(x2e);Wer=r(tCt,"mobilebert"),tCt.forEach(t),Her=r(fBe," \u2014 "),hQ=n(fBe,"A",{href:!0});var aCt=s(hQ);Uer=r(aCt,"MobileBertForQuestionAnswering"),aCt.forEach(t),Jer=r(fBe," (MobileBERT model)"),fBe.forEach(t),Yer=i(X),Rv=n(X,"LI",{});var mBe=s(Rv);$2e=n(mBe,"STRONG",{});var nCt=s($2e);Ker=r(nCt,"mpnet"),nCt.forEach(t),Zer=r(mBe," \u2014 "),pQ=n(mBe,"A",{href:!0});var sCt=s(pQ);eor=r(sCt,"MPNetForQuestionAnswering"),sCt.forEach(t),oor=r(mBe," (MPNet model)"),mBe.forEach(t),ror=i(X),Pv=n(X,"LI",{});var gBe=s(Pv);k2e=n(gBe,"STRONG",{});var lCt=s(k2e);tor=r(lCt,"nezha"),lCt.forEach(t),aor=r(gBe," \u2014 "),_Q=n(gBe,"A",{href:!0});var iCt=s(_Q);nor=r(iCt,"NezhaForQuestionAnswering"),iCt.forEach(t),sor=r(gBe," (Nezha model)"),gBe.forEach(t),lor=i(X),Bv=n(X,"LI",{});var hBe=s(Bv);S2e=n(hBe,"STRONG",{});var dCt=s(S2e);ior=r(dCt,"nystromformer"),dCt.forEach(t),dor=r(hBe," \u2014 "),uQ=n(hBe,"A",{href:!0});var cCt=s(uQ);cor=r(cCt,"NystromformerForQuestionAnswering"),cCt.forEach(t),mor=r(hBe," (Nystr\xF6mformer model)"),hBe.forEach(t),gor=i(X),Nv=n(X,"LI",{});var pBe=s(Nv);R2e=n(pBe,"STRONG",{});var fCt=s(R2e);hor=r(fCt,"qdqbert"),fCt.forEach(t),por=r(pBe," \u2014 "),bQ=n(pBe,"A",{href:!0});var mCt=s(bQ);_or=r(mCt,"QDQBertForQuestionAnswering"),mCt.forEach(t),uor=r(pBe," (QDQBert model)"),pBe.forEach(t),bor=i(X),Iv=n(X,"LI",{});var _Be=s(Iv);P2e=n(_Be,"STRONG",{});var gCt=s(P2e);vor=r(gCt,"reformer"),gCt.forEach(t),For=r(_Be," \u2014 "),vQ=n(_Be,"A",{href:!0});var hCt=s(vQ);Tor=r(hCt,"ReformerForQuestionAnswering"),hCt.forEach(t),Mor=r(_Be," (Reformer model)"),_Be.forEach(t),Eor=i(X),qv=n(X,"LI",{});var uBe=s(qv);B2e=n(uBe,"STRONG",{});var pCt=s(B2e);Cor=r(pCt,"rembert"),pCt.forEach(t),wor=r(uBe," \u2014 "),FQ=n(uBe,"A",{href:!0});var _Ct=s(FQ);Aor=r(_Ct,"RemBertForQuestionAnswering"),_Ct.forEach(t),Lor=r(uBe," (RemBERT model)"),uBe.forEach(t),yor=i(X),jv=n(X,"LI",{});var bBe=s(jv);N2e=n(bBe,"STRONG",{});var uCt=s(N2e);xor=r(uCt,"roberta"),uCt.forEach(t),$or=r(bBe," \u2014 "),TQ=n(bBe,"A",{href:!0});var bCt=s(TQ);kor=r(bCt,"RobertaForQuestionAnswering"),bCt.forEach(t),Sor=r(bBe," (RoBERTa model)"),bBe.forEach(t),Ror=i(X),Dv=n(X,"LI",{});var vBe=s(Dv);I2e=n(vBe,"STRONG",{});var vCt=s(I2e);Por=r(vCt,"roformer"),vCt.forEach(t),Bor=r(vBe," \u2014 "),MQ=n(vBe,"A",{href:!0});var FCt=s(MQ);Nor=r(FCt,"RoFormerForQuestionAnswering"),FCt.forEach(t),Ior=r(vBe," (RoFormer model)"),vBe.forEach(t),qor=i(X),Gv=n(X,"LI",{});var FBe=s(Gv);q2e=n(FBe,"STRONG",{});var TCt=s(q2e);jor=r(TCt,"splinter"),TCt.forEach(t),Dor=r(FBe," \u2014 "),EQ=n(FBe,"A",{href:!0});var MCt=s(EQ);Gor=r(MCt,"SplinterForQuestionAnswering"),MCt.forEach(t),Oor=r(FBe," (Splinter model)"),FBe.forEach(t),Vor=i(X),Ov=n(X,"LI",{});var TBe=s(Ov);j2e=n(TBe,"STRONG",{});var ECt=s(j2e);Xor=r(ECt,"squeezebert"),ECt.forEach(t),zor=r(TBe," \u2014 "),CQ=n(TBe,"A",{href:!0});var CCt=s(CQ);Qor=r(CCt,"SqueezeBertForQuestionAnswering"),CCt.forEach(t),Wor=r(TBe," (SqueezeBERT model)"),TBe.forEach(t),Hor=i(X),Vv=n(X,"LI",{});var MBe=s(Vv);D2e=n(MBe,"STRONG",{});var wCt=s(D2e);Uor=r(wCt,"xlm"),wCt.forEach(t),Jor=r(MBe," \u2014 "),wQ=n(MBe,"A",{href:!0});var ACt=s(wQ);Yor=r(ACt,"XLMForQuestionAnsweringSimple"),ACt.forEach(t),Kor=r(MBe," (XLM model)"),MBe.forEach(t),Zor=i(X),Xv=n(X,"LI",{});var EBe=s(Xv);G2e=n(EBe,"STRONG",{});var LCt=s(G2e);err=r(LCt,"xlm-roberta"),LCt.forEach(t),orr=r(EBe," \u2014 "),AQ=n(EBe,"A",{href:!0});var yCt=s(AQ);rrr=r(yCt,"XLMRobertaForQuestionAnswering"),yCt.forEach(t),trr=r(EBe," (XLM-RoBERTa model)"),EBe.forEach(t),arr=i(X),zv=n(X,"LI",{});var CBe=s(zv);O2e=n(CBe,"STRONG",{});var xCt=s(O2e);nrr=r(xCt,"xlm-roberta-xl"),xCt.forEach(t),srr=r(CBe," \u2014 "),LQ=n(CBe,"A",{href:!0});var $Ct=s(LQ);lrr=r($Ct,"XLMRobertaXLForQuestionAnswering"),$Ct.forEach(t),irr=r(CBe," (XLM-RoBERTa-XL model)"),CBe.forEach(t),drr=i(X),Qv=n(X,"LI",{});var wBe=s(Qv);V2e=n(wBe,"STRONG",{});var kCt=s(V2e);crr=r(kCt,"xlnet"),kCt.forEach(t),frr=r(wBe," \u2014 "),yQ=n(wBe,"A",{href:!0});var SCt=s(yQ);mrr=r(SCt,"XLNetForQuestionAnsweringSimple"),SCt.forEach(t),grr=r(wBe," (XLNet model)"),wBe.forEach(t),hrr=i(X),Wv=n(X,"LI",{});var ABe=s(Wv);X2e=n(ABe,"STRONG",{});var RCt=s(X2e);prr=r(RCt,"yoso"),RCt.forEach(t),_rr=r(ABe," \u2014 "),xQ=n(ABe,"A",{href:!0});var PCt=s(xQ);urr=r(PCt,"YosoForQuestionAnswering"),PCt.forEach(t),brr=r(ABe," (YOSO model)"),ABe.forEach(t),X.forEach(t),vrr=i(pa),Hv=n(pa,"P",{});var LBe=s(Hv);Frr=r(LBe,"The model is set in evaluation mode by default using "),z2e=n(LBe,"CODE",{});var BCt=s(z2e);Trr=r(BCt,"model.eval()"),BCt.forEach(t),Mrr=r(LBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q2e=n(LBe,"CODE",{});var NCt=s(Q2e);Err=r(NCt,"model.train()"),NCt.forEach(t),LBe.forEach(t),Crr=i(pa),T(Uv.$$.fragment,pa),pa.forEach(t),dl.forEach(t),bVe=i(f),hd=n(f,"H2",{class:!0});var Cze=s(hd);Jv=n(Cze,"A",{id:!0,class:!0,href:!0});var ICt=s(Jv);W2e=n(ICt,"SPAN",{});var qCt=s(W2e);T(c8.$$.fragment,qCt),qCt.forEach(t),ICt.forEach(t),wrr=i(Cze),H2e=n(Cze,"SPAN",{});var jCt=s(H2e);Arr=r(jCt,"AutoModelForTableQuestionAnswering"),jCt.forEach(t),Cze.forEach(t),vVe=i(f),Do=n(f,"DIV",{class:!0});var cl=s(Do);T(f8.$$.fragment,cl),Lrr=i(cl),pd=n(cl,"P",{});var pre=s(pd);yrr=r(pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Q=n(pre,"A",{href:!0});var DCt=s($Q);xrr=r(DCt,"from_pretrained()"),DCt.forEach(t),$rr=r(pre," class method or the "),kQ=n(pre,"A",{href:!0});var GCt=s(kQ);krr=r(GCt,"from_config()"),GCt.forEach(t),Srr=r(pre,` class
method.`),pre.forEach(t),Rrr=i(cl),m8=n(cl,"P",{});var wze=s(m8);Prr=r(wze,"This class cannot be instantiated directly using "),U2e=n(wze,"CODE",{});var OCt=s(U2e);Brr=r(OCt,"__init__()"),OCt.forEach(t),Nrr=r(wze," (throws an error)."),wze.forEach(t),Irr=i(cl),_t=n(cl,"DIV",{class:!0});var f6=s(_t);T(g8.$$.fragment,f6),qrr=i(f6),J2e=n(f6,"P",{});var VCt=s(J2e);jrr=r(VCt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),VCt.forEach(t),Drr=i(f6),_d=n(f6,"P",{});var _re=s(_d);Grr=r(_re,`Note:
Loading a model from its configuration file does `),Y2e=n(_re,"STRONG",{});var XCt=s(Y2e);Orr=r(XCt,"not"),XCt.forEach(t),Vrr=r(_re,` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=n(_re,"A",{href:!0});var zCt=s(SQ);Xrr=r(zCt,"from_pretrained()"),zCt.forEach(t),zrr=r(_re," to load the model weights."),_re.forEach(t),Qrr=i(f6),T(Yv.$$.fragment,f6),f6.forEach(t),Wrr=i(cl),so=n(cl,"DIV",{class:!0});var _a=s(so);T(h8.$$.fragment,_a),Hrr=i(_a),K2e=n(_a,"P",{});var QCt=s(K2e);Urr=r(QCt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),QCt.forEach(t),Jrr=i(_a),za=n(_a,"P",{});var m6=s(za);Yrr=r(m6,"The model class to instantiate is selected based on the "),Z2e=n(m6,"CODE",{});var WCt=s(Z2e);Krr=r(WCt,"model_type"),WCt.forEach(t),Zrr=r(m6,` property of the config object (either
passed as an argument or loaded from `),e1e=n(m6,"CODE",{});var HCt=s(e1e);etr=r(HCt,"pretrained_model_name_or_path"),HCt.forEach(t),otr=r(m6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o1e=n(m6,"CODE",{});var UCt=s(o1e);rtr=r(UCt,"pretrained_model_name_or_path"),UCt.forEach(t),ttr=r(m6,":"),m6.forEach(t),atr=i(_a),r1e=n(_a,"UL",{});var JCt=s(r1e);Kv=n(JCt,"LI",{});var yBe=s(Kv);t1e=n(yBe,"STRONG",{});var YCt=s(t1e);ntr=r(YCt,"tapas"),YCt.forEach(t),str=r(yBe," \u2014 "),RQ=n(yBe,"A",{href:!0});var KCt=s(RQ);ltr=r(KCt,"TapasForQuestionAnswering"),KCt.forEach(t),itr=r(yBe," (TAPAS model)"),yBe.forEach(t),JCt.forEach(t),dtr=i(_a),Zv=n(_a,"P",{});var xBe=s(Zv);ctr=r(xBe,"The model is set in evaluation mode by default using "),a1e=n(xBe,"CODE",{});var ZCt=s(a1e);ftr=r(ZCt,"model.eval()"),ZCt.forEach(t),mtr=r(xBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n1e=n(xBe,"CODE",{});var e3t=s(n1e);gtr=r(e3t,"model.train()"),e3t.forEach(t),xBe.forEach(t),htr=i(_a),T(eF.$$.fragment,_a),_a.forEach(t),cl.forEach(t),FVe=i(f),ud=n(f,"H2",{class:!0});var Aze=s(ud);oF=n(Aze,"A",{id:!0,class:!0,href:!0});var o3t=s(oF);s1e=n(o3t,"SPAN",{});var r3t=s(s1e);T(p8.$$.fragment,r3t),r3t.forEach(t),o3t.forEach(t),ptr=i(Aze),l1e=n(Aze,"SPAN",{});var t3t=s(l1e);_tr=r(t3t,"AutoModelForImageClassification"),t3t.forEach(t),Aze.forEach(t),TVe=i(f),Go=n(f,"DIV",{class:!0});var fl=s(Go);T(_8.$$.fragment,fl),utr=i(fl),bd=n(fl,"P",{});var ure=s(bd);btr=r(ure,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),PQ=n(ure,"A",{href:!0});var a3t=s(PQ);vtr=r(a3t,"from_pretrained()"),a3t.forEach(t),Ftr=r(ure," class method or the "),BQ=n(ure,"A",{href:!0});var n3t=s(BQ);Ttr=r(n3t,"from_config()"),n3t.forEach(t),Mtr=r(ure,` class
method.`),ure.forEach(t),Etr=i(fl),u8=n(fl,"P",{});var Lze=s(u8);Ctr=r(Lze,"This class cannot be instantiated directly using "),i1e=n(Lze,"CODE",{});var s3t=s(i1e);wtr=r(s3t,"__init__()"),s3t.forEach(t),Atr=r(Lze," (throws an error)."),Lze.forEach(t),Ltr=i(fl),ut=n(fl,"DIV",{class:!0});var g6=s(ut);T(b8.$$.fragment,g6),ytr=i(g6),d1e=n(g6,"P",{});var l3t=s(d1e);xtr=r(l3t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),l3t.forEach(t),$tr=i(g6),vd=n(g6,"P",{});var bre=s(vd);ktr=r(bre,`Note:
Loading a model from its configuration file does `),c1e=n(bre,"STRONG",{});var i3t=s(c1e);Str=r(i3t,"not"),i3t.forEach(t),Rtr=r(bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),NQ=n(bre,"A",{href:!0});var d3t=s(NQ);Ptr=r(d3t,"from_pretrained()"),d3t.forEach(t),Btr=r(bre," to load the model weights."),bre.forEach(t),Ntr=i(g6),T(rF.$$.fragment,g6),g6.forEach(t),Itr=i(fl),lo=n(fl,"DIV",{class:!0});var ua=s(lo);T(v8.$$.fragment,ua),qtr=i(ua),f1e=n(ua,"P",{});var c3t=s(f1e);jtr=r(c3t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),c3t.forEach(t),Dtr=i(ua),Qa=n(ua,"P",{});var h6=s(Qa);Gtr=r(h6,"The model class to instantiate is selected based on the "),m1e=n(h6,"CODE",{});var f3t=s(m1e);Otr=r(f3t,"model_type"),f3t.forEach(t),Vtr=r(h6,` property of the config object (either
passed as an argument or loaded from `),g1e=n(h6,"CODE",{});var m3t=s(g1e);Xtr=r(m3t,"pretrained_model_name_or_path"),m3t.forEach(t),ztr=r(h6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h1e=n(h6,"CODE",{});var g3t=s(h1e);Qtr=r(g3t,"pretrained_model_name_or_path"),g3t.forEach(t),Wtr=r(h6,":"),h6.forEach(t),Htr=i(ua),Fe=n(ua,"UL",{});var Te=s(Fe);tF=n(Te,"LI",{});var $Be=s(tF);p1e=n($Be,"STRONG",{});var h3t=s(p1e);Utr=r(h3t,"beit"),h3t.forEach(t),Jtr=r($Be," \u2014 "),IQ=n($Be,"A",{href:!0});var p3t=s(IQ);Ytr=r(p3t,"BeitForImageClassification"),p3t.forEach(t),Ktr=r($Be," (BEiT model)"),$Be.forEach(t),Ztr=i(Te),aF=n(Te,"LI",{});var kBe=s(aF);_1e=n(kBe,"STRONG",{});var _3t=s(_1e);ear=r(_3t,"convnext"),_3t.forEach(t),oar=r(kBe," \u2014 "),qQ=n(kBe,"A",{href:!0});var u3t=s(qQ);rar=r(u3t,"ConvNextForImageClassification"),u3t.forEach(t),tar=r(kBe," (ConvNeXT model)"),kBe.forEach(t),aar=i(Te),nF=n(Te,"LI",{});var SBe=s(nF);u1e=n(SBe,"STRONG",{});var b3t=s(u1e);nar=r(b3t,"cvt"),b3t.forEach(t),sar=r(SBe," \u2014 "),jQ=n(SBe,"A",{href:!0});var v3t=s(jQ);lar=r(v3t,"CvtForImageClassification"),v3t.forEach(t),iar=r(SBe," (CvT model)"),SBe.forEach(t),dar=i(Te),sF=n(Te,"LI",{});var RBe=s(sF);b1e=n(RBe,"STRONG",{});var F3t=s(b1e);car=r(F3t,"data2vec-vision"),F3t.forEach(t),far=r(RBe," \u2014 "),DQ=n(RBe,"A",{href:!0});var T3t=s(DQ);mar=r(T3t,"Data2VecVisionForImageClassification"),T3t.forEach(t),gar=r(RBe," (Data2VecVision model)"),RBe.forEach(t),har=i(Te),Ws=n(Te,"LI",{});var hS=s(Ws);v1e=n(hS,"STRONG",{});var M3t=s(v1e);par=r(M3t,"deit"),M3t.forEach(t),_ar=r(hS," \u2014 "),GQ=n(hS,"A",{href:!0});var E3t=s(GQ);uar=r(E3t,"DeiTForImageClassification"),E3t.forEach(t),bar=r(hS," or "),OQ=n(hS,"A",{href:!0});var C3t=s(OQ);Far=r(C3t,"DeiTForImageClassificationWithTeacher"),C3t.forEach(t),Tar=r(hS," (DeiT model)"),hS.forEach(t),Mar=i(Te),lF=n(Te,"LI",{});var PBe=s(lF);F1e=n(PBe,"STRONG",{});var w3t=s(F1e);Ear=r(w3t,"imagegpt"),w3t.forEach(t),Car=r(PBe," \u2014 "),VQ=n(PBe,"A",{href:!0});var A3t=s(VQ);war=r(A3t,"ImageGPTForImageClassification"),A3t.forEach(t),Aar=r(PBe," (ImageGPT model)"),PBe.forEach(t),Lar=i(Te),Hs=n(Te,"LI",{});var pS=s(Hs);T1e=n(pS,"STRONG",{});var L3t=s(T1e);yar=r(L3t,"levit"),L3t.forEach(t),xar=r(pS," \u2014 "),XQ=n(pS,"A",{href:!0});var y3t=s(XQ);$ar=r(y3t,"LevitForImageClassification"),y3t.forEach(t),kar=r(pS," or "),zQ=n(pS,"A",{href:!0});var x3t=s(zQ);Sar=r(x3t,"LevitForImageClassificationWithTeacher"),x3t.forEach(t),Rar=r(pS," (LeViT model)"),pS.forEach(t),Par=i(Te),bt=n(Te,"LI",{});var $f=s(bt);M1e=n($f,"STRONG",{});var $3t=s(M1e);Bar=r($3t,"perceiver"),$3t.forEach(t),Nar=r($f," \u2014 "),QQ=n($f,"A",{href:!0});var k3t=s(QQ);Iar=r(k3t,"PerceiverForImageClassificationLearned"),k3t.forEach(t),qar=r($f," or "),WQ=n($f,"A",{href:!0});var S3t=s(WQ);jar=r(S3t,"PerceiverForImageClassificationFourier"),S3t.forEach(t),Dar=r($f," or "),HQ=n($f,"A",{href:!0});var R3t=s(HQ);Gar=r(R3t,"PerceiverForImageClassificationConvProcessing"),R3t.forEach(t),Oar=r($f," (Perceiver model)"),$f.forEach(t),Var=i(Te),iF=n(Te,"LI",{});var BBe=s(iF);E1e=n(BBe,"STRONG",{});var P3t=s(E1e);Xar=r(P3t,"poolformer"),P3t.forEach(t),zar=r(BBe," \u2014 "),UQ=n(BBe,"A",{href:!0});var B3t=s(UQ);Qar=r(B3t,"PoolFormerForImageClassification"),B3t.forEach(t),War=r(BBe," (PoolFormer model)"),BBe.forEach(t),Har=i(Te),dF=n(Te,"LI",{});var NBe=s(dF);C1e=n(NBe,"STRONG",{});var N3t=s(C1e);Uar=r(N3t,"regnet"),N3t.forEach(t),Jar=r(NBe," \u2014 "),JQ=n(NBe,"A",{href:!0});var I3t=s(JQ);Yar=r(I3t,"RegNetForImageClassification"),I3t.forEach(t),Kar=r(NBe," (RegNet model)"),NBe.forEach(t),Zar=i(Te),cF=n(Te,"LI",{});var IBe=s(cF);w1e=n(IBe,"STRONG",{});var q3t=s(w1e);enr=r(q3t,"resnet"),q3t.forEach(t),onr=r(IBe," \u2014 "),YQ=n(IBe,"A",{href:!0});var j3t=s(YQ);rnr=r(j3t,"ResNetForImageClassification"),j3t.forEach(t),tnr=r(IBe," (ResNet model)"),IBe.forEach(t),anr=i(Te),fF=n(Te,"LI",{});var qBe=s(fF);A1e=n(qBe,"STRONG",{});var D3t=s(A1e);nnr=r(D3t,"segformer"),D3t.forEach(t),snr=r(qBe," \u2014 "),KQ=n(qBe,"A",{href:!0});var G3t=s(KQ);lnr=r(G3t,"SegformerForImageClassification"),G3t.forEach(t),inr=r(qBe," (SegFormer model)"),qBe.forEach(t),dnr=i(Te),mF=n(Te,"LI",{});var jBe=s(mF);L1e=n(jBe,"STRONG",{});var O3t=s(L1e);cnr=r(O3t,"swin"),O3t.forEach(t),fnr=r(jBe," \u2014 "),ZQ=n(jBe,"A",{href:!0});var V3t=s(ZQ);mnr=r(V3t,"SwinForImageClassification"),V3t.forEach(t),gnr=r(jBe," (Swin Transformer model)"),jBe.forEach(t),hnr=i(Te),gF=n(Te,"LI",{});var DBe=s(gF);y1e=n(DBe,"STRONG",{});var X3t=s(y1e);pnr=r(X3t,"van"),X3t.forEach(t),_nr=r(DBe," \u2014 "),eW=n(DBe,"A",{href:!0});var z3t=s(eW);unr=r(z3t,"VanForImageClassification"),z3t.forEach(t),bnr=r(DBe," (VAN model)"),DBe.forEach(t),vnr=i(Te),hF=n(Te,"LI",{});var GBe=s(hF);x1e=n(GBe,"STRONG",{});var Q3t=s(x1e);Fnr=r(Q3t,"vit"),Q3t.forEach(t),Tnr=r(GBe," \u2014 "),oW=n(GBe,"A",{href:!0});var W3t=s(oW);Mnr=r(W3t,"ViTForImageClassification"),W3t.forEach(t),Enr=r(GBe," (ViT model)"),GBe.forEach(t),Te.forEach(t),Cnr=i(ua),pF=n(ua,"P",{});var OBe=s(pF);wnr=r(OBe,"The model is set in evaluation mode by default using "),$1e=n(OBe,"CODE",{});var H3t=s($1e);Anr=r(H3t,"model.eval()"),H3t.forEach(t),Lnr=r(OBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k1e=n(OBe,"CODE",{});var U3t=s(k1e);ynr=r(U3t,"model.train()"),U3t.forEach(t),OBe.forEach(t),xnr=i(ua),T(_F.$$.fragment,ua),ua.forEach(t),fl.forEach(t),MVe=i(f),Fd=n(f,"H2",{class:!0});var yze=s(Fd);uF=n(yze,"A",{id:!0,class:!0,href:!0});var J3t=s(uF);S1e=n(J3t,"SPAN",{});var Y3t=s(S1e);T(F8.$$.fragment,Y3t),Y3t.forEach(t),J3t.forEach(t),$nr=i(yze),R1e=n(yze,"SPAN",{});var K3t=s(R1e);knr=r(K3t,"AutoModelForVision2Seq"),K3t.forEach(t),yze.forEach(t),EVe=i(f),Oo=n(f,"DIV",{class:!0});var ml=s(Oo);T(T8.$$.fragment,ml),Snr=i(ml),Td=n(ml,"P",{});var vre=s(Td);Rnr=r(vre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),rW=n(vre,"A",{href:!0});var Z3t=s(rW);Pnr=r(Z3t,"from_pretrained()"),Z3t.forEach(t),Bnr=r(vre," class method or the "),tW=n(vre,"A",{href:!0});var e5t=s(tW);Nnr=r(e5t,"from_config()"),e5t.forEach(t),Inr=r(vre,` class
method.`),vre.forEach(t),qnr=i(ml),M8=n(ml,"P",{});var xze=s(M8);jnr=r(xze,"This class cannot be instantiated directly using "),P1e=n(xze,"CODE",{});var o5t=s(P1e);Dnr=r(o5t,"__init__()"),o5t.forEach(t),Gnr=r(xze," (throws an error)."),xze.forEach(t),Onr=i(ml),vt=n(ml,"DIV",{class:!0});var p6=s(vt);T(E8.$$.fragment,p6),Vnr=i(p6),B1e=n(p6,"P",{});var r5t=s(B1e);Xnr=r(r5t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),r5t.forEach(t),znr=i(p6),Md=n(p6,"P",{});var Fre=s(Md);Qnr=r(Fre,`Note:
Loading a model from its configuration file does `),N1e=n(Fre,"STRONG",{});var t5t=s(N1e);Wnr=r(t5t,"not"),t5t.forEach(t),Hnr=r(Fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),aW=n(Fre,"A",{href:!0});var a5t=s(aW);Unr=r(a5t,"from_pretrained()"),a5t.forEach(t),Jnr=r(Fre," to load the model weights."),Fre.forEach(t),Ynr=i(p6),T(bF.$$.fragment,p6),p6.forEach(t),Knr=i(ml),io=n(ml,"DIV",{class:!0});var ba=s(io);T(C8.$$.fragment,ba),Znr=i(ba),I1e=n(ba,"P",{});var n5t=s(I1e);esr=r(n5t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),n5t.forEach(t),osr=i(ba),Wa=n(ba,"P",{});var _6=s(Wa);rsr=r(_6,"The model class to instantiate is selected based on the "),q1e=n(_6,"CODE",{});var s5t=s(q1e);tsr=r(s5t,"model_type"),s5t.forEach(t),asr=r(_6,` property of the config object (either
passed as an argument or loaded from `),j1e=n(_6,"CODE",{});var l5t=s(j1e);nsr=r(l5t,"pretrained_model_name_or_path"),l5t.forEach(t),ssr=r(_6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D1e=n(_6,"CODE",{});var i5t=s(D1e);lsr=r(i5t,"pretrained_model_name_or_path"),i5t.forEach(t),isr=r(_6,":"),_6.forEach(t),dsr=i(ba),G1e=n(ba,"UL",{});var d5t=s(G1e);vF=n(d5t,"LI",{});var VBe=s(vF);O1e=n(VBe,"STRONG",{});var c5t=s(O1e);csr=r(c5t,"vision-encoder-decoder"),c5t.forEach(t),fsr=r(VBe," \u2014 "),nW=n(VBe,"A",{href:!0});var f5t=s(nW);msr=r(f5t,"VisionEncoderDecoderModel"),f5t.forEach(t),gsr=r(VBe," (Vision Encoder decoder model)"),VBe.forEach(t),d5t.forEach(t),hsr=i(ba),FF=n(ba,"P",{});var XBe=s(FF);psr=r(XBe,"The model is set in evaluation mode by default using "),V1e=n(XBe,"CODE",{});var m5t=s(V1e);_sr=r(m5t,"model.eval()"),m5t.forEach(t),usr=r(XBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X1e=n(XBe,"CODE",{});var g5t=s(X1e);bsr=r(g5t,"model.train()"),g5t.forEach(t),XBe.forEach(t),vsr=i(ba),T(TF.$$.fragment,ba),ba.forEach(t),ml.forEach(t),CVe=i(f),Ed=n(f,"H2",{class:!0});var $ze=s(Ed);MF=n($ze,"A",{id:!0,class:!0,href:!0});var h5t=s(MF);z1e=n(h5t,"SPAN",{});var p5t=s(z1e);T(w8.$$.fragment,p5t),p5t.forEach(t),h5t.forEach(t),Fsr=i($ze),Q1e=n($ze,"SPAN",{});var _5t=s(Q1e);Tsr=r(_5t,"AutoModelForVisualQuestionAnswering"),_5t.forEach(t),$ze.forEach(t),wVe=i(f),Vo=n(f,"DIV",{class:!0});var gl=s(Vo);T(A8.$$.fragment,gl),Msr=i(gl),Cd=n(gl,"P",{});var Tre=s(Cd);Esr=r(Tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),sW=n(Tre,"A",{href:!0});var u5t=s(sW);Csr=r(u5t,"from_pretrained()"),u5t.forEach(t),wsr=r(Tre," class method or the "),lW=n(Tre,"A",{href:!0});var b5t=s(lW);Asr=r(b5t,"from_config()"),b5t.forEach(t),Lsr=r(Tre,` class
method.`),Tre.forEach(t),ysr=i(gl),L8=n(gl,"P",{});var kze=s(L8);xsr=r(kze,"This class cannot be instantiated directly using "),W1e=n(kze,"CODE",{});var v5t=s(W1e);$sr=r(v5t,"__init__()"),v5t.forEach(t),ksr=r(kze," (throws an error)."),kze.forEach(t),Ssr=i(gl),Ft=n(gl,"DIV",{class:!0});var u6=s(Ft);T(y8.$$.fragment,u6),Rsr=i(u6),H1e=n(u6,"P",{});var F5t=s(H1e);Psr=r(F5t,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),F5t.forEach(t),Bsr=i(u6),wd=n(u6,"P",{});var Mre=s(wd);Nsr=r(Mre,`Note:
Loading a model from its configuration file does `),U1e=n(Mre,"STRONG",{});var T5t=s(U1e);Isr=r(T5t,"not"),T5t.forEach(t),qsr=r(Mre,` load the model weights. It only affects the
model\u2019s configuration. Use `),iW=n(Mre,"A",{href:!0});var M5t=s(iW);jsr=r(M5t,"from_pretrained()"),M5t.forEach(t),Dsr=r(Mre," to load the model weights."),Mre.forEach(t),Gsr=i(u6),T(EF.$$.fragment,u6),u6.forEach(t),Osr=i(gl),co=n(gl,"DIV",{class:!0});var va=s(co);T(x8.$$.fragment,va),Vsr=i(va),J1e=n(va,"P",{});var E5t=s(J1e);Xsr=r(E5t,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),E5t.forEach(t),zsr=i(va),Ha=n(va,"P",{});var b6=s(Ha);Qsr=r(b6,"The model class to instantiate is selected based on the "),Y1e=n(b6,"CODE",{});var C5t=s(Y1e);Wsr=r(C5t,"model_type"),C5t.forEach(t),Hsr=r(b6,` property of the config object (either
passed as an argument or loaded from `),K1e=n(b6,"CODE",{});var w5t=s(K1e);Usr=r(w5t,"pretrained_model_name_or_path"),w5t.forEach(t),Jsr=r(b6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=n(b6,"CODE",{});var A5t=s(Z1e);Ysr=r(A5t,"pretrained_model_name_or_path"),A5t.forEach(t),Ksr=r(b6,":"),b6.forEach(t),Zsr=i(va),e7e=n(va,"UL",{});var L5t=s(e7e);CF=n(L5t,"LI",{});var zBe=s(CF);o7e=n(zBe,"STRONG",{});var y5t=s(o7e);elr=r(y5t,"vilt"),y5t.forEach(t),olr=r(zBe," \u2014 "),dW=n(zBe,"A",{href:!0});var x5t=s(dW);rlr=r(x5t,"ViltForQuestionAnswering"),x5t.forEach(t),tlr=r(zBe," (ViLT model)"),zBe.forEach(t),L5t.forEach(t),alr=i(va),wF=n(va,"P",{});var QBe=s(wF);nlr=r(QBe,"The model is set in evaluation mode by default using "),r7e=n(QBe,"CODE",{});var $5t=s(r7e);slr=r($5t,"model.eval()"),$5t.forEach(t),llr=r(QBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t7e=n(QBe,"CODE",{});var k5t=s(t7e);ilr=r(k5t,"model.train()"),k5t.forEach(t),QBe.forEach(t),dlr=i(va),T(AF.$$.fragment,va),va.forEach(t),gl.forEach(t),AVe=i(f),Ad=n(f,"H2",{class:!0});var Sze=s(Ad);LF=n(Sze,"A",{id:!0,class:!0,href:!0});var S5t=s(LF);a7e=n(S5t,"SPAN",{});var R5t=s(a7e);T($8.$$.fragment,R5t),R5t.forEach(t),S5t.forEach(t),clr=i(Sze),n7e=n(Sze,"SPAN",{});var P5t=s(n7e);flr=r(P5t,"AutoModelForAudioClassification"),P5t.forEach(t),Sze.forEach(t),LVe=i(f),Xo=n(f,"DIV",{class:!0});var hl=s(Xo);T(k8.$$.fragment,hl),mlr=i(hl),Ld=n(hl,"P",{});var Ere=s(Ld);glr=r(Ere,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),cW=n(Ere,"A",{href:!0});var B5t=s(cW);hlr=r(B5t,"from_pretrained()"),B5t.forEach(t),plr=r(Ere," class method or the "),fW=n(Ere,"A",{href:!0});var N5t=s(fW);_lr=r(N5t,"from_config()"),N5t.forEach(t),ulr=r(Ere,` class
method.`),Ere.forEach(t),blr=i(hl),S8=n(hl,"P",{});var Rze=s(S8);vlr=r(Rze,"This class cannot be instantiated directly using "),s7e=n(Rze,"CODE",{});var I5t=s(s7e);Flr=r(I5t,"__init__()"),I5t.forEach(t),Tlr=r(Rze," (throws an error)."),Rze.forEach(t),Mlr=i(hl),Tt=n(hl,"DIV",{class:!0});var v6=s(Tt);T(R8.$$.fragment,v6),Elr=i(v6),l7e=n(v6,"P",{});var q5t=s(l7e);Clr=r(q5t,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),q5t.forEach(t),wlr=i(v6),yd=n(v6,"P",{});var Cre=s(yd);Alr=r(Cre,`Note:
Loading a model from its configuration file does `),i7e=n(Cre,"STRONG",{});var j5t=s(i7e);Llr=r(j5t,"not"),j5t.forEach(t),ylr=r(Cre,` load the model weights. It only affects the
model\u2019s configuration. Use `),mW=n(Cre,"A",{href:!0});var D5t=s(mW);xlr=r(D5t,"from_pretrained()"),D5t.forEach(t),$lr=r(Cre," to load the model weights."),Cre.forEach(t),klr=i(v6),T(yF.$$.fragment,v6),v6.forEach(t),Slr=i(hl),fo=n(hl,"DIV",{class:!0});var Fa=s(fo);T(P8.$$.fragment,Fa),Rlr=i(Fa),d7e=n(Fa,"P",{});var G5t=s(d7e);Plr=r(G5t,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),G5t.forEach(t),Blr=i(Fa),Ua=n(Fa,"P",{});var F6=s(Ua);Nlr=r(F6,"The model class to instantiate is selected based on the "),c7e=n(F6,"CODE",{});var O5t=s(c7e);Ilr=r(O5t,"model_type"),O5t.forEach(t),qlr=r(F6,` property of the config object (either
passed as an argument or loaded from `),f7e=n(F6,"CODE",{});var V5t=s(f7e);jlr=r(V5t,"pretrained_model_name_or_path"),V5t.forEach(t),Dlr=r(F6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m7e=n(F6,"CODE",{});var X5t=s(m7e);Glr=r(X5t,"pretrained_model_name_or_path"),X5t.forEach(t),Olr=r(F6,":"),F6.forEach(t),Vlr=i(Fa),Pe=n(Fa,"UL",{});var ze=s(Pe);xF=n(ze,"LI",{});var WBe=s(xF);g7e=n(WBe,"STRONG",{});var z5t=s(g7e);Xlr=r(z5t,"data2vec-audio"),z5t.forEach(t),zlr=r(WBe," \u2014 "),gW=n(WBe,"A",{href:!0});var Q5t=s(gW);Qlr=r(Q5t,"Data2VecAudioForSequenceClassification"),Q5t.forEach(t),Wlr=r(WBe," (Data2VecAudio model)"),WBe.forEach(t),Hlr=i(ze),$F=n(ze,"LI",{});var HBe=s($F);h7e=n(HBe,"STRONG",{});var W5t=s(h7e);Ulr=r(W5t,"hubert"),W5t.forEach(t),Jlr=r(HBe," \u2014 "),hW=n(HBe,"A",{href:!0});var H5t=s(hW);Ylr=r(H5t,"HubertForSequenceClassification"),H5t.forEach(t),Klr=r(HBe," (Hubert model)"),HBe.forEach(t),Zlr=i(ze),kF=n(ze,"LI",{});var UBe=s(kF);p7e=n(UBe,"STRONG",{});var U5t=s(p7e);eir=r(U5t,"sew"),U5t.forEach(t),oir=r(UBe," \u2014 "),pW=n(UBe,"A",{href:!0});var J5t=s(pW);rir=r(J5t,"SEWForSequenceClassification"),J5t.forEach(t),tir=r(UBe," (SEW model)"),UBe.forEach(t),air=i(ze),SF=n(ze,"LI",{});var JBe=s(SF);_7e=n(JBe,"STRONG",{});var Y5t=s(_7e);nir=r(Y5t,"sew-d"),Y5t.forEach(t),sir=r(JBe," \u2014 "),_W=n(JBe,"A",{href:!0});var K5t=s(_W);lir=r(K5t,"SEWDForSequenceClassification"),K5t.forEach(t),iir=r(JBe," (SEW-D model)"),JBe.forEach(t),dir=i(ze),RF=n(ze,"LI",{});var YBe=s(RF);u7e=n(YBe,"STRONG",{});var Z5t=s(u7e);cir=r(Z5t,"unispeech"),Z5t.forEach(t),fir=r(YBe," \u2014 "),uW=n(YBe,"A",{href:!0});var e0t=s(uW);mir=r(e0t,"UniSpeechForSequenceClassification"),e0t.forEach(t),gir=r(YBe," (UniSpeech model)"),YBe.forEach(t),hir=i(ze),PF=n(ze,"LI",{});var KBe=s(PF);b7e=n(KBe,"STRONG",{});var o0t=s(b7e);pir=r(o0t,"unispeech-sat"),o0t.forEach(t),_ir=r(KBe," \u2014 "),bW=n(KBe,"A",{href:!0});var r0t=s(bW);uir=r(r0t,"UniSpeechSatForSequenceClassification"),r0t.forEach(t),bir=r(KBe," (UniSpeechSat model)"),KBe.forEach(t),vir=i(ze),BF=n(ze,"LI",{});var ZBe=s(BF);v7e=n(ZBe,"STRONG",{});var t0t=s(v7e);Fir=r(t0t,"wav2vec2"),t0t.forEach(t),Tir=r(ZBe," \u2014 "),vW=n(ZBe,"A",{href:!0});var a0t=s(vW);Mir=r(a0t,"Wav2Vec2ForSequenceClassification"),a0t.forEach(t),Eir=r(ZBe," (Wav2Vec2 model)"),ZBe.forEach(t),Cir=i(ze),NF=n(ze,"LI",{});var eNe=s(NF);F7e=n(eNe,"STRONG",{});var n0t=s(F7e);wir=r(n0t,"wav2vec2-conformer"),n0t.forEach(t),Air=r(eNe," \u2014 "),FW=n(eNe,"A",{href:!0});var s0t=s(FW);Lir=r(s0t,"Wav2Vec2ConformerForSequenceClassification"),s0t.forEach(t),yir=r(eNe," (Wav2Vec2-Conformer model)"),eNe.forEach(t),xir=i(ze),IF=n(ze,"LI",{});var oNe=s(IF);T7e=n(oNe,"STRONG",{});var l0t=s(T7e);$ir=r(l0t,"wavlm"),l0t.forEach(t),kir=r(oNe," \u2014 "),TW=n(oNe,"A",{href:!0});var i0t=s(TW);Sir=r(i0t,"WavLMForSequenceClassification"),i0t.forEach(t),Rir=r(oNe," (WavLM model)"),oNe.forEach(t),ze.forEach(t),Pir=i(Fa),qF=n(Fa,"P",{});var rNe=s(qF);Bir=r(rNe,"The model is set in evaluation mode by default using "),M7e=n(rNe,"CODE",{});var d0t=s(M7e);Nir=r(d0t,"model.eval()"),d0t.forEach(t),Iir=r(rNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E7e=n(rNe,"CODE",{});var c0t=s(E7e);qir=r(c0t,"model.train()"),c0t.forEach(t),rNe.forEach(t),jir=i(Fa),T(jF.$$.fragment,Fa),Fa.forEach(t),hl.forEach(t),yVe=i(f),xd=n(f,"H2",{class:!0});var Pze=s(xd);DF=n(Pze,"A",{id:!0,class:!0,href:!0});var f0t=s(DF);C7e=n(f0t,"SPAN",{});var m0t=s(C7e);T(B8.$$.fragment,m0t),m0t.forEach(t),f0t.forEach(t),Dir=i(Pze),w7e=n(Pze,"SPAN",{});var g0t=s(w7e);Gir=r(g0t,"AutoModelForAudioFrameClassification"),g0t.forEach(t),Pze.forEach(t),xVe=i(f),zo=n(f,"DIV",{class:!0});var pl=s(zo);T(N8.$$.fragment,pl),Oir=i(pl),$d=n(pl,"P",{});var wre=s($d);Vir=r(wre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),MW=n(wre,"A",{href:!0});var h0t=s(MW);Xir=r(h0t,"from_pretrained()"),h0t.forEach(t),zir=r(wre," class method or the "),EW=n(wre,"A",{href:!0});var p0t=s(EW);Qir=r(p0t,"from_config()"),p0t.forEach(t),Wir=r(wre,` class
method.`),wre.forEach(t),Hir=i(pl),I8=n(pl,"P",{});var Bze=s(I8);Uir=r(Bze,"This class cannot be instantiated directly using "),A7e=n(Bze,"CODE",{});var _0t=s(A7e);Jir=r(_0t,"__init__()"),_0t.forEach(t),Yir=r(Bze," (throws an error)."),Bze.forEach(t),Kir=i(pl),Mt=n(pl,"DIV",{class:!0});var T6=s(Mt);T(q8.$$.fragment,T6),Zir=i(T6),L7e=n(T6,"P",{});var u0t=s(L7e);edr=r(u0t,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),u0t.forEach(t),odr=i(T6),kd=n(T6,"P",{});var Are=s(kd);rdr=r(Are,`Note:
Loading a model from its configuration file does `),y7e=n(Are,"STRONG",{});var b0t=s(y7e);tdr=r(b0t,"not"),b0t.forEach(t),adr=r(Are,` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=n(Are,"A",{href:!0});var v0t=s(CW);ndr=r(v0t,"from_pretrained()"),v0t.forEach(t),sdr=r(Are," to load the model weights."),Are.forEach(t),ldr=i(T6),T(GF.$$.fragment,T6),T6.forEach(t),idr=i(pl),mo=n(pl,"DIV",{class:!0});var Ta=s(mo);T(j8.$$.fragment,Ta),ddr=i(Ta),x7e=n(Ta,"P",{});var F0t=s(x7e);cdr=r(F0t,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),F0t.forEach(t),fdr=i(Ta),Ja=n(Ta,"P",{});var M6=s(Ja);mdr=r(M6,"The model class to instantiate is selected based on the "),$7e=n(M6,"CODE",{});var T0t=s($7e);gdr=r(T0t,"model_type"),T0t.forEach(t),hdr=r(M6,` property of the config object (either
passed as an argument or loaded from `),k7e=n(M6,"CODE",{});var M0t=s(k7e);pdr=r(M0t,"pretrained_model_name_or_path"),M0t.forEach(t),_dr=r(M6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S7e=n(M6,"CODE",{});var E0t=s(S7e);udr=r(E0t,"pretrained_model_name_or_path"),E0t.forEach(t),bdr=r(M6,":"),M6.forEach(t),vdr=i(Ta),ot=n(Ta,"UL",{});var _l=s(ot);OF=n(_l,"LI",{});var tNe=s(OF);R7e=n(tNe,"STRONG",{});var C0t=s(R7e);Fdr=r(C0t,"data2vec-audio"),C0t.forEach(t),Tdr=r(tNe," \u2014 "),wW=n(tNe,"A",{href:!0});var w0t=s(wW);Mdr=r(w0t,"Data2VecAudioForAudioFrameClassification"),w0t.forEach(t),Edr=r(tNe," (Data2VecAudio model)"),tNe.forEach(t),Cdr=i(_l),VF=n(_l,"LI",{});var aNe=s(VF);P7e=n(aNe,"STRONG",{});var A0t=s(P7e);wdr=r(A0t,"unispeech-sat"),A0t.forEach(t),Adr=r(aNe," \u2014 "),AW=n(aNe,"A",{href:!0});var L0t=s(AW);Ldr=r(L0t,"UniSpeechSatForAudioFrameClassification"),L0t.forEach(t),ydr=r(aNe," (UniSpeechSat model)"),aNe.forEach(t),xdr=i(_l),XF=n(_l,"LI",{});var nNe=s(XF);B7e=n(nNe,"STRONG",{});var y0t=s(B7e);$dr=r(y0t,"wav2vec2"),y0t.forEach(t),kdr=r(nNe," \u2014 "),LW=n(nNe,"A",{href:!0});var x0t=s(LW);Sdr=r(x0t,"Wav2Vec2ForAudioFrameClassification"),x0t.forEach(t),Rdr=r(nNe," (Wav2Vec2 model)"),nNe.forEach(t),Pdr=i(_l),zF=n(_l,"LI",{});var sNe=s(zF);N7e=n(sNe,"STRONG",{});var $0t=s(N7e);Bdr=r($0t,"wav2vec2-conformer"),$0t.forEach(t),Ndr=r(sNe," \u2014 "),yW=n(sNe,"A",{href:!0});var k0t=s(yW);Idr=r(k0t,"Wav2Vec2ConformerForAudioFrameClassification"),k0t.forEach(t),qdr=r(sNe," (Wav2Vec2-Conformer model)"),sNe.forEach(t),jdr=i(_l),QF=n(_l,"LI",{});var lNe=s(QF);I7e=n(lNe,"STRONG",{});var S0t=s(I7e);Ddr=r(S0t,"wavlm"),S0t.forEach(t),Gdr=r(lNe," \u2014 "),xW=n(lNe,"A",{href:!0});var R0t=s(xW);Odr=r(R0t,"WavLMForAudioFrameClassification"),R0t.forEach(t),Vdr=r(lNe," (WavLM model)"),lNe.forEach(t),_l.forEach(t),Xdr=i(Ta),WF=n(Ta,"P",{});var iNe=s(WF);zdr=r(iNe,"The model is set in evaluation mode by default using "),q7e=n(iNe,"CODE",{});var P0t=s(q7e);Qdr=r(P0t,"model.eval()"),P0t.forEach(t),Wdr=r(iNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j7e=n(iNe,"CODE",{});var B0t=s(j7e);Hdr=r(B0t,"model.train()"),B0t.forEach(t),iNe.forEach(t),Udr=i(Ta),T(HF.$$.fragment,Ta),Ta.forEach(t),pl.forEach(t),$Ve=i(f),Sd=n(f,"H2",{class:!0});var Nze=s(Sd);UF=n(Nze,"A",{id:!0,class:!0,href:!0});var N0t=s(UF);D7e=n(N0t,"SPAN",{});var I0t=s(D7e);T(D8.$$.fragment,I0t),I0t.forEach(t),N0t.forEach(t),Jdr=i(Nze),G7e=n(Nze,"SPAN",{});var q0t=s(G7e);Ydr=r(q0t,"AutoModelForCTC"),q0t.forEach(t),Nze.forEach(t),kVe=i(f),Qo=n(f,"DIV",{class:!0});var ul=s(Qo);T(G8.$$.fragment,ul),Kdr=i(ul),Rd=n(ul,"P",{});var Lre=s(Rd);Zdr=r(Lre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),$W=n(Lre,"A",{href:!0});var j0t=s($W);ecr=r(j0t,"from_pretrained()"),j0t.forEach(t),ocr=r(Lre," class method or the "),kW=n(Lre,"A",{href:!0});var D0t=s(kW);rcr=r(D0t,"from_config()"),D0t.forEach(t),tcr=r(Lre,` class
method.`),Lre.forEach(t),acr=i(ul),O8=n(ul,"P",{});var Ize=s(O8);ncr=r(Ize,"This class cannot be instantiated directly using "),O7e=n(Ize,"CODE",{});var G0t=s(O7e);scr=r(G0t,"__init__()"),G0t.forEach(t),lcr=r(Ize," (throws an error)."),Ize.forEach(t),icr=i(ul),Et=n(ul,"DIV",{class:!0});var E6=s(Et);T(V8.$$.fragment,E6),dcr=i(E6),V7e=n(E6,"P",{});var O0t=s(V7e);ccr=r(O0t,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),O0t.forEach(t),fcr=i(E6),Pd=n(E6,"P",{});var yre=s(Pd);mcr=r(yre,`Note:
Loading a model from its configuration file does `),X7e=n(yre,"STRONG",{});var V0t=s(X7e);gcr=r(V0t,"not"),V0t.forEach(t),hcr=r(yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=n(yre,"A",{href:!0});var X0t=s(SW);pcr=r(X0t,"from_pretrained()"),X0t.forEach(t),_cr=r(yre," to load the model weights."),yre.forEach(t),ucr=i(E6),T(JF.$$.fragment,E6),E6.forEach(t),bcr=i(ul),go=n(ul,"DIV",{class:!0});var Ma=s(go);T(X8.$$.fragment,Ma),vcr=i(Ma),z7e=n(Ma,"P",{});var z0t=s(z7e);Fcr=r(z0t,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),z0t.forEach(t),Tcr=i(Ma),Ya=n(Ma,"P",{});var C6=s(Ya);Mcr=r(C6,"The model class to instantiate is selected based on the "),Q7e=n(C6,"CODE",{});var Q0t=s(Q7e);Ecr=r(Q0t,"model_type"),Q0t.forEach(t),Ccr=r(C6,` property of the config object (either
passed as an argument or loaded from `),W7e=n(C6,"CODE",{});var W0t=s(W7e);wcr=r(W0t,"pretrained_model_name_or_path"),W0t.forEach(t),Acr=r(C6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H7e=n(C6,"CODE",{});var H0t=s(H7e);Lcr=r(H0t,"pretrained_model_name_or_path"),H0t.forEach(t),ycr=r(C6,":"),C6.forEach(t),xcr=i(Ma),Le=n(Ma,"UL",{});var Be=s(Le);YF=n(Be,"LI",{});var dNe=s(YF);U7e=n(dNe,"STRONG",{});var U0t=s(U7e);$cr=r(U0t,"data2vec-audio"),U0t.forEach(t),kcr=r(dNe," \u2014 "),RW=n(dNe,"A",{href:!0});var J0t=s(RW);Scr=r(J0t,"Data2VecAudioForCTC"),J0t.forEach(t),Rcr=r(dNe," (Data2VecAudio model)"),dNe.forEach(t),Pcr=i(Be),KF=n(Be,"LI",{});var cNe=s(KF);J7e=n(cNe,"STRONG",{});var Y0t=s(J7e);Bcr=r(Y0t,"hubert"),Y0t.forEach(t),Ncr=r(cNe," \u2014 "),PW=n(cNe,"A",{href:!0});var K0t=s(PW);Icr=r(K0t,"HubertForCTC"),K0t.forEach(t),qcr=r(cNe," (Hubert model)"),cNe.forEach(t),jcr=i(Be),ZF=n(Be,"LI",{});var fNe=s(ZF);Y7e=n(fNe,"STRONG",{});var Z0t=s(Y7e);Dcr=r(Z0t,"mctct"),Z0t.forEach(t),Gcr=r(fNe," \u2014 "),BW=n(fNe,"A",{href:!0});var ewt=s(BW);Ocr=r(ewt,"MCTCTForCTC"),ewt.forEach(t),Vcr=r(fNe," (M-CTC-T model)"),fNe.forEach(t),Xcr=i(Be),eT=n(Be,"LI",{});var mNe=s(eT);K7e=n(mNe,"STRONG",{});var owt=s(K7e);zcr=r(owt,"sew"),owt.forEach(t),Qcr=r(mNe," \u2014 "),NW=n(mNe,"A",{href:!0});var rwt=s(NW);Wcr=r(rwt,"SEWForCTC"),rwt.forEach(t),Hcr=r(mNe," (SEW model)"),mNe.forEach(t),Ucr=i(Be),oT=n(Be,"LI",{});var gNe=s(oT);Z7e=n(gNe,"STRONG",{});var twt=s(Z7e);Jcr=r(twt,"sew-d"),twt.forEach(t),Ycr=r(gNe," \u2014 "),IW=n(gNe,"A",{href:!0});var awt=s(IW);Kcr=r(awt,"SEWDForCTC"),awt.forEach(t),Zcr=r(gNe," (SEW-D model)"),gNe.forEach(t),efr=i(Be),rT=n(Be,"LI",{});var hNe=s(rT);e4e=n(hNe,"STRONG",{});var nwt=s(e4e);ofr=r(nwt,"unispeech"),nwt.forEach(t),rfr=r(hNe," \u2014 "),qW=n(hNe,"A",{href:!0});var swt=s(qW);tfr=r(swt,"UniSpeechForCTC"),swt.forEach(t),afr=r(hNe," (UniSpeech model)"),hNe.forEach(t),nfr=i(Be),tT=n(Be,"LI",{});var pNe=s(tT);o4e=n(pNe,"STRONG",{});var lwt=s(o4e);sfr=r(lwt,"unispeech-sat"),lwt.forEach(t),lfr=r(pNe," \u2014 "),jW=n(pNe,"A",{href:!0});var iwt=s(jW);ifr=r(iwt,"UniSpeechSatForCTC"),iwt.forEach(t),dfr=r(pNe," (UniSpeechSat model)"),pNe.forEach(t),cfr=i(Be),aT=n(Be,"LI",{});var _Ne=s(aT);r4e=n(_Ne,"STRONG",{});var dwt=s(r4e);ffr=r(dwt,"wav2vec2"),dwt.forEach(t),mfr=r(_Ne," \u2014 "),DW=n(_Ne,"A",{href:!0});var cwt=s(DW);gfr=r(cwt,"Wav2Vec2ForCTC"),cwt.forEach(t),hfr=r(_Ne," (Wav2Vec2 model)"),_Ne.forEach(t),pfr=i(Be),nT=n(Be,"LI",{});var uNe=s(nT);t4e=n(uNe,"STRONG",{});var fwt=s(t4e);_fr=r(fwt,"wav2vec2-conformer"),fwt.forEach(t),ufr=r(uNe," \u2014 "),GW=n(uNe,"A",{href:!0});var mwt=s(GW);bfr=r(mwt,"Wav2Vec2ConformerForCTC"),mwt.forEach(t),vfr=r(uNe," (Wav2Vec2-Conformer model)"),uNe.forEach(t),Ffr=i(Be),sT=n(Be,"LI",{});var bNe=s(sT);a4e=n(bNe,"STRONG",{});var gwt=s(a4e);Tfr=r(gwt,"wavlm"),gwt.forEach(t),Mfr=r(bNe," \u2014 "),OW=n(bNe,"A",{href:!0});var hwt=s(OW);Efr=r(hwt,"WavLMForCTC"),hwt.forEach(t),Cfr=r(bNe," (WavLM model)"),bNe.forEach(t),Be.forEach(t),wfr=i(Ma),lT=n(Ma,"P",{});var vNe=s(lT);Afr=r(vNe,"The model is set in evaluation mode by default using "),n4e=n(vNe,"CODE",{});var pwt=s(n4e);Lfr=r(pwt,"model.eval()"),pwt.forEach(t),yfr=r(vNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s4e=n(vNe,"CODE",{});var _wt=s(s4e);xfr=r(_wt,"model.train()"),_wt.forEach(t),vNe.forEach(t),$fr=i(Ma),T(iT.$$.fragment,Ma),Ma.forEach(t),ul.forEach(t),SVe=i(f),Bd=n(f,"H2",{class:!0});var qze=s(Bd);dT=n(qze,"A",{id:!0,class:!0,href:!0});var uwt=s(dT);l4e=n(uwt,"SPAN",{});var bwt=s(l4e);T(z8.$$.fragment,bwt),bwt.forEach(t),uwt.forEach(t),kfr=i(qze),i4e=n(qze,"SPAN",{});var vwt=s(i4e);Sfr=r(vwt,"AutoModelForSpeechSeq2Seq"),vwt.forEach(t),qze.forEach(t),RVe=i(f),Wo=n(f,"DIV",{class:!0});var bl=s(Wo);T(Q8.$$.fragment,bl),Rfr=i(bl),Nd=n(bl,"P",{});var xre=s(Nd);Pfr=r(xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),VW=n(xre,"A",{href:!0});var Fwt=s(VW);Bfr=r(Fwt,"from_pretrained()"),Fwt.forEach(t),Nfr=r(xre," class method or the "),XW=n(xre,"A",{href:!0});var Twt=s(XW);Ifr=r(Twt,"from_config()"),Twt.forEach(t),qfr=r(xre,` class
method.`),xre.forEach(t),jfr=i(bl),W8=n(bl,"P",{});var jze=s(W8);Dfr=r(jze,"This class cannot be instantiated directly using "),d4e=n(jze,"CODE",{});var Mwt=s(d4e);Gfr=r(Mwt,"__init__()"),Mwt.forEach(t),Ofr=r(jze," (throws an error)."),jze.forEach(t),Vfr=i(bl),Ct=n(bl,"DIV",{class:!0});var w6=s(Ct);T(H8.$$.fragment,w6),Xfr=i(w6),c4e=n(w6,"P",{});var Ewt=s(c4e);zfr=r(Ewt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ewt.forEach(t),Qfr=i(w6),Id=n(w6,"P",{});var $re=s(Id);Wfr=r($re,`Note:
Loading a model from its configuration file does `),f4e=n($re,"STRONG",{});var Cwt=s(f4e);Hfr=r(Cwt,"not"),Cwt.forEach(t),Ufr=r($re,` load the model weights. It only affects the
model\u2019s configuration. Use `),zW=n($re,"A",{href:!0});var wwt=s(zW);Jfr=r(wwt,"from_pretrained()"),wwt.forEach(t),Yfr=r($re," to load the model weights."),$re.forEach(t),Kfr=i(w6),T(cT.$$.fragment,w6),w6.forEach(t),Zfr=i(bl),ho=n(bl,"DIV",{class:!0});var Ea=s(ho);T(U8.$$.fragment,Ea),emr=i(Ea),m4e=n(Ea,"P",{});var Awt=s(m4e);omr=r(Awt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Awt.forEach(t),rmr=i(Ea),Ka=n(Ea,"P",{});var A6=s(Ka);tmr=r(A6,"The model class to instantiate is selected based on the "),g4e=n(A6,"CODE",{});var Lwt=s(g4e);amr=r(Lwt,"model_type"),Lwt.forEach(t),nmr=r(A6,` property of the config object (either
passed as an argument or loaded from `),h4e=n(A6,"CODE",{});var ywt=s(h4e);smr=r(ywt,"pretrained_model_name_or_path"),ywt.forEach(t),lmr=r(A6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p4e=n(A6,"CODE",{});var xwt=s(p4e);imr=r(xwt,"pretrained_model_name_or_path"),xwt.forEach(t),dmr=r(A6,":"),A6.forEach(t),cmr=i(Ea),J8=n(Ea,"UL",{});var Dze=s(J8);fT=n(Dze,"LI",{});var FNe=s(fT);_4e=n(FNe,"STRONG",{});var $wt=s(_4e);fmr=r($wt,"speech-encoder-decoder"),$wt.forEach(t),mmr=r(FNe," \u2014 "),QW=n(FNe,"A",{href:!0});var kwt=s(QW);gmr=r(kwt,"SpeechEncoderDecoderModel"),kwt.forEach(t),hmr=r(FNe," (Speech Encoder decoder model)"),FNe.forEach(t),pmr=i(Dze),mT=n(Dze,"LI",{});var TNe=s(mT);u4e=n(TNe,"STRONG",{});var Swt=s(u4e);_mr=r(Swt,"speech_to_text"),Swt.forEach(t),umr=r(TNe," \u2014 "),WW=n(TNe,"A",{href:!0});var Rwt=s(WW);bmr=r(Rwt,"Speech2TextForConditionalGeneration"),Rwt.forEach(t),vmr=r(TNe," (Speech2Text model)"),TNe.forEach(t),Dze.forEach(t),Fmr=i(Ea),gT=n(Ea,"P",{});var MNe=s(gT);Tmr=r(MNe,"The model is set in evaluation mode by default using "),b4e=n(MNe,"CODE",{});var Pwt=s(b4e);Mmr=r(Pwt,"model.eval()"),Pwt.forEach(t),Emr=r(MNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v4e=n(MNe,"CODE",{});var Bwt=s(v4e);Cmr=r(Bwt,"model.train()"),Bwt.forEach(t),MNe.forEach(t),wmr=i(Ea),T(hT.$$.fragment,Ea),Ea.forEach(t),bl.forEach(t),PVe=i(f),qd=n(f,"H2",{class:!0});var Gze=s(qd);pT=n(Gze,"A",{id:!0,class:!0,href:!0});var Nwt=s(pT);F4e=n(Nwt,"SPAN",{});var Iwt=s(F4e);T(Y8.$$.fragment,Iwt),Iwt.forEach(t),Nwt.forEach(t),Amr=i(Gze),T4e=n(Gze,"SPAN",{});var qwt=s(T4e);Lmr=r(qwt,"AutoModelForAudioXVector"),qwt.forEach(t),Gze.forEach(t),BVe=i(f),Ho=n(f,"DIV",{class:!0});var vl=s(Ho);T(K8.$$.fragment,vl),ymr=i(vl),jd=n(vl,"P",{});var kre=s(jd);xmr=r(kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),HW=n(kre,"A",{href:!0});var jwt=s(HW);$mr=r(jwt,"from_pretrained()"),jwt.forEach(t),kmr=r(kre," class method or the "),UW=n(kre,"A",{href:!0});var Dwt=s(UW);Smr=r(Dwt,"from_config()"),Dwt.forEach(t),Rmr=r(kre,` class
method.`),kre.forEach(t),Pmr=i(vl),Z8=n(vl,"P",{});var Oze=s(Z8);Bmr=r(Oze,"This class cannot be instantiated directly using "),M4e=n(Oze,"CODE",{});var Gwt=s(M4e);Nmr=r(Gwt,"__init__()"),Gwt.forEach(t),Imr=r(Oze," (throws an error)."),Oze.forEach(t),qmr=i(vl),wt=n(vl,"DIV",{class:!0});var L6=s(wt);T(e9.$$.fragment,L6),jmr=i(L6),E4e=n(L6,"P",{});var Owt=s(E4e);Dmr=r(Owt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Owt.forEach(t),Gmr=i(L6),Dd=n(L6,"P",{});var Sre=s(Dd);Omr=r(Sre,`Note:
Loading a model from its configuration file does `),C4e=n(Sre,"STRONG",{});var Vwt=s(C4e);Vmr=r(Vwt,"not"),Vwt.forEach(t),Xmr=r(Sre,` load the model weights. It only affects the
model\u2019s configuration. Use `),JW=n(Sre,"A",{href:!0});var Xwt=s(JW);zmr=r(Xwt,"from_pretrained()"),Xwt.forEach(t),Qmr=r(Sre," to load the model weights."),Sre.forEach(t),Wmr=i(L6),T(_T.$$.fragment,L6),L6.forEach(t),Hmr=i(vl),po=n(vl,"DIV",{class:!0});var Ca=s(po);T(o9.$$.fragment,Ca),Umr=i(Ca),w4e=n(Ca,"P",{});var zwt=s(w4e);Jmr=r(zwt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),zwt.forEach(t),Ymr=i(Ca),Za=n(Ca,"P",{});var y6=s(Za);Kmr=r(y6,"The model class to instantiate is selected based on the "),A4e=n(y6,"CODE",{});var Qwt=s(A4e);Zmr=r(Qwt,"model_type"),Qwt.forEach(t),egr=r(y6,` property of the config object (either
passed as an argument or loaded from `),L4e=n(y6,"CODE",{});var Wwt=s(L4e);ogr=r(Wwt,"pretrained_model_name_or_path"),Wwt.forEach(t),rgr=r(y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y4e=n(y6,"CODE",{});var Hwt=s(y4e);tgr=r(Hwt,"pretrained_model_name_or_path"),Hwt.forEach(t),agr=r(y6,":"),y6.forEach(t),ngr=i(Ca),rt=n(Ca,"UL",{});var Fl=s(rt);uT=n(Fl,"LI",{});var ENe=s(uT);x4e=n(ENe,"STRONG",{});var Uwt=s(x4e);sgr=r(Uwt,"data2vec-audio"),Uwt.forEach(t),lgr=r(ENe," \u2014 "),YW=n(ENe,"A",{href:!0});var Jwt=s(YW);igr=r(Jwt,"Data2VecAudioForXVector"),Jwt.forEach(t),dgr=r(ENe," (Data2VecAudio model)"),ENe.forEach(t),cgr=i(Fl),bT=n(Fl,"LI",{});var CNe=s(bT);$4e=n(CNe,"STRONG",{});var Ywt=s($4e);fgr=r(Ywt,"unispeech-sat"),Ywt.forEach(t),mgr=r(CNe," \u2014 "),KW=n(CNe,"A",{href:!0});var Kwt=s(KW);ggr=r(Kwt,"UniSpeechSatForXVector"),Kwt.forEach(t),hgr=r(CNe," (UniSpeechSat model)"),CNe.forEach(t),pgr=i(Fl),vT=n(Fl,"LI",{});var wNe=s(vT);k4e=n(wNe,"STRONG",{});var Zwt=s(k4e);_gr=r(Zwt,"wav2vec2"),Zwt.forEach(t),ugr=r(wNe," \u2014 "),ZW=n(wNe,"A",{href:!0});var eAt=s(ZW);bgr=r(eAt,"Wav2Vec2ForXVector"),eAt.forEach(t),vgr=r(wNe," (Wav2Vec2 model)"),wNe.forEach(t),Fgr=i(Fl),FT=n(Fl,"LI",{});var ANe=s(FT);S4e=n(ANe,"STRONG",{});var oAt=s(S4e);Tgr=r(oAt,"wav2vec2-conformer"),oAt.forEach(t),Mgr=r(ANe," \u2014 "),eH=n(ANe,"A",{href:!0});var rAt=s(eH);Egr=r(rAt,"Wav2Vec2ConformerForXVector"),rAt.forEach(t),Cgr=r(ANe," (Wav2Vec2-Conformer model)"),ANe.forEach(t),wgr=i(Fl),TT=n(Fl,"LI",{});var LNe=s(TT);R4e=n(LNe,"STRONG",{});var tAt=s(R4e);Agr=r(tAt,"wavlm"),tAt.forEach(t),Lgr=r(LNe," \u2014 "),oH=n(LNe,"A",{href:!0});var aAt=s(oH);ygr=r(aAt,"WavLMForXVector"),aAt.forEach(t),xgr=r(LNe," (WavLM model)"),LNe.forEach(t),Fl.forEach(t),$gr=i(Ca),MT=n(Ca,"P",{});var yNe=s(MT);kgr=r(yNe,"The model is set in evaluation mode by default using "),P4e=n(yNe,"CODE",{});var nAt=s(P4e);Sgr=r(nAt,"model.eval()"),nAt.forEach(t),Rgr=r(yNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B4e=n(yNe,"CODE",{});var sAt=s(B4e);Pgr=r(sAt,"model.train()"),sAt.forEach(t),yNe.forEach(t),Bgr=i(Ca),T(ET.$$.fragment,Ca),Ca.forEach(t),vl.forEach(t),NVe=i(f),Gd=n(f,"H2",{class:!0});var Vze=s(Gd);CT=n(Vze,"A",{id:!0,class:!0,href:!0});var lAt=s(CT);N4e=n(lAt,"SPAN",{});var iAt=s(N4e);T(r9.$$.fragment,iAt),iAt.forEach(t),lAt.forEach(t),Ngr=i(Vze),I4e=n(Vze,"SPAN",{});var dAt=s(I4e);Igr=r(dAt,"AutoModelForMaskedImageModeling"),dAt.forEach(t),Vze.forEach(t),IVe=i(f),Uo=n(f,"DIV",{class:!0});var Tl=s(Uo);T(t9.$$.fragment,Tl),qgr=i(Tl),Od=n(Tl,"P",{});var Rre=s(Od);jgr=r(Rre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),rH=n(Rre,"A",{href:!0});var cAt=s(rH);Dgr=r(cAt,"from_pretrained()"),cAt.forEach(t),Ggr=r(Rre," class method or the "),tH=n(Rre,"A",{href:!0});var fAt=s(tH);Ogr=r(fAt,"from_config()"),fAt.forEach(t),Vgr=r(Rre,` class
method.`),Rre.forEach(t),Xgr=i(Tl),a9=n(Tl,"P",{});var Xze=s(a9);zgr=r(Xze,"This class cannot be instantiated directly using "),q4e=n(Xze,"CODE",{});var mAt=s(q4e);Qgr=r(mAt,"__init__()"),mAt.forEach(t),Wgr=r(Xze," (throws an error)."),Xze.forEach(t),Hgr=i(Tl),At=n(Tl,"DIV",{class:!0});var x6=s(At);T(n9.$$.fragment,x6),Ugr=i(x6),j4e=n(x6,"P",{});var gAt=s(j4e);Jgr=r(gAt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),gAt.forEach(t),Ygr=i(x6),Vd=n(x6,"P",{});var Pre=s(Vd);Kgr=r(Pre,`Note:
Loading a model from its configuration file does `),D4e=n(Pre,"STRONG",{});var hAt=s(D4e);Zgr=r(hAt,"not"),hAt.forEach(t),ehr=r(Pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=n(Pre,"A",{href:!0});var pAt=s(aH);ohr=r(pAt,"from_pretrained()"),pAt.forEach(t),rhr=r(Pre," to load the model weights."),Pre.forEach(t),thr=i(x6),T(wT.$$.fragment,x6),x6.forEach(t),ahr=i(Tl),_o=n(Tl,"DIV",{class:!0});var wa=s(_o);T(s9.$$.fragment,wa),nhr=i(wa),G4e=n(wa,"P",{});var _At=s(G4e);shr=r(_At,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),_At.forEach(t),lhr=i(wa),en=n(wa,"P",{});var $6=s(en);ihr=r($6,"The model class to instantiate is selected based on the "),O4e=n($6,"CODE",{});var uAt=s(O4e);dhr=r(uAt,"model_type"),uAt.forEach(t),chr=r($6,` property of the config object (either
passed as an argument or loaded from `),V4e=n($6,"CODE",{});var bAt=s(V4e);fhr=r(bAt,"pretrained_model_name_or_path"),bAt.forEach(t),mhr=r($6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X4e=n($6,"CODE",{});var vAt=s(X4e);ghr=r(vAt,"pretrained_model_name_or_path"),vAt.forEach(t),hhr=r($6,":"),$6.forEach(t),phr=i(wa),Xd=n(wa,"UL",{});var Bre=s(Xd);AT=n(Bre,"LI",{});var xNe=s(AT);z4e=n(xNe,"STRONG",{});var FAt=s(z4e);_hr=r(FAt,"deit"),FAt.forEach(t),uhr=r(xNe," \u2014 "),nH=n(xNe,"A",{href:!0});var TAt=s(nH);bhr=r(TAt,"DeiTForMaskedImageModeling"),TAt.forEach(t),vhr=r(xNe," (DeiT model)"),xNe.forEach(t),Fhr=i(Bre),LT=n(Bre,"LI",{});var $Ne=s(LT);Q4e=n($Ne,"STRONG",{});var MAt=s(Q4e);Thr=r(MAt,"swin"),MAt.forEach(t),Mhr=r($Ne," \u2014 "),sH=n($Ne,"A",{href:!0});var EAt=s(sH);Ehr=r(EAt,"SwinForMaskedImageModeling"),EAt.forEach(t),Chr=r($Ne," (Swin Transformer model)"),$Ne.forEach(t),whr=i(Bre),yT=n(Bre,"LI",{});var kNe=s(yT);W4e=n(kNe,"STRONG",{});var CAt=s(W4e);Ahr=r(CAt,"vit"),CAt.forEach(t),Lhr=r(kNe," \u2014 "),lH=n(kNe,"A",{href:!0});var wAt=s(lH);yhr=r(wAt,"ViTForMaskedImageModeling"),wAt.forEach(t),xhr=r(kNe," (ViT model)"),kNe.forEach(t),Bre.forEach(t),$hr=i(wa),xT=n(wa,"P",{});var SNe=s(xT);khr=r(SNe,"The model is set in evaluation mode by default using "),H4e=n(SNe,"CODE",{});var AAt=s(H4e);Shr=r(AAt,"model.eval()"),AAt.forEach(t),Rhr=r(SNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U4e=n(SNe,"CODE",{});var LAt=s(U4e);Phr=r(LAt,"model.train()"),LAt.forEach(t),SNe.forEach(t),Bhr=i(wa),T($T.$$.fragment,wa),wa.forEach(t),Tl.forEach(t),qVe=i(f),zd=n(f,"H2",{class:!0});var zze=s(zd);kT=n(zze,"A",{id:!0,class:!0,href:!0});var yAt=s(kT);J4e=n(yAt,"SPAN",{});var xAt=s(J4e);T(l9.$$.fragment,xAt),xAt.forEach(t),yAt.forEach(t),Nhr=i(zze),Y4e=n(zze,"SPAN",{});var $At=s(Y4e);Ihr=r($At,"AutoModelForObjectDetection"),$At.forEach(t),zze.forEach(t),jVe=i(f),Jo=n(f,"DIV",{class:!0});var Ml=s(Jo);T(i9.$$.fragment,Ml),qhr=i(Ml),Qd=n(Ml,"P",{});var Nre=s(Qd);jhr=r(Nre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),iH=n(Nre,"A",{href:!0});var kAt=s(iH);Dhr=r(kAt,"from_pretrained()"),kAt.forEach(t),Ghr=r(Nre," class method or the "),dH=n(Nre,"A",{href:!0});var SAt=s(dH);Ohr=r(SAt,"from_config()"),SAt.forEach(t),Vhr=r(Nre,` class
method.`),Nre.forEach(t),Xhr=i(Ml),d9=n(Ml,"P",{});var Qze=s(d9);zhr=r(Qze,"This class cannot be instantiated directly using "),K4e=n(Qze,"CODE",{});var RAt=s(K4e);Qhr=r(RAt,"__init__()"),RAt.forEach(t),Whr=r(Qze," (throws an error)."),Qze.forEach(t),Hhr=i(Ml),Lt=n(Ml,"DIV",{class:!0});var k6=s(Lt);T(c9.$$.fragment,k6),Uhr=i(k6),Z4e=n(k6,"P",{});var PAt=s(Z4e);Jhr=r(PAt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),PAt.forEach(t),Yhr=i(k6),Wd=n(k6,"P",{});var Ire=s(Wd);Khr=r(Ire,`Note:
Loading a model from its configuration file does `),ebe=n(Ire,"STRONG",{});var BAt=s(ebe);Zhr=r(BAt,"not"),BAt.forEach(t),epr=r(Ire,` load the model weights. It only affects the
model\u2019s configuration. Use `),cH=n(Ire,"A",{href:!0});var NAt=s(cH);opr=r(NAt,"from_pretrained()"),NAt.forEach(t),rpr=r(Ire," to load the model weights."),Ire.forEach(t),tpr=i(k6),T(ST.$$.fragment,k6),k6.forEach(t),apr=i(Ml),uo=n(Ml,"DIV",{class:!0});var Aa=s(uo);T(f9.$$.fragment,Aa),npr=i(Aa),obe=n(Aa,"P",{});var IAt=s(obe);spr=r(IAt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),IAt.forEach(t),lpr=i(Aa),on=n(Aa,"P",{});var S6=s(on);ipr=r(S6,"The model class to instantiate is selected based on the "),rbe=n(S6,"CODE",{});var qAt=s(rbe);dpr=r(qAt,"model_type"),qAt.forEach(t),cpr=r(S6,` property of the config object (either
passed as an argument or loaded from `),tbe=n(S6,"CODE",{});var jAt=s(tbe);fpr=r(jAt,"pretrained_model_name_or_path"),jAt.forEach(t),mpr=r(S6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),abe=n(S6,"CODE",{});var DAt=s(abe);gpr=r(DAt,"pretrained_model_name_or_path"),DAt.forEach(t),hpr=r(S6,":"),S6.forEach(t),ppr=i(Aa),m9=n(Aa,"UL",{});var Wze=s(m9);RT=n(Wze,"LI",{});var RNe=s(RT);nbe=n(RNe,"STRONG",{});var GAt=s(nbe);_pr=r(GAt,"detr"),GAt.forEach(t),upr=r(RNe," \u2014 "),fH=n(RNe,"A",{href:!0});var OAt=s(fH);bpr=r(OAt,"DetrForObjectDetection"),OAt.forEach(t),vpr=r(RNe," (DETR model)"),RNe.forEach(t),Fpr=i(Wze),PT=n(Wze,"LI",{});var PNe=s(PT);sbe=n(PNe,"STRONG",{});var VAt=s(sbe);Tpr=r(VAt,"yolos"),VAt.forEach(t),Mpr=r(PNe," \u2014 "),mH=n(PNe,"A",{href:!0});var XAt=s(mH);Epr=r(XAt,"YolosForObjectDetection"),XAt.forEach(t),Cpr=r(PNe," (YOLOS model)"),PNe.forEach(t),Wze.forEach(t),wpr=i(Aa),BT=n(Aa,"P",{});var BNe=s(BT);Apr=r(BNe,"The model is set in evaluation mode by default using "),lbe=n(BNe,"CODE",{});var zAt=s(lbe);Lpr=r(zAt,"model.eval()"),zAt.forEach(t),ypr=r(BNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ibe=n(BNe,"CODE",{});var QAt=s(ibe);xpr=r(QAt,"model.train()"),QAt.forEach(t),BNe.forEach(t),$pr=i(Aa),T(NT.$$.fragment,Aa),Aa.forEach(t),Ml.forEach(t),DVe=i(f),Hd=n(f,"H2",{class:!0});var Hze=s(Hd);IT=n(Hze,"A",{id:!0,class:!0,href:!0});var WAt=s(IT);dbe=n(WAt,"SPAN",{});var HAt=s(dbe);T(g9.$$.fragment,HAt),HAt.forEach(t),WAt.forEach(t),kpr=i(Hze),cbe=n(Hze,"SPAN",{});var UAt=s(cbe);Spr=r(UAt,"AutoModelForImageSegmentation"),UAt.forEach(t),Hze.forEach(t),GVe=i(f),Yo=n(f,"DIV",{class:!0});var El=s(Yo);T(h9.$$.fragment,El),Rpr=i(El),Ud=n(El,"P",{});var qre=s(Ud);Ppr=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),gH=n(qre,"A",{href:!0});var JAt=s(gH);Bpr=r(JAt,"from_pretrained()"),JAt.forEach(t),Npr=r(qre," class method or the "),hH=n(qre,"A",{href:!0});var YAt=s(hH);Ipr=r(YAt,"from_config()"),YAt.forEach(t),qpr=r(qre,` class
method.`),qre.forEach(t),jpr=i(El),p9=n(El,"P",{});var Uze=s(p9);Dpr=r(Uze,"This class cannot be instantiated directly using "),fbe=n(Uze,"CODE",{});var KAt=s(fbe);Gpr=r(KAt,"__init__()"),KAt.forEach(t),Opr=r(Uze," (throws an error)."),Uze.forEach(t),Vpr=i(El),yt=n(El,"DIV",{class:!0});var R6=s(yt);T(_9.$$.fragment,R6),Xpr=i(R6),mbe=n(R6,"P",{});var ZAt=s(mbe);zpr=r(ZAt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),ZAt.forEach(t),Qpr=i(R6),Jd=n(R6,"P",{});var jre=s(Jd);Wpr=r(jre,`Note:
Loading a model from its configuration file does `),gbe=n(jre,"STRONG",{});var e6t=s(gbe);Hpr=r(e6t,"not"),e6t.forEach(t),Upr=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),pH=n(jre,"A",{href:!0});var o6t=s(pH);Jpr=r(o6t,"from_pretrained()"),o6t.forEach(t),Ypr=r(jre," to load the model weights."),jre.forEach(t),Kpr=i(R6),T(qT.$$.fragment,R6),R6.forEach(t),Zpr=i(El),bo=n(El,"DIV",{class:!0});var La=s(bo);T(u9.$$.fragment,La),e_r=i(La),hbe=n(La,"P",{});var r6t=s(hbe);o_r=r(r6t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),r6t.forEach(t),r_r=i(La),rn=n(La,"P",{});var P6=s(rn);t_r=r(P6,"The model class to instantiate is selected based on the "),pbe=n(P6,"CODE",{});var t6t=s(pbe);a_r=r(t6t,"model_type"),t6t.forEach(t),n_r=r(P6,` property of the config object (either
passed as an argument or loaded from `),_be=n(P6,"CODE",{});var a6t=s(_be);s_r=r(a6t,"pretrained_model_name_or_path"),a6t.forEach(t),l_r=r(P6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ube=n(P6,"CODE",{});var n6t=s(ube);i_r=r(n6t,"pretrained_model_name_or_path"),n6t.forEach(t),d_r=r(P6,":"),P6.forEach(t),c_r=i(La),bbe=n(La,"UL",{});var s6t=s(bbe);jT=n(s6t,"LI",{});var NNe=s(jT);vbe=n(NNe,"STRONG",{});var l6t=s(vbe);f_r=r(l6t,"detr"),l6t.forEach(t),m_r=r(NNe," \u2014 "),_H=n(NNe,"A",{href:!0});var i6t=s(_H);g_r=r(i6t,"DetrForSegmentation"),i6t.forEach(t),h_r=r(NNe," (DETR model)"),NNe.forEach(t),s6t.forEach(t),p_r=i(La),DT=n(La,"P",{});var INe=s(DT);__r=r(INe,"The model is set in evaluation mode by default using "),Fbe=n(INe,"CODE",{});var d6t=s(Fbe);u_r=r(d6t,"model.eval()"),d6t.forEach(t),b_r=r(INe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tbe=n(INe,"CODE",{});var c6t=s(Tbe);v_r=r(c6t,"model.train()"),c6t.forEach(t),INe.forEach(t),F_r=i(La),T(GT.$$.fragment,La),La.forEach(t),El.forEach(t),OVe=i(f),Yd=n(f,"H2",{class:!0});var Jze=s(Yd);OT=n(Jze,"A",{id:!0,class:!0,href:!0});var f6t=s(OT);Mbe=n(f6t,"SPAN",{});var m6t=s(Mbe);T(b9.$$.fragment,m6t),m6t.forEach(t),f6t.forEach(t),T_r=i(Jze),Ebe=n(Jze,"SPAN",{});var g6t=s(Ebe);M_r=r(g6t,"AutoModelForSemanticSegmentation"),g6t.forEach(t),Jze.forEach(t),VVe=i(f),Ko=n(f,"DIV",{class:!0});var Cl=s(Ko);T(v9.$$.fragment,Cl),E_r=i(Cl),Kd=n(Cl,"P",{});var Dre=s(Kd);C_r=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),uH=n(Dre,"A",{href:!0});var h6t=s(uH);w_r=r(h6t,"from_pretrained()"),h6t.forEach(t),A_r=r(Dre," class method or the "),bH=n(Dre,"A",{href:!0});var p6t=s(bH);L_r=r(p6t,"from_config()"),p6t.forEach(t),y_r=r(Dre,` class
method.`),Dre.forEach(t),x_r=i(Cl),F9=n(Cl,"P",{});var Yze=s(F9);$_r=r(Yze,"This class cannot be instantiated directly using "),Cbe=n(Yze,"CODE",{});var _6t=s(Cbe);k_r=r(_6t,"__init__()"),_6t.forEach(t),S_r=r(Yze," (throws an error)."),Yze.forEach(t),R_r=i(Cl),xt=n(Cl,"DIV",{class:!0});var B6=s(xt);T(T9.$$.fragment,B6),P_r=i(B6),wbe=n(B6,"P",{});var u6t=s(wbe);B_r=r(u6t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),u6t.forEach(t),N_r=i(B6),Zd=n(B6,"P",{});var Gre=s(Zd);I_r=r(Gre,`Note:
Loading a model from its configuration file does `),Abe=n(Gre,"STRONG",{});var b6t=s(Abe);q_r=r(b6t,"not"),b6t.forEach(t),j_r=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),vH=n(Gre,"A",{href:!0});var v6t=s(vH);D_r=r(v6t,"from_pretrained()"),v6t.forEach(t),G_r=r(Gre," to load the model weights."),Gre.forEach(t),O_r=i(B6),T(VT.$$.fragment,B6),B6.forEach(t),V_r=i(Cl),vo=n(Cl,"DIV",{class:!0});var ya=s(vo);T(M9.$$.fragment,ya),X_r=i(ya),Lbe=n(ya,"P",{});var F6t=s(Lbe);z_r=r(F6t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),F6t.forEach(t),Q_r=i(ya),tn=n(ya,"P",{});var N6=s(tn);W_r=r(N6,"The model class to instantiate is selected based on the "),ybe=n(N6,"CODE",{});var T6t=s(ybe);H_r=r(T6t,"model_type"),T6t.forEach(t),U_r=r(N6,` property of the config object (either
passed as an argument or loaded from `),xbe=n(N6,"CODE",{});var M6t=s(xbe);J_r=r(M6t,"pretrained_model_name_or_path"),M6t.forEach(t),Y_r=r(N6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$be=n(N6,"CODE",{});var E6t=s($be);K_r=r(E6t,"pretrained_model_name_or_path"),E6t.forEach(t),Z_r=r(N6,":"),N6.forEach(t),eur=i(ya),an=n(ya,"UL",{});var I6=s(an);XT=n(I6,"LI",{});var qNe=s(XT);kbe=n(qNe,"STRONG",{});var C6t=s(kbe);our=r(C6t,"beit"),C6t.forEach(t),rur=r(qNe," \u2014 "),FH=n(qNe,"A",{href:!0});var w6t=s(FH);tur=r(w6t,"BeitForSemanticSegmentation"),w6t.forEach(t),aur=r(qNe," (BEiT model)"),qNe.forEach(t),nur=i(I6),zT=n(I6,"LI",{});var jNe=s(zT);Sbe=n(jNe,"STRONG",{});var A6t=s(Sbe);sur=r(A6t,"data2vec-vision"),A6t.forEach(t),lur=r(jNe," \u2014 "),TH=n(jNe,"A",{href:!0});var L6t=s(TH);iur=r(L6t,"Data2VecVisionForSemanticSegmentation"),L6t.forEach(t),dur=r(jNe," (Data2VecVision model)"),jNe.forEach(t),cur=i(I6),QT=n(I6,"LI",{});var DNe=s(QT);Rbe=n(DNe,"STRONG",{});var y6t=s(Rbe);fur=r(y6t,"dpt"),y6t.forEach(t),mur=r(DNe," \u2014 "),MH=n(DNe,"A",{href:!0});var x6t=s(MH);gur=r(x6t,"DPTForSemanticSegmentation"),x6t.forEach(t),hur=r(DNe," (DPT model)"),DNe.forEach(t),pur=i(I6),WT=n(I6,"LI",{});var GNe=s(WT);Pbe=n(GNe,"STRONG",{});var $6t=s(Pbe);_ur=r($6t,"segformer"),$6t.forEach(t),uur=r(GNe," \u2014 "),EH=n(GNe,"A",{href:!0});var k6t=s(EH);bur=r(k6t,"SegformerForSemanticSegmentation"),k6t.forEach(t),vur=r(GNe," (SegFormer model)"),GNe.forEach(t),I6.forEach(t),Fur=i(ya),HT=n(ya,"P",{});var ONe=s(HT);Tur=r(ONe,"The model is set in evaluation mode by default using "),Bbe=n(ONe,"CODE",{});var S6t=s(Bbe);Mur=r(S6t,"model.eval()"),S6t.forEach(t),Eur=r(ONe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nbe=n(ONe,"CODE",{});var R6t=s(Nbe);Cur=r(R6t,"model.train()"),R6t.forEach(t),ONe.forEach(t),wur=i(ya),T(UT.$$.fragment,ya),ya.forEach(t),Cl.forEach(t),XVe=i(f),ec=n(f,"H2",{class:!0});var Kze=s(ec);JT=n(Kze,"A",{id:!0,class:!0,href:!0});var P6t=s(JT);Ibe=n(P6t,"SPAN",{});var B6t=s(Ibe);T(E9.$$.fragment,B6t),B6t.forEach(t),P6t.forEach(t),Aur=i(Kze),qbe=n(Kze,"SPAN",{});var N6t=s(qbe);Lur=r(N6t,"AutoModelForInstanceSegmentation"),N6t.forEach(t),Kze.forEach(t),zVe=i(f),Zo=n(f,"DIV",{class:!0});var wl=s(Zo);T(C9.$$.fragment,wl),yur=i(wl),oc=n(wl,"P",{});var Ore=s(oc);xur=r(Ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),CH=n(Ore,"A",{href:!0});var I6t=s(CH);$ur=r(I6t,"from_pretrained()"),I6t.forEach(t),kur=r(Ore," class method or the "),wH=n(Ore,"A",{href:!0});var q6t=s(wH);Sur=r(q6t,"from_config()"),q6t.forEach(t),Rur=r(Ore,` class
method.`),Ore.forEach(t),Pur=i(wl),w9=n(wl,"P",{});var Zze=s(w9);Bur=r(Zze,"This class cannot be instantiated directly using "),jbe=n(Zze,"CODE",{});var j6t=s(jbe);Nur=r(j6t,"__init__()"),j6t.forEach(t),Iur=r(Zze," (throws an error)."),Zze.forEach(t),qur=i(wl),$t=n(wl,"DIV",{class:!0});var q6=s($t);T(A9.$$.fragment,q6),jur=i(q6),Dbe=n(q6,"P",{});var D6t=s(Dbe);Dur=r(D6t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),D6t.forEach(t),Gur=i(q6),rc=n(q6,"P",{});var Vre=s(rc);Our=r(Vre,`Note:
Loading a model from its configuration file does `),Gbe=n(Vre,"STRONG",{});var G6t=s(Gbe);Vur=r(G6t,"not"),G6t.forEach(t),Xur=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),AH=n(Vre,"A",{href:!0});var O6t=s(AH);zur=r(O6t,"from_pretrained()"),O6t.forEach(t),Qur=r(Vre," to load the model weights."),Vre.forEach(t),Wur=i(q6),T(YT.$$.fragment,q6),q6.forEach(t),Hur=i(wl),Fo=n(wl,"DIV",{class:!0});var xa=s(Fo);T(L9.$$.fragment,xa),Uur=i(xa),Obe=n(xa,"P",{});var V6t=s(Obe);Jur=r(V6t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),V6t.forEach(t),Yur=i(xa),nn=n(xa,"P",{});var j6=s(nn);Kur=r(j6,"The model class to instantiate is selected based on the "),Vbe=n(j6,"CODE",{});var X6t=s(Vbe);Zur=r(X6t,"model_type"),X6t.forEach(t),e2r=r(j6,` property of the config object (either
passed as an argument or loaded from `),Xbe=n(j6,"CODE",{});var z6t=s(Xbe);o2r=r(z6t,"pretrained_model_name_or_path"),z6t.forEach(t),r2r=r(j6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=n(j6,"CODE",{});var Q6t=s(zbe);t2r=r(Q6t,"pretrained_model_name_or_path"),Q6t.forEach(t),a2r=r(j6,":"),j6.forEach(t),n2r=i(xa),Qbe=n(xa,"UL",{});var W6t=s(Qbe);KT=n(W6t,"LI",{});var VNe=s(KT);Wbe=n(VNe,"STRONG",{});var H6t=s(Wbe);s2r=r(H6t,"maskformer"),H6t.forEach(t),l2r=r(VNe," \u2014 "),LH=n(VNe,"A",{href:!0});var U6t=s(LH);i2r=r(U6t,"MaskFormerForInstanceSegmentation"),U6t.forEach(t),d2r=r(VNe," (MaskFormer model)"),VNe.forEach(t),W6t.forEach(t),c2r=i(xa),ZT=n(xa,"P",{});var XNe=s(ZT);f2r=r(XNe,"The model is set in evaluation mode by default using "),Hbe=n(XNe,"CODE",{});var J6t=s(Hbe);m2r=r(J6t,"model.eval()"),J6t.forEach(t),g2r=r(XNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ube=n(XNe,"CODE",{});var Y6t=s(Ube);h2r=r(Y6t,"model.train()"),Y6t.forEach(t),XNe.forEach(t),p2r=i(xa),T(eM.$$.fragment,xa),xa.forEach(t),wl.forEach(t),QVe=i(f),tc=n(f,"H2",{class:!0});var eQe=s(tc);oM=n(eQe,"A",{id:!0,class:!0,href:!0});var K6t=s(oM);Jbe=n(K6t,"SPAN",{});var Z6t=s(Jbe);T(y9.$$.fragment,Z6t),Z6t.forEach(t),K6t.forEach(t),_2r=i(eQe),Ybe=n(eQe,"SPAN",{});var eLt=s(Ybe);u2r=r(eLt,"TFAutoModel"),eLt.forEach(t),eQe.forEach(t),WVe=i(f),er=n(f,"DIV",{class:!0});var Al=s(er);T(x9.$$.fragment,Al),b2r=i(Al),ac=n(Al,"P",{});var Xre=s(ac);v2r=r(Xre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),yH=n(Xre,"A",{href:!0});var oLt=s(yH);F2r=r(oLt,"from_pretrained()"),oLt.forEach(t),T2r=r(Xre," class method or the "),xH=n(Xre,"A",{href:!0});var rLt=s(xH);M2r=r(rLt,"from_config()"),rLt.forEach(t),E2r=r(Xre,` class
method.`),Xre.forEach(t),C2r=i(Al),$9=n(Al,"P",{});var oQe=s($9);w2r=r(oQe,"This class cannot be instantiated directly using "),Kbe=n(oQe,"CODE",{});var tLt=s(Kbe);A2r=r(tLt,"__init__()"),tLt.forEach(t),L2r=r(oQe," (throws an error)."),oQe.forEach(t),y2r=i(Al),kt=n(Al,"DIV",{class:!0});var D6=s(kt);T(k9.$$.fragment,D6),x2r=i(D6),Zbe=n(D6,"P",{});var aLt=s(Zbe);$2r=r(aLt,"Instantiates one of the base model classes of the library from a configuration."),aLt.forEach(t),k2r=i(D6),nc=n(D6,"P",{});var zre=s(nc);S2r=r(zre,`Note:
Loading a model from its configuration file does `),eve=n(zre,"STRONG",{});var nLt=s(eve);R2r=r(nLt,"not"),nLt.forEach(t),P2r=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=n(zre,"A",{href:!0});var sLt=s($H);B2r=r(sLt,"from_pretrained()"),sLt.forEach(t),N2r=r(zre," to load the model weights."),zre.forEach(t),I2r=i(D6),T(rM.$$.fragment,D6),D6.forEach(t),q2r=i(Al),xr=n(Al,"DIV",{class:!0});var Ll=s(xr);T(S9.$$.fragment,Ll),j2r=i(Ll),ove=n(Ll,"P",{});var lLt=s(ove);D2r=r(lLt,"Instantiate one of the base model classes of the library from a pretrained model."),lLt.forEach(t),G2r=i(Ll),sn=n(Ll,"P",{});var G6=s(sn);O2r=r(G6,"The model class to instantiate is selected based on the "),rve=n(G6,"CODE",{});var iLt=s(rve);V2r=r(iLt,"model_type"),iLt.forEach(t),X2r=r(G6,` property of the config object (either
passed as an argument or loaded from `),tve=n(G6,"CODE",{});var dLt=s(tve);z2r=r(dLt,"pretrained_model_name_or_path"),dLt.forEach(t),Q2r=r(G6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ave=n(G6,"CODE",{});var cLt=s(ave);W2r=r(cLt,"pretrained_model_name_or_path"),cLt.forEach(t),H2r=r(G6,":"),G6.forEach(t),U2r=i(Ll),q=n(Ll,"UL",{});var D=s(q);tM=n(D,"LI",{});var zNe=s(tM);nve=n(zNe,"STRONG",{});var fLt=s(nve);J2r=r(fLt,"albert"),fLt.forEach(t),Y2r=r(zNe," \u2014 "),kH=n(zNe,"A",{href:!0});var mLt=s(kH);K2r=r(mLt,"TFAlbertModel"),mLt.forEach(t),Z2r=r(zNe," (ALBERT model)"),zNe.forEach(t),e1r=i(D),aM=n(D,"LI",{});var QNe=s(aM);sve=n(QNe,"STRONG",{});var gLt=s(sve);o1r=r(gLt,"bart"),gLt.forEach(t),r1r=r(QNe," \u2014 "),SH=n(QNe,"A",{href:!0});var hLt=s(SH);t1r=r(hLt,"TFBartModel"),hLt.forEach(t),a1r=r(QNe," (BART model)"),QNe.forEach(t),n1r=i(D),nM=n(D,"LI",{});var WNe=s(nM);lve=n(WNe,"STRONG",{});var pLt=s(lve);s1r=r(pLt,"bert"),pLt.forEach(t),l1r=r(WNe," \u2014 "),RH=n(WNe,"A",{href:!0});var _Lt=s(RH);i1r=r(_Lt,"TFBertModel"),_Lt.forEach(t),d1r=r(WNe," (BERT model)"),WNe.forEach(t),c1r=i(D),sM=n(D,"LI",{});var HNe=s(sM);ive=n(HNe,"STRONG",{});var uLt=s(ive);f1r=r(uLt,"blenderbot"),uLt.forEach(t),m1r=r(HNe," \u2014 "),PH=n(HNe,"A",{href:!0});var bLt=s(PH);g1r=r(bLt,"TFBlenderbotModel"),bLt.forEach(t),h1r=r(HNe," (Blenderbot model)"),HNe.forEach(t),p1r=i(D),lM=n(D,"LI",{});var UNe=s(lM);dve=n(UNe,"STRONG",{});var vLt=s(dve);_1r=r(vLt,"blenderbot-small"),vLt.forEach(t),u1r=r(UNe," \u2014 "),BH=n(UNe,"A",{href:!0});var FLt=s(BH);b1r=r(FLt,"TFBlenderbotSmallModel"),FLt.forEach(t),v1r=r(UNe," (BlenderbotSmall model)"),UNe.forEach(t),F1r=i(D),iM=n(D,"LI",{});var JNe=s(iM);cve=n(JNe,"STRONG",{});var TLt=s(cve);T1r=r(TLt,"camembert"),TLt.forEach(t),M1r=r(JNe," \u2014 "),NH=n(JNe,"A",{href:!0});var MLt=s(NH);E1r=r(MLt,"TFCamembertModel"),MLt.forEach(t),C1r=r(JNe," (CamemBERT model)"),JNe.forEach(t),w1r=i(D),dM=n(D,"LI",{});var YNe=s(dM);fve=n(YNe,"STRONG",{});var ELt=s(fve);A1r=r(ELt,"clip"),ELt.forEach(t),L1r=r(YNe," \u2014 "),IH=n(YNe,"A",{href:!0});var CLt=s(IH);y1r=r(CLt,"TFCLIPModel"),CLt.forEach(t),x1r=r(YNe," (CLIP model)"),YNe.forEach(t),$1r=i(D),cM=n(D,"LI",{});var KNe=s(cM);mve=n(KNe,"STRONG",{});var wLt=s(mve);k1r=r(wLt,"convbert"),wLt.forEach(t),S1r=r(KNe," \u2014 "),qH=n(KNe,"A",{href:!0});var ALt=s(qH);R1r=r(ALt,"TFConvBertModel"),ALt.forEach(t),P1r=r(KNe," (ConvBERT model)"),KNe.forEach(t),B1r=i(D),fM=n(D,"LI",{});var ZNe=s(fM);gve=n(ZNe,"STRONG",{});var LLt=s(gve);N1r=r(LLt,"convnext"),LLt.forEach(t),I1r=r(ZNe," \u2014 "),jH=n(ZNe,"A",{href:!0});var yLt=s(jH);q1r=r(yLt,"TFConvNextModel"),yLt.forEach(t),j1r=r(ZNe," (ConvNeXT model)"),ZNe.forEach(t),D1r=i(D),mM=n(D,"LI",{});var eIe=s(mM);hve=n(eIe,"STRONG",{});var xLt=s(hve);G1r=r(xLt,"ctrl"),xLt.forEach(t),O1r=r(eIe," \u2014 "),DH=n(eIe,"A",{href:!0});var $Lt=s(DH);V1r=r($Lt,"TFCTRLModel"),$Lt.forEach(t),X1r=r(eIe," (CTRL model)"),eIe.forEach(t),z1r=i(D),gM=n(D,"LI",{});var oIe=s(gM);pve=n(oIe,"STRONG",{});var kLt=s(pve);Q1r=r(kLt,"data2vec-vision"),kLt.forEach(t),W1r=r(oIe," \u2014 "),GH=n(oIe,"A",{href:!0});var SLt=s(GH);H1r=r(SLt,"TFData2VecVisionModel"),SLt.forEach(t),U1r=r(oIe," (Data2VecVision model)"),oIe.forEach(t),J1r=i(D),hM=n(D,"LI",{});var rIe=s(hM);_ve=n(rIe,"STRONG",{});var RLt=s(_ve);Y1r=r(RLt,"deberta"),RLt.forEach(t),K1r=r(rIe," \u2014 "),OH=n(rIe,"A",{href:!0});var PLt=s(OH);Z1r=r(PLt,"TFDebertaModel"),PLt.forEach(t),e7r=r(rIe," (DeBERTa model)"),rIe.forEach(t),o7r=i(D),pM=n(D,"LI",{});var tIe=s(pM);uve=n(tIe,"STRONG",{});var BLt=s(uve);r7r=r(BLt,"deberta-v2"),BLt.forEach(t),t7r=r(tIe," \u2014 "),VH=n(tIe,"A",{href:!0});var NLt=s(VH);a7r=r(NLt,"TFDebertaV2Model"),NLt.forEach(t),n7r=r(tIe," (DeBERTa-v2 model)"),tIe.forEach(t),s7r=i(D),_M=n(D,"LI",{});var aIe=s(_M);bve=n(aIe,"STRONG",{});var ILt=s(bve);l7r=r(ILt,"distilbert"),ILt.forEach(t),i7r=r(aIe," \u2014 "),XH=n(aIe,"A",{href:!0});var qLt=s(XH);d7r=r(qLt,"TFDistilBertModel"),qLt.forEach(t),c7r=r(aIe," (DistilBERT model)"),aIe.forEach(t),f7r=i(D),uM=n(D,"LI",{});var nIe=s(uM);vve=n(nIe,"STRONG",{});var jLt=s(vve);m7r=r(jLt,"dpr"),jLt.forEach(t),g7r=r(nIe," \u2014 "),zH=n(nIe,"A",{href:!0});var DLt=s(zH);h7r=r(DLt,"TFDPRQuestionEncoder"),DLt.forEach(t),p7r=r(nIe," (DPR model)"),nIe.forEach(t),_7r=i(D),bM=n(D,"LI",{});var sIe=s(bM);Fve=n(sIe,"STRONG",{});var GLt=s(Fve);u7r=r(GLt,"electra"),GLt.forEach(t),b7r=r(sIe," \u2014 "),QH=n(sIe,"A",{href:!0});var OLt=s(QH);v7r=r(OLt,"TFElectraModel"),OLt.forEach(t),F7r=r(sIe," (ELECTRA model)"),sIe.forEach(t),T7r=i(D),vM=n(D,"LI",{});var lIe=s(vM);Tve=n(lIe,"STRONG",{});var VLt=s(Tve);M7r=r(VLt,"flaubert"),VLt.forEach(t),E7r=r(lIe," \u2014 "),WH=n(lIe,"A",{href:!0});var XLt=s(WH);C7r=r(XLt,"TFFlaubertModel"),XLt.forEach(t),w7r=r(lIe," (FlauBERT model)"),lIe.forEach(t),A7r=i(D),Us=n(D,"LI",{});var _S=s(Us);Mve=n(_S,"STRONG",{});var zLt=s(Mve);L7r=r(zLt,"funnel"),zLt.forEach(t),y7r=r(_S," \u2014 "),HH=n(_S,"A",{href:!0});var QLt=s(HH);x7r=r(QLt,"TFFunnelModel"),QLt.forEach(t),$7r=r(_S," or "),UH=n(_S,"A",{href:!0});var WLt=s(UH);k7r=r(WLt,"TFFunnelBaseModel"),WLt.forEach(t),S7r=r(_S," (Funnel Transformer model)"),_S.forEach(t),R7r=i(D),FM=n(D,"LI",{});var iIe=s(FM);Eve=n(iIe,"STRONG",{});var HLt=s(Eve);P7r=r(HLt,"gpt2"),HLt.forEach(t),B7r=r(iIe," \u2014 "),JH=n(iIe,"A",{href:!0});var ULt=s(JH);N7r=r(ULt,"TFGPT2Model"),ULt.forEach(t),I7r=r(iIe," (OpenAI GPT-2 model)"),iIe.forEach(t),q7r=i(D),TM=n(D,"LI",{});var dIe=s(TM);Cve=n(dIe,"STRONG",{});var JLt=s(Cve);j7r=r(JLt,"gptj"),JLt.forEach(t),D7r=r(dIe," \u2014 "),YH=n(dIe,"A",{href:!0});var YLt=s(YH);G7r=r(YLt,"TFGPTJModel"),YLt.forEach(t),O7r=r(dIe," (GPT-J model)"),dIe.forEach(t),V7r=i(D),MM=n(D,"LI",{});var cIe=s(MM);wve=n(cIe,"STRONG",{});var KLt=s(wve);X7r=r(KLt,"hubert"),KLt.forEach(t),z7r=r(cIe," \u2014 "),KH=n(cIe,"A",{href:!0});var ZLt=s(KH);Q7r=r(ZLt,"TFHubertModel"),ZLt.forEach(t),W7r=r(cIe," (Hubert model)"),cIe.forEach(t),H7r=i(D),EM=n(D,"LI",{});var fIe=s(EM);Ave=n(fIe,"STRONG",{});var eyt=s(Ave);U7r=r(eyt,"layoutlm"),eyt.forEach(t),J7r=r(fIe," \u2014 "),ZH=n(fIe,"A",{href:!0});var oyt=s(ZH);Y7r=r(oyt,"TFLayoutLMModel"),oyt.forEach(t),K7r=r(fIe," (LayoutLM model)"),fIe.forEach(t),Z7r=i(D),CM=n(D,"LI",{});var mIe=s(CM);Lve=n(mIe,"STRONG",{});var ryt=s(Lve);e4r=r(ryt,"led"),ryt.forEach(t),o4r=r(mIe," \u2014 "),eU=n(mIe,"A",{href:!0});var tyt=s(eU);r4r=r(tyt,"TFLEDModel"),tyt.forEach(t),t4r=r(mIe," (LED model)"),mIe.forEach(t),a4r=i(D),wM=n(D,"LI",{});var gIe=s(wM);yve=n(gIe,"STRONG",{});var ayt=s(yve);n4r=r(ayt,"longformer"),ayt.forEach(t),s4r=r(gIe," \u2014 "),oU=n(gIe,"A",{href:!0});var nyt=s(oU);l4r=r(nyt,"TFLongformerModel"),nyt.forEach(t),i4r=r(gIe," (Longformer model)"),gIe.forEach(t),d4r=i(D),AM=n(D,"LI",{});var hIe=s(AM);xve=n(hIe,"STRONG",{});var syt=s(xve);c4r=r(syt,"lxmert"),syt.forEach(t),f4r=r(hIe," \u2014 "),rU=n(hIe,"A",{href:!0});var lyt=s(rU);m4r=r(lyt,"TFLxmertModel"),lyt.forEach(t),g4r=r(hIe," (LXMERT model)"),hIe.forEach(t),h4r=i(D),LM=n(D,"LI",{});var pIe=s(LM);$ve=n(pIe,"STRONG",{});var iyt=s($ve);p4r=r(iyt,"marian"),iyt.forEach(t),_4r=r(pIe," \u2014 "),tU=n(pIe,"A",{href:!0});var dyt=s(tU);u4r=r(dyt,"TFMarianModel"),dyt.forEach(t),b4r=r(pIe," (Marian model)"),pIe.forEach(t),v4r=i(D),yM=n(D,"LI",{});var _Ie=s(yM);kve=n(_Ie,"STRONG",{});var cyt=s(kve);F4r=r(cyt,"mbart"),cyt.forEach(t),T4r=r(_Ie," \u2014 "),aU=n(_Ie,"A",{href:!0});var fyt=s(aU);M4r=r(fyt,"TFMBartModel"),fyt.forEach(t),E4r=r(_Ie," (mBART model)"),_Ie.forEach(t),C4r=i(D),xM=n(D,"LI",{});var uIe=s(xM);Sve=n(uIe,"STRONG",{});var myt=s(Sve);w4r=r(myt,"mobilebert"),myt.forEach(t),A4r=r(uIe," \u2014 "),nU=n(uIe,"A",{href:!0});var gyt=s(nU);L4r=r(gyt,"TFMobileBertModel"),gyt.forEach(t),y4r=r(uIe," (MobileBERT model)"),uIe.forEach(t),x4r=i(D),$M=n(D,"LI",{});var bIe=s($M);Rve=n(bIe,"STRONG",{});var hyt=s(Rve);$4r=r(hyt,"mpnet"),hyt.forEach(t),k4r=r(bIe," \u2014 "),sU=n(bIe,"A",{href:!0});var pyt=s(sU);S4r=r(pyt,"TFMPNetModel"),pyt.forEach(t),R4r=r(bIe," (MPNet model)"),bIe.forEach(t),P4r=i(D),kM=n(D,"LI",{});var vIe=s(kM);Pve=n(vIe,"STRONG",{});var _yt=s(Pve);B4r=r(_yt,"mt5"),_yt.forEach(t),N4r=r(vIe," \u2014 "),lU=n(vIe,"A",{href:!0});var uyt=s(lU);I4r=r(uyt,"TFMT5Model"),uyt.forEach(t),q4r=r(vIe," (MT5 model)"),vIe.forEach(t),j4r=i(D),SM=n(D,"LI",{});var FIe=s(SM);Bve=n(FIe,"STRONG",{});var byt=s(Bve);D4r=r(byt,"openai-gpt"),byt.forEach(t),G4r=r(FIe," \u2014 "),iU=n(FIe,"A",{href:!0});var vyt=s(iU);O4r=r(vyt,"TFOpenAIGPTModel"),vyt.forEach(t),V4r=r(FIe," (OpenAI GPT model)"),FIe.forEach(t),X4r=i(D),RM=n(D,"LI",{});var TIe=s(RM);Nve=n(TIe,"STRONG",{});var Fyt=s(Nve);z4r=r(Fyt,"opt"),Fyt.forEach(t),Q4r=r(TIe," \u2014 "),dU=n(TIe,"A",{href:!0});var Tyt=s(dU);W4r=r(Tyt,"TFOPTModel"),Tyt.forEach(t),H4r=r(TIe," (OPT model)"),TIe.forEach(t),U4r=i(D),PM=n(D,"LI",{});var MIe=s(PM);Ive=n(MIe,"STRONG",{});var Myt=s(Ive);J4r=r(Myt,"pegasus"),Myt.forEach(t),Y4r=r(MIe," \u2014 "),cU=n(MIe,"A",{href:!0});var Eyt=s(cU);K4r=r(Eyt,"TFPegasusModel"),Eyt.forEach(t),Z4r=r(MIe," (Pegasus model)"),MIe.forEach(t),ebr=i(D),BM=n(D,"LI",{});var EIe=s(BM);qve=n(EIe,"STRONG",{});var Cyt=s(qve);obr=r(Cyt,"regnet"),Cyt.forEach(t),rbr=r(EIe," \u2014 "),fU=n(EIe,"A",{href:!0});var wyt=s(fU);tbr=r(wyt,"TFRegNetModel"),wyt.forEach(t),abr=r(EIe," (RegNet model)"),EIe.forEach(t),nbr=i(D),NM=n(D,"LI",{});var CIe=s(NM);jve=n(CIe,"STRONG",{});var Ayt=s(jve);sbr=r(Ayt,"rembert"),Ayt.forEach(t),lbr=r(CIe," \u2014 "),mU=n(CIe,"A",{href:!0});var Lyt=s(mU);ibr=r(Lyt,"TFRemBertModel"),Lyt.forEach(t),dbr=r(CIe," (RemBERT model)"),CIe.forEach(t),cbr=i(D),IM=n(D,"LI",{});var wIe=s(IM);Dve=n(wIe,"STRONG",{});var yyt=s(Dve);fbr=r(yyt,"resnet"),yyt.forEach(t),mbr=r(wIe," \u2014 "),gU=n(wIe,"A",{href:!0});var xyt=s(gU);gbr=r(xyt,"TFResNetModel"),xyt.forEach(t),hbr=r(wIe," (ResNet model)"),wIe.forEach(t),pbr=i(D),qM=n(D,"LI",{});var AIe=s(qM);Gve=n(AIe,"STRONG",{});var $yt=s(Gve);_br=r($yt,"roberta"),$yt.forEach(t),ubr=r(AIe," \u2014 "),hU=n(AIe,"A",{href:!0});var kyt=s(hU);bbr=r(kyt,"TFRobertaModel"),kyt.forEach(t),vbr=r(AIe," (RoBERTa model)"),AIe.forEach(t),Fbr=i(D),jM=n(D,"LI",{});var LIe=s(jM);Ove=n(LIe,"STRONG",{});var Syt=s(Ove);Tbr=r(Syt,"roformer"),Syt.forEach(t),Mbr=r(LIe," \u2014 "),pU=n(LIe,"A",{href:!0});var Ryt=s(pU);Ebr=r(Ryt,"TFRoFormerModel"),Ryt.forEach(t),Cbr=r(LIe," (RoFormer model)"),LIe.forEach(t),wbr=i(D),DM=n(D,"LI",{});var yIe=s(DM);Vve=n(yIe,"STRONG",{});var Pyt=s(Vve);Abr=r(Pyt,"speech_to_text"),Pyt.forEach(t),Lbr=r(yIe," \u2014 "),_U=n(yIe,"A",{href:!0});var Byt=s(_U);ybr=r(Byt,"TFSpeech2TextModel"),Byt.forEach(t),xbr=r(yIe," (Speech2Text model)"),yIe.forEach(t),$br=i(D),GM=n(D,"LI",{});var xIe=s(GM);Xve=n(xIe,"STRONG",{});var Nyt=s(Xve);kbr=r(Nyt,"swin"),Nyt.forEach(t),Sbr=r(xIe," \u2014 "),uU=n(xIe,"A",{href:!0});var Iyt=s(uU);Rbr=r(Iyt,"TFSwinModel"),Iyt.forEach(t),Pbr=r(xIe," (Swin Transformer model)"),xIe.forEach(t),Bbr=i(D),OM=n(D,"LI",{});var $Ie=s(OM);zve=n($Ie,"STRONG",{});var qyt=s(zve);Nbr=r(qyt,"t5"),qyt.forEach(t),Ibr=r($Ie," \u2014 "),bU=n($Ie,"A",{href:!0});var jyt=s(bU);qbr=r(jyt,"TFT5Model"),jyt.forEach(t),jbr=r($Ie," (T5 model)"),$Ie.forEach(t),Dbr=i(D),VM=n(D,"LI",{});var kIe=s(VM);Qve=n(kIe,"STRONG",{});var Dyt=s(Qve);Gbr=r(Dyt,"tapas"),Dyt.forEach(t),Obr=r(kIe," \u2014 "),vU=n(kIe,"A",{href:!0});var Gyt=s(vU);Vbr=r(Gyt,"TFTapasModel"),Gyt.forEach(t),Xbr=r(kIe," (TAPAS model)"),kIe.forEach(t),zbr=i(D),XM=n(D,"LI",{});var SIe=s(XM);Wve=n(SIe,"STRONG",{});var Oyt=s(Wve);Qbr=r(Oyt,"transfo-xl"),Oyt.forEach(t),Wbr=r(SIe," \u2014 "),FU=n(SIe,"A",{href:!0});var Vyt=s(FU);Hbr=r(Vyt,"TFTransfoXLModel"),Vyt.forEach(t),Ubr=r(SIe," (Transformer-XL model)"),SIe.forEach(t),Jbr=i(D),zM=n(D,"LI",{});var RIe=s(zM);Hve=n(RIe,"STRONG",{});var Xyt=s(Hve);Ybr=r(Xyt,"vit"),Xyt.forEach(t),Kbr=r(RIe," \u2014 "),TU=n(RIe,"A",{href:!0});var zyt=s(TU);Zbr=r(zyt,"TFViTModel"),zyt.forEach(t),evr=r(RIe," (ViT model)"),RIe.forEach(t),ovr=i(D),QM=n(D,"LI",{});var PIe=s(QM);Uve=n(PIe,"STRONG",{});var Qyt=s(Uve);rvr=r(Qyt,"vit_mae"),Qyt.forEach(t),tvr=r(PIe," \u2014 "),MU=n(PIe,"A",{href:!0});var Wyt=s(MU);avr=r(Wyt,"TFViTMAEModel"),Wyt.forEach(t),nvr=r(PIe," (ViTMAE model)"),PIe.forEach(t),svr=i(D),WM=n(D,"LI",{});var BIe=s(WM);Jve=n(BIe,"STRONG",{});var Hyt=s(Jve);lvr=r(Hyt,"wav2vec2"),Hyt.forEach(t),ivr=r(BIe," \u2014 "),EU=n(BIe,"A",{href:!0});var Uyt=s(EU);dvr=r(Uyt,"TFWav2Vec2Model"),Uyt.forEach(t),cvr=r(BIe," (Wav2Vec2 model)"),BIe.forEach(t),fvr=i(D),HM=n(D,"LI",{});var NIe=s(HM);Yve=n(NIe,"STRONG",{});var Jyt=s(Yve);mvr=r(Jyt,"xlm"),Jyt.forEach(t),gvr=r(NIe," \u2014 "),CU=n(NIe,"A",{href:!0});var Yyt=s(CU);hvr=r(Yyt,"TFXLMModel"),Yyt.forEach(t),pvr=r(NIe," (XLM model)"),NIe.forEach(t),_vr=i(D),UM=n(D,"LI",{});var IIe=s(UM);Kve=n(IIe,"STRONG",{});var Kyt=s(Kve);uvr=r(Kyt,"xlm-roberta"),Kyt.forEach(t),bvr=r(IIe," \u2014 "),wU=n(IIe,"A",{href:!0});var Zyt=s(wU);vvr=r(Zyt,"TFXLMRobertaModel"),Zyt.forEach(t),Fvr=r(IIe," (XLM-RoBERTa model)"),IIe.forEach(t),Tvr=i(D),JM=n(D,"LI",{});var qIe=s(JM);Zve=n(qIe,"STRONG",{});var e8t=s(Zve);Mvr=r(e8t,"xlnet"),e8t.forEach(t),Evr=r(qIe," \u2014 "),AU=n(qIe,"A",{href:!0});var o8t=s(AU);Cvr=r(o8t,"TFXLNetModel"),o8t.forEach(t),wvr=r(qIe," (XLNet model)"),qIe.forEach(t),D.forEach(t),Avr=i(Ll),T(YM.$$.fragment,Ll),Ll.forEach(t),Al.forEach(t),HVe=i(f),sc=n(f,"H2",{class:!0});var rQe=s(sc);KM=n(rQe,"A",{id:!0,class:!0,href:!0});var r8t=s(KM);eFe=n(r8t,"SPAN",{});var t8t=s(eFe);T(R9.$$.fragment,t8t),t8t.forEach(t),r8t.forEach(t),Lvr=i(rQe),oFe=n(rQe,"SPAN",{});var a8t=s(oFe);yvr=r(a8t,"TFAutoModelForPreTraining"),a8t.forEach(t),rQe.forEach(t),UVe=i(f),or=n(f,"DIV",{class:!0});var yl=s(or);T(P9.$$.fragment,yl),xvr=i(yl),lc=n(yl,"P",{});var Qre=s(lc);$vr=r(Qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),LU=n(Qre,"A",{href:!0});var n8t=s(LU);kvr=r(n8t,"from_pretrained()"),n8t.forEach(t),Svr=r(Qre," class method or the "),yU=n(Qre,"A",{href:!0});var s8t=s(yU);Rvr=r(s8t,"from_config()"),s8t.forEach(t),Pvr=r(Qre,` class
method.`),Qre.forEach(t),Bvr=i(yl),B9=n(yl,"P",{});var tQe=s(B9);Nvr=r(tQe,"This class cannot be instantiated directly using "),rFe=n(tQe,"CODE",{});var l8t=s(rFe);Ivr=r(l8t,"__init__()"),l8t.forEach(t),qvr=r(tQe," (throws an error)."),tQe.forEach(t),jvr=i(yl),St=n(yl,"DIV",{class:!0});var O6=s(St);T(N9.$$.fragment,O6),Dvr=i(O6),tFe=n(O6,"P",{});var i8t=s(tFe);Gvr=r(i8t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),i8t.forEach(t),Ovr=i(O6),ic=n(O6,"P",{});var Wre=s(ic);Vvr=r(Wre,`Note:
Loading a model from its configuration file does `),aFe=n(Wre,"STRONG",{});var d8t=s(aFe);Xvr=r(d8t,"not"),d8t.forEach(t),zvr=r(Wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=n(Wre,"A",{href:!0});var c8t=s(xU);Qvr=r(c8t,"from_pretrained()"),c8t.forEach(t),Wvr=r(Wre," to load the model weights."),Wre.forEach(t),Hvr=i(O6),T(ZM.$$.fragment,O6),O6.forEach(t),Uvr=i(yl),$r=n(yl,"DIV",{class:!0});var xl=s($r);T(I9.$$.fragment,xl),Jvr=i(xl),nFe=n(xl,"P",{});var f8t=s(nFe);Yvr=r(f8t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),f8t.forEach(t),Kvr=i(xl),ln=n(xl,"P",{});var V6=s(ln);Zvr=r(V6,"The model class to instantiate is selected based on the "),sFe=n(V6,"CODE",{});var m8t=s(sFe);eFr=r(m8t,"model_type"),m8t.forEach(t),oFr=r(V6,` property of the config object (either
passed as an argument or loaded from `),lFe=n(V6,"CODE",{});var g8t=s(lFe);rFr=r(g8t,"pretrained_model_name_or_path"),g8t.forEach(t),tFr=r(V6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iFe=n(V6,"CODE",{});var h8t=s(iFe);aFr=r(h8t,"pretrained_model_name_or_path"),h8t.forEach(t),nFr=r(V6,":"),V6.forEach(t),sFr=i(xl),se=n(xl,"UL",{});var le=s(se);eE=n(le,"LI",{});var jIe=s(eE);dFe=n(jIe,"STRONG",{});var p8t=s(dFe);lFr=r(p8t,"albert"),p8t.forEach(t),iFr=r(jIe," \u2014 "),$U=n(jIe,"A",{href:!0});var _8t=s($U);dFr=r(_8t,"TFAlbertForPreTraining"),_8t.forEach(t),cFr=r(jIe," (ALBERT model)"),jIe.forEach(t),fFr=i(le),oE=n(le,"LI",{});var DIe=s(oE);cFe=n(DIe,"STRONG",{});var u8t=s(cFe);mFr=r(u8t,"bart"),u8t.forEach(t),gFr=r(DIe," \u2014 "),kU=n(DIe,"A",{href:!0});var b8t=s(kU);hFr=r(b8t,"TFBartForConditionalGeneration"),b8t.forEach(t),pFr=r(DIe," (BART model)"),DIe.forEach(t),_Fr=i(le),rE=n(le,"LI",{});var GIe=s(rE);fFe=n(GIe,"STRONG",{});var v8t=s(fFe);uFr=r(v8t,"bert"),v8t.forEach(t),bFr=r(GIe," \u2014 "),SU=n(GIe,"A",{href:!0});var F8t=s(SU);vFr=r(F8t,"TFBertForPreTraining"),F8t.forEach(t),FFr=r(GIe," (BERT model)"),GIe.forEach(t),TFr=i(le),tE=n(le,"LI",{});var OIe=s(tE);mFe=n(OIe,"STRONG",{});var T8t=s(mFe);MFr=r(T8t,"camembert"),T8t.forEach(t),EFr=r(OIe," \u2014 "),RU=n(OIe,"A",{href:!0});var M8t=s(RU);CFr=r(M8t,"TFCamembertForMaskedLM"),M8t.forEach(t),wFr=r(OIe," (CamemBERT model)"),OIe.forEach(t),AFr=i(le),aE=n(le,"LI",{});var VIe=s(aE);gFe=n(VIe,"STRONG",{});var E8t=s(gFe);LFr=r(E8t,"ctrl"),E8t.forEach(t),yFr=r(VIe," \u2014 "),PU=n(VIe,"A",{href:!0});var C8t=s(PU);xFr=r(C8t,"TFCTRLLMHeadModel"),C8t.forEach(t),$Fr=r(VIe," (CTRL model)"),VIe.forEach(t),kFr=i(le),nE=n(le,"LI",{});var XIe=s(nE);hFe=n(XIe,"STRONG",{});var w8t=s(hFe);SFr=r(w8t,"distilbert"),w8t.forEach(t),RFr=r(XIe," \u2014 "),BU=n(XIe,"A",{href:!0});var A8t=s(BU);PFr=r(A8t,"TFDistilBertForMaskedLM"),A8t.forEach(t),BFr=r(XIe," (DistilBERT model)"),XIe.forEach(t),NFr=i(le),sE=n(le,"LI",{});var zIe=s(sE);pFe=n(zIe,"STRONG",{});var L8t=s(pFe);IFr=r(L8t,"electra"),L8t.forEach(t),qFr=r(zIe," \u2014 "),NU=n(zIe,"A",{href:!0});var y8t=s(NU);jFr=r(y8t,"TFElectraForPreTraining"),y8t.forEach(t),DFr=r(zIe," (ELECTRA model)"),zIe.forEach(t),GFr=i(le),lE=n(le,"LI",{});var QIe=s(lE);_Fe=n(QIe,"STRONG",{});var x8t=s(_Fe);OFr=r(x8t,"flaubert"),x8t.forEach(t),VFr=r(QIe," \u2014 "),IU=n(QIe,"A",{href:!0});var $8t=s(IU);XFr=r($8t,"TFFlaubertWithLMHeadModel"),$8t.forEach(t),zFr=r(QIe," (FlauBERT model)"),QIe.forEach(t),QFr=i(le),iE=n(le,"LI",{});var WIe=s(iE);uFe=n(WIe,"STRONG",{});var k8t=s(uFe);WFr=r(k8t,"funnel"),k8t.forEach(t),HFr=r(WIe," \u2014 "),qU=n(WIe,"A",{href:!0});var S8t=s(qU);UFr=r(S8t,"TFFunnelForPreTraining"),S8t.forEach(t),JFr=r(WIe," (Funnel Transformer model)"),WIe.forEach(t),YFr=i(le),dE=n(le,"LI",{});var HIe=s(dE);bFe=n(HIe,"STRONG",{});var R8t=s(bFe);KFr=r(R8t,"gpt2"),R8t.forEach(t),ZFr=r(HIe," \u2014 "),jU=n(HIe,"A",{href:!0});var P8t=s(jU);eTr=r(P8t,"TFGPT2LMHeadModel"),P8t.forEach(t),oTr=r(HIe," (OpenAI GPT-2 model)"),HIe.forEach(t),rTr=i(le),cE=n(le,"LI",{});var UIe=s(cE);vFe=n(UIe,"STRONG",{});var B8t=s(vFe);tTr=r(B8t,"layoutlm"),B8t.forEach(t),aTr=r(UIe," \u2014 "),DU=n(UIe,"A",{href:!0});var N8t=s(DU);nTr=r(N8t,"TFLayoutLMForMaskedLM"),N8t.forEach(t),sTr=r(UIe," (LayoutLM model)"),UIe.forEach(t),lTr=i(le),fE=n(le,"LI",{});var JIe=s(fE);FFe=n(JIe,"STRONG",{});var I8t=s(FFe);iTr=r(I8t,"lxmert"),I8t.forEach(t),dTr=r(JIe," \u2014 "),GU=n(JIe,"A",{href:!0});var q8t=s(GU);cTr=r(q8t,"TFLxmertForPreTraining"),q8t.forEach(t),fTr=r(JIe," (LXMERT model)"),JIe.forEach(t),mTr=i(le),mE=n(le,"LI",{});var YIe=s(mE);TFe=n(YIe,"STRONG",{});var j8t=s(TFe);gTr=r(j8t,"mobilebert"),j8t.forEach(t),hTr=r(YIe," \u2014 "),OU=n(YIe,"A",{href:!0});var D8t=s(OU);pTr=r(D8t,"TFMobileBertForPreTraining"),D8t.forEach(t),_Tr=r(YIe," (MobileBERT model)"),YIe.forEach(t),uTr=i(le),gE=n(le,"LI",{});var KIe=s(gE);MFe=n(KIe,"STRONG",{});var G8t=s(MFe);bTr=r(G8t,"mpnet"),G8t.forEach(t),vTr=r(KIe," \u2014 "),VU=n(KIe,"A",{href:!0});var O8t=s(VU);FTr=r(O8t,"TFMPNetForMaskedLM"),O8t.forEach(t),TTr=r(KIe," (MPNet model)"),KIe.forEach(t),MTr=i(le),hE=n(le,"LI",{});var ZIe=s(hE);EFe=n(ZIe,"STRONG",{});var V8t=s(EFe);ETr=r(V8t,"openai-gpt"),V8t.forEach(t),CTr=r(ZIe," \u2014 "),XU=n(ZIe,"A",{href:!0});var X8t=s(XU);wTr=r(X8t,"TFOpenAIGPTLMHeadModel"),X8t.forEach(t),ATr=r(ZIe," (OpenAI GPT model)"),ZIe.forEach(t),LTr=i(le),pE=n(le,"LI",{});var eqe=s(pE);CFe=n(eqe,"STRONG",{});var z8t=s(CFe);yTr=r(z8t,"roberta"),z8t.forEach(t),xTr=r(eqe," \u2014 "),zU=n(eqe,"A",{href:!0});var Q8t=s(zU);$Tr=r(Q8t,"TFRobertaForMaskedLM"),Q8t.forEach(t),kTr=r(eqe," (RoBERTa model)"),eqe.forEach(t),STr=i(le),_E=n(le,"LI",{});var oqe=s(_E);wFe=n(oqe,"STRONG",{});var W8t=s(wFe);RTr=r(W8t,"t5"),W8t.forEach(t),PTr=r(oqe," \u2014 "),QU=n(oqe,"A",{href:!0});var H8t=s(QU);BTr=r(H8t,"TFT5ForConditionalGeneration"),H8t.forEach(t),NTr=r(oqe," (T5 model)"),oqe.forEach(t),ITr=i(le),uE=n(le,"LI",{});var rqe=s(uE);AFe=n(rqe,"STRONG",{});var U8t=s(AFe);qTr=r(U8t,"tapas"),U8t.forEach(t),jTr=r(rqe," \u2014 "),WU=n(rqe,"A",{href:!0});var J8t=s(WU);DTr=r(J8t,"TFTapasForMaskedLM"),J8t.forEach(t),GTr=r(rqe," (TAPAS model)"),rqe.forEach(t),OTr=i(le),bE=n(le,"LI",{});var tqe=s(bE);LFe=n(tqe,"STRONG",{});var Y8t=s(LFe);VTr=r(Y8t,"transfo-xl"),Y8t.forEach(t),XTr=r(tqe," \u2014 "),HU=n(tqe,"A",{href:!0});var K8t=s(HU);zTr=r(K8t,"TFTransfoXLLMHeadModel"),K8t.forEach(t),QTr=r(tqe," (Transformer-XL model)"),tqe.forEach(t),WTr=i(le),vE=n(le,"LI",{});var aqe=s(vE);yFe=n(aqe,"STRONG",{});var Z8t=s(yFe);HTr=r(Z8t,"vit_mae"),Z8t.forEach(t),UTr=r(aqe," \u2014 "),UU=n(aqe,"A",{href:!0});var e9t=s(UU);JTr=r(e9t,"TFViTMAEForPreTraining"),e9t.forEach(t),YTr=r(aqe," (ViTMAE model)"),aqe.forEach(t),KTr=i(le),FE=n(le,"LI",{});var nqe=s(FE);xFe=n(nqe,"STRONG",{});var o9t=s(xFe);ZTr=r(o9t,"xlm"),o9t.forEach(t),eMr=r(nqe," \u2014 "),JU=n(nqe,"A",{href:!0});var r9t=s(JU);oMr=r(r9t,"TFXLMWithLMHeadModel"),r9t.forEach(t),rMr=r(nqe," (XLM model)"),nqe.forEach(t),tMr=i(le),TE=n(le,"LI",{});var sqe=s(TE);$Fe=n(sqe,"STRONG",{});var t9t=s($Fe);aMr=r(t9t,"xlm-roberta"),t9t.forEach(t),nMr=r(sqe," \u2014 "),YU=n(sqe,"A",{href:!0});var a9t=s(YU);sMr=r(a9t,"TFXLMRobertaForMaskedLM"),a9t.forEach(t),lMr=r(sqe," (XLM-RoBERTa model)"),sqe.forEach(t),iMr=i(le),ME=n(le,"LI",{});var lqe=s(ME);kFe=n(lqe,"STRONG",{});var n9t=s(kFe);dMr=r(n9t,"xlnet"),n9t.forEach(t),cMr=r(lqe," \u2014 "),KU=n(lqe,"A",{href:!0});var s9t=s(KU);fMr=r(s9t,"TFXLNetLMHeadModel"),s9t.forEach(t),mMr=r(lqe," (XLNet model)"),lqe.forEach(t),le.forEach(t),gMr=i(xl),T(EE.$$.fragment,xl),xl.forEach(t),yl.forEach(t),JVe=i(f),dc=n(f,"H2",{class:!0});var aQe=s(dc);CE=n(aQe,"A",{id:!0,class:!0,href:!0});var l9t=s(CE);SFe=n(l9t,"SPAN",{});var i9t=s(SFe);T(q9.$$.fragment,i9t),i9t.forEach(t),l9t.forEach(t),hMr=i(aQe),RFe=n(aQe,"SPAN",{});var d9t=s(RFe);pMr=r(d9t,"TFAutoModelForCausalLM"),d9t.forEach(t),aQe.forEach(t),YVe=i(f),rr=n(f,"DIV",{class:!0});var $l=s(rr);T(j9.$$.fragment,$l),_Mr=i($l),cc=n($l,"P",{});var Hre=s(cc);uMr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),ZU=n(Hre,"A",{href:!0});var c9t=s(ZU);bMr=r(c9t,"from_pretrained()"),c9t.forEach(t),vMr=r(Hre," class method or the "),eJ=n(Hre,"A",{href:!0});var f9t=s(eJ);FMr=r(f9t,"from_config()"),f9t.forEach(t),TMr=r(Hre,` class
method.`),Hre.forEach(t),MMr=i($l),D9=n($l,"P",{});var nQe=s(D9);EMr=r(nQe,"This class cannot be instantiated directly using "),PFe=n(nQe,"CODE",{});var m9t=s(PFe);CMr=r(m9t,"__init__()"),m9t.forEach(t),wMr=r(nQe," (throws an error)."),nQe.forEach(t),AMr=i($l),Rt=n($l,"DIV",{class:!0});var X6=s(Rt);T(G9.$$.fragment,X6),LMr=i(X6),BFe=n(X6,"P",{});var g9t=s(BFe);yMr=r(g9t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),g9t.forEach(t),xMr=i(X6),fc=n(X6,"P",{});var Ure=s(fc);$Mr=r(Ure,`Note:
Loading a model from its configuration file does `),NFe=n(Ure,"STRONG",{});var h9t=s(NFe);kMr=r(h9t,"not"),h9t.forEach(t),SMr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=n(Ure,"A",{href:!0});var p9t=s(oJ);RMr=r(p9t,"from_pretrained()"),p9t.forEach(t),PMr=r(Ure," to load the model weights."),Ure.forEach(t),BMr=i(X6),T(wE.$$.fragment,X6),X6.forEach(t),NMr=i($l),kr=n($l,"DIV",{class:!0});var kl=s(kr);T(O9.$$.fragment,kl),IMr=i(kl),IFe=n(kl,"P",{});var _9t=s(IFe);qMr=r(_9t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),_9t.forEach(t),jMr=i(kl),dn=n(kl,"P",{});var z6=s(dn);DMr=r(z6,"The model class to instantiate is selected based on the "),qFe=n(z6,"CODE",{});var u9t=s(qFe);GMr=r(u9t,"model_type"),u9t.forEach(t),OMr=r(z6,` property of the config object (either
passed as an argument or loaded from `),jFe=n(z6,"CODE",{});var b9t=s(jFe);VMr=r(b9t,"pretrained_model_name_or_path"),b9t.forEach(t),XMr=r(z6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DFe=n(z6,"CODE",{});var v9t=s(DFe);zMr=r(v9t,"pretrained_model_name_or_path"),v9t.forEach(t),QMr=r(z6,":"),z6.forEach(t),WMr=i(kl),Me=n(kl,"UL",{});var Ce=s(Me);AE=n(Ce,"LI",{});var iqe=s(AE);GFe=n(iqe,"STRONG",{});var F9t=s(GFe);HMr=r(F9t,"bert"),F9t.forEach(t),UMr=r(iqe," \u2014 "),rJ=n(iqe,"A",{href:!0});var T9t=s(rJ);JMr=r(T9t,"TFBertLMHeadModel"),T9t.forEach(t),YMr=r(iqe," (BERT model)"),iqe.forEach(t),KMr=i(Ce),LE=n(Ce,"LI",{});var dqe=s(LE);OFe=n(dqe,"STRONG",{});var M9t=s(OFe);ZMr=r(M9t,"camembert"),M9t.forEach(t),eEr=r(dqe," \u2014 "),tJ=n(dqe,"A",{href:!0});var E9t=s(tJ);oEr=r(E9t,"TFCamembertForCausalLM"),E9t.forEach(t),rEr=r(dqe," (CamemBERT model)"),dqe.forEach(t),tEr=i(Ce),yE=n(Ce,"LI",{});var cqe=s(yE);VFe=n(cqe,"STRONG",{});var C9t=s(VFe);aEr=r(C9t,"ctrl"),C9t.forEach(t),nEr=r(cqe," \u2014 "),aJ=n(cqe,"A",{href:!0});var w9t=s(aJ);sEr=r(w9t,"TFCTRLLMHeadModel"),w9t.forEach(t),lEr=r(cqe," (CTRL model)"),cqe.forEach(t),iEr=i(Ce),xE=n(Ce,"LI",{});var fqe=s(xE);XFe=n(fqe,"STRONG",{});var A9t=s(XFe);dEr=r(A9t,"gpt2"),A9t.forEach(t),cEr=r(fqe," \u2014 "),nJ=n(fqe,"A",{href:!0});var L9t=s(nJ);fEr=r(L9t,"TFGPT2LMHeadModel"),L9t.forEach(t),mEr=r(fqe," (OpenAI GPT-2 model)"),fqe.forEach(t),gEr=i(Ce),$E=n(Ce,"LI",{});var mqe=s($E);zFe=n(mqe,"STRONG",{});var y9t=s(zFe);hEr=r(y9t,"gptj"),y9t.forEach(t),pEr=r(mqe," \u2014 "),sJ=n(mqe,"A",{href:!0});var x9t=s(sJ);_Er=r(x9t,"TFGPTJForCausalLM"),x9t.forEach(t),uEr=r(mqe," (GPT-J model)"),mqe.forEach(t),bEr=i(Ce),kE=n(Ce,"LI",{});var gqe=s(kE);QFe=n(gqe,"STRONG",{});var $9t=s(QFe);vEr=r($9t,"openai-gpt"),$9t.forEach(t),FEr=r(gqe," \u2014 "),lJ=n(gqe,"A",{href:!0});var k9t=s(lJ);TEr=r(k9t,"TFOpenAIGPTLMHeadModel"),k9t.forEach(t),MEr=r(gqe," (OpenAI GPT model)"),gqe.forEach(t),EEr=i(Ce),SE=n(Ce,"LI",{});var hqe=s(SE);WFe=n(hqe,"STRONG",{});var S9t=s(WFe);CEr=r(S9t,"opt"),S9t.forEach(t),wEr=r(hqe," \u2014 "),iJ=n(hqe,"A",{href:!0});var R9t=s(iJ);AEr=r(R9t,"TFOPTForCausalLM"),R9t.forEach(t),LEr=r(hqe," (OPT model)"),hqe.forEach(t),yEr=i(Ce),RE=n(Ce,"LI",{});var pqe=s(RE);HFe=n(pqe,"STRONG",{});var P9t=s(HFe);xEr=r(P9t,"rembert"),P9t.forEach(t),$Er=r(pqe," \u2014 "),dJ=n(pqe,"A",{href:!0});var B9t=s(dJ);kEr=r(B9t,"TFRemBertForCausalLM"),B9t.forEach(t),SEr=r(pqe," (RemBERT model)"),pqe.forEach(t),REr=i(Ce),PE=n(Ce,"LI",{});var _qe=s(PE);UFe=n(_qe,"STRONG",{});var N9t=s(UFe);PEr=r(N9t,"roberta"),N9t.forEach(t),BEr=r(_qe," \u2014 "),cJ=n(_qe,"A",{href:!0});var I9t=s(cJ);NEr=r(I9t,"TFRobertaForCausalLM"),I9t.forEach(t),IEr=r(_qe," (RoBERTa model)"),_qe.forEach(t),qEr=i(Ce),BE=n(Ce,"LI",{});var uqe=s(BE);JFe=n(uqe,"STRONG",{});var q9t=s(JFe);jEr=r(q9t,"roformer"),q9t.forEach(t),DEr=r(uqe," \u2014 "),fJ=n(uqe,"A",{href:!0});var j9t=s(fJ);GEr=r(j9t,"TFRoFormerForCausalLM"),j9t.forEach(t),OEr=r(uqe," (RoFormer model)"),uqe.forEach(t),VEr=i(Ce),NE=n(Ce,"LI",{});var bqe=s(NE);YFe=n(bqe,"STRONG",{});var D9t=s(YFe);XEr=r(D9t,"transfo-xl"),D9t.forEach(t),zEr=r(bqe," \u2014 "),mJ=n(bqe,"A",{href:!0});var G9t=s(mJ);QEr=r(G9t,"TFTransfoXLLMHeadModel"),G9t.forEach(t),WEr=r(bqe," (Transformer-XL model)"),bqe.forEach(t),HEr=i(Ce),IE=n(Ce,"LI",{});var vqe=s(IE);KFe=n(vqe,"STRONG",{});var O9t=s(KFe);UEr=r(O9t,"xlm"),O9t.forEach(t),JEr=r(vqe," \u2014 "),gJ=n(vqe,"A",{href:!0});var V9t=s(gJ);YEr=r(V9t,"TFXLMWithLMHeadModel"),V9t.forEach(t),KEr=r(vqe," (XLM model)"),vqe.forEach(t),ZEr=i(Ce),qE=n(Ce,"LI",{});var Fqe=s(qE);ZFe=n(Fqe,"STRONG",{});var X9t=s(ZFe);eCr=r(X9t,"xlnet"),X9t.forEach(t),oCr=r(Fqe," \u2014 "),hJ=n(Fqe,"A",{href:!0});var z9t=s(hJ);rCr=r(z9t,"TFXLNetLMHeadModel"),z9t.forEach(t),tCr=r(Fqe," (XLNet model)"),Fqe.forEach(t),Ce.forEach(t),aCr=i(kl),T(jE.$$.fragment,kl),kl.forEach(t),$l.forEach(t),KVe=i(f),mc=n(f,"H2",{class:!0});var sQe=s(mc);DE=n(sQe,"A",{id:!0,class:!0,href:!0});var Q9t=s(DE);eTe=n(Q9t,"SPAN",{});var W9t=s(eTe);T(V9.$$.fragment,W9t),W9t.forEach(t),Q9t.forEach(t),nCr=i(sQe),oTe=n(sQe,"SPAN",{});var H9t=s(oTe);sCr=r(H9t,"TFAutoModelForImageClassification"),H9t.forEach(t),sQe.forEach(t),ZVe=i(f),tr=n(f,"DIV",{class:!0});var Sl=s(tr);T(X9.$$.fragment,Sl),lCr=i(Sl),gc=n(Sl,"P",{});var Jre=s(gc);iCr=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),pJ=n(Jre,"A",{href:!0});var U9t=s(pJ);dCr=r(U9t,"from_pretrained()"),U9t.forEach(t),cCr=r(Jre," class method or the "),_J=n(Jre,"A",{href:!0});var J9t=s(_J);fCr=r(J9t,"from_config()"),J9t.forEach(t),mCr=r(Jre,` class
method.`),Jre.forEach(t),gCr=i(Sl),z9=n(Sl,"P",{});var lQe=s(z9);hCr=r(lQe,"This class cannot be instantiated directly using "),rTe=n(lQe,"CODE",{});var Y9t=s(rTe);pCr=r(Y9t,"__init__()"),Y9t.forEach(t),_Cr=r(lQe," (throws an error)."),lQe.forEach(t),uCr=i(Sl),Pt=n(Sl,"DIV",{class:!0});var Q6=s(Pt);T(Q9.$$.fragment,Q6),bCr=i(Q6),tTe=n(Q6,"P",{});var K9t=s(tTe);vCr=r(K9t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),K9t.forEach(t),FCr=i(Q6),hc=n(Q6,"P",{});var Yre=s(hc);TCr=r(Yre,`Note:
Loading a model from its configuration file does `),aTe=n(Yre,"STRONG",{});var Z9t=s(aTe);MCr=r(Z9t,"not"),Z9t.forEach(t),ECr=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),uJ=n(Yre,"A",{href:!0});var ext=s(uJ);CCr=r(ext,"from_pretrained()"),ext.forEach(t),wCr=r(Yre," to load the model weights."),Yre.forEach(t),ACr=i(Q6),T(GE.$$.fragment,Q6),Q6.forEach(t),LCr=i(Sl),Sr=n(Sl,"DIV",{class:!0});var Rl=s(Sr);T(W9.$$.fragment,Rl),yCr=i(Rl),nTe=n(Rl,"P",{});var oxt=s(nTe);xCr=r(oxt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),oxt.forEach(t),$Cr=i(Rl),cn=n(Rl,"P",{});var W6=s(cn);kCr=r(W6,"The model class to instantiate is selected based on the "),sTe=n(W6,"CODE",{});var rxt=s(sTe);SCr=r(rxt,"model_type"),rxt.forEach(t),RCr=r(W6,` property of the config object (either
passed as an argument or loaded from `),lTe=n(W6,"CODE",{});var txt=s(lTe);PCr=r(txt,"pretrained_model_name_or_path"),txt.forEach(t),BCr=r(W6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=n(W6,"CODE",{});var axt=s(iTe);NCr=r(axt,"pretrained_model_name_or_path"),axt.forEach(t),ICr=r(W6,":"),W6.forEach(t),qCr=i(Rl),ar=n(Rl,"UL",{});var $a=s(ar);OE=n($a,"LI",{});var Tqe=s(OE);dTe=n(Tqe,"STRONG",{});var nxt=s(dTe);jCr=r(nxt,"convnext"),nxt.forEach(t),DCr=r(Tqe," \u2014 "),bJ=n(Tqe,"A",{href:!0});var sxt=s(bJ);GCr=r(sxt,"TFConvNextForImageClassification"),sxt.forEach(t),OCr=r(Tqe," (ConvNeXT model)"),Tqe.forEach(t),VCr=i($a),VE=n($a,"LI",{});var Mqe=s(VE);cTe=n(Mqe,"STRONG",{});var lxt=s(cTe);XCr=r(lxt,"data2vec-vision"),lxt.forEach(t),zCr=r(Mqe," \u2014 "),vJ=n(Mqe,"A",{href:!0});var ixt=s(vJ);QCr=r(ixt,"TFData2VecVisionForImageClassification"),ixt.forEach(t),WCr=r(Mqe," (Data2VecVision model)"),Mqe.forEach(t),HCr=i($a),XE=n($a,"LI",{});var Eqe=s(XE);fTe=n(Eqe,"STRONG",{});var dxt=s(fTe);UCr=r(dxt,"regnet"),dxt.forEach(t),JCr=r(Eqe," \u2014 "),FJ=n(Eqe,"A",{href:!0});var cxt=s(FJ);YCr=r(cxt,"TFRegNetForImageClassification"),cxt.forEach(t),KCr=r(Eqe," (RegNet model)"),Eqe.forEach(t),ZCr=i($a),zE=n($a,"LI",{});var Cqe=s(zE);mTe=n(Cqe,"STRONG",{});var fxt=s(mTe);e3r=r(fxt,"resnet"),fxt.forEach(t),o3r=r(Cqe," \u2014 "),TJ=n(Cqe,"A",{href:!0});var mxt=s(TJ);r3r=r(mxt,"TFResNetForImageClassification"),mxt.forEach(t),t3r=r(Cqe," (ResNet model)"),Cqe.forEach(t),a3r=i($a),QE=n($a,"LI",{});var wqe=s(QE);gTe=n(wqe,"STRONG",{});var gxt=s(gTe);n3r=r(gxt,"swin"),gxt.forEach(t),s3r=r(wqe," \u2014 "),MJ=n(wqe,"A",{href:!0});var hxt=s(MJ);l3r=r(hxt,"TFSwinForImageClassification"),hxt.forEach(t),i3r=r(wqe," (Swin Transformer model)"),wqe.forEach(t),d3r=i($a),WE=n($a,"LI",{});var Aqe=s(WE);hTe=n(Aqe,"STRONG",{});var pxt=s(hTe);c3r=r(pxt,"vit"),pxt.forEach(t),f3r=r(Aqe," \u2014 "),EJ=n(Aqe,"A",{href:!0});var _xt=s(EJ);m3r=r(_xt,"TFViTForImageClassification"),_xt.forEach(t),g3r=r(Aqe," (ViT model)"),Aqe.forEach(t),$a.forEach(t),h3r=i(Rl),T(HE.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),eXe=i(f),pc=n(f,"H2",{class:!0});var iQe=s(pc);UE=n(iQe,"A",{id:!0,class:!0,href:!0});var uxt=s(UE);pTe=n(uxt,"SPAN",{});var bxt=s(pTe);T(H9.$$.fragment,bxt),bxt.forEach(t),uxt.forEach(t),p3r=i(iQe),_Te=n(iQe,"SPAN",{});var vxt=s(_Te);_3r=r(vxt,"TFAutoModelForMaskedLM"),vxt.forEach(t),iQe.forEach(t),oXe=i(f),nr=n(f,"DIV",{class:!0});var Pl=s(nr);T(U9.$$.fragment,Pl),u3r=i(Pl),_c=n(Pl,"P",{});var Kre=s(_c);b3r=r(Kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),CJ=n(Kre,"A",{href:!0});var Fxt=s(CJ);v3r=r(Fxt,"from_pretrained()"),Fxt.forEach(t),F3r=r(Kre," class method or the "),wJ=n(Kre,"A",{href:!0});var Txt=s(wJ);T3r=r(Txt,"from_config()"),Txt.forEach(t),M3r=r(Kre,` class
method.`),Kre.forEach(t),E3r=i(Pl),J9=n(Pl,"P",{});var dQe=s(J9);C3r=r(dQe,"This class cannot be instantiated directly using "),uTe=n(dQe,"CODE",{});var Mxt=s(uTe);w3r=r(Mxt,"__init__()"),Mxt.forEach(t),A3r=r(dQe," (throws an error)."),dQe.forEach(t),L3r=i(Pl),Bt=n(Pl,"DIV",{class:!0});var H6=s(Bt);T(Y9.$$.fragment,H6),y3r=i(H6),bTe=n(H6,"P",{});var Ext=s(bTe);x3r=r(Ext,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Ext.forEach(t),$3r=i(H6),uc=n(H6,"P",{});var Zre=s(uc);k3r=r(Zre,`Note:
Loading a model from its configuration file does `),vTe=n(Zre,"STRONG",{});var Cxt=s(vTe);S3r=r(Cxt,"not"),Cxt.forEach(t),R3r=r(Zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),AJ=n(Zre,"A",{href:!0});var wxt=s(AJ);P3r=r(wxt,"from_pretrained()"),wxt.forEach(t),B3r=r(Zre," to load the model weights."),Zre.forEach(t),N3r=i(H6),T(JE.$$.fragment,H6),H6.forEach(t),I3r=i(Pl),Rr=n(Pl,"DIV",{class:!0});var Bl=s(Rr);T(K9.$$.fragment,Bl),q3r=i(Bl),FTe=n(Bl,"P",{});var Axt=s(FTe);j3r=r(Axt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Axt.forEach(t),D3r=i(Bl),fn=n(Bl,"P",{});var U6=s(fn);G3r=r(U6,"The model class to instantiate is selected based on the "),TTe=n(U6,"CODE",{});var Lxt=s(TTe);O3r=r(Lxt,"model_type"),Lxt.forEach(t),V3r=r(U6,` property of the config object (either
passed as an argument or loaded from `),MTe=n(U6,"CODE",{});var yxt=s(MTe);X3r=r(yxt,"pretrained_model_name_or_path"),yxt.forEach(t),z3r=r(U6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ETe=n(U6,"CODE",{});var xxt=s(ETe);Q3r=r(xxt,"pretrained_model_name_or_path"),xxt.forEach(t),W3r=r(U6,":"),U6.forEach(t),H3r=i(Bl),ie=n(Bl,"UL",{});var fe=s(ie);YE=n(fe,"LI",{});var Lqe=s(YE);CTe=n(Lqe,"STRONG",{});var $xt=s(CTe);U3r=r($xt,"albert"),$xt.forEach(t),J3r=r(Lqe," \u2014 "),LJ=n(Lqe,"A",{href:!0});var kxt=s(LJ);Y3r=r(kxt,"TFAlbertForMaskedLM"),kxt.forEach(t),K3r=r(Lqe," (ALBERT model)"),Lqe.forEach(t),Z3r=i(fe),KE=n(fe,"LI",{});var yqe=s(KE);wTe=n(yqe,"STRONG",{});var Sxt=s(wTe);e5r=r(Sxt,"bert"),Sxt.forEach(t),o5r=r(yqe," \u2014 "),yJ=n(yqe,"A",{href:!0});var Rxt=s(yJ);r5r=r(Rxt,"TFBertForMaskedLM"),Rxt.forEach(t),t5r=r(yqe," (BERT model)"),yqe.forEach(t),a5r=i(fe),ZE=n(fe,"LI",{});var xqe=s(ZE);ATe=n(xqe,"STRONG",{});var Pxt=s(ATe);n5r=r(Pxt,"camembert"),Pxt.forEach(t),s5r=r(xqe," \u2014 "),xJ=n(xqe,"A",{href:!0});var Bxt=s(xJ);l5r=r(Bxt,"TFCamembertForMaskedLM"),Bxt.forEach(t),i5r=r(xqe," (CamemBERT model)"),xqe.forEach(t),d5r=i(fe),eC=n(fe,"LI",{});var $qe=s(eC);LTe=n($qe,"STRONG",{});var Nxt=s(LTe);c5r=r(Nxt,"convbert"),Nxt.forEach(t),f5r=r($qe," \u2014 "),$J=n($qe,"A",{href:!0});var Ixt=s($J);m5r=r(Ixt,"TFConvBertForMaskedLM"),Ixt.forEach(t),g5r=r($qe," (ConvBERT model)"),$qe.forEach(t),h5r=i(fe),oC=n(fe,"LI",{});var kqe=s(oC);yTe=n(kqe,"STRONG",{});var qxt=s(yTe);p5r=r(qxt,"deberta"),qxt.forEach(t),_5r=r(kqe," \u2014 "),kJ=n(kqe,"A",{href:!0});var jxt=s(kJ);u5r=r(jxt,"TFDebertaForMaskedLM"),jxt.forEach(t),b5r=r(kqe," (DeBERTa model)"),kqe.forEach(t),v5r=i(fe),rC=n(fe,"LI",{});var Sqe=s(rC);xTe=n(Sqe,"STRONG",{});var Dxt=s(xTe);F5r=r(Dxt,"deberta-v2"),Dxt.forEach(t),T5r=r(Sqe," \u2014 "),SJ=n(Sqe,"A",{href:!0});var Gxt=s(SJ);M5r=r(Gxt,"TFDebertaV2ForMaskedLM"),Gxt.forEach(t),E5r=r(Sqe," (DeBERTa-v2 model)"),Sqe.forEach(t),C5r=i(fe),tC=n(fe,"LI",{});var Rqe=s(tC);$Te=n(Rqe,"STRONG",{});var Oxt=s($Te);w5r=r(Oxt,"distilbert"),Oxt.forEach(t),A5r=r(Rqe," \u2014 "),RJ=n(Rqe,"A",{href:!0});var Vxt=s(RJ);L5r=r(Vxt,"TFDistilBertForMaskedLM"),Vxt.forEach(t),y5r=r(Rqe," (DistilBERT model)"),Rqe.forEach(t),x5r=i(fe),aC=n(fe,"LI",{});var Pqe=s(aC);kTe=n(Pqe,"STRONG",{});var Xxt=s(kTe);$5r=r(Xxt,"electra"),Xxt.forEach(t),k5r=r(Pqe," \u2014 "),PJ=n(Pqe,"A",{href:!0});var zxt=s(PJ);S5r=r(zxt,"TFElectraForMaskedLM"),zxt.forEach(t),R5r=r(Pqe," (ELECTRA model)"),Pqe.forEach(t),P5r=i(fe),nC=n(fe,"LI",{});var Bqe=s(nC);STe=n(Bqe,"STRONG",{});var Qxt=s(STe);B5r=r(Qxt,"flaubert"),Qxt.forEach(t),N5r=r(Bqe," \u2014 "),BJ=n(Bqe,"A",{href:!0});var Wxt=s(BJ);I5r=r(Wxt,"TFFlaubertWithLMHeadModel"),Wxt.forEach(t),q5r=r(Bqe," (FlauBERT model)"),Bqe.forEach(t),j5r=i(fe),sC=n(fe,"LI",{});var Nqe=s(sC);RTe=n(Nqe,"STRONG",{});var Hxt=s(RTe);D5r=r(Hxt,"funnel"),Hxt.forEach(t),G5r=r(Nqe," \u2014 "),NJ=n(Nqe,"A",{href:!0});var Uxt=s(NJ);O5r=r(Uxt,"TFFunnelForMaskedLM"),Uxt.forEach(t),V5r=r(Nqe," (Funnel Transformer model)"),Nqe.forEach(t),X5r=i(fe),lC=n(fe,"LI",{});var Iqe=s(lC);PTe=n(Iqe,"STRONG",{});var Jxt=s(PTe);z5r=r(Jxt,"layoutlm"),Jxt.forEach(t),Q5r=r(Iqe," \u2014 "),IJ=n(Iqe,"A",{href:!0});var Yxt=s(IJ);W5r=r(Yxt,"TFLayoutLMForMaskedLM"),Yxt.forEach(t),H5r=r(Iqe," (LayoutLM model)"),Iqe.forEach(t),U5r=i(fe),iC=n(fe,"LI",{});var qqe=s(iC);BTe=n(qqe,"STRONG",{});var Kxt=s(BTe);J5r=r(Kxt,"longformer"),Kxt.forEach(t),Y5r=r(qqe," \u2014 "),qJ=n(qqe,"A",{href:!0});var Zxt=s(qJ);K5r=r(Zxt,"TFLongformerForMaskedLM"),Zxt.forEach(t),Z5r=r(qqe," (Longformer model)"),qqe.forEach(t),e0r=i(fe),dC=n(fe,"LI",{});var jqe=s(dC);NTe=n(jqe,"STRONG",{});var e$t=s(NTe);o0r=r(e$t,"mobilebert"),e$t.forEach(t),r0r=r(jqe," \u2014 "),jJ=n(jqe,"A",{href:!0});var o$t=s(jJ);t0r=r(o$t,"TFMobileBertForMaskedLM"),o$t.forEach(t),a0r=r(jqe," (MobileBERT model)"),jqe.forEach(t),n0r=i(fe),cC=n(fe,"LI",{});var Dqe=s(cC);ITe=n(Dqe,"STRONG",{});var r$t=s(ITe);s0r=r(r$t,"mpnet"),r$t.forEach(t),l0r=r(Dqe," \u2014 "),DJ=n(Dqe,"A",{href:!0});var t$t=s(DJ);i0r=r(t$t,"TFMPNetForMaskedLM"),t$t.forEach(t),d0r=r(Dqe," (MPNet model)"),Dqe.forEach(t),c0r=i(fe),fC=n(fe,"LI",{});var Gqe=s(fC);qTe=n(Gqe,"STRONG",{});var a$t=s(qTe);f0r=r(a$t,"rembert"),a$t.forEach(t),m0r=r(Gqe," \u2014 "),GJ=n(Gqe,"A",{href:!0});var n$t=s(GJ);g0r=r(n$t,"TFRemBertForMaskedLM"),n$t.forEach(t),h0r=r(Gqe," (RemBERT model)"),Gqe.forEach(t),p0r=i(fe),mC=n(fe,"LI",{});var Oqe=s(mC);jTe=n(Oqe,"STRONG",{});var s$t=s(jTe);_0r=r(s$t,"roberta"),s$t.forEach(t),u0r=r(Oqe," \u2014 "),OJ=n(Oqe,"A",{href:!0});var l$t=s(OJ);b0r=r(l$t,"TFRobertaForMaskedLM"),l$t.forEach(t),v0r=r(Oqe," (RoBERTa model)"),Oqe.forEach(t),F0r=i(fe),gC=n(fe,"LI",{});var Vqe=s(gC);DTe=n(Vqe,"STRONG",{});var i$t=s(DTe);T0r=r(i$t,"roformer"),i$t.forEach(t),M0r=r(Vqe," \u2014 "),VJ=n(Vqe,"A",{href:!0});var d$t=s(VJ);E0r=r(d$t,"TFRoFormerForMaskedLM"),d$t.forEach(t),C0r=r(Vqe," (RoFormer model)"),Vqe.forEach(t),w0r=i(fe),hC=n(fe,"LI",{});var Xqe=s(hC);GTe=n(Xqe,"STRONG",{});var c$t=s(GTe);A0r=r(c$t,"tapas"),c$t.forEach(t),L0r=r(Xqe," \u2014 "),XJ=n(Xqe,"A",{href:!0});var f$t=s(XJ);y0r=r(f$t,"TFTapasForMaskedLM"),f$t.forEach(t),x0r=r(Xqe," (TAPAS model)"),Xqe.forEach(t),$0r=i(fe),pC=n(fe,"LI",{});var zqe=s(pC);OTe=n(zqe,"STRONG",{});var m$t=s(OTe);k0r=r(m$t,"xlm"),m$t.forEach(t),S0r=r(zqe," \u2014 "),zJ=n(zqe,"A",{href:!0});var g$t=s(zJ);R0r=r(g$t,"TFXLMWithLMHeadModel"),g$t.forEach(t),P0r=r(zqe," (XLM model)"),zqe.forEach(t),B0r=i(fe),_C=n(fe,"LI",{});var Qqe=s(_C);VTe=n(Qqe,"STRONG",{});var h$t=s(VTe);N0r=r(h$t,"xlm-roberta"),h$t.forEach(t),I0r=r(Qqe," \u2014 "),QJ=n(Qqe,"A",{href:!0});var p$t=s(QJ);q0r=r(p$t,"TFXLMRobertaForMaskedLM"),p$t.forEach(t),j0r=r(Qqe," (XLM-RoBERTa model)"),Qqe.forEach(t),fe.forEach(t),D0r=i(Bl),T(uC.$$.fragment,Bl),Bl.forEach(t),Pl.forEach(t),rXe=i(f),bc=n(f,"H2",{class:!0});var cQe=s(bc);bC=n(cQe,"A",{id:!0,class:!0,href:!0});var _$t=s(bC);XTe=n(_$t,"SPAN",{});var u$t=s(XTe);T(Z9.$$.fragment,u$t),u$t.forEach(t),_$t.forEach(t),G0r=i(cQe),zTe=n(cQe,"SPAN",{});var b$t=s(zTe);O0r=r(b$t,"TFAutoModelForSeq2SeqLM"),b$t.forEach(t),cQe.forEach(t),tXe=i(f),sr=n(f,"DIV",{class:!0});var Nl=s(sr);T(ex.$$.fragment,Nl),V0r=i(Nl),vc=n(Nl,"P",{});var ete=s(vc);X0r=r(ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),WJ=n(ete,"A",{href:!0});var v$t=s(WJ);z0r=r(v$t,"from_pretrained()"),v$t.forEach(t),Q0r=r(ete," class method or the "),HJ=n(ete,"A",{href:!0});var F$t=s(HJ);W0r=r(F$t,"from_config()"),F$t.forEach(t),H0r=r(ete,` class
method.`),ete.forEach(t),U0r=i(Nl),ox=n(Nl,"P",{});var fQe=s(ox);J0r=r(fQe,"This class cannot be instantiated directly using "),QTe=n(fQe,"CODE",{});var T$t=s(QTe);Y0r=r(T$t,"__init__()"),T$t.forEach(t),K0r=r(fQe," (throws an error)."),fQe.forEach(t),Z0r=i(Nl),Nt=n(Nl,"DIV",{class:!0});var J6=s(Nt);T(rx.$$.fragment,J6),ewr=i(J6),WTe=n(J6,"P",{});var M$t=s(WTe);owr=r(M$t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),M$t.forEach(t),rwr=i(J6),Fc=n(J6,"P",{});var ote=s(Fc);twr=r(ote,`Note:
Loading a model from its configuration file does `),HTe=n(ote,"STRONG",{});var E$t=s(HTe);awr=r(E$t,"not"),E$t.forEach(t),nwr=r(ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),UJ=n(ote,"A",{href:!0});var C$t=s(UJ);swr=r(C$t,"from_pretrained()"),C$t.forEach(t),lwr=r(ote," to load the model weights."),ote.forEach(t),iwr=i(J6),T(vC.$$.fragment,J6),J6.forEach(t),dwr=i(Nl),Pr=n(Nl,"DIV",{class:!0});var Il=s(Pr);T(tx.$$.fragment,Il),cwr=i(Il),UTe=n(Il,"P",{});var w$t=s(UTe);fwr=r(w$t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),w$t.forEach(t),mwr=i(Il),mn=n(Il,"P",{});var Y6=s(mn);gwr=r(Y6,"The model class to instantiate is selected based on the "),JTe=n(Y6,"CODE",{});var A$t=s(JTe);hwr=r(A$t,"model_type"),A$t.forEach(t),pwr=r(Y6,` property of the config object (either
passed as an argument or loaded from `),YTe=n(Y6,"CODE",{});var L$t=s(YTe);_wr=r(L$t,"pretrained_model_name_or_path"),L$t.forEach(t),uwr=r(Y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KTe=n(Y6,"CODE",{});var y$t=s(KTe);bwr=r(y$t,"pretrained_model_name_or_path"),y$t.forEach(t),vwr=r(Y6,":"),Y6.forEach(t),Fwr=i(Il),ye=n(Il,"UL",{});var Ne=s(ye);FC=n(Ne,"LI",{});var Wqe=s(FC);ZTe=n(Wqe,"STRONG",{});var x$t=s(ZTe);Twr=r(x$t,"bart"),x$t.forEach(t),Mwr=r(Wqe," \u2014 "),JJ=n(Wqe,"A",{href:!0});var $$t=s(JJ);Ewr=r($$t,"TFBartForConditionalGeneration"),$$t.forEach(t),Cwr=r(Wqe," (BART model)"),Wqe.forEach(t),wwr=i(Ne),TC=n(Ne,"LI",{});var Hqe=s(TC);eMe=n(Hqe,"STRONG",{});var k$t=s(eMe);Awr=r(k$t,"blenderbot"),k$t.forEach(t),Lwr=r(Hqe," \u2014 "),YJ=n(Hqe,"A",{href:!0});var S$t=s(YJ);ywr=r(S$t,"TFBlenderbotForConditionalGeneration"),S$t.forEach(t),xwr=r(Hqe," (Blenderbot model)"),Hqe.forEach(t),$wr=i(Ne),MC=n(Ne,"LI",{});var Uqe=s(MC);oMe=n(Uqe,"STRONG",{});var R$t=s(oMe);kwr=r(R$t,"blenderbot-small"),R$t.forEach(t),Swr=r(Uqe," \u2014 "),KJ=n(Uqe,"A",{href:!0});var P$t=s(KJ);Rwr=r(P$t,"TFBlenderbotSmallForConditionalGeneration"),P$t.forEach(t),Pwr=r(Uqe," (BlenderbotSmall model)"),Uqe.forEach(t),Bwr=i(Ne),EC=n(Ne,"LI",{});var Jqe=s(EC);rMe=n(Jqe,"STRONG",{});var B$t=s(rMe);Nwr=r(B$t,"encoder-decoder"),B$t.forEach(t),Iwr=r(Jqe," \u2014 "),ZJ=n(Jqe,"A",{href:!0});var N$t=s(ZJ);qwr=r(N$t,"TFEncoderDecoderModel"),N$t.forEach(t),jwr=r(Jqe," (Encoder decoder model)"),Jqe.forEach(t),Dwr=i(Ne),CC=n(Ne,"LI",{});var Yqe=s(CC);tMe=n(Yqe,"STRONG",{});var I$t=s(tMe);Gwr=r(I$t,"led"),I$t.forEach(t),Owr=r(Yqe," \u2014 "),eY=n(Yqe,"A",{href:!0});var q$t=s(eY);Vwr=r(q$t,"TFLEDForConditionalGeneration"),q$t.forEach(t),Xwr=r(Yqe," (LED model)"),Yqe.forEach(t),zwr=i(Ne),wC=n(Ne,"LI",{});var Kqe=s(wC);aMe=n(Kqe,"STRONG",{});var j$t=s(aMe);Qwr=r(j$t,"marian"),j$t.forEach(t),Wwr=r(Kqe," \u2014 "),oY=n(Kqe,"A",{href:!0});var D$t=s(oY);Hwr=r(D$t,"TFMarianMTModel"),D$t.forEach(t),Uwr=r(Kqe," (Marian model)"),Kqe.forEach(t),Jwr=i(Ne),AC=n(Ne,"LI",{});var Zqe=s(AC);nMe=n(Zqe,"STRONG",{});var G$t=s(nMe);Ywr=r(G$t,"mbart"),G$t.forEach(t),Kwr=r(Zqe," \u2014 "),rY=n(Zqe,"A",{href:!0});var O$t=s(rY);Zwr=r(O$t,"TFMBartForConditionalGeneration"),O$t.forEach(t),eAr=r(Zqe," (mBART model)"),Zqe.forEach(t),oAr=i(Ne),LC=n(Ne,"LI",{});var eje=s(LC);sMe=n(eje,"STRONG",{});var V$t=s(sMe);rAr=r(V$t,"mt5"),V$t.forEach(t),tAr=r(eje," \u2014 "),tY=n(eje,"A",{href:!0});var X$t=s(tY);aAr=r(X$t,"TFMT5ForConditionalGeneration"),X$t.forEach(t),nAr=r(eje," (MT5 model)"),eje.forEach(t),sAr=i(Ne),yC=n(Ne,"LI",{});var oje=s(yC);lMe=n(oje,"STRONG",{});var z$t=s(lMe);lAr=r(z$t,"pegasus"),z$t.forEach(t),iAr=r(oje," \u2014 "),aY=n(oje,"A",{href:!0});var Q$t=s(aY);dAr=r(Q$t,"TFPegasusForConditionalGeneration"),Q$t.forEach(t),cAr=r(oje," (Pegasus model)"),oje.forEach(t),fAr=i(Ne),xC=n(Ne,"LI",{});var rje=s(xC);iMe=n(rje,"STRONG",{});var W$t=s(iMe);mAr=r(W$t,"t5"),W$t.forEach(t),gAr=r(rje," \u2014 "),nY=n(rje,"A",{href:!0});var H$t=s(nY);hAr=r(H$t,"TFT5ForConditionalGeneration"),H$t.forEach(t),pAr=r(rje," (T5 model)"),rje.forEach(t),Ne.forEach(t),_Ar=i(Il),T($C.$$.fragment,Il),Il.forEach(t),Nl.forEach(t),aXe=i(f),Tc=n(f,"H2",{class:!0});var mQe=s(Tc);kC=n(mQe,"A",{id:!0,class:!0,href:!0});var U$t=s(kC);dMe=n(U$t,"SPAN",{});var J$t=s(dMe);T(ax.$$.fragment,J$t),J$t.forEach(t),U$t.forEach(t),uAr=i(mQe),cMe=n(mQe,"SPAN",{});var Y$t=s(cMe);bAr=r(Y$t,"TFAutoModelForSequenceClassification"),Y$t.forEach(t),mQe.forEach(t),nXe=i(f),lr=n(f,"DIV",{class:!0});var ql=s(lr);T(nx.$$.fragment,ql),vAr=i(ql),Mc=n(ql,"P",{});var rte=s(Mc);FAr=r(rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),sY=n(rte,"A",{href:!0});var K$t=s(sY);TAr=r(K$t,"from_pretrained()"),K$t.forEach(t),MAr=r(rte," class method or the "),lY=n(rte,"A",{href:!0});var Z$t=s(lY);EAr=r(Z$t,"from_config()"),Z$t.forEach(t),CAr=r(rte,` class
method.`),rte.forEach(t),wAr=i(ql),sx=n(ql,"P",{});var gQe=s(sx);AAr=r(gQe,"This class cannot be instantiated directly using "),fMe=n(gQe,"CODE",{});var ekt=s(fMe);LAr=r(ekt,"__init__()"),ekt.forEach(t),yAr=r(gQe," (throws an error)."),gQe.forEach(t),xAr=i(ql),It=n(ql,"DIV",{class:!0});var K6=s(It);T(lx.$$.fragment,K6),$Ar=i(K6),mMe=n(K6,"P",{});var okt=s(mMe);kAr=r(okt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),okt.forEach(t),SAr=i(K6),Ec=n(K6,"P",{});var tte=s(Ec);RAr=r(tte,`Note:
Loading a model from its configuration file does `),gMe=n(tte,"STRONG",{});var rkt=s(gMe);PAr=r(rkt,"not"),rkt.forEach(t),BAr=r(tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=n(tte,"A",{href:!0});var tkt=s(iY);NAr=r(tkt,"from_pretrained()"),tkt.forEach(t),IAr=r(tte," to load the model weights."),tte.forEach(t),qAr=i(K6),T(SC.$$.fragment,K6),K6.forEach(t),jAr=i(ql),Br=n(ql,"DIV",{class:!0});var jl=s(Br);T(ix.$$.fragment,jl),DAr=i(jl),hMe=n(jl,"P",{});var akt=s(hMe);GAr=r(akt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),akt.forEach(t),OAr=i(jl),gn=n(jl,"P",{});var Z6=s(gn);VAr=r(Z6,"The model class to instantiate is selected based on the "),pMe=n(Z6,"CODE",{});var nkt=s(pMe);XAr=r(nkt,"model_type"),nkt.forEach(t),zAr=r(Z6,` property of the config object (either
passed as an argument or loaded from `),_Me=n(Z6,"CODE",{});var skt=s(_Me);QAr=r(skt,"pretrained_model_name_or_path"),skt.forEach(t),WAr=r(Z6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uMe=n(Z6,"CODE",{});var lkt=s(uMe);HAr=r(lkt,"pretrained_model_name_or_path"),lkt.forEach(t),UAr=r(Z6,":"),Z6.forEach(t),JAr=i(jl),te=n(jl,"UL",{});var ne=s(te);RC=n(ne,"LI",{});var tje=s(RC);bMe=n(tje,"STRONG",{});var ikt=s(bMe);YAr=r(ikt,"albert"),ikt.forEach(t),KAr=r(tje," \u2014 "),dY=n(tje,"A",{href:!0});var dkt=s(dY);ZAr=r(dkt,"TFAlbertForSequenceClassification"),dkt.forEach(t),e6r=r(tje," (ALBERT model)"),tje.forEach(t),o6r=i(ne),PC=n(ne,"LI",{});var aje=s(PC);vMe=n(aje,"STRONG",{});var ckt=s(vMe);r6r=r(ckt,"bert"),ckt.forEach(t),t6r=r(aje," \u2014 "),cY=n(aje,"A",{href:!0});var fkt=s(cY);a6r=r(fkt,"TFBertForSequenceClassification"),fkt.forEach(t),n6r=r(aje," (BERT model)"),aje.forEach(t),s6r=i(ne),BC=n(ne,"LI",{});var nje=s(BC);FMe=n(nje,"STRONG",{});var mkt=s(FMe);l6r=r(mkt,"camembert"),mkt.forEach(t),i6r=r(nje," \u2014 "),fY=n(nje,"A",{href:!0});var gkt=s(fY);d6r=r(gkt,"TFCamembertForSequenceClassification"),gkt.forEach(t),c6r=r(nje," (CamemBERT model)"),nje.forEach(t),f6r=i(ne),NC=n(ne,"LI",{});var sje=s(NC);TMe=n(sje,"STRONG",{});var hkt=s(TMe);m6r=r(hkt,"convbert"),hkt.forEach(t),g6r=r(sje," \u2014 "),mY=n(sje,"A",{href:!0});var pkt=s(mY);h6r=r(pkt,"TFConvBertForSequenceClassification"),pkt.forEach(t),p6r=r(sje," (ConvBERT model)"),sje.forEach(t),_6r=i(ne),IC=n(ne,"LI",{});var lje=s(IC);MMe=n(lje,"STRONG",{});var _kt=s(MMe);u6r=r(_kt,"ctrl"),_kt.forEach(t),b6r=r(lje," \u2014 "),gY=n(lje,"A",{href:!0});var ukt=s(gY);v6r=r(ukt,"TFCTRLForSequenceClassification"),ukt.forEach(t),F6r=r(lje," (CTRL model)"),lje.forEach(t),T6r=i(ne),qC=n(ne,"LI",{});var ije=s(qC);EMe=n(ije,"STRONG",{});var bkt=s(EMe);M6r=r(bkt,"deberta"),bkt.forEach(t),E6r=r(ije," \u2014 "),hY=n(ije,"A",{href:!0});var vkt=s(hY);C6r=r(vkt,"TFDebertaForSequenceClassification"),vkt.forEach(t),w6r=r(ije," (DeBERTa model)"),ije.forEach(t),A6r=i(ne),jC=n(ne,"LI",{});var dje=s(jC);CMe=n(dje,"STRONG",{});var Fkt=s(CMe);L6r=r(Fkt,"deberta-v2"),Fkt.forEach(t),y6r=r(dje," \u2014 "),pY=n(dje,"A",{href:!0});var Tkt=s(pY);x6r=r(Tkt,"TFDebertaV2ForSequenceClassification"),Tkt.forEach(t),$6r=r(dje," (DeBERTa-v2 model)"),dje.forEach(t),k6r=i(ne),DC=n(ne,"LI",{});var cje=s(DC);wMe=n(cje,"STRONG",{});var Mkt=s(wMe);S6r=r(Mkt,"distilbert"),Mkt.forEach(t),R6r=r(cje," \u2014 "),_Y=n(cje,"A",{href:!0});var Ekt=s(_Y);P6r=r(Ekt,"TFDistilBertForSequenceClassification"),Ekt.forEach(t),B6r=r(cje," (DistilBERT model)"),cje.forEach(t),N6r=i(ne),GC=n(ne,"LI",{});var fje=s(GC);AMe=n(fje,"STRONG",{});var Ckt=s(AMe);I6r=r(Ckt,"electra"),Ckt.forEach(t),q6r=r(fje," \u2014 "),uY=n(fje,"A",{href:!0});var wkt=s(uY);j6r=r(wkt,"TFElectraForSequenceClassification"),wkt.forEach(t),D6r=r(fje," (ELECTRA model)"),fje.forEach(t),G6r=i(ne),OC=n(ne,"LI",{});var mje=s(OC);LMe=n(mje,"STRONG",{});var Akt=s(LMe);O6r=r(Akt,"flaubert"),Akt.forEach(t),V6r=r(mje," \u2014 "),bY=n(mje,"A",{href:!0});var Lkt=s(bY);X6r=r(Lkt,"TFFlaubertForSequenceClassification"),Lkt.forEach(t),z6r=r(mje," (FlauBERT model)"),mje.forEach(t),Q6r=i(ne),VC=n(ne,"LI",{});var gje=s(VC);yMe=n(gje,"STRONG",{});var ykt=s(yMe);W6r=r(ykt,"funnel"),ykt.forEach(t),H6r=r(gje," \u2014 "),vY=n(gje,"A",{href:!0});var xkt=s(vY);U6r=r(xkt,"TFFunnelForSequenceClassification"),xkt.forEach(t),J6r=r(gje," (Funnel Transformer model)"),gje.forEach(t),Y6r=i(ne),XC=n(ne,"LI",{});var hje=s(XC);xMe=n(hje,"STRONG",{});var $kt=s(xMe);K6r=r($kt,"gpt2"),$kt.forEach(t),Z6r=r(hje," \u2014 "),FY=n(hje,"A",{href:!0});var kkt=s(FY);eLr=r(kkt,"TFGPT2ForSequenceClassification"),kkt.forEach(t),oLr=r(hje," (OpenAI GPT-2 model)"),hje.forEach(t),rLr=i(ne),zC=n(ne,"LI",{});var pje=s(zC);$Me=n(pje,"STRONG",{});var Skt=s($Me);tLr=r(Skt,"gptj"),Skt.forEach(t),aLr=r(pje," \u2014 "),TY=n(pje,"A",{href:!0});var Rkt=s(TY);nLr=r(Rkt,"TFGPTJForSequenceClassification"),Rkt.forEach(t),sLr=r(pje," (GPT-J model)"),pje.forEach(t),lLr=i(ne),QC=n(ne,"LI",{});var _je=s(QC);kMe=n(_je,"STRONG",{});var Pkt=s(kMe);iLr=r(Pkt,"layoutlm"),Pkt.forEach(t),dLr=r(_je," \u2014 "),MY=n(_je,"A",{href:!0});var Bkt=s(MY);cLr=r(Bkt,"TFLayoutLMForSequenceClassification"),Bkt.forEach(t),fLr=r(_je," (LayoutLM model)"),_je.forEach(t),mLr=i(ne),WC=n(ne,"LI",{});var uje=s(WC);SMe=n(uje,"STRONG",{});var Nkt=s(SMe);gLr=r(Nkt,"longformer"),Nkt.forEach(t),hLr=r(uje," \u2014 "),EY=n(uje,"A",{href:!0});var Ikt=s(EY);pLr=r(Ikt,"TFLongformerForSequenceClassification"),Ikt.forEach(t),_Lr=r(uje," (Longformer model)"),uje.forEach(t),uLr=i(ne),HC=n(ne,"LI",{});var bje=s(HC);RMe=n(bje,"STRONG",{});var qkt=s(RMe);bLr=r(qkt,"mobilebert"),qkt.forEach(t),vLr=r(bje," \u2014 "),CY=n(bje,"A",{href:!0});var jkt=s(CY);FLr=r(jkt,"TFMobileBertForSequenceClassification"),jkt.forEach(t),TLr=r(bje," (MobileBERT model)"),bje.forEach(t),MLr=i(ne),UC=n(ne,"LI",{});var vje=s(UC);PMe=n(vje,"STRONG",{});var Dkt=s(PMe);ELr=r(Dkt,"mpnet"),Dkt.forEach(t),CLr=r(vje," \u2014 "),wY=n(vje,"A",{href:!0});var Gkt=s(wY);wLr=r(Gkt,"TFMPNetForSequenceClassification"),Gkt.forEach(t),ALr=r(vje," (MPNet model)"),vje.forEach(t),LLr=i(ne),JC=n(ne,"LI",{});var Fje=s(JC);BMe=n(Fje,"STRONG",{});var Okt=s(BMe);yLr=r(Okt,"openai-gpt"),Okt.forEach(t),xLr=r(Fje," \u2014 "),AY=n(Fje,"A",{href:!0});var Vkt=s(AY);$Lr=r(Vkt,"TFOpenAIGPTForSequenceClassification"),Vkt.forEach(t),kLr=r(Fje," (OpenAI GPT model)"),Fje.forEach(t),SLr=i(ne),YC=n(ne,"LI",{});var Tje=s(YC);NMe=n(Tje,"STRONG",{});var Xkt=s(NMe);RLr=r(Xkt,"rembert"),Xkt.forEach(t),PLr=r(Tje," \u2014 "),LY=n(Tje,"A",{href:!0});var zkt=s(LY);BLr=r(zkt,"TFRemBertForSequenceClassification"),zkt.forEach(t),NLr=r(Tje," (RemBERT model)"),Tje.forEach(t),ILr=i(ne),KC=n(ne,"LI",{});var Mje=s(KC);IMe=n(Mje,"STRONG",{});var Qkt=s(IMe);qLr=r(Qkt,"roberta"),Qkt.forEach(t),jLr=r(Mje," \u2014 "),yY=n(Mje,"A",{href:!0});var Wkt=s(yY);DLr=r(Wkt,"TFRobertaForSequenceClassification"),Wkt.forEach(t),GLr=r(Mje," (RoBERTa model)"),Mje.forEach(t),OLr=i(ne),ZC=n(ne,"LI",{});var Eje=s(ZC);qMe=n(Eje,"STRONG",{});var Hkt=s(qMe);VLr=r(Hkt,"roformer"),Hkt.forEach(t),XLr=r(Eje," \u2014 "),xY=n(Eje,"A",{href:!0});var Ukt=s(xY);zLr=r(Ukt,"TFRoFormerForSequenceClassification"),Ukt.forEach(t),QLr=r(Eje," (RoFormer model)"),Eje.forEach(t),WLr=i(ne),e3=n(ne,"LI",{});var Cje=s(e3);jMe=n(Cje,"STRONG",{});var Jkt=s(jMe);HLr=r(Jkt,"tapas"),Jkt.forEach(t),ULr=r(Cje," \u2014 "),$Y=n(Cje,"A",{href:!0});var Ykt=s($Y);JLr=r(Ykt,"TFTapasForSequenceClassification"),Ykt.forEach(t),YLr=r(Cje," (TAPAS model)"),Cje.forEach(t),KLr=i(ne),o3=n(ne,"LI",{});var wje=s(o3);DMe=n(wje,"STRONG",{});var Kkt=s(DMe);ZLr=r(Kkt,"transfo-xl"),Kkt.forEach(t),eyr=r(wje," \u2014 "),kY=n(wje,"A",{href:!0});var Zkt=s(kY);oyr=r(Zkt,"TFTransfoXLForSequenceClassification"),Zkt.forEach(t),ryr=r(wje," (Transformer-XL model)"),wje.forEach(t),tyr=i(ne),r3=n(ne,"LI",{});var Aje=s(r3);GMe=n(Aje,"STRONG",{});var eSt=s(GMe);ayr=r(eSt,"xlm"),eSt.forEach(t),nyr=r(Aje," \u2014 "),SY=n(Aje,"A",{href:!0});var oSt=s(SY);syr=r(oSt,"TFXLMForSequenceClassification"),oSt.forEach(t),lyr=r(Aje," (XLM model)"),Aje.forEach(t),iyr=i(ne),t3=n(ne,"LI",{});var Lje=s(t3);OMe=n(Lje,"STRONG",{});var rSt=s(OMe);dyr=r(rSt,"xlm-roberta"),rSt.forEach(t),cyr=r(Lje," \u2014 "),RY=n(Lje,"A",{href:!0});var tSt=s(RY);fyr=r(tSt,"TFXLMRobertaForSequenceClassification"),tSt.forEach(t),myr=r(Lje," (XLM-RoBERTa model)"),Lje.forEach(t),gyr=i(ne),a3=n(ne,"LI",{});var yje=s(a3);VMe=n(yje,"STRONG",{});var aSt=s(VMe);hyr=r(aSt,"xlnet"),aSt.forEach(t),pyr=r(yje," \u2014 "),PY=n(yje,"A",{href:!0});var nSt=s(PY);_yr=r(nSt,"TFXLNetForSequenceClassification"),nSt.forEach(t),uyr=r(yje," (XLNet model)"),yje.forEach(t),ne.forEach(t),byr=i(jl),T(n3.$$.fragment,jl),jl.forEach(t),ql.forEach(t),sXe=i(f),Cc=n(f,"H2",{class:!0});var hQe=s(Cc);s3=n(hQe,"A",{id:!0,class:!0,href:!0});var sSt=s(s3);XMe=n(sSt,"SPAN",{});var lSt=s(XMe);T(dx.$$.fragment,lSt),lSt.forEach(t),sSt.forEach(t),vyr=i(hQe),zMe=n(hQe,"SPAN",{});var iSt=s(zMe);Fyr=r(iSt,"TFAutoModelForMultipleChoice"),iSt.forEach(t),hQe.forEach(t),lXe=i(f),ir=n(f,"DIV",{class:!0});var Dl=s(ir);T(cx.$$.fragment,Dl),Tyr=i(Dl),wc=n(Dl,"P",{});var ate=s(wc);Myr=r(ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),BY=n(ate,"A",{href:!0});var dSt=s(BY);Eyr=r(dSt,"from_pretrained()"),dSt.forEach(t),Cyr=r(ate," class method or the "),NY=n(ate,"A",{href:!0});var cSt=s(NY);wyr=r(cSt,"from_config()"),cSt.forEach(t),Ayr=r(ate,` class
method.`),ate.forEach(t),Lyr=i(Dl),fx=n(Dl,"P",{});var pQe=s(fx);yyr=r(pQe,"This class cannot be instantiated directly using "),QMe=n(pQe,"CODE",{});var fSt=s(QMe);xyr=r(fSt,"__init__()"),fSt.forEach(t),$yr=r(pQe," (throws an error)."),pQe.forEach(t),kyr=i(Dl),qt=n(Dl,"DIV",{class:!0});var eL=s(qt);T(mx.$$.fragment,eL),Syr=i(eL),WMe=n(eL,"P",{});var mSt=s(WMe);Ryr=r(mSt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),mSt.forEach(t),Pyr=i(eL),Ac=n(eL,"P",{});var nte=s(Ac);Byr=r(nte,`Note:
Loading a model from its configuration file does `),HMe=n(nte,"STRONG",{});var gSt=s(HMe);Nyr=r(gSt,"not"),gSt.forEach(t),Iyr=r(nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(nte,"A",{href:!0});var hSt=s(IY);qyr=r(hSt,"from_pretrained()"),hSt.forEach(t),jyr=r(nte," to load the model weights."),nte.forEach(t),Dyr=i(eL),T(l3.$$.fragment,eL),eL.forEach(t),Gyr=i(Dl),Nr=n(Dl,"DIV",{class:!0});var Gl=s(Nr);T(gx.$$.fragment,Gl),Oyr=i(Gl),UMe=n(Gl,"P",{});var pSt=s(UMe);Vyr=r(pSt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),pSt.forEach(t),Xyr=i(Gl),hn=n(Gl,"P",{});var oL=s(hn);zyr=r(oL,"The model class to instantiate is selected based on the "),JMe=n(oL,"CODE",{});var _St=s(JMe);Qyr=r(_St,"model_type"),_St.forEach(t),Wyr=r(oL,` property of the config object (either
passed as an argument or loaded from `),YMe=n(oL,"CODE",{});var uSt=s(YMe);Hyr=r(uSt,"pretrained_model_name_or_path"),uSt.forEach(t),Uyr=r(oL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KMe=n(oL,"CODE",{});var bSt=s(KMe);Jyr=r(bSt,"pretrained_model_name_or_path"),bSt.forEach(t),Yyr=r(oL,":"),oL.forEach(t),Kyr=i(Gl),_e=n(Gl,"UL",{});var ve=s(_e);i3=n(ve,"LI",{});var xje=s(i3);ZMe=n(xje,"STRONG",{});var vSt=s(ZMe);Zyr=r(vSt,"albert"),vSt.forEach(t),e8r=r(xje," \u2014 "),qY=n(xje,"A",{href:!0});var FSt=s(qY);o8r=r(FSt,"TFAlbertForMultipleChoice"),FSt.forEach(t),r8r=r(xje," (ALBERT model)"),xje.forEach(t),t8r=i(ve),d3=n(ve,"LI",{});var $je=s(d3);eEe=n($je,"STRONG",{});var TSt=s(eEe);a8r=r(TSt,"bert"),TSt.forEach(t),n8r=r($je," \u2014 "),jY=n($je,"A",{href:!0});var MSt=s(jY);s8r=r(MSt,"TFBertForMultipleChoice"),MSt.forEach(t),l8r=r($je," (BERT model)"),$je.forEach(t),i8r=i(ve),c3=n(ve,"LI",{});var kje=s(c3);oEe=n(kje,"STRONG",{});var ESt=s(oEe);d8r=r(ESt,"camembert"),ESt.forEach(t),c8r=r(kje," \u2014 "),DY=n(kje,"A",{href:!0});var CSt=s(DY);f8r=r(CSt,"TFCamembertForMultipleChoice"),CSt.forEach(t),m8r=r(kje," (CamemBERT model)"),kje.forEach(t),g8r=i(ve),f3=n(ve,"LI",{});var Sje=s(f3);rEe=n(Sje,"STRONG",{});var wSt=s(rEe);h8r=r(wSt,"convbert"),wSt.forEach(t),p8r=r(Sje," \u2014 "),GY=n(Sje,"A",{href:!0});var ASt=s(GY);_8r=r(ASt,"TFConvBertForMultipleChoice"),ASt.forEach(t),u8r=r(Sje," (ConvBERT model)"),Sje.forEach(t),b8r=i(ve),m3=n(ve,"LI",{});var Rje=s(m3);tEe=n(Rje,"STRONG",{});var LSt=s(tEe);v8r=r(LSt,"distilbert"),LSt.forEach(t),F8r=r(Rje," \u2014 "),OY=n(Rje,"A",{href:!0});var ySt=s(OY);T8r=r(ySt,"TFDistilBertForMultipleChoice"),ySt.forEach(t),M8r=r(Rje," (DistilBERT model)"),Rje.forEach(t),E8r=i(ve),g3=n(ve,"LI",{});var Pje=s(g3);aEe=n(Pje,"STRONG",{});var xSt=s(aEe);C8r=r(xSt,"electra"),xSt.forEach(t),w8r=r(Pje," \u2014 "),VY=n(Pje,"A",{href:!0});var $St=s(VY);A8r=r($St,"TFElectraForMultipleChoice"),$St.forEach(t),L8r=r(Pje," (ELECTRA model)"),Pje.forEach(t),y8r=i(ve),h3=n(ve,"LI",{});var Bje=s(h3);nEe=n(Bje,"STRONG",{});var kSt=s(nEe);x8r=r(kSt,"flaubert"),kSt.forEach(t),$8r=r(Bje," \u2014 "),XY=n(Bje,"A",{href:!0});var SSt=s(XY);k8r=r(SSt,"TFFlaubertForMultipleChoice"),SSt.forEach(t),S8r=r(Bje," (FlauBERT model)"),Bje.forEach(t),R8r=i(ve),p3=n(ve,"LI",{});var Nje=s(p3);sEe=n(Nje,"STRONG",{});var RSt=s(sEe);P8r=r(RSt,"funnel"),RSt.forEach(t),B8r=r(Nje," \u2014 "),zY=n(Nje,"A",{href:!0});var PSt=s(zY);N8r=r(PSt,"TFFunnelForMultipleChoice"),PSt.forEach(t),I8r=r(Nje," (Funnel Transformer model)"),Nje.forEach(t),q8r=i(ve),_3=n(ve,"LI",{});var Ije=s(_3);lEe=n(Ije,"STRONG",{});var BSt=s(lEe);j8r=r(BSt,"longformer"),BSt.forEach(t),D8r=r(Ije," \u2014 "),QY=n(Ije,"A",{href:!0});var NSt=s(QY);G8r=r(NSt,"TFLongformerForMultipleChoice"),NSt.forEach(t),O8r=r(Ije," (Longformer model)"),Ije.forEach(t),V8r=i(ve),u3=n(ve,"LI",{});var qje=s(u3);iEe=n(qje,"STRONG",{});var ISt=s(iEe);X8r=r(ISt,"mobilebert"),ISt.forEach(t),z8r=r(qje," \u2014 "),WY=n(qje,"A",{href:!0});var qSt=s(WY);Q8r=r(qSt,"TFMobileBertForMultipleChoice"),qSt.forEach(t),W8r=r(qje," (MobileBERT model)"),qje.forEach(t),H8r=i(ve),b3=n(ve,"LI",{});var jje=s(b3);dEe=n(jje,"STRONG",{});var jSt=s(dEe);U8r=r(jSt,"mpnet"),jSt.forEach(t),J8r=r(jje," \u2014 "),HY=n(jje,"A",{href:!0});var DSt=s(HY);Y8r=r(DSt,"TFMPNetForMultipleChoice"),DSt.forEach(t),K8r=r(jje," (MPNet model)"),jje.forEach(t),Z8r=i(ve),v3=n(ve,"LI",{});var Dje=s(v3);cEe=n(Dje,"STRONG",{});var GSt=s(cEe);e9r=r(GSt,"rembert"),GSt.forEach(t),o9r=r(Dje," \u2014 "),UY=n(Dje,"A",{href:!0});var OSt=s(UY);r9r=r(OSt,"TFRemBertForMultipleChoice"),OSt.forEach(t),t9r=r(Dje," (RemBERT model)"),Dje.forEach(t),a9r=i(ve),F3=n(ve,"LI",{});var Gje=s(F3);fEe=n(Gje,"STRONG",{});var VSt=s(fEe);n9r=r(VSt,"roberta"),VSt.forEach(t),s9r=r(Gje," \u2014 "),JY=n(Gje,"A",{href:!0});var XSt=s(JY);l9r=r(XSt,"TFRobertaForMultipleChoice"),XSt.forEach(t),i9r=r(Gje," (RoBERTa model)"),Gje.forEach(t),d9r=i(ve),T3=n(ve,"LI",{});var Oje=s(T3);mEe=n(Oje,"STRONG",{});var zSt=s(mEe);c9r=r(zSt,"roformer"),zSt.forEach(t),f9r=r(Oje," \u2014 "),YY=n(Oje,"A",{href:!0});var QSt=s(YY);m9r=r(QSt,"TFRoFormerForMultipleChoice"),QSt.forEach(t),g9r=r(Oje," (RoFormer model)"),Oje.forEach(t),h9r=i(ve),M3=n(ve,"LI",{});var Vje=s(M3);gEe=n(Vje,"STRONG",{});var WSt=s(gEe);p9r=r(WSt,"xlm"),WSt.forEach(t),_9r=r(Vje," \u2014 "),KY=n(Vje,"A",{href:!0});var HSt=s(KY);u9r=r(HSt,"TFXLMForMultipleChoice"),HSt.forEach(t),b9r=r(Vje," (XLM model)"),Vje.forEach(t),v9r=i(ve),E3=n(ve,"LI",{});var Xje=s(E3);hEe=n(Xje,"STRONG",{});var USt=s(hEe);F9r=r(USt,"xlm-roberta"),USt.forEach(t),T9r=r(Xje," \u2014 "),ZY=n(Xje,"A",{href:!0});var JSt=s(ZY);M9r=r(JSt,"TFXLMRobertaForMultipleChoice"),JSt.forEach(t),E9r=r(Xje," (XLM-RoBERTa model)"),Xje.forEach(t),C9r=i(ve),C3=n(ve,"LI",{});var zje=s(C3);pEe=n(zje,"STRONG",{});var YSt=s(pEe);w9r=r(YSt,"xlnet"),YSt.forEach(t),A9r=r(zje," \u2014 "),eK=n(zje,"A",{href:!0});var KSt=s(eK);L9r=r(KSt,"TFXLNetForMultipleChoice"),KSt.forEach(t),y9r=r(zje," (XLNet model)"),zje.forEach(t),ve.forEach(t),x9r=i(Gl),T(w3.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),iXe=i(f),Lc=n(f,"H2",{class:!0});var _Qe=s(Lc);A3=n(_Qe,"A",{id:!0,class:!0,href:!0});var ZSt=s(A3);_Ee=n(ZSt,"SPAN",{});var eRt=s(_Ee);T(hx.$$.fragment,eRt),eRt.forEach(t),ZSt.forEach(t),$9r=i(_Qe),uEe=n(_Qe,"SPAN",{});var oRt=s(uEe);k9r=r(oRt,"TFAutoModelForNextSentencePrediction"),oRt.forEach(t),_Qe.forEach(t),dXe=i(f),dr=n(f,"DIV",{class:!0});var Ol=s(dr);T(px.$$.fragment,Ol),S9r=i(Ol),yc=n(Ol,"P",{});var ste=s(yc);R9r=r(ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),oK=n(ste,"A",{href:!0});var rRt=s(oK);P9r=r(rRt,"from_pretrained()"),rRt.forEach(t),B9r=r(ste," class method or the "),rK=n(ste,"A",{href:!0});var tRt=s(rK);N9r=r(tRt,"from_config()"),tRt.forEach(t),I9r=r(ste,` class
method.`),ste.forEach(t),q9r=i(Ol),_x=n(Ol,"P",{});var uQe=s(_x);j9r=r(uQe,"This class cannot be instantiated directly using "),bEe=n(uQe,"CODE",{});var aRt=s(bEe);D9r=r(aRt,"__init__()"),aRt.forEach(t),G9r=r(uQe," (throws an error)."),uQe.forEach(t),O9r=i(Ol),jt=n(Ol,"DIV",{class:!0});var rL=s(jt);T(ux.$$.fragment,rL),V9r=i(rL),vEe=n(rL,"P",{});var nRt=s(vEe);X9r=r(nRt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),nRt.forEach(t),z9r=i(rL),xc=n(rL,"P",{});var lte=s(xc);Q9r=r(lte,`Note:
Loading a model from its configuration file does `),FEe=n(lte,"STRONG",{});var sRt=s(FEe);W9r=r(sRt,"not"),sRt.forEach(t),H9r=r(lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=n(lte,"A",{href:!0});var lRt=s(tK);U9r=r(lRt,"from_pretrained()"),lRt.forEach(t),J9r=r(lte," to load the model weights."),lte.forEach(t),Y9r=i(rL),T(L3.$$.fragment,rL),rL.forEach(t),K9r=i(Ol),Ir=n(Ol,"DIV",{class:!0});var Vl=s(Ir);T(bx.$$.fragment,Vl),Z9r=i(Vl),TEe=n(Vl,"P",{});var iRt=s(TEe);exr=r(iRt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),iRt.forEach(t),oxr=i(Vl),pn=n(Vl,"P",{});var tL=s(pn);rxr=r(tL,"The model class to instantiate is selected based on the "),MEe=n(tL,"CODE",{});var dRt=s(MEe);txr=r(dRt,"model_type"),dRt.forEach(t),axr=r(tL,` property of the config object (either
passed as an argument or loaded from `),EEe=n(tL,"CODE",{});var cRt=s(EEe);nxr=r(cRt,"pretrained_model_name_or_path"),cRt.forEach(t),sxr=r(tL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CEe=n(tL,"CODE",{});var fRt=s(CEe);lxr=r(fRt,"pretrained_model_name_or_path"),fRt.forEach(t),ixr=r(tL,":"),tL.forEach(t),dxr=i(Vl),vx=n(Vl,"UL",{});var bQe=s(vx);y3=n(bQe,"LI",{});var Qje=s(y3);wEe=n(Qje,"STRONG",{});var mRt=s(wEe);cxr=r(mRt,"bert"),mRt.forEach(t),fxr=r(Qje," \u2014 "),aK=n(Qje,"A",{href:!0});var gRt=s(aK);mxr=r(gRt,"TFBertForNextSentencePrediction"),gRt.forEach(t),gxr=r(Qje," (BERT model)"),Qje.forEach(t),hxr=i(bQe),x3=n(bQe,"LI",{});var Wje=s(x3);AEe=n(Wje,"STRONG",{});var hRt=s(AEe);pxr=r(hRt,"mobilebert"),hRt.forEach(t),_xr=r(Wje," \u2014 "),nK=n(Wje,"A",{href:!0});var pRt=s(nK);uxr=r(pRt,"TFMobileBertForNextSentencePrediction"),pRt.forEach(t),bxr=r(Wje," (MobileBERT model)"),Wje.forEach(t),bQe.forEach(t),vxr=i(Vl),T($3.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),cXe=i(f),$c=n(f,"H2",{class:!0});var vQe=s($c);k3=n(vQe,"A",{id:!0,class:!0,href:!0});var _Rt=s(k3);LEe=n(_Rt,"SPAN",{});var uRt=s(LEe);T(Fx.$$.fragment,uRt),uRt.forEach(t),_Rt.forEach(t),Fxr=i(vQe),yEe=n(vQe,"SPAN",{});var bRt=s(yEe);Txr=r(bRt,"TFAutoModelForTableQuestionAnswering"),bRt.forEach(t),vQe.forEach(t),fXe=i(f),cr=n(f,"DIV",{class:!0});var Xl=s(cr);T(Tx.$$.fragment,Xl),Mxr=i(Xl),kc=n(Xl,"P",{});var ite=s(kc);Exr=r(ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),sK=n(ite,"A",{href:!0});var vRt=s(sK);Cxr=r(vRt,"from_pretrained()"),vRt.forEach(t),wxr=r(ite," class method or the "),lK=n(ite,"A",{href:!0});var FRt=s(lK);Axr=r(FRt,"from_config()"),FRt.forEach(t),Lxr=r(ite,` class
method.`),ite.forEach(t),yxr=i(Xl),Mx=n(Xl,"P",{});var FQe=s(Mx);xxr=r(FQe,"This class cannot be instantiated directly using "),xEe=n(FQe,"CODE",{});var TRt=s(xEe);$xr=r(TRt,"__init__()"),TRt.forEach(t),kxr=r(FQe," (throws an error)."),FQe.forEach(t),Sxr=i(Xl),Dt=n(Xl,"DIV",{class:!0});var aL=s(Dt);T(Ex.$$.fragment,aL),Rxr=i(aL),$Ee=n(aL,"P",{});var MRt=s($Ee);Pxr=r(MRt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),MRt.forEach(t),Bxr=i(aL),Sc=n(aL,"P",{});var dte=s(Sc);Nxr=r(dte,`Note:
Loading a model from its configuration file does `),kEe=n(dte,"STRONG",{});var ERt=s(kEe);Ixr=r(ERt,"not"),ERt.forEach(t),qxr=r(dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),iK=n(dte,"A",{href:!0});var CRt=s(iK);jxr=r(CRt,"from_pretrained()"),CRt.forEach(t),Dxr=r(dte," to load the model weights."),dte.forEach(t),Gxr=i(aL),T(S3.$$.fragment,aL),aL.forEach(t),Oxr=i(Xl),qr=n(Xl,"DIV",{class:!0});var zl=s(qr);T(Cx.$$.fragment,zl),Vxr=i(zl),SEe=n(zl,"P",{});var wRt=s(SEe);Xxr=r(wRt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),wRt.forEach(t),zxr=i(zl),_n=n(zl,"P",{});var nL=s(_n);Qxr=r(nL,"The model class to instantiate is selected based on the "),REe=n(nL,"CODE",{});var ARt=s(REe);Wxr=r(ARt,"model_type"),ARt.forEach(t),Hxr=r(nL,` property of the config object (either
passed as an argument or loaded from `),PEe=n(nL,"CODE",{});var LRt=s(PEe);Uxr=r(LRt,"pretrained_model_name_or_path"),LRt.forEach(t),Jxr=r(nL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BEe=n(nL,"CODE",{});var yRt=s(BEe);Yxr=r(yRt,"pretrained_model_name_or_path"),yRt.forEach(t),Kxr=r(nL,":"),nL.forEach(t),Zxr=i(zl),NEe=n(zl,"UL",{});var xRt=s(NEe);R3=n(xRt,"LI",{});var Hje=s(R3);IEe=n(Hje,"STRONG",{});var $Rt=s(IEe);e$r=r($Rt,"tapas"),$Rt.forEach(t),o$r=r(Hje," \u2014 "),dK=n(Hje,"A",{href:!0});var kRt=s(dK);r$r=r(kRt,"TFTapasForQuestionAnswering"),kRt.forEach(t),t$r=r(Hje," (TAPAS model)"),Hje.forEach(t),xRt.forEach(t),a$r=i(zl),T(P3.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),mXe=i(f),Rc=n(f,"H2",{class:!0});var TQe=s(Rc);B3=n(TQe,"A",{id:!0,class:!0,href:!0});var SRt=s(B3);qEe=n(SRt,"SPAN",{});var RRt=s(qEe);T(wx.$$.fragment,RRt),RRt.forEach(t),SRt.forEach(t),n$r=i(TQe),jEe=n(TQe,"SPAN",{});var PRt=s(jEe);s$r=r(PRt,"TFAutoModelForTokenClassification"),PRt.forEach(t),TQe.forEach(t),gXe=i(f),fr=n(f,"DIV",{class:!0});var Ql=s(fr);T(Ax.$$.fragment,Ql),l$r=i(Ql),Pc=n(Ql,"P",{});var cte=s(Pc);i$r=r(cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),cK=n(cte,"A",{href:!0});var BRt=s(cK);d$r=r(BRt,"from_pretrained()"),BRt.forEach(t),c$r=r(cte," class method or the "),fK=n(cte,"A",{href:!0});var NRt=s(fK);f$r=r(NRt,"from_config()"),NRt.forEach(t),m$r=r(cte,` class
method.`),cte.forEach(t),g$r=i(Ql),Lx=n(Ql,"P",{});var MQe=s(Lx);h$r=r(MQe,"This class cannot be instantiated directly using "),DEe=n(MQe,"CODE",{});var IRt=s(DEe);p$r=r(IRt,"__init__()"),IRt.forEach(t),_$r=r(MQe," (throws an error)."),MQe.forEach(t),u$r=i(Ql),Gt=n(Ql,"DIV",{class:!0});var sL=s(Gt);T(yx.$$.fragment,sL),b$r=i(sL),GEe=n(sL,"P",{});var qRt=s(GEe);v$r=r(qRt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),qRt.forEach(t),F$r=i(sL),Bc=n(sL,"P",{});var fte=s(Bc);T$r=r(fte,`Note:
Loading a model from its configuration file does `),OEe=n(fte,"STRONG",{});var jRt=s(OEe);M$r=r(jRt,"not"),jRt.forEach(t),E$r=r(fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),mK=n(fte,"A",{href:!0});var DRt=s(mK);C$r=r(DRt,"from_pretrained()"),DRt.forEach(t),w$r=r(fte," to load the model weights."),fte.forEach(t),A$r=i(sL),T(N3.$$.fragment,sL),sL.forEach(t),L$r=i(Ql),jr=n(Ql,"DIV",{class:!0});var Wl=s(jr);T(xx.$$.fragment,Wl),y$r=i(Wl),VEe=n(Wl,"P",{});var GRt=s(VEe);x$r=r(GRt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),GRt.forEach(t),$$r=i(Wl),un=n(Wl,"P",{});var lL=s(un);k$r=r(lL,"The model class to instantiate is selected based on the "),XEe=n(lL,"CODE",{});var ORt=s(XEe);S$r=r(ORt,"model_type"),ORt.forEach(t),R$r=r(lL,` property of the config object (either
passed as an argument or loaded from `),zEe=n(lL,"CODE",{});var VRt=s(zEe);P$r=r(VRt,"pretrained_model_name_or_path"),VRt.forEach(t),B$r=r(lL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=n(lL,"CODE",{});var XRt=s(QEe);N$r=r(XRt,"pretrained_model_name_or_path"),XRt.forEach(t),I$r=r(lL,":"),lL.forEach(t),q$r=i(Wl),de=n(Wl,"UL",{});var me=s(de);I3=n(me,"LI",{});var Uje=s(I3);WEe=n(Uje,"STRONG",{});var zRt=s(WEe);j$r=r(zRt,"albert"),zRt.forEach(t),D$r=r(Uje," \u2014 "),gK=n(Uje,"A",{href:!0});var QRt=s(gK);G$r=r(QRt,"TFAlbertForTokenClassification"),QRt.forEach(t),O$r=r(Uje," (ALBERT model)"),Uje.forEach(t),V$r=i(me),q3=n(me,"LI",{});var Jje=s(q3);HEe=n(Jje,"STRONG",{});var WRt=s(HEe);X$r=r(WRt,"bert"),WRt.forEach(t),z$r=r(Jje," \u2014 "),hK=n(Jje,"A",{href:!0});var HRt=s(hK);Q$r=r(HRt,"TFBertForTokenClassification"),HRt.forEach(t),W$r=r(Jje," (BERT model)"),Jje.forEach(t),H$r=i(me),j3=n(me,"LI",{});var Yje=s(j3);UEe=n(Yje,"STRONG",{});var URt=s(UEe);U$r=r(URt,"camembert"),URt.forEach(t),J$r=r(Yje," \u2014 "),pK=n(Yje,"A",{href:!0});var JRt=s(pK);Y$r=r(JRt,"TFCamembertForTokenClassification"),JRt.forEach(t),K$r=r(Yje," (CamemBERT model)"),Yje.forEach(t),Z$r=i(me),D3=n(me,"LI",{});var Kje=s(D3);JEe=n(Kje,"STRONG",{});var YRt=s(JEe);ekr=r(YRt,"convbert"),YRt.forEach(t),okr=r(Kje," \u2014 "),_K=n(Kje,"A",{href:!0});var KRt=s(_K);rkr=r(KRt,"TFConvBertForTokenClassification"),KRt.forEach(t),tkr=r(Kje," (ConvBERT model)"),Kje.forEach(t),akr=i(me),G3=n(me,"LI",{});var Zje=s(G3);YEe=n(Zje,"STRONG",{});var ZRt=s(YEe);nkr=r(ZRt,"deberta"),ZRt.forEach(t),skr=r(Zje," \u2014 "),uK=n(Zje,"A",{href:!0});var ePt=s(uK);lkr=r(ePt,"TFDebertaForTokenClassification"),ePt.forEach(t),ikr=r(Zje," (DeBERTa model)"),Zje.forEach(t),dkr=i(me),O3=n(me,"LI",{});var eDe=s(O3);KEe=n(eDe,"STRONG",{});var oPt=s(KEe);ckr=r(oPt,"deberta-v2"),oPt.forEach(t),fkr=r(eDe," \u2014 "),bK=n(eDe,"A",{href:!0});var rPt=s(bK);mkr=r(rPt,"TFDebertaV2ForTokenClassification"),rPt.forEach(t),gkr=r(eDe," (DeBERTa-v2 model)"),eDe.forEach(t),hkr=i(me),V3=n(me,"LI",{});var oDe=s(V3);ZEe=n(oDe,"STRONG",{});var tPt=s(ZEe);pkr=r(tPt,"distilbert"),tPt.forEach(t),_kr=r(oDe," \u2014 "),vK=n(oDe,"A",{href:!0});var aPt=s(vK);ukr=r(aPt,"TFDistilBertForTokenClassification"),aPt.forEach(t),bkr=r(oDe," (DistilBERT model)"),oDe.forEach(t),vkr=i(me),X3=n(me,"LI",{});var rDe=s(X3);eCe=n(rDe,"STRONG",{});var nPt=s(eCe);Fkr=r(nPt,"electra"),nPt.forEach(t),Tkr=r(rDe," \u2014 "),FK=n(rDe,"A",{href:!0});var sPt=s(FK);Mkr=r(sPt,"TFElectraForTokenClassification"),sPt.forEach(t),Ekr=r(rDe," (ELECTRA model)"),rDe.forEach(t),Ckr=i(me),z3=n(me,"LI",{});var tDe=s(z3);oCe=n(tDe,"STRONG",{});var lPt=s(oCe);wkr=r(lPt,"flaubert"),lPt.forEach(t),Akr=r(tDe," \u2014 "),TK=n(tDe,"A",{href:!0});var iPt=s(TK);Lkr=r(iPt,"TFFlaubertForTokenClassification"),iPt.forEach(t),ykr=r(tDe," (FlauBERT model)"),tDe.forEach(t),xkr=i(me),Q3=n(me,"LI",{});var aDe=s(Q3);rCe=n(aDe,"STRONG",{});var dPt=s(rCe);$kr=r(dPt,"funnel"),dPt.forEach(t),kkr=r(aDe," \u2014 "),MK=n(aDe,"A",{href:!0});var cPt=s(MK);Skr=r(cPt,"TFFunnelForTokenClassification"),cPt.forEach(t),Rkr=r(aDe," (Funnel Transformer model)"),aDe.forEach(t),Pkr=i(me),W3=n(me,"LI",{});var nDe=s(W3);tCe=n(nDe,"STRONG",{});var fPt=s(tCe);Bkr=r(fPt,"layoutlm"),fPt.forEach(t),Nkr=r(nDe," \u2014 "),EK=n(nDe,"A",{href:!0});var mPt=s(EK);Ikr=r(mPt,"TFLayoutLMForTokenClassification"),mPt.forEach(t),qkr=r(nDe," (LayoutLM model)"),nDe.forEach(t),jkr=i(me),H3=n(me,"LI",{});var sDe=s(H3);aCe=n(sDe,"STRONG",{});var gPt=s(aCe);Dkr=r(gPt,"longformer"),gPt.forEach(t),Gkr=r(sDe," \u2014 "),CK=n(sDe,"A",{href:!0});var hPt=s(CK);Okr=r(hPt,"TFLongformerForTokenClassification"),hPt.forEach(t),Vkr=r(sDe," (Longformer model)"),sDe.forEach(t),Xkr=i(me),U3=n(me,"LI",{});var lDe=s(U3);nCe=n(lDe,"STRONG",{});var pPt=s(nCe);zkr=r(pPt,"mobilebert"),pPt.forEach(t),Qkr=r(lDe," \u2014 "),wK=n(lDe,"A",{href:!0});var _Pt=s(wK);Wkr=r(_Pt,"TFMobileBertForTokenClassification"),_Pt.forEach(t),Hkr=r(lDe," (MobileBERT model)"),lDe.forEach(t),Ukr=i(me),J3=n(me,"LI",{});var iDe=s(J3);sCe=n(iDe,"STRONG",{});var uPt=s(sCe);Jkr=r(uPt,"mpnet"),uPt.forEach(t),Ykr=r(iDe," \u2014 "),AK=n(iDe,"A",{href:!0});var bPt=s(AK);Kkr=r(bPt,"TFMPNetForTokenClassification"),bPt.forEach(t),Zkr=r(iDe," (MPNet model)"),iDe.forEach(t),eSr=i(me),Y3=n(me,"LI",{});var dDe=s(Y3);lCe=n(dDe,"STRONG",{});var vPt=s(lCe);oSr=r(vPt,"rembert"),vPt.forEach(t),rSr=r(dDe," \u2014 "),LK=n(dDe,"A",{href:!0});var FPt=s(LK);tSr=r(FPt,"TFRemBertForTokenClassification"),FPt.forEach(t),aSr=r(dDe," (RemBERT model)"),dDe.forEach(t),nSr=i(me),K3=n(me,"LI",{});var cDe=s(K3);iCe=n(cDe,"STRONG",{});var TPt=s(iCe);sSr=r(TPt,"roberta"),TPt.forEach(t),lSr=r(cDe," \u2014 "),yK=n(cDe,"A",{href:!0});var MPt=s(yK);iSr=r(MPt,"TFRobertaForTokenClassification"),MPt.forEach(t),dSr=r(cDe," (RoBERTa model)"),cDe.forEach(t),cSr=i(me),Z3=n(me,"LI",{});var fDe=s(Z3);dCe=n(fDe,"STRONG",{});var EPt=s(dCe);fSr=r(EPt,"roformer"),EPt.forEach(t),mSr=r(fDe," \u2014 "),xK=n(fDe,"A",{href:!0});var CPt=s(xK);gSr=r(CPt,"TFRoFormerForTokenClassification"),CPt.forEach(t),hSr=r(fDe," (RoFormer model)"),fDe.forEach(t),pSr=i(me),e5=n(me,"LI",{});var mDe=s(e5);cCe=n(mDe,"STRONG",{});var wPt=s(cCe);_Sr=r(wPt,"xlm"),wPt.forEach(t),uSr=r(mDe," \u2014 "),$K=n(mDe,"A",{href:!0});var APt=s($K);bSr=r(APt,"TFXLMForTokenClassification"),APt.forEach(t),vSr=r(mDe," (XLM model)"),mDe.forEach(t),FSr=i(me),o5=n(me,"LI",{});var gDe=s(o5);fCe=n(gDe,"STRONG",{});var LPt=s(fCe);TSr=r(LPt,"xlm-roberta"),LPt.forEach(t),MSr=r(gDe," \u2014 "),kK=n(gDe,"A",{href:!0});var yPt=s(kK);ESr=r(yPt,"TFXLMRobertaForTokenClassification"),yPt.forEach(t),CSr=r(gDe," (XLM-RoBERTa model)"),gDe.forEach(t),wSr=i(me),r5=n(me,"LI",{});var hDe=s(r5);mCe=n(hDe,"STRONG",{});var xPt=s(mCe);ASr=r(xPt,"xlnet"),xPt.forEach(t),LSr=r(hDe," \u2014 "),SK=n(hDe,"A",{href:!0});var $Pt=s(SK);ySr=r($Pt,"TFXLNetForTokenClassification"),$Pt.forEach(t),xSr=r(hDe," (XLNet model)"),hDe.forEach(t),me.forEach(t),$Sr=i(Wl),T(t5.$$.fragment,Wl),Wl.forEach(t),Ql.forEach(t),hXe=i(f),Nc=n(f,"H2",{class:!0});var EQe=s(Nc);a5=n(EQe,"A",{id:!0,class:!0,href:!0});var kPt=s(a5);gCe=n(kPt,"SPAN",{});var SPt=s(gCe);T($x.$$.fragment,SPt),SPt.forEach(t),kPt.forEach(t),kSr=i(EQe),hCe=n(EQe,"SPAN",{});var RPt=s(hCe);SSr=r(RPt,"TFAutoModelForQuestionAnswering"),RPt.forEach(t),EQe.forEach(t),pXe=i(f),mr=n(f,"DIV",{class:!0});var Hl=s(mr);T(kx.$$.fragment,Hl),RSr=i(Hl),Ic=n(Hl,"P",{});var mte=s(Ic);PSr=r(mte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),RK=n(mte,"A",{href:!0});var PPt=s(RK);BSr=r(PPt,"from_pretrained()"),PPt.forEach(t),NSr=r(mte," class method or the "),PK=n(mte,"A",{href:!0});var BPt=s(PK);ISr=r(BPt,"from_config()"),BPt.forEach(t),qSr=r(mte,` class
method.`),mte.forEach(t),jSr=i(Hl),Sx=n(Hl,"P",{});var CQe=s(Sx);DSr=r(CQe,"This class cannot be instantiated directly using "),pCe=n(CQe,"CODE",{});var NPt=s(pCe);GSr=r(NPt,"__init__()"),NPt.forEach(t),OSr=r(CQe," (throws an error)."),CQe.forEach(t),VSr=i(Hl),Ot=n(Hl,"DIV",{class:!0});var iL=s(Ot);T(Rx.$$.fragment,iL),XSr=i(iL),_Ce=n(iL,"P",{});var IPt=s(_Ce);zSr=r(IPt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),IPt.forEach(t),QSr=i(iL),qc=n(iL,"P",{});var gte=s(qc);WSr=r(gte,`Note:
Loading a model from its configuration file does `),uCe=n(gte,"STRONG",{});var qPt=s(uCe);HSr=r(qPt,"not"),qPt.forEach(t),USr=r(gte,` load the model weights. It only affects the
model\u2019s configuration. Use `),BK=n(gte,"A",{href:!0});var jPt=s(BK);JSr=r(jPt,"from_pretrained()"),jPt.forEach(t),YSr=r(gte," to load the model weights."),gte.forEach(t),KSr=i(iL),T(n5.$$.fragment,iL),iL.forEach(t),ZSr=i(Hl),Dr=n(Hl,"DIV",{class:!0});var Ul=s(Dr);T(Px.$$.fragment,Ul),eRr=i(Ul),bCe=n(Ul,"P",{});var DPt=s(bCe);oRr=r(DPt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),DPt.forEach(t),rRr=i(Ul),bn=n(Ul,"P",{});var dL=s(bn);tRr=r(dL,"The model class to instantiate is selected based on the "),vCe=n(dL,"CODE",{});var GPt=s(vCe);aRr=r(GPt,"model_type"),GPt.forEach(t),nRr=r(dL,` property of the config object (either
passed as an argument or loaded from `),FCe=n(dL,"CODE",{});var OPt=s(FCe);sRr=r(OPt,"pretrained_model_name_or_path"),OPt.forEach(t),lRr=r(dL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=n(dL,"CODE",{});var VPt=s(TCe);iRr=r(VPt,"pretrained_model_name_or_path"),VPt.forEach(t),dRr=r(dL,":"),dL.forEach(t),cRr=i(Ul),ce=n(Ul,"UL",{});var ge=s(ce);s5=n(ge,"LI",{});var pDe=s(s5);MCe=n(pDe,"STRONG",{});var XPt=s(MCe);fRr=r(XPt,"albert"),XPt.forEach(t),mRr=r(pDe," \u2014 "),NK=n(pDe,"A",{href:!0});var zPt=s(NK);gRr=r(zPt,"TFAlbertForQuestionAnswering"),zPt.forEach(t),hRr=r(pDe," (ALBERT model)"),pDe.forEach(t),pRr=i(ge),l5=n(ge,"LI",{});var _De=s(l5);ECe=n(_De,"STRONG",{});var QPt=s(ECe);_Rr=r(QPt,"bert"),QPt.forEach(t),uRr=r(_De," \u2014 "),IK=n(_De,"A",{href:!0});var WPt=s(IK);bRr=r(WPt,"TFBertForQuestionAnswering"),WPt.forEach(t),vRr=r(_De," (BERT model)"),_De.forEach(t),FRr=i(ge),i5=n(ge,"LI",{});var uDe=s(i5);CCe=n(uDe,"STRONG",{});var HPt=s(CCe);TRr=r(HPt,"camembert"),HPt.forEach(t),MRr=r(uDe," \u2014 "),qK=n(uDe,"A",{href:!0});var UPt=s(qK);ERr=r(UPt,"TFCamembertForQuestionAnswering"),UPt.forEach(t),CRr=r(uDe," (CamemBERT model)"),uDe.forEach(t),wRr=i(ge),d5=n(ge,"LI",{});var bDe=s(d5);wCe=n(bDe,"STRONG",{});var JPt=s(wCe);ARr=r(JPt,"convbert"),JPt.forEach(t),LRr=r(bDe," \u2014 "),jK=n(bDe,"A",{href:!0});var YPt=s(jK);yRr=r(YPt,"TFConvBertForQuestionAnswering"),YPt.forEach(t),xRr=r(bDe," (ConvBERT model)"),bDe.forEach(t),$Rr=i(ge),c5=n(ge,"LI",{});var vDe=s(c5);ACe=n(vDe,"STRONG",{});var KPt=s(ACe);kRr=r(KPt,"deberta"),KPt.forEach(t),SRr=r(vDe," \u2014 "),DK=n(vDe,"A",{href:!0});var ZPt=s(DK);RRr=r(ZPt,"TFDebertaForQuestionAnswering"),ZPt.forEach(t),PRr=r(vDe," (DeBERTa model)"),vDe.forEach(t),BRr=i(ge),f5=n(ge,"LI",{});var FDe=s(f5);LCe=n(FDe,"STRONG",{});var eBt=s(LCe);NRr=r(eBt,"deberta-v2"),eBt.forEach(t),IRr=r(FDe," \u2014 "),GK=n(FDe,"A",{href:!0});var oBt=s(GK);qRr=r(oBt,"TFDebertaV2ForQuestionAnswering"),oBt.forEach(t),jRr=r(FDe," (DeBERTa-v2 model)"),FDe.forEach(t),DRr=i(ge),m5=n(ge,"LI",{});var TDe=s(m5);yCe=n(TDe,"STRONG",{});var rBt=s(yCe);GRr=r(rBt,"distilbert"),rBt.forEach(t),ORr=r(TDe," \u2014 "),OK=n(TDe,"A",{href:!0});var tBt=s(OK);VRr=r(tBt,"TFDistilBertForQuestionAnswering"),tBt.forEach(t),XRr=r(TDe," (DistilBERT model)"),TDe.forEach(t),zRr=i(ge),g5=n(ge,"LI",{});var MDe=s(g5);xCe=n(MDe,"STRONG",{});var aBt=s(xCe);QRr=r(aBt,"electra"),aBt.forEach(t),WRr=r(MDe," \u2014 "),VK=n(MDe,"A",{href:!0});var nBt=s(VK);HRr=r(nBt,"TFElectraForQuestionAnswering"),nBt.forEach(t),URr=r(MDe," (ELECTRA model)"),MDe.forEach(t),JRr=i(ge),h5=n(ge,"LI",{});var EDe=s(h5);$Ce=n(EDe,"STRONG",{});var sBt=s($Ce);YRr=r(sBt,"flaubert"),sBt.forEach(t),KRr=r(EDe," \u2014 "),XK=n(EDe,"A",{href:!0});var lBt=s(XK);ZRr=r(lBt,"TFFlaubertForQuestionAnsweringSimple"),lBt.forEach(t),ePr=r(EDe," (FlauBERT model)"),EDe.forEach(t),oPr=i(ge),p5=n(ge,"LI",{});var CDe=s(p5);kCe=n(CDe,"STRONG",{});var iBt=s(kCe);rPr=r(iBt,"funnel"),iBt.forEach(t),tPr=r(CDe," \u2014 "),zK=n(CDe,"A",{href:!0});var dBt=s(zK);aPr=r(dBt,"TFFunnelForQuestionAnswering"),dBt.forEach(t),nPr=r(CDe," (Funnel Transformer model)"),CDe.forEach(t),sPr=i(ge),_5=n(ge,"LI",{});var wDe=s(_5);SCe=n(wDe,"STRONG",{});var cBt=s(SCe);lPr=r(cBt,"gptj"),cBt.forEach(t),iPr=r(wDe," \u2014 "),QK=n(wDe,"A",{href:!0});var fBt=s(QK);dPr=r(fBt,"TFGPTJForQuestionAnswering"),fBt.forEach(t),cPr=r(wDe," (GPT-J model)"),wDe.forEach(t),fPr=i(ge),u5=n(ge,"LI",{});var ADe=s(u5);RCe=n(ADe,"STRONG",{});var mBt=s(RCe);mPr=r(mBt,"longformer"),mBt.forEach(t),gPr=r(ADe," \u2014 "),WK=n(ADe,"A",{href:!0});var gBt=s(WK);hPr=r(gBt,"TFLongformerForQuestionAnswering"),gBt.forEach(t),pPr=r(ADe," (Longformer model)"),ADe.forEach(t),_Pr=i(ge),b5=n(ge,"LI",{});var LDe=s(b5);PCe=n(LDe,"STRONG",{});var hBt=s(PCe);uPr=r(hBt,"mobilebert"),hBt.forEach(t),bPr=r(LDe," \u2014 "),HK=n(LDe,"A",{href:!0});var pBt=s(HK);vPr=r(pBt,"TFMobileBertForQuestionAnswering"),pBt.forEach(t),FPr=r(LDe," (MobileBERT model)"),LDe.forEach(t),TPr=i(ge),v5=n(ge,"LI",{});var yDe=s(v5);BCe=n(yDe,"STRONG",{});var _Bt=s(BCe);MPr=r(_Bt,"mpnet"),_Bt.forEach(t),EPr=r(yDe," \u2014 "),UK=n(yDe,"A",{href:!0});var uBt=s(UK);CPr=r(uBt,"TFMPNetForQuestionAnswering"),uBt.forEach(t),wPr=r(yDe," (MPNet model)"),yDe.forEach(t),APr=i(ge),F5=n(ge,"LI",{});var xDe=s(F5);NCe=n(xDe,"STRONG",{});var bBt=s(NCe);LPr=r(bBt,"rembert"),bBt.forEach(t),yPr=r(xDe," \u2014 "),JK=n(xDe,"A",{href:!0});var vBt=s(JK);xPr=r(vBt,"TFRemBertForQuestionAnswering"),vBt.forEach(t),$Pr=r(xDe," (RemBERT model)"),xDe.forEach(t),kPr=i(ge),T5=n(ge,"LI",{});var $De=s(T5);ICe=n($De,"STRONG",{});var FBt=s(ICe);SPr=r(FBt,"roberta"),FBt.forEach(t),RPr=r($De," \u2014 "),YK=n($De,"A",{href:!0});var TBt=s(YK);PPr=r(TBt,"TFRobertaForQuestionAnswering"),TBt.forEach(t),BPr=r($De," (RoBERTa model)"),$De.forEach(t),NPr=i(ge),M5=n(ge,"LI",{});var kDe=s(M5);qCe=n(kDe,"STRONG",{});var MBt=s(qCe);IPr=r(MBt,"roformer"),MBt.forEach(t),qPr=r(kDe," \u2014 "),KK=n(kDe,"A",{href:!0});var EBt=s(KK);jPr=r(EBt,"TFRoFormerForQuestionAnswering"),EBt.forEach(t),DPr=r(kDe," (RoFormer model)"),kDe.forEach(t),GPr=i(ge),E5=n(ge,"LI",{});var SDe=s(E5);jCe=n(SDe,"STRONG",{});var CBt=s(jCe);OPr=r(CBt,"xlm"),CBt.forEach(t),VPr=r(SDe," \u2014 "),ZK=n(SDe,"A",{href:!0});var wBt=s(ZK);XPr=r(wBt,"TFXLMForQuestionAnsweringSimple"),wBt.forEach(t),zPr=r(SDe," (XLM model)"),SDe.forEach(t),QPr=i(ge),C5=n(ge,"LI",{});var RDe=s(C5);DCe=n(RDe,"STRONG",{});var ABt=s(DCe);WPr=r(ABt,"xlm-roberta"),ABt.forEach(t),HPr=r(RDe," \u2014 "),eZ=n(RDe,"A",{href:!0});var LBt=s(eZ);UPr=r(LBt,"TFXLMRobertaForQuestionAnswering"),LBt.forEach(t),JPr=r(RDe," (XLM-RoBERTa model)"),RDe.forEach(t),YPr=i(ge),w5=n(ge,"LI",{});var PDe=s(w5);GCe=n(PDe,"STRONG",{});var yBt=s(GCe);KPr=r(yBt,"xlnet"),yBt.forEach(t),ZPr=r(PDe," \u2014 "),oZ=n(PDe,"A",{href:!0});var xBt=s(oZ);eBr=r(xBt,"TFXLNetForQuestionAnsweringSimple"),xBt.forEach(t),oBr=r(PDe," (XLNet model)"),PDe.forEach(t),ge.forEach(t),rBr=i(Ul),T(A5.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),_Xe=i(f),jc=n(f,"H2",{class:!0});var wQe=s(jc);L5=n(wQe,"A",{id:!0,class:!0,href:!0});var $Bt=s(L5);OCe=n($Bt,"SPAN",{});var kBt=s(OCe);T(Bx.$$.fragment,kBt),kBt.forEach(t),$Bt.forEach(t),tBr=i(wQe),VCe=n(wQe,"SPAN",{});var SBt=s(VCe);aBr=r(SBt,"TFAutoModelForVision2Seq"),SBt.forEach(t),wQe.forEach(t),uXe=i(f),gr=n(f,"DIV",{class:!0});var Jl=s(gr);T(Nx.$$.fragment,Jl),nBr=i(Jl),Dc=n(Jl,"P",{});var hte=s(Dc);sBr=r(hte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),rZ=n(hte,"A",{href:!0});var RBt=s(rZ);lBr=r(RBt,"from_pretrained()"),RBt.forEach(t),iBr=r(hte," class method or the "),tZ=n(hte,"A",{href:!0});var PBt=s(tZ);dBr=r(PBt,"from_config()"),PBt.forEach(t),cBr=r(hte,` class
method.`),hte.forEach(t),fBr=i(Jl),Ix=n(Jl,"P",{});var AQe=s(Ix);mBr=r(AQe,"This class cannot be instantiated directly using "),XCe=n(AQe,"CODE",{});var BBt=s(XCe);gBr=r(BBt,"__init__()"),BBt.forEach(t),hBr=r(AQe," (throws an error)."),AQe.forEach(t),pBr=i(Jl),Vt=n(Jl,"DIV",{class:!0});var cL=s(Vt);T(qx.$$.fragment,cL),_Br=i(cL),zCe=n(cL,"P",{});var NBt=s(zCe);uBr=r(NBt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),NBt.forEach(t),bBr=i(cL),Gc=n(cL,"P",{});var pte=s(Gc);vBr=r(pte,`Note:
Loading a model from its configuration file does `),QCe=n(pte,"STRONG",{});var IBt=s(QCe);FBr=r(IBt,"not"),IBt.forEach(t),TBr=r(pte,` load the model weights. It only affects the
model\u2019s configuration. Use `),aZ=n(pte,"A",{href:!0});var qBt=s(aZ);MBr=r(qBt,"from_pretrained()"),qBt.forEach(t),EBr=r(pte," to load the model weights."),pte.forEach(t),CBr=i(cL),T(y5.$$.fragment,cL),cL.forEach(t),wBr=i(Jl),Gr=n(Jl,"DIV",{class:!0});var Yl=s(Gr);T(jx.$$.fragment,Yl),ABr=i(Yl),WCe=n(Yl,"P",{});var jBt=s(WCe);LBr=r(jBt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),jBt.forEach(t),yBr=i(Yl),vn=n(Yl,"P",{});var fL=s(vn);xBr=r(fL,"The model class to instantiate is selected based on the "),HCe=n(fL,"CODE",{});var DBt=s(HCe);$Br=r(DBt,"model_type"),DBt.forEach(t),kBr=r(fL,` property of the config object (either
passed as an argument or loaded from `),UCe=n(fL,"CODE",{});var GBt=s(UCe);SBr=r(GBt,"pretrained_model_name_or_path"),GBt.forEach(t),RBr=r(fL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JCe=n(fL,"CODE",{});var OBt=s(JCe);PBr=r(OBt,"pretrained_model_name_or_path"),OBt.forEach(t),BBr=r(fL,":"),fL.forEach(t),NBr=i(Yl),YCe=n(Yl,"UL",{});var VBt=s(YCe);x5=n(VBt,"LI",{});var BDe=s(x5);KCe=n(BDe,"STRONG",{});var XBt=s(KCe);IBr=r(XBt,"vision-encoder-decoder"),XBt.forEach(t),qBr=r(BDe," \u2014 "),nZ=n(BDe,"A",{href:!0});var zBt=s(nZ);jBr=r(zBt,"TFVisionEncoderDecoderModel"),zBt.forEach(t),DBr=r(BDe," (Vision Encoder decoder model)"),BDe.forEach(t),VBt.forEach(t),GBr=i(Yl),T($5.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),bXe=i(f),Oc=n(f,"H2",{class:!0});var LQe=s(Oc);k5=n(LQe,"A",{id:!0,class:!0,href:!0});var QBt=s(k5);ZCe=n(QBt,"SPAN",{});var WBt=s(ZCe);T(Dx.$$.fragment,WBt),WBt.forEach(t),QBt.forEach(t),OBr=i(LQe),e3e=n(LQe,"SPAN",{});var HBt=s(e3e);VBr=r(HBt,"TFAutoModelForSpeechSeq2Seq"),HBt.forEach(t),LQe.forEach(t),vXe=i(f),hr=n(f,"DIV",{class:!0});var Kl=s(hr);T(Gx.$$.fragment,Kl),XBr=i(Kl),Vc=n(Kl,"P",{});var _te=s(Vc);zBr=r(_te,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),sZ=n(_te,"A",{href:!0});var UBt=s(sZ);QBr=r(UBt,"from_pretrained()"),UBt.forEach(t),WBr=r(_te," class method or the "),lZ=n(_te,"A",{href:!0});var JBt=s(lZ);HBr=r(JBt,"from_config()"),JBt.forEach(t),UBr=r(_te,` class
method.`),_te.forEach(t),JBr=i(Kl),Ox=n(Kl,"P",{});var yQe=s(Ox);YBr=r(yQe,"This class cannot be instantiated directly using "),o3e=n(yQe,"CODE",{});var YBt=s(o3e);KBr=r(YBt,"__init__()"),YBt.forEach(t),ZBr=r(yQe," (throws an error)."),yQe.forEach(t),eNr=i(Kl),Xt=n(Kl,"DIV",{class:!0});var mL=s(Xt);T(Vx.$$.fragment,mL),oNr=i(mL),r3e=n(mL,"P",{});var KBt=s(r3e);rNr=r(KBt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),KBt.forEach(t),tNr=i(mL),Xc=n(mL,"P",{});var ute=s(Xc);aNr=r(ute,`Note:
Loading a model from its configuration file does `),t3e=n(ute,"STRONG",{});var ZBt=s(t3e);nNr=r(ZBt,"not"),ZBt.forEach(t),sNr=r(ute,` load the model weights. It only affects the
model\u2019s configuration. Use `),iZ=n(ute,"A",{href:!0});var eNt=s(iZ);lNr=r(eNt,"from_pretrained()"),eNt.forEach(t),iNr=r(ute," to load the model weights."),ute.forEach(t),dNr=i(mL),T(S5.$$.fragment,mL),mL.forEach(t),cNr=i(Kl),Or=n(Kl,"DIV",{class:!0});var Zl=s(Or);T(Xx.$$.fragment,Zl),fNr=i(Zl),a3e=n(Zl,"P",{});var oNt=s(a3e);mNr=r(oNt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),oNt.forEach(t),gNr=i(Zl),Fn=n(Zl,"P",{});var gL=s(Fn);hNr=r(gL,"The model class to instantiate is selected based on the "),n3e=n(gL,"CODE",{});var rNt=s(n3e);pNr=r(rNt,"model_type"),rNt.forEach(t),_Nr=r(gL,` property of the config object (either
passed as an argument or loaded from `),s3e=n(gL,"CODE",{});var tNt=s(s3e);uNr=r(tNt,"pretrained_model_name_or_path"),tNt.forEach(t),bNr=r(gL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l3e=n(gL,"CODE",{});var aNt=s(l3e);vNr=r(aNt,"pretrained_model_name_or_path"),aNt.forEach(t),FNr=r(gL,":"),gL.forEach(t),TNr=i(Zl),i3e=n(Zl,"UL",{});var nNt=s(i3e);R5=n(nNt,"LI",{});var NDe=s(R5);d3e=n(NDe,"STRONG",{});var sNt=s(d3e);MNr=r(sNt,"speech_to_text"),sNt.forEach(t),ENr=r(NDe," \u2014 "),dZ=n(NDe,"A",{href:!0});var lNt=s(dZ);CNr=r(lNt,"TFSpeech2TextForConditionalGeneration"),lNt.forEach(t),wNr=r(NDe," (Speech2Text model)"),NDe.forEach(t),nNt.forEach(t),ANr=i(Zl),T(P5.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),FXe=i(f),zc=n(f,"H2",{class:!0});var xQe=s(zc);B5=n(xQe,"A",{id:!0,class:!0,href:!0});var iNt=s(B5);c3e=n(iNt,"SPAN",{});var dNt=s(c3e);T(zx.$$.fragment,dNt),dNt.forEach(t),iNt.forEach(t),LNr=i(xQe),f3e=n(xQe,"SPAN",{});var cNt=s(f3e);yNr=r(cNt,"FlaxAutoModel"),cNt.forEach(t),xQe.forEach(t),TXe=i(f),pr=n(f,"DIV",{class:!0});var ei=s(pr);T(Qx.$$.fragment,ei),xNr=i(ei),Qc=n(ei,"P",{});var bte=s(Qc);$Nr=r(bte,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),cZ=n(bte,"A",{href:!0});var fNt=s(cZ);kNr=r(fNt,"from_pretrained()"),fNt.forEach(t),SNr=r(bte," class method or the "),fZ=n(bte,"A",{href:!0});var mNt=s(fZ);RNr=r(mNt,"from_config()"),mNt.forEach(t),PNr=r(bte,` class
method.`),bte.forEach(t),BNr=i(ei),Wx=n(ei,"P",{});var $Qe=s(Wx);NNr=r($Qe,"This class cannot be instantiated directly using "),m3e=n($Qe,"CODE",{});var gNt=s(m3e);INr=r(gNt,"__init__()"),gNt.forEach(t),qNr=r($Qe," (throws an error)."),$Qe.forEach(t),jNr=i(ei),zt=n(ei,"DIV",{class:!0});var hL=s(zt);T(Hx.$$.fragment,hL),DNr=i(hL),g3e=n(hL,"P",{});var hNt=s(g3e);GNr=r(hNt,"Instantiates one of the base model classes of the library from a configuration."),hNt.forEach(t),ONr=i(hL),Wc=n(hL,"P",{});var vte=s(Wc);VNr=r(vte,`Note:
Loading a model from its configuration file does `),h3e=n(vte,"STRONG",{});var pNt=s(h3e);XNr=r(pNt,"not"),pNt.forEach(t),zNr=r(vte,` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=n(vte,"A",{href:!0});var _Nt=s(mZ);QNr=r(_Nt,"from_pretrained()"),_Nt.forEach(t),WNr=r(vte," to load the model weights."),vte.forEach(t),HNr=i(hL),T(N5.$$.fragment,hL),hL.forEach(t),UNr=i(ei),Vr=n(ei,"DIV",{class:!0});var oi=s(Vr);T(Ux.$$.fragment,oi),JNr=i(oi),p3e=n(oi,"P",{});var uNt=s(p3e);YNr=r(uNt,"Instantiate one of the base model classes of the library from a pretrained model."),uNt.forEach(t),KNr=i(oi),Tn=n(oi,"P",{});var pL=s(Tn);ZNr=r(pL,"The model class to instantiate is selected based on the "),_3e=n(pL,"CODE",{});var bNt=s(_3e);eIr=r(bNt,"model_type"),bNt.forEach(t),oIr=r(pL,` property of the config object (either
passed as an argument or loaded from `),u3e=n(pL,"CODE",{});var vNt=s(u3e);rIr=r(vNt,"pretrained_model_name_or_path"),vNt.forEach(t),tIr=r(pL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b3e=n(pL,"CODE",{});var FNt=s(b3e);aIr=r(FNt,"pretrained_model_name_or_path"),FNt.forEach(t),nIr=r(pL,":"),pL.forEach(t),sIr=i(oi),oe=n(oi,"UL",{});var ae=s(oe);I5=n(ae,"LI",{});var IDe=s(I5);v3e=n(IDe,"STRONG",{});var TNt=s(v3e);lIr=r(TNt,"albert"),TNt.forEach(t),iIr=r(IDe," \u2014 "),gZ=n(IDe,"A",{href:!0});var MNt=s(gZ);dIr=r(MNt,"FlaxAlbertModel"),MNt.forEach(t),cIr=r(IDe," (ALBERT model)"),IDe.forEach(t),fIr=i(ae),q5=n(ae,"LI",{});var qDe=s(q5);F3e=n(qDe,"STRONG",{});var ENt=s(F3e);mIr=r(ENt,"bart"),ENt.forEach(t),gIr=r(qDe," \u2014 "),hZ=n(qDe,"A",{href:!0});var CNt=s(hZ);hIr=r(CNt,"FlaxBartModel"),CNt.forEach(t),pIr=r(qDe," (BART model)"),qDe.forEach(t),_Ir=i(ae),j5=n(ae,"LI",{});var jDe=s(j5);T3e=n(jDe,"STRONG",{});var wNt=s(T3e);uIr=r(wNt,"beit"),wNt.forEach(t),bIr=r(jDe," \u2014 "),pZ=n(jDe,"A",{href:!0});var ANt=s(pZ);vIr=r(ANt,"FlaxBeitModel"),ANt.forEach(t),FIr=r(jDe," (BEiT model)"),jDe.forEach(t),TIr=i(ae),D5=n(ae,"LI",{});var DDe=s(D5);M3e=n(DDe,"STRONG",{});var LNt=s(M3e);MIr=r(LNt,"bert"),LNt.forEach(t),EIr=r(DDe," \u2014 "),_Z=n(DDe,"A",{href:!0});var yNt=s(_Z);CIr=r(yNt,"FlaxBertModel"),yNt.forEach(t),wIr=r(DDe," (BERT model)"),DDe.forEach(t),AIr=i(ae),G5=n(ae,"LI",{});var GDe=s(G5);E3e=n(GDe,"STRONG",{});var xNt=s(E3e);LIr=r(xNt,"big_bird"),xNt.forEach(t),yIr=r(GDe," \u2014 "),uZ=n(GDe,"A",{href:!0});var $Nt=s(uZ);xIr=r($Nt,"FlaxBigBirdModel"),$Nt.forEach(t),$Ir=r(GDe," (BigBird model)"),GDe.forEach(t),kIr=i(ae),O5=n(ae,"LI",{});var ODe=s(O5);C3e=n(ODe,"STRONG",{});var kNt=s(C3e);SIr=r(kNt,"blenderbot"),kNt.forEach(t),RIr=r(ODe," \u2014 "),bZ=n(ODe,"A",{href:!0});var SNt=s(bZ);PIr=r(SNt,"FlaxBlenderbotModel"),SNt.forEach(t),BIr=r(ODe," (Blenderbot model)"),ODe.forEach(t),NIr=i(ae),V5=n(ae,"LI",{});var VDe=s(V5);w3e=n(VDe,"STRONG",{});var RNt=s(w3e);IIr=r(RNt,"blenderbot-small"),RNt.forEach(t),qIr=r(VDe," \u2014 "),vZ=n(VDe,"A",{href:!0});var PNt=s(vZ);jIr=r(PNt,"FlaxBlenderbotSmallModel"),PNt.forEach(t),DIr=r(VDe," (BlenderbotSmall model)"),VDe.forEach(t),GIr=i(ae),X5=n(ae,"LI",{});var XDe=s(X5);A3e=n(XDe,"STRONG",{});var BNt=s(A3e);OIr=r(BNt,"clip"),BNt.forEach(t),VIr=r(XDe," \u2014 "),FZ=n(XDe,"A",{href:!0});var NNt=s(FZ);XIr=r(NNt,"FlaxCLIPModel"),NNt.forEach(t),zIr=r(XDe," (CLIP model)"),XDe.forEach(t),QIr=i(ae),z5=n(ae,"LI",{});var zDe=s(z5);L3e=n(zDe,"STRONG",{});var INt=s(L3e);WIr=r(INt,"distilbert"),INt.forEach(t),HIr=r(zDe," \u2014 "),TZ=n(zDe,"A",{href:!0});var qNt=s(TZ);UIr=r(qNt,"FlaxDistilBertModel"),qNt.forEach(t),JIr=r(zDe," (DistilBERT model)"),zDe.forEach(t),YIr=i(ae),Q5=n(ae,"LI",{});var QDe=s(Q5);y3e=n(QDe,"STRONG",{});var jNt=s(y3e);KIr=r(jNt,"electra"),jNt.forEach(t),ZIr=r(QDe," \u2014 "),MZ=n(QDe,"A",{href:!0});var DNt=s(MZ);eqr=r(DNt,"FlaxElectraModel"),DNt.forEach(t),oqr=r(QDe," (ELECTRA model)"),QDe.forEach(t),rqr=i(ae),W5=n(ae,"LI",{});var WDe=s(W5);x3e=n(WDe,"STRONG",{});var GNt=s(x3e);tqr=r(GNt,"gpt2"),GNt.forEach(t),aqr=r(WDe," \u2014 "),EZ=n(WDe,"A",{href:!0});var ONt=s(EZ);nqr=r(ONt,"FlaxGPT2Model"),ONt.forEach(t),sqr=r(WDe," (OpenAI GPT-2 model)"),WDe.forEach(t),lqr=i(ae),H5=n(ae,"LI",{});var HDe=s(H5);$3e=n(HDe,"STRONG",{});var VNt=s($3e);iqr=r(VNt,"gpt_neo"),VNt.forEach(t),dqr=r(HDe," \u2014 "),CZ=n(HDe,"A",{href:!0});var XNt=s(CZ);cqr=r(XNt,"FlaxGPTNeoModel"),XNt.forEach(t),fqr=r(HDe," (GPT Neo model)"),HDe.forEach(t),mqr=i(ae),U5=n(ae,"LI",{});var UDe=s(U5);k3e=n(UDe,"STRONG",{});var zNt=s(k3e);gqr=r(zNt,"gptj"),zNt.forEach(t),hqr=r(UDe," \u2014 "),wZ=n(UDe,"A",{href:!0});var QNt=s(wZ);pqr=r(QNt,"FlaxGPTJModel"),QNt.forEach(t),_qr=r(UDe," (GPT-J model)"),UDe.forEach(t),uqr=i(ae),J5=n(ae,"LI",{});var JDe=s(J5);S3e=n(JDe,"STRONG",{});var WNt=s(S3e);bqr=r(WNt,"longt5"),WNt.forEach(t),vqr=r(JDe," \u2014 "),AZ=n(JDe,"A",{href:!0});var HNt=s(AZ);Fqr=r(HNt,"FlaxLongT5Model"),HNt.forEach(t),Tqr=r(JDe," (LongT5 model)"),JDe.forEach(t),Mqr=i(ae),Y5=n(ae,"LI",{});var YDe=s(Y5);R3e=n(YDe,"STRONG",{});var UNt=s(R3e);Eqr=r(UNt,"marian"),UNt.forEach(t),Cqr=r(YDe," \u2014 "),LZ=n(YDe,"A",{href:!0});var JNt=s(LZ);wqr=r(JNt,"FlaxMarianModel"),JNt.forEach(t),Aqr=r(YDe," (Marian model)"),YDe.forEach(t),Lqr=i(ae),K5=n(ae,"LI",{});var KDe=s(K5);P3e=n(KDe,"STRONG",{});var YNt=s(P3e);yqr=r(YNt,"mbart"),YNt.forEach(t),xqr=r(KDe," \u2014 "),yZ=n(KDe,"A",{href:!0});var KNt=s(yZ);$qr=r(KNt,"FlaxMBartModel"),KNt.forEach(t),kqr=r(KDe," (mBART model)"),KDe.forEach(t),Sqr=i(ae),Z5=n(ae,"LI",{});var ZDe=s(Z5);B3e=n(ZDe,"STRONG",{});var ZNt=s(B3e);Rqr=r(ZNt,"mt5"),ZNt.forEach(t),Pqr=r(ZDe," \u2014 "),xZ=n(ZDe,"A",{href:!0});var eIt=s(xZ);Bqr=r(eIt,"FlaxMT5Model"),eIt.forEach(t),Nqr=r(ZDe," (MT5 model)"),ZDe.forEach(t),Iqr=i(ae),e0=n(ae,"LI",{});var eGe=s(e0);N3e=n(eGe,"STRONG",{});var oIt=s(N3e);qqr=r(oIt,"opt"),oIt.forEach(t),jqr=r(eGe," \u2014 "),$Z=n(eGe,"A",{href:!0});var rIt=s($Z);Dqr=r(rIt,"FlaxOPTModel"),rIt.forEach(t),Gqr=r(eGe," (OPT model)"),eGe.forEach(t),Oqr=i(ae),o0=n(ae,"LI",{});var oGe=s(o0);I3e=n(oGe,"STRONG",{});var tIt=s(I3e);Vqr=r(tIt,"pegasus"),tIt.forEach(t),Xqr=r(oGe," \u2014 "),kZ=n(oGe,"A",{href:!0});var aIt=s(kZ);zqr=r(aIt,"FlaxPegasusModel"),aIt.forEach(t),Qqr=r(oGe," (Pegasus model)"),oGe.forEach(t),Wqr=i(ae),r0=n(ae,"LI",{});var rGe=s(r0);q3e=n(rGe,"STRONG",{});var nIt=s(q3e);Hqr=r(nIt,"roberta"),nIt.forEach(t),Uqr=r(rGe," \u2014 "),SZ=n(rGe,"A",{href:!0});var sIt=s(SZ);Jqr=r(sIt,"FlaxRobertaModel"),sIt.forEach(t),Yqr=r(rGe," (RoBERTa model)"),rGe.forEach(t),Kqr=i(ae),t0=n(ae,"LI",{});var tGe=s(t0);j3e=n(tGe,"STRONG",{});var lIt=s(j3e);Zqr=r(lIt,"roformer"),lIt.forEach(t),ejr=r(tGe," \u2014 "),RZ=n(tGe,"A",{href:!0});var iIt=s(RZ);ojr=r(iIt,"FlaxRoFormerModel"),iIt.forEach(t),rjr=r(tGe," (RoFormer model)"),tGe.forEach(t),tjr=i(ae),a0=n(ae,"LI",{});var aGe=s(a0);D3e=n(aGe,"STRONG",{});var dIt=s(D3e);ajr=r(dIt,"t5"),dIt.forEach(t),njr=r(aGe," \u2014 "),PZ=n(aGe,"A",{href:!0});var cIt=s(PZ);sjr=r(cIt,"FlaxT5Model"),cIt.forEach(t),ljr=r(aGe," (T5 model)"),aGe.forEach(t),ijr=i(ae),n0=n(ae,"LI",{});var nGe=s(n0);G3e=n(nGe,"STRONG",{});var fIt=s(G3e);djr=r(fIt,"vision-text-dual-encoder"),fIt.forEach(t),cjr=r(nGe," \u2014 "),BZ=n(nGe,"A",{href:!0});var mIt=s(BZ);fjr=r(mIt,"FlaxVisionTextDualEncoderModel"),mIt.forEach(t),mjr=r(nGe," (VisionTextDualEncoder model)"),nGe.forEach(t),gjr=i(ae),s0=n(ae,"LI",{});var sGe=s(s0);O3e=n(sGe,"STRONG",{});var gIt=s(O3e);hjr=r(gIt,"vit"),gIt.forEach(t),pjr=r(sGe," \u2014 "),NZ=n(sGe,"A",{href:!0});var hIt=s(NZ);_jr=r(hIt,"FlaxViTModel"),hIt.forEach(t),ujr=r(sGe," (ViT model)"),sGe.forEach(t),bjr=i(ae),l0=n(ae,"LI",{});var lGe=s(l0);V3e=n(lGe,"STRONG",{});var pIt=s(V3e);vjr=r(pIt,"wav2vec2"),pIt.forEach(t),Fjr=r(lGe," \u2014 "),IZ=n(lGe,"A",{href:!0});var _It=s(IZ);Tjr=r(_It,"FlaxWav2Vec2Model"),_It.forEach(t),Mjr=r(lGe," (Wav2Vec2 model)"),lGe.forEach(t),Ejr=i(ae),i0=n(ae,"LI",{});var iGe=s(i0);X3e=n(iGe,"STRONG",{});var uIt=s(X3e);Cjr=r(uIt,"xglm"),uIt.forEach(t),wjr=r(iGe," \u2014 "),qZ=n(iGe,"A",{href:!0});var bIt=s(qZ);Ajr=r(bIt,"FlaxXGLMModel"),bIt.forEach(t),Ljr=r(iGe," (XGLM model)"),iGe.forEach(t),yjr=i(ae),d0=n(ae,"LI",{});var dGe=s(d0);z3e=n(dGe,"STRONG",{});var vIt=s(z3e);xjr=r(vIt,"xlm-roberta"),vIt.forEach(t),$jr=r(dGe," \u2014 "),jZ=n(dGe,"A",{href:!0});var FIt=s(jZ);kjr=r(FIt,"FlaxXLMRobertaModel"),FIt.forEach(t),Sjr=r(dGe," (XLM-RoBERTa model)"),dGe.forEach(t),ae.forEach(t),Rjr=i(oi),T(c0.$$.fragment,oi),oi.forEach(t),ei.forEach(t),MXe=i(f),Hc=n(f,"H2",{class:!0});var kQe=s(Hc);f0=n(kQe,"A",{id:!0,class:!0,href:!0});var TIt=s(f0);Q3e=n(TIt,"SPAN",{});var MIt=s(Q3e);T(Jx.$$.fragment,MIt),MIt.forEach(t),TIt.forEach(t),Pjr=i(kQe),W3e=n(kQe,"SPAN",{});var EIt=s(W3e);Bjr=r(EIt,"FlaxAutoModelForCausalLM"),EIt.forEach(t),kQe.forEach(t),EXe=i(f),_r=n(f,"DIV",{class:!0});var ri=s(_r);T(Yx.$$.fragment,ri),Njr=i(ri),Uc=n(ri,"P",{});var Fte=s(Uc);Ijr=r(Fte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),DZ=n(Fte,"A",{href:!0});var CIt=s(DZ);qjr=r(CIt,"from_pretrained()"),CIt.forEach(t),jjr=r(Fte," class method or the "),GZ=n(Fte,"A",{href:!0});var wIt=s(GZ);Djr=r(wIt,"from_config()"),wIt.forEach(t),Gjr=r(Fte,` class
method.`),Fte.forEach(t),Ojr=i(ri),Kx=n(ri,"P",{});var SQe=s(Kx);Vjr=r(SQe,"This class cannot be instantiated directly using "),H3e=n(SQe,"CODE",{});var AIt=s(H3e);Xjr=r(AIt,"__init__()"),AIt.forEach(t),zjr=r(SQe," (throws an error)."),SQe.forEach(t),Qjr=i(ri),Qt=n(ri,"DIV",{class:!0});var _L=s(Qt);T(Zx.$$.fragment,_L),Wjr=i(_L),U3e=n(_L,"P",{});var LIt=s(U3e);Hjr=r(LIt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),LIt.forEach(t),Ujr=i(_L),Jc=n(_L,"P",{});var Tte=s(Jc);Jjr=r(Tte,`Note:
Loading a model from its configuration file does `),J3e=n(Tte,"STRONG",{});var yIt=s(J3e);Yjr=r(yIt,"not"),yIt.forEach(t),Kjr=r(Tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),OZ=n(Tte,"A",{href:!0});var xIt=s(OZ);Zjr=r(xIt,"from_pretrained()"),xIt.forEach(t),eDr=r(Tte," to load the model weights."),Tte.forEach(t),oDr=i(_L),T(m0.$$.fragment,_L),_L.forEach(t),rDr=i(ri),Xr=n(ri,"DIV",{class:!0});var ti=s(Xr);T(e$.$$.fragment,ti),tDr=i(ti),Y3e=n(ti,"P",{});var $It=s(Y3e);aDr=r($It,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),$It.forEach(t),nDr=i(ti),Mn=n(ti,"P",{});var uL=s(Mn);sDr=r(uL,"The model class to instantiate is selected based on the "),K3e=n(uL,"CODE",{});var kIt=s(K3e);lDr=r(kIt,"model_type"),kIt.forEach(t),iDr=r(uL,` property of the config object (either
passed as an argument or loaded from `),Z3e=n(uL,"CODE",{});var SIt=s(Z3e);dDr=r(SIt,"pretrained_model_name_or_path"),SIt.forEach(t),cDr=r(uL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e5e=n(uL,"CODE",{});var RIt=s(e5e);fDr=r(RIt,"pretrained_model_name_or_path"),RIt.forEach(t),mDr=r(uL,":"),uL.forEach(t),gDr=i(ti),xe=n(ti,"UL",{});var Ie=s(xe);g0=n(Ie,"LI",{});var cGe=s(g0);o5e=n(cGe,"STRONG",{});var PIt=s(o5e);hDr=r(PIt,"bart"),PIt.forEach(t),pDr=r(cGe," \u2014 "),VZ=n(cGe,"A",{href:!0});var BIt=s(VZ);_Dr=r(BIt,"FlaxBartForCausalLM"),BIt.forEach(t),uDr=r(cGe," (BART model)"),cGe.forEach(t),bDr=i(Ie),h0=n(Ie,"LI",{});var fGe=s(h0);r5e=n(fGe,"STRONG",{});var NIt=s(r5e);vDr=r(NIt,"bert"),NIt.forEach(t),FDr=r(fGe," \u2014 "),XZ=n(fGe,"A",{href:!0});var IIt=s(XZ);TDr=r(IIt,"FlaxBertForCausalLM"),IIt.forEach(t),MDr=r(fGe," (BERT model)"),fGe.forEach(t),EDr=i(Ie),p0=n(Ie,"LI",{});var mGe=s(p0);t5e=n(mGe,"STRONG",{});var qIt=s(t5e);CDr=r(qIt,"big_bird"),qIt.forEach(t),wDr=r(mGe," \u2014 "),zZ=n(mGe,"A",{href:!0});var jIt=s(zZ);ADr=r(jIt,"FlaxBigBirdForCausalLM"),jIt.forEach(t),LDr=r(mGe," (BigBird model)"),mGe.forEach(t),yDr=i(Ie),_0=n(Ie,"LI",{});var gGe=s(_0);a5e=n(gGe,"STRONG",{});var DIt=s(a5e);xDr=r(DIt,"electra"),DIt.forEach(t),$Dr=r(gGe," \u2014 "),QZ=n(gGe,"A",{href:!0});var GIt=s(QZ);kDr=r(GIt,"FlaxElectraForCausalLM"),GIt.forEach(t),SDr=r(gGe," (ELECTRA model)"),gGe.forEach(t),RDr=i(Ie),u0=n(Ie,"LI",{});var hGe=s(u0);n5e=n(hGe,"STRONG",{});var OIt=s(n5e);PDr=r(OIt,"gpt2"),OIt.forEach(t),BDr=r(hGe," \u2014 "),WZ=n(hGe,"A",{href:!0});var VIt=s(WZ);NDr=r(VIt,"FlaxGPT2LMHeadModel"),VIt.forEach(t),IDr=r(hGe," (OpenAI GPT-2 model)"),hGe.forEach(t),qDr=i(Ie),b0=n(Ie,"LI",{});var pGe=s(b0);s5e=n(pGe,"STRONG",{});var XIt=s(s5e);jDr=r(XIt,"gpt_neo"),XIt.forEach(t),DDr=r(pGe," \u2014 "),HZ=n(pGe,"A",{href:!0});var zIt=s(HZ);GDr=r(zIt,"FlaxGPTNeoForCausalLM"),zIt.forEach(t),ODr=r(pGe," (GPT Neo model)"),pGe.forEach(t),VDr=i(Ie),v0=n(Ie,"LI",{});var _Ge=s(v0);l5e=n(_Ge,"STRONG",{});var QIt=s(l5e);XDr=r(QIt,"gptj"),QIt.forEach(t),zDr=r(_Ge," \u2014 "),UZ=n(_Ge,"A",{href:!0});var WIt=s(UZ);QDr=r(WIt,"FlaxGPTJForCausalLM"),WIt.forEach(t),WDr=r(_Ge," (GPT-J model)"),_Ge.forEach(t),HDr=i(Ie),F0=n(Ie,"LI",{});var uGe=s(F0);i5e=n(uGe,"STRONG",{});var HIt=s(i5e);UDr=r(HIt,"opt"),HIt.forEach(t),JDr=r(uGe," \u2014 "),JZ=n(uGe,"A",{href:!0});var UIt=s(JZ);YDr=r(UIt,"FlaxOPTForCausalLM"),UIt.forEach(t),KDr=r(uGe," (OPT model)"),uGe.forEach(t),ZDr=i(Ie),T0=n(Ie,"LI",{});var bGe=s(T0);d5e=n(bGe,"STRONG",{});var JIt=s(d5e);eGr=r(JIt,"roberta"),JIt.forEach(t),oGr=r(bGe," \u2014 "),YZ=n(bGe,"A",{href:!0});var YIt=s(YZ);rGr=r(YIt,"FlaxRobertaForCausalLM"),YIt.forEach(t),tGr=r(bGe," (RoBERTa model)"),bGe.forEach(t),aGr=i(Ie),M0=n(Ie,"LI",{});var vGe=s(M0);c5e=n(vGe,"STRONG",{});var KIt=s(c5e);nGr=r(KIt,"xglm"),KIt.forEach(t),sGr=r(vGe," \u2014 "),KZ=n(vGe,"A",{href:!0});var ZIt=s(KZ);lGr=r(ZIt,"FlaxXGLMForCausalLM"),ZIt.forEach(t),iGr=r(vGe," (XGLM model)"),vGe.forEach(t),Ie.forEach(t),dGr=i(ti),T(E0.$$.fragment,ti),ti.forEach(t),ri.forEach(t),CXe=i(f),Yc=n(f,"H2",{class:!0});var RQe=s(Yc);C0=n(RQe,"A",{id:!0,class:!0,href:!0});var eqt=s(C0);f5e=n(eqt,"SPAN",{});var oqt=s(f5e);T(o$.$$.fragment,oqt),oqt.forEach(t),eqt.forEach(t),cGr=i(RQe),m5e=n(RQe,"SPAN",{});var rqt=s(m5e);fGr=r(rqt,"FlaxAutoModelForPreTraining"),rqt.forEach(t),RQe.forEach(t),wXe=i(f),ur=n(f,"DIV",{class:!0});var ai=s(ur);T(r$.$$.fragment,ai),mGr=i(ai),Kc=n(ai,"P",{});var Mte=s(Kc);gGr=r(Mte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZZ=n(Mte,"A",{href:!0});var tqt=s(ZZ);hGr=r(tqt,"from_pretrained()"),tqt.forEach(t),pGr=r(Mte," class method or the "),eee=n(Mte,"A",{href:!0});var aqt=s(eee);_Gr=r(aqt,"from_config()"),aqt.forEach(t),uGr=r(Mte,` class
method.`),Mte.forEach(t),bGr=i(ai),t$=n(ai,"P",{});var PQe=s(t$);vGr=r(PQe,"This class cannot be instantiated directly using "),g5e=n(PQe,"CODE",{});var nqt=s(g5e);FGr=r(nqt,"__init__()"),nqt.forEach(t),TGr=r(PQe," (throws an error)."),PQe.forEach(t),MGr=i(ai),Wt=n(ai,"DIV",{class:!0});var bL=s(Wt);T(a$.$$.fragment,bL),EGr=i(bL),h5e=n(bL,"P",{});var sqt=s(h5e);CGr=r(sqt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),sqt.forEach(t),wGr=i(bL),Zc=n(bL,"P",{});var Ete=s(Zc);AGr=r(Ete,`Note:
Loading a model from its configuration file does `),p5e=n(Ete,"STRONG",{});var lqt=s(p5e);LGr=r(lqt,"not"),lqt.forEach(t),yGr=r(Ete,` load the model weights. It only affects the
model\u2019s configuration. Use `),oee=n(Ete,"A",{href:!0});var iqt=s(oee);xGr=r(iqt,"from_pretrained()"),iqt.forEach(t),$Gr=r(Ete," to load the model weights."),Ete.forEach(t),kGr=i(bL),T(w0.$$.fragment,bL),bL.forEach(t),SGr=i(ai),zr=n(ai,"DIV",{class:!0});var ni=s(zr);T(n$.$$.fragment,ni),RGr=i(ni),_5e=n(ni,"P",{});var dqt=s(_5e);PGr=r(dqt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),dqt.forEach(t),BGr=i(ni),En=n(ni,"P",{});var vL=s(En);NGr=r(vL,"The model class to instantiate is selected based on the "),u5e=n(vL,"CODE",{});var cqt=s(u5e);IGr=r(cqt,"model_type"),cqt.forEach(t),qGr=r(vL,` property of the config object (either
passed as an argument or loaded from `),b5e=n(vL,"CODE",{});var fqt=s(b5e);jGr=r(fqt,"pretrained_model_name_or_path"),fqt.forEach(t),DGr=r(vL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v5e=n(vL,"CODE",{});var mqt=s(v5e);GGr=r(mqt,"pretrained_model_name_or_path"),mqt.forEach(t),OGr=r(vL,":"),vL.forEach(t),VGr=i(ni),Ee=n(ni,"UL",{});var we=s(Ee);A0=n(we,"LI",{});var FGe=s(A0);F5e=n(FGe,"STRONG",{});var gqt=s(F5e);XGr=r(gqt,"albert"),gqt.forEach(t),zGr=r(FGe," \u2014 "),ree=n(FGe,"A",{href:!0});var hqt=s(ree);QGr=r(hqt,"FlaxAlbertForPreTraining"),hqt.forEach(t),WGr=r(FGe," (ALBERT model)"),FGe.forEach(t),HGr=i(we),L0=n(we,"LI",{});var TGe=s(L0);T5e=n(TGe,"STRONG",{});var pqt=s(T5e);UGr=r(pqt,"bart"),pqt.forEach(t),JGr=r(TGe," \u2014 "),tee=n(TGe,"A",{href:!0});var _qt=s(tee);YGr=r(_qt,"FlaxBartForConditionalGeneration"),_qt.forEach(t),KGr=r(TGe," (BART model)"),TGe.forEach(t),ZGr=i(we),y0=n(we,"LI",{});var MGe=s(y0);M5e=n(MGe,"STRONG",{});var uqt=s(M5e);eOr=r(uqt,"bert"),uqt.forEach(t),oOr=r(MGe," \u2014 "),aee=n(MGe,"A",{href:!0});var bqt=s(aee);rOr=r(bqt,"FlaxBertForPreTraining"),bqt.forEach(t),tOr=r(MGe," (BERT model)"),MGe.forEach(t),aOr=i(we),x0=n(we,"LI",{});var EGe=s(x0);E5e=n(EGe,"STRONG",{});var vqt=s(E5e);nOr=r(vqt,"big_bird"),vqt.forEach(t),sOr=r(EGe," \u2014 "),nee=n(EGe,"A",{href:!0});var Fqt=s(nee);lOr=r(Fqt,"FlaxBigBirdForPreTraining"),Fqt.forEach(t),iOr=r(EGe," (BigBird model)"),EGe.forEach(t),dOr=i(we),$0=n(we,"LI",{});var CGe=s($0);C5e=n(CGe,"STRONG",{});var Tqt=s(C5e);cOr=r(Tqt,"electra"),Tqt.forEach(t),fOr=r(CGe," \u2014 "),see=n(CGe,"A",{href:!0});var Mqt=s(see);mOr=r(Mqt,"FlaxElectraForPreTraining"),Mqt.forEach(t),gOr=r(CGe," (ELECTRA model)"),CGe.forEach(t),hOr=i(we),k0=n(we,"LI",{});var wGe=s(k0);w5e=n(wGe,"STRONG",{});var Eqt=s(w5e);pOr=r(Eqt,"longt5"),Eqt.forEach(t),_Or=r(wGe," \u2014 "),lee=n(wGe,"A",{href:!0});var Cqt=s(lee);uOr=r(Cqt,"FlaxLongT5ForConditionalGeneration"),Cqt.forEach(t),bOr=r(wGe," (LongT5 model)"),wGe.forEach(t),vOr=i(we),S0=n(we,"LI",{});var AGe=s(S0);A5e=n(AGe,"STRONG",{});var wqt=s(A5e);FOr=r(wqt,"mbart"),wqt.forEach(t),TOr=r(AGe," \u2014 "),iee=n(AGe,"A",{href:!0});var Aqt=s(iee);MOr=r(Aqt,"FlaxMBartForConditionalGeneration"),Aqt.forEach(t),EOr=r(AGe," (mBART model)"),AGe.forEach(t),COr=i(we),R0=n(we,"LI",{});var LGe=s(R0);L5e=n(LGe,"STRONG",{});var Lqt=s(L5e);wOr=r(Lqt,"mt5"),Lqt.forEach(t),AOr=r(LGe," \u2014 "),dee=n(LGe,"A",{href:!0});var yqt=s(dee);LOr=r(yqt,"FlaxMT5ForConditionalGeneration"),yqt.forEach(t),yOr=r(LGe," (MT5 model)"),LGe.forEach(t),xOr=i(we),P0=n(we,"LI",{});var yGe=s(P0);y5e=n(yGe,"STRONG",{});var xqt=s(y5e);$Or=r(xqt,"roberta"),xqt.forEach(t),kOr=r(yGe," \u2014 "),cee=n(yGe,"A",{href:!0});var $qt=s(cee);SOr=r($qt,"FlaxRobertaForMaskedLM"),$qt.forEach(t),ROr=r(yGe," (RoBERTa model)"),yGe.forEach(t),POr=i(we),B0=n(we,"LI",{});var xGe=s(B0);x5e=n(xGe,"STRONG",{});var kqt=s(x5e);BOr=r(kqt,"roformer"),kqt.forEach(t),NOr=r(xGe," \u2014 "),fee=n(xGe,"A",{href:!0});var Sqt=s(fee);IOr=r(Sqt,"FlaxRoFormerForMaskedLM"),Sqt.forEach(t),qOr=r(xGe," (RoFormer model)"),xGe.forEach(t),jOr=i(we),N0=n(we,"LI",{});var $Ge=s(N0);$5e=n($Ge,"STRONG",{});var Rqt=s($5e);DOr=r(Rqt,"t5"),Rqt.forEach(t),GOr=r($Ge," \u2014 "),mee=n($Ge,"A",{href:!0});var Pqt=s(mee);OOr=r(Pqt,"FlaxT5ForConditionalGeneration"),Pqt.forEach(t),VOr=r($Ge," (T5 model)"),$Ge.forEach(t),XOr=i(we),I0=n(we,"LI",{});var kGe=s(I0);k5e=n(kGe,"STRONG",{});var Bqt=s(k5e);zOr=r(Bqt,"wav2vec2"),Bqt.forEach(t),QOr=r(kGe," \u2014 "),gee=n(kGe,"A",{href:!0});var Nqt=s(gee);WOr=r(Nqt,"FlaxWav2Vec2ForPreTraining"),Nqt.forEach(t),HOr=r(kGe," (Wav2Vec2 model)"),kGe.forEach(t),UOr=i(we),q0=n(we,"LI",{});var SGe=s(q0);S5e=n(SGe,"STRONG",{});var Iqt=s(S5e);JOr=r(Iqt,"xlm-roberta"),Iqt.forEach(t),YOr=r(SGe," \u2014 "),hee=n(SGe,"A",{href:!0});var qqt=s(hee);KOr=r(qqt,"FlaxXLMRobertaForMaskedLM"),qqt.forEach(t),ZOr=r(SGe," (XLM-RoBERTa model)"),SGe.forEach(t),we.forEach(t),eVr=i(ni),T(j0.$$.fragment,ni),ni.forEach(t),ai.forEach(t),AXe=i(f),ef=n(f,"H2",{class:!0});var BQe=s(ef);D0=n(BQe,"A",{id:!0,class:!0,href:!0});var jqt=s(D0);R5e=n(jqt,"SPAN",{});var Dqt=s(R5e);T(s$.$$.fragment,Dqt),Dqt.forEach(t),jqt.forEach(t),oVr=i(BQe),P5e=n(BQe,"SPAN",{});var Gqt=s(P5e);rVr=r(Gqt,"FlaxAutoModelForMaskedLM"),Gqt.forEach(t),BQe.forEach(t),LXe=i(f),br=n(f,"DIV",{class:!0});var si=s(br);T(l$.$$.fragment,si),tVr=i(si),of=n(si,"P",{});var Cte=s(of);aVr=r(Cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pee=n(Cte,"A",{href:!0});var Oqt=s(pee);nVr=r(Oqt,"from_pretrained()"),Oqt.forEach(t),sVr=r(Cte," class method or the "),_ee=n(Cte,"A",{href:!0});var Vqt=s(_ee);lVr=r(Vqt,"from_config()"),Vqt.forEach(t),iVr=r(Cte,` class
method.`),Cte.forEach(t),dVr=i(si),i$=n(si,"P",{});var NQe=s(i$);cVr=r(NQe,"This class cannot be instantiated directly using "),B5e=n(NQe,"CODE",{});var Xqt=s(B5e);fVr=r(Xqt,"__init__()"),Xqt.forEach(t),mVr=r(NQe," (throws an error)."),NQe.forEach(t),gVr=i(si),Ht=n(si,"DIV",{class:!0});var FL=s(Ht);T(d$.$$.fragment,FL),hVr=i(FL),N5e=n(FL,"P",{});var zqt=s(N5e);pVr=r(zqt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),zqt.forEach(t),_Vr=i(FL),rf=n(FL,"P",{});var wte=s(rf);uVr=r(wte,`Note:
Loading a model from its configuration file does `),I5e=n(wte,"STRONG",{});var Qqt=s(I5e);bVr=r(Qqt,"not"),Qqt.forEach(t),vVr=r(wte,` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=n(wte,"A",{href:!0});var Wqt=s(uee);FVr=r(Wqt,"from_pretrained()"),Wqt.forEach(t),TVr=r(wte," to load the model weights."),wte.forEach(t),MVr=i(FL),T(G0.$$.fragment,FL),FL.forEach(t),EVr=i(si),Qr=n(si,"DIV",{class:!0});var li=s(Qr);T(c$.$$.fragment,li),CVr=i(li),q5e=n(li,"P",{});var Hqt=s(q5e);wVr=r(Hqt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Hqt.forEach(t),AVr=i(li),Cn=n(li,"P",{});var TL=s(Cn);LVr=r(TL,"The model class to instantiate is selected based on the "),j5e=n(TL,"CODE",{});var Uqt=s(j5e);yVr=r(Uqt,"model_type"),Uqt.forEach(t),xVr=r(TL,` property of the config object (either
passed as an argument or loaded from `),D5e=n(TL,"CODE",{});var Jqt=s(D5e);$Vr=r(Jqt,"pretrained_model_name_or_path"),Jqt.forEach(t),kVr=r(TL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G5e=n(TL,"CODE",{});var Yqt=s(G5e);SVr=r(Yqt,"pretrained_model_name_or_path"),Yqt.forEach(t),RVr=r(TL,":"),TL.forEach(t),PVr=i(li),$e=n(li,"UL",{});var qe=s($e);O0=n(qe,"LI",{});var RGe=s(O0);O5e=n(RGe,"STRONG",{});var Kqt=s(O5e);BVr=r(Kqt,"albert"),Kqt.forEach(t),NVr=r(RGe," \u2014 "),bee=n(RGe,"A",{href:!0});var Zqt=s(bee);IVr=r(Zqt,"FlaxAlbertForMaskedLM"),Zqt.forEach(t),qVr=r(RGe," (ALBERT model)"),RGe.forEach(t),jVr=i(qe),V0=n(qe,"LI",{});var PGe=s(V0);V5e=n(PGe,"STRONG",{});var ejt=s(V5e);DVr=r(ejt,"bart"),ejt.forEach(t),GVr=r(PGe," \u2014 "),vee=n(PGe,"A",{href:!0});var ojt=s(vee);OVr=r(ojt,"FlaxBartForConditionalGeneration"),ojt.forEach(t),VVr=r(PGe," (BART model)"),PGe.forEach(t),XVr=i(qe),X0=n(qe,"LI",{});var BGe=s(X0);X5e=n(BGe,"STRONG",{});var rjt=s(X5e);zVr=r(rjt,"bert"),rjt.forEach(t),QVr=r(BGe," \u2014 "),Fee=n(BGe,"A",{href:!0});var tjt=s(Fee);WVr=r(tjt,"FlaxBertForMaskedLM"),tjt.forEach(t),HVr=r(BGe," (BERT model)"),BGe.forEach(t),UVr=i(qe),z0=n(qe,"LI",{});var NGe=s(z0);z5e=n(NGe,"STRONG",{});var ajt=s(z5e);JVr=r(ajt,"big_bird"),ajt.forEach(t),YVr=r(NGe," \u2014 "),Tee=n(NGe,"A",{href:!0});var njt=s(Tee);KVr=r(njt,"FlaxBigBirdForMaskedLM"),njt.forEach(t),ZVr=r(NGe," (BigBird model)"),NGe.forEach(t),eXr=i(qe),Q0=n(qe,"LI",{});var IGe=s(Q0);Q5e=n(IGe,"STRONG",{});var sjt=s(Q5e);oXr=r(sjt,"distilbert"),sjt.forEach(t),rXr=r(IGe," \u2014 "),Mee=n(IGe,"A",{href:!0});var ljt=s(Mee);tXr=r(ljt,"FlaxDistilBertForMaskedLM"),ljt.forEach(t),aXr=r(IGe," (DistilBERT model)"),IGe.forEach(t),nXr=i(qe),W0=n(qe,"LI",{});var qGe=s(W0);W5e=n(qGe,"STRONG",{});var ijt=s(W5e);sXr=r(ijt,"electra"),ijt.forEach(t),lXr=r(qGe," \u2014 "),Eee=n(qGe,"A",{href:!0});var djt=s(Eee);iXr=r(djt,"FlaxElectraForMaskedLM"),djt.forEach(t),dXr=r(qGe," (ELECTRA model)"),qGe.forEach(t),cXr=i(qe),H0=n(qe,"LI",{});var jGe=s(H0);H5e=n(jGe,"STRONG",{});var cjt=s(H5e);fXr=r(cjt,"mbart"),cjt.forEach(t),mXr=r(jGe," \u2014 "),Cee=n(jGe,"A",{href:!0});var fjt=s(Cee);gXr=r(fjt,"FlaxMBartForConditionalGeneration"),fjt.forEach(t),hXr=r(jGe," (mBART model)"),jGe.forEach(t),pXr=i(qe),U0=n(qe,"LI",{});var DGe=s(U0);U5e=n(DGe,"STRONG",{});var mjt=s(U5e);_Xr=r(mjt,"roberta"),mjt.forEach(t),uXr=r(DGe," \u2014 "),wee=n(DGe,"A",{href:!0});var gjt=s(wee);bXr=r(gjt,"FlaxRobertaForMaskedLM"),gjt.forEach(t),vXr=r(DGe," (RoBERTa model)"),DGe.forEach(t),FXr=i(qe),J0=n(qe,"LI",{});var GGe=s(J0);J5e=n(GGe,"STRONG",{});var hjt=s(J5e);TXr=r(hjt,"roformer"),hjt.forEach(t),MXr=r(GGe," \u2014 "),Aee=n(GGe,"A",{href:!0});var pjt=s(Aee);EXr=r(pjt,"FlaxRoFormerForMaskedLM"),pjt.forEach(t),CXr=r(GGe," (RoFormer model)"),GGe.forEach(t),wXr=i(qe),Y0=n(qe,"LI",{});var OGe=s(Y0);Y5e=n(OGe,"STRONG",{});var _jt=s(Y5e);AXr=r(_jt,"xlm-roberta"),_jt.forEach(t),LXr=r(OGe," \u2014 "),Lee=n(OGe,"A",{href:!0});var ujt=s(Lee);yXr=r(ujt,"FlaxXLMRobertaForMaskedLM"),ujt.forEach(t),xXr=r(OGe," (XLM-RoBERTa model)"),OGe.forEach(t),qe.forEach(t),$Xr=i(li),T(K0.$$.fragment,li),li.forEach(t),si.forEach(t),yXe=i(f),tf=n(f,"H2",{class:!0});var IQe=s(tf);Z0=n(IQe,"A",{id:!0,class:!0,href:!0});var bjt=s(Z0);K5e=n(bjt,"SPAN",{});var vjt=s(K5e);T(f$.$$.fragment,vjt),vjt.forEach(t),bjt.forEach(t),kXr=i(IQe),Z5e=n(IQe,"SPAN",{});var Fjt=s(Z5e);SXr=r(Fjt,"FlaxAutoModelForSeq2SeqLM"),Fjt.forEach(t),IQe.forEach(t),xXe=i(f),vr=n(f,"DIV",{class:!0});var ii=s(vr);T(m$.$$.fragment,ii),RXr=i(ii),af=n(ii,"P",{});var Ate=s(af);PXr=r(Ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),yee=n(Ate,"A",{href:!0});var Tjt=s(yee);BXr=r(Tjt,"from_pretrained()"),Tjt.forEach(t),NXr=r(Ate," class method or the "),xee=n(Ate,"A",{href:!0});var Mjt=s(xee);IXr=r(Mjt,"from_config()"),Mjt.forEach(t),qXr=r(Ate,` class
method.`),Ate.forEach(t),jXr=i(ii),g$=n(ii,"P",{});var qQe=s(g$);DXr=r(qQe,"This class cannot be instantiated directly using "),e0e=n(qQe,"CODE",{});var Ejt=s(e0e);GXr=r(Ejt,"__init__()"),Ejt.forEach(t),OXr=r(qQe," (throws an error)."),qQe.forEach(t),VXr=i(ii),Ut=n(ii,"DIV",{class:!0});var ML=s(Ut);T(h$.$$.fragment,ML),XXr=i(ML),o0e=n(ML,"P",{});var Cjt=s(o0e);zXr=r(Cjt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Cjt.forEach(t),QXr=i(ML),nf=n(ML,"P",{});var Lte=s(nf);WXr=r(Lte,`Note:
Loading a model from its configuration file does `),r0e=n(Lte,"STRONG",{});var wjt=s(r0e);HXr=r(wjt,"not"),wjt.forEach(t),UXr=r(Lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),$ee=n(Lte,"A",{href:!0});var Ajt=s($ee);JXr=r(Ajt,"from_pretrained()"),Ajt.forEach(t),YXr=r(Lte," to load the model weights."),Lte.forEach(t),KXr=i(ML),T(ew.$$.fragment,ML),ML.forEach(t),ZXr=i(ii),Wr=n(ii,"DIV",{class:!0});var di=s(Wr);T(p$.$$.fragment,di),ezr=i(di),t0e=n(di,"P",{});var Ljt=s(t0e);ozr=r(Ljt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Ljt.forEach(t),rzr=i(di),wn=n(di,"P",{});var EL=s(wn);tzr=r(EL,"The model class to instantiate is selected based on the "),a0e=n(EL,"CODE",{});var yjt=s(a0e);azr=r(yjt,"model_type"),yjt.forEach(t),nzr=r(EL,` property of the config object (either
passed as an argument or loaded from `),n0e=n(EL,"CODE",{});var xjt=s(n0e);szr=r(xjt,"pretrained_model_name_or_path"),xjt.forEach(t),lzr=r(EL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s0e=n(EL,"CODE",{});var $jt=s(s0e);izr=r($jt,"pretrained_model_name_or_path"),$jt.forEach(t),dzr=r(EL,":"),EL.forEach(t),czr=i(di),ke=n(di,"UL",{});var je=s(ke);ow=n(je,"LI",{});var VGe=s(ow);l0e=n(VGe,"STRONG",{});var kjt=s(l0e);fzr=r(kjt,"bart"),kjt.forEach(t),mzr=r(VGe," \u2014 "),kee=n(VGe,"A",{href:!0});var Sjt=s(kee);gzr=r(Sjt,"FlaxBartForConditionalGeneration"),Sjt.forEach(t),hzr=r(VGe," (BART model)"),VGe.forEach(t),pzr=i(je),rw=n(je,"LI",{});var XGe=s(rw);i0e=n(XGe,"STRONG",{});var Rjt=s(i0e);_zr=r(Rjt,"blenderbot"),Rjt.forEach(t),uzr=r(XGe," \u2014 "),See=n(XGe,"A",{href:!0});var Pjt=s(See);bzr=r(Pjt,"FlaxBlenderbotForConditionalGeneration"),Pjt.forEach(t),vzr=r(XGe," (Blenderbot model)"),XGe.forEach(t),Fzr=i(je),tw=n(je,"LI",{});var zGe=s(tw);d0e=n(zGe,"STRONG",{});var Bjt=s(d0e);Tzr=r(Bjt,"blenderbot-small"),Bjt.forEach(t),Mzr=r(zGe," \u2014 "),Ree=n(zGe,"A",{href:!0});var Njt=s(Ree);Ezr=r(Njt,"FlaxBlenderbotSmallForConditionalGeneration"),Njt.forEach(t),Czr=r(zGe," (BlenderbotSmall model)"),zGe.forEach(t),wzr=i(je),aw=n(je,"LI",{});var QGe=s(aw);c0e=n(QGe,"STRONG",{});var Ijt=s(c0e);Azr=r(Ijt,"encoder-decoder"),Ijt.forEach(t),Lzr=r(QGe," \u2014 "),Pee=n(QGe,"A",{href:!0});var qjt=s(Pee);yzr=r(qjt,"FlaxEncoderDecoderModel"),qjt.forEach(t),xzr=r(QGe," (Encoder decoder model)"),QGe.forEach(t),$zr=i(je),nw=n(je,"LI",{});var WGe=s(nw);f0e=n(WGe,"STRONG",{});var jjt=s(f0e);kzr=r(jjt,"longt5"),jjt.forEach(t),Szr=r(WGe," \u2014 "),Bee=n(WGe,"A",{href:!0});var Djt=s(Bee);Rzr=r(Djt,"FlaxLongT5ForConditionalGeneration"),Djt.forEach(t),Pzr=r(WGe," (LongT5 model)"),WGe.forEach(t),Bzr=i(je),sw=n(je,"LI",{});var HGe=s(sw);m0e=n(HGe,"STRONG",{});var Gjt=s(m0e);Nzr=r(Gjt,"marian"),Gjt.forEach(t),Izr=r(HGe," \u2014 "),Nee=n(HGe,"A",{href:!0});var Ojt=s(Nee);qzr=r(Ojt,"FlaxMarianMTModel"),Ojt.forEach(t),jzr=r(HGe," (Marian model)"),HGe.forEach(t),Dzr=i(je),lw=n(je,"LI",{});var UGe=s(lw);g0e=n(UGe,"STRONG",{});var Vjt=s(g0e);Gzr=r(Vjt,"mbart"),Vjt.forEach(t),Ozr=r(UGe," \u2014 "),Iee=n(UGe,"A",{href:!0});var Xjt=s(Iee);Vzr=r(Xjt,"FlaxMBartForConditionalGeneration"),Xjt.forEach(t),Xzr=r(UGe," (mBART model)"),UGe.forEach(t),zzr=i(je),iw=n(je,"LI",{});var JGe=s(iw);h0e=n(JGe,"STRONG",{});var zjt=s(h0e);Qzr=r(zjt,"mt5"),zjt.forEach(t),Wzr=r(JGe," \u2014 "),qee=n(JGe,"A",{href:!0});var Qjt=s(qee);Hzr=r(Qjt,"FlaxMT5ForConditionalGeneration"),Qjt.forEach(t),Uzr=r(JGe," (MT5 model)"),JGe.forEach(t),Jzr=i(je),dw=n(je,"LI",{});var YGe=s(dw);p0e=n(YGe,"STRONG",{});var Wjt=s(p0e);Yzr=r(Wjt,"pegasus"),Wjt.forEach(t),Kzr=r(YGe," \u2014 "),jee=n(YGe,"A",{href:!0});var Hjt=s(jee);Zzr=r(Hjt,"FlaxPegasusForConditionalGeneration"),Hjt.forEach(t),eQr=r(YGe," (Pegasus model)"),YGe.forEach(t),oQr=i(je),cw=n(je,"LI",{});var KGe=s(cw);_0e=n(KGe,"STRONG",{});var Ujt=s(_0e);rQr=r(Ujt,"t5"),Ujt.forEach(t),tQr=r(KGe," \u2014 "),Dee=n(KGe,"A",{href:!0});var Jjt=s(Dee);aQr=r(Jjt,"FlaxT5ForConditionalGeneration"),Jjt.forEach(t),nQr=r(KGe," (T5 model)"),KGe.forEach(t),je.forEach(t),sQr=i(di),T(fw.$$.fragment,di),di.forEach(t),ii.forEach(t),$Xe=i(f),sf=n(f,"H2",{class:!0});var jQe=s(sf);mw=n(jQe,"A",{id:!0,class:!0,href:!0});var Yjt=s(mw);u0e=n(Yjt,"SPAN",{});var Kjt=s(u0e);T(_$.$$.fragment,Kjt),Kjt.forEach(t),Yjt.forEach(t),lQr=i(jQe),b0e=n(jQe,"SPAN",{});var Zjt=s(b0e);iQr=r(Zjt,"FlaxAutoModelForSequenceClassification"),Zjt.forEach(t),jQe.forEach(t),kXe=i(f),Fr=n(f,"DIV",{class:!0});var ci=s(Fr);T(u$.$$.fragment,ci),dQr=i(ci),lf=n(ci,"P",{});var yte=s(lf);cQr=r(yte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Gee=n(yte,"A",{href:!0});var eDt=s(Gee);fQr=r(eDt,"from_pretrained()"),eDt.forEach(t),mQr=r(yte," class method or the "),Oee=n(yte,"A",{href:!0});var oDt=s(Oee);gQr=r(oDt,"from_config()"),oDt.forEach(t),hQr=r(yte,` class
method.`),yte.forEach(t),pQr=i(ci),b$=n(ci,"P",{});var DQe=s(b$);_Qr=r(DQe,"This class cannot be instantiated directly using "),v0e=n(DQe,"CODE",{});var rDt=s(v0e);uQr=r(rDt,"__init__()"),rDt.forEach(t),bQr=r(DQe," (throws an error)."),DQe.forEach(t),vQr=i(ci),Jt=n(ci,"DIV",{class:!0});var CL=s(Jt);T(v$.$$.fragment,CL),FQr=i(CL),F0e=n(CL,"P",{});var tDt=s(F0e);TQr=r(tDt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),tDt.forEach(t),MQr=i(CL),df=n(CL,"P",{});var xte=s(df);EQr=r(xte,`Note:
Loading a model from its configuration file does `),T0e=n(xte,"STRONG",{});var aDt=s(T0e);CQr=r(aDt,"not"),aDt.forEach(t),wQr=r(xte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=n(xte,"A",{href:!0});var nDt=s(Vee);AQr=r(nDt,"from_pretrained()"),nDt.forEach(t),LQr=r(xte," to load the model weights."),xte.forEach(t),yQr=i(CL),T(gw.$$.fragment,CL),CL.forEach(t),xQr=i(ci),Hr=n(ci,"DIV",{class:!0});var fi=s(Hr);T(F$.$$.fragment,fi),$Qr=i(fi),M0e=n(fi,"P",{});var sDt=s(M0e);kQr=r(sDt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),sDt.forEach(t),SQr=i(fi),An=n(fi,"P",{});var wL=s(An);RQr=r(wL,"The model class to instantiate is selected based on the "),E0e=n(wL,"CODE",{});var lDt=s(E0e);PQr=r(lDt,"model_type"),lDt.forEach(t),BQr=r(wL,` property of the config object (either
passed as an argument or loaded from `),C0e=n(wL,"CODE",{});var iDt=s(C0e);NQr=r(iDt,"pretrained_model_name_or_path"),iDt.forEach(t),IQr=r(wL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w0e=n(wL,"CODE",{});var dDt=s(w0e);qQr=r(dDt,"pretrained_model_name_or_path"),dDt.forEach(t),jQr=r(wL,":"),wL.forEach(t),DQr=i(fi),Se=n(fi,"UL",{});var De=s(Se);hw=n(De,"LI",{});var ZGe=s(hw);A0e=n(ZGe,"STRONG",{});var cDt=s(A0e);GQr=r(cDt,"albert"),cDt.forEach(t),OQr=r(ZGe," \u2014 "),Xee=n(ZGe,"A",{href:!0});var fDt=s(Xee);VQr=r(fDt,"FlaxAlbertForSequenceClassification"),fDt.forEach(t),XQr=r(ZGe," (ALBERT model)"),ZGe.forEach(t),zQr=i(De),pw=n(De,"LI",{});var eOe=s(pw);L0e=n(eOe,"STRONG",{});var mDt=s(L0e);QQr=r(mDt,"bart"),mDt.forEach(t),WQr=r(eOe," \u2014 "),zee=n(eOe,"A",{href:!0});var gDt=s(zee);HQr=r(gDt,"FlaxBartForSequenceClassification"),gDt.forEach(t),UQr=r(eOe," (BART model)"),eOe.forEach(t),JQr=i(De),_w=n(De,"LI",{});var oOe=s(_w);y0e=n(oOe,"STRONG",{});var hDt=s(y0e);YQr=r(hDt,"bert"),hDt.forEach(t),KQr=r(oOe," \u2014 "),Qee=n(oOe,"A",{href:!0});var pDt=s(Qee);ZQr=r(pDt,"FlaxBertForSequenceClassification"),pDt.forEach(t),eWr=r(oOe," (BERT model)"),oOe.forEach(t),oWr=i(De),uw=n(De,"LI",{});var rOe=s(uw);x0e=n(rOe,"STRONG",{});var _Dt=s(x0e);rWr=r(_Dt,"big_bird"),_Dt.forEach(t),tWr=r(rOe," \u2014 "),Wee=n(rOe,"A",{href:!0});var uDt=s(Wee);aWr=r(uDt,"FlaxBigBirdForSequenceClassification"),uDt.forEach(t),nWr=r(rOe," (BigBird model)"),rOe.forEach(t),sWr=i(De),bw=n(De,"LI",{});var tOe=s(bw);$0e=n(tOe,"STRONG",{});var bDt=s($0e);lWr=r(bDt,"distilbert"),bDt.forEach(t),iWr=r(tOe," \u2014 "),Hee=n(tOe,"A",{href:!0});var vDt=s(Hee);dWr=r(vDt,"FlaxDistilBertForSequenceClassification"),vDt.forEach(t),cWr=r(tOe," (DistilBERT model)"),tOe.forEach(t),fWr=i(De),vw=n(De,"LI",{});var aOe=s(vw);k0e=n(aOe,"STRONG",{});var FDt=s(k0e);mWr=r(FDt,"electra"),FDt.forEach(t),gWr=r(aOe," \u2014 "),Uee=n(aOe,"A",{href:!0});var TDt=s(Uee);hWr=r(TDt,"FlaxElectraForSequenceClassification"),TDt.forEach(t),pWr=r(aOe," (ELECTRA model)"),aOe.forEach(t),_Wr=i(De),Fw=n(De,"LI",{});var nOe=s(Fw);S0e=n(nOe,"STRONG",{});var MDt=s(S0e);uWr=r(MDt,"mbart"),MDt.forEach(t),bWr=r(nOe," \u2014 "),Jee=n(nOe,"A",{href:!0});var EDt=s(Jee);vWr=r(EDt,"FlaxMBartForSequenceClassification"),EDt.forEach(t),FWr=r(nOe," (mBART model)"),nOe.forEach(t),TWr=i(De),Tw=n(De,"LI",{});var sOe=s(Tw);R0e=n(sOe,"STRONG",{});var CDt=s(R0e);MWr=r(CDt,"roberta"),CDt.forEach(t),EWr=r(sOe," \u2014 "),Yee=n(sOe,"A",{href:!0});var wDt=s(Yee);CWr=r(wDt,"FlaxRobertaForSequenceClassification"),wDt.forEach(t),wWr=r(sOe," (RoBERTa model)"),sOe.forEach(t),AWr=i(De),Mw=n(De,"LI",{});var lOe=s(Mw);P0e=n(lOe,"STRONG",{});var ADt=s(P0e);LWr=r(ADt,"roformer"),ADt.forEach(t),yWr=r(lOe," \u2014 "),Kee=n(lOe,"A",{href:!0});var LDt=s(Kee);xWr=r(LDt,"FlaxRoFormerForSequenceClassification"),LDt.forEach(t),$Wr=r(lOe," (RoFormer model)"),lOe.forEach(t),kWr=i(De),Ew=n(De,"LI",{});var iOe=s(Ew);B0e=n(iOe,"STRONG",{});var yDt=s(B0e);SWr=r(yDt,"xlm-roberta"),yDt.forEach(t),RWr=r(iOe," \u2014 "),Zee=n(iOe,"A",{href:!0});var xDt=s(Zee);PWr=r(xDt,"FlaxXLMRobertaForSequenceClassification"),xDt.forEach(t),BWr=r(iOe," (XLM-RoBERTa model)"),iOe.forEach(t),De.forEach(t),NWr=i(fi),T(Cw.$$.fragment,fi),fi.forEach(t),ci.forEach(t),SXe=i(f),cf=n(f,"H2",{class:!0});var GQe=s(cf);ww=n(GQe,"A",{id:!0,class:!0,href:!0});var $Dt=s(ww);N0e=n($Dt,"SPAN",{});var kDt=s(N0e);T(T$.$$.fragment,kDt),kDt.forEach(t),$Dt.forEach(t),IWr=i(GQe),I0e=n(GQe,"SPAN",{});var SDt=s(I0e);qWr=r(SDt,"FlaxAutoModelForQuestionAnswering"),SDt.forEach(t),GQe.forEach(t),RXe=i(f),Tr=n(f,"DIV",{class:!0});var mi=s(Tr);T(M$.$$.fragment,mi),jWr=i(mi),ff=n(mi,"P",{});var $te=s(ff);DWr=r($te,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),eoe=n($te,"A",{href:!0});var RDt=s(eoe);GWr=r(RDt,"from_pretrained()"),RDt.forEach(t),OWr=r($te," class method or the "),ooe=n($te,"A",{href:!0});var PDt=s(ooe);VWr=r(PDt,"from_config()"),PDt.forEach(t),XWr=r($te,` class
method.`),$te.forEach(t),zWr=i(mi),E$=n(mi,"P",{});var OQe=s(E$);QWr=r(OQe,"This class cannot be instantiated directly using "),q0e=n(OQe,"CODE",{});var BDt=s(q0e);WWr=r(BDt,"__init__()"),BDt.forEach(t),HWr=r(OQe," (throws an error)."),OQe.forEach(t),UWr=i(mi),Yt=n(mi,"DIV",{class:!0});var AL=s(Yt);T(C$.$$.fragment,AL),JWr=i(AL),j0e=n(AL,"P",{});var NDt=s(j0e);YWr=r(NDt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),NDt.forEach(t),KWr=i(AL),mf=n(AL,"P",{});var kte=s(mf);ZWr=r(kte,`Note:
Loading a model from its configuration file does `),D0e=n(kte,"STRONG",{});var IDt=s(D0e);eHr=r(IDt,"not"),IDt.forEach(t),oHr=r(kte,` load the model weights. It only affects the
model\u2019s configuration. Use `),roe=n(kte,"A",{href:!0});var qDt=s(roe);rHr=r(qDt,"from_pretrained()"),qDt.forEach(t),tHr=r(kte," to load the model weights."),kte.forEach(t),aHr=i(AL),T(Aw.$$.fragment,AL),AL.forEach(t),nHr=i(mi),Ur=n(mi,"DIV",{class:!0});var gi=s(Ur);T(w$.$$.fragment,gi),sHr=i(gi),G0e=n(gi,"P",{});var jDt=s(G0e);lHr=r(jDt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),jDt.forEach(t),iHr=i(gi),Ln=n(gi,"P",{});var LL=s(Ln);dHr=r(LL,"The model class to instantiate is selected based on the "),O0e=n(LL,"CODE",{});var DDt=s(O0e);cHr=r(DDt,"model_type"),DDt.forEach(t),fHr=r(LL,` property of the config object (either
passed as an argument or loaded from `),V0e=n(LL,"CODE",{});var GDt=s(V0e);mHr=r(GDt,"pretrained_model_name_or_path"),GDt.forEach(t),gHr=r(LL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X0e=n(LL,"CODE",{});var ODt=s(X0e);hHr=r(ODt,"pretrained_model_name_or_path"),ODt.forEach(t),pHr=r(LL,":"),LL.forEach(t),_Hr=i(gi),Re=n(gi,"UL",{});var Ge=s(Re);Lw=n(Ge,"LI",{});var dOe=s(Lw);z0e=n(dOe,"STRONG",{});var VDt=s(z0e);uHr=r(VDt,"albert"),VDt.forEach(t),bHr=r(dOe," \u2014 "),toe=n(dOe,"A",{href:!0});var XDt=s(toe);vHr=r(XDt,"FlaxAlbertForQuestionAnswering"),XDt.forEach(t),FHr=r(dOe," (ALBERT model)"),dOe.forEach(t),THr=i(Ge),yw=n(Ge,"LI",{});var cOe=s(yw);Q0e=n(cOe,"STRONG",{});var zDt=s(Q0e);MHr=r(zDt,"bart"),zDt.forEach(t),EHr=r(cOe," \u2014 "),aoe=n(cOe,"A",{href:!0});var QDt=s(aoe);CHr=r(QDt,"FlaxBartForQuestionAnswering"),QDt.forEach(t),wHr=r(cOe," (BART model)"),cOe.forEach(t),AHr=i(Ge),xw=n(Ge,"LI",{});var fOe=s(xw);W0e=n(fOe,"STRONG",{});var WDt=s(W0e);LHr=r(WDt,"bert"),WDt.forEach(t),yHr=r(fOe," \u2014 "),noe=n(fOe,"A",{href:!0});var HDt=s(noe);xHr=r(HDt,"FlaxBertForQuestionAnswering"),HDt.forEach(t),$Hr=r(fOe," (BERT model)"),fOe.forEach(t),kHr=i(Ge),$w=n(Ge,"LI",{});var mOe=s($w);H0e=n(mOe,"STRONG",{});var UDt=s(H0e);SHr=r(UDt,"big_bird"),UDt.forEach(t),RHr=r(mOe," \u2014 "),soe=n(mOe,"A",{href:!0});var JDt=s(soe);PHr=r(JDt,"FlaxBigBirdForQuestionAnswering"),JDt.forEach(t),BHr=r(mOe," (BigBird model)"),mOe.forEach(t),NHr=i(Ge),kw=n(Ge,"LI",{});var gOe=s(kw);U0e=n(gOe,"STRONG",{});var YDt=s(U0e);IHr=r(YDt,"distilbert"),YDt.forEach(t),qHr=r(gOe," \u2014 "),loe=n(gOe,"A",{href:!0});var KDt=s(loe);jHr=r(KDt,"FlaxDistilBertForQuestionAnswering"),KDt.forEach(t),DHr=r(gOe," (DistilBERT model)"),gOe.forEach(t),GHr=i(Ge),Sw=n(Ge,"LI",{});var hOe=s(Sw);J0e=n(hOe,"STRONG",{});var ZDt=s(J0e);OHr=r(ZDt,"electra"),ZDt.forEach(t),VHr=r(hOe," \u2014 "),ioe=n(hOe,"A",{href:!0});var eGt=s(ioe);XHr=r(eGt,"FlaxElectraForQuestionAnswering"),eGt.forEach(t),zHr=r(hOe," (ELECTRA model)"),hOe.forEach(t),QHr=i(Ge),Rw=n(Ge,"LI",{});var pOe=s(Rw);Y0e=n(pOe,"STRONG",{});var oGt=s(Y0e);WHr=r(oGt,"mbart"),oGt.forEach(t),HHr=r(pOe," \u2014 "),doe=n(pOe,"A",{href:!0});var rGt=s(doe);UHr=r(rGt,"FlaxMBartForQuestionAnswering"),rGt.forEach(t),JHr=r(pOe," (mBART model)"),pOe.forEach(t),YHr=i(Ge),Pw=n(Ge,"LI",{});var _Oe=s(Pw);K0e=n(_Oe,"STRONG",{});var tGt=s(K0e);KHr=r(tGt,"roberta"),tGt.forEach(t),ZHr=r(_Oe," \u2014 "),coe=n(_Oe,"A",{href:!0});var aGt=s(coe);eUr=r(aGt,"FlaxRobertaForQuestionAnswering"),aGt.forEach(t),oUr=r(_Oe," (RoBERTa model)"),_Oe.forEach(t),rUr=i(Ge),Bw=n(Ge,"LI",{});var uOe=s(Bw);Z0e=n(uOe,"STRONG",{});var nGt=s(Z0e);tUr=r(nGt,"roformer"),nGt.forEach(t),aUr=r(uOe," \u2014 "),foe=n(uOe,"A",{href:!0});var sGt=s(foe);nUr=r(sGt,"FlaxRoFormerForQuestionAnswering"),sGt.forEach(t),sUr=r(uOe," (RoFormer model)"),uOe.forEach(t),lUr=i(Ge),Nw=n(Ge,"LI",{});var bOe=s(Nw);ewe=n(bOe,"STRONG",{});var lGt=s(ewe);iUr=r(lGt,"xlm-roberta"),lGt.forEach(t),dUr=r(bOe," \u2014 "),moe=n(bOe,"A",{href:!0});var iGt=s(moe);cUr=r(iGt,"FlaxXLMRobertaForQuestionAnswering"),iGt.forEach(t),fUr=r(bOe," (XLM-RoBERTa model)"),bOe.forEach(t),Ge.forEach(t),mUr=i(gi),T(Iw.$$.fragment,gi),gi.forEach(t),mi.forEach(t),PXe=i(f),gf=n(f,"H2",{class:!0});var VQe=s(gf);qw=n(VQe,"A",{id:!0,class:!0,href:!0});var dGt=s(qw);owe=n(dGt,"SPAN",{});var cGt=s(owe);T(A$.$$.fragment,cGt),cGt.forEach(t),dGt.forEach(t),gUr=i(VQe),rwe=n(VQe,"SPAN",{});var fGt=s(rwe);hUr=r(fGt,"FlaxAutoModelForTokenClassification"),fGt.forEach(t),VQe.forEach(t),BXe=i(f),Mr=n(f,"DIV",{class:!0});var hi=s(Mr);T(L$.$$.fragment,hi),pUr=i(hi),hf=n(hi,"P",{});var Ste=s(hf);_Ur=r(Ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),goe=n(Ste,"A",{href:!0});var mGt=s(goe);uUr=r(mGt,"from_pretrained()"),mGt.forEach(t),bUr=r(Ste," class method or the "),hoe=n(Ste,"A",{href:!0});var gGt=s(hoe);vUr=r(gGt,"from_config()"),gGt.forEach(t),FUr=r(Ste,` class
method.`),Ste.forEach(t),TUr=i(hi),y$=n(hi,"P",{});var XQe=s(y$);MUr=r(XQe,"This class cannot be instantiated directly using "),twe=n(XQe,"CODE",{});var hGt=s(twe);EUr=r(hGt,"__init__()"),hGt.forEach(t),CUr=r(XQe," (throws an error)."),XQe.forEach(t),wUr=i(hi),Kt=n(hi,"DIV",{class:!0});var yL=s(Kt);T(x$.$$.fragment,yL),AUr=i(yL),awe=n(yL,"P",{});var pGt=s(awe);LUr=r(pGt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),pGt.forEach(t),yUr=i(yL),pf=n(yL,"P",{});var Rte=s(pf);xUr=r(Rte,`Note:
Loading a model from its configuration file does `),nwe=n(Rte,"STRONG",{});var _Gt=s(nwe);$Ur=r(_Gt,"not"),_Gt.forEach(t),kUr=r(Rte,` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=n(Rte,"A",{href:!0});var uGt=s(poe);SUr=r(uGt,"from_pretrained()"),uGt.forEach(t),RUr=r(Rte," to load the model weights."),Rte.forEach(t),PUr=i(yL),T(jw.$$.fragment,yL),yL.forEach(t),BUr=i(hi),Jr=n(hi,"DIV",{class:!0});var pi=s(Jr);T($$.$$.fragment,pi),NUr=i(pi),swe=n(pi,"P",{});var bGt=s(swe);IUr=r(bGt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),bGt.forEach(t),qUr=i(pi),yn=n(pi,"P",{});var xL=s(yn);jUr=r(xL,"The model class to instantiate is selected based on the "),lwe=n(xL,"CODE",{});var vGt=s(lwe);DUr=r(vGt,"model_type"),vGt.forEach(t),GUr=r(xL,` property of the config object (either
passed as an argument or loaded from `),iwe=n(xL,"CODE",{});var FGt=s(iwe);OUr=r(FGt,"pretrained_model_name_or_path"),FGt.forEach(t),VUr=r(xL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dwe=n(xL,"CODE",{});var TGt=s(dwe);XUr=r(TGt,"pretrained_model_name_or_path"),TGt.forEach(t),zUr=r(xL,":"),xL.forEach(t),QUr=i(pi),Ve=n(pi,"UL",{});var To=s(Ve);Dw=n(To,"LI",{});var vOe=s(Dw);cwe=n(vOe,"STRONG",{});var MGt=s(cwe);WUr=r(MGt,"albert"),MGt.forEach(t),HUr=r(vOe," \u2014 "),_oe=n(vOe,"A",{href:!0});var EGt=s(_oe);UUr=r(EGt,"FlaxAlbertForTokenClassification"),EGt.forEach(t),JUr=r(vOe," (ALBERT model)"),vOe.forEach(t),YUr=i(To),Gw=n(To,"LI",{});var FOe=s(Gw);fwe=n(FOe,"STRONG",{});var CGt=s(fwe);KUr=r(CGt,"bert"),CGt.forEach(t),ZUr=r(FOe," \u2014 "),uoe=n(FOe,"A",{href:!0});var wGt=s(uoe);eJr=r(wGt,"FlaxBertForTokenClassification"),wGt.forEach(t),oJr=r(FOe," (BERT model)"),FOe.forEach(t),rJr=i(To),Ow=n(To,"LI",{});var TOe=s(Ow);mwe=n(TOe,"STRONG",{});var AGt=s(mwe);tJr=r(AGt,"big_bird"),AGt.forEach(t),aJr=r(TOe," \u2014 "),boe=n(TOe,"A",{href:!0});var LGt=s(boe);nJr=r(LGt,"FlaxBigBirdForTokenClassification"),LGt.forEach(t),sJr=r(TOe," (BigBird model)"),TOe.forEach(t),lJr=i(To),Vw=n(To,"LI",{});var MOe=s(Vw);gwe=n(MOe,"STRONG",{});var yGt=s(gwe);iJr=r(yGt,"distilbert"),yGt.forEach(t),dJr=r(MOe," \u2014 "),voe=n(MOe,"A",{href:!0});var xGt=s(voe);cJr=r(xGt,"FlaxDistilBertForTokenClassification"),xGt.forEach(t),fJr=r(MOe," (DistilBERT model)"),MOe.forEach(t),mJr=i(To),Xw=n(To,"LI",{});var EOe=s(Xw);hwe=n(EOe,"STRONG",{});var $Gt=s(hwe);gJr=r($Gt,"electra"),$Gt.forEach(t),hJr=r(EOe," \u2014 "),Foe=n(EOe,"A",{href:!0});var kGt=s(Foe);pJr=r(kGt,"FlaxElectraForTokenClassification"),kGt.forEach(t),_Jr=r(EOe," (ELECTRA model)"),EOe.forEach(t),uJr=i(To),zw=n(To,"LI",{});var COe=s(zw);pwe=n(COe,"STRONG",{});var SGt=s(pwe);bJr=r(SGt,"roberta"),SGt.forEach(t),vJr=r(COe," \u2014 "),Toe=n(COe,"A",{href:!0});var RGt=s(Toe);FJr=r(RGt,"FlaxRobertaForTokenClassification"),RGt.forEach(t),TJr=r(COe," (RoBERTa model)"),COe.forEach(t),MJr=i(To),Qw=n(To,"LI",{});var wOe=s(Qw);_we=n(wOe,"STRONG",{});var PGt=s(_we);EJr=r(PGt,"roformer"),PGt.forEach(t),CJr=r(wOe," \u2014 "),Moe=n(wOe,"A",{href:!0});var BGt=s(Moe);wJr=r(BGt,"FlaxRoFormerForTokenClassification"),BGt.forEach(t),AJr=r(wOe," (RoFormer model)"),wOe.forEach(t),LJr=i(To),Ww=n(To,"LI",{});var AOe=s(Ww);uwe=n(AOe,"STRONG",{});var NGt=s(uwe);yJr=r(NGt,"xlm-roberta"),NGt.forEach(t),xJr=r(AOe," \u2014 "),Eoe=n(AOe,"A",{href:!0});var IGt=s(Eoe);$Jr=r(IGt,"FlaxXLMRobertaForTokenClassification"),IGt.forEach(t),kJr=r(AOe," (XLM-RoBERTa model)"),AOe.forEach(t),To.forEach(t),SJr=i(pi),T(Hw.$$.fragment,pi),pi.forEach(t),hi.forEach(t),NXe=i(f),_f=n(f,"H2",{class:!0});var zQe=s(_f);Uw=n(zQe,"A",{id:!0,class:!0,href:!0});var qGt=s(Uw);bwe=n(qGt,"SPAN",{});var jGt=s(bwe);T(k$.$$.fragment,jGt),jGt.forEach(t),qGt.forEach(t),RJr=i(zQe),vwe=n(zQe,"SPAN",{});var DGt=s(vwe);PJr=r(DGt,"FlaxAutoModelForMultipleChoice"),DGt.forEach(t),zQe.forEach(t),IXe=i(f),Er=n(f,"DIV",{class:!0});var _i=s(Er);T(S$.$$.fragment,_i),BJr=i(_i),uf=n(_i,"P",{});var Pte=s(uf);NJr=r(Pte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Coe=n(Pte,"A",{href:!0});var GGt=s(Coe);IJr=r(GGt,"from_pretrained()"),GGt.forEach(t),qJr=r(Pte," class method or the "),woe=n(Pte,"A",{href:!0});var OGt=s(woe);jJr=r(OGt,"from_config()"),OGt.forEach(t),DJr=r(Pte,` class
method.`),Pte.forEach(t),GJr=i(_i),R$=n(_i,"P",{});var QQe=s(R$);OJr=r(QQe,"This class cannot be instantiated directly using "),Fwe=n(QQe,"CODE",{});var VGt=s(Fwe);VJr=r(VGt,"__init__()"),VGt.forEach(t),XJr=r(QQe," (throws an error)."),QQe.forEach(t),zJr=i(_i),Zt=n(_i,"DIV",{class:!0});var $L=s(Zt);T(P$.$$.fragment,$L),QJr=i($L),Twe=n($L,"P",{});var XGt=s(Twe);WJr=r(XGt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),XGt.forEach(t),HJr=i($L),bf=n($L,"P",{});var Bte=s(bf);UJr=r(Bte,`Note:
Loading a model from its configuration file does `),Mwe=n(Bte,"STRONG",{});var zGt=s(Mwe);JJr=r(zGt,"not"),zGt.forEach(t),YJr=r(Bte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aoe=n(Bte,"A",{href:!0});var QGt=s(Aoe);KJr=r(QGt,"from_pretrained()"),QGt.forEach(t),ZJr=r(Bte," to load the model weights."),Bte.forEach(t),eYr=i($L),T(Jw.$$.fragment,$L),$L.forEach(t),oYr=i(_i),Yr=n(_i,"DIV",{class:!0});var ui=s(Yr);T(B$.$$.fragment,ui),rYr=i(ui),Ewe=n(ui,"P",{});var WGt=s(Ewe);tYr=r(WGt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),WGt.forEach(t),aYr=i(ui),xn=n(ui,"P",{});var kL=s(xn);nYr=r(kL,"The model class to instantiate is selected based on the "),Cwe=n(kL,"CODE",{});var HGt=s(Cwe);sYr=r(HGt,"model_type"),HGt.forEach(t),lYr=r(kL,` property of the config object (either
passed as an argument or loaded from `),wwe=n(kL,"CODE",{});var UGt=s(wwe);iYr=r(UGt,"pretrained_model_name_or_path"),UGt.forEach(t),dYr=r(kL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Awe=n(kL,"CODE",{});var JGt=s(Awe);cYr=r(JGt,"pretrained_model_name_or_path"),JGt.forEach(t),fYr=r(kL,":"),kL.forEach(t),mYr=i(ui),Xe=n(ui,"UL",{});var Mo=s(Xe);Yw=n(Mo,"LI",{});var LOe=s(Yw);Lwe=n(LOe,"STRONG",{});var YGt=s(Lwe);gYr=r(YGt,"albert"),YGt.forEach(t),hYr=r(LOe," \u2014 "),Loe=n(LOe,"A",{href:!0});var KGt=s(Loe);pYr=r(KGt,"FlaxAlbertForMultipleChoice"),KGt.forEach(t),_Yr=r(LOe," (ALBERT model)"),LOe.forEach(t),uYr=i(Mo),Kw=n(Mo,"LI",{});var yOe=s(Kw);ywe=n(yOe,"STRONG",{});var ZGt=s(ywe);bYr=r(ZGt,"bert"),ZGt.forEach(t),vYr=r(yOe," \u2014 "),yoe=n(yOe,"A",{href:!0});var eOt=s(yoe);FYr=r(eOt,"FlaxBertForMultipleChoice"),eOt.forEach(t),TYr=r(yOe," (BERT model)"),yOe.forEach(t),MYr=i(Mo),Zw=n(Mo,"LI",{});var xOe=s(Zw);xwe=n(xOe,"STRONG",{});var oOt=s(xwe);EYr=r(oOt,"big_bird"),oOt.forEach(t),CYr=r(xOe," \u2014 "),xoe=n(xOe,"A",{href:!0});var rOt=s(xoe);wYr=r(rOt,"FlaxBigBirdForMultipleChoice"),rOt.forEach(t),AYr=r(xOe," (BigBird model)"),xOe.forEach(t),LYr=i(Mo),eA=n(Mo,"LI",{});var $Oe=s(eA);$we=n($Oe,"STRONG",{});var tOt=s($we);yYr=r(tOt,"distilbert"),tOt.forEach(t),xYr=r($Oe," \u2014 "),$oe=n($Oe,"A",{href:!0});var aOt=s($oe);$Yr=r(aOt,"FlaxDistilBertForMultipleChoice"),aOt.forEach(t),kYr=r($Oe," (DistilBERT model)"),$Oe.forEach(t),SYr=i(Mo),oA=n(Mo,"LI",{});var kOe=s(oA);kwe=n(kOe,"STRONG",{});var nOt=s(kwe);RYr=r(nOt,"electra"),nOt.forEach(t),PYr=r(kOe," \u2014 "),koe=n(kOe,"A",{href:!0});var sOt=s(koe);BYr=r(sOt,"FlaxElectraForMultipleChoice"),sOt.forEach(t),NYr=r(kOe," (ELECTRA model)"),kOe.forEach(t),IYr=i(Mo),rA=n(Mo,"LI",{});var SOe=s(rA);Swe=n(SOe,"STRONG",{});var lOt=s(Swe);qYr=r(lOt,"roberta"),lOt.forEach(t),jYr=r(SOe," \u2014 "),Soe=n(SOe,"A",{href:!0});var iOt=s(Soe);DYr=r(iOt,"FlaxRobertaForMultipleChoice"),iOt.forEach(t),GYr=r(SOe," (RoBERTa model)"),SOe.forEach(t),OYr=i(Mo),tA=n(Mo,"LI",{});var ROe=s(tA);Rwe=n(ROe,"STRONG",{});var dOt=s(Rwe);VYr=r(dOt,"roformer"),dOt.forEach(t),XYr=r(ROe," \u2014 "),Roe=n(ROe,"A",{href:!0});var cOt=s(Roe);zYr=r(cOt,"FlaxRoFormerForMultipleChoice"),cOt.forEach(t),QYr=r(ROe," (RoFormer model)"),ROe.forEach(t),WYr=i(Mo),aA=n(Mo,"LI",{});var POe=s(aA);Pwe=n(POe,"STRONG",{});var fOt=s(Pwe);HYr=r(fOt,"xlm-roberta"),fOt.forEach(t),UYr=r(POe," \u2014 "),Poe=n(POe,"A",{href:!0});var mOt=s(Poe);JYr=r(mOt,"FlaxXLMRobertaForMultipleChoice"),mOt.forEach(t),YYr=r(POe," (XLM-RoBERTa model)"),POe.forEach(t),Mo.forEach(t),KYr=i(ui),T(nA.$$.fragment,ui),ui.forEach(t),_i.forEach(t),qXe=i(f),vf=n(f,"H2",{class:!0});var WQe=s(vf);sA=n(WQe,"A",{id:!0,class:!0,href:!0});var gOt=s(sA);Bwe=n(gOt,"SPAN",{});var hOt=s(Bwe);T(N$.$$.fragment,hOt),hOt.forEach(t),gOt.forEach(t),ZYr=i(WQe),Nwe=n(WQe,"SPAN",{});var pOt=s(Nwe);eKr=r(pOt,"FlaxAutoModelForNextSentencePrediction"),pOt.forEach(t),WQe.forEach(t),jXe=i(f),Cr=n(f,"DIV",{class:!0});var bi=s(Cr);T(I$.$$.fragment,bi),oKr=i(bi),Ff=n(bi,"P",{});var Nte=s(Ff);rKr=r(Nte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Boe=n(Nte,"A",{href:!0});var _Ot=s(Boe);tKr=r(_Ot,"from_pretrained()"),_Ot.forEach(t),aKr=r(Nte," class method or the "),Noe=n(Nte,"A",{href:!0});var uOt=s(Noe);nKr=r(uOt,"from_config()"),uOt.forEach(t),sKr=r(Nte,` class
method.`),Nte.forEach(t),lKr=i(bi),q$=n(bi,"P",{});var HQe=s(q$);iKr=r(HQe,"This class cannot be instantiated directly using "),Iwe=n(HQe,"CODE",{});var bOt=s(Iwe);dKr=r(bOt,"__init__()"),bOt.forEach(t),cKr=r(HQe," (throws an error)."),HQe.forEach(t),fKr=i(bi),ea=n(bi,"DIV",{class:!0});var SL=s(ea);T(j$.$$.fragment,SL),mKr=i(SL),qwe=n(SL,"P",{});var vOt=s(qwe);gKr=r(vOt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),vOt.forEach(t),hKr=i(SL),Tf=n(SL,"P",{});var Ite=s(Tf);pKr=r(Ite,`Note:
Loading a model from its configuration file does `),jwe=n(Ite,"STRONG",{});var FOt=s(jwe);_Kr=r(FOt,"not"),FOt.forEach(t),uKr=r(Ite,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ioe=n(Ite,"A",{href:!0});var TOt=s(Ioe);bKr=r(TOt,"from_pretrained()"),TOt.forEach(t),vKr=r(Ite," to load the model weights."),Ite.forEach(t),FKr=i(SL),T(lA.$$.fragment,SL),SL.forEach(t),TKr=i(bi),Kr=n(bi,"DIV",{class:!0});var vi=s(Kr);T(D$.$$.fragment,vi),MKr=i(vi),Dwe=n(vi,"P",{});var MOt=s(Dwe);EKr=r(MOt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),MOt.forEach(t),CKr=i(vi),$n=n(vi,"P",{});var RL=s($n);wKr=r(RL,"The model class to instantiate is selected based on the "),Gwe=n(RL,"CODE",{});var EOt=s(Gwe);AKr=r(EOt,"model_type"),EOt.forEach(t),LKr=r(RL,` property of the config object (either
passed as an argument or loaded from `),Owe=n(RL,"CODE",{});var COt=s(Owe);yKr=r(COt,"pretrained_model_name_or_path"),COt.forEach(t),xKr=r(RL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vwe=n(RL,"CODE",{});var wOt=s(Vwe);$Kr=r(wOt,"pretrained_model_name_or_path"),wOt.forEach(t),kKr=r(RL,":"),RL.forEach(t),SKr=i(vi),Xwe=n(vi,"UL",{});var AOt=s(Xwe);iA=n(AOt,"LI",{});var BOe=s(iA);zwe=n(BOe,"STRONG",{});var LOt=s(zwe);RKr=r(LOt,"bert"),LOt.forEach(t),PKr=r(BOe," \u2014 "),qoe=n(BOe,"A",{href:!0});var yOt=s(qoe);BKr=r(yOt,"FlaxBertForNextSentencePrediction"),yOt.forEach(t),NKr=r(BOe," (BERT model)"),BOe.forEach(t),AOt.forEach(t),IKr=i(vi),T(dA.$$.fragment,vi),vi.forEach(t),bi.forEach(t),DXe=i(f),Mf=n(f,"H2",{class:!0});var UQe=s(Mf);cA=n(UQe,"A",{id:!0,class:!0,href:!0});var xOt=s(cA);Qwe=n(xOt,"SPAN",{});var $Ot=s(Qwe);T(G$.$$.fragment,$Ot),$Ot.forEach(t),xOt.forEach(t),qKr=i(UQe),Wwe=n(UQe,"SPAN",{});var kOt=s(Wwe);jKr=r(kOt,"FlaxAutoModelForImageClassification"),kOt.forEach(t),UQe.forEach(t),GXe=i(f),wr=n(f,"DIV",{class:!0});var Fi=s(wr);T(O$.$$.fragment,Fi),DKr=i(Fi),Ef=n(Fi,"P",{});var qte=s(Ef);GKr=r(qte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),joe=n(qte,"A",{href:!0});var SOt=s(joe);OKr=r(SOt,"from_pretrained()"),SOt.forEach(t),VKr=r(qte," class method or the "),Doe=n(qte,"A",{href:!0});var ROt=s(Doe);XKr=r(ROt,"from_config()"),ROt.forEach(t),zKr=r(qte,` class
method.`),qte.forEach(t),QKr=i(Fi),V$=n(Fi,"P",{});var JQe=s(V$);WKr=r(JQe,"This class cannot be instantiated directly using "),Hwe=n(JQe,"CODE",{});var POt=s(Hwe);HKr=r(POt,"__init__()"),POt.forEach(t),UKr=r(JQe," (throws an error)."),JQe.forEach(t),JKr=i(Fi),oa=n(Fi,"DIV",{class:!0});var PL=s(oa);T(X$.$$.fragment,PL),YKr=i(PL),Uwe=n(PL,"P",{});var BOt=s(Uwe);KKr=r(BOt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),BOt.forEach(t),ZKr=i(PL),Cf=n(PL,"P",{});var jte=s(Cf);eZr=r(jte,`Note:
Loading a model from its configuration file does `),Jwe=n(jte,"STRONG",{});var NOt=s(Jwe);oZr=r(NOt,"not"),NOt.forEach(t),rZr=r(jte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Goe=n(jte,"A",{href:!0});var IOt=s(Goe);tZr=r(IOt,"from_pretrained()"),IOt.forEach(t),aZr=r(jte," to load the model weights."),jte.forEach(t),nZr=i(PL),T(fA.$$.fragment,PL),PL.forEach(t),sZr=i(Fi),Zr=n(Fi,"DIV",{class:!0});var Ti=s(Zr);T(z$.$$.fragment,Ti),lZr=i(Ti),Ywe=n(Ti,"P",{});var qOt=s(Ywe);iZr=r(qOt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),qOt.forEach(t),dZr=i(Ti),kn=n(Ti,"P",{});var BL=s(kn);cZr=r(BL,"The model class to instantiate is selected based on the "),Kwe=n(BL,"CODE",{});var jOt=s(Kwe);fZr=r(jOt,"model_type"),jOt.forEach(t),mZr=r(BL,` property of the config object (either
passed as an argument or loaded from `),Zwe=n(BL,"CODE",{});var DOt=s(Zwe);gZr=r(DOt,"pretrained_model_name_or_path"),DOt.forEach(t),hZr=r(BL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eAe=n(BL,"CODE",{});var GOt=s(eAe);pZr=r(GOt,"pretrained_model_name_or_path"),GOt.forEach(t),_Zr=r(BL,":"),BL.forEach(t),uZr=i(Ti),Q$=n(Ti,"UL",{});var YQe=s(Q$);mA=n(YQe,"LI",{});var NOe=s(mA);oAe=n(NOe,"STRONG",{});var OOt=s(oAe);bZr=r(OOt,"beit"),OOt.forEach(t),vZr=r(NOe," \u2014 "),Ooe=n(NOe,"A",{href:!0});var VOt=s(Ooe);FZr=r(VOt,"FlaxBeitForImageClassification"),VOt.forEach(t),TZr=r(NOe," (BEiT model)"),NOe.forEach(t),MZr=i(YQe),gA=n(YQe,"LI",{});var IOe=s(gA);rAe=n(IOe,"STRONG",{});var XOt=s(rAe);EZr=r(XOt,"vit"),XOt.forEach(t),CZr=r(IOe," \u2014 "),Voe=n(IOe,"A",{href:!0});var zOt=s(Voe);wZr=r(zOt,"FlaxViTForImageClassification"),zOt.forEach(t),AZr=r(IOe," (ViT model)"),IOe.forEach(t),YQe.forEach(t),LZr=i(Ti),T(hA.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),OXe=i(f),wf=n(f,"H2",{class:!0});var KQe=s(wf);pA=n(KQe,"A",{id:!0,class:!0,href:!0});var QOt=s(pA);tAe=n(QOt,"SPAN",{});var WOt=s(tAe);T(W$.$$.fragment,WOt),WOt.forEach(t),QOt.forEach(t),yZr=i(KQe),aAe=n(KQe,"SPAN",{});var HOt=s(aAe);xZr=r(HOt,"FlaxAutoModelForVision2Seq"),HOt.forEach(t),KQe.forEach(t),VXe=i(f),Ar=n(f,"DIV",{class:!0});var Mi=s(Ar);T(H$.$$.fragment,Mi),$Zr=i(Mi),Af=n(Mi,"P",{});var Dte=s(Af);kZr=r(Dte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Xoe=n(Dte,"A",{href:!0});var UOt=s(Xoe);SZr=r(UOt,"from_pretrained()"),UOt.forEach(t),RZr=r(Dte," class method or the "),zoe=n(Dte,"A",{href:!0});var JOt=s(zoe);PZr=r(JOt,"from_config()"),JOt.forEach(t),BZr=r(Dte,` class
method.`),Dte.forEach(t),NZr=i(Mi),U$=n(Mi,"P",{});var ZQe=s(U$);IZr=r(ZQe,"This class cannot be instantiated directly using "),nAe=n(ZQe,"CODE",{});var YOt=s(nAe);qZr=r(YOt,"__init__()"),YOt.forEach(t),jZr=r(ZQe," (throws an error)."),ZQe.forEach(t),DZr=i(Mi),ra=n(Mi,"DIV",{class:!0});var NL=s(ra);T(J$.$$.fragment,NL),GZr=i(NL),sAe=n(NL,"P",{});var KOt=s(sAe);OZr=r(KOt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),KOt.forEach(t),VZr=i(NL),Lf=n(NL,"P",{});var Gte=s(Lf);XZr=r(Gte,`Note:
Loading a model from its configuration file does `),lAe=n(Gte,"STRONG",{});var ZOt=s(lAe);zZr=r(ZOt,"not"),ZOt.forEach(t),QZr=r(Gte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qoe=n(Gte,"A",{href:!0});var eVt=s(Qoe);WZr=r(eVt,"from_pretrained()"),eVt.forEach(t),HZr=r(Gte," to load the model weights."),Gte.forEach(t),UZr=i(NL),T(_A.$$.fragment,NL),NL.forEach(t),JZr=i(Mi),et=n(Mi,"DIV",{class:!0});var Ei=s(et);T(Y$.$$.fragment,Ei),YZr=i(Ei),iAe=n(Ei,"P",{});var oVt=s(iAe);KZr=r(oVt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),oVt.forEach(t),ZZr=i(Ei),Sn=n(Ei,"P",{});var IL=s(Sn);eet=r(IL,"The model class to instantiate is selected based on the "),dAe=n(IL,"CODE",{});var rVt=s(dAe);oet=r(rVt,"model_type"),rVt.forEach(t),ret=r(IL,` property of the config object (either
passed as an argument or loaded from `),cAe=n(IL,"CODE",{});var tVt=s(cAe);tet=r(tVt,"pretrained_model_name_or_path"),tVt.forEach(t),aet=r(IL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fAe=n(IL,"CODE",{});var aVt=s(fAe);net=r(aVt,"pretrained_model_name_or_path"),aVt.forEach(t),set=r(IL,":"),IL.forEach(t),iet=i(Ei),mAe=n(Ei,"UL",{});var nVt=s(mAe);uA=n(nVt,"LI",{});var qOe=s(uA);gAe=n(qOe,"STRONG",{});var sVt=s(gAe);det=r(sVt,"vision-encoder-decoder"),sVt.forEach(t),cet=r(qOe," \u2014 "),Woe=n(qOe,"A",{href:!0});var lVt=s(Woe);fet=r(lVt,"FlaxVisionEncoderDecoderModel"),lVt.forEach(t),met=r(qOe," (Vision Encoder decoder model)"),qOe.forEach(t),nVt.forEach(t),get=i(Ei),T(bA.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(gzt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Pn,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoConfig"),c(Nn,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoModel"),c(In,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoTokenizer"),c($i,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertModel"),c(Bf,"id","extending-the-auto-classes"),c(Bf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Bf,"href","#extending-the-auto-classes"),c(ki,"class","relative group"),c(If,"id","transformers.AutoConfig"),c(If,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(If,"href","#transformers.AutoConfig"),c(Si,"class","relative group"),c(ES,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(CS,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig"),c(wS,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig"),c(AS,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig"),c(LS,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig"),c(yS,"href","/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(xS,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig"),c($S,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(kS,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(SS,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(RS,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig"),c(PS,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig"),c(BS,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig"),c(NS,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPConfig"),c(IS,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenConfig"),c(qS,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig"),c(jS,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig"),c(DS,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig"),c(GS,"href","/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtConfig"),c(OS,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(VS,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(XS,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(zS,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig"),c(QS,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(WS,"href","/docs/transformers/pr_17427/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(HS,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTConfig"),c(US,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrConfig"),c(JS,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig"),c(YS,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRConfig"),c(KS,"href","/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTConfig"),c(ZS,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig"),c(eR,"href","/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(oR,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig"),c(rR,"href","/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaConfig"),c(tR,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig"),c(aR,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTConfig"),c(nR,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig"),c(sR,"href","/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNConfig"),c(lR,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config"),c(iR,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(dR,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(cR,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig"),c(fR,"href","/docs/transformers/pr_17427/en/model_doc/groupvit#transformers.GroupViTConfig"),c(mR,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig"),c(gR,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig"),c(hR,"href","/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(pR,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(_R,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(uR,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(bR,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig"),c(vR,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitConfig"),c(FR,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig"),c(TR,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config"),c(MR,"href","/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeConfig"),c(ER,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig"),c(CR,"href","/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Config"),c(wR,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig"),c(AR,"href","/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(LR,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig"),c(yR,"href","/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTConfig"),c(xR,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c($R,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(kR,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig"),c(SR,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config"),c(RR,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig"),c(PR,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(BR,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(NR,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig"),c(IR,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig"),c(qR,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig"),c(jR,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig"),c(DR,"href","/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(GR,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(OR,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(VR,"href","/docs/transformers/pr_17427/en/model_doc/rag#transformers.RagConfig"),c(XR,"href","/docs/transformers/pr_17427/en/model_doc/realm#transformers.RealmConfig"),c(zR,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig"),c(QR,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig"),c(WR,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig"),c(HR,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig"),c(UR,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertConfig"),c(JR,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig"),c(YR,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig"),c(KR,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerConfig"),c(ZR,"href","/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWConfig"),c(eP,"href","/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDConfig"),c(oP,"href","/docs/transformers/pr_17427/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(rP,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(tP,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(aP,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterConfig"),c(nP,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(sP,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig"),c(lP,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config"),c(iP,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig"),c(dP,"href","/docs/transformers/pr_17427/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(cP,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(fP,"href","/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRConfig"),c(mP,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(gP,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(hP,"href","/docs/transformers/pr_17427/en/model_doc/van#transformers.VanConfig"),c(pP,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltConfig"),c(_P,"href","/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(uP,"href","/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(bP,"href","/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(vP,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig"),c(FP,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(TP,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(MP,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(EP,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig"),c(CP,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig"),c(wP,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig"),c(AP,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(LP,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(yP,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(xP,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig"),c($P,"href","/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosConfig"),c(kP,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hg,"id","transformers.AutoTokenizer"),c(Hg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hg,"href","#transformers.AutoTokenizer"),c(Pi,"class","relative group"),c(SP,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(RP,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizer"),c(PP,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(BP,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartTokenizer"),c(NP,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartTokenizerFast"),c(IP,"href","/docs/transformers/pr_17427/en/model_doc/barthez#transformers.BarthezTokenizer"),c(qP,"href","/docs/transformers/pr_17427/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(jP,"href","/docs/transformers/pr_17427/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(DP,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(GP,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(OP,"href","/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(VP,"href","/docs/transformers/pr_17427/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(XP,"href","/docs/transformers/pr_17427/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(zP,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(QP,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(WP,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(HP,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(UP,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(JP,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(YP,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(KP,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(ZP,"href","/docs/transformers/pr_17427/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(eB,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertTokenizer"),c(oB,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(rB,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineTokenizer"),c(tB,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPTokenizer"),c(aB,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(nB,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(sB,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(lB,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(iB,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(dB,"href","/docs/transformers/pr_17427/en/model_doc/cpm#transformers.CpmTokenizer"),c(cB,"href","/docs/transformers/pr_17427/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(fB,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(mB,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizer"),c(gB,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(hB,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaTokenizer"),c(pB,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(_B,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(uB,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(bB,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(vB,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(FB,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(TB,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(MB,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraTokenizer"),c(EB,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(CB,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(wB,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetTokenizer"),c(AB,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(LB,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(yB,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelTokenizer"),c(xB,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c($B,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(kB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(SB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(RB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(PB,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(BB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(NB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(IB,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPTokenizer"),c(qB,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(jB,"href","/docs/transformers/pr_17427/en/model_doc/herbert#transformers.HerbertTokenizer"),c(DB,"href","/docs/transformers/pr_17427/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(GB,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(OB,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizer"),c(VB,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(XB,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(zB,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(QB,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(WB,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(HB,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(UB,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(JB,"href","/docs/transformers/pr_17427/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(YB,"href","/docs/transformers/pr_17427/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(KB,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDTokenizer"),c(ZB,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDTokenizerFast"),c(eN,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerTokenizer"),c(oN,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(rN,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Tokenizer"),c(tN,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5TokenizerFast"),c(aN,"href","/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeTokenizer"),c(nN,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(sN,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(lN,"href","/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(iN,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianTokenizer"),c(dN,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartTokenizer"),c(cN,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(fN,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(mN,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(gN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(hN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(pN,"href","/docs/transformers/pr_17427/en/model_doc/mluke#transformers.MLukeTokenizer"),c(_N,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(uN,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(bN,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(vN,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(FN,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Tokenizer"),c(TN,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5TokenizerFast"),c(MN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(EN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(CN,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizer"),c(wN,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(AN,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(LN,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(yN,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(xN,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusTokenizer"),c($N,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(kN,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(SN,"href","/docs/transformers/pr_17427/en/model_doc/phobert#transformers.PhobertTokenizer"),c(RN,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartTokenizer"),c(PN,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(BN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(NN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(IN,"href","/docs/transformers/pr_17427/en/model_doc/rag#transformers.RagTokenizer"),c(qN,"href","/docs/transformers/pr_17427/en/model_doc/realm#transformers.RealmTokenizer"),c(jN,"href","/docs/transformers/pr_17427/en/model_doc/realm#transformers.RealmTokenizerFast"),c(DN,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerTokenizer"),c(GN,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(ON,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertTokenizer"),c(VN,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(XN,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(zN,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(QN,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizer"),c(WN,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(HN,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(UN,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(JN,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(YN,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(KN,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterTokenizer"),c(ZN,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(eI,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(oI,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(rI,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Tokenizer"),c(tI,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5TokenizerFast"),c(aI,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasTokenizer"),c(nI,"href","/docs/transformers/pr_17427/en/model_doc/tapex#transformers.TapexTokenizer"),c(sI,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(lI,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(iI,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(dI,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(cI,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(fI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(mI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(gI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(hI,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMTokenizer"),c(pI,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(_I,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMTokenizer"),c(uI,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(bI,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(vI,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(FI,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizer"),c(TI,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(MI,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(EI,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(CI,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizer"),c(wI,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($h,"id","transformers.AutoFeatureExtractor"),c($h,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($h,"href","#transformers.AutoFeatureExtractor"),c(Bi,"class","relative group"),c(AI,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(LI,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(yI,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(xI,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c($I,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(kI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(SI,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(RI,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(PI,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(BI,"href","/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(NI,"href","/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(II,"href","/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(qI,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(jI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(DI,"href","/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(GI,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(OI,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(VI,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(XI,"href","/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(zI,"href","/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(QI,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(WI,"href","/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(HI,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(UI,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(JI,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(YI,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(KI,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(ZI,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(eq,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(oq,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(rq,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(tq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(aq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(nq,"href","/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gp,"id","transformers.AutoProcessor"),c(gp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gp,"href","#transformers.AutoProcessor"),c(Ni,"class","relative group"),c(sq,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(lq,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPProcessor"),c(iq,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPProcessor"),c(dq,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(cq,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(fq,"href","/docs/transformers/pr_17427/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(mq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(gq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(hq,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(pq,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(_q,"href","/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRProcessor"),c(uq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(bq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(vq,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltProcessor"),c(Fq,"href","/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(Tq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Mq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Eq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bp,"id","transformers.AutoModel"),c(Bp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Bp,"href","#transformers.AutoModel"),c(qi,"class","relative group"),c(Cq,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wq,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aq,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lq,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertModel"),c(yq,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartModel"),c(xq,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitModel"),c($q,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertModel"),c(kq,"href","/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(Sq,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdModel"),c(Rq,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(Pq,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(Bq,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(Nq,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomModel"),c(Iq,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertModel"),c(qq,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineModel"),c(jq,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPModel"),c(Dq,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenModel"),c(Gq,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertModel"),c(Oq,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextModel"),c(Vq,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLModel"),c(Xq,"href","/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtModel"),c(zq,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(Qq,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(Wq,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(Hq,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaModel"),c(Uq,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(Jq,"href","/docs/transformers/pr_17427/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(Yq,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTModel"),c(Kq,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrModel"),c(Zq,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertModel"),c(ej,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(oj,"href","/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTModel"),c(rj,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraModel"),c(tj,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertModel"),c(aj,"href","/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaModel"),c(nj,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetModel"),c(sj,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTModel"),c(lj,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelModel"),c(ij,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelBaseModel"),c(dj,"href","/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNModel"),c(cj,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Model"),c(fj,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(mj,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(gj,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJModel"),c(hj,"href","/docs/transformers/pr_17427/en/model_doc/groupvit#transformers.GroupViTModel"),c(pj,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertModel"),c(_j,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertModel"),c(uj,"href","/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(bj,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(vj,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Fj,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Tj,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDModel"),c(Mj,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitModel"),c(Ej,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerModel"),c(Cj,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Model"),c(wj,"href","/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeModel"),c(Aj,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertModel"),c(Lj,"href","/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Model"),c(yj,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianModel"),c(xj,"href","/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerModel"),c($j,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartModel"),c(kj,"href","/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTModel"),c(Sj,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(Rj,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertModel"),c(Pj,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetModel"),c(Bj,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Model"),c(Nj,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaModel"),c(Ij,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerModel"),c(qj,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(jj,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTModel"),c(Dj,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusModel"),c(Gj,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverModel"),c(Oj,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartModel"),c(Vj,"href","/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerModel"),c(Xj,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(zj,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Qj,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerModel"),c(Wj,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetModel"),c(Hj,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertModel"),c(Uj,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetModel"),c(Jj,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertModel"),c(Yj,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaModel"),c(Kj,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerModel"),c(Zj,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerModel"),c(eD,"href","/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWModel"),c(oD,"href","/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDModel"),c(rD,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(tD,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterModel"),c(aD,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(nD,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinModel"),c(sD,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Model"),c(lD,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasModel"),c(iD,"href","/docs/transformers/pr_17427/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(dD,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(cD,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechModel"),c(fD,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(mD,"href","/docs/transformers/pr_17427/en/model_doc/van#transformers.VanModel"),c(gD,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltModel"),c(hD,"href","/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(pD,"href","/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertModel"),c(_D,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTModel"),c(uD,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(bD,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(vD,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(FD,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMModel"),c(TD,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMModel"),c(MD,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMModel"),c(ED,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(CD,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(wD,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(AD,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetModel"),c(LD,"href","/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosModel"),c(yD,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ju,"id","transformers.AutoModelForPreTraining"),c(ju,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ju,"href","#transformers.AutoModelForPreTraining"),c(Gi,"class","relative group"),c(xD,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($D,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kD,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SD,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForPreTraining"),c(RD,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(PD,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForPreTraining"),c(BD,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(ND,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForCausalLM"),c(ID,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(qD,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(jD,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(DD,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(GD,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(OD,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(VD,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForPreTraining"),c(XD,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(zD,"href","/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaForPreTraining"),c(QD,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForPreTraining"),c(WD,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(HD,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(UD,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(JD,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(YD,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(KD,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(ZD,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(eG,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(oG,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(rG,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(tG,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(aG,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(nG,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertModel"),c(sG,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(lG,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(iG,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(dG,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(cG,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(fG,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(mG,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(gG,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(hG,"href","/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(pG,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(_G,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(uG,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(bG,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(vG,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(FG,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(TG,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R2,"id","transformers.AutoModelForCausalLM"),c(R2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R2,"href","#transformers.AutoModelForCausalLM"),c(Xi,"class","relative group"),c(MG,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EG,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CG,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wG,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForCausalLM"),c(AG,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertLMHeadModel"),c(LG,"href","/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(yG,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(xG,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c($G,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(kG,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(SG,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForCausalLM"),c(RG,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(PG,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(BG,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(NG,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(IG,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForCausalLM"),c(qG,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(jG,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(DG,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(GG,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(OG,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianForCausalLM"),c(VG,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForCausalLM"),c(XG,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(zG,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(QG,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTForCausalLM"),c(WG,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(HG,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(UG,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(JG,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(YG,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(KG,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(ZG,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(eO,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(oO,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(rO,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(tO,"href","/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(aO,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(nO,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(sO,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(lO,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(iO,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(dO,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(M1,"id","transformers.AutoModelForMaskedLM"),c(M1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M1,"href","#transformers.AutoModelForMaskedLM"),c(Wi,"class","relative group"),c(cO,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fO,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mO,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gO,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(hO,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(pO,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForMaskedLM"),c(_O,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(uO,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(bO,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(vO,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(FO,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(TO,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(MO,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(EO,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(CO,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(wO,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(AO,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(LO,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(yO,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(xO,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c($O,"href","/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeForMaskedLM"),c(kO,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(SO,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(RO,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(PO,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(BO,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(NO,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(IO,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(qO,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(jO,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(DO,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(GO,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(OO,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(VO,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(XO,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(zO,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(QO,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(WO,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(HO,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d7,"id","transformers.AutoModelForSeq2SeqLM"),c(d7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d7,"href","#transformers.AutoModelForSeq2SeqLM"),c(Ji,"class","relative group"),c(UO,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JO,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YO,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KO,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(ZO,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(eV,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(oV,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(rV,"href","/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(tV,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(aV,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(nV,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(sV,"href","/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(lV,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianMTModel"),c(iV,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(dV,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(cV,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(fV,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(mV,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(gV,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(hV,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($7,"id","transformers.AutoModelForSequenceClassification"),c($7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($7,"href","#transformers.AutoModelForSequenceClassification"),c(Zi,"class","relative group"),c(pV,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_V,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uV,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bV,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(vV,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForSequenceClassification"),c(FV,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForSequenceClassification"),c(TV,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(MV,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(EV,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(CV,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(wV,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(AV,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(LV,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(yV,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(xV,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c($V,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(kV,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(SV,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(RV,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(PV,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(BV,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(NV,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(IV,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(qV,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(jV,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(DV,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(GV,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(OV,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(VV,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForSequenceClassification"),c(XV,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(zV,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(QV,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(WV,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(HV,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(UV,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(JV,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(YV,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(KV,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(ZV,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(eX,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(oX,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(rX,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(tX,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(aX,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(nX,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(sX,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(lX,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(iX,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(dX,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(cX,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(fX,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(mX,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x4,"id","transformers.AutoModelForMultipleChoice"),c(x4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x4,"href","#transformers.AutoModelForMultipleChoice"),c(rd,"class","relative group"),c(gX,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hX,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pX,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_X,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(uX,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForMultipleChoice"),c(bX,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(vX,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(FX,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(TX,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(MX,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(EX,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(CX,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(wX,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(AX,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(LX,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(yX,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(xX,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c($X,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(kX,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(SX,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(RX,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(PX,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(BX,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(NX,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(IX,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(qX,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(jX,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(DX,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(GX,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(OX,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(VX,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(XX,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(zX,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(db,"id","transformers.AutoModelForNextSentencePrediction"),c(db,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(db,"href","#transformers.AutoModelForNextSentencePrediction"),c(nd,"class","relative group"),c(QX,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WX,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HX,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UX,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(JX,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(YX,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(KX,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(ZX,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(ez,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vb,"id","transformers.AutoModelForTokenClassification"),c(vb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vb,"href","#transformers.AutoModelForTokenClassification"),c(id,"class","relative group"),c(oz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(az,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(nz,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForTokenClassification"),c(sz,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(lz,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(iz,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(dz,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForTokenClassification"),c(cz,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(fz,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(mz,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(gz,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(hz,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(pz,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(_z,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(uz,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(bz,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(vz,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(Fz,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(Tz,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(Mz,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(Ez,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(Cz,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(wz,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(Az,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(Lz,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(yz,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(xz,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c($z,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(kz,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(Sz,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(Rz,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(Pz,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(Bz,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(Nz,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(Iz,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(qz,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(jz,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nv,"id","transformers.AutoModelForQuestionAnswering"),c(nv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nv,"href","#transformers.AutoModelForQuestionAnswering"),c(fd,"class","relative group"),c(Dz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Oz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vz,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(Xz,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(zz,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(Qz,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(Wz,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(Hz,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(Uz,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(Jz,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(Yz,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(Kz,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(Zz,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(eQ,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(oQ,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(rQ,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(tQ,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(aQ,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(nQ,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(sQ,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(lQ,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(iQ,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(dQ,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(cQ,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(fQ,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(mQ,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(gQ,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(hQ,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(pQ,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(_Q,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(uQ,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(bQ,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(vQ,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(FQ,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(TQ,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(MQ,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(EQ,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(CQ,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(wQ,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(AQ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(LQ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(yQ,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(xQ,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jv,"id","transformers.AutoModelForTableQuestionAnswering"),c(Jv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jv,"href","#transformers.AutoModelForTableQuestionAnswering"),c(hd,"class","relative group"),c($Q,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RQ,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oF,"id","transformers.AutoModelForImageClassification"),c(oF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oF,"href","#transformers.AutoModelForImageClassification"),c(ud,"class","relative group"),c(PQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IQ,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitForImageClassification"),c(qQ,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(jQ,"href","/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtForImageClassification"),c(DQ,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(GQ,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForImageClassification"),c(OQ,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(VQ,"href","/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(XQ,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitForImageClassification"),c(zQ,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(QQ,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(WQ,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(HQ,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(UQ,"href","/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(JQ,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(YQ,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(KQ,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(ZQ,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinForImageClassification"),c(eW,"href","/docs/transformers/pr_17427/en/model_doc/van#transformers.VanForImageClassification"),c(oW,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uF,"id","transformers.AutoModelForVision2Seq"),c(uF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uF,"href","#transformers.AutoModelForVision2Seq"),c(Fd,"class","relative group"),c(rW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nW,"href","/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MF,"id","transformers.AutoModelForVisualQuestionAnswering"),c(MF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(MF,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Ed,"class","relative group"),c(sW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dW,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LF,"id","transformers.AutoModelForAudioClassification"),c(LF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LF,"href","#transformers.AutoModelForAudioClassification"),c(Ad,"class","relative group"),c(cW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gW,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(hW,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(pW,"href","/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(_W,"href","/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(uW,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(bW,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(vW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(FW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(TW,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DF,"id","transformers.AutoModelForAudioFrameClassification"),c(DF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DF,"href","#transformers.AutoModelForAudioFrameClassification"),c(xd,"class","relative group"),c(MW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wW,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(AW,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(LW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(yW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(xW,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UF,"id","transformers.AutoModelForCTC"),c(UF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UF,"href","#transformers.AutoModelForCTC"),c(Sd,"class","relative group"),c($W,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RW,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(PW,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertForCTC"),c(BW,"href","/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTForCTC"),c(NW,"href","/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWForCTC"),c(IW,"href","/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDForCTC"),c(qW,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(jW,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(DW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(GW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(OW,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dT,"id","transformers.AutoModelForSpeechSeq2Seq"),c(dT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dT,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Bd,"class","relative group"),c(VW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QW,"href","/docs/transformers/pr_17427/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(WW,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pT,"id","transformers.AutoModelForAudioXVector"),c(pT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pT,"href","#transformers.AutoModelForAudioXVector"),c(qd,"class","relative group"),c(HW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YW,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(KW,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(ZW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(eH,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(oH,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CT,"id","transformers.AutoModelForMaskedImageModeling"),c(CT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CT,"href","#transformers.AutoModelForMaskedImageModeling"),c(Gd,"class","relative group"),c(rH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nH,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(sH,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(lH,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kT,"id","transformers.AutoModelForObjectDetection"),c(kT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kT,"href","#transformers.AutoModelForObjectDetection"),c(zd,"class","relative group"),c(iH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fH,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrForObjectDetection"),c(mH,"href","/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IT,"id","transformers.AutoModelForImageSegmentation"),c(IT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(IT,"href","#transformers.AutoModelForImageSegmentation"),c(Hd,"class","relative group"),c(gH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_H,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OT,"id","transformers.AutoModelForSemanticSegmentation"),c(OT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(OT,"href","#transformers.AutoModelForSemanticSegmentation"),c(Yd,"class","relative group"),c(uH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FH,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(TH,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(MH,"href","/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(EH,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JT,"id","transformers.AutoModelForInstanceSegmentation"),c(JT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JT,"href","#transformers.AutoModelForInstanceSegmentation"),c(ec,"class","relative group"),c(CH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LH,"href","/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oM,"id","transformers.TFAutoModel"),c(oM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oM,"href","#transformers.TFAutoModel"),c(tc,"class","relative group"),c(yH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($H,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kH,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertModel"),c(SH,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartModel"),c(RH,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertModel"),c(PH,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(BH,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(NH,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertModel"),c(IH,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.TFCLIPModel"),c(qH,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertModel"),c(jH,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.TFConvNextModel"),c(DH,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLModel"),c(GH,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(OH,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaModel"),c(VH,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(XH,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(zH,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(QH,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraModel"),c(WH,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(HH,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelModel"),c(UH,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(JH,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2Model"),c(YH,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJModel"),c(KH,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.TFHubertModel"),c(ZH,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(eU,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.TFLEDModel"),c(oU,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerModel"),c(rU,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.TFLxmertModel"),c(tU,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.TFMarianModel"),c(aU,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.TFMBartModel"),c(nU,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(sU,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetModel"),c(lU,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.TFMT5Model"),c(iU,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(dU,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.TFOPTModel"),c(cU,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.TFPegasusModel"),c(fU,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.TFRegNetModel"),c(mU,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertModel"),c(gU,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.TFResNetModel"),c(hU,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaModel"),c(pU,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerModel"),c(_U,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(uU,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.TFSwinModel"),c(bU,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5Model"),c(vU,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasModel"),c(FU,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(TU,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.TFViTModel"),c(MU,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(EU,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(CU,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMModel"),c(wU,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(AU,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KM,"id","transformers.TFAutoModelForPreTraining"),c(KM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KM,"href","#transformers.TFAutoModelForPreTraining"),c(sc,"class","relative group"),c(LU,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yU,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xU,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($U,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(kU,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(SU,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForPreTraining"),c(RU,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(PU,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(BU,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(NU,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(IU,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(qU,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(jU,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(DU,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(GU,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(OU,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(VU,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(XU,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(zU,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(QU,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(WU,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(HU,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(UU,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(JU,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(YU,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(KU,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CE,"id","transformers.TFAutoModelForCausalLM"),c(CE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CE,"href","#transformers.TFAutoModelForCausalLM"),c(dc,"class","relative group"),c(ZU,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rJ,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(tJ,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(aJ,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(nJ,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(sJ,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(lJ,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(iJ,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(dJ,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(cJ,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(fJ,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(mJ,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(gJ,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(hJ,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DE,"id","transformers.TFAutoModelForImageClassification"),c(DE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DE,"href","#transformers.TFAutoModelForImageClassification"),c(mc,"class","relative group"),c(pJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_J,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bJ,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(vJ,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(FJ,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(TJ,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(MJ,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(EJ,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UE,"id","transformers.TFAutoModelForMaskedLM"),c(UE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UE,"href","#transformers.TFAutoModelForMaskedLM"),c(pc,"class","relative group"),c(CJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LJ,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(yJ,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(xJ,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c($J,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(kJ,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(SJ,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(RJ,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(PJ,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(BJ,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(NJ,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(IJ,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(qJ,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(jJ,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(DJ,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(GJ,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(OJ,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(VJ,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(XJ,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(zJ,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(QJ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bC,"id","transformers.TFAutoModelForSeq2SeqLM"),c(bC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bC,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(bc,"class","relative group"),c(WJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JJ,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(YJ,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(KJ,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(ZJ,"href","/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(eY,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(oY,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.TFMarianMTModel"),c(rY,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(tY,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(aY,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(nY,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kC,"id","transformers.TFAutoModelForSequenceClassification"),c(kC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kC,"href","#transformers.TFAutoModelForSequenceClassification"),c(Tc,"class","relative group"),c(sY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dY,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(cY,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(fY,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(mY,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(gY,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(hY,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(pY,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(_Y,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(uY,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(bY,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(vY,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(FY,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(TY,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(MY,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(EY,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(CY,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(wY,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(AY,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(LY,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(yY,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(xY,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c($Y,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(kY,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(SY,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(RY,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(PY,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s3,"id","transformers.TFAutoModelForMultipleChoice"),c(s3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s3,"href","#transformers.TFAutoModelForMultipleChoice"),c(Cc,"class","relative group"),c(BY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qY,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(jY,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(DY,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(GY,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(OY,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(VY,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(XY,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(zY,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(QY,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(WY,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(HY,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(UY,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(JY,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(YY,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(KY,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(ZY,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(eK,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A3,"id","transformers.TFAutoModelForNextSentencePrediction"),c(A3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A3,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Lc,"class","relative group"),c(oK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aK,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(nK,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(k3,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(k3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k3,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c($c,"class","relative group"),c(sK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dK,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B3,"id","transformers.TFAutoModelForTokenClassification"),c(B3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B3,"href","#transformers.TFAutoModelForTokenClassification"),c(Rc,"class","relative group"),c(cK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gK,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(hK,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(pK,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(_K,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(uK,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(bK,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(vK,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(FK,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(TK,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(MK,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(EK,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(CK,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(wK,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(AK,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(LK,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(yK,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(xK,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c($K,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(kK,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(SK,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a5,"id","transformers.TFAutoModelForQuestionAnswering"),c(a5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a5,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Nc,"class","relative group"),c(RK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(IK,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(qK,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(jK,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(DK,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(GK,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(OK,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(VK,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(XK,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(zK,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(QK,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(WK,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(HK,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(UK,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(JK,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(YK,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(KK,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(ZK,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(eZ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(oZ,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L5,"id","transformers.TFAutoModelForVision2Seq"),c(L5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L5,"href","#transformers.TFAutoModelForVision2Seq"),c(jc,"class","relative group"),c(rZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nZ,"href","/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(k5,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(k5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k5,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Oc,"class","relative group"),c(sZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dZ,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B5,"id","transformers.FlaxAutoModel"),c(B5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B5,"href","#transformers.FlaxAutoModel"),c(zc,"class","relative group"),c(cZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gZ,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertModel"),c(hZ,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartModel"),c(pZ,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.FlaxBeitModel"),c(_Z,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertModel"),c(uZ,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(bZ,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(vZ,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(FZ,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.FlaxCLIPModel"),c(TZ,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(MZ,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraModel"),c(EZ,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(CZ,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(wZ,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(AZ,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(LZ,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.FlaxMarianModel"),c(yZ,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartModel"),c(xZ,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5Model"),c($Z,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.FlaxOPTModel"),c(kZ,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(SZ,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(RZ,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(PZ,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5Model"),c(BZ,"href","/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(NZ,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.FlaxViTModel"),c(IZ,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(qZ,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(jZ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f0,"id","transformers.FlaxAutoModelForCausalLM"),c(f0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f0,"href","#transformers.FlaxAutoModelForCausalLM"),c(Hc,"class","relative group"),c(DZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VZ,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(XZ,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(zZ,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(QZ,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(WZ,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(HZ,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(UZ,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(JZ,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(YZ,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(KZ,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C0,"id","transformers.FlaxAutoModelForPreTraining"),c(C0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C0,"href","#transformers.FlaxAutoModelForPreTraining"),c(Yc,"class","relative group"),c(ZZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ree,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(tee,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(aee,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(nee,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(see,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(lee,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(iee,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(dee,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(cee,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(fee,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(mee,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(gee,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(hee,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D0,"id","transformers.FlaxAutoModelForMaskedLM"),c(D0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D0,"href","#transformers.FlaxAutoModelForMaskedLM"),c(ef,"class","relative group"),c(pee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_ee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bee,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(vee,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Fee,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(Tee,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Mee,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Eee,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Cee,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(wee,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Aee,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Lee,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z0,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(Z0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z0,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(tf,"class","relative group"),c(yee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($ee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kee,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(See,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Ree,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Pee,"href","/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Bee,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Nee,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Iee,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(qee,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(jee,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(Dee,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mw,"id","transformers.FlaxAutoModelForSequenceClassification"),c(mw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mw,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(sf,"class","relative group"),c(Gee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Oee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Vee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xee,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(zee,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Qee,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(Wee,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(Hee,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Uee,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Jee,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Yee,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Kee,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Zee,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ww,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ww,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(cf,"class","relative group"),c(eoe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ooe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(roe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(toe,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(aoe,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(noe,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(soe,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(loe,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(ioe,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(doe,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(coe,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(foe,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(moe,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qw,"id","transformers.FlaxAutoModelForTokenClassification"),c(qw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qw,"href","#transformers.FlaxAutoModelForTokenClassification"),c(gf,"class","relative group"),c(goe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hoe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(poe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_oe,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(uoe,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(boe,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(voe,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Foe,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Toe,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Moe,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Eoe,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uw,"id","transformers.FlaxAutoModelForMultipleChoice"),c(Uw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uw,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(_f,"class","relative group"),c(Coe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(woe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aoe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Loe,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(yoe,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(xoe,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c($oe,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(koe,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Soe,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Roe,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Poe,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sA,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(sA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sA,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(vf,"class","relative group"),c(Boe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Noe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ioe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qoe,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cA,"id","transformers.FlaxAutoModelForImageClassification"),c(cA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cA,"href","#transformers.FlaxAutoModelForImageClassification"),c(Mf,"class","relative group"),c(joe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Doe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Goe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ooe,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Voe,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pA,"id","transformers.FlaxAutoModelForVision2Seq"),c(pA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pA,"href","#transformers.FlaxAutoModelForVision2Seq"),c(wf,"class","relative group"),c(Xoe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zoe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qoe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Woe,"href","/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Eo),e(Eo,Ci),b(f,kf,u),b(f,nt,u),e(nt,wi),e(nt,Ai),e(Ai,qL),e(nt,Sf),b(f,Oe,u),b(f,Qe,u),e(Qe,Li),e(Qe,Pn),e(Pn,jL),e(Qe,Bn),e(Qe,Nn),e(Nn,DL),e(Qe,yi),e(Qe,In),e(In,GL),e(Qe,xi),b(f,Rf,u),M(ka,f,u),b(f,We,u),b(f,Ae,u),e(Ae,uS),e(Ae,$i),e($i,bS),e(Ae,vS),b(f,Co,u),b(f,Sa,u),e(Sa,FS),e(Sa,Pf),e(Pf,TS),e(Sa,eWe),b(f,jOe,u),b(f,ki,u),e(ki,Bf),e(Bf,Ote),M(OL,Ote,null),e(ki,oWe),e(ki,Vte),e(Vte,rWe),b(f,DOe,u),b(f,qn,u),e(qn,tWe),e(qn,Xte),e(Xte,aWe),e(qn,nWe),e(qn,zte),e(zte,sWe),e(qn,lWe),b(f,GOe,u),M(VL,f,u),b(f,OOe,u),b(f,MS,u),e(MS,iWe),b(f,VOe,u),M(Nf,f,u),b(f,XOe,u),b(f,Si,u),e(Si,If),e(If,Qte),M(XL,Qte,null),e(Si,dWe),e(Si,Wte),e(Wte,cWe),b(f,zOe,u),b(f,wo,u),M(zL,wo,null),e(wo,fWe),e(wo,QL),e(QL,mWe),e(QL,ES),e(ES,gWe),e(QL,hWe),e(wo,pWe),e(wo,WL),e(WL,_We),e(WL,Hte),e(Hte,uWe),e(WL,bWe),e(wo,vWe),e(wo,Lr),M(HL,Lr,null),e(Lr,FWe),e(Lr,Ute),e(Ute,TWe),e(Lr,MWe),e(Lr,Ri),e(Ri,EWe),e(Ri,Jte),e(Jte,CWe),e(Ri,wWe),e(Ri,Yte),e(Yte,AWe),e(Ri,LWe),e(Lr,yWe),e(Lr,A),e(A,qf),e(qf,Kte),e(Kte,xWe),e(qf,$We),e(qf,CS),e(CS,kWe),e(qf,SWe),e(A,RWe),e(A,jf),e(jf,Zte),e(Zte,PWe),e(jf,BWe),e(jf,wS),e(wS,NWe),e(jf,IWe),e(A,qWe),e(A,Df),e(Df,eae),e(eae,jWe),e(Df,DWe),e(Df,AS),e(AS,GWe),e(Df,OWe),e(A,VWe),e(A,Gf),e(Gf,oae),e(oae,XWe),e(Gf,zWe),e(Gf,LS),e(LS,QWe),e(Gf,WWe),e(A,HWe),e(A,Of),e(Of,rae),e(rae,UWe),e(Of,JWe),e(Of,yS),e(yS,YWe),e(Of,KWe),e(A,ZWe),e(A,Vf),e(Vf,tae),e(tae,eHe),e(Vf,oHe),e(Vf,xS),e(xS,rHe),e(Vf,tHe),e(A,aHe),e(A,Xf),e(Xf,aae),e(aae,nHe),e(Xf,sHe),e(Xf,$S),e($S,lHe),e(Xf,iHe),e(A,dHe),e(A,zf),e(zf,nae),e(nae,cHe),e(zf,fHe),e(zf,kS),e(kS,mHe),e(zf,gHe),e(A,hHe),e(A,Qf),e(Qf,sae),e(sae,pHe),e(Qf,_He),e(Qf,SS),e(SS,uHe),e(Qf,bHe),e(A,vHe),e(A,Wf),e(Wf,lae),e(lae,FHe),e(Wf,THe),e(Wf,RS),e(RS,MHe),e(Wf,EHe),e(A,CHe),e(A,Hf),e(Hf,iae),e(iae,wHe),e(Hf,AHe),e(Hf,PS),e(PS,LHe),e(Hf,yHe),e(A,xHe),e(A,Uf),e(Uf,dae),e(dae,$He),e(Uf,kHe),e(Uf,BS),e(BS,SHe),e(Uf,RHe),e(A,PHe),e(A,Jf),e(Jf,cae),e(cae,BHe),e(Jf,NHe),e(Jf,NS),e(NS,IHe),e(Jf,qHe),e(A,jHe),e(A,Yf),e(Yf,fae),e(fae,DHe),e(Yf,GHe),e(Yf,IS),e(IS,OHe),e(Yf,VHe),e(A,XHe),e(A,Kf),e(Kf,mae),e(mae,zHe),e(Kf,QHe),e(Kf,qS),e(qS,WHe),e(Kf,HHe),e(A,UHe),e(A,Zf),e(Zf,gae),e(gae,JHe),e(Zf,YHe),e(Zf,jS),e(jS,KHe),e(Zf,ZHe),e(A,eUe),e(A,em),e(em,hae),e(hae,oUe),e(em,rUe),e(em,DS),e(DS,tUe),e(em,aUe),e(A,nUe),e(A,om),e(om,pae),e(pae,sUe),e(om,lUe),e(om,GS),e(GS,iUe),e(om,dUe),e(A,cUe),e(A,rm),e(rm,_ae),e(_ae,fUe),e(rm,mUe),e(rm,OS),e(OS,gUe),e(rm,hUe),e(A,pUe),e(A,tm),e(tm,uae),e(uae,_Ue),e(tm,uUe),e(tm,VS),e(VS,bUe),e(tm,vUe),e(A,FUe),e(A,am),e(am,bae),e(bae,TUe),e(am,MUe),e(am,XS),e(XS,EUe),e(am,CUe),e(A,wUe),e(A,nm),e(nm,vae),e(vae,AUe),e(nm,LUe),e(nm,zS),e(zS,yUe),e(nm,xUe),e(A,$Ue),e(A,sm),e(sm,Fae),e(Fae,kUe),e(sm,SUe),e(sm,QS),e(QS,RUe),e(sm,PUe),e(A,BUe),e(A,lm),e(lm,Tae),e(Tae,NUe),e(lm,IUe),e(lm,WS),e(WS,qUe),e(lm,jUe),e(A,DUe),e(A,im),e(im,Mae),e(Mae,GUe),e(im,OUe),e(im,HS),e(HS,VUe),e(im,XUe),e(A,zUe),e(A,dm),e(dm,Eae),e(Eae,QUe),e(dm,WUe),e(dm,US),e(US,HUe),e(dm,UUe),e(A,JUe),e(A,cm),e(cm,Cae),e(Cae,YUe),e(cm,KUe),e(cm,JS),e(JS,ZUe),e(cm,eJe),e(A,oJe),e(A,fm),e(fm,wae),e(wae,rJe),e(fm,tJe),e(fm,YS),e(YS,aJe),e(fm,nJe),e(A,sJe),e(A,mm),e(mm,Aae),e(Aae,lJe),e(mm,iJe),e(mm,KS),e(KS,dJe),e(mm,cJe),e(A,fJe),e(A,gm),e(gm,Lae),e(Lae,mJe),e(gm,gJe),e(gm,ZS),e(ZS,hJe),e(gm,pJe),e(A,_Je),e(A,hm),e(hm,yae),e(yae,uJe),e(hm,bJe),e(hm,eR),e(eR,vJe),e(hm,FJe),e(A,TJe),e(A,pm),e(pm,xae),e(xae,MJe),e(pm,EJe),e(pm,oR),e(oR,CJe),e(pm,wJe),e(A,AJe),e(A,_m),e(_m,$ae),e($ae,LJe),e(_m,yJe),e(_m,rR),e(rR,xJe),e(_m,$Je),e(A,kJe),e(A,um),e(um,kae),e(kae,SJe),e(um,RJe),e(um,tR),e(tR,PJe),e(um,BJe),e(A,NJe),e(A,bm),e(bm,Sae),e(Sae,IJe),e(bm,qJe),e(bm,aR),e(aR,jJe),e(bm,DJe),e(A,GJe),e(A,vm),e(vm,Rae),e(Rae,OJe),e(vm,VJe),e(vm,nR),e(nR,XJe),e(vm,zJe),e(A,QJe),e(A,Fm),e(Fm,Pae),e(Pae,WJe),e(Fm,HJe),e(Fm,sR),e(sR,UJe),e(Fm,JJe),e(A,YJe),e(A,Tm),e(Tm,Bae),e(Bae,KJe),e(Tm,ZJe),e(Tm,lR),e(lR,eYe),e(Tm,oYe),e(A,rYe),e(A,Mm),e(Mm,Nae),e(Nae,tYe),e(Mm,aYe),e(Mm,iR),e(iR,nYe),e(Mm,sYe),e(A,lYe),e(A,Em),e(Em,Iae),e(Iae,iYe),e(Em,dYe),e(Em,dR),e(dR,cYe),e(Em,fYe),e(A,mYe),e(A,Cm),e(Cm,qae),e(qae,gYe),e(Cm,hYe),e(Cm,cR),e(cR,pYe),e(Cm,_Ye),e(A,uYe),e(A,wm),e(wm,jae),e(jae,bYe),e(wm,vYe),e(wm,fR),e(fR,FYe),e(wm,TYe),e(A,MYe),e(A,Am),e(Am,Dae),e(Dae,EYe),e(Am,CYe),e(Am,mR),e(mR,wYe),e(Am,AYe),e(A,LYe),e(A,Lm),e(Lm,Gae),e(Gae,yYe),e(Lm,xYe),e(Lm,gR),e(gR,$Ye),e(Lm,kYe),e(A,SYe),e(A,ym),e(ym,Oae),e(Oae,RYe),e(ym,PYe),e(ym,hR),e(hR,BYe),e(ym,NYe),e(A,IYe),e(A,xm),e(xm,Vae),e(Vae,qYe),e(xm,jYe),e(xm,pR),e(pR,DYe),e(xm,GYe),e(A,OYe),e(A,$m),e($m,Xae),e(Xae,VYe),e($m,XYe),e($m,_R),e(_R,zYe),e($m,QYe),e(A,WYe),e(A,km),e(km,zae),e(zae,HYe),e(km,UYe),e(km,uR),e(uR,JYe),e(km,YYe),e(A,KYe),e(A,Sm),e(Sm,Qae),e(Qae,ZYe),e(Sm,eKe),e(Sm,bR),e(bR,oKe),e(Sm,rKe),e(A,tKe),e(A,Rm),e(Rm,Wae),e(Wae,aKe),e(Rm,nKe),e(Rm,vR),e(vR,sKe),e(Rm,lKe),e(A,iKe),e(A,Pm),e(Pm,Hae),e(Hae,dKe),e(Pm,cKe),e(Pm,FR),e(FR,fKe),e(Pm,mKe),e(A,gKe),e(A,Bm),e(Bm,Uae),e(Uae,hKe),e(Bm,pKe),e(Bm,TR),e(TR,_Ke),e(Bm,uKe),e(A,bKe),e(A,Nm),e(Nm,Jae),e(Jae,vKe),e(Nm,FKe),e(Nm,MR),e(MR,TKe),e(Nm,MKe),e(A,EKe),e(A,Im),e(Im,Yae),e(Yae,CKe),e(Im,wKe),e(Im,ER),e(ER,AKe),e(Im,LKe),e(A,yKe),e(A,qm),e(qm,Kae),e(Kae,xKe),e(qm,$Ke),e(qm,CR),e(CR,kKe),e(qm,SKe),e(A,RKe),e(A,jm),e(jm,Zae),e(Zae,PKe),e(jm,BKe),e(jm,wR),e(wR,NKe),e(jm,IKe),e(A,qKe),e(A,Dm),e(Dm,ene),e(ene,jKe),e(Dm,DKe),e(Dm,AR),e(AR,GKe),e(Dm,OKe),e(A,VKe),e(A,Gm),e(Gm,one),e(one,XKe),e(Gm,zKe),e(Gm,LR),e(LR,QKe),e(Gm,WKe),e(A,HKe),e(A,Om),e(Om,rne),e(rne,UKe),e(Om,JKe),e(Om,yR),e(yR,YKe),e(Om,KKe),e(A,ZKe),e(A,Vm),e(Vm,tne),e(tne,eZe),e(Vm,oZe),e(Vm,xR),e(xR,rZe),e(Vm,tZe),e(A,aZe),e(A,Xm),e(Xm,ane),e(ane,nZe),e(Xm,sZe),e(Xm,$R),e($R,lZe),e(Xm,iZe),e(A,dZe),e(A,zm),e(zm,nne),e(nne,cZe),e(zm,fZe),e(zm,kR),e(kR,mZe),e(zm,gZe),e(A,hZe),e(A,Qm),e(Qm,sne),e(sne,pZe),e(Qm,_Ze),e(Qm,SR),e(SR,uZe),e(Qm,bZe),e(A,vZe),e(A,Wm),e(Wm,lne),e(lne,FZe),e(Wm,TZe),e(Wm,RR),e(RR,MZe),e(Wm,EZe),e(A,CZe),e(A,Hm),e(Hm,ine),e(ine,wZe),e(Hm,AZe),e(Hm,PR),e(PR,LZe),e(Hm,yZe),e(A,xZe),e(A,Um),e(Um,dne),e(dne,$Ze),e(Um,kZe),e(Um,BR),e(BR,SZe),e(Um,RZe),e(A,PZe),e(A,Jm),e(Jm,cne),e(cne,BZe),e(Jm,NZe),e(Jm,NR),e(NR,IZe),e(Jm,qZe),e(A,jZe),e(A,Ym),e(Ym,fne),e(fne,DZe),e(Ym,GZe),e(Ym,IR),e(IR,OZe),e(Ym,VZe),e(A,XZe),e(A,Km),e(Km,mne),e(mne,zZe),e(Km,QZe),e(Km,qR),e(qR,WZe),e(Km,HZe),e(A,UZe),e(A,Zm),e(Zm,gne),e(gne,JZe),e(Zm,YZe),e(Zm,jR),e(jR,KZe),e(Zm,ZZe),e(A,eeo),e(A,eg),e(eg,hne),e(hne,oeo),e(eg,reo),e(eg,DR),e(DR,teo),e(eg,aeo),e(A,neo),e(A,og),e(og,pne),e(pne,seo),e(og,leo),e(og,GR),e(GR,ieo),e(og,deo),e(A,ceo),e(A,rg),e(rg,_ne),e(_ne,feo),e(rg,meo),e(rg,OR),e(OR,geo),e(rg,heo),e(A,peo),e(A,tg),e(tg,une),e(une,_eo),e(tg,ueo),e(tg,VR),e(VR,beo),e(tg,veo),e(A,Feo),e(A,ag),e(ag,bne),e(bne,Teo),e(ag,Meo),e(ag,XR),e(XR,Eeo),e(ag,Ceo),e(A,weo),e(A,ng),e(ng,vne),e(vne,Aeo),e(ng,Leo),e(ng,zR),e(zR,yeo),e(ng,xeo),e(A,$eo),e(A,sg),e(sg,Fne),e(Fne,keo),e(sg,Seo),e(sg,QR),e(QR,Reo),e(sg,Peo),e(A,Beo),e(A,lg),e(lg,Tne),e(Tne,Neo),e(lg,Ieo),e(lg,WR),e(WR,qeo),e(lg,jeo),e(A,Deo),e(A,ig),e(ig,Mne),e(Mne,Geo),e(ig,Oeo),e(ig,HR),e(HR,Veo),e(ig,Xeo),e(A,zeo),e(A,dg),e(dg,Ene),e(Ene,Qeo),e(dg,Weo),e(dg,UR),e(UR,Heo),e(dg,Ueo),e(A,Jeo),e(A,cg),e(cg,Cne),e(Cne,Yeo),e(cg,Keo),e(cg,JR),e(JR,Zeo),e(cg,eoo),e(A,ooo),e(A,fg),e(fg,wne),e(wne,roo),e(fg,too),e(fg,YR),e(YR,aoo),e(fg,noo),e(A,soo),e(A,mg),e(mg,Ane),e(Ane,loo),e(mg,ioo),e(mg,KR),e(KR,doo),e(mg,coo),e(A,foo),e(A,gg),e(gg,Lne),e(Lne,moo),e(gg,goo),e(gg,ZR),e(ZR,hoo),e(gg,poo),e(A,_oo),e(A,hg),e(hg,yne),e(yne,uoo),e(hg,boo),e(hg,eP),e(eP,voo),e(hg,Foo),e(A,Too),e(A,pg),e(pg,xne),e(xne,Moo),e(pg,Eoo),e(pg,oP),e(oP,Coo),e(pg,woo),e(A,Aoo),e(A,_g),e(_g,$ne),e($ne,Loo),e(_g,yoo),e(_g,rP),e(rP,xoo),e(_g,$oo),e(A,koo),e(A,ug),e(ug,kne),e(kne,Soo),e(ug,Roo),e(ug,tP),e(tP,Poo),e(ug,Boo),e(A,Noo),e(A,bg),e(bg,Sne),e(Sne,Ioo),e(bg,qoo),e(bg,aP),e(aP,joo),e(bg,Doo),e(A,Goo),e(A,vg),e(vg,Rne),e(Rne,Ooo),e(vg,Voo),e(vg,nP),e(nP,Xoo),e(vg,zoo),e(A,Qoo),e(A,Fg),e(Fg,Pne),e(Pne,Woo),e(Fg,Hoo),e(Fg,sP),e(sP,Uoo),e(Fg,Joo),e(A,Yoo),e(A,Tg),e(Tg,Bne),e(Bne,Koo),e(Tg,Zoo),e(Tg,lP),e(lP,ero),e(Tg,oro),e(A,rro),e(A,Mg),e(Mg,Nne),e(Nne,tro),e(Mg,aro),e(Mg,iP),e(iP,nro),e(Mg,sro),e(A,lro),e(A,Eg),e(Eg,Ine),e(Ine,iro),e(Eg,dro),e(Eg,dP),e(dP,cro),e(Eg,fro),e(A,mro),e(A,Cg),e(Cg,qne),e(qne,gro),e(Cg,hro),e(Cg,cP),e(cP,pro),e(Cg,_ro),e(A,uro),e(A,wg),e(wg,jne),e(jne,bro),e(wg,vro),e(wg,fP),e(fP,Fro),e(wg,Tro),e(A,Mro),e(A,Ag),e(Ag,Dne),e(Dne,Ero),e(Ag,Cro),e(Ag,mP),e(mP,wro),e(Ag,Aro),e(A,Lro),e(A,Lg),e(Lg,Gne),e(Gne,yro),e(Lg,xro),e(Lg,gP),e(gP,$ro),e(Lg,kro),e(A,Sro),e(A,yg),e(yg,One),e(One,Rro),e(yg,Pro),e(yg,hP),e(hP,Bro),e(yg,Nro),e(A,Iro),e(A,xg),e(xg,Vne),e(Vne,qro),e(xg,jro),e(xg,pP),e(pP,Dro),e(xg,Gro),e(A,Oro),e(A,$g),e($g,Xne),e(Xne,Vro),e($g,Xro),e($g,_P),e(_P,zro),e($g,Qro),e(A,Wro),e(A,kg),e(kg,zne),e(zne,Hro),e(kg,Uro),e(kg,uP),e(uP,Jro),e(kg,Yro),e(A,Kro),e(A,Sg),e(Sg,Qne),e(Qne,Zro),e(Sg,eto),e(Sg,bP),e(bP,oto),e(Sg,rto),e(A,tto),e(A,Rg),e(Rg,Wne),e(Wne,ato),e(Rg,nto),e(Rg,vP),e(vP,sto),e(Rg,lto),e(A,ito),e(A,Pg),e(Pg,Hne),e(Hne,dto),e(Pg,cto),e(Pg,FP),e(FP,fto),e(Pg,mto),e(A,gto),e(A,Bg),e(Bg,Une),e(Une,hto),e(Bg,pto),e(Bg,TP),e(TP,_to),e(Bg,uto),e(A,bto),e(A,Ng),e(Ng,Jne),e(Jne,vto),e(Ng,Fto),e(Ng,MP),e(MP,Tto),e(Ng,Mto),e(A,Eto),e(A,Ig),e(Ig,Yne),e(Yne,Cto),e(Ig,wto),e(Ig,EP),e(EP,Ato),e(Ig,Lto),e(A,yto),e(A,qg),e(qg,Kne),e(Kne,xto),e(qg,$to),e(qg,CP),e(CP,kto),e(qg,Sto),e(A,Rto),e(A,jg),e(jg,Zne),e(Zne,Pto),e(jg,Bto),e(jg,wP),e(wP,Nto),e(jg,Ito),e(A,qto),e(A,Dg),e(Dg,ese),e(ese,jto),e(Dg,Dto),e(Dg,AP),e(AP,Gto),e(Dg,Oto),e(A,Vto),e(A,Gg),e(Gg,ose),e(ose,Xto),e(Gg,zto),e(Gg,LP),e(LP,Qto),e(Gg,Wto),e(A,Hto),e(A,Og),e(Og,rse),e(rse,Uto),e(Og,Jto),e(Og,yP),e(yP,Yto),e(Og,Kto),e(A,Zto),e(A,Vg),e(Vg,tse),e(tse,eao),e(Vg,oao),e(Vg,xP),e(xP,rao),e(Vg,tao),e(A,aao),e(A,Xg),e(Xg,ase),e(ase,nao),e(Xg,sao),e(Xg,$P),e($P,lao),e(Xg,iao),e(A,dao),e(A,zg),e(zg,nse),e(nse,cao),e(zg,fao),e(zg,kP),e(kP,mao),e(zg,gao),e(Lr,hao),M(Qg,Lr,null),e(wo,pao),e(wo,Wg),M(UL,Wg,null),e(Wg,_ao),e(Wg,sse),e(sse,uao),b(f,QOe,u),b(f,Pi,u),e(Pi,Hg),e(Hg,lse),M(JL,lse,null),e(Pi,bao),e(Pi,ise),e(ise,vao),b(f,WOe,u),b(f,Ao,u),M(YL,Ao,null),e(Ao,Fao),e(Ao,KL),e(KL,Tao),e(KL,SP),e(SP,Mao),e(KL,Eao),e(Ao,Cao),e(Ao,ZL),e(ZL,wao),e(ZL,dse),e(dse,Aao),e(ZL,Lao),e(Ao,yao),e(Ao,yr),M(ey,yr,null),e(yr,xao),e(yr,cse),e(cse,$ao),e(yr,kao),e(yr,Ra),e(Ra,Sao),e(Ra,fse),e(fse,Rao),e(Ra,Pao),e(Ra,mse),e(mse,Bao),e(Ra,Nao),e(Ra,gse),e(gse,Iao),e(Ra,qao),e(yr,jao),e(yr,k),e(k,jn),e(jn,hse),e(hse,Dao),e(jn,Gao),e(jn,RP),e(RP,Oao),e(jn,Vao),e(jn,PP),e(PP,Xao),e(jn,zao),e(k,Qao),e(k,Dn),e(Dn,pse),e(pse,Wao),e(Dn,Hao),e(Dn,BP),e(BP,Uao),e(Dn,Jao),e(Dn,NP),e(NP,Yao),e(Dn,Kao),e(k,Zao),e(k,Gn),e(Gn,_se),e(_se,eno),e(Gn,ono),e(Gn,IP),e(IP,rno),e(Gn,tno),e(Gn,qP),e(qP,ano),e(Gn,nno),e(k,sno),e(k,Ug),e(Ug,use),e(use,lno),e(Ug,ino),e(Ug,jP),e(jP,dno),e(Ug,cno),e(k,fno),e(k,On),e(On,bse),e(bse,mno),e(On,gno),e(On,DP),e(DP,hno),e(On,pno),e(On,GP),e(GP,_no),e(On,uno),e(k,bno),e(k,Jg),e(Jg,vse),e(vse,vno),e(Jg,Fno),e(Jg,OP),e(OP,Tno),e(Jg,Mno),e(k,Eno),e(k,Yg),e(Yg,Fse),e(Fse,Cno),e(Yg,wno),e(Yg,VP),e(VP,Ano),e(Yg,Lno),e(k,yno),e(k,Kg),e(Kg,Tse),e(Tse,xno),e(Kg,$no),e(Kg,XP),e(XP,kno),e(Kg,Sno),e(k,Rno),e(k,Vn),e(Vn,Mse),e(Mse,Pno),e(Vn,Bno),e(Vn,zP),e(zP,Nno),e(Vn,Ino),e(Vn,QP),e(QP,qno),e(Vn,jno),e(k,Dno),e(k,Xn),e(Xn,Ese),e(Ese,Gno),e(Xn,Ono),e(Xn,WP),e(WP,Vno),e(Xn,Xno),e(Xn,HP),e(HP,zno),e(Xn,Qno),e(k,Wno),e(k,zn),e(zn,Cse),e(Cse,Hno),e(zn,Uno),e(zn,UP),e(UP,Jno),e(zn,Yno),e(zn,JP),e(JP,Kno),e(zn,Zno),e(k,eso),e(k,Zg),e(Zg,wse),e(wse,oso),e(Zg,rso),e(Zg,YP),e(YP,tso),e(Zg,aso),e(k,nso),e(k,eh),e(eh,Ase),e(Ase,sso),e(eh,lso),e(eh,KP),e(KP,iso),e(eh,dso),e(k,cso),e(k,oh),e(oh,Lse),e(Lse,fso),e(oh,mso),e(oh,ZP),e(ZP,gso),e(oh,hso),e(k,pso),e(k,Qn),e(Qn,yse),e(yse,_so),e(Qn,uso),e(Qn,eB),e(eB,bso),e(Qn,vso),e(Qn,oB),e(oB,Fso),e(Qn,Tso),e(k,Mso),e(k,rh),e(rh,xse),e(xse,Eso),e(rh,Cso),e(rh,rB),e(rB,wso),e(rh,Aso),e(k,Lso),e(k,Wn),e(Wn,$se),e($se,yso),e(Wn,xso),e(Wn,tB),e(tB,$so),e(Wn,kso),e(Wn,aB),e(aB,Sso),e(Wn,Rso),e(k,Pso),e(k,Hn),e(Hn,kse),e(kse,Bso),e(Hn,Nso),e(Hn,nB),e(nB,Iso),e(Hn,qso),e(Hn,sB),e(sB,jso),e(Hn,Dso),e(k,Gso),e(k,Un),e(Un,Sse),e(Sse,Oso),e(Un,Vso),e(Un,lB),e(lB,Xso),e(Un,zso),e(Un,iB),e(iB,Qso),e(Un,Wso),e(k,Hso),e(k,Jn),e(Jn,Rse),e(Rse,Uso),e(Jn,Jso),e(Jn,dB),e(dB,Yso),e(Jn,Kso),e(Jn,cB),e(cB,Zso),e(Jn,elo),e(k,olo),e(k,th),e(th,Pse),e(Pse,rlo),e(th,tlo),e(th,fB),e(fB,alo),e(th,nlo),e(k,slo),e(k,Yn),e(Yn,Bse),e(Bse,llo),e(Yn,ilo),e(Yn,mB),e(mB,dlo),e(Yn,clo),e(Yn,gB),e(gB,flo),e(Yn,mlo),e(k,glo),e(k,Kn),e(Kn,Nse),e(Nse,hlo),e(Kn,plo),e(Kn,hB),e(hB,_lo),e(Kn,ulo),e(Kn,pB),e(pB,blo),e(Kn,vlo),e(k,Flo),e(k,Zn),e(Zn,Ise),e(Ise,Tlo),e(Zn,Mlo),e(Zn,_B),e(_B,Elo),e(Zn,Clo),e(Zn,uB),e(uB,wlo),e(Zn,Alo),e(k,Llo),e(k,es),e(es,qse),e(qse,ylo),e(es,xlo),e(es,bB),e(bB,$lo),e(es,klo),e(es,vB),e(vB,Slo),e(es,Rlo),e(k,Plo),e(k,os),e(os,jse),e(jse,Blo),e(os,Nlo),e(os,FB),e(FB,Ilo),e(os,qlo),e(os,TB),e(TB,jlo),e(os,Dlo),e(k,Glo),e(k,rs),e(rs,Dse),e(Dse,Olo),e(rs,Vlo),e(rs,MB),e(MB,Xlo),e(rs,zlo),e(rs,EB),e(EB,Qlo),e(rs,Wlo),e(k,Hlo),e(k,ah),e(ah,Gse),e(Gse,Ulo),e(ah,Jlo),e(ah,CB),e(CB,Ylo),e(ah,Klo),e(k,Zlo),e(k,ts),e(ts,Ose),e(Ose,eio),e(ts,oio),e(ts,wB),e(wB,rio),e(ts,tio),e(ts,AB),e(AB,aio),e(ts,nio),e(k,sio),e(k,nh),e(nh,Vse),e(Vse,lio),e(nh,iio),e(nh,LB),e(LB,dio),e(nh,cio),e(k,fio),e(k,as),e(as,Xse),e(Xse,mio),e(as,gio),e(as,yB),e(yB,hio),e(as,pio),e(as,xB),e(xB,_io),e(as,uio),e(k,bio),e(k,ns),e(ns,zse),e(zse,vio),e(ns,Fio),e(ns,$B),e($B,Tio),e(ns,Mio),e(ns,kB),e(kB,Eio),e(ns,Cio),e(k,wio),e(k,ss),e(ss,Qse),e(Qse,Aio),e(ss,Lio),e(ss,SB),e(SB,yio),e(ss,xio),e(ss,RB),e(RB,$io),e(ss,kio),e(k,Sio),e(k,sh),e(sh,Wse),e(Wse,Rio),e(sh,Pio),e(sh,PB),e(PB,Bio),e(sh,Nio),e(k,Iio),e(k,ls),e(ls,Hse),e(Hse,qio),e(ls,jio),e(ls,BB),e(BB,Dio),e(ls,Gio),e(ls,NB),e(NB,Oio),e(ls,Vio),e(k,Xio),e(k,is),e(is,Use),e(Use,zio),e(is,Qio),e(is,IB),e(IB,Wio),e(is,Hio),e(is,qB),e(qB,Uio),e(is,Jio),e(k,Yio),e(k,ds),e(ds,Jse),e(Jse,Kio),e(ds,Zio),e(ds,jB),e(jB,edo),e(ds,odo),e(ds,DB),e(DB,rdo),e(ds,tdo),e(k,ado),e(k,lh),e(lh,Yse),e(Yse,ndo),e(lh,sdo),e(lh,GB),e(GB,ldo),e(lh,ido),e(k,ddo),e(k,cs),e(cs,Kse),e(Kse,cdo),e(cs,fdo),e(cs,OB),e(OB,mdo),e(cs,gdo),e(cs,VB),e(VB,hdo),e(cs,pdo),e(k,_do),e(k,fs),e(fs,Zse),e(Zse,udo),e(fs,bdo),e(fs,XB),e(XB,vdo),e(fs,Fdo),e(fs,zB),e(zB,Tdo),e(fs,Mdo),e(k,Edo),e(k,ms),e(ms,ele),e(ele,Cdo),e(ms,wdo),e(ms,QB),e(QB,Ado),e(ms,Ldo),e(ms,WB),e(WB,ydo),e(ms,xdo),e(k,$do),e(k,gs),e(gs,ole),e(ole,kdo),e(gs,Sdo),e(gs,HB),e(HB,Rdo),e(gs,Pdo),e(gs,UB),e(UB,Bdo),e(gs,Ndo),e(k,Ido),e(k,hs),e(hs,rle),e(rle,qdo),e(hs,jdo),e(hs,JB),e(JB,Ddo),e(hs,Gdo),e(hs,YB),e(YB,Odo),e(hs,Vdo),e(k,Xdo),e(k,ps),e(ps,tle),e(tle,zdo),e(ps,Qdo),e(ps,KB),e(KB,Wdo),e(ps,Hdo),e(ps,ZB),e(ZB,Udo),e(ps,Jdo),e(k,Ydo),e(k,_s),e(_s,ale),e(ale,Kdo),e(_s,Zdo),e(_s,eN),e(eN,eco),e(_s,oco),e(_s,oN),e(oN,rco),e(_s,tco),e(k,aco),e(k,us),e(us,nle),e(nle,nco),e(us,sco),e(us,rN),e(rN,lco),e(us,ico),e(us,tN),e(tN,dco),e(us,cco),e(k,fco),e(k,ih),e(ih,sle),e(sle,mco),e(ih,gco),e(ih,aN),e(aN,hco),e(ih,pco),e(k,_co),e(k,bs),e(bs,lle),e(lle,uco),e(bs,bco),e(bs,nN),e(nN,vco),e(bs,Fco),e(bs,sN),e(sN,Tco),e(bs,Mco),e(k,Eco),e(k,dh),e(dh,ile),e(ile,Cco),e(dh,wco),e(dh,lN),e(lN,Aco),e(dh,Lco),e(k,yco),e(k,ch),e(ch,dle),e(dle,xco),e(ch,$co),e(ch,iN),e(iN,kco),e(ch,Sco),e(k,Rco),e(k,vs),e(vs,cle),e(cle,Pco),e(vs,Bco),e(vs,dN),e(dN,Nco),e(vs,Ico),e(vs,cN),e(cN,qco),e(vs,jco),e(k,Dco),e(k,Fs),e(Fs,fle),e(fle,Gco),e(Fs,Oco),e(Fs,fN),e(fN,Vco),e(Fs,Xco),e(Fs,mN),e(mN,zco),e(Fs,Qco),e(k,Wco),e(k,Ts),e(Ts,mle),e(mle,Hco),e(Ts,Uco),e(Ts,gN),e(gN,Jco),e(Ts,Yco),e(Ts,hN),e(hN,Kco),e(Ts,Zco),e(k,efo),e(k,fh),e(fh,gle),e(gle,ofo),e(fh,rfo),e(fh,pN),e(pN,tfo),e(fh,afo),e(k,nfo),e(k,Ms),e(Ms,hle),e(hle,sfo),e(Ms,lfo),e(Ms,_N),e(_N,ifo),e(Ms,dfo),e(Ms,uN),e(uN,cfo),e(Ms,ffo),e(k,mfo),e(k,Es),e(Es,ple),e(ple,gfo),e(Es,hfo),e(Es,bN),e(bN,pfo),e(Es,_fo),e(Es,vN),e(vN,ufo),e(Es,bfo),e(k,vfo),e(k,Cs),e(Cs,_le),e(_le,Ffo),e(Cs,Tfo),e(Cs,FN),e(FN,Mfo),e(Cs,Efo),e(Cs,TN),e(TN,Cfo),e(Cs,wfo),e(k,Afo),e(k,ws),e(ws,ule),e(ule,Lfo),e(ws,yfo),e(ws,MN),e(MN,xfo),e(ws,$fo),e(ws,EN),e(EN,kfo),e(ws,Sfo),e(k,Rfo),e(k,As),e(As,ble),e(ble,Pfo),e(As,Bfo),e(As,CN),e(CN,Nfo),e(As,Ifo),e(As,wN),e(wN,qfo),e(As,jfo),e(k,Dfo),e(k,Ls),e(Ls,vle),e(vle,Gfo),e(Ls,Ofo),e(Ls,AN),e(AN,Vfo),e(Ls,Xfo),e(Ls,LN),e(LN,zfo),e(Ls,Qfo),e(k,Wfo),e(k,mh),e(mh,Fle),e(Fle,Hfo),e(mh,Ufo),e(mh,yN),e(yN,Jfo),e(mh,Yfo),e(k,Kfo),e(k,ys),e(ys,Tle),e(Tle,Zfo),e(ys,emo),e(ys,xN),e(xN,omo),e(ys,rmo),e(ys,$N),e($N,tmo),e(ys,amo),e(k,nmo),e(k,gh),e(gh,Mle),e(Mle,smo),e(gh,lmo),e(gh,kN),e(kN,imo),e(gh,dmo),e(k,cmo),e(k,hh),e(hh,Ele),e(Ele,fmo),e(hh,mmo),e(hh,SN),e(SN,gmo),e(hh,hmo),e(k,pmo),e(k,ph),e(ph,Cle),e(Cle,_mo),e(ph,umo),e(ph,RN),e(RN,bmo),e(ph,vmo),e(k,Fmo),e(k,_h),e(_h,wle),e(wle,Tmo),e(_h,Mmo),e(_h,PN),e(PN,Emo),e(_h,Cmo),e(k,wmo),e(k,xs),e(xs,Ale),e(Ale,Amo),e(xs,Lmo),e(xs,BN),e(BN,ymo),e(xs,xmo),e(xs,NN),e(NN,$mo),e(xs,kmo),e(k,Smo),e(k,uh),e(uh,Lle),e(Lle,Rmo),e(uh,Pmo),e(uh,IN),e(IN,Bmo),e(uh,Nmo),e(k,Imo),e(k,$s),e($s,yle),e(yle,qmo),e($s,jmo),e($s,qN),e(qN,Dmo),e($s,Gmo),e($s,jN),e(jN,Omo),e($s,Vmo),e(k,Xmo),e(k,ks),e(ks,xle),e(xle,zmo),e(ks,Qmo),e(ks,DN),e(DN,Wmo),e(ks,Hmo),e(ks,GN),e(GN,Umo),e(ks,Jmo),e(k,Ymo),e(k,Ss),e(Ss,$le),e($le,Kmo),e(Ss,Zmo),e(Ss,ON),e(ON,ego),e(Ss,ogo),e(Ss,VN),e(VN,rgo),e(Ss,tgo),e(k,ago),e(k,Rs),e(Rs,kle),e(kle,ngo),e(Rs,sgo),e(Rs,XN),e(XN,lgo),e(Rs,igo),e(Rs,zN),e(zN,dgo),e(Rs,cgo),e(k,fgo),e(k,Ps),e(Ps,Sle),e(Sle,mgo),e(Ps,ggo),e(Ps,QN),e(QN,hgo),e(Ps,pgo),e(Ps,WN),e(WN,_go),e(Ps,ugo),e(k,bgo),e(k,Bs),e(Bs,Rle),e(Rle,vgo),e(Bs,Fgo),e(Bs,HN),e(HN,Tgo),e(Bs,Mgo),e(Bs,UN),e(UN,Ego),e(Bs,Cgo),e(k,wgo),e(k,bh),e(bh,Ple),e(Ple,Ago),e(bh,Lgo),e(bh,JN),e(JN,ygo),e(bh,xgo),e(k,$go),e(k,vh),e(vh,Ble),e(Ble,kgo),e(vh,Sgo),e(vh,YN),e(YN,Rgo),e(vh,Pgo),e(k,Bgo),e(k,Ns),e(Ns,Nle),e(Nle,Ngo),e(Ns,Igo),e(Ns,KN),e(KN,qgo),e(Ns,jgo),e(Ns,ZN),e(ZN,Dgo),e(Ns,Ggo),e(k,Ogo),e(k,Is),e(Is,Ile),e(Ile,Vgo),e(Is,Xgo),e(Is,eI),e(eI,zgo),e(Is,Qgo),e(Is,oI),e(oI,Wgo),e(Is,Hgo),e(k,Ugo),e(k,qs),e(qs,qle),e(qle,Jgo),e(qs,Ygo),e(qs,rI),e(rI,Kgo),e(qs,Zgo),e(qs,tI),e(tI,eho),e(qs,oho),e(k,rho),e(k,Fh),e(Fh,jle),e(jle,tho),e(Fh,aho),e(Fh,aI),e(aI,nho),e(Fh,sho),e(k,lho),e(k,Th),e(Th,Dle),e(Dle,iho),e(Th,dho),e(Th,nI),e(nI,cho),e(Th,fho),e(k,mho),e(k,Mh),e(Mh,Gle),e(Gle,gho),e(Mh,hho),e(Mh,sI),e(sI,pho),e(Mh,_ho),e(k,uho),e(k,js),e(js,Ole),e(Ole,bho),e(js,vho),e(js,lI),e(lI,Fho),e(js,Tho),e(js,iI),e(iI,Mho),e(js,Eho),e(k,Cho),e(k,Ds),e(Ds,Vle),e(Vle,who),e(Ds,Aho),e(Ds,dI),e(dI,Lho),e(Ds,yho),e(Ds,cI),e(cI,xho),e(Ds,$ho),e(k,kho),e(k,Eh),e(Eh,Xle),e(Xle,Sho),e(Eh,Rho),e(Eh,fI),e(fI,Pho),e(Eh,Bho),e(k,Nho),e(k,Ch),e(Ch,zle),e(zle,Iho),e(Ch,qho),e(Ch,mI),e(mI,jho),e(Ch,Dho),e(k,Gho),e(k,wh),e(wh,Qle),e(Qle,Oho),e(wh,Vho),e(wh,gI),e(gI,Xho),e(wh,zho),e(k,Qho),e(k,Gs),e(Gs,Wle),e(Wle,Who),e(Gs,Hho),e(Gs,hI),e(hI,Uho),e(Gs,Jho),e(Gs,pI),e(pI,Yho),e(Gs,Kho),e(k,Zho),e(k,Ah),e(Ah,Hle),e(Hle,epo),e(Ah,opo),e(Ah,_I),e(_I,rpo),e(Ah,tpo),e(k,apo),e(k,Lh),e(Lh,Ule),e(Ule,npo),e(Lh,spo),e(Lh,uI),e(uI,lpo),e(Lh,ipo),e(k,dpo),e(k,Os),e(Os,Jle),e(Jle,cpo),e(Os,fpo),e(Os,bI),e(bI,mpo),e(Os,gpo),e(Os,vI),e(vI,hpo),e(Os,ppo),e(k,_po),e(k,Vs),e(Vs,Yle),e(Yle,upo),e(Vs,bpo),e(Vs,FI),e(FI,vpo),e(Vs,Fpo),e(Vs,TI),e(TI,Tpo),e(Vs,Mpo),e(k,Epo),e(k,Xs),e(Xs,Kle),e(Kle,Cpo),e(Xs,wpo),e(Xs,MI),e(MI,Apo),e(Xs,Lpo),e(Xs,EI),e(EI,ypo),e(Xs,xpo),e(k,$po),e(k,zs),e(zs,Zle),e(Zle,kpo),e(zs,Spo),e(zs,CI),e(CI,Rpo),e(zs,Ppo),e(zs,wI),e(wI,Bpo),e(zs,Npo),e(yr,Ipo),M(yh,yr,null),e(Ao,qpo),e(Ao,xh),M(oy,xh,null),e(xh,jpo),e(xh,eie),e(eie,Dpo),b(f,HOe,u),b(f,Bi,u),e(Bi,$h),e($h,oie),M(ry,oie,null),e(Bi,Gpo),e(Bi,rie),e(rie,Opo),b(f,UOe,u),b(f,Lo,u),M(ty,Lo,null),e(Lo,Vpo),e(Lo,ay),e(ay,Xpo),e(ay,AI),e(AI,zpo),e(ay,Qpo),e(Lo,Wpo),e(Lo,ny),e(ny,Hpo),e(ny,tie),e(tie,Upo),e(ny,Jpo),e(Lo,Ypo),e(Lo,He),M(sy,He,null),e(He,Kpo),e(He,aie),e(aie,Zpo),e(He,e_o),e(He,Pa),e(Pa,o_o),e(Pa,nie),e(nie,r_o),e(Pa,t_o),e(Pa,sie),e(sie,a_o),e(Pa,n_o),e(Pa,lie),e(lie,s_o),e(Pa,l_o),e(He,i_o),e(He,Y),e(Y,kh),e(kh,iie),e(iie,d_o),e(kh,c_o),e(kh,LI),e(LI,f_o),e(kh,m_o),e(Y,g_o),e(Y,Sh),e(Sh,die),e(die,h_o),e(Sh,p_o),e(Sh,yI),e(yI,__o),e(Sh,u_o),e(Y,b_o),e(Y,Rh),e(Rh,cie),e(cie,v_o),e(Rh,F_o),e(Rh,xI),e(xI,T_o),e(Rh,M_o),e(Y,E_o),e(Y,Ph),e(Ph,fie),e(fie,C_o),e(Ph,w_o),e(Ph,$I),e($I,A_o),e(Ph,L_o),e(Y,y_o),e(Y,Bh),e(Bh,mie),e(mie,x_o),e(Bh,$_o),e(Bh,kI),e(kI,k_o),e(Bh,S_o),e(Y,R_o),e(Y,Nh),e(Nh,gie),e(gie,P_o),e(Nh,B_o),e(Nh,SI),e(SI,N_o),e(Nh,I_o),e(Y,q_o),e(Y,Ih),e(Ih,hie),e(hie,j_o),e(Ih,D_o),e(Ih,RI),e(RI,G_o),e(Ih,O_o),e(Y,V_o),e(Y,qh),e(qh,pie),e(pie,X_o),e(qh,z_o),e(qh,PI),e(PI,Q_o),e(qh,W_o),e(Y,H_o),e(Y,jh),e(jh,_ie),e(_ie,U_o),e(jh,J_o),e(jh,BI),e(BI,Y_o),e(jh,K_o),e(Y,Z_o),e(Y,Dh),e(Dh,uie),e(uie,euo),e(Dh,ouo),e(Dh,NI),e(NI,ruo),e(Dh,tuo),e(Y,auo),e(Y,Gh),e(Gh,bie),e(bie,nuo),e(Gh,suo),e(Gh,II),e(II,luo),e(Gh,iuo),e(Y,duo),e(Y,Oh),e(Oh,vie),e(vie,cuo),e(Oh,fuo),e(Oh,qI),e(qI,muo),e(Oh,guo),e(Y,huo),e(Y,Vh),e(Vh,Fie),e(Fie,puo),e(Vh,_uo),e(Vh,jI),e(jI,uuo),e(Vh,buo),e(Y,vuo),e(Y,Xh),e(Xh,Tie),e(Tie,Fuo),e(Xh,Tuo),e(Xh,DI),e(DI,Muo),e(Xh,Euo),e(Y,Cuo),e(Y,zh),e(zh,Mie),e(Mie,wuo),e(zh,Auo),e(zh,GI),e(GI,Luo),e(zh,yuo),e(Y,xuo),e(Y,Qh),e(Qh,Eie),e(Eie,$uo),e(Qh,kuo),e(Qh,OI),e(OI,Suo),e(Qh,Ruo),e(Y,Puo),e(Y,Wh),e(Wh,Cie),e(Cie,Buo),e(Wh,Nuo),e(Wh,VI),e(VI,Iuo),e(Wh,quo),e(Y,juo),e(Y,Hh),e(Hh,wie),e(wie,Duo),e(Hh,Guo),e(Hh,XI),e(XI,Ouo),e(Hh,Vuo),e(Y,Xuo),e(Y,Uh),e(Uh,Aie),e(Aie,zuo),e(Uh,Quo),e(Uh,zI),e(zI,Wuo),e(Uh,Huo),e(Y,Uuo),e(Y,Jh),e(Jh,Lie),e(Lie,Juo),e(Jh,Yuo),e(Jh,QI),e(QI,Kuo),e(Jh,Zuo),e(Y,e2o),e(Y,Yh),e(Yh,yie),e(yie,o2o),e(Yh,r2o),e(Yh,WI),e(WI,t2o),e(Yh,a2o),e(Y,n2o),e(Y,Kh),e(Kh,xie),e(xie,s2o),e(Kh,l2o),e(Kh,HI),e(HI,i2o),e(Kh,d2o),e(Y,c2o),e(Y,Zh),e(Zh,$ie),e($ie,f2o),e(Zh,m2o),e(Zh,UI),e(UI,g2o),e(Zh,h2o),e(Y,p2o),e(Y,ep),e(ep,kie),e(kie,_2o),e(ep,u2o),e(ep,JI),e(JI,b2o),e(ep,v2o),e(Y,F2o),e(Y,op),e(op,Sie),e(Sie,T2o),e(op,M2o),e(op,YI),e(YI,E2o),e(op,C2o),e(Y,w2o),e(Y,rp),e(rp,Rie),e(Rie,A2o),e(rp,L2o),e(rp,KI),e(KI,y2o),e(rp,x2o),e(Y,$2o),e(Y,tp),e(tp,Pie),e(Pie,k2o),e(tp,S2o),e(tp,ZI),e(ZI,R2o),e(tp,P2o),e(Y,B2o),e(Y,ap),e(ap,Bie),e(Bie,N2o),e(ap,I2o),e(ap,eq),e(eq,q2o),e(ap,j2o),e(Y,D2o),e(Y,np),e(np,Nie),e(Nie,G2o),e(np,O2o),e(np,oq),e(oq,V2o),e(np,X2o),e(Y,z2o),e(Y,sp),e(sp,Iie),e(Iie,Q2o),e(sp,W2o),e(sp,rq),e(rq,H2o),e(sp,U2o),e(Y,J2o),e(Y,lp),e(lp,qie),e(qie,Y2o),e(lp,K2o),e(lp,tq),e(tq,Z2o),e(lp,e1o),e(Y,o1o),e(Y,ip),e(ip,jie),e(jie,r1o),e(ip,t1o),e(ip,aq),e(aq,a1o),e(ip,n1o),e(Y,s1o),e(Y,dp),e(dp,Die),e(Die,l1o),e(dp,i1o),e(dp,nq),e(nq,d1o),e(dp,c1o),e(He,f1o),M(cp,He,null),e(He,m1o),M(fp,He,null),e(Lo,g1o),e(Lo,mp),M(ly,mp,null),e(mp,h1o),e(mp,Gie),e(Gie,p1o),b(f,JOe,u),b(f,Ni,u),e(Ni,gp),e(gp,Oie),M(iy,Oie,null),e(Ni,_1o),e(Ni,Vie),e(Vie,u1o),b(f,YOe,u),b(f,yo,u),M(dy,yo,null),e(yo,b1o),e(yo,cy),e(cy,v1o),e(cy,sq),e(sq,F1o),e(cy,T1o),e(yo,M1o),e(yo,fy),e(fy,E1o),e(fy,Xie),e(Xie,C1o),e(fy,w1o),e(yo,A1o),e(yo,Ue),M(my,Ue,null),e(Ue,L1o),e(Ue,zie),e(zie,y1o),e(Ue,x1o),e(Ue,Ii),e(Ii,$1o),e(Ii,Qie),e(Qie,k1o),e(Ii,S1o),e(Ii,Wie),e(Wie,R1o),e(Ii,P1o),e(Ue,B1o),e(Ue,he),e(he,hp),e(hp,Hie),e(Hie,N1o),e(hp,I1o),e(hp,lq),e(lq,q1o),e(hp,j1o),e(he,D1o),e(he,pp),e(pp,Uie),e(Uie,G1o),e(pp,O1o),e(pp,Jie),e(Jie,V1o),e(pp,X1o),e(he,z1o),e(he,_p),e(_p,Yie),e(Yie,Q1o),e(_p,W1o),e(_p,iq),e(iq,H1o),e(_p,U1o),e(he,J1o),e(he,up),e(up,Kie),e(Kie,Y1o),e(up,K1o),e(up,dq),e(dq,Z1o),e(up,e7o),e(he,o7o),e(he,bp),e(bp,Zie),e(Zie,r7o),e(bp,t7o),e(bp,cq),e(cq,a7o),e(bp,n7o),e(he,s7o),e(he,vp),e(vp,ede),e(ede,l7o),e(vp,i7o),e(vp,fq),e(fq,d7o),e(vp,c7o),e(he,f7o),e(he,Fp),e(Fp,ode),e(ode,m7o),e(Fp,g7o),e(Fp,mq),e(mq,h7o),e(Fp,p7o),e(he,_7o),e(he,Tp),e(Tp,rde),e(rde,u7o),e(Tp,b7o),e(Tp,gq),e(gq,v7o),e(Tp,F7o),e(he,T7o),e(he,Mp),e(Mp,tde),e(tde,M7o),e(Mp,E7o),e(Mp,hq),e(hq,C7o),e(Mp,w7o),e(he,A7o),e(he,Ep),e(Ep,ade),e(ade,L7o),e(Ep,y7o),e(Ep,pq),e(pq,x7o),e(Ep,$7o),e(he,k7o),e(he,Cp),e(Cp,nde),e(nde,S7o),e(Cp,R7o),e(Cp,_q),e(_q,P7o),e(Cp,B7o),e(he,N7o),e(he,wp),e(wp,sde),e(sde,I7o),e(wp,q7o),e(wp,uq),e(uq,j7o),e(wp,D7o),e(he,G7o),e(he,Ap),e(Ap,lde),e(lde,O7o),e(Ap,V7o),e(Ap,bq),e(bq,X7o),e(Ap,z7o),e(he,Q7o),e(he,Lp),e(Lp,ide),e(ide,W7o),e(Lp,H7o),e(Lp,vq),e(vq,U7o),e(Lp,J7o),e(he,Y7o),e(he,yp),e(yp,dde),e(dde,K7o),e(yp,Z7o),e(yp,Fq),e(Fq,e4o),e(yp,o4o),e(he,r4o),e(he,xp),e(xp,cde),e(cde,t4o),e(xp,a4o),e(xp,Tq),e(Tq,n4o),e(xp,s4o),e(he,l4o),e(he,$p),e($p,fde),e(fde,i4o),e($p,d4o),e($p,Mq),e(Mq,c4o),e($p,f4o),e(he,m4o),e(he,kp),e(kp,mde),e(mde,g4o),e(kp,h4o),e(kp,Eq),e(Eq,p4o),e(kp,_4o),e(Ue,u4o),M(Sp,Ue,null),e(Ue,b4o),M(Rp,Ue,null),e(yo,v4o),e(yo,Pp),M(gy,Pp,null),e(Pp,F4o),e(Pp,gde),e(gde,T4o),b(f,KOe,u),b(f,qi,u),e(qi,Bp),e(Bp,hde),M(hy,hde,null),e(qi,M4o),e(qi,pde),e(pde,E4o),b(f,ZOe,u),b(f,xo,u),M(py,xo,null),e(xo,C4o),e(xo,ji),e(ji,w4o),e(ji,Cq),e(Cq,A4o),e(ji,L4o),e(ji,wq),e(wq,y4o),e(ji,x4o),e(xo,$4o),e(xo,_y),e(_y,k4o),e(_y,_de),e(_de,S4o),e(_y,R4o),e(xo,P4o),e(xo,st),M(uy,st,null),e(st,B4o),e(st,ude),e(ude,N4o),e(st,I4o),e(st,Di),e(Di,q4o),e(Di,bde),e(bde,j4o),e(Di,D4o),e(Di,Aq),e(Aq,G4o),e(Di,O4o),e(st,V4o),M(Np,st,null),e(xo,X4o),e(xo,Je),M(by,Je,null),e(Je,z4o),e(Je,vde),e(vde,Q4o),e(Je,W4o),e(Je,Ba),e(Ba,H4o),e(Ba,Fde),e(Fde,U4o),e(Ba,J4o),e(Ba,Tde),e(Tde,Y4o),e(Ba,K4o),e(Ba,Mde),e(Mde,Z4o),e(Ba,ebo),e(Je,obo),e(Je,y),e(y,Ip),e(Ip,Ede),e(Ede,rbo),e(Ip,tbo),e(Ip,Lq),e(Lq,abo),e(Ip,nbo),e(y,sbo),e(y,qp),e(qp,Cde),e(Cde,lbo),e(qp,ibo),e(qp,yq),e(yq,dbo),e(qp,cbo),e(y,fbo),e(y,jp),e(jp,wde),e(wde,mbo),e(jp,gbo),e(jp,xq),e(xq,hbo),e(jp,pbo),e(y,_bo),e(y,Dp),e(Dp,Ade),e(Ade,ubo),e(Dp,bbo),e(Dp,$q),e($q,vbo),e(Dp,Fbo),e(y,Tbo),e(y,Gp),e(Gp,Lde),e(Lde,Mbo),e(Gp,Ebo),e(Gp,kq),e(kq,Cbo),e(Gp,wbo),e(y,Abo),e(y,Op),e(Op,yde),e(yde,Lbo),e(Op,ybo),e(Op,Sq),e(Sq,xbo),e(Op,$bo),e(y,kbo),e(y,Vp),e(Vp,xde),e(xde,Sbo),e(Vp,Rbo),e(Vp,Rq),e(Rq,Pbo),e(Vp,Bbo),e(y,Nbo),e(y,Xp),e(Xp,$de),e($de,Ibo),e(Xp,qbo),e(Xp,Pq),e(Pq,jbo),e(Xp,Dbo),e(y,Gbo),e(y,zp),e(zp,kde),e(kde,Obo),e(zp,Vbo),e(zp,Bq),e(Bq,Xbo),e(zp,zbo),e(y,Qbo),e(y,Qp),e(Qp,Sde),e(Sde,Wbo),e(Qp,Hbo),e(Qp,Nq),e(Nq,Ubo),e(Qp,Jbo),e(y,Ybo),e(y,Wp),e(Wp,Rde),e(Rde,Kbo),e(Wp,Zbo),e(Wp,Iq),e(Iq,evo),e(Wp,ovo),e(y,rvo),e(y,Hp),e(Hp,Pde),e(Pde,tvo),e(Hp,avo),e(Hp,qq),e(qq,nvo),e(Hp,svo),e(y,lvo),e(y,Up),e(Up,Bde),e(Bde,ivo),e(Up,dvo),e(Up,jq),e(jq,cvo),e(Up,fvo),e(y,mvo),e(y,Jp),e(Jp,Nde),e(Nde,gvo),e(Jp,hvo),e(Jp,Dq),e(Dq,pvo),e(Jp,_vo),e(y,uvo),e(y,Yp),e(Yp,Ide),e(Ide,bvo),e(Yp,vvo),e(Yp,Gq),e(Gq,Fvo),e(Yp,Tvo),e(y,Mvo),e(y,Kp),e(Kp,qde),e(qde,Evo),e(Kp,Cvo),e(Kp,Oq),e(Oq,wvo),e(Kp,Avo),e(y,Lvo),e(y,Zp),e(Zp,jde),e(jde,yvo),e(Zp,xvo),e(Zp,Vq),e(Vq,$vo),e(Zp,kvo),e(y,Svo),e(y,e_),e(e_,Dde),e(Dde,Rvo),e(e_,Pvo),e(e_,Xq),e(Xq,Bvo),e(e_,Nvo),e(y,Ivo),e(y,o_),e(o_,Gde),e(Gde,qvo),e(o_,jvo),e(o_,zq),e(zq,Dvo),e(o_,Gvo),e(y,Ovo),e(y,r_),e(r_,Ode),e(Ode,Vvo),e(r_,Xvo),e(r_,Qq),e(Qq,zvo),e(r_,Qvo),e(y,Wvo),e(y,t_),e(t_,Vde),e(Vde,Hvo),e(t_,Uvo),e(t_,Wq),e(Wq,Jvo),e(t_,Yvo),e(y,Kvo),e(y,a_),e(a_,Xde),e(Xde,Zvo),e(a_,eFo),e(a_,Hq),e(Hq,oFo),e(a_,rFo),e(y,tFo),e(y,n_),e(n_,zde),e(zde,aFo),e(n_,nFo),e(n_,Uq),e(Uq,sFo),e(n_,lFo),e(y,iFo),e(y,s_),e(s_,Qde),e(Qde,dFo),e(s_,cFo),e(s_,Jq),e(Jq,fFo),e(s_,mFo),e(y,gFo),e(y,l_),e(l_,Wde),e(Wde,hFo),e(l_,pFo),e(l_,Yq),e(Yq,_Fo),e(l_,uFo),e(y,bFo),e(y,i_),e(i_,Hde),e(Hde,vFo),e(i_,FFo),e(i_,Kq),e(Kq,TFo),e(i_,MFo),e(y,EFo),e(y,d_),e(d_,Ude),e(Ude,CFo),e(d_,wFo),e(d_,Zq),e(Zq,AFo),e(d_,LFo),e(y,yFo),e(y,c_),e(c_,Jde),e(Jde,xFo),e(c_,$Fo),e(c_,ej),e(ej,kFo),e(c_,SFo),e(y,RFo),e(y,f_),e(f_,Yde),e(Yde,PFo),e(f_,BFo),e(f_,oj),e(oj,NFo),e(f_,IFo),e(y,qFo),e(y,m_),e(m_,Kde),e(Kde,jFo),e(m_,DFo),e(m_,rj),e(rj,GFo),e(m_,OFo),e(y,VFo),e(y,g_),e(g_,Zde),e(Zde,XFo),e(g_,zFo),e(g_,tj),e(tj,QFo),e(g_,WFo),e(y,HFo),e(y,h_),e(h_,ece),e(ece,UFo),e(h_,JFo),e(h_,aj),e(aj,YFo),e(h_,KFo),e(y,ZFo),e(y,p_),e(p_,oce),e(oce,eTo),e(p_,oTo),e(p_,nj),e(nj,rTo),e(p_,tTo),e(y,aTo),e(y,__),e(__,rce),e(rce,nTo),e(__,sTo),e(__,sj),e(sj,lTo),e(__,iTo),e(y,dTo),e(y,Qs),e(Qs,tce),e(tce,cTo),e(Qs,fTo),e(Qs,lj),e(lj,mTo),e(Qs,gTo),e(Qs,ij),e(ij,hTo),e(Qs,pTo),e(y,_To),e(y,u_),e(u_,ace),e(ace,uTo),e(u_,bTo),e(u_,dj),e(dj,vTo),e(u_,FTo),e(y,TTo),e(y,b_),e(b_,nce),e(nce,MTo),e(b_,ETo),e(b_,cj),e(cj,CTo),e(b_,wTo),e(y,ATo),e(y,v_),e(v_,sce),e(sce,LTo),e(v_,yTo),e(v_,fj),e(fj,xTo),e(v_,$To),e(y,kTo),e(y,F_),e(F_,lce),e(lce,STo),e(F_,RTo),e(F_,mj),e(mj,PTo),e(F_,BTo),e(y,NTo),e(y,T_),e(T_,ice),e(ice,ITo),e(T_,qTo),e(T_,gj),e(gj,jTo),e(T_,DTo),e(y,GTo),e(y,M_),e(M_,dce),e(dce,OTo),e(M_,VTo),e(M_,hj),e(hj,XTo),e(M_,zTo),e(y,QTo),e(y,E_),e(E_,cce),e(cce,WTo),e(E_,HTo),e(E_,pj),e(pj,UTo),e(E_,JTo),e(y,YTo),e(y,C_),e(C_,fce),e(fce,KTo),e(C_,ZTo),e(C_,_j),e(_j,eMo),e(C_,oMo),e(y,rMo),e(y,w_),e(w_,mce),e(mce,tMo),e(w_,aMo),e(w_,uj),e(uj,nMo),e(w_,sMo),e(y,lMo),e(y,A_),e(A_,gce),e(gce,iMo),e(A_,dMo),e(A_,bj),e(bj,cMo),e(A_,fMo),e(y,mMo),e(y,L_),e(L_,hce),e(hce,gMo),e(L_,hMo),e(L_,vj),e(vj,pMo),e(L_,_Mo),e(y,uMo),e(y,y_),e(y_,pce),e(pce,bMo),e(y_,vMo),e(y_,Fj),e(Fj,FMo),e(y_,TMo),e(y,MMo),e(y,x_),e(x_,_ce),e(_ce,EMo),e(x_,CMo),e(x_,Tj),e(Tj,wMo),e(x_,AMo),e(y,LMo),e(y,$_),e($_,uce),e(uce,yMo),e($_,xMo),e($_,Mj),e(Mj,$Mo),e($_,kMo),e(y,SMo),e(y,k_),e(k_,bce),e(bce,RMo),e(k_,PMo),e(k_,Ej),e(Ej,BMo),e(k_,NMo),e(y,IMo),e(y,S_),e(S_,vce),e(vce,qMo),e(S_,jMo),e(S_,Cj),e(Cj,DMo),e(S_,GMo),e(y,OMo),e(y,R_),e(R_,Fce),e(Fce,VMo),e(R_,XMo),e(R_,wj),e(wj,zMo),e(R_,QMo),e(y,WMo),e(y,P_),e(P_,Tce),e(Tce,HMo),e(P_,UMo),e(P_,Aj),e(Aj,JMo),e(P_,YMo),e(y,KMo),e(y,B_),e(B_,Mce),e(Mce,ZMo),e(B_,eEo),e(B_,Lj),e(Lj,oEo),e(B_,rEo),e(y,tEo),e(y,N_),e(N_,Ece),e(Ece,aEo),e(N_,nEo),e(N_,yj),e(yj,sEo),e(N_,lEo),e(y,iEo),e(y,I_),e(I_,Cce),e(Cce,dEo),e(I_,cEo),e(I_,xj),e(xj,fEo),e(I_,mEo),e(y,gEo),e(y,q_),e(q_,wce),e(wce,hEo),e(q_,pEo),e(q_,$j),e($j,_Eo),e(q_,uEo),e(y,bEo),e(y,j_),e(j_,Ace),e(Ace,vEo),e(j_,FEo),e(j_,kj),e(kj,TEo),e(j_,MEo),e(y,EEo),e(y,D_),e(D_,Lce),e(Lce,CEo),e(D_,wEo),e(D_,Sj),e(Sj,AEo),e(D_,LEo),e(y,yEo),e(y,G_),e(G_,yce),e(yce,xEo),e(G_,$Eo),e(G_,Rj),e(Rj,kEo),e(G_,SEo),e(y,REo),e(y,O_),e(O_,xce),e(xce,PEo),e(O_,BEo),e(O_,Pj),e(Pj,NEo),e(O_,IEo),e(y,qEo),e(y,V_),e(V_,$ce),e($ce,jEo),e(V_,DEo),e(V_,Bj),e(Bj,GEo),e(V_,OEo),e(y,VEo),e(y,X_),e(X_,kce),e(kce,XEo),e(X_,zEo),e(X_,Nj),e(Nj,QEo),e(X_,WEo),e(y,HEo),e(y,z_),e(z_,Sce),e(Sce,UEo),e(z_,JEo),e(z_,Ij),e(Ij,YEo),e(z_,KEo),e(y,ZEo),e(y,Q_),e(Q_,Rce),e(Rce,eCo),e(Q_,oCo),e(Q_,qj),e(qj,rCo),e(Q_,tCo),e(y,aCo),e(y,W_),e(W_,Pce),e(Pce,nCo),e(W_,sCo),e(W_,jj),e(jj,lCo),e(W_,iCo),e(y,dCo),e(y,H_),e(H_,Bce),e(Bce,cCo),e(H_,fCo),e(H_,Dj),e(Dj,mCo),e(H_,gCo),e(y,hCo),e(y,U_),e(U_,Nce),e(Nce,pCo),e(U_,_Co),e(U_,Gj),e(Gj,uCo),e(U_,bCo),e(y,vCo),e(y,J_),e(J_,Ice),e(Ice,FCo),e(J_,TCo),e(J_,Oj),e(Oj,MCo),e(J_,ECo),e(y,CCo),e(y,Y_),e(Y_,qce),e(qce,wCo),e(Y_,ACo),e(Y_,Vj),e(Vj,LCo),e(Y_,yCo),e(y,xCo),e(y,K_),e(K_,jce),e(jce,$Co),e(K_,kCo),e(K_,Xj),e(Xj,SCo),e(K_,RCo),e(y,PCo),e(y,Z_),e(Z_,Dce),e(Dce,BCo),e(Z_,NCo),e(Z_,zj),e(zj,ICo),e(Z_,qCo),e(y,jCo),e(y,eu),e(eu,Gce),e(Gce,DCo),e(eu,GCo),e(eu,Qj),e(Qj,OCo),e(eu,VCo),e(y,XCo),e(y,ou),e(ou,Oce),e(Oce,zCo),e(ou,QCo),e(ou,Wj),e(Wj,WCo),e(ou,HCo),e(y,UCo),e(y,ru),e(ru,Vce),e(Vce,JCo),e(ru,YCo),e(ru,Hj),e(Hj,KCo),e(ru,ZCo),e(y,e3o),e(y,tu),e(tu,Xce),e(Xce,o3o),e(tu,r3o),e(tu,Uj),e(Uj,t3o),e(tu,a3o),e(y,n3o),e(y,au),e(au,zce),e(zce,s3o),e(au,l3o),e(au,Jj),e(Jj,i3o),e(au,d3o),e(y,c3o),e(y,nu),e(nu,Qce),e(Qce,f3o),e(nu,m3o),e(nu,Yj),e(Yj,g3o),e(nu,h3o),e(y,p3o),e(y,su),e(su,Wce),e(Wce,_3o),e(su,u3o),e(su,Kj),e(Kj,b3o),e(su,v3o),e(y,F3o),e(y,lu),e(lu,Hce),e(Hce,T3o),e(lu,M3o),e(lu,Zj),e(Zj,E3o),e(lu,C3o),e(y,w3o),e(y,iu),e(iu,Uce),e(Uce,A3o),e(iu,L3o),e(iu,eD),e(eD,y3o),e(iu,x3o),e(y,$3o),e(y,du),e(du,Jce),e(Jce,k3o),e(du,S3o),e(du,oD),e(oD,R3o),e(du,P3o),e(y,B3o),e(y,cu),e(cu,Yce),e(Yce,N3o),e(cu,I3o),e(cu,rD),e(rD,q3o),e(cu,j3o),e(y,D3o),e(y,fu),e(fu,Kce),e(Kce,G3o),e(fu,O3o),e(fu,tD),e(tD,V3o),e(fu,X3o),e(y,z3o),e(y,mu),e(mu,Zce),e(Zce,Q3o),e(mu,W3o),e(mu,aD),e(aD,H3o),e(mu,U3o),e(y,J3o),e(y,gu),e(gu,efe),e(efe,Y3o),e(gu,K3o),e(gu,nD),e(nD,Z3o),e(gu,e5o),e(y,o5o),e(y,hu),e(hu,ofe),e(ofe,r5o),e(hu,t5o),e(hu,sD),e(sD,a5o),e(hu,n5o),e(y,s5o),e(y,pu),e(pu,rfe),e(rfe,l5o),e(pu,i5o),e(pu,lD),e(lD,d5o),e(pu,c5o),e(y,f5o),e(y,_u),e(_u,tfe),e(tfe,m5o),e(_u,g5o),e(_u,iD),e(iD,h5o),e(_u,p5o),e(y,_5o),e(y,uu),e(uu,afe),e(afe,u5o),e(uu,b5o),e(uu,dD),e(dD,v5o),e(uu,F5o),e(y,T5o),e(y,bu),e(bu,nfe),e(nfe,M5o),e(bu,E5o),e(bu,cD),e(cD,C5o),e(bu,w5o),e(y,A5o),e(y,vu),e(vu,sfe),e(sfe,L5o),e(vu,y5o),e(vu,fD),e(fD,x5o),e(vu,$5o),e(y,k5o),e(y,Fu),e(Fu,lfe),e(lfe,S5o),e(Fu,R5o),e(Fu,mD),e(mD,P5o),e(Fu,B5o),e(y,N5o),e(y,Tu),e(Tu,ife),e(ife,I5o),e(Tu,q5o),e(Tu,gD),e(gD,j5o),e(Tu,D5o),e(y,G5o),e(y,Mu),e(Mu,dfe),e(dfe,O5o),e(Mu,V5o),e(Mu,hD),e(hD,X5o),e(Mu,z5o),e(y,Q5o),e(y,Eu),e(Eu,cfe),e(cfe,W5o),e(Eu,H5o),e(Eu,pD),e(pD,U5o),e(Eu,J5o),e(y,Y5o),e(y,Cu),e(Cu,ffe),e(ffe,K5o),e(Cu,Z5o),e(Cu,_D),e(_D,e0o),e(Cu,o0o),e(y,r0o),e(y,wu),e(wu,mfe),e(mfe,t0o),e(wu,a0o),e(wu,uD),e(uD,n0o),e(wu,s0o),e(y,l0o),e(y,Au),e(Au,gfe),e(gfe,i0o),e(Au,d0o),e(Au,bD),e(bD,c0o),e(Au,f0o),e(y,m0o),e(y,Lu),e(Lu,hfe),e(hfe,g0o),e(Lu,h0o),e(Lu,vD),e(vD,p0o),e(Lu,_0o),e(y,u0o),e(y,yu),e(yu,pfe),e(pfe,b0o),e(yu,v0o),e(yu,FD),e(FD,F0o),e(yu,T0o),e(y,M0o),e(y,xu),e(xu,_fe),e(_fe,E0o),e(xu,C0o),e(xu,TD),e(TD,w0o),e(xu,A0o),e(y,L0o),e(y,$u),e($u,ufe),e(ufe,y0o),e($u,x0o),e($u,MD),e(MD,$0o),e($u,k0o),e(y,S0o),e(y,ku),e(ku,bfe),e(bfe,R0o),e(ku,P0o),e(ku,ED),e(ED,B0o),e(ku,N0o),e(y,I0o),e(y,Su),e(Su,vfe),e(vfe,q0o),e(Su,j0o),e(Su,CD),e(CD,D0o),e(Su,G0o),e(y,O0o),e(y,Ru),e(Ru,Ffe),e(Ffe,V0o),e(Ru,X0o),e(Ru,wD),e(wD,z0o),e(Ru,Q0o),e(y,W0o),e(y,Pu),e(Pu,Tfe),e(Tfe,H0o),e(Pu,U0o),e(Pu,AD),e(AD,J0o),e(Pu,Y0o),e(y,K0o),e(y,Bu),e(Bu,Mfe),e(Mfe,Z0o),e(Bu,ewo),e(Bu,LD),e(LD,owo),e(Bu,rwo),e(y,two),e(y,Nu),e(Nu,Efe),e(Efe,awo),e(Nu,nwo),e(Nu,yD),e(yD,swo),e(Nu,lwo),e(Je,iwo),e(Je,Iu),e(Iu,dwo),e(Iu,Cfe),e(Cfe,cwo),e(Iu,fwo),e(Iu,wfe),e(wfe,mwo),e(Je,gwo),M(qu,Je,null),b(f,eVe,u),b(f,Gi,u),e(Gi,ju),e(ju,Afe),M(vy,Afe,null),e(Gi,hwo),e(Gi,Lfe),e(Lfe,pwo),b(f,oVe,u),b(f,$o,u),M(Fy,$o,null),e($o,_wo),e($o,Oi),e(Oi,uwo),e(Oi,xD),e(xD,bwo),e(Oi,vwo),e(Oi,$D),e($D,Fwo),e(Oi,Two),e($o,Mwo),e($o,Ty),e(Ty,Ewo),e(Ty,yfe),e(yfe,Cwo),e(Ty,wwo),e($o,Awo),e($o,lt),M(My,lt,null),e(lt,Lwo),e(lt,xfe),e(xfe,ywo),e(lt,xwo),e(lt,Vi),e(Vi,$wo),e(Vi,$fe),e($fe,kwo),e(Vi,Swo),e(Vi,kD),e(kD,Rwo),e(Vi,Pwo),e(lt,Bwo),M(Du,lt,null),e($o,Nwo),e($o,Ye),M(Ey,Ye,null),e(Ye,Iwo),e(Ye,kfe),e(kfe,qwo),e(Ye,jwo),e(Ye,Na),e(Na,Dwo),e(Na,Sfe),e(Sfe,Gwo),e(Na,Owo),e(Na,Rfe),e(Rfe,Vwo),e(Na,Xwo),e(Na,Pfe),e(Pfe,zwo),e(Na,Qwo),e(Ye,Wwo),e(Ye,G),e(G,Gu),e(Gu,Bfe),e(Bfe,Hwo),e(Gu,Uwo),e(Gu,SD),e(SD,Jwo),e(Gu,Ywo),e(G,Kwo),e(G,Ou),e(Ou,Nfe),e(Nfe,Zwo),e(Ou,eAo),e(Ou,RD),e(RD,oAo),e(Ou,rAo),e(G,tAo),e(G,Vu),e(Vu,Ife),e(Ife,aAo),e(Vu,nAo),e(Vu,PD),e(PD,sAo),e(Vu,lAo),e(G,iAo),e(G,Xu),e(Xu,qfe),e(qfe,dAo),e(Xu,cAo),e(Xu,BD),e(BD,fAo),e(Xu,mAo),e(G,gAo),e(G,zu),e(zu,jfe),e(jfe,hAo),e(zu,pAo),e(zu,ND),e(ND,_Ao),e(zu,uAo),e(G,bAo),e(G,Qu),e(Qu,Dfe),e(Dfe,vAo),e(Qu,FAo),e(Qu,ID),e(ID,TAo),e(Qu,MAo),e(G,EAo),e(G,Wu),e(Wu,Gfe),e(Gfe,CAo),e(Wu,wAo),e(Wu,qD),e(qD,AAo),e(Wu,LAo),e(G,yAo),e(G,Hu),e(Hu,Ofe),e(Ofe,xAo),e(Hu,$Ao),e(Hu,jD),e(jD,kAo),e(Hu,SAo),e(G,RAo),e(G,Uu),e(Uu,Vfe),e(Vfe,PAo),e(Uu,BAo),e(Uu,DD),e(DD,NAo),e(Uu,IAo),e(G,qAo),e(G,Ju),e(Ju,Xfe),e(Xfe,jAo),e(Ju,DAo),e(Ju,GD),e(GD,GAo),e(Ju,OAo),e(G,VAo),e(G,Yu),e(Yu,zfe),e(zfe,XAo),e(Yu,zAo),e(Yu,OD),e(OD,QAo),e(Yu,WAo),e(G,HAo),e(G,Ku),e(Ku,Qfe),e(Qfe,UAo),e(Ku,JAo),e(Ku,VD),e(VD,YAo),e(Ku,KAo),e(G,ZAo),e(G,Zu),e(Zu,Wfe),e(Wfe,e6o),e(Zu,o6o),e(Zu,XD),e(XD,r6o),e(Zu,t6o),e(G,a6o),e(G,e2),e(e2,Hfe),e(Hfe,n6o),e(e2,s6o),e(e2,zD),e(zD,l6o),e(e2,i6o),e(G,d6o),e(G,o2),e(o2,Ufe),e(Ufe,c6o),e(o2,f6o),e(o2,QD),e(QD,m6o),e(o2,g6o),e(G,h6o),e(G,r2),e(r2,Jfe),e(Jfe,p6o),e(r2,_6o),e(r2,WD),e(WD,u6o),e(r2,b6o),e(G,v6o),e(G,t2),e(t2,Yfe),e(Yfe,F6o),e(t2,T6o),e(t2,HD),e(HD,M6o),e(t2,E6o),e(G,C6o),e(G,a2),e(a2,Kfe),e(Kfe,w6o),e(a2,A6o),e(a2,UD),e(UD,L6o),e(a2,y6o),e(G,x6o),e(G,n2),e(n2,Zfe),e(Zfe,$6o),e(n2,k6o),e(n2,JD),e(JD,S6o),e(n2,R6o),e(G,P6o),e(G,s2),e(s2,eme),e(eme,B6o),e(s2,N6o),e(s2,YD),e(YD,I6o),e(s2,q6o),e(G,j6o),e(G,l2),e(l2,ome),e(ome,D6o),e(l2,G6o),e(l2,KD),e(KD,O6o),e(l2,V6o),e(G,X6o),e(G,i2),e(i2,rme),e(rme,z6o),e(i2,Q6o),e(i2,ZD),e(ZD,W6o),e(i2,H6o),e(G,U6o),e(G,d2),e(d2,tme),e(tme,J6o),e(d2,Y6o),e(d2,eG),e(eG,K6o),e(d2,Z6o),e(G,eLo),e(G,c2),e(c2,ame),e(ame,oLo),e(c2,rLo),e(c2,oG),e(oG,tLo),e(c2,aLo),e(G,nLo),e(G,f2),e(f2,nme),e(nme,sLo),e(f2,lLo),e(f2,rG),e(rG,iLo),e(f2,dLo),e(G,cLo),e(G,m2),e(m2,sme),e(sme,fLo),e(m2,mLo),e(m2,tG),e(tG,gLo),e(m2,hLo),e(G,pLo),e(G,g2),e(g2,lme),e(lme,_Lo),e(g2,uLo),e(g2,aG),e(aG,bLo),e(g2,vLo),e(G,FLo),e(G,h2),e(h2,ime),e(ime,TLo),e(h2,MLo),e(h2,nG),e(nG,ELo),e(h2,CLo),e(G,wLo),e(G,p2),e(p2,dme),e(dme,ALo),e(p2,LLo),e(p2,sG),e(sG,yLo),e(p2,xLo),e(G,$Lo),e(G,_2),e(_2,cme),e(cme,kLo),e(_2,SLo),e(_2,lG),e(lG,RLo),e(_2,PLo),e(G,BLo),e(G,u2),e(u2,fme),e(fme,NLo),e(u2,ILo),e(u2,iG),e(iG,qLo),e(u2,jLo),e(G,DLo),e(G,b2),e(b2,mme),e(mme,GLo),e(b2,OLo),e(b2,dG),e(dG,VLo),e(b2,XLo),e(G,zLo),e(G,v2),e(v2,gme),e(gme,QLo),e(v2,WLo),e(v2,cG),e(cG,HLo),e(v2,ULo),e(G,JLo),e(G,F2),e(F2,hme),e(hme,YLo),e(F2,KLo),e(F2,fG),e(fG,ZLo),e(F2,eyo),e(G,oyo),e(G,T2),e(T2,pme),e(pme,ryo),e(T2,tyo),e(T2,mG),e(mG,ayo),e(T2,nyo),e(G,syo),e(G,M2),e(M2,_me),e(_me,lyo),e(M2,iyo),e(M2,gG),e(gG,dyo),e(M2,cyo),e(G,fyo),e(G,E2),e(E2,ume),e(ume,myo),e(E2,gyo),e(E2,hG),e(hG,hyo),e(E2,pyo),e(G,_yo),e(G,C2),e(C2,bme),e(bme,uyo),e(C2,byo),e(C2,pG),e(pG,vyo),e(C2,Fyo),e(G,Tyo),e(G,w2),e(w2,vme),e(vme,Myo),e(w2,Eyo),e(w2,_G),e(_G,Cyo),e(w2,wyo),e(G,Ayo),e(G,A2),e(A2,Fme),e(Fme,Lyo),e(A2,yyo),e(A2,uG),e(uG,xyo),e(A2,$yo),e(G,kyo),e(G,L2),e(L2,Tme),e(Tme,Syo),e(L2,Ryo),e(L2,bG),e(bG,Pyo),e(L2,Byo),e(G,Nyo),e(G,y2),e(y2,Mme),e(Mme,Iyo),e(y2,qyo),e(y2,vG),e(vG,jyo),e(y2,Dyo),e(G,Gyo),e(G,x2),e(x2,Eme),e(Eme,Oyo),e(x2,Vyo),e(x2,FG),e(FG,Xyo),e(x2,zyo),e(G,Qyo),e(G,$2),e($2,Cme),e(Cme,Wyo),e($2,Hyo),e($2,TG),e(TG,Uyo),e($2,Jyo),e(Ye,Yyo),e(Ye,k2),e(k2,Kyo),e(k2,wme),e(wme,Zyo),e(k2,e8o),e(k2,Ame),e(Ame,o8o),e(Ye,r8o),M(S2,Ye,null),b(f,rVe,u),b(f,Xi,u),e(Xi,R2),e(R2,Lme),M(Cy,Lme,null),e(Xi,t8o),e(Xi,yme),e(yme,a8o),b(f,tVe,u),b(f,ko,u),M(wy,ko,null),e(ko,n8o),e(ko,zi),e(zi,s8o),e(zi,MG),e(MG,l8o),e(zi,i8o),e(zi,EG),e(EG,d8o),e(zi,c8o),e(ko,f8o),e(ko,Ay),e(Ay,m8o),e(Ay,xme),e(xme,g8o),e(Ay,h8o),e(ko,p8o),e(ko,it),M(Ly,it,null),e(it,_8o),e(it,$me),e($me,u8o),e(it,b8o),e(it,Qi),e(Qi,v8o),e(Qi,kme),e(kme,F8o),e(Qi,T8o),e(Qi,CG),e(CG,M8o),e(Qi,E8o),e(it,C8o),M(P2,it,null),e(ko,w8o),e(ko,Ke),M(yy,Ke,null),e(Ke,A8o),e(Ke,Sme),e(Sme,L8o),e(Ke,y8o),e(Ke,Ia),e(Ia,x8o),e(Ia,Rme),e(Rme,$8o),e(Ia,k8o),e(Ia,Pme),e(Pme,S8o),e(Ia,R8o),e(Ia,Bme),e(Bme,P8o),e(Ia,B8o),e(Ke,N8o),e(Ke,z),e(z,B2),e(B2,Nme),e(Nme,I8o),e(B2,q8o),e(B2,wG),e(wG,j8o),e(B2,D8o),e(z,G8o),e(z,N2),e(N2,Ime),e(Ime,O8o),e(N2,V8o),e(N2,AG),e(AG,X8o),e(N2,z8o),e(z,Q8o),e(z,I2),e(I2,qme),e(qme,W8o),e(I2,H8o),e(I2,LG),e(LG,U8o),e(I2,J8o),e(z,Y8o),e(z,q2),e(q2,jme),e(jme,K8o),e(q2,Z8o),e(q2,yG),e(yG,e9o),e(q2,o9o),e(z,r9o),e(z,j2),e(j2,Dme),e(Dme,t9o),e(j2,a9o),e(j2,xG),e(xG,n9o),e(j2,s9o),e(z,l9o),e(z,D2),e(D2,Gme),e(Gme,i9o),e(D2,d9o),e(D2,$G),e($G,c9o),e(D2,f9o),e(z,m9o),e(z,G2),e(G2,Ome),e(Ome,g9o),e(G2,h9o),e(G2,kG),e(kG,p9o),e(G2,_9o),e(z,u9o),e(z,O2),e(O2,Vme),e(Vme,b9o),e(O2,v9o),e(O2,SG),e(SG,F9o),e(O2,T9o),e(z,M9o),e(z,V2),e(V2,Xme),e(Xme,E9o),e(V2,C9o),e(V2,RG),e(RG,w9o),e(V2,A9o),e(z,L9o),e(z,X2),e(X2,zme),e(zme,y9o),e(X2,x9o),e(X2,PG),e(PG,$9o),e(X2,k9o),e(z,S9o),e(z,z2),e(z2,Qme),e(Qme,R9o),e(z2,P9o),e(z2,BG),e(BG,B9o),e(z2,N9o),e(z,I9o),e(z,Q2),e(Q2,Wme),e(Wme,q9o),e(Q2,j9o),e(Q2,NG),e(NG,D9o),e(Q2,G9o),e(z,O9o),e(z,W2),e(W2,Hme),e(Hme,V9o),e(W2,X9o),e(W2,IG),e(IG,z9o),e(W2,Q9o),e(z,W9o),e(z,H2),e(H2,Ume),e(Ume,H9o),e(H2,U9o),e(H2,qG),e(qG,J9o),e(H2,Y9o),e(z,K9o),e(z,U2),e(U2,Jme),e(Jme,Z9o),e(U2,exo),e(U2,jG),e(jG,oxo),e(U2,rxo),e(z,txo),e(z,J2),e(J2,Yme),e(Yme,axo),e(J2,nxo),e(J2,DG),e(DG,sxo),e(J2,lxo),e(z,ixo),e(z,Y2),e(Y2,Kme),e(Kme,dxo),e(Y2,cxo),e(Y2,GG),e(GG,fxo),e(Y2,mxo),e(z,gxo),e(z,K2),e(K2,Zme),e(Zme,hxo),e(K2,pxo),e(K2,OG),e(OG,_xo),e(K2,uxo),e(z,bxo),e(z,Z2),e(Z2,ege),e(ege,vxo),e(Z2,Fxo),e(Z2,VG),e(VG,Txo),e(Z2,Mxo),e(z,Exo),e(z,e1),e(e1,oge),e(oge,Cxo),e(e1,wxo),e(e1,XG),e(XG,Axo),e(e1,Lxo),e(z,yxo),e(z,o1),e(o1,rge),e(rge,xxo),e(o1,$xo),e(o1,zG),e(zG,kxo),e(o1,Sxo),e(z,Rxo),e(z,r1),e(r1,tge),e(tge,Pxo),e(r1,Bxo),e(r1,QG),e(QG,Nxo),e(r1,Ixo),e(z,qxo),e(z,t1),e(t1,age),e(age,jxo),e(t1,Dxo),e(t1,WG),e(WG,Gxo),e(t1,Oxo),e(z,Vxo),e(z,a1),e(a1,nge),e(nge,Xxo),e(a1,zxo),e(a1,HG),e(HG,Qxo),e(a1,Wxo),e(z,Hxo),e(z,n1),e(n1,sge),e(sge,Uxo),e(n1,Jxo),e(n1,UG),e(UG,Yxo),e(n1,Kxo),e(z,Zxo),e(z,s1),e(s1,lge),e(lge,e$o),e(s1,o$o),e(s1,JG),e(JG,r$o),e(s1,t$o),e(z,a$o),e(z,l1),e(l1,ige),e(ige,n$o),e(l1,s$o),e(l1,YG),e(YG,l$o),e(l1,i$o),e(z,d$o),e(z,i1),e(i1,dge),e(dge,c$o),e(i1,f$o),e(i1,KG),e(KG,m$o),e(i1,g$o),e(z,h$o),e(z,d1),e(d1,cge),e(cge,p$o),e(d1,_$o),e(d1,ZG),e(ZG,u$o),e(d1,b$o),e(z,v$o),e(z,c1),e(c1,fge),e(fge,F$o),e(c1,T$o),e(c1,eO),e(eO,M$o),e(c1,E$o),e(z,C$o),e(z,f1),e(f1,mge),e(mge,w$o),e(f1,A$o),e(f1,oO),e(oO,L$o),e(f1,y$o),e(z,x$o),e(z,m1),e(m1,gge),e(gge,$$o),e(m1,k$o),e(m1,rO),e(rO,S$o),e(m1,R$o),e(z,P$o),e(z,g1),e(g1,hge),e(hge,B$o),e(g1,N$o),e(g1,tO),e(tO,I$o),e(g1,q$o),e(z,j$o),e(z,h1),e(h1,pge),e(pge,D$o),e(h1,G$o),e(h1,aO),e(aO,O$o),e(h1,V$o),e(z,X$o),e(z,p1),e(p1,_ge),e(_ge,z$o),e(p1,Q$o),e(p1,nO),e(nO,W$o),e(p1,H$o),e(z,U$o),e(z,_1),e(_1,uge),e(uge,J$o),e(_1,Y$o),e(_1,sO),e(sO,K$o),e(_1,Z$o),e(z,eko),e(z,u1),e(u1,bge),e(bge,oko),e(u1,rko),e(u1,lO),e(lO,tko),e(u1,ako),e(z,nko),e(z,b1),e(b1,vge),e(vge,sko),e(b1,lko),e(b1,iO),e(iO,iko),e(b1,dko),e(z,cko),e(z,v1),e(v1,Fge),e(Fge,fko),e(v1,mko),e(v1,dO),e(dO,gko),e(v1,hko),e(Ke,pko),e(Ke,F1),e(F1,_ko),e(F1,Tge),e(Tge,uko),e(F1,bko),e(F1,Mge),e(Mge,vko),e(Ke,Fko),M(T1,Ke,null),b(f,aVe,u),b(f,Wi,u),e(Wi,M1),e(M1,Ege),M(xy,Ege,null),e(Wi,Tko),e(Wi,Cge),e(Cge,Mko),b(f,nVe,u),b(f,So,u),M($y,So,null),e(So,Eko),e(So,Hi),e(Hi,Cko),e(Hi,cO),e(cO,wko),e(Hi,Ako),e(Hi,fO),e(fO,Lko),e(Hi,yko),e(So,xko),e(So,ky),e(ky,$ko),e(ky,wge),e(wge,kko),e(ky,Sko),e(So,Rko),e(So,dt),M(Sy,dt,null),e(dt,Pko),e(dt,Age),e(Age,Bko),e(dt,Nko),e(dt,Ui),e(Ui,Iko),e(Ui,Lge),e(Lge,qko),e(Ui,jko),e(Ui,mO),e(mO,Dko),e(Ui,Gko),e(dt,Oko),M(E1,dt,null),e(So,Vko),e(So,Ze),M(Ry,Ze,null),e(Ze,Xko),e(Ze,yge),e(yge,zko),e(Ze,Qko),e(Ze,qa),e(qa,Wko),e(qa,xge),e(xge,Hko),e(qa,Uko),e(qa,$ge),e($ge,Jko),e(qa,Yko),e(qa,kge),e(kge,Kko),e(qa,Zko),e(Ze,eSo),e(Ze,W),e(W,C1),e(C1,Sge),e(Sge,oSo),e(C1,rSo),e(C1,gO),e(gO,tSo),e(C1,aSo),e(W,nSo),e(W,w1),e(w1,Rge),e(Rge,sSo),e(w1,lSo),e(w1,hO),e(hO,iSo),e(w1,dSo),e(W,cSo),e(W,A1),e(A1,Pge),e(Pge,fSo),e(A1,mSo),e(A1,pO),e(pO,gSo),e(A1,hSo),e(W,pSo),e(W,L1),e(L1,Bge),e(Bge,_So),e(L1,uSo),e(L1,_O),e(_O,bSo),e(L1,vSo),e(W,FSo),e(W,y1),e(y1,Nge),e(Nge,TSo),e(y1,MSo),e(y1,uO),e(uO,ESo),e(y1,CSo),e(W,wSo),e(W,x1),e(x1,Ige),e(Ige,ASo),e(x1,LSo),e(x1,bO),e(bO,ySo),e(x1,xSo),e(W,$So),e(W,$1),e($1,qge),e(qge,kSo),e($1,SSo),e($1,vO),e(vO,RSo),e($1,PSo),e(W,BSo),e(W,k1),e(k1,jge),e(jge,NSo),e(k1,ISo),e(k1,FO),e(FO,qSo),e(k1,jSo),e(W,DSo),e(W,S1),e(S1,Dge),e(Dge,GSo),e(S1,OSo),e(S1,TO),e(TO,VSo),e(S1,XSo),e(W,zSo),e(W,R1),e(R1,Gge),e(Gge,QSo),e(R1,WSo),e(R1,MO),e(MO,HSo),e(R1,USo),e(W,JSo),e(W,P1),e(P1,Oge),e(Oge,YSo),e(P1,KSo),e(P1,EO),e(EO,ZSo),e(P1,eRo),e(W,oRo),e(W,B1),e(B1,Vge),e(Vge,rRo),e(B1,tRo),e(B1,CO),e(CO,aRo),e(B1,nRo),e(W,sRo),e(W,N1),e(N1,Xge),e(Xge,lRo),e(N1,iRo),e(N1,wO),e(wO,dRo),e(N1,cRo),e(W,fRo),e(W,I1),e(I1,zge),e(zge,mRo),e(I1,gRo),e(I1,AO),e(AO,hRo),e(I1,pRo),e(W,_Ro),e(W,q1),e(q1,Qge),e(Qge,uRo),e(q1,bRo),e(q1,LO),e(LO,vRo),e(q1,FRo),e(W,TRo),e(W,j1),e(j1,Wge),e(Wge,MRo),e(j1,ERo),e(j1,yO),e(yO,CRo),e(j1,wRo),e(W,ARo),e(W,D1),e(D1,Hge),e(Hge,LRo),e(D1,yRo),e(D1,xO),e(xO,xRo),e(D1,$Ro),e(W,kRo),e(W,G1),e(G1,Uge),e(Uge,SRo),e(G1,RRo),e(G1,$O),e($O,PRo),e(G1,BRo),e(W,NRo),e(W,O1),e(O1,Jge),e(Jge,IRo),e(O1,qRo),e(O1,kO),e(kO,jRo),e(O1,DRo),e(W,GRo),e(W,V1),e(V1,Yge),e(Yge,ORo),e(V1,VRo),e(V1,SO),e(SO,XRo),e(V1,zRo),e(W,QRo),e(W,X1),e(X1,Kge),e(Kge,WRo),e(X1,HRo),e(X1,RO),e(RO,URo),e(X1,JRo),e(W,YRo),e(W,z1),e(z1,Zge),e(Zge,KRo),e(z1,ZRo),e(z1,PO),e(PO,ePo),e(z1,oPo),e(W,rPo),e(W,Q1),e(Q1,ehe),e(ehe,tPo),e(Q1,aPo),e(Q1,BO),e(BO,nPo),e(Q1,sPo),e(W,lPo),e(W,W1),e(W1,ohe),e(ohe,iPo),e(W1,dPo),e(W1,NO),e(NO,cPo),e(W1,fPo),e(W,mPo),e(W,H1),e(H1,rhe),e(rhe,gPo),e(H1,hPo),e(H1,IO),e(IO,pPo),e(H1,_Po),e(W,uPo),e(W,U1),e(U1,the),e(the,bPo),e(U1,vPo),e(U1,qO),e(qO,FPo),e(U1,TPo),e(W,MPo),e(W,J1),e(J1,ahe),e(ahe,EPo),e(J1,CPo),e(J1,jO),e(jO,wPo),e(J1,APo),e(W,LPo),e(W,Y1),e(Y1,nhe),e(nhe,yPo),e(Y1,xPo),e(Y1,DO),e(DO,$Po),e(Y1,kPo),e(W,SPo),e(W,K1),e(K1,she),e(she,RPo),e(K1,PPo),e(K1,GO),e(GO,BPo),e(K1,NPo),e(W,IPo),e(W,Z1),e(Z1,lhe),e(lhe,qPo),e(Z1,jPo),e(Z1,OO),e(OO,DPo),e(Z1,GPo),e(W,OPo),e(W,e7),e(e7,ihe),e(ihe,VPo),e(e7,XPo),e(e7,VO),e(VO,zPo),e(e7,QPo),e(W,WPo),e(W,o7),e(o7,dhe),e(dhe,HPo),e(o7,UPo),e(o7,XO),e(XO,JPo),e(o7,YPo),e(W,KPo),e(W,r7),e(r7,che),e(che,ZPo),e(r7,eBo),e(r7,fhe),e(fhe,oBo),e(r7,rBo),e(W,tBo),e(W,t7),e(t7,mhe),e(mhe,aBo),e(t7,nBo),e(t7,zO),e(zO,sBo),e(t7,lBo),e(W,iBo),e(W,a7),e(a7,ghe),e(ghe,dBo),e(a7,cBo),e(a7,QO),e(QO,fBo),e(a7,mBo),e(W,gBo),e(W,n7),e(n7,hhe),e(hhe,hBo),e(n7,pBo),e(n7,WO),e(WO,_Bo),e(n7,uBo),e(W,bBo),e(W,s7),e(s7,phe),e(phe,vBo),e(s7,FBo),e(s7,HO),e(HO,TBo),e(s7,MBo),e(Ze,EBo),e(Ze,l7),e(l7,CBo),e(l7,_he),e(_he,wBo),e(l7,ABo),e(l7,uhe),e(uhe,LBo),e(Ze,yBo),M(i7,Ze,null),b(f,sVe,u),b(f,Ji,u),e(Ji,d7),e(d7,bhe),M(Py,bhe,null),e(Ji,xBo),e(Ji,vhe),e(vhe,$Bo),b(f,lVe,u),b(f,Ro,u),M(By,Ro,null),e(Ro,kBo),e(Ro,Yi),e(Yi,SBo),e(Yi,UO),e(UO,RBo),e(Yi,PBo),e(Yi,JO),e(JO,BBo),e(Yi,NBo),e(Ro,IBo),e(Ro,Ny),e(Ny,qBo),e(Ny,Fhe),e(Fhe,jBo),e(Ny,DBo),e(Ro,GBo),e(Ro,ct),M(Iy,ct,null),e(ct,OBo),e(ct,The),e(The,VBo),e(ct,XBo),e(ct,Ki),e(Ki,zBo),e(Ki,Mhe),e(Mhe,QBo),e(Ki,WBo),e(Ki,YO),e(YO,HBo),e(Ki,UBo),e(ct,JBo),M(c7,ct,null),e(Ro,YBo),e(Ro,eo),M(qy,eo,null),e(eo,KBo),e(eo,Ehe),e(Ehe,ZBo),e(eo,eNo),e(eo,ja),e(ja,oNo),e(ja,Che),e(Che,rNo),e(ja,tNo),e(ja,whe),e(whe,aNo),e(ja,nNo),e(ja,Ahe),e(Ahe,sNo),e(ja,lNo),e(eo,iNo),e(eo,pe),e(pe,f7),e(f7,Lhe),e(Lhe,dNo),e(f7,cNo),e(f7,KO),e(KO,fNo),e(f7,mNo),e(pe,gNo),e(pe,m7),e(m7,yhe),e(yhe,hNo),e(m7,pNo),e(m7,ZO),e(ZO,_No),e(m7,uNo),e(pe,bNo),e(pe,g7),e(g7,xhe),e(xhe,vNo),e(g7,FNo),e(g7,eV),e(eV,TNo),e(g7,MNo),e(pe,ENo),e(pe,h7),e(h7,$he),e($he,CNo),e(h7,wNo),e(h7,oV),e(oV,ANo),e(h7,LNo),e(pe,yNo),e(pe,p7),e(p7,khe),e(khe,xNo),e(p7,$No),e(p7,rV),e(rV,kNo),e(p7,SNo),e(pe,RNo),e(pe,_7),e(_7,She),e(She,PNo),e(_7,BNo),e(_7,tV),e(tV,NNo),e(_7,INo),e(pe,qNo),e(pe,u7),e(u7,Rhe),e(Rhe,jNo),e(u7,DNo),e(u7,aV),e(aV,GNo),e(u7,ONo),e(pe,VNo),e(pe,b7),e(b7,Phe),e(Phe,XNo),e(b7,zNo),e(b7,nV),e(nV,QNo),e(b7,WNo),e(pe,HNo),e(pe,v7),e(v7,Bhe),e(Bhe,UNo),e(v7,JNo),e(v7,sV),e(sV,YNo),e(v7,KNo),e(pe,ZNo),e(pe,F7),e(F7,Nhe),e(Nhe,eIo),e(F7,oIo),e(F7,lV),e(lV,rIo),e(F7,tIo),e(pe,aIo),e(pe,T7),e(T7,Ihe),e(Ihe,nIo),e(T7,sIo),e(T7,iV),e(iV,lIo),e(T7,iIo),e(pe,dIo),e(pe,M7),e(M7,qhe),e(qhe,cIo),e(M7,fIo),e(M7,dV),e(dV,mIo),e(M7,gIo),e(pe,hIo),e(pe,E7),e(E7,jhe),e(jhe,pIo),e(E7,_Io),e(E7,cV),e(cV,uIo),e(E7,bIo),e(pe,vIo),e(pe,C7),e(C7,Dhe),e(Dhe,FIo),e(C7,TIo),e(C7,fV),e(fV,MIo),e(C7,EIo),e(pe,CIo),e(pe,w7),e(w7,Ghe),e(Ghe,wIo),e(w7,AIo),e(w7,mV),e(mV,LIo),e(w7,yIo),e(pe,xIo),e(pe,A7),e(A7,Ohe),e(Ohe,$Io),e(A7,kIo),e(A7,gV),e(gV,SIo),e(A7,RIo),e(pe,PIo),e(pe,L7),e(L7,Vhe),e(Vhe,BIo),e(L7,NIo),e(L7,hV),e(hV,IIo),e(L7,qIo),e(eo,jIo),e(eo,y7),e(y7,DIo),e(y7,Xhe),e(Xhe,GIo),e(y7,OIo),e(y7,zhe),e(zhe,VIo),e(eo,XIo),M(x7,eo,null),b(f,iVe,u),b(f,Zi,u),e(Zi,$7),e($7,Qhe),M(jy,Qhe,null),e(Zi,zIo),e(Zi,Whe),e(Whe,QIo),b(f,dVe,u),b(f,Po,u),M(Dy,Po,null),e(Po,WIo),e(Po,ed),e(ed,HIo),e(ed,pV),e(pV,UIo),e(ed,JIo),e(ed,_V),e(_V,YIo),e(ed,KIo),e(Po,ZIo),e(Po,Gy),e(Gy,eqo),e(Gy,Hhe),e(Hhe,oqo),e(Gy,rqo),e(Po,tqo),e(Po,ft),M(Oy,ft,null),e(ft,aqo),e(ft,Uhe),e(Uhe,nqo),e(ft,sqo),e(ft,od),e(od,lqo),e(od,Jhe),e(Jhe,iqo),e(od,dqo),e(od,uV),e(uV,cqo),e(od,fqo),e(ft,mqo),M(k7,ft,null),e(Po,gqo),e(Po,oo),M(Vy,oo,null),e(oo,hqo),e(oo,Yhe),e(Yhe,pqo),e(oo,_qo),e(oo,Da),e(Da,uqo),e(Da,Khe),e(Khe,bqo),e(Da,vqo),e(Da,Zhe),e(Zhe,Fqo),e(Da,Tqo),e(Da,epe),e(epe,Mqo),e(Da,Eqo),e(oo,Cqo),e(oo,I),e(I,S7),e(S7,ope),e(ope,wqo),e(S7,Aqo),e(S7,bV),e(bV,Lqo),e(S7,yqo),e(I,xqo),e(I,R7),e(R7,rpe),e(rpe,$qo),e(R7,kqo),e(R7,vV),e(vV,Sqo),e(R7,Rqo),e(I,Pqo),e(I,P7),e(P7,tpe),e(tpe,Bqo),e(P7,Nqo),e(P7,FV),e(FV,Iqo),e(P7,qqo),e(I,jqo),e(I,B7),e(B7,ape),e(ape,Dqo),e(B7,Gqo),e(B7,TV),e(TV,Oqo),e(B7,Vqo),e(I,Xqo),e(I,N7),e(N7,npe),e(npe,zqo),e(N7,Qqo),e(N7,MV),e(MV,Wqo),e(N7,Hqo),e(I,Uqo),e(I,I7),e(I7,spe),e(spe,Jqo),e(I7,Yqo),e(I7,EV),e(EV,Kqo),e(I7,Zqo),e(I,ejo),e(I,q7),e(q7,lpe),e(lpe,ojo),e(q7,rjo),e(q7,CV),e(CV,tjo),e(q7,ajo),e(I,njo),e(I,j7),e(j7,ipe),e(ipe,sjo),e(j7,ljo),e(j7,wV),e(wV,ijo),e(j7,djo),e(I,cjo),e(I,D7),e(D7,dpe),e(dpe,fjo),e(D7,mjo),e(D7,AV),e(AV,gjo),e(D7,hjo),e(I,pjo),e(I,G7),e(G7,cpe),e(cpe,_jo),e(G7,ujo),e(G7,LV),e(LV,bjo),e(G7,vjo),e(I,Fjo),e(I,O7),e(O7,fpe),e(fpe,Tjo),e(O7,Mjo),e(O7,yV),e(yV,Ejo),e(O7,Cjo),e(I,wjo),e(I,V7),e(V7,mpe),e(mpe,Ajo),e(V7,Ljo),e(V7,xV),e(xV,yjo),e(V7,xjo),e(I,$jo),e(I,X7),e(X7,gpe),e(gpe,kjo),e(X7,Sjo),e(X7,$V),e($V,Rjo),e(X7,Pjo),e(I,Bjo),e(I,z7),e(z7,hpe),e(hpe,Njo),e(z7,Ijo),e(z7,kV),e(kV,qjo),e(z7,jjo),e(I,Djo),e(I,Q7),e(Q7,ppe),e(ppe,Gjo),e(Q7,Ojo),e(Q7,SV),e(SV,Vjo),e(Q7,Xjo),e(I,zjo),e(I,W7),e(W7,_pe),e(_pe,Qjo),e(W7,Wjo),e(W7,RV),e(RV,Hjo),e(W7,Ujo),e(I,Jjo),e(I,H7),e(H7,upe),e(upe,Yjo),e(H7,Kjo),e(H7,PV),e(PV,Zjo),e(H7,eDo),e(I,oDo),e(I,U7),e(U7,bpe),e(bpe,rDo),e(U7,tDo),e(U7,BV),e(BV,aDo),e(U7,nDo),e(I,sDo),e(I,J7),e(J7,vpe),e(vpe,lDo),e(J7,iDo),e(J7,NV),e(NV,dDo),e(J7,cDo),e(I,fDo),e(I,Y7),e(Y7,Fpe),e(Fpe,mDo),e(Y7,gDo),e(Y7,IV),e(IV,hDo),e(Y7,pDo),e(I,_Do),e(I,K7),e(K7,Tpe),e(Tpe,uDo),e(K7,bDo),e(K7,qV),e(qV,vDo),e(K7,FDo),e(I,TDo),e(I,Z7),e(Z7,Mpe),e(Mpe,MDo),e(Z7,EDo),e(Z7,jV),e(jV,CDo),e(Z7,wDo),e(I,ADo),e(I,e4),e(e4,Epe),e(Epe,LDo),e(e4,yDo),e(e4,DV),e(DV,xDo),e(e4,$Do),e(I,kDo),e(I,o4),e(o4,Cpe),e(Cpe,SDo),e(o4,RDo),e(o4,GV),e(GV,PDo),e(o4,BDo),e(I,NDo),e(I,r4),e(r4,wpe),e(wpe,IDo),e(r4,qDo),e(r4,OV),e(OV,jDo),e(r4,DDo),e(I,GDo),e(I,t4),e(t4,Ape),e(Ape,ODo),e(t4,VDo),e(t4,VV),e(VV,XDo),e(t4,zDo),e(I,QDo),e(I,a4),e(a4,Lpe),e(Lpe,WDo),e(a4,HDo),e(a4,XV),e(XV,UDo),e(a4,JDo),e(I,YDo),e(I,n4),e(n4,ype),e(ype,KDo),e(n4,ZDo),e(n4,zV),e(zV,eGo),e(n4,oGo),e(I,rGo),e(I,s4),e(s4,xpe),e(xpe,tGo),e(s4,aGo),e(s4,QV),e(QV,nGo),e(s4,sGo),e(I,lGo),e(I,l4),e(l4,$pe),e($pe,iGo),e(l4,dGo),e(l4,WV),e(WV,cGo),e(l4,fGo),e(I,mGo),e(I,i4),e(i4,kpe),e(kpe,gGo),e(i4,hGo),e(i4,HV),e(HV,pGo),e(i4,_Go),e(I,uGo),e(I,d4),e(d4,Spe),e(Spe,bGo),e(d4,vGo),e(d4,UV),e(UV,FGo),e(d4,TGo),e(I,MGo),e(I,c4),e(c4,Rpe),e(Rpe,EGo),e(c4,CGo),e(c4,JV),e(JV,wGo),e(c4,AGo),e(I,LGo),e(I,f4),e(f4,Ppe),e(Ppe,yGo),e(f4,xGo),e(f4,YV),e(YV,$Go),e(f4,kGo),e(I,SGo),e(I,m4),e(m4,Bpe),e(Bpe,RGo),e(m4,PGo),e(m4,KV),e(KV,BGo),e(m4,NGo),e(I,IGo),e(I,g4),e(g4,Npe),e(Npe,qGo),e(g4,jGo),e(g4,ZV),e(ZV,DGo),e(g4,GGo),e(I,OGo),e(I,h4),e(h4,Ipe),e(Ipe,VGo),e(h4,XGo),e(h4,eX),e(eX,zGo),e(h4,QGo),e(I,WGo),e(I,p4),e(p4,qpe),e(qpe,HGo),e(p4,UGo),e(p4,oX),e(oX,JGo),e(p4,YGo),e(I,KGo),e(I,_4),e(_4,jpe),e(jpe,ZGo),e(_4,eOo),e(_4,rX),e(rX,oOo),e(_4,rOo),e(I,tOo),e(I,u4),e(u4,Dpe),e(Dpe,aOo),e(u4,nOo),e(u4,tX),e(tX,sOo),e(u4,lOo),e(I,iOo),e(I,b4),e(b4,Gpe),e(Gpe,dOo),e(b4,cOo),e(b4,aX),e(aX,fOo),e(b4,mOo),e(I,gOo),e(I,v4),e(v4,Ope),e(Ope,hOo),e(v4,pOo),e(v4,nX),e(nX,_Oo),e(v4,uOo),e(I,bOo),e(I,F4),e(F4,Vpe),e(Vpe,vOo),e(F4,FOo),e(F4,sX),e(sX,TOo),e(F4,MOo),e(I,EOo),e(I,T4),e(T4,Xpe),e(Xpe,COo),e(T4,wOo),e(T4,lX),e(lX,AOo),e(T4,LOo),e(I,yOo),e(I,M4),e(M4,zpe),e(zpe,xOo),e(M4,$Oo),e(M4,iX),e(iX,kOo),e(M4,SOo),e(I,ROo),e(I,E4),e(E4,Qpe),e(Qpe,POo),e(E4,BOo),e(E4,dX),e(dX,NOo),e(E4,IOo),e(I,qOo),e(I,C4),e(C4,Wpe),e(Wpe,jOo),e(C4,DOo),e(C4,cX),e(cX,GOo),e(C4,OOo),e(I,VOo),e(I,w4),e(w4,Hpe),e(Hpe,XOo),e(w4,zOo),e(w4,fX),e(fX,QOo),e(w4,WOo),e(I,HOo),e(I,A4),e(A4,Upe),e(Upe,UOo),e(A4,JOo),e(A4,mX),e(mX,YOo),e(A4,KOo),e(oo,ZOo),e(oo,L4),e(L4,eVo),e(L4,Jpe),e(Jpe,oVo),e(L4,rVo),e(L4,Ype),e(Ype,tVo),e(oo,aVo),M(y4,oo,null),b(f,cVe,u),b(f,rd,u),e(rd,x4),e(x4,Kpe),M(Xy,Kpe,null),e(rd,nVo),e(rd,Zpe),e(Zpe,sVo),b(f,fVe,u),b(f,Bo,u),M(zy,Bo,null),e(Bo,lVo),e(Bo,td),e(td,iVo),e(td,gX),e(gX,dVo),e(td,cVo),e(td,hX),e(hX,fVo),e(td,mVo),e(Bo,gVo),e(Bo,Qy),e(Qy,hVo),e(Qy,e_e),e(e_e,pVo),e(Qy,_Vo),e(Bo,uVo),e(Bo,mt),M(Wy,mt,null),e(mt,bVo),e(mt,o_e),e(o_e,vVo),e(mt,FVo),e(mt,ad),e(ad,TVo),e(ad,r_e),e(r_e,MVo),e(ad,EVo),e(ad,pX),e(pX,CVo),e(ad,wVo),e(mt,AVo),M($4,mt,null),e(Bo,LVo),e(Bo,ro),M(Hy,ro,null),e(ro,yVo),e(ro,t_e),e(t_e,xVo),e(ro,$Vo),e(ro,Ga),e(Ga,kVo),e(Ga,a_e),e(a_e,SVo),e(Ga,RVo),e(Ga,n_e),e(n_e,PVo),e(Ga,BVo),e(Ga,s_e),e(s_e,NVo),e(Ga,IVo),e(ro,qVo),e(ro,Z),e(Z,k4),e(k4,l_e),e(l_e,jVo),e(k4,DVo),e(k4,_X),e(_X,GVo),e(k4,OVo),e(Z,VVo),e(Z,S4),e(S4,i_e),e(i_e,XVo),e(S4,zVo),e(S4,uX),e(uX,QVo),e(S4,WVo),e(Z,HVo),e(Z,R4),e(R4,d_e),e(d_e,UVo),e(R4,JVo),e(R4,bX),e(bX,YVo),e(R4,KVo),e(Z,ZVo),e(Z,P4),e(P4,c_e),e(c_e,eXo),e(P4,oXo),e(P4,vX),e(vX,rXo),e(P4,tXo),e(Z,aXo),e(Z,B4),e(B4,f_e),e(f_e,nXo),e(B4,sXo),e(B4,FX),e(FX,lXo),e(B4,iXo),e(Z,dXo),e(Z,N4),e(N4,m_e),e(m_e,cXo),e(N4,fXo),e(N4,TX),e(TX,mXo),e(N4,gXo),e(Z,hXo),e(Z,I4),e(I4,g_e),e(g_e,pXo),e(I4,_Xo),e(I4,MX),e(MX,uXo),e(I4,bXo),e(Z,vXo),e(Z,q4),e(q4,h_e),e(h_e,FXo),e(q4,TXo),e(q4,EX),e(EX,MXo),e(q4,EXo),e(Z,CXo),e(Z,j4),e(j4,p_e),e(p_e,wXo),e(j4,AXo),e(j4,CX),e(CX,LXo),e(j4,yXo),e(Z,xXo),e(Z,D4),e(D4,__e),e(__e,$Xo),e(D4,kXo),e(D4,wX),e(wX,SXo),e(D4,RXo),e(Z,PXo),e(Z,G4),e(G4,u_e),e(u_e,BXo),e(G4,NXo),e(G4,AX),e(AX,IXo),e(G4,qXo),e(Z,jXo),e(Z,O4),e(O4,b_e),e(b_e,DXo),e(O4,GXo),e(O4,LX),e(LX,OXo),e(O4,VXo),e(Z,XXo),e(Z,V4),e(V4,v_e),e(v_e,zXo),e(V4,QXo),e(V4,yX),e(yX,WXo),e(V4,HXo),e(Z,UXo),e(Z,X4),e(X4,F_e),e(F_e,JXo),e(X4,YXo),e(X4,xX),e(xX,KXo),e(X4,ZXo),e(Z,ezo),e(Z,z4),e(z4,T_e),e(T_e,ozo),e(z4,rzo),e(z4,$X),e($X,tzo),e(z4,azo),e(Z,nzo),e(Z,Q4),e(Q4,M_e),e(M_e,szo),e(Q4,lzo),e(Q4,kX),e(kX,izo),e(Q4,dzo),e(Z,czo),e(Z,W4),e(W4,E_e),e(E_e,fzo),e(W4,mzo),e(W4,SX),e(SX,gzo),e(W4,hzo),e(Z,pzo),e(Z,H4),e(H4,C_e),e(C_e,_zo),e(H4,uzo),e(H4,RX),e(RX,bzo),e(H4,vzo),e(Z,Fzo),e(Z,U4),e(U4,w_e),e(w_e,Tzo),e(U4,Mzo),e(U4,PX),e(PX,Ezo),e(U4,Czo),e(Z,wzo),e(Z,J4),e(J4,A_e),e(A_e,Azo),e(J4,Lzo),e(J4,BX),e(BX,yzo),e(J4,xzo),e(Z,$zo),e(Z,Y4),e(Y4,L_e),e(L_e,kzo),e(Y4,Szo),e(Y4,NX),e(NX,Rzo),e(Y4,Pzo),e(Z,Bzo),e(Z,K4),e(K4,y_e),e(y_e,Nzo),e(K4,Izo),e(K4,IX),e(IX,qzo),e(K4,jzo),e(Z,Dzo),e(Z,Z4),e(Z4,x_e),e(x_e,Gzo),e(Z4,Ozo),e(Z4,qX),e(qX,Vzo),e(Z4,Xzo),e(Z,zzo),e(Z,eb),e(eb,$_e),e($_e,Qzo),e(eb,Wzo),e(eb,jX),e(jX,Hzo),e(eb,Uzo),e(Z,Jzo),e(Z,ob),e(ob,k_e),e(k_e,Yzo),e(ob,Kzo),e(ob,DX),e(DX,Zzo),e(ob,eQo),e(Z,oQo),e(Z,rb),e(rb,S_e),e(S_e,rQo),e(rb,tQo),e(rb,GX),e(GX,aQo),e(rb,nQo),e(Z,sQo),e(Z,tb),e(tb,R_e),e(R_e,lQo),e(tb,iQo),e(tb,OX),e(OX,dQo),e(tb,cQo),e(Z,fQo),e(Z,ab),e(ab,P_e),e(P_e,mQo),e(ab,gQo),e(ab,VX),e(VX,hQo),e(ab,pQo),e(Z,_Qo),e(Z,nb),e(nb,B_e),e(B_e,uQo),e(nb,bQo),e(nb,XX),e(XX,vQo),e(nb,FQo),e(Z,TQo),e(Z,sb),e(sb,N_e),e(N_e,MQo),e(sb,EQo),e(sb,zX),e(zX,CQo),e(sb,wQo),e(ro,AQo),e(ro,lb),e(lb,LQo),e(lb,I_e),e(I_e,yQo),e(lb,xQo),e(lb,q_e),e(q_e,$Qo),e(ro,kQo),M(ib,ro,null),b(f,mVe,u),b(f,nd,u),e(nd,db),e(db,j_e),M(Uy,j_e,null),e(nd,SQo),e(nd,D_e),e(D_e,RQo),b(f,gVe,u),b(f,No,u),M(Jy,No,null),e(No,PQo),e(No,sd),e(sd,BQo),e(sd,QX),e(QX,NQo),e(sd,IQo),e(sd,WX),e(WX,qQo),e(sd,jQo),e(No,DQo),e(No,Yy),e(Yy,GQo),e(Yy,G_e),e(G_e,OQo),e(Yy,VQo),e(No,XQo),e(No,gt),M(Ky,gt,null),e(gt,zQo),e(gt,O_e),e(O_e,QQo),e(gt,WQo),e(gt,ld),e(ld,HQo),e(ld,V_e),e(V_e,UQo),e(ld,JQo),e(ld,HX),e(HX,YQo),e(ld,KQo),e(gt,ZQo),M(cb,gt,null),e(No,eWo),e(No,to),M(Zy,to,null),e(to,oWo),e(to,X_e),e(X_e,rWo),e(to,tWo),e(to,Oa),e(Oa,aWo),e(Oa,z_e),e(z_e,nWo),e(Oa,sWo),e(Oa,Q_e),e(Q_e,lWo),e(Oa,iWo),e(Oa,W_e),e(W_e,dWo),e(Oa,cWo),e(to,fWo),e(to,Io),e(Io,fb),e(fb,H_e),e(H_e,mWo),e(fb,gWo),e(fb,UX),e(UX,hWo),e(fb,pWo),e(Io,_Wo),e(Io,mb),e(mb,U_e),e(U_e,uWo),e(mb,bWo),e(mb,JX),e(JX,vWo),e(mb,FWo),e(Io,TWo),e(Io,gb),e(gb,J_e),e(J_e,MWo),e(gb,EWo),e(gb,YX),e(YX,CWo),e(gb,wWo),e(Io,AWo),e(Io,hb),e(hb,Y_e),e(Y_e,LWo),e(hb,yWo),e(hb,KX),e(KX,xWo),e(hb,$Wo),e(Io,kWo),e(Io,pb),e(pb,K_e),e(K_e,SWo),e(pb,RWo),e(pb,ZX),e(ZX,PWo),e(pb,BWo),e(Io,NWo),e(Io,_b),e(_b,Z_e),e(Z_e,IWo),e(_b,qWo),e(_b,ez),e(ez,jWo),e(_b,DWo),e(to,GWo),e(to,ub),e(ub,OWo),e(ub,eue),e(eue,VWo),e(ub,XWo),e(ub,oue),e(oue,zWo),e(to,QWo),M(bb,to,null),b(f,hVe,u),b(f,id,u),e(id,vb),e(vb,rue),M(e8,rue,null),e(id,WWo),e(id,tue),e(tue,HWo),b(f,pVe,u),b(f,qo,u),M(o8,qo,null),e(qo,UWo),e(qo,dd),e(dd,JWo),e(dd,oz),e(oz,YWo),e(dd,KWo),e(dd,rz),e(rz,ZWo),e(dd,eHo),e(qo,oHo),e(qo,r8),e(r8,rHo),e(r8,aue),e(aue,tHo),e(r8,aHo),e(qo,nHo),e(qo,ht),M(t8,ht,null),e(ht,sHo),e(ht,nue),e(nue,lHo),e(ht,iHo),e(ht,cd),e(cd,dHo),e(cd,sue),e(sue,cHo),e(cd,fHo),e(cd,tz),e(tz,mHo),e(cd,gHo),e(ht,hHo),M(Fb,ht,null),e(qo,pHo),e(qo,ao),M(a8,ao,null),e(ao,_Ho),e(ao,lue),e(lue,uHo),e(ao,bHo),e(ao,Va),e(Va,vHo),e(Va,iue),e(iue,FHo),e(Va,THo),e(Va,due),e(due,MHo),e(Va,EHo),e(Va,cue),e(cue,CHo),e(Va,wHo),e(ao,AHo),e(ao,H),e(H,Tb),e(Tb,fue),e(fue,LHo),e(Tb,yHo),e(Tb,az),e(az,xHo),e(Tb,$Ho),e(H,kHo),e(H,Mb),e(Mb,mue),e(mue,SHo),e(Mb,RHo),e(Mb,nz),e(nz,PHo),e(Mb,BHo),e(H,NHo),e(H,Eb),e(Eb,gue),e(gue,IHo),e(Eb,qHo),e(Eb,sz),e(sz,jHo),e(Eb,DHo),e(H,GHo),e(H,Cb),e(Cb,hue),e(hue,OHo),e(Cb,VHo),e(Cb,lz),e(lz,XHo),e(Cb,zHo),e(H,QHo),e(H,wb),e(wb,pue),e(pue,WHo),e(wb,HHo),e(wb,iz),e(iz,UHo),e(wb,JHo),e(H,YHo),e(H,Ab),e(Ab,_ue),e(_ue,KHo),e(Ab,ZHo),e(Ab,dz),e(dz,eUo),e(Ab,oUo),e(H,rUo),e(H,Lb),e(Lb,uue),e(uue,tUo),e(Lb,aUo),e(Lb,cz),e(cz,nUo),e(Lb,sUo),e(H,lUo),e(H,yb),e(yb,bue),e(bue,iUo),e(yb,dUo),e(yb,fz),e(fz,cUo),e(yb,fUo),e(H,mUo),e(H,xb),e(xb,vue),e(vue,gUo),e(xb,hUo),e(xb,mz),e(mz,pUo),e(xb,_Uo),e(H,uUo),e(H,$b),e($b,Fue),e(Fue,bUo),e($b,vUo),e($b,gz),e(gz,FUo),e($b,TUo),e(H,MUo),e(H,kb),e(kb,Tue),e(Tue,EUo),e(kb,CUo),e(kb,hz),e(hz,wUo),e(kb,AUo),e(H,LUo),e(H,Sb),e(Sb,Mue),e(Mue,yUo),e(Sb,xUo),e(Sb,pz),e(pz,$Uo),e(Sb,kUo),e(H,SUo),e(H,Rb),e(Rb,Eue),e(Eue,RUo),e(Rb,PUo),e(Rb,_z),e(_z,BUo),e(Rb,NUo),e(H,IUo),e(H,Pb),e(Pb,Cue),e(Cue,qUo),e(Pb,jUo),e(Pb,uz),e(uz,DUo),e(Pb,GUo),e(H,OUo),e(H,Bb),e(Bb,wue),e(wue,VUo),e(Bb,XUo),e(Bb,bz),e(bz,zUo),e(Bb,QUo),e(H,WUo),e(H,Nb),e(Nb,Aue),e(Aue,HUo),e(Nb,UUo),e(Nb,vz),e(vz,JUo),e(Nb,YUo),e(H,KUo),e(H,Ib),e(Ib,Lue),e(Lue,ZUo),e(Ib,eJo),e(Ib,Fz),e(Fz,oJo),e(Ib,rJo),e(H,tJo),e(H,qb),e(qb,yue),e(yue,aJo),e(qb,nJo),e(qb,Tz),e(Tz,sJo),e(qb,lJo),e(H,iJo),e(H,jb),e(jb,xue),e(xue,dJo),e(jb,cJo),e(jb,Mz),e(Mz,fJo),e(jb,mJo),e(H,gJo),e(H,Db),e(Db,$ue),e($ue,hJo),e(Db,pJo),e(Db,Ez),e(Ez,_Jo),e(Db,uJo),e(H,bJo),e(H,Gb),e(Gb,kue),e(kue,vJo),e(Gb,FJo),e(Gb,Cz),e(Cz,TJo),e(Gb,MJo),e(H,EJo),e(H,Ob),e(Ob,Sue),e(Sue,CJo),e(Ob,wJo),e(Ob,wz),e(wz,AJo),e(Ob,LJo),e(H,yJo),e(H,Vb),e(Vb,Rue),e(Rue,xJo),e(Vb,$Jo),e(Vb,Az),e(Az,kJo),e(Vb,SJo),e(H,RJo),e(H,Xb),e(Xb,Pue),e(Pue,PJo),e(Xb,BJo),e(Xb,Lz),e(Lz,NJo),e(Xb,IJo),e(H,qJo),e(H,zb),e(zb,Bue),e(Bue,jJo),e(zb,DJo),e(zb,yz),e(yz,GJo),e(zb,OJo),e(H,VJo),e(H,Qb),e(Qb,Nue),e(Nue,XJo),e(Qb,zJo),e(Qb,xz),e(xz,QJo),e(Qb,WJo),e(H,HJo),e(H,Wb),e(Wb,Iue),e(Iue,UJo),e(Wb,JJo),e(Wb,$z),e($z,YJo),e(Wb,KJo),e(H,ZJo),e(H,Hb),e(Hb,que),e(que,eYo),e(Hb,oYo),e(Hb,kz),e(kz,rYo),e(Hb,tYo),e(H,aYo),e(H,Ub),e(Ub,jue),e(jue,nYo),e(Ub,sYo),e(Ub,Sz),e(Sz,lYo),e(Ub,iYo),e(H,dYo),e(H,Jb),e(Jb,Due),e(Due,cYo),e(Jb,fYo),e(Jb,Rz),e(Rz,mYo),e(Jb,gYo),e(H,hYo),e(H,Yb),e(Yb,Gue),e(Gue,pYo),e(Yb,_Yo),e(Yb,Pz),e(Pz,uYo),e(Yb,bYo),e(H,vYo),e(H,Kb),e(Kb,Oue),e(Oue,FYo),e(Kb,TYo),e(Kb,Bz),e(Bz,MYo),e(Kb,EYo),e(H,CYo),e(H,Zb),e(Zb,Vue),e(Vue,wYo),e(Zb,AYo),e(Zb,Nz),e(Nz,LYo),e(Zb,yYo),e(H,xYo),e(H,ev),e(ev,Xue),e(Xue,$Yo),e(ev,kYo),e(ev,Iz),e(Iz,SYo),e(ev,RYo),e(H,PYo),e(H,ov),e(ov,zue),e(zue,BYo),e(ov,NYo),e(ov,qz),e(qz,IYo),e(ov,qYo),e(H,jYo),e(H,rv),e(rv,Que),e(Que,DYo),e(rv,GYo),e(rv,jz),e(jz,OYo),e(rv,VYo),e(ao,XYo),e(ao,tv),e(tv,zYo),e(tv,Wue),e(Wue,QYo),e(tv,WYo),e(tv,Hue),e(Hue,HYo),e(ao,UYo),M(av,ao,null),b(f,_Ve,u),b(f,fd,u),e(fd,nv),e(nv,Uue),M(n8,Uue,null),e(fd,JYo),e(fd,Jue),e(Jue,YYo),b(f,uVe,u),b(f,jo,u),M(s8,jo,null),e(jo,KYo),e(jo,md),e(md,ZYo),e(md,Dz),e(Dz,eKo),e(md,oKo),e(md,Gz),e(Gz,rKo),e(md,tKo),e(jo,aKo),e(jo,l8),e(l8,nKo),e(l8,Yue),e(Yue,sKo),e(l8,lKo),e(jo,iKo),e(jo,pt),M(i8,pt,null),e(pt,dKo),e(pt,Kue),e(Kue,cKo),e(pt,fKo),e(pt,gd),e(gd,mKo),e(gd,Zue),e(Zue,gKo),e(gd,hKo),e(gd,Oz),e(Oz,pKo),e(gd,_Ko),e(pt,uKo),M(sv,pt,null),e(jo,bKo),e(jo,no),M(d8,no,null),e(no,vKo),e(no,e2e),e(e2e,FKo),e(no,TKo),e(no,Xa),e(Xa,MKo),e(Xa,o2e),e(o2e,EKo),e(Xa,CKo),e(Xa,r2e),e(r2e,wKo),e(Xa,AKo),e(Xa,t2e),e(t2e,LKo),e(Xa,yKo),e(no,xKo),e(no,V),e(V,lv),e(lv,a2e),e(a2e,$Ko),e(lv,kKo),e(lv,Vz),e(Vz,SKo),e(lv,RKo),e(V,PKo),e(V,iv),e(iv,n2e),e(n2e,BKo),e(iv,NKo),e(iv,Xz),e(Xz,IKo),e(iv,qKo),e(V,jKo),e(V,dv),e(dv,s2e),e(s2e,DKo),e(dv,GKo),e(dv,zz),e(zz,OKo),e(dv,VKo),e(V,XKo),e(V,cv),e(cv,l2e),e(l2e,zKo),e(cv,QKo),e(cv,Qz),e(Qz,WKo),e(cv,HKo),e(V,UKo),e(V,fv),e(fv,i2e),e(i2e,JKo),e(fv,YKo),e(fv,Wz),e(Wz,KKo),e(fv,ZKo),e(V,eZo),e(V,mv),e(mv,d2e),e(d2e,oZo),e(mv,rZo),e(mv,Hz),e(Hz,tZo),e(mv,aZo),e(V,nZo),e(V,gv),e(gv,c2e),e(c2e,sZo),e(gv,lZo),e(gv,Uz),e(Uz,iZo),e(gv,dZo),e(V,cZo),e(V,hv),e(hv,f2e),e(f2e,fZo),e(hv,mZo),e(hv,Jz),e(Jz,gZo),e(hv,hZo),e(V,pZo),e(V,pv),e(pv,m2e),e(m2e,_Zo),e(pv,uZo),e(pv,Yz),e(Yz,bZo),e(pv,vZo),e(V,FZo),e(V,_v),e(_v,g2e),e(g2e,TZo),e(_v,MZo),e(_v,Kz),e(Kz,EZo),e(_v,CZo),e(V,wZo),e(V,uv),e(uv,h2e),e(h2e,AZo),e(uv,LZo),e(uv,Zz),e(Zz,yZo),e(uv,xZo),e(V,$Zo),e(V,bv),e(bv,p2e),e(p2e,kZo),e(bv,SZo),e(bv,eQ),e(eQ,RZo),e(bv,PZo),e(V,BZo),e(V,vv),e(vv,_2e),e(_2e,NZo),e(vv,IZo),e(vv,oQ),e(oQ,qZo),e(vv,jZo),e(V,DZo),e(V,Fv),e(Fv,u2e),e(u2e,GZo),e(Fv,OZo),e(Fv,rQ),e(rQ,VZo),e(Fv,XZo),e(V,zZo),e(V,Tv),e(Tv,b2e),e(b2e,QZo),e(Tv,WZo),e(Tv,tQ),e(tQ,HZo),e(Tv,UZo),e(V,JZo),e(V,Mv),e(Mv,v2e),e(v2e,YZo),e(Mv,KZo),e(Mv,aQ),e(aQ,ZZo),e(Mv,eer),e(V,oer),e(V,Ev),e(Ev,F2e),e(F2e,rer),e(Ev,ter),e(Ev,nQ),e(nQ,aer),e(Ev,ner),e(V,ser),e(V,Cv),e(Cv,T2e),e(T2e,ler),e(Cv,ier),e(Cv,sQ),e(sQ,der),e(Cv,cer),e(V,fer),e(V,wv),e(wv,M2e),e(M2e,mer),e(wv,ger),e(wv,lQ),e(lQ,her),e(wv,per),e(V,_er),e(V,Av),e(Av,E2e),e(E2e,uer),e(Av,ber),e(Av,iQ),e(iQ,ver),e(Av,Fer),e(V,Ter),e(V,Lv),e(Lv,C2e),e(C2e,Mer),e(Lv,Eer),e(Lv,dQ),e(dQ,Cer),e(Lv,wer),e(V,Aer),e(V,yv),e(yv,w2e),e(w2e,Ler),e(yv,yer),e(yv,cQ),e(cQ,xer),e(yv,$er),e(V,ker),e(V,xv),e(xv,A2e),e(A2e,Ser),e(xv,Rer),e(xv,fQ),e(fQ,Per),e(xv,Ber),e(V,Ner),e(V,$v),e($v,L2e),e(L2e,Ier),e($v,qer),e($v,mQ),e(mQ,jer),e($v,Der),e(V,Ger),e(V,kv),e(kv,y2e),e(y2e,Oer),e(kv,Ver),e(kv,gQ),e(gQ,Xer),e(kv,zer),e(V,Qer),e(V,Sv),e(Sv,x2e),e(x2e,Wer),e(Sv,Her),e(Sv,hQ),e(hQ,Uer),e(Sv,Jer),e(V,Yer),e(V,Rv),e(Rv,$2e),e($2e,Ker),e(Rv,Zer),e(Rv,pQ),e(pQ,eor),e(Rv,oor),e(V,ror),e(V,Pv),e(Pv,k2e),e(k2e,tor),e(Pv,aor),e(Pv,_Q),e(_Q,nor),e(Pv,sor),e(V,lor),e(V,Bv),e(Bv,S2e),e(S2e,ior),e(Bv,dor),e(Bv,uQ),e(uQ,cor),e(Bv,mor),e(V,gor),e(V,Nv),e(Nv,R2e),e(R2e,hor),e(Nv,por),e(Nv,bQ),e(bQ,_or),e(Nv,uor),e(V,bor),e(V,Iv),e(Iv,P2e),e(P2e,vor),e(Iv,For),e(Iv,vQ),e(vQ,Tor),e(Iv,Mor),e(V,Eor),e(V,qv),e(qv,B2e),e(B2e,Cor),e(qv,wor),e(qv,FQ),e(FQ,Aor),e(qv,Lor),e(V,yor),e(V,jv),e(jv,N2e),e(N2e,xor),e(jv,$or),e(jv,TQ),e(TQ,kor),e(jv,Sor),e(V,Ror),e(V,Dv),e(Dv,I2e),e(I2e,Por),e(Dv,Bor),e(Dv,MQ),e(MQ,Nor),e(Dv,Ior),e(V,qor),e(V,Gv),e(Gv,q2e),e(q2e,jor),e(Gv,Dor),e(Gv,EQ),e(EQ,Gor),e(Gv,Oor),e(V,Vor),e(V,Ov),e(Ov,j2e),e(j2e,Xor),e(Ov,zor),e(Ov,CQ),e(CQ,Qor),e(Ov,Wor),e(V,Hor),e(V,Vv),e(Vv,D2e),e(D2e,Uor),e(Vv,Jor),e(Vv,wQ),e(wQ,Yor),e(Vv,Kor),e(V,Zor),e(V,Xv),e(Xv,G2e),e(G2e,err),e(Xv,orr),e(Xv,AQ),e(AQ,rrr),e(Xv,trr),e(V,arr),e(V,zv),e(zv,O2e),e(O2e,nrr),e(zv,srr),e(zv,LQ),e(LQ,lrr),e(zv,irr),e(V,drr),e(V,Qv),e(Qv,V2e),e(V2e,crr),e(Qv,frr),e(Qv,yQ),e(yQ,mrr),e(Qv,grr),e(V,hrr),e(V,Wv),e(Wv,X2e),e(X2e,prr),e(Wv,_rr),e(Wv,xQ),e(xQ,urr),e(Wv,brr),e(no,vrr),e(no,Hv),e(Hv,Frr),e(Hv,z2e),e(z2e,Trr),e(Hv,Mrr),e(Hv,Q2e),e(Q2e,Err),e(no,Crr),M(Uv,no,null),b(f,bVe,u),b(f,hd,u),e(hd,Jv),e(Jv,W2e),M(c8,W2e,null),e(hd,wrr),e(hd,H2e),e(H2e,Arr),b(f,vVe,u),b(f,Do,u),M(f8,Do,null),e(Do,Lrr),e(Do,pd),e(pd,yrr),e(pd,$Q),e($Q,xrr),e(pd,$rr),e(pd,kQ),e(kQ,krr),e(pd,Srr),e(Do,Rrr),e(Do,m8),e(m8,Prr),e(m8,U2e),e(U2e,Brr),e(m8,Nrr),e(Do,Irr),e(Do,_t),M(g8,_t,null),e(_t,qrr),e(_t,J2e),e(J2e,jrr),e(_t,Drr),e(_t,_d),e(_d,Grr),e(_d,Y2e),e(Y2e,Orr),e(_d,Vrr),e(_d,SQ),e(SQ,Xrr),e(_d,zrr),e(_t,Qrr),M(Yv,_t,null),e(Do,Wrr),e(Do,so),M(h8,so,null),e(so,Hrr),e(so,K2e),e(K2e,Urr),e(so,Jrr),e(so,za),e(za,Yrr),e(za,Z2e),e(Z2e,Krr),e(za,Zrr),e(za,e1e),e(e1e,etr),e(za,otr),e(za,o1e),e(o1e,rtr),e(za,ttr),e(so,atr),e(so,r1e),e(r1e,Kv),e(Kv,t1e),e(t1e,ntr),e(Kv,str),e(Kv,RQ),e(RQ,ltr),e(Kv,itr),e(so,dtr),e(so,Zv),e(Zv,ctr),e(Zv,a1e),e(a1e,ftr),e(Zv,mtr),e(Zv,n1e),e(n1e,gtr),e(so,htr),M(eF,so,null),b(f,FVe,u),b(f,ud,u),e(ud,oF),e(oF,s1e),M(p8,s1e,null),e(ud,ptr),e(ud,l1e),e(l1e,_tr),b(f,TVe,u),b(f,Go,u),M(_8,Go,null),e(Go,utr),e(Go,bd),e(bd,btr),e(bd,PQ),e(PQ,vtr),e(bd,Ftr),e(bd,BQ),e(BQ,Ttr),e(bd,Mtr),e(Go,Etr),e(Go,u8),e(u8,Ctr),e(u8,i1e),e(i1e,wtr),e(u8,Atr),e(Go,Ltr),e(Go,ut),M(b8,ut,null),e(ut,ytr),e(ut,d1e),e(d1e,xtr),e(ut,$tr),e(ut,vd),e(vd,ktr),e(vd,c1e),e(c1e,Str),e(vd,Rtr),e(vd,NQ),e(NQ,Ptr),e(vd,Btr),e(ut,Ntr),M(rF,ut,null),e(Go,Itr),e(Go,lo),M(v8,lo,null),e(lo,qtr),e(lo,f1e),e(f1e,jtr),e(lo,Dtr),e(lo,Qa),e(Qa,Gtr),e(Qa,m1e),e(m1e,Otr),e(Qa,Vtr),e(Qa,g1e),e(g1e,Xtr),e(Qa,ztr),e(Qa,h1e),e(h1e,Qtr),e(Qa,Wtr),e(lo,Htr),e(lo,Fe),e(Fe,tF),e(tF,p1e),e(p1e,Utr),e(tF,Jtr),e(tF,IQ),e(IQ,Ytr),e(tF,Ktr),e(Fe,Ztr),e(Fe,aF),e(aF,_1e),e(_1e,ear),e(aF,oar),e(aF,qQ),e(qQ,rar),e(aF,tar),e(Fe,aar),e(Fe,nF),e(nF,u1e),e(u1e,nar),e(nF,sar),e(nF,jQ),e(jQ,lar),e(nF,iar),e(Fe,dar),e(Fe,sF),e(sF,b1e),e(b1e,car),e(sF,far),e(sF,DQ),e(DQ,mar),e(sF,gar),e(Fe,har),e(Fe,Ws),e(Ws,v1e),e(v1e,par),e(Ws,_ar),e(Ws,GQ),e(GQ,uar),e(Ws,bar),e(Ws,OQ),e(OQ,Far),e(Ws,Tar),e(Fe,Mar),e(Fe,lF),e(lF,F1e),e(F1e,Ear),e(lF,Car),e(lF,VQ),e(VQ,war),e(lF,Aar),e(Fe,Lar),e(Fe,Hs),e(Hs,T1e),e(T1e,yar),e(Hs,xar),e(Hs,XQ),e(XQ,$ar),e(Hs,kar),e(Hs,zQ),e(zQ,Sar),e(Hs,Rar),e(Fe,Par),e(Fe,bt),e(bt,M1e),e(M1e,Bar),e(bt,Nar),e(bt,QQ),e(QQ,Iar),e(bt,qar),e(bt,WQ),e(WQ,jar),e(bt,Dar),e(bt,HQ),e(HQ,Gar),e(bt,Oar),e(Fe,Var),e(Fe,iF),e(iF,E1e),e(E1e,Xar),e(iF,zar),e(iF,UQ),e(UQ,Qar),e(iF,War),e(Fe,Har),e(Fe,dF),e(dF,C1e),e(C1e,Uar),e(dF,Jar),e(dF,JQ),e(JQ,Yar),e(dF,Kar),e(Fe,Zar),e(Fe,cF),e(cF,w1e),e(w1e,enr),e(cF,onr),e(cF,YQ),e(YQ,rnr),e(cF,tnr),e(Fe,anr),e(Fe,fF),e(fF,A1e),e(A1e,nnr),e(fF,snr),e(fF,KQ),e(KQ,lnr),e(fF,inr),e(Fe,dnr),e(Fe,mF),e(mF,L1e),e(L1e,cnr),e(mF,fnr),e(mF,ZQ),e(ZQ,mnr),e(mF,gnr),e(Fe,hnr),e(Fe,gF),e(gF,y1e),e(y1e,pnr),e(gF,_nr),e(gF,eW),e(eW,unr),e(gF,bnr),e(Fe,vnr),e(Fe,hF),e(hF,x1e),e(x1e,Fnr),e(hF,Tnr),e(hF,oW),e(oW,Mnr),e(hF,Enr),e(lo,Cnr),e(lo,pF),e(pF,wnr),e(pF,$1e),e($1e,Anr),e(pF,Lnr),e(pF,k1e),e(k1e,ynr),e(lo,xnr),M(_F,lo,null),b(f,MVe,u),b(f,Fd,u),e(Fd,uF),e(uF,S1e),M(F8,S1e,null),e(Fd,$nr),e(Fd,R1e),e(R1e,knr),b(f,EVe,u),b(f,Oo,u),M(T8,Oo,null),e(Oo,Snr),e(Oo,Td),e(Td,Rnr),e(Td,rW),e(rW,Pnr),e(Td,Bnr),e(Td,tW),e(tW,Nnr),e(Td,Inr),e(Oo,qnr),e(Oo,M8),e(M8,jnr),e(M8,P1e),e(P1e,Dnr),e(M8,Gnr),e(Oo,Onr),e(Oo,vt),M(E8,vt,null),e(vt,Vnr),e(vt,B1e),e(B1e,Xnr),e(vt,znr),e(vt,Md),e(Md,Qnr),e(Md,N1e),e(N1e,Wnr),e(Md,Hnr),e(Md,aW),e(aW,Unr),e(Md,Jnr),e(vt,Ynr),M(bF,vt,null),e(Oo,Knr),e(Oo,io),M(C8,io,null),e(io,Znr),e(io,I1e),e(I1e,esr),e(io,osr),e(io,Wa),e(Wa,rsr),e(Wa,q1e),e(q1e,tsr),e(Wa,asr),e(Wa,j1e),e(j1e,nsr),e(Wa,ssr),e(Wa,D1e),e(D1e,lsr),e(Wa,isr),e(io,dsr),e(io,G1e),e(G1e,vF),e(vF,O1e),e(O1e,csr),e(vF,fsr),e(vF,nW),e(nW,msr),e(vF,gsr),e(io,hsr),e(io,FF),e(FF,psr),e(FF,V1e),e(V1e,_sr),e(FF,usr),e(FF,X1e),e(X1e,bsr),e(io,vsr),M(TF,io,null),b(f,CVe,u),b(f,Ed,u),e(Ed,MF),e(MF,z1e),M(w8,z1e,null),e(Ed,Fsr),e(Ed,Q1e),e(Q1e,Tsr),b(f,wVe,u),b(f,Vo,u),M(A8,Vo,null),e(Vo,Msr),e(Vo,Cd),e(Cd,Esr),e(Cd,sW),e(sW,Csr),e(Cd,wsr),e(Cd,lW),e(lW,Asr),e(Cd,Lsr),e(Vo,ysr),e(Vo,L8),e(L8,xsr),e(L8,W1e),e(W1e,$sr),e(L8,ksr),e(Vo,Ssr),e(Vo,Ft),M(y8,Ft,null),e(Ft,Rsr),e(Ft,H1e),e(H1e,Psr),e(Ft,Bsr),e(Ft,wd),e(wd,Nsr),e(wd,U1e),e(U1e,Isr),e(wd,qsr),e(wd,iW),e(iW,jsr),e(wd,Dsr),e(Ft,Gsr),M(EF,Ft,null),e(Vo,Osr),e(Vo,co),M(x8,co,null),e(co,Vsr),e(co,J1e),e(J1e,Xsr),e(co,zsr),e(co,Ha),e(Ha,Qsr),e(Ha,Y1e),e(Y1e,Wsr),e(Ha,Hsr),e(Ha,K1e),e(K1e,Usr),e(Ha,Jsr),e(Ha,Z1e),e(Z1e,Ysr),e(Ha,Ksr),e(co,Zsr),e(co,e7e),e(e7e,CF),e(CF,o7e),e(o7e,elr),e(CF,olr),e(CF,dW),e(dW,rlr),e(CF,tlr),e(co,alr),e(co,wF),e(wF,nlr),e(wF,r7e),e(r7e,slr),e(wF,llr),e(wF,t7e),e(t7e,ilr),e(co,dlr),M(AF,co,null),b(f,AVe,u),b(f,Ad,u),e(Ad,LF),e(LF,a7e),M($8,a7e,null),e(Ad,clr),e(Ad,n7e),e(n7e,flr),b(f,LVe,u),b(f,Xo,u),M(k8,Xo,null),e(Xo,mlr),e(Xo,Ld),e(Ld,glr),e(Ld,cW),e(cW,hlr),e(Ld,plr),e(Ld,fW),e(fW,_lr),e(Ld,ulr),e(Xo,blr),e(Xo,S8),e(S8,vlr),e(S8,s7e),e(s7e,Flr),e(S8,Tlr),e(Xo,Mlr),e(Xo,Tt),M(R8,Tt,null),e(Tt,Elr),e(Tt,l7e),e(l7e,Clr),e(Tt,wlr),e(Tt,yd),e(yd,Alr),e(yd,i7e),e(i7e,Llr),e(yd,ylr),e(yd,mW),e(mW,xlr),e(yd,$lr),e(Tt,klr),M(yF,Tt,null),e(Xo,Slr),e(Xo,fo),M(P8,fo,null),e(fo,Rlr),e(fo,d7e),e(d7e,Plr),e(fo,Blr),e(fo,Ua),e(Ua,Nlr),e(Ua,c7e),e(c7e,Ilr),e(Ua,qlr),e(Ua,f7e),e(f7e,jlr),e(Ua,Dlr),e(Ua,m7e),e(m7e,Glr),e(Ua,Olr),e(fo,Vlr),e(fo,Pe),e(Pe,xF),e(xF,g7e),e(g7e,Xlr),e(xF,zlr),e(xF,gW),e(gW,Qlr),e(xF,Wlr),e(Pe,Hlr),e(Pe,$F),e($F,h7e),e(h7e,Ulr),e($F,Jlr),e($F,hW),e(hW,Ylr),e($F,Klr),e(Pe,Zlr),e(Pe,kF),e(kF,p7e),e(p7e,eir),e(kF,oir),e(kF,pW),e(pW,rir),e(kF,tir),e(Pe,air),e(Pe,SF),e(SF,_7e),e(_7e,nir),e(SF,sir),e(SF,_W),e(_W,lir),e(SF,iir),e(Pe,dir),e(Pe,RF),e(RF,u7e),e(u7e,cir),e(RF,fir),e(RF,uW),e(uW,mir),e(RF,gir),e(Pe,hir),e(Pe,PF),e(PF,b7e),e(b7e,pir),e(PF,_ir),e(PF,bW),e(bW,uir),e(PF,bir),e(Pe,vir),e(Pe,BF),e(BF,v7e),e(v7e,Fir),e(BF,Tir),e(BF,vW),e(vW,Mir),e(BF,Eir),e(Pe,Cir),e(Pe,NF),e(NF,F7e),e(F7e,wir),e(NF,Air),e(NF,FW),e(FW,Lir),e(NF,yir),e(Pe,xir),e(Pe,IF),e(IF,T7e),e(T7e,$ir),e(IF,kir),e(IF,TW),e(TW,Sir),e(IF,Rir),e(fo,Pir),e(fo,qF),e(qF,Bir),e(qF,M7e),e(M7e,Nir),e(qF,Iir),e(qF,E7e),e(E7e,qir),e(fo,jir),M(jF,fo,null),b(f,yVe,u),b(f,xd,u),e(xd,DF),e(DF,C7e),M(B8,C7e,null),e(xd,Dir),e(xd,w7e),e(w7e,Gir),b(f,xVe,u),b(f,zo,u),M(N8,zo,null),e(zo,Oir),e(zo,$d),e($d,Vir),e($d,MW),e(MW,Xir),e($d,zir),e($d,EW),e(EW,Qir),e($d,Wir),e(zo,Hir),e(zo,I8),e(I8,Uir),e(I8,A7e),e(A7e,Jir),e(I8,Yir),e(zo,Kir),e(zo,Mt),M(q8,Mt,null),e(Mt,Zir),e(Mt,L7e),e(L7e,edr),e(Mt,odr),e(Mt,kd),e(kd,rdr),e(kd,y7e),e(y7e,tdr),e(kd,adr),e(kd,CW),e(CW,ndr),e(kd,sdr),e(Mt,ldr),M(GF,Mt,null),e(zo,idr),e(zo,mo),M(j8,mo,null),e(mo,ddr),e(mo,x7e),e(x7e,cdr),e(mo,fdr),e(mo,Ja),e(Ja,mdr),e(Ja,$7e),e($7e,gdr),e(Ja,hdr),e(Ja,k7e),e(k7e,pdr),e(Ja,_dr),e(Ja,S7e),e(S7e,udr),e(Ja,bdr),e(mo,vdr),e(mo,ot),e(ot,OF),e(OF,R7e),e(R7e,Fdr),e(OF,Tdr),e(OF,wW),e(wW,Mdr),e(OF,Edr),e(ot,Cdr),e(ot,VF),e(VF,P7e),e(P7e,wdr),e(VF,Adr),e(VF,AW),e(AW,Ldr),e(VF,ydr),e(ot,xdr),e(ot,XF),e(XF,B7e),e(B7e,$dr),e(XF,kdr),e(XF,LW),e(LW,Sdr),e(XF,Rdr),e(ot,Pdr),e(ot,zF),e(zF,N7e),e(N7e,Bdr),e(zF,Ndr),e(zF,yW),e(yW,Idr),e(zF,qdr),e(ot,jdr),e(ot,QF),e(QF,I7e),e(I7e,Ddr),e(QF,Gdr),e(QF,xW),e(xW,Odr),e(QF,Vdr),e(mo,Xdr),e(mo,WF),e(WF,zdr),e(WF,q7e),e(q7e,Qdr),e(WF,Wdr),e(WF,j7e),e(j7e,Hdr),e(mo,Udr),M(HF,mo,null),b(f,$Ve,u),b(f,Sd,u),e(Sd,UF),e(UF,D7e),M(D8,D7e,null),e(Sd,Jdr),e(Sd,G7e),e(G7e,Ydr),b(f,kVe,u),b(f,Qo,u),M(G8,Qo,null),e(Qo,Kdr),e(Qo,Rd),e(Rd,Zdr),e(Rd,$W),e($W,ecr),e(Rd,ocr),e(Rd,kW),e(kW,rcr),e(Rd,tcr),e(Qo,acr),e(Qo,O8),e(O8,ncr),e(O8,O7e),e(O7e,scr),e(O8,lcr),e(Qo,icr),e(Qo,Et),M(V8,Et,null),e(Et,dcr),e(Et,V7e),e(V7e,ccr),e(Et,fcr),e(Et,Pd),e(Pd,mcr),e(Pd,X7e),e(X7e,gcr),e(Pd,hcr),e(Pd,SW),e(SW,pcr),e(Pd,_cr),e(Et,ucr),M(JF,Et,null),e(Qo,bcr),e(Qo,go),M(X8,go,null),e(go,vcr),e(go,z7e),e(z7e,Fcr),e(go,Tcr),e(go,Ya),e(Ya,Mcr),e(Ya,Q7e),e(Q7e,Ecr),e(Ya,Ccr),e(Ya,W7e),e(W7e,wcr),e(Ya,Acr),e(Ya,H7e),e(H7e,Lcr),e(Ya,ycr),e(go,xcr),e(go,Le),e(Le,YF),e(YF,U7e),e(U7e,$cr),e(YF,kcr),e(YF,RW),e(RW,Scr),e(YF,Rcr),e(Le,Pcr),e(Le,KF),e(KF,J7e),e(J7e,Bcr),e(KF,Ncr),e(KF,PW),e(PW,Icr),e(KF,qcr),e(Le,jcr),e(Le,ZF),e(ZF,Y7e),e(Y7e,Dcr),e(ZF,Gcr),e(ZF,BW),e(BW,Ocr),e(ZF,Vcr),e(Le,Xcr),e(Le,eT),e(eT,K7e),e(K7e,zcr),e(eT,Qcr),e(eT,NW),e(NW,Wcr),e(eT,Hcr),e(Le,Ucr),e(Le,oT),e(oT,Z7e),e(Z7e,Jcr),e(oT,Ycr),e(oT,IW),e(IW,Kcr),e(oT,Zcr),e(Le,efr),e(Le,rT),e(rT,e4e),e(e4e,ofr),e(rT,rfr),e(rT,qW),e(qW,tfr),e(rT,afr),e(Le,nfr),e(Le,tT),e(tT,o4e),e(o4e,sfr),e(tT,lfr),e(tT,jW),e(jW,ifr),e(tT,dfr),e(Le,cfr),e(Le,aT),e(aT,r4e),e(r4e,ffr),e(aT,mfr),e(aT,DW),e(DW,gfr),e(aT,hfr),e(Le,pfr),e(Le,nT),e(nT,t4e),e(t4e,_fr),e(nT,ufr),e(nT,GW),e(GW,bfr),e(nT,vfr),e(Le,Ffr),e(Le,sT),e(sT,a4e),e(a4e,Tfr),e(sT,Mfr),e(sT,OW),e(OW,Efr),e(sT,Cfr),e(go,wfr),e(go,lT),e(lT,Afr),e(lT,n4e),e(n4e,Lfr),e(lT,yfr),e(lT,s4e),e(s4e,xfr),e(go,$fr),M(iT,go,null),b(f,SVe,u),b(f,Bd,u),e(Bd,dT),e(dT,l4e),M(z8,l4e,null),e(Bd,kfr),e(Bd,i4e),e(i4e,Sfr),b(f,RVe,u),b(f,Wo,u),M(Q8,Wo,null),e(Wo,Rfr),e(Wo,Nd),e(Nd,Pfr),e(Nd,VW),e(VW,Bfr),e(Nd,Nfr),e(Nd,XW),e(XW,Ifr),e(Nd,qfr),e(Wo,jfr),e(Wo,W8),e(W8,Dfr),e(W8,d4e),e(d4e,Gfr),e(W8,Ofr),e(Wo,Vfr),e(Wo,Ct),M(H8,Ct,null),e(Ct,Xfr),e(Ct,c4e),e(c4e,zfr),e(Ct,Qfr),e(Ct,Id),e(Id,Wfr),e(Id,f4e),e(f4e,Hfr),e(Id,Ufr),e(Id,zW),e(zW,Jfr),e(Id,Yfr),e(Ct,Kfr),M(cT,Ct,null),e(Wo,Zfr),e(Wo,ho),M(U8,ho,null),e(ho,emr),e(ho,m4e),e(m4e,omr),e(ho,rmr),e(ho,Ka),e(Ka,tmr),e(Ka,g4e),e(g4e,amr),e(Ka,nmr),e(Ka,h4e),e(h4e,smr),e(Ka,lmr),e(Ka,p4e),e(p4e,imr),e(Ka,dmr),e(ho,cmr),e(ho,J8),e(J8,fT),e(fT,_4e),e(_4e,fmr),e(fT,mmr),e(fT,QW),e(QW,gmr),e(fT,hmr),e(J8,pmr),e(J8,mT),e(mT,u4e),e(u4e,_mr),e(mT,umr),e(mT,WW),e(WW,bmr),e(mT,vmr),e(ho,Fmr),e(ho,gT),e(gT,Tmr),e(gT,b4e),e(b4e,Mmr),e(gT,Emr),e(gT,v4e),e(v4e,Cmr),e(ho,wmr),M(hT,ho,null),b(f,PVe,u),b(f,qd,u),e(qd,pT),e(pT,F4e),M(Y8,F4e,null),e(qd,Amr),e(qd,T4e),e(T4e,Lmr),b(f,BVe,u),b(f,Ho,u),M(K8,Ho,null),e(Ho,ymr),e(Ho,jd),e(jd,xmr),e(jd,HW),e(HW,$mr),e(jd,kmr),e(jd,UW),e(UW,Smr),e(jd,Rmr),e(Ho,Pmr),e(Ho,Z8),e(Z8,Bmr),e(Z8,M4e),e(M4e,Nmr),e(Z8,Imr),e(Ho,qmr),e(Ho,wt),M(e9,wt,null),e(wt,jmr),e(wt,E4e),e(E4e,Dmr),e(wt,Gmr),e(wt,Dd),e(Dd,Omr),e(Dd,C4e),e(C4e,Vmr),e(Dd,Xmr),e(Dd,JW),e(JW,zmr),e(Dd,Qmr),e(wt,Wmr),M(_T,wt,null),e(Ho,Hmr),e(Ho,po),M(o9,po,null),e(po,Umr),e(po,w4e),e(w4e,Jmr),e(po,Ymr),e(po,Za),e(Za,Kmr),e(Za,A4e),e(A4e,Zmr),e(Za,egr),e(Za,L4e),e(L4e,ogr),e(Za,rgr),e(Za,y4e),e(y4e,tgr),e(Za,agr),e(po,ngr),e(po,rt),e(rt,uT),e(uT,x4e),e(x4e,sgr),e(uT,lgr),e(uT,YW),e(YW,igr),e(uT,dgr),e(rt,cgr),e(rt,bT),e(bT,$4e),e($4e,fgr),e(bT,mgr),e(bT,KW),e(KW,ggr),e(bT,hgr),e(rt,pgr),e(rt,vT),e(vT,k4e),e(k4e,_gr),e(vT,ugr),e(vT,ZW),e(ZW,bgr),e(vT,vgr),e(rt,Fgr),e(rt,FT),e(FT,S4e),e(S4e,Tgr),e(FT,Mgr),e(FT,eH),e(eH,Egr),e(FT,Cgr),e(rt,wgr),e(rt,TT),e(TT,R4e),e(R4e,Agr),e(TT,Lgr),e(TT,oH),e(oH,ygr),e(TT,xgr),e(po,$gr),e(po,MT),e(MT,kgr),e(MT,P4e),e(P4e,Sgr),e(MT,Rgr),e(MT,B4e),e(B4e,Pgr),e(po,Bgr),M(ET,po,null),b(f,NVe,u),b(f,Gd,u),e(Gd,CT),e(CT,N4e),M(r9,N4e,null),e(Gd,Ngr),e(Gd,I4e),e(I4e,Igr),b(f,IVe,u),b(f,Uo,u),M(t9,Uo,null),e(Uo,qgr),e(Uo,Od),e(Od,jgr),e(Od,rH),e(rH,Dgr),e(Od,Ggr),e(Od,tH),e(tH,Ogr),e(Od,Vgr),e(Uo,Xgr),e(Uo,a9),e(a9,zgr),e(a9,q4e),e(q4e,Qgr),e(a9,Wgr),e(Uo,Hgr),e(Uo,At),M(n9,At,null),e(At,Ugr),e(At,j4e),e(j4e,Jgr),e(At,Ygr),e(At,Vd),e(Vd,Kgr),e(Vd,D4e),e(D4e,Zgr),e(Vd,ehr),e(Vd,aH),e(aH,ohr),e(Vd,rhr),e(At,thr),M(wT,At,null),e(Uo,ahr),e(Uo,_o),M(s9,_o,null),e(_o,nhr),e(_o,G4e),e(G4e,shr),e(_o,lhr),e(_o,en),e(en,ihr),e(en,O4e),e(O4e,dhr),e(en,chr),e(en,V4e),e(V4e,fhr),e(en,mhr),e(en,X4e),e(X4e,ghr),e(en,hhr),e(_o,phr),e(_o,Xd),e(Xd,AT),e(AT,z4e),e(z4e,_hr),e(AT,uhr),e(AT,nH),e(nH,bhr),e(AT,vhr),e(Xd,Fhr),e(Xd,LT),e(LT,Q4e),e(Q4e,Thr),e(LT,Mhr),e(LT,sH),e(sH,Ehr),e(LT,Chr),e(Xd,whr),e(Xd,yT),e(yT,W4e),e(W4e,Ahr),e(yT,Lhr),e(yT,lH),e(lH,yhr),e(yT,xhr),e(_o,$hr),e(_o,xT),e(xT,khr),e(xT,H4e),e(H4e,Shr),e(xT,Rhr),e(xT,U4e),e(U4e,Phr),e(_o,Bhr),M($T,_o,null),b(f,qVe,u),b(f,zd,u),e(zd,kT),e(kT,J4e),M(l9,J4e,null),e(zd,Nhr),e(zd,Y4e),e(Y4e,Ihr),b(f,jVe,u),b(f,Jo,u),M(i9,Jo,null),e(Jo,qhr),e(Jo,Qd),e(Qd,jhr),e(Qd,iH),e(iH,Dhr),e(Qd,Ghr),e(Qd,dH),e(dH,Ohr),e(Qd,Vhr),e(Jo,Xhr),e(Jo,d9),e(d9,zhr),e(d9,K4e),e(K4e,Qhr),e(d9,Whr),e(Jo,Hhr),e(Jo,Lt),M(c9,Lt,null),e(Lt,Uhr),e(Lt,Z4e),e(Z4e,Jhr),e(Lt,Yhr),e(Lt,Wd),e(Wd,Khr),e(Wd,ebe),e(ebe,Zhr),e(Wd,epr),e(Wd,cH),e(cH,opr),e(Wd,rpr),e(Lt,tpr),M(ST,Lt,null),e(Jo,apr),e(Jo,uo),M(f9,uo,null),e(uo,npr),e(uo,obe),e(obe,spr),e(uo,lpr),e(uo,on),e(on,ipr),e(on,rbe),e(rbe,dpr),e(on,cpr),e(on,tbe),e(tbe,fpr),e(on,mpr),e(on,abe),e(abe,gpr),e(on,hpr),e(uo,ppr),e(uo,m9),e(m9,RT),e(RT,nbe),e(nbe,_pr),e(RT,upr),e(RT,fH),e(fH,bpr),e(RT,vpr),e(m9,Fpr),e(m9,PT),e(PT,sbe),e(sbe,Tpr),e(PT,Mpr),e(PT,mH),e(mH,Epr),e(PT,Cpr),e(uo,wpr),e(uo,BT),e(BT,Apr),e(BT,lbe),e(lbe,Lpr),e(BT,ypr),e(BT,ibe),e(ibe,xpr),e(uo,$pr),M(NT,uo,null),b(f,DVe,u),b(f,Hd,u),e(Hd,IT),e(IT,dbe),M(g9,dbe,null),e(Hd,kpr),e(Hd,cbe),e(cbe,Spr),b(f,GVe,u),b(f,Yo,u),M(h9,Yo,null),e(Yo,Rpr),e(Yo,Ud),e(Ud,Ppr),e(Ud,gH),e(gH,Bpr),e(Ud,Npr),e(Ud,hH),e(hH,Ipr),e(Ud,qpr),e(Yo,jpr),e(Yo,p9),e(p9,Dpr),e(p9,fbe),e(fbe,Gpr),e(p9,Opr),e(Yo,Vpr),e(Yo,yt),M(_9,yt,null),e(yt,Xpr),e(yt,mbe),e(mbe,zpr),e(yt,Qpr),e(yt,Jd),e(Jd,Wpr),e(Jd,gbe),e(gbe,Hpr),e(Jd,Upr),e(Jd,pH),e(pH,Jpr),e(Jd,Ypr),e(yt,Kpr),M(qT,yt,null),e(Yo,Zpr),e(Yo,bo),M(u9,bo,null),e(bo,e_r),e(bo,hbe),e(hbe,o_r),e(bo,r_r),e(bo,rn),e(rn,t_r),e(rn,pbe),e(pbe,a_r),e(rn,n_r),e(rn,_be),e(_be,s_r),e(rn,l_r),e(rn,ube),e(ube,i_r),e(rn,d_r),e(bo,c_r),e(bo,bbe),e(bbe,jT),e(jT,vbe),e(vbe,f_r),e(jT,m_r),e(jT,_H),e(_H,g_r),e(jT,h_r),e(bo,p_r),e(bo,DT),e(DT,__r),e(DT,Fbe),e(Fbe,u_r),e(DT,b_r),e(DT,Tbe),e(Tbe,v_r),e(bo,F_r),M(GT,bo,null),b(f,OVe,u),b(f,Yd,u),e(Yd,OT),e(OT,Mbe),M(b9,Mbe,null),e(Yd,T_r),e(Yd,Ebe),e(Ebe,M_r),b(f,VVe,u),b(f,Ko,u),M(v9,Ko,null),e(Ko,E_r),e(Ko,Kd),e(Kd,C_r),e(Kd,uH),e(uH,w_r),e(Kd,A_r),e(Kd,bH),e(bH,L_r),e(Kd,y_r),e(Ko,x_r),e(Ko,F9),e(F9,$_r),e(F9,Cbe),e(Cbe,k_r),e(F9,S_r),e(Ko,R_r),e(Ko,xt),M(T9,xt,null),e(xt,P_r),e(xt,wbe),e(wbe,B_r),e(xt,N_r),e(xt,Zd),e(Zd,I_r),e(Zd,Abe),e(Abe,q_r),e(Zd,j_r),e(Zd,vH),e(vH,D_r),e(Zd,G_r),e(xt,O_r),M(VT,xt,null),e(Ko,V_r),e(Ko,vo),M(M9,vo,null),e(vo,X_r),e(vo,Lbe),e(Lbe,z_r),e(vo,Q_r),e(vo,tn),e(tn,W_r),e(tn,ybe),e(ybe,H_r),e(tn,U_r),e(tn,xbe),e(xbe,J_r),e(tn,Y_r),e(tn,$be),e($be,K_r),e(tn,Z_r),e(vo,eur),e(vo,an),e(an,XT),e(XT,kbe),e(kbe,our),e(XT,rur),e(XT,FH),e(FH,tur),e(XT,aur),e(an,nur),e(an,zT),e(zT,Sbe),e(Sbe,sur),e(zT,lur),e(zT,TH),e(TH,iur),e(zT,dur),e(an,cur),e(an,QT),e(QT,Rbe),e(Rbe,fur),e(QT,mur),e(QT,MH),e(MH,gur),e(QT,hur),e(an,pur),e(an,WT),e(WT,Pbe),e(Pbe,_ur),e(WT,uur),e(WT,EH),e(EH,bur),e(WT,vur),e(vo,Fur),e(vo,HT),e(HT,Tur),e(HT,Bbe),e(Bbe,Mur),e(HT,Eur),e(HT,Nbe),e(Nbe,Cur),e(vo,wur),M(UT,vo,null),b(f,XVe,u),b(f,ec,u),e(ec,JT),e(JT,Ibe),M(E9,Ibe,null),e(ec,Aur),e(ec,qbe),e(qbe,Lur),b(f,zVe,u),b(f,Zo,u),M(C9,Zo,null),e(Zo,yur),e(Zo,oc),e(oc,xur),e(oc,CH),e(CH,$ur),e(oc,kur),e(oc,wH),e(wH,Sur),e(oc,Rur),e(Zo,Pur),e(Zo,w9),e(w9,Bur),e(w9,jbe),e(jbe,Nur),e(w9,Iur),e(Zo,qur),e(Zo,$t),M(A9,$t,null),e($t,jur),e($t,Dbe),e(Dbe,Dur),e($t,Gur),e($t,rc),e(rc,Our),e(rc,Gbe),e(Gbe,Vur),e(rc,Xur),e(rc,AH),e(AH,zur),e(rc,Qur),e($t,Wur),M(YT,$t,null),e(Zo,Hur),e(Zo,Fo),M(L9,Fo,null),e(Fo,Uur),e(Fo,Obe),e(Obe,Jur),e(Fo,Yur),e(Fo,nn),e(nn,Kur),e(nn,Vbe),e(Vbe,Zur),e(nn,e2r),e(nn,Xbe),e(Xbe,o2r),e(nn,r2r),e(nn,zbe),e(zbe,t2r),e(nn,a2r),e(Fo,n2r),e(Fo,Qbe),e(Qbe,KT),e(KT,Wbe),e(Wbe,s2r),e(KT,l2r),e(KT,LH),e(LH,i2r),e(KT,d2r),e(Fo,c2r),e(Fo,ZT),e(ZT,f2r),e(ZT,Hbe),e(Hbe,m2r),e(ZT,g2r),e(ZT,Ube),e(Ube,h2r),e(Fo,p2r),M(eM,Fo,null),b(f,QVe,u),b(f,tc,u),e(tc,oM),e(oM,Jbe),M(y9,Jbe,null),e(tc,_2r),e(tc,Ybe),e(Ybe,u2r),b(f,WVe,u),b(f,er,u),M(x9,er,null),e(er,b2r),e(er,ac),e(ac,v2r),e(ac,yH),e(yH,F2r),e(ac,T2r),e(ac,xH),e(xH,M2r),e(ac,E2r),e(er,C2r),e(er,$9),e($9,w2r),e($9,Kbe),e(Kbe,A2r),e($9,L2r),e(er,y2r),e(er,kt),M(k9,kt,null),e(kt,x2r),e(kt,Zbe),e(Zbe,$2r),e(kt,k2r),e(kt,nc),e(nc,S2r),e(nc,eve),e(eve,R2r),e(nc,P2r),e(nc,$H),e($H,B2r),e(nc,N2r),e(kt,I2r),M(rM,kt,null),e(er,q2r),e(er,xr),M(S9,xr,null),e(xr,j2r),e(xr,ove),e(ove,D2r),e(xr,G2r),e(xr,sn),e(sn,O2r),e(sn,rve),e(rve,V2r),e(sn,X2r),e(sn,tve),e(tve,z2r),e(sn,Q2r),e(sn,ave),e(ave,W2r),e(sn,H2r),e(xr,U2r),e(xr,q),e(q,tM),e(tM,nve),e(nve,J2r),e(tM,Y2r),e(tM,kH),e(kH,K2r),e(tM,Z2r),e(q,e1r),e(q,aM),e(aM,sve),e(sve,o1r),e(aM,r1r),e(aM,SH),e(SH,t1r),e(aM,a1r),e(q,n1r),e(q,nM),e(nM,lve),e(lve,s1r),e(nM,l1r),e(nM,RH),e(RH,i1r),e(nM,d1r),e(q,c1r),e(q,sM),e(sM,ive),e(ive,f1r),e(sM,m1r),e(sM,PH),e(PH,g1r),e(sM,h1r),e(q,p1r),e(q,lM),e(lM,dve),e(dve,_1r),e(lM,u1r),e(lM,BH),e(BH,b1r),e(lM,v1r),e(q,F1r),e(q,iM),e(iM,cve),e(cve,T1r),e(iM,M1r),e(iM,NH),e(NH,E1r),e(iM,C1r),e(q,w1r),e(q,dM),e(dM,fve),e(fve,A1r),e(dM,L1r),e(dM,IH),e(IH,y1r),e(dM,x1r),e(q,$1r),e(q,cM),e(cM,mve),e(mve,k1r),e(cM,S1r),e(cM,qH),e(qH,R1r),e(cM,P1r),e(q,B1r),e(q,fM),e(fM,gve),e(gve,N1r),e(fM,I1r),e(fM,jH),e(jH,q1r),e(fM,j1r),e(q,D1r),e(q,mM),e(mM,hve),e(hve,G1r),e(mM,O1r),e(mM,DH),e(DH,V1r),e(mM,X1r),e(q,z1r),e(q,gM),e(gM,pve),e(pve,Q1r),e(gM,W1r),e(gM,GH),e(GH,H1r),e(gM,U1r),e(q,J1r),e(q,hM),e(hM,_ve),e(_ve,Y1r),e(hM,K1r),e(hM,OH),e(OH,Z1r),e(hM,e7r),e(q,o7r),e(q,pM),e(pM,uve),e(uve,r7r),e(pM,t7r),e(pM,VH),e(VH,a7r),e(pM,n7r),e(q,s7r),e(q,_M),e(_M,bve),e(bve,l7r),e(_M,i7r),e(_M,XH),e(XH,d7r),e(_M,c7r),e(q,f7r),e(q,uM),e(uM,vve),e(vve,m7r),e(uM,g7r),e(uM,zH),e(zH,h7r),e(uM,p7r),e(q,_7r),e(q,bM),e(bM,Fve),e(Fve,u7r),e(bM,b7r),e(bM,QH),e(QH,v7r),e(bM,F7r),e(q,T7r),e(q,vM),e(vM,Tve),e(Tve,M7r),e(vM,E7r),e(vM,WH),e(WH,C7r),e(vM,w7r),e(q,A7r),e(q,Us),e(Us,Mve),e(Mve,L7r),e(Us,y7r),e(Us,HH),e(HH,x7r),e(Us,$7r),e(Us,UH),e(UH,k7r),e(Us,S7r),e(q,R7r),e(q,FM),e(FM,Eve),e(Eve,P7r),e(FM,B7r),e(FM,JH),e(JH,N7r),e(FM,I7r),e(q,q7r),e(q,TM),e(TM,Cve),e(Cve,j7r),e(TM,D7r),e(TM,YH),e(YH,G7r),e(TM,O7r),e(q,V7r),e(q,MM),e(MM,wve),e(wve,X7r),e(MM,z7r),e(MM,KH),e(KH,Q7r),e(MM,W7r),e(q,H7r),e(q,EM),e(EM,Ave),e(Ave,U7r),e(EM,J7r),e(EM,ZH),e(ZH,Y7r),e(EM,K7r),e(q,Z7r),e(q,CM),e(CM,Lve),e(Lve,e4r),e(CM,o4r),e(CM,eU),e(eU,r4r),e(CM,t4r),e(q,a4r),e(q,wM),e(wM,yve),e(yve,n4r),e(wM,s4r),e(wM,oU),e(oU,l4r),e(wM,i4r),e(q,d4r),e(q,AM),e(AM,xve),e(xve,c4r),e(AM,f4r),e(AM,rU),e(rU,m4r),e(AM,g4r),e(q,h4r),e(q,LM),e(LM,$ve),e($ve,p4r),e(LM,_4r),e(LM,tU),e(tU,u4r),e(LM,b4r),e(q,v4r),e(q,yM),e(yM,kve),e(kve,F4r),e(yM,T4r),e(yM,aU),e(aU,M4r),e(yM,E4r),e(q,C4r),e(q,xM),e(xM,Sve),e(Sve,w4r),e(xM,A4r),e(xM,nU),e(nU,L4r),e(xM,y4r),e(q,x4r),e(q,$M),e($M,Rve),e(Rve,$4r),e($M,k4r),e($M,sU),e(sU,S4r),e($M,R4r),e(q,P4r),e(q,kM),e(kM,Pve),e(Pve,B4r),e(kM,N4r),e(kM,lU),e(lU,I4r),e(kM,q4r),e(q,j4r),e(q,SM),e(SM,Bve),e(Bve,D4r),e(SM,G4r),e(SM,iU),e(iU,O4r),e(SM,V4r),e(q,X4r),e(q,RM),e(RM,Nve),e(Nve,z4r),e(RM,Q4r),e(RM,dU),e(dU,W4r),e(RM,H4r),e(q,U4r),e(q,PM),e(PM,Ive),e(Ive,J4r),e(PM,Y4r),e(PM,cU),e(cU,K4r),e(PM,Z4r),e(q,ebr),e(q,BM),e(BM,qve),e(qve,obr),e(BM,rbr),e(BM,fU),e(fU,tbr),e(BM,abr),e(q,nbr),e(q,NM),e(NM,jve),e(jve,sbr),e(NM,lbr),e(NM,mU),e(mU,ibr),e(NM,dbr),e(q,cbr),e(q,IM),e(IM,Dve),e(Dve,fbr),e(IM,mbr),e(IM,gU),e(gU,gbr),e(IM,hbr),e(q,pbr),e(q,qM),e(qM,Gve),e(Gve,_br),e(qM,ubr),e(qM,hU),e(hU,bbr),e(qM,vbr),e(q,Fbr),e(q,jM),e(jM,Ove),e(Ove,Tbr),e(jM,Mbr),e(jM,pU),e(pU,Ebr),e(jM,Cbr),e(q,wbr),e(q,DM),e(DM,Vve),e(Vve,Abr),e(DM,Lbr),e(DM,_U),e(_U,ybr),e(DM,xbr),e(q,$br),e(q,GM),e(GM,Xve),e(Xve,kbr),e(GM,Sbr),e(GM,uU),e(uU,Rbr),e(GM,Pbr),e(q,Bbr),e(q,OM),e(OM,zve),e(zve,Nbr),e(OM,Ibr),e(OM,bU),e(bU,qbr),e(OM,jbr),e(q,Dbr),e(q,VM),e(VM,Qve),e(Qve,Gbr),e(VM,Obr),e(VM,vU),e(vU,Vbr),e(VM,Xbr),e(q,zbr),e(q,XM),e(XM,Wve),e(Wve,Qbr),e(XM,Wbr),e(XM,FU),e(FU,Hbr),e(XM,Ubr),e(q,Jbr),e(q,zM),e(zM,Hve),e(Hve,Ybr),e(zM,Kbr),e(zM,TU),e(TU,Zbr),e(zM,evr),e(q,ovr),e(q,QM),e(QM,Uve),e(Uve,rvr),e(QM,tvr),e(QM,MU),e(MU,avr),e(QM,nvr),e(q,svr),e(q,WM),e(WM,Jve),e(Jve,lvr),e(WM,ivr),e(WM,EU),e(EU,dvr),e(WM,cvr),e(q,fvr),e(q,HM),e(HM,Yve),e(Yve,mvr),e(HM,gvr),e(HM,CU),e(CU,hvr),e(HM,pvr),e(q,_vr),e(q,UM),e(UM,Kve),e(Kve,uvr),e(UM,bvr),e(UM,wU),e(wU,vvr),e(UM,Fvr),e(q,Tvr),e(q,JM),e(JM,Zve),e(Zve,Mvr),e(JM,Evr),e(JM,AU),e(AU,Cvr),e(JM,wvr),e(xr,Avr),M(YM,xr,null),b(f,HVe,u),b(f,sc,u),e(sc,KM),e(KM,eFe),M(R9,eFe,null),e(sc,Lvr),e(sc,oFe),e(oFe,yvr),b(f,UVe,u),b(f,or,u),M(P9,or,null),e(or,xvr),e(or,lc),e(lc,$vr),e(lc,LU),e(LU,kvr),e(lc,Svr),e(lc,yU),e(yU,Rvr),e(lc,Pvr),e(or,Bvr),e(or,B9),e(B9,Nvr),e(B9,rFe),e(rFe,Ivr),e(B9,qvr),e(or,jvr),e(or,St),M(N9,St,null),e(St,Dvr),e(St,tFe),e(tFe,Gvr),e(St,Ovr),e(St,ic),e(ic,Vvr),e(ic,aFe),e(aFe,Xvr),e(ic,zvr),e(ic,xU),e(xU,Qvr),e(ic,Wvr),e(St,Hvr),M(ZM,St,null),e(or,Uvr),e(or,$r),M(I9,$r,null),e($r,Jvr),e($r,nFe),e(nFe,Yvr),e($r,Kvr),e($r,ln),e(ln,Zvr),e(ln,sFe),e(sFe,eFr),e(ln,oFr),e(ln,lFe),e(lFe,rFr),e(ln,tFr),e(ln,iFe),e(iFe,aFr),e(ln,nFr),e($r,sFr),e($r,se),e(se,eE),e(eE,dFe),e(dFe,lFr),e(eE,iFr),e(eE,$U),e($U,dFr),e(eE,cFr),e(se,fFr),e(se,oE),e(oE,cFe),e(cFe,mFr),e(oE,gFr),e(oE,kU),e(kU,hFr),e(oE,pFr),e(se,_Fr),e(se,rE),e(rE,fFe),e(fFe,uFr),e(rE,bFr),e(rE,SU),e(SU,vFr),e(rE,FFr),e(se,TFr),e(se,tE),e(tE,mFe),e(mFe,MFr),e(tE,EFr),e(tE,RU),e(RU,CFr),e(tE,wFr),e(se,AFr),e(se,aE),e(aE,gFe),e(gFe,LFr),e(aE,yFr),e(aE,PU),e(PU,xFr),e(aE,$Fr),e(se,kFr),e(se,nE),e(nE,hFe),e(hFe,SFr),e(nE,RFr),e(nE,BU),e(BU,PFr),e(nE,BFr),e(se,NFr),e(se,sE),e(sE,pFe),e(pFe,IFr),e(sE,qFr),e(sE,NU),e(NU,jFr),e(sE,DFr),e(se,GFr),e(se,lE),e(lE,_Fe),e(_Fe,OFr),e(lE,VFr),e(lE,IU),e(IU,XFr),e(lE,zFr),e(se,QFr),e(se,iE),e(iE,uFe),e(uFe,WFr),e(iE,HFr),e(iE,qU),e(qU,UFr),e(iE,JFr),e(se,YFr),e(se,dE),e(dE,bFe),e(bFe,KFr),e(dE,ZFr),e(dE,jU),e(jU,eTr),e(dE,oTr),e(se,rTr),e(se,cE),e(cE,vFe),e(vFe,tTr),e(cE,aTr),e(cE,DU),e(DU,nTr),e(cE,sTr),e(se,lTr),e(se,fE),e(fE,FFe),e(FFe,iTr),e(fE,dTr),e(fE,GU),e(GU,cTr),e(fE,fTr),e(se,mTr),e(se,mE),e(mE,TFe),e(TFe,gTr),e(mE,hTr),e(mE,OU),e(OU,pTr),e(mE,_Tr),e(se,uTr),e(se,gE),e(gE,MFe),e(MFe,bTr),e(gE,vTr),e(gE,VU),e(VU,FTr),e(gE,TTr),e(se,MTr),e(se,hE),e(hE,EFe),e(EFe,ETr),e(hE,CTr),e(hE,XU),e(XU,wTr),e(hE,ATr),e(se,LTr),e(se,pE),e(pE,CFe),e(CFe,yTr),e(pE,xTr),e(pE,zU),e(zU,$Tr),e(pE,kTr),e(se,STr),e(se,_E),e(_E,wFe),e(wFe,RTr),e(_E,PTr),e(_E,QU),e(QU,BTr),e(_E,NTr),e(se,ITr),e(se,uE),e(uE,AFe),e(AFe,qTr),e(uE,jTr),e(uE,WU),e(WU,DTr),e(uE,GTr),e(se,OTr),e(se,bE),e(bE,LFe),e(LFe,VTr),e(bE,XTr),e(bE,HU),e(HU,zTr),e(bE,QTr),e(se,WTr),e(se,vE),e(vE,yFe),e(yFe,HTr),e(vE,UTr),e(vE,UU),e(UU,JTr),e(vE,YTr),e(se,KTr),e(se,FE),e(FE,xFe),e(xFe,ZTr),e(FE,eMr),e(FE,JU),e(JU,oMr),e(FE,rMr),e(se,tMr),e(se,TE),e(TE,$Fe),e($Fe,aMr),e(TE,nMr),e(TE,YU),e(YU,sMr),e(TE,lMr),e(se,iMr),e(se,ME),e(ME,kFe),e(kFe,dMr),e(ME,cMr),e(ME,KU),e(KU,fMr),e(ME,mMr),e($r,gMr),M(EE,$r,null),b(f,JVe,u),b(f,dc,u),e(dc,CE),e(CE,SFe),M(q9,SFe,null),e(dc,hMr),e(dc,RFe),e(RFe,pMr),b(f,YVe,u),b(f,rr,u),M(j9,rr,null),e(rr,_Mr),e(rr,cc),e(cc,uMr),e(cc,ZU),e(ZU,bMr),e(cc,vMr),e(cc,eJ),e(eJ,FMr),e(cc,TMr),e(rr,MMr),e(rr,D9),e(D9,EMr),e(D9,PFe),e(PFe,CMr),e(D9,wMr),e(rr,AMr),e(rr,Rt),M(G9,Rt,null),e(Rt,LMr),e(Rt,BFe),e(BFe,yMr),e(Rt,xMr),e(Rt,fc),e(fc,$Mr),e(fc,NFe),e(NFe,kMr),e(fc,SMr),e(fc,oJ),e(oJ,RMr),e(fc,PMr),e(Rt,BMr),M(wE,Rt,null),e(rr,NMr),e(rr,kr),M(O9,kr,null),e(kr,IMr),e(kr,IFe),e(IFe,qMr),e(kr,jMr),e(kr,dn),e(dn,DMr),e(dn,qFe),e(qFe,GMr),e(dn,OMr),e(dn,jFe),e(jFe,VMr),e(dn,XMr),e(dn,DFe),e(DFe,zMr),e(dn,QMr),e(kr,WMr),e(kr,Me),e(Me,AE),e(AE,GFe),e(GFe,HMr),e(AE,UMr),e(AE,rJ),e(rJ,JMr),e(AE,YMr),e(Me,KMr),e(Me,LE),e(LE,OFe),e(OFe,ZMr),e(LE,eEr),e(LE,tJ),e(tJ,oEr),e(LE,rEr),e(Me,tEr),e(Me,yE),e(yE,VFe),e(VFe,aEr),e(yE,nEr),e(yE,aJ),e(aJ,sEr),e(yE,lEr),e(Me,iEr),e(Me,xE),e(xE,XFe),e(XFe,dEr),e(xE,cEr),e(xE,nJ),e(nJ,fEr),e(xE,mEr),e(Me,gEr),e(Me,$E),e($E,zFe),e(zFe,hEr),e($E,pEr),e($E,sJ),e(sJ,_Er),e($E,uEr),e(Me,bEr),e(Me,kE),e(kE,QFe),e(QFe,vEr),e(kE,FEr),e(kE,lJ),e(lJ,TEr),e(kE,MEr),e(Me,EEr),e(Me,SE),e(SE,WFe),e(WFe,CEr),e(SE,wEr),e(SE,iJ),e(iJ,AEr),e(SE,LEr),e(Me,yEr),e(Me,RE),e(RE,HFe),e(HFe,xEr),e(RE,$Er),e(RE,dJ),e(dJ,kEr),e(RE,SEr),e(Me,REr),e(Me,PE),e(PE,UFe),e(UFe,PEr),e(PE,BEr),e(PE,cJ),e(cJ,NEr),e(PE,IEr),e(Me,qEr),e(Me,BE),e(BE,JFe),e(JFe,jEr),e(BE,DEr),e(BE,fJ),e(fJ,GEr),e(BE,OEr),e(Me,VEr),e(Me,NE),e(NE,YFe),e(YFe,XEr),e(NE,zEr),e(NE,mJ),e(mJ,QEr),e(NE,WEr),e(Me,HEr),e(Me,IE),e(IE,KFe),e(KFe,UEr),e(IE,JEr),e(IE,gJ),e(gJ,YEr),e(IE,KEr),e(Me,ZEr),e(Me,qE),e(qE,ZFe),e(ZFe,eCr),e(qE,oCr),e(qE,hJ),e(hJ,rCr),e(qE,tCr),e(kr,aCr),M(jE,kr,null),b(f,KVe,u),b(f,mc,u),e(mc,DE),e(DE,eTe),M(V9,eTe,null),e(mc,nCr),e(mc,oTe),e(oTe,sCr),b(f,ZVe,u),b(f,tr,u),M(X9,tr,null),e(tr,lCr),e(tr,gc),e(gc,iCr),e(gc,pJ),e(pJ,dCr),e(gc,cCr),e(gc,_J),e(_J,fCr),e(gc,mCr),e(tr,gCr),e(tr,z9),e(z9,hCr),e(z9,rTe),e(rTe,pCr),e(z9,_Cr),e(tr,uCr),e(tr,Pt),M(Q9,Pt,null),e(Pt,bCr),e(Pt,tTe),e(tTe,vCr),e(Pt,FCr),e(Pt,hc),e(hc,TCr),e(hc,aTe),e(aTe,MCr),e(hc,ECr),e(hc,uJ),e(uJ,CCr),e(hc,wCr),e(Pt,ACr),M(GE,Pt,null),e(tr,LCr),e(tr,Sr),M(W9,Sr,null),e(Sr,yCr),e(Sr,nTe),e(nTe,xCr),e(Sr,$Cr),e(Sr,cn),e(cn,kCr),e(cn,sTe),e(sTe,SCr),e(cn,RCr),e(cn,lTe),e(lTe,PCr),e(cn,BCr),e(cn,iTe),e(iTe,NCr),e(cn,ICr),e(Sr,qCr),e(Sr,ar),e(ar,OE),e(OE,dTe),e(dTe,jCr),e(OE,DCr),e(OE,bJ),e(bJ,GCr),e(OE,OCr),e(ar,VCr),e(ar,VE),e(VE,cTe),e(cTe,XCr),e(VE,zCr),e(VE,vJ),e(vJ,QCr),e(VE,WCr),e(ar,HCr),e(ar,XE),e(XE,fTe),e(fTe,UCr),e(XE,JCr),e(XE,FJ),e(FJ,YCr),e(XE,KCr),e(ar,ZCr),e(ar,zE),e(zE,mTe),e(mTe,e3r),e(zE,o3r),e(zE,TJ),e(TJ,r3r),e(zE,t3r),e(ar,a3r),e(ar,QE),e(QE,gTe),e(gTe,n3r),e(QE,s3r),e(QE,MJ),e(MJ,l3r),e(QE,i3r),e(ar,d3r),e(ar,WE),e(WE,hTe),e(hTe,c3r),e(WE,f3r),e(WE,EJ),e(EJ,m3r),e(WE,g3r),e(Sr,h3r),M(HE,Sr,null),b(f,eXe,u),b(f,pc,u),e(pc,UE),e(UE,pTe),M(H9,pTe,null),e(pc,p3r),e(pc,_Te),e(_Te,_3r),b(f,oXe,u),b(f,nr,u),M(U9,nr,null),e(nr,u3r),e(nr,_c),e(_c,b3r),e(_c,CJ),e(CJ,v3r),e(_c,F3r),e(_c,wJ),e(wJ,T3r),e(_c,M3r),e(nr,E3r),e(nr,J9),e(J9,C3r),e(J9,uTe),e(uTe,w3r),e(J9,A3r),e(nr,L3r),e(nr,Bt),M(Y9,Bt,null),e(Bt,y3r),e(Bt,bTe),e(bTe,x3r),e(Bt,$3r),e(Bt,uc),e(uc,k3r),e(uc,vTe),e(vTe,S3r),e(uc,R3r),e(uc,AJ),e(AJ,P3r),e(uc,B3r),e(Bt,N3r),M(JE,Bt,null),e(nr,I3r),e(nr,Rr),M(K9,Rr,null),e(Rr,q3r),e(Rr,FTe),e(FTe,j3r),e(Rr,D3r),e(Rr,fn),e(fn,G3r),e(fn,TTe),e(TTe,O3r),e(fn,V3r),e(fn,MTe),e(MTe,X3r),e(fn,z3r),e(fn,ETe),e(ETe,Q3r),e(fn,W3r),e(Rr,H3r),e(Rr,ie),e(ie,YE),e(YE,CTe),e(CTe,U3r),e(YE,J3r),e(YE,LJ),e(LJ,Y3r),e(YE,K3r),e(ie,Z3r),e(ie,KE),e(KE,wTe),e(wTe,e5r),e(KE,o5r),e(KE,yJ),e(yJ,r5r),e(KE,t5r),e(ie,a5r),e(ie,ZE),e(ZE,ATe),e(ATe,n5r),e(ZE,s5r),e(ZE,xJ),e(xJ,l5r),e(ZE,i5r),e(ie,d5r),e(ie,eC),e(eC,LTe),e(LTe,c5r),e(eC,f5r),e(eC,$J),e($J,m5r),e(eC,g5r),e(ie,h5r),e(ie,oC),e(oC,yTe),e(yTe,p5r),e(oC,_5r),e(oC,kJ),e(kJ,u5r),e(oC,b5r),e(ie,v5r),e(ie,rC),e(rC,xTe),e(xTe,F5r),e(rC,T5r),e(rC,SJ),e(SJ,M5r),e(rC,E5r),e(ie,C5r),e(ie,tC),e(tC,$Te),e($Te,w5r),e(tC,A5r),e(tC,RJ),e(RJ,L5r),e(tC,y5r),e(ie,x5r),e(ie,aC),e(aC,kTe),e(kTe,$5r),e(aC,k5r),e(aC,PJ),e(PJ,S5r),e(aC,R5r),e(ie,P5r),e(ie,nC),e(nC,STe),e(STe,B5r),e(nC,N5r),e(nC,BJ),e(BJ,I5r),e(nC,q5r),e(ie,j5r),e(ie,sC),e(sC,RTe),e(RTe,D5r),e(sC,G5r),e(sC,NJ),e(NJ,O5r),e(sC,V5r),e(ie,X5r),e(ie,lC),e(lC,PTe),e(PTe,z5r),e(lC,Q5r),e(lC,IJ),e(IJ,W5r),e(lC,H5r),e(ie,U5r),e(ie,iC),e(iC,BTe),e(BTe,J5r),e(iC,Y5r),e(iC,qJ),e(qJ,K5r),e(iC,Z5r),e(ie,e0r),e(ie,dC),e(dC,NTe),e(NTe,o0r),e(dC,r0r),e(dC,jJ),e(jJ,t0r),e(dC,a0r),e(ie,n0r),e(ie,cC),e(cC,ITe),e(ITe,s0r),e(cC,l0r),e(cC,DJ),e(DJ,i0r),e(cC,d0r),e(ie,c0r),e(ie,fC),e(fC,qTe),e(qTe,f0r),e(fC,m0r),e(fC,GJ),e(GJ,g0r),e(fC,h0r),e(ie,p0r),e(ie,mC),e(mC,jTe),e(jTe,_0r),e(mC,u0r),e(mC,OJ),e(OJ,b0r),e(mC,v0r),e(ie,F0r),e(ie,gC),e(gC,DTe),e(DTe,T0r),e(gC,M0r),e(gC,VJ),e(VJ,E0r),e(gC,C0r),e(ie,w0r),e(ie,hC),e(hC,GTe),e(GTe,A0r),e(hC,L0r),e(hC,XJ),e(XJ,y0r),e(hC,x0r),e(ie,$0r),e(ie,pC),e(pC,OTe),e(OTe,k0r),e(pC,S0r),e(pC,zJ),e(zJ,R0r),e(pC,P0r),e(ie,B0r),e(ie,_C),e(_C,VTe),e(VTe,N0r),e(_C,I0r),e(_C,QJ),e(QJ,q0r),e(_C,j0r),e(Rr,D0r),M(uC,Rr,null),b(f,rXe,u),b(f,bc,u),e(bc,bC),e(bC,XTe),M(Z9,XTe,null),e(bc,G0r),e(bc,zTe),e(zTe,O0r),b(f,tXe,u),b(f,sr,u),M(ex,sr,null),e(sr,V0r),e(sr,vc),e(vc,X0r),e(vc,WJ),e(WJ,z0r),e(vc,Q0r),e(vc,HJ),e(HJ,W0r),e(vc,H0r),e(sr,U0r),e(sr,ox),e(ox,J0r),e(ox,QTe),e(QTe,Y0r),e(ox,K0r),e(sr,Z0r),e(sr,Nt),M(rx,Nt,null),e(Nt,ewr),e(Nt,WTe),e(WTe,owr),e(Nt,rwr),e(Nt,Fc),e(Fc,twr),e(Fc,HTe),e(HTe,awr),e(Fc,nwr),e(Fc,UJ),e(UJ,swr),e(Fc,lwr),e(Nt,iwr),M(vC,Nt,null),e(sr,dwr),e(sr,Pr),M(tx,Pr,null),e(Pr,cwr),e(Pr,UTe),e(UTe,fwr),e(Pr,mwr),e(Pr,mn),e(mn,gwr),e(mn,JTe),e(JTe,hwr),e(mn,pwr),e(mn,YTe),e(YTe,_wr),e(mn,uwr),e(mn,KTe),e(KTe,bwr),e(mn,vwr),e(Pr,Fwr),e(Pr,ye),e(ye,FC),e(FC,ZTe),e(ZTe,Twr),e(FC,Mwr),e(FC,JJ),e(JJ,Ewr),e(FC,Cwr),e(ye,wwr),e(ye,TC),e(TC,eMe),e(eMe,Awr),e(TC,Lwr),e(TC,YJ),e(YJ,ywr),e(TC,xwr),e(ye,$wr),e(ye,MC),e(MC,oMe),e(oMe,kwr),e(MC,Swr),e(MC,KJ),e(KJ,Rwr),e(MC,Pwr),e(ye,Bwr),e(ye,EC),e(EC,rMe),e(rMe,Nwr),e(EC,Iwr),e(EC,ZJ),e(ZJ,qwr),e(EC,jwr),e(ye,Dwr),e(ye,CC),e(CC,tMe),e(tMe,Gwr),e(CC,Owr),e(CC,eY),e(eY,Vwr),e(CC,Xwr),e(ye,zwr),e(ye,wC),e(wC,aMe),e(aMe,Qwr),e(wC,Wwr),e(wC,oY),e(oY,Hwr),e(wC,Uwr),e(ye,Jwr),e(ye,AC),e(AC,nMe),e(nMe,Ywr),e(AC,Kwr),e(AC,rY),e(rY,Zwr),e(AC,eAr),e(ye,oAr),e(ye,LC),e(LC,sMe),e(sMe,rAr),e(LC,tAr),e(LC,tY),e(tY,aAr),e(LC,nAr),e(ye,sAr),e(ye,yC),e(yC,lMe),e(lMe,lAr),e(yC,iAr),e(yC,aY),e(aY,dAr),e(yC,cAr),e(ye,fAr),e(ye,xC),e(xC,iMe),e(iMe,mAr),e(xC,gAr),e(xC,nY),e(nY,hAr),e(xC,pAr),e(Pr,_Ar),M($C,Pr,null),b(f,aXe,u),b(f,Tc,u),e(Tc,kC),e(kC,dMe),M(ax,dMe,null),e(Tc,uAr),e(Tc,cMe),e(cMe,bAr),b(f,nXe,u),b(f,lr,u),M(nx,lr,null),e(lr,vAr),e(lr,Mc),e(Mc,FAr),e(Mc,sY),e(sY,TAr),e(Mc,MAr),e(Mc,lY),e(lY,EAr),e(Mc,CAr),e(lr,wAr),e(lr,sx),e(sx,AAr),e(sx,fMe),e(fMe,LAr),e(sx,yAr),e(lr,xAr),e(lr,It),M(lx,It,null),e(It,$Ar),e(It,mMe),e(mMe,kAr),e(It,SAr),e(It,Ec),e(Ec,RAr),e(Ec,gMe),e(gMe,PAr),e(Ec,BAr),e(Ec,iY),e(iY,NAr),e(Ec,IAr),e(It,qAr),M(SC,It,null),e(lr,jAr),e(lr,Br),M(ix,Br,null),e(Br,DAr),e(Br,hMe),e(hMe,GAr),e(Br,OAr),e(Br,gn),e(gn,VAr),e(gn,pMe),e(pMe,XAr),e(gn,zAr),e(gn,_Me),e(_Me,QAr),e(gn,WAr),e(gn,uMe),e(uMe,HAr),e(gn,UAr),e(Br,JAr),e(Br,te),e(te,RC),e(RC,bMe),e(bMe,YAr),e(RC,KAr),e(RC,dY),e(dY,ZAr),e(RC,e6r),e(te,o6r),e(te,PC),e(PC,vMe),e(vMe,r6r),e(PC,t6r),e(PC,cY),e(cY,a6r),e(PC,n6r),e(te,s6r),e(te,BC),e(BC,FMe),e(FMe,l6r),e(BC,i6r),e(BC,fY),e(fY,d6r),e(BC,c6r),e(te,f6r),e(te,NC),e(NC,TMe),e(TMe,m6r),e(NC,g6r),e(NC,mY),e(mY,h6r),e(NC,p6r),e(te,_6r),e(te,IC),e(IC,MMe),e(MMe,u6r),e(IC,b6r),e(IC,gY),e(gY,v6r),e(IC,F6r),e(te,T6r),e(te,qC),e(qC,EMe),e(EMe,M6r),e(qC,E6r),e(qC,hY),e(hY,C6r),e(qC,w6r),e(te,A6r),e(te,jC),e(jC,CMe),e(CMe,L6r),e(jC,y6r),e(jC,pY),e(pY,x6r),e(jC,$6r),e(te,k6r),e(te,DC),e(DC,wMe),e(wMe,S6r),e(DC,R6r),e(DC,_Y),e(_Y,P6r),e(DC,B6r),e(te,N6r),e(te,GC),e(GC,AMe),e(AMe,I6r),e(GC,q6r),e(GC,uY),e(uY,j6r),e(GC,D6r),e(te,G6r),e(te,OC),e(OC,LMe),e(LMe,O6r),e(OC,V6r),e(OC,bY),e(bY,X6r),e(OC,z6r),e(te,Q6r),e(te,VC),e(VC,yMe),e(yMe,W6r),e(VC,H6r),e(VC,vY),e(vY,U6r),e(VC,J6r),e(te,Y6r),e(te,XC),e(XC,xMe),e(xMe,K6r),e(XC,Z6r),e(XC,FY),e(FY,eLr),e(XC,oLr),e(te,rLr),e(te,zC),e(zC,$Me),e($Me,tLr),e(zC,aLr),e(zC,TY),e(TY,nLr),e(zC,sLr),e(te,lLr),e(te,QC),e(QC,kMe),e(kMe,iLr),e(QC,dLr),e(QC,MY),e(MY,cLr),e(QC,fLr),e(te,mLr),e(te,WC),e(WC,SMe),e(SMe,gLr),e(WC,hLr),e(WC,EY),e(EY,pLr),e(WC,_Lr),e(te,uLr),e(te,HC),e(HC,RMe),e(RMe,bLr),e(HC,vLr),e(HC,CY),e(CY,FLr),e(HC,TLr),e(te,MLr),e(te,UC),e(UC,PMe),e(PMe,ELr),e(UC,CLr),e(UC,wY),e(wY,wLr),e(UC,ALr),e(te,LLr),e(te,JC),e(JC,BMe),e(BMe,yLr),e(JC,xLr),e(JC,AY),e(AY,$Lr),e(JC,kLr),e(te,SLr),e(te,YC),e(YC,NMe),e(NMe,RLr),e(YC,PLr),e(YC,LY),e(LY,BLr),e(YC,NLr),e(te,ILr),e(te,KC),e(KC,IMe),e(IMe,qLr),e(KC,jLr),e(KC,yY),e(yY,DLr),e(KC,GLr),e(te,OLr),e(te,ZC),e(ZC,qMe),e(qMe,VLr),e(ZC,XLr),e(ZC,xY),e(xY,zLr),e(ZC,QLr),e(te,WLr),e(te,e3),e(e3,jMe),e(jMe,HLr),e(e3,ULr),e(e3,$Y),e($Y,JLr),e(e3,YLr),e(te,KLr),e(te,o3),e(o3,DMe),e(DMe,ZLr),e(o3,eyr),e(o3,kY),e(kY,oyr),e(o3,ryr),e(te,tyr),e(te,r3),e(r3,GMe),e(GMe,ayr),e(r3,nyr),e(r3,SY),e(SY,syr),e(r3,lyr),e(te,iyr),e(te,t3),e(t3,OMe),e(OMe,dyr),e(t3,cyr),e(t3,RY),e(RY,fyr),e(t3,myr),e(te,gyr),e(te,a3),e(a3,VMe),e(VMe,hyr),e(a3,pyr),e(a3,PY),e(PY,_yr),e(a3,uyr),e(Br,byr),M(n3,Br,null),b(f,sXe,u),b(f,Cc,u),e(Cc,s3),e(s3,XMe),M(dx,XMe,null),e(Cc,vyr),e(Cc,zMe),e(zMe,Fyr),b(f,lXe,u),b(f,ir,u),M(cx,ir,null),e(ir,Tyr),e(ir,wc),e(wc,Myr),e(wc,BY),e(BY,Eyr),e(wc,Cyr),e(wc,NY),e(NY,wyr),e(wc,Ayr),e(ir,Lyr),e(ir,fx),e(fx,yyr),e(fx,QMe),e(QMe,xyr),e(fx,$yr),e(ir,kyr),e(ir,qt),M(mx,qt,null),e(qt,Syr),e(qt,WMe),e(WMe,Ryr),e(qt,Pyr),e(qt,Ac),e(Ac,Byr),e(Ac,HMe),e(HMe,Nyr),e(Ac,Iyr),e(Ac,IY),e(IY,qyr),e(Ac,jyr),e(qt,Dyr),M(l3,qt,null),e(ir,Gyr),e(ir,Nr),M(gx,Nr,null),e(Nr,Oyr),e(Nr,UMe),e(UMe,Vyr),e(Nr,Xyr),e(Nr,hn),e(hn,zyr),e(hn,JMe),e(JMe,Qyr),e(hn,Wyr),e(hn,YMe),e(YMe,Hyr),e(hn,Uyr),e(hn,KMe),e(KMe,Jyr),e(hn,Yyr),e(Nr,Kyr),e(Nr,_e),e(_e,i3),e(i3,ZMe),e(ZMe,Zyr),e(i3,e8r),e(i3,qY),e(qY,o8r),e(i3,r8r),e(_e,t8r),e(_e,d3),e(d3,eEe),e(eEe,a8r),e(d3,n8r),e(d3,jY),e(jY,s8r),e(d3,l8r),e(_e,i8r),e(_e,c3),e(c3,oEe),e(oEe,d8r),e(c3,c8r),e(c3,DY),e(DY,f8r),e(c3,m8r),e(_e,g8r),e(_e,f3),e(f3,rEe),e(rEe,h8r),e(f3,p8r),e(f3,GY),e(GY,_8r),e(f3,u8r),e(_e,b8r),e(_e,m3),e(m3,tEe),e(tEe,v8r),e(m3,F8r),e(m3,OY),e(OY,T8r),e(m3,M8r),e(_e,E8r),e(_e,g3),e(g3,aEe),e(aEe,C8r),e(g3,w8r),e(g3,VY),e(VY,A8r),e(g3,L8r),e(_e,y8r),e(_e,h3),e(h3,nEe),e(nEe,x8r),e(h3,$8r),e(h3,XY),e(XY,k8r),e(h3,S8r),e(_e,R8r),e(_e,p3),e(p3,sEe),e(sEe,P8r),e(p3,B8r),e(p3,zY),e(zY,N8r),e(p3,I8r),e(_e,q8r),e(_e,_3),e(_3,lEe),e(lEe,j8r),e(_3,D8r),e(_3,QY),e(QY,G8r),e(_3,O8r),e(_e,V8r),e(_e,u3),e(u3,iEe),e(iEe,X8r),e(u3,z8r),e(u3,WY),e(WY,Q8r),e(u3,W8r),e(_e,H8r),e(_e,b3),e(b3,dEe),e(dEe,U8r),e(b3,J8r),e(b3,HY),e(HY,Y8r),e(b3,K8r),e(_e,Z8r),e(_e,v3),e(v3,cEe),e(cEe,e9r),e(v3,o9r),e(v3,UY),e(UY,r9r),e(v3,t9r),e(_e,a9r),e(_e,F3),e(F3,fEe),e(fEe,n9r),e(F3,s9r),e(F3,JY),e(JY,l9r),e(F3,i9r),e(_e,d9r),e(_e,T3),e(T3,mEe),e(mEe,c9r),e(T3,f9r),e(T3,YY),e(YY,m9r),e(T3,g9r),e(_e,h9r),e(_e,M3),e(M3,gEe),e(gEe,p9r),e(M3,_9r),e(M3,KY),e(KY,u9r),e(M3,b9r),e(_e,v9r),e(_e,E3),e(E3,hEe),e(hEe,F9r),e(E3,T9r),e(E3,ZY),e(ZY,M9r),e(E3,E9r),e(_e,C9r),e(_e,C3),e(C3,pEe),e(pEe,w9r),e(C3,A9r),e(C3,eK),e(eK,L9r),e(C3,y9r),e(Nr,x9r),M(w3,Nr,null),b(f,iXe,u),b(f,Lc,u),e(Lc,A3),e(A3,_Ee),M(hx,_Ee,null),e(Lc,$9r),e(Lc,uEe),e(uEe,k9r),b(f,dXe,u),b(f,dr,u),M(px,dr,null),e(dr,S9r),e(dr,yc),e(yc,R9r),e(yc,oK),e(oK,P9r),e(yc,B9r),e(yc,rK),e(rK,N9r),e(yc,I9r),e(dr,q9r),e(dr,_x),e(_x,j9r),e(_x,bEe),e(bEe,D9r),e(_x,G9r),e(dr,O9r),e(dr,jt),M(ux,jt,null),e(jt,V9r),e(jt,vEe),e(vEe,X9r),e(jt,z9r),e(jt,xc),e(xc,Q9r),e(xc,FEe),e(FEe,W9r),e(xc,H9r),e(xc,tK),e(tK,U9r),e(xc,J9r),e(jt,Y9r),M(L3,jt,null),e(dr,K9r),e(dr,Ir),M(bx,Ir,null),e(Ir,Z9r),e(Ir,TEe),e(TEe,exr),e(Ir,oxr),e(Ir,pn),e(pn,rxr),e(pn,MEe),e(MEe,txr),e(pn,axr),e(pn,EEe),e(EEe,nxr),e(pn,sxr),e(pn,CEe),e(CEe,lxr),e(pn,ixr),e(Ir,dxr),e(Ir,vx),e(vx,y3),e(y3,wEe),e(wEe,cxr),e(y3,fxr),e(y3,aK),e(aK,mxr),e(y3,gxr),e(vx,hxr),e(vx,x3),e(x3,AEe),e(AEe,pxr),e(x3,_xr),e(x3,nK),e(nK,uxr),e(x3,bxr),e(Ir,vxr),M($3,Ir,null),b(f,cXe,u),b(f,$c,u),e($c,k3),e(k3,LEe),M(Fx,LEe,null),e($c,Fxr),e($c,yEe),e(yEe,Txr),b(f,fXe,u),b(f,cr,u),M(Tx,cr,null),e(cr,Mxr),e(cr,kc),e(kc,Exr),e(kc,sK),e(sK,Cxr),e(kc,wxr),e(kc,lK),e(lK,Axr),e(kc,Lxr),e(cr,yxr),e(cr,Mx),e(Mx,xxr),e(Mx,xEe),e(xEe,$xr),e(Mx,kxr),e(cr,Sxr),e(cr,Dt),M(Ex,Dt,null),e(Dt,Rxr),e(Dt,$Ee),e($Ee,Pxr),e(Dt,Bxr),e(Dt,Sc),e(Sc,Nxr),e(Sc,kEe),e(kEe,Ixr),e(Sc,qxr),e(Sc,iK),e(iK,jxr),e(Sc,Dxr),e(Dt,Gxr),M(S3,Dt,null),e(cr,Oxr),e(cr,qr),M(Cx,qr,null),e(qr,Vxr),e(qr,SEe),e(SEe,Xxr),e(qr,zxr),e(qr,_n),e(_n,Qxr),e(_n,REe),e(REe,Wxr),e(_n,Hxr),e(_n,PEe),e(PEe,Uxr),e(_n,Jxr),e(_n,BEe),e(BEe,Yxr),e(_n,Kxr),e(qr,Zxr),e(qr,NEe),e(NEe,R3),e(R3,IEe),e(IEe,e$r),e(R3,o$r),e(R3,dK),e(dK,r$r),e(R3,t$r),e(qr,a$r),M(P3,qr,null),b(f,mXe,u),b(f,Rc,u),e(Rc,B3),e(B3,qEe),M(wx,qEe,null),e(Rc,n$r),e(Rc,jEe),e(jEe,s$r),b(f,gXe,u),b(f,fr,u),M(Ax,fr,null),e(fr,l$r),e(fr,Pc),e(Pc,i$r),e(Pc,cK),e(cK,d$r),e(Pc,c$r),e(Pc,fK),e(fK,f$r),e(Pc,m$r),e(fr,g$r),e(fr,Lx),e(Lx,h$r),e(Lx,DEe),e(DEe,p$r),e(Lx,_$r),e(fr,u$r),e(fr,Gt),M(yx,Gt,null),e(Gt,b$r),e(Gt,GEe),e(GEe,v$r),e(Gt,F$r),e(Gt,Bc),e(Bc,T$r),e(Bc,OEe),e(OEe,M$r),e(Bc,E$r),e(Bc,mK),e(mK,C$r),e(Bc,w$r),e(Gt,A$r),M(N3,Gt,null),e(fr,L$r),e(fr,jr),M(xx,jr,null),e(jr,y$r),e(jr,VEe),e(VEe,x$r),e(jr,$$r),e(jr,un),e(un,k$r),e(un,XEe),e(XEe,S$r),e(un,R$r),e(un,zEe),e(zEe,P$r),e(un,B$r),e(un,QEe),e(QEe,N$r),e(un,I$r),e(jr,q$r),e(jr,de),e(de,I3),e(I3,WEe),e(WEe,j$r),e(I3,D$r),e(I3,gK),e(gK,G$r),e(I3,O$r),e(de,V$r),e(de,q3),e(q3,HEe),e(HEe,X$r),e(q3,z$r),e(q3,hK),e(hK,Q$r),e(q3,W$r),e(de,H$r),e(de,j3),e(j3,UEe),e(UEe,U$r),e(j3,J$r),e(j3,pK),e(pK,Y$r),e(j3,K$r),e(de,Z$r),e(de,D3),e(D3,JEe),e(JEe,ekr),e(D3,okr),e(D3,_K),e(_K,rkr),e(D3,tkr),e(de,akr),e(de,G3),e(G3,YEe),e(YEe,nkr),e(G3,skr),e(G3,uK),e(uK,lkr),e(G3,ikr),e(de,dkr),e(de,O3),e(O3,KEe),e(KEe,ckr),e(O3,fkr),e(O3,bK),e(bK,mkr),e(O3,gkr),e(de,hkr),e(de,V3),e(V3,ZEe),e(ZEe,pkr),e(V3,_kr),e(V3,vK),e(vK,ukr),e(V3,bkr),e(de,vkr),e(de,X3),e(X3,eCe),e(eCe,Fkr),e(X3,Tkr),e(X3,FK),e(FK,Mkr),e(X3,Ekr),e(de,Ckr),e(de,z3),e(z3,oCe),e(oCe,wkr),e(z3,Akr),e(z3,TK),e(TK,Lkr),e(z3,ykr),e(de,xkr),e(de,Q3),e(Q3,rCe),e(rCe,$kr),e(Q3,kkr),e(Q3,MK),e(MK,Skr),e(Q3,Rkr),e(de,Pkr),e(de,W3),e(W3,tCe),e(tCe,Bkr),e(W3,Nkr),e(W3,EK),e(EK,Ikr),e(W3,qkr),e(de,jkr),e(de,H3),e(H3,aCe),e(aCe,Dkr),e(H3,Gkr),e(H3,CK),e(CK,Okr),e(H3,Vkr),e(de,Xkr),e(de,U3),e(U3,nCe),e(nCe,zkr),e(U3,Qkr),e(U3,wK),e(wK,Wkr),e(U3,Hkr),e(de,Ukr),e(de,J3),e(J3,sCe),e(sCe,Jkr),e(J3,Ykr),e(J3,AK),e(AK,Kkr),e(J3,Zkr),e(de,eSr),e(de,Y3),e(Y3,lCe),e(lCe,oSr),e(Y3,rSr),e(Y3,LK),e(LK,tSr),e(Y3,aSr),e(de,nSr),e(de,K3),e(K3,iCe),e(iCe,sSr),e(K3,lSr),e(K3,yK),e(yK,iSr),e(K3,dSr),e(de,cSr),e(de,Z3),e(Z3,dCe),e(dCe,fSr),e(Z3,mSr),e(Z3,xK),e(xK,gSr),e(Z3,hSr),e(de,pSr),e(de,e5),e(e5,cCe),e(cCe,_Sr),e(e5,uSr),e(e5,$K),e($K,bSr),e(e5,vSr),e(de,FSr),e(de,o5),e(o5,fCe),e(fCe,TSr),e(o5,MSr),e(o5,kK),e(kK,ESr),e(o5,CSr),e(de,wSr),e(de,r5),e(r5,mCe),e(mCe,ASr),e(r5,LSr),e(r5,SK),e(SK,ySr),e(r5,xSr),e(jr,$Sr),M(t5,jr,null),b(f,hXe,u),b(f,Nc,u),e(Nc,a5),e(a5,gCe),M($x,gCe,null),e(Nc,kSr),e(Nc,hCe),e(hCe,SSr),b(f,pXe,u),b(f,mr,u),M(kx,mr,null),e(mr,RSr),e(mr,Ic),e(Ic,PSr),e(Ic,RK),e(RK,BSr),e(Ic,NSr),e(Ic,PK),e(PK,ISr),e(Ic,qSr),e(mr,jSr),e(mr,Sx),e(Sx,DSr),e(Sx,pCe),e(pCe,GSr),e(Sx,OSr),e(mr,VSr),e(mr,Ot),M(Rx,Ot,null),e(Ot,XSr),e(Ot,_Ce),e(_Ce,zSr),e(Ot,QSr),e(Ot,qc),e(qc,WSr),e(qc,uCe),e(uCe,HSr),e(qc,USr),e(qc,BK),e(BK,JSr),e(qc,YSr),e(Ot,KSr),M(n5,Ot,null),e(mr,ZSr),e(mr,Dr),M(Px,Dr,null),e(Dr,eRr),e(Dr,bCe),e(bCe,oRr),e(Dr,rRr),e(Dr,bn),e(bn,tRr),e(bn,vCe),e(vCe,aRr),e(bn,nRr),e(bn,FCe),e(FCe,sRr),e(bn,lRr),e(bn,TCe),e(TCe,iRr),e(bn,dRr),e(Dr,cRr),e(Dr,ce),e(ce,s5),e(s5,MCe),e(MCe,fRr),e(s5,mRr),e(s5,NK),e(NK,gRr),e(s5,hRr),e(ce,pRr),e(ce,l5),e(l5,ECe),e(ECe,_Rr),e(l5,uRr),e(l5,IK),e(IK,bRr),e(l5,vRr),e(ce,FRr),e(ce,i5),e(i5,CCe),e(CCe,TRr),e(i5,MRr),e(i5,qK),e(qK,ERr),e(i5,CRr),e(ce,wRr),e(ce,d5),e(d5,wCe),e(wCe,ARr),e(d5,LRr),e(d5,jK),e(jK,yRr),e(d5,xRr),e(ce,$Rr),e(ce,c5),e(c5,ACe),e(ACe,kRr),e(c5,SRr),e(c5,DK),e(DK,RRr),e(c5,PRr),e(ce,BRr),e(ce,f5),e(f5,LCe),e(LCe,NRr),e(f5,IRr),e(f5,GK),e(GK,qRr),e(f5,jRr),e(ce,DRr),e(ce,m5),e(m5,yCe),e(yCe,GRr),e(m5,ORr),e(m5,OK),e(OK,VRr),e(m5,XRr),e(ce,zRr),e(ce,g5),e(g5,xCe),e(xCe,QRr),e(g5,WRr),e(g5,VK),e(VK,HRr),e(g5,URr),e(ce,JRr),e(ce,h5),e(h5,$Ce),e($Ce,YRr),e(h5,KRr),e(h5,XK),e(XK,ZRr),e(h5,ePr),e(ce,oPr),e(ce,p5),e(p5,kCe),e(kCe,rPr),e(p5,tPr),e(p5,zK),e(zK,aPr),e(p5,nPr),e(ce,sPr),e(ce,_5),e(_5,SCe),e(SCe,lPr),e(_5,iPr),e(_5,QK),e(QK,dPr),e(_5,cPr),e(ce,fPr),e(ce,u5),e(u5,RCe),e(RCe,mPr),e(u5,gPr),e(u5,WK),e(WK,hPr),e(u5,pPr),e(ce,_Pr),e(ce,b5),e(b5,PCe),e(PCe,uPr),e(b5,bPr),e(b5,HK),e(HK,vPr),e(b5,FPr),e(ce,TPr),e(ce,v5),e(v5,BCe),e(BCe,MPr),e(v5,EPr),e(v5,UK),e(UK,CPr),e(v5,wPr),e(ce,APr),e(ce,F5),e(F5,NCe),e(NCe,LPr),e(F5,yPr),e(F5,JK),e(JK,xPr),e(F5,$Pr),e(ce,kPr),e(ce,T5),e(T5,ICe),e(ICe,SPr),e(T5,RPr),e(T5,YK),e(YK,PPr),e(T5,BPr),e(ce,NPr),e(ce,M5),e(M5,qCe),e(qCe,IPr),e(M5,qPr),e(M5,KK),e(KK,jPr),e(M5,DPr),e(ce,GPr),e(ce,E5),e(E5,jCe),e(jCe,OPr),e(E5,VPr),e(E5,ZK),e(ZK,XPr),e(E5,zPr),e(ce,QPr),e(ce,C5),e(C5,DCe),e(DCe,WPr),e(C5,HPr),e(C5,eZ),e(eZ,UPr),e(C5,JPr),e(ce,YPr),e(ce,w5),e(w5,GCe),e(GCe,KPr),e(w5,ZPr),e(w5,oZ),e(oZ,eBr),e(w5,oBr),e(Dr,rBr),M(A5,Dr,null),b(f,_Xe,u),b(f,jc,u),e(jc,L5),e(L5,OCe),M(Bx,OCe,null),e(jc,tBr),e(jc,VCe),e(VCe,aBr),b(f,uXe,u),b(f,gr,u),M(Nx,gr,null),e(gr,nBr),e(gr,Dc),e(Dc,sBr),e(Dc,rZ),e(rZ,lBr),e(Dc,iBr),e(Dc,tZ),e(tZ,dBr),e(Dc,cBr),e(gr,fBr),e(gr,Ix),e(Ix,mBr),e(Ix,XCe),e(XCe,gBr),e(Ix,hBr),e(gr,pBr),e(gr,Vt),M(qx,Vt,null),e(Vt,_Br),e(Vt,zCe),e(zCe,uBr),e(Vt,bBr),e(Vt,Gc),e(Gc,vBr),e(Gc,QCe),e(QCe,FBr),e(Gc,TBr),e(Gc,aZ),e(aZ,MBr),e(Gc,EBr),e(Vt,CBr),M(y5,Vt,null),e(gr,wBr),e(gr,Gr),M(jx,Gr,null),e(Gr,ABr),e(Gr,WCe),e(WCe,LBr),e(Gr,yBr),e(Gr,vn),e(vn,xBr),e(vn,HCe),e(HCe,$Br),e(vn,kBr),e(vn,UCe),e(UCe,SBr),e(vn,RBr),e(vn,JCe),e(JCe,PBr),e(vn,BBr),e(Gr,NBr),e(Gr,YCe),e(YCe,x5),e(x5,KCe),e(KCe,IBr),e(x5,qBr),e(x5,nZ),e(nZ,jBr),e(x5,DBr),e(Gr,GBr),M($5,Gr,null),b(f,bXe,u),b(f,Oc,u),e(Oc,k5),e(k5,ZCe),M(Dx,ZCe,null),e(Oc,OBr),e(Oc,e3e),e(e3e,VBr),b(f,vXe,u),b(f,hr,u),M(Gx,hr,null),e(hr,XBr),e(hr,Vc),e(Vc,zBr),e(Vc,sZ),e(sZ,QBr),e(Vc,WBr),e(Vc,lZ),e(lZ,HBr),e(Vc,UBr),e(hr,JBr),e(hr,Ox),e(Ox,YBr),e(Ox,o3e),e(o3e,KBr),e(Ox,ZBr),e(hr,eNr),e(hr,Xt),M(Vx,Xt,null),e(Xt,oNr),e(Xt,r3e),e(r3e,rNr),e(Xt,tNr),e(Xt,Xc),e(Xc,aNr),e(Xc,t3e),e(t3e,nNr),e(Xc,sNr),e(Xc,iZ),e(iZ,lNr),e(Xc,iNr),e(Xt,dNr),M(S5,Xt,null),e(hr,cNr),e(hr,Or),M(Xx,Or,null),e(Or,fNr),e(Or,a3e),e(a3e,mNr),e(Or,gNr),e(Or,Fn),e(Fn,hNr),e(Fn,n3e),e(n3e,pNr),e(Fn,_Nr),e(Fn,s3e),e(s3e,uNr),e(Fn,bNr),e(Fn,l3e),e(l3e,vNr),e(Fn,FNr),e(Or,TNr),e(Or,i3e),e(i3e,R5),e(R5,d3e),e(d3e,MNr),e(R5,ENr),e(R5,dZ),e(dZ,CNr),e(R5,wNr),e(Or,ANr),M(P5,Or,null),b(f,FXe,u),b(f,zc,u),e(zc,B5),e(B5,c3e),M(zx,c3e,null),e(zc,LNr),e(zc,f3e),e(f3e,yNr),b(f,TXe,u),b(f,pr,u),M(Qx,pr,null),e(pr,xNr),e(pr,Qc),e(Qc,$Nr),e(Qc,cZ),e(cZ,kNr),e(Qc,SNr),e(Qc,fZ),e(fZ,RNr),e(Qc,PNr),e(pr,BNr),e(pr,Wx),e(Wx,NNr),e(Wx,m3e),e(m3e,INr),e(Wx,qNr),e(pr,jNr),e(pr,zt),M(Hx,zt,null),e(zt,DNr),e(zt,g3e),e(g3e,GNr),e(zt,ONr),e(zt,Wc),e(Wc,VNr),e(Wc,h3e),e(h3e,XNr),e(Wc,zNr),e(Wc,mZ),e(mZ,QNr),e(Wc,WNr),e(zt,HNr),M(N5,zt,null),e(pr,UNr),e(pr,Vr),M(Ux,Vr,null),e(Vr,JNr),e(Vr,p3e),e(p3e,YNr),e(Vr,KNr),e(Vr,Tn),e(Tn,ZNr),e(Tn,_3e),e(_3e,eIr),e(Tn,oIr),e(Tn,u3e),e(u3e,rIr),e(Tn,tIr),e(Tn,b3e),e(b3e,aIr),e(Tn,nIr),e(Vr,sIr),e(Vr,oe),e(oe,I5),e(I5,v3e),e(v3e,lIr),e(I5,iIr),e(I5,gZ),e(gZ,dIr),e(I5,cIr),e(oe,fIr),e(oe,q5),e(q5,F3e),e(F3e,mIr),e(q5,gIr),e(q5,hZ),e(hZ,hIr),e(q5,pIr),e(oe,_Ir),e(oe,j5),e(j5,T3e),e(T3e,uIr),e(j5,bIr),e(j5,pZ),e(pZ,vIr),e(j5,FIr),e(oe,TIr),e(oe,D5),e(D5,M3e),e(M3e,MIr),e(D5,EIr),e(D5,_Z),e(_Z,CIr),e(D5,wIr),e(oe,AIr),e(oe,G5),e(G5,E3e),e(E3e,LIr),e(G5,yIr),e(G5,uZ),e(uZ,xIr),e(G5,$Ir),e(oe,kIr),e(oe,O5),e(O5,C3e),e(C3e,SIr),e(O5,RIr),e(O5,bZ),e(bZ,PIr),e(O5,BIr),e(oe,NIr),e(oe,V5),e(V5,w3e),e(w3e,IIr),e(V5,qIr),e(V5,vZ),e(vZ,jIr),e(V5,DIr),e(oe,GIr),e(oe,X5),e(X5,A3e),e(A3e,OIr),e(X5,VIr),e(X5,FZ),e(FZ,XIr),e(X5,zIr),e(oe,QIr),e(oe,z5),e(z5,L3e),e(L3e,WIr),e(z5,HIr),e(z5,TZ),e(TZ,UIr),e(z5,JIr),e(oe,YIr),e(oe,Q5),e(Q5,y3e),e(y3e,KIr),e(Q5,ZIr),e(Q5,MZ),e(MZ,eqr),e(Q5,oqr),e(oe,rqr),e(oe,W5),e(W5,x3e),e(x3e,tqr),e(W5,aqr),e(W5,EZ),e(EZ,nqr),e(W5,sqr),e(oe,lqr),e(oe,H5),e(H5,$3e),e($3e,iqr),e(H5,dqr),e(H5,CZ),e(CZ,cqr),e(H5,fqr),e(oe,mqr),e(oe,U5),e(U5,k3e),e(k3e,gqr),e(U5,hqr),e(U5,wZ),e(wZ,pqr),e(U5,_qr),e(oe,uqr),e(oe,J5),e(J5,S3e),e(S3e,bqr),e(J5,vqr),e(J5,AZ),e(AZ,Fqr),e(J5,Tqr),e(oe,Mqr),e(oe,Y5),e(Y5,R3e),e(R3e,Eqr),e(Y5,Cqr),e(Y5,LZ),e(LZ,wqr),e(Y5,Aqr),e(oe,Lqr),e(oe,K5),e(K5,P3e),e(P3e,yqr),e(K5,xqr),e(K5,yZ),e(yZ,$qr),e(K5,kqr),e(oe,Sqr),e(oe,Z5),e(Z5,B3e),e(B3e,Rqr),e(Z5,Pqr),e(Z5,xZ),e(xZ,Bqr),e(Z5,Nqr),e(oe,Iqr),e(oe,e0),e(e0,N3e),e(N3e,qqr),e(e0,jqr),e(e0,$Z),e($Z,Dqr),e(e0,Gqr),e(oe,Oqr),e(oe,o0),e(o0,I3e),e(I3e,Vqr),e(o0,Xqr),e(o0,kZ),e(kZ,zqr),e(o0,Qqr),e(oe,Wqr),e(oe,r0),e(r0,q3e),e(q3e,Hqr),e(r0,Uqr),e(r0,SZ),e(SZ,Jqr),e(r0,Yqr),e(oe,Kqr),e(oe,t0),e(t0,j3e),e(j3e,Zqr),e(t0,ejr),e(t0,RZ),e(RZ,ojr),e(t0,rjr),e(oe,tjr),e(oe,a0),e(a0,D3e),e(D3e,ajr),e(a0,njr),e(a0,PZ),e(PZ,sjr),e(a0,ljr),e(oe,ijr),e(oe,n0),e(n0,G3e),e(G3e,djr),e(n0,cjr),e(n0,BZ),e(BZ,fjr),e(n0,mjr),e(oe,gjr),e(oe,s0),e(s0,O3e),e(O3e,hjr),e(s0,pjr),e(s0,NZ),e(NZ,_jr),e(s0,ujr),e(oe,bjr),e(oe,l0),e(l0,V3e),e(V3e,vjr),e(l0,Fjr),e(l0,IZ),e(IZ,Tjr),e(l0,Mjr),e(oe,Ejr),e(oe,i0),e(i0,X3e),e(X3e,Cjr),e(i0,wjr),e(i0,qZ),e(qZ,Ajr),e(i0,Ljr),e(oe,yjr),e(oe,d0),e(d0,z3e),e(z3e,xjr),e(d0,$jr),e(d0,jZ),e(jZ,kjr),e(d0,Sjr),e(Vr,Rjr),M(c0,Vr,null),b(f,MXe,u),b(f,Hc,u),e(Hc,f0),e(f0,Q3e),M(Jx,Q3e,null),e(Hc,Pjr),e(Hc,W3e),e(W3e,Bjr),b(f,EXe,u),b(f,_r,u),M(Yx,_r,null),e(_r,Njr),e(_r,Uc),e(Uc,Ijr),e(Uc,DZ),e(DZ,qjr),e(Uc,jjr),e(Uc,GZ),e(GZ,Djr),e(Uc,Gjr),e(_r,Ojr),e(_r,Kx),e(Kx,Vjr),e(Kx,H3e),e(H3e,Xjr),e(Kx,zjr),e(_r,Qjr),e(_r,Qt),M(Zx,Qt,null),e(Qt,Wjr),e(Qt,U3e),e(U3e,Hjr),e(Qt,Ujr),e(Qt,Jc),e(Jc,Jjr),e(Jc,J3e),e(J3e,Yjr),e(Jc,Kjr),e(Jc,OZ),e(OZ,Zjr),e(Jc,eDr),e(Qt,oDr),M(m0,Qt,null),e(_r,rDr),e(_r,Xr),M(e$,Xr,null),e(Xr,tDr),e(Xr,Y3e),e(Y3e,aDr),e(Xr,nDr),e(Xr,Mn),e(Mn,sDr),e(Mn,K3e),e(K3e,lDr),e(Mn,iDr),e(Mn,Z3e),e(Z3e,dDr),e(Mn,cDr),e(Mn,e5e),e(e5e,fDr),e(Mn,mDr),e(Xr,gDr),e(Xr,xe),e(xe,g0),e(g0,o5e),e(o5e,hDr),e(g0,pDr),e(g0,VZ),e(VZ,_Dr),e(g0,uDr),e(xe,bDr),e(xe,h0),e(h0,r5e),e(r5e,vDr),e(h0,FDr),e(h0,XZ),e(XZ,TDr),e(h0,MDr),e(xe,EDr),e(xe,p0),e(p0,t5e),e(t5e,CDr),e(p0,wDr),e(p0,zZ),e(zZ,ADr),e(p0,LDr),e(xe,yDr),e(xe,_0),e(_0,a5e),e(a5e,xDr),e(_0,$Dr),e(_0,QZ),e(QZ,kDr),e(_0,SDr),e(xe,RDr),e(xe,u0),e(u0,n5e),e(n5e,PDr),e(u0,BDr),e(u0,WZ),e(WZ,NDr),e(u0,IDr),e(xe,qDr),e(xe,b0),e(b0,s5e),e(s5e,jDr),e(b0,DDr),e(b0,HZ),e(HZ,GDr),e(b0,ODr),e(xe,VDr),e(xe,v0),e(v0,l5e),e(l5e,XDr),e(v0,zDr),e(v0,UZ),e(UZ,QDr),e(v0,WDr),e(xe,HDr),e(xe,F0),e(F0,i5e),e(i5e,UDr),e(F0,JDr),e(F0,JZ),e(JZ,YDr),e(F0,KDr),e(xe,ZDr),e(xe,T0),e(T0,d5e),e(d5e,eGr),e(T0,oGr),e(T0,YZ),e(YZ,rGr),e(T0,tGr),e(xe,aGr),e(xe,M0),e(M0,c5e),e(c5e,nGr),e(M0,sGr),e(M0,KZ),e(KZ,lGr),e(M0,iGr),e(Xr,dGr),M(E0,Xr,null),b(f,CXe,u),b(f,Yc,u),e(Yc,C0),e(C0,f5e),M(o$,f5e,null),e(Yc,cGr),e(Yc,m5e),e(m5e,fGr),b(f,wXe,u),b(f,ur,u),M(r$,ur,null),e(ur,mGr),e(ur,Kc),e(Kc,gGr),e(Kc,ZZ),e(ZZ,hGr),e(Kc,pGr),e(Kc,eee),e(eee,_Gr),e(Kc,uGr),e(ur,bGr),e(ur,t$),e(t$,vGr),e(t$,g5e),e(g5e,FGr),e(t$,TGr),e(ur,MGr),e(ur,Wt),M(a$,Wt,null),e(Wt,EGr),e(Wt,h5e),e(h5e,CGr),e(Wt,wGr),e(Wt,Zc),e(Zc,AGr),e(Zc,p5e),e(p5e,LGr),e(Zc,yGr),e(Zc,oee),e(oee,xGr),e(Zc,$Gr),e(Wt,kGr),M(w0,Wt,null),e(ur,SGr),e(ur,zr),M(n$,zr,null),e(zr,RGr),e(zr,_5e),e(_5e,PGr),e(zr,BGr),e(zr,En),e(En,NGr),e(En,u5e),e(u5e,IGr),e(En,qGr),e(En,b5e),e(b5e,jGr),e(En,DGr),e(En,v5e),e(v5e,GGr),e(En,OGr),e(zr,VGr),e(zr,Ee),e(Ee,A0),e(A0,F5e),e(F5e,XGr),e(A0,zGr),e(A0,ree),e(ree,QGr),e(A0,WGr),e(Ee,HGr),e(Ee,L0),e(L0,T5e),e(T5e,UGr),e(L0,JGr),e(L0,tee),e(tee,YGr),e(L0,KGr),e(Ee,ZGr),e(Ee,y0),e(y0,M5e),e(M5e,eOr),e(y0,oOr),e(y0,aee),e(aee,rOr),e(y0,tOr),e(Ee,aOr),e(Ee,x0),e(x0,E5e),e(E5e,nOr),e(x0,sOr),e(x0,nee),e(nee,lOr),e(x0,iOr),e(Ee,dOr),e(Ee,$0),e($0,C5e),e(C5e,cOr),e($0,fOr),e($0,see),e(see,mOr),e($0,gOr),e(Ee,hOr),e(Ee,k0),e(k0,w5e),e(w5e,pOr),e(k0,_Or),e(k0,lee),e(lee,uOr),e(k0,bOr),e(Ee,vOr),e(Ee,S0),e(S0,A5e),e(A5e,FOr),e(S0,TOr),e(S0,iee),e(iee,MOr),e(S0,EOr),e(Ee,COr),e(Ee,R0),e(R0,L5e),e(L5e,wOr),e(R0,AOr),e(R0,dee),e(dee,LOr),e(R0,yOr),e(Ee,xOr),e(Ee,P0),e(P0,y5e),e(y5e,$Or),e(P0,kOr),e(P0,cee),e(cee,SOr),e(P0,ROr),e(Ee,POr),e(Ee,B0),e(B0,x5e),e(x5e,BOr),e(B0,NOr),e(B0,fee),e(fee,IOr),e(B0,qOr),e(Ee,jOr),e(Ee,N0),e(N0,$5e),e($5e,DOr),e(N0,GOr),e(N0,mee),e(mee,OOr),e(N0,VOr),e(Ee,XOr),e(Ee,I0),e(I0,k5e),e(k5e,zOr),e(I0,QOr),e(I0,gee),e(gee,WOr),e(I0,HOr),e(Ee,UOr),e(Ee,q0),e(q0,S5e),e(S5e,JOr),e(q0,YOr),e(q0,hee),e(hee,KOr),e(q0,ZOr),e(zr,eVr),M(j0,zr,null),b(f,AXe,u),b(f,ef,u),e(ef,D0),e(D0,R5e),M(s$,R5e,null),e(ef,oVr),e(ef,P5e),e(P5e,rVr),b(f,LXe,u),b(f,br,u),M(l$,br,null),e(br,tVr),e(br,of),e(of,aVr),e(of,pee),e(pee,nVr),e(of,sVr),e(of,_ee),e(_ee,lVr),e(of,iVr),e(br,dVr),e(br,i$),e(i$,cVr),e(i$,B5e),e(B5e,fVr),e(i$,mVr),e(br,gVr),e(br,Ht),M(d$,Ht,null),e(Ht,hVr),e(Ht,N5e),e(N5e,pVr),e(Ht,_Vr),e(Ht,rf),e(rf,uVr),e(rf,I5e),e(I5e,bVr),e(rf,vVr),e(rf,uee),e(uee,FVr),e(rf,TVr),e(Ht,MVr),M(G0,Ht,null),e(br,EVr),e(br,Qr),M(c$,Qr,null),e(Qr,CVr),e(Qr,q5e),e(q5e,wVr),e(Qr,AVr),e(Qr,Cn),e(Cn,LVr),e(Cn,j5e),e(j5e,yVr),e(Cn,xVr),e(Cn,D5e),e(D5e,$Vr),e(Cn,kVr),e(Cn,G5e),e(G5e,SVr),e(Cn,RVr),e(Qr,PVr),e(Qr,$e),e($e,O0),e(O0,O5e),e(O5e,BVr),e(O0,NVr),e(O0,bee),e(bee,IVr),e(O0,qVr),e($e,jVr),e($e,V0),e(V0,V5e),e(V5e,DVr),e(V0,GVr),e(V0,vee),e(vee,OVr),e(V0,VVr),e($e,XVr),e($e,X0),e(X0,X5e),e(X5e,zVr),e(X0,QVr),e(X0,Fee),e(Fee,WVr),e(X0,HVr),e($e,UVr),e($e,z0),e(z0,z5e),e(z5e,JVr),e(z0,YVr),e(z0,Tee),e(Tee,KVr),e(z0,ZVr),e($e,eXr),e($e,Q0),e(Q0,Q5e),e(Q5e,oXr),e(Q0,rXr),e(Q0,Mee),e(Mee,tXr),e(Q0,aXr),e($e,nXr),e($e,W0),e(W0,W5e),e(W5e,sXr),e(W0,lXr),e(W0,Eee),e(Eee,iXr),e(W0,dXr),e($e,cXr),e($e,H0),e(H0,H5e),e(H5e,fXr),e(H0,mXr),e(H0,Cee),e(Cee,gXr),e(H0,hXr),e($e,pXr),e($e,U0),e(U0,U5e),e(U5e,_Xr),e(U0,uXr),e(U0,wee),e(wee,bXr),e(U0,vXr),e($e,FXr),e($e,J0),e(J0,J5e),e(J5e,TXr),e(J0,MXr),e(J0,Aee),e(Aee,EXr),e(J0,CXr),e($e,wXr),e($e,Y0),e(Y0,Y5e),e(Y5e,AXr),e(Y0,LXr),e(Y0,Lee),e(Lee,yXr),e(Y0,xXr),e(Qr,$Xr),M(K0,Qr,null),b(f,yXe,u),b(f,tf,u),e(tf,Z0),e(Z0,K5e),M(f$,K5e,null),e(tf,kXr),e(tf,Z5e),e(Z5e,SXr),b(f,xXe,u),b(f,vr,u),M(m$,vr,null),e(vr,RXr),e(vr,af),e(af,PXr),e(af,yee),e(yee,BXr),e(af,NXr),e(af,xee),e(xee,IXr),e(af,qXr),e(vr,jXr),e(vr,g$),e(g$,DXr),e(g$,e0e),e(e0e,GXr),e(g$,OXr),e(vr,VXr),e(vr,Ut),M(h$,Ut,null),e(Ut,XXr),e(Ut,o0e),e(o0e,zXr),e(Ut,QXr),e(Ut,nf),e(nf,WXr),e(nf,r0e),e(r0e,HXr),e(nf,UXr),e(nf,$ee),e($ee,JXr),e(nf,YXr),e(Ut,KXr),M(ew,Ut,null),e(vr,ZXr),e(vr,Wr),M(p$,Wr,null),e(Wr,ezr),e(Wr,t0e),e(t0e,ozr),e(Wr,rzr),e(Wr,wn),e(wn,tzr),e(wn,a0e),e(a0e,azr),e(wn,nzr),e(wn,n0e),e(n0e,szr),e(wn,lzr),e(wn,s0e),e(s0e,izr),e(wn,dzr),e(Wr,czr),e(Wr,ke),e(ke,ow),e(ow,l0e),e(l0e,fzr),e(ow,mzr),e(ow,kee),e(kee,gzr),e(ow,hzr),e(ke,pzr),e(ke,rw),e(rw,i0e),e(i0e,_zr),e(rw,uzr),e(rw,See),e(See,bzr),e(rw,vzr),e(ke,Fzr),e(ke,tw),e(tw,d0e),e(d0e,Tzr),e(tw,Mzr),e(tw,Ree),e(Ree,Ezr),e(tw,Czr),e(ke,wzr),e(ke,aw),e(aw,c0e),e(c0e,Azr),e(aw,Lzr),e(aw,Pee),e(Pee,yzr),e(aw,xzr),e(ke,$zr),e(ke,nw),e(nw,f0e),e(f0e,kzr),e(nw,Szr),e(nw,Bee),e(Bee,Rzr),e(nw,Pzr),e(ke,Bzr),e(ke,sw),e(sw,m0e),e(m0e,Nzr),e(sw,Izr),e(sw,Nee),e(Nee,qzr),e(sw,jzr),e(ke,Dzr),e(ke,lw),e(lw,g0e),e(g0e,Gzr),e(lw,Ozr),e(lw,Iee),e(Iee,Vzr),e(lw,Xzr),e(ke,zzr),e(ke,iw),e(iw,h0e),e(h0e,Qzr),e(iw,Wzr),e(iw,qee),e(qee,Hzr),e(iw,Uzr),e(ke,Jzr),e(ke,dw),e(dw,p0e),e(p0e,Yzr),e(dw,Kzr),e(dw,jee),e(jee,Zzr),e(dw,eQr),e(ke,oQr),e(ke,cw),e(cw,_0e),e(_0e,rQr),e(cw,tQr),e(cw,Dee),e(Dee,aQr),e(cw,nQr),e(Wr,sQr),M(fw,Wr,null),b(f,$Xe,u),b(f,sf,u),e(sf,mw),e(mw,u0e),M(_$,u0e,null),e(sf,lQr),e(sf,b0e),e(b0e,iQr),b(f,kXe,u),b(f,Fr,u),M(u$,Fr,null),e(Fr,dQr),e(Fr,lf),e(lf,cQr),e(lf,Gee),e(Gee,fQr),e(lf,mQr),e(lf,Oee),e(Oee,gQr),e(lf,hQr),e(Fr,pQr),e(Fr,b$),e(b$,_Qr),e(b$,v0e),e(v0e,uQr),e(b$,bQr),e(Fr,vQr),e(Fr,Jt),M(v$,Jt,null),e(Jt,FQr),e(Jt,F0e),e(F0e,TQr),e(Jt,MQr),e(Jt,df),e(df,EQr),e(df,T0e),e(T0e,CQr),e(df,wQr),e(df,Vee),e(Vee,AQr),e(df,LQr),e(Jt,yQr),M(gw,Jt,null),e(Fr,xQr),e(Fr,Hr),M(F$,Hr,null),e(Hr,$Qr),e(Hr,M0e),e(M0e,kQr),e(Hr,SQr),e(Hr,An),e(An,RQr),e(An,E0e),e(E0e,PQr),e(An,BQr),e(An,C0e),e(C0e,NQr),e(An,IQr),e(An,w0e),e(w0e,qQr),e(An,jQr),e(Hr,DQr),e(Hr,Se),e(Se,hw),e(hw,A0e),e(A0e,GQr),e(hw,OQr),e(hw,Xee),e(Xee,VQr),e(hw,XQr),e(Se,zQr),e(Se,pw),e(pw,L0e),e(L0e,QQr),e(pw,WQr),e(pw,zee),e(zee,HQr),e(pw,UQr),e(Se,JQr),e(Se,_w),e(_w,y0e),e(y0e,YQr),e(_w,KQr),e(_w,Qee),e(Qee,ZQr),e(_w,eWr),e(Se,oWr),e(Se,uw),e(uw,x0e),e(x0e,rWr),e(uw,tWr),e(uw,Wee),e(Wee,aWr),e(uw,nWr),e(Se,sWr),e(Se,bw),e(bw,$0e),e($0e,lWr),e(bw,iWr),e(bw,Hee),e(Hee,dWr),e(bw,cWr),e(Se,fWr),e(Se,vw),e(vw,k0e),e(k0e,mWr),e(vw,gWr),e(vw,Uee),e(Uee,hWr),e(vw,pWr),e(Se,_Wr),e(Se,Fw),e(Fw,S0e),e(S0e,uWr),e(Fw,bWr),e(Fw,Jee),e(Jee,vWr),e(Fw,FWr),e(Se,TWr),e(Se,Tw),e(Tw,R0e),e(R0e,MWr),e(Tw,EWr),e(Tw,Yee),e(Yee,CWr),e(Tw,wWr),e(Se,AWr),e(Se,Mw),e(Mw,P0e),e(P0e,LWr),e(Mw,yWr),e(Mw,Kee),e(Kee,xWr),e(Mw,$Wr),e(Se,kWr),e(Se,Ew),e(Ew,B0e),e(B0e,SWr),e(Ew,RWr),e(Ew,Zee),e(Zee,PWr),e(Ew,BWr),e(Hr,NWr),M(Cw,Hr,null),b(f,SXe,u),b(f,cf,u),e(cf,ww),e(ww,N0e),M(T$,N0e,null),e(cf,IWr),e(cf,I0e),e(I0e,qWr),b(f,RXe,u),b(f,Tr,u),M(M$,Tr,null),e(Tr,jWr),e(Tr,ff),e(ff,DWr),e(ff,eoe),e(eoe,GWr),e(ff,OWr),e(ff,ooe),e(ooe,VWr),e(ff,XWr),e(Tr,zWr),e(Tr,E$),e(E$,QWr),e(E$,q0e),e(q0e,WWr),e(E$,HWr),e(Tr,UWr),e(Tr,Yt),M(C$,Yt,null),e(Yt,JWr),e(Yt,j0e),e(j0e,YWr),e(Yt,KWr),e(Yt,mf),e(mf,ZWr),e(mf,D0e),e(D0e,eHr),e(mf,oHr),e(mf,roe),e(roe,rHr),e(mf,tHr),e(Yt,aHr),M(Aw,Yt,null),e(Tr,nHr),e(Tr,Ur),M(w$,Ur,null),e(Ur,sHr),e(Ur,G0e),e(G0e,lHr),e(Ur,iHr),e(Ur,Ln),e(Ln,dHr),e(Ln,O0e),e(O0e,cHr),e(Ln,fHr),e(Ln,V0e),e(V0e,mHr),e(Ln,gHr),e(Ln,X0e),e(X0e,hHr),e(Ln,pHr),e(Ur,_Hr),e(Ur,Re),e(Re,Lw),e(Lw,z0e),e(z0e,uHr),e(Lw,bHr),e(Lw,toe),e(toe,vHr),e(Lw,FHr),e(Re,THr),e(Re,yw),e(yw,Q0e),e(Q0e,MHr),e(yw,EHr),e(yw,aoe),e(aoe,CHr),e(yw,wHr),e(Re,AHr),e(Re,xw),e(xw,W0e),e(W0e,LHr),e(xw,yHr),e(xw,noe),e(noe,xHr),e(xw,$Hr),e(Re,kHr),e(Re,$w),e($w,H0e),e(H0e,SHr),e($w,RHr),e($w,soe),e(soe,PHr),e($w,BHr),e(Re,NHr),e(Re,kw),e(kw,U0e),e(U0e,IHr),e(kw,qHr),e(kw,loe),e(loe,jHr),e(kw,DHr),e(Re,GHr),e(Re,Sw),e(Sw,J0e),e(J0e,OHr),e(Sw,VHr),e(Sw,ioe),e(ioe,XHr),e(Sw,zHr),e(Re,QHr),e(Re,Rw),e(Rw,Y0e),e(Y0e,WHr),e(Rw,HHr),e(Rw,doe),e(doe,UHr),e(Rw,JHr),e(Re,YHr),e(Re,Pw),e(Pw,K0e),e(K0e,KHr),e(Pw,ZHr),e(Pw,coe),e(coe,eUr),e(Pw,oUr),e(Re,rUr),e(Re,Bw),e(Bw,Z0e),e(Z0e,tUr),e(Bw,aUr),e(Bw,foe),e(foe,nUr),e(Bw,sUr),e(Re,lUr),e(Re,Nw),e(Nw,ewe),e(ewe,iUr),e(Nw,dUr),e(Nw,moe),e(moe,cUr),e(Nw,fUr),e(Ur,mUr),M(Iw,Ur,null),b(f,PXe,u),b(f,gf,u),e(gf,qw),e(qw,owe),M(A$,owe,null),e(gf,gUr),e(gf,rwe),e(rwe,hUr),b(f,BXe,u),b(f,Mr,u),M(L$,Mr,null),e(Mr,pUr),e(Mr,hf),e(hf,_Ur),e(hf,goe),e(goe,uUr),e(hf,bUr),e(hf,hoe),e(hoe,vUr),e(hf,FUr),e(Mr,TUr),e(Mr,y$),e(y$,MUr),e(y$,twe),e(twe,EUr),e(y$,CUr),e(Mr,wUr),e(Mr,Kt),M(x$,Kt,null),e(Kt,AUr),e(Kt,awe),e(awe,LUr),e(Kt,yUr),e(Kt,pf),e(pf,xUr),e(pf,nwe),e(nwe,$Ur),e(pf,kUr),e(pf,poe),e(poe,SUr),e(pf,RUr),e(Kt,PUr),M(jw,Kt,null),e(Mr,BUr),e(Mr,Jr),M($$,Jr,null),e(Jr,NUr),e(Jr,swe),e(swe,IUr),e(Jr,qUr),e(Jr,yn),e(yn,jUr),e(yn,lwe),e(lwe,DUr),e(yn,GUr),e(yn,iwe),e(iwe,OUr),e(yn,VUr),e(yn,dwe),e(dwe,XUr),e(yn,zUr),e(Jr,QUr),e(Jr,Ve),e(Ve,Dw),e(Dw,cwe),e(cwe,WUr),e(Dw,HUr),e(Dw,_oe),e(_oe,UUr),e(Dw,JUr),e(Ve,YUr),e(Ve,Gw),e(Gw,fwe),e(fwe,KUr),e(Gw,ZUr),e(Gw,uoe),e(uoe,eJr),e(Gw,oJr),e(Ve,rJr),e(Ve,Ow),e(Ow,mwe),e(mwe,tJr),e(Ow,aJr),e(Ow,boe),e(boe,nJr),e(Ow,sJr),e(Ve,lJr),e(Ve,Vw),e(Vw,gwe),e(gwe,iJr),e(Vw,dJr),e(Vw,voe),e(voe,cJr),e(Vw,fJr),e(Ve,mJr),e(Ve,Xw),e(Xw,hwe),e(hwe,gJr),e(Xw,hJr),e(Xw,Foe),e(Foe,pJr),e(Xw,_Jr),e(Ve,uJr),e(Ve,zw),e(zw,pwe),e(pwe,bJr),e(zw,vJr),e(zw,Toe),e(Toe,FJr),e(zw,TJr),e(Ve,MJr),e(Ve,Qw),e(Qw,_we),e(_we,EJr),e(Qw,CJr),e(Qw,Moe),e(Moe,wJr),e(Qw,AJr),e(Ve,LJr),e(Ve,Ww),e(Ww,uwe),e(uwe,yJr),e(Ww,xJr),e(Ww,Eoe),e(Eoe,$Jr),e(Ww,kJr),e(Jr,SJr),M(Hw,Jr,null),b(f,NXe,u),b(f,_f,u),e(_f,Uw),e(Uw,bwe),M(k$,bwe,null),e(_f,RJr),e(_f,vwe),e(vwe,PJr),b(f,IXe,u),b(f,Er,u),M(S$,Er,null),e(Er,BJr),e(Er,uf),e(uf,NJr),e(uf,Coe),e(Coe,IJr),e(uf,qJr),e(uf,woe),e(woe,jJr),e(uf,DJr),e(Er,GJr),e(Er,R$),e(R$,OJr),e(R$,Fwe),e(Fwe,VJr),e(R$,XJr),e(Er,zJr),e(Er,Zt),M(P$,Zt,null),e(Zt,QJr),e(Zt,Twe),e(Twe,WJr),e(Zt,HJr),e(Zt,bf),e(bf,UJr),e(bf,Mwe),e(Mwe,JJr),e(bf,YJr),e(bf,Aoe),e(Aoe,KJr),e(bf,ZJr),e(Zt,eYr),M(Jw,Zt,null),e(Er,oYr),e(Er,Yr),M(B$,Yr,null),e(Yr,rYr),e(Yr,Ewe),e(Ewe,tYr),e(Yr,aYr),e(Yr,xn),e(xn,nYr),e(xn,Cwe),e(Cwe,sYr),e(xn,lYr),e(xn,wwe),e(wwe,iYr),e(xn,dYr),e(xn,Awe),e(Awe,cYr),e(xn,fYr),e(Yr,mYr),e(Yr,Xe),e(Xe,Yw),e(Yw,Lwe),e(Lwe,gYr),e(Yw,hYr),e(Yw,Loe),e(Loe,pYr),e(Yw,_Yr),e(Xe,uYr),e(Xe,Kw),e(Kw,ywe),e(ywe,bYr),e(Kw,vYr),e(Kw,yoe),e(yoe,FYr),e(Kw,TYr),e(Xe,MYr),e(Xe,Zw),e(Zw,xwe),e(xwe,EYr),e(Zw,CYr),e(Zw,xoe),e(xoe,wYr),e(Zw,AYr),e(Xe,LYr),e(Xe,eA),e(eA,$we),e($we,yYr),e(eA,xYr),e(eA,$oe),e($oe,$Yr),e(eA,kYr),e(Xe,SYr),e(Xe,oA),e(oA,kwe),e(kwe,RYr),e(oA,PYr),e(oA,koe),e(koe,BYr),e(oA,NYr),e(Xe,IYr),e(Xe,rA),e(rA,Swe),e(Swe,qYr),e(rA,jYr),e(rA,Soe),e(Soe,DYr),e(rA,GYr),e(Xe,OYr),e(Xe,tA),e(tA,Rwe),e(Rwe,VYr),e(tA,XYr),e(tA,Roe),e(Roe,zYr),e(tA,QYr),e(Xe,WYr),e(Xe,aA),e(aA,Pwe),e(Pwe,HYr),e(aA,UYr),e(aA,Poe),e(Poe,JYr),e(aA,YYr),e(Yr,KYr),M(nA,Yr,null),b(f,qXe,u),b(f,vf,u),e(vf,sA),e(sA,Bwe),M(N$,Bwe,null),e(vf,ZYr),e(vf,Nwe),e(Nwe,eKr),b(f,jXe,u),b(f,Cr,u),M(I$,Cr,null),e(Cr,oKr),e(Cr,Ff),e(Ff,rKr),e(Ff,Boe),e(Boe,tKr),e(Ff,aKr),e(Ff,Noe),e(Noe,nKr),e(Ff,sKr),e(Cr,lKr),e(Cr,q$),e(q$,iKr),e(q$,Iwe),e(Iwe,dKr),e(q$,cKr),e(Cr,fKr),e(Cr,ea),M(j$,ea,null),e(ea,mKr),e(ea,qwe),e(qwe,gKr),e(ea,hKr),e(ea,Tf),e(Tf,pKr),e(Tf,jwe),e(jwe,_Kr),e(Tf,uKr),e(Tf,Ioe),e(Ioe,bKr),e(Tf,vKr),e(ea,FKr),M(lA,ea,null),e(Cr,TKr),e(Cr,Kr),M(D$,Kr,null),e(Kr,MKr),e(Kr,Dwe),e(Dwe,EKr),e(Kr,CKr),e(Kr,$n),e($n,wKr),e($n,Gwe),e(Gwe,AKr),e($n,LKr),e($n,Owe),e(Owe,yKr),e($n,xKr),e($n,Vwe),e(Vwe,$Kr),e($n,kKr),e(Kr,SKr),e(Kr,Xwe),e(Xwe,iA),e(iA,zwe),e(zwe,RKr),e(iA,PKr),e(iA,qoe),e(qoe,BKr),e(iA,NKr),e(Kr,IKr),M(dA,Kr,null),b(f,DXe,u),b(f,Mf,u),e(Mf,cA),e(cA,Qwe),M(G$,Qwe,null),e(Mf,qKr),e(Mf,Wwe),e(Wwe,jKr),b(f,GXe,u),b(f,wr,u),M(O$,wr,null),e(wr,DKr),e(wr,Ef),e(Ef,GKr),e(Ef,joe),e(joe,OKr),e(Ef,VKr),e(Ef,Doe),e(Doe,XKr),e(Ef,zKr),e(wr,QKr),e(wr,V$),e(V$,WKr),e(V$,Hwe),e(Hwe,HKr),e(V$,UKr),e(wr,JKr),e(wr,oa),M(X$,oa,null),e(oa,YKr),e(oa,Uwe),e(Uwe,KKr),e(oa,ZKr),e(oa,Cf),e(Cf,eZr),e(Cf,Jwe),e(Jwe,oZr),e(Cf,rZr),e(Cf,Goe),e(Goe,tZr),e(Cf,aZr),e(oa,nZr),M(fA,oa,null),e(wr,sZr),e(wr,Zr),M(z$,Zr,null),e(Zr,lZr),e(Zr,Ywe),e(Ywe,iZr),e(Zr,dZr),e(Zr,kn),e(kn,cZr),e(kn,Kwe),e(Kwe,fZr),e(kn,mZr),e(kn,Zwe),e(Zwe,gZr),e(kn,hZr),e(kn,eAe),e(eAe,pZr),e(kn,_Zr),e(Zr,uZr),e(Zr,Q$),e(Q$,mA),e(mA,oAe),e(oAe,bZr),e(mA,vZr),e(mA,Ooe),e(Ooe,FZr),e(mA,TZr),e(Q$,MZr),e(Q$,gA),e(gA,rAe),e(rAe,EZr),e(gA,CZr),e(gA,Voe),e(Voe,wZr),e(gA,AZr),e(Zr,LZr),M(hA,Zr,null),b(f,OXe,u),b(f,wf,u),e(wf,pA),e(pA,tAe),M(W$,tAe,null),e(wf,yZr),e(wf,aAe),e(aAe,xZr),b(f,VXe,u),b(f,Ar,u),M(H$,Ar,null),e(Ar,$Zr),e(Ar,Af),e(Af,kZr),e(Af,Xoe),e(Xoe,SZr),e(Af,RZr),e(Af,zoe),e(zoe,PZr),e(Af,BZr),e(Ar,NZr),e(Ar,U$),e(U$,IZr),e(U$,nAe),e(nAe,qZr),e(U$,jZr),e(Ar,DZr),e(Ar,ra),M(J$,ra,null),e(ra,GZr),e(ra,sAe),e(sAe,OZr),e(ra,VZr),e(ra,Lf),e(Lf,XZr),e(Lf,lAe),e(lAe,zZr),e(Lf,QZr),e(Lf,Qoe),e(Qoe,WZr),e(Lf,HZr),e(ra,UZr),M(_A,ra,null),e(Ar,JZr),e(Ar,et),M(Y$,et,null),e(et,YZr),e(et,iAe),e(iAe,KZr),e(et,ZZr),e(et,Sn),e(Sn,eet),e(Sn,dAe),e(dAe,oet),e(Sn,ret),e(Sn,cAe),e(cAe,tet),e(Sn,aet),e(Sn,fAe),e(fAe,net),e(Sn,set),e(et,iet),e(et,mAe),e(mAe,uA),e(uA,gAe),e(gAe,det),e(uA,cet),e(uA,Woe),e(Woe,fet),e(uA,met),e(et,get),M(bA,et,null),XXe=!0},p(f,[u]){const K$={};u&2&&(K$.$$scope={dirty:u,ctx:f}),Nf.$set(K$);const hAe={};u&2&&(hAe.$$scope={dirty:u,ctx:f}),Qg.$set(hAe);const pAe={};u&2&&(pAe.$$scope={dirty:u,ctx:f}),yh.$set(pAe);const _Ae={};u&2&&(_Ae.$$scope={dirty:u,ctx:f}),cp.$set(_Ae);const Z$={};u&2&&(Z$.$$scope={dirty:u,ctx:f}),fp.$set(Z$);const uAe={};u&2&&(uAe.$$scope={dirty:u,ctx:f}),Sp.$set(uAe);const Rn={};u&2&&(Rn.$$scope={dirty:u,ctx:f}),Rp.$set(Rn);const bAe={};u&2&&(bAe.$$scope={dirty:u,ctx:f}),Np.$set(bAe);const vAe={};u&2&&(vAe.$$scope={dirty:u,ctx:f}),qu.$set(vAe);const FAe={};u&2&&(FAe.$$scope={dirty:u,ctx:f}),Du.$set(FAe);const ek={};u&2&&(ek.$$scope={dirty:u,ctx:f}),S2.$set(ek);const TAe={};u&2&&(TAe.$$scope={dirty:u,ctx:f}),P2.$set(TAe);const ok={};u&2&&(ok.$$scope={dirty:u,ctx:f}),T1.$set(ok);const MAe={};u&2&&(MAe.$$scope={dirty:u,ctx:f}),E1.$set(MAe);const rk={};u&2&&(rk.$$scope={dirty:u,ctx:f}),i7.$set(rk);const EAe={};u&2&&(EAe.$$scope={dirty:u,ctx:f}),c7.$set(EAe);const CAe={};u&2&&(CAe.$$scope={dirty:u,ctx:f}),x7.$set(CAe);const wAe={};u&2&&(wAe.$$scope={dirty:u,ctx:f}),k7.$set(wAe);const yf={};u&2&&(yf.$$scope={dirty:u,ctx:f}),y4.$set(yf);const AAe={};u&2&&(AAe.$$scope={dirty:u,ctx:f}),$4.$set(AAe);const LAe={};u&2&&(LAe.$$scope={dirty:u,ctx:f}),ib.$set(LAe);const yAe={};u&2&&(yAe.$$scope={dirty:u,ctx:f}),cb.$set(yAe);const tk={};u&2&&(tk.$$scope={dirty:u,ctx:f}),bb.$set(tk);const xAe={};u&2&&(xAe.$$scope={dirty:u,ctx:f}),Fb.$set(xAe);const $Ae={};u&2&&($Ae.$$scope={dirty:u,ctx:f}),av.$set($Ae);const kAe={};u&2&&(kAe.$$scope={dirty:u,ctx:f}),sv.$set(kAe);const tt={};u&2&&(tt.$$scope={dirty:u,ctx:f}),Uv.$set(tt);const ak={};u&2&&(ak.$$scope={dirty:u,ctx:f}),Yv.$set(ak);const SAe={};u&2&&(SAe.$$scope={dirty:u,ctx:f}),eF.$set(SAe);const nk={};u&2&&(nk.$$scope={dirty:u,ctx:f}),rF.$set(nk);const RAe={};u&2&&(RAe.$$scope={dirty:u,ctx:f}),_F.$set(RAe);const at={};u&2&&(at.$$scope={dirty:u,ctx:f}),bF.$set(at);const PAe={};u&2&&(PAe.$$scope={dirty:u,ctx:f}),TF.$set(PAe);const xf={};u&2&&(xf.$$scope={dirty:u,ctx:f}),EF.$set(xf);const BAe={};u&2&&(BAe.$$scope={dirty:u,ctx:f}),AF.$set(BAe);const NAe={};u&2&&(NAe.$$scope={dirty:u,ctx:f}),yF.$set(NAe);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),jF.$set(L);const vA={};u&2&&(vA.$$scope={dirty:u,ctx:f}),GF.$set(vA);const IAe={};u&2&&(IAe.$$scope={dirty:u,ctx:f}),HF.$set(IAe);const qAe={};u&2&&(qAe.$$scope={dirty:u,ctx:f}),JF.$set(qAe);const FA={};u&2&&(FA.$$scope={dirty:u,ctx:f}),iT.$set(FA);const jAe={};u&2&&(jAe.$$scope={dirty:u,ctx:f}),cT.$set(jAe);const DAe={};u&2&&(DAe.$$scope={dirty:u,ctx:f}),hT.$set(DAe);const TA={};u&2&&(TA.$$scope={dirty:u,ctx:f}),_T.$set(TA);const GAe={};u&2&&(GAe.$$scope={dirty:u,ctx:f}),ET.$set(GAe);const OAe={};u&2&&(OAe.$$scope={dirty:u,ctx:f}),wT.$set(OAe);const MA={};u&2&&(MA.$$scope={dirty:u,ctx:f}),$T.$set(MA);const VAe={};u&2&&(VAe.$$scope={dirty:u,ctx:f}),ST.$set(VAe);const XAe={};u&2&&(XAe.$$scope={dirty:u,ctx:f}),NT.$set(XAe);const EA={};u&2&&(EA.$$scope={dirty:u,ctx:f}),qT.$set(EA);const zAe={};u&2&&(zAe.$$scope={dirty:u,ctx:f}),GT.$set(zAe);const QAe={};u&2&&(QAe.$$scope={dirty:u,ctx:f}),VT.$set(QAe);const CA={};u&2&&(CA.$$scope={dirty:u,ctx:f}),UT.$set(CA);const WAe={};u&2&&(WAe.$$scope={dirty:u,ctx:f}),YT.$set(WAe);const HAe={};u&2&&(HAe.$$scope={dirty:u,ctx:f}),eM.$set(HAe);const wA={};u&2&&(wA.$$scope={dirty:u,ctx:f}),rM.$set(wA);const UAe={};u&2&&(UAe.$$scope={dirty:u,ctx:f}),YM.$set(UAe);const JAe={};u&2&&(JAe.$$scope={dirty:u,ctx:f}),ZM.$set(JAe);const AA={};u&2&&(AA.$$scope={dirty:u,ctx:f}),EE.$set(AA);const YAe={};u&2&&(YAe.$$scope={dirty:u,ctx:f}),wE.$set(YAe);const KAe={};u&2&&(KAe.$$scope={dirty:u,ctx:f}),jE.$set(KAe);const LA={};u&2&&(LA.$$scope={dirty:u,ctx:f}),GE.$set(LA);const ZAe={};u&2&&(ZAe.$$scope={dirty:u,ctx:f}),HE.$set(ZAe);const e6e={};u&2&&(e6e.$$scope={dirty:u,ctx:f}),JE.$set(e6e);const yA={};u&2&&(yA.$$scope={dirty:u,ctx:f}),uC.$set(yA);const o6e={};u&2&&(o6e.$$scope={dirty:u,ctx:f}),vC.$set(o6e);const r6e={};u&2&&(r6e.$$scope={dirty:u,ctx:f}),$C.$set(r6e);const xA={};u&2&&(xA.$$scope={dirty:u,ctx:f}),SC.$set(xA);const t6e={};u&2&&(t6e.$$scope={dirty:u,ctx:f}),n3.$set(t6e);const a6e={};u&2&&(a6e.$$scope={dirty:u,ctx:f}),l3.$set(a6e);const $A={};u&2&&($A.$$scope={dirty:u,ctx:f}),w3.$set($A);const n6e={};u&2&&(n6e.$$scope={dirty:u,ctx:f}),L3.$set(n6e);const s6e={};u&2&&(s6e.$$scope={dirty:u,ctx:f}),$3.$set(s6e);const kA={};u&2&&(kA.$$scope={dirty:u,ctx:f}),S3.$set(kA);const l6e={};u&2&&(l6e.$$scope={dirty:u,ctx:f}),P3.$set(l6e);const i6e={};u&2&&(i6e.$$scope={dirty:u,ctx:f}),N3.$set(i6e);const SA={};u&2&&(SA.$$scope={dirty:u,ctx:f}),t5.$set(SA);const d6e={};u&2&&(d6e.$$scope={dirty:u,ctx:f}),n5.$set(d6e);const c6e={};u&2&&(c6e.$$scope={dirty:u,ctx:f}),A5.$set(c6e);const RA={};u&2&&(RA.$$scope={dirty:u,ctx:f}),y5.$set(RA);const f6e={};u&2&&(f6e.$$scope={dirty:u,ctx:f}),$5.$set(f6e);const m6e={};u&2&&(m6e.$$scope={dirty:u,ctx:f}),S5.$set(m6e);const PA={};u&2&&(PA.$$scope={dirty:u,ctx:f}),P5.$set(PA);const g6e={};u&2&&(g6e.$$scope={dirty:u,ctx:f}),N5.$set(g6e);const h6e={};u&2&&(h6e.$$scope={dirty:u,ctx:f}),c0.$set(h6e);const BA={};u&2&&(BA.$$scope={dirty:u,ctx:f}),m0.$set(BA);const p6e={};u&2&&(p6e.$$scope={dirty:u,ctx:f}),E0.$set(p6e);const _6e={};u&2&&(_6e.$$scope={dirty:u,ctx:f}),w0.$set(_6e);const NA={};u&2&&(NA.$$scope={dirty:u,ctx:f}),j0.$set(NA);const u6e={};u&2&&(u6e.$$scope={dirty:u,ctx:f}),G0.$set(u6e);const b6e={};u&2&&(b6e.$$scope={dirty:u,ctx:f}),K0.$set(b6e);const IA={};u&2&&(IA.$$scope={dirty:u,ctx:f}),ew.$set(IA);const v6e={};u&2&&(v6e.$$scope={dirty:u,ctx:f}),fw.$set(v6e);const F6e={};u&2&&(F6e.$$scope={dirty:u,ctx:f}),gw.$set(F6e);const qA={};u&2&&(qA.$$scope={dirty:u,ctx:f}),Cw.$set(qA);const T6e={};u&2&&(T6e.$$scope={dirty:u,ctx:f}),Aw.$set(T6e);const M6e={};u&2&&(M6e.$$scope={dirty:u,ctx:f}),Iw.$set(M6e);const jA={};u&2&&(jA.$$scope={dirty:u,ctx:f}),jw.$set(jA);const E6e={};u&2&&(E6e.$$scope={dirty:u,ctx:f}),Hw.$set(E6e);const C6e={};u&2&&(C6e.$$scope={dirty:u,ctx:f}),Jw.$set(C6e);const DA={};u&2&&(DA.$$scope={dirty:u,ctx:f}),nA.$set(DA);const w6e={};u&2&&(w6e.$$scope={dirty:u,ctx:f}),lA.$set(w6e);const A6e={};u&2&&(A6e.$$scope={dirty:u,ctx:f}),dA.$set(A6e);const GA={};u&2&&(GA.$$scope={dirty:u,ctx:f}),fA.$set(GA);const L6e={};u&2&&(L6e.$$scope={dirty:u,ctx:f}),hA.$set(L6e);const y6e={};u&2&&(y6e.$$scope={dirty:u,ctx:f}),_A.$set(y6e);const OA={};u&2&&(OA.$$scope={dirty:u,ctx:f}),bA.$set(OA)},i(f){XXe||(E(d.$$.fragment,f),E(ka.$$.fragment,f),E(OL.$$.fragment,f),E(VL.$$.fragment,f),E(Nf.$$.fragment,f),E(XL.$$.fragment,f),E(zL.$$.fragment,f),E(HL.$$.fragment,f),E(Qg.$$.fragment,f),E(UL.$$.fragment,f),E(JL.$$.fragment,f),E(YL.$$.fragment,f),E(ey.$$.fragment,f),E(yh.$$.fragment,f),E(oy.$$.fragment,f),E(ry.$$.fragment,f),E(ty.$$.fragment,f),E(sy.$$.fragment,f),E(cp.$$.fragment,f),E(fp.$$.fragment,f),E(ly.$$.fragment,f),E(iy.$$.fragment,f),E(dy.$$.fragment,f),E(my.$$.fragment,f),E(Sp.$$.fragment,f),E(Rp.$$.fragment,f),E(gy.$$.fragment,f),E(hy.$$.fragment,f),E(py.$$.fragment,f),E(uy.$$.fragment,f),E(Np.$$.fragment,f),E(by.$$.fragment,f),E(qu.$$.fragment,f),E(vy.$$.fragment,f),E(Fy.$$.fragment,f),E(My.$$.fragment,f),E(Du.$$.fragment,f),E(Ey.$$.fragment,f),E(S2.$$.fragment,f),E(Cy.$$.fragment,f),E(wy.$$.fragment,f),E(Ly.$$.fragment,f),E(P2.$$.fragment,f),E(yy.$$.fragment,f),E(T1.$$.fragment,f),E(xy.$$.fragment,f),E($y.$$.fragment,f),E(Sy.$$.fragment,f),E(E1.$$.fragment,f),E(Ry.$$.fragment,f),E(i7.$$.fragment,f),E(Py.$$.fragment,f),E(By.$$.fragment,f),E(Iy.$$.fragment,f),E(c7.$$.fragment,f),E(qy.$$.fragment,f),E(x7.$$.fragment,f),E(jy.$$.fragment,f),E(Dy.$$.fragment,f),E(Oy.$$.fragment,f),E(k7.$$.fragment,f),E(Vy.$$.fragment,f),E(y4.$$.fragment,f),E(Xy.$$.fragment,f),E(zy.$$.fragment,f),E(Wy.$$.fragment,f),E($4.$$.fragment,f),E(Hy.$$.fragment,f),E(ib.$$.fragment,f),E(Uy.$$.fragment,f),E(Jy.$$.fragment,f),E(Ky.$$.fragment,f),E(cb.$$.fragment,f),E(Zy.$$.fragment,f),E(bb.$$.fragment,f),E(e8.$$.fragment,f),E(o8.$$.fragment,f),E(t8.$$.fragment,f),E(Fb.$$.fragment,f),E(a8.$$.fragment,f),E(av.$$.fragment,f),E(n8.$$.fragment,f),E(s8.$$.fragment,f),E(i8.$$.fragment,f),E(sv.$$.fragment,f),E(d8.$$.fragment,f),E(Uv.$$.fragment,f),E(c8.$$.fragment,f),E(f8.$$.fragment,f),E(g8.$$.fragment,f),E(Yv.$$.fragment,f),E(h8.$$.fragment,f),E(eF.$$.fragment,f),E(p8.$$.fragment,f),E(_8.$$.fragment,f),E(b8.$$.fragment,f),E(rF.$$.fragment,f),E(v8.$$.fragment,f),E(_F.$$.fragment,f),E(F8.$$.fragment,f),E(T8.$$.fragment,f),E(E8.$$.fragment,f),E(bF.$$.fragment,f),E(C8.$$.fragment,f),E(TF.$$.fragment,f),E(w8.$$.fragment,f),E(A8.$$.fragment,f),E(y8.$$.fragment,f),E(EF.$$.fragment,f),E(x8.$$.fragment,f),E(AF.$$.fragment,f),E($8.$$.fragment,f),E(k8.$$.fragment,f),E(R8.$$.fragment,f),E(yF.$$.fragment,f),E(P8.$$.fragment,f),E(jF.$$.fragment,f),E(B8.$$.fragment,f),E(N8.$$.fragment,f),E(q8.$$.fragment,f),E(GF.$$.fragment,f),E(j8.$$.fragment,f),E(HF.$$.fragment,f),E(D8.$$.fragment,f),E(G8.$$.fragment,f),E(V8.$$.fragment,f),E(JF.$$.fragment,f),E(X8.$$.fragment,f),E(iT.$$.fragment,f),E(z8.$$.fragment,f),E(Q8.$$.fragment,f),E(H8.$$.fragment,f),E(cT.$$.fragment,f),E(U8.$$.fragment,f),E(hT.$$.fragment,f),E(Y8.$$.fragment,f),E(K8.$$.fragment,f),E(e9.$$.fragment,f),E(_T.$$.fragment,f),E(o9.$$.fragment,f),E(ET.$$.fragment,f),E(r9.$$.fragment,f),E(t9.$$.fragment,f),E(n9.$$.fragment,f),E(wT.$$.fragment,f),E(s9.$$.fragment,f),E($T.$$.fragment,f),E(l9.$$.fragment,f),E(i9.$$.fragment,f),E(c9.$$.fragment,f),E(ST.$$.fragment,f),E(f9.$$.fragment,f),E(NT.$$.fragment,f),E(g9.$$.fragment,f),E(h9.$$.fragment,f),E(_9.$$.fragment,f),E(qT.$$.fragment,f),E(u9.$$.fragment,f),E(GT.$$.fragment,f),E(b9.$$.fragment,f),E(v9.$$.fragment,f),E(T9.$$.fragment,f),E(VT.$$.fragment,f),E(M9.$$.fragment,f),E(UT.$$.fragment,f),E(E9.$$.fragment,f),E(C9.$$.fragment,f),E(A9.$$.fragment,f),E(YT.$$.fragment,f),E(L9.$$.fragment,f),E(eM.$$.fragment,f),E(y9.$$.fragment,f),E(x9.$$.fragment,f),E(k9.$$.fragment,f),E(rM.$$.fragment,f),E(S9.$$.fragment,f),E(YM.$$.fragment,f),E(R9.$$.fragment,f),E(P9.$$.fragment,f),E(N9.$$.fragment,f),E(ZM.$$.fragment,f),E(I9.$$.fragment,f),E(EE.$$.fragment,f),E(q9.$$.fragment,f),E(j9.$$.fragment,f),E(G9.$$.fragment,f),E(wE.$$.fragment,f),E(O9.$$.fragment,f),E(jE.$$.fragment,f),E(V9.$$.fragment,f),E(X9.$$.fragment,f),E(Q9.$$.fragment,f),E(GE.$$.fragment,f),E(W9.$$.fragment,f),E(HE.$$.fragment,f),E(H9.$$.fragment,f),E(U9.$$.fragment,f),E(Y9.$$.fragment,f),E(JE.$$.fragment,f),E(K9.$$.fragment,f),E(uC.$$.fragment,f),E(Z9.$$.fragment,f),E(ex.$$.fragment,f),E(rx.$$.fragment,f),E(vC.$$.fragment,f),E(tx.$$.fragment,f),E($C.$$.fragment,f),E(ax.$$.fragment,f),E(nx.$$.fragment,f),E(lx.$$.fragment,f),E(SC.$$.fragment,f),E(ix.$$.fragment,f),E(n3.$$.fragment,f),E(dx.$$.fragment,f),E(cx.$$.fragment,f),E(mx.$$.fragment,f),E(l3.$$.fragment,f),E(gx.$$.fragment,f),E(w3.$$.fragment,f),E(hx.$$.fragment,f),E(px.$$.fragment,f),E(ux.$$.fragment,f),E(L3.$$.fragment,f),E(bx.$$.fragment,f),E($3.$$.fragment,f),E(Fx.$$.fragment,f),E(Tx.$$.fragment,f),E(Ex.$$.fragment,f),E(S3.$$.fragment,f),E(Cx.$$.fragment,f),E(P3.$$.fragment,f),E(wx.$$.fragment,f),E(Ax.$$.fragment,f),E(yx.$$.fragment,f),E(N3.$$.fragment,f),E(xx.$$.fragment,f),E(t5.$$.fragment,f),E($x.$$.fragment,f),E(kx.$$.fragment,f),E(Rx.$$.fragment,f),E(n5.$$.fragment,f),E(Px.$$.fragment,f),E(A5.$$.fragment,f),E(Bx.$$.fragment,f),E(Nx.$$.fragment,f),E(qx.$$.fragment,f),E(y5.$$.fragment,f),E(jx.$$.fragment,f),E($5.$$.fragment,f),E(Dx.$$.fragment,f),E(Gx.$$.fragment,f),E(Vx.$$.fragment,f),E(S5.$$.fragment,f),E(Xx.$$.fragment,f),E(P5.$$.fragment,f),E(zx.$$.fragment,f),E(Qx.$$.fragment,f),E(Hx.$$.fragment,f),E(N5.$$.fragment,f),E(Ux.$$.fragment,f),E(c0.$$.fragment,f),E(Jx.$$.fragment,f),E(Yx.$$.fragment,f),E(Zx.$$.fragment,f),E(m0.$$.fragment,f),E(e$.$$.fragment,f),E(E0.$$.fragment,f),E(o$.$$.fragment,f),E(r$.$$.fragment,f),E(a$.$$.fragment,f),E(w0.$$.fragment,f),E(n$.$$.fragment,f),E(j0.$$.fragment,f),E(s$.$$.fragment,f),E(l$.$$.fragment,f),E(d$.$$.fragment,f),E(G0.$$.fragment,f),E(c$.$$.fragment,f),E(K0.$$.fragment,f),E(f$.$$.fragment,f),E(m$.$$.fragment,f),E(h$.$$.fragment,f),E(ew.$$.fragment,f),E(p$.$$.fragment,f),E(fw.$$.fragment,f),E(_$.$$.fragment,f),E(u$.$$.fragment,f),E(v$.$$.fragment,f),E(gw.$$.fragment,f),E(F$.$$.fragment,f),E(Cw.$$.fragment,f),E(T$.$$.fragment,f),E(M$.$$.fragment,f),E(C$.$$.fragment,f),E(Aw.$$.fragment,f),E(w$.$$.fragment,f),E(Iw.$$.fragment,f),E(A$.$$.fragment,f),E(L$.$$.fragment,f),E(x$.$$.fragment,f),E(jw.$$.fragment,f),E($$.$$.fragment,f),E(Hw.$$.fragment,f),E(k$.$$.fragment,f),E(S$.$$.fragment,f),E(P$.$$.fragment,f),E(Jw.$$.fragment,f),E(B$.$$.fragment,f),E(nA.$$.fragment,f),E(N$.$$.fragment,f),E(I$.$$.fragment,f),E(j$.$$.fragment,f),E(lA.$$.fragment,f),E(D$.$$.fragment,f),E(dA.$$.fragment,f),E(G$.$$.fragment,f),E(O$.$$.fragment,f),E(X$.$$.fragment,f),E(fA.$$.fragment,f),E(z$.$$.fragment,f),E(hA.$$.fragment,f),E(W$.$$.fragment,f),E(H$.$$.fragment,f),E(J$.$$.fragment,f),E(_A.$$.fragment,f),E(Y$.$$.fragment,f),E(bA.$$.fragment,f),XXe=!0)},o(f){C(d.$$.fragment,f),C(ka.$$.fragment,f),C(OL.$$.fragment,f),C(VL.$$.fragment,f),C(Nf.$$.fragment,f),C(XL.$$.fragment,f),C(zL.$$.fragment,f),C(HL.$$.fragment,f),C(Qg.$$.fragment,f),C(UL.$$.fragment,f),C(JL.$$.fragment,f),C(YL.$$.fragment,f),C(ey.$$.fragment,f),C(yh.$$.fragment,f),C(oy.$$.fragment,f),C(ry.$$.fragment,f),C(ty.$$.fragment,f),C(sy.$$.fragment,f),C(cp.$$.fragment,f),C(fp.$$.fragment,f),C(ly.$$.fragment,f),C(iy.$$.fragment,f),C(dy.$$.fragment,f),C(my.$$.fragment,f),C(Sp.$$.fragment,f),C(Rp.$$.fragment,f),C(gy.$$.fragment,f),C(hy.$$.fragment,f),C(py.$$.fragment,f),C(uy.$$.fragment,f),C(Np.$$.fragment,f),C(by.$$.fragment,f),C(qu.$$.fragment,f),C(vy.$$.fragment,f),C(Fy.$$.fragment,f),C(My.$$.fragment,f),C(Du.$$.fragment,f),C(Ey.$$.fragment,f),C(S2.$$.fragment,f),C(Cy.$$.fragment,f),C(wy.$$.fragment,f),C(Ly.$$.fragment,f),C(P2.$$.fragment,f),C(yy.$$.fragment,f),C(T1.$$.fragment,f),C(xy.$$.fragment,f),C($y.$$.fragment,f),C(Sy.$$.fragment,f),C(E1.$$.fragment,f),C(Ry.$$.fragment,f),C(i7.$$.fragment,f),C(Py.$$.fragment,f),C(By.$$.fragment,f),C(Iy.$$.fragment,f),C(c7.$$.fragment,f),C(qy.$$.fragment,f),C(x7.$$.fragment,f),C(jy.$$.fragment,f),C(Dy.$$.fragment,f),C(Oy.$$.fragment,f),C(k7.$$.fragment,f),C(Vy.$$.fragment,f),C(y4.$$.fragment,f),C(Xy.$$.fragment,f),C(zy.$$.fragment,f),C(Wy.$$.fragment,f),C($4.$$.fragment,f),C(Hy.$$.fragment,f),C(ib.$$.fragment,f),C(Uy.$$.fragment,f),C(Jy.$$.fragment,f),C(Ky.$$.fragment,f),C(cb.$$.fragment,f),C(Zy.$$.fragment,f),C(bb.$$.fragment,f),C(e8.$$.fragment,f),C(o8.$$.fragment,f),C(t8.$$.fragment,f),C(Fb.$$.fragment,f),C(a8.$$.fragment,f),C(av.$$.fragment,f),C(n8.$$.fragment,f),C(s8.$$.fragment,f),C(i8.$$.fragment,f),C(sv.$$.fragment,f),C(d8.$$.fragment,f),C(Uv.$$.fragment,f),C(c8.$$.fragment,f),C(f8.$$.fragment,f),C(g8.$$.fragment,f),C(Yv.$$.fragment,f),C(h8.$$.fragment,f),C(eF.$$.fragment,f),C(p8.$$.fragment,f),C(_8.$$.fragment,f),C(b8.$$.fragment,f),C(rF.$$.fragment,f),C(v8.$$.fragment,f),C(_F.$$.fragment,f),C(F8.$$.fragment,f),C(T8.$$.fragment,f),C(E8.$$.fragment,f),C(bF.$$.fragment,f),C(C8.$$.fragment,f),C(TF.$$.fragment,f),C(w8.$$.fragment,f),C(A8.$$.fragment,f),C(y8.$$.fragment,f),C(EF.$$.fragment,f),C(x8.$$.fragment,f),C(AF.$$.fragment,f),C($8.$$.fragment,f),C(k8.$$.fragment,f),C(R8.$$.fragment,f),C(yF.$$.fragment,f),C(P8.$$.fragment,f),C(jF.$$.fragment,f),C(B8.$$.fragment,f),C(N8.$$.fragment,f),C(q8.$$.fragment,f),C(GF.$$.fragment,f),C(j8.$$.fragment,f),C(HF.$$.fragment,f),C(D8.$$.fragment,f),C(G8.$$.fragment,f),C(V8.$$.fragment,f),C(JF.$$.fragment,f),C(X8.$$.fragment,f),C(iT.$$.fragment,f),C(z8.$$.fragment,f),C(Q8.$$.fragment,f),C(H8.$$.fragment,f),C(cT.$$.fragment,f),C(U8.$$.fragment,f),C(hT.$$.fragment,f),C(Y8.$$.fragment,f),C(K8.$$.fragment,f),C(e9.$$.fragment,f),C(_T.$$.fragment,f),C(o9.$$.fragment,f),C(ET.$$.fragment,f),C(r9.$$.fragment,f),C(t9.$$.fragment,f),C(n9.$$.fragment,f),C(wT.$$.fragment,f),C(s9.$$.fragment,f),C($T.$$.fragment,f),C(l9.$$.fragment,f),C(i9.$$.fragment,f),C(c9.$$.fragment,f),C(ST.$$.fragment,f),C(f9.$$.fragment,f),C(NT.$$.fragment,f),C(g9.$$.fragment,f),C(h9.$$.fragment,f),C(_9.$$.fragment,f),C(qT.$$.fragment,f),C(u9.$$.fragment,f),C(GT.$$.fragment,f),C(b9.$$.fragment,f),C(v9.$$.fragment,f),C(T9.$$.fragment,f),C(VT.$$.fragment,f),C(M9.$$.fragment,f),C(UT.$$.fragment,f),C(E9.$$.fragment,f),C(C9.$$.fragment,f),C(A9.$$.fragment,f),C(YT.$$.fragment,f),C(L9.$$.fragment,f),C(eM.$$.fragment,f),C(y9.$$.fragment,f),C(x9.$$.fragment,f),C(k9.$$.fragment,f),C(rM.$$.fragment,f),C(S9.$$.fragment,f),C(YM.$$.fragment,f),C(R9.$$.fragment,f),C(P9.$$.fragment,f),C(N9.$$.fragment,f),C(ZM.$$.fragment,f),C(I9.$$.fragment,f),C(EE.$$.fragment,f),C(q9.$$.fragment,f),C(j9.$$.fragment,f),C(G9.$$.fragment,f),C(wE.$$.fragment,f),C(O9.$$.fragment,f),C(jE.$$.fragment,f),C(V9.$$.fragment,f),C(X9.$$.fragment,f),C(Q9.$$.fragment,f),C(GE.$$.fragment,f),C(W9.$$.fragment,f),C(HE.$$.fragment,f),C(H9.$$.fragment,f),C(U9.$$.fragment,f),C(Y9.$$.fragment,f),C(JE.$$.fragment,f),C(K9.$$.fragment,f),C(uC.$$.fragment,f),C(Z9.$$.fragment,f),C(ex.$$.fragment,f),C(rx.$$.fragment,f),C(vC.$$.fragment,f),C(tx.$$.fragment,f),C($C.$$.fragment,f),C(ax.$$.fragment,f),C(nx.$$.fragment,f),C(lx.$$.fragment,f),C(SC.$$.fragment,f),C(ix.$$.fragment,f),C(n3.$$.fragment,f),C(dx.$$.fragment,f),C(cx.$$.fragment,f),C(mx.$$.fragment,f),C(l3.$$.fragment,f),C(gx.$$.fragment,f),C(w3.$$.fragment,f),C(hx.$$.fragment,f),C(px.$$.fragment,f),C(ux.$$.fragment,f),C(L3.$$.fragment,f),C(bx.$$.fragment,f),C($3.$$.fragment,f),C(Fx.$$.fragment,f),C(Tx.$$.fragment,f),C(Ex.$$.fragment,f),C(S3.$$.fragment,f),C(Cx.$$.fragment,f),C(P3.$$.fragment,f),C(wx.$$.fragment,f),C(Ax.$$.fragment,f),C(yx.$$.fragment,f),C(N3.$$.fragment,f),C(xx.$$.fragment,f),C(t5.$$.fragment,f),C($x.$$.fragment,f),C(kx.$$.fragment,f),C(Rx.$$.fragment,f),C(n5.$$.fragment,f),C(Px.$$.fragment,f),C(A5.$$.fragment,f),C(Bx.$$.fragment,f),C(Nx.$$.fragment,f),C(qx.$$.fragment,f),C(y5.$$.fragment,f),C(jx.$$.fragment,f),C($5.$$.fragment,f),C(Dx.$$.fragment,f),C(Gx.$$.fragment,f),C(Vx.$$.fragment,f),C(S5.$$.fragment,f),C(Xx.$$.fragment,f),C(P5.$$.fragment,f),C(zx.$$.fragment,f),C(Qx.$$.fragment,f),C(Hx.$$.fragment,f),C(N5.$$.fragment,f),C(Ux.$$.fragment,f),C(c0.$$.fragment,f),C(Jx.$$.fragment,f),C(Yx.$$.fragment,f),C(Zx.$$.fragment,f),C(m0.$$.fragment,f),C(e$.$$.fragment,f),C(E0.$$.fragment,f),C(o$.$$.fragment,f),C(r$.$$.fragment,f),C(a$.$$.fragment,f),C(w0.$$.fragment,f),C(n$.$$.fragment,f),C(j0.$$.fragment,f),C(s$.$$.fragment,f),C(l$.$$.fragment,f),C(d$.$$.fragment,f),C(G0.$$.fragment,f),C(c$.$$.fragment,f),C(K0.$$.fragment,f),C(f$.$$.fragment,f),C(m$.$$.fragment,f),C(h$.$$.fragment,f),C(ew.$$.fragment,f),C(p$.$$.fragment,f),C(fw.$$.fragment,f),C(_$.$$.fragment,f),C(u$.$$.fragment,f),C(v$.$$.fragment,f),C(gw.$$.fragment,f),C(F$.$$.fragment,f),C(Cw.$$.fragment,f),C(T$.$$.fragment,f),C(M$.$$.fragment,f),C(C$.$$.fragment,f),C(Aw.$$.fragment,f),C(w$.$$.fragment,f),C(Iw.$$.fragment,f),C(A$.$$.fragment,f),C(L$.$$.fragment,f),C(x$.$$.fragment,f),C(jw.$$.fragment,f),C($$.$$.fragment,f),C(Hw.$$.fragment,f),C(k$.$$.fragment,f),C(S$.$$.fragment,f),C(P$.$$.fragment,f),C(Jw.$$.fragment,f),C(B$.$$.fragment,f),C(nA.$$.fragment,f),C(N$.$$.fragment,f),C(I$.$$.fragment,f),C(j$.$$.fragment,f),C(lA.$$.fragment,f),C(D$.$$.fragment,f),C(dA.$$.fragment,f),C(G$.$$.fragment,f),C(O$.$$.fragment,f),C(X$.$$.fragment,f),C(fA.$$.fragment,f),C(z$.$$.fragment,f),C(hA.$$.fragment,f),C(W$.$$.fragment,f),C(H$.$$.fragment,f),C(J$.$$.fragment,f),C(_A.$$.fragment,f),C(Y$.$$.fragment,f),C(bA.$$.fragment,f),XXe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(kf),f&&t(nt),f&&t(Oe),f&&t(Qe),f&&t(Rf),w(ka,f),f&&t(We),f&&t(Ae),f&&t(Co),f&&t(Sa),f&&t(jOe),f&&t(ki),w(OL),f&&t(DOe),f&&t(qn),f&&t(GOe),w(VL,f),f&&t(OOe),f&&t(MS),f&&t(VOe),w(Nf,f),f&&t(XOe),f&&t(Si),w(XL),f&&t(zOe),f&&t(wo),w(zL),w(HL),w(Qg),w(UL),f&&t(QOe),f&&t(Pi),w(JL),f&&t(WOe),f&&t(Ao),w(YL),w(ey),w(yh),w(oy),f&&t(HOe),f&&t(Bi),w(ry),f&&t(UOe),f&&t(Lo),w(ty),w(sy),w(cp),w(fp),w(ly),f&&t(JOe),f&&t(Ni),w(iy),f&&t(YOe),f&&t(yo),w(dy),w(my),w(Sp),w(Rp),w(gy),f&&t(KOe),f&&t(qi),w(hy),f&&t(ZOe),f&&t(xo),w(py),w(uy),w(Np),w(by),w(qu),f&&t(eVe),f&&t(Gi),w(vy),f&&t(oVe),f&&t($o),w(Fy),w(My),w(Du),w(Ey),w(S2),f&&t(rVe),f&&t(Xi),w(Cy),f&&t(tVe),f&&t(ko),w(wy),w(Ly),w(P2),w(yy),w(T1),f&&t(aVe),f&&t(Wi),w(xy),f&&t(nVe),f&&t(So),w($y),w(Sy),w(E1),w(Ry),w(i7),f&&t(sVe),f&&t(Ji),w(Py),f&&t(lVe),f&&t(Ro),w(By),w(Iy),w(c7),w(qy),w(x7),f&&t(iVe),f&&t(Zi),w(jy),f&&t(dVe),f&&t(Po),w(Dy),w(Oy),w(k7),w(Vy),w(y4),f&&t(cVe),f&&t(rd),w(Xy),f&&t(fVe),f&&t(Bo),w(zy),w(Wy),w($4),w(Hy),w(ib),f&&t(mVe),f&&t(nd),w(Uy),f&&t(gVe),f&&t(No),w(Jy),w(Ky),w(cb),w(Zy),w(bb),f&&t(hVe),f&&t(id),w(e8),f&&t(pVe),f&&t(qo),w(o8),w(t8),w(Fb),w(a8),w(av),f&&t(_Ve),f&&t(fd),w(n8),f&&t(uVe),f&&t(jo),w(s8),w(i8),w(sv),w(d8),w(Uv),f&&t(bVe),f&&t(hd),w(c8),f&&t(vVe),f&&t(Do),w(f8),w(g8),w(Yv),w(h8),w(eF),f&&t(FVe),f&&t(ud),w(p8),f&&t(TVe),f&&t(Go),w(_8),w(b8),w(rF),w(v8),w(_F),f&&t(MVe),f&&t(Fd),w(F8),f&&t(EVe),f&&t(Oo),w(T8),w(E8),w(bF),w(C8),w(TF),f&&t(CVe),f&&t(Ed),w(w8),f&&t(wVe),f&&t(Vo),w(A8),w(y8),w(EF),w(x8),w(AF),f&&t(AVe),f&&t(Ad),w($8),f&&t(LVe),f&&t(Xo),w(k8),w(R8),w(yF),w(P8),w(jF),f&&t(yVe),f&&t(xd),w(B8),f&&t(xVe),f&&t(zo),w(N8),w(q8),w(GF),w(j8),w(HF),f&&t($Ve),f&&t(Sd),w(D8),f&&t(kVe),f&&t(Qo),w(G8),w(V8),w(JF),w(X8),w(iT),f&&t(SVe),f&&t(Bd),w(z8),f&&t(RVe),f&&t(Wo),w(Q8),w(H8),w(cT),w(U8),w(hT),f&&t(PVe),f&&t(qd),w(Y8),f&&t(BVe),f&&t(Ho),w(K8),w(e9),w(_T),w(o9),w(ET),f&&t(NVe),f&&t(Gd),w(r9),f&&t(IVe),f&&t(Uo),w(t9),w(n9),w(wT),w(s9),w($T),f&&t(qVe),f&&t(zd),w(l9),f&&t(jVe),f&&t(Jo),w(i9),w(c9),w(ST),w(f9),w(NT),f&&t(DVe),f&&t(Hd),w(g9),f&&t(GVe),f&&t(Yo),w(h9),w(_9),w(qT),w(u9),w(GT),f&&t(OVe),f&&t(Yd),w(b9),f&&t(VVe),f&&t(Ko),w(v9),w(T9),w(VT),w(M9),w(UT),f&&t(XVe),f&&t(ec),w(E9),f&&t(zVe),f&&t(Zo),w(C9),w(A9),w(YT),w(L9),w(eM),f&&t(QVe),f&&t(tc),w(y9),f&&t(WVe),f&&t(er),w(x9),w(k9),w(rM),w(S9),w(YM),f&&t(HVe),f&&t(sc),w(R9),f&&t(UVe),f&&t(or),w(P9),w(N9),w(ZM),w(I9),w(EE),f&&t(JVe),f&&t(dc),w(q9),f&&t(YVe),f&&t(rr),w(j9),w(G9),w(wE),w(O9),w(jE),f&&t(KVe),f&&t(mc),w(V9),f&&t(ZVe),f&&t(tr),w(X9),w(Q9),w(GE),w(W9),w(HE),f&&t(eXe),f&&t(pc),w(H9),f&&t(oXe),f&&t(nr),w(U9),w(Y9),w(JE),w(K9),w(uC),f&&t(rXe),f&&t(bc),w(Z9),f&&t(tXe),f&&t(sr),w(ex),w(rx),w(vC),w(tx),w($C),f&&t(aXe),f&&t(Tc),w(ax),f&&t(nXe),f&&t(lr),w(nx),w(lx),w(SC),w(ix),w(n3),f&&t(sXe),f&&t(Cc),w(dx),f&&t(lXe),f&&t(ir),w(cx),w(mx),w(l3),w(gx),w(w3),f&&t(iXe),f&&t(Lc),w(hx),f&&t(dXe),f&&t(dr),w(px),w(ux),w(L3),w(bx),w($3),f&&t(cXe),f&&t($c),w(Fx),f&&t(fXe),f&&t(cr),w(Tx),w(Ex),w(S3),w(Cx),w(P3),f&&t(mXe),f&&t(Rc),w(wx),f&&t(gXe),f&&t(fr),w(Ax),w(yx),w(N3),w(xx),w(t5),f&&t(hXe),f&&t(Nc),w($x),f&&t(pXe),f&&t(mr),w(kx),w(Rx),w(n5),w(Px),w(A5),f&&t(_Xe),f&&t(jc),w(Bx),f&&t(uXe),f&&t(gr),w(Nx),w(qx),w(y5),w(jx),w($5),f&&t(bXe),f&&t(Oc),w(Dx),f&&t(vXe),f&&t(hr),w(Gx),w(Vx),w(S5),w(Xx),w(P5),f&&t(FXe),f&&t(zc),w(zx),f&&t(TXe),f&&t(pr),w(Qx),w(Hx),w(N5),w(Ux),w(c0),f&&t(MXe),f&&t(Hc),w(Jx),f&&t(EXe),f&&t(_r),w(Yx),w(Zx),w(m0),w(e$),w(E0),f&&t(CXe),f&&t(Yc),w(o$),f&&t(wXe),f&&t(ur),w(r$),w(a$),w(w0),w(n$),w(j0),f&&t(AXe),f&&t(ef),w(s$),f&&t(LXe),f&&t(br),w(l$),w(d$),w(G0),w(c$),w(K0),f&&t(yXe),f&&t(tf),w(f$),f&&t(xXe),f&&t(vr),w(m$),w(h$),w(ew),w(p$),w(fw),f&&t($Xe),f&&t(sf),w(_$),f&&t(kXe),f&&t(Fr),w(u$),w(v$),w(gw),w(F$),w(Cw),f&&t(SXe),f&&t(cf),w(T$),f&&t(RXe),f&&t(Tr),w(M$),w(C$),w(Aw),w(w$),w(Iw),f&&t(PXe),f&&t(gf),w(A$),f&&t(BXe),f&&t(Mr),w(L$),w(x$),w(jw),w($$),w(Hw),f&&t(NXe),f&&t(_f),w(k$),f&&t(IXe),f&&t(Er),w(S$),w(P$),w(Jw),w(B$),w(nA),f&&t(qXe),f&&t(vf),w(N$),f&&t(jXe),f&&t(Cr),w(I$),w(j$),w(lA),w(D$),w(dA),f&&t(DXe),f&&t(Mf),w(G$),f&&t(GXe),f&&t(wr),w(O$),w(X$),w(fA),w(z$),w(hA),f&&t(OXe),f&&t(wf),w(W$),f&&t(VXe),f&&t(Ar),w(H$),w(J$),w(_A),w(Y$),w(bA)}}}const gzt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function hzt($){return mVt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Tzt extends iVt{constructor(g){super();dVt(this,g,hzt,mzt,cVt,{})}}export{Tzt as default,gzt as metadata};
